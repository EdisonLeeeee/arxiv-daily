[
  {
    "id": "arXiv:2211.10443",
    "title": "Social media mining for toxicovigilance of prescription medications:  End-to-end pipeline, challenges and future work",
    "abstract": "Substance use, substance use disorder, and overdoses related to substance use\nare major public health problems globally and in the United States. A key\naspect of addressing these problems from a public health standpoint is improved\nsurveillance. Traditional surveillance systems are laggy, and social media are\npotentially useful sources of timely data. However, mining knowledge from\nsocial media is challenging, and requires the development of advanced\nartificial intelligence, specifically natural language processing (NLP) and\nmachine learning methods. We developed a sophisticated end-to-end pipeline for\nmining information about nonmedical prescription medication use from social\nmedia, namely Twitter and Reddit. Our pipeline employs supervised machine\nlearning and NLP for filtering out noise and characterizing the chatter. In\nthis paper, we describe our end-to-end pipeline developed over four years. In\naddition to describing our data mining infrastructure, we discuss existing\nchallenges in social media mining for toxicovigilance, and possible future\nresearch directions.",
    "descriptor": "",
    "authors": [
      "Abeed Sarker"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10443"
  },
  {
    "id": "arXiv:2211.10445",
    "title": "Building a Subspace of Policies for Scalable Continual Learning",
    "abstract": "The ability to continuously acquire new knowledge and skills is crucial for\nautonomous agents. Existing methods are typically based on either fixed-size\nmodels that struggle to learn a large number of diverse behaviors, or\ngrowing-size models that scale poorly with the number of tasks. In this work,\nwe aim to strike a better balance between an agent's size and performance by\ndesigning a method that grows adaptively depending on the task sequence. We\nintroduce Continual Subspace of Policies (CSP), a new approach that\nincrementally builds a subspace of policies for training a reinforcement\nlearning agent on a sequence of tasks. The subspace's high expressivity allows\nCSP to perform well for many different tasks while growing sublinearly with the\nnumber of tasks. Our method does not suffer from forgetting and displays\npositive transfer to new tasks. CSP outperforms a number of popular baselines\non a wide range of scenarios from two challenging domains, Brax (locomotion)\nand Continual World (manipulation).",
    "descriptor": "",
    "authors": [
      "Jean-Baptiste Gaya",
      "Thang Doan",
      "Lucas Caccia",
      "Laure Soulier",
      "Ludovic Denoyer",
      "Roberta Raileanu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10445"
  },
  {
    "id": "arXiv:2211.10446",
    "title": "Discovering Locally Maximal Bipartite Subgraphs",
    "abstract": "Induced bipartite subgraphs of maximal vertex cardinality are an essential\nconcept for the analysis of graphs. Yet, discovering them in large graphs is\nknown to be computationally hard. Therefore, we consider in this work a weaker\nnotion of this problem, where we discard the maximality constraint in favor of\ninclusion maximality. Thus, we aim to discover locally maximal bipartite\nsubgraphs. For this, we present three heuristic approaches to extract such\nsubgraphs and compare their results to the solutions of the global problem. For\nthe latter, we employ the algorithmic strength of fast SAT-solvers. Our three\nproposed heuristics are based on a greedy strategy, a simulated annealing\napproach, and a genetic algorithm, respectively. We evaluate all four\nalgorithms with respect to their time requirement and the vertex cardinality of\nthe discovered bipartite subgraphs on several benchmark datasets",
    "descriptor": "\nComments: 12 pages, 3 figures, 3 tables\n",
    "authors": [
      "Dominik D\u00fcrrschnabel",
      "Tom Hanika",
      "Gerd Stumme"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.10446"
  },
  {
    "id": "arXiv:2211.10459",
    "title": "A Unified Framework for Quantifying Privacy Risk in Synthetic Data",
    "abstract": "Synthetic data is often presented as a method for sharing sensitive\ninformation in a privacy-preserving manner by reproducing the global\nstatistical properties of the original data without disclosing sensitive\ninformation about any individual. In practice, as with other anonymization\nmethods, privacy risks cannot be entirely eliminated. The residual privacy\nrisks need instead to be ex-post assessed. We present Anonymeter, a statistical\nframework to jointly quantify different types of privacy risks in synthetic\ntabular datasets. We equip this framework with attack-based evaluations for the\nsingling out, linkability, and inference risks, the three key indicators of\nfactual anonymization according to the European General Data Protection\nRegulation (GDPR). To the best of our knowledge, we are the first to introduce\na coherent and legally aligned evaluation of these three privacy risks for\nsynthetic data, and to design privacy attacks which model directly the singling\nout and linkability risks. We demonstrate the effectiveness of our methods by\nconducting an extensive set of experiments that measure the privacy risks of\ndata with deliberately inserted privacy leakages, and of synthetic data\ngenerated with and without differential privacy. Our results highlight that the\nthree privacy risks reported by our framework scale linearly with the amount of\nprivacy leakage in the data. Furthermore, we observe that synthetic data\nexhibits the lowest vulnerability against linkability, indicating one-to-one\nrelationships between real and synthetic data records are not preserved.\nFinally, we demonstrate quantitatively that Anonymeter outperforms existing\nsynthetic data privacy evaluation frameworks both in terms of detecting privacy\nleaks, as well as computation speed. To contribute to a privacy-conscious usage\nof synthetic data, we open source Anonymeter at\nhttps://github.com/statice/anonymeter.",
    "descriptor": "",
    "authors": [
      "Matteo Giomi",
      "Franziska Boenisch",
      "Christoph Wehmeyer",
      "Borb\u00e1la Tasn\u00e1di"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.10459"
  },
  {
    "id": "arXiv:2211.10460",
    "title": "Knowledge Graph Refinement based on Triplet BERT-Networks",
    "abstract": "Knowledge graph embedding techniques are widely used for knowledge graph\nrefinement tasks such as graph completion and triple classification. These\ntechniques aim at embedding the entities and relations of a Knowledge Graph\n(KG) in a low dimensional continuous feature space. This paper adopts a\ntransformer-based triplet network creating an embedding space that clusters the\ninformation about an entity or relation in the KG. It creates textual sequences\nfrom facts and fine-tunes a triplet network of pre-trained transformer-based\nlanguage models. It adheres to an evaluation paradigm that relies on an\nefficient spatial semantic search technique. We show that this evaluation\nprotocol is more adapted to a few-shot setting for the relation prediction\ntask. Our proposed GilBERT method is evaluated on triplet classification and\nrelation prediction tasks on multiple well-known benchmark knowledge graphs\nsuch as FB13, WN11, and FB15K. We show that GilBERT achieves better or\ncomparable results to the state-of-the-art performance on these two refinement\ntasks.",
    "descriptor": "\nComments: Accepted and presented at the DeepOntoNLP Workshop of the ESWC 2022 conference\n",
    "authors": [
      "Armita Khajeh Nassiri",
      "Nathalie Pernelle",
      "Fatiha Sais",
      "Gianluca Quercini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10460"
  },
  {
    "id": "arXiv:2211.10469",
    "title": "Hub-VAE: Unsupervised Hub-based Regularization of Variational  Autoencoders",
    "abstract": "Exemplar-based methods rely on informative data points or prototypes to guide\nthe optimization of learning algorithms. Such data facilitate interpretable\nmodel design and prediction. Of particular interest is the utility of exemplars\nin learning unsupervised deep representations. In this paper, we leverage hubs,\nwhich emerge as frequent neighbors in high-dimensional spaces, as exemplars to\nregularize a variational autoencoder and to learn a discriminative embedding\nfor unsupervised down-stream tasks. We propose an unsupervised, data-driven\nregularization of the latent space with a mixture of hub-based priors and a\nhub-based contrastive loss. Experimental evaluation shows that our algorithm\nachieves superior cluster separability in the embedding space, and accurate\ndata reconstruction and generation, compared to baselines and state-of-the-art\ntechniques.",
    "descriptor": "",
    "authors": [
      "Priya Mani",
      "Carlotta Domeniconi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10469"
  },
  {
    "id": "arXiv:2211.10470",
    "title": "A mixed-reality dataset for category-level 6D pose and size estimation  of hand-occluded containers",
    "abstract": "Estimating the 6D pose and size of household containers is challenging due to\nlarge intra-class variations in the object properties, such as shape, size,\nappearance, and transparency. The task is made more difficult when these\nobjects are held and manipulated by a person due to varying degrees of hand\nocclusions caused by the type of grasps and by the viewpoint of the camera\nobserving the person holding the object. In this paper, we present a\nmixed-reality dataset of hand-occluded containers for category-level 6D object\npose and size estimation. The dataset consists of 138,240 images of rendered\nhands and forearms holding 48 synthetic objects, split into 3 grasp categories\nover 30 real backgrounds. We re-train and test an existing model for 6D object\npose estimation on our mixed-reality dataset. We discuss the impact of the use\nof this dataset in improving the task of 6D pose and size estimation.",
    "descriptor": "\nComments: 5 pages, 4 figures, 1 table. Submitted to IEEE ICASSP 2023. Webpage at this https URL\n",
    "authors": [
      "Xavier Weber",
      "Alessio Xompero",
      "Andrea Cavallaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10470"
  },
  {
    "id": "arXiv:2211.10471",
    "title": "Prophet-Inequalities over Time",
    "abstract": "In this paper, we introduce an over-time variant of the well-known\nprophet-inequality with i.i.d. random variables. Instead of stopping with one\nrealized value at some point in the process, we decide for each step how long\nwe select the value. Then we cannot select another value until this period is\nover. The goal is to maximize the expectation of the sum of selected values. We\ndescribe the structure of the optimal stopping rule and give upper and lower\nbounds on the prophet-inequality. - Which, in online algorithms terminology,\ncorresponds to bounds on the competitive ratio of an online algorithm.\nWe give a surprisingly simple algorithm with a single threshold that results\nin a prophet-inequality of $\\approx 0.396$ for all input lengths $n$.\nAdditionally, as our main result, we present a more advanced algorithm\nresulting in a prophet-inequality of $\\approx 0.598$ when the number of steps\ntends to infinity. We complement our results by an upper bound that shows that\nthe best possible prophet-inequality is at most $1/\\varphi \\approx 0.618$,\nwhere $\\varphi$ denotes the golden ratio. As part of the proof, we give an\nadvanced bound on the weighted mediant.",
    "descriptor": "",
    "authors": [
      "Andreas Abels",
      "Elias Pitschmann",
      "Daniel Schmand"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.10471"
  },
  {
    "id": "arXiv:2211.10473",
    "title": "Dynamic Interactional And Cooperative Network For Shield Machine",
    "abstract": "The shield machine (SM) is a complex mechanical device used for tunneling.\nHowever, the monitoring and deciding were mainly done by artificial experience\nduring traditional construction, which brought some limitations, such as hidden\nmechanical failures, human operator error, and sensor anomalies. To deal with\nthese challenges, many scholars have studied SM intelligent methods. Most of\nthese methods only take SM into account but do not consider the SM operating\nenvironment. So, this paper discussed the relationship among SM, geological\ninformation, and control terminals. Then, according to the relationship, models\nwere established for the control terminal, including SM rate prediction and SM\nanomaly detection. The experimental results show that compared with baseline\nmodels, the proposed models in this paper perform better. In the proposed\nmodel, the R2 and MSE of rate prediction can reach 92.2\\%, and 0.0064\nrespectively. The abnormal detection rate of anomaly detection is up to 98.2\\%.",
    "descriptor": "",
    "authors": [
      "Dazhi Gao",
      "Rongyang Li",
      "Hongbo Wang",
      "Lingfeng Mao",
      "Huansheng Ning"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.10473"
  },
  {
    "id": "arXiv:2211.10476",
    "title": "System architecture of a four-wheel drive Formula Student vehicle",
    "abstract": "Formula Student vehicles are becoming increasingly complex, especially with\nthe current shift from internal combustion engines toward electric powertrains.\nThe interaction between software and hardware is complex and imposes additional\nchallenges for systems integration. This paper provides a structured\nintroduction to the OBR22 Oxford Brookes Racing Formula Student electric\nvehicle. From a system architecture perspective, the four-wheel drive in-hub\nmotors topology is described. Diagrams of the hardware components, the\narchitecture of the high voltage and communication systems are presented. This\npaper also demonstrates the model-based development process, including an\noverview of the model-in-the-loop (MiL) and hardware-in-the-loop (HiL) control\ndesign phases.",
    "descriptor": "\nComments: 11 pages, 8 figures\n",
    "authors": [
      "Adriano Schommer",
      "Gordana Collier",
      "Robert Norris",
      "Denise Morrey",
      "Ludmila Nesi Maria",
      "Chris Johnston"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.10476"
  },
  {
    "id": "arXiv:2211.10480",
    "title": "ACIC: Admission-Controlled Instruction Cache",
    "abstract": "The front end bottleneck in datacenter workloads has come under increased\nscrutiny, with the growing code footprint, involvement of numerous libraries\nand OS services, and the unpredictability in the instruction stream. Our\nexamination of these workloads points to burstiness in accesses to instruction\nblocks, which has also been observed in data accesses. Such burstiness is\nlargely due to spatial and short-duration temporal localities, that LRU fails\nto recognize and optimize for, when a single cache caters to both forms of\nlocality. Instead, we incorporate a small i-Filter as in previous works to\nseparate spatial from temporal accesses. However, a simple separation does not\nsuffice, and we additionally need to predict whether the block will continue to\nhave temporal locality, after the burst of spatial locality. This combination\nof i-Filter and temporal locality predictor constitutes our\nAdmission-Controlled Instruction Cache (ACIC). ACIC outperforms a number of\nstate-of-the-art pollution reduction techniques (replacement algorithms,\nbypassing mechanisms, victim caches), providing 1.0223 speedup on the average\nover a baseline LRU based conventional i-cache (bridging over half of the gap\nbetween LRU and OPT) across several datacenter workloads.",
    "descriptor": "",
    "authors": [
      "Yunjin Wang",
      "Chia-Hao Chang",
      "Anand Sivasubramaniam",
      "Niranjan Soundararajan"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.10480"
  },
  {
    "id": "arXiv:2211.10482",
    "title": "Compiling Structured Tensor Algebra",
    "abstract": "Tensor algebra is essential for data-intensive workloads in various\ncomputational domains. Computational scientists face a trade-off between the\nspecialization degree provided by dense tensor algebra and the algorithmic\nefficiency that leverages the structure provided by sparse tensors. This paper\npresents StructTensor, a framework that symbolically computes structure at\ncompilation time. This is enabled by Structured Tensor Unified Representation\n(STUR), an intermediate language that can capture tensor computations as well\nas their sparsity and redundancy structures. Through a mathematical view of\nlossless tensor computations, we show that our symbolic structure computation\nand the related optimizations are sound. Finally, for different tensor\ncomputation workloads and structures, we experimentally show how capturing the\nsymbolic structure can result in outperforming state-of-the-art frameworks for\nboth dense and sparse tensor algebra.",
    "descriptor": "",
    "authors": [
      "Mahdi Ghorbani",
      "Mathieu Huot",
      "Shideh Hashemian",
      "Amir Shaikhha"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Mathematical Software (cs.MS)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2211.10482"
  },
  {
    "id": "arXiv:2211.10486",
    "title": "DGRec: Graph Neural Network for Recommendation with Diversified  Embedding Generation",
    "abstract": "Graph Neural Network (GNN) based recommender systems have been attracting\nmore and more attention in recent years due to their excellent performance in\naccuracy. Representing user-item interactions as a bipartite graph, a GNN model\ngenerates user and item representations by aggregating embeddings of their\nneighbors. However, such an aggregation procedure often accumulates information\npurely based on the graph structure, overlooking the redundancy of the\naggregated neighbors and resulting in poor diversity of the recommended list.\nIn this paper, we propose diversifying GNN-based recommender systems by\ndirectly improving the embedding generation procedure. Particularly, we utilize\nthe following three modules: submodular neighbor selection to find a subset of\ndiverse neighbors to aggregate for each GNN node, layer attention to assign\nattention weights for each layer, and loss reweighting to focus on the learning\nof items belonging to long-tail categories. Blending the three modules into\nGNN, we present DGRec(Diversified GNN-based Recommender System) for diversified\nrecommendation. Experiments on real-world datasets demonstrate that the\nproposed method can achieve the best diversity while keeping the accuracy\ncomparable to state-of-the-art GNN-based recommender systems.",
    "descriptor": "\nComments: 10 pages, WSDM 2023\n",
    "authors": [
      "Liangwei Yang",
      "Shengjie Wang",
      "Yunzhe Tao",
      "Jiankai Sun",
      "Xiaolong Liu",
      "Philip S. Yu",
      "Taiqing Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.10486"
  },
  {
    "id": "arXiv:2211.10495",
    "title": "A DPU Solution for Container Overlay Networks",
    "abstract": "There is an increasing demand to incorporate hybrid environments as part of\nworkflows across edge, cloud, and HPC systems. In a such converging environment\nof cloud and HPC, containers are starting to play a more prominent role,\nbringing their networking infrastructure along with them. However, the current\nbody of work shows that container overlay networks, which are often used to\nconnect containers across physical hosts, are ill-suited for the HPC\nenvironment. They tend to impose significant overhead and noise, resulting in\ndegraded performance and disturbance to co-processes on the same host. This\npaper focuses on utilizing a novel class of hardware, Data Processing Unit, to\noffload the networking stack of overlay networks away from the host onto the\nDPU. We intend to show that such ancillary offload is possible and that it will\nresult in decreased overhead on host nodes which in turn will improve the\nperformance of running processes.",
    "descriptor": "\nComments: Pre-print version presented at SuperCompCloud workshop at SC22 conference\n",
    "authors": [
      "Anton Njavro",
      "James Tau",
      "Taylor Groves",
      "Nicholas J. Wright",
      "Richard West"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.10495"
  },
  {
    "id": "arXiv:2211.10506",
    "title": "A Transformer Framework for Data Fusion and Multi-Task Learning in Smart  Cities",
    "abstract": "Rapid global urbanization is a double-edged sword, heralding promises of\neconomical prosperity and public health while also posing unique environmental\nand humanitarian challenges. Smart and connected communities (S&CCs) apply\ndata-centric solutions to these problems by integrating artificial intelligence\n(AI) and the Internet of Things (IoT). This coupling of intelligent\ntechnologies also poses interesting system design challenges regarding\nheterogeneous data fusion and task diversity. Transformers are of particular\ninterest to address these problems, given their success across diverse fields\nof natural language processing (NLP), computer vision, time-series regression,\nand multi-modal data fusion. This begs the question whether Transformers can be\nfurther diversified to leverage fusions of IoT data sources for heterogeneous\nmulti-task learning in S&CC trade spaces. In this paper, a Transformer-based AI\nsystem for emerging smart cities is proposed. Designed using a pure encoder\nbackbone, and further customized through interchangeable input embedding and\noutput task heads, the system supports virtually any input data and output task\ntypes present S&CCs. This generalizability is demonstrated through learning\ndiverse task sets representative of S&CC environments, including multivariate\ntime-series regression, visual plant disease classification, and\nimage-time-series fusion tasks using a combination of Beijing PM2.5 and Plant\nVillage datasets. Simulation results show that the proposed Transformer-based\nsystem can handle various input data types via custom sequence embedding\ntechniques, and are naturally suited to learning a diverse set of tasks. The\nresults also show that multi-task learners increase both memory and\ncomputational efficiency while maintaining comparable performance to both\nsingle-task variants, and non-Transformer baselines.",
    "descriptor": "\nComments: 14 pages, 10 figures, 3 tables\n",
    "authors": [
      "Alexander C. DeRieux",
      "Walid Saad",
      "Wangda Zuo",
      "Rachmawan Budiarto",
      "Mochamad Donny Koerniawan",
      "Dwi Novitasari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10506"
  },
  {
    "id": "arXiv:2211.10507",
    "title": "Efficient Determinant Maximization for All Matroids",
    "abstract": "Determinant maximization provides an elegant generalization of problems in\nmany areas, including convex geometry, statistics, machine learning, fair\nallocation of goods, and network design. In an instance of the determinant\nmaximization problem, we are given a collection of vectors $v_1,\\ldots, v_n \\in\n\\mathbb{R}^d$, and the goal is to pick a subset $S\\subseteq [n]$ of given\nvectors to maximize the determinant of the matrix $\\sum_{i \\in S} v_iv_i^\\top$,\nwhere the picked set of vectors $S$ must satisfy some combinatorial constraint\nsuch as cardinality constraint ($|S| \\leq k$) or matroid constraint ($S$ is a\nbasis of a matroid defined on $[n]$).\nIn this work, we give a combinatorial algorithm for the determinant\nmaximization problem under a matroid constraint that achieves\n$O(d^{O(d)})$-approximation for any matroid of rank $r\\geq d$. This complements\nthe recent result of~\\cite{BrownLPST22} that achieves a similar bound for\nmatroids of rank $r\\leq d$, relying on a geometric interpretation of the\ndeterminant. Our result matches the best-known estimation\nalgorithms~\\cite{madan2020maximizing} for the problem, which could estimate the\nobjective value but could not give an approximate solution with a similar\nguarantee. Our work follows the framework developed by~\\cite{BrownLPST22} of\nusing matroid intersection based algorithms for determinant maximization. To\novercome the lack of a simple geometric interpretation of the objective when $r\n\\geq d$, our approach combines ideas from combinatorial optimization with\nalgebraic properties of the determinant. We also critically use the properties\nof a convex programming relaxation of the problem introduced\nby~\\cite{madan2020maximizing}.",
    "descriptor": "",
    "authors": [
      "Adam Brown",
      "Aditi Laddha",
      "Madhusudhan Pittu",
      "Mohit Singh"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.10507"
  },
  {
    "id": "arXiv:2211.10511",
    "title": "Knowledge Graph Generation From Text",
    "abstract": "In this work we propose a novel end-to-end multi-stage Knowledge Graph (KG)\ngeneration system from textual inputs, separating the overall process into two\nstages. The graph nodes are generated first using pretrained language model,\nfollowed by a simple edge construction head, enabling efficient KG extraction\nfrom the text. For each stage we consider several architectural choices that\ncan be used depending on the available training resources. We evaluated the\nmodel on a recent WebNLG 2020 Challenge dataset, matching the state-of-the-art\nperformance on text-to-RDF generation task, as well as on New York Times (NYT)\nand a large-scale TekGen datasets, showing strong overall performance,\noutperforming the existing baselines. We believe that the proposed system can\nserve as a viable KG construction alternative to the existing linearization or\nsampling-based graph generation approaches. Our code can be found at\nhttps://github.com/IBM/Grapher",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Igor Melnyk",
      "Pierre Dognin",
      "Payel Das"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10511"
  },
  {
    "id": "arXiv:2211.10516",
    "title": "PIM-tree: A Skew-resistant Index for Processing-in-Memory",
    "abstract": "The performance of today's in-memory indexes is bottlenecked by the memory\nlatency/bandwidth wall. Processing-in-memory (PIM) is an emerging approach that\npotentially mitigates this bottleneck, by enabling low-latency memory access\nwhose aggregate memory bandwidth scales with the number of PIM nodes. There is\nan inherent tension, however, between minimizing inter-node communication and\nachieving load balance in PIM systems, in the presence of workload skew. This\npaper presents PIM-tree, an ordered index for PIM systems that achieves both\nlow communication and high load balance, regardless of the degree of skew in\nthe data and the queries. Our skew-resistant index is based on a novel division\nof labor between the multi-core host CPU and the PIM nodes, which leverages the\nstrengths of each. We introduce push-pull search, which dynamically decides\nwhether to push queries to a PIM-tree node (CPU -> PIM-node) or pull the node's\nkeys back to the CPU (PIM-node -> CPU) based on workload skew. Combined with\nother PIM-friendly optimizations (shadow subtrees and chunked skip lists), our\nPIM-tree provides high-throughput, (guaranteed) low communication, and\n(guaranteed) high load balance, for batches of point queries, updates, and\nrange scans.\nWe implement the PIM-tree structure, in addition to prior proposed PIM\nindexes, on the latest PIM system from UPMEM, with 32 CPU cores and 2048 PIM\nnodes. On workloads with 500 million keys and batches of one million queries,\nthe throughput using PIM-trees is up to 69.7x and 59.1x higher than the two\nbest prior methods. As far as we know these are the first implementations of an\nordered index on a real PIM system.",
    "descriptor": "",
    "authors": [
      "Hongbo Kang",
      "Yiwei Zhao",
      "Guy E. Blelloch",
      "Laxman Dhulipala",
      "Yan Gu",
      "Charles McGuffey",
      "Phillip B. Gibbons"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2211.10516"
  },
  {
    "id": "arXiv:2211.10517",
    "title": "Social Diversity Reduces the Complexity and Cost of Fostering Fairness",
    "abstract": "Institutions and investors are constantly faced with the challenge of\nappropriately distributing endowments. No budget is limitless and optimising\noverall spending without sacrificing positive outcomes has been approached and\nresolved using several heuristics. To date, prior works have failed to consider\nhow to encourage fairness in a population where social diversity is ubiquitous,\nand in which investors can only partially observe the population. Herein, by\nincorporating social diversity in the Ultimatum game through heterogeneous\ngraphs, we investigate the effects of several interference mechanisms which\nassume incomplete information and flexible standards of fairness. We quantify\nthe role of diversity and show how it reduces the need for information\ngathering, allowing us to relax a strict, costly interference process.\nFurthermore, we find that the influence of certain individuals, expressed by\ndifferent network centrality measures, can be exploited to further reduce\nspending if minimal fairness requirements are lowered. Our results indicate\nthat diversity changes and opens up novel mechanisms available to institutions\nwishing to promote fairness. Overall, our analysis provides novel insights to\nguide institutional policies in socially diverse complex systems.",
    "descriptor": "",
    "authors": [
      "Theodor Cimpeanu",
      "Alessandro Di Stefano",
      "Cedric Perret",
      "Anh Han"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2211.10517"
  },
  {
    "id": "arXiv:2211.10524",
    "title": "Analysis of Reinforcement Learning Schemes for Trajectory Optimization  of an Aerial Radio Unit",
    "abstract": "This paper introduces the deployment of unmanned aerial vehicles (UAVs) as\nlightweight wireless access points that leverage the fixed infrastructure in\nthe context of the emerging open radio access network (O-RAN). More precisely,\nwe propose an aerial radio unit that dynamically serves an under served area\nand connects to the distributed unit via a wireless fronthaul between the UAV\nand the closest tower. In this paper we analyze the UAV trajectory in terms of\nartificial intelligence (AI) when it serves both UEs and central units (CUs) at\nthe same time in multi input multi output (MIMO) fading channel. We first\ndemonstrate the nonconvexity of the problem of maximizing the overall network\nthroughput based on UAV location, and then we use two different machine\nlearning approaches to solve it. We first assume that the environment is a\ngridworld and then let the UAV explore the environment by flying from point A\nto point B, using both the offline Q-learning and the online SARSA algorithm\nand the achieved path-loss as the reward. With the intention of maximizing the\naverage payoff, the trajectory in the second scenario is described as a Markov\ndecision process (MDP). According to simulations, MDP produces better results\nin a smaller setting and in less time. In contrast, SARSA performs better in\nlarger environments at the expense of a longer flight duration.",
    "descriptor": "\nComments: 6 pages, 7 figures, 1 table\n",
    "authors": [
      "Hossein Mohammadi",
      "Vuk Marojevic",
      "Bodong Shang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.10524"
  },
  {
    "id": "arXiv:2211.10526",
    "title": "Castling-ViT: Compressing Self-Attention via Switching Towards  Linear-Angular Attention During Vision Transformer Inference",
    "abstract": "Vision Transformers (ViTs) have shown impressive performance but still\nrequire a high computation cost as compared to convolutional neural networks\n(CNNs), due to the global similarity measurements and thus a quadratic\ncomplexity with the input tokens. Existing efficient ViTs adopt local attention\n(e.g., Swin) or linear attention (e.g., Performer), which sacrifice ViTs'\ncapabilities of capturing either global or local context. In this work, we ask\nan important research question: Can ViTs learn both global and local context\nwhile being more efficient during inference? To this end, we propose a\nframework called Castling-ViT, which trains ViTs using both linear-angular\nattention and masked softmax-based quadratic attention, but then switches to\nhaving only linear angular attention during ViT inference. Our Castling-ViT\nleverages angular kernels to measure the similarities between queries and keys\nvia spectral angles. And we further simplify it with two techniques: (1) a\nnovel linear-angular attention mechanism: we decompose the angular kernels into\nlinear terms and high-order residuals, and only keep the linear terms; and (2)\nwe adopt two parameterized modules to approximate high-order residuals: a\ndepthwise convolution and an auxiliary masked softmax attention to help learn\nboth global and local information, where the masks for softmax attention are\nregularized to gradually become zeros and thus incur no overhead during ViT\ninference. Extensive experiments and ablation studies on three tasks\nconsistently validate the effectiveness of the proposed Castling-ViT, e.g.,\nachieving up to a 1.8% higher accuracy or 40% MACs reduction on ImageNet\nclassification and 1.2 higher mAP on COCO detection under comparable FLOPs, as\ncompared to ViTs with vanilla softmax-based attentions.",
    "descriptor": "",
    "authors": [
      "Haoran You",
      "Yunyang Xiong",
      "Xiaoliang Dai",
      "Bichen Wu",
      "Peizhao Zhang",
      "Haoqi Fan",
      "Peter Vajda",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10526"
  },
  {
    "id": "arXiv:2211.10527",
    "title": "PMNet: Robust Pathloss Map Prediction via Supervised Learning",
    "abstract": "Pathloss prediction is an essential component of wireless network planning.\nWhile ray-tracing based methods have been successfully used for many years,\nthey require significant computational effort that may become prohibitive with\nthe increased network densification and/or use of higher frequencies in 5G/B5G\n(beyond 5 G) systems. In this paper, we propose and evaluate a data-driven and\nmodel-free pathloss prediction method, dubbed PMNet. This method uses a\nsupervised learning approach: training a neural network (NN) with a limited\namount of ray tracing (or channel measurement) data and map data and then\npredicting the pathloss over location with no ray tracing data with a high\nlevel of accuracy. Our proposed pathloss map prediction-oriented NN\narchitecture, which is empowered by state-of-the-art computer vision\ntechniques, outperforms other architectures that have been previously proposed\n(e.g., UNet, RadioUNet) in terms of accuracy while showing generalization\ncapability. Moreover, PMNet trained on a 4-fold smaller dataset surpasses the\nother baselines (trained on a 4-fold larger dataset), corroborating the\npotential of PMNet.",
    "descriptor": "",
    "authors": [
      "Ju-Hyung Lee",
      "Omer Gokalp Serbetci",
      "Dheeraj Panneer Selvam",
      "Andreas F. Molisch"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.10527"
  },
  {
    "id": "arXiv:2211.10528",
    "title": "Where is my Wallet? Modeling Object Proposal Sets for Egocentric Visual  Query Localization",
    "abstract": "This paper deals with the problem of localizing objects in image and video\ndatasets from visual exemplars. In particular, we focus on the challenging\nproblem of egocentric visual query localization. We first identify grave\nimplicit biases in current query-conditioned model design and visual query\ndatasets. Then, we directly tackle such biases at both frame and object set\nlevels. Concretely, our method solves these issues by expanding limited\nannotations and dynamically dropping object proposals during training.\nAdditionally, we propose a novel transformer-based module that allows for\nobject-proposal set context to be considered while incorporating query\ninformation. We name our module Conditioned Contextual Transformer or\nCocoFormer. Our experiments show the proposed adaptations improve egocentric\nquery detection, leading to a better visual query localization system in both\n2D and 3D configurations. Thus, we are able to improve frame-level detection\nperformance from 26.28% to 31.26 in AP, which correspondingly improves the VQ2D\nand VQ3D localization scores by significant margins. Our improved context-aware\nquery object detector ranked first and second in the VQ2D and VQ3D tasks in the\n2nd Ego4D challenge. In addition to this, we showcase the relevance of our\nproposed model in the Few-Shot Detection (FSD) task, where we also achieve SOTA\nresults. Our code is available at\nhttps://github.com/facebookresearch/vq2d_cvpr.",
    "descriptor": "\nComments: We ranked first and second in the VQ2D and VQ3D tasks in the 2nd Ego4D challenge\n",
    "authors": [
      "Mengmeng Xu",
      "Yanghao Li",
      "Cheng-Yang Fu",
      "Bernard Ghanem",
      "Tao Xiang",
      "Juan-Manuel Perez-Rua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10528"
  },
  {
    "id": "arXiv:2211.10530",
    "title": "Provable Defense against Backdoor Policies in Reinforcement Learning",
    "abstract": "We propose a provable defense mechanism against backdoor policies in\nreinforcement learning under subspace trigger assumption. A backdoor policy is\na security threat where an adversary publishes a seemingly well-behaved policy\nwhich in fact allows hidden triggers. During deployment, the adversary can\nmodify observed states in a particular way to trigger unexpected actions and\nharm the agent. We assume the agent does not have the resources to re-train a\ngood policy. Instead, our defense mechanism sanitizes the backdoor policy by\nprojecting observed states to a 'safe subspace', estimated from a small number\nof interactions with a clean (non-triggered) environment. Our sanitized policy\nachieves $\\epsilon$ approximate optimality in the presence of triggers,\nprovided the number of clean interactions is $O\\left(\\frac{D}{(1-\\gamma)^4\n\\epsilon^2}\\right)$ where $\\gamma$ is the discounting factor and $D$ is the\ndimension of state space. Empirically, we show that our sanitization defense\nperforms well on two Atari game environments.",
    "descriptor": "\nComments: Accepted at Neurips 2022\n",
    "authors": [
      "Shubham Kumar Bharti",
      "Xuezhou Zhang",
      "Adish Singla",
      "Xiaojin Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10530"
  },
  {
    "id": "arXiv:2211.10531",
    "title": "Trigonometric splines of several variables",
    "abstract": "Under consideration methods of constructing trigonometric interpolation\nsplines of two variables on rectangular areas. These methods are easily\ngeneralized to the case of trigonometric interpolation splines of several\nvariables on such domains. A numerical example illustrating the main\ntheoretical propositions is considered. The given methods of constructing such\nsplines can be widely used in practice.",
    "descriptor": "",
    "authors": [
      "V. Denysiuk"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.10531"
  },
  {
    "id": "arXiv:2211.10532",
    "title": "Semantic Encoder Guided Generative Adversarial Face Ultra-Resolution  Network",
    "abstract": "Face super-resolution is a domain-specific image super-resolution, which aims\nto generate High-Resolution (HR) face images from their Low-Resolution (LR)\ncounterparts. In this paper, we propose a novel face super-resolution method,\nnamely Semantic Encoder guided Generative Adversarial Face Ultra-Resolution\nNetwork (SEGA-FURN) to ultra-resolve an unaligned tiny LR face image to its HR\ncounterpart with multiple ultra-upscaling factors (e.g., 4x and 8x). The\nproposed network is composed of a novel semantic encoder that has the ability\nto capture the embedded semantics to guide adversarial learning and a novel\ngenerator that uses a hierarchical architecture named Residual in Internal\nDense Block (RIDB). Moreover, we propose a joint discriminator which\ndiscriminates both image data and embedded semantics. The joint discriminator\nlearns the joint probability distribution of the image space and latent space.\nWe also use a Relativistic average Least Squares loss (RaLS) as the adversarial\nloss to alleviate the gradient vanishing problem and enhance the stability of\nthe training procedure. Extensive experiments on large face datasets have\nproved that the proposed method can achieve superior super-resolution results\nand significantly outperform other state-of-the-art methods in both qualitative\nand quantitative comparisons.",
    "descriptor": "\nComments: 11 pages,5 figures,3 tables\n",
    "authors": [
      "Xiang Wang",
      "Yimin Yang",
      "Qixiang Pang",
      "Xiao Lu",
      "Yu Liu",
      "Shan Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10532"
  },
  {
    "id": "arXiv:2211.10540",
    "title": "Waiting Nets (Extended Version)",
    "abstract": "In Time Petri nets (TPNs), time and control are tightly connected: time\nmeasurement for a transition starts only when all resources needed to fire it\nare available. Further, upper bounds on duration of enabledness can force\ntransitions to fire (this is called urgency). For many systems, one wants to\ndecouple control and time, i.e. start measuring time as soon as a part of the\npreset of a transition is filled, and fire it after some delay \\underline{and}\nwhen all needed resources are available. This paper considers an extension of\nTPN called waiting nets that dissociates time measurement and control. Their\nsemantics allows time measurement to start with incomplete presets, and can\nignore urgency when upper bounds of intervals are reached but all resources\nneeded to fire are not yet available. Firing of a transition is then allowed as\nsoon as missing resources are available. It is known that extending bounded\nTPNs with stopwatches leads to undecidability. Our extension is weaker, and we\nshow how to compute a finite state class graph for bounded waiting nets,\nyielding decidability of reachability and coverability. We then compare\nexpressiveness of waiting nets with that of other models w.r.t. timed language\nequivalence, and show that they are strictly more expressive than TPNs.",
    "descriptor": "",
    "authors": [
      "Lo\u00efc H\u00e9lou\u00ebt",
      "Pranay Agrawal"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2211.10540"
  },
  {
    "id": "arXiv:2211.10546",
    "title": "Evaluating COVID-19 Sequence Data Using Nearest-Neighbors Based Network  Model",
    "abstract": "The SARS-CoV-2 coronavirus is the cause of the COVID-19 disease in humans.\nLike many coronaviruses, it can adapt to different hosts and evolve into\ndifferent lineages. It is well-known that the major SARS-CoV-2 lineages are\ncharacterized by mutations that happen predominantly in the spike protein.\nUnderstanding the spike protein structure and how it can be perturbed is vital\nfor understanding and determining if a lineage is of concern. These are crucial\nto identifying and controlling current outbreaks and preventing future\npandemics. Machine learning (ML) methods are a viable solution to this effort,\ngiven the volume of available sequencing data, much of which is unaligned or\neven unassembled. However, such ML methods require fixed-length numerical\nfeature vectors in Euclidean space to be applicable. Similarly, euclidean space\nis not considered the best choice when working with the classification and\nclustering tasks for biological sequences. For this purpose, we design a method\nthat converts the protein (spike) sequences into the sequence similarity\nnetwork (SSN). We can then use SSN as an input for the classical algorithms\nfrom the graph mining domain for the typical tasks such as classification and\nclustering to understand the data. We show that the proposed alignment-free\nmethod is able to outperform the current SOTA method in terms of clustering\nresults. Similarly, we are able to achieve higher classification accuracy using\nwell-known Node2Vec-based embedding compared to other baseline embedding\napproaches.",
    "descriptor": "\nComments: Accepted at IEEE BigData 2022. arXiv admin note: text overlap with arXiv:2209.04952\n",
    "authors": [
      "Sarwan Ali"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2211.10546"
  },
  {
    "id": "arXiv:2211.10549",
    "title": "Local Contrastive Feature learning for Tabular Data",
    "abstract": "Contrastive self-supervised learning has been successfully used in many\ndomains, such as images, texts, graphs, etc., to learn features without\nrequiring label information. In this paper, we propose a new local contrastive\nfeature learning (LoCL) framework, and our theme is to learn local\npatterns/features from tabular data. In order to create a niche for local\nlearning, we use feature correlations to create a maximum-spanning tree, and\nbreak the tree into feature subsets, with strongly correlated features being\nassigned next to each other. Convolutional learning of the features is used to\nlearn latent feature space, regulated by contrastive and reconstruction losses.\nExperiments on public tabular datasets show the effectiveness of the proposed\nmethod versus state-of-the-art baseline methods.",
    "descriptor": "",
    "authors": [
      "Zhabiz Gharibshah",
      "Xingquan Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10549"
  },
  {
    "id": "arXiv:2211.10550",
    "title": "Debiasing Meta-Gradient Reinforcement Learning by Learning the Outer  Value Function",
    "abstract": "Meta-gradient Reinforcement Learning (RL) allows agents to self-tune their\nhyper-parameters in an online fashion during training. In this paper, we\nidentify a bias in the meta-gradient of current meta-gradient RL approaches.\nThis bias comes from using the critic that is trained using the meta-learned\ndiscount factor for the advantage estimation in the outer objective which\nrequires a different discount factor. Because the meta-learned discount factor\nis typically lower than the one used in the outer objective, the resulting bias\ncan cause the meta-gradient to favor myopic policies. We propose a simple\nsolution to this issue: we eliminate this bias by using an alternative,\n\\emph{outer} value function in the estimation of the outer loss. To obtain this\nouter value function we add a second head to the critic network and train it\nalongside the classic critic, using the outer loss discount factor. On an\nillustrative toy problem, we show that the bias can cause catastrophic failure\nof current meta-gradient RL approaches, and show that our proposed solution\nfixes it. We then apply our method to a more complex environment and\ndemonstrate that fixing the meta-gradient bias can significantly improve\nperformance.",
    "descriptor": "\nComments: Published at the 6th Workshop on Meta-Learning at NeurIPS 2022, New Orleans\n",
    "authors": [
      "Cl\u00e9ment Bonnet",
      "Laurence Midgley",
      "Alexandre Laterre"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10550"
  },
  {
    "id": "arXiv:2211.10551",
    "title": "A Practical Stereo Depth System for Smart Glasses",
    "abstract": "We present the design of a productionized end-to-end stereo depth sensing\nsystem that does pre-processing, online stereo rectification, and stereo depth\nestimation with a fallback to monocular depth estimation when rectification is\nunreliable. The output of our depth sensing system is then used in a novel view\ngeneration pipeline to create 3D computational photography effect using\npoint-of-view images captured by smart glasses. All these steps are executed\non-device on the stringent compute budget of a mobile phone, and because we\nexpect the users can use a wide range of smartphones, our design needs to be\ngeneral and cannot be dependent on a particular hardware or ML accelerator such\nas a smartphone GPU. Although each of these steps is well-studied, a\ndescription of a practical system is still lacking. For such a system, each of\nthese steps need to work in tandem with one another and fallback gracefully on\nfailures within the system or less than ideal input data. We show how we handle\nunforeseen changes to calibration, e.g. due to heat, robustly support depth\nestimation in the wild, and still abide by the memory and latency constraints\nrequired for a smooth user experience. We show that our trained models are\nfast, that run in less than 1s on a six-year-old Samsung Galaxy S8 phone's CPU.\nOur models generalize well to unseen data and achieve good results on\nMiddlebury and in-the-wild images captured from the smart glasses.",
    "descriptor": "",
    "authors": [
      "Jialiang Wang",
      "Daniel Scharstein",
      "Akash Bapat",
      "Kevin Blackburn-Matzen",
      "Matthew Yu",
      "Jonathan Lehman",
      "Suhib Alsisan",
      "Yanghan Wang",
      "Sam Tsai",
      "Jan-Michael Frahm",
      "Zijian He",
      "Peter Vajda",
      "Michael F. Cohen",
      "Matt Uyttendaele"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10551"
  },
  {
    "id": "arXiv:2211.10556",
    "title": "A Distanced Matching Game, Decremental APSP in Expanders, and Faster  Deterministic Algorithms for Graph Cut Problems",
    "abstract": "Expander graphs play a central role in graph theory and algorithms. With a\nnumber of powerful algorithmic tools developed around them, such as the\nCut-Matching game, expander pruning, expander decomposition, and algorithms for\ndecremental All-Pairs Shortest Paths (APSP) in expanders, to name just a few,\nthe use of expanders in the design of graph algorithms has become ubiquitous.\nSpecific applications of interest to us are fast deterministic algorithms for\ncut problems in static graphs, and algorithms for dynamic distance-based graph\nproblems, such as APSP.\nUnfortunately, the use of expanders in these settings incurs a number of\ndrawbacks. For example, the best currently known algorithm for decremental APSP\nin constant-degree expanders can only achieve a $(\\log\nn)^{O(1/\\epsilon^2)}$-approximation with $n^{1+O(\\epsilon)}$ total update time\nfor any $\\epsilon$. All currently known algorithms for the Cut Player in the\nCut-Matching game are either randomized, or provide rather weak guarantees.\nThis, in turn, leads to somewhat weak algorithmic guarantees for several\ncentral cut problems: for example, the best current almost linear time\ndeterministic algorithm for Sparsest Cut can only achieve approximation factor\n$(\\log n)^{\\omega(1)}$. Lastly, when relying on expanders in distance-based\nproblems, such as dynamic APSP, via current methods, it seems inevitable that\none has to settle for approximation factors that are at least $\\Omega(\\log n)$.\nIn this paper we propose the use of well-connected graphs, and introduce a\nnew algorithmic toolkit for such graphs that, in a sense, mirrors the above\nmentioned algorithmic tools for expanders. One of these new tools is the\nDistanced Matching game, an analogue of the Cut-Matching game for\nwell-connected graphs. We demonstrate the power of these new tools by obtaining\nbetter results for several of the problems mentioned above.",
    "descriptor": "",
    "authors": [
      "Julia Chuzhoy"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.10556"
  },
  {
    "id": "arXiv:2211.10558",
    "title": "Neural frames: A Tool for Studying the Tangent Bundles Underlying Image  Datasets and How Deep Learning Models Process Them",
    "abstract": "The assumption that many forms of high-dimensional data, such as images,\nactually live on low-dimensional manifolds, sometimes known as the manifold\nhypothesis, underlies much of our intuition for how and why deep learning\nworks. Despite the central role that they play in our intuition, data manifolds\nare surprisingly hard to measure in the case of high-dimensional, sparsely\nsampled image datasets. This is particularly frustrating since the capability\nto measure data manifolds would provide a revealing window into the inner\nworkings and dynamics of deep learning models. Motivated by this, we introduce\nneural frames, a novel and easy to use tool inspired by the notion of a frame\nfrom differential geometry. Neural frames can be used to explore the local\nneighborhoods of data manifolds as they pass through the hidden layers of\nneural networks even when one only has a single datapoint available. We present\na mathematical framework for neural frames and explore some of their\nproperties. We then use them to make a range of observations about how modern\nmodel architectures and training routines, such as heavy augmentation and\nadversarial training, affect the local behavior of a model.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Henry Kvinge",
      "Grayson Jorgenson",
      "Davis Brown",
      "Charles Godfrey",
      "Tegan Emerson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10558"
  },
  {
    "id": "arXiv:2211.10563",
    "title": "Real-World Image Super Resolution via Unsupervised Bi-directional Cycle  Domain Transfer Learning based Generative Adversarial Network",
    "abstract": "Deep Convolutional Neural Networks (DCNNs) have exhibited impressive\nperformance on image super-resolution tasks. However, these deep learning-based\nsuper-resolution methods perform poorly in real-world super-resolution tasks,\nwhere the paired high-resolution and low-resolution images are unavailable and\nthe low-resolution images are degraded by complicated and unknown kernels. To\nbreak these limitations, we propose the Unsupervised Bi-directional Cycle\nDomain Transfer Learning-based Generative Adversarial Network (UBCDTL-GAN),\nwhich consists of an Unsupervised Bi-directional Cycle Domain Transfer Network\n(UBCDTN) and the Semantic Encoder guided Super Resolution Network (SESRN).\nFirst, the UBCDTN is able to produce an approximated real-like LR image through\ntransferring the LR image from an artificially degraded domain to the\nreal-world LR image domain. Second, the SESRN has the ability to super-resolve\nthe approximated real-like LR image to a photo-realistic HR image. Extensive\nexperiments on unpaired real-world image benchmark datasets demonstrate that\nthe proposed method achieves superior performance compared to state-of-the-art\nmethods.",
    "descriptor": "\nComments: 12 pages, 5 figures,3 tables. This work is submitted to IEEE Transactions on Systems, Man, and Cybernetics: Systems (2022). It's under review by IEEE Transactions on Systems, Man, and Cybernetics: Systems for now\n",
    "authors": [
      "Xiang Wang",
      "Yimin Yang",
      "Zhichang Guo",
      "Zhili Zhou",
      "Yu Liu",
      "Qixiang Pang",
      "Shan Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10563"
  },
  {
    "id": "arXiv:2211.10564",
    "title": "Gumbel-Softmax Selective Networks",
    "abstract": "ML models often operate within the context of a larger system that can adapt\nits response when the ML model is uncertain, such as falling back on safe\ndefaults or a human in the loop. This commonly encountered operational context\ncalls for principled techniques for training ML models with the option to\nabstain from predicting when uncertain. Selective neural networks are trained\nwith an integrated option to abstain, allowing them to learn to recognize and\noptimize for the subset of the data distribution for which confident\npredictions can be made. However, optimizing selective networks is challenging\ndue to the non-differentiability of the binary selection function (the discrete\ndecision of whether to predict or abstain). This paper presents a general\nmethod for training selective networks that leverages the Gumbel-softmax\nreparameterization trick to enable selection within an end-to-end\ndifferentiable training framework. Experiments on public datasets demonstrate\nthe potential of Gumbel-softmax selective networks for selective regression and\nclassification.",
    "descriptor": "",
    "authors": [
      "Mahmoud Salem",
      "Mohamed Osama Ahmed",
      "Frederick Tung",
      "Gabriel Oliveira"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10564"
  },
  {
    "id": "arXiv:2211.10567",
    "title": "CL-CrossVQA: A Continual Learning Benchmark for Cross-Domain Visual  Question Answering",
    "abstract": "Visual Question Answering (VQA) is a multi-discipline research task. To\nproduce the right answer, it requires an understanding of the visual content of\nimages, the natural language questions, as well as commonsense reasoning over\nthe information contained in the image and world knowledge. Recently,\nlarge-scale Vision-and-Language Pre-trained Models (VLPMs) have been the\nmainstream approach to VQA tasks due to their superior performance. The\nstandard practice is to fine-tune large-scale VLPMs pre-trained on huge\ngeneral-domain datasets using the domain-specific VQA datasets. However, in\nreality, the application domain can change over time, necessitating VLPMs to\ncontinually learn and adapt to new domains without forgetting previously\nacquired knowledge. Most existing continual learning (CL) research concentrates\non unimodal tasks, whereas a more practical application scenario, i.e, CL on\ncross-domain VQA, has not been studied. Motivated by this, we introduce\nCL-CrossVQA, a rigorous Continual Learning benchmark for Cross-domain Visual\nQuestion Answering, through which we conduct extensive experiments on 4 VLPMs,\n4 CL approaches, and 5 VQA datasets from different domains. In addition, by\nprobing the forgetting phenomenon of the intermediate layers, we provide\ninsights into how model architecture affects CL performance, why CL approaches\ncan help mitigate forgetting in VLPMs to some extent, and how to design CL\napproaches suitable for VLPMs in this challenging continual learning\nenvironment. To facilitate future work on CL for cross-domain VQA, we will\nrelease our datasets and code.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Yao Zhang",
      "Haokun Chen",
      "Ahmed Frikha",
      "Yezi Yang",
      "Denis Krompass",
      "Gengyuan Zhang",
      "Jindong Gu",
      "Volker Tresp"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10567"
  },
  {
    "id": "arXiv:2211.10574",
    "title": "A 2030 United States Macro Grid Unlocking Geographical Diversity to  Accomplish Clean Energy Goals",
    "abstract": "Some U.S. states have set clean energy goals and targets in an effort to\ndecarbonize their electricity sectors. There are many reasons for such goals\nand targets, including the increasingly apparent effects of climate change. A\nhandful of states (Washington, California, New York, and Virginia) are aiming\nfor deep decarbonization by 2050 or earlier, a mere 30 years or less from\ntoday. The urgency of substantial carbon emissions reduction (50% or more by\n2030) needed to avoid catastrophic climate impacts requires even more ambitious\nefforts than some of the original targets (e.g., a 30% renewable portfolio\nstandard) set for between now and 2030. With the cost of solar and wind energy\nfalling faster than expected in recent years, economics are also driving rapid\nexpansion of clean energy investments. With this in mind, this report examines\ncombinations of interregional AC and High-Voltage DC (HVDC) transmission\nupgrades and additions to evaluate the benefits of large-scale transmission\nexpansion.",
    "descriptor": "",
    "authors": [
      "Yixing Xu",
      "Daniel Olsen",
      "Bainan Xia",
      "Dan Livengood",
      "Victoria Hunt",
      "Yifan Li",
      "Lane Smith"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.10574"
  },
  {
    "id": "arXiv:2211.10575",
    "title": "Bayesian autoencoders for data-driven discovery of coordinates,  governing equations and fundamental constants",
    "abstract": "Recent progress in autoencoder-based sparse identification of nonlinear\ndynamics (SINDy) under $\\ell_1$ constraints allows joint discoveries of\ngoverning equations and latent coordinate systems from spatio-temporal data,\nincluding simulated video frames. However, it is challenging for $\\ell_1$-based\nsparse inference to perform correct identification for real data due to the\nnoisy measurements and often limited sample sizes. To address the data-driven\ndiscovery of physics in the low-data and high-noise regimes, we propose\nBayesian SINDy autoencoders, which incorporate a hierarchical Bayesian\nsparsifying prior: Spike-and-slab Gaussian Lasso. Bayesian SINDy autoencoder\nenables the joint discovery of governing equations and coordinate systems with\na theoretically guaranteed uncertainty estimate. To resolve the challenging\ncomputational tractability of the Bayesian hierarchical setting, we adapt an\nadaptive empirical Bayesian method with Stochatic gradient Langevin dynamics\n(SGLD) which gives a computationally tractable way of Bayesian posterior\nsampling within our framework. Bayesian SINDy autoencoder achieves better\nphysics discovery with lower data and fewer training epochs, along with valid\nuncertainty quantification suggested by the experimental studies. The Bayesian\nSINDy autoencoder can be applied to real video data, with accurate physics\ndiscovery which correctly identifies the governing equation and provides a\nclose estimate for standard physics constants like gravity $g$, for example, in\nvideos of a pendulum.",
    "descriptor": "\nComments: 28 pages, 11 figures\n",
    "authors": [
      "L. Mars Gao",
      "J. Nathan Kutz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10575"
  },
  {
    "id": "arXiv:2211.10578",
    "title": "ABINet++: Autonomous, Bidirectional and Iterative Language Modeling for  Scene Text Spotting",
    "abstract": "Scene text spotting is of great importance to the computer vision community\ndue to its wide variety of applications. Recent methods attempt to introduce\nlinguistic knowledge for challenging recognition rather than pure visual\nclassification. However, how to effectively model the linguistic rules in\nend-to-end deep networks remains a research challenge. In this paper, we argue\nthat the limited capacity of language models comes from 1) implicit language\nmodeling; 2) unidirectional feature representation; and 3) language model with\nnoise input. Correspondingly, we propose an autonomous, bidirectional and\niterative ABINet++ for scene text spotting. Firstly, the autonomous suggests\nenforcing explicitly language modeling by decoupling the recognizer into vision\nmodel and language model and blocking gradient flow between both models.\nSecondly, a novel bidirectional cloze network (BCN) as the language model is\nproposed based on bidirectional feature representation. Thirdly, we propose an\nexecution manner of iterative correction for the language model which can\neffectively alleviate the impact of noise input. Finally, to polish ABINet++ in\nlong text recognition, we propose to aggregate horizontal features by embedding\nTransformer units inside a U-Net, and design a position and content attention\nmodule which integrates character order and content to attend to character\nfeatures precisely. ABINet++ achieves state-of-the-art performance on both\nscene text recognition and scene text spotting benchmarks, which consistently\ndemonstrates the superiority of our method in various environments especially\non low-quality images. Besides, extensive experiments including in English and\nChinese also prove that, a text spotter that incorporates our language modeling\nmethod can significantly improve its performance both in accuracy and speed\ncompared with commonly used attention-based recognizers.",
    "descriptor": "\nComments: Accepted by TPAMI. Code is available at \\url{this https URL}. arXiv admin note: substantial text overlap with arXiv:2103.06495\n",
    "authors": [
      "Shancheng Fang",
      "Zhendong Mao",
      "Hongtao Xie",
      "Yuxin Wang",
      "Chenggang Yan",
      "Yongdong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10578"
  },
  {
    "id": "arXiv:2211.10579",
    "title": "Tired of Over-smoothing? Stress Graph Drawing Is All You Need!",
    "abstract": "In designing and applying graph neural networks, we often fall into some\noptimization pitfalls, the most deceptive of which is that we can only build a\ndeep model by solving over-smoothing. The fundamental reason is that we do not\nunderstand how graph neural networks work. Stress graph drawing can offer a\nunique viewpoint to message iteration in the graph, such as the root of the\nover-smoothing problem lies in the inability of graph models to maintain an\nideal distance between nodes. We further elucidate the trigger conditions of\nover-smoothing and propose Stress Graph Neural Networks. By introducing the\nattractive and repulsive message passing from stress iteration, we show how to\nbuild a deep model without preventing over-smoothing, how to use repulsive\ninformation, and how to optimize the current message-passing scheme to\napproximate the full stress message propagation. By performing different tasks\non 23 datasets, we verified the effectiveness of our attractive and repulsive\nmodels and the derived relationship between stress iteration and graph neural\nnetworks. We believe that stress graph drawing will be a popular resource for\nunderstanding and designing graph neural networks.",
    "descriptor": "\nComments: 13 pages, 10 figures, 11 tables, and 27 formulas\n",
    "authors": [
      "Xue Li",
      "Yuanzhi Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10579"
  },
  {
    "id": "arXiv:2211.10580",
    "title": "Normal Transformer: Extracting Surface Geometry from LiDAR Points  Enhanced by Visual Semantics",
    "abstract": "High-quality estimation of surface normal can help reduce ambiguity in many\ngeometry understanding problems, such as collision avoidance and occlusion\ninference. This paper presents a technique for estimating the normal from 3D\npoint clouds and 2D colour images. We have developed a transformer neural\nnetwork that learns to utilise the hybrid information of visual semantic and 3D\ngeometric data, as well as effective learning strategies. Compared to existing\nmethods, the information fusion of the proposed method is more effective, which\nis supported by experiments.\nWe have also built a simulation environment of outdoor traffic scenes in a 3D\nrendering engine to obtain annotated data to train the normal estimator. The\nmodel trained on synthetic data is tested on the real scenes in the KITTI\ndataset. And subsequent tasks built upon the estimated normal directions in the\nKITTI dataset show that the proposed estimator has advantage over existing\nmethods.",
    "descriptor": "",
    "authors": [
      "Ancheng Lin",
      "Jun Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10580"
  },
  {
    "id": "arXiv:2211.10581",
    "title": "Sparse4D: Multi-view 3D Object Detection with Sparse Spatial-Temporal  Fusion",
    "abstract": "Bird-eye-view (BEV) based methods have made great progress recently in\nmulti-view 3D detection task. Comparing with BEV based methods, sparse based\nmethods lag behind in performance, but still have lots of non-negligible\nmerits. To push sparse 3D detection further, in this work, we introduce a novel\nmethod, named Sparse4D, which does the iterative refinement of anchor boxes via\nsparsely sampling and fusing spatial-temporal features. (1) Sparse 4D Sampling:\nfor each 3D anchor, we assign multiple 4D keypoints, which are then projected\nto multi-view/scale/timestamp image features to sample corresponding features;\n(2) Hierarchy Feature Fusion: we hierarchically fuse sampled features of\ndifferent view/scale, different timestamp and different keypoints to generate\nhigh-quality instance feature. In this way, Sparse4D can efficiently and\neffectively achieve 3D detection without relying on dense view transformation\nnor global attention, and is more friendly to edge devices deployment.\nFurthermore, we introduce an instance-level depth reweight module to alleviate\nthe ill-posed issue in 3D-to-2D projection. In experiment, our method\noutperforms all sparse based methods and most BEV based methods on detection\ntask in the nuScenes dataset.",
    "descriptor": "",
    "authors": [
      "Xuewu Lin",
      "Tianwei Lin",
      "Zixiang Pei",
      "Lichao Huang",
      "Zhizhong Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10581"
  },
  {
    "id": "arXiv:2211.10582",
    "title": "Can Gradient Descent Provably Learn Linear Dynamic Systems?",
    "abstract": "We study the learning ability of linear recurrent neural networks with\ngradient descent. We prove the first theoretical guarantee on linear RNNs with\nGradient Descent to learn any stable linear dynamic system. We show that\ndespite the non-convexity of the optimization loss if the width of the RNN is\nlarge enough (and the required width in hidden layers does not rely on the\nlength of the input sequence), a linear RNN can provably learn any stable\nlinear dynamic system with the sample and time complexity polynomial in\n$\\frac{1}{1-\\rho_C}$ where $\\rho_C$ is roughly the spectral radius of the\nstable system. Our results provide the first theoretical guarantee to learn a\nlinear RNN and demonstrate how can the recurrent structure help to learn a\ndynamic system.",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Lifu Wang",
      "Bo Shen",
      "Bo Hu",
      "Xing Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.10582"
  },
  {
    "id": "arXiv:2211.10583",
    "title": "The Information-State Based Approach to Linear System Identification",
    "abstract": "This paper considers the problem of system identification for linear systems.\nWe propose a new system realization approach that uses an ``information-state\"\nas the state vector, where the ``information-state\" is composed of a finite\nnumber of past inputs and outputs. The system identification algorithm uses\ninput-output data to fit an autoregressive moving average model (ARMA) to\nrepresent the current output in terms of finite past inputs and outputs. This\ninformation-state-based approach allows us to directly realize a state-space\nmodel using the estimated ARMA or time-varying ARMA parameters for linear time\ninvariant (LTI) or linear time varying (LTV) systems, respectively. The paper\ndevelops the theoretical foundation for using ARMA parameters-based system\nrepresentation using only the concept of linear observability, details the\nreasoning for exact output modeling using only the finite history, and shows\nthat there is no need to separate the free and the forced response for\nidentification. The proposed approach is tested on various different systems,\nand the performance is compared with state-of-the-art system identification\ntechniques.",
    "descriptor": "",
    "authors": [
      "Mohamed Naveed Gul Mohamed",
      "Raman Goyal",
      "Suman Chakravorty",
      "Ran Wang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.10583"
  },
  {
    "id": "arXiv:2211.10585",
    "title": "Prediction-aware and Reinforcement Learning based Altruistic Cooperative  Driving",
    "abstract": "Autonomous vehicle (AV) navigation in the presence of Human-driven vehicles\n(HVs) is challenging, as HVs continuously update their policies in response to\nAVs. In order to navigate safely in the presence of complex AV-HV social\ninteractions, the AVs must learn to predict these changes. Humans are capable\nof navigating such challenging social interaction settings because of their\nintrinsic knowledge about other agents behaviors and use that to forecast what\nmight happen in the future. Inspired by humans, we provide our AVs the\ncapability of anticipating future states and leveraging prediction in a\ncooperative reinforcement learning (RL) decision-making framework, to improve\nsafety and robustness. In this paper, we propose an integration of two\nessential and earlier-presented components of AVs: social navigation and\nprediction. We formulate the AV decision-making process as a RL problem and\nseek to obtain optimal policies that produce socially beneficial results\nutilizing a prediction-aware planning and social-aware optimization RL\nframework. We also propose a Hybrid Predictive Network (HPN) that anticipates\nfuture observations. The HPN is used in a multi-step prediction chain to\ncompute a window of predicted future observations to be used by the value\nfunction network (VFN). Finally, a safe VFN is trained to optimize a social\nutility using a sequence of previous and predicted observations, and a safety\nprioritizer is used to leverage the interpretable kinematic predictions to mask\nthe unsafe actions, constraining the RL policy. We compare our prediction-aware\nAV to state-of-the-art solutions and demonstrate performance improvements in\nterms of efficiency and safety in multiple simulated scenarios.",
    "descriptor": "",
    "authors": [
      "Rodolfo Valiente",
      "Mahdi Razzaghpour",
      "Behrad Toghi",
      "Ghayoor Shah",
      "Yaser P. Fallah"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.10585"
  },
  {
    "id": "arXiv:2211.10586",
    "title": "Scaling Up Dataset Distillation to ImageNet-1K with Constant Memory",
    "abstract": "Dataset distillation methods aim to compress a large dataset into a small set\nof synthetic samples, such that when being trained on, competitive performances\ncan be achieved compared to regular training on the entire dataset. Among\nrecently proposed methods, Matching Training Trajectories (MTT) achieves\nstate-of-the-art performance on CIFAR-10/100, while having difficulty scaling\nto ImageNet-1k dataset due to the large memory requirement when performing\nunrolled gradient computation through back-propagation. Surprisingly, we show\nthat there exists a procedure to exactly calculate the gradient of the\ntrajectory matching loss with constant GPU memory requirement (irrelevant to\nthe number of unrolled steps). With this finding, the proposed memory-efficient\ntrajectory matching method can easily scale to ImageNet-1K with 6x memory\nreduction while introducing only around 2% runtime overhead than original MTT.\nFurther, we find that assigning soft labels for synthetic images is crucial for\nthe performance when scaling to larger number of categories (e.g., 1,000) and\npropose a novel soft label version of trajectory matching that facilities\nbetter aligning of model training trajectories on large datasets. The proposed\nalgorithm not only surpasses previous SOTA on ImageNet-1K under extremely low\nIPCs (Images Per Class), but also for the first time enables us to scale up to\n50 IPCs on ImageNet-1K. Our method (TESLA) achieves 27.9% testing accuracy, a\nremarkable +18.2% margin over prior arts.",
    "descriptor": "\nComments: ICLR 2023 submission link: this https URL\n",
    "authors": [
      "Justin Cui",
      "Ruochen Wang",
      "Si Si",
      "Cho-Jui Hsieh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10586"
  },
  {
    "id": "arXiv:2211.10588",
    "title": "Prior Guided Deep Difference Meta-Learner for Fast Adaptation to  Stylized Segmentation",
    "abstract": "When a pre-trained general auto-segmentation model is deployed at a new\ninstitution, a support framework in the proposed Prior-guided DDL network will\nlearn the systematic difference between the model predictions and the final\ncontours revised and approved by clinicians for an initial group of patients.\nThe learned style feature differences are concatenated with the new patients\n(query) features and then decoded to get the style-adapted segmentations. The\nmodel is independent of practice styles and anatomical structures. It\nmeta-learns with simulated style differences and does not need to be exposed to\nany real clinical stylized structures during training. Once trained on the\nsimulated data, it can be deployed for clinical use to adapt to new practice\nstyles and new anatomical structures without further training.\nTo show the proof of concept, we tested the Prior-guided DDL network on six\ndifferent practice style variations for three different anatomical structures.\nPre-trained segmentation models were adapted from post-operative clinical\ntarget volume (CTV) segmentation to segment CTVstyle1, CTVstyle2, and\nCTVstyle3, from parotid gland segmentation to segment Parotidsuperficial, and\nfrom rectum segmentation to segment Rectumsuperior and Rectumposterior. The\nmode performance was quantified with Dice Similarity Coefficient (DSC). With\nadaptation based on only the first three patients, the average DSCs were\nimproved from 78.6, 71.9, 63.0, 52.2, 46.3 and 69.6 to 84.4, 77.8, 73.0, 77.8,\n70.5, 68.1, for CTVstyle1, CTVstyle2, and CTVstyle3, Parotidsuperficial,\nRectumsuperior, and Rectumposterior, respectively, showing the great potential\nof the Priorguided DDL network for a fast and effortless adaptation to new\npractice styles",
    "descriptor": "",
    "authors": [
      "Anjali Balagopal",
      "Dan Nguyen",
      "Ti Bai",
      "Michael Dohopolski",
      "Mu-Han Lin",
      "Steve Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10588"
  },
  {
    "id": "arXiv:2211.10589",
    "title": "Air-Aided Communication Between Ground Assets in a Poisson Forest",
    "abstract": "Ground assets deployed in a cluttered environment with randomized obstacles\n(e.g., a forest) may experience line of sight (LoS) obstruction due to those\nobstacles. Air assets can be deployed in the vicinity to aid the communication\nby establishing two-hop paths between the ground assets. Obstacles that are\ntaller than a position-dependent critical height may still obstruct the LoS\nbetween a ground asset and an air asset. In this paper, we provide an\nanalytical framework for computing the probability of obtaining a LoS path in a\nPoisson forest. Given the locations and heights of a ground asset and an air\nasset, we establish the critical height, which is a function of distance. To\naccount for this dependence on distance, the blocking is modeled as an\ninhomogenous Poisson point process, and the LoS probability is its void\nprobability. Examples and closed-form expressions are provided for two\nobstruction height distributions: uniform and truncated Gaussian. The examples\nare validated through simulation. Additionally, the end-to-end throughput is\ndetermined and shown to be a metric that balances communication distance with\nthe impact of LoS blockage. Throughput is used to determine the range at which\nit is better to relay communications through the air asset, and, when the air\nasset is deployed, its optimal height.",
    "descriptor": "\nComments: Military Communications Conference, MILCOM 2022\n",
    "authors": [
      "Juan David Pabon",
      "Shaikha Alkandari",
      "Matthew C. Valenti",
      "Xi Yu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Emerging Technologies (cs.ET)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.10589"
  },
  {
    "id": "arXiv:2211.10590",
    "title": "Molecular Structure-Property Co-Trained Foundation Model for In Silico  Chemistry",
    "abstract": "Recently, deep learning approaches have been extensively studied for various\nproblems in chemistry, such as virtual screening, de novo molecule design, etc.\nDespite the impressive successes, end-to-end training for specific tasks\nusually requires separately designed networks, so it's often difficult to\nacquire a unified principle to synergistically combine existing architectures\nand training datasets for novel tasks. To address this, inspired by recent\nadvances of pre-trained multi-modal foundation models such as Vision-Language\nPretrained models (VLP), here we present a novel multimodal foundation model\nthat can be used {\\em in silico} for various downstream tasks in chemistry.\nSpecifically, our framework, dubbed as the structure-property multi-modal\n(SPMM) foundation model, is based on the dual-stream transformer with X-shape\nattention, so that it can align the molecule structure and the chemical\nproperties in a common embedding space. Accordingly, SPMM can simultaneously\nperform chemical property prediction from given structure-describing strings\nand allows the generation of molecular structures for given chemical\nproperties, which was previously not possible with a single architecture.\nFurthermore, we show that the outstanding unimodal representation of a molecule\nemerges from multimodal learning, which has the potential to be fine-tuned for\nmany other downstream tasks.",
    "descriptor": "",
    "authors": [
      "Jinho Chang",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10590"
  },
  {
    "id": "arXiv:2211.10593",
    "title": "MatrixVT: Efficient Multi-Camera to BEV Transformation for 3D Perception",
    "abstract": "This paper proposes an efficient multi-camera to Bird's-Eye-View (BEV) view\ntransformation method for 3D perception, dubbed MatrixVT. Existing view\ntransformers either suffer from poor transformation efficiency or rely on\ndevice-specific operators, hindering the broad application of BEV models. In\ncontrast, our method generates BEV features efficiently with only convolutions\nand matrix multiplications (MatMul). Specifically, we propose describing the\nBEV feature as the MatMul of image feature and a sparse Feature Transporting\nMatrix (FTM). A Prime Extraction module is then introduced to compress the\ndimension of image features and reduce FTM's sparsity. Moreover, we propose the\nRing \\& Ray Decomposition to replace the FTM with two matrices and reformulate\nour pipeline to reduce calculation further. Compared to existing methods,\nMatrixVT enjoys a faster speed and less memory footprint while remaining\ndeploy-friendly. Extensive experiments on the nuScenes benchmark demonstrate\nthat our method is highly efficient but obtains results on par with the SOTA\nmethod in object detection and map segmentation tasks",
    "descriptor": "",
    "authors": [
      "Hongyu Zhou",
      "Zheng Ge",
      "Zeming Li",
      "Xiangyu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10593"
  },
  {
    "id": "arXiv:2211.10594",
    "title": "Autoregressive GNN-ODE GRU Model for Network Dynamics",
    "abstract": "Revealing the continuous dynamics on the networks is essential for\nunderstanding, predicting, and even controlling complex systems, but it is hard\nto learn and model the continuous network dynamics because of complex and\nunknown governing equations, high dimensions of complex systems, and\nunsatisfactory observations. Moreover, in real cases, observed time-series data\nare usually non-uniform and sparse, which also causes serious challenges. In\nthis paper, we propose an Autoregressive GNN-ODE GRU Model (AGOG) to learn and\ncapture the continuous network dynamics and realize predictions of node states\nat an arbitrary time in a data-driven manner. The GNN module is used to model\ncomplicated and nonlinear network dynamics. The hidden state of node states is\nspecified by the ODE system, and the augmented ODE system is utilized to map\nthe GNN into the continuous time domain. The hidden state is updated through\nGRUCell by observations. As prior knowledge, the true observations at the same\ntimestamp are combined with the hidden states for the next prediction. We use\nthe autoregressive model to make a one-step ahead prediction based on\nobservation history. The prediction is achieved by solving an initial-value\nproblem for ODE. To verify the performance of our model, we visualize the\nlearned dynamics and test them in three tasks: interpolation reconstruction,\nextrapolation prediction, and regular sequences prediction. The results\ndemonstrate that our model can capture the continuous dynamic process of\ncomplex systems accurately and make precise predictions of node states with\nminimal error. Our model can consistently outperform other baselines or achieve\ncomparable performance.",
    "descriptor": "",
    "authors": [
      "Bo Liang",
      "Lin Wang",
      "Xiaofan Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10594"
  },
  {
    "id": "arXiv:2211.10595",
    "title": "Explainable Artificial Intelligence and Causal Inference based ATM Fraud  Detection",
    "abstract": "Gaining the trust of customers and providing them empathy are very critical\nin the financial domain. Frequent occurrence of fraudulent activities affects\nthese two factors. Hence, financial organizations and banks must take utmost\ncare to mitigate them. Among them, ATM fraudulent transaction is a common\nproblem faced by banks. There following are the critical challenges involved in\nfraud datasets: the dataset is highly imbalanced, the fraud pattern is\nchanging, etc. Owing to the rarity of fraudulent activities, Fraud detection\ncan be formulated as either a binary classification problem or One class\nclassification (OCC). In this study, we handled these techniques on an ATM\ntransactions dataset collected from India. In binary classification, we\ninvestigated the effectiveness of various over-sampling techniques, such as the\nSynthetic Minority Oversampling Technique (SMOTE) and its variants, Generative\nAdversarial Networks (GAN), to achieve oversampling. Further, we employed\nvarious machine learning techniques viz., Naive Bayes (NB), Logistic Regression\n(LR), Support Vector Machine (SVM), Decision Tree (DT), Random Forest (RF),\nGradient Boosting Tree (GBT), Multi-layer perceptron (MLP). GBT outperformed\nthe rest of the models by achieving 0.963 AUC, and DT stands second with 0.958\nAUC. DT is the winner if the complexity and interpretability aspects are\nconsidered. Among all the oversampling approaches, SMOTE and its variants were\nobserved to perform better. In OCC, IForest attained 0.959 CR, and OCSVM\nsecured second place with 0.947 CR. Further, we incorporated explainable\nartificial intelligence (XAI) and causal inference (CI) in the fraud detection\nframework and studied it through various analyses.",
    "descriptor": "\nComments: 34 pages; 21 Figures; 8 Tables\n",
    "authors": [
      "Yelleti Vivek",
      "Vadlamani Ravi",
      "Abhay Anand Mane",
      "Laveti Ramesh Naidu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.10595"
  },
  {
    "id": "arXiv:2211.10596",
    "title": "Bipartite-play Dialogue Collection for Practical Automatic Evaluation of  Dialogue Systems",
    "abstract": "Automation of dialogue system evaluation is a driving force for the efficient\ndevelopment of dialogue systems. This paper introduces the bipartite-play\nmethod, a dialogue collection method for automating dialogue system evaluation.\nIt addresses the limitations of existing dialogue collection methods: (i)\ninability to compare with systems that are not publicly available, and (ii)\nvulnerability to cheating by intentionally selecting systems to be compared.\nExperimental results show that the automatic evaluation using the\nbipartite-play method mitigates these two drawbacks and correlates as strongly\nwith human subjectivity as existing methods.",
    "descriptor": "\nComments: 9 pages, Accepted to The AACL-IJCNLP 2022 Student Research Workshop (SRW)\n",
    "authors": [
      "Shiki Sato",
      "Yosuke Kishinami",
      "Hiroaki Sugiyama",
      "Reina Akama",
      "Ryoko Tokuhisa",
      "Jun Suzuki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.10596"
  },
  {
    "id": "arXiv:2211.10597",
    "title": "Adjacent Slice Feature Guided 2.5D Network for Pulmonary Nodule  Segmentation",
    "abstract": "More and more attention has been paid to the segmentation of pulmonary\nnodules. Among the current methods based on deep learning, 3D segmentation\nmethods directly input 3D images, which takes up a lot of memory and brings\nhuge computation. However, most of the 2D segmentation methods with less\nparameters and calculation have the problem of lacking spatial relations\nbetween slices, resulting in poor segmentation performance. In order to solve\nthese problems, we propose an adjacent slice feature guided 2.5D network. In\nthis paper, we design an adjacent slice feature fusion model to introduce\ninformation from adjacent slices. To further improve the model performance, we\nconstruct a multi-scale fusion module to capture more context information, in\naddition, we design an edge-constrained loss function to optimize the\nsegmentation results in the edge region. Fully experiments show that our method\nperforms better than other existing methods in pulmonary nodule segmentation\ntask.",
    "descriptor": "",
    "authors": [
      "Xinwei Xue",
      "Gaoyu Wang",
      "Long Ma",
      "Qi Jia",
      "Yi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10597"
  },
  {
    "id": "arXiv:2211.10598",
    "title": "LIDAR GAIT: Benchmarking 3D Gait Recognition with Point Clouds",
    "abstract": "Video-based gait recognition has achieved impressive results in constrained\nscenarios. However, visual cameras neglect human 3D structure information,\nwhich limits the feasibility of gait recognition in the 3D wild world. In this\nwork, instead of extracting gait features from images, we explore precise 3D\ngait features from point clouds and propose a simple yet efficient 3D gait\nrecognition framework, termed multi-view projection network (MVPNet). MVPNet\nfirst projects point clouds into multiple depth maps from different\nperspectives, and then fuse depth images together, to learn the compact\nrepresentation with 3D geometry information. Due to the lack of point cloud\ndatasets, we build the first large-scale Lidar-based gait recognition dataset,\nLIDAR GAIT, collected by a Lidar sensor and an RGB camera mounted on a robot.\nThe dataset contains 25,279 sequences from 1,050 subjects and covers many\ndifferent variations, including visibility, views, occlusions, clothing,\ncarrying, and scenes. Extensive experiments show that, (1) 3D structure\ninformation serves as a significant feature for gait recognition. (2) MVPNet\nnot only competes with five representative point-based methods, but it also\noutperforms existing camera-based methods by large margins. (3) The Lidar\nsensor is superior to the RGB camera for gait recognition in the wild. LIDAR\nGAIT dataset and MVPNet code will be publicly available.",
    "descriptor": "\nComments: 16 pages, 16 figures, 3 tables\n",
    "authors": [
      "Chuanfu Shen",
      "Chao Fan",
      "Wei Wu",
      "Rui Wang",
      "George Q. Huang",
      "Shiqi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10598"
  },
  {
    "id": "arXiv:2211.10599",
    "title": "Eigenvalue Analysis and Applications of the Legendre  Dual-Petrov-Galerkin Methods for Initial Value Problems",
    "abstract": "In this paper, we show that the eigenvalues and eigenvectors of the spectral\ndiscretisation matrices resulted from the Legendre dual-Petrov-Galerkin (LDPG)\nmethod for the $m$th-order initial value problem (IVP): $u^{(m)}(t)=\\sigma\nu(t),\\, t\\in (-1,1)$ with constant $\\sigma\\not=0$ and usual initial conditions\nat $t=-1,$ are associated with the generalised Bessel polynomials (GBPs). The\nessential idea of the analysis is to properly construct the basis functions for\nthe solution and its dual spaces so that the matrix of the $m$th derivative is\nan identity matrix, and the mass matrix is then identical or approximately\nequals to the Jacobi matrix of the three-term recurrence of GBPs with specific\ninteger parameters. This allows us to characterise the eigenvalue distributions\nand identify the eigenvectors. As a by-product, we are able to answer some open\nquestions related to the very limited known results on the collocation method\nat Legendre points (studied in 1980s) for the first-order IVP, by reformulating\nit into a Petrov-Galerkin formulation. Moreover, we present two stable\nalgorithms for computing zeros of the GBPs, and develop a general space-time\nspectral method for evolutionary PDEs using either the matrix diagonalisation,\nwhich is restricted to a small number of unknowns in time due to the\nill-conditioning but is fully parallel, or the QZ decomposition which is\nnumerically stable for a large number of unknowns in time but involves\nsequential computations. We provide ample numerical results to demonstrate the\nhigh accuracy and robustness of the space-time spectral methods for some\ninteresting examples of linear and nonlinear wave problems.",
    "descriptor": "\nComments: 25 pages, 31 figures\n",
    "authors": [
      "Desong Kong",
      "Jie Shen",
      "Li-Lian Wang",
      "Shuhuang Xiang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.10599"
  },
  {
    "id": "arXiv:2211.10603",
    "title": "Investigating the Security of EV Charging Mobile Applications As an  Attack Surface",
    "abstract": "The adoption rate of EVs has witnessed a significant increase in recent years\ndriven by multiple factors, chief among which is the increased flexibility and\nease of access to charging infrastructure. To improve user experience, increase\nsystem flexibility and commercialize the charging process, mobile applications\nhave been incorporated into the EV charging ecosystem. EV charging mobile\napplications allow consumers to remotely trigger actions on charging stations\nand use functionalities such as start/stop charging sessions, pay for usage,\nand locate charging stations, to name a few. In this paper, we study the\nsecurity posture of the EV charging ecosystem against remote attacks, which\nexploit the insecurity of the EV charging mobile applications as an attack\nsurface. We leverage a combination of static and dynamic analysis techniques to\nanalyze the security of widely used EV charging mobile applications. Our\nanalysis of 31 widely used mobile applications and their interactions with\nvarious components such as the cloud management systems indicate the lack of\nuser/vehicle verification and improper authorization for critical functions,\nwhich lead to remote (dis)charging session hijacking and Denial of Service\n(DoS) attacks against the EV charging station. Indeed, we discuss specific\nremote attack scenarios and their impact on the EV users. More importantly, our\nanalysis results demonstrate the feasibility of leveraging existing\nvulnerabilities across various EV charging mobile applications to perform\nwide-scale coordinated remote charging/discharging attacks against the\nconnected critical infrastructure (e.g., power grid), with significant\nundesired economical and operational implications. Finally, we propose counter\nmeasures to secure the infrastructure and impede adversaries from performing\nreconnaissance and launching remote attacks using compromised accounts.",
    "descriptor": "",
    "authors": [
      "K. Sarieddine",
      "M. A. Sayed",
      "S. Torabi",
      "R. Atallah",
      "C. Assi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.10603"
  },
  {
    "id": "arXiv:2211.10605",
    "title": "ISAC Meets SWIPT: Multi-functional Wireless Systems Integrating Sensing,  Communication, and Powering",
    "abstract": "This paper unifies integrated sensing and communication (ISAC) and\nsimultaneous wireless information and power transfer (SWIPT), by investigating\na new multi-functional multiple-input multiple-output (MIMO) system integrating\nwireless sensing, communication, and powering. In this system, one\nmulti-antenna hybrid access point (H-AP) transmits wireless signals to\ncommunicate with one multi-antenna information decoding (ID) receiver,\nwirelessly charge one multi-antenna energy harvesting (EH) receiver, and\nperform radar target sensing based on the echo signal at the same time. Under\nthis setup, we aim to reveal the fundamental performance tradeoff limits among\nsensing, communication, and powering, in terms of the estimation Cramer-Rao\nbound (CRB), achievable communication rate, and harvested energy level,\nrespectively. In particular, we consider two different target models for radar\nsensing, namely the point and extended targets, for which we are interested in\nestimating the target angle and the complete target response matrix,\nrespectively. For both models, we define the achievable CRB-rate-energy (C-R-E)\nregion and characterize its Pareto boundary by maximizing the achievable rate\nat the ID receiver, subject to the estimation CRB requirement for target\nsensing, the harvested energy requirement at the EH receiver, and the maximum\ntransmit power constraint at the H-AP. We obtain the well-structured optimal\ntransmit covariance solutions to the two formulated problems by applying\nadvanced convex optimization techniques. Numerical results show the optimal\nC-R-E region boundary achieved by our proposed design, as compared to the\nbenchmark schemes based on time switching and eigenmode transmission (EMT).",
    "descriptor": "\nComments: 30 pages, 9 figures, submitted to IEEE TCOM. arXiv admin note: substantial text overlap with arXiv:2210.16716\n",
    "authors": [
      "Yilong Chen",
      "Haocheng Hua",
      "Jie Xu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.10605"
  },
  {
    "id": "arXiv:2211.10608",
    "title": "Semantic-aware Texture-Structure Feature Collaboration for Underwater  Image Enhancement",
    "abstract": "Underwater image enhancement has become an attractive topic as a significant\ntechnology in marine engineering and aquatic robotics. However, the limited\nnumber of datasets and imperfect hand-crafted ground truth weaken its\nrobustness to unseen scenarios, and hamper the application to high-level vision\ntasks. To address the above limitations, we develop an efficient and compact\nenhancement network in collaboration with a high-level semantic-aware\npretrained model, aiming to exploit its hierarchical feature representation as\nan auxiliary for the low-level underwater image enhancement. Specifically, we\ntend to characterize the shallow layer features as textures while the deep\nlayer features as structures in the semantic-aware model, and propose a\nmulti-path Contextual Feature Refinement Module (CFRM) to refine features in\nmultiple scales and model the correlation between different features. In\naddition, a feature dominative network is devised to perform channel-wise\nmodulation on the aggregated texture and structure features for the adaptation\nto different feature patterns of the enhancement network. Extensive experiments\non benchmarks demonstrate that the proposed algorithm achieves more appealing\nresults and outperforms state-of-the-art methods by large margins. We also\napply the proposed algorithm to the underwater salient object detection task to\nreveal the favorable semantic-aware ability for high-level vision tasks. The\ncode is available at STSC.",
    "descriptor": "\nComments: Accepted by ICRA2022\n",
    "authors": [
      "Di Wang",
      "Long Ma",
      "Risheng Liu",
      "Xin Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10608"
  },
  {
    "id": "arXiv:2211.10609",
    "title": "Class-Specific Attention (CSA) for Time-Series Classification",
    "abstract": "Most neural network-based classifiers extract features using several hidden\nlayers and make predictions at the output layer by utilizing these extracted\nfeatures. We observe that not all features are equally pronounced in all\nclasses; we call such features class-specific features. Existing models do not\nfully utilize the class-specific differences in features as they feed all\nextracted features from the hidden layers equally to the output layers. Recent\nattention mechanisms allow giving different emphasis (or attention) to\ndifferent features, but these attention models are themselves class-agnostic.\nIn this paper, we propose a novel class-specific attention (CSA) module to\ncapture significant class-specific features and improve the overall\nclassification performance of time series. The CSA module is designed in a way\nsuch that it can be adopted in existing neural network (NN) based models to\nconduct time series classification. In the experiments, this module is plugged\ninto five start-of-the-art neural network models for time series classification\nto test its effectiveness by using 40 different real datasets. Extensive\nexperiments show that an NN model embedded with the CSA module can improve the\nbase model in most cases and the accuracy improvement can be up to 42%. Our\nstatistical analysis show that the performance of an NN model embedding the CSA\nmodule is better than the base NN model on 67% of MTS and 80% of UTS test cases\nand is significantly better on 11% of MTS and 13% of UTS test cases.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Yifan Hao",
      "Huiping Cao",
      "K. Selcuk Candan",
      "Jiefei Liu",
      "Huiying Chen",
      "Ziwei Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10609"
  },
  {
    "id": "arXiv:2211.10611",
    "title": "Optical IRS Aided B5G V2V Solution for Road Safety Applications",
    "abstract": "In this work, we showcase the potential benefit of employing optical\nintelligent reflecting surfaces (O-IRS) for improving safety message\ndissemination for vehicular visible light communication (V-VLC) systems\nparticularly at the road intersections. Buildings, roadside structures,\nsignboards, and other impediments commonly hinder line-of-sight (LoS)\ncommunication between vehicles at urban crossroads scenarios. We propose using\nO-IRS at road intersection to improve the communication link's reliability. We\ncompare the performance of proposed scheme with baseline scenarios such as\noptical relay and non line-of-sight (NLOS) road reflection (NRR) aided\nvehicle-to-vehicle (V2V) communication. From obtained results, it has been\nshown that O-IRS offers considerable performance enhancement as compared to the\nbaseline scenarios. In particular, O-IRS can achieve longer communication range\nas compared to the optical relay aided V-VLC systems while ensuring desired\nquality-of-service (QoS).",
    "descriptor": "\nComments: This work has been accepted for presentation at IEEE ANTS 2022\n",
    "authors": [
      "Tathagat Pal",
      "Gurinder Singh",
      "Vivek Ashok Bohara",
      "Anand Srivastava"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.10611"
  },
  {
    "id": "arXiv:2211.10615",
    "title": "Exploring the Confounding Factors of Academic Career Success: An  Empirical Study with Deep Predictive Modeling",
    "abstract": "Understanding determinants of success in academic careers is critically\nimportant to both scholars and their employing organizations. While\nconsiderable research efforts have been made in this direction, there is still\na lack of a quantitative approach to modeling the academic careers of scholars\ndue to the massive confounding factors. To this end, in this paper, we propose\nto explore the determinants of academic career success through an empirical and\npredictive modeling perspective, with a focus on two typical academic honors,\ni.e., IEEE Fellow and ACM Fellow. We analyze the importance of different\nfactors quantitatively, and obtain some insightful findings. Specifically, we\nanalyze the co-author network and find that potential scholars work closely\nwith influential scholars early on and more closely as they grow. Then we\ncompare the academic performance of male and female Fellows. After comparison,\nwe find that to be elected, females need to put in more effort than males. In\naddition, we also find that being a Fellow could not bring the improvements of\ncitations and productivity growth. We hope these derived factors and findings\ncan help scholars to improve their competitiveness and develop well in their\nacademic careers.",
    "descriptor": "",
    "authors": [
      "Chenguang Du",
      "Deqing Wang",
      "Fuzhen Zhuang",
      "Hengshu Zhu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.10615"
  },
  {
    "id": "arXiv:2211.10618",
    "title": "Fully implicit frictional dynamics with soft constraints",
    "abstract": "Dynamics simulation with frictional contacts is important for a wide range of\napplications, from cloth simulation to object manipulation. Recent methods\nusing smoothed friction forces have enabled robust and differentiable\nsimulation of elastodynamics with friction. However, the resulting frictional\nbehaviors can be qualitatively inaccurate and may not converge to analytic\nsolutions. Here we propose an alternative, fully implicit, formulation for\nsimulating elastodynamics subject to frictional contacts with realistic\nfriction behavior. Furthermore, we demonstrate how higher-order time\nintegration can be used in our method, as well as in incremental potential\nmethods. We develop an inexact Newton method with forward-mode automatic\ndifferentiation that simplifies the implementation and improves performance.\nFinally, we show how our method can be extended to respond to volume changes\nusing a unified penalty function derived from first principles and capable of\nemulating compressible as well as nearly incompressible media.",
    "descriptor": "",
    "authors": [
      "Egor Larionov",
      "Andreas Longva",
      "Uri M. Ascher",
      "Jan Bender",
      "Dinesh K. Pai"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.10618"
  },
  {
    "id": "arXiv:2211.10622",
    "title": "Rethinking Batch Sample Relationships for Data Representation: A  Batch-Graph Transformer based Approach",
    "abstract": "Exploring sample relationships within each mini-batch has shown great\npotential for learning image representations. Existing works generally adopt\nthe regular Transformer to model the visual content relationships, ignoring the\ncues of semantic/label correlations between samples. Also, they generally adopt\nthe \"full\" self-attention mechanism which are obviously redundant and also\nsensitive to the noisy samples. To overcome these issues, in this paper, we\ndesign a simple yet flexible Batch-Graph Transformer (BGFormer) for mini-batch\nsample representations by deeply capturing the relationships of image samples\nfrom both visual and semantic perspectives. BGFormer has three main aspects.\n(1) It employs a flexible graph model, termed Batch Graph to jointly encode the\nvisual and semantic relationships of samples within each mini-batch. (2) It\nexplores the neighborhood relationships of samples by borrowing the idea of\nsparse graph representation which thus performs robustly, w.r.t., noisy\nsamples. (3) It devises a novel Transformer architecture that mainly adopts\ndual structure-constrained self-attention (SSA), together with graph\nnormalization, FFN, etc, to carefully exploit the batch graph information for\nsample tokens (nodes) representations. As an application, we apply BGFormer to\nthe metric learning tasks. Extensive experiments on four popular datasets\ndemonstrate the effectiveness of the proposed model.",
    "descriptor": "",
    "authors": [
      "Xixi Wang",
      "Bo Jiang",
      "Xiao Wang",
      "Bin Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10622"
  },
  {
    "id": "arXiv:2211.10623",
    "title": "Do Pre-trained Language Models Indeed Understand Software Engineering  Tasks?",
    "abstract": "Artificial intelligence (AI) for software engineering (SE) tasks has recently\nachieved promising performance. In this paper, we investigate to what extent\nthe pre-trained language model truly understands those SE tasks such as code\nsearch, code summarization, etc. We conduct a comprehensive empirical study on\na board set of AI for SE (AI4SE) tasks by feeding them with variant inputs: 1)\nwith various masking rates and 2) with sufficient input subset method. Then,\nthe trained models are evaluated on different SE tasks, including code search,\ncode summarization, and duplicate bug report detection. Our experimental\nresults show that pre-trained language models are insensitive to the given\ninput, thus they achieve similar performance in these three SE tasks. We refer\nto this phenomenon as overinterpretation, where a model confidently makes a\ndecision without salient features, or where a model finds some irrelevant\nrelationships between the final decision and the dataset. Our study\ninvestigates two approaches to mitigate the overinterpretation phenomenon:\nwhole word mask strategy and ensembling. To the best of our knowledge, we are\nthe first to reveal this overinterpretation phenomenon to the AI4SE community,\nwhich is an important reminder for researchers to design the input for the\nmodels and calls for necessary future work in understanding and implementing\nAI4SE tasks.",
    "descriptor": "",
    "authors": [
      "Yao Li",
      "Tao Zhang",
      "Xiapu Luo",
      "Haipeng Cai",
      "Sen Fang",
      "Dawei Yuan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.10623"
  },
  {
    "id": "arXiv:2211.10624",
    "title": "A Unified Model for Video Understanding and Knowledge Embedding with  Heterogeneous Knowledge Graph Dataset",
    "abstract": "Video understanding is an important task in short video business platforms\nand it has a wide application in video recommendation and classification. Most\nof the existing video understanding works only focus on the information that\nappeared within the video content, including the video frames, audio and text.\nHowever, introducing common sense knowledge from the external Knowledge Graph\n(KG) dataset is essential for video understanding when referring to the content\nwhich is less relevant to the video. Owing to the lack of video knowledge graph\ndataset, the work which integrates video understanding and KG is rare. In this\npaper, we propose a heterogeneous dataset that contains the multi-modal video\nentity and fruitful common sense relations. This dataset also provides multiple\nnovel video inference tasks like the Video-Relation-Tag (VRT) and\nVideo-Relation-Video (VRV) tasks. Furthermore, based on this dataset, we\npropose an end-to-end model that jointly optimizes the video understanding\nobjective with knowledge graph embedding, which can not only better inject\nfactual knowledge into video understanding but also generate effective\nmulti-modal entity embedding for KG. Comprehensive experiments indicate that\ncombining video understanding embedding with factual knowledge benefits the\ncontent-based video retrieval performance. Moreover, it also helps the model\ngenerate better knowledge graph embedding which outperforms traditional\nKGE-based methods on VRT and VRV tasks with at least 42.36% and 17.73%\nimprovement in HITS@10.",
    "descriptor": "",
    "authors": [
      "Jiaxin Deng",
      "Dong Shen",
      "Haojie Pan",
      "Xiangyu Wu",
      "Ximan Liu",
      "Gaofeng Meng",
      "Fan Yang",
      "Size Li",
      "Ruiji Fu",
      "Zhongyuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10624"
  },
  {
    "id": "arXiv:2211.10627",
    "title": "Graph Augmentation Clustering Network",
    "abstract": "Existing graph clustering networks heavily rely on a predefined graph and may\nfail if the initial graph is of low quality. To tackle this issue, we propose a\nnovel graph augmentation clustering network capable of adaptively enhancing the\ninitial graph to achieve better clustering performance. Specifically, we first\nintegrate the node attribute and topology structure information to learn the\nlatent feature representation. Then, we explore the local geometric structure\ninformation on the embedding space to construct an adjacency graph and\nsubsequently develop an adaptive graph augmentation architecture to fuse that\ngraph with the initial one dynamically. Finally, we minimize the Jeffreys\ndivergence between multiple derived distributions to conduct network training\nin an unsupervised fashion. Extensive experiments on six commonly used\nbenchmark datasets demonstrate that the proposed method consistently\noutperforms several state-of-the-art approaches. In particular, our method\nimproves the ARI by more than 9.39\\% over the best baseline on DBLP. The source\ncodes and data have been submitted to the appendix.",
    "descriptor": "",
    "authors": [
      "Zhihao Peng",
      "Hui Liu",
      "Yuheng Jia",
      "Junhui Hou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.10627"
  },
  {
    "id": "arXiv:2211.10628",
    "title": "An Accurate Hybrid Delay Model for Multi-Input Gates",
    "abstract": "Accurately modeling the delay of multi-input gates is challenging due to\nvariations caused by switching different inputs in close temporal proximity.\nThis paper introduces a hybrid model for a CMOS NOR gate, which is based on\nreplacing transistors with time-variant resistors. We analytically solve the\nresulting non-constant coefficient differential equations and derive\nexpressions for the gate delays, which also paved the way to an empirical\nparametrization procedure. By comparison with Spice simulation data, we show\nthat our model indeed faithfully represents all relevant multi-input switching\neffects. Using an implementation in the Involution Tool, we also demonstrate\nthat it surpasses the few alternative models known so far in terms of accuracy.",
    "descriptor": "",
    "authors": [
      "Arman Ferdowsi",
      "Ulrich Schmid",
      "Josef Salzmann"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2211.10628"
  },
  {
    "id": "arXiv:2211.10629",
    "title": "Unifying Label-inputted Graph Neural Networks with Deep Equilibrium  Models",
    "abstract": "For node classification, Graph Neural Networks (GNN) assign predefined labels\nto graph nodes according to node features propagated along the graph structure.\nApart from the traditional end-to-end manner inherited from deep learning, many\nsubsequent works input assigned labels into GNNs to improve their\nclassification performance. Such label-inputted GNNs (LGNN) combine the\nadvantages of learnable feature propagation and long-range label propagation,\nproducing state-of-the-art performance on various benchmarks. However, the\ntheoretical foundations of LGNNs are not well-established, and the combination\nis with seam because the long-range propagation is memory-consuming for\noptimization. To this end, this work interprets LGNNs with the theory of\nImplicit GNN (IGNN), which outputs a fixed state point of iterating its network\ninfinite times and optimizes the infinite-range propagation with constant\nmemory consumption. Besides, previous contributions to LGNNs inspire us to\novercome the heavy computation in training IGNN by iterating the network only\nonce but starting from historical states, which are randomly masked in\nforward-pass to implicitly guarantee the existence and uniqueness of the fixed\npoint. Our improvements to IGNNs are network agnostic: for the first time, they\nare extended with complex networks and applied to large-scale graphs.\nExperiments on two synthetic and six real-world datasets verify the advantages\nof our method in terms of long-range dependencies capturing, label transitions\nmodelling, accuracy, scalability, efficiency, and well-posedness.",
    "descriptor": "\nComments: 11 pages, 5 figures\n",
    "authors": [
      "Yi Luo",
      "Guiduo Duan",
      "Guangchun Luo",
      "Aiguo Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10629"
  },
  {
    "id": "arXiv:2211.10630",
    "title": "I saw, I conceived, I concluded: Progressive Concepts as Bottlenecks",
    "abstract": "Concept bottleneck models (CBMs) include a bottleneck of human-interpretable\nconcepts providing explainability and intervention during inference by\ncorrecting the predicted, intermediate concepts. This makes CBMs attractive for\nhigh-stakes decision-making. In this paper, we take the quality assessment of\nfetal ultrasound scans as a real-life use case for CBM decision support in\nhealthcare. For this case, simple binary concepts are not sufficiently\nreliable, as they are mapped directly from images of highly variable quality,\nfor which variable model calibration might lead to unstable binarized concepts.\nMoreover, scalar concepts do not provide the intuitive spatial feedback\nrequested by users.\nTo address this, we design a hierarchical CBM imitating the sequential expert\ndecision-making process of \"seeing\", \"conceiving\" and \"concluding\". Our model\nfirst passes through a layer of visual, segmentation-based concepts, and next a\nsecond layer of property concepts directly associated with the decision-making\ntask. We note that experts can intervene on both the visual and property\nconcepts during inference. Additionally, we increase the bottleneck capacity by\nconsidering task-relevant concept interaction.\nOur application of ultrasound scan quality assessment is challenging, as it\nrelies on balancing the (often poor) image quality against an assessment of the\nvisibility and geometric properties of standardized image content. Our\nvalidation shows that -- in contrast with previous CBM models -- our CBM models\nactually outperform equivalent concept-free models in terms of predictive\nperformance. Moreover, we illustrate how interventions can further improve our\nperformance over the state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Manxi Lin",
      "Aasa Feragen",
      "Zahra Bashir",
      "Martin Gr\u00f8nneb\u00e6k Tolsgaard",
      "Anders Nymark Christensen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10630"
  },
  {
    "id": "arXiv:2211.10636",
    "title": "Efficient Video Representation Learning via Masked Video Modeling with  Motion-centric Token Selection",
    "abstract": "Self-supervised Video Representation Learning (VRL) aims to learn\ntransferrable representations from uncurated, unlabeled video streams that\ncould be utilized for diverse downstream tasks. With recent advances in Masked\nImage Modeling (MIM), in which the model learns to predict randomly masked\nregions in the images given only the visible patches, MIM-based VRL methods\nhave emerged and demonstrated their potential by significantly outperforming\nprevious VRL methods. However, they require an excessive amount of computations\ndue to the added temporal dimension. This is because existing MIM-based VRL\nmethods overlook spatial and temporal inequality of information density among\nthe patches in arriving videos by resorting to random masking strategies,\nthereby wasting computations on predicting uninformative tokens/frames. To\ntackle these limitations of Masked Video Modeling, we propose a new token\nselection method that masks our more important tokens according to the object's\nmotions in an online manner, which we refer to as Motion-centric Token\nSelection. Further, we present a dynamic frame selection strategy that allows\nthe model to focus on informative and causal frames with minimal redundancy. We\nvalidate our method over multiple benchmark and Ego4D datasets, showing that\nthe pre-trained model using our proposed method significantly outperforms\nstate-of-the-art VRL methods on downstream tasks, such as action recognition\nand object state change classification while largely reducing memory\nrequirements during pre-training and fine-tuning.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Sunil Hwang",
      "Jaehong Yoon",
      "Youngwan Lee",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10636"
  },
  {
    "id": "arXiv:2211.10641",
    "title": "Domain-Adaptive Self-Supervised Pre-Training for Face & Body Detection  in Drawings",
    "abstract": "Drawings are powerful means of pictorial abstraction and communication.\nUnderstanding diverse forms of drawings, including digital arts, cartoons, and\ncomics, has been a major problem of interest for the computer vision and\ncomputer graphics communities. Although there are large amounts of digitized\ndrawings from comic books and cartoons, they contain vast stylistic variations,\nwhich necessitate expensive manual labeling for training domain-specific\nrecognizers. In this work, we show how self-supervised learning, based on a\nteacher-student network with a modified student network update design, can be\nused to build face and body detectors. Our setup allows exploiting large\namounts of unlabeled data from the target domain when labels are provided for\nonly a small subset of it. We further demonstrate that style transfer can be\nincorporated into our learning pipeline to bootstrap detectors using a vast\namount of out-of-domain labeled images from natural images (i.e., images from\nthe real world). Our combined architecture yields detectors with\nstate-of-the-art (SOTA) and near-SOTA performance using minimal annotation\neffort.",
    "descriptor": "\nComments: Preprint, 8 pages of the paper itself + 7 pages of Supplementary Material. Includes 8 figures and 7 tables\n",
    "authors": [
      "Bar\u0131\u015f Batuhan Topal",
      "Deniz Yuret",
      "Tevfik Metin Sezgin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10641"
  },
  {
    "id": "arXiv:2211.10642",
    "title": "On the Multidimensional Augmentation of Fingerprint Data for Indoor  Localization in A Large-Scale Building Complex Based on Multi-Output Gaussian  Process",
    "abstract": "Wi-Fi fingerprinting becomes a dominant solution for large-scale indoor\nlocalization due to its major advantage of not requiring new infrastructure and\ndedicated devices. The number and the distribution of Reference Points (RPs)\nfor the measurement of localization fingerprints like RSSI during the offline\nphase, however, greatly affects the localization accuracy; for instance, the\nUJIIndoorLoc is known to have the issue of uneven spatial distribution of RPs\nover buildings and floors. Data augmentation has been proposed as a feasible\nsolution to not only improve the smaller number and the uneven distribution of\nRPs in the existing fingerprint databases but also reduce the labor and time\ncosts of constructing new fingerprint databases. In this paper, we propose the\nmultidimensional augmentation of fingerprint data for indoor localization in a\nlarge-scale building complex based on Multi-Output Gaussian Process (MOGP) and\nsystematically investigate the impact of augmentation ratio as well as MOGP\nkernel functions and models with their hyperparameters on the performance of\nindoor localization using the UJIIndoorLoc database and the state-of-the-art\nneural network indoor localization model based on a hierarchical RNN. The\ninvestigation based on experimental results suggests that we can generate\nsynthetic RSSI fingerprint data up to ten times the original data -- i.e., the\naugmentation ratio of 10 -- through the proposed multidimensional MOGP-based\ndata augmentation without significantly affecting the indoor localization\nperformance compared to that of the original data alone, which extends the\nspatial coverage of the combined RPs and thereby could improve the localization\nperformance at the locations that are not part of the test dataset.",
    "descriptor": "\nComments: 10 pages, 6 figures, under review for journal publication\n",
    "authors": [
      "Zhe Tang",
      "Sihao Li",
      "Kyeong Soo Kim",
      "Jeremy Smith"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10642"
  },
  {
    "id": "arXiv:2211.10643",
    "title": "Downscaled Representation Matters: Improving Image Rescaling with  Collaborative Downscaled Images",
    "abstract": "Deep networks have achieved great success in image rescaling (IR) task that\nseeks to learn the optimal downscaled representations, i.e., low-resolution\n(LR) images, to reconstruct the original high-resolution (HR) images. Compared\nwith super-resolution methods that consider a fixed downscaling scheme, e.g.,\nbicubic, IR often achieves significantly better reconstruction performance\nthanks to the learned downscaled representations. This highlights the\nimportance of a good downscaled representation in image reconstruction tasks.\nExisting IR methods mainly learn the downscaled representation by jointly\noptimizing the downscaling and upscaling models. Unlike them, we seek to\nimprove the downscaled representation through a different and more direct way:\noptimizing the downscaled image itself instead of the down-/upscaling models.\nSpecifically, we propose a collaborative downscaling scheme that directly\ngenerates the collaborative LR examples by descending the gradient w.r.t. the\nreconstruction loss on them to benefit the IR process. Furthermore, since LR\nimages are downscaled from the corresponding HR images, one can also improve\nthe downscaled representation if we have a better representation in the HR\ndomain. Inspired by this, we propose a Hierarchical Collaborative Downscaling\n(HCD) method that performs gradient descent in both HR and LR domains to\nimprove the downscaled representations. Extensive experiments show that our HCD\nsignificantly improves the reconstruction performance both quantitatively and\nqualitatively. Moreover, we also highlight the flexibility of our HCD since it\ncan generalize well across diverse IR models.",
    "descriptor": "\nComments: 11 pages, 8 figures\n",
    "authors": [
      "Bingna Xu",
      "Yong Guo",
      "Luoqian Jiang",
      "Mianjie Yu",
      "Jian Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10643"
  },
  {
    "id": "arXiv:2211.10646",
    "title": "Rate-Distortion Modeling for Bit Rate Constrained Point Cloud  Compression",
    "abstract": "As being one of the main representation formats of 3D real world and\nwell-suited for virtual reality and augmented reality applications, point\nclouds have gained a lot of popularity. In order to reduce the huge amount of\ndata, a considerable amount of research on point cloud compression has been\ndone. However, given a target bit rate, how to properly choose the color and\ngeometry quantization parameters for compressing point clouds is still an open\nissue. In this paper, we propose a rate-distortion model based quantization\nparameter selection scheme for bit rate constrained point cloud compression.\nFirstly, to overcome the measurement uncertainty in evaluating the distortion\nof the point clouds, we propose a unified model to combine the geometry\ndistortion and color distortion. In this model, we take into account the\ncorrelation between geometry and color variables of point clouds and derive a\ndimensionless quantity to represent the overall quality degradation. Then, we\nderive the relationships of overall distortion and bit rate with the\nquantization parameters. Finally, we formulate the bit rate constrained point\ncloud compression as a constrained minimization problem using the derived\npolynomial models and deduce the solution via an iterative numerical method.\nExperimental results show that the proposed algorithm can achieve optimal\ndecoded point cloud quality at various target bit rates, and substantially\noutperform the video-rate-distortion model based point cloud compression\nscheme.",
    "descriptor": "\nComments: Accepted to IEEE Transactions on Circuits and Systems for Video Technology\n",
    "authors": [
      "Pan Gao",
      "Shengzhou Luo",
      "Manoranjan Paul"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Information Theory (cs.IT)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.10646"
  },
  {
    "id": "arXiv:2211.10647",
    "title": "Mutual Balancing in State-Object Components for Compositional Zero-Shot  Learning",
    "abstract": "Compositional Zero-Shot Learning (CZSL) aims to recognize unseen compositions\nfrom seen states and objects. The disparity between the manually labeled\nsemantic information and its actual visual features causes a significant\nimbalance of visual deviation in the distribution of various object classes and\nstate classes, which is ignored by existing methods. To ameliorate these\nissues, we consider the CZSL task as an unbalanced multi-label classification\ntask and propose a novel method called MUtual balancing in STate-object\ncomponents (MUST) for CZSL, which provides a balancing inductive bias for the\nmodel. In particular, we split the classification of the composition classes\ninto two consecutive processes to analyze the entanglement of the two\ncomponents to get additional knowledge in advance, which reflects the degree of\nvisual deviation between the two components. We use the knowledge gained to\nmodify the model's training process in order to generate more distinct class\nborders for classes with significant visual deviations. Extensive experiments\ndemonstrate that our approach significantly outperforms the state-of-the-art on\nMIT-States, UT-Zappos, and C-GQA when combined with the basic CZSL frameworks,\nand it can improve various CZSL frameworks. Our codes are available on\nhttps://anonymous.4open.science/r/MUST_CGE/.",
    "descriptor": "",
    "authors": [
      "Chenyi Jiang",
      "Dubing Chen",
      "Shidong Wang",
      "Yuming Shen",
      "Haofeng Zhang",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10647"
  },
  {
    "id": "arXiv:2211.10648",
    "title": "Anonymizing Periodical Releases of SRS Data by Fusing Differential  Privacy",
    "abstract": "Spontaneous reporting systems (SRS) have been developed to collect adverse\nevent records that contain personal demographics and sensitive information like\ndrug indications and adverse reactions. The release of SRS data may disclose\nthe privacy of the data provider. Unlike other microdata, very few\nanonymyization methods have been proposed to protect individual privacy while\npublishing SRS data. MS(k, {\\theta}*)-bounding is the first privacy model for\nSRS data that considers multiple individual records, mutli-valued sensitive\nattributes, and rare events. PPMS(k, {\\theta}*)-bounding then is proposed for\nsolving cross-release attacks caused by the follow-up cases in the periodical\nSRS releasing scenario. A recent trend of microdata anonymization combines the\ntraditional syntactic model and differential privacy, fusing the advantages of\nboth models to yield a better privacy protection method. This paper proposes\nthe PPMS-DP(k, {\\theta}*, {\\epsilon}) framework, an enhancement of PPMS(k,\n{\\theta}*)-bounding that embraces differential privacy to improve privacy\nprotection of periodically released SRS data. We propose two anonymization\nalgorithms conforming to the PPMS-DP(k, {\\theta}*, {\\epsilon}) framework,\nPPMS-DPnum and PPMS-DPall. Experimental results on the FAERS datasets show that\nboth PPMS-DPnum and PPMS-DPall provide significantly better privacy protection\nthan PPMS-(k, {\\theta}*)-bounding without sacrificing data distortion and data\nutility.",
    "descriptor": "\nComments: 10 pages, 11 figures\n",
    "authors": [
      "Yi-Yuang Wu",
      "Zhi-Xun Shen",
      "Wen-Yang Lin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.10648"
  },
  {
    "id": "arXiv:2211.10649",
    "title": "LibSignal: An Open Library for Traffic Signal Control",
    "abstract": "This paper introduces a library for cross-simulator comparison of\nreinforcement learning models in traffic signal control tasks. This library is\ndeveloped to implement recent state-of-the-art reinforcement learning models\nwith extensible interfaces and unified cross-simulator evaluation metrics. It\nsupports commonly-used simulators in traffic signal control tasks, including\nSimulation of Urban MObility(SUMO) and CityFlow, and multiple benchmark\ndatasets for fair comparisons. We conducted experiments to validate our\nimplementation of the models and to calibrate the simulators so that the\nexperiments from one simulator could be referential to the other. Based on the\nvalidated models and calibrated environments, this paper compares and reports\nthe performance of current state-of-the-art RL algorithms across different\ndatasets and simulators. This is the first time that these methods have been\ncompared fairly under the same datasets with different simulators.",
    "descriptor": "\nComments: 11 pages + 6 pages appendix. Accepted by NeurIPS 2022 Workshop: Reinforcement Learning for Real Life. Website: this https URL\n",
    "authors": [
      "Hao Mei",
      "Xiaoliang Lei",
      "Longchao Da",
      "Bin Shi",
      "Hua Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10649"
  },
  {
    "id": "arXiv:2211.10655",
    "title": "Solving 3D Inverse Problems using Pre-trained 2D Diffusion Models",
    "abstract": "Diffusion models have emerged as the new state-of-the-art generative model\nwith high quality samples, with intriguing properties such as mode coverage and\nhigh flexibility. They have also been shown to be effective inverse problem\nsolvers, acting as the prior of the distribution, while the information of the\nforward model can be granted at the sampling stage. Nonetheless, as the\ngenerative process remains in the same high dimensional (i.e. identical to data\ndimension) space, the models have not been extended to 3D inverse problems due\nto the extremely high memory and computational cost. In this paper, we combine\nthe ideas from the conventional model-based iterative reconstruction with the\nmodern diffusion models, which leads to a highly effective method for solving\n3D medical image reconstruction tasks such as sparse-view tomography, limited\nangle tomography, compressed sensing MRI from pre-trained 2D diffusion models.\nIn essence, we propose to augment the 2D diffusion prior with a model-based\nprior in the remaining direction at test time, such that one can achieve\ncoherent reconstructions across all dimensions. Our method can be run in a\nsingle commodity GPU, and establishes the new state-of-the-art, showing that\nthe proposed method can perform reconstructions of high fidelity and accuracy\neven in the most extreme cases (e.g. 2-view 3D tomography). We further reveal\nthat the generalization capacity of the proposed method is surprisingly high,\nand can be used to reconstruct volumes that are entirely different from the\ntraining dataset.",
    "descriptor": "\nComments: 14 pages, 10 figures\n",
    "authors": [
      "Hyungjin Chung",
      "Dohoon Ryu",
      "Michael T. McCann",
      "Marc L. Klasky",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10655"
  },
  {
    "id": "arXiv:2211.10656",
    "title": "Parallel Diffusion Models of Operator and Image for Blind Inverse  Problems",
    "abstract": "Diffusion model-based inverse problem solvers have demonstrated\nstate-of-the-art performance in cases where the forward operator is known (i.e.\nnon-blind). However, the applicability of the method to blind inverse problems\nhas yet to be explored. In this work, we show that we can indeed solve a family\nof blind inverse problems by constructing another diffusion prior for the\nforward operator. Specifically, parallel reverse diffusion guided by gradients\nfrom the intermediate stages enables joint optimization of both the forward\noperator parameters as well as the image, such that both are jointly estimated\nat the end of the parallel reverse diffusion procedure. We show the efficacy of\nour method on two representative tasks -- blind deblurring, and imaging through\nturbulence -- and show that our method yields state-of-the-art performance,\nwhile also being flexible to be applicable to general blind inverse problems\nwhen we know the functional forms.",
    "descriptor": "\nComments: 25 pages, 13 figures\n",
    "authors": [
      "Hyungjin Chung",
      "Jeongsol Kim",
      "Sehui Kim",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.10656"
  },
  {
    "id": "arXiv:2211.10658",
    "title": "EDGE: Editable Dance Generation From Music",
    "abstract": "Dance is an important human art form, but creating new dances can be\ndifficult and time-consuming. In this work, we introduce Editable Dance\nGEneration (EDGE), a state-of-the-art method for editable dance generation that\nis capable of creating realistic, physically-plausible dances while remaining\nfaithful to the input music. EDGE uses a transformer-based diffusion model\npaired with Jukebox, a strong music feature extractor, and confers powerful\nediting capabilities well-suited to dance, including joint-wise conditioning,\nand in-betweening. We introduce a new metric for physical plausibility, and\nevaluate dance quality generated by our method extensively through (1) multiple\nquantitative metrics on physical plausibility, beat alignment, and diversity\nbenchmarks, and more importantly, (2) a large-scale user study, demonstrating a\nsignificant improvement over previous state-of-the-art methods. Qualitative\nsamples from our model can be found at our website.",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Jonathan Tseng",
      "Rodrigo Castellon",
      "C. Karen Liu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.10658"
  },
  {
    "id": "arXiv:2211.10660",
    "title": "Evaluating the Perceived Safety of Urban City via Maximum Entropy Deep  Inverse Reinforcement Learning",
    "abstract": "Inspired by expert evaluation policy for urban perception, we proposed a\nnovel inverse reinforcement learning (IRL) based framework for predicting urban\nsafety and recovering the corresponding reward function. We also presented a\nscalable state representation method to model the prediction problem as a\nMarkov decision process (MDP) and use reinforcement learning (RL) to solve the\nproblem. Additionally, we built a dataset called SmallCity based on the\ncrowdsourcing method to conduct the research. As far as we know, this is the\nfirst time the IRL approach has been introduced to the urban safety perception\nand planning field to help experts quantitatively analyze perceptual features.\nOur results showed that IRL has promising prospects in this field. We will\nlater open-source the crowdsourcing data collection site and the model proposed\nin this paper.",
    "descriptor": "\nComments: ACML2022 Camera-ready Version\n",
    "authors": [
      "Yaxuan Wang",
      "Zhixin Zeng",
      "Qijun Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10660"
  },
  {
    "id": "arXiv:2211.10661",
    "title": "Phonemic Adversarial Attack against Audio Recognition in Real World",
    "abstract": "Recently, adversarial attacks for audio recognition have attracted much\nattention. However, most of the existing studies mainly rely on the\ncoarse-grain audio features at the instance level to generate adversarial\nnoises, which leads to expensive generation time costs and weak universal\nattacking ability. Motivated by the observations that all audio speech consists\nof fundamental phonemes, this paper proposes a phonemic adversarial tack (PAT)\nparadigm, which attacks the fine-grain audio features at the phoneme level\ncommonly shared across audio instances, to generate phonemic adversarial\nnoises, enjoying the more general attacking ability with fast generation speed.\nSpecifically, for accelerating the generation, a phoneme density balanced\nsampling strategy is introduced to sample quantity less but phonemic features\nabundant audio instances as the training data via estimating the phoneme\ndensity, which substantially alleviates the heavy dependency on the large\ntraining dataset. Moreover, for promoting universal attacking ability, the\nphonemic noise is optimized in an asynchronous way with a sliding window, which\nenhances the phoneme diversity and thus well captures the critical fundamental\nphonemic patterns. By conducting extensive experiments, we comprehensively\ninvestigate the proposed PAT framework and demonstrate that it outperforms the\nSOTA baselines by large margins (i.e., at least 11X speed up and 78% attacking\nability improvement).",
    "descriptor": "",
    "authors": [
      "Jiakai Wang",
      "Zhendong Chen",
      "Zixin Yin",
      "Qinghong Yang",
      "Xianglong Liu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.10661"
  },
  {
    "id": "arXiv:2211.10665",
    "title": "CryptOpt: Verified Compilation with Random Program Search for  Cryptographic Primitives",
    "abstract": "Most software domains rely on compilers to translate high-level code to\nmultiple different machine languages, with performance not too much worse than\nwhat developers would have the patience to write directly in assembly language.\nHowever, cryptography has been an exception, where many performance-critical\nroutines have been written directly in assembly (sometimes through\nmetaprogramming layers). Some past work has shown how to do formal verification\nof that assembly, and other work has shown how to generate C code automatically\nalong with formal proof, but with consequent performance penalties vs. the\nbest-known assembly. We present CryptOpt, the first compilation pipeline that\nspecializes high-level cryptographic functional programs into assembly code\nsignificantly faster than what GCC or Clang produce, with mechanized proof (in\nCoq) whose final theorem statement mentions little beyond the input functional\nprogram and the operational semantics of x86-64 assembly. On the optimization\nside, we apply randomized search through the space of assembly programs, with\nrepeated automatic benchmarking on target CPUs. On the formal-verification\nside, we connect to the Fiat Cryptography framework (which translates\nfunctional programs into C-like IR code) and extend it with a new formally\nverified program-equivalence checker, incorporating a modest subset of known\nfeatures of SMT solvers and symbolic-execution engines. The overall prototype\nis quite practical, e.g. producing new fastest-known implementations for the\nrelatively new Intel i9 12G, of finite-field arithmetic for both Curve25519\n(part of the TLS standard) and the Bitcoin elliptic curve secp256k1.",
    "descriptor": "",
    "authors": [
      "Joel Kuepper",
      "Andres Erbsen",
      "Jason Gross",
      "Owen Conoly",
      "Chuyue Sun",
      "Samuel Tian",
      "David Wu",
      "Adam Chlipala",
      "Chitchanok Chuengsatiansup",
      "Daniel Genkin",
      "Markus Wagner",
      "Yuval Yarom"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.10665"
  },
  {
    "id": "arXiv:2211.10666",
    "title": "VarietySound: Timbre-Controllable Video to Sound Generation via  Unsupervised Information Disentanglement",
    "abstract": "Video to sound generation aims to generate realistic and natural sound given\na video input. However, previous video-to-sound generation methods can only\ngenerate a random or average timbre without any controls or specializations of\nthe generated sound timbre, leading to the problem that people cannot obtain\nthe desired timbre under these methods sometimes. In this paper, we pose the\ntask of generating sound with a specific timbre given a video input and a\nreference audio sample. To solve this task, we disentangle each target sound\naudio into three components: temporal information, acoustic information, and\nbackground information. We first use three encoders to encode these components\nrespectively: 1) a temporal encoder to encode temporal information, which is\nfed with video frames since the input video shares the same temporal\ninformation as the original audio; 2) an acoustic encoder to encode timbre\ninformation, which takes the original audio as input and discards its temporal\ninformation by a temporal-corrupting operation; and 3) a background encoder to\nencode the residual or background sound, which uses the background part of the\noriginal audio as input. To make the generated result achieve better quality\nand temporal alignment, we also adopt a mel discriminator and a temporal\ndiscriminator for the adversarial training. Our experimental results on the VAS\ndataset demonstrate that our method can generate high-quality audio samples\nwith good synchronization with events in video and high timbre similarity with\nthe reference audio.",
    "descriptor": "",
    "authors": [
      "Chenye Cui",
      "Yi Ren",
      "Jinglin Liu",
      "Rongjie Huang",
      "Zhou Zhao"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.10666"
  },
  {
    "id": "arXiv:2211.10670",
    "title": "Towards Adversarial Robustness of Deep Vision Algorithms",
    "abstract": "Deep learning methods have achieved great success in solving computer vision\ntasks, and they have been widely utilized in artificially intelligent systems\nfor image processing, analysis, and understanding. However, deep neural\nnetworks have been shown to be vulnerable to adversarial perturbations in input\ndata. The security issues of deep neural networks have thus come to the fore.\nIt is imperative to study the adversarial robustness of deep vision algorithms\ncomprehensively. This talk focuses on the adversarial robustness of image\nclassification models and image denoisers. We will discuss the robustness of\ndeep vision algorithms from three perspectives: 1) robustness evaluation (we\npropose the ObsAtk to evaluate the robustness of denoisers), 2) robustness\nimprovement (HAT, TisODE, and CIFS are developed to robustify vision models),\nand 3) the connection between adversarial robustness and generalization\ncapability to new domains (we find that adversarially robust denoisers can deal\nwith unseen types of real-world noise).",
    "descriptor": "\nComments: PhD thesis\n",
    "authors": [
      "Hanshu Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10670"
  },
  {
    "id": "arXiv:2211.10672",
    "title": "Leveraging Users' Social Network Embeddings for Fake News Detection on  Twitter",
    "abstract": "Social networks (SNs) are increasingly important sources of news for many\npeople. The online connections made by users allows information to spread more\neasily than traditional news media (e.g., newspaper, television). However, they\nalso make the spread of fake news easier than in traditional media, especially\nthrough the users' social network connections. In this paper, we focus on\ninvestigating if the SNs' users connection structure can aid fake news\ndetection on Twitter. In particular, we propose to embed users based on their\nfollower or friendship networks on the Twitter platform, so as to identify the\ngroups that users form. Indeed, by applying unsupervised graph embedding\nmethods on the graphs from the Twitter users' social network connections, we\nobserve that users engaged with fake news are more tightly clustered together\nthan users only engaged in factual news. Thus, we hypothesise that the embedded\nuser's network can help detect fake news effectively. Through extensive\nexperiments using a publicly available Twitter dataset, our results show that\napplying graph embedding methods on SNs, using the user connections as network\ninformation, can indeed classify fake news more effectively than most\nlanguage-based approaches. Specifically, we observe a significant improvement\nover using only the textual information (i.e., TF.IDF or a BERT language\nmodel), as well as over models that deploy both advanced textual features\n(i.e., stance detection) and complex network features (e.g., users network,\npublishers cross citations). We conclude that the Twitter users' friendship and\nfollowers network information can significantly outperform language-based\napproaches, as well as the existing state-of-the-art fake news detection models\nthat use a more sophisticated network structure, in classifying fake news on\nTwitter.",
    "descriptor": "\nComments: 15 pages, 5 figures\n",
    "authors": [
      "Ting Su",
      "Craig Macdonald",
      "Iadh Ounis"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.10672"
  },
  {
    "id": "arXiv:2211.10674",
    "title": "Passivity and Immersion based-modified gradient estimator: A control  perspective in parameter estimation",
    "abstract": "In this paper, a constructive and systematic strategy with more apparent\ndegrees of freedom to achieve the accurate estimation of unknown parameters via\na control perspective is proposed. By adding a virtual control in the final\nequation of the gradient dynamics, the Gradient Estimator (GE) and Memory\nRegressor and Extension (MRE) approaches are extended. The solution of the\nvirtual control law is identified by the P&I approach. The P&I approach is\nbased on the choice of an appropriate implicit manifold and the generation of a\nsuitable passive output and a related storage function. This facilitates the\nvirtual control law being obtained in a way that the parametric error converges\nasymptotically to zero. Because the above ideas connect with the P&I approach\nand GE, the developed methodology is labeled the passivity and immersion-based\nmodified gradient estimator (MGE). The proposed P&I-based modified gradient\nestimator is extended via the MRE approach. This modification provides improved\ntransient response and fast convergence. Based on certain PE and non-PE\nexamples, a comparative analysis is carried out to show the efficacy of the\nproposed approaches.",
    "descriptor": "",
    "authors": [
      "Syed Shadab Nayyer",
      "G. Revati",
      "S. R. Wagh",
      "N. M. Singh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.10674"
  },
  {
    "id": "arXiv:2211.10675",
    "title": "Proceedings 9th Workshop on Horn Clauses for Verification and Synthesis  and 10th International Workshop on Verification and Program Transformation",
    "abstract": "These proceedings include selected papers presented at the 9th Workshop on\nHorn Clauses for Verification and Synthesis and the Tenth International\nWorkshop on Verification and Program Transformation, both affiliated with ETAPS\n2022.\nMany Program Verification and Synthesis problems of interest can be modeled\ndirectly using Horn clauses and many recent advances in the CLP and CAV\ncommunities have centered around efficiently solving problems presented as Horn\nclauses.\nThe HCVS series of workshops aims to bring together researchers working in\nthe communities of Constraint/Logic Programming (e.g., ICLP and CP), Program\nVerification (e.g., CAV, TACAS, and VMCAI), and Automated Deduction (e.g.,\nCADE, IJCAR), on the topic of Horn clause based analysis, verification, and\nsynthesis.\nHorn clauses for verification and synthesis have been advocated by these\ncommunities in different times and from different perspectives and HCVS is\norganized to stimulate interaction and a fruitful exchange and integration of\nexperiences.\nThe aim of the VPT workshop is to bring together researchers working in the\nfields of Program Verification and Program Transformation.\nThere is a great potential for beneficial interactions between these two\nfields because:\n1) On one hand, methods and tools developed in the field of Program\nTransformation such as partial evaluation, fold/unfold transformations, and\nsupercompilation, have all been applied with success for the verification of\ninfinite state and parameterized systems.\n2) On the other hand, model checking, abstract interpretation, SAT and SMT\nsolving and automated theorem proving have been used to enhance program\ntransformation techniques. Moreover, the formal certification of program\ntransformation tools, such as automated refactoring tools and compilers, has\nrecently attracted considerable interest, posed major challenges.",
    "descriptor": "",
    "authors": [
      "Geoffrey W. Hamilton",
      "Temesghen Kahsai",
      "Maurizio Proietti"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)",
      "Symbolic Computation (cs.SC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.10675"
  },
  {
    "id": "arXiv:2211.10678",
    "title": "Entity-Assisted Language Models for Identifying Check-worthy Sentences",
    "abstract": "We propose a new uniform framework for text classification and ranking that\ncan automate the process of identifying check-worthy sentences in political\ndebates and speech transcripts. Our framework combines the semantic analysis of\nthe sentences, with additional entity embeddings obtained through the\nidentified entities within the sentences. In particular, we analyse the\nsemantic meaning of each sentence using state-of-the-art neural language models\nsuch as BERT, ALBERT, and RoBERTa, while embeddings for entities are obtained\nfrom knowledge graph (KG) embedding models. Specifically, we instantiate our\nframework using five different language models, entity embeddings obtained from\nsix different KG embedding models, as well as two combination methods leading\nto several Entity-Assisted neural language models. We extensively evaluate the\neffectiveness of our framework using two publicly available datasets from the\nCLEF' 2019 & 2020 CheckThat! Labs. Our results show that the neural language\nmodels significantly outperform traditional TF.IDF and LSTM methods. In\naddition, we show that the ALBERT model is consistently the most effective\nmodel among all the tested neural language models. Our entity embeddings\nsignificantly outperform other existing approaches from the literature that are\nbased on similarity and relatedness scores between the entities in a sentence,\nwhen used alongside a KG embedding.",
    "descriptor": "\nComments: 22 pages, 15 tables, 3 figures\n",
    "authors": [
      "Ting Su",
      "Craig Macdonald",
      "Iadh Ounis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10678"
  },
  {
    "id": "arXiv:2211.10681",
    "title": "Decomposed Soft Prompt Guided Fusion Enhancing for Compositional  Zero-Shot Learning",
    "abstract": "Compositional Zero-Shot Learning (CZSL) aims to recognize novel concepts\nformed by known states and objects during training. Existing methods either\nlearn the combined state-object representation, challenging the generalization\nof unseen compositions, or design two classifiers to identify state and object\nseparately from image features, ignoring the intrinsic relationship between\nthem. To jointly eliminate the above issues and construct a more robust CZSL\nsystem, we propose a novel framework termed Decomposed Fusion with Soft Prompt\n(DFSP)1, by involving vision-language models (VLMs) for unseen composition\nrecognition. Specifically, DFSP constructs a vector combination of learnable\nsoft prompts with state and object to establish the joint representation of\nthem. In addition, a cross-modal decomposed fusion module is designed between\nthe language and image branches, which decomposes state and object among\nlanguage features instead of image features. Notably, being fused with the\ndecomposed features, the image features can be more expressive for learning the\nrelationship with states and objects, respectively, to improve the response of\nunseen compositions in the pair space, hence narrowing the domain gap between\nseen and unseen sets. Experimental results on three challenging benchmarks\ndemonstrate that our approach significantly outperforms other state-of-the-art\nmethods by large margins.",
    "descriptor": "\nComments: 10 pages included reference, conference\n",
    "authors": [
      "Xiaocheng Lu",
      "Ziming Liu",
      "Song Guo",
      "Jingcai Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10681"
  },
  {
    "id": "arXiv:2211.10682",
    "title": "DiffStyler: Controllable Dual Diffusion for Text-Driven Image  Stylization",
    "abstract": "Despite the impressive results of arbitrary image-guided style transfer\nmethods, text-driven image stylization has recently been proposed for\ntransferring a natural image into the stylized one according to textual\ndescriptions of the target style provided by the user. Unlike previous\nimage-to-image transfer approaches, text-guided stylization progress provides\nusers with a more precise and intuitive way to express the desired style.\nHowever, the huge discrepancy between cross-modal inputs/outputs makes it\nchallenging to conduct text-driven image stylization in a typical feed-forward\nCNN pipeline. In this paper, we present DiffStyler on the basis of diffusion\nmodels. The cross-modal style information can be easily integrated as guidance\nduring the diffusion progress step-by-step. In particular, we use a dual\ndiffusion processing architecture to control the balance between the content\nand style of the diffused results. Furthermore, we propose a content\nimage-based learnable noise on which the reverse denoising process is based,\nenabling the stylization results to better preserve the structure information\nof the content image. We validate the proposed DiffStyler beyond the baseline\nmethods through extensive qualitative and quantitative experiments.",
    "descriptor": "",
    "authors": [
      "Nisha Huang",
      "Yuxin Zhang",
      "Fan Tang",
      "Chongyang Ma",
      "Haibin Huang",
      "Yong Zhang",
      "Weiming Dong",
      "Changsheng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.10682"
  },
  {
    "id": "arXiv:2211.10684",
    "title": "Personalized Federated Learning with Hidden Information on Personalized  Prior",
    "abstract": "Federated learning (FL for simplification) is a distributed machine learning\ntechnique that utilizes global servers and collaborative clients to achieve\nprivacy-preserving global model training without direct data sharing. However,\nheterogeneous data problem, as one of FL's main problems, makes it difficult\nfor the global model to perform effectively on each client's local data. Thus,\npersonalized federated learning (PFL for simplification) aims to improve the\nperformance of the model on local data as much as possible. Bayesian learning,\nwhere the parameters of the model are seen as random variables with a prior\nassumption, is a feasible solution to the heterogeneous data problem due to the\ntendency that the more local data the model use, the more it focuses on the\nlocal data, otherwise focuses on the prior. When Bayesian learning is applied\nto PFL, the global model provides global knowledge as a prior to the local\ntraining process. In this paper, we employ Bayesian learning to model PFL by\nassuming a prior in the scaled exponential family, and therefore propose\npFedBreD, a framework to solve the problem we model using Bregman divergence\nregularization. Empirically, our experiments show that, under the prior\nassumption of the spherical Gaussian and the first order strategy of mean\nselection, our proposal significantly outcompetes other PFL algorithms on\nmultiple public benchmarks.",
    "descriptor": "\nComments: 19 pages, 6 figures, 3 tables\n",
    "authors": [
      "Mingjia Shi",
      "Yuhao Zhou",
      "Qing Ye",
      "Jiancheng Lv"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.10684"
  },
  {
    "id": "arXiv:2211.10685",
    "title": "Pairwise Instance Relation Augmentation for Long-tailed Multi-label Text  Classification",
    "abstract": "Multi-label text classification (MLTC) is one of the key tasks in natural\nlanguage processing. It aims to assign multiple target labels to one document.\nDue to the uneven popularity of labels, the number of documents per label\nfollows a long-tailed distribution in most cases. It is much more challenging\nto learn classifiers for data-scarce tail labels than for data-rich head\nlabels. The main reason is that head labels usually have sufficient\ninformation, e.g., a large intra-class diversity, while tail labels do not. In\nresponse, we propose a Pairwise Instance Relation Augmentation Network (PIRAN)\nto augment tailed-label documents for balancing tail labels and head labels.\nPIRAN consists of a relation collector and an instance generator. The former\naims to extract the document pairwise relations from head labels. Taking these\nrelations as perturbations, the latter tries to generate new document instances\nin high-level feature space around the limited given tailed-label instances.\nMeanwhile, two regularizers (diversity and consistency) are designed to\nconstrain the generation process. The consistency-regularizer encourages the\nvariance of tail labels to be close to head labels and further balances the\nwhole datasets. And diversity-regularizer makes sure the generated instances\nhave diversity and avoids generating redundant instances. Extensive\nexperimental results on three benchmark datasets demonstrate that PIRAN\nconsistently outperforms the SOTA methods, and dramatically improves the\nperformance of tail labels.",
    "descriptor": "",
    "authors": [
      "Lin Xiao",
      "Pengyu Xu",
      "Liping Jing",
      "Xiangliang Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.10685"
  },
  {
    "id": "arXiv:2211.10686",
    "title": "Spikeformer: A Novel Architecture for Training High-Performance  Low-Latency Spiking Neural Network",
    "abstract": "Spiking neural networks (SNNs) have made great progress on both performance\nand efficiency over the last few years,but their unique working pattern makes\nit hard to train a high-performance low-latency SNN.Thus the development of\nSNNs still lags behind traditional artificial neural networks (ANNs).To\ncompensate this gap,many extraordinary works have been\nproposed.Nevertheless,these works are mainly based on the same kind of network\nstructure (i.e.CNN) and their performance is worse than their ANN\ncounterparts,which limits the applications of SNNs.To this end,we propose a\nnovel Transformer-based SNN,termed \"Spikeformer\",which outperforms its ANN\ncounterpart on both static dataset and neuromorphic dataset and may be an\nalternative architecture to CNN for training high-performance SNNs.First,to\ndeal with the problem of \"data hungry\" and the unstable training period\nexhibited in the vanilla model,we design the Convolutional Tokenizer (CT)\nmodule,which improves the accuracy of the original model on DVS-Gesture by more\nthan 16%.Besides,in order to better incorporate the attention mechanism inside\nTransformer and the spatio-temporal information inherent to SNN,we adopt\nspatio-temporal attention (STA) instead of spatial-wise or temporal-wise\nattention.With our proposed method,we achieve competitive or state-of-the-art\n(SOTA) SNN performance on DVS-CIFAR10,DVS-Gesture,and ImageNet datasets with\nthe least simulation time steps (i.e.low latency).Remarkably,our Spikeformer\noutperforms other SNNs on ImageNet by a large margin (i.e.more than 5%) and\neven outperforms its ANN counterpart by 3.1% and 2.2% on DVS-Gesture and\nImageNet respectively,indicating that Spikeformer is a promising architecture\nfor training large-scale SNNs and may be more suitable for SNNs compared to\nCNN.We believe that this work shall keep the development of SNNs in step with\nANNs as much as possible.Code will be available.",
    "descriptor": "",
    "authors": [
      "Yudong Li",
      "Yunlin Lei",
      "Xu Yang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10686"
  },
  {
    "id": "arXiv:2211.10688",
    "title": "ReInform: Selecting paths with reinforcement learning for contextualized  link prediction",
    "abstract": "We propose to use reinforcement learning to inform transformer-based\ncontextualized link prediction models by providing paths that are most useful\nfor predicting the correct answer. This is in contrast to previous approaches,\nthat either used reinforcement learning (RL) to directly search for the answer,\nor based their prediction on limited or randomly selected context. Our\nexperiments on WN18RR and FB15k-237 show that contextualized link prediction\nmodels consistently outperform RL-based answer search, and that additional\nimprovements (of up to 13.5\\% MRR) can be gained by combining RL with a link\nprediction model.",
    "descriptor": "",
    "authors": [
      "Marina Speranskaya",
      "Sameh Methias",
      "Benjamin Roth"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10688"
  },
  {
    "id": "arXiv:2211.10691",
    "title": "Two Facets of SDE Under an Information-Theoretic Lens: Generalization of  SGD via Training Trajectories and via Terminal States",
    "abstract": "Stochastic differential equations (SDEs) have been shown recently to well\ncharacterize the dynamics of training machine learning models with SGD. This\nprovides two opportunities for better understanding the generalization\nbehaviour of SGD through its SDE approximation. First, under the SDE\ncharacterization, SGD may be regarded as the full-batch gradient descent with\nGaussian gradient noise. This allows the application of the generalization\nbounds developed by Xu & Raginsky (2017) to analyzing the generalization\nbehaviour of SGD, resulting in upper bounds in terms of the mutual information\nbetween the training set and the training trajectory. Second, under mild\nassumptions, it is possible to obtain an estimate of the steady-state weight\ndistribution of SDE. Using this estimate, we apply the PAC-Bayes-like\ninformation-theoretic bounds developed in both Xu & Raginsky (2017) and Negrea\net al. (2019) to obtain generalization upper bounds in terms of the KL\ndivergence between the steady-state weight distribution of SGD with respect to\na prior distribution. Among various options, one may choose the prior as the\nsteady-state weight distribution obtained by SGD on the same training set but\nwith one example held out. In this case, the bound can be elegantly expressed\nusing the influence function (Koh & Liang, 2017), which suggests that the\ngeneralization of the SGD is related to the stability of SGD. Various insights\nare presented along the development of these bounds, which are subsequently\nvalidated numerically.",
    "descriptor": "",
    "authors": [
      "Ziqiao Wang",
      "Yongyi Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.10691"
  },
  {
    "id": "arXiv:2211.10696",
    "title": "Practical Challenges And Pitfalls Of Bluetooth Mesh Data Collection  Experiments With Esp-32 Microcontrollers",
    "abstract": "Testing network algorithms in physical environments using real hardware is an\nimportant step to reduce the gap between theory and practice in the field, and\nan interesting way to explore technologies such as Bluetooth Mesh. We\nimplemented a Bluetooth Mesh data collection strategy and deployed it in indoor\nand outdoor settings, using ESP-32 microcontrollers. This data collection\nstrategy also covers an alternative packet routing strategy based on Bluetooth\nMesh - MAM - already discussed and simulated in previous work using the OMNET++\nsimulator. We compared the real-world ESP-32 experiments with the past\nsimulations, and the results differed significantly: the simulations predicted\na +459\\% unique message collection compared to the results we obtained with the\nESP-32. Based on those results, we also identified vast room for improvement in\nour ESP-32 implementation for future work, including solving an unexpected\npacket duplication in the MAM algorithm implementation. Even so, MAM performed\nbetter than Bluetooth Mesh's default relay strategy, with up to +4.06\\% more\n(unique) data messages collected. We also discuss some challenges we\nexperienced when implementing, deploying, and running benchmarks using\nBluetooth Mesh and the ESP-32 platform.",
    "descriptor": "\nComments: 12 pages, 6 figures and graphs\n",
    "authors": [
      "Marcelo Paulon J. V.",
      "Bruno Jos\u00e9 Olivieri de Souza",
      "Thiago de Souza Lamenza",
      "Markus Endler"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.10696"
  },
  {
    "id": "arXiv:2211.10699",
    "title": "Wireless Connectivity of a Ground-and-Air Sensor Network",
    "abstract": "This paper shows that, when considering outdoor scenarios and wireless\ncommunications using the IEEE 802.11 protocol with dipole antennas, the ground\nreflection is a significant propagation mechanism. This way, the Two-Ray model\nfor this environment allows predicting, with some accuracy, the received signal\npower. This study is relevant for the application in the communication between\noverflying Unmanned Aerial Vehicles (UAVs) and ground sensors. In the proposed\nWireless Sensor Network (WSN) scenario, the UAVs must receive information from\nthe environment, which is collected by sensors positioned on the ground, and\nneed to maintain connectivity between them and the base station, in order to\nmaintain the quality of service, while moving through the environment.",
    "descriptor": "\nComments: 8 pages, 11 figures\n",
    "authors": [
      "Clara R. P. Baldansa",
      "Roberto C. G. Porto",
      "Bruno Jos\u00e9 Olivieri de Souza",
      "V\u00edtor G. Andrezo Carneiro",
      "Markus Endler"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.10699"
  },
  {
    "id": "arXiv:2211.10700",
    "title": "Near-Field Intelligent Reflecting Surfaces for Millimeter Wave MIMO Full  Duplex",
    "abstract": "Full duplex (FD) systems suffer from very high hardware cost and high power\nconsumption to mitigate the self-interference (SI) in the analog domain.\nMoreover, in millimeter wave (mmWave) they rely on hybrid beamforming (HYBF) as\na signal processing tool to partially deal with the SI, which presents many\ndrawback, e.g., high insertion loss, high power consumption and high\ncomputational complexity for its configuration. This article proposes the use\nof near-field (NF-) IRSs for FD systems with the objective to solve the\naforementioned issues cost-efficiently. Namely, we propose to truncate the\nanalog stage of the mmWave FD systems and assist them with an NF-IRS, to\nsimultaneously and smartly control the uplink (DL) and downlink (DL) channels,\nwhile assisting in shaping the SI channel: this to obtain very strong passive\nSI cancellation. A novel joint active and passive beamforming design for the\nweighted sum-rate (WSR) maximization of a NF-IRS-assisted mmWave point-to-point\nFD system is presented. Results show that the proposed solution fully reaps the\nbenefits of the IRSs only when they operate in the NF, which leads to\nconsiderably higher gains compared to the conventional massive MIMO (mMIMO)\nmmWave FD and half duplex (HD) systems.",
    "descriptor": "",
    "authors": [
      "Chandan Kumar Sheemar",
      "Stefano Tomasin",
      "Dirk Slock",
      "Symeon Chatzinotas"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.10700"
  },
  {
    "id": "arXiv:2211.10701",
    "title": "Complementary Labels Learning with Augmented Classes",
    "abstract": "Complementary Labels Learning (CLL) arises in many real-world tasks such as\nprivate questions classification and online learning, which aims to alleviate\nthe annotation cost compared with standard supervised learning. Unfortunately,\nmost previous CLL algorithms were in a stable environment rather than an open\nand dynamic scenarios, where data collected from unseen augmented classes in\nthe training process might emerge in the testing phase. In this paper, we\npropose a novel problem setting called Complementary Labels Learning with\nAugmented Classes (CLLAC), which brings the challenge that classifiers trained\nby complementary labels should not only be able to classify the instances from\nobserved classes accurately, but also recognize the instance from the Augmented\nClasses in the testing phase. Specifically, by using unlabeled data, we propose\nan unbiased estimator of classification risk for CLLAC, which is guaranteed to\nbe provably consistent. Moreover, we provide generalization error bound for\nproposed method which shows that the optimal parametric convergence rate is\nachieved for estimation error. Finally, the experimental results on several\nbenchmark datasets verify the effectiveness of the proposed method.",
    "descriptor": "",
    "authors": [
      "Zhongnian Li",
      "Jian Zhang",
      "Mengting Xu",
      "Xinzheng Xu",
      "Daoqiang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10701"
  },
  {
    "id": "arXiv:2211.10703",
    "title": "Non-centered parametric variational Bayes' approach for hierarchical  inverse problems of partial differential equations",
    "abstract": "This paper proposes a non-centered parameterization based\ninfinite-dimensional mean-field variational inference (NCP-iMFVI) approach for\nsolving the hierarchical Bayesian inverse problems. This method can generate\navailable estimates from the approximated posterior distribution efficiently.\nTo avoid the mutually singular obstacle that occurred in the\ninfinite-dimensional hierarchical approach, we propose a rigorous theory of the\nnon-centered variational Bayesian approach. Since the non-centered\nparameterization weakens the connection between the parameter and the\nhyper-parameter, we can introduce the hyper-parameter to all terms of the\neigendecomposition of the prior covariance operator. We also show the\nrelationships between the NCP-iMFVI and infinite-dimensional hierarchical\napproaches with centered parameterization. The proposed algorithm is applied to\nthree inverse problems governed by the simple smooth equation, the Helmholtz\nequation, and the steady-state Darcy flow equation. Numerical results confirm\nour theoretical findings, illustrate the efficiency of solving the iMFVI\nproblem formulated by large-scale linear and nonlinear statistical inverse\nproblems, and verify the mesh-independent property.",
    "descriptor": "\nComments: 38 pages\n",
    "authors": [
      "Jiaming Sui",
      "Junxiong Jia"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.10703"
  },
  {
    "id": "arXiv:2211.10705",
    "title": "TORE: Token Reduction for Efficient Human Mesh Recovery with Transformer",
    "abstract": "In this paper, we introduce a set of effective TOken REduction (TORE)\nstrategies for Transformer-based Human Mesh Recovery from monocular images.\nCurrent SOTA performance is achieved by Transformer-based structures. However,\nthey suffer from high model complexity and computation cost caused by redundant\ntokens. We propose token reduction strategies based on two important aspects,\ni.e., the 3D geometry structure and 2D image feature, where we hierarchically\nrecover the mesh geometry with priors from body structure and conduct token\nclustering to pass fewer but more discriminative image feature tokens to the\nTransformer. As a result, our method vastly reduces the number of tokens\ninvolved in high-complexity interactions in the Transformer, achieving\ncompetitive accuracy of shape recovery at a significantly reduced computational\ncost. We conduct extensive experiments across a wide range of benchmarks to\nvalidate the proposed method and further demonstrate the generalizability of\nour method on hand mesh recovery. Our code will be publicly available once the\npaper is published.",
    "descriptor": "",
    "authors": [
      "Zhiyang Dou",
      "Qingxuan Wu",
      "Cheng Lin",
      "Zeyu Cao",
      "Qiangqiang Wu",
      "Weilin Wan",
      "Taku Komura",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10705"
  },
  {
    "id": "arXiv:2211.10706",
    "title": "A Comparison Between Different Formulations for Solving Axisymmetric  Time-Harmonic Electromagnetic Wave Problems",
    "abstract": "In many time-harmonic electromagnetic wave problems, the considered geometry\nexhibits an axial symmetry. In this case, by exploiting a Fourier expansion\nalong the azimuthal direction, fully three-dimensional (3D) calculations can be\ncarried out on a two-dimensional (2D) angular cross section of the problem,\nthus significantly reducing the computational effort. However, the transition\nfrom a full 3D problem to a 2D analysis introduces additional difficulties such\nas, among others, a singularity in the variational formulation. In this work,\nwe compare and discuss different finite element formulations to deal with these\nobstacles. Particular attention is paid to spurious modes and to the\nconvergence behavior when using high-order elements.",
    "descriptor": "\nComments: 8 pages, 4 figures, pre-submission version (preprint). Scientific Computing in Electrical Engineering, SCEE 2020, Eindhoven, The Netherlands, February 2020\n",
    "authors": [
      "Erik Schnaubelt",
      "Nicolas Marsic",
      "Herbert De Gersem"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.10706"
  },
  {
    "id": "arXiv:2211.10707",
    "title": "Suffering from Vaccines or from Government? : Partisan Bias in COVID-19  Vaccine Adverse Events Coverage",
    "abstract": "Vaccine adverse events have been presumed to be a relatively objective\nmeasure that is immune to political polarization. The real-world data, however,\nshows the correlation between presidential disapproval ratings and the\nsubjective severity of adverse events. This paper investigates the partisan\nbias in COVID vaccine adverse events coverage with language models that can\nclassify the topic of vaccine-related articles and the political disposition of\nnews comments. Based on 90K news articles from 52 major newspaper companies, we\nfound that conservative media are inclined to report adverse events more\nfrequently than their liberal counterparts, while the coverage itself was\nstatistically uncorrelated with the severity of real-world adverse events. The\nusers who support the conservative opposing party were more likely to write the\npopular comments from 2.3K random sampled articles on news platforms. This\nresearch implies that bipartisanship can still play a significant role in\nforming public opinion on the COVID vaccine even after the majority of the\npopulation's vaccination",
    "descriptor": "\nComments: 5 pages, 5 figures, 2 tables\n",
    "authors": [
      "TaeYoung Kang",
      "Hanbin Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.10707"
  },
  {
    "id": "arXiv:2211.10708",
    "title": "A Survey on Differential Privacy with Machine Learning and Future  Outlook",
    "abstract": "Nowadays, machine learning models and applications have become increasingly\npervasive. With this rapid increase in the development and employment of\nmachine learning models, a concern regarding privacy has risen. Thus, there is\na legitimate need to protect the data from leaking and from any attacks. One of\nthe strongest and most prevalent privacy models that can be used to protect\nmachine learning models from any attacks and vulnerabilities is differential\nprivacy (DP). DP is strict and rigid definition of privacy, where it can\nguarantee that an adversary is not capable to reliably predict if a specific\nparticipant is included in the dataset or not. It works by injecting a noise to\nthe data whether to the inputs, the outputs, the ground truth labels, the\nobjective functions, or even to the gradients to alleviate the privacy issue\nand protect the data. To this end, this survey paper presents different\ndifferentially private machine learning algorithms categorized into two main\ncategories (traditional machine learning models vs. deep learning models).\nMoreover, future research directions for differential privacy with machine\nlearning algorithms are outlined.",
    "descriptor": "\nComments: 12 pages, 3 figures\n",
    "authors": [
      "Samah Baraheem",
      "Zhongmei Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.10708"
  },
  {
    "id": "arXiv:2211.10709",
    "title": "Metaphorical Language Change Is Self-Organized Criticality",
    "abstract": "One way to resolve the actuation problem of metaphorical language change is\nto provide a statistical profile of metaphorical constructions and generative\nrules with antecedent conditions. Based on arguments from the view of language\nas complex systems and the dynamic view of metaphor, this paper argues that\nmetaphorical language change qualifies as a self-organized criticality state\nand the linguistic expressions of a metaphor can be profiled as a fractal with\nspatio-temporal correlations. Synchronously, these metaphorical expressions\nself-organize into a self-similar, scale-invariant fractal that follows a\npower-law distribution; temporally, long range inter-dependence constrains the\nself-organization process by the way of transformation rules that are intrinsic\nof a language system. This argument is verified in the paper with statistical\nanalyses of twelve randomly selected Chinese verb metaphors in a large-scale\ndiachronic corpus.",
    "descriptor": "",
    "authors": [
      "Xuri Tang",
      "Huifang Ye"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2211.10709"
  },
  {
    "id": "arXiv:2211.10712",
    "title": "Comparison of different coding schemes for 1-bit ADC",
    "abstract": "This paper devotes to comparison of different coding schemes (various\nconstructions of Polar and LDPC codes, Product codes and BCH codes) for the\ncase when information is transmitted over AWGN channel with quantization with\nlowest possible complexity and resolution: 1-bit. We examine performance (in\nterms of Frame-error-rate -- FER) for schemes mentioned above and give some\nreasoning for results we obtained. Also we give some recommendations for\nchoosing coding schemes for a given code rate and code length.",
    "descriptor": "",
    "authors": [
      "Fedor Ivanov",
      "Dmitry Osipov"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.10712"
  },
  {
    "id": "arXiv:2211.10713",
    "title": "A privacy-preserving data storage and service framework based on deep  learning and blockchain for construction workers' wearable IoT sensors",
    "abstract": "Classifying brain signals collected by wearable Internet of Things (IoT)\nsensors, especially brain-computer interfaces (BCIs), is one of the\nfastest-growing areas of research. However, research has mostly ignored the\nsecure storage and privacy protection issues of collected personal\nneurophysiological data. Therefore, in this article, we try to bridge this gap\nand propose a secure privacy-preserving protocol for implementing BCI\napplications. We first transformed brain signals into images and used\ngenerative adversarial network to generate synthetic signals to protect data\nprivacy. Subsequently, we applied the paradigm of transfer learning for signal\nclassification. The proposed method was evaluated by a case study and results\nindicate that real electroencephalogram data augmented with artificially\ngenerated samples provide superior classification performance. In addition, we\nproposed a blockchain-based scheme and developed a prototype on Ethereum, which\naims to make storing, querying and sharing personal neurophysiological data and\nanalysis reports secure and privacy-aware. The rights of three main transaction\nbodies - construction workers, BCI service providers and project managers - are\ndescribed and the advantages of the proposed system are discussed. We believe\nthis paper provides a well-rounded solution to safeguard private data against\ncyber-attacks, level the playing field for BCI application developers, and to\nthe end improve professional well-being in the industry.",
    "descriptor": "",
    "authors": [
      "Xiaoshan Zhou",
      "Pin-Chao Liao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2211.10713"
  },
  {
    "id": "arXiv:2211.10714",
    "title": "PIC4rl-gym: a ROS2 modular framework for Robots Autonomous Navigation  with Deep Reinforcement Learning",
    "abstract": "Learning agents can optimize standard autonomous navigation improving\nflexibility, efficiency, and computational cost of the system by adopting a\nwide variety of approaches. This work introduces the \\textit{PIC4rl-gym}, a\nfundamental modular framework to enhance navigation and learning research by\nmixing ROS2 and Gazebo, the standard tools of the robotics community, with Deep\nReinforcement Learning (DRL). The paper describes the whole structure of the\nPIC4rl-gym, which fully integrates DRL agent's training and testing in several\nindoor and outdoor navigation scenarios and tasks. A modular approach is\nadopted to easily customize the simulation by selecting new platforms, sensors,\nor models. We demonstrate the potential of our novel gym by benchmarking the\nresulting policies, trained for different navigation tasks, with a complete set\nof metrics.",
    "descriptor": "",
    "authors": [
      "Mauro Martini",
      "Andrea Eirale",
      "Simone Cerrato",
      "Marcello Chiaberge"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10714"
  },
  {
    "id": "arXiv:2211.10715",
    "title": "Single Stage Multi-Pose Virtual Try-On",
    "abstract": "Multi-pose virtual try-on (MPVTON) aims to fit a target garment onto a person\nat a target pose. Compared to traditional virtual try-on (VTON) that fits the\ngarment but keeps the pose unchanged, MPVTON provides a better try-on\nexperience, but is also more challenging due to the dual garment and pose\nediting objectives. Existing MPVTON methods adopt a pipeline comprising three\ndisjoint modules including a target semantic layout prediction module, a coarse\ntry-on image generator and a refinement try-on image generator. These models\nare trained separately, leading to sub-optimal model training and\nunsatisfactory results. In this paper, we propose a novel single stage model\nfor MPVTON. Key to our model is a parallel flow estimation module that predicts\nthe flow fields for both person and garment images conditioned on the target\npose. The predicted flows are subsequently used to warp the appearance feature\nmaps of the person and the garment images to construct a style map. The map is\nthen used to modulate the target pose's feature map for target try-on image\ngeneration. With the parallel flow estimation design, our model can be trained\nend-to-end in a single stage and is more computationally efficient, resulting\nin new SOTA performance on existing MPVTON benchmarks. We further introduce\nmulti-task training and demonstrate that our model can also be applied for\ntraditional VTON and pose transfer tasks and achieve comparable performance to\nSOTA specialized models on both tasks.",
    "descriptor": "",
    "authors": [
      "Sen He",
      "Yi-Zhe Song",
      "Tao Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10715"
  },
  {
    "id": "arXiv:2211.10716",
    "title": "MARSIM: A light-weight point-realistic simulator for LiDAR-based UAVs",
    "abstract": "The emergence of low-cost, small form factor and light-weight solid-state\nLiDAR sensors have brought new opportunities for autonomous unmanned aerial\nvehicles (UAVs) by advancing navigation safety and computation efficiency. Yet\nthe successful developments of LiDAR-based UAVs must rely on extensive\nsimulations. Existing simulators can hardly perform simulations of real-world\nenvironments due to the requirements of dense mesh maps that are difficult to\nobtain. In this paper, we develop a point-realistic simulator of real-world\nscenes for LiDAR-based UAVs. The key idea is the underlying point rendering\nmethod, where we construct a depth image directly from the point cloud map and\ninterpolate it to obtain realistic LiDAR point measurements. Our developed\nsimulator is able to run on a light-weight computing platform and supports the\nsimulation of LiDARs with different resolution and scanning patterns, dynamic\nobstacles, and multi-UAV systems. Developed in the ROS framework, the simulator\ncan easily communicate with other key modules of an autonomous robot, such as\nperception, state estimation, planning, and control. Finally, the simulator\nprovides 10 high-resolution point cloud maps of various real-world\nenvironments, including forests of different densities, historic building,\noffice, parking garage, and various complex indoor environments. These\nrealistic maps provide diverse testing scenarios for an autonomous UAV.\nEvaluation results show that the developed simulator achieves superior\nperformance in terms of time and memory consumption against Gazebo and that the\nsimulated UAV flights highly match the actual one in real-world environments.\nWe believe such a point-realistic and light-weight simulator is crucial to\nbridge the gap between UAV simulation and experiments and will significantly\nfacilitate the research of LiDAR-based autonomous UAVs in the future.",
    "descriptor": "\nComments: 8 pages, 13 figures\n",
    "authors": [
      "Fanze Kong",
      "Xiyuan Liu",
      "Benxu Tang",
      "Jiarong Lin",
      "Yunfan Ren",
      "Yixi Cai",
      "Fangcheng Zhu",
      "Nan Chen",
      "Fu Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.10716"
  },
  {
    "id": "arXiv:2211.10717",
    "title": "Error estimates and variance reduction for nonequilibrium stochastic  dynamics",
    "abstract": "Equilibrium properties in statistical physics are obtained by computing\naverages with respect to Boltzmann-Gibbs measures, sampled in practice using\nergodic dynamics such as the Langevin dynamics. Some quantities however cannot\nbe computed by simply sampling the Boltzmann-Gibbs measure, in particular\ntransport coefficients, which relate the current of some physical quantity of\ninterest to the forcing needed to induce it. For instance, a temperature\ndifference induces an energy current, the proportionality factor between these\ntwo quantities being the thermal conductivity. From an abstract point of view,\ntransport coefficients can also be considered as some form of sensitivity\nanalysis with respect to an added forcing to the baseline dynamics. There are\nvarious numerical techniques to estimate transport coefficients, which all\nsuffer from large errors, in particular large statistical errors. This\ncontribution reviews the most popular methods, namely the Green-Kubo approach\nwhere the transport coefficient is expressed as some time-integrated\ncorrelation function, and the approach based on longtime averages of the\nstochastic dynamics perturbed by an external driving (so-called nonequilibrium\nmolecular dynamics). In each case, the various sources of errors are made\nprecise, in particular the bias related to the time discretization of the\nunderlying continuous dynamics, and the variance of the associated Monte Carlo\nestimators. Some recent alternative techniques to estimate transport\ncoefficients are also discussed.",
    "descriptor": "",
    "authors": [
      "Gabriel Stoltz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Statistical Mechanics (cond-mat.stat-mech)"
    ],
    "url": "https://arxiv.org/abs/2211.10717"
  },
  {
    "id": "arXiv:2211.10718",
    "title": "Upper and Lower Bounds on Bit-Error Rate for Convolutional Codes",
    "abstract": "In this paper, we provide a new approach to the analytical estimation of the\nbit-error rate (BER) for convolutional codes for Viterbi decoding in the binary\nsymmetric channel (BSC). The expressions we obtained for lower and upper BER\nbounds are based on the active distances of the code and their distance\nspectrum. The estimates are derived for convolutional codes with the rate\n$R=\\frac{1}{2}$ but can be easily generalized for any convolutional code with\nrate $R=\\frac 1n$ and systematic encoder. The suggested approach is not\ncomputationally expensive for any crossover probability of BSC channel and\nconvolutional code memory, and it allows to obtain precise estimates of BER.",
    "descriptor": "",
    "authors": [
      "Anastasia Kurmukova",
      "Fedor Ivanov",
      "Victor Zyablov"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.10718"
  },
  {
    "id": "arXiv:2211.10724",
    "title": "Deep Smart Contract Intent Detection",
    "abstract": "Nowadays, security activities in smart contracts concentrate on vulnerability\ndetection. Despite early success, we find that developers' intent to write\nsmart contracts is a more noteworthy security concern because smart contracts\nwith malicious intent have caused significant users' financial loss.\nUnfortunately, current approaches to identify the aforementioned malicious\nsmart contracts rely on smart contract security audits, which entail huge\nmanpower consumption and financial expenditure. To resolve this issue, we\npropose a novel deep learning-based approach, SmartIntentNN, to conduct\nautomated smart contract intent detection. SmartIntentNN consists of three\nprimary parts: a pre-trained sentence encoder to generate the contextual\nrepresentations of smart contracts, a K-means clustering method to highlight\nintent-related representations, and a bidirectional LSTM-based (long-short term\nmemory) multi-label classification network to predict the intents in smart\ncontracts. To evaluate the performance of SmartIntentNN, we collect more than\n40,000 real smart contracts and perform a series of comparison experiments with\nour selected baseline approaches. The experimental results demonstrate that\nSmartIntentNN outperforms all baselines by up to 0.8212 in terms of the\nf1-score metric.",
    "descriptor": "\nComments: 12 pages, 9 figures, conference\n",
    "authors": [
      "Youwei Huang",
      "Tao Zhang",
      "Sen Fang",
      "Youshuai Tan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10724"
  },
  {
    "id": "arXiv:2211.10725",
    "title": "Intelligence Processing Units Accelerate Neuromorphic Learning",
    "abstract": "Spiking neural networks (SNNs) have achieved orders of magnitude improvement\nin terms of energy consumption and latency when performing inference with deep\nlearning workloads. Error backpropagation is presently regarded as the most\neffective method for training SNNs, but in a twist of irony, when training on\nmodern graphics processing units (GPUs) this becomes more expensive than\nnon-spiking networks. The emergence of Graphcore's Intelligence Processing\nUnits (IPUs) balances the parallelized nature of deep learning workloads with\nthe sequential, reusable, and sparsified nature of operations prevalent when\ntraining SNNs. IPUs adopt multi-instruction multi-data (MIMD) parallelism by\nrunning individual processing threads on smaller data blocks, which is a\nnatural fit for the sequential, non-vectorized steps required to solve spiking\nneuron dynamical state equations. We present an IPU-optimized release of our\ncustom SNN Python package, snnTorch, which exploits fine-grained parallelism by\nutilizing low-level, pre-compiled custom operations to accelerate irregular and\nsparse data access patterns that are characteristic of training SNN workloads.\nWe provide a rigorous performance assessment across a suite of commonly used\nspiking neuron models, and propose methods to further reduce training run-time\nvia half-precision training. By amortizing the cost of sequential processing\ninto vectorizable population codes, we ultimately demonstrate the potential for\nintegrating domain-specific accelerators with the next generation of neural\nnetworks.",
    "descriptor": "\nComments: 10 pages, 9 figures, journal\n",
    "authors": [
      "Pao-Sheng Vincent Sun",
      "Alexander Titterton",
      "Anjlee Gopiani",
      "Tim Santos",
      "Arindam Basu",
      "Wei D. Lu",
      "Jason K. Eshraghian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10725"
  },
  {
    "id": "arXiv:2211.10732",
    "title": "Passive Micron-scale Time-of-Flight with Sunlight Interferometry",
    "abstract": "We introduce an interferometric technique for passive time-of-flight imaging\nand depth sensing at micrometer axial resolutions. Our technique uses a\nfull-field Michelson interferometer, modified to use sunlight as the only light\nsource. The large spectral bandwidth of sunlight makes it possible to acquire\nmicrometer-resolution time-resolved scene responses, through a simple axial\nscanning operation. Additionally, the angular bandwidth of sunlight makes it\npossible to capture time-of-flight measurements insensitive to indirect\nillumination effects, such as interreflections and subsurface scattering. We\nbuild an experimental prototype that we operate outdoors, under direct\nsunlight, and in adverse environmental conditions such as mechanical vibrations\nand vehicle traffic. We use this prototype to demonstrate, for the first time,\npassive imaging capabilities such as micrometer-scale depth sensing robust to\nindirect illumination, direct-only imaging, and imaging through diffusers.",
    "descriptor": "",
    "authors": [
      "Alankar Kotwal",
      "Anat Levin",
      "Ioannis Gkioulekas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2211.10732"
  },
  {
    "id": "arXiv:2211.10735",
    "title": "Towards Ontology-Based Requirements Engineering for IoT-Supported  Well-Being, Aging and Health",
    "abstract": "Ontologies serve as a one of the formal means to represent and model\nknowledge in computer science, electrical engineering, system engineering and\nother related disciplines. Ontologies within requirements engineering may be\nused for formal representation of system requirements. In the Internet of\nThings, ontologies may be used to represent sensor knowledge and describe\nacquired data semantics. Designing an ontology comprehensive enough with an\nappropriate level of knowledge expressiveness, serving multiple purposes, from\nsystem requirements specifications to modeling knowledge based on data from IoT\nsensors, is one of the great challenges. This paper proposes an approach\ntowards ontology-based requirements engineering for well-being, aging and\nhealth supported by the Internet of Things. Such an ontology design does not\naim at creating a new ontology, but extending the appropriate one already\nexisting, SAREF4EHAW, in order align with the well-being, aging and health\nconcepts and structure the knowledge within the domain. Other contributions\ninclude a conceptual formulation for Well-Being, Aging and Health and a related\ntaxonomy, as well as a concept of One Well-Being, Aging and Health. New\nattributes and relations have been proposed for the new ontology extension,\nalong with the updated list of use cases and particular ontological\nrequirements not covered by the original ontology. Future work envisions full\nspecification of the new ontology extension, as well as structuring system\nrequirements and sensor measurement parameters to follow description logic.",
    "descriptor": "\nComments: 10 pages, 2 figures, 2 tables\n",
    "authors": [
      "Hrvoje Belani",
      "Petar Solic",
      "Toni Perkovic"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.10735"
  },
  {
    "id": "arXiv:2211.10737",
    "title": "Accuracy Boosters: Epoch-Driven Mixed-Mantissa Block Floating-Point for  DNN Training",
    "abstract": "The unprecedented growth in DNN model complexity, size and the amount of\ntraining data have led to a commensurate increase in demand for computing and a\nsearch for minimal encoding. Recent research advocates Hybrid Block\nFloating-Point (HBFP) as a technique that minimizes silicon provisioning in\naccelerators by converting the majority of arithmetic operations in training to\n8-bit fixed-point. In this paper, we perform a full-scale exploration of the\nHBFP design space including minimal mantissa encoding, varying block sizes, and\nmixed mantissa bit-width across layers and epochs. We propose \\emph{Accuracy\nBoosters}, an epoch-driven mixed-mantissa HBFP that uses 6-bit mantissa only in\nthe last epoch and converts $99.7\\%$ of all arithmetic operations in training\nto 4-bit mantissas. Accuracy Boosters enable reducing silicon provisioning for\nan HBFP training accelerator by $16.98\\times$ as compared to FP32, while\npreserving or outperforming FP32 accuracy.",
    "descriptor": "\nComments: Under review as a conference paper at ICLR 2023\n",
    "authors": [
      "Simla Burcu Harma",
      "Canberk S\u00f6nmez",
      "Babak Falsafi",
      "Martin Jaggi",
      "Yunho Oh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10737"
  },
  {
    "id": "arXiv:2211.10738",
    "title": "Relational Symmetry based Knowledge Graph Contrastive Learning",
    "abstract": "Knowledge graph embedding (KGE) aims to learn powerful representations to\nbenefit various artificial intelligence applications, such as question\nanswering and recommendations. Meanwhile, contrastive learning (CL), as an\neffective mechanism to enhance the discriminative capacity of the learned\nrepresentations, has been leveraged in different fields, especially graph-based\nmodels. However, since the structures of knowledge graphs (KGs) are usually\nmore complicated compared to homogeneous graphs, it is hard to construct\nappropriate contrastive sample pairs. In this paper, we find that the entities\nwithin a symmetrical structure are usually more similar and correlated. This\nkey property can be utilized to construct contrastive positive pairs for\ncontrastive learning. Following the ideas above, we propose a relational\nsymmetrical structure based knowledge graph contrastive learning framework,\ntermed KGE-SymCL, which leverages the symmetrical structure information in KGs\nto enhance the discriminative ability of KGE models. Concretely, a\nplug-and-play approach is designed by taking the entities in the relational\nsymmetrical positions as the positive samples. Besides, a self-supervised\nalignment loss is used to pull together the constructed positive sample pairs\nfor contrastive learning. Extensive experimental results on benchmark datasets\nhave verified the good generalization and superiority of the proposed\nframework.",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Ke Liang",
      "Yue Liu",
      "Sihang Zhou",
      "Xinwang Liu",
      "Wenxuan Tu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10738"
  },
  {
    "id": "arXiv:2211.10739",
    "title": "EDEN: A Plug-in Equivariant Distance Encoding to Beyond the 1-WL Test",
    "abstract": "The message-passing scheme is the core of graph representation learning.\nWhile most existing message-passing graph neural networks (MPNNs) are\npermutation-invariant in graph-level representation learning and\npermutation-equivariant in node- and edge-level representation learning, their\nexpressive power is commonly limited by the 1-Weisfeiler-Lehman (1-WL) graph\nisomorphism test. Recently proposed expressive graph neural networks (GNNs)\nwith specially designed complex message-passing mechanisms are not practical.\nTo bridge the gap, we propose a plug-in Equivariant Distance ENcoding (EDEN)\nfor MPNNs. EDEN is derived from a series of interpretable transformations on\nthe graph's distance matrix. We theoretically prove that EDEN is\npermutation-equivariant for all level graph representation learning, and we\nempirically illustrate that EDEN's expressive power can reach up to the 3-WL\ntest. Extensive experiments on real-world datasets show that combining EDEN\nwith conventional GNNs surpasses recent advanced GNNs.",
    "descriptor": "",
    "authors": [
      "Chang Liu",
      "Yuwen Yang",
      "Yue Ding",
      "Hongtao Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10739"
  },
  {
    "id": "arXiv:2211.10742",
    "title": "Moment-SoS Methods for Optimal Transport Problems",
    "abstract": "Most common Optimal Transport (OT) solvers are currently based on an\napproximation of underlying measures by discrete measures. However, it is\nsometimes relevant to work only with moments of measures instead of the measure\nitself, and many common OT problems can be formulated as moment problems (the\nmost relevant examples being $L^p$-Wasserstein distances, barycenters, and\nGromov-Wasserstein discrepancies on Euclidean spaces). We leverage this fact to\ndevelop a generalized moment formulation that covers these classes of OT\nproblems. The transport plan is represented through its moments on a given\nbasis, and the marginal constraints are expressed in terms of moment\nconstraints. A practical computation then consists in considering a truncation\nof the involved moment sequences up to a certain order, and using the\npolynomial sums-of-squares hierarchy for measures supported on semi-algebraic\nsets. We prove that the strategy converges to the solution of the OT problem as\nthe order increases. We also show how to approximate linear quantities of\ninterest, and how to estimate the support of the optimal transport map from the\ncomputed moments using Christoffel-Darboux kernels. Numerical experiments\nillustrate the good behavior of the approach.",
    "descriptor": "",
    "authors": [
      "Olga Mula",
      "Anthony Nouy"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2211.10742"
  },
  {
    "id": "arXiv:2211.10743",
    "title": "Monitoring the edges of product networks using distances",
    "abstract": "Foucaud {\\it et al.} recently introduced and initiated the study of a new\ngraph-theoretic concept in the area of network monitoring. Let $G$ be a graph\nwith vertex set $V(G)$, $M$ a subset of $V(G)$, and $e$ be an edge in $E(G)$,\nand let $P(M, e)$ be the set of pairs $(x,y)$ such that $d_G(x, y)\\neq\nd_{G-e}(x, y)$ where $x\\in M$ and $y\\in V(G)$. $M$ is called a\n\\emph{distance-edge-monitoring set} if every edge $e$ of $G$ is monitored by\nsome vertex of $M$, that is, the set $P(M, e)$ is nonempty. The {\\em\ndistance-edge-monitoring number} of $G$, denoted by $\\operatorname{dem}(G)$, is\ndefined as the smallest size of distance-edge-monitoring sets of $G$. For two\ngraphs $G,H$ of order $m,n$, respectively, in this paper we prove that\n$\\max\\{m\\operatorname{dem}(H),n\\operatorname{dem}(G)\\}\n\\leq\\operatorname{dem}(G\\,\\Box \\,H) \\leq\nm\\operatorname{dem}(H)+n\\operatorname{dem}(G)\n-\\operatorname{dem}(G)\\operatorname{dem}(H)$, where $\\Box$ is the Cartesian\nproduct operation. Moreover, we characterize the graphs attaining the upper and\nlower bounds and show their applications on some known networks. We also obtain\nthe distance-edge-monitoring numbers of join, corona, cluster, and some\nspecific networks.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Wen Li",
      "Ralf Klasing",
      "Yaping Mao",
      "Bo Ning"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Networking and Internet Architecture (cs.NI)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.10743"
  },
  {
    "id": "arXiv:2211.10745",
    "title": "A priori error analysis of discrete-ordinate weak Galerkin method for  radiative transfer equation",
    "abstract": "This research article discusses a numerical solution of the radiative\ntransfer equation based on the weak Galerkin finite element method. We\ndiscretize the angular variable by means of the discrete-ordinate method. Then\nthe resulting semi-discrete hyperbolic system is approximated using the weak\nGalerkin method. The stability result for the proposed numerical method is\ndevised. A \\emph{priori} error analysis is established under the suitable norm.\nIn order to examine the theoretical results, numerical experiments are carried\nout.",
    "descriptor": "",
    "authors": [
      "Maneesh Kumar Singh"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.10745"
  },
  {
    "id": "arXiv:2211.10752",
    "title": "Towards Robust Dataset Learning",
    "abstract": "Adversarial training has been actively studied in recent computer vision\nresearch to improve the robustness of models. However, due to the huge\ncomputational cost of generating adversarial samples, adversarial training\nmethods are often slow. In this paper, we study the problem of learning a\nrobust dataset such that any classifier naturally trained on the dataset is\nadversarially robust. Such a dataset benefits the downstream tasks as natural\ntraining is much faster than adversarial training, and demonstrates that the\ndesired property of robustness is transferable between models and data. In this\nwork, we propose a principled, tri-level optimization to formulate the robust\ndataset learning problem. We show that, under an abstraction model that\ncharacterizes robust vs. non-robust features, the proposed method provably\nlearns a robust dataset. Extensive experiments on MNIST, CIFAR10, and\nTinyImageNet demostrate the effectiveness of our algorithm with different\nnetwork initializations and architectures.",
    "descriptor": "",
    "authors": [
      "Yihan Wu",
      "Xinda Li",
      "Florian Kerschbaum",
      "Heng Huang",
      "Hongyang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10752"
  },
  {
    "id": "arXiv:2211.10753",
    "title": "Continual Learning-Based MIMO Channel Estimation: A Benchmarking Study",
    "abstract": "With the proliferation of deep learning techniques for wireless\ncommunication, several works have adopted learning-based approaches to solve\nthe channel estimation problem. While these methods are usually promoted for\ntheir computational efficiency at inference time, their use is restricted to\nspecific stationary training settings in terms of communication system\nparameters, e.g., signal-to-noise ratio (SNR) and coherence time. Therefore,\nthe performance of these learning-based solutions will degrade when the models\nare tested on different settings than the ones used for training. This\nmotivates our work in which we investigate continual supervised learning (CL)\nto mitigate the shortcomings of the current approaches. In particular, we\ndesign a set of channel estimation tasks wherein we vary different parameters\nof the channel model. We focus on Gauss-Markov Rayleigh fading channel\nestimation to assess the impact of non-stationarity on performance in terms of\nthe mean square error (MSE) criterion. We study a selection of state-of-the-art\nCL methods and we showcase empirically the importance of catastrophic\nforgetting in continuously evolving channel settings. Our results demonstrate\nthat the CL algorithms can improve the interference performance in two channel\nestimation tasks governed by changes in the SNR level and coherence time.",
    "descriptor": "",
    "authors": [
      "Mohamed Akrout",
      "Amal Feriani",
      "Faouzi Bellili",
      "Amine Mezghani",
      "Ekram Hossain"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.10753"
  },
  {
    "id": "arXiv:2211.10754",
    "title": "HALSIE -- Hybrid Approach to Learning Segmentation by Simultaneously  Exploiting Image and Event Modalities",
    "abstract": "Standard frame-based algorithms fail to retrieve accurate segmentation maps\nin challenging real-time applications like autonomous navigation, owing to the\nlimited dynamic range and motion blur prevalent in traditional cameras. Event\ncameras address these limitations by asynchronously detecting changes in\nper-pixel intensity to generate event streams with high temporal resolution,\nhigh dynamic range, and no motion blur. However, event camera outputs cannot be\ndirectly used to generate reliable segmentation maps as they only capture\ninformation at the pixels in motion. To augment the missing contextual\ninformation, we postulate that fusing spatially dense frames with temporally\ndense events can generate semantic maps with fine-grained predictions. To this\nend, we propose HALSIE, a hybrid approach to learning segmentation by\nsimultaneously leveraging image and event modalities. To enable efficient\nlearning across modalities, our proposed hybrid framework comprises two input\nbranches, a Spiking Neural Network (SNN) branch and a standard Artificial\nNeural Network (ANN) branch to process event and frame data respectively, while\nexploiting their corresponding neural dynamics. Our hybrid network outperforms\nthe state-of-the-art semantic segmentation benchmarks on DDD17 and MVSEC\ndatasets and shows comparable performance on the DSEC-Semantic dataset with\nupto 33.23$\\times$ reduction in network parameters. Further, our method shows\nupto 18.92$\\times$ improvement in inference cost compared to existing SOTA\napproaches, making it suitable for resource-constrained edge applications.",
    "descriptor": "",
    "authors": [
      "Shristi Das Biswas",
      "Adarsh Kosta",
      "Chamika Liyanagedera",
      "Marco Apolinario",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10754"
  },
  {
    "id": "arXiv:2211.10756",
    "title": "Investigating the Potential of Artificial Intelligence Powered  Interfaces to Support Different Types of Memory for People with Dementia",
    "abstract": "There has been a growing interest in HCI to understand the specific\ntechnological needs of people with dementia and supporting them in\nself-managing daily activities. One of the most difficult challenges to address\nis supporting the fluctuating accessibility needs of people with dementia,\nwhich vary with the specific type of dementia and the progression of the\ncondition. Researchers have identified auto-personalized interfaces, and more\nrecently, Artificial Intelligence or AI-driven personalization as a potential\nsolution to making commercial technology accessible in a scalable manner for\nusers with fluctuating ability. However, there is a lack of understanding on\nthe perceptions of people with dementia around AI as an aid to their everyday\ntechnology use and its role in their overall self-management systems, which\ninclude other non-AI technology, and human assistance. In this paper, we\npresent future directions for the design of AI-based systems to personalize an\ninterface for dementia-related changes in different types of memory, along with\nexpectations for AI interactions with the user with dementia.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Hanuma Teja Maddali",
      "Emma Dixon",
      "Alisha Pradhan",
      "Amanda Lazar"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10756"
  },
  {
    "id": "arXiv:2211.10758",
    "title": "A priori error estimates of two fully discrete coupled schemes for  Biot's consolidation model",
    "abstract": "This paper concentrates on a priori error estimates of two fully discrete\ncoupled schemes for Biot's consolidation model based on the three-field\nformulation introduced by Oyarzua et al. (SIAM Journal on Numerical Analysis,\n2016). The spatial discretizations are based on the Taylor-Hood finite elements\ncombined with Lagrange elements for the three primary variables. For time\ndiscretization, we consider two methods. One uses the backward Euler method,\nand the other applies a combination of the backward Euler and Crank-Nicolson\nmethods. A priori error estimates show that the two schemes are unconditionally\nconvergent with optimal error orders. Detailed numerical experiments are\npresented to validate the theoretical analysis.",
    "descriptor": "",
    "authors": [
      "Huipeng Gu",
      "Mingchao Cai",
      "Jingzhi Li",
      "Guoliang Ju"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.10758"
  },
  {
    "id": "arXiv:2211.10760",
    "title": "An experimental study on Synthetic Tabular Data Evaluation",
    "abstract": "In this paper, we present the findings of various methodologies for measuring\nthe similarity of synthetic data generated from tabular data samples. We\nparticularly apply our research to the case where the synthetic data has many\nmore samples than the real data. This task has a special complexity: validating\nthe reliability of this synthetically generated data with a much higher number\nof samples than the original. We evaluated the most commonly used global\nmetrics found in the literature. We introduced a novel approach based on the\ndata's topological signature analysis. Topological data analysis has several\nadvantages in addressing this latter challenge. The study of qualitative\ngeometric information focuses on geometric properties while neglecting\nquantitative distance function values. This is especially useful with\nhigh-dimensional synthetic data where the sample size has been significantly\nincreased. It is comparable to introducing new data points into the data space\nwithin the limits set by the original data. Then, in large synthetic data\nspaces, points will be much more concentrated than in the original space, and\ntheir analysis will become much more sensitive to both the metrics used and\nnoise. Instead, the concept of \"closeness\" between points is used for\nqualitative geometric information. Finally, we suggest an approach based on\ndata Eigen vectors for evaluating the level of noise in synthetic data. This\napproach can also be used to assess the similarity of original and synthetic\ndata.",
    "descriptor": "",
    "authors": [
      "Javier Marin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10760"
  },
  {
    "id": "arXiv:2211.10763",
    "title": "PIDray: A Large-scale X-ray Benchmark for Real-World Prohibited Item  Detection",
    "abstract": "Automatic security inspection relying on computer vision technology is a\nchallenging task in real-world scenarios due to many factors, such as\nintra-class variance, class imbalance, and occlusion. Most previous methods\nrarely touch the cases where the prohibited items are deliberately hidden in\nmessy objects because of the scarcity of large-scale datasets, hindering their\napplications. To address this issue and facilitate related research, we present\na large-scale dataset, named PIDray, which covers various cases in real-world\nscenarios for prohibited item detection, especially for deliberately hidden\nitems. In specific, PIDray collects 124,486 X-ray images for $12$ categories of\nprohibited items, and each image is manually annotated with careful inspection,\nwhich makes it, to our best knowledge, to largest prohibited items detection\ndataset to date. Meanwhile, we propose a general divide-and-conquer pipeline to\ndevelop baseline algorithms on PIDray. Specifically, we adopt the tree-like\nstructure to suppress the influence of the long-tailed issue in the PIDray\ndataset, where the first course-grained node is tasked with the binary\nclassification to alleviate the influence of head category, while the\nsubsequent fine-grained node is dedicated to the specific tasks of the tail\ncategories. Based on this simple yet effective scheme, we offer strong\ntask-specific baselines across object detection, instance segmentation, and\nmulti-label classification tasks and verify the generalization ability on\ncommon datasets (e.g., COCO and PASCAL VOC). Extensive experiments on PIDray\ndemonstrate that the proposed method performs favorably against current\nstate-of-the-art methods, especially for deliberately hidden items. Our\nbenchmark and codes will be released at https://github.com/lutao2021/PIDray.",
    "descriptor": "\nComments: Tech. report. arXiv admin note: text overlap with arXiv:2108.07020\n",
    "authors": [
      "Libo Zhang",
      "Lutao Jiang",
      "Ruyi Ji",
      "Heng Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10763"
  },
  {
    "id": "arXiv:2211.10764",
    "title": "Understanding the Bystander Effect on Toxic Twitter Conversations",
    "abstract": "In this study, we explore the power of group dynamics to shape the toxicity\nof Twitter conversations. First, we examine how the presence of others in a\nconversation can potentially diffuse Twitter users' responsibility to address a\ntoxic direct reply. Second, we examine whether the toxicity of the first direct\nreply to a toxic tweet in conversations establishes the group norms for\nsubsequent replies. By doing so, we outline how bystanders and the tone of\ninitial responses to a toxic reply are explanatory factors which affect whether\nothers feel uninhibited to post their own abusive or derogatory replies. We\ntest this premise by analyzing a random sample of more than 156k tweets\nbelonging to ~9k conversations. Central to this work is the social\npsychological research on the \"bystander effect\" documenting that the presence\nof bystanders has the power to alter the dynamics of a social situation. If the\nfirst direct reply reaffirms the divisive tone, other replies may follow suit.\nWe find evidence of a bystander effect, with our results showing that an\nincreased number of users participating in the conversation before receiving a\ntoxic tweet is negatively associated with the number of Twitter users who\nresponded to the toxic reply in a non-toxic way. We also find that the initial\nresponses to toxic tweets within conversations is of great importance. Posting\na toxic reply immediately after a toxic comment is negatively associated with\nusers posting non-toxic replies and Twitter conversations becoming increasingly\ntoxic.",
    "descriptor": "",
    "authors": [
      "Ana Aleksandric",
      "Mohit Singhal",
      "Anne Groggel",
      "Shirin Nilizadeh"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.10764"
  },
  {
    "id": "arXiv:2211.10766",
    "title": "Sociality and Skill Sharing in the Garden",
    "abstract": "Gardening is an activity that involves a number of dimensions of increasing\ninterest to HCI and CSCW researchers, including recreation, sustainability, and\nengagement with nature. This paper considers the garden setting in order to\nunderstand the role that collaborative and social computing technologies might\nplay for practitioners engaging in outdoor skilled activities. We conducted\nparticipant observations with nine experienced gardeners aged 22-71 years.\nThrough this process, we find that gardeners continuously configure their\nenvironments to accommodate their preferences for sociality. They share\nembodied skills and help others attune to sensory information in person, but\nalso influence learning through the features in their garden that are observed\nby others. This paper provides an understanding of sociality in the garden,\nhighlights skill sharing as a key domain for design in this space, and\ncontributes design considerations for collaborative technologies in outdoor\nsettings.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Hanuma Teja Maddali",
      "Amanda Lazar"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.10766"
  },
  {
    "id": "arXiv:2211.10769",
    "title": "Assessing Opportunities of SYCL and Intel oneAPI for Biological Sequence  Alignment",
    "abstract": "Background and objectives. The computational biology area is growing up over\nthe years. The interest in researching and developing computational tools for\nthe acquisition, storage, organization, analysis, and visualization of\nbiological data generates the need to create new hardware architectures and new\nsoftware tools that allow processing big data in acceptable times. In this\nsense, heterogeneous computing takes an important role in providing solutions\nbut at the same time generates new challenges for developers in relation to the\nimpossibility of porting source code between different architectures.\nMethods. Intel has recently introduced oneAPI, a new unified programming\nenvironment that allows code developed in the SYCL-based Data Parallel C++\n(DPC++) language to be run on different devices such as CPUs, GPUs, and FPGAs,\namong others. Due to the large amount of CUDA software in the field of\nbioinformatics, this paper presents the migration process of the SW\\# suite, a\nbiological sequence alignment tool developed in CUDA, to DPC++ through the\noneAPI compatibility tool dpc (recently renowned as SYCLomatic).\nResults. SW\\# has been completely migrated with a small programmer\nintervention in terms of hand-coding. Moreover, it has been possible to port\nthe migrated code between different architectures (considering different target\nplatforms and vendors), with no noticeable performance degradation.\nConclusions. The SYCLomatic tool presented a great performance-portability\nrate. SYCL and Intel oneAPI can offer attractive opportunities for the\nBioinformatics community, especially considering the vast existence of\nCUDA-based legacy codes.",
    "descriptor": "",
    "authors": [
      "Manuel Costanzo",
      "Enzo Rucci",
      "Carlos Garc\u00eda S\u00e1nchez",
      "Marcelo Naiouf",
      "Manuel Prieto-Mat\u00edas"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.10769"
  },
  {
    "id": "arXiv:2211.10772",
    "title": "DeepSolo: Let Transformer Decoder with Explicit Points Solo for Text  Spotting",
    "abstract": "End-to-end text spotting aims to integrate scene text detection and\nrecognition into a unified framework. Dealing with the relationship between the\ntwo sub-tasks plays a pivotal role in designing effective spotters. Although\ntransformer-based methods eliminate the heuristic post-processing, they still\nsuffer from the synergy issue between the sub-tasks and low training\nefficiency. In this paper, we present DeepSolo, a simple detection transformer\nbaseline that lets a single Decoder with Explicit Points Solo for text\ndetection and recognition simultaneously. Technically, for each text instance,\nwe represent the character sequence as ordered points and model them with\nlearnable explicit point queries. After passing a single decoder, the point\nqueries have encoded requisite text semantics and locations and thus can be\nfurther decoded to the center line, boundary, script, and confidence of text\nvia very simple prediction heads in parallel, solving the sub-tasks in text\nspotting in a unified framework. Besides, we also introduce a text-matching\ncriterion to deliver more accurate supervisory signals, thus enabling more\nefficient training. Quantitative experiments on public benchmarks demonstrate\nthat DeepSolo outperforms previous state-of-the-art methods and achieves better\ntraining efficiency. In addition, DeepSolo is also compatible with line\nannotations, which require much less annotation cost than polygons. The code\nwill be released.",
    "descriptor": "",
    "authors": [
      "Maoyuan Ye",
      "Jing Zhang",
      "Shanshan Zhao",
      "Juhua Liu",
      "Tongliang Liu",
      "Bo Du",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10772"
  },
  {
    "id": "arXiv:2211.10773",
    "title": "A Two-Stage Active Learning Algorithm for $k$-Nearest Neighbors",
    "abstract": "We introduce a simple and intuitive two-stage active learning algorithm for\nthe training of $k$-nearest neighbors classifiers. We provide consistency\nguarantees for a modified $k$-nearest neighbors classifier trained on samples\nacquired via our scheme, and show that when the conditional probability\nfunction $\\mathbb{P}(Y=y|X=x)$ is sufficiently smooth and the Tsybakov noise\ncondition holds, our actively trained classifiers converge to the Bayes optimal\nclassifier at a faster asymptotic rate than passively trained $k$-nearest\nneighbor classifiers.",
    "descriptor": "",
    "authors": [
      "Nick Rittler",
      "Kamalika Chaudhuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10773"
  },
  {
    "id": "arXiv:2211.10780",
    "title": "ArtELingo: A Million Emotion Annotations of WikiArt with Emphasis on  Diversity over Language and Culture",
    "abstract": "This paper introduces ArtELingo, a new benchmark and dataset, designed to\nencourage work on diversity across languages and cultures. Following ArtEmis, a\ncollection of 80k artworks from WikiArt with 0.45M emotion labels and\nEnglish-only captions, ArtELingo adds another 0.79M annotations in Arabic and\nChinese, plus 4.8K in Spanish to evaluate \"cultural-transfer\" performance. More\nthan 51K artworks have 5 annotations or more in 3 languages. This diversity\nmakes it possible to study similarities and differences across languages and\ncultures. Further, we investigate captioning tasks, and find diversity improves\nthe performance of baseline models. ArtELingo is publicly available at\nhttps://www.artelingo.org/ with standard splits and baseline models. We hope\nour work will help ease future research on multilinguality and culturally-aware\nAI.",
    "descriptor": "\nComments: 9 pages, Accepted at EMNLP 22, for more details see this https URL\n",
    "authors": [
      "Youssef Mohamed",
      "Mohamed Abdelfattah",
      "Shyma Alhuwaider",
      "Feifan Li",
      "Xiangliang Zhang",
      "Kenneth Ward Church",
      "Mohamed Elhoseiny"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10780"
  },
  {
    "id": "arXiv:2211.10782",
    "title": "Let Graph be the Go Board: Gradient-free Node Injection Attack for Graph  Neural Networks via Reinforcement Learning",
    "abstract": "Graph Neural Networks (GNNs) have drawn significant attentions over the years\nand been broadly applied to essential applications requiring solid robustness\nor vigorous security standards, such as product recommendation and user\nbehavior modeling. Under these scenarios, exploiting GNN's vulnerabilities and\nfurther downgrading its performance become extremely incentive for adversaries.\nPrevious attackers mainly focus on structural perturbations or node injections\nto the existing graphs, guided by gradients from the surrogate models. Although\nthey deliver promising results, several limitations still exist. For the\nstructural perturbation attack, to launch a proposed attack, adversaries need\nto manipulate the existing graph topology, which is impractical in most\ncircumstances. Whereas for the node injection attack, though being more\npractical, current approaches require training surrogate models to simulate a\nwhite-box setting, which results in significant performance downgrade when the\nsurrogate architecture diverges from the actual victim model. To bridge these\ngaps, in this paper, we study the problem of black-box node injection attack,\nwithout training a potentially misleading surrogate model. Specifically, we\nmodel the node injection attack as a Markov decision process and propose\nGradient-free Graph Advantage Actor Critic, namely G2A2C, a reinforcement\nlearning framework in the fashion of advantage actor critic. By directly\nquerying the victim model, G2A2C learns to inject highly malicious nodes with\nextremely limited attacking budgets, while maintaining a similar node feature\ndistribution. Through our comprehensive experiments over eight acknowledged\nbenchmark datasets with different characteristics, we demonstrate the superior\nperformance of our proposed G2A2C over the existing state-of-the-art attackers.\nSource code is publicly available at: https://github.com/jumxglhf/G2A2C}.",
    "descriptor": "\nComments: AAAI 2023. arXiv admin note: substantial text overlap with arXiv:2202.09389\n",
    "authors": [
      "Mingxuan Ju",
      "Yujie Fan",
      "Chuxu Zhang",
      "Yanfang Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.10782"
  },
  {
    "id": "arXiv:2211.10791",
    "title": "NIO: Lightweight neural operator-based architecture for video frame  interpolation",
    "abstract": "We present, NIO - Neural Interpolation Operator, a lightweight efficient\nneural operator-based architecture to perform video frame interpolation.\nCurrent deep learning based methods rely on local convolutions for feature\nlearning and require a large amount of training on comprehensive datasets.\nFurthermore, transformer-based architectures are large and need dedicated GPUs\nfor training. On the other hand, NIO, our neural operator-based approach learns\nthe features in the frames by translating the image matrix into the Fourier\nspace by using Fast Fourier Transform (FFT). The model performs global\nconvolution, making it discretization invariant. We show that NIO can produce\nvisually-smooth and accurate results and converges in fewer epochs than\nstate-of-the-art approaches. To evaluate the visual quality of our interpolated\nframes, we calculate the structural similarity index (SSIM) and Peak Signal to\nNoise Ratio (PSNR) between the generated frame and the ground truth frame. We\nprovide the quantitative performance of our model on Vimeo-90K dataset, DAVIS,\nUCF101 and DISFA+ dataset.",
    "descriptor": "",
    "authors": [
      "Hrishikesh Viswanath",
      "Md Ashiqur Rahman",
      "Rashmi Bhaskara",
      "Aniket Bera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10791"
  },
  {
    "id": "arXiv:2211.10793",
    "title": "BENK: The Beran Estimator with Neural Kernels for Estimating the  Heterogeneous Treatment Effect",
    "abstract": "A method for estimating the conditional average treatment effect under\ncondition of censored time-to-event data called BENK (the Beran Estimator with\nNeural Kernels) is proposed. The main idea behind the method is to apply the\nBeran estimator for estimating the survival functions of controls and\ntreatments. Instead of typical kernel functions in the Beran estimator, it is\nproposed to implement kernels in the form of neural networks of a specific form\ncalled the neural kernels. The conditional average treatment effect is\nestimated by using the survival functions as outcomes of the control and\ntreatment neural networks which consists of a set of neural kernels with shared\nparameters. The neural kernels are more flexible and can accurately model a\ncomplex location structure of feature vectors. Various numerical simulation\nexperiments illustrate BENK and compare it with the well-known T-learner,\nS-learner and X-learner for several types of the control and treatment outcome\nfunctions based on the Cox models, the random survival forest and the\nNadaraya-Watson regression with Gaussian kernels. The code of proposed\nalgorithms implementing BENK is available in https://github.com/Stasychbr/BENK.",
    "descriptor": "",
    "authors": [
      "Stanislav R. Kirpichenko",
      "Lev V. Utkin",
      "Andrei V. Konstantinov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.10793"
  },
  {
    "id": "arXiv:2211.10794",
    "title": "NVDiff: Graph Generation through the Diffusion of Node Vectors",
    "abstract": "Learning to generate graphs is challenging as a graph is a set of pairwise\nconnected, unordered nodes encoding complex combinatorial structures. Recently,\nseveral works have proposed graph generative models based on normalizing flows\nor score-based diffusion models. However, these models need to generate nodes\nand edges in parallel from the same process, whose dimensionality is\nunnecessarily high. We propose NVDiff, which takes the VGAE structure and uses\na score-based generative model (SGM) as a flexible prior to sample node\nvectors. By modeling only node vectors in the latent space, NVDiff\nsignificantly reduces the dimension of the diffusion process and thus improves\nsampling speed. Built on the NVDiff framework, we introduce an attention-based\nscore network capable of capturing both local and global contexts of graphs.\nExperiments indicate that NVDiff significantly reduces computations and can\nmodel much larger graphs than competing methods. At the same time, it achieves\nsuperior or competitive performances over various datasets compared to previous\nmethods.",
    "descriptor": "",
    "authors": [
      "Xiaohui Chen",
      "Yukun Li",
      "Aonan Zhang",
      "Li-ping Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10794"
  },
  {
    "id": "arXiv:2211.10796",
    "title": "Quantifying Human Bias and Knowledge to guide ML models during Training",
    "abstract": "This paper discusses a crowdsourcing based method that we designed to\nquantify the importance of different attributes of a dataset in determining the\noutcome of a classification problem. This heuristic, provided by humans acts as\nthe initial weight seed for machine learning models and guides the model\ntowards a better optimal during the gradient descent process. Often times when\ndealing with data, it is not uncommon to deal with skewed datasets, that over\nrepresent items of certain classes, while underrepresenting the rest. Skewed\ndatasets may lead to unforeseen issues with models such as learning a biased\nfunction or overfitting. Traditional data augmentation techniques in supervised\nlearning include oversampling and training with synthetic data. We introduce an\nexperimental approach to dealing with such unbalanced datasets by including\nhumans in the training process. We ask humans to rank the importance of\nfeatures of the dataset, and through rank aggregation, determine the initial\nweight bias for the model. We show that collective human bias can allow ML\nmodels to learn insights about the true population instead of the biased\nsample. In this paper, we use two rank aggregator methods Kemeny Young and the\nMarkov Chain aggregator to quantify human opinion on importance of features.\nThis work mainly tests the effectiveness of human knowledge on binary\nclassification (Popular vs Not-popular) problems on two ML models: Deep Neural\nNetworks and Support Vector Machines. This approach considers humans as weak\nlearners and relies on aggregation to offset individual biases and domain\nunfamiliarity.",
    "descriptor": "",
    "authors": [
      "Hrishikesh Viswanath",
      "Andrey Shor",
      "Yoshimasa Kitaguchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.10796"
  },
  {
    "id": "arXiv:2211.10797",
    "title": "An Empirical Study On Contrastive Search And Contrastive Decoding For  Open-ended Text Generation",
    "abstract": "In the study, we empirically compare the two recently proposed decoding\nmethods, i.e. Contrastive Search (CS) and Contrastive Decoding (CD), for\nopen-ended text generation. The automatic evaluation results suggest that,\nwhile CS performs worse than CD on the MAUVE metric, it substantially surpasses\nCD on the diversity and coherence metrics. More notably, extensive human\nevaluations across three different domains demonstrate that human annotators\nare universally more in favor of CS over CD with substantial margins.\nThe contradicted results between MAUVE and human evaluations reveal that\nMAUVE does not accurately reflect human preferences. Therefore, we call upon\nthe research community to develop better evaluation metrics for open-ended text\ngeneration. To ensure the reproducibility of our work, we have open-sourced all\nour code, evaluation results, as well as human annotations at\nhttps://github.com/yxuansu/Contrastive_Search_versus_Contrastive_Decoding.",
    "descriptor": "\nComments: Technical report with 9 pages, 5 tables, and 6 figures\n",
    "authors": [
      "Yixuan Su",
      "Jialu Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.10797"
  },
  {
    "id": "arXiv:2211.10801",
    "title": "Peeling the Onion: Hierarchical Reduction of Data Redundancy for  Efficient Vision Transformer Training",
    "abstract": "Vision transformers (ViTs) have recently obtained success in many\napplications, but their intensive computation and heavy memory usage at both\ntraining and inference time limit their generalization. Previous compression\nalgorithms usually start from the pre-trained dense models and only focus on\nefficient inference, while time-consuming training is still unavoidable. In\ncontrast, this paper points out that the million-scale training data is\nredundant, which is the fundamental reason for the tedious training. To address\nthe issue, this paper aims to introduce sparsity into data and proposes an\nend-to-end efficient training framework from three sparse perspectives, dubbed\nTri-Level E-ViT. Specifically, we leverage a hierarchical data redundancy\nreduction scheme, by exploring the sparsity under three levels: number of\ntraining examples in the dataset, number of patches (tokens) in each example,\nand number of connections between tokens that lie in attention weights. With\nextensive experiments, we demonstrate that our proposed technique can\nnoticeably accelerate training for various ViT architectures while maintaining\naccuracy. Remarkably, under certain ratios, we are able to improve the ViT\naccuracy rather than compromising it. For example, we can achieve 15.2% speedup\nwith 72.6% (+0.4) Top-1 accuracy on Deit-T, and 15.7% speedup with 79.9% (+0.1)\nTop-1 accuracy on Deit-S. This proves the existence of data redundancy in ViT.",
    "descriptor": "\nComments: AAAI 2023\n",
    "authors": [
      "Zhenglun Kong",
      "Haoyu Ma",
      "Geng Yuan",
      "Mengshu Sun",
      "Yanyue Xie",
      "Peiyan Dong",
      "Xin Meng",
      "Xuan Shen",
      "Hao Tang",
      "Minghai Qin",
      "Tianlong Chen",
      "Xiaolong Ma",
      "Xiaohui Xie",
      "Zhangyang Wang",
      "Yanzhi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10801"
  },
  {
    "id": "arXiv:2211.10802",
    "title": "An adaptive route choice model for integrated fixed and flexible transit  systems",
    "abstract": "Over the past decade, there has been a surge of interest in the transport\ncommunity in the application of agent-based simulation models to evaluate\nflexible transit solutions characterized by different degrees of short-term\nflexibility in routing and scheduling. A central modeling decision in the\ndevelopment of an agent-based simulation model for the evaluation of flexible\ntransit is how one chooses to represent the mode- and route-choices of\ntravelers. The real-time adaptive behavior of travelers is intuitively\nimportant to model in the presence of a flexible transit service, where the\nrouting and scheduling of vehicles is highly dependent on supply-demand\ndynamics at a closer to real-time temporal resolution. We propose a\nutility-based transit route-choice model with representation of within-day\nadaptive travel behavior and between-day learning where station-based\nfixed-transit, flexible-transit, and active-mode alternatives may be\ndynamically combined in a single path. To enable experimentation, this\nroute-choice model is implemented within an agent-based dynamic public transit\nsimulation framework. Model properties are first explored in a choice between\nfixed- and flexible-transit modes for a toy network. The framework is then\napplied to illustrate level-of-service trade-offs and analyze traveler mode\nchoices within a mixed fixed- and flexible transit system in a case study based\non a real-life branched transit service in Stockholm, Sweden.",
    "descriptor": "\nComments: 33 pages, 9 figures, preprint\n",
    "authors": [
      "David Leffler",
      "Wilco Burghout",
      "Oded Cats",
      "Erik Jenelius"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.10802"
  },
  {
    "id": "arXiv:2211.10806",
    "title": "AiCEF: An AI-assisted Cyber Exercise Content Generation Framework Using  Named Entity Recognition",
    "abstract": "Content generation that is both relevant and up to date with the current\nthreats of the target audience is a critical element in the success of any\nCyber Security Exercise (CSE). Through this work, we explore the results of\napplying machine learning techniques to unstructured information sources to\ngenerate structured CSE content. The corpus of our work is a large dataset of\npublicly available cyber security articles that have been used to predict\nfuture threats and to form the skeleton for new exercise scenarios. Machine\nlearning techniques, like named entity recognition (NER) and topic extraction,\nhave been utilised to structure the information based on a novel ontology we\ndeveloped, named Cyber Exercise Scenario Ontology (CESO). Moreover, we used\nclustering with outliers to classify the generated extracted data into objects\nof our ontology. Graph comparison methodologies were used to match generated\nscenario fragments to known threat actors' tactics and help enrich the proposed\nscenario accordingly with the help of synthetic text generators. CESO has also\nbeen chosen as the prominent way to express both fragments and the final\nproposed scenario content by our AI-assisted Cyber Exercise Framework (AiCEF).\nOur methodology was put to test by providing a set of generated scenarios for\nevaluation to a group of experts to be used as part of a real-world awareness\ntabletop exercise.",
    "descriptor": "",
    "authors": [
      "Alexandros Zacharis",
      "Constantinos Patsakis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.10806"
  },
  {
    "id": "arXiv:2211.10807",
    "title": "Concept-based Explanations using Non-negative Concept Activation Vectors  and Decision Tree for CNN Models",
    "abstract": "This paper evaluates whether training a decision tree based on concepts\nextracted from a concept-based explainer can increase interpretability for\nConvolutional Neural Networks (CNNs) models and boost the fidelity and\nperformance of the used explainer. CNNs for computer vision have shown\nexceptional performance in critical industries. However, it is a significant\nbarrier when deploying CNNs due to their complexity and lack of\ninterpretability. Recent studies to explain computer vision models have shifted\nfrom extracting low-level features (pixel-based explanations) to mid-or\nhigh-level features (concept-based explanations). The current research\ndirection tends to use extracted features in developing approximation\nalgorithms such as linear or decision tree models to interpret an original\nmodel. In this work, we modify one of the state-of-the-art concept-based\nexplanations and propose an alternative framework named TreeICE. We design a\nsystematic evaluation based on the requirements of fidelity (approximate models\nto original model's labels), performance (approximate models to ground-truth\nlabels), and interpretability (meaningful of approximate models to humans). We\nconduct computational evaluation (for fidelity and performance) and human\nsubject experiments (for interpretability) We find that Tree-ICE outperforms\nthe baseline in interpretability and generates more human readable explanations\nin the form of a semantic tree structure. This work features how important to\nhave more understandable explanations when interpretability is crucial.",
    "descriptor": "",
    "authors": [
      "Gayda Mutahar",
      "Tim Miller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10807"
  },
  {
    "id": "arXiv:2211.10808",
    "title": "Combining State-of-the-Art Models with Maximal Marginal Relevance for  Few-Shot and Zero-Shot Multi-Document Summarization",
    "abstract": "In Natural Language Processing, multi-document summarization (MDS) poses many\nchallenges to researchers above those posed by single-document summarization\n(SDS). These challenges include the increased search space and greater\npotential for the inclusion of redundant information. While advancements in\ndeep learning approaches have led to the development of several advanced\nlanguage models capable of summarization, the variety of training data specific\nto the problem of MDS remains relatively limited. Therefore, MDS approaches\nwhich require little to no pretraining, known as few-shot or zero-shot\napplications, respectively, could be beneficial additions to the current set of\ntools available in summarization. To explore one possible approach, we devise a\nstrategy for combining state-of-the-art models' outputs using maximal marginal\nrelevance (MMR) with a focus on query relevance rather than document diversity.\nOur MMR-based approach shows improvement over some aspects of the current\nstate-of-the-art results in both few-shot and zero-shot MDS applications while\nmaintaining a state-of-the-art standard of output by all available metrics.",
    "descriptor": "",
    "authors": [
      "David Adams",
      "Gandharv Suri",
      "Yllias Chali"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.10808"
  },
  {
    "id": "arXiv:2211.10812",
    "title": "Face Swapping as A Simple Arithmetic Operation",
    "abstract": "We propose a novel high-fidelity face swapping method called \"Arithmetic Face\nSwapping\" (AFS) that explicitly disentangles the intermediate latent space W+\nof a pretrained StyleGAN into the \"identity\" and \"style\" subspaces so that a\nlatent code in W+ is the sum of an \"identity\" code and a \"style\" code in the\ncorresponding subspaces. Via our disentanglement, face swapping (FS) can be\nregarded as a simple arithmetic operation in W+, i.e., the summation of a\nsource \"identity\" code and a target \"style\" code. This makes AFS more intuitive\nand elegant than other FS methods. In addition, our method can generalize over\nthe standard face swapping to support other interesting operations, e.g.,\ncombining the identity of one source with styles of multiple targets and vice\nversa. We implement our identity-style disentanglement by learning a neural\nnetwork that maps a latent code to a \"style\" code. We provide a condition for\nthis network which theoretically guarantees identity preservation of the source\nface even after a sequence of face swapping operations. Extensive experiments\ndemonstrate the advantage of our method over state-of-the-art FS methods in\nproducing high-quality swapped faces.",
    "descriptor": "",
    "authors": [
      "Truong Vu",
      "Kien Do",
      "Khang Nguyen",
      "Khoat Than"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10812"
  },
  {
    "id": "arXiv:2211.10815",
    "title": "Non-stationary Risk-sensitive Reinforcement Learning: Near-optimal  Dynamic Regret, Adaptive Detection, and Separation Design",
    "abstract": "We study risk-sensitive reinforcement learning (RL) based on an entropic risk\nmeasure in episodic non-stationary Markov decision processes (MDPs). Both the\nreward functions and the state transition kernels are unknown and allowed to\nvary arbitrarily over time with a budget on their cumulative variations. When\nthis variation budget is known a prior, we propose two restart-based\nalgorithms, namely Restart-RSMB and Restart-RSQ, and establish their dynamic\nregrets. Based on these results, we further present a meta-algorithm that does\nnot require any prior knowledge of the variation budget and can adaptively\ndetect the non-stationarity on the exponential value functions. A dynamic\nregret lower bound is then established for non-stationary risk-sensitive RL to\ncertify the near-optimality of the proposed algorithms. Our results also show\nthat the risk control and the handling of the non-stationarity can be\nseparately designed in the algorithm if the variation budget is known a prior,\nwhile the non-stationary detection mechanism in the adaptive algorithm depends\non the risk parameter. This work offers the first non-asymptotic theoretical\nanalyses for the non-stationary risk-sensitive RL in the literature.",
    "descriptor": "\nComments: 33 pages,3 figures, AAAI 2023\n",
    "authors": [
      "Yuhao Ding",
      "Ming Jin",
      "Javad Lavaei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.10815"
  },
  {
    "id": "arXiv:2211.10819",
    "title": "Block size estimation for data partitioning in HPC applications using  machine learning techniques",
    "abstract": "The extensive use of HPC infrastructures and frameworks for running\ndata-intensive applications has led to a growing interest in data partitioning\ntechniques and strategies. In fact, finding an effective partitioning, i.e. a\nsuitable size for data blocks, is a key strategy to speed-up parallel\ndata-intensive applications and increase scalability. This paper describes a\nmethodology for data block size estimation in HPC applications, which relies on\nsupervised machine learning techniques. The implementation of the proposed\nmethodology was evaluated using as a testbed dislib, a distributed computing\nlibrary highly focused on machine learning algorithms built on top of the\nPyCOMPSs framework. We assessed the effectiveness of our solution through an\nextensive experimental evaluation considering different algorithms, datasets,\nand infrastructures, including the MareNostrum 4 supercomputer. The results we\nobtained show that the methodology is able to efficiently determine a suitable\nway to split a given dataset, thus enabling the efficient execution of\ndata-parallel applications in high performance environments.",
    "descriptor": "",
    "authors": [
      "Riccardo Cantini",
      "Fabrizio Marozzo",
      "Alessio Orsino",
      "Domenico Talia",
      "Paolo Trunfio",
      "Rosa M. Badia",
      "Jorge Ejarque",
      "Fernando Vazquez"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10819"
  },
  {
    "id": "arXiv:2211.10821",
    "title": "DeepGAR: Deep Graph Learning for Analogical Reasoning",
    "abstract": "Analogical reasoning is the process of discovering and mapping\ncorrespondences from a target subject to a base subject. As the most well-known\ncomputational method of analogical reasoning, Structure-Mapping Theory (SMT)\nabstracts both target and base subjects into relational graphs and forms the\ncognitive process of analogical reasoning by finding a corresponding subgraph\n(i.e., correspondence) in the target graph that is aligned with the base graph.\nHowever, incorporating deep learning for SMT is still under-explored due to\nseveral obstacles: 1) the combinatorial complexity of searching for the\ncorrespondence in the target graph; 2) the correspondence mining is restricted\nby various cognitive theory-driven constraints. To address both challenges, we\npropose a novel framework for Analogical Reasoning (DeepGAR) that identifies\nthe correspondence between source and target domains by assuring cognitive\ntheory-driven constraints. Specifically, we design a geometric constraint\nembedding space to induce subgraph relation from node embeddings for efficient\nsubgraph search. Furthermore, we develop novel learning and optimization\nstrategies that could end-to-end identify correspondences that are strictly\nconsistent with constraints driven by the cognitive theory. Extensive\nexperiments are conducted on synthetic and real-world datasets to demonstrate\nthe effectiveness of the proposed DeepGAR over existing methods.",
    "descriptor": "\nComments: 22nd IEEE International Conference on Data Mining (ICDM 2022)\n",
    "authors": [
      "Chen Ling",
      "Tanmoy Chowdhury",
      "Junji Jiang",
      "Junxiang Wang",
      "Xuchao Zhang",
      "Haifeng Chen",
      "Liang Zhao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.10821"
  },
  {
    "id": "arXiv:2211.10825",
    "title": "Identifiability of dynamic networks: the essential r\u00f4le of dources and  dinks",
    "abstract": "The paper [1] presented the first results on generic identifiability of\ndynamic networks with partial excitation and partial measurements, i.e.\nnetworks where not all nodes are excited or not all nodes are measured. One key\ncontribution of that paper was to establish a set of necessary conditions on\nthe excitation and measurement pattern (EMP) that guarantee generic\nidentifiability. In a nutshell, these conditions established that all sources\nmust be excited and all sinks measured, and that all other nodes must be either\nexcited or measured. In the present paper, we show that two other types of\nnodes, which are defined by the local topology of the network, play an\nessential r\\^ole in the search for a valid EMP, i.e. one that guarantees\ngeneric identifiability. We have called these nodes dources and dinks. We show\nthat a network is generically identifiable only if, in addition to the above\nmentioned conditions, all dources are excited and all dinks are measured. We\nalso show that sources and dources are the only nodes in a network that always\nneed to be excited, and that sinks and dinks are the only nodes that need to be\nmeasured for an EMP to be valid.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Automatic Control\n",
    "authors": [
      "Eduardo Mapurunga",
      "Michel Gevers",
      "Alexandre S. Bazanella"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.10825"
  },
  {
    "id": "arXiv:2211.10827",
    "title": "Structure-Enhanced Deep Reinforcement Learning for Optimal Transmission  Scheduling",
    "abstract": "Remote state estimation of large-scale distributed dynamic processes plays an\nimportant role in Industry 4.0 applications. In this paper, by leveraging the\ntheoretical results of structural properties of optimal scheduling policies, we\ndevelop a structure-enhanced deep reinforcement learning (DRL) framework for\noptimal scheduling of a multi-sensor remote estimation system to achieve the\nminimum overall estimation mean-square error (MSE). In particular, we propose a\nstructure-enhanced action selection method, which tends to select actions that\nobey the policy structure. This explores the action space more effectively and\nenhances the learning efficiency of DRL agents. Furthermore, we introduce a\nstructure-enhanced loss function to add penalty to actions that do not follow\nthe policy structure. The new loss function guides the DRL to converge to the\noptimal policy structure quickly. Our numerical results show that the proposed\nstructure-enhanced DRL algorithms can save the training time by 50% and reduce\nthe remote estimation MSE by 10% to 25%, when compared to benchmark DRL\nalgorithms.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Jiazheng Chen",
      "Wanchun Liu",
      "Daniel E. Quevedo",
      "Yonghui Li",
      "Branka Vucetic"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.10827"
  },
  {
    "id": "arXiv:2211.10828",
    "title": "Instability in clinical risk stratification models using deep learning",
    "abstract": "While it has been well known in the ML community that deep learning models\nsuffer from instability, the consequences for healthcare deployments are under\ncharacterised. We study the stability of different model architectures trained\non electronic health records, using a set of outpatient prediction tasks as a\ncase study. We show that repeated training runs of the same deep learning model\non the same training data can result in significantly different outcomes at a\npatient level even though global performance metrics remain stable. We propose\ntwo stability metrics for measuring the effect of randomness of model training,\nas well as mitigation strategies for improving model stability.",
    "descriptor": "\nComments: Accepted for publication in Machine Learning for Health (ML4H) 2022\n",
    "authors": [
      "Daniel Lopez-Martinez",
      "Alex Yakubovich",
      "Martin Seneviratne",
      "Adam D. Lelkes",
      "Akshit Tyagi",
      "Jonas Kemp",
      "Ethan Steinberg",
      "N. Lance Downing",
      "Ron C. Li",
      "Keith E. Morse",
      "Nigam H. Shah",
      "Ming-Jun Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10828"
  },
  {
    "id": "arXiv:2211.10830",
    "title": "Discrete Lagrangian Neural Networks with Automatic Symmetry Discovery",
    "abstract": "By one of the most fundamental principles in physics, a dynamical system will\nexhibit those motions which extremise an action functional. This leads to the\nformation of the Euler-Lagrange equations, which serve as a model of how the\nsystem will behave in time. If the dynamics exhibit additional symmetries, then\nthe motion fulfils additional conservation laws, such as conservation of energy\n(time invariance), momentum (translation invariance), or angular momentum\n(rotational invariance). To learn a system representation, one could learn the\ndiscrete Euler-Lagrange equations, or alternatively, learn the discrete\nLagrangian function $\\mathcal{L}_d$ which defines them. Based on ideas from Lie\ngroup theory, in this work we introduce a framework to learn a discrete\nLagrangian along with its symmetry group from discrete observations of motions\nand, therefore, identify conserved quantities. The learning process does not\nrestrict the form of the Lagrangian, does not require velocity or momentum\nobservations or predictions and incorporates a cost term which safeguards\nagainst unwanted solutions and against potential numerical issues in forward\nsimulations. The learnt discrete quantities are related to their continuous\nanalogues using variational backward error analysis and numerical results\ndemonstrate the improvement such models can have both qualitatively and\nquantitatively even in the presence of noise.",
    "descriptor": "",
    "authors": [
      "Yana Lishkova",
      "Paul Scherer",
      "Steffen Ridderbusch",
      "Mateja Jamnik",
      "Pietro Li\u00f2",
      "Sina Ober-Bl\u00f6baum",
      "Christian Offen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Symplectic Geometry (math.SG)"
    ],
    "url": "https://arxiv.org/abs/2211.10830"
  },
  {
    "id": "arXiv:2211.10831",
    "title": "Joint Embedding Predictive Architectures Focus on Slow Features",
    "abstract": "Many common methods for learning a world model for pixel-based environments\nuse generative architectures trained with pixel-level reconstruction\nobjectives. Recently proposed Joint Embedding Predictive Architectures (JEPA)\noffer a reconstruction-free alternative. In this work, we analyze performance\nof JEPA trained with VICReg and SimCLR objectives in the fully offline setting\nwithout access to rewards, and compare the results to the performance of the\ngenerative architecture. We test the methods in a simple environment with a\nmoving dot with various background distractors, and probe learned\nrepresentations for the dot's location. We find that JEPA methods perform on\npar or better than reconstruction when distractor noise changes every time\nstep, but fail when the noise is fixed. Furthermore, we provide a theoretical\nexplanation for the poor performance of JEPA-based methods with fixed noise,\nhighlighting an important limitation.",
    "descriptor": "\nComments: 4 pages (3 figures) short paper for SSL Theory and Practice workshop at NeurIPS 2022. Code is available at this https URL\n",
    "authors": [
      "Vlad Sobal",
      "Jyothir S V",
      "Siddhartha Jalagam",
      "Nicolas Carion",
      "Kyunghyun Cho",
      "Yann LeCun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10831"
  },
  {
    "id": "arXiv:2211.10832",
    "title": "NeuroSketch: Fast and Approximate Evaluation of Range Aggregate Queries  with Neural Networks",
    "abstract": "Range aggregate queries (RAQs) are an integral part of many real-world\napplications, where, often, fast and approximate answers for the queries are\ndesired. Recent work has studied answering RAQs using machine learning (ML)\nmodels, where a model of the data is learned to answer the queries. However,\nthere is no theoretical understanding of why and when the ML based approaches\nperform well. Furthermore, since the ML approaches model the data, they fail to\ncapitalize on any query specific information to improve performance in\npractice. In this paper, we focus on modeling ``queries'' rather than data and\ntrain neural networks to learn the query answers. This change of focus allows\nus to theoretically study our ML approach to provide a distribution and query\ndependent error bound for neural networks when answering RAQs. We confirm our\ntheoretical results by developing NeuroSketch, a neural network framework to\nanswer RAQs in practice. Extensive experimental study on real-world,\nTPC-benchmark and synthetic datasets show that NeuroSketch answers RAQs\nmultiple orders of magnitude faster than state-of-the-art and with better\naccuracy.",
    "descriptor": "\nComments: Conference paper in SIGMOD 2023. arXiv admin note: text overlap with arXiv:2107.04922\n",
    "authors": [
      "Sepanta Zeighami",
      "Cyrus Shahabi",
      "Vatsal Sharan"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.10832"
  },
  {
    "id": "arXiv:2211.10833",
    "title": "A two dimensional fluid model for TCP/AQM analysis",
    "abstract": "This work proposes a new mathematical model for the TCP/AQM system that aims\nto improve the accuracy of existing fluid models, especially with respect to\nthe sequential events that occur in the network. The analysis is based on the\nconsideration of two time bases, one at the queue's router level and the other\nat the congestion window level, which leads to the derivation of a new\nnonlinear two-dimensional fluid model for Internet congestion control. To avoid\nthe difficult task of assessing stability of a 2D nonlinear dynamic model, we\nperform a local stability analysis of a 2D linear TCP AQM model. By\nconstructing a new two dimensional second order Bessel Legendre Lyapunov\nfunctional, new matrix inequalities are derived to evaluate the stability of\nthe 0-input system and to synthesize a feedback controller. Finally, two\nInternet traffic scenarios, with state space matrices for replicability, are\npresented, demonstrating the validity of the theoretical results.",
    "descriptor": "\nComments: Active queue management, network assisted congestion control, TCP/AQM, 2D time delay systems, Roesser model, 2D second order bessel Legendre, Lyapunov\n",
    "authors": [
      "Sadek Belamfedel Alaoui",
      "Alejandro J. Rojas",
      "Abdelaziz Hmamed",
      "El Houssaine Tissir"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.10833"
  },
  {
    "id": "arXiv:2211.10835",
    "title": "Context-aware learning of hierarchies of low-fidelity models for  multi-fidelity uncertainty quantification",
    "abstract": "Multi-fidelity Monte Carlo methods leverage low-fidelity and surrogate models\nfor variance reduction to make tractable uncertainty quantification even when\nnumerically simulating the physical systems of interest with high-fidelity\nmodels is computationally expensive. This work proposes a context-aware\nmulti-fidelity Monte Carlo method that optimally balances the costs of training\nlow-fidelity models with the costs of Monte Carlo sampling. It generalizes the\npreviously developed context-aware bi-fidelity Monte Carlo method to\nhierarchies of multiple models and to more general types of low-fidelity\nmodels. When training low-fidelity models, the proposed approach takes into\naccount the context in which the learned low-fidelity models will be used,\nnamely for variance reduction in Monte Carlo estimation, which allows it to\nfind optimal trade-offs between training and sampling to minimize upper bounds\nof the mean-squared errors of the estimators for given computational budgets.\nThis is in stark contrast to traditional surrogate modeling and model reduction\ntechniques that construct low-fidelity models with the primary goal of\napproximating well the high-fidelity model outputs and typically ignore the\ncontext in which the learned models will be used in upstream tasks. The\nproposed context-aware multi-fidelity Monte Carlo method applies to hierarchies\nof a wide range of types of low-fidelity models such as sparse-grid and\ndeep-network models. Numerical experiments with the gyrokinetic simulation code\n\\textsc{Gene} show speedups of up to two orders of magnitude compared to\nstandard estimators when quantifying uncertainties in small-scale fluctuations\nin confined plasma in fusion reactors. This corresponds to a runtime reduction\nfrom 72 days to about four hours on one node of the Lonestar6 supercomputer at\nthe Texas Advanced Computing Center.",
    "descriptor": "\nComments: 25 pages, 12 figures, 3 tables\n",
    "authors": [
      "Ionut-Gabriel Farcas",
      "Benjamin Peherstorfer",
      "Tobias Neckel",
      "Frank Jenko",
      "Hans-Joachim Bungartz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.10835"
  },
  {
    "id": "arXiv:2211.10837",
    "title": "Non-reversible Parallel Tempering for Deep Posterior Approximation",
    "abstract": "Parallel tempering (PT), also known as replica exchange, is the go-to\nworkhorse for simulations of multi-modal distributions. The key to the success\nof PT is to adopt efficient swap schemes. The popular deterministic even-odd\n(DEO) scheme exploits the non-reversibility property and has successfully\nreduced the communication cost from $O(P^2)$ to $O(P)$ given sufficiently many\n$P$ chains. However, such an innovation largely disappears in big data due to\nthe limited chains and few bias-corrected swaps. To handle this issue, we\ngeneralize the DEO scheme to promote non-reversibility and propose a few\nsolutions to tackle the underlying bias caused by the geometric stopping time.\nNotably, in big data scenarios, we obtain an appealing communication cost\n$O(P\\log P)$ based on the optimal window size. In addition, we also adopt\nstochastic gradient descent (SGD) with large and constant learning rates as\nexploration kernels. Such a user-friendly nature enables us to conduct\napproximation tasks for complex posteriors without much tuning costs.",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Wei Deng",
      "Qian Zhang",
      "Qi Feng",
      "Faming Liang",
      "Guang Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.10837"
  },
  {
    "id": "arXiv:2211.10841",
    "title": "SeDR: Segment Representation Learning for Long Documents Dense Retrieval",
    "abstract": "Recently, Dense Retrieval (DR) has become a promising solution to document\nretrieval, where document representations are used to perform effective and\nefficient semantic search. However, DR remains challenging on long documents,\ndue to the quadratic complexity of its Transformer-based encoder and the finite\ncapacity of a low-dimension embedding. Current DR models use suboptimal\nstrategies such as truncating or splitting-and-pooling to long documents\nleading to poor utilization of whole document information. In this work, to\ntackle this problem, we propose Segment representation learning for long\ndocuments Dense Retrieval (SeDR). In SeDR, Segment-Interaction Transformer is\nproposed to encode long documents into document-aware and segment-sensitive\nrepresentations, while it holds the complexity of splitting-and-pooling and\noutperforms other segment-interaction patterns on DR. Since GPU memory\nrequirements for long document encoding causes insufficient negatives for DR\ntraining, Late-Cache Negative is further proposed to provide additional cache\nnegatives for optimizing representation learning. Experiments on MS MARCO and\nTREC-DL datasets show that SeDR achieves superior performance among DR models,\nand confirm the effectiveness of SeDR on long document retrieval.",
    "descriptor": "",
    "authors": [
      "Junying Chen",
      "Qingcai Chen",
      "Dongfang Li",
      "Yutao Huang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.10841"
  },
  {
    "id": "arXiv:2211.10843",
    "title": "Mask Off: Analytic-based Malware Detection By Transfer Learning and  Model Personalization",
    "abstract": "The vulnerability of smartphones to cyberattacks has been a severe concern to\nusers arising from the integrity of installed applications (\\textit{apps}).\nAlthough applications are to provide legitimate and diversified on-the-go\nservices, harmful and dangerous ones have also uncovered the feasible way to\npenetrate smartphones for malicious behaviors. Thorough application analysis is\nkey to revealing malicious intent and providing more insights into the\napplication behavior for security risk assessments. Such in-depth analysis\nmotivates employing deep neural networks (DNNs) for a set of features and\npatterns extracted from applications to facilitate detecting potentially\ndangerous applications independently. This paper presents an Analytic-based\ndeep neural network, Android Malware detection (ADAM), that employs a\nfine-grained set of features to train feature-specific DNNs to have consensus\non the application labels when their ground truth is unknown. In addition, ADAM\nleverages the transfer learning technique to obtain its adjustability to new\napplications across smartphones for recycling the pre-trained model(s) and\nmaking them more adaptable by model personalization and federated learning\ntechniques. This adjustability is also assisted by federated learning guards,\nwhich protect ADAM against poisoning attacks through model analysis. ADAM\nrelies on a diverse dataset containing more than 153000 applications with over\n41000 extracted features for DNNs training. The ADAM's feature-specific DNNs,\non average, achieved more than 98% accuracy, resulting in an outstanding\nperformance against data manipulation attacks.",
    "descriptor": "",
    "authors": [
      "Amirmohammad Pasdar",
      "Young Choon Lee",
      "Seok-Hee Hong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10843"
  },
  {
    "id": "arXiv:2211.10844",
    "title": "Learning to Generate Image Embeddings with User-level Differential  Privacy",
    "abstract": "Small on-device models have been successfully trained with user-level\ndifferential privacy (DP) for next word prediction and image classification\ntasks in the past. However, existing methods can fail when directly applied to\nlearn embedding models using supervised training data with a large class space.\nTo achieve user-level DP for large image-to-embedding feature extractors, we\npropose DP-FedEmb, a variant of federated learning algorithms with per-user\nsensitivity control and noise addition, to train from user-partitioned data\ncentralized in the datacenter. DP-FedEmb combines virtual clients, partial\naggregation, private local fine-tuning, and public pretraining to achieve\nstrong privacy utility trade-offs. We apply DP-FedEmb to train image embedding\nmodels for faces, landmarks and natural species, and demonstrate its superior\nutility under same privacy budget on benchmark datasets DigiFace, EMNIST, GLD\nand iNaturalist. We further illustrate it is possible to achieve strong\nuser-level DP guarantees of $\\epsilon<2$ while controlling the utility drop\nwithin 5%, when millions of users can participate in training.",
    "descriptor": "",
    "authors": [
      "Zheng Xu",
      "Maxwell Collins",
      "Yuxiao Wang",
      "Liviu Panait",
      "Sewoong Oh",
      "Sean Augenstein",
      "Ting Liu",
      "Florian Schroff",
      "H. Brendan McMahan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10844"
  },
  {
    "id": "arXiv:2211.10846",
    "title": "An integral-like numerical approach for solving Burgers' equation",
    "abstract": "An integral-like approach established on spline polynomial interpolations is\napplied to the one-dimensional Burgers' equation. The Hopf-Cole transformation\nthat converts non-linear Burgers' equation to linear diffusion problem is\nemulated by using Taylor series expansion. The diffusion equation is then\nsolved by using analytic integral formulas. Four experiments were performed to\nexamine its accuracy, stability and parallel scalability. The correctness of\nthe numerical solutions is evaluated by comparing with exact solution and\nassessed error norms. Due to its integral-like characteristic, large time step\nsize can be employed without loss of accuracy and numerical stability. For\npractical applications, at least cubic interpolation is recommended. Parallel\nefficiency seen in the weak-scaling experiment depends on time step size but\ngenerally adequate.",
    "descriptor": "\nComments: Under submission. 20 pages, 5 figures, 6 tables\n",
    "authors": [
      "Somrath Kanoksirirath"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.10846"
  },
  {
    "id": "arXiv:2211.10850",
    "title": "Context-Aware Data Augmentation for LIDAR 3D Object Detection",
    "abstract": "For 3D object detection, labeling lidar point cloud is difficult, so data\naugmentation is an important module to make full use of precious annotated\ndata. As a widely used data augmentation method, GT-sample effectively improves\ndetection performance by inserting groundtruths into the lidar frame during\ntraining. However, these samples are often placed in unreasonable areas, which\nmisleads model to learn the wrong context information between targets and\nbackgrounds. To address this problem, in this paper, we propose a context-aware\ndata augmentation method (CA-aug) , which ensures the reasonable placement of\ninserted objects by calculating the \"Validspace\" of the lidar point cloud.\nCA-aug is lightweight and compatible with other augmentation methods. Compared\nwith the GT-sample and the similar method in Lidar-aug(SOTA), it brings higher\naccuracy to the existing detectors. We also present an in-depth study of\naugmentation methods for the range-view-based(RV-based) models and find that\nCA-aug can fully exploit the potential of RV-based networks. The experiment on\nKITTI val split shows that CA-aug can improve the mAP of the test model by 8%.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Xuzhong Hu",
      "Zaipeng Duan",
      "Jie Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10850"
  },
  {
    "id": "arXiv:2211.10851",
    "title": "Reward is not Necessary: How to Create a Compositional Self-Preserving  Agent for Life-Long Learning",
    "abstract": "We introduce a physiological model-based agent as proof-of-principle that it\nis possible to define a flexible self-preserving system that does not use a\nreward signal or reward-maximization as an objective. We achieve this by\nintroducing the Self-Preserving Agent (SPA) with a physiological structure\nwhere the system can get trapped in an absorbing state if the agent does not\nsolve and execute goal-directed polices. Our agent is defined using new class\nof Bellman equations called Operator Bellman Equations (OBEs), for encoding\njointly non-stationary non-Markovian tasks formalized as a Temporal Goal Markov\nDecision Process (TGMDP). OBEs produce optimal goal-conditioned spatiotemporal\ntransition operators that map an initial state-time to the final state-times of\na policy used to complete a goal, and can also be used to forecast future\nstates in multiple dynamic physiological state-spaces. SPA is equipped with an\nintrinsic motivation function called the valence function, which quantifies the\nchanges in empowerment (the channel capacity of a transition operator) after\nfollowing a policy. Because empowerment is a function of a transition operator,\nthere is a natural synergism between empowerment and OBEs: the OBEs create\nhierarchical transition operators, and the valence function can evaluate\nhierarchical empowerment change defined on these operators. The valence\nfunction can then be used for goal selection, wherein the agent chooses a\npolicy sequence that realizes goal states which produce maximum empowerment\ngain. In doing so, the agent will seek freedom and avoid internal death-states\nthat undermine its ability to control both external and internal states in the\nfuture, thereby exhibiting the capacity of predictive and anticipatory\nself-preservation. We also compare SPA to Multi-objective RL, and discuss its\ncapacity for symbolic reasoning and life-long learning.",
    "descriptor": "\nComments: 54 pages\n",
    "authors": [
      "Thomas J. Ringstrom"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10851"
  },
  {
    "id": "arXiv:2211.10854",
    "title": "Mulco: Recognizing Chinese Nested Named Entities Through Multiple Scopes",
    "abstract": "Nested Named Entity Recognition (NNER) has been a long-term challenge to\nresearchers as an important sub-area of Named Entity Recognition. NNER is where\none entity may be part of a longer entity, and this may happen on multiple\nlevels, as the term nested suggests. These nested structures make traditional\nsequence labeling methods unable to properly recognize all entities. While\nrecent researches focus on designing better recognition methods for NNER in a\nvariety of languages, the Chinese NNER (CNNER) still lacks attention, where a\nfree-for-access, CNNER-specialized benchmark is absent. In this paper, we aim\nto solve CNNER problems by providing a Chinese dataset and a learning-based\nmodel to tackle the issue. To facilitate the research on this task, we release\nChiNesE, a CNNER dataset with 20,000 sentences sampled from online passages of\nmultiple domains, containing 117,284 entities failing in 10 categories, where\n43.8 percent of those entities are nested. Based on ChiNesE, we propose Mulco,\na novel method that can recognize named entities in nested structures through\nmultiple scopes. Each scope use a designed scope-based sequence labeling\nmethod, which predicts an anchor and the length of a named entity to recognize\nit. Experiment results show that Mulco has outperformed several baseline\nmethods with the different recognizing schemes on ChiNesE. We also conduct\nextensive experiments on ACE2005 Chinese corpus, where Mulco has achieved the\nbest performance compared with the baseline methods.",
    "descriptor": "",
    "authors": [
      "Jiuding Yang",
      "Jinwen Luo",
      "Weidong Guo",
      "Jerry Chen",
      "Di Niu",
      "Yu Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10854"
  },
  {
    "id": "arXiv:2211.10855",
    "title": "Finite-Time Distributed Optimization with Quantized Gradient Descent",
    "abstract": "In this paper, we consider the unconstrained distributed optimization\nproblem, in which the exchange of information in the network is captured by a\ndirected graph topology, and thus nodes can send information to their\nout-neighbors only. Additionally, the communication channels among the nodes\nhave limited bandwidth, to alleviate the limitation, quantized messages should\nbe exchanged among the nodes. For solving the distributed optimization problem,\nwe combine a distributed quantized consensus algorithm (which requires the\nnodes to exchange quantized messages and converges in a finite number of steps)\nwith a gradient descent method. Specifically, at every optimization step, each\nnode performs a gradient descent step (i.e., subtracts the scaled gradient from\nits current estimate), and then performs a finite-time calculation of the\nquantized average of every node's estimate in the network. As a consequence,\nthis algorithm approximately mimics the centralized gradient descent algorithm.\nThe performance of the proposed algorithm is demonstrated via simple\nillustrative examples.",
    "descriptor": "",
    "authors": [
      "Apostolos I. Rikos",
      "Wei Jiang",
      "Themistoklis Charalambous",
      "Karl H. Johansson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.10855"
  },
  {
    "id": "arXiv:2211.10856",
    "title": "Diffeomorphic Information Neural Estimation",
    "abstract": "Mutual Information (MI) and Conditional Mutual Information (CMI) are\nmulti-purpose tools from information theory that are able to naturally measure\nthe statistical dependencies between random variables, thus they are usually of\ncentral interest in several statistical and machine learning tasks, such as\nconditional independence testing and representation learning. However,\nestimating CMI, or even MI, is infamously challenging due the intractable\nformulation. In this study, we introduce DINE (Diffeomorphic Information Neural\nEstimator)-a novel approach for estimating CMI of continuous random variables,\ninspired by the invariance of CMI over diffeomorphic maps. We show that the\nvariables of interest can be replaced with appropriate surrogates that follow\nsimpler distributions, allowing the CMI to be efficiently evaluated via\nanalytical solutions. Additionally, we demonstrate the quality of the proposed\nestimator in comparison with state-of-the-arts in three important tasks,\nincluding estimating MI, CMI, as well as its application in conditional\nindependence testing. The empirical evaluations show that DINE consistently\noutperforms competitors in all tasks and is able to adapt very well to complex\nand high-dimensional relationships.",
    "descriptor": "\nComments: Accepted at the Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI 2023)\n",
    "authors": [
      "Bao Duong",
      "Thin Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.10856"
  },
  {
    "id": "arXiv:2211.10857",
    "title": "Restarted Nonnegativity Preserving Tensor Splitting Methods via Relaxed  Anderson Acceleration for Solving Multi-linear Systems",
    "abstract": "Multilinear systems play an important role in scientific calculations of\npractical problems. In this paper, we consider a tensor splitting method with a\nrelaxed Anderson acceleration for solving multilinear systems. The new method\npreserves nonnegativity for every iterative step and improves the existing\nones. Furthermore, the convergence analysis of the proposed method is given.\nThe new algorithm performs effectively for numerical experiments.",
    "descriptor": "",
    "authors": [
      "Dongdong Liu",
      "Xifu Liu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.10857"
  },
  {
    "id": "arXiv:2211.10858",
    "title": "An interpretable imbalanced semi-supervised deep learning framework for  improving differential diagnosis of skin diseases",
    "abstract": "Dermatological diseases are among the most common disorders worldwide. This\npaper presents the first study of the interpretability and imbalanced\nsemi-supervised learning of the multiclass intelligent skin diagnosis framework\n(ISDL) using 58,457 skin images with 10,857 unlabeled samples. Pseudo-labelled\nsamples from minority classes have a higher probability at each iteration of\nclass-rebalancing self-training, thereby promoting the utilization of unlabeled\nsamples to solve the class imbalance problem. Our ISDL achieved a promising\nperformance with an accuracy of 0.979, sensitivity of 0.975, specificity of\n0.973, macro-F1 score of 0.974 and area under the receiver operating\ncharacteristic curve (AUC) of 0.999 for multi-label skin disease\nclassification. The Shapley Additive explanation (SHAP) method is combined with\nour ISDL to explain how the deep learning model makes predictions. This finding\nis consistent with the clinical diagnosis. We also proposed a sampling\ndistribution optimisation strategy to select pseudo-labelled samples in a more\neffective manner using ISDLplus. Furthermore, it has the potential to relieve\nthe pressure placed on professional doctors, as well as help with practical\nissues associated with a shortage of such doctors in rural areas.",
    "descriptor": "",
    "authors": [
      "Futian Weng",
      "Yan Xu",
      "Yuanting Ma",
      "Jinghan Sun",
      "Shijun Shan",
      "Qiyuan Li",
      "Jianping Zhu",
      "Yang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10858"
  },
  {
    "id": "arXiv:2211.10859",
    "title": "A Blockchain Protocol for Human-in-the-Loop AI",
    "abstract": "Intelligent human inputs are required both in the training and operation of\nAI systems, and within the governance of blockchain systems and decentralized\nautonomous organizations (DAOs). This paper presents a formal definition of\nHuman Intelligence Primitives (HIPs), and describes the design and\nimplementation of an Ethereum protocol for their on-chain collection, modeling,\nand integration in machine learning workflows.",
    "descriptor": "\nComments: Trustworthy and Socially Responsible Machine Learning (TSRML) co-located with NeurIPS 2022\n",
    "authors": [
      "Nassim Dehouche",
      "Richard Blythman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.10859"
  },
  {
    "id": "arXiv:2211.10861",
    "title": "Efficient Meta Reinforcement Learning for Preference-based Fast  Adaptation",
    "abstract": "Learning new task-specific skills from a few trials is a fundamental\nchallenge for artificial intelligence. Meta reinforcement learning (meta-RL)\ntackles this problem by learning transferable policies that support few-shot\nadaptation to unseen tasks. Despite recent advances in meta-RL, most existing\nmethods require the access to the environmental reward function of new tasks to\ninfer the task objective, which is not realistic in many practical\napplications. To bridge this gap, we study the problem of few-shot adaptation\nin the context of human-in-the-loop reinforcement learning. We develop a\nmeta-RL algorithm that enables fast policy adaptation with preference-based\nfeedback. The agent can adapt to new tasks by querying human's preference\nbetween behavior trajectories instead of using per-step numeric rewards. By\nextending techniques from information theory, our approach can design query\nsequences to maximize the information gain from human interactions while\ntolerating the inherent error of non-expert human oracle. In experiments, we\nextensively evaluate our method, Adaptation with Noisy OracLE (ANOLE), on a\nvariety of meta-RL benchmark tasks and demonstrate substantial improvement over\nbaseline algorithms in terms of both feedback efficiency and error tolerance.",
    "descriptor": "\nComments: Thirty-sixth Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Zhizhou Ren",
      "Anji Liu",
      "Yitao Liang",
      "Jian Peng",
      "Jianzhu Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10861"
  },
  {
    "id": "arXiv:2211.10865",
    "title": "IC3D: Image-Conditioned 3D Diffusion for Shape Generation",
    "abstract": "In the last years, Denoising Diffusion Probabilistic Models (DDPMs) obtained\nstate-of-the-art results in many generative tasks, outperforming GANs and other\nclasses of generative models. In particular, they reached impressive results in\nvarious image generation sub-tasks, among which conditional generation tasks\nsuch as text-guided image synthesis. Given the success of DDPMs in 2D\ngeneration, they have more recently been applied to 3D shape generation,\noutperforming previous approaches and reaching state-of-the-art results.\nHowever, 3D data pose additional challenges, such as the choice of the 3D\nrepresentation, which impacts design choices and model efficiency. While\nreaching state-of-the-art results in generation quality, existing 3D DDPM works\nmake little or no use of guidance, mainly being unconditional or\nclass-conditional. In this paper, we present IC3D, the first Image-Conditioned\n3D Diffusion model that generates 3D shapes by image guidance. It is also the\nfirst 3D DDPM model that adopts voxels as a 3D representation. To guide our\nDDPM, we present and leverage CISP (Contrastive Image-Shape Pre-training), a\nmodel jointly embedding images and shapes by contrastive pre-training, inspired\nby text-to-image DDPM works. Our generative diffusion model outperforms the\nstate-of-the-art in 3D generation quality and diversity. Furthermore, we show\nthat our generated shapes are preferred by human evaluators to a SoTA\nsingle-view 3D reconstruction model in terms of quality and coherence to the\nquery image by running a side-by-side human evaluation.",
    "descriptor": "",
    "authors": [
      "Cristian Sbrolli",
      "Paolo Cudrano",
      "Matteo Frosi",
      "Matteo Matteucci"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10865"
  },
  {
    "id": "arXiv:2211.10866",
    "title": "Estimating Task Completion Times for Network Rollouts using Statistical  Models within Partitioning-based Regression Methods",
    "abstract": "This paper proposes a data and Machine Learning-based forecasting solution\nfor the Telecommunications network-rollout planning problem. Milestone\ncompletion-time estimation is crucial to network-rollout planning; accurate\nestimates enable better crew utilisation and optimised cost of materials and\nlogistics. Using historical data of milestone completion times, a model needs\nto incorporate domain knowledge, handle noise and yet be interpretable to\nproject managers. This paper proposes partition-based regression models that\nincorporate data-driven statistical models within each partition, as a solution\nto the problem. Benchmarking experiments demonstrate that the proposed approach\nobtains competitive to better performance, at a small fraction of the model\ncomplexity of the best alternative approach based on Gradient Boosting.\nExperiments also demonstrate that the proposed approach is effective for both\nshort and long-range forecasts. The proposed idea is applicable in any context\nrequiring time-series regression with noisy and attributed data.",
    "descriptor": "",
    "authors": [
      "Venkatachalam Natchiappan",
      "Shrihari Vasudevan",
      "Thalanayar Muthukumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.10866"
  },
  {
    "id": "arXiv:2211.10867",
    "title": "Constraining Multi-scale Pairwise Features between Encoder and Decoder  Using Contrastive Learning for Unpaired Image-to-Image Translation",
    "abstract": "Contrastive learning (CL) has shown great potential in image-to-image\ntranslation (I2I). Current CL-based I2I methods usually re-exploit the encoder\nof the generator to maximize the mutual information between the input and\ngenerated images, which does not exert an active effect on the decoder part. In\naddition, though negative samples play a crucial role in CL, most existing\nmethods adopt a random sampling strategy, which may be less effective. In this\npaper, we rethink the CL paradigm in the unpaired I2I tasks from two\nperspectives and propose a new one-sided image translation framework called\nEnCo. First, we present an explicit constraint on the multi-scale pairwise\nfeatures between the encoder and decoder of the generator to guarantee the\nsemantic consistency of the input and generated images. Second, we propose a\ndiscriminative attention-guided negative sampling strategy to replace the\nrandom negative sampling, which significantly improves the performance of the\ngenerative model with an almost negligible computational overhead. Compared\nwith existing methods, EnCo acts more effective and efficient. Extensive\nexperiments on several popular I2I datasets demonstrate the effectiveness and\nadvantages of our proposed approach, and we achieve several state-of-the-art\ncompared to previous methods.",
    "descriptor": "\nComments: 16 pages, 10 figures\n",
    "authors": [
      "Xiuding Cai",
      "Yaoyao Zhu",
      "Dong Miao",
      "Linjie Fu",
      "Yu Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10867"
  },
  {
    "id": "arXiv:2211.10869",
    "title": "UniMASK: Unified Inference in Sequential Decision Problems",
    "abstract": "Randomly masking and predicting word tokens has been a successful approach in\npre-training language models for a variety of downstream tasks. In this work,\nwe observe that the same idea also applies naturally to sequential\ndecision-making, where many well-studied tasks like behavior cloning, offline\nreinforcement learning, inverse dynamics, and waypoint conditioning correspond\nto different sequence maskings over a sequence of states, actions, and returns.\nWe introduce the UniMASK framework, which provides a unified way to specify\nmodels which can be trained on many different sequential decision-making tasks.\nWe show that a single UniMASK model is often capable of carrying out many tasks\nwith performance similar to or better than single-task models. Additionally,\nafter fine-tuning, our UniMASK models consistently outperform comparable\nsingle-task models. Our code is publicly available at\nhttps://github.com/micahcarroll/uniMASK.",
    "descriptor": "\nComments: NeurIPS 2022 (Oral). A prior version was published at an ICML Workshop, available at arXiv:2204.13326\n",
    "authors": [
      "Micah Carroll",
      "Orr Paradise",
      "Jessy Lin",
      "Raluca Georgescu",
      "Mingfei Sun",
      "David Bignell",
      "Stephanie Milani",
      "Katja Hofmann",
      "Matthew Hausknecht",
      "Anca Dragan",
      "Sam Devlin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10869"
  },
  {
    "id": "arXiv:2211.10871",
    "title": "SafeLight: A Reinforcement Learning Method toward Collision-free Traffic  Signal Control",
    "abstract": "Traffic signal control is safety-critical for our daily life. Roughly\none-quarter of road accidents in the U.S. happen at intersections due to\nproblematic signal timing, urging the development of safety-oriented\nintersection control. However, existing studies on adaptive traffic signal\ncontrol using reinforcement learning technologies have focused mainly on\nminimizing traffic delay but neglecting the potential exposure to unsafe\nconditions. We, for the first time, incorporate road safety standards as\nenforcement to ensure the safety of existing reinforcement learning methods,\naiming toward operating intersections with zero collisions. We have proposed a\nsafety-enhanced residual reinforcement learning method (SafeLight) and employed\nmultiple optimization techniques, such as multi-objective loss function and\nreward shaping for better knowledge integration. Extensive experiments are\nconducted using both synthetic and real-world benchmark datasets. Results show\nthat our method can significantly reduce collisions while increasing traffic\nmobility.",
    "descriptor": "\nComments: Accepted by AAAI 2023, appendix included. 9 pages + 5 pages appendix, 12 figures, in Proceedings of the Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI'23), Feb 2023\n",
    "authors": [
      "Wenlu Du",
      "Junyi Ye",
      "Jingyi Gu",
      "Jing Li",
      "Hua Wei",
      "Guiling Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10871"
  },
  {
    "id": "arXiv:2211.10872",
    "title": "MetaMax: Improved Open-Set Deep Neural Networks via Weibull Calibration",
    "abstract": "Open-set recognition refers to the problem in which classes that were not\nseen during training appear at inference time. This requires the ability to\nidentify instances of novel classes while maintaining discriminative capability\nfor closed-set classification. OpenMax was the first deep neural network-based\napproach to address open-set recognition by calibrating the predictive scores\nof a standard closed-set classification network. In this paper we present\nMetaMax, a more effective post-processing technique that improves upon\ncontemporary methods by directly modeling class activation vectors. MetaMax\nremoves the need for computing class mean activation vectors (MAVs) and\ndistances between a query image and a class MAV as required in OpenMax.\nExperimental results show that MetaMax outperforms OpenMax and is comparable in\nperformance to other state-of-the-art approaches.",
    "descriptor": "\nComments: To be presented at the 2023 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) Workshop on Dealing with Novelty in Open Worlds (DNOW)\n",
    "authors": [
      "Zongyao Lyu",
      "Nolan B. Gutierrez",
      "William J. Beksi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10872"
  },
  {
    "id": "arXiv:2211.10873",
    "title": "Interpretable Scientific Discovery with Symbolic Regression: A Review",
    "abstract": "Symbolic regression is emerging as a promising machine learning method for\nlearning succinct underlying interpretable mathematical expressions directly\nfrom data. Whereas it has been traditionally tackled with genetic programming,\nit has recently gained a growing interest in deep learning as a data-driven\nmodel discovery method, achieving significant advances in various application\ndomains ranging from fundamental to applied sciences. This survey presents a\nstructured and comprehensive overview of symbolic regression methods and\ndiscusses their strengths and limitations.",
    "descriptor": "",
    "authors": [
      "Nour Makke",
      "Sanjay Chawla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "High Energy Physics - Phenomenology (hep-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.10873"
  },
  {
    "id": "arXiv:2211.10877",
    "title": "Artificial Interrogation for Attributing Language Models",
    "abstract": "This paper presents solutions to the Machine Learning Model Attribution\nchallenge (MLMAC) collectively organized by MITRE, Microsoft, Schmidt-Futures,\nRobust-Intelligence, Lincoln-Network, and Huggingface community. The challenge\nprovides twelve open-sourced base versions of popular language models developed\nby well-known organizations and twelve fine-tuned language models for text\ngeneration. The names and architecture details of fine-tuned models were kept\nhidden, and participants can access these models only through the rest APIs\ndeveloped by the organizers. Given these constraints, the goal of the contest\nis to identify which fine-tuned models originated from which base model. To\nsolve this challenge, we have assumed that fine-tuned models and their\ncorresponding base versions must share a similar vocabulary set with a matching\nsyntactical writing style that resonates in their generated outputs. Our\nstrategy is to develop a set of queries to interrogate base and fine-tuned\nmodels. And then perform one-to-many pairing between them based on similarities\nin their generated responses, where more than one fine-tuned model can pair\nwith a base model but not vice-versa. We have employed four distinct approaches\nfor measuring the resemblance between the responses generated from the models\nof both sets. The first approach uses evaluation metrics of the machine\ntranslation, and the second uses a vector space model. The third approach uses\nstate-of-the-art multi-class text classification, Transformer models. Lastly,\nthe fourth approach uses a set of Transformer based binary text classifiers,\none for each provided base model, to perform multi-class text classification in\na one-vs-all fashion. This paper reports implementation details, comparison,\nand experimental studies, of these approaches along with the final obtained\nresults.",
    "descriptor": "",
    "authors": [
      "Farhan Dhanani",
      "Muhammad Rafi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10877"
  },
  {
    "id": "arXiv:2211.10878",
    "title": "DYNAFED: Tackling Client Data Heterogeneity with Global Dynamics",
    "abstract": "The Federated Learning (FL) paradigm is known to face challenges under\nheterogeneous client data. Local training on non-iid distributed data results\nin deflected local optimum, which causes the client models drift further away\nfrom each other and degrades the aggregated global model's performance. A\nnatural solution is to gather all client data onto the server, such that the\nserver has a global view of the entire data distribution. Unfortunately, this\nreduces to regular training, which compromises clients' privacy and conflicts\nwith the purpose of FL. In this paper, we put forth an idea to collect and\nleverage global knowledge on the server without hindering data privacy. We\nunearth such knowledge from the dynamics of the global model's trajectory.\nSpecifically, we first reserve a short trajectory of global model snapshots on\nthe server. Then, we synthesize a small pseudo dataset such that the model\ntrained on it mimics the dynamics of the reserved global model trajectory.\nAfterward, the synthesized data is used to help aggregate the deflected clients\ninto the global model. We name our method Dynafed, which enjoys the following\nadvantages: 1) we do not rely on any external on-server dataset, which requires\nno additional cost for data collection; 2) the pseudo data can be synthesized\nin early communication rounds, which enables Dynafed to take effect early for\nboosting the convergence and stabilizing training; 3) the pseudo data only\nneeds to be synthesized once and can be directly utilized on the server to help\naggregation in subsequent rounds. Experiments across extensive benchmarks are\nconducted to showcase the effectiveness of Dynafed. We also provide insights\nand understanding of the underlying mechanism of our method.",
    "descriptor": "",
    "authors": [
      "Renjie Pi",
      "Weizhong Zhang",
      "Yueqi Xie",
      "Jiahui Gao",
      "Xiaoyu Wang",
      "Sunghun Kim",
      "Qifeng Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10878"
  },
  {
    "id": "arXiv:2211.10879",
    "title": "Bode Integral Limitation For Irrational Systems",
    "abstract": "Bode integrals of sensitivity and sensitivity-like functions along with\ncomplementary sensitivity and complementary sensitivity-like functions are\nconventionally used for describing performance limitations of a feedback\ncontrol system. In this paper, we investigate the Bode integral and evaluate\nwhat happens when a fractional order Proportional-Integral-Derivative (PID)\ncontroller is used in a feedback control system. We extend our analysis to when\nfractal PID controllers are applied to irrational systems. We split this into\ntwo cases: when the sequence of infinitely many right half plane open-loop\npoles doesn't have any limit points and when it does have a limit point. In\nboth cases, we prove that the structure of the Bode Integral is similar to the\nclassical version under certain conditions of convergence. We also provide a\nsufficient condition for the controller to lower the Bode sensitivity integral.",
    "descriptor": "\nComments: 13 pages, 7 figures\n",
    "authors": [
      "William Chang",
      "Fariba Ariaei",
      "Edmond Jonckheere"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.10879"
  },
  {
    "id": "arXiv:2211.10880",
    "title": "PartCom: Part Composition Learning for 3D Open-Set Recognition",
    "abstract": "3D recognition is the foundation of 3D deep learning in many emerging fields,\nsuch as autonomous driving and robotics.Existing 3D methods mainly focus on the\nrecognition of a fixed set of known classes and neglect possible unknown\nclasses during testing. These unknown classes may cause serious accidents in\nsafety-critical applications, i.e. autonomous driving. In this work, we make a\nfirst attempt to address 3D open-set recognition (OSR) so that a classifier can\nrecognize known classes as well as be aware of unknown classes. We analyze\nopen-set risks in the 3D domain and point out the overconfidence and\nunder-representation problems that make existing methods perform poorly on the\n3D OSR task. To resolve above problems, we propose a novel part prototype-based\nOSR method named PartCom. We use part prototypes to represent a 3D shape as a\npart composition, since a part composition can represent the overall structure\nof a shape and can help distinguish different known classes and unknown ones.\nThen we formulate two constraints on part prototypes to ensure their\neffectiveness. To reduce open-set risks further, we devise a PUFS module to\nsynthesize unknown features as representatives of unknown samples by mixing up\npart composite features of different classes. We conduct experiments on three\nkinds of 3D OSR tasks based on both CAD shape dataset and scan shape dataset.\nExtensive experiments show that our method is powerful in classifying known\nclasses and unknown ones and can attain much better results than SOTA baselines\non all 3D OSR tasks. The project will be released.",
    "descriptor": "",
    "authors": [
      "Weng Tingyu",
      "Xiao Jun",
      "Jiang Haiyong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10880"
  },
  {
    "id": "arXiv:2211.10881",
    "title": "Deepfake Detection: A Comprehensive Study from the Reliability  Perspective",
    "abstract": "The mushroomed Deepfake synthetic materials circulated on the internet have\nraised serious social impact to politicians, celebrities, and every human being\non earth. In this paper, we provide a thorough review of the existing models\nfollowing the development history of the Deepfake detection studies and define\nthe research challenges of Deepfake detection in three aspects, namely,\ntransferability, interpretability, and reliability. While the transferability\nand interpretability challenges have both been frequently discussed and\nattempted to solve with quantitative evaluations, the reliability issue has\nbeen barely considered, leading to the lack of reliable evidence in real-life\nusages and even for prosecutions on Deepfake related cases in court. We\ntherefore conduct a model reliability study scheme using statistical random\nsampling knowledge and the publicly available benchmark datasets to\nqualitatively validate the detection performance of the existing models on\narbitrary Deepfake candidate suspects. A barely remarked systematic data\npre-processing procedure is demonstrated along with the fair training and\ntesting experiments on the existing detection models. Case studies are further\nexecuted to justify the real-life Deepfake cases including different groups of\nvictims with the help of reliably qualified detection models. The model\nreliability study provides a workflow for the detection models to act as or\nassist evidence for Deepfake forensic investigation in court once approved by\nauthentication experts or institutions.",
    "descriptor": "\nComments: 20 pages for peer review\n",
    "authors": [
      "Tianyi Wang",
      "Kam Pui Chow",
      "Xiaojun Chang",
      "Yinglong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.10881"
  },
  {
    "id": "arXiv:2211.10882",
    "title": "On Multi-head Ensemble of Smoothed Classifiers for Certified Robustness",
    "abstract": "Randomized Smoothing (RS) is a promising technique for certified robustness,\nand recently in RS the ensemble of multiple deep neural networks (DNNs) has\nshown state-of-the-art performances. However, such an ensemble brings heavy\ncomputation burdens in both training and certification, and yet under-exploits\nindividual DNNs and their mutual effects, as the communication between these\nclassifiers is commonly ignored in optimization. In this work, starting from a\nsingle DNN, we augment the network with multiple heads, each of which pertains\na classifier for the ensemble. A novel training strategy, namely Self-PAced\nCircular-TEaching (SPACTE), is proposed accordingly. SPACTE enables a circular\ncommunication flow among those augmented heads, i.e., each head teaches its\nneighbor with the self-paced learning using smoothed losses, which are\nspecifically designed in relation to certified robustness. The deployed\nmulti-head structure and the circular-teaching scheme of SPACTE jointly\ncontribute to diversify and enhance the classifiers in augmented heads for\nensemble, leading to even stronger certified robustness than ensembling\nmultiple DNNs (effectiveness) at the cost of much less computational expenses\n(efficiency), verified by extensive experiments and discussions.",
    "descriptor": "",
    "authors": [
      "Kun Fang",
      "Qinghua Tao",
      "Yingwen Wu",
      "Tao Li",
      "Xiaolin Huang",
      "Jie Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10882"
  },
  {
    "id": "arXiv:2211.10883",
    "title": "Audio-visual video face hallucination with frequency supervision and  cross modality support by speech based lip reading loss",
    "abstract": "Recently, there has been numerous breakthroughs in face hallucination tasks.\nHowever, the task remains rather challenging in videos in comparison to the\nimages due to inherent consistency issues. The presence of extra temporal\ndimension in video face hallucination makes it non-trivial to learn the facial\nmotion through out the sequence. In order to learn these fine spatio-temporal\nmotion details, we propose a novel cross-modal audio-visual Video Face\nHallucination Generative Adversarial Network (VFH-GAN). The architecture\nexploits the semantic correlation of between the movement of the facial\nstructure and the associated speech signal. Another major issue in present\nvideo based approaches is the presence of blurriness around the key facial\nregions such as mouth and lips - where spatial displacement is much higher in\ncomparison to other areas. The proposed approach explicitly defines a lip\nreading loss to learn the fine grain motion in these facial areas. During\ntraining, GANs have potential to fit frequencies from low to high, which leads\nto miss the hard to synthesize frequencies. Therefore, to add salient frequency\nfeatures to the network we add a frequency based loss function. The visual and\nthe quantitative comparison with state-of-the-art shows a significant\nimprovement in performance and efficacy.",
    "descriptor": "",
    "authors": [
      "Shailza Sharma",
      "Abhinav Dhall",
      "Vinay Kumar",
      "Vivek Singh Bawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10883"
  },
  {
    "id": "arXiv:2211.10885",
    "title": "Contrastive Regularization for Multimodal Emotion Recognition Using  Audio and Text",
    "abstract": "Speech emotion recognition is a challenge and an important step towards more\nnatural human-computer interaction (HCI). The popular approach is multimodal\nemotion recognition based on model-level fusion, which means that the\nmultimodal signals can be encoded to acquire embeddings, and then the\nembeddings are concatenated together for the final classification. However, due\nto the influence of noise or other factors, each modality does not always tend\nto the same emotional category, which affects the generalization of a model. In\nthis paper, we propose a novel regularization method via contrastive learning\nfor multimodal emotion recognition using audio and text. By introducing a\ndiscriminator to distinguish the difference between the same and different\nemotional pairs, we explicitly restrict the latent code of each modality to\ncontain the same emotional information, so as to reduce the noise interference\nand get more discriminative representation. Experiments are performed on the\nstandard IEMOCAP dataset for 4-class emotion recognition. The results show a\nsignificant improvement of 1.44\\% and 1.53\\% in terms of weighted accuracy (WA)\nand unweighted accuracy (UA) compared to the baseline system.",
    "descriptor": "\nComments: Completed in October 2020 and submitted to ICASSP2021\n",
    "authors": [
      "Fan Qian",
      "Jiqing Han"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.10885"
  },
  {
    "id": "arXiv:2211.10887",
    "title": "Differential Privacy from Locally Adjustable Graph Algorithms: $k$-Core  Decomposition, Low Out-Degree Ordering, and Densest Subgraphs",
    "abstract": "Differentially private algorithms allow large-scale data analytics while\npreserving user privacy. Designing such algorithms for graph data is gaining\nimportance with the growth of large networks that model various (sensitive)\nrelationships between individuals. While there exists a rich history of\nimportant literature in this space, to the best of our knowledge, no results\nformalize a relationship between certain parallel and distributed graph\nalgorithms and differentially private graph analysis. In this paper, we define\n\\emph{locally adjustable} graph algorithms and show that algorithms of this\ntype can be transformed into differentially private algorithms.\nOur formalization is motivated by a set of results that we present in the\ncentral and local models of differential privacy for a number of problems,\nincluding $k$-core decomposition, low out-degree ordering, and densest\nsubgraphs. First, we design an $\\varepsilon$-edge differentially private (DP)\nalgorithm that returns a subset of nodes that induce a subgraph of density at\nleast $\\frac{D^*}{1+\\eta} - O\\left(\\text{poly}(\\log n)/\\varepsilon\\right),$\nwhere $D^*$ is the density of the densest subgraph in the input graph (for any\nconstant $\\eta > 0$). This algorithm achieves a two-fold improvement on the\nmultiplicative approximation factor of the previously best-known private\ndensest subgraph algorithms while maintaining a near-linear runtime.\nThen, we present an $\\varepsilon$-locally edge differentially private (LEDP)\nalgorithm for $k$-core decompositions. Our LEDP algorithm provides approximates\nthe core numbers (for any constant $\\eta > 0$) with $(2+\\eta)$ multiplicative\nand $O\\left(\\text{poly}\\left(\\log n\\right)/\\varepsilon\\right)$ additive error.\nThis is the first differentially private algorithm that outputs private\n$k$-core decomposition statistics.",
    "descriptor": "",
    "authors": [
      "Laxman Dhulipala",
      "Quanquan C. Liu",
      "Sofya Raskhodnikova",
      "Jessica Shi",
      "Julian Shun",
      "Shangdi Yu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.10887"
  },
  {
    "id": "arXiv:2211.10888",
    "title": "Adaptive Edge-to-Edge Interaction Learning for Point Cloud Analysis",
    "abstract": "Recent years have witnessed the great success of deep learning on various\npoint cloud analysis tasks, e.g., classification and semantic segmentation.\nSince point cloud data is sparse and irregularly distributed, one key issue for\npoint cloud data processing is extracting useful information from local\nregions. To achieve this, previous works mainly extract the points' features\nfrom local regions by learning the relation between each pair of adjacent\npoints. However, these works ignore the relation between edges in local\nregions, which encodes the local shape information. Associating the\nneighbouring edges could potentially make the point-to-point relation more\naware of the local structure and more robust. To explore the role of the\nrelation between edges, this paper proposes a novel Adaptive Edge-to-Edge\nInteraction Learning module, which aims to enhance the point-to-point relation\nthrough modelling the edge-to-edge interaction in the local region adaptively.\nWe further extend the module to a symmetric version to capture the local\nstructure more thoroughly. Taking advantage of the proposed modules, we develop\ntwo networks for segmentation and shape classification tasks, respectively.\nVarious experiments on several public point cloud datasets demonstrate the\neffectiveness of our method for point cloud analysis.",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Shanshan Zhao",
      "Mingming Gong",
      "Xi Li",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10888"
  },
  {
    "id": "arXiv:2211.10889",
    "title": "Metadata Caching in Presto: Towards Fast Data Processing",
    "abstract": "Presto is an open-source distributed SQL query engine for OLAP, aiming for\n\"SQL on everything\". Since open-sourced in 2013, Presto has been consistently\ngaining popularity in large-scale data analytics and attracting adoption from a\nwide range of enterprises. From the development and operation of Presto, we\nwitnessed a significant amount of CPU consumption on parsing column-oriented\ndata files in Presto worker nodes. This blocks some companies, including Meta,\nfrom increasing analytical data volumes.\nIn this paper, we present a metadata caching layer, built on top of the\nAlluxio SDK cache and incorporated in each Presto worker node, to cache the\nintermediate results in file parsing. The metadata cache provides two caching\nmethods: caching the decompressed metadata bytes from raw data files and\ncaching the deserialized metadata objects. Our evaluation of the TPC-DS\nbenchmark on Presto demonstrates that when the cache is warm, the first method\ncan reduce the query's CPU consumption by 10%-20%, whereas the second method\ncan minimize the CPU usage by 20%-40%.",
    "descriptor": "\nComments: 5 pages, 8 figures\n",
    "authors": [
      "Beinan Wang",
      "Chunxu Tang",
      "Rongrong Zhong",
      "Bin Fan",
      "Yi Wang",
      "Jasmine Wang",
      "Shouwei Chen",
      "Bowen Ding",
      "Lu Zhang"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.10889"
  },
  {
    "id": "arXiv:2211.10890",
    "title": "Can Single-Pass Contrastive Learning Work for Both Homophilic and  Heterophilic Graph?",
    "abstract": "Existing graph contrastive learning (GCL) typically requires two forward pass\nfor a single instance to construct the contrastive loss. Despite its remarkable\nsuccess, it is unclear whether such a dual-pass design is (theoretically)\nnecessary. Besides, the empirical results are hitherto limited to the\nhomophilic graph benchmarks. Then a natural question arises: Can we design a\nmethod that works for both homophilic and heterophilic graphs with a\nperformance guarantee? To answer this, we analyze the concentration property of\nfeatures obtained by neighborhood aggregation on both homophilic and\nheterophilic graphs, introduce the single-pass graph contrastive learning loss\nbased on the property, and provide performance guarantees of the minimizer of\nthe loss on downstream tasks. As a direct consequence of our analysis, we\nimplement the Single-Pass Graph Contrastive Learning method (SP-GCL).\nEmpirically, on 14 benchmark datasets with varying degrees of heterophily, the\nfeatures learned by the SP-GCL can match or outperform existing strong\nbaselines with significantly less computational overhead, which verifies the\nusefulness of our findings in real-world cases.",
    "descriptor": "\nComments: 20 pages, 6 figures, 9 tables. arXiv admin note: substantial text overlap with arXiv:2204.04874\n",
    "authors": [
      "Haonan Wang",
      "Jieyu Zhang",
      "Qi Zhu",
      "Wei Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.10890"
  },
  {
    "id": "arXiv:2211.10892",
    "title": "Are Out-of-Distribution Detection Methods Reliable?",
    "abstract": "This paper establishes a novel evaluation framework for assessing the\nperformance of out-of-distribution (OOD) detection in realistic settings. Our\ngoal is to expose the shortcomings of existing OOD detection benchmarks and\nencourage a necessary research direction shift toward satisfying the\nrequirements of real-world applications. We expand OOD detection research by\nintroducing new OOD test datasets CIFAR-10-R, CIFAR-100-R, and MVTec-R, which\nallow researchers to benchmark OOD detection performance under realistic\ndistribution shifts. We also introduce a generalizability score to measure a\nmethod's ability to generalize from standard OOD detection test datasets to a\nrealistic setting. Contrary to existing OOD detection research, we demonstrate\nthat further performance improvements on standard benchmark datasets do not\nincrease the usability of such models in the real world. State-of-the-art\n(SOTA) methods tested on our realistic distributionally-shifted datasets drop\nin performance for up to 45%. This setting is critical for evaluating the\nreliability of OOD models before they are deployed in real-world environments.",
    "descriptor": "",
    "authors": [
      "Vahid Reza Khazaie",
      "Anthony Wong",
      "Mohammad Sabokrou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10892"
  },
  {
    "id": "arXiv:2211.10894",
    "title": "TuRaN: True Random Number Generation Using Supply Voltage Underscaling  in SRAMs",
    "abstract": "Prior works propose SRAM-based TRNGs that extract entropy from SRAM arrays.\nSRAM arrays are widely used in a majority of specialized or general-purpose\nchips that perform the computation to store data inside the chip. Thus,\nSRAM-based TRNGs present a low-cost alternative to dedicated hardware TRNGs.\nHowever, existing SRAM-based TRNGs suffer from 1) low TRNG throughput, 2) high\nenergy consumption, 3) high TRNG latency, and 4) the inability to generate true\nrandom numbers continuously, which limits the application space of SRAM-based\nTRNGs. Our goal in this paper is to design an SRAM-based TRNG that overcomes\nthese four key limitations and thus, extends the application space of\nSRAM-based TRNGs. To this end, we propose TuRaN, a new high-throughput,\nenergy-efficient, and low-latency SRAM-based TRNG that can sustain continuous\noperation. TuRaN leverages the key observation that accessing SRAM cells\nresults in random access failures when the supply voltage is reduced below the\nmanufacturer-recommended supply voltage. TuRaN generates random numbers at high\nthroughput by repeatedly accessing SRAM cells with reduced supply voltage and\npost-processing the resulting random faults using the SHA-256 hash function. To\ndemonstrate the feasibility of TuRaN, we conduct SPICE simulations on different\nprocess nodes and analyze the potential of access failure for use as an entropy\nsource. We verify and support our simulation results by conducting real-world\nexperiments on two commercial off-the-shelf FPGA boards. We evaluate the\nquality of the random numbers generated by TuRaN using the widely-adopted NIST\nstandard randomness tests and observe that TuRaN passes all tests. TuRaN\ngenerates true random numbers with (i) an average (maximum) throughput of\n1.6Gbps (1.812Gbps), (ii) 0.11nJ/bit energy consumption, and (iii) 278.46us\nlatency.",
    "descriptor": "",
    "authors": [
      "\u0130smail Emir Y\u00fcksel",
      "Ataberk Olgun",
      "Behzad Salami",
      "F. Nisa Bostanc\u0131",
      "Yahya Can Tu\u011frul",
      "A. Giray Ya\u011fl\u0131k\u00e7\u0131",
      "Nika Mansouri Ghiasi",
      "Onur Mutlu",
      "O\u011fuz Ergin"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.10894"
  },
  {
    "id": "arXiv:2211.10896",
    "title": "Spectral Adversarial Training for Robust Graph Neural Network",
    "abstract": "Recent studies demonstrate that Graph Neural Networks (GNNs) are vulnerable\nto slight but adversarially designed perturbations, known as adversarial\nexamples. To address this issue, robust training methods against adversarial\nexamples have received considerable attention in the literature.\n\\emph{Adversarial Training (AT)} is a successful approach to learning a robust\nmodel using adversarially perturbed training samples. Existing AT methods on\nGNNs typically construct adversarial perturbations in terms of graph structures\nor node features. However, they are less effective and fraught with challenges\non graph data due to the discreteness of graph structure and the relationships\nbetween connected examples. In this work, we seek to address these challenges\nand propose Spectral Adversarial Training (SAT), a simple yet effective\nadversarial training approach for GNNs. SAT first adopts a low-rank\napproximation of the graph structure based on spectral decomposition, and then\nconstructs adversarial perturbations in the spectral domain rather than\ndirectly manipulating the original graph structure. To investigate its\neffectiveness, we employ SAT on three widely used GNNs. Experimental results on\nfour public graph datasets demonstrate that SAT significantly improves the\nrobustness of GNNs against adversarial attacks without sacrificing\nclassification accuracy and training efficiency.",
    "descriptor": "\nComments: Accepted by TKDE. Code availiable at this https URL\n",
    "authors": [
      "Jintang Li",
      "Jiaying Peng",
      "Liang Chen",
      "Zibin Zheng",
      "Tingting Liang",
      "Qing Ling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10896"
  },
  {
    "id": "arXiv:2211.10897",
    "title": "Best-Effort Communication Improves Performance and Scales Robustly on  Conventional Hardware",
    "abstract": "Here, we test the performance and scalability of fully-asynchronous,\nbest-effort communication on existing, commercially-available HPC hardware.\nA first set of experiments tested whether best-effort communication\nstrategies can benefit performance compared to the traditional perfect\ncommunication model. At high CPU counts, best-effort communication improved\nboth the number of computational steps executed per unit time and the solution\nquality achieved within a fixed-duration run window.\nUnder the best-effort model, characterizing the distribution of quality of\nservice across processing components and over time is critical to understanding\nthe actual computation being performed. Additionally, a complete picture of\nscalability under the best-effort model requires analysis of how such quality\nof service fares at scale. To answer these questions, we designed and measured\na suite of quality of service metrics: simulation update period, message\nlatency, message delivery failure rate, and message delivery coagulation. Under\na lower communication-intensivity benchmark parameterization, we found that\nmedian values for all quality of service metrics were stable when scaling from\n64 to 256 process. Under maximal communication intensivity, we found only minor\n-- and, in most cases, nil -- degradation in median quality of service.\nIn an additional set of experiments, we tested the effect of an apparently\nfaulty compute node on performance and quality of service. Despite extreme\nquality of service degradation among that node and its clique, median\nperformance and quality of service remained stable.",
    "descriptor": "",
    "authors": [
      "Matthew Andres Moreno",
      "Charles Ofria"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.10897"
  },
  {
    "id": "arXiv:2211.10901",
    "title": "A Universal Framework of Superimposed RIS-Phase Modulation for MISO  Communication",
    "abstract": "To fully exploit the additional dimension brought by reconfigurable\nintelligent surface (RIS), it is recently suggested by information theory that\nmodulating information upon RIS phases is able to send extra information with\nincreased communication rate. In this paper, we propose a novel superimposed\nRIS-phase modulation (SRPM) scheme to transfer extra messages by superimposing\ninformation-bearing phase offsets to conventionally optimized RIS phases. The\nproposed SRPM is interpreted as a universal framework for RIS phase modulation.\nTheoretical union bound of the average bit error rate (ABER) of the proposed\nSRPM is also derived with the maximum likelihood (ML) detection. The diversity\norder is characterized as 0.5 for all parameter settings, which is useful for\ndetermining the optimal choice of the phase modulation parameters. Furthermore,\nwe discover that doubling the number of either RIS reflecting elements or the\ntransmit antennas is equivalent to a 3 dB increment in the transmit power for\nSRPM. Numerical results demonstrate the effectiveness of SRPM and reveal that\nit achieves reliable communication of more bits than existing schemes.",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Vehicular Technology\n",
    "authors": [
      "Jiacheng Yao",
      "Jindan Xu",
      "Wei Xu",
      "Chau Yuen",
      "Xiaohu You"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.10901"
  },
  {
    "id": "arXiv:2211.10902",
    "title": "Noisy Symbolic Abstractions for Deep RL: A case study with Reward  Machines",
    "abstract": "Natural and formal languages provide an effective mechanism for humans to\nspecify instructions and reward functions. We investigate how to generate\npolicies via RL when reward functions are specified in a symbolic language\ncaptured by Reward Machines, an increasingly popular automaton-inspired\nstructure. We are interested in the case where the mapping of environment state\nto a symbolic (here, Reward Machine) vocabulary -- commonly known as the\nlabelling function -- is uncertain from the perspective of the agent. We\nformulate the problem of policy learning in Reward Machines with noisy symbolic\nabstractions as a special class of POMDP optimization problem, and investigate\nseveral methods to address the problem, building on existing and new\ntechniques, the latter focused on predicting Reward Machine state, rather than\non grounding of individual symbols. We analyze these methods and evaluate them\nexperimentally under varying degrees of uncertainty in the correct\ninterpretation of the symbolic vocabulary. We verify the strength of our\napproach and the limitation of existing methods via an empirical investigation\non both illustrative, toy domains and partially observable, deep RL domains.",
    "descriptor": "\nComments: NeurIPS Deep Reinforcement Learning Workshop 2022\n",
    "authors": [
      "Andrew C. Li",
      "Zizhao Chen",
      "Pashootan Vaezipoor",
      "Toryn Q. Klassen",
      "Rodrigo Toro Icarte",
      "Sheila A. McIlraith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2211.10902"
  },
  {
    "id": "arXiv:2211.10904",
    "title": "Temporal Knowledge Graph Reasoning with Historical Contrastive Learning",
    "abstract": "Temporal knowledge graph, serving as an effective way to store and model\ndynamic relations, shows promising prospects in event forecasting. However,\nmost temporal knowledge graph reasoning methods are highly dependent on the\nrecurrence or periodicity of events, which brings challenges to inferring\nfuture events related to entities that lack historical interaction. In fact,\nthe current moment is often the combined effect of a small part of historical\ninformation and those unobserved underlying factors. To this end, we propose a\nnew event forecasting model called Contrastive Event Network (CENET), based on\na novel training framework of historical contrastive learning. CENET learns\nboth the historical and non-historical dependency to distinguish the most\npotential entities that can best match the given query. Simultaneously, it\ntrains representations of queries to investigate whether the current moment\ndepends more on historical or non-historical events by launching contrastive\nlearning. The representations further help train a binary classifier whose\noutput is a boolean mask to indicate related entities in the search space.\nDuring the inference process, CENET employs a mask-based strategy to generate\nthe final results. We evaluate our proposed model on five benchmark graphs. The\nresults demonstrate that CENET significantly outperforms all existing methods\nin most metrics, achieving at least $8.3\\%$ relative improvement of Hits@1 over\nprevious state-of-the-art baselines on event-based datasets.",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Yi Xu",
      "Junjie Ou",
      "Hui Xu",
      "Luoyi Fu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10904"
  },
  {
    "id": "arXiv:2211.10906",
    "title": "Learning from Long-Tailed Noisy Data with Sample Selection and Balanced  Loss",
    "abstract": "The success of deep learning depends on large-scale and well-curated training\ndata, while data in real-world applications are commonly long-tailed and noisy.\nMany methods have been proposed to deal with long-tailed data or noisy data,\nwhile a few methods are developed to tackle long-tailed noisy data. To solve\nthis, we propose a robust method for learning from long-tailed noisy data with\nsample selection and balanced loss. Specifically, we separate the noisy\ntraining data into clean labeled set and unlabeled set with sample selection,\nand train the deep neural network in a semi-supervised manner with a novel\nbalanced loss based on model bias. Experiments on benchmarks demonstrate that\nour method outperforms existing state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Lefan Zhang",
      "Zhang-Hao Tian",
      "Wei Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10906"
  },
  {
    "id": "arXiv:2211.10907",
    "title": "Quantifying the Individual Differences of Driver' Risk Perception with  Just Four Interpretable Parameters",
    "abstract": "There will be a long time when automated vehicles are mixed with human-driven\nvehicles. Understanding how drivers assess driving risks and modelling their\nindividual differences are significant for automated vehicles to develop\nhuman-like and customized behaviors, so as to gain people's trust and\nacceptance. However, the reality is that existing driving risk models are\ndeveloped at a statistical level, and no one scenario-universal driving risk\nmeasure can correctly describe risk perception differences among drivers. We\nproposed a concise yet effective model, called Potential Damage Risk (PODAR)\nmodel, which provides a universal and physically meaningful structure for\ndriving risk estimation and is suitable for general non-collision and collision\nscenes. In this paper, based on an open-accessed dataset collected from an\nobstacle avoidance experiment, four physical-interpretable parameters in PODAR,\nincluding prediction horizon, damage scale, temporal attenuation, and spatial\nattention, are calibrated and consequently individual risk perception models\nare established for each driver. The results prove the capacity and potential\nof PODAR to model individual differences in perceived driving risk, laying the\nfoundation for autonomous driving to develop human-like behaviors.",
    "descriptor": "\nComments: 14 pages, 9 figures, 1 table\n",
    "authors": [
      "Chen Chen",
      "Zhiqian Lan",
      "Guojian Zhan",
      "Yao Lyu",
      "Bingbing Nie",
      "Shengbo Eben Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.10907"
  },
  {
    "id": "arXiv:2211.10908",
    "title": "ESTAS: Effective and Stable Trojan Attacks in Self-supervised Encoders  with One Target Unlabelled Sample",
    "abstract": "Emerging self-supervised learning (SSL) has become a popular image\nrepresentation encoding method to obviate the reliance on labeled data and\nlearn rich representations from large-scale, ubiquitous unlabelled data. Then\none can train a downstream classifier on top of the pre-trained SSL image\nencoder with few or no labeled downstream data. Although extensive works show\nthat SSL has achieved remarkable and competitive performance on different\ndownstream tasks, its security concerns, e.g, Trojan attacks in SSL encoders,\nare still not well-studied. In this work, we present a novel Trojan Attack\nmethod, denoted by ESTAS, that can enable an effective and stable attack in SSL\nencoders with only one target unlabeled sample. In particular, we propose\nconsistent trigger poisoning and cascade optimization in ESTAS to improve\nattack efficacy and model accuracy, and eliminate the expensive target-class\ndata sample extraction from large-scale disordered unlabelled data. Our\nsubstantial experiments on multiple datasets show that ESTAS stably achieves >\n99% attacks success rate (ASR) with one target-class sample. Compared to prior\nworks, ESTAS attains > 30% ASR increase and > 8.3% accuracy improvement on\naverage.",
    "descriptor": "\nComments: 10 pages, 7 figures, 6 tables\n",
    "authors": [
      "Jiaqi Xue",
      "Qian Lou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10908"
  },
  {
    "id": "arXiv:2211.10909",
    "title": "TSEXPLAIN: Explaining Aggregated Time Series by Surfacing Evolving  Contributors",
    "abstract": "Aggregated time series are generated effortlessly everywhere, e.g., \"total\nconfirmed covid-19 cases since 2019\" and \"total liquor sales over time.\"\nUnderstanding \"how\" and \"why\" these key performance indicators (KPI) evolve\nover time is critical to making data-informed decisions. Existing explanation\nengines focus on explaining one aggregated value or the difference between two\nrelations. However, this falls short of explaining KPIs' continuous changes\nover time. Motivated by this, we propose TSEXPLAIN, a system that explains\naggregated time series by surfacing the underlying evolving top contributors.\nUnder the hood, we leverage prior works on two-relations diff as a building\nblock and formulate a K-Segmentation problem to segment the time series such\nthat each segment after segmentation shares consistent explanations, i.e.,\ncontributors. To quantify consistency in each segment, we propose a novel\nwithin-segment variance design that is explanation-aware; to derive the optimal\nK-Segmentation scheme, we develop an efficient dynamic programming algorithm.\nExperiments on synthetic and real-world datasets show that our\nexplanation-aware segmentation can effectively identify evolving explanations\nfor aggregated time series and outperform explanation-agnostic segmentation.\nFurther, we proposed an optimal selection strategy of K and several\noptimizations to speed up TSEXPLAIN for interactive user experience, achieving\nup to 13X efficiency improvement.",
    "descriptor": "\nComments: 17 pages; Accepted by ICDE 2023\n",
    "authors": [
      "Yiru Chen",
      "Silu Huang"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.10909"
  },
  {
    "id": "arXiv:2211.10911",
    "title": "Non-verbal Facial Action Units-based Automatic Depression Classification",
    "abstract": "Depression is a common mental disorder that causes people to experience\ndepressed mood, loss of interest or pleasure, feelings of guilt or low\nself-worth. Traditional clinical depression diagnosis methods are subjective\nand time consuming. Since depression can be reflected by human facial\nexpressions, We propose a non-verbal facial behavior-based automatic depression\nclassification approach. In this paper, both short-term behavior-based and\nclip-based depression classification are constructed. The final clip-level\ndecision of short-term behavior-based depression detection is yielded by\naveraging the predictions of all short-term behaviors while we modelling\nbehaviors contained in all frames based on two Gaussian Mixture Models. To\nevaluate the proposed approaches, we select a gender balanced subset from AVEC\n2019 depression corpus containing 30 participants. The experimental results\nshow that our method achieved more than 75% depression classification accuracy,\nwhere both GMM-based clip-level depression modelling and rank pooling-based\nshort-term depression behavior modelling achieved at least 70% classification\naccuracy. The result indicates that our approach can leverage complementary\ninformation from both systems to achieve promising depression predictions from\nfacial behaviors.",
    "descriptor": "",
    "authors": [
      "Chuang Yu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.10911"
  },
  {
    "id": "arXiv:2211.10916",
    "title": "ECM-OPCC: Efficient Context Model for Octree-based Point Cloud  Compression",
    "abstract": "Recently, deep learning methods have shown promising results in point cloud\ncompression. For octree-based point cloud compression, previous works show that\nthe information of ancestor nodes and sibling nodes are equally important for\npredicting current node. However, those works either adopt insufficient context\nor bring intolerable decoding complexity (e.g. >600s). To address this problem,\nwe propose a sufficient yet efficient context model and design an efficient\ndeep learning codec for point clouds. Specifically, we first propose a\nwindow-constrained multi-group coding strategy to exploit the autoregressive\ncontext while maintaining decoding efficiency. Then, we propose a dual\ntransformer architecture to utilize the dependency of current node on its\nancestors and siblings. We also propose a random-masking pre-train method to\nenhance our model. Experimental results show that our approach achieves\nstate-of-the-art performance for both lossy and lossless point cloud\ncompression. Moreover, our multi-group coding strategy saves 98% decoding time\ncompared with previous octree-based compression method.",
    "descriptor": "",
    "authors": [
      "Yiqi Jin",
      "Ziyu Zu",
      "Tongda Xu",
      "Yuhuan Lin",
      "Yan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.10916"
  },
  {
    "id": "arXiv:2211.10921",
    "title": "MEESO: A Multi-objective End-to-End Self-Optimized Approach for  Automatically Building Deep Learning Models",
    "abstract": "Deep learning has been widely used in various applications from different\nfields such as computer vision, natural language processing, etc. However, the\ntraining models are often manually developed via many costly experiments. This\nmanual work usually requires substantial computing resources, time, and\nexperience. To simplify the use of deep learning and alleviate human effort,\nautomated deep learning has emerged as a potential tool that releases the\nburden for both users and researchers. Generally, an automatic approach should\nsupport the diversity of model selection and the evaluation should allow users\nto decide upon their demands. To that end, we propose a multi-objective\nend-to-end self-optimized approach for constructing deep learning models\nautomatically. Experimental results on well-known datasets such as MNIST,\nFashion, and Cifar10 show that our algorithm can discover various competitive\nmodels compared with the state-of-the-art approach. In addition, our approach\nalso introduces multi-objective trade-off solutions for both accuracy and\nuncertainty metrics for users to make better decisions.",
    "descriptor": "",
    "authors": [
      "Thanh Phuong Pham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10921"
  },
  {
    "id": "arXiv:2211.10922",
    "title": "Auto-Focus Contrastive Learning for Image Manipulation Detection",
    "abstract": "Generally, current image manipulation detection models are simply built on\nmanipulation traces. However, we argue that those models achieve sub-optimal\ndetection performance as it tends to: 1) distinguish the manipulation traces\nfrom a lot of noisy information within the entire image, and 2) ignore the\ntrace relations among the pixels of each manipulated region and its\nsurroundings. To overcome these limitations, we propose an Auto-Focus\nContrastive Learning (AF-CL) network for image manipulation detection. It\ncontains two main ideas, i.e., multi-scale view generation (MSVG) and trace\nrelation modeling (TRM). Specifically, MSVG aims to generate a pair of views,\neach of which contains the manipulated region and its surroundings at a\ndifferent scale, while TRM plays a role in modeling the trace relations among\nthe pixels of each manipulated region and its surroundings for learning the\ndiscriminative representation. After learning the AF-CL network by minimizing\nthe distance between the representations of corresponding views, the learned\nnetwork is able to automatically focus on the manipulated region and its\nsurroundings and sufficiently explore their trace relations for accurate\nmanipulation detection. Extensive experiments demonstrate that, compared to the\nstate-of-the-arts, AF-CL provides significant performance improvements, i.e.,\nup to 2.5%, 7.5%, and 0.8% F1 score, on CAISA, NIST, and Coverage datasets,\nrespectively.",
    "descriptor": "",
    "authors": [
      "Wenyan Pan",
      "Zhili Zhou",
      "Guangcan Liu",
      "Teng Huang",
      "Hongyang Yan",
      "Q.M. Jonathan Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10922"
  },
  {
    "id": "arXiv:2211.10923",
    "title": "Traceable and Authenticable Image Tagging for Fake News Detection",
    "abstract": "To prevent fake news images from misleading the public, it is desirable not\nonly to verify the authenticity of news images but also to trace the source of\nfake news, so as to provide a complete forensic chain for reliable fake news\ndetection. To simultaneously achieve the goals of authenticity verification and\nsource tracing, we propose a traceable and authenticable image tagging approach\nthat is based on a design of Decoupled Invertible Neural Network (DINN). The\ndesigned DINN can simultaneously embed the dual-tags, \\textit{i.e.},\nauthenticable tag and traceable tag, into each news image before publishing,\nand then separately extract them for authenticity verification and source\ntracing. Moreover, to improve the accuracy of dual-tags extraction, we design a\nparallel Feature Aware Projection Model (FAPM) to help the DINN preserve\nessential tag information. In addition, we define a Distance Metric-Guided\nModule (DMGM) that learns asymmetric one-class representations to enable the\ndual-tags to achieve different robustness performances under malicious\nmanipulations. Extensive experiments, on diverse datasets and unseen\nmanipulations, demonstrate that the proposed tagging approach achieves\nexcellent performance in the aspects of both authenticity verification and\nsource tracing for reliable fake news detection and outperforms the prior\nworks.",
    "descriptor": "",
    "authors": [
      "Ruohan Meng",
      "Zhili Zhou",
      "Qi Cui",
      "Kwok-Yan Lam",
      "Alex Kot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10923"
  },
  {
    "id": "arXiv:2211.10924",
    "title": "Uniform convergence of optimal order under a balanced norm of a local  discontinuous Galerkin method on a Shishkin mesh",
    "abstract": "For singularly perturbed reaction-diffusion problems in 1D and 2D, we study a\nlocal discontinuous Galerkin (LDG) method on a Shishkin mesh. In these cases,\nthe standard energy norm is too weak to capture adequately the behavior of the\nboundary layers that appear in the solutions. To deal with this deficiency, we\nintroduce a balanced norm stronger than the energy norm. In order to achieve\noptimal convergence under the balanced norm in one-dimensional case, we design\nnovel numerical fluxes and propose a special interpolation that consists of a\nGauss-Radau projection and a local $L^2$ projection. Moreover, we generalize\nthe numerical fluxes and interpolation, and extend convergence analysis of\noptimal order from 1D to 2D. Finally, numerical experiments are presented to\nconfirm the theoretical results.",
    "descriptor": "\nComments: 22pages, two tables\n",
    "authors": [
      "Jin Zhang",
      "Wenchao Zheng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.10924"
  },
  {
    "id": "arXiv:2211.10927",
    "title": "GLT-T: Global-Local Transformer Voting for 3D Single Object Tracking in  Point Clouds",
    "abstract": "Current 3D single object tracking methods are typically based on VoteNet, a\n3D region proposal network. Despite the success, using a single seed point\nfeature as the cue for offset learning in VoteNet prevents high-quality 3D\nproposals from being generated. Moreover, seed points with different importance\nare treated equally in the voting process, aggravating this defect. To address\nthese issues, we propose a novel global-local transformer voting scheme to\nprovide more informative cues and guide the model pay more attention on\npotential seed points, promoting the generation of high-quality 3D proposals.\nTechnically, a global-local transformer (GLT) module is employed to integrate\nobject- and patch-aware prior into seed point features to effectively form\nstrong feature representation for geometric positions of the seed points, thus\nproviding more robust and accurate cues for offset learning. Subsequently, a\nsimple yet effective training strategy is designed to train the GLT module. We\ndevelop an importance prediction branch to learn the potential importance of\nthe seed points and treat the output weights vector as a training constraint\nterm. By incorporating the above components together, we exhibit a superior\ntracking method GLT-T. Extensive experiments on challenging KITTI and NuScenes\nbenchmarks demonstrate that GLT-T achieves state-of-the-art performance in the\n3D single object tracking task. Besides, further ablation studies show the\nadvantages of the proposed global-local transformer voting scheme over the\noriginal VoteNet. Code and models will be available at\nhttps://github.com/haooozi/GLT-T.",
    "descriptor": "\nComments: Accepted to AAAI 2023. The source code and models will be available at this https URL\n",
    "authors": [
      "Jiahao Nie",
      "Zhiwei He",
      "Yuxiang Yang",
      "Mingyu Gao",
      "Jing Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10927"
  },
  {
    "id": "arXiv:2211.10929",
    "title": "Towards Generalizable Graph Contrastive Learning: An Information Theory  Perspective",
    "abstract": "Graph contrastive learning (GCL) emerges as the most representative approach\nfor graph representation learning, which leverages the principle of maximizing\nmutual information (InfoMax) to learn node representations applied in\ndownstream tasks. To explore better generalization from GCL to downstream\ntasks, previous methods heuristically define data augmentation or pretext\ntasks. However, the generalization ability of GCL and its theoretical principle\nare still less reported. In this paper, we first propose a metric named GCL-GE\nfor GCL generalization ability. Considering the intractability of the metric\ndue to the agnostic downstream task, we theoretically prove a mutual\ninformation upper bound for it from an information-theoretic perspective.\nGuided by the bound, we design a GCL framework named InfoAdv with enhanced\ngeneralization ability, which jointly optimizes the generalization metric and\nInfoMax to strike the right balance between pretext task fitting and the\ngeneralization ability on downstream tasks. We empirically validate our\ntheoretical findings on a number of representative benchmarks, and experimental\nresults demonstrate that our model achieves state-of-the-art performance.",
    "descriptor": "\nComments: 25 pages, 7 figures, 6 tables\n",
    "authors": [
      "Yige Yuan",
      "Bingbing Xu",
      "Huawei Shen",
      "Qi Cao",
      "Keting Cen",
      "Wen Zheng",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10929"
  },
  {
    "id": "arXiv:2211.10931",
    "title": "Attention-based Class Activation Diffusion for Weakly-Supervised  Semantic Segmentation",
    "abstract": "Extracting class activation maps (CAM) is a key step for weakly-supervised\nsemantic segmentation (WSSS). The CAM of convolution neural networks fails to\ncapture long-range feature dependency on the image and result in the coverage\non only foreground object parts, i.e., a lot of false negatives. An intuitive\nsolution is ``coupling'' the CAM with the long-range attention matrix of visual\ntransformers (ViT) We find that the direct ``coupling'', e.g., pixel-wise\nmultiplication of attention and activation, achieves a more global coverage (on\nthe foreground), but unfortunately goes with a great increase of false\npositives, i.e., background pixels are mistakenly included. This paper aims to\ntackle this issue. It proposes a new method to couple CAM and Attention matrix\nin a probabilistic Diffusion way, and dub it AD-CAM. Intuitively, it integrates\nViT attention and CAM activation in a conservative and convincing way.\nConservative is achieved by refining the attention between a pair of pixels\nbased on their respective attentions to common neighbors, where the intuition\nis two pixels having very different neighborhoods are rarely dependent, i.e.,\ntheir attention should be reduced. Convincing is achieved by diffusing a\npixel's activation to its neighbors (on the CAM) in proportion to the\ncorresponding attentions (on the AM). In experiments, our results on two\nchallenging WSSS benchmarks PASCAL VOC and MS~COCO show that AD-CAM as pseudo\nlabels can yield stronger WSSS models than the state-of-the-art variants of\nCAM.",
    "descriptor": "",
    "authors": [
      "Jianqiang Huang",
      "Jian Wang",
      "Qianru Sun",
      "Hanwang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10931"
  },
  {
    "id": "arXiv:2211.10933",
    "title": "Invisible Backdoor Attack with Dynamic Triggers against Person  Re-identification",
    "abstract": "In recent years, person Re-identification (ReID) has rapidly progressed with\nwide real-world applications, but also poses significant risks of adversarial\nattacks. In this paper, we focus on the backdoor attack on deep ReID models.\nExisting backdoor attack methods follow an all-to-one/all attack scenario,\nwhere all the target classes in the test set have already been seen in the\ntraining set. However, ReID is a much more complex fine-grained open-set\nrecognition problem, where the identities in the test set are not contained in\nthe training set. Thus, previous backdoor attack methods for classification are\nnot applicable for ReID. To ameliorate this issue, we propose a novel backdoor\nattack on deep ReID under a new all-to-unknown scenario, called Dynamic\nTriggers Invisible Backdoor Attack (DT-IBA). Instead of learning fixed triggers\nfor the target classes from the training set, DT-IBA can dynamically generate\nnew triggers for any unknown identities. Specifically, an identity hashing\nnetwork is proposed to first extract target identity information from a\nreference image, which is then injected into the benign images by image\nsteganography. We extensively validate the effectiveness and stealthiness of\nthe proposed attack on benchmark datasets, and evaluate the effectiveness of\nseveral defense methods against our attack.",
    "descriptor": "",
    "authors": [
      "Wenli Sun",
      "Xinyang Jiang",
      "Shuguang Dou",
      "Dongsheng Li",
      "Duoqian Miao",
      "Cheng Deng",
      "Cairong Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.10933"
  },
  {
    "id": "arXiv:2211.10934",
    "title": "Active Exploration based on Information Gain by Particle Filter for  Efficient Spatial Concept Formation",
    "abstract": "Autonomous robots are required to actively and adaptively learn the\ncategories and words of various places by exploring the surrounding environment\nand interacting with users. In semantic mapping and spatial language\nacquisition conducted using robots, it is costly and labor-intensive to prepare\ntraining datasets that contain linguistic instructions from users. Therefore,\nwe aimed to enable mobile robots to learn spatial concepts through autonomous\nactive exploration. This study is characterized by interpreting the `action' of\nthe robot that asks the user the question `What kind of place is this?' in the\ncontext of active inference. We propose an active inference method, spatial\nconcept formation with information gain-based active exploration (SpCoAE), that\ncombines sequential Bayesian inference by particle filters and position\ndetermination based on information gain in a probabilistic generative model.\nOur experiment shows that the proposed method can efficiently determine a\nposition to form appropriate spatial concepts in home environments. In\nparticular, it is important to conduct efficient exploration that leads to\nappropriate concept formation and quickly covers the environment without\nadopting a haphazard exploration strategy.",
    "descriptor": "",
    "authors": [
      "Akira Taniguchi",
      "Yoshiki Tabuchi",
      "Tomochika Ishikawa",
      "Lotfi El Hafi",
      "Yoshinobu Hagiwara",
      "Tadahiro Taniguchi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10934"
  },
  {
    "id": "arXiv:2211.10936",
    "title": "Learning to Search for Job Shop Scheduling via Deep Reinforcement  Learning",
    "abstract": "Recent studies in using deep reinforcement learning (DRL) to solve Job-shop\nscheduling problems (JSSP) focus on construction heuristics. However, their\nperformance is still far from optimality, mainly because the underlying graph\nrepresentation scheme is unsuitable for modeling partial solutions at each\nconstruction step. This paper proposes a novel DRL-based method to learn\nimprovement heuristics for JSSP, where graph representation is employed to\nencode complete solutions. We design a Graph Neural Network based\nrepresentation scheme, consisting of two modules to effectively capture the\ninformation of dynamic topology and different types of nodes in graphs\nencountered during the improvement process. To speed up solution evaluation\nduring improvement, we design a novel message-passing mechanism that can\nevaluate multiple solutions simultaneously. Extensive experiments on classic\nbenchmarks show that the improvement policy learned by our method outperforms\nstate-of-the-art DRL-based methods by a large margin.",
    "descriptor": "",
    "authors": [
      "Cong Zhang",
      "Wen Song",
      "Zhiguang Cao",
      "Jie Zhang",
      "Puay Siew Tan",
      "Chi Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10936"
  },
  {
    "id": "arXiv:2211.10938",
    "title": "AI-KD: Adversarial learning and Implicit regularization for  self-Knowledge Distillation",
    "abstract": "We present a novel adversarial penalized self-knowledge distillation method,\nnamed adversarial learning and implicit regularization for self-knowledge\ndistillation (AI-KD), which regularizes the training procedure by adversarial\nlearning and implicit distillations. Our model not only distills the\ndeterministic and progressive knowledge which are from the pre-trained and\nprevious epoch predictive probabilities but also transfers the knowledge of the\ndeterministic predictive distributions using adversarial learning. The\nmotivation is that the self-knowledge distillation methods regularize the\npredictive probabilities with soft targets, but the exact distributions may be\nhard to predict. Our method deploys a discriminator to distinguish the\ndistributions between the pre-trained and student models while the student\nmodel is trained to fool the discriminator in the trained procedure. Thus, the\nstudent model not only can learn the pre-trained model's predictive\nprobabilities but also align the distributions between the pre-trained and\nstudent models. We demonstrate the effectiveness of the proposed method with\nnetwork architectures on multiple datasets and show the proposed method\nachieves better performance than state-of-the-art methods.",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Hyungmin Kim",
      "Sungho Suh",
      "Sunghyun Baek",
      "Daehwan Kim",
      "Daun Jeong",
      "Hansang Cho",
      "Junmo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10938"
  },
  {
    "id": "arXiv:2211.10943",
    "title": "Scalable Collaborative Learning via Representation Sharing",
    "abstract": "Privacy-preserving machine learning has become a key conundrum for\nmulti-party artificial intelligence. Federated learning (FL) and Split Learning\n(SL) are two frameworks that enable collaborative learning while keeping the\ndata private (on device). In FL, each data holder trains a model locally and\nreleases it to a central server for aggregation. In SL, the clients must\nrelease individual cut-layer activations (smashed data) to the server and wait\nfor its response (during both inference and back propagation). While relevant\nin several settings, both of these schemes have a high communication cost, rely\non server-level computation algorithms and do not allow for tunable levels of\ncollaboration. In this work, we present a novel approach for privacy-preserving\nmachine learning, where the clients collaborate via online knowledge\ndistillation using a contrastive loss (contrastive w.r.t. the labels). The goal\nis to ensure that the participants learn similar features on similar classes\nwithout sharing their input data. To do so, each client releases averaged last\nhidden layer activations of similar labels to a central server that only acts\nas a relay (i.e., is not involved in the training or aggregation of the\nmodels). Then, the clients download these last layer activations (feature\nrepresentations) of the ensemble of users and distill their knowledge in their\npersonal model using a contrastive objective. For cross-device applications\n(i.e., small local datasets and limited computational capacity), this approach\nincreases the utility of the models compared to independent learning and other\nfederated knowledge distillation (FD) schemes, is communication efficient and\nis scalable with the number of clients. We prove theoretically that our\nframework is well-posed, and we benchmark its performance against standard FD\nand FL on various datasets using different model architectures.",
    "descriptor": "",
    "authors": [
      "Fr\u00e9d\u00e9ric Berdoz",
      "Abhishek Singh",
      "Martin Jaggi",
      "Ramesh Raskar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10943"
  },
  {
    "id": "arXiv:2211.10944",
    "title": "Feature Weaken: Vicinal Data Augmentation for Classification",
    "abstract": "Deep learning usually relies on training large-scale data samples to achieve\nbetter performance. However, over-fitting based on training data always remains\na problem. Scholars have proposed various strategies, such as feature dropping\nand feature mixing, to improve the generalization continuously. For the same\npurpose, we subversively propose a novel training method, Feature Weaken, which\ncan be regarded as a data augmentation method. Feature Weaken constructs the\nvicinal data distribution with the same cosine similarity for model training by\nweakening features of the original samples. In especially, Feature Weaken\nchanges the spatial distribution of samples, adjusts sample boundaries, and\nreduces the gradient optimization value of back-propagation. This work can not\nonly improve the classification performance and generalization of the model,\nbut also stabilize the model training and accelerate the model convergence. We\nconduct extensive experiments on classical deep convolution neural models with\nfive common image classification datasets and the Bert model with four common\ntext classification datasets. Compared with the classical models or the\ngeneralization improvement methods, such as Dropout, Mixup, Cutout, and CutMix,\nFeature Weaken shows good compatibility and performance. We also use\nadversarial samples to perform the robustness experiments, and the results show\nthat Feature Weaken is effective in improving the robustness of the model.",
    "descriptor": "\nComments: 9 pages,6 figures\n",
    "authors": [
      "Songhao Jiang",
      "Yan Chu",
      "Tianxing Ma",
      "Tianning Zang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10944"
  },
  {
    "id": "arXiv:2211.10946",
    "title": "Normalizing Flows for Human Pose Anomaly Detection",
    "abstract": "Video anomaly detection is an ill-posed problem because it relies on many\nparameters such as appearance, pose, camera angle, background, and more. We\ndistill the problem to anomaly detection of human pose, thus reducing the risk\nof nuisance parameters such as appearance affecting the result. Focusing on\npose alone also has the side benefit of reducing bias against distinct minority\ngroups. Our model works directly on human pose graph sequences and is\nexceptionally lightweight ($\\sim1K$ parameters), capable of running on any\nmachine able to run the pose estimation with negligible additional resources.\nWe leverage the highly compact pose representation in a normalizing flows\nframework, which we extend to tackle the unique characteristics of\nspatio-temporal pose data and show its advantages in this use case. Our\nalgorithm uses normalizing flows to learn a bijective mapping between the pose\ndata distribution and a Gaussian distribution, using spatio-temporal graph\nconvolution blocks. The algorithm is quite general and can handle training data\nof only normal examples, as well as a supervised dataset that consists of\nlabeled normal and abnormal examples. We report state-of-the-art results on two\nanomaly detection benchmarks - the unsupervised ShanghaiTech dataset and the\nrecent supervised UBnormal dataset.",
    "descriptor": "",
    "authors": [
      "Or Hirschorn",
      "Shai Avidan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.10946"
  },
  {
    "id": "arXiv:2211.10948",
    "title": "FedDCT: Federated Learning of Large Convolutional Neural Networks on  Resource Constrained Devices using Divide and Co-Training",
    "abstract": "We introduce FedDCT, a novel distributed learning paradigm that enables the\nusage of large, high-performance CNNs on resource-limited edge devices. As\nopposed to traditional FL approaches, which require each client to train the\nfull-size neural network independently during each training round, the proposed\nFedDCT allows a cluster of several clients to collaboratively train a large\ndeep learning model by dividing it into an ensemble of several small sub-models\nand train them on multiple devices in parallel while maintaining privacy. In\nthis co-training process, clients from the same cluster can also learn from\neach other, further improving their ensemble performance. In the aggregation\nstage, the server takes a weighted average of all the ensemble models trained\nby all the clusters. FedDCT reduces the memory requirements and allows low-end\ndevices to participate in FL. We empirically conduct extensive experiments on\nstandardized datasets, including CIFAR-10, CIFAR-100, and two real-world\nmedical datasets HAM10000 and VAIPE. Experimental results show that FedDCT\noutperforms a set of current SOTA FL methods with interesting convergence\nbehaviors. Furthermore, compared to other existing approaches, FedDCT achieves\nhigher accuracy and substantially reduces the number of communication rounds\n(with $4-8$ times fewer memory requirements) to achieve the desired accuracy on\nthe testing dataset without incurring any extra training cost on the server\nside.",
    "descriptor": "\nComments: Under review by the IEEE Transactions on Network and Service Management\n",
    "authors": [
      "Quan Nguyen",
      "Hieu H. Pham",
      "Kok-Seng Wong",
      "Phi Le Nguyen",
      "Truong Thao Nguyen",
      "Minh N. Do"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10948"
  },
  {
    "id": "arXiv:2211.10950",
    "title": "Synthesizing Coherent Story with Auto-Regressive Latent Diffusion Models",
    "abstract": "Conditioned diffusion models have demonstrated state-of-the-art text-to-image\nsynthesis capacity. Recently, most works focus on synthesizing independent\nimages; While for real-world applications, it is common and necessary to\ngenerate a series of coherent images for story-stelling. In this work, we\nmainly focus on story visualization and continuation tasks and propose AR-LDM,\na latent diffusion model auto-regressively conditioned on history captions and\ngenerated images. Moreover, AR-LDM can generalize to new characters through\nadaptation. To our best knowledge, this is the first work successfully\nleveraging diffusion models for coherent visual story synthesizing.\nQuantitative results show that AR-LDM achieves SoTA FID scores on PororoSV,\nFlintstonesSV, and the newly introduced challenging dataset VIST containing\nnatural images. Large-scale human evaluations show that AR-LDM has superior\nperformance in terms of quality, relevance, and consistency.",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Xichen Pan",
      "Pengda Qin",
      "Yuhong Li",
      "Hui Xue",
      "Wenhu Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10950"
  },
  {
    "id": "arXiv:2211.10954",
    "title": "A Survey of Scheduling in Time-Sensitive Networking (TSN)",
    "abstract": "TSN is an enhancement of Ethernet which provides various mechanisms for\nreal-time communication. Time-triggered (TT) traffic represents periodic data\nstreams with strict real-time requirements. Amongst others, TSN supports\nscheduled transmission of TT streams, i.e., the transmission of their packets\nby edge nodes is coordinated in such a way that none or very little queuing\ndelay occurs in intermediate nodes. TSN supports multiple priority queues per\negress port. The TAS uses so-called gates to explicitly allow and block these\nqueues for transmission on a short periodic timescale. The TAS is utilized to\nprotect scheduled traffic from other traffic to minimize its queuing delay. In\nthis work, we consider scheduling in TSN which comprises the computation of\nperiodic transmission instants at edge nodes and the periodic opening and\nclosing of queue gates.\nIn this paper, we first give a brief overview of TSN features and standards.\nWe state the TSN scheduling problem and explain common extensions which also\ninclude optimization problems. We review scheduling and optimization methods\nthat have been used in this context. Then, the contribution of currently\navailable research work is surveyed. We extract and compile optimization\nobjectives, solved problem instances, and evaluation results. Research domains\nare identified, and specific contributions are analyzed. Finally, we discuss\npotential research directions and open problems.",
    "descriptor": "\nComments: 34 pages, 19 figures, 9 tables 110 references\n",
    "authors": [
      "Thomas St\u00fcber",
      "Lukas Osswald",
      "Steffen Lindner",
      "Michael Menth"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.10954"
  },
  {
    "id": "arXiv:2211.10955",
    "title": "Learning with Noisily-labeled Class-imbalanced Data",
    "abstract": "Real-world large-scale datasets are both noisily labeled and\nclass-imbalanced. The issues seriously hurt the generalization of trained\nmodels. It is hence significant to address the simultaneous incorrect labeling\nand class-imbalance, i.e., the problem of learning with noisy labels on\nlong-tailed data. Previous works develop several methods for the problem.\nHowever, they always rely on strong assumptions that are invalid or hard to be\nchecked in practice. In this paper, to handle the problem and address the\nlimitations of prior works, we propose a representation calibration method\nRCAL. Specifically, RCAL works with the representations extracted by\nunsupervised contrastive learning. We assume that without incorrect labeling\nand class imbalance, the representations of instances in each class conform to\na multivariate Gaussian distribution, which is much milder and easier to be\nchecked. Based on the assumption, we recover underlying representation\ndistributions from polluted ones resulting from mislabeled and class-imbalanced\ndata. Additional data points are then sampled from the recovered distributions\nto help generalization. Moreover, during classifier training, representation\nlearning takes advantage of representation robustness brought by contrastive\nlearning, which further improves the classifier performance. Experiments on\nmultiple benchmarks justify our claims and confirm the superiority of the\nproposed method.",
    "descriptor": "",
    "authors": [
      "Manyi Zhang",
      "Chun Yuan",
      "Jun Yao",
      "Weiran Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10955"
  },
  {
    "id": "arXiv:2211.10957",
    "title": "Efficient Representations of Object Geometry for Reinforcement Learning  of Interactive Grasping Policies",
    "abstract": "Grasping objects of different shapes and sizes - a foundational, effortless\nskill for humans - remains a challenging task in robotics. Although model-based\napproaches can predict stable grasp configurations for known object models,\nthey struggle to generalize to novel objects and often operate in a\nnon-interactive open-loop manner. In this work, we present a reinforcement\nlearning framework that learns the interactive grasping of various\ngeometrically distinct real-world objects by continuously controlling an\nanthropomorphic robotic hand. We explore several explicit representations of\nobject geometry as input to the policy. Moreover, we propose to inform the\npolicy implicitly through signed distances and show that this is naturally\nsuited to guide the search through a shaped reward component. Finally, we\ndemonstrate that the proposed framework is able to learn even in more\nchallenging conditions, such as targeted grasping from a cluttered bin.\nNecessary pre-grasping behaviors such as object reorientation and utilization\nof environmental constraints emerge in this case. Videos of learned interactive\npolicies are available at https://maltemosbach.github.\nio/geometry_aware_grasping_policies.",
    "descriptor": "",
    "authors": [
      "Malte Mosbach",
      "Sven Behnke"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10957"
  },
  {
    "id": "arXiv:2211.10960",
    "title": "CoCoNet: Coupled Contrastive Learning Network with Multi-level Feature  Ensemble for Multi-modality Image Fusion",
    "abstract": "Infrared and visible image fusion targets to provide an informative image by\ncombining complementary information from different sensors. Existing\nlearning-based fusion approaches attempt to construct various loss functions to\npreserve complementary features from both modalities, while neglecting to\ndiscover the inter-relationship between the two modalities, leading to\nredundant or even invalid information on the fusion results. To alleviate these\nissues, we propose a coupled contrastive learning network, dubbed CoCoNet, to\nrealize infrared and visible image fusion in an end-to-end manner. Concretely,\nto simultaneously retain typical features from both modalities and remove\nunwanted information emerging on the fused result, we develop a coupled\ncontrastive constraint in our loss function.In a fused imge, its foreground\ntarget/background detail part is pulled close to the infrared/visible source\nand pushed far away from the visible/infrared source in the representation\nspace. We further exploit image characteristics to provide data-sensitive\nweights, which allows our loss function to build a more reliable relationship\nwith source images. Furthermore, to learn rich hierarchical feature\nrepresentation and comprehensively transfer features in the fusion process, a\nmulti-level attention module is established. In addition, we also apply the\nproposed CoCoNet on medical image fusion of different types, e.g., magnetic\nresonance image and positron emission tomography image, magnetic resonance\nimage and single photon emission computed tomography image. Extensive\nexperiments demonstrate that our method achieves the state-of-the-art (SOTA)\nperformance under both subjective and objective evaluation, especially in\npreserving prominent targets and recovering vital textural details.",
    "descriptor": "\nComments: 25 pages, 16 figures\n",
    "authors": [
      "Jinyuan Liu",
      "Runjia Lin",
      "Guanyao Wu",
      "Risheng Liu",
      "Zhongxuan Luo",
      "Xin Fan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10960"
  },
  {
    "id": "arXiv:2211.10962",
    "title": "PG-Schema: Schemas for Property Graphs",
    "abstract": "Property graphs have reached a high level of maturity, witnessed by multiple\nrobust graph database systems as well as the ongoing standardization effort\naiming at a creating a new standard Graph Query Language (GQL). Yet, despite\ndocumented demand, schema support is limited in existing systems. It is\nanticipated that the second version of the GQL Standard will have an rich DDL.\nWith is in mind, we propose PG-SCHEMAS, a simple yet powerful formalism for\nspecifying property graph schemas, featuring flexible type definitions\nsupporting multi-inheritance as well as an expressive constraint language based\non recently proposed PG-KEYS.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Angela Bonifati",
      "Stefania Dumbrava",
      "George Fletcher",
      "Jan Hidders",
      "Bei Li",
      "Leonid Libkin",
      "Wim Martens",
      "Filip Murlak",
      "Stefan Plantikow",
      "Ognjen Savkovi\u0107",
      "Juan Sequeda",
      "S\u0142awek Staworko",
      "Dominik Tomaszuk",
      "Hannes Voigt",
      "Domagoj Vrgo\u010d",
      "Mingxi Wu"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.10962"
  },
  {
    "id": "arXiv:2211.10963",
    "title": "A Lightweight Domain Adaptive Absolute Pose Regressor Using Barlow Twins  Objective",
    "abstract": "Identifying the camera pose for a given image is a challenging problem with\napplications in robotics, autonomous vehicles, and augmented/virtual reality.\nLately, learning-based methods have shown to be effective for absolute camera\npose estimation. However, these methods are not accurate when generalizing to\ndifferent domains. In this paper, a domain adaptive training framework for\nabsolute pose regression is introduced. In the proposed framework, the scene\nimage is augmented for different domains by using generative methods to train\nparallel branches using Barlow Twins objective. The parallel branches leverage\na lightweight CNN-based absolute pose regressor architecture. Further, the\nefficacy of incorporating spatial and channel-wise attention in the regression\nhead for rotation prediction is investigated. Our method is evaluated with two\ndatasets, Cambridge landmarks and 7Scenes. The results demonstrate that, even\nwith using roughly 24 times fewer FLOPs, 12 times fewer activations, and 5\ntimes fewer parameters than MS-Transformer, our approach outperforms all the\nCNN-based architectures and achieves performance comparable to\ntransformer-based architectures. Our method ranks 2nd and 4th with the\nCambridge Landmarks and 7Scenes datasets, respectively. In addition, for\naugmented domains not encountered during training, our approach significantly\noutperforms the MS-transformer. Furthermore, it is shown that our domain\nadaptive framework achieves better performance than the single branch model\ntrained with the identical CNN backbone with all instances of the unseen\ndistribution.",
    "descriptor": "\nComments: [draft-v1] 18 pages, 8 figures, and 10 tables\n",
    "authors": [
      "Praveen Kumar Rajendran",
      "Quoc-Vinh Lai-Dang",
      "Luiz Felipe Vecchietti",
      "Dongsoo Har"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10963"
  },
  {
    "id": "arXiv:2211.10964",
    "title": "A space-time framework for periodic flows with applications to  hydrofoils",
    "abstract": "In this paper we propose a space-time framework for the computation of\nperiodic flows. We employ the isogeometric analysis framework to achieve\nhigher-order smoothness in both space and time. The discretization is performed\nusing residual-based variational multiscale modelling and weak boundary\nconditions are adopted to enhance the accuracy near the moving boundaries of\nthe computational domain. We show conservation properties and present a\nconservative method for force extraction. We apply our framework to the\ncomputation of a heaving and pitching hydrofoil. Numerical results display very\naccurate results on course meshes.",
    "descriptor": "",
    "authors": [
      "J. Lotz",
      "M. ten Eikelder",
      "I. Akkerman"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2211.10964"
  },
  {
    "id": "arXiv:2211.10966",
    "title": "Decoding Attention from Gaze: A Benchmark Dataset and End-to-End Models",
    "abstract": "Eye-tracking has potential to provide rich behavioral data about human\ncognition in ecologically valid environments. However, analyzing this rich data\nis often challenging. Most automated analyses are specific to simplistic\nartificial visual stimuli with well-separated, static regions of interest,\nwhile most analyses in the context of complex visual stimuli, such as most\nnatural scenes, rely on laborious and time-consuming manual annotation. This\npaper studies using computer vision tools for \"attention decoding\", the task of\nassessing the locus of a participant's overt visual attention over time. We\nprovide a publicly available Multiple Object Eye-Tracking (MOET) dataset,\nconsisting of gaze data from participants tracking specific objects, annotated\nwith labels and bounding boxes, in crowded real-world videos, for training and\nevaluating attention decoding algorithms. We also propose two end-to-end deep\nlearning models for attention decoding and compare these to state-of-the-art\nheuristic methods.",
    "descriptor": "\nComments: To be published in Proceedings of the NeurIPS 2022 Gaze Meets ML Workshop\n",
    "authors": [
      "Karan Uppal",
      "Jaeah Kim",
      "Shashank Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10966"
  },
  {
    "id": "arXiv:2211.10967",
    "title": "Font Representation Learning via Paired-glyph Matching",
    "abstract": "Fonts can convey profound meanings of words in various forms of glyphs.\nWithout typography knowledge, manually selecting an appropriate font or\ndesigning a new font is a tedious and painful task. To allow users to explore\nvast font styles and create new font styles, font retrieval and font style\ntransfer methods have been proposed. These tasks increase the need for learning\nhigh-quality font representations. Therefore, we propose a novel font\nrepresentation learning scheme to embed font styles into the latent space. For\nthe discriminative representation of a font from others, we propose a\npaired-glyph matching-based font representation learning model that attracts\nthe representations of glyphs in the same font to one another, but pushes away\nthose of other fonts. Through evaluations on font retrieval with query glyphs\non new fonts, we show our font representation learning scheme achieves better\ngeneralization performance than the existing font representation learning\ntechniques. Finally on the downstream font style transfer and generation tasks,\nwe confirm the benefits of transfer learning with the proposed method. The\nsource code is available at https://github.com/junhocho/paired-glyph-matching.",
    "descriptor": "\nComments: Accepted to BMVC2022\n",
    "authors": [
      "Junho Cho",
      "Kyuewang Lee",
      "Jin Young Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10967"
  },
  {
    "id": "arXiv:2211.10969",
    "title": "Bidder Subset Selection Problem in Auction Design",
    "abstract": "Motivated by practical concerns in the online advertising industry, we study\na bidder subset selection problem in single-item auctions. In this problem, a\nlarge pool of candidate bidders have independent values sampled from known\nprior distributions. The seller needs to pick a subset of bidders and run a\ngiven auction format on the selected subset to maximize her expected revenue.\nWe propose two frameworks for the subset restrictions: (i) capacity constraint\non the set of selected bidders; and (ii) incurred costs for the bidders invited\nto the auction. For the second-price auction with anonymous reserve (SPA-AR),\nwe give constant approximation polynomial time algorithms in both frameworks\n(in the latter framework under mild assumptions about the market). Our results\nare in stark contrast to the previous work of Mehta, Nadav, Psomas, Rubinstein\n[NeurIPS 2020], who showed hardness of approximation for the SPA without a\nreserve price. We also give complimentary approximation results for other\nwell-studied auction formats such as anonymous posted pricing and sequential\nposted pricing. On a technical level, we find that the revenue of SPA-AR as a\nset function $f(S)$ of its bidders $S$ is fractionally-subadditive but not\nsubmodular. Our bidder selection problem with invitation costs is a natural\nquestion about (approximately) answering a demand oracle for $f(\\cdot)$ under a\ngiven vector of costs, a common computational assumption in the literature on\ncombinatorial auctions.",
    "descriptor": "\nComments: 17 pages. To appear at SODA 2023\n",
    "authors": [
      "Xiaohui Bei",
      "Nick Gravin",
      "Pinyan Lu",
      "Zhihao Gavin Tang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.10969"
  },
  {
    "id": "arXiv:2211.10971",
    "title": "On Holistic Multi-Step Cyberattack Detection via a Graph-based  Correlation Approach",
    "abstract": "While digitization of distribution grids through information and\ncommunications technology brings numerous benefits, it also increases the\ngrid's vulnerability to serious cyber attacks. Unlike conventional systems,\nattacks on many industrial control systems such as power grids often occur in\nmultiple stages, with the attacker taking several steps at once to achieve its\ngoal. Detection mechanisms with situational awareness are needed to detect\norchestrated attack steps as part of a coherent attack campaign. To provide a\nfoundation for detection and prevention of such attacks, this paper addresses\nthe detection of multi-stage cyber attacks with the aid of a graph-based cyber\nintelligence database and alert correlation approach. Specifically, we propose\nan approach to detect multi-stage attacks by leveraging heterogeneous data to\nform a knowledge base and employ a model-based correlation approach on the\ngenerated alerts to identify multi-stage cyber attack sequences taking place in\nthe network. We investigate the detection quality of the proposed approach by\nusing a case study of a multi-stage cyber attack campaign in a\nfuture-orientated power grid pilot.",
    "descriptor": "\nComments: IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids (SmartGridComm) 2022\n",
    "authors": [
      "\u00d6mer Sen",
      "Chijioke Eze",
      "Andreas Ulbig",
      "Antonello Monti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.10971"
  },
  {
    "id": "arXiv:2211.10972",
    "title": "A Comparative Analysis of Transfer Learning-based Techniques for the  Classification of Melanocytic Nevi",
    "abstract": "Skin cancer is a fatal manifestation of cancer. Unrepaired deoxyribo-nucleic\nacid (DNA) in skin cells, causes genetic defects in the skin and leads to skin\ncancer. To deal with lethal mortality rates coupled with skyrocketing costs of\nmedical treatment, early diagnosis is mandatory. To tackle these challenges,\nresearchers have developed a variety of rapid detection tools for skin cancer.\nLesion-specific criteria are utilized to distinguish benign skin cancer from\nmalignant melanoma. In this study, a comparative analysis has been performed on\nfive Transfer Learning-based techniques that have the potential to be leveraged\nfor the classification of melanocytic nevi. These techniques are based on deep\nconvolutional neural networks (DCNNs) that have been pre-trained on thousands\nof open-source images and are used for day-to-day classification tasks in many\ninstances.",
    "descriptor": "\nComments: 12 pages, 5 figures, submitted to International Conference on Advances and Applications of Artificial Intelligence and Machine Learning (ICAAAIML) 2022, to be published in Springer's Lecture Notes in Electrical Engineering\n",
    "authors": [
      "Sanya Sinha",
      "Nilay Gupta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10972"
  },
  {
    "id": "arXiv:2211.10973",
    "title": "FakeSV: A Multimodal Benchmark with Rich Social Context for Fake News  Detection on Short Video Platforms",
    "abstract": "Short video platforms have become an important channel for news sharing, but\nalso a new breeding ground for fake news. To mitigate this problem, research of\nfake news video detection has recently received a lot of attention. Existing\nworks face two roadblocks: the scarcity of comprehensive and largescale\ndatasets and insufficient utilization of multimodal information. Therefore, in\nthis paper, we construct the largest Chinese short video dataset about fake\nnews named FakeSV, which includes news content, user comments, and publisher\nprofiles simultaneously. To understand the characteristics of fake news videos,\nwe conduct exploratory analysis of FakeSV from different perspectives.\nMoreover, we provide a new multimodal detection model named SV-FEND, which\nexploits the cross-modal correlations to select the most informative features\nand utilizes the social context information for detection. Extensive\nexperiments evaluate the superiority of the proposed method and provide\ndetailed comparisons of different methods and modalities for future works.",
    "descriptor": "\nComments: To appear in AAAI 2023 AISI track\n",
    "authors": [
      "Peng Qi",
      "Yuyan Bu",
      "Juan Cao",
      "Wei Ji",
      "Ruihao Shui",
      "Junbin Xiao",
      "Danding Wang",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.10973"
  },
  {
    "id": "arXiv:2211.10974",
    "title": "Investigating the Cybersecurity of Smart Grids Based on Cyber-Physical  Twin Approach",
    "abstract": "While the increasing penetration of information and communication technology\ninto distribution grid brings numerous benefits, it also opens up a new threat\nlandscape, particularly through cyberattacks. To provide a basis for\ncountermeasures against such threats, this paper addresses the investigation of\nthe impact and manifestations of cyberattacks on smart grids by replicating the\npower grid in a secure, isolated, and controlled laboratory environment as a\ncyber-physical twin. Currently, detecting intrusions by unauthorized third\nparties into the central monitoring and control system of grid operators,\nespecially attacks within the grid perimeter, is a major challenge. The\ndevelopment and validation of methods to detect and prevent coordinated and\ntimed attacks on electric power systems depends not only on the availability\nand quality of data from such attack scenarios, but also on suitable realistic\ninvestigation environments. However, to create a comprehensive investigation\nenvironment, a realistic representation of the study object is required to\nthoroughly investigate critical cyberattacks on grid operations and evaluate\ntheir impact on the power grid using real data. In this paper, we demonstrate\nour cyber-physical twin approach using a microgrid in the context of a\ncyberattack case study.",
    "descriptor": "\nComments: IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids (SmartGridComm) 2022\n",
    "authors": [
      "\u00d6mer Sen",
      "Florian Schmidtke",
      "Federico Carere",
      "Francesca Santori",
      "Andreas Ulbig",
      "Antonello Monti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.10974"
  },
  {
    "id": "arXiv:2211.10979",
    "title": "A Hybrid Multi-GPU Implementation of Simplex Algorithm with CPU  Collaboration",
    "abstract": "The simplex algorithm has been successfully used for many years in solving\nlinear programming (LP) problems. Due to the intensive computations required\n(especially for the solution of large LP problems), parallel approaches have\nalso extensively been studied. The computational power provided by the modern\nGPUs as well as the rapid development of multicore CPU systems have led OpenMP\nand CUDA programming models to the top preferences during the last years.\nHowever, the desired efficient collaboration between CPU and GPU through the\ncombined use of the above programming models is still considered a hard\nresearch problem. In the above context, we demonstrate here an excessively\nefficient implementation of standard simplex, targeting to the best possible\nexploitation of the concurrent use of all the computing resources, on a\nmulticore platform with multiple CUDA-enabled GPUs. More concretely, we present\na novel hybrid collaboration scheme which is based on the concurrent execution\nof suitably spread CPU-assigned (via multithreading) and GPU-offloaded\ncomputations. The experimental results extracted through the cooperative use of\nOpenMP and CUDA over a notably powerful modern hybrid platform (consisting of\n32 cores and two high-spec GPUs, Titan Rtx and Rtx 2080Ti) highlight that the\nperformance of the presented here hybrid GPU/CPU collaboration scheme is\nclearly superior to the GPU-only implementation under almost all conditions.\nThe corresponding measurements validate the value of using all resources\nconcurrently, even in the case of a multi-GPU configuration platform.\nFurthermore, the given implementations are completely comparable (and slightly\nsuperior in most cases) to other related attempts in the bibliography, and\nclearly superior to the native CPU-implementation with 32 cores.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Basilis Mamalis",
      "Marios Perlitis"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.10979"
  },
  {
    "id": "arXiv:2211.10981",
    "title": "Real-time Local Feature with Global Visual Information Enhancement",
    "abstract": "Local feature provides compact and invariant image representation for various\nvisual tasks. Current deep learning-based local feature algorithms always\nutilize convolution neural network (CNN) architecture with limited receptive\nfield. Besides, even with high-performance GPU devices, the computational\nefficiency of local features cannot be satisfactory. In this paper, we tackle\nsuch problems by proposing a CNN-based local feature algorithm. The proposed\nmethod introduces a global enhancement module to fuse global visual clues in a\nlight-weight network, and then optimizes the network by novel deep\nreinforcement learning scheme from the perspective of local feature matching\ntask. Experiments on the public benchmarks demonstrate that the proposal can\nachieve considerable robustness against visual interference and meanwhile run\nin real time.",
    "descriptor": "\nComments: 6 pages, 5 figures, 2 tables. Accepted by ICIEA 2022\n",
    "authors": [
      "Jinyu Miao",
      "Haosong Yue",
      "Zhong Liu",
      "Xingming Wu",
      "Zaojun Fang",
      "Guilin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10981"
  },
  {
    "id": "arXiv:2211.10986",
    "title": "UnifiedABSA: A Unified ABSA Framework Based on Multi-task Instruction  Tuning",
    "abstract": "Aspect-Based Sentiment Analysis (ABSA) aims to provide fine-grained\naspect-level sentiment information. There are many ABSA tasks, and the current\ndominant paradigm is to train task-specific models for each task. However,\napplication scenarios of ABSA tasks are often diverse. This solution usually\nrequires a large amount of labeled data from each task to perform excellently.\nThese dedicated models are separately trained and separately predicted,\nignoring the relationship between tasks. To tackle these issues, we present\nUnifiedABSA, a general-purpose ABSA framework based on multi-task instruction\ntuning, which can uniformly model various tasks and capture the inter-task\ndependency with multi-task learning. Extensive experiments on two benchmark\ndatasets show that UnifiedABSA can significantly outperform dedicated models on\n11 ABSA tasks and show its superiority in terms of data efficiency.",
    "descriptor": "",
    "authors": [
      "Zengzhi Wang",
      "Rui Xia",
      "Jianfei Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.10986"
  },
  {
    "id": "arXiv:2211.10990",
    "title": "Enhancing Intra-class Information Extraction for Heterophilous Graphs:  One Neural Architecture Search Approach",
    "abstract": "In recent years, Graph Neural Networks (GNNs) have been popular in graph\nrepresentation learning which assumes the homophily property, i.e., the\nconnected nodes have the same label or have similar features. However, they may\nfail to generalize into the heterophilous graphs which in the low/medium level\nof homophily. Existing methods tend to address this problem by enhancing the\nintra-class information extraction, i.e., either by designing better GNNs to\nimprove the model effectiveness, or re-designing the graph structures to\nincorporate more potential intra-class nodes from distant hops. Despite the\nsuccess, we observe two aspects that can be further improved: (a) enhancing the\nego feature information extraction from node itself which is more reliable in\nextracting the intra-class information; (b) designing node-wise GNNs can better\nadapt to the nodes with different homophily ratios. In this paper, we propose a\nnovel method IIE-GNN (Intra-class Information Enhanced Graph Neural Networks)\nto achieve two improvements. A unified framework is proposed based on the\nliterature, in which the intra-class information from the node itself and\nneighbors can be extracted based on seven carefully designed blocks. With the\nhelp of neural architecture search (NAS), we propose a novel search space based\non the framework, and then provide an architecture predictor to design GNNs for\neach node. We further conduct experiments to show that IIE-GNN can improve the\nmodel performance by designing node-wise GNNs to enhance intra-class\ninformation extraction.",
    "descriptor": "",
    "authors": [
      "Lanning Wei",
      "Zhiqiang He",
      "Huan Zhao",
      "Quanming Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10990"
  },
  {
    "id": "arXiv:2211.10991",
    "title": "Modeling Fine-grained Information via Knowledge-aware Hierarchical Graph  for Zero-shot Entity Retrieval",
    "abstract": "Zero-shot entity retrieval, aiming to link mentions to candidate entities\nunder the zero-shot setting, is vital for many tasks in Natural Language\nProcessing. Most existing methods represent mentions/entities via the sentence\nembeddings of corresponding context from the Pre-trained Language Model.\nHowever, we argue that such coarse-grained sentence embeddings can not fully\nmodel the mentions/entities, especially when the attention scores towards\nmentions/entities are relatively low. In this work, we propose GER, a\n\\textbf{G}raph enhanced \\textbf{E}ntity \\textbf{R}etrieval framework, to\ncapture more fine-grained information as complementary to sentence embeddings.\nWe extract the knowledge units from the corresponding context and then\nconstruct a mention/entity centralized graph. Hence, we can learn the\nfine-grained information about mention/entity by aggregating information from\nthese knowledge units. To avoid the graph information bottleneck for the\ncentral mention/entity node, we construct a hierarchical graph and design a\nnovel Hierarchical Graph Attention Network~(HGAN). Experimental results on\npopular benchmarks demonstrate that our proposed GER framework performs better\nthan previous state-of-the-art models. The code has been available at\nhttps://github.com/wutaiqiang/GER-WSDM2023.",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Taiqiang Wu",
      "Xingyu Bai",
      "Weigang Guo",
      "Weijie Liu",
      "Siheng Li",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.10991"
  },
  {
    "id": "arXiv:2211.10992",
    "title": "How to Describe Images in a More Funny Way? Towards a Modular Approach  to Cross-Modal Sarcasm Generation",
    "abstract": "Sarcasm generation has been investigated in previous studies by considering\nit as a text-to-text generation problem, i.e., generating a sarcastic sentence\nfor an input sentence. In this paper, we study a new problem of cross-modal\nsarcasm generation (CMSG), i.e., generating a sarcastic description for a given\nimage. CMSG is challenging as models need to satisfy the characteristics of\nsarcasm, as well as the correlation between different modalities. In addition,\nthere should be some inconsistency between the two modalities, which requires\nimagination. Moreover, high-quality training data is insufficient. To address\nthese problems, we take a step toward generating sarcastic descriptions from\nimages without paired training data and propose an\nExtraction-Generation-Ranking based Modular method (EGRM) for cross-model\nsarcasm generation. Specifically, EGRM first extracts diverse information from\nan image at different levels and uses the obtained image tags, sentimental\ndescriptive caption, and commonsense-based consequence to generate candidate\nsarcastic texts. Then, a comprehensive ranking algorithm, which considers\nimage-text relation, sarcasticness, and grammaticality, is proposed to select a\nfinal text from the candidate texts. Human evaluation at five criteria on a\ntotal of 1200 generated image-text pairs from eight systems and auxiliary\nautomatic evaluation show the superiority of our method.",
    "descriptor": "",
    "authors": [
      "Jie Ruan",
      "Yue Wu",
      "Xiaojun Wan",
      "Yuesheng Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.10992"
  },
  {
    "id": "arXiv:2211.10994",
    "title": "DesNet: Decomposed Scale-Consistent Network for Unsupervised Depth  Completion",
    "abstract": "Unsupervised depth completion aims to recover dense depth from the sparse one\nwithout using the ground-truth annotation. Although depth measurement obtained\nfrom LiDAR is usually sparse, it contains valid and real distance information,\ni.e., scale-consistent absolute depth values. Meanwhile, scale-agnostic\ncounterparts seek to estimate relative depth and have achieved impressive\nperformance. To leverage both the inherent characteristics, we thus suggest to\nmodel scale-consistent depth upon unsupervised scale-agnostic frameworks.\nSpecifically, we propose the decomposed scale-consistent learning (DSCL)\nstrategy, which disintegrates the absolute depth into relative depth prediction\nand global scale estimation, contributing to individual learning benefits. But\nunfortunately, most existing unsupervised scale-agnostic frameworks heavily\nsuffer from depth holes due to the extremely sparse depth input and weak\nsupervised signal. To tackle this issue, we introduce the global depth guidance\n(GDG) module, which attentively propagates dense depth reference into the\nsparse target via novel dense-to-sparse attention. Extensive experiments show\nthe superiority of our method on outdoor KITTI benchmark, ranking 1st and\noutperforming the best KBNet more than 12% in RMSE. In addition, our approach\nachieves state-of-the-art performance on indoor NYUv2 dataset.",
    "descriptor": "\nComments: Accepted by AAAI2023\n",
    "authors": [
      "Zhiqiang Yan",
      "Kun Wang",
      "Xiang Li",
      "Zhenyu Zhang",
      "Jun Li",
      "Jian Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10994"
  },
  {
    "id": "arXiv:2211.10995",
    "title": "Distinctive Fire and Smoke Detection with Self-Similar",
    "abstract": "Deep learning based object detection is demonstrating a preponderance in the\npractical artificial intelligence. However, there still are some objects that\nare difficult to be recognized such as fire and smoke because of their\nnon-solid shapes. However, these objects have a mathematical fractal feature of\nself-similar that can relieve us from struggling with their various shapes. To\nthis end, we propose to utilize the Hausdorff distance to evaluate the\nself-similarity and accordingly tailored a loss function to improve the\ndetection accuracy of fire and smoke. Moreover, we proposed a general labeling\ncriterion for these objects based on their geometrical features. Our\nexperiments on commonly used baseline networks for object detection have\nverified that our method is valid and have improved the detecting accuracy by\n2.23%.",
    "descriptor": "",
    "authors": [
      "Zeyu Shangguan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10995"
  },
  {
    "id": "arXiv:2211.10996",
    "title": "MINTIME: Multi-Identity Size-Invariant Video Deepfake Detection",
    "abstract": "In this paper, we introduce MINTIME, a video deepfake detection approach that\ncaptures spatial and temporal anomalies and handles instances of multiple\npeople in the same video and variations in face sizes. Previous approaches\ndisregard such information either by using simple a-posteriori aggregation\nschemes, i.e., average or max operation, or using only one identity for the\ninference, i.e., the largest one. On the contrary, the proposed approach builds\non a Spatio-Temporal TimeSformer combined with a Convolutional Neural Network\nbackbone to capture spatio-temporal anomalies from the face sequences of\nmultiple identities depicted in a video. This is achieved through an\nIdentity-aware Attention mechanism that attends to each face sequence\nindependently based on a masking operation and facilitates video-level\naggregation. In addition, two novel embeddings are employed: (i) the Temporal\nCoherent Positional Embedding that encodes each face sequence's temporal\ninformation and (ii) the Size Embedding that encodes the size of the faces as a\nratio to the video frame size. These extensions allow our system to adapt\nparticularly well in the wild by learning how to aggregate information of\nmultiple identities, which is usually disregarded by other methods in the\nliterature. It achieves state-of-the-art results on the ForgeryNet dataset with\nan improvement of up to 14% AUC in videos containing multiple people and\ndemonstrates ample generalization capabilities in cross-forgery and\ncross-dataset settings. The code is publicly available at\nhttps://github.com/davide-coccomini/MINTIME-Multi-Identity-size-iNvariant-TIMEsformer-for-Video-Deepfake-Detection",
    "descriptor": "",
    "authors": [
      "Davide Alessandro Coccomini",
      "Giorgos Kordopatis Zilos",
      "Giuseppe Amato",
      "Roberto Caldelli",
      "Fabrizio Falchi",
      "Symeon Papadopoulos",
      "Claudio Gennaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10996"
  },
  {
    "id": "arXiv:2211.10997",
    "title": "Embracing Ambiguity: Improving Similarity-oriented Tasks with Contextual  Synonym Knowledge",
    "abstract": "Contextual synonym knowledge is crucial for those similarity-oriented tasks\nwhose core challenge lies in capturing semantic similarity between entities in\ntheir contexts, such as entity linking and entity matching. However, most\nPre-trained Language Models (PLMs) lack synonym knowledge due to inherent\nlimitations of their pre-training objectives such as masked language modeling\n(MLM). Existing works which inject synonym knowledge into PLMs often suffer\nfrom two severe problems: (i) Neglecting the ambiguity of synonyms, and (ii)\nUndermining semantic understanding of original PLMs, which is caused by\ninconsistency between the exact semantic similarity of the synonyms and the\nbroad conceptual relevance learned from the original corpus. To address these\nissues, we propose PICSO, a flexible framework that supports the injection of\ncontextual synonym knowledge from multiple domains into PLMs via a novel\nentity-aware Adapter which focuses on the semantics of the entities (synonyms)\nin the contexts. Meanwhile, PICSO stores the synonym knowledge in additional\nparameters of the Adapter structure, which prevents it from corrupting the\nsemantic understanding of the original PLM. Extensive experiments demonstrate\nthat PICSO can dramatically outperform the original PLMs and the other\nknowledge and synonym injection models on four different similarity-oriented\ntasks. In addition, experiments on GLUE prove that PICSO also benefits general\nnatural language understanding tasks. Codes and data will be public.",
    "descriptor": "\nComments: This work has been submitted to the Neurocomputing. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Yangning Li",
      "Jiaoyan Chen",
      "Yinghui Li",
      "Tianyu Yu",
      "Xi Chen",
      "Hai-Tao Zheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.10997"
  },
  {
    "id": "arXiv:2211.10999",
    "title": "LA-VocE: Low-SNR Audio-visual Speech Enhancement using Neural Vocoders",
    "abstract": "Audio-visual speech enhancement aims to extract clean speech from a noisy\nenvironment by leveraging not only the audio itself but also the target\nspeaker's lip movements. This approach has been shown to yield improvements\nover audio-only speech enhancement, particularly for the removal of interfering\nspeech. Despite recent advances in speech synthesis, most audio-visual\napproaches continue to use spectral mapping/masking to reproduce the clean\naudio, often resulting in visual backbones added to existing speech enhancement\narchitectures. In this work, we propose LA-VocE, a new two-stage approach that\npredicts mel-spectrograms from noisy audio-visual speech via a\ntransformer-based architecture, and then converts them into waveform audio\nusing a neural vocoder (HiFi-GAN). We train and evaluate our framework on\nthousands of speakers and 11+ different languages, and study our model's\nability to adapt to different levels of background noise and speech\ninterference. Our experiments show that LA-VocE outperforms existing methods\naccording to multiple metrics, particularly under very noisy scenarios.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Rodrigo Mira",
      "Buye Xu",
      "Jacob Donley",
      "Anurag Kumar",
      "Stavros Petridis",
      "Vamsi Krishna Ithapu",
      "Maja Pantic"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.10999"
  },
  {
    "id": "arXiv:2211.11000",
    "title": "Topological Distance Games",
    "abstract": "We introduce a class of strategic games in which agents are assigned to nodes\nof a topology graph and the utility of an agent depends on both the agent's\ninherent utilities for other agents as well as her distance from these agents\non the topology graph. This model of topological distance games (TDGs) offers\nan appealing combination of important aspects of several prominent settings in\ncoalition formation, including (additively separable) hedonic games, social\ndistance games, and Schelling games. We study the existence and complexity of\nstable outcomes in TDGs -- for instance, while a jump stable assignment may not\nexist in general, we show that the existence is guaranteed in several special\ncases. We also investigate the dynamics induced by performing beneficial jumps.",
    "descriptor": "\nComments: Appears in the 37th AAAI Conference on Artificial Intelligence (AAAI), 2023\n",
    "authors": [
      "Martin Bullinger",
      "Warut Suksompong"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.11000"
  },
  {
    "id": "arXiv:2211.11001",
    "title": "F2SD: A dataset for end-to-end group detection algorithms",
    "abstract": "The lack of large-scale datasets has been impeding the advance of deep\nlearning approaches to the problem of F-formation detection. Moreover, most\nresearch works on this problem rely on input sensor signals of object location\nand orientation rather than image signals. To address this, we develop a new,\nlarge-scale dataset of simulated images for F-formation detection, called\nF-formation Simulation Dataset (F2SD). F2SD contains nearly 60,000 images\nsimulated from GTA-5, with bounding boxes and orientation information on\nimages, making it useful for a wide variety of modelling approaches. It is also\ncloser to practical scenarios, where three-dimensional location and orientation\ninformation are costly to record. It is challenging to construct such a\nlarge-scale simulated dataset while keeping it realistic. Furthermore, the\navailable research utilizes conventional methods to detect groups. They do not\ndetect groups directly from the image. In this work, we propose (1) a\nlarge-scale simulation dataset F2SD and a pipeline for F-formation simulation,\n(2) a first-ever end-to-end baseline model for the task, and experiments on our\nsimulation dataset.",
    "descriptor": "\nComments: Accepted at ICMV 2022\n",
    "authors": [
      "Giang Hoang",
      "Tuan Nguyen Dinh",
      "Tung Cao Hoang",
      "Son Le Duy",
      "Keisuke Hihara",
      "Yumeka Utada",
      "Akihiko Torii",
      "Naoki Izumi",
      "Long Tran Quoc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11001"
  },
  {
    "id": "arXiv:2211.11004",
    "title": "Minimizing the Accumulated Trajectory Error to Improve Dataset  Distillation",
    "abstract": "Model-based deep learning has achieved astounding successes due in part to\nthe availability of large-scale realworld data. However, processing such\nmassive amounts of data comes at a considerable cost in terms of computations,\nstorage, training and the search for good neural architectures. Dataset\ndistillation has thus recently come to the fore. This paradigm involves\ndistilling information from large real-world datasets into tiny and compact\nsynthetic datasets such that processing the latter yields similar performances\nas the former. State-of-the-art methods primarily rely on learning the\nsynthetic dataset by matching the gradients obtained during training between\nthe real and synthetic data. However, these gradient-matching methods suffer\nfrom the accumulated trajectory error caused by the discrepancy between the\ndistillation and subsequent evaluation. To alleviate the adverse impact of this\naccumulated trajectory error, we propose a novel approach that encourages the\noptimization algorithm to seek a flat trajectory. We show that the weights\ntrained on synthetic data are robust against the accumulated errors\nperturbations with the regularization towards the flat trajectory. Our method,\ncalled Flat Trajectory Distillation (FTD), is shown to boost the performance of\ngradient-matching methods by up to 4.7% on a subset of images of the ImageNet\ndataset with higher resolution images. We also validate the effectiveness and\ngeneralizability of our method with datasets of different resolutions and\ndemonstrate its applicability to neural architecture search.",
    "descriptor": "",
    "authors": [
      "Jiawei Du",
      "Yidi Jiang",
      "Vincent T. F. Tan",
      "Joey Tianyi Zhou",
      "Haizhou Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11004"
  },
  {
    "id": "arXiv:2211.11009",
    "title": "Optimal resizable arrays",
    "abstract": "A \\emph{resizable array} is an array that can \\emph{grow} and \\emph{shrink}\nby the addition or removal of items from its end, or both its ends, while still\nsupporting constant-time \\emph{access} to each item stored in the array given\nits \\emph{index}. Since the size of an array, i.e., the number of items in it,\nvaries over time, space-efficient maintenance of a resizable array requires\ndynamic memory management. A standard doubling technique allows the maintenance\nof an array of size~$N$ using only $O(N)$ space, with $O(1)$ amortized time, or\neven $O(1)$ worst-case time, per operation. Sitarski and Brodnik et al.\\\ndescribe much better solutions that maintain a resizable array of size~$N$\nusing only $N+O(\\sqrt{N})$ space, still with $O(1)$ time per operation. Brodnik\net al.\\ give a simple proof that this is best possible.\nWe distinguish between the space needed for \\emph{storing} a resizable array,\nand accessing its items, and the \\emph{temporary} space that may be needed\nwhile growing or shrinking the array. For every integer $r\\ge 2$, we show that\n$N+O(N^{1/r})$ space is sufficient for storing and accessing an array of\nsize~$N$, if $N+O(N^{1-1/r})$ space can be used briefly during grow and shrink\noperations. Accessing an item by index takes $O(1)$ worst-case time while grow\nand shrink operations take $O(r)$ amortized time. Using an exact analysis of a\n\\emph{growth game}, we show that for any data structure from a wide class of\ndata structures that uses only $N+O(N^{1/r})$ space to store the array, the\namortized cost of grow is $\\Omega(r)$, even if only grow and access operations\nare allowed. The time for grow and shrink operations cannot be made worst-case,\nunless $r=2$.",
    "descriptor": "\nComments: To appear in SOSA 2023\n",
    "authors": [
      "Robert E. Tarjan",
      "Uri Zwick"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.11009"
  },
  {
    "id": "arXiv:2211.11010",
    "title": "Revisiting Color-Event based Tracking: A Unified Network, Dataset, and  Metric",
    "abstract": "Combining the Color and Event cameras (also called Dynamic Vision Sensors,\nDVS) for robust object tracking is a newly emerging research topic in recent\nyears. Existing color-event tracking framework usually contains multiple\nscattered modules which may lead to low efficiency and high computational\ncomplexity, including feature extraction, fusion, matching, interactive\nlearning, etc. In this paper, we propose a single-stage backbone network for\nColor-Event Unified Tracking (CEUTrack), which achieves the above functions\nsimultaneously. Given the event points and RGB frames, we first transform the\npoints into voxels and crop the template and search regions for both\nmodalities, respectively. Then, these regions are projected into tokens and\nparallelly fed into the unified Transformer backbone network. The output\nfeatures will be fed into a tracking head for target object localization. Our\nproposed CEUTrack is simple, effective, and efficient, which achieves over 75\nFPS and new SOTA performance. To better validate the effectiveness of our model\nand address the data deficiency of this task, we also propose a generic and\nlarge-scale benchmark dataset for color-event tracking, termed COESOT, which\ncontains 90 categories and 1354 video sequences. Additionally, a new evaluation\nmetric named BOC is proposed in our evaluation toolkit to evaluate the\nprominence with respect to the baseline methods. We hope the newly proposed\nmethod, dataset, and evaluation metric provide a better platform for\ncolor-event-based tracking. The dataset, toolkit, and source code will be\nreleased on: \\url{https://github.com/Event-AHU/COESOT}.",
    "descriptor": "",
    "authors": [
      "Chuanming Tang",
      "Xiao Wang",
      "Ju Huang",
      "Bo Jiang",
      "Lin Zhu",
      "Jianlin Zhang",
      "Yaowei Wang",
      "Yonghong Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.11010"
  },
  {
    "id": "arXiv:2211.11013",
    "title": "Machine Learning Methods for Anomaly Detection in Nuclear Power Plant  Power Transformers",
    "abstract": "Power transformers are an important component of a nuclear power plant (NPP).\nCurrently, the NPP operates a lot of power transformers with extended service\nlife, which exceeds the designated 25 years. Due to the extension of the\nservice life, the task of monitoring the technical condition of power\ntransformers becomes urgent. An important method for monitoring power\ntransformers is Chromatographic Analysis of Dissolved Gas. It is based on the\nprinciple of controlling the concentration of gases dissolved in transformer\noil. The appearance of almost any type of defect in equipment is accompanied by\nthe formation of gases that dissolve in oil, and specific types of defects\ngenerate their gases in different quantities. At present, at NPPs, the\nmonitoring systems for transformer equipment use predefined control limits for\nthe concentration of dissolved gases in the oil. This study describes the\nstages of developing an algorithm to detect defects and faults in transformers\nautomatically using machine learning and data analysis methods. Among machine\nlearning models, we trained Logistic Regression, Decision Trees, Random Forest,\nGradient Boosting, Neural Networks. The best of them were then combined into an\nensemble (StackingClassifier) showing F1-score of 0.974 on a test sample. To\ndevelop mathematical models, we used data on the state of transformers,\ncontaining time series with values of gas concentrations (H2, CO, C2H4, C2H2).\nThe datasets were labeled and contained four operating modes: normal mode,\npartial discharge, low energy discharge, low-temperature overheating.",
    "descriptor": "\nComments: 9 pages, 5 figures, 4 tables, 33 references\n",
    "authors": [
      "Iurii Katser",
      "Dmitriy Raspopov",
      "Vyacheslav Kozitsin",
      "Maxim Mezhov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.11013"
  },
  {
    "id": "arXiv:2211.11014",
    "title": "Understanding and Improving Knowledge Distillation for  Quantization-Aware Training of Large Transformer Encoders",
    "abstract": "Knowledge distillation (KD) has been a ubiquitous method for model\ncompression to strengthen the capability of a lightweight model with the\ntransferred knowledge from the teacher. In particular, KD has been employed in\nquantization-aware training (QAT) of Transformer encoders like BERT to improve\nthe accuracy of the student model with the reduced-precision weight parameters.\nHowever, little is understood about which of the various KD approaches best\nfits the QAT of Transformers. In this work, we provide an in-depth analysis of\nthe mechanism of KD on attention recovery of quantized large Transformers. In\nparticular, we reveal that the previously adopted MSE loss on the attention\nscore is insufficient for recovering the self-attention information. Therefore,\nwe propose two KD methods; attention-map and attention-output losses.\nFurthermore, we explore the unification of both losses to address\ntask-dependent preference between attention-map and output losses. The\nexperimental results on various Transformer encoder models demonstrate that the\nproposed KD methods achieve state-of-the-art accuracy for QAT with sub-2-bit\nweight quantization.",
    "descriptor": "\nComments: EMNLP 2022 Main Track Long Paper\n",
    "authors": [
      "Minsoo Kim",
      "Sihwa Lee",
      "Sukjin Hong",
      "Du-Seong Chang",
      "Jungwook Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11014"
  },
  {
    "id": "arXiv:2211.11018",
    "title": "MagicVideo: Efficient Video Generation With Latent Diffusion Models",
    "abstract": "We present an efficient text-to-video generation framework based on latent\ndiffusion models, termed MagicVideo. Given a text description, MagicVideo can\ngenerate photo-realistic video clips with high relevance to the text content.\nWith the proposed efficient latent 3D U-Net design, MagicVideo can generate\nvideo clips with 256x256 spatial resolution on a single GPU card, which is 64x\nfaster than the recent video diffusion model (VDM). Unlike previous works that\ntrain video generation from scratch in the RGB space, we propose to generate\nvideo clips in a low-dimensional latent space. We further utilize all the\nconvolution operator weights of pre-trained text-to-image generative U-Net\nmodels for faster training. To achieve this, we introduce two new designs to\nadapt the U-Net decoder to video data: a framewise lightweight adaptor for the\nimage-to-video distribution adjustment and a directed temporal attention module\nto capture frame temporal dependencies. The whole generation process is within\nthe low-dimension latent space of a pre-trained variation auto-encoder. We\ndemonstrate that MagicVideo can generate both realistic video content and\nimaginary content in a photo-realistic style with a trade-off in terms of\nquality and computational cost. Refer to https://magicvideo.github.io/# for\nmore examples.",
    "descriptor": "",
    "authors": [
      "Daquan Zhou",
      "Weimin Wang",
      "Hanshu Yan",
      "Weiwei Lv",
      "Yizhe Zhu",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11018"
  },
  {
    "id": "arXiv:2211.11024",
    "title": "Deterministic Identification For MC ISI-Poisson Channel",
    "abstract": "Several applications of molecular communications (MC) feature an alarm-prompt\nbehavior for which the prevalent Shannon capacity may not be the appropriate\nperformance metric. The identification capacity as an alternative measure for\nsuch systems has been motivated and established in the literature. In this\npaper, we study deterministic identification (DI) for the discrete-time\n\\emph{Poisson} channel (DTPC) with inter-symbol interference (ISI) where the\ntransmitter is restricted to an average and a peak molecule release rate\nconstraint. Such a channel serves as a model for diffusive MC systems featuring\nlong channel impulse responses and employing molecule counting receivers. We\nderive lower and upper bounds on the DI capacity of the DTPC with ISI when the\nnumber of ISI channel taps $K$ may grow with the codeword length $n$ (e.g., due\nto increasing symbol rate). As a key finding, we establish that for\ndeterministic encoding, the codebook size scales as $2^{(n\\log n)R}$ assuming\nthat the number of ISI channel taps scales as $K = 2^{\\kappa \\log n}$, where\n$R$ is the coding rate and $\\kappa$ is the ISI rate. Moreover, we show that\noptimizing $\\kappa$ leads to an effective identification rate [bits/s] that\nscales linearly with $n$, which is in contrast to the typical transmission rate\n[bits/s] that is independent of $n$.",
    "descriptor": "\nComments: 29 pages, 3 figures. arXiv admin note: substantial text overlap with arXiv:2203.02784\n",
    "authors": [
      "Mohammad Javad Salariseddigh",
      "Vahid Jamali",
      "Uzi Pereg",
      "Holger Boche",
      "Christian Deppe",
      "Robert Schober"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.11024"
  },
  {
    "id": "arXiv:2211.11027",
    "title": "Safe Reinforcement Learning using Data-Driven Predictive Control",
    "abstract": "Reinforcement learning (RL) algorithms can achieve state-of-the-art\nperformance in decision-making and continuous control tasks. However, applying\nRL algorithms on safety-critical systems still needs to be well justified due\nto the exploration nature of many RL algorithms, especially when the model of\nthe robot and the environment are unknown. To address this challenge, we\npropose a data-driven safety layer that acts as a filter for unsafe actions.\nThe safety layer uses a data-driven predictive controller to enforce safety\nguarantees for RL policies during training and after deployment. The RL agent\nproposes an action that is verified by computing the data-driven reachability\nanalysis. If there is an intersection between the reachable set of the robot\nusing the proposed action, we call the data-driven predictive controller to\nfind the closest safe action to the proposed unsafe action. The safety layer\npenalizes the RL agent if the proposed action is unsafe and replaces it with\nthe closest safe one. In the simulation, we show that our method outperforms\nstate-of-the-art safe RL methods on the robotics navigation problem for a\nTurtlebot 3 in Gazebo and a quadrotor in Unreal Engine 4 (UE4).",
    "descriptor": "",
    "authors": [
      "Mahmoud Selim",
      "Amr Alanwar",
      "M. Watheq El-Kharashi",
      "Hazem M. Abbas",
      "Karl H. Johansson"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.11027"
  },
  {
    "id": "arXiv:2211.11030",
    "title": "Adversarial Cheap Talk",
    "abstract": "Adversarial attacks in reinforcement learning (RL) often assume\nhighly-privileged access to the victim's parameters, environment, or data.\nInstead, this paper proposes a novel adversarial setting called a Cheap Talk\nMDP in which an Adversary can merely append deterministic messages to the\nVictim's observation, resulting in a minimal range of influence. The Adversary\ncannot occlude ground truth, influence underlying environment dynamics or\nreward signals, introduce non-stationarity, add stochasticity, see the Victim's\nactions, or access their parameters. Additionally, we present a simple\nmeta-learning algorithm called Adversarial Cheap Talk (ACT) to train\nAdversaries in this setting. We demonstrate that an Adversary trained with ACT\ncan still significantly influence the Victim's training and testing\nperformance, despite the highly constrained setting. Affecting train-time\nperformance reveals a new attack vector and provides insight into the success\nand failure modes of existing RL algorithms. More specifically, we show that an\nACT Adversary is capable of harming performance by interfering with the\nlearner's function approximation, or instead helping the Victim's performance\nby outputting useful features. Finally, we show that an ACT Adversary can\nmanipulate messages during train-time to directly and arbitrarily control the\nVictim at test-time.",
    "descriptor": "",
    "authors": [
      "Chris Lu",
      "Timon Willi",
      "Alistair Letcher",
      "Jakob Foerster"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.11030"
  },
  {
    "id": "arXiv:2211.11031",
    "title": "Aging with GRACE: Lifelong Model Editing with Discrete Key-Value  Adaptors",
    "abstract": "Large pre-trained models decay over long-term deployment as input\ndistributions shift, user requirements change, or crucial knowledge gaps are\ndiscovered. Recently, model editors have been proposed to modify a model's\nbehavior by adjusting its weights during deployment. However, when editing the\nsame model multiple times, these approaches quickly decay a model's performance\non upstream data and forget how to fix previous errors. We propose and study a\nnovel Lifelong Model Editing setting, where streaming errors are identified for\na deployed model and we update the model to correct its predictions without\ninfluencing unrelated inputs without access to training edits, exogenous\ndatasets, or any upstream data for the edited model. To approach this problem,\nwe introduce General Retrieval Adaptors for Continual Editing, or GRACE, which\nlearns to cache a chosen layer's activations in an adaptive codebook as edits\nstream in, leaving original model weights frozen. GRACE can thus edit models\nthousands of times in a row using only streaming errors, while minimally\ninfluencing unrelated inputs. Experimentally, we show that GRACE improves over\nrecent model editors and generalizes to unseen inputs. Our code is available at\nhttps://www.github.com/thartvigsen/grace.",
    "descriptor": "",
    "authors": [
      "Thomas Hartvigsen",
      "Swami Sankaranarayanan",
      "Hamid Palangi",
      "Yoon Kim",
      "Marzyeh Ghassemi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11031"
  },
  {
    "id": "arXiv:2211.11033",
    "title": "On the Complexity of Bayesian Generalization",
    "abstract": "We consider concept generalization at a large scale in the diverse and\nnatural visual spectrum. Established computational modes (i.e., rule-based or\nsimilarity-based) are primarily studied isolated and focus on confined and\nabstract problem spaces. In this work, we study these two modes when the\nproblem space scales up, and the $complexity$ of concepts becomes diverse.\nSpecifically, at the $representational \\ level$, we seek to answer how the\ncomplexity varies when a visual concept is mapped to the representation space.\nPrior psychology literature has shown that two types of complexities (i.e.,\nsubjective complexity and visual complexity) (Griffiths and Tenenbaum, 2003)\nbuild an inverted-U relation (Donderi, 2006; Sun and Firestone, 2021).\nLeveraging Representativeness of Attribute (RoA), we computationally confirm\nthe following observation: Models use attributes with high RoA to describe\nvisual concepts, and the description length falls in an inverted-U relation\nwith the increment in visual complexity. At the $computational \\ level$, we aim\nto answer how the complexity of representation affects the shift between the\nrule- and similarity-based generalization. We hypothesize that\ncategory-conditioned visual modeling estimates the co-occurrence frequency\nbetween visual and categorical attributes, thus potentially serving as the\nprior for the natural visual world. Experimental results show that\nrepresentations with relatively high subjective complexity outperform those\nwith relatively low subjective complexity in the rule-based generalization,\nwhile the trend is the opposite in the similarity-based generalization.",
    "descriptor": "",
    "authors": [
      "Yu-Zhe Shi",
      "Manjie Xu",
      "John E. Hopcroft",
      "Kun He",
      "Joshua B. Tenenbaum",
      "Song-Chun Zhu",
      "Ying Nian Wu",
      "Wenjuan Han",
      "Yixin Zhu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11033"
  },
  {
    "id": "arXiv:2211.11035",
    "title": "Heterogenous Ensemble of Models for Molecular Property Prediction",
    "abstract": "Previous works have demonstrated the importance of considering different\nmodalities on molecules, each of which provide a varied granularity of\ninformation for downstream property prediction tasks. Our method combines\nvariants of the recent TransformerM architecture with Transformer, GNN, and\nResNet backbone architectures. Models are trained on the 2D data, 3D data, and\nimage modalities of molecular graphs. We ensemble these models with a\nHuberRegressor. The models are trained on 4 different train/validation splits\nof the original train + valid datasets. This yields a winning solution to the\n2\\textsuperscript{nd} edition of the OGB Large-Scale Challenge (2022) on the\nPCQM4Mv2 molecular property prediction dataset. Our proposed method achieves a\ntest-challenge MAE of $0.0723$ and a validation MAE of $0.07145$. Total\ninference time for our solution is less than 2 hours. We open-source our code\nat https://github.com/jfpuget/NVIDIA-PCQM4Mv2.",
    "descriptor": "",
    "authors": [
      "Sajad Darabi",
      "Shayan Fazeli",
      "Jiwei Liu",
      "Alexandre Milesi",
      "Pawel Morkisz",
      "Jean-Fran\u00e7ois Puget",
      "Gilberto Titericz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.11035"
  },
  {
    "id": "arXiv:2211.11038",
    "title": "Mission-Aware Value of Information Censoring for Distributed Filtering",
    "abstract": "In this paper, we study the problem of distributed estimation with an\nemphasis on communication-efficiency. The proposed algorithm is based on a\nwindowed maximum a posteriori (MAP) estimation problem, wherein each agent in\nthe network locally computes a Kalman-like filter estimate that approximates\nthe centralized MAP solution. Information sharing among agents is restricted to\ntheir neighbors only, with guarantees on overall estimate consistency provided\nvia logarithmic opinion pooling. The problem is efficiently distributed using\nthe alternating direction method of multipliers (ADMM), whose overall\ncommunication usage is further reduced by a value of information (VoI)\ncensoring mechanism, wherein agents only transmit their primal-dual iterates\nwhen deemed valuable to do so. The proposed censoring mechanism is\nmission-aware, enabling a globally efficient use of communication resources\nwhile guaranteeing possibly different local estimation requirements. To\nillustrate the validity of the approach we perform simulations in a target\ntracking scenario.",
    "descriptor": "",
    "authors": [
      "Miguel Calvo-Fullana",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.11038"
  },
  {
    "id": "arXiv:2211.11039",
    "title": "Deep Composite Face Image Attacks: Generation, Vulnerability and  Detection",
    "abstract": "Face manipulation attacks have drawn the attention of biometric researchers\nbecause of their vulnerability to Face Recognition Systems (FRS). This paper\nproposes a novel scheme to generate Composite Face Image Attacks (CFIA) based\non the Generative Adversarial Networks (GANs). Given the face images from\ncontributory data subjects, the proposed CFIA method will independently\ngenerate the segmented facial attributes, then blend them using transparent\nmasks to generate the CFIA samples. { The primary motivation for CFIA is to\nutilize deep learning to generate facial attribute-based composite attacks,\nwhich has been explored relatively less in the current literature.} We generate\n$14$ different combinations of facial attributes resulting in $14$ unique CFIA\nsamples for each pair of contributory data subjects. Extensive experiments are\ncarried out on our newly generated CFIA dataset consisting of 1000 unique\nidentities with 2000 bona fide samples and 14000 CFIA samples, thus resulting\nin an overall 16000 face image samples. We perform a sequence of experiments to\nbenchmark the vulnerability of CFIA to automatic FRS (based on both\ndeep-learning and commercial-off-the-shelf (COTS). We introduced a new metric\nnamed Generalized Morphing Attack Potential (GMAP) to benchmark the\nvulnerability effectively. Additional experiments are performed to compute the\nperceptual quality of the generated CFIA samples. Finally, the CFIA detection\nperformance is presented using three different Face Morphing Attack Detection\n(MAD) algorithms. The proposed CFIA method indicates good perceptual quality\nbased on the obtained results. Further, { FRS is vulnerable to CFIA} (much\nhigher than SOTA), making it difficult to detect by human observers and\nautomatic detection algorithms. Lastly, we performed experiments to detect the\nCFIA samples using three different detection techniques automatically.",
    "descriptor": "",
    "authors": [
      "Jag Mohan Singh",
      "Raghavendra Ramachandra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11039"
  },
  {
    "id": "arXiv:2211.11040",
    "title": "PointResNet: Residual Network for 3D Point Cloud Segmentation and  Classification",
    "abstract": "Point cloud segmentation and classification are some of the primary tasks in\n3D computer vision with applications ranging from augmented reality to\nrobotics. However, processing point clouds using deep learning-based algorithms\nis quite challenging due to the irregular point formats. Voxelization or 3D\ngrid-based representation are different ways of applying deep neural networks\nto this problem. In this paper, we propose PointResNet, a residual block-based\napproach. Our model directly processes the 3D points, using a deep neural\nnetwork for the segmentation and classification tasks. The main components of\nthe architecture are: 1) residual blocks and 2) multi-layered perceptron (MLP).\nWe show that it preserves profound features and structural information, which\nare useful for segmentation and classification tasks. The experimental\nevaluations demonstrate that the proposed model produces the best results for\nsegmentation and comparable results for classification in comparison to the\nconventional baselines.",
    "descriptor": "\nComments: Paper Under Review at IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2023\n",
    "authors": [
      "Aadesh Desai",
      "Saagar Parikh",
      "Seema Kumari",
      "Shanmuganathan Raman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11040"
  },
  {
    "id": "arXiv:2211.11041",
    "title": "Pragmatic Constraint on Distributional Semantics",
    "abstract": "This paper studies the limits of language models' statistical learning in the\ncontext of Zipf's law. First, we demonstrate that Zipf-law token distribution\nemerges irrespective of the chosen tokenization. Second, we show that Zipf\ndistribution is characterized by two distinct groups of tokens that differ both\nin terms of their frequency and their semantics. Namely, the tokens that have a\none-to-one correspondence with one semantic concept have different statistical\nproperties than those with semantic ambiguity. Finally, we demonstrate how\nthese properties interfere with statistical learning procedures motivated by\ndistributional semantics.",
    "descriptor": "",
    "authors": [
      "Elizaveta Zhemchuzhina",
      "Nikolai Filippov",
      "Ivan P. Yamshchikov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.11041"
  },
  {
    "id": "arXiv:2211.11048",
    "title": "Discretisations and Preconditioners for Magnetohydrodynamics Models",
    "abstract": "The magnetohydrodynamics (MHD) equations are generally known to be difficult\nto solve numerically, due to their highly nonlinear structure and the strong\ncoupling between the electromagnetic and hydrodynamic variables, especially for\nhigh Reynolds and coupling numbers.\nIn the first part of this work, we present a scalable augmented Lagrangian\npreconditioner for a finite element discretisation of the\n$\\mathbf{B}$-$\\mathbf{E}$ formulation of the incompressible viscoresistive MHD\nequations. For stationary problems, our solver achieves robust performance with\nrespect to the Reynolds and coupling numbers in two dimensions and good results\nin three dimensions. Our approach relies on specialised parameter-robust\nmultigrid methods for the hydrodynamic and electromagnetic blocks. The scheme\nensures exactly divergence-free approximations of both the velocity and the\nmagnetic field up to solver tolerances.\nIn the second part, we focus on incompressible, resistive Hall MHD models and\nderive structure-preserving finite element methods for these equations. We\npresent a variational formulation of Hall MHD that enforces the magnetic\nGauss's law precisely (up to solver tolerances) and prove the well-posedness of\na Picard linearisation. For the transient problem, we present time\ndiscretisations that preserve the energy and magnetic and hybrid helicity\nprecisely in the ideal limit for two types of boundary conditions.\nIn the third part, we investigate anisothermal MHD models. We start by\nperforming a bifurcation analysis for a magnetic Rayleigh--B\\'enard problem at\na high coupling number $S=1{,}000$ by choosing the Rayleigh number in the range\nbetween 0 and $100{,}000$ as the bifurcation parameter. We study the effect of\nthe coupling number on the bifurcation diagram and outline how we create\ninitial guesses to obtain complex solution patterns and disconnected branches\nfor high coupling numbers.",
    "descriptor": "\nComments: Doctoral thesis, Mathematical Institute, University of Oxford. 174 pages\n",
    "authors": [
      "Fabian Laakmann"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.11048"
  },
  {
    "id": "arXiv:2211.11049",
    "title": "Explaining (Sarcastic) Utterances to Enhance Affect Understanding in  Multimodal Dialogues",
    "abstract": "Conversations emerge as the primary media for exchanging ideas and\nconceptions. From the listener's perspective, identifying various affective\nqualities, such as sarcasm, humour, and emotions, is paramount for\ncomprehending the true connotation of the emitted utterance. However, one of\nthe major hurdles faced in learning these affect dimensions is the presence of\nfigurative language, viz. irony, metaphor, or sarcasm. We hypothesize that any\ndetection system constituting the exhaustive and explicit presentation of the\nemitted utterance would improve the overall comprehension of the dialogue. To\nthis end, we explore the task of Sarcasm Explanation in Dialogues, which aims\nto unfold the hidden irony behind sarcastic utterances. We propose MOSES, a\ndeep neural network, which takes a multimodal (sarcastic) dialogue instance as\nan input and generates a natural language sentence as its explanation.\nSubsequently, we leverage the generated explanation for various natural\nlanguage understanding tasks in a conversational dialogue setup, such as\nsarcasm detection, humour identification, and emotion recognition. Our\nevaluation shows that MOSES outperforms the state-of-the-art system for SED by\nan average of ~2% on different evaluation metrics, such as ROUGE, BLEU, and\nMETEOR. Further, we observe that leveraging the generated explanation advances\nthree downstream tasks for affect classification - an average improvement of\n~14% F1-score in the sarcasm detection task and ~2% in the humour\nidentification and emotion recognition task. We also perform extensive analyses\nto assess the quality of the results.",
    "descriptor": "\nComments: Accepted at AAAI 2023. 11 Pages; 14 Tables; 3 Figures\n",
    "authors": [
      "Shivani Kumar",
      "Ishani Mondal",
      "Md Shad Akhtar",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11049"
  },
  {
    "id": "arXiv:2211.11052",
    "title": "Convexifying Transformers: Improving optimization and understanding of  transformer networks",
    "abstract": "Understanding the fundamental mechanism behind the success of transformer\nnetworks is still an open problem in the deep learning literature. Although\ntheir remarkable performance has been mostly attributed to the self-attention\nmechanism, the literature still lacks a solid analysis of these networks and\ninterpretation of the functions learned by them. To this end, we study the\ntraining problem of attention/transformer networks and introduce a novel convex\nanalytic approach to improve the understanding and optimization of these\nnetworks. Particularly, we first introduce a convex alternative to the\nself-attention mechanism and reformulate the regularized training problem of\ntransformer networks with our alternative convex attention. Then, we cast the\nreformulation as a convex optimization problem that is interpretable and easier\nto optimize. Moreover, as a byproduct of our convex analysis, we reveal an\nimplicit regularization mechanism, which promotes sparsity across tokens.\nTherefore, we not only improve the optimization of attention/transformer\nnetworks but also provide a solid theoretical understanding of the functions\nlearned by them. We also demonstrate the effectiveness of our theory through\nseveral numerical experiments.",
    "descriptor": "",
    "authors": [
      "Tolga Ergen",
      "Behnam Neyshabur",
      "Harsh Mehta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.11052"
  },
  {
    "id": "arXiv:2211.11053",
    "title": "Continuous Time-Delay Estimation From Sampled Measurements",
    "abstract": "An algorithm for continuous time-delay estimation from sampled output data\nand known input of finite energy is presented. The continuous time-delay\nmodeling allows for the estimation of subsample delays. The proposed estimation\nalgorithm consists of two steps. First, the continuous Laguerre spectrum of the\noutput signal is estimated from discrete-time (sampled) noisy measurements.\nSecond, an estimate of the delay value is obtained in Laguerre domain given a\ncontinuous-time description of the input. The second step of the algorithm is\nshown to be intrinsically biased, the bias sources are established, and the\nbias itself is modeled. The proposed delay estimation approach is compared in a\nMonte-Carlo simulation with state-of-the-art methods implemented in time,\nfrequency, and Laguerre domain demonstrating comparable or higher accuracy for\nthe considered case.",
    "descriptor": "",
    "authors": [
      "Mohamed Abdalmoaty",
      "Alexander Medvedev"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.11053"
  },
  {
    "id": "arXiv:2211.11056",
    "title": "Safe Control Under Input Limits with Neural Control Barrier Functions",
    "abstract": "We propose new methods to synthesize control barrier function (CBF)-based\nsafe controllers that avoid input saturation, which can cause safety\nviolations. In particular, our method is created for high-dimensional, general\nnonlinear systems, for which such tools are scarce. We leverage techniques from\nmachine learning, like neural networks and deep learning, to simplify this\nchallenging problem in nonlinear control design. The method consists of a\nlearner-critic architecture, in which the critic gives counterexamples of input\nsaturation and the learner optimizes a neural CBF to eliminate those\ncounterexamples. We provide empirical results on a 10D state, 4D input\nquadcopter-pendulum system. Our learned CBF avoids input saturation and\nmaintains safety over nearly 100% of trials.",
    "descriptor": "\nComments: CORL 2022\n",
    "authors": [
      "Simin Liu",
      "Changliu Liu",
      "John Dolan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.11056"
  },
  {
    "id": "arXiv:2211.11057",
    "title": "Semantic Similarity-Based Clustering of Findings From Security Testing  Tools",
    "abstract": "Over the last years, software development in domains with high security\ndemands transitioned from traditional methodologies to uniting modern\napproaches from software development and operations (DevOps). Key principles of\nDevOps gained more importance and are now applied to security aspects of\nsoftware development, resulting in the automation of security-enhancing\nactivities. In particular, it is common practice to use automated security\ntesting tools that generate reports after inspecting a software artifact from\nmultiple perspectives. However, this raises the challenge of generating\nduplicate security findings. To identify these duplicate findings manually, a\nsecurity expert has to invest resources like time, effort, and knowledge. A\npartial automation of this process could reduce the analysis effort, encourage\nDevOps principles, and diminish the chance of human error. In this study, we\ninvestigated the potential of applying Natural Language Processing for\nclustering semantically similar security findings to support the identification\nof problem-specific duplicate findings. Towards this goal, we developed a web\napplication for annotating and assessing security testing tool reports and\npublished a human-annotated corpus of clustered security findings. In addition,\nwe performed a comparison of different semantic similarity techniques for\nautomatically grouping security findings. Finally, we assess the resulting\nclusters using both quantitative and qualitative evaluation methods.",
    "descriptor": "\nComments: Accepted to ICNLSP 2022\n",
    "authors": [
      "Phillip Schneider",
      "Markus Voggenreiter",
      "Abdullah Gulraiz",
      "Florian Matthes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.11057"
  },
  {
    "id": "arXiv:2211.11059",
    "title": "Coarse-to-fine Task-driven Inpainting for Geoscience Images",
    "abstract": "The processing and recognition of geoscience images have wide applications.\nMost of existing researches focus on understanding the high-quality geoscience\nimages by assuming that all the images are clear. However, in many real-world\ncases, the geoscience images might contain occlusions during the image\nacquisition. This problem actually implies the image inpainting problem in\ncomputer vision and multimedia. To the best of our knowledge, all the existing\nimage inpainting algorithms learn to repair the occluded regions for a better\nvisualization quality, they are excellent for natural images but not good\nenough for geoscience images by ignoring the geoscience related tasks. This\npaper aims to repair the occluded regions for a better geoscience task\nperformance with the advanced visualization quality simultaneously, without\nchanging the current deployed deep learning based geoscience models. Because of\nthe complex context of geoscience images, we propose a coarse-to-fine\nencoder-decoder network with coarse-to-fine adversarial context discriminators\nto reconstruct the occluded image regions. Due to the limited data of\ngeoscience images, we use a MaskMix based data augmentation method to exploit\nmore information from limited geoscience image data. The experimental results\non three public geoscience datasets for remote sensing scene recognition,\ncross-view geolocation and semantic segmentation tasks respectively show the\neffectiveness and accuracy of the proposed method.",
    "descriptor": "",
    "authors": [
      "Sun Huiming",
      "Ma Jin",
      "Guo Qing",
      "Song Shaoyue",
      "Yuewei Lin",
      "Yu Hongkai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11059"
  },
  {
    "id": "arXiv:2211.11061",
    "title": "Deep learning delay coordinate dynamics for chaotic attractors from  partial observable data",
    "abstract": "A common problem in time series analysis is to predict dynamics with only\nscalar or partial observations of the underlying dynamical system. For data on\na smooth compact manifold, Takens theorem proves a time delayed embedding of\nthe partial state is diffeomorphic to the attractor, although for chaotic and\nhighly nonlinear systems learning these delay coordinate mappings is\nchallenging. We utilize deep artificial neural networks (ANNs) to learn\ndiscrete discrete time maps and continuous time flows of the partial state.\nGiven training data for the full state, we also learn a reconstruction map.\nThus, predictions of a time series can be made from the current state and\nseveral previous observations with embedding parameters determined from time\nseries analysis. The state space for time evolution is of comparable dimension\nto reduced order manifold models. These are advantages over recurrent neural\nnetwork models, which require a high dimensional internal state or additional\nmemory terms and hyperparameters. We demonstrate the capacity of deep ANNs to\npredict chaotic behavior from a scalar observation on a manifold of dimension\nthree via the Lorenz system. We also consider multivariate observations on the\nKuramoto-Sivashinsky equation, where the observation dimension required for\naccurately reproducing dynamics increases with the manifold dimension via the\nspatial extent of the system.",
    "descriptor": "",
    "authors": [
      "Charles D. Young",
      "Michael D. Graham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2211.11061"
  },
  {
    "id": "arXiv:2211.11062",
    "title": "Patch-level Gaze Distribution Prediction for Gaze Following",
    "abstract": "Gaze following aims to predict where a person is looking in a scene, by\npredicting the target location, or indicating that the target is located\noutside the image. Recent works detect the gaze target by training a heatmap\nregression task with a pixel-wise mean-square error (MSE) loss, while\nformulating the in/out prediction task as a binary classification task. This\ntraining formulation puts a strict, pixel-level constraint in higher resolution\non the single annotation available in training, and does not consider\nannotation variance and the correlation between the two subtasks. To address\nthese issues, we introduce the patch distribution prediction (PDP) method. We\nreplace the in/out prediction branch in previous models with the PDP branch, by\npredicting a patch-level gaze distribution that also considers the outside\ncases. Experiments show that our model regularizes the MSE loss by predicting\nbetter heatmap distributions on images with larger annotation variances,\nmeanwhile bridging the gap between the target prediction and in/out prediction\nsubtasks, showing a significant improvement in performance on both subtasks on\npublic gaze following datasets.",
    "descriptor": "\nComments: Accepted to WACV 2023\n",
    "authors": [
      "Qiaomu Miao",
      "Minh Hoai",
      "Dimitris Samaras"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11062"
  },
  {
    "id": "arXiv:2211.11063",
    "title": "Probabilistic bounds on the $k-$Traveling Salesman Problem and the  Traveling Repairman Problem",
    "abstract": "The $k-$traveling salesman problem ($k$-TSP) seeks a tour of minimal length\nthat visits a subset of $k\\leq n$ points. The traveling repairman problem (TRP)\nseeks a complete tour with minimal latency. This paper provides constant-factor\nprobabilistic approximations of both problems. We first show that the optimal\nlength of the $k$-TSP path grows at a rate of\n$\\Theta\\left(k/n^{\\frac{1}{2}\\left(1+\\frac{1}{k-1}\\right)}\\right)$. The proof\nprovides a constant-factor approximation scheme, which solves a TSP in a\nhigh-concentration zone -- leveraging large deviations of local concentrations.\nThen, we show that the optimal TRP latency grows at a rate of $\\Theta(n\\sqrt\nn)$. This result extends the classical Beardwood-Halton-Hammersley theorem to\nthe TRP. Again, the proof provides a constant-factor approximation scheme,\nwhich visits zones by decreasing order of probability density. We discuss\npractical implications of this result in the design of transportation and\nlogistics systems. Finally, we propose dedicated notions of fairness --\nrandomized population-based fairness for the $k$-TSP and geographical fairness\nfor the TRP -- and give algorithms to balance efficiency and fairness.",
    "descriptor": "",
    "authors": [
      "Mo\u00efse Blanchard",
      "Alexandre Jacquillat",
      "Patrick Jaillet"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.11063"
  },
  {
    "id": "arXiv:2211.11065",
    "title": "Additional Results and Extensions for the paper \"Probabilistic bounds on  the $k-$Traveling Salesman Problem and the Traveling Repairman Problem''",
    "abstract": "This technical report provides additional results for the main paper\n``Probabilistic bounds on the $k-$Traveling Salesman Problem ($k-$TSP) and the\nTraveling Repairman Problem (TRP)''. For the $k-$TSP, we extend the\nprobabilistic bounds derived in the main paper to the case of distributions\nwith general densities. For the TRP, we propose a utility-based notion of\nfairness and derive constant-factor probabilistic bounds for this objective,\nthus extending the TRP bounds from the main paper to non-linear utilities.",
    "descriptor": "",
    "authors": [
      "Mo\u00efse Blanchard",
      "Alexandre Jacquillat",
      "Patrick Jaillet"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.11065"
  },
  {
    "id": "arXiv:2211.11066",
    "title": "Hybrid Transformer Based Feature Fusion for Self-Supervised Monocular  Depth Estimation",
    "abstract": "With an unprecedented increase in the number of agents and systems that aim\nto navigate the real world using visual cues and the rising impetus for 3D\nVision Models, the importance of depth estimation is hard to understate. While\nsupervised methods remain the gold standard in the domain, the copious amount\nof paired stereo data required to train such models makes them impractical.\nMost State of the Art (SOTA) works in the self-supervised and unsupervised\ndomain employ a ResNet-based encoder architecture to predict disparity maps\nfrom a given input image which are eventually used alongside a camera pose\nestimator to predict depth without direct supervision. The fully convolutional\nnature of ResNets makes them susceptible to capturing per-pixel local\ninformation only, which is suboptimal for depth prediction. Our key insight for\ndoing away with this bottleneck is to use Vision Transformers, which employ\nself-attention to capture the global contextual information present in an input\nimage. Our model fuses per-pixel local information learned using two fully\nconvolutional depth encoders with global contextual information learned by a\ntransformer encoder at different scales. It does so using a mask-guided\nmulti-stream convolution in the feature space to achieve state-of-the-art\nperformance on most standard benchmarks.",
    "descriptor": "\nComments: Presented at the Advances in Image Manipulation Workshop at ECCV 2022\n",
    "authors": [
      "Snehal Singh Tomar",
      "Maitreya Suin",
      "A.N. Rajagopalan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11066"
  },
  {
    "id": "arXiv:2211.11069",
    "title": "Learning Nonlinear Couplings in Network of Agents from a Single Sample  Trajectory",
    "abstract": "We consider a class of stochastic dynamical networks whose governing dynamics\ncan be modeled using a coupling function. It is shown that the dynamics of such\nnetworks can generate geometrically ergodic trajectories under some reasonable\nassumptions. We show that a general class of coupling functions can be learned\nusing only one sample trajectory from the network. This is practically\nplausible as in numerous applications it is desired to run an experiment only\nonce but for a longer period of time, rather than repeating the same experiment\nmultiple times from different initial conditions. Building upon ideas from the\nconcentration inequalities for geometrically ergodic Markov chains, we\nformulate several results about the convergence of the empirical estimator to\nthe true coupling function. Our theoretical findings are supported by extensive\nsimulation results.",
    "descriptor": "\nComments: 15 pages, 5 figures\n",
    "authors": [
      "Arash Amini",
      "Qiyu Sun",
      "Nader Motee"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2211.11069"
  },
  {
    "id": "arXiv:2211.11070",
    "title": "Who Tracks Who? An Surveillance Capitalist Examination of Commercial  Bluetooth Tracking Networks",
    "abstract": "Object and person tracking networks powered by Bluetooth and mobile devices\nhave become increasingly popular for purposes of public safety and individual\nconcerns. This essay examines popular commercial tracking networks and their\ncampaigns from Apple, Samsung and Tile with reference to surveillance\ncapitalism and digital privacy, discovering the hidden assets commodified\nthrough said networks, and their potential of turning users into unregulated\ndigital labour while leaving individual privacy at risk.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Hongrui Jin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.11070"
  },
  {
    "id": "arXiv:2211.11074",
    "title": "Overfreezing Meets Overparameterization: A Double Descent Perspective on  Transfer Learning of Deep Neural Networks",
    "abstract": "We study the generalization behavior of transfer learning of deep neural\nnetworks (DNNs). We adopt the overparameterization perspective -- featuring\ninterpolation of the training data (i.e., approximately zero train error) and\nthe double descent phenomenon -- to explain the delicate effect of the transfer\nlearning setting on generalization performance. We study how the generalization\nbehavior of transfer learning is affected by the dataset size in the source and\ntarget tasks, the number of transferred layers that are kept frozen in the\ntarget DNN training, and the similarity between the source and target tasks. We\nshow that the test error evolution during the target DNN training has a more\nsignificant double descent effect when the target training dataset is\nsufficiently large with some label noise. In addition, a larger source training\ndataset can delay the arrival to interpolation and double descent peak in the\ntarget DNN training. Moreover, we demonstrate that the number of frozen layers\ncan determine whether the transfer learning is effectively underparameterized\nor overparameterized and, in turn, this may affect the relative success or\nfailure of learning. Specifically, we show that too many frozen layers may make\na transfer from a less related source task better or on par with a transfer\nfrom a more related source task; we call this case overfreezing. We establish\nour results using image classification experiments with the residual network\n(ResNet) and vision transformer (ViT) architectures.",
    "descriptor": "",
    "authors": [
      "Yehuda Dar",
      "Lorenzo Luzi",
      "Richard G. Baraniuk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11074"
  },
  {
    "id": "arXiv:2211.11076",
    "title": "Vibration Free Flexible Object Handling with a Robot Manipulator Using  Learning Control",
    "abstract": "Many industries extensively use flexible materials. Effective approaches for\nhandling flexible objects with a robot manipulator must address residual\nvibrations. Existing solutions rely on complex models, use additional\ninstrumentation for sensing the vibrations, or do not exploit the repetitive\nnature of most industrial tasks. This paper develops an iterative learning\ncontrol approach that jointly learns model parameters and residual dynamics\nusing only the interoceptive sensors of the robot. The learned model is\nsubsequently utilized to design optimal (PTP) trajectories that accounts for\nresidual vibration, nonlinear kinematics of the manipulator and joint limits.\nWe experimentally show that the proposed approach reduces the residual\nvibrations by an order of magnitude compared with optimal vibration suppression\nusing the analytical model and threefold compared with the available\nstate-of-the-art method. These results demonstrate that effective handling of a\nflexible object does not require neither complex models nor additional\ninstrumentation.",
    "descriptor": "\nComments: Have been submitted to IFAC World Congress\n",
    "authors": [
      "Daniele Ronzani",
      "Shamil Mamedov",
      "Jan Swevers"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.11076"
  },
  {
    "id": "arXiv:2211.11077",
    "title": "A Unified Model for Tracking and Image-Video Detection Has More Power",
    "abstract": "Objection detection (OD) has been one of the most fundamental tasks in\ncomputer vision. Recent developments in deep learning have pushed the\nperformance of image OD to new heights by learning-based, data-driven\napproaches. On the other hand, video OD remains less explored, mostly due to\nmuch more expensive data annotation needs. At the same time, multi-object\ntracking (MOT) which requires reasoning about track identities and\nspatio-temporal trajectories, shares similar spirits with video OD. However,\nmost MOT datasets are class-specific (e.g., person-annotated only), which\nconstrains a model's flexibility to perform tracking on other objects. We\npropose TrIVD (Tracking and Image-Video Detection), the first framework that\nunifies image OD, video OD, and MOT within one end-to-end model. To handle the\ndiscrepancies and semantic overlaps across datasets, TrIVD formulates\ndetection/tracking as grounding and reasons about object categories via\nvisual-text alignments. The unified formulation enables cross-dataset,\nmulti-task training, and thus equips TrIVD with the ability to leverage\nframe-level features, video-level spatio-temporal relations, as well as track\nidentity associations. With such joint training, we can now extend the\nknowledge from OD data, that comes with much richer object category\nannotations, to MOT and achieve zero-shot tracking capability. Experiments\ndemonstrate that TrIVD achieves state-of-the-art performances across all\nimage/video OD and MOT tasks.",
    "descriptor": "\nComments: (13 pages, 4 figures)\n",
    "authors": [
      "Peirong Liu",
      "Rui Wang",
      "Pengchuan Zhang",
      "Omid Poursaeed",
      "Yipin Zhou",
      "Xuefei Cao",
      "Sreya Dutta Roy",
      "Ashish Shah",
      "Ser-Nam Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11077"
  },
  {
    "id": "arXiv:2211.11081",
    "title": "A Theory of Unsupervised Translation Motivated by Understanding Animal  Communication",
    "abstract": "Recent years have seen breakthroughs in neural language models that capture\nnuances of language, culture, and knowledge. Neural networks are capable of\ntranslating between languages -- in some cases even between two languages where\nthere is little or no access to parallel translations, in what is known as\nUnsupervised Machine Translation (UMT). Given this progress, it is intriguing\nto ask whether machine learning tools can ultimately enable understanding\nanimal communication, particularly that of highly intelligent animals. Our work\nis motivated by an ambitious interdisciplinary initiative, Project CETI, which\nis collecting a large corpus of sperm whale communications for machine\nanalysis.\nWe propose a theoretical framework for analyzing UMT when no parallel data\nare available and when it cannot be assumed that the source and target corpora\naddress related subject domains or posses similar linguistic structure. The\nframework requires access to a prior probability distribution that should\nassign non-zero probability to possible translations. We instantiate our\nframework with two models of language. Our analysis suggests that accuracy of\ntranslation depends on the complexity of the source language and the amount of\n``common ground'' between the source language and target prior.\nWe also prove upper bounds on the amount of data required from the source\nlanguage in the unsupervised setting as a function of the amount of data\nrequired in a hypothetical supervised setting. Surprisingly, our bounds suggest\nthat the amount of source data required for unsupervised translation is\ncomparable to the supervised setting. For one of the language models which we\nanalyze we also prove a nearly matching lower bound.\nOur analysis is purely information-theoretic and as such can inform how much\nsource data needs to be collected, but does not yield a computationally\nefficient procedure.",
    "descriptor": "",
    "authors": [
      "Shafi Goldwasser",
      "David F. Gruber",
      "Adam Tauman Kalai",
      "Orr Paradise"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11081"
  },
  {
    "id": "arXiv:2211.11082",
    "title": "DynIBaR: Neural Dynamic Image-Based Rendering",
    "abstract": "We address the problem of synthesizing novel views from a monocular video\ndepicting a complex dynamic scene. State-of-the-art methods based on temporally\nvarying Neural Radiance Fields (aka dynamic NeRFs) have shown impressive\nresults on this task. However, for long videos with complex object motions and\nuncontrolled camera trajectories, these methods can produce blurry or\ninaccurate renderings, hampering their use in real-world applications. Instead\nof encoding the entire dynamic scene within the weights of an MLP, we present a\nnew approach that addresses these limitations by adopting a volumetric\nimage-based rendering framework that synthesizes new viewpoints by aggregating\nfeatures from nearby views in a scene-motion-aware manner. Our system retains\nthe advantages of prior methods in its ability to model complex scenes and\nview-dependent effects, but also enables synthesizing photo-realistic novel\nviews from long videos featuring complex scene dynamics with unconstrained\ncamera trajectories. We demonstrate significant improvements over\nstate-of-the-art methods on dynamic scene datasets, and also apply our approach\nto in-the-wild videos with challenging camera and object motion, where prior\nmethods fail to produce high-quality renderings. Our project webpage is at\ndynibar.github.io.",
    "descriptor": "",
    "authors": [
      "Zhengqi Li",
      "Qianqian Wang",
      "Forrester Cole",
      "Richard Tucker",
      "Noah Snavely"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11082"
  },
  {
    "id": "arXiv:2211.11085",
    "title": "R2-MLP: Round-Roll MLP for Multi-View 3D Object Recognition",
    "abstract": "Recently, vision architectures based exclusively on multi-layer perceptrons\n(MLPs) have gained much attention in the computer vision community. MLP-like\nmodels achieve competitive performance on a single 2D image classification with\nless inductive bias without hand-crafted convolution layers. In this work, we\nexplore the effectiveness of MLP-based architecture for the view-based 3D\nobject recognition task. We present an MLP-based architecture termed as\nRound-Roll MLP (R$^2$-MLP). It extends the spatial-shift MLP backbone by\nconsidering the communications between patches from different views. R$^2$-MLP\nrolls part of the channels along the view dimension and promotes information\nexchange between neighboring views. We benchmark MLP results on ModelNet10 and\nModelNet40 datasets with ablations in various aspects. The experimental results\nshow that, with a conceptually simple structure, our R$^2$-MLP achieves\ncompetitive performance compared with existing state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Shuo Chen",
      "Tan Yu",
      "Ping Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11085"
  },
  {
    "id": "arXiv:2211.11086",
    "title": "An Embarrassingly Simple Baseline for Imbalanced Semi-Supervised  Learning",
    "abstract": "Semi-supervised learning (SSL) has shown great promise in leveraging\nunlabeled data to improve model performance. While standard SSL assumes uniform\ndata distribution, we consider a more realistic and challenging setting called\nimbalanced SSL, where imbalanced class distributions occur in both labeled and\nunlabeled data. Although there are existing endeavors to tackle this challenge,\ntheir performance degenerates when facing severe imbalance since they can not\nreduce the class imbalance sufficiently and effectively. In this paper, we\nstudy a simple yet overlooked baseline -- SimiS -- which tackles data imbalance\nby simply supplementing labeled data with pseudo-labels, according to the\ndifference in class distribution from the most frequent class. Such a simple\nbaseline turns out to be highly effective in reducing class imbalance. It\noutperforms existing methods by a significant margin, e.g., 12.8%, 13.6%, and\n16.7% over previous SOTA on CIFAR100-LT, FOOD101-LT, and ImageNet127\nrespectively. The reduced imbalance results in faster convergence and better\npseudo-label accuracy of SimiS. The simplicity of our method also makes it\npossible to be combined with other re-balancing techniques to improve the\nperformance further. Moreover, our method shows great robustness to a wide\nrange of data distributions, which holds enormous potential in practice. Code\nwill be publicly available.",
    "descriptor": "\nComments: Imbalanced Semi-Supervised Learning\n",
    "authors": [
      "Hao Chen",
      "Yue Fan",
      "Yidong Wang",
      "Jindong Wang",
      "Bernt Schiele",
      "Xing Xie",
      "Marios Savvides",
      "Bhiksha Raj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11086"
  },
  {
    "id": "arXiv:2211.11087",
    "title": "Conceptor-Aided Debiasing of Contextualized Embeddings",
    "abstract": "Pre-trained language models reflect the inherent social biases of their\ntraining corpus. Many methods have been proposed to mitigate this issue, but\nthey often fail to debias or they sacrifice model accuracy. We use\nconceptors--a soft projection method--to identify and remove the bias subspace\nin contextual embeddings in BERT and GPT. We propose two methods of applying\nconceptors (1) bias subspace projection by post-processing; and (2) a new\narchitecture, conceptor-intervened BERT (CI-BERT), which explicitly\nincorporates the conceptor projection into all layers during training. We find\nthat conceptor post-processing achieves state-of-the-art debiasing results\nwhile maintaining or improving BERT's performance on the GLUE benchmark.\nAlthough CI-BERT's training takes all layers' bias into account and can\noutperform its post-processing counterpart in bias mitigation, CI-BERT reduces\nthe language model accuracy. We also show the importance of carefully\nconstructing the bias subspace. The best results are obtained by removing\noutliers from the list of biased words, intersecting them (using the conceptor\nAND operation), and computing their embeddings using the sentences from a\ncleaner corpus.",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Yifei Li",
      "Lyle Ungar",
      "Jo\u00e3o Sedoc"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11087"
  },
  {
    "id": "arXiv:2211.11088",
    "title": "Co-optimizing Consumption and EV Charging under Net Energy Metering",
    "abstract": "We consider the co-optimization of flexible household consumption, electric\nvehicle charging, and behind-the-meter distributed energy resources under the\nnet energy metering tariff. Using a stochastic dynamic programming formulation,\nwe show that the solution to the dynamic programming co-optimization is a\nprocrastination threshold policy that delays and minimizes electricity\npurchasing for EV charging in each time interval. The policy thresholds can be\ncomputed off-line, simplifying the continuous action space dynamic optimization\nto decoupled closed-form charging and consumption decisions. Empirical studies\nusing renewable, consumption, and EV data demonstrate the benefits of\nco-optimization.",
    "descriptor": "",
    "authors": [
      "Minjae Jeon",
      "Lang Tong",
      "Qing Zhao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.11088"
  },
  {
    "id": "arXiv:2211.11089",
    "title": "Multi-Arm Bin-Picking in Real-Time: A Combined Task and Motion Planning  Approach",
    "abstract": "Automated bin-picking is a prerequisite for fully automated manufacturing and\nwarehouses. To successfully pick an item from an unstructured bin the robot\nneeds to first detect possible grasps for the objects, decide on the object to\nremove and consequently plan and execute a feasible trajectory to retrieve the\nchosen object. Over the last years significant progress has been made towards\nsolving these problems. However, when multiple robot arms are cooperating the\ndecision and planning problems become exponentially harder. We propose an\nintegrated multi-arm bin-picking pipeline (IMAPIP), and demonstrate that it is\nable to reliably pick objects from a bin in real-time using multiple robot\narms. IMAPIP solves the multi-arm bin-picking task first at high-level using a\ngeometry-aware policy integrated in a combined task and motion planning\nframework. We then plan motions consistent with this policy using the BIT*\nalgorithm on the motion planning level. We show that this integrated solution\nenables robot arm cooperation. In our experiments, we show the proposed\ngeometry-aware policy outperforms a baseline by increasing bin-picking time by\n28\\% using two robot arms. The policy is robust to changes in the position of\nthe bin and number of objects. We also show that IMAPIP to successfully scale\nup to four robot arms working in close proximity.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Ilyes Toumi",
      "Andreas Orthey",
      "Alexander von Rohr",
      "Ngo Anh Vien"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.11089"
  },
  {
    "id": "arXiv:2211.11092",
    "title": "Q-Ensemble for Offline RL: Don't Scale the Ensemble, Scale the Batch  Size",
    "abstract": "Training large neural networks is known to be time-consuming, with the\nlearning duration taking days or even weeks. To address this problem,\nlarge-batch optimization was introduced. This approach demonstrated that\nscaling mini-batch sizes with appropriate learning rate adjustments can speed\nup the training process by orders of magnitude. While long training time was\nnot typically a major issue for model-free deep offline RL algorithms, recently\nintroduced Q-ensemble methods achieving state-of-the-art performance made this\nissue more relevant, notably extending the training duration. In this work, we\ndemonstrate how this class of methods can benefit from large-batch\noptimization, which is commonly overlooked by the deep offline RL community. We\nshow that scaling the mini-batch size and naively adjusting the learning rate\nallows for (1) a reduced size of the Q-ensemble, (2) stronger penalization of\nout-of-distribution actions, and (3) improved convergence time, effectively\nshortening training duration by 3-4x times on average.",
    "descriptor": "\nComments: Accepted at 3rd Offline Reinforcement Learning Workshop at Neural Information Processing Systems, 2022\n",
    "authors": [
      "Alexander Nikulin",
      "Vladislav Kurenkov",
      "Denis Tarasov",
      "Dmitry Akimov",
      "Sergey Kolesnikov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.11092"
  },
  {
    "id": "arXiv:2211.11093",
    "title": "VER: Learning Natural Language Representations for Verbalizing Entities  and Relations",
    "abstract": "Entities and relationships between entities are vital in the real world.\nEssentially, we understand the world by understanding entities and relations.\nFor instance, to understand a field, e.g., computer science, we need to\nunderstand the relevant concepts, e.g., machine learning, and the relationships\nbetween concepts, e.g., machine learning and artificial intelligence. To\nunderstand a person, we should first know who he/she is and how he/she is\nrelated to others. To understand entities and relations, humans may refer to\nnatural language descriptions. For instance, when learning a new scientific\nterm, people usually start by reading its definition in dictionaries or\nencyclopedias. To know the relationship between two entities, humans tend to\ncreate a sentence to connect them. In this paper, we propose VER: A Unified\nModel for Verbalizing Entities and Relations. Specifically, we attempt to build\na system that takes any entity or entity set as input and generates a sentence\nto represent entities and relations, named ``natural language representation''.\nExtensive experiments demonstrate that our model can generate high-quality\nsentences describing entities and entity relationships and facilitate various\ntasks on entities and relations, including definition modeling, relation\nmodeling, and generative commonsense reasoning.",
    "descriptor": "",
    "authors": [
      "Jie Huang",
      "Kevin Chen-Chuan Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11093"
  },
  {
    "id": "arXiv:2211.11096",
    "title": "Let Offline RL Flow: Training Conservative Agents in the Latent Space of  Normalizing Flows",
    "abstract": "Offline reinforcement learning aims to train a policy on a pre-recorded and\nfixed dataset without any additional environment interactions. There are two\nmajor challenges in this setting: (1) extrapolation error caused by\napproximating the value of state-action pairs not well-covered by the training\ndata and (2) distributional shift between behavior and inference policies. One\nway to tackle these problems is to induce conservatism - i.e., keeping the\nlearned policies closer to the behavioral ones. To achieve this, we build upon\nrecent works on learning policies in latent action spaces and use a special\nform of Normalizing Flows for constructing a generative model, which we use as\na conservative action encoder. This Normalizing Flows action encoder is\npre-trained in a supervised manner on the offline dataset, and then an\nadditional policy model - controller in the latent space - is trained via\nreinforcement learning. This approach avoids querying actions outside of the\ntraining dataset and therefore does not require additional regularization for\nout-of-dataset actions. We evaluate our method on various locomotion and\nnavigation tasks, demonstrating that our approach outperforms recently proposed\nalgorithms with generative action models on a large portion of datasets.",
    "descriptor": "\nComments: Accepted at 3rd Offline Reinforcement Learning Workshop at Neural Information Processing Systems, 2022\n",
    "authors": [
      "Dmitriy Akimov",
      "Vladislav Kurenkov",
      "Alexander Nikulin",
      "Denis Tarasov",
      "Sergey Kolesnikov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.11096"
  },
  {
    "id": "arXiv:2211.11097",
    "title": "Annual Benefit Analysis of Integrating the Seasonal Hydrogen Storage  into the Renewable Power Grids",
    "abstract": "There have been growing interests in integrating hydrogen storage into the\npower grids with high renewable penetration levels. The economic benefits and\npower grid reliability are both essential for the hydrogen storage integration.\nIn this paper, an annual scheduling model (ASM) for energy hubs (EH) coupled\npower grids is proposed to investigate the annual benefits of the seasonal\nhydrogen storage (SHS). Each energy hub consists of the hydrogen storage,\nelectrolyzers and fuel cells. The electrical and hydrogen energy can be\nexchanged on the bus with energy hub. The physical constraints for both grids\nand EHs are enforced in ASM. The proposed ASM considers the intra-season daily\noperation of the EH coupled grids. Four typical daily profiles are used in ASM\nto represent the grid conditions in four seasons, which reduces the\ncomputational burden. Besides, both the intra-season and cross-season hydrogen\nexchange and storage are modeled in the ASM. Hence, the utilization of hydrogen\nstorage is optimized on a year-round level. Numerical simulations are conducted\non the IEEE 24-bus system. The simulation results indicate that the seasonal\nhydrogen storage can effectively save the annual operation cost and reduce the\nrenewable curtailments.",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Jin Lu",
      "Xingpeng Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.11097"
  },
  {
    "id": "arXiv:2211.11100",
    "title": "Data-driven Tracking of the Bounce-back Path after Disasters: Critical  Milestones of Population Activity Recovery and Their Spatial Inequality",
    "abstract": "The ability to measure and track the speed and trajectory of a community's\npost-disaster recovery is essential to inform resource allocation and\nprioritization. The current survey-based approaches to examining community\nrecovery, however, have significant lags and put the burden of data collection\non affected people. Also, the existing literature lacks quantitative measures\nfor important milestones to inform the assessment of recovery trajectory.\nRecognizing these gaps, this study uses location-based data related to\nvisitation patterns and credit card transactions to specify critical recovery\nmilestones related to population activity recovery. Using data from 2017\nHurricane Harvey in Harris County (Texas), the study specifies four critical\npost-disaster recovery milestones and calculates quantitative measurements of\nthe length of time between the end of a hazard event and when the spatial areas\n(census tracts) reached these milestones based on fluctuations in visits to\nessential and non-essential facilities, and essential and non-essential credit\ncard transactions. Accordingly, an integrated recovery metric is created for an\noverall measurement of each spatial area's recovery progression. Exploratory\nstatistical analyses were conducted to examine whether variations in community\nrecovery progression in achieving the critical milestones is correlated to its\nflood status, socioeconomic characteristics, and demographic composition.\nFinally, the extent of spatial inequality is examined. The results show the\npresence of moderate spatial inequality in population activity recovery in\nHurricane Harvey, based upon which the inequality of recovery is measured.\nResults of this study can benefit post-disaster recovery resource allocation as\nwell as improve community resilience towards future natural hazards.",
    "descriptor": "",
    "authors": [
      "Yuqin Jiang",
      "Faxi Yuan",
      "Hamed Farahmand",
      "Kushal Acharya",
      "Jingdi Zhang",
      "Ali Mostafavi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.11100"
  },
  {
    "id": "arXiv:2211.11106",
    "title": "Efficient shallow learning as an alternative to deep learning",
    "abstract": "The realization of complex classification tasks requires training of deep\nlearning (DL) architectures consisting of tens or even hundreds of\nconvolutional and fully connected hidden layers, which is far from the reality\nof the human brain. According to the DL rationale, the first convolutional\nlayer reveals localized patterns in the input and large-scale patterns in the\nfollowing layers, until it reliably characterizes a class of inputs. Here, we\ndemonstrate that with a fixed ratio between the depths of the first and second\nconvolutional layers, the error rates of the generalized shallow LeNet\narchitecture, consisting of only five layers, decay as a power law with the\nnumber of filters in the first convolutional layer. The extrapolation of this\npower law indicates that the generalized LeNet can achieve small error rates\nthat were previously obtained for the CIFAR-10 database using DL architectures.\nA power law with a similar exponent also characterizes the generalized VGG-16\narchitecture. However, this results in a significantly increased number of\noperations required to achieve a given error rate with respect to LeNet. This\npower law phenomenon governs various generalized LeNet and VGG-16\narchitectures, hinting at its universal behavior and suggesting a quantitative\nhierarchical time-space complexity among machine learning architectures.\nAdditionally, the conservation law along the convolutional layers, which is the\nsquare-root of their size times their depth, is found to asymptotically\nminimize error rates. The efficient shallow learning that is demonstrated in\nthis study calls for further quantitative examination using various databases\nand architectures and its accelerated implementation using future dedicated\nhardware developments.",
    "descriptor": "\nComments: 26 pages, 4 figures\n",
    "authors": [
      "Yuval Meir",
      "Ofek Tevet",
      "Yarden Tzach",
      "Shiri Hodassman",
      "Ronit D. Gross",
      "Ido Kanter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11106"
  },
  {
    "id": "arXiv:2211.11109",
    "title": "Deep Learning on a Healthy Data Diet: Finding Important Examples for  Fairness",
    "abstract": "Data-driven predictive solutions predominant in commercial applications tend\nto suffer from biases and stereotypes, which raises equity concerns. Prediction\nmodels may discover, use, or amplify spurious correlations based on gender or\nother protected personal characteristics, thus discriminating against\nmarginalized groups. Mitigating gender bias has become an important research\nfocus in natural language processing (NLP) and is an area where annotated\ncorpora are available. Data augmentation reduces gender bias by adding\ncounterfactual examples to the training dataset. In this work, we show that\nsome of the examples in the augmented dataset can be not important or even\nharmful for fairness. We hence propose a general method for pruning both the\nfactual and counterfactual examples to maximize the model's fairness as\nmeasured by the demographic parity, equality of opportunity, and equality of\nodds. The fairness achieved by our method surpasses that of data augmentation\non three text classification datasets, using no more than half of the examples\nin the augmented dataset. Our experiments are conducted using models of varying\nsizes and pre-training settings.",
    "descriptor": "\nComments: In Proceedings of AAAI 2023\n",
    "authors": [
      "Abdelrahman Zayed",
      "Prasanna Parthasarathi",
      "Goncalo Mordido",
      "Hamid Palangi",
      "Samira Shabanian",
      "Sarath Chandar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11109"
  },
  {
    "id": "arXiv:2211.11113",
    "title": "From Fake News to #FakeNews: Mining Direct and Indirect Relationships  among Hashtags for Fake News Detection",
    "abstract": "The COVID-19 pandemic has gained worldwide attention and allowed fake news,\nsuch as ``COVID-19 is the flu,'' to spread quickly and widely on social media.\nCombating this coronavirus infodemic demands effective methods to detect fake\nnews. To this end, we propose a method to infer news credibility from hashtags\ninvolved in news dissemination on social media, motivated by the tight\nconnection between hashtags and news credibility observed in our empirical\nanalyses. We first introduce a new graph that captures all (direct and\n\\textit{indirect}) relationships among hashtags. Then, a language-independent\nsemi-supervised algorithm is developed to predict fake news based on this\nconstructed graph. This study first investigates the indirect relationship\namong hashtags; the proposed approach can be extended to any homogeneous graph\nto capture a comprehensive relationship among nodes. Language independence\nopens the proposed method to multilingual fake news detection. Experiments\nconducted on two real-world datasets demonstrate the effectiveness of our\napproach in identifying fake news, especially at an \\textit{early} stage of\npropagation.",
    "descriptor": "",
    "authors": [
      "Xinyi Zhou",
      "Reza Zafarani",
      "Emilio Ferrara"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.11113"
  },
  {
    "id": "arXiv:2211.11114",
    "title": "Semi-supervised Local Cluster Extraction by Compressive Sensing",
    "abstract": "Local clustering problem aims at extracting a small local structure inside a\ngraph without the necessity of knowing the entire graph structure. As the local\nstructure is usually small in size compared to the entire graph, one can think\nof it as a compressive sensing problem where the indices of target cluster can\nbe thought as a sparse solution to a linear system. In this paper, we propose a\nnew semi-supervised local cluster extraction approach by applying the idea of\ncompressive sensing based on two pioneering works under the same framework. Our\napproves improves the existing works by making the initial cut to be the entire\ngraph and hence overcomes a major limitation of existing works, which is the\nlow quality of initial cut. Extensive experimental results on multiple\nbenchmark datasets demonstrate the effectiveness of our approach.",
    "descriptor": "",
    "authors": [
      "Zhaiming Shen",
      "Ming-Jun Lai",
      "Sheng Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.11114"
  },
  {
    "id": "arXiv:2211.11116",
    "title": "Structure-Encoding Auxiliary Tasks for Improved Visual Representation in  Vision-and-Language Navigation",
    "abstract": "In Vision-and-Language Navigation (VLN), researchers typically take an image\nencoder pre-trained on ImageNet without fine-tuning on the environments that\nthe agent will be trained or tested on. However, the distribution shift between\nthe training images from ImageNet and the views in the navigation environments\nmay render the ImageNet pre-trained image encoder suboptimal. Therefore, in\nthis paper, we design a set of structure-encoding auxiliary tasks (SEA) that\nleverage the data in the navigation environments to pre-train and improve the\nimage encoder. Specifically, we design and customize (1) 3D jigsaw, (2)\ntraversability prediction, and (3) instance classification to pre-train the\nimage encoder. Through rigorous ablations, our SEA pre-trained features are\nshown to better encode structural information of the scenes, which ImageNet\npre-trained features fail to properly encode but is crucial for the target\nnavigation task. The SEA pre-trained features can be easily plugged into\nexisting VLN agents without any tuning. For example, on Test-Unseen\nenvironments, the VLN agents combined with our SEA pre-trained features achieve\nabsolute success rate improvement of 12% for Speaker-Follower, 5% for\nEnv-Dropout, and 4% for AuxRN.",
    "descriptor": "",
    "authors": [
      "Chia-Wen Kuo",
      "Chih-Yao Ma",
      "Judy Hoffman",
      "Zsolt Kira"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11116"
  },
  {
    "id": "arXiv:2211.11118",
    "title": "The Internal Operads of Combinatory Algebras",
    "abstract": "We argue that operads provide a general framework for dealing with\npolynomials and combinatory completeness of combinatory algebras, including the\nclassical $\\mathbf{SK}$-algebras, linear $\\mathbf{BCI}$-algebras, planar\n$\\mathbf{BI}(\\_)^\\bullet$-algebras as well as the braided $\\mathbf{BC^\\pm\nI}$-algebras. We show that every extensional combinatory algebra gives rise to\na canonical closed operad, which we shall call the internal operad of the\ncombinatory algebra. The internal operad construction gives a left adjoint to\nthe forgetful functor from closed operads to extensional combinatory algebras.\nAs a by-product, we derive extensionality axioms for the classes of combinatory\nalgebras mentioned above.",
    "descriptor": "",
    "authors": [
      "Masahito Hasegawa"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.11118"
  },
  {
    "id": "arXiv:2211.11119",
    "title": "Counterfactual Learning with Multioutput Deep Kernels",
    "abstract": "In this paper, we address the challenge of performing counterfactual\ninference with observational data via Bayesian nonparametric regression\nadjustment, with a focus on high-dimensional settings featuring multiple\nactions and multiple correlated outcomes. We present a general class of\ncounterfactual multi-task deep kernels models that estimate causal effects and\nlearn policies proficiently thanks to their sample efficiency gains, while\nscaling well with high dimensions. In the first part of the work, we rely on\nStructural Causal Models (SCM) to formally introduce the setup and the problem\nof identifying counterfactual quantities under observed confounding. We then\ndiscuss the benefits of tackling the task of causal effects estimation via\nstacked coregionalized Gaussian Processes and Deep Kernels. Finally, we\ndemonstrate the use of the proposed methods on simulated experiments that span\nindividual causal effects estimation, off-policy evaluation and optimization.",
    "descriptor": "",
    "authors": [
      "Alberto Caron",
      "Gianluca Baio",
      "Ioanna Manolopoulou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.11119"
  },
  {
    "id": "arXiv:2211.11127",
    "title": "BBReach: Tight and Scalable Black-Box Reachability Analysis of Deep  Reinforcement Learning Systems",
    "abstract": "Reachability analysis is a promising technique to automatically prove or\ndisprove the reliability and safety of AI-empowered software systems that are\ndeveloped by using Deep Reinforcement Learning (DRL). Existing approaches\nsuffer however from limited scalability and large overestimation as they must\nover-approximate the complex and almost inexplicable system components, namely\ndeep neural networks (DNNs). In this paper we propose a novel, tight and\nscalable reachability analysis approach for DRL systems. By training on\nabstract states, our approach treats the embedded DNNs as black boxes to avoid\nthe over-approximation for neural networks in computing reachable sets. To\ntackle the state explosion problem inherent to abstraction-based approaches, we\ndevise a novel adjacent interval aggregation algorithm which balances the\ngrowth of abstract states and the overestimation caused by the abstraction. We\nimplement a tool, called BBReach, and assess it on an extensive benchmark of\ncontrol systems to demonstrate its tightness, scalability, and efficiency.",
    "descriptor": "",
    "authors": [
      "Jiaxu Tian",
      "Dapeng Zhi",
      "Si Liu",
      "Peixin Wang",
      "Guy Katz",
      "Min Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11127"
  },
  {
    "id": "arXiv:2211.11130",
    "title": "Safe Stabilization for Stochastic Time-Delay Systems",
    "abstract": "This paper addresses the safe stabilization problem of stochastic nonlinear\ntime-delay systems. Based on the Krasovskii approach, we first propose a\nstochastic control Lyapunov-Krasovskii functional to guarantee the\nstabilization objective and a stochastic control barrier-Krasovskii functional\nto ensure the safety objective. Both functionals are developed respectively for\neach control objectives for the first time. Since the optimization problem is\nnot easy to be resolved for stochastic time-delay systems, we derive a sliding\nmode based approach to combine the proposed two functionals and to meditate\nstabilization and safety objectives, which allows to achieve the stabilization\nobjective under the safety requirement. The proposed approach is illustrated\nvia a numerical example.",
    "descriptor": "\nComments: 7 pages, 4 figures, submitted. arXiv admin note: text overlap with arXiv:2204.12106\n",
    "authors": [
      "Wei Ren"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.11130"
  },
  {
    "id": "arXiv:2211.11131",
    "title": "Doubly Contrastive End-to-End Semantic Segmentation for Autonomous  Driving under Adverse Weather",
    "abstract": "Road scene understanding tasks have recently become crucial for self-driving\nvehicles. In particular, real-time semantic segmentation is indispensable for\nintelligent self-driving agents to recognize roadside objects in the driving\narea. As prior research works have primarily sought to improve the segmentation\nperformance with computationally heavy operations, they require far significant\nhardware resources for both training and deployment, and thus are not suitable\nfor real-time applications. As such, we propose a doubly contrastive approach\nto improve the performance of a more practical lightweight model for\nself-driving, specifically under adverse weather conditions such as fog,\nnighttime, rain and snow. Our proposed approach exploits both image- and\npixel-level contrasts in an end-to-end supervised learning scheme without\nrequiring a memory bank for global consistency or the pretraining step used in\nconventional contrastive methods. We validate the effectiveness of our method\nusing SwiftNet on the ACDC dataset, where it achieves up to 1.34%p improvement\nin mIoU (ResNet-18 backbone) at 66.7 FPS (2048x1024 resolution) on a single RTX\n3080 Mobile GPU at inference. Furthermore, we demonstrate that replacing\nimage-level supervision with self-supervision achieves comparable performance\nwhen pre-trained with clear weather images.",
    "descriptor": "\nComments: Accepted for publication at BMVC 2022\n",
    "authors": [
      "Jongoh Jeong",
      "Jong-Hwan Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11131"
  },
  {
    "id": "arXiv:2211.11133",
    "title": "Towards Greener Solutions for Steering Angle Prediction",
    "abstract": "In this paper, we investigate the two most popular families of deep neural\narchitectures (i.e., ResNets and Inception nets) for the autonomous driving\ntask of steering angle prediction. This work provides preliminary evidence that\nInception architectures can perform as well or better than ResNet architectures\nwith less complexity for the autonomous driving task. Primary motivation\nincludes support for further research in smaller, more efficient neural network\narchitectures such that can not only accomplish complex tasks, such as steering\nangle predictions, but also produce less carbon emissions, or, more succinctly,\nneural networks that are more environmentally friendly. We look at various\nsizes of ResNet and InceptionNet models to compare results. Our derived models\ncan achieve state-of-the-art results in terms of steering angle MSE.",
    "descriptor": "",
    "authors": [
      "Jeremy C. Hagler",
      "David J. Lamb",
      "Qing Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11133"
  },
  {
    "id": "arXiv:2211.11136",
    "title": "Wood traceability system using blockchain and zero-knowledge proof",
    "abstract": "The system proposed in this study uses zero-knowledge proof (ZKP) to verify\nthe traceability of wood recorded in a public blockchain. Wood is a byproduct\nof several states, ranging from standing trees to logs, lumber, and wood\nproducts (hereinafter ``wood objects''). The advantage of using the blockchain\nfor record keeping is that participants can freely record the information at\ntheir discretion, without any restrictions. However, the openness of the\nblockchain may allow a malicious third party to introduce disinformation. In\nthis study, we employ ZKP and near-field communication (NFC) chips to eliminate\nthe possibility of disinformation introduction. ZKP is used to prove/validate\nchanges in the state of wood objects, and the unique nonce associated with that\nstate is encrypted and recorded on an NFC chip. The nonce is concealed and id\nof the wood object is defined as hash value of this nonce. We developed a\nprototype system based on an Android application and an Ethereum smart\ncontract. We confirm that wood traceability and verification can be performed\nusing the prototype system.",
    "descriptor": "\nComments: 4 pages, 3 figures, accepted for Blockchain and Cryptocurrency Congress (B2C' 2022)\n",
    "authors": [
      "Kyohei Shibano",
      "Tohru Nakajima",
      "Gento Mogi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.11136"
  },
  {
    "id": "arXiv:2211.11137",
    "title": "Long Range Constraints for Neural Texture Synthesis Using Sliced  Wasserstein Loss",
    "abstract": "In the past decade, exemplar-based texture synthesis algorithms have seen\nstrong gains in performance by matching statistics of deep convolutional neural\nnetworks. However, these algorithms require regularization terms or user-added\nspatial tags to capture long range constraints in images. Having access to a\nuser-added spatial tag for all situations is not always feasible, and\nregularization terms can be difficult to tune. It would be ideal to create an\nalgorithm that does not have any of the aforementioned drawbacks. Thus, we\npropose a new set of statistics for exemplar based texture synthesis based on\nSliced Wasserstein Loss and create a multi-scale algorithm to synthesize\ntextures without a user-added spatial tag. Lastly, we study the ability of our\nproposed algorithm to capture long range constraints in images and compare our\nresults to other exemplar-based neural texture synthesis algorithms.",
    "descriptor": "\nComments: Submitted to IEEE for possible publication\n",
    "authors": [
      "Liping Yin",
      "Albert Chua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11137"
  },
  {
    "id": "arXiv:2211.11138",
    "title": "Diffusion-Based Scene Graph to Image Generation with Masked Contrastive  Pre-Training",
    "abstract": "Generating images from graph-structured inputs, such as scene graphs, is\nuniquely challenging due to the difficulty of aligning nodes and connections in\ngraphs with objects and their relations in images. Most existing methods\naddress this challenge by using scene layouts, which are image-like\nrepresentations of scene graphs designed to capture the coarse structures of\nscene images. Because scene layouts are manually crafted, the alignment with\nimages may not be fully optimized, causing suboptimal compliance between the\ngenerated images and the original scene graphs. To tackle this issue, we\npropose to learn scene graph embeddings by directly optimizing their alignment\nwith images. Specifically, we pre-train an encoder to extract both global and\nlocal information from scene graphs that are predictive of the corresponding\nimages, relying on two loss functions: masked autoencoding loss and contrastive\nloss. The former trains embeddings by reconstructing randomly masked image\nregions, while the latter trains embeddings to discriminate between compliant\nand non-compliant images according to the scene graph. Given these embeddings,\nwe build a latent diffusion model to generate images from scene graphs. The\nresulting method, called SGDiff, allows for the semantic manipulation of\ngenerated images by modifying scene graph nodes and connections. On the Visual\nGenome and COCO-Stuff datasets, we demonstrate that SGDiff outperforms\nstate-of-the-art methods, as measured by both the Inception Score and Fr\\'echet\nInception Distance (FID) metrics. We will release our source code and trained\nmodels at https://github.com/YangLing0818/SGDiff.",
    "descriptor": "\nComments: Code and models shall be released at this https URL\n",
    "authors": [
      "Ling Yang",
      "Zhilin Huang",
      "Yang Song",
      "Shenda Hong",
      "Guohao Li",
      "Wentao Zhang",
      "Bin Cui",
      "Bernard Ghanem",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11138"
  },
  {
    "id": "arXiv:2211.11141",
    "title": "Attacking Shortest Paths by Cutting Edges",
    "abstract": "Identifying shortest paths between nodes in a network is a common graph\nanalysis problem that is important for many applications involving routing of\nresources. An adversary that can manipulate the graph structure could alter\ntraffic patterns to gain some benefit (e.g., make more money by directing\ntraffic to a toll road). This paper presents the Force Path Cut problem, in\nwhich an adversary removes edges from a graph to make a particular path the\nshortest between its terminal nodes. We prove that this problem is APX-hard,\nbut introduce PATHATTACK, a polynomial-time approximation algorithm that\nguarantees a solution within a logarithmic factor of the optimal value. In\naddition, we introduce the Force Edge Cut and Force Node Cut problems, in which\nthe adversary targets a particular edge or node, respectively, rather than an\nentire path. We derive a nonconvex optimization formulation for these problems,\nand derive a heuristic algorithm that uses PATHATTACK as a subroutine. We\ndemonstrate all of these algorithms on a diverse set of real and synthetic\nnetworks, illustrating the network types that benefit most from the proposed\nalgorithms.",
    "descriptor": "\nComments: 37 pages, 11 figures; Extended version of arXiv:2104.03761\n",
    "authors": [
      "Benjamin A. Miller",
      "Zohair Shafi",
      "Wheeler Ruml",
      "Yevgeniy Vorobeychik",
      "Tina Eliassi-Rad",
      "Scott Alfeld"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.11141"
  },
  {
    "id": "arXiv:2211.11147",
    "title": "A conjecture on optimal quaternary linear codes with one-dimensional  Hermitian hull",
    "abstract": "Linear codes with small hulls over finite fields have been extensively\nstudied due to their practical applications in computational complexity and\ninformation protection. In this paper, we develop a general method to determine\nthe exact value of $D_4^H(n,k,1)$ for $n\\leq 12$ or $k\\in\n\\{1,2,3,n-1,n-2,n-3\\}$, where $D_4^H(n,k,1)$ denotes the largest minimum\ndistance among all quaternary linear $[n,k]$ codes with one-dimensional\nHermitian hull. As a consequence, we solve a conjecture proposed by Mankean and\nJitman on the largest minimum distance of a quaternary linear code with\none-dimensional Hermitian hull. As an application, we construct some binary\nentanglement-assisted quantum error-correcting codes (EAQECCs) from quaternary\nlinear codes with one-dimensional Hermitian hull. Some of these EAQECCs are\noptimal codes, and some of them are better than previously known ones.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2211.02480\n",
    "authors": [
      "Shitao Li",
      "Minjia Shi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.11147"
  },
  {
    "id": "arXiv:2211.11152",
    "title": "You Need Multiple Exiting: Dynamic Early Exiting for Accelerating  Unified Vision Language Model",
    "abstract": "Large-scale Transformer models bring significant improvements for various\ndownstream vision language tasks with a unified architecture. The performance\nimprovements come with increasing model size, resulting in slow inference speed\nand increased cost for severing. While some certain predictions benefit from\nthe full complexity of the large-scale model, not all of inputs need the same\namount of computation to conduct, potentially leading to computation resource\nwaste. To handle this challenge, early exiting is proposed to adaptively\nallocate computational power in term of input complexity to improve inference\nefficiency. The existing early exiting strategies usually adopt output\nconfidence based on intermediate layers as a proxy of input complexity to incur\nthe decision of skipping following layers. However, such strategies cannot\napply to encoder in the widely-used unified architecture with both encoder and\ndecoder due to difficulty of output confidence estimation in the encoder. It is\nsuboptimal in term of saving computation power to ignore the early exiting in\nencoder component. To handle this challenge, we propose a novel early exiting\nstrategy for unified visual language models, which allows dynamically skip the\nlayers in encoder and decoder simultaneously in term of input layer-wise\nsimilarities with multiple times of early exiting, namely \\textbf{MuE}. By\ndecomposing the image and text modalities in the encoder, MuE is flexible and\ncan skip different layers in term of modalities, advancing the inference\nefficiency while minimizing performance drop. Experiments on the SNLI-VE and MS\nCOCO datasets show that the proposed approach MuE can reduce expected inference\ntime by up to 50\\% and 40\\% while maintaining 99\\% and 96\\% performance\nrespectively.",
    "descriptor": "",
    "authors": [
      "Shengkun Tang",
      "Yaqing Wang",
      "Zhenglun Kong",
      "Tianchi Zhang",
      "Yao Li",
      "Caiwen Ding",
      "Yanzhi Wang",
      "Yi Liang",
      "Dongkuan Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11152"
  },
  {
    "id": "arXiv:2211.11153",
    "title": "Unifying Vision-Language Representation Space with Single-tower  Transformer",
    "abstract": "Contrastive learning is a form of distance learning that aims to learn\ninvariant features from two related representations. In this paper, we explore\nthe bold hypothesis that an image and its caption can be simply regarded as two\ndifferent views of the underlying mutual information, and train a model to\nlearn a unified vision-language representation space that encodes both\nmodalities at once in a modality-agnostic manner. We first identify\ndifficulties in learning a generic one-tower model for vision-language\npretraining (VLP), and propose OneR as a simple yet effective framework for our\ngoal. We discover intriguing properties that distinguish OneR from the previous\nworks that learn modality-specific representation spaces such as zero-shot\nobject localization, text-guided visual reasoning and multi-modal retrieval,\nand present analyses to provide insights into this new form of multi-modal\nrepresentation learning. Thorough evaluations demonstrate the potential of a\nunified modality-agnostic VLP framework.",
    "descriptor": "\nComments: AAAI 2023, 11 pages\n",
    "authors": [
      "Jiho Jang",
      "Chaerin Kong",
      "Donghyeon Jeon",
      "Seonhoon Kim",
      "Nojun Kwak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11153"
  },
  {
    "id": "arXiv:2211.11154",
    "title": "DVGG: Deep Variational Grasp Generation for Dextrous Manipulation",
    "abstract": "Grasping with anthropomorphic robotic hands involves much more hand-object\ninteractions compared to parallel-jaw grippers. Modeling hand-object\ninteractions is essential to the study of multi-finger hand dextrous\nmanipulation. This work presents DVGG, an efficient grasp generation network\nthat takes single-view observation as input and predicts high-quality grasp\nconfigurations for unknown objects. In general, our generative model consists\nof three components: 1) Point cloud completion for the target object based on\nthe partial observation; 2) Diverse sets of grasps generation given the\ncomplete point cloud; 3) Iterative grasp pose refinement for physically\nplausible grasp optimization. To train our model, we build a large-scale\ngrasping dataset that contains about 300 common object models with 1.5M\nannotated grasps in simulation. Experiments in simulation show that our model\ncan predict robust grasp poses with a wide variety and high success rate. Real\nrobot platform experiments demonstrate that the model trained on our dataset\nperforms well in the real world. Remarkably, our method achieves a grasp\nsuccess rate of 70.7\\% for novel objects in the real robot platform, which is a\nsignificant improvement over the baseline methods.",
    "descriptor": "\nComments: Accepted by Robotics and Automation Letters (RA-L, 2021)\n",
    "authors": [
      "Wei Wei",
      "Daheng Li",
      "Peng Wang",
      "Yiming Li",
      "Wanyi Li",
      "Yongkang Luo",
      "Jun Zhong"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.11154"
  },
  {
    "id": "arXiv:2211.11155",
    "title": "From Indoor To Outdoor: Unsupervised Domain Adaptive Gait Recognition",
    "abstract": "Gait recognition is an important AI task, which has been progressed rapidly\nwith the development of deep learning. However, existing learning based gait\nrecognition methods mainly focus on the single domain, especially the\nconstrained laboratory environment. In this paper, we study a new problem of\nunsupervised domain adaptive gait recognition (UDA-GR), that learns a gait\nidentifier with supervised labels from the indoor scenes (source domain), and\nis applied to the outdoor wild scenes (target domain). For this purpose, we\ndevelop an uncertainty estimation and regularization based UDA-GR method.\nSpecifically, we investigate the characteristic of gaits in the indoor and\noutdoor scenes, for estimating the gait sample uncertainty, which is used in\nthe unsupervised fine-tuning on the target domain to alleviate the noises of\nthe pseudo labels. We also establish a new benchmark for the proposed problem,\nexperimental results on which show the effectiveness of the proposed method. We\nwill release the benchmark and source code in this work to the public.",
    "descriptor": "",
    "authors": [
      "Likai Wang",
      "Ruize Han",
      "Wei Feng",
      "Song Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11155"
  },
  {
    "id": "arXiv:2211.11156",
    "title": "A Continuous $hp-$Mesh Model for Discontinuous Petrov-Galerkin Finite  Element Schemes with Optimal Test Functions",
    "abstract": "We present an anisotropic $hp-$mesh adaptation strategy using a continuous\nmesh model for discontinuous Petrov-Galerkin (DPG) finite element schemes with\noptimal test functions, extending our previous work on $h-$adaptation. The\nproposed strategy utilizes the inbuilt residual-based error estimator of the\nDPG discretization to compute both the polynomial distribution and the\nanisotropy of the mesh elements. In order to predict the optimal order of\napproximation, we solve local problems on element patches, thus making these\ncomputations highly parallelizable. The continuous mesh model is formulated\neither with respect to the error in the solution, measured in a suitable norm,\nor with respect to certain admissible target functionals. We demonstrate the\nperformance of the proposed strategy using several numerical examples on\ntriangular grids.\nKeywords: Discontinuous Petrov-Galerkin, Continuous mesh models, $hp-$\nadaptations, Anisotropy",
    "descriptor": "",
    "authors": [
      "Ankit Chakraborty",
      "Georg May"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.11156"
  },
  {
    "id": "arXiv:2211.11158",
    "title": "Language in a Bottle: Language Model Guided Concept Bottlenecks for  Interpretable Image Classification",
    "abstract": "Concept Bottleneck Models (CBM) are inherently interpretable models that\nfactor model decisions into human-readable concepts. They allow people to\neasily understand why a model is failing, a critical feature for high-stakes\napplications. CBMs require manually specified concepts and often under-perform\ntheir black box counterparts, preventing their broad adoption. We address these\nshortcomings and are first to show how to construct high-performance CBMs\nwithout manual specification of similar accuracy to black box models. Our\napproach, Language Guided Bottlenecks (LaBo), leverages a language model,\nGPT-3, to define a large space of possible bottlenecks. Given a problem domain,\nLaBo uses GPT-3 to produce factual sentences about categories to form candidate\nconcepts. LaBo efficiently searches possible bottlenecks through a novel\nsubmodular utility that promotes the selection of discriminative and diverse\ninformation. Ultimately, GPT-3's sentential concepts can be aligned to images\nusing CLIP, to form a bottleneck layer. Experiments demonstrate that LaBo is a\nhighly effective prior for concepts important to visual recognition. In the\nevaluation with 11 diverse datasets, LaBo bottlenecks excel at few-shot\nclassification: they are 11.7% more accurate than black box linear probes at 1\nshot and comparable with more data. Overall, LaBo demonstrates that inherently\ninterpretable models can be widely applied at similar, or better, performance\nthan black box approaches.",
    "descriptor": "\nComments: 18 pages, 12 figures, 16 tables\n",
    "authors": [
      "Yue Yang",
      "Artemis Panagopoulou",
      "Shenghao Zhou",
      "Daniel Jin",
      "Chris Callison-Burch",
      "Mark Yatskar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11158"
  },
  {
    "id": "arXiv:2211.11159",
    "title": "Directed Acyclic Graph Factorization Machines for CTR Prediction via  Knowledge Distillation",
    "abstract": "With the growth of high-dimensional sparse data in web-scale recommender\nsystems, the computational cost to learn high-order feature interaction in CTR\nprediction task largely increases, which limits the use of high-order\ninteraction models in real industrial applications. Some recent knowledge\ndistillation based methods transfer knowledge from complex teacher models to\nshallow student models for accelerating the online model inference. However,\nthey suffer from the degradation of model accuracy in knowledge distillation\nprocess. It is challenging to balance the efficiency and effectiveness of the\nshallow student models. To address this problem, we propose a Directed Acyclic\nGraph Factorization Machine (KD-DAGFM) to learn the high-order feature\ninteractions from existing complex interaction models for CTR prediction via\nKnowledge Distillation. The proposed lightweight student model DAGFM can learn\narbitrary explicit feature interactions from teacher networks, which achieves\napproximately lossless performance and is proved by a dynamic programming\nalgorithm. Besides, an improved general model KD-DAGFM+ is shown to be\neffective in distilling both explicit and implicit feature interactions from\nany complex teacher model. Extensive experiments are conducted on four\nreal-world datasets, including a large-scale industrial dataset from WeChat\nplatform with billions of feature dimensions. KD-DAGFM achieves the best\nperformance with less than 21.5% FLOPs of the state-of-the-art method on both\nonline and offline experiments, showing the superiority of DAGFM to deal with\nthe industrial scale data in CTR prediction task. Our implementation code is\navailable at: https://github.com/RUCAIBox/DAGFM.",
    "descriptor": "",
    "authors": [
      "Zhen Tian",
      "Ting Bai",
      "Zibin Zhang",
      "Zhiyuan Xu",
      "Kangyi Lin",
      "Ji-Rong Wen",
      "Wayne Xin Zhao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11159"
  },
  {
    "id": "arXiv:2211.11160",
    "title": "Unsupervised Explanation Generation via Correct Instantiations",
    "abstract": "While large pre-trained language models (PLM) have shown their great skills\nat solving discriminative tasks, a significant gap remains when compared with\nhumans for explanation-related tasks. Among them, explaining the reason why a\nstatement is wrong (e.g., against commonsense) is incredibly challenging. The\nmajor difficulty is finding the conflict point, where the statement contradicts\nour real world. This paper proposes Neon, a two-phrase, unsupervised\nexplanation generation framework. Neon first generates corrected instantiations\nof the statement (phase I), then uses them to prompt large PLMs to find the\nconflict point and complete the explanation (phase II). We conduct extensive\nexperiments on two standard explanation benchmarks, i.e., ComVE and e-SNLI.\nAccording to both automatic and human evaluations, Neon outperforms baselines,\neven for those with human-annotated instantiations. In addition to explaining a\nnegative prediction, we further demonstrate that Neon remains effective when\ngeneralizing to different scenarios.",
    "descriptor": "\nComments: Accepted to AAAI-23\n",
    "authors": [
      "Sijie Cheng",
      "Zhiyong Wu",
      "Jiangjie Chen",
      "Zhixing Li",
      "Yang Liu",
      "Lingpeng Kong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11160"
  },
  {
    "id": "arXiv:2211.11165",
    "title": "A Benchmark of Video-Based Clothes-Changing Person Re-Identification",
    "abstract": "Person re-identification (Re-ID) is a classical computer vision task and has\nachieved great progress so far. Recently, long-term Re-ID with clothes-changing\nhas attracted increasing attention. However, existing methods mainly focus on\nimage-based setting, where richer temporal information is overlooked. In this\npaper, we focus on the relatively new yet practical problem of clothes-changing\nvideo-based person re-identification (CCVReID), which is less studied. We\nsystematically study this problem by simultaneously considering the challenge\nof the clothes inconsistency issue and the temporal information contained in\nthe video sequence for the person Re-ID problem. Based on this, we develop a\ntwo-branch confidence-aware re-ranking framework for handling the CCVReID\nproblem. The proposed framework integrates two branches that consider both the\nclassical appearance features and cloth-free gait features through a\nconfidence-guided re-ranking strategy. This method provides the baseline method\nfor further studies. Also, we build two new benchmark datasets for CCVReID\nproblem, including a large-scale synthetic video dataset and a real-world one,\nboth containing human sequences with various clothing changes. We will release\nthe benchmark and code in this work to the public.",
    "descriptor": "",
    "authors": [
      "Likai Wang",
      "Xiangqun Zhang",
      "Ruize Han",
      "Jialin Yang",
      "Xiaoyu Li",
      "Wei Feng",
      "Song Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11165"
  },
  {
    "id": "arXiv:2211.11167",
    "title": "Vision Transformer with Super Token Sampling",
    "abstract": "Vision transformer has achieved impressive performance for many vision tasks.\nHowever, it may suffer from high redundancy in capturing local features for\nshallow layers. Local self-attention or early-stage convolutions are thus\nutilized, which sacrifice the capacity to capture long-range dependency. A\nchallenge then arises: can we access efficient and effective global context\nmodeling at the early stages of a neural network? To address this issue, we\ndraw inspiration from the design of superpixels, which reduces the number of\nimage primitives in subsequent processing, and introduce super tokens into\nvision transformer. Super tokens attempt to provide a semantically meaningful\ntessellation of visual content, thus reducing the token number in\nself-attention as well as preserving global modeling. Specifically, we propose\na simple yet strong super token attention (STA) mechanism with three steps: the\nfirst samples super tokens from visual tokens via sparse association learning,\nthe second performs self-attention on super tokens, and the last maps them back\nto the original token space. STA decomposes vanilla global attention into\nmultiplications of a sparse association map and a low-dimensional attention,\nleading to high efficiency in capturing global dependencies. Based on STA, we\ndevelop a hierarchical vision transformer. Extensive experiments demonstrate\nits strong performance on various vision tasks. In particular, without any\nextra training data or label, it achieves 86.4% top-1 accuracy on ImageNet-1K\nwith less than 100M parameters. It also achieves 53.9 box AP and 46.8 mask AP\non the COCO detection task, and 51.9 mIOU on the ADE20K semantic segmentation\ntask. Code will be released at https://github.com/hhb072/SViT.",
    "descriptor": "\nComments: 12 pages, 4 figures, 8 tables\n",
    "authors": [
      "Huaibo Huang",
      "Xiaoqiang Zhou",
      "Jie Cao",
      "Ran He",
      "Tieniu Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11167"
  },
  {
    "id": "arXiv:2211.11172",
    "title": "HARL: Hierarchical Adaptive Reinforcement Learning Based Auto Scheduler  for Neural Networks",
    "abstract": "To efficiently perform inference with neural networks, the underlying tensor\nprograms require sufficient tuning efforts before being deployed into\nproduction environments. Usually, enormous tensor program candidates need to be\nsufficiently explored to find the one with the best performance. This is\nnecessary to make the neural network products meet the high demand of\nreal-world applications such as natural language processing, auto-driving, etc.\nAuto-schedulers are being developed to avoid the need for human intervention.\nHowever, due to the gigantic search space and lack of intelligent search\nguidance, current auto-schedulers require hours to days of tuning time to find\nthe best-performing tensor program for the entire neural network.\nIn this paper, we propose HARL, a reinforcement learning (RL) based\nauto-scheduler specifically designed for efficient tensor program exploration.\nHARL uses a hierarchical RL architecture in which learning-based decisions are\nmade at all different levels of search granularity. It also automatically\nadjusts exploration configurations in real-time for faster performance\nconvergence. As a result, HARL improves the tensor operator performance by 22%\nand the search speed by 4.3x compared to the state-of-the-art auto-scheduler.\nInference performance and search speed are also significantly improved on\nend-to-end neural networks.",
    "descriptor": "",
    "authors": [
      "Zining Zhang",
      "Bingsheng He",
      "Zhenjie Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2211.11172"
  },
  {
    "id": "arXiv:2211.11173",
    "title": "A min-max theorem for the minimum fleet-size problem",
    "abstract": "A retrospective fleet-sizing problem can be solved via bipartite matching,\nwhere a maximum cardinality matching corresponds to the minimum number of\nvehicles needed to cover all trips. We prove a min-max theorem on this minimum\nfleet-size problem: the maximum number of pairwise incompatible trips is equal\nto the minimum fleet size needed.",
    "descriptor": "",
    "authors": [
      "Tinghan",
      "David Shmoys"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.11173"
  },
  {
    "id": "arXiv:2211.11174",
    "title": "On the Robustness, Generalization, and Forgetting of Shape-Texture  Debiased Continual Learning",
    "abstract": "Tremendous progress has been made in continual learning to maintain good\nperformance on old tasks when learning new tasks by tackling the catastrophic\nforgetting problem of neural networks. This paper advances continual learning\nby further considering its out-of-distribution robustness, in response to the\nvulnerability of continually trained models to distribution shifts (e.g., due\nto data corruptions and domain shifts) in inference. To this end, we propose\nshape-texture debiased continual learning. The key idea is to learn\ngeneralizable and robust representations for each task with shape-texture\ndebiased training. In order to transform standard continual learning to\nshape-texture debiased continual learning, we propose shape-texture debiased\ndata generation and online shape-texture debiased self-distillation.\nExperiments on six datasets demonstrate the benefits of our approach in\nimproving generalization and robustness, as well as reducing forgetting. Our\nanalysis on the flatness of the loss landscape explains the advantages.\nMoreover, our approach can be easily combined with new advanced architectures\nsuch as vision transformer, and applied to more challenging scenarios such as\nexemplar-free continual learning.",
    "descriptor": "",
    "authors": [
      "Zenglin Shi",
      "Ying Sun",
      "Joo Hwee Lim",
      "Mengmi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11174"
  },
  {
    "id": "arXiv:2211.11175",
    "title": "CoPEM: Cooperative Perception Error Models for Autonomous Driving",
    "abstract": "In this paper, we introduce the notion of Cooperative Perception Error Models\n(coPEMs) towards achieving an effective and efficient integration of V2X\nsolutions within a virtual test environment. We focus our analysis on the\nocclusion problem in the (onboard) perception of Autonomous Vehicles (AV),\nwhich can manifest as misdetection errors on the occluded objects. Cooperative\nperception (CP) solutions based on Vehicle-to-Everything (V2X) communications\naim to avoid such issues by cooperatively leveraging additional points of view\nfor the world around the AV. This approach usually requires many sensors,\nmainly cameras and LiDARs, to be deployed simultaneously in the environment\neither as part of the road infrastructure or on other traffic vehicles.\nHowever, implementing a large number of sensor models in a virtual simulation\npipeline is often prohibitively computationally expensive. Therefore, in this\npaper, we rely on extending Perception Error Models (PEMs) to efficiently\nimplement such cooperative perception solutions along with the errors and\nuncertainties associated with them. We demonstrate the approach by comparing\nthe safety achievable by an AV challenged with a traffic scenario where\nocclusion is the primary cause of a potential collision.",
    "descriptor": "\nComments: Accepted at 2021 IEEE International Conference on Intelligent Transportation Systems - ITSC2022 6 pages, 6 figures\n",
    "authors": [
      "Andrea Piazzoni",
      "Jim Cherian",
      "Roshan Vijai",
      "Lap-Pui Chau",
      "Justin Dauwels"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11175"
  },
  {
    "id": "arXiv:2211.11176",
    "title": "Spatiotemporal Modeling of Multivariate Signals With Graph Neural  Networks and Structured State Space Models",
    "abstract": "Multivariate signals are prevalent in various domains, such as healthcare,\ntransportation systems, and space sciences. Modeling spatiotemporal\ndependencies in multivariate signals is challenging due to (1) long-range\ntemporal dependencies and (2) complex spatial correlations between sensors. To\naddress these challenges, we propose representing multivariate signals as\ngraphs and introduce GraphS4mer, a general graph neural network (GNN)\narchitecture that captures both spatial and temporal dependencies in\nmultivariate signals. Specifically, (1) we leverage Structured State Spaces\nmodel (S4), a state-of-the-art sequence model, to capture long-term temporal\ndependencies and (2) we propose a graph structure learning layer in GraphS4mer\nto learn dynamically evolving graph structures in the data. We evaluate our\nproposed model on three distinct tasks and show that GraphS4mer consistently\nimproves over existing models, including (1) seizure detection from\nelectroencephalography signals, outperforming a previous GNN with\nself-supervised pretraining by 3.1 points in AUROC; (2) sleep staging from\npolysomnography signals, a 4.1 points improvement in macro-F1 score compared to\nexisting sleep staging models; and (3) traffic forecasting, reducing MAE by\n8.8% compared to existing GNNs and by 1.4% compared to Transformer-based\nmodels.",
    "descriptor": "",
    "authors": [
      "Siyi Tang",
      "Jared A. Dunnmon",
      "Liangqiong Qu",
      "Khaled K. Saab",
      "Christopher Lee-Messer",
      "Daniel L. Rubin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.11176"
  },
  {
    "id": "arXiv:2211.11177",
    "title": "NeuMap: Neural Coordinate Mapping by Auto-Transdecoder for Camera  Localization",
    "abstract": "This paper presents an end-to-end neural mapping method for camera\nlocalization, encoding a whole scene into a grid of latent codes, with which a\nTransformer-based auto-decoder regresses 3D coordinates of query pixels.\nState-of-the-art camera localization methods require each scene to be stored as\na 3D point cloud with per-point features, which takes several gigabytes of\nstorage per scene. While compression is possible, the performance drops\nsignificantly at high compression rates. NeuMap achieves extremely high\ncompression rates with minimal performance drop by using 1) learnable latent\ncodes to store scene information and 2) a scene-agnostic Transformer-based\nauto-decoder to infer coordinates for a query pixel. The scene-agnostic network\ndesign also learns robust matching priors by training with large-scale data,\nand further allows us to just optimize the codes quickly for a new scene while\nfixing the network weights. Extensive evaluations with five benchmarks show\nthat NeuMap outperforms all the other coordinate regression methods\nsignificantly and reaches similar performance as the feature matching methods\nwhile having a much smaller scene representation size. For example, NeuMap\nachieves 39.1% accuracy in Aachen night benchmark with only 6MB of data, while\nother compelling methods require 100MB or a few gigabytes and fail completely\nunder high compression settings. The codes are available at\nhttps://github.com/Tangshitao/NeuMap.",
    "descriptor": "",
    "authors": [
      "Shitao Tang",
      "Sicong Tang",
      "Andrea Tagliasacchi",
      "Ping Tan",
      "Yasutaka Furukawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11177"
  },
  {
    "id": "arXiv:2211.11178",
    "title": "Adaptive Finite-Time Model Estimation and Control for Manipulator Visual  Servoing using Sliding Mode Control and Neural Networks",
    "abstract": "The image-based visual servoing without models of system is challenging since\nit is hard to fetch an accurate estimation of hand-eye relationship via merely\nvisual measurement. Whereas, the accuracy of estimated hand-eye relationship\nexpressed in local linear format with Jacobian matrix is important to whole\nsystem's performance. In this article, we proposed a finite-time controller as\nwell as a Jacobian matrix estimator in a combination of online and offline way.\nThe local linear formulation is formulated first. Then, we use a combination of\nonline and offline method to boost the estimation of the highly coupled and\nnonlinear hand-eye relationship with data collected via depth camera. A neural\nnetwork (NN) is pre-trained to give a relative reasonable initial estimation of\nJacobian matrix. Then, an online updating method is carried out to modify the\noffline trained NN for a more accurate estimation. Moreover, sliding mode\ncontrol algorithm is introduced to realize a finite-time controller. Compared\nwith previous methods, our algorithm possesses better convergence speed. The\nproposed estimator possesses excellent performance in the accuracy of initial\nestimation and powerful tracking capabilities for time-varying estimation for\nJacobian matrix compared with other data-driven estimators. The proposed scheme\nacquires the combination of neural network and finite-time control effect which\ndrives a faster convergence speed compared with the exponentially converge\nones. Another main feature of our algorithm is that the state signals in system\nis proved to be semi-global practical finite-time stable. Several experiments\nare carried out to validate proposed algorithm's performance.",
    "descriptor": "\nComments: 24 pages, 10 figures\n",
    "authors": [
      "Haibin Zeng",
      "Yueyong Lyu",
      "Jiaming Qi",
      "Shuangquan Zou",
      "Tanghao Qin",
      "Wenyu Qin"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.11178"
  },
  {
    "id": "arXiv:2211.11179",
    "title": "Spatio-temporal point processes with deep non-stationary kernels",
    "abstract": "Point process data are becoming ubiquitous in modern applications, such as\nsocial networks, health care, and finance. Despite the powerful expressiveness\nof the popular recurrent neural network (RNN) models for point process data,\nthey may not successfully capture sophisticated non-stationary dependencies in\nthe data due to their recurrent structures. Another popular type of deep model\nfor point process data is based on representing the influence kernel (rather\nthan the intensity function) by neural networks. We take the latter approach\nand develop a new deep non-stationary influence kernel that can model\nnon-stationary spatio-temporal point processes. The main idea is to approximate\nthe influence kernel with a novel and general low-rank decomposition, enabling\nefficient representation through deep neural networks and computational\nefficiency and better performance. We also take a new approach to maintain the\nnon-negativity constraint of the conditional intensity by introducing a\nlog-barrier penalty. We demonstrate our proposed method's good performance and\ncomputational efficiency compared with the state-of-the-art on simulated and\nreal data.",
    "descriptor": "",
    "authors": [
      "Zheng Dong",
      "Xiuyuan Cheng",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.11179"
  },
  {
    "id": "arXiv:2211.11180",
    "title": "306-321 GHz Wideband Channel Measurement and Analysis in an Indoor Lobby",
    "abstract": "The Terahertz (0.1-10 THz) band has been envisioned as one of the promising\nspectrum bands to support ultra-broadband sixth-generation (6G) and beyond\ncommunications. In this paper, a wideband channel measurement campaign in an\nindoor lobby at 306-321 GHz is presented. The measurement system consists of a\nvector network analyzer (VNA)-based channel sounder, and a directional antenna\nequipped at the receiver to resolve multi-path components (MPCs) in the angular\ndomain. In particular, 21 positions and 3780 channel impulse responses (CIRs)\nare measured in the lobby, including the line-of-sight (LoS), non-line-of-sight\n(NLoS) and obstructed-line-of-sight (OLoS) cases. Multi-path propagation is\nelaborated in terms of clustering results, and the effect of typical scatterers\nin the indoor lobby scenario in the THz band is explored. Moreover, indoor THz\nchannel characteristics are analyzed in depth. Specifically, best direction and\nomni-directional path losses are analyzed by invoking close-in and alpha-beta\npath loss models. The most clusters are observed in the OLoS case, followed by\nNLoS and then LoS cases. On average, the power dispersion of MPCs is smaller in\nthe LoS case in both temporal and angular domains, compared with the NLoS and\nOLoS counterparts.",
    "descriptor": "\nComments: 6 pages, 15 figures\n",
    "authors": [
      "Yiqin Wang",
      "Yuanbo Li",
      "Yi Chen",
      "Ziming Yu",
      "Chong Han"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.11180"
  },
  {
    "id": "arXiv:2211.11181",
    "title": "A review of laser scanning for geological and geotechnical applications  in underground mining",
    "abstract": "Laser scanning can provide timely assessments of mine sites despite adverse\nchallenges in the operational environment. Although there are several published\narticles on laser scanning, there is a need to review them in the context of\nunderground mining applications. To this end, a holistic review of laser\nscanning is presented including progress in 3D scanning systems, data\ncapture/processing techniques and primary applications in underground mines.\nLaser scanning technology has advanced significantly in terms of mobility and\nmapping, but there are constraints in coherent and consistent data collection\nat certain mines due to feature deficiency, dynamics, and environmental\ninfluences such as dust and water. Studies suggest that laser scanning has\nmatured over the years for change detection, clearance measurements and\nstructure mapping applications. However, there is scope for improvements in\nlithology identification, surface parameter measurements, logistic tracking and\nautonomous navigation. Laser scanning has the potential to provide real-time\nsolutions but the lack of infrastructure in underground mines for data\ntransfer, geodetic networking and processing capacity remain limiting factors.\nNevertheless, laser scanners are becoming an integral part of mine automation\nthanks to their affordability, accuracy and mobility, which should support\ntheir widespread usage in years to come.",
    "descriptor": "",
    "authors": [
      "Sarvesh Kumar Singh",
      "Bikram Pratap Banerjee",
      "Simit Raval"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11181"
  },
  {
    "id": "arXiv:2211.11182",
    "title": "Deep Projective Rotation Estimation through Relative Supervision",
    "abstract": "Orientation estimation is the core to a variety of vision and robotics tasks\nsuch as camera and object pose estimation. Deep learning has offered a way to\ndevelop image-based orientation estimators; however, such estimators often\nrequire training on a large labeled dataset, which can be time-intensive to\ncollect. In this work, we explore whether self-supervised learning from\nunlabeled data can be used to alleviate this issue. Specifically, we assume\naccess to estimates of the relative orientation between neighboring poses, such\nthat can be obtained via a local alignment method. While self-supervised\nlearning has been used successfully for translational object keypoints, in this\nwork, we show that naively applying relative supervision to the rotational\ngroup $SO(3)$ will often fail to converge due to the non-convexity of the\nrotational space. To tackle this challenge, we propose a new algorithm for\nself-supervised orientation estimation which utilizes Modified Rodrigues\nParameters to stereographically project the closed manifold of $SO(3)$ to the\nopen manifold of $\\mathbb{R}^{3}$, allowing the optimization to be done in an\nopen Euclidean space. We empirically validate the benefits of the proposed\nalgorithm for rotational averaging problem in two settings: (1) direct\noptimization on rotation parameters, and (2) optimization of parameters of a\nconvolutional neural network that predicts object orientations from images. In\nboth settings, we demonstrate that our proposed algorithm is able to converge\nto a consistent relative orientation frame much faster than algorithms that\npurely operate in the $SO(3)$ space. Additional information can be found at\nhttps://sites.google.com/view/deep-projective-rotation/home .",
    "descriptor": "\nComments: Conference on Robot Learning (CoRL), 2022. Supplementary material is available at this https URL\n",
    "authors": [
      "Brian Okorn",
      "Chuer Pan",
      "Martial Hebert",
      "David Held"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11182"
  },
  {
    "id": "arXiv:2211.11183",
    "title": "A Bayesian Causal Inference Approach for Assessing Fairness in Clinical  Decision-Making",
    "abstract": "Fairness in clinical decision-making is a critical element of health equity,\nbut assessing fairness of clinical decisions from observational data is\nchallenging. Recently, many fairness notions have been proposed to quantify\nfairness in decision-making, among which causality-based fairness notions have\ngained increasing attention due to its potential in adjusting for confounding\nand reasoning about bias. However, causal fairness notions remain\nunder-explored in the context of clinical decision-making with large-scale\nhealthcare data. In this work, we propose a Bayesian causal inference approach\nfor assessing a causal fairness notion called principal fairness in clinical\nsettings. We demonstrate our approach using both simulated data and electronic\nhealth records (EHR) data.",
    "descriptor": "",
    "authors": [
      "Linying Zhang",
      "Lauren R. Richter",
      "Yixin Wang",
      "Anna Ostropolets",
      "Noemie Elhadad",
      "David M. Blei",
      "George Hripcsak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11183"
  },
  {
    "id": "arXiv:2211.11185",
    "title": "Terahertz Channel Measurement and Analysis on a University Campus Street",
    "abstract": "Owning abundant bandwidth resource, the Terahertz (0.1-10 THz) band is a\npromising spectrum to support sixth-generation (6G) and beyond communications.\nAs the foundation of channel study in the spectrum, channel measurement is\nongoing in covering representative 6G communication scenarios and promising THz\nfrequency bands. In this paper, a wideband channel measurement in an L-shaped\nuniversity campus street is conducted at 306-321 GHz and 356-371 GHz. In\nparticular, ten line-of-sight (LoS) and eight non-line-of-sight (NLoS) points\nare measured at the two frequency bands, respectively. In total, 6480 channel\nimpulse responses (CIRs) are obtained from the measurement, based on which\nmulti-path propagation in the L-shaped roadway in the THz band is elaborated to\nidentify major scatterers of walls, vehicles, etc. in the environment and their\nimpact on multi-path components (MPCs). Furthermore, outdoor THz channel\ncharacteristics in the two frequency bands are analyzed, including path losses,\nshadow fading, cluster parameters, delay spread and angular spread. In contrast\nwith the counterparts in the similar outdoor scenario at lower frequencies, the\nresults verify the sparsity of MPCs at THz frequencies and indicate smaller\npower spreads in both temporal and spatial domains in the THz band.",
    "descriptor": "\nComments: 6 pages, 15 figures\n",
    "authors": [
      "Yiqin Wang",
      "Yuanbo Li",
      "Yi Chen",
      "Ziming Yu",
      "Chong Han"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.11185"
  },
  {
    "id": "arXiv:2211.11186",
    "title": "DualApp: Tight Over-Approximation for Neural Network Robustness  Verification via Under-Approximation",
    "abstract": "The robustness of neural networks is fundamental to the hosting system's\nreliability and security. Formal verification has been proven to be effective\nin providing provable robustness guarantees. To improve the verification\nscalability, over-approximating the non-linear activation functions in neural\nnetworks by linear constraints is widely adopted, which transforms the\nverification problem into an efficiently solvable linear programming problem.\nAs over-approximations inevitably introduce overestimation, many efforts have\nbeen dedicated to defining the tightest possible approximations. Recent studies\nhave however showed that the existing so-called tightest approximations are\nsuperior to each other. In this paper we identify and report an crucial factor\nin defining tight approximations, namely the approximation domains of\nactivation functions. We observe that existing approaches only rely on\noverestimated domains, while the corresponding tight approximation may not\nnecessarily be tight on its actual domain. We propose a novel\nunder-approximation-guided approach, called dual-approximation, to define tight\nover-approximations and two complementary under-approximation algorithms based\non sampling and gradient descent. The overestimated domain guarantees the\nsoundness while the underestimated one guides the tightness. We implement our\napproach into a tool called DualApp and extensively evaluate it on a\ncomprehensive benchmark of 84 collected and trained neural networks with\ndifferent architectures. The experimental results show that DualApp outperforms\nthe state-of-the-art approximation-based approaches, with up to 71.22%\nimprovement to the verification result.",
    "descriptor": "\nComments: 13 pages, 9 fugures, 3 tables\n",
    "authors": [
      "Yiting Wu",
      "Zhaodi Zhang",
      "Zhiyi Xue",
      "Si Liu",
      "Min Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11186"
  },
  {
    "id": "arXiv:2211.11187",
    "title": "L3Cube-MahaSBERT and HindSBERT: Sentence BERT Models and Benchmarking  BERT Sentence Representations for Hindi and Marathi",
    "abstract": "Sentence representation from vanilla BERT models does not work well on\nsentence similarity tasks. Sentence-BERT models specifically trained on STS or\nNLI datasets are shown to provide state-of-the-art performance. However,\nbuilding these models for low-resource languages is not straightforward due to\nthe lack of these specialized datasets. This work focuses on two low-resource\nIndian languages, Hindi and Marathi. We train sentence-BERT models for these\nlanguages using synthetic NLI and STS datasets prepared using machine\ntranslation. We show that the strategy of NLI pre-training followed by STSb\nfine-tuning is effective in generating high-performance sentence-similarity\nmodels for Hindi and Marathi. The vanilla BERT models trained using this simple\nstrategy outperform the multilingual LaBSE trained using a complex training\nstrategy. These models are evaluated on downstream text classification and\nsimilarity tasks. We evaluate these models on real text classification datasets\nto show embeddings obtained from synthetic data training are generalizable to\nreal datasets as well and thus represent an effective training strategy for\nlow-resource languages. We also provide a comparative analysis of sentence\nembeddings from fast text models, multilingual BERT models (mBERT, IndicBERT,\nxlm-RoBERTa, MuRIL), multilingual sentence embedding models (LASER, LaBSE), and\nmonolingual BERT models based on L3Cube-MahaBERT and HindBERT. We release\nL3Cube-MahaSBERT and HindSBERT, the state-of-the-art sentence-BERT models for\nMarathi and Hindi respectively. Our work also serves as a guide to building\nlow-resource sentence embedding models.",
    "descriptor": "\nComments: Accepted at Computing Conference 2023\n",
    "authors": [
      "Ananya Joshi",
      "Aditi Kajale",
      "Janhavi Gadre",
      "Samruddhi Deode",
      "Raviraj Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11187"
  },
  {
    "id": "arXiv:2211.11188",
    "title": "Simultaneous Multiple Object Detection and Pose Estimation using 3D  Model Infusion with Monocular Vision",
    "abstract": "Multiple object detection and pose estimation are vital computer vision\ntasks. The latter relates to the former as a downstream problem in applications\nsuch as robotics and autonomous driving. However, due to the high complexity of\nboth tasks, existing methods generally treat them independently, which is\nsub-optimal. We propose simultaneous neural modeling of both using monocular\nvision and 3D model infusion. Our Simultaneous Multiple Object detection and\nPose Estimation network (SMOPE-Net) is an end-to-end trainable multitasking\nnetwork with a composite loss that also provides the advantages of anchor-free\ndetections for efficient downstream pose estimation. To enable the annotation\nof training data for our learning objective, we develop a Twin-Space object\nlabeling method and demonstrate its correctness analytically and empirically.\nUsing the labeling method, we provide the KITTI-6DoF dataset with $\\sim7.5$K\nannotated frames. Extensive experiments on KITTI-6DoF and the popular LineMod\ndatasets show a consistent performance gain with SMOPE-Net over existing pose\nestimation methods. Here are links to our proposed\n\\href{https://anonymous.4open.science/r/SMOPE-Net-D3DF}{SMOPE-Net},\n\\href{https://anonymous.4open.science/r/LabelImg3D-6B16}{KITTI-6DoF dataset},\nand \\href{https://anonymous.4open.science/r/LabelImg3D-6B16}{LabelImg3D\nlabeling tool}.",
    "descriptor": "",
    "authors": [
      "Congliang Li",
      "Shijie Sun",
      "Xiangyu Song",
      "Huansheng Song",
      "Naveed Akhtar",
      "Ajmal Saeed Mian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11188"
  },
  {
    "id": "arXiv:2211.11189",
    "title": "Lemmas of Differential Privacy",
    "abstract": "We aim to collect buried lemmas that are useful for proofs. In particular, we\ntry to provide self-contained proofs for those lemmas and categorise them\naccording to their usage.",
    "descriptor": "\nComments: Comments, feedback, and suggested additions welcome\n",
    "authors": [
      "Yiyang Huang",
      "Cl\u00e9ment L. Canonne"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.11189"
  },
  {
    "id": "arXiv:2211.11190",
    "title": "Cross-Modal Contrastive Learning for Robust Reasoning in VQA",
    "abstract": "Multi-modal reasoning in visual question answering (VQA) has witnessed rapid\nprogress recently. However, most reasoning models heavily rely on shortcuts\nlearned from training data, which prevents their usage in challenging\nreal-world scenarios. In this paper, we propose a simple but effective\ncross-modal contrastive learning strategy to get rid of the shortcut reasoning\ncaused by imbalanced annotations and improve the overall performance. Different\nfrom existing contrastive learning with complex negative categories on coarse\n(Image, Question, Answer) triplet level, we leverage the correspondences\nbetween the language and image modalities to perform finer-grained cross-modal\ncontrastive learning. We treat each Question-Answer (QA) pair as a whole, and\ndifferentiate between images that conform with it and those against it. To\nalleviate the issue of sampling bias, we further build connected graphs among\nimages. For each positive pair, we regard the images from different graphs as\nnegative samples and deduct the version of multi-positive contrastive learning.\nTo our best knowledge, it is the first paper that reveals a general contrastive\nlearning strategy without delicate hand-craft rules can contribute to robust\nVQA reasoning. Experiments on several mainstream VQA datasets demonstrate our\nsuperiority compared to the state of the arts. Code is available at\n\\url{https://github.com/qizhust/cmcl_vqa_pl}.",
    "descriptor": "",
    "authors": [
      "Qi Zheng",
      "Chaoyue Wang",
      "Daqing Liu",
      "Dadong Wang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11190"
  },
  {
    "id": "arXiv:2211.11191",
    "title": "Correlative Preference Transfer with Hierarchical Hypergraph Network for  Multi-Domain Recommendation",
    "abstract": "Advanced recommender systems usually involve multiple domains (scenarios or\ncategories) for various marketing strategies, and users interact with them to\nsatisfy their diverse demands. The goal of multi-domain recommendation is to\nimprove the recommendation performance of all domains simultaneously.\nConventional graph neural network based methods usually deal with each domain\nseparately, or train a shared model for serving all domains. The former fails\nto leverage users' cross-domain behaviors, making the behavior sparseness issue\na great obstacle. The latter learns shared user representation with respect to\nall domains, which neglects users' domain-specific preferences. These\nshortcomings greatly limit their performance in multi-domain recommendation.\nTo tackle the limitations, an appropriate way is to learn from multi-domain\nuser feedbacks and obtain separate user representations to characterize their\ndomain-specific preferences. In this paper we propose $\\mathsf{H^3Trans}$, a\nhierarchical hypergraph network based correlative preference transfer framework\nfor multi-domain recommendation. $\\mathsf{H^3Trans}$ represents multi-domain\nfeedbacks into a unified graph to help preference transfer via taking full\nadvantage of users' multi-domain behaviors. We incorporate two hyperedge-based\nmodules, namely dynamic item transfer module (Hyper-I) and adaptive user\naggregation module (Hyper-U). Hyper-I extracts correlative information from\nmulti-domain user-item feedbacks for eliminating domain discrepancy of item\nrepresentations. Hyper-U aggregates users' scattered preferences in multiple\ndomains and further exploits the high-order (not only pair-wise) connections\namong them to learn user representations. Experimental results on both public\ndatasets and large-scale production datasets verify the superiority of\n$\\mathsf{H^3Trans}$ for multi-domain recommendation.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Zixuan Xu",
      "Penghui Wei",
      "Shaoguo Liu",
      "Liang Wang",
      "Bo Zheng"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.11191"
  },
  {
    "id": "arXiv:2211.11197",
    "title": "An Empirical Study of Package Management Issues via Stack Overflow",
    "abstract": "The package manager (PM) is crucial to most technology stacks, acting as a\nbroker to ensure that a verified dependency package is correctly installed,\nconfigured, or removed from an application. Diversity in technology stacks has\nled to dozens of PMs with various features. While our recent study indicates\nthat package management features of PM are related to end-user experiences, it\nis unclear what those issues are and what information is required to resolve\nthem. In this paper, we have investigated PM issues faced by end-users through\nan empirical study of content on Stack Overflow (SO). We carried out a\nqualitative analysis of 1,131 questions and their accepted answer posts for\nthree popular PMs (i.e., Maven, npm, and NuGet) to identify issue types,\nunderlying causes, and their resolutions. Our results confirm that end-users\nstruggle with PM tool usage (approximately 64-72%). We observe that most issues\nare raised by end-users due to lack of instructions and errors messages from PM\ntools. In terms of issue resolution, we find that external link sharing is the\nmost common practice to resolve PM issues. Additionally, we observe that links\npointing to useful resources (i.e., official documentation websites, tutorials,\netc.) are most frequently shared, indicating the potential for tool support and\nthe ability to provide relevant information for PM end-users.",
    "descriptor": "",
    "authors": [
      "Syful Islam",
      "Raula Gaikovina Kula",
      "Christoph Treude",
      "Bodin Chinthanet",
      "Takashi Ishio",
      "Kenichi Matsumoto"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.11197"
  },
  {
    "id": "arXiv:2211.11201",
    "title": "Uncertainty Reduction for 3D Point Cloud Self-Supervised Traversability  Estimation",
    "abstract": "Traversability estimation in off-road environments requires a robust\nperception system. Recently, approaches to learning a traversability estimation\nfrom past vehicle experiences in a self-supervised manner are arising as they\ncan greatly reduce human labeling costs and labeling errors. Nonetheless, the\nlearning setting from self-supervised traversability estimation suffers from\ncongenital uncertainties that appear according to the scarcity of negative\ninformation. Negative data are rarely harvested as the system can be severely\ndamaged while logging the data. To mitigate the uncertainty, we introduce a\nmethod to incorporate unlabeled data in order to leverage the uncertainty.\nFirst, we design a learning architecture that inputs query and support data.\nSecond, unlabeled data are assigned based on the proximity in the metric space.\nThird, a new metric for uncertainty measures is introduced. We evaluated our\napproach on our own dataset, `Dtrail', which is composed of a wide variety of\nnegative data.",
    "descriptor": "",
    "authors": [
      "Jihwan Bae",
      "Junwon Seo",
      "Taekyung Kim",
      "Hae-gon Jeon",
      "Kiho Kwak",
      "Inwook Shim"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11201"
  },
  {
    "id": "arXiv:2211.11202",
    "title": "FLNeRF: 3D Facial Landmarks Estimation in Neural Radiance Fields",
    "abstract": "This paper presents the first significant work on directly predicting 3D face\nlandmarks on neural radiance fields (NeRFs), without using intermediate\nrepresentations such as 2D images, depth maps, or point clouds. Our 3D\ncoarse-to-fine Face Landmarks NeRF (FLNeRF) model efficiently samples from the\nNeRF on the whole face with individual facial features for accurate landmarks.\nTo mitigate the limited number of facial expressions in the available data,\nlocal and non-linear NeRF warp is applied at facial features in fine scale to\nsimulate large emotions range, including exaggerated facial expressions (e.g.,\ncheek blowing, wide opening mouth, eye blinking), for training FLNeRF. With\nsuch expression augmentation, our model can predict 3D landmarks not limited to\nthe 20 discrete expressions given in the data. Robust 3D NeRF facial landmarks\ncontribute to many downstream tasks. As an example, we modify MoFaNeRF to\nenable high-quality face editing and swapping using face landmarks on NeRF,\nallowing more direct control and wider range of complex expressions.\nExperiments show that the improved model using landmarks achieves comparable to\nbetter results. Github link: https://github.com/ZHANG1023/FLNeRF.",
    "descriptor": "\nComments: Hao Zhang and Tianyuan Dai contributed equally\n",
    "authors": [
      "Hao Zhang",
      "Tianyuan Dai",
      "Yu-Wing Tai",
      "Chi-Keung Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.11202"
  },
  {
    "id": "arXiv:2211.11206",
    "title": "Cultural Re-contextualization of Fairness Research in Language  Technologies in India",
    "abstract": "Recent research has revealed undesirable biases in NLP data and models.\nHowever, these efforts largely focus on social disparities in the West, and are\nnot directly portable to other geo-cultural contexts. In this position paper,\nwe outline a holistic research agenda to re-contextualize NLP fairness research\nfor the Indian context, accounting for Indian societal context, bridging\ntechnological gaps in capability and resources, and adapting to Indian cultural\nvalues. We also summarize findings from an empirical study on various social\nbiases along different axes of disparities relevant to India, demonstrating\ntheir prevalence in corpora and models.",
    "descriptor": "\nComments: Accepted to NeurIPS Workshop on \"Cultures in AI/AI in Culture\". This is a non-archival short version, to cite please refer to our complete paper: arXiv:2209.12226\n",
    "authors": [
      "Shaily Bhatt",
      "Sunipa Dev",
      "Partha Talukdar",
      "Shachi Dave",
      "Vinodkumar Prabhakaran"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.11206"
  },
  {
    "id": "arXiv:2211.11208",
    "title": "Next3D: Generative Neural Texture Rasterization for 3D-Aware Head  Avatars",
    "abstract": "3D-aware generative adversarial networks (GANs) synthesize high-fidelity and\nmulti-view-consistent facial images using only collections of single-view 2D\nimagery. Towards fine-grained control over facial attributes, recent efforts\nincorporate 3D Morphable Face Model (3DMM) to describe deformation in\ngenerative radiance fields either explicitly or implicitly. Explicit methods\nprovide fine-grained expression control but cannot handle topological changes\ncaused by hair and accessories, while implicit ones can model varied topologies\nbut have limited generalization caused by the unconstrained deformation fields.\nWe propose a novel 3D GAN framework for unsupervised learning of generative,\nhigh-quality and 3D-consistent facial avatars from unstructured 2D images. To\nachieve both deformation accuracy and topological flexibility, we propose a 3D\nrepresentation called Generative Texture-Rasterized Tri-planes. The proposed\nrepresentation learns Generative Neural Textures on top of parametric mesh\ntemplates and then projects them into three orthogonal-viewed feature planes\nthrough rasterization, forming a tri-plane feature representation for volume\nrendering. In this way, we combine both fine-grained expression control of\nmesh-guided explicit deformation and the flexibility of implicit volumetric\nrepresentation. We further propose specific modules for modeling mouth interior\nwhich is not taken into account by 3DMM. Our method demonstrates\nstate-of-the-art 3D-aware synthesis quality and animation ability through\nextensive experiments. Furthermore, serving as 3D prior, our animatable 3D\nrepresentation boosts multiple applications including one-shot facial avatars\nand 3D-aware stylization.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Jingxiang Sun",
      "Xuan Wang",
      "Lizhen Wang",
      "Xiaoyu Li",
      "Yong Zhang",
      "Hongwen Zhang",
      "Yebin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11208"
  },
  {
    "id": "arXiv:2211.11209",
    "title": "A Novel Uncalibrated Visual Servoing Controller Baesd on Model-Free  Adaptive Control Method with Neural Network",
    "abstract": "Nowadays, with the continuous expansion of application scenarios of robotic\narms, there are more and more scenarios where nonspecialist come into contact\nwith robotic arms. However, in terms of robotic arm visual servoing,\ntraditional Position-based Visual Servoing (PBVS) requires a lot of calibration\nwork, which is challenging for the nonspecialist to cope with. To cope with\nthis situation, Uncalibrated Image-Based Visual Servoing (UIBVS) frees people\nfrom tedious calibration work. This work applied a model-free adaptive control\n(MFAC) method which means that the parameters of controller are updated in real\ntime, bringing better ability of suppression changes of system and environment.\nAn artificial intelligent neural network is applied in designs of controller\nand estimator for hand-eye relationship. The neural network is updated with the\nknowledge of the system input and output information in MFAC method. Inspired\nby \"predictive model\" and \"receding-horizon\" in Model Predictive Control (MPC)\nmethod and introducing similar structures into our algorithm, we realizes the\nuncalibrated visual servoing for both stationary targets and moving\ntrajectories. Simulated experiments with a robotic manipulator will be carried\nout to validate the proposed algorithm.",
    "descriptor": "\nComments: 16 pages, 8 figures\n",
    "authors": [
      "Haibin Zeng",
      "Yueyong Lyu",
      "Jiaming Qi",
      "Shuangquan Zou",
      "Tanghao Qin",
      "Wenyu Qin"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.11209"
  },
  {
    "id": "arXiv:2211.11210",
    "title": "Contrastive Masked Autoencoders for Self-Supervised Video Hashing",
    "abstract": "Self-Supervised Video Hashing (SSVH) models learn to generate short binary\nrepresentations for videos without ground-truth supervision, facilitating\nlarge-scale video retrieval efficiency and attracting increasing research\nattention. The success of SSVH lies in the understanding of video content and\nthe ability to capture the semantic relation among unlabeled videos. Typically,\nstate-of-the-art SSVH methods consider these two points in a two-stage training\npipeline, where they firstly train an auxiliary network by instance-wise\nmask-and-predict tasks and secondly train a hashing model to preserve the\npseudo-neighborhood structure transferred from the auxiliary network. This\nconsecutive training strategy is inflexible and also unnecessary. In this\npaper, we propose a simple yet effective one-stage SSVH method called ConMH,\nwhich incorporates video semantic information and video similarity relationship\nunderstanding in a single stage. To capture video semantic information for\nbetter hashing learning, we adopt an encoder-decoder structure to reconstruct\nthe video from its temporal-masked frames. Particularly, we find that a higher\nmasking ratio helps video understanding. Besides, we fully exploit the\nsimilarity relationship between videos by maximizing agreement between two\naugmented views of a video, which contributes to more discriminative and robust\nhash codes. Extensive experiments on three large-scale video datasets (\\ie,\nFCVID, ActivityNet and YFCC) indicate that ConMH achieves state-of-the-art\nresults. Code is available at https://github.com/huangmozhi9527/ConMH.",
    "descriptor": "\nComments: This work is accepted by the AAAI 2023. 9 pages, 6 figures, 6 tables\n",
    "authors": [
      "Yuting Wang",
      "Jinpeng Wang",
      "Bin Chen",
      "Ziyun Zeng",
      "Shutao Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.11210"
  },
  {
    "id": "arXiv:2211.11215",
    "title": "SegNeRF: 3D Part Segmentation with Neural Radiance Fields",
    "abstract": "Recent advances in Neural Radiance Fields (NeRF) boast impressive\nperformances for generative tasks such as novel view synthesis and 3D\nreconstruction. Methods based on neural radiance fields are able to represent\nthe 3D world implicitly by relying exclusively on posed images. Yet, they have\nseldom been explored in the realm of discriminative tasks such as 3D part\nsegmentation.In this work, we attempt to bridge that gap by proposing SegNeRF:\na neural field representation that integrates a semantic field along with the\nusual radiance field. SegNeRF inherits from previous works the ability to\nperform novel view synthesis and 3D reconstruction, and enables 3D part\nsegmentation from a few images. Our extensive experiments on PartNet show that\nSegNeRF is capable of simultaneously predicting geometry, appearance, and\nsemantic information from posed images, even for unseen objects. The predicted\nsemantic fields allow SegNeRF to achieve an average mIoU of $\\textbf{30.30%}$\nfor 2D novel view segmentation, and $\\textbf{37.46%}$ for 3D part segmentation,\nboasting competitive performance against point-based methods by using only a\nfew posed images. Additionally, SegNeRF is able to generate an explicit 3D\nmodel from a single image of an object taken in the wild, with its\ncorresponding part segmentation.",
    "descriptor": "",
    "authors": [
      "Jesus Zarzar",
      "Sara Rojas",
      "Silvio Giancola",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11215"
  },
  {
    "id": "arXiv:2211.11216",
    "title": "Exploring the Efficacy of Pre-trained Checkpoints in Text-to-Music  Generation Task",
    "abstract": "Benefiting from large-scale datasets and pre-trained models, the field of\ngenerative models has recently gained significant momentum. However, most\ndatasets for symbolic music are very small, which potentially limits the\nperformance of data-driven multimodal models. An intuitive solution to this\nproblem is to leverage pre-trained models from other modalities (e.g., natural\nlanguage) to improve the performance of symbolic music-related multimodal\ntasks. In this paper, we carry out the first study of generating complete and\nsemantically consistent symbolic music scores from text descriptions, and\nexplore the efficacy of using publicly available checkpoints (i.e., BERT,\nGPT-2, and BART) for natural language processing in the task of text-to-music\ngeneration. Our experimental results show that the improvement from using\npre-trained checkpoints is statistically significant in terms of BLEU score and\nedit distance similarity. We analyse the capabilities and limitations of our\nmodel to better understand the potential of language-music models.",
    "descriptor": "\nComments: 5 pages, 2 figures, 2 tables\n",
    "authors": [
      "Shangda Wu",
      "Maosong Sun"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.11216"
  },
  {
    "id": "arXiv:2211.11219",
    "title": "Best of Both Worlds in Online Control: Competitive Ratio and Policy  Regret",
    "abstract": "We consider the fundamental problem of online control of a linear dynamical\nsystem from two different viewpoints: regret minimization and competitive\nanalysis. We prove that the optimal competitive policy is well-approximated by\na convex parameterized policy class, known as a disturbance-action control\n(DAC) policies. Using this structural result, we show that several recently\nproposed online control algorithms achieve the best of both worlds: sublinear\nregret vs. the best DAC policy selected in hindsight, and optimal competitive\nratio, up to an additive correction which grows sublinearly in the time\nhorizon. We further conclude that sublinear regret vs. the optimal competitive\npolicy is attainable when the linear dynamical system is unknown, and even when\na stabilizing controller for the dynamics is not available a priori.",
    "descriptor": "",
    "authors": [
      "Gautam Goel",
      "Naman Agarwal",
      "Karan Singh",
      "Elad Hazan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11219"
  },
  {
    "id": "arXiv:2211.11220",
    "title": "STGlow: A Flow-based Generative Framework with Dual Graphormer for  Pedestrian Trajectory Prediction",
    "abstract": "Pedestrian trajectory prediction task is an essential component of\nintelligent systems, and its applications include but are not limited to\nautonomous driving, robot navigation, and anomaly detection of monitoring\nsystems. Due to the diversity of motion behaviors and the complex social\ninteractions among pedestrians, accurately forecasting the future trajectory of\npedestrians is challenging. Existing approaches commonly adopt GANs or CVAEs to\ngenerate diverse trajectories. However, GAN-based methods do not directly model\ndata in a latent space, which makes them fail to have full support over the\nunderlying data distribution; CVAE-based methods optimize a lower bound on the\nlog-likelihood of observations, causing the learned distribution to deviate\nfrom the underlying distribution. The above limitations make existing\napproaches often generate highly biased or unnatural trajectories.In this\npaper, we propose a novel generative flow based framework with dual graphormer\nfor pedestrian trajectory prediction (STGlow). Different from previous\napproaches, our method can more accurately model the underlying data\ndistribution by optimizing the exact log-likelihood of motion behaviors.\nBesides, our method has clear physical meanings to simulate the evolution of\nhuman motion behaviors, where the forward process of the flow gradually\ndegrades the complex motion behavior into a simple behavior, while its reverse\nprocess represents the evolution of a simple behavior to the complex motion\nbehavior. Further, we introduce a dual graphormer combining with the graph\nstructure to more adequately model the temporal dependencies and the mutual\nspatial interactions. Experimental results on several benchmarks demonstrate\nthat our method achieves much better performance compared to previous\nstate-of-the-art approaches.",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Rongqin Liang",
      "Yuanman Li",
      "Jiantao Zhou",
      "Xia Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11220"
  },
  {
    "id": "arXiv:2211.11224",
    "title": "Exploring the Effectiveness of Mask-Guided Feature Modulation as a  Mechanism for Localized Style Editing of Real Images",
    "abstract": "The success of Deep Generative Models at high-resolution image generation has\nled to their extensive utilization for style editing of real images. Most\nexisting methods work on the principle of inverting real images onto their\nlatent space, followed by determining controllable directions. Both inversion\nof real images and determination of controllable latent directions are\ncomputationally expensive operations. Moreover, the determination of\ncontrollable latent directions requires additional human supervision. This work\naims to explore the efficacy of mask-guided feature modulation in the latent\nspace of a Deep Generative Model as a solution to these bottlenecks. To this\nend, we present the SemanticStyle Autoencoder (SSAE), a deep Generative\nAutoencoder model that leverages semantic mask-guided latent space manipulation\nfor highly localized photorealistic style editing of real images. We present\nqualitative and quantitative results for the same and their analysis. This work\nshall serve as a guiding primer for future work.",
    "descriptor": "\nComments: To appear as a Student Abstract Track paper in Proceedings of the AAAI Conference (2023)\n",
    "authors": [
      "Snehal Singh Tomar",
      "Maitreya Suin",
      "A.N. Rajagopalan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11224"
  },
  {
    "id": "arXiv:2211.11225",
    "title": "TimbreCLIP: Connecting Timbre to Text and Images",
    "abstract": "We present work in progress on TimbreCLIP, an audio-text cross modal\nembedding trained on single instrument notes. We evaluate the models with a\ncross-modal retrieval task on synth patches. Finally, we demonstrate the\napplication of TimbreCLIP on two tasks: text-driven audio equalization and\ntimbre to image generation.",
    "descriptor": "\nComments: Submitted to AAAI workshop on creative AI across modalities\n",
    "authors": [
      "Nicolas Jonason",
      "Bob L.T. Sturm"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.11225"
  },
  {
    "id": "arXiv:2211.11226",
    "title": "Learn from Yesterday: A Semi-Supervised Continual Learning Method for  Supervision-Limited Text-to-SQL Task Streams",
    "abstract": "Conventional text-to-SQL studies are limited to a single task with a\nfixed-size training and test set. When confronted with a stream of tasks common\nin real-world applications, existing methods struggle with the problems of\ninsufficient supervised data and high retraining costs. The former tends to\ncause overfitting on unseen databases for the new task, while the latter makes\na full review of instances from past tasks impractical for the model, resulting\nin forgetting of learned SQL structures and database schemas. To address the\nproblems, this paper proposes integrating semi-supervised learning (SSL) and\ncontinual learning (CL) in a stream of text-to-SQL tasks and offers two\npromising solutions in turn. The first solution Vanilla is to perform\nself-training, augmenting the supervised training data with predicted\npseudo-labeled instances of the current task, while replacing the full volume\nretraining with episodic memory replay to balance the training efficiency with\nthe performance of previous tasks. The improved solution SFNet takes advantage\nof the intrinsic connection between CL and SSL. It uses in-memory past\ninformation to help current SSL, while adding high-quality pseudo instances in\nmemory to improve future replay. The experiments on two datasets shows that\nSFNet outperforms the widely-used SSL-only and CL-only baselines on multiple\nmetrics.",
    "descriptor": "\nComments: Accepted by AAAI-2023\n",
    "authors": [
      "Yongrui Chen",
      "Xinnan Guo",
      "Tongtong Wu",
      "Guilin Qi",
      "Yang Li",
      "Yang Dong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11226"
  },
  {
    "id": "arXiv:2211.11227",
    "title": "Explainable Model-specific Algorithm Selection for Multi-Label  Classification",
    "abstract": "Multi-label classification (MLC) is an ML task of predictive modeling in\nwhich a data instance can simultaneously belong to multiple classes. MLC is\nincreasingly gaining interest in different application domains such as text\nmining, computer vision, and bioinformatics. Several MLC algorithms have been\nproposed in the literature, resulting in a meta-optimization problem that the\nuser needs to address: which MLC approach to select for a given dataset? To\naddress this algorithm selection problem, we investigate in this work the\nquality of an automated approach that uses characteristics of the datasets -\nso-called features - and a trained algorithm selector to choose which algorithm\nto apply for a given task. For our empirical evaluation, we use a portfolio of\n38 datasets. We consider eight MLC algorithms, whose quality we evaluate using\nsix different performance metrics. We show that our automated algorithm\nselector outperforms any of the single MLC algorithms, and this is for all\nevaluated performance measures. Our selection approach is explainable, a\ncharacteristic that we exploit to investigate which meta-features have the\nlargest influence on the decisions made by the algorithm selector. Finally, we\nalso quantify the importance of the most significant meta-features for various\ndomains.",
    "descriptor": "",
    "authors": [
      "Ana Kostovska",
      "Carola Doerr",
      "Sa\u0161o D\u017eeroski",
      "Dragi Kocev",
      "Pan\u010de Panov",
      "Tome Eftimov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11227"
  },
  {
    "id": "arXiv:2211.11236",
    "title": "Boosting the Transferability of Adversarial Attacks with Global Momentum  Initialization",
    "abstract": "Deep neural networks are vulnerable to adversarial examples, which attach\nhuman invisible perturbations to benign inputs. Simultaneously, adversarial\nexamples exhibit transferability under different models, which makes practical\nblack-box attacks feasible. However, existing methods are still incapable of\nachieving desired transfer attack performance. In this work, from the\nperspective of gradient optimization and consistency, we analyze and discover\nthe gradient elimination phenomenon as well as the local momentum optimum\ndilemma. To tackle these issues, we propose Global Momentum Initialization (GI)\nto suppress gradient elimination and help search for the global optimum.\nSpecifically, we perform gradient pre-convergence before the attack and carry\nout a global search during the pre-convergence stage. Our method can be easily\ncombined with almost all existing transfer methods, and we improve the success\nrate of transfer attacks significantly by an average of 6.4% under various\nadvanced defense mechanisms compared to state-of-the-art methods. Eventually,\nwe achieve an attack success rate of 95.4%, fully illustrating the insecurity\nof existing defense mechanisms.",
    "descriptor": "",
    "authors": [
      "Jiafeng Wang",
      "Zhaoyu Chen",
      "Kaixun Jiang",
      "Dingkang Yang",
      "Lingyi Hong",
      "Yan Wang",
      "Wenqiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.11236"
  },
  {
    "id": "arXiv:2211.11238",
    "title": "RobustLoc: Robust Camera Pose Regression in Challenging Driving  Environments",
    "abstract": "Camera relocalization has various applications in autonomous driving.\nPrevious camera pose regression models consider only ideal scenarios where\nthere is little environmental perturbation. To deal with challenging driving\nenvironments that may have changing seasons, weather, illumination, and the\npresence of unstable objects, we propose RobustLoc, which derives its\nrobustness against perturbations from neural differential equations. Our model\nuses a convolutional neural network to extract feature maps from multi-view\nimages, a robust neural differential equation diffusion block module to diffuse\ninformation interactively, and a branched pose decoder with multi-layer\ntraining to estimate the vehicle poses. Experiments demonstrate that RobustLoc\nsurpasses current state-of-the-art camera pose regression models and achieves\nrobust performance in various environments. Our code is released at:\nhttps://github.com/sijieaaa/RobustLoc",
    "descriptor": "",
    "authors": [
      "Sijie Wang",
      "Qiyu Kang",
      "Rui She",
      "Wee Peng Tay",
      "Andreas Hartmannsgruber",
      "Diego Navarro Navarro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11238"
  },
  {
    "id": "arXiv:2211.11242",
    "title": "Label Mask AutoEncoder(L-MAE): A Pure Transformer Method to Augment  Semantic Segmentation Datasets",
    "abstract": "Semantic segmentation models based on the conventional neural network can\nachieve remarkable performance in such tasks, while the dataset is crucial to\nthe training model process. Significant progress in expanding datasets has been\nmade in semi-supervised semantic segmentation recently. However, completing the\npixel-level information remains challenging due to possible missing in a label.\nInspired by Mask AutoEncoder, we present a simple yet effective Pixel-Level\ncompletion method, Label Mask AutoEncoder(L-MAE), that fully uses the existing\ninformation in the label to predict results. The proposed model adopts the\nfusion strategy that stacks the label and the corresponding image, namely Fuse\nMap. Moreover, since some of the image information is lost when masking the\nFuse Map, direct reconstruction may lead to poor performance. Our proposed\nImage Patch Supplement algorithm can supplement the missing information, as the\nexperiment shows, an average of 4.1% mIoU can be improved. The Pascal VOC2012\ndataset (224 crop size, 20 classes) and the Cityscape dataset (448 crop size,\n19 classes) are used in the comparative experiments. With the Mask Ratio\nsetting to 50%, in terms of the prediction region, the proposed model achieves\n91.0% and 86.4% of mIoU on Pascal VOC 2012 and Cityscape, respectively,\noutperforming other current supervised semantic segmentation models. Our code\nand models are available at https://github.com/jjrccop/Label-Mask-Auto-Encoder.",
    "descriptor": "",
    "authors": [
      "Jiaru Jia",
      "Mingzhe Liu",
      "Jiake Xie",
      "Xin Chen",
      "Aiqing Yang",
      "Xin Jiang",
      "Hong Zhang",
      "Yong Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11242"
  },
  {
    "id": "arXiv:2211.11243",
    "title": "Exploiting Personalized Invariance for Better Out-of-distribution  Generalization in Federated Learning",
    "abstract": "Recently, data heterogeneity among the training datasets on the local clients\n(a.k.a., Non-IID data) has attracted intense interest in Federated Learning\n(FL), and many personalized federated learning methods have been proposed to\nhandle it. However, the distribution shift between the training dataset and\ntesting dataset on each client is never considered in FL, despite it being\ngeneral in real-world scenarios. We notice that the distribution shift (a.k.a.,\nout-of-distribution generalization) problem under Non-IID federated setting\nbecomes rather challenging due to the entanglement between personalized and\nspurious information. To tackle the above problem, we elaborate a general\ndual-regularized learning framework to explore the personalized invariance,\ncompared with the exsiting personalized federated learning methods which are\nregularized by a single baseline (usually the global model). Utilizing the\npersonalized invariant features, the developed personalized models can\nefficiently exploit the most relevant information and meanwhile eliminate\nspurious information so as to enhance the out-of-distribution generalization\nperformance for each client. Both the theoretical analysis on convergence and\nOOD generalization performance and the results of extensive experiments\ndemonstrate the superiority of our method over the existing federated learning\nand invariant learning methods, in diverse out-of-distribution and Non-IID data\ncases.",
    "descriptor": "",
    "authors": [
      "Xueyang Tang",
      "Song Guo",
      "Jie Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.11243"
  },
  {
    "id": "arXiv:2211.11246",
    "title": "LSTM based models stability in the context of Sentiment Analysis for  social media",
    "abstract": "Deep learning techniques have proven their effectiveness for Sentiment\nAnalysis (SA) related tasks. Recurrent neural networks (RNN), especially Long\nShort-Term Memory (LSTM) and Bidirectional LSTM, have become a reference for\nbuilding accurate predictive models. However, the models complexity and the\nnumber of hyperparameters to configure raises several questions related to\ntheir stability. In this paper, we present various LSTM models and their key\nparameters, and we perform experiments to test the stability of these models in\nthe context of Sentiment Analysis.",
    "descriptor": "\nComments: Short note, 3 pages, MoroccoAI Annual Conference 2021\n",
    "authors": [
      "Bousselham El Haddaoui",
      "Raddouane Chiheb",
      "Rdouan Faizi",
      "Abdellatif El Afia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.11246"
  },
  {
    "id": "arXiv:2211.11248",
    "title": "Video Background Music Generation: Dataset, Method and Evaluation",
    "abstract": "Music is essential when editing videos, but selecting music manually is\ndifficult and time-consuming. Thus, we seek to automatically generate\nbackground music tracks given video input. This is a challenging task since it\nrequires plenty of paired videos and music to learn their correspondence.\nUnfortunately, there exist no such datasets. To close this gap, we introduce a\ndataset, benchmark model, and evaluation metric for video background music\ngeneration. We introduce SymMV, a video and symbolic music dataset, along with\nchord, rhythm, melody, and accompaniment annotations. To the best of our\nknowledge, it is the first video-music dataset with high-quality symbolic music\nand detailed annotations. We also propose a benchmark video background music\ngeneration framework named V-MusProd, which utilizes music priors of chords,\nmelody, and accompaniment along with video-music relations of semantic, color,\nand motion features. To address the lack of objective metrics for video-music\ncorrespondence, we propose a retrieval-based metric VMCP built upon a powerful\nvideo-music representation learning model. Experiments show that with our\ndataset, V-MusProd outperforms the state-of-the-art method in both music\nquality and correspondence with videos. We believe our dataset, benchmark\nmodel, and evaluation metric will boost the development of video background\nmusic generation.",
    "descriptor": "",
    "authors": [
      "Le Zhuo",
      "Zhaokai Wang",
      "Baisen Wang",
      "Yue Liao",
      "Stanley Peng",
      "Chenxi Bao",
      "Miao Lu",
      "Xiaobo Li",
      "Si Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.11248"
  },
  {
    "id": "arXiv:2211.11250",
    "title": "Computationally Efficient Approach for Preheating of Battery Electric  Vehicles before Fast Charging in Cold Climates",
    "abstract": "This paper investigates battery preheating before fast charging, for a\nbattery electric vehicle (BEV) driving in a cold climate. To prevent the\nbattery from performance degradation at low temperatures, a thermal management\n(TM) system has been considered, including a high-voltage coolant heater (HVCH)\nfor the battery and cabin compartment heating. Accordingly, an optimal control\nproblem (OCP) has been formulated in the form of a nonlinear program (NLP),\naiming at minimising the total energy consumption of the battery. The main\nfocus here is to develop a computationally efficient approach, mimicking the\noptimal preheating behavior without a noticeable increase in the total energy\nconsumption. The proposed algorithm is simple enough to be implemented in a\nlow-level electronic control unit of the vehicle, by eliminating the need for\nsolving the full NLP in the cost of only 1Wh increase in the total energy\nconsumption.",
    "descriptor": "",
    "authors": [
      "Ahad Hamednia",
      "Jimmy Forsman",
      "Nikolce Murgovski",
      "Viktor Larsson",
      "Jonas Fredriksson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.11250"
  },
  {
    "id": "arXiv:2211.11252",
    "title": "OSDG 2.0: a multilingual tool for classifying text data by UN  Sustainable Development Goals (SDGs)",
    "abstract": "Despite concrete indicators and targets, monitoring the progress of the UN\nSustainable Development Goals (SDGs) remains a challenge, given the many\ndifferent actors, initiatives, and institutions involved. OSDG, an open-source\nclassification tool aims to help navigate the SDG related ambiguities through a\nsimple and easy to use application. The tool allows to map and connect\nactivities to the SDGs by identifying SDG -relevant content in any text. This\npaper presents OSDG 2.0, a new iteration of the partnership's work, which marks\na significant improvement in the tool's methodology, as well as support for\ncontent in 15 languages.",
    "descriptor": "",
    "authors": [
      "Lukas Pukelis",
      "Nuria Bautista-Puig",
      "Gust\u0117 Statulevi\u010di\u016bt\u0117",
      "Vilius Stan\u010diauskas",
      "Gokhan Dikmener",
      "Dina Akylbekova"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2211.11252"
  },
  {
    "id": "arXiv:2211.11255",
    "title": "Diffusion Denoising Process for Perceptron Bias in Out-of-distribution  Detection",
    "abstract": "Out-of-distribution (OOD) detection is an important task to ensure the\nreliability and safety of deep learning and the discriminator models outperform\nothers for now. However, the feature extraction of the discriminator models\nmust compress the data and lose certain information, leaving room for bad cases\nand malicious attacks. In this paper, we provide a new assumption that the\ndiscriminator models are more sensitive to some subareas of the input space and\nsuch perceptron bias causes bad cases and overconfidence areas. Under this\nassumption, we design new detection methods and indicator scores. For detection\nmethods, we introduce diffusion models (DMs) into OOD detection. We find that\nthe diffusion denoising process (DDP) of DMs also functions as a novel form of\nasymmetric interpolation, which is suitable to enhance the input and reduce the\noverconfidence areas. For indicator scores, we find that the features of the\ndiscriminator models of OOD inputs occur sharp changes under DDP and use the\nnorm of this dynamic change as our indicator scores. Therefore, we develop a\nnew framework to combine the discriminator and generation models to do OOD\ndetection under our new assumption. The discriminator models provide proper\ndetection spaces and the generation models reduce the overconfidence problem.\nAccording to our experiments on CIFAR10 and CIFAR100, our methods get\ncompetitive results with state-of-the-art methods. Our implementation is\navailable at https://github.com/luping-liu/DiffOOD.",
    "descriptor": "",
    "authors": [
      "Luping Liu",
      "Yi Ren",
      "Xize Cheng",
      "Zhou Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.11255"
  },
  {
    "id": "arXiv:2211.11256",
    "title": "UniMSE: Towards Unified Multimodal Sentiment Analysis and Emotion  Recognition",
    "abstract": "Multimodal sentiment analysis (MSA) and emotion recognition in conversation\n(ERC) are key research topics for computers to understand human behaviors. From\na psychological perspective, emotions are the expression of affect or feelings\nduring a short period, while sentiments are formed and held for a longer\nperiod. However, most existing works study sentiment and emotion separately and\ndo not fully exploit the complementary knowledge behind the two. In this paper,\nwe propose a multimodal sentiment knowledge-sharing framework (UniMSE) that\nunifies MSA and ERC tasks from features, labels, and models. We perform\nmodality fusion at the syntactic and semantic levels and introduce contrastive\nlearning between modalities and samples to better capture the difference and\nconsistency between sentiments and emotions. Experiments on four public\nbenchmark datasets, MOSI, MOSEI, MELD, and IEMOCAP, demonstrate the\neffectiveness of the proposed method and achieve consistent improvements\ncompared with state-of-the-art methods.",
    "descriptor": "\nComments: Accepted to EMNLP 2022 main conference\n",
    "authors": [
      "Guimin Hu",
      "Ting-En Lin",
      "Yi Zhao",
      "Guangming Lu",
      "Yuchuan Wu",
      "Yongbin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11256"
  },
  {
    "id": "arXiv:2211.11257",
    "title": "Computational Optics Meet Domain Adaptation: Transferring Semantic  Segmentation Beyond Aberrations",
    "abstract": "Semantic scene understanding with Minimalist Optical Systems (MOS) in mobile\nand wearable applications remains a challenge due to the corrupted imaging\nquality induced by optical aberrations. However, previous works only focus on\nimproving the subjective imaging quality through computational optics, i.e.\nComputational Imaging (CI) technique, ignoring the feasibility in semantic\nsegmentation. In this paper, we pioneer to investigate Semantic Segmentation\nunder Optical Aberrations (SSOA) of MOS. To benchmark SSOA, we construct\nVirtual Prototype Lens (VPL) groups through optical simulation, generating\nCityscapes-ab and KITTI-360-ab datasets under different behaviors and levels of\naberrations. We look into SSOA via an unsupervised domain adaptation\nperspective to address the scarcity of labeled aberration data in real-world\nscenarios. Further, we propose Computational Imaging Assisted Domain Adaptation\n(CIADA) to leverage prior knowledge of CI for robust performance in SSOA. Based\non our benchmark, we conduct experiments on the robustness of state-of-the-art\nsegmenters against aberrations. In addition, extensive evaluations of possible\nsolutions to SSOA reveal that CIADA achieves superior performance under all\naberration distributions, paving the way for the applications of MOS in\nsemantic scene understanding. Code and dataset will be made publicly available\nat https://github.com/zju-jiangqi/CIADA.",
    "descriptor": "\nComments: Code and dataset will be made publicly available at this https URL\n",
    "authors": [
      "Qi Jiang",
      "Hao Shi",
      "Shaohua Gao",
      "Jiaming Zhang",
      "Kailun Yang",
      "Lei Sun",
      "Kaiwei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2211.11257"
  },
  {
    "id": "arXiv:2211.11259",
    "title": "From Traditional Adaptive Data Caching to Adaptive Context Caching: A  Survey",
    "abstract": "Context data is in demand more than ever with the rapid increase in the\ndevelopment of many context-aware Internet of Things applications. Research in\ncontext and context-awareness is being conducted to broaden its applicability\nin light of many practical and technical challenges. One of the challenges is\nimproving performance when responding to large number of context queries.\nContext Management Platforms that infer and deliver context to applications\nmeasure this problem using Quality of Service (QoS) parameters. Although\ncaching is a proven way to improve QoS, transiency of context and features such\nas variability, heterogeneity of context queries pose an additional real-time\ncost management problem. This paper presents a critical survey of\nstate-of-the-art in adaptive data caching with the objective of developing a\nbody of knowledge in cost- and performance-efficient adaptive caching\nstrategies. We comprehensively survey a large number of research publications\nand evaluate, compare, and contrast different techniques, policies, approaches,\nand schemes in adaptive caching. Our critical analysis is motivated by the\nfocus on adaptively caching context as a core research problem. A formal\ndefinition for adaptive context caching is then proposed, followed by\nidentified features and requirements of a well-designed, objective optimal\nadaptive context caching strategy.",
    "descriptor": "\nComments: This paper is currently under review with ACM Computing Surveys Journal at this time of publishing in arxiv.org\n",
    "authors": [
      "Shakthi Weerasinghe",
      "Arkady Zaslavsky",
      "Seng W. Loke",
      "Alireza Hassani",
      "Amin Abken",
      "Alexey Medvedev"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11259"
  },
  {
    "id": "arXiv:2211.11260",
    "title": "Discovering Evolution Strategies via Meta-Black-Box Optimization",
    "abstract": "Optimizing functions without access to gradients is the remit of black-box\nmethods such as evolution strategies. While highly general, their learning\ndynamics are often times heuristic and inflexible - exactly the limitations\nthat meta-learning can address. Hence, we propose to discover effective update\nrules for evolution strategies via meta-learning. Concretely, our approach\nemploys a search strategy parametrized by a self-attention-based architecture,\nwhich guarantees the update rule is invariant to the ordering of the candidate\nsolutions. We show that meta-evolving this system on a small set of\nrepresentative low-dimensional analytic optimization problems is sufficient to\ndiscover new evolution strategies capable of generalizing to unseen\noptimization problems, population sizes and optimization horizons. Furthermore,\nthe same learned evolution strategy can outperform established neuroevolution\nbaselines on supervised and continuous control tasks. As additional\ncontributions, we ablate the individual neural network components of our\nmethod; reverse engineer the learned strategy into an explicit heuristic form,\nwhich remains highly competitive; and show that it is possible to\nself-referentially train an evolution strategy from scratch, with the learned\nupdate rule used to drive the outer meta-learning loop.",
    "descriptor": "\nComments: 22 pages, 21 figures\n",
    "authors": [
      "Robert Tjarko Lange",
      "Tom Schaul",
      "Yutian Chen",
      "Tom Zahavy",
      "Valenti Dallibard",
      "Chris Lu",
      "Satinder Singh",
      "Sebastian Flennerhag"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11260"
  },
  {
    "id": "arXiv:2211.11262",
    "title": "Boosting Novel Category Discovery Over Domains with Soft Contrastive  Learning and All-in-One Classifier",
    "abstract": "Unsupervised domain adaptation (UDA) has been highly successful in\ntransferring knowledge acquired from a label-rich source domain to a\nlabel-scarce target domain. Open-set domain adaptation (ODA) and universal\ndomain adaptation (UNDA) have been proposed as solutions to the problem\nconcerning the presence of additional novel categories in the target domain.\nExisting ODA and UNDA approaches treat all novel categories as one unified\nunknown class and attempt to detect this unknown class during the training\nprocess. We find that domain variance leads to more significant view-noise in\nunsupervised data augmentation, affecting the further applications of\ncontrastive learning~(CL), as well as the current closed-set classifier and\nopen-set classifier causing the model to be overconfident in novel class\ndiscovery. To address the above two issues, we propose Soft-contrastive\nAll-in-one Network~(SAN) for ODA and UNDA tasks. SAN includes a novel\ndata-augmentation-based CL loss, which is used to improve the representational\ncapability, and a more human-intuitive classifier, which is used to improve the\nnew class discovery capability. The soft contrastive learning~(SCL) loss is\nused to weaken the adverse effects of the data-augmentation label noise\nproblem, which is amplified in domain transfer. The All-in-One~(AIO) classifier\novercomes the overconfidence problem of the current mainstream closed-set\nclassifier and open-set classifier in a more human-intuitive way. The\nvisualization results and ablation experiments demonstrate the importance of\nthe two proposed innovations. Moreover, extensive experimental results on ODA\nand UNDA show that SAN has advantages over the existing state-of-the-art\nmethods.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Zelin Zang",
      "Lei Shang",
      "Senqiao Yang",
      "Baigui Sun",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11262"
  },
  {
    "id": "arXiv:2211.11270",
    "title": "LHDR: HDR Reconstruction for Legacy Content using a Lightweight DNN",
    "abstract": "High dynamic range (HDR) image is widely-used in graphics and photography due\nto the rich information it contains. Recently the community has started using\ndeep neural network (DNN) to reconstruct standard dynamic range (SDR) images\ninto HDR. Albeit the superiority of current DNN-based methods, their\napplication scenario is still limited: (1) heavy model impedes real-time\nprocessing, and (2) inapplicable to legacy SDR content with more degradation\ntypes. Therefore, we propose a lightweight DNN-based method trained to tackle\nlegacy SDR. For better design, we reform the problem modeling and emphasize\ndegradation model. Experiments show that our method reached appealing\nperformance with minimal computational cost compared with others.",
    "descriptor": "\nComments: Accepted in ACCV2022\n",
    "authors": [
      "Cheng Guo",
      "Xiuhua Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.11270"
  },
  {
    "id": "arXiv:2211.11276",
    "title": "300 GHz Channel Measurement and Characterization in the Atrium of a  Building",
    "abstract": "With abundant bandwidth resource, the Terahertz band (0.1~THz to 10~THz) is\nenvisioned as a key technology to realize ultra-high data rates in the 6G and\nbeyond mobile communication systems. However, moving to the THz band, existing\nchannel models dedicated for microwave or millimeter-wave bands are\nineffective. To fill this research gap, extensive channel measurement campaigns\nand characterizations are necessary. In this paper, using a frequency-domain\nVector Network Analyzer (VNA)-based sounder, a measurement campaign is\nconducted in the outdoor atrium of a building in 306-321 GHz band. The measured\ndata are further processed to obtain the channel transfer functions (CTFs),\nparameters of multipath components (MPCs), as well as clustering results. Based\non the MPC parameters, the channel characteristics, such as path loss, shadow\nfading, K-factor, etc., are calculated and analyzed. The extracted channel\ncharacteristics and numerology are helpful to study channel modeling and guide\nsystem design for THz communications.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Yuanbo Li",
      "Yiqin Wang",
      "Yi Chen",
      "Ziming Yu",
      "Chong Han"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.11276"
  },
  {
    "id": "arXiv:2211.11277",
    "title": "DrapeNet: Generating Garments and Draping them with Self-Supervision",
    "abstract": "Recent approaches to drape garments quickly over arbitrary human bodies\nleverage self-supervision to eliminate the need for large training sets.\nHowever, they are designed to train one network per clothing item, which\nseverely limits their generalization abilities. In our work, we rely on\nself-supervision to train a single network to drape multiple garments. This is\nachieved by predicting a 3D deformation field conditioned on the latent codes\nof a generative network, which models garments as unsigned distance fields. Our\npipeline can generate and drape previously unseen garments of any topology,\nwhose shape can be edited by manipulating their latent codes. Being fully\ndifferentiable, our formulation makes it possible to recover accurate 3D models\nof garments from partial observations -- images or 3D scans -- via gradient\ndescent. Our code will be made publicly available.",
    "descriptor": "",
    "authors": [
      "Luca De Luigi",
      "Ren Li",
      "Beno\u00eet Guillard",
      "Mathieu Salzmann",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11277"
  },
  {
    "id": "arXiv:2211.11281",
    "title": "Intelligent Computing: The Latest Advances, Challenges and Future",
    "abstract": "Computing is a critical driving force in the development of human\ncivilization. In recent years, we have witnessed the emergence of intelligent\ncomputing, a new computing paradigm that is reshaping traditional computing and\npromoting digital revolution in the era of big data, artificial intelligence\nand internet-of-things with new computing theories, architectures, methods,\nsystems, and applications. Intelligent computing has greatly broadened the\nscope of computing, extending it from traditional computing on data to\nincreasingly diverse computing paradigms such as perceptual intelligence,\ncognitive intelligence, autonomous intelligence, and human-computer fusion\nintelligence. Intelligence and computing have undergone paths of different\nevolution and development for a long time but have become increasingly\nintertwined in recent years: intelligent computing is not only\nintelligence-oriented but also intelligence-driven. Such cross-fertilization\nhas prompted the emergence and rapid advancement of intelligent computing.\nIntelligent computing is still in its infancy and an abundance of innovations\nin the theories, systems, and applications of intelligent computing are\nexpected to occur soon. We present the first comprehensive survey of literature\non intelligent computing, covering its theory fundamentals, the technological\nfusion of intelligence and computing, important applications, challenges, and\nfuture perspectives. We believe that this survey is highly timely and will\nprovide a comprehensive reference and cast valuable insights into intelligent\ncomputing for academic and industrial researchers and practitioners.",
    "descriptor": "",
    "authors": [
      "Shiqiang Zhu",
      "Ting Yu",
      "Tao Xu",
      "Hongyang Chen",
      "Schahram Dustdar",
      "Sylvain Gigan",
      "Deniz Gunduz",
      "Ekram Hossain",
      "Yaochu Jin",
      "Feng Lin",
      "Bo Liu",
      "Zhiguo Wan",
      "Ji Zhang",
      "Zhifeng Zhao",
      "Wentao Zhu",
      "Zuoning Chen",
      "Tariq Durrani",
      "Huaimin Wang",
      "Jiangxing Wu",
      "Tongyi Zhang",
      "Yunhe Pan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11281"
  },
  {
    "id": "arXiv:2211.11282",
    "title": "Task-Specific Data Augmentation and Inference Processing for VIPriors  Instance Segmentation Challenge",
    "abstract": "Instance segmentation is applied widely in image editing, image analysis and\nautonomous driving, etc. However, insufficient data is a common problem in\npractical applications. The Visual Inductive Priors(VIPriors) Instance\nSegmentation Challenge has focused on this problem. VIPriors for Data-Efficient\nComputer Vision Challenges ask competitors to train models from scratch in a\ndata-deficient setting, but there are some visual inductive priors that can be\nused. In order to address the VIPriors instance segmentation problem, we\ndesigned a Task-Specific Data Augmentation(TS-DA) strategy and Inference\nProcessing(TS-IP) strategy. The main purpose of task-specific data augmentation\nstrategy is to tackle the data-deficient problem. And in order to make the most\nof visual inductive priors, we designed a task-specific inference processing\nstrategy. We demonstrate the applicability of proposed method on VIPriors\nInstance Segmentation Challenge. The segmentation model applied is Hybrid Task\nCascade based detector on the Swin-Base based CBNetV2 backbone. Experimental\nresults demonstrate that proposed method can achieve a competitive result on\nthe test set of 2022 VIPriors Instance Segmentation Challenge, with 0.531\nAP@0.50:0.95.",
    "descriptor": "\nComments: The first place solution for ECCV 2022 VIPriors Instance Segmentation Challenge. arXiv admin note: text overlap with arXiv:2209.13899\n",
    "authors": [
      "Bo Yan",
      "Xingran Zhao",
      "Yadong Li",
      "Hongbin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11282"
  },
  {
    "id": "arXiv:2211.11284",
    "title": "Intent-Based Orchestration for Application Relocation in a 5G  Cloud-native Platform",
    "abstract": "The need of mobile network operators for cost-effectiveness is driving 5G and\nbeyond networks towards highly flexible and agile deployments to adapt to\ndynamic and resource-constrained scenarios while meeting a myriad of user\nnetwork stakeholders' requirements. In this setting, we consider that\nzero-touch orchestration schemes based on cloud-native deployments equipped\nwith end-to-end monitoring capabilities provide the necessary technology mix to\nbe a solution candidate. This demonstration, built on top of an end-to-end\ncloud-native 5G experimental platform with over-the-air transmissions, shows\nhow dynamic orchestration can relocate container-based end-user applications to\nfulfil intent-based requirements. Accordingly, we provide an experimental\nvalidation to showcase how the platform enables the desired flexible and agile\n5G deployments.",
    "descriptor": "",
    "authors": [
      "Sergio Barrachina-Mu\u00f1oz",
      "Jorge Baranda",
      "Miquel Payar\u00f3",
      "Josep Mangues-Bafalluy"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.11284"
  },
  {
    "id": "arXiv:2211.11290",
    "title": "Koopman interpretation and analysis of a public-key cryptosystem:  Diffie-Hellman key exchange",
    "abstract": "The security of public-key cryptosystems relies on computationally hard\nproblems, that are classically analyzed by number theoretic methods. In this\npaper, we introduce a new perspective on cryptosystems by interpreting the\nDiffie-Hellman key exchange as a nonlinear dynamical system. Employing Koopman\ntheory, we transfer this dynamical system into a higher-dimensional space to\nanalytically derive a purely linear system that equivalently describes the\nunderlying cryptosystem. In this form, analytic tools for linear systems allow\nus to reconstruct the secret integers of the key exchange by simple\nmanipulations. Moreover, we provide an upper bound on the minimal required\nlifting dimension to obtain perfect accuracy. To demonstrate the potential of\nour method, we relate our findings to existing results on algorithmic\ncomplexity. Finally, we transfer this approach to a data-driven setting where\nthe Koopman representation is learned from data samples of the cryptosystem.",
    "descriptor": "\nComments: 8 pages. This work has been submitted to IFAC for possible publication\n",
    "authors": [
      "Sebastian Schlor",
      "Robin Str\u00e4sser",
      "Frank Allg\u00f6wer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.11290"
  },
  {
    "id": "arXiv:2211.11292",
    "title": "Revealing intra-urban spatial structure through an exploratory analysis  by combining road network abstraction model and taxi trajectory data",
    "abstract": "The unprecedented urbanization in China has dramatically changed the urban\nspatial structure of cities. With the proliferation of individual-level\ngeospatial big data, previous studies have widely used the network abstraction\nmodel to reveal the underlying urban spatial structure. However, the\nconstruction of network abstraction models primarily focuses on the topology of\nthe road network without considering individual travel flows along with the\nroad networks. Individual travel flows reflect the urban dynamics, which can\nfurther help understand the underlying spatial structure. This study therefore\naims to reveal the intra-urban spatial structure by integrating the road\nnetwork abstraction model and individual travel flows. To achieve this goal, we\n1) quantify the spatial interaction relatedness of road segments based on the\nWord2Vec model using large volumes of taxi trip data, then 2) characterize the\nroad abstraction network model according to the identified spatial interaction\nrelatedness, and 3) implement a community detection algorithm to reveal\nsub-regions of a city. Our results reveal three levels of hierarchical spatial\nstructures in the Wuhan metropolitan area. This study provides a data-driven\napproach to the investigation of urban spatial structure via identifying\ntraffic interaction patterns on the road network, offering insights to urban\nplanning practice and transportation management.",
    "descriptor": "",
    "authors": [
      "Sheng Hu",
      "Song Gao",
      "Wei Luo",
      "Liang Wu",
      "Tianqi Li",
      "Yongyang Xu",
      "Ziwei Zhang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.11292"
  },
  {
    "id": "arXiv:2211.11293",
    "title": "FlowLens: Seeing Beyond the FoV via Flow-guided Clip-Recurrent  Transformer",
    "abstract": "Limited by hardware cost and system size, camera's Field-of-View (FoV) is not\nalways satisfactory. However, from a spatio-temporal perspective, information\nbeyond the camera's physical FoV is off-the-shelf and can actually be obtained\n\"for free\" from the past. In this paper, we propose a novel task termed\nBeyond-FoV Estimation, aiming to exploit past visual cues and bidirectional\nbreak through the physical FoV of a camera. We put forward a FlowLens\narchitecture to expand the FoV by achieving feature propagation explicitly by\noptical flow and implicitly by a novel clip-recurrent transformer, which has\ntwo appealing features: 1) FlowLens comprises a newly proposed Clip-Recurrent\nHub with 3D-Decoupled Cross Attention (DDCA) to progressively process global\ninformation accumulated in the temporal dimension. 2) A multi-branch Mix Fusion\nFeed Forward Network (MixF3N) is integrated to enhance the spatially-precise\nflow of local features. To foster training and evaluation, we establish\nKITTI360-EX, a dataset for outer- and inner FoV expansion. Extensive\nexperiments on both video inpainting and beyond-FoV estimation tasks show that\nFlowLens achieves state-of-the-art performance. Code will be made publicly\navailable at https://github.com/MasterHow/FlowLens.",
    "descriptor": "\nComments: Code will be made publicly available at this https URL\n",
    "authors": [
      "Hao Shi",
      "Qi Jiang",
      "Kailun Yang",
      "Xiaoting Yin",
      "Kaiwei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.11293"
  },
  {
    "id": "arXiv:2211.11294",
    "title": "TSDF: A simple yet comprehensive, unified data storage and exchange  format standard for digital biosensor data in health applications",
    "abstract": "Digital sensors are increasingly being used to monitor the change over time\nof physiological processes in biological health and disease, often using\nwearable devices. This generates very large amounts of digital sensor data, for\nwhich, a consensus on a common storage, exchange and archival data format\nstandard, has yet to be reached. To address this gap, we propose Time Series\nData Format (TSDF): a unified, standardized format for storing all types of\nphysiological sensor data, across diverse disease areas. We pose a series of\nformat design criteria and review in detail current storage and exchange\nformats. When judged against these criteria, we find these current formats\nlacking, and propose a very simple, intuitive standard for both numerical\nsensor data and metadata, based on raw binary data and JSON-format text files,\nfor sensor measurements/timestamps and metadata, respectively. By focusing on\nthe common characteristics of diverse biosensor data, we define a set of\nnecessary and sufficient metadata fields for storing, processing, exchanging,\narchiving and reliably interpreting, multi-channel biological time series data.\nOur aim is for this standardized format to increase the interpretability and\nexchangeability of data, thereby contributing to scientific reproducibility in\nstudies where digital biosensor data forms a key evidence base.",
    "descriptor": "",
    "authors": [
      "Kasper Claes",
      "Valentina Ticcinelli",
      "Reham Badawy",
      "Yordan P. Raykov",
      "Luc J.W. Evers",
      "Max A. Little"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.11294"
  },
  {
    "id": "arXiv:2211.11296",
    "title": "SeeABLE: Soft Discrepancies and Bounded Contrastive Learning for  Exposing Deepfakes",
    "abstract": "Modern deepfake detectors have achieved encouraging results, when training\nand test images are drawn from the same collection. However, when applying\nthese detectors to faces manipulated using an unknown technique, considerable\nperformance drops are typically observed. In this work, we propose a novel\ndeepfake detector, called SeeABLE, that formalizes the detection problem as a\n(one-class) out-of-distribution detection task and generalizes better to unseen\ndeepfakes. Specifically, SeeABLE uses a novel data augmentation strategy to\nsynthesize fine-grained local image anomalies (referred to as\nsoft-discrepancies) and pushes those pristine disrupted faces towards\npredefined prototypes using a novel regression-based bounded contrastive loss.\nTo strengthen the generalization performance of SeeABLE to unknown deepfake\ntypes, we generate a rich set of soft discrepancies and train the detector: (i)\nto localize, which part of the face was modified, and (ii) to identify the\nalteration type. Using extensive experiments on widely used datasets, SeeABLE\nconsiderably outperforms existing detectors, with gains of up to +10\\% on the\nDFDC-preview dataset in term of detection accuracy over SoTA methods while\nusing a simpler model. Code will be made publicly available.",
    "descriptor": "",
    "authors": [
      "Nicolas Larue",
      "Ngoc-Son Vu",
      "Vitomir Struc",
      "Peter Peer",
      "Vassilis Christophides"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11296"
  },
  {
    "id": "arXiv:2211.11297",
    "title": "In-sample Curriculum Learning by Sequence Completion for Natural  Language Generation",
    "abstract": "Curriculum learning has shown promising improvements in multiple domains by\ntraining machine learning models from easy samples to hard ones. Previous works\nwhich either design rules or train models for scoring the difficulty highly\nrely on task-specific expertise, and cannot generalize. Inspired by the\n``easy-to-hard'' intuition, we propose to do in-sample curriculum learning for\nnatural language generation tasks. Our learning strategy starts training the\nmodel to generate the last few words, i.e., do sequence completion, and\ngradually extends to generate the whole output sequence. Comprehensive\nexperiments show that it generalizes well to different tasks and achieves\nsignificant improvements over strong baselines.",
    "descriptor": "",
    "authors": [
      "Qi Jia",
      "Yizhu Liu",
      "Haifeng Tang",
      "Kenny Q. Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11297"
  },
  {
    "id": "arXiv:2211.11298",
    "title": "Exploring Physical Latent Spaces for Deep Learning",
    "abstract": "We explore training deep neural network models in conjunction with physical\nsimulations via partial differential equations (PDEs), using the simulated\ndegrees of freedom as latent space for the neural network. In contrast to\nprevious work, we do not impose constraints on the simulated space, but rather\ntreat its degrees of freedom purely as tools to be used by the neural network.\nWe demonstrate this concept for learning reduced representations. It is\ntypically extremely challenging for conventional simulations to faithfully\npreserve the correct solutions over long time-spans with traditional, reduced\nrepresentations. This problem is particularly pronounced for solutions with\nlarge amounts of small scale features. Here, data-driven methods can learn to\nrestore the details as required for accurate solutions of the underlying PDE\nproblem. We explore the use of physical, reduced latent space within this\ncontext, and train models such that they can modify the content of physical\nstates as much as needed to best satisfy the learning objective. Surprisingly,\nthis autonomy allows the neural network to discover alternate dynamics that\nenable a significantly improved performance in the given tasks. We demonstrate\nthis concept for a range of challenging test cases, among others, for\nNavier-Stokes based turbulence simulations.",
    "descriptor": "\nComments: 25 pages, 29 figures\n",
    "authors": [
      "Chloe Paliard",
      "Nils Thuerey",
      "Kiwon Um"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11298"
  },
  {
    "id": "arXiv:2211.11300",
    "title": "Multi-Level Knowledge Distillation for Out-of-Distribution Detection in  Text",
    "abstract": "Self-supervised representation learning has proved to be a valuable component\nfor out-of-distribution (OoD) detection with only the texts of in-distribution\n(ID) examples. These approaches either train a language model from scratch or\nfine-tune a pre-trained language model using ID examples, and then take\nperplexity as output by the language model as OoD scores. In this paper, we\nanalyse the complementary characteristics of both OoD detection methods and\npropose a multi-level knowledge distillation approach to integrate their\nstrengths, while mitigating their limitations. Specifically, we use a\nfine-tuned model as the teacher to teach a randomly initialized student model\non the ID examples. Besides the prediction layer distillation, we present a\nsimilarity-based intermediate layer distillation method to facilitate the\nstudent's awareness of the information flow inside the teacher's layers. In\nthis way, the derived student model gains the teacher's rich knowledge about\nthe ID data manifold due to pre-training, while benefiting from seeing only ID\nexamples during parameter learning, which promotes more distinguishable\nfeatures for OoD detection. We conduct extensive experiments over multiple\nbenchmark datasets, i.e., CLINC150, SST, 20 NewsGroups, and AG News; showing\nthat the proposed method yields new state-of-the-art performance.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Qianhui Wu",
      "Huiqiang Jiang",
      "Haonan Yin",
      "Borje F. Karlsson",
      "Chin-Yew Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11300"
  },
  {
    "id": "arXiv:2211.11303",
    "title": "Hierarchical LU preconditioning for the time-harmonic Maxwell equations",
    "abstract": "The time-harmonic Maxwell equations are used to study the effect of electric\nand magnetic fields on each other. Although the linear systems resulting from\nsolving this system using FEMs are sparse, direct solvers cannot reach the\nlinear complexity. In fact, due to the indefinite system matrix, iterative\nsolvers suffer from slow convergence. In this work, we study the effect of\nusing the inverse of $\\mathcal{H}$-matrix approximations of the Galerkin\nmatrices arising from N\\'ed\\'elec's edge FEM discretization to solve the linear\nsystem directly. We also investigate the impact of applying an $\\mathcal{H}-LU$\nfactorization as a preconditioner and we study the number of iterations to\nsolve the linear system using iterative solvers.",
    "descriptor": "",
    "authors": [
      "Maryam Parvizi",
      "Amirreza Khodadadian",
      "Sven Beuchler",
      "Thomas Wick"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.11303"
  },
  {
    "id": "arXiv:2211.11304",
    "title": "TCBERT: A Technical Report for Chinese Topic Classification BERT",
    "abstract": "Bidirectional Encoder Representations from Transformers or\nBERT~\\cite{devlin-etal-2019-bert} has been one of the base models for various\nNLP tasks due to its remarkable performance. Variants customized for different\nlanguages and tasks are proposed to further improve the performance. In this\nwork, we investigate supervised continued\npre-training~\\cite{gururangan-etal-2020-dont} on BERT for Chinese topic\nclassification task. Specifically, we incorporate prompt-based learning and\ncontrastive learning into the pre-training. To adapt to the task of Chinese\ntopic classification, we collect around 2.1M Chinese data spanning various\ntopics. The pre-trained Chinese Topic Classification BERTs (TCBERTs) with\ndifferent parameter sizes are open-sourced at\n\\url{https://huggingface.co/IDEA-CCNL}.",
    "descriptor": "",
    "authors": [
      "Ting Han",
      "Kunhao Pan",
      "Xinyu Chen",
      "Dingjie Song",
      "Yuchen Fan",
      "Xinyu Gao",
      "Ruyi Gan",
      "Jiaxing Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11304"
  },
  {
    "id": "arXiv:2211.11306",
    "title": "A Computationally Efficient Robust Model Predictive Control Framework  for Ecological Adaptive Cruise Control Strategy of Electric Vehicles",
    "abstract": "The recent advancement in vehicular networking technology provides novel\nsolutions for designing intelligent and sustainable vehicle motion controllers.\nThis work addresses a car-following task, where the feedback linearisation\nmethod is combined with a robust model predictive control (RMPC) scheme to\nsafely, optimally and efficiently control a connected electric vehicle. In\nparticular, the nonlinear dynamics are linearised through a feedback\nlinearisation method to maintain an efficient computational speed and to\nguarantee global optimality. At the same time, the inevitable model mismatch is\ndealt with by the RMPC design. The control objective of the RMPC is to optimise\nthe electric energy efficiency of the ego vehicle with consideration of a\nbounded model mismatch disturbance subject to satisfaction of physical and\nsafety constraints. Numerical results first verify the validity and robustness\nthrough a comparison between the proposed RMPC and a nominal MPC. Further\ninvestigation into the performance of the proposed method reveals a higher\nenergy efficiency and passenger comfort level as compared to a recently\nproposed benchmark method using the space-domain modelling approach.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Sheng Yu",
      "Xiao Pan",
      "Anastasis Georgiou",
      "Boli Chen",
      "Imad M. Jaimoukha",
      "Simos A. Evangelou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.11306"
  },
  {
    "id": "arXiv:2211.11308",
    "title": "Novel transfer learning schemes based on Siamese networks and synthetic  data",
    "abstract": "Transfer learning schemes based on deep networks which have been trained on\nhuge image corpora offer state-of-the-art technologies in computer vision.\nHere, supervised and semi-supervised approaches constitute efficient\ntechnologies which work well with comparably small data sets. Yet, such\napplications are currently restricted to application domains where suitable\ndeepnetwork models are readily available. In this contribution, we address an\nimportant application area in the domain of biotechnology, the automatic\nanalysis of CHO-K1 suspension growth in microfluidic single-cell cultivation,\nwhere data characteristics are very dissimilar to existing domains and trained\ndeep networks cannot easily be adapted by classical transfer learning. We\npropose a novel transfer learning scheme which expands a recently introduced\nTwin-VAE architecture, which is trained on realistic and synthetic data, and we\nmodify its specialized training procedure to the transfer learning domain. In\nthe specific domain, often only few to no labels exist and annotations are\ncostly. We investigate a novel transfer learning strategy, which incorporates a\nsimultaneous retraining on natural and synthetic data using an invariant shared\nrepresentation as well as suitable target variables, while it learns to handle\nunseen data from a different microscopy tech nology. We show the superiority of\nthe variation of our Twin-VAE architecture over the state-of-the-art transfer\nlearning methodology in image processing as well as classical image processing\ntechnologies, which persists, even with strongly shortened training times and\nleads to satisfactory results in this domain. The source code is available at\nhttps://github.com/dstallmann/transfer_learning_twinvae, works cross-platform,\nis open-source and free (MIT licensed) software. We make the data sets\navailable at https://pub.uni-bielefeld.de/record/2960030.",
    "descriptor": "",
    "authors": [
      "Dominik Stallmann",
      "Philip Kenneweg",
      "Barbara Hammer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.11308"
  },
  {
    "id": "arXiv:2211.11309",
    "title": "H-VFI: Hierarchical Frame Interpolation for Videos with Large Motions",
    "abstract": "Capitalizing on the rapid development of neural networks, recent video frame\ninterpolation (VFI) methods have achieved notable improvements. However, they\nstill fall short for real-world videos containing large motions. Complex\ndeformation and/or occlusion caused by large motions make it an extremely\ndifficult problem in video frame interpolation. In this paper, we propose a\nsimple yet effective solution, H-VFI, to deal with large motions in video frame\ninterpolation. H-VFI contributes a hierarchical video interpolation transformer\n(HVIT) to learn a deformable kernel in a coarse-to-fine strategy in multiple\nscales. The learnt deformable kernel is then utilized in convolving the input\nframes for predicting the interpolated frame. Starting from the smallest scale,\nH-VFI updates the deformable kernel by a residual in succession based on former\npredicted kernels, intermediate interpolated results and hierarchical features\nfrom transformer. Bias and masks to refine the final outputs are then predicted\nby a transformer block based on interpolated results. The advantage of such a\nprogressive approximation is that the large motion frame interpolation problem\ncan be decomposed into several relatively simpler sub-tasks, which enables a\nvery accurate prediction in the final results. Another noteworthy contribution\nof our paper consists of a large-scale high-quality dataset, YouTube200K, which\ncontains videos depicting a great variety of scenarios captured at high\nresolution and high frame rate. Extensive experiments on multiple frame\ninterpolation benchmarks validate that H-VFI outperforms existing\nstate-of-the-art methods especially for videos with large motions.",
    "descriptor": "",
    "authors": [
      "Changlin Li",
      "Guangyang Wu",
      "Yanan Sun",
      "Xin Tao",
      "Chi-Keung Tang",
      "Yu-Wing Tai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11309"
  },
  {
    "id": "arXiv:2211.11312",
    "title": "Understanding the Vulnerability of Skeleton-based Human Activity  Recognition via Black-box Attack",
    "abstract": "Human Activity Recognition (HAR) has been employed in a wide range of\napplications, e.g. self-driving cars, where safety and lives are at stake.\nRecently, the robustness of existing skeleton-based HAR methods has been\nquestioned due to their vulnerability to adversarial attacks, which causes\nconcerns considering the scale of the implication. However, the proposed\nattacks require the full-knowledge of the attacked classifier, which is overly\nrestrictive. In this paper, we show such threats indeed exist, even when the\nattacker only has access to the input/output of the model. To this end, we\npropose the very first black-box adversarial attack approach in skeleton-based\nHAR called BASAR. BASAR explores the interplay between the classification\nboundary and the natural motion manifold. To our best knowledge, this is the\nfirst time data manifold is introduced in adversarial attacks on time series.\nVia BASAR, we find on-manifold adversarial samples are extremely deceitful and\nrather common in skeletal motions, in contrast to the common belief that\nadversarial samples only exist off-manifold. Through exhaustive evaluation, we\nshow that BASAR can deliver successful attacks across classifiers, datasets,\nand attack modes. By attack, BASAR helps identify the potential causes of the\nmodel vulnerability and provides insights on possible improvements. Finally, to\nmitigate the newly identified threat, we propose a new adversarial training\napproach by leveraging the sophisticated distributions of on/off-manifold\nadversarial samples, called mixed manifold-based adversarial training (MMAT).\nMMAT can successfully help defend against adversarial attacks without\ncompromising classification accuracy.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2103.05266\n",
    "authors": [
      "Yunfeng Diao",
      "He Wang",
      "Tianjia Shao",
      "Yong-Liang Yang",
      "Kun Zhou",
      "David Hogg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11312"
  },
  {
    "id": "arXiv:2211.11314",
    "title": "JSON Stats Analyzer",
    "abstract": "In this paper, we present the JSON Stats Analyzer, a free-to-use open-source\nweb-based JavaScript tool and module that provides JSON document analysis. We\nexplain how the JSON Stats Analyzer works, its usage alongside the\ndemonstration of eleven JSON documents from Tier 1, Tier 2 and Tier 3 from our\nproposed taxonomy that categorizes JSON documents according to their size,\ncontent, redundancy and nesting characteristics. For each JSON document, we\nprovide its definition, characteristics and the document structure, alongside a\nvisual representation of the JSON document structure and its summary\nstatistics.",
    "descriptor": "\nComments: 18 pages. arXiv admin note: text overlap with arXiv:2201.03051\n",
    "authors": [
      "Juan Cruz Viotti",
      "Mital Kinderkhedia"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.11314"
  },
  {
    "id": "arXiv:2211.11315",
    "title": "Beyond Attentive Tokens: Incorporating Token Importance and Diversity  for Efficient Vision Transformers",
    "abstract": "Vision transformers have achieved significant improvements on various vision\ntasks but their quadratic interactions between tokens significantly reduce\ncomputational efficiency. Many pruning methods have been proposed to remove\nredundant tokens for efficient vision transformers recently. However, existing\nstudies mainly focus on the token importance to preserve local attentive tokens\nbut completely ignore the global token diversity. In this paper, we emphasize\nthe cruciality of diverse global semantics and propose an efficient token\ndecoupling and merging method that can jointly consider the token importance\nand diversity for token pruning. According to the class token attention, we\ndecouple the attentive and inattentive tokens. In addition to preserving the\nmost discriminative local tokens, we merge similar inattentive tokens and match\nhomogeneous attentive tokens to maximize the token diversity. Despite its\nsimplicity, our method obtains a promising trade-off between model complexity\nand classification accuracy. On DeiT-S, our method reduces the FLOPs by 35%\nwith only a 0.2% accuracy drop. Notably, benefiting from maintaining the token\ndiversity, our method can even improve the accuracy of DeiT-T by 0.1% after\nreducing its FLOPs by 40%.",
    "descriptor": "",
    "authors": [
      "Sifan Long",
      "Zhen Zhao",
      "Jimin Pi",
      "Shengsheng Wang",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11315"
  },
  {
    "id": "arXiv:2211.11316",
    "title": "ElegantSeg: End-to-End Holistic Learning for Extra-Large Image Semantic  Segmentation",
    "abstract": "This paper presents a new paradigm for Extra-large image semantic\nSegmentation, called ElegantSeg, that capably processes holistic extra-large\nimage semantic segmentation (ELISS). The extremely large sizes of extra-large\nimages (ELIs) tend to cause GPU memory exhaustion. To tackle this issue,\nprevailing works either follow the global-local fusion pipeline or conduct the\nmulti-stage refinement. These methods can only process limited information at\none time, and they are not able to thoroughly exploit the abundant information\nin ELIs. Unlike previous methods, ElegantSeg can elegantly process holistic\nELISS by extending the tensor storage from GPU memory to host memory. To the\nbest of our knowledge, it is the first time that ELISS can be performed\nholistically. Besides, ElegantSeg is specifically designed with three modules\nto utilize the characteristics of ELIs, including the multiple large kernel\nmodule for developing long-range dependency, the efficient class relation\nmodule for building holistic contextual relationships, and the boundary-aware\nenhancement module for obtaining complete object boundaries. ElegantSeg\noutperforms previous state-of-the-art on two typical ELISS datasets. We hope\nthat ElegantSeg can open a new perspective for ELISS. The code and models will\nbe made publicly available.",
    "descriptor": "",
    "authors": [
      "Wei Chen",
      "Yansheng Li",
      "Bo Dang",
      "Yongjun Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11316"
  },
  {
    "id": "arXiv:2211.11317",
    "title": "DeSTSeg: Segmentation Guided Denoising Student-Teacher for Anomaly  Detection",
    "abstract": "Visual anomaly detection, an important problem in computer vision, is usually\nformulated as a one-class classification and segmentation task. The\nstudent-teacher (S-T) framework has proved to be effective in solving this\nchallenge. However, previous works based on S-T only empirically applied\nconstraints on normal data and fused multi-level information. In this study, we\npropose an improved model called DeSTSeg, which integrates a pre-trained\nteacher network, a denoising student encoder-decoder, and a segmentation\nnetwork into one framework. First, to strengthen the constraints on anomalous\ndata, we introduce a denoising procedure that allows the student network to\nlearn more robust representations. From synthetically corrupted normal images,\nwe train the student network to match the teacher network feature of the same\nimages without corruption. Second, to fuse the multi-level S-T features\nadaptively, we train a segmentation network with rich supervision from\nsynthetic anomaly masks, achieving a substantial performance improvement.\nExperiments on the industrial inspection benchmark dataset demonstrate that our\nmethod achieves state-of-the-art performance, 98.6% on image-level ROC, 75.8%\non pixel-level average precision, and 76.4% on instance-level average\nprecision.",
    "descriptor": "",
    "authors": [
      "Xuan Zhang",
      "Shiyu Li",
      "Xi Li",
      "Ping Huang",
      "Jiulong Shan",
      "Ting Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11317"
  },
  {
    "id": "arXiv:2211.11318",
    "title": "Avoiding order reduction with explicit Runge-Kutta exponential methods  in nonlinear initial boundary value problems",
    "abstract": "In this paper a technique is given to recover the classical order of the\nmethod when explicit exponential Runge-Kutta methods integrate\nreaction-diffusion problems. Although methods of high stiff order for problems\nwith vanishing boundary conditions can be constructed, that may imply\nincreasing the number of stages and therefore, the computational cost seems\nbigger than the technique which is suggested here, which just adds some terms\nwith information on the boundaries. Moreover, time-dependent boundary\nconditions are directly tackled here.",
    "descriptor": "",
    "authors": [
      "Bego\u00f1a Cano",
      "Mar\u00ed a Jes\u00fas Moreta"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.11318"
  },
  {
    "id": "arXiv:2211.11319",
    "title": "VectorFusion: Text-to-SVG by Abstracting Pixel-Based Diffusion Models",
    "abstract": "Diffusion models have shown impressive results in text-to-image synthesis.\nUsing massive datasets of captioned images, diffusion models learn to generate\nraster images of highly diverse objects and scenes. However, designers\nfrequently use vector representations of images like Scalable Vector Graphics\n(SVGs) for digital icons or art. Vector graphics can be scaled to any size, and\nare compact. We show that a text-conditioned diffusion model trained on pixel\nrepresentations of images can be used to generate SVG-exportable vector\ngraphics. We do so without access to large datasets of captioned SVGs. By\noptimizing a differentiable vector graphics rasterizer, our method,\nVectorFusion, distills abstract semantic knowledge out of a pretrained\ndiffusion model. Inspired by recent text-to-3D work, we learn an SVG consistent\nwith a caption using Score Distillation Sampling. To accelerate generation and\nimprove fidelity, VectorFusion also initializes from an image sample.\nExperiments show greater quality than prior work, and demonstrate a range of\nstyles including pixel art and sketches. See our project webpage at\nhttps://ajayj.com/vectorfusion .",
    "descriptor": "\nComments: Project webpage: this https URL\n",
    "authors": [
      "Ajay Jain",
      "Amber Xie",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11319"
  },
  {
    "id": "arXiv:2211.11320",
    "title": "Recovering Fine Details for Neural Implicit Surface Reconstruction",
    "abstract": "Recent works on implicit neural representations have made significant\nstrides. Learning implicit neural surfaces using volume rendering has gained\npopularity in multi-view reconstruction without 3D supervision. However,\naccurately recovering fine details is still challenging, due to the underlying\nambiguity of geometry and appearance representation. In this paper, we present\nD-NeuS, a volume rendering-base neural implicit surface reconstruction method\ncapable to recover fine geometry details, which extends NeuS by two additional\nloss functions targeting enhanced reconstruction quality. First, we encourage\nthe rendered surface points from alpha compositing to have zero signed distance\nvalues, alleviating the geometry bias arising from transforming SDF to density\nfor volume rendering. Second, we impose multi-view feature consistency on the\nsurface points, derived by interpolating SDF zero-crossings from sampled points\nalong rays. Extensive quantitative and qualitative results demonstrate that our\nmethod reconstructs high-accuracy surfaces with details, and outperforms the\nstate of the art.",
    "descriptor": "",
    "authors": [
      "Decai Chen",
      "Peng Zhang",
      "Ingo Feldmann",
      "Oliver Schreer",
      "Peter Eisert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11320"
  },
  {
    "id": "arXiv:2211.11321",
    "title": "SPIN: Simulated Poisoning and Inversion Network for Federated  Learning-Based 6G Vehicular Networks",
    "abstract": "The applications concerning vehicular networks benefit from the vision of\nbeyond 5G and 6G technologies such as ultra-dense network topologies, low\nlatency, and high data rates. Vehicular networks have always faced data privacy\npreservation concerns, which lead to the advent of distributed learning\ntechniques such as federated learning. Although federated learning has solved\ndata privacy preservation issues to some extent, the technique is quite\nvulnerable to model inversion and model poisoning attacks. We assume that the\ndesign of defense mechanism and attacks are two sides of the same coin.\nDesigning a method to reduce vulnerability requires the attack to be effective\nand challenging with real-world implications. In this work, we propose\nsimulated poisoning and inversion network (SPIN) that leverages the\noptimization approach for reconstructing data from a differential model trained\nby a vehicular node and intercepted when transmitted to roadside unit (RSU). We\nthen train a generative adversarial network (GAN) to improve the generation of\ndata with each passing round and global update from the RSU, accordingly.\nEvaluation results show the qualitative and quantitative effectiveness of the\nproposed approach. The attack initiated by SPIN can reduce up to 22% accuracy\non publicly available datasets while just using a single attacker. We assume\nthat revealing the simulation of such attacks would help us find its defense\nmechanism in an effective manner.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Sunder Ali Khowaja",
      "Parus Khuwaja",
      "Kapal Dev",
      "Angelos Antonopoulos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.11321"
  },
  {
    "id": "arXiv:2211.11323",
    "title": "A Generalized EigenGame with Extensions to Multiview Representation  Learning",
    "abstract": "Generalized Eigenvalue Problems (GEPs) encompass a range of interesting\ndimensionality reduction methods. Development of efficient stochastic\napproaches to these problems would allow them to scale to larger datasets.\nCanonical Correlation Analysis (CCA) is one example of a GEP for dimensionality\nreduction which has found extensive use in problems with two or more views of\nthe data. Deep learning extensions of CCA require large mini-batch sizes, and\ntherefore large memory consumption, in the stochastic setting to achieve good\nperformance and this has limited its application in practice. Inspired by the\nGeneralized Hebbian Algorithm, we develop an approach to solving stochastic\nGEPs in which all constraints are softly enforced by Lagrange multipliers. Then\nby considering the integral of this Lagrangian function, its pseudo-utility,\nand inspired by recent formulations of Principal Components Analysis and GEPs\nas games with differentiable utilities, we develop a game-theory inspired\napproach to solving GEPs. We show that our approaches share much of the\ntheoretical grounding of the previous Hebbian and game theoretic approaches for\nthe linear case but our method permits extension to general function\napproximators like neural networks for certain GEPs for dimensionality\nreduction including CCA which means our method can be used for deep multiview\nrepresentation learning. We demonstrate the effectiveness of our method for\nsolving GEPs in the stochastic setting using canonical multiview datasets and\ndemonstrate state-of-the-art performance for optimizing Deep CCA.",
    "descriptor": "",
    "authors": [
      "James Chapman",
      "Ana Lawry Aguila",
      "Lennie Wells"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.11323"
  },
  {
    "id": "arXiv:2211.11324",
    "title": "Slow Motion Matters: A Slow Motion Enhanced Network for Weakly  Supervised Temporal Action Localization",
    "abstract": "Weakly supervised temporal action localization (WTAL) aims to localize\nactions in untrimmed videos with only weak supervision information (e.g.\nvideo-level labels). Most existing models handle all input videos with a fixed\ntemporal scale. However, such models are not sensitive to actions whose pace of\nthe movements is different from the ``normal\" speed, especially slow-motion\naction instances, which complete the movements with a much slower speed than\ntheir counterparts with a normal speed. Here arises the slow-motion blurred\nissue: It is hard to explore salient slow-motion information from videos at\n``normal\" speed. In this paper, we propose a novel framework termed Slow Motion\nEnhanced Network (SMEN) to improve the ability of a WTAL network by\ncompensating its sensitivity on slow-motion action segments. The proposed SMEN\ncomprises a Mining module and a Localization module. The mining module\ngenerates mask to mine slow-motion-related features by utilizing the\nrelationships between the normal motion and slow motion; while the localization\nmodule leverages the mined slow-motion features as complementary information to\nimprove the temporal action localization results. Our proposed framework can be\neasily adapted by existing WTAL networks and enable them be more sensitive to\nslow-motion actions. Extensive experiments on three benchmarks are conducted,\nwhich demonstrate the high performance of our proposed framework.",
    "descriptor": "",
    "authors": [
      "Weiqi Sun",
      "Rui Su",
      "Qian Yu",
      "Dong Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11324"
  },
  {
    "id": "arXiv:2211.11328",
    "title": "Toeplitz Low-Rank Approximation with Sublinear Query Complexity",
    "abstract": "We present a sublinear query algorithm for outputting a near-optimal low-rank\napproximation to any positive semidefinite Toeplitz matrix $T \\in \\mathbb{R}^{d\n\\times d}$. In particular, for any integer rank $k \\leq d$ and $\\epsilon,\\delta\n> 0$, our algorithm makes $\\tilde{O} \\left (k^2 \\cdot \\log(1/\\delta) \\cdot\n\\text{poly}(1/\\epsilon) \\right )$ queries to the entries of $T$ and outputs a\nrank $\\tilde{O} \\left (k \\cdot \\log(1/\\delta)/\\epsilon\\right )$ matrix\n$\\tilde{T} \\in \\mathbb{R}^{d \\times d}$ such that $\\| T - \\tilde{T}\\|_F \\leq\n(1+\\epsilon) \\cdot \\|T-T_k\\|_F + \\delta \\|T\\|_F$. Here, $\\|\\cdot\\|_F$ is the\nFrobenius norm and $T_k$ is the optimal rank-$k$ approximation to $T$, given by\nprojection onto its top $k$ eigenvectors. $\\tilde{O}(\\cdot)$ hides\n$\\text{polylog}(d) $ factors. Our algorithm is \\emph{structure-preserving}, in\nthat the approximation $\\tilde{T}$ is also Toeplitz. A key technical\ncontribution is a proof that any positive semidefinite Toeplitz matrix in fact\nhas a near-optimal low-rank approximation which is itself Toeplitz.\nSurprisingly, this basic existence result was not previously known. Building on\nthis result, along with the well-established off-grid Fourier structure of\nToeplitz matrices [Cybenko'82], we show that Toeplitz $\\tilde{T}$ with near\noptimal error can be recovered with a small number of random queries via a\nleverage-score-based off-grid sparse Fourier sampling scheme.",
    "descriptor": "\nComments: Accepted in SODA 2023\n",
    "authors": [
      "Michael Kapralov",
      "Hannah Lawrence",
      "Mikhail Makarov",
      "Cameron Musco",
      "Kshiteej Sheth"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.11328"
  },
  {
    "id": "arXiv:2211.11329",
    "title": "Simultaneous recovery of a locally rough interface and the embedded  obstacle with the reverse time migration",
    "abstract": "Consider the inverse acoustic scattering of time-harmonic point sources by an\nunbounded locally rough interface with bounded obstacles embedded in the lower\nhalf-space. A novel version of reverse time migration is proposed to\nreconstruct both the locally rough interface and the embedded obstacle. By a\nmodified Helmholtz-Kirchhoff identity associated with a planar interface, we\nobtain a modified imaging functional which has been shown that it always peaks\non the local perturbation of the interface and on the embedded obstacle.\nNumerical examples are presented to demonstrate the effectiveness of the\nmethod.",
    "descriptor": "\nComments: 21 pages, 19 figures\n",
    "authors": [
      "Jianliang Li",
      "Jiaqing Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.11329"
  },
  {
    "id": "arXiv:2211.11331",
    "title": "BrainTTA: A 35 fJ/op Compiler Programmable Mixed-Precision  Transport-Triggered NN SoC",
    "abstract": "Recently, accelerators for extremely quantized deep neural network (DNN)\ninference with operand widths as low as 1-bit have gained popularity due to\ntheir ability to largely cut down energy cost per inference. In this paper, a\nflexible SoC with mixed-precision support is presented. Contrary to the current\ntrend of fixed-datapath accelerators, this architecture makes use of a flexible\ndatapath based on a Transport-Triggered Architecture (TTA). The architecture is\nfully programmable using C. The accelerator has a peak energy efficiency of\n35/67/405 fJ/op (binary, ternary, and 8-bit precision) and a throughput of\n614/307/77 GOPS, which is unprecedented for a programmable architecture.",
    "descriptor": "",
    "authors": [
      "Maarten Molendijk",
      "Floran de Putter",
      "Manil Gomony",
      "Pekka J\u00e4\u00e4skel\u00e4inen",
      "Henk Corporaal"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.11331"
  },
  {
    "id": "arXiv:2211.11332",
    "title": "OPTION: OPTImization Algorithm Benchmarking ONtology",
    "abstract": "Many optimization algorithm benchmarking platforms allow users to share their\nexperimental data to promote reproducible and reusable research. However,\ndifferent platforms use different data models and formats, which drastically\ncomplicates the identification of relevant datasets, their interpretation, and\ntheir interoperability. Therefore, a semantically rich, ontology-based,\nmachine-readable data model that can be used by different platforms is highly\ndesirable. In this paper, we report on the development of such an ontology,\nwhich we call OPTION (OPTImization algorithm benchmarking ONtology). Our\nontology provides the vocabulary needed for semantic annotation of the core\nentities involved in the benchmarking process, such as algorithms, problems,\nand evaluation measures. It also provides means for automatic data integration,\nimproved interoperability, and powerful querying capabilities, thereby\nincreasing the value of the benchmarking data. We demonstrate the utility of\nOPTION, by annotating and querying a corpus of benchmark performance data from\nthe BBOB collection of the COCO framework and from the Yet Another Black-Box\nOptimization Benchmark (YABBOB) family of the Nevergrad environment. In\naddition, we integrate features of the BBOB functional performance landscape\ninto the OPTION knowledge base using publicly available datasets with\nexploratory landscape analysis. Finally, we integrate the OPTION knowledge base\ninto the IOHprofiler environment and provide users with the ability to perform\nmeta-analysis of performance data.",
    "descriptor": "",
    "authors": [
      "Ana Kostovska",
      "Diederick Vermetten",
      "Carola Doerr",
      "Saso D\u017eeroski",
      "Pan\u010de Panov",
      "Tome Eftimov"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.11332"
  },
  {
    "id": "arXiv:2211.11334",
    "title": "Data-Driven Feedback Linearization of Nonlinear Systems with Periodic  Orbits in the Zero-Dynamics",
    "abstract": "In this article, we present data-driven feedback linearization for nonlinear\nsystems with periodic orbits in the zero-dynamics. This scenario is challenging\nfor data-driven control design because the higher order terms of the internal\ndynamics in the discretization appear as disturbance inputs to the controllable\nsubsystem of the normal form. Our design consists of two parts: a data-driven\nfeedback linearization based controller and a two-part estimator that can\nreconstruct the unknown nonlinear terms in the normal form of a nonlinear\nsystem. We investigate the effects of coupling between the subsystems in the\nnormal form of the closed-loop nonlinear system and conclude that the presence\nof such coupling prevents asymptotic convergence of the controllable states. We\nalso show that the estimation error in the controllable states scales linearly\nwith the sampling time. Finally, we present a simulation based validation of\nthe proposed data-driven feedback linearization.",
    "descriptor": "",
    "authors": [
      "Karthik Shenoy",
      "Akshit Saradagi",
      "Ramkrishna Pasumarthy",
      "Vijaysekhar Chellaboina"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.11334"
  },
  {
    "id": "arXiv:2211.11335",
    "title": "Instance-specific and Model-adaptive Supervision for Semi-supervised  Semantic Segmentation",
    "abstract": "Recently, semi-supervised semantic segmentation has achieved promising\nperformance with a small fraction of labeled data. However, most existing\nstudies treat all unlabeled data equally and barely consider the differences\nand training difficulties among unlabeled instances. Differentiating unlabeled\ninstances can promote instance-specific supervision to adapt to the model's\nevolution dynamically. In this paper, we emphasize the cruciality of instance\ndifferences and propose an instance-specific and model-adaptive supervision for\nsemi-supervised semantic segmentation, named iMAS. Relying on the model's\nperformance, iMAS employs a class-weighted symmetric intersection-over-union to\nevaluate quantitative hardness of each unlabeled instance and supervises the\ntraining on unlabeled data in a model-adaptive manner. Specifically, iMAS\nlearns from unlabeled instances progressively by weighing their corresponding\nconsistency losses based on the evaluated hardness. Besides, iMAS dynamically\nadjusts the augmentation for each instance such that the distortion degree of\naugmented instances is adapted to the model's generalization capability across\nthe training course. Not integrating additional losses and training procedures,\niMAS can obtain remarkable performance gains against current state-of-the-art\napproaches on segmentation benchmarks under different semi-supervised partition\nprotocols.",
    "descriptor": "",
    "authors": [
      "Zhen Zhao",
      "Sifan Long",
      "Jimin Pi",
      "Jingdong Wang",
      "Luping Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11335"
  },
  {
    "id": "arXiv:2211.11337",
    "title": "DreamArtist: Towards Controllable One-Shot Text-to-Image Generation via  Contrastive Prompt-Tuning",
    "abstract": "Large-scale text-to-image generation models with an exponential evolution can\ncurrently synthesize high-resolution, feature-rich, high-quality images based\non text guidance. However, they are often overwhelmed by words of new concepts,\nstyles, or object entities that always emerge. Although there are some recent\nattempts to use fine-tuning or prompt-tuning methods to teach the model a new\nconcept as a new pseudo-word from a given reference image set, these methods\nare not only still difficult to synthesize diverse and high-quality images\nwithout distortion and artifacts, but also suffer from low controllability.\nTo address these problems, we propose a DreamArtist method that employs a\nlearning strategy of contrastive prompt-tuning, which introduces both positive\nand negative embeddings as pseudo-words and trains them jointly. The positive\nembedding aggressively learns characteristics in the reference image to drive\nthe model diversified generation, while the negative embedding introspects in a\nself-supervised manner to rectify the mistakes and inadequacies from positive\nembedding in reverse. It learns not only what is correct but also what should\nbe avoided. Extensive experiments on image quality and diversity analysis,\ncontrollability analysis, model learning analysis and task expansion have\ndemonstrated that our model learns not only concept but also form, content and\ncontext. Pseudo-words of DreamArtist have similar properties as true words to\ngenerate high-quality images.",
    "descriptor": "",
    "authors": [
      "Ziyi Dong",
      "Pengxu Wei",
      "Liang Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.11337"
  },
  {
    "id": "arXiv:2211.11338",
    "title": "Approximation in the extended functional tensor train format",
    "abstract": "This work proposes the extended functional tensor train (EFTT) format for\ncompressing and working with multivariate functions on tensor product domains.\nOur compression algorithm combines tensorized Chebyshev interpolation with a\nlow-rank approximation algorithm that is entirely based on function\nevaluations. Compared to existing methods based on the functional tensor train\nformat, our approach often reduces the required storage, sometimes\nconsiderably, while achieving the same accuracy. In particular, we reduce the\nnumber of function evaluations required to achieve a prescribed accuracy by up\nto over 96% compared to the algorithm from [Gorodetsky, Karaman and Marzouk,\nComput. Methods Appl. Mech. Eng., 347 (2019)] .",
    "descriptor": "",
    "authors": [
      "Christoph Str\u00f6ssner",
      "Bonan Sun",
      "Daniel Kressner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.11338"
  },
  {
    "id": "arXiv:2211.11344",
    "title": "Estimating the Effective Support Size in Constant Query Complexity",
    "abstract": "Estimating the support size of a distribution is a well-studied problem in\nstatistics. Motivated by the fact that this problem is highly non-robust (as\nsmall perturbations in the distributions can drastically affect the support\nsize) and thus hard to estimate, Goldreich [ECCC 2019] studied the query\ncomplexity of estimating the $\\epsilon$-\\emph{effective support size}\n$\\text{Ess}_\\epsilon$ of a distribution ${P}$, which is equal to the smallest\nsupport size of a distribution that is $\\epsilon$-far in total variation\ndistance from ${P}$.\nIn his paper, he shows an algorithm in the dual access setting (where we may\nboth receive random samples and query the sampling probability $p(x)$ for any\n$x$) for a bicriteria approximation, giving an answer in\n$[\\text{Ess}_{(1+\\beta)\\epsilon},(1+\\gamma) \\text{Ess}_{\\epsilon}]$ for some\nvalues $\\beta, \\gamma > 0$. However, his algorithm has either super-constant\nquery complexity in the support size or super-constant approximation ratio\n$1+\\gamma = \\omega(1)$. He then asked if this is necessary, or if it is\npossible to get a constant-factor approximation in a number of queries\nindependent of the support size.\nWe answer his question by showing that not only is complexity independent of\n$n$ possible for $\\gamma>0$, but also for $\\gamma=0$, that is, that the\nbicriteria relaxation is not necessary. Specifically, we show an algorithm with\nquery complexity $O(\\frac{1}{\\beta^3 \\epsilon^3})$. That is, for any $0 <\n\\epsilon, \\beta < 1$, we output in this complexity a number $\\tilde{n} \\in\n[\\text{Ess}_{(1+\\beta)\\epsilon},\\text{Ess}_\\epsilon]$. We also show that it is\npossible to solve the approximate version with approximation ratio $1+\\gamma$\nin complexity $O\\left(\\frac{1}{\\beta^2 \\epsilon} + \\frac{1}{\\beta \\epsilon\n\\gamma^2}\\right)$. Our algorithm is very simple, and has $4$ short lines of\npseudocode.",
    "descriptor": "",
    "authors": [
      "Shyam Narayanan",
      "Jakub T\u011btek"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2211.11344"
  },
  {
    "id": "arXiv:2211.11348",
    "title": "Safety-critical model predictive control with control barrier function  for dynamic obstacle avoidance",
    "abstract": "In this paper, a safety critical control scheme for a nonholonomic robot is\ndeveloped to generate control signals that result in optimal obstacle-free\npaths through dynamic environments. A barrier function is used to obtain a\nsafety envelope for the robot. We formulate the control synthesis problem as an\noptimal control problem that enforces control barrier function (CBF)\nconstraints to achieve obstacle avoidance. A nonlinear model predictive control\n(NMPC) with CBF is studied to guarantee system safety and accomplish optimal\nperformance at a short prediction horizon, which reduces computational burden\nin real-time NMPC implementation. An obstacle avoidance constraint under the\nEuclidean norm is also incorporated into NMPC to emphasize the effectiveness of\nCBF in both point stabilization and trajectory tracking problem of the robot.\nThe performance of the proposed controller achieving both static and dynamic\nobstacle avoidance is verified using several simulation scenarios.",
    "descriptor": "\nComments: 6 pages, 6 figures, IFAC World Congress 2023\n",
    "authors": [
      "Nhat Nguyen Minh",
      "Stephen McIlvanna",
      "Yuzhu Sun",
      "Yan Jin",
      "Mien Van"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.11348"
  },
  {
    "id": "arXiv:2211.11349",
    "title": "Data-Driven Offline Decision-Making via Invariant Representation  Learning",
    "abstract": "The goal in offline data-driven decision-making is synthesize decisions that\noptimize a black-box utility function, using a previously-collected static\ndataset, with no active interaction. These problems appear in many forms:\noffline reinforcement learning (RL), where we must produce actions that\noptimize the long-term reward, bandits from logged data, where the goal is to\ndetermine the correct arm, and offline model-based optimization (MBO) problems,\nwhere we must find the optimal design provided access to only a static dataset.\nA key challenge in all these settings is distributional shift: when we optimize\nwith respect to the input into a model trained from offline data, it is easy to\nproduce an out-of-distribution (OOD) input that appears erroneously good. In\ncontrast to prior approaches that utilize pessimism or conservatism to tackle\nthis problem, in this paper, we formulate offline data-driven decision-making\nas domain adaptation, where the goal is to make accurate predictions for the\nvalue of optimized decisions (\"target domain\"), when training only on the\ndataset (\"source domain\"). This perspective leads to invariant objective models\n(IOM), our approach for addressing distributional shift by enforcing invariance\nbetween the learned representations of the training dataset and optimized\ndecisions. In IOM, if the optimized decisions are too different from the\ntraining dataset, the representation will be forced to lose much of the\ninformation that distinguishes good designs from bad ones, making all choices\nseem mediocre. Critically, when the optimizer is aware of this representational\ntradeoff, it should choose not to stray too far from the training distribution,\nleading to a natural trade-off between distributional shift and learning\nperformance.",
    "descriptor": "\nComments: This is an extended version of the NeurIPS 2022 conference paper titled: \"Data-Driven Offline Model-Based Optimization via Invariant Representation Learning\"\n",
    "authors": [
      "Han Qi",
      "Yi Su",
      "Aviral Kumar",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11349"
  },
  {
    "id": "arXiv:2211.11350",
    "title": "Rooms with Text: A Dataset for Overlaying Text Detection",
    "abstract": "In this paper, we introduce a new dataset of room interior pictures with\noverlaying and scene text, totalling to 4836 annotated images in 25 product\ncategories. We provide details on the collection and annotation process of our\ndataset, and analyze its statistics. Furthermore, we propose a baseline method\nfor overlaying text detection, that leverages the character region-aware text\ndetection framework to guide the classification model. We validate our approach\nand show its efficiency in terms of binary classification metrics, reaching the\nfinal performance of 0.95 F1 score, with false positive and false negative\nrates of 0.02 and 0.06 correspondingly.",
    "descriptor": "\nComments: Text in Everything workshop at ECCV 2022\n",
    "authors": [
      "Oleg Smirnov",
      "Aditya Tewari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11350"
  },
  {
    "id": "arXiv:2211.11351",
    "title": "Are All Combinations Equal? Combining Textual and Visual Features with  Multiple Space Learning for Text-Based Video Retrieval",
    "abstract": "In this paper we tackle the cross-modal video retrieval problem and, more\nspecifically, we focus on text-to-video retrieval. We investigate how to\noptimally combine multiple diverse textual and visual features into feature\npairs that lead to generating multiple joint feature spaces, which encode\ntext-video pairs into comparable representations. To learn these\nrepresentations our proposed network architecture is trained by following a\nmultiple space learning procedure. Moreover, at the retrieval stage, we\nintroduce additional softmax operations for revising the inferred query-video\nsimilarities. Extensive experiments in several setups based on three\nlarge-scale datasets (IACC.3, V3C1, and MSR-VTT) lead to conclusions on how to\nbest combine text-visual features and document the performance of the proposed\nnetwork. Source code is made publicly available at:\nhttps://github.com/bmezaris/TextToVideoRetrieval-TtimesV",
    "descriptor": "\nComments: Accepted for publication; to be included in Proc. ECCV Workshops 2022. The version posted here is the \"submitted manuscript\" version\n",
    "authors": [
      "Damianos Galanopoulos",
      "Vasileios Mezaris"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11351"
  },
  {
    "id": "arXiv:2211.11352",
    "title": "Brief Announcement: Broadcasting Time in Dynamic Rooted Trees is Linear",
    "abstract": "We study the broadcast problem on dynamic networks with $n$ processes. The\nprocesses communicate in synchronous rounds along an arbitrary rooted tree. The\nsequence of trees is given by an adversary whose goal is to maximize the number\nof rounds until at least one process reaches all other processes. Previous\nresearch has shown a $\\lceil{\\frac{3n-1}{2}}\\rceil-2$ lower bound and an\n$O(n\\log\\log n)$ upper bound. We show the first linear upper bound for this\nproblem, namely $\\lceil{(1 + \\sqrt 2) n-1}\\rceil \\approx 2.4n$. Our result\nfollows from a detailed analysis of the evolution of the adjacency matrix of\nthe network over time.",
    "descriptor": "\nComments: 5 pages, 1 figure, published in PODC'22, further work: arXiv:2211.10151\n",
    "authors": [
      "Antoine El-Hayek",
      "Monika Henzinger",
      "Stefan Schmid"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.11352"
  },
  {
    "id": "arXiv:2211.11354",
    "title": "Object-level 3D Semantic Mapping using a Network of Smart Edge Sensors",
    "abstract": "Autonomous robots that interact with their environment require a detailed\nsemantic scene model. For this, volumetric semantic maps are frequently used.\nThe scene understanding can further be improved by including object-level\ninformation in the map. In this work, we extend a multi-view 3D semantic\nmapping system consisting of a network of distributed smart edge sensors with\nobject-level information, to enable downstream tasks that need object-level\ninput. Objects are represented in the map via their 3D mesh model or as an\nobject-centric volumetric sub-map that can model arbitrary object geometry when\nno detailed 3D model is available. We propose a keypoint-based approach to\nestimate object poses via PnP and refinement via ICP alignment of the 3D object\nmodel with the observed point cloud segments. Object instances are tracked to\nintegrate observations over time and to be robust against temporary occlusions.\nOur method is evaluated on the public Behave dataset where it shows pose\nestimation accuracy within a few centimeters and in real-world experiments with\nthe sensor network in a challenging lab environment where multiple chairs and a\ntable are tracked through the scene online, in real time even under high\nocclusions.",
    "descriptor": "\nComments: 9 pages, 12 figures, 6th IEEE International Conference on Robotic Computing (IRC), Naples, Italy, December 2022\n",
    "authors": [
      "Julian Hau",
      "Simon Bultmann",
      "Sven Behnke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.11354"
  },
  {
    "id": "arXiv:2211.11355",
    "title": "Blind Knowledge Distillation for Robust Image Classification",
    "abstract": "Optimizing neural networks with noisy labels is a challenging task,\nespecially if the label set contains real-world noise. Networks tend to\ngeneralize to reasonable patterns in the early training stages and overfit to\nspecific details of noisy samples in the latter ones. We introduce Blind\nKnowledge Distillation - a novel teacher-student approach for learning with\nnoisy labels by masking the ground truth related teacher output to filter out\npotentially corrupted knowledge and to estimate the tipping point from\ngeneralizing to overfitting. Based on this, we enable the estimation of noise\nin the training data with Otsus algorithm. With this estimation, we train the\nnetwork with a modified weighted cross-entropy loss function. We show in our\nexperiments that Blind Knowledge Distillation detects overfitting effectively\nduring training and improves the detection of clean and noisy labels on the\nrecently published CIFAR-N dataset. Code is available at GitHub.",
    "descriptor": "\nComments: 8 pages, 4 figures, 2 tables. Submitted to the 1st Learning and Mining with Noisy Labels Challenge on IJCAI22, see this http URL Code is available this https URL\n",
    "authors": [
      "Timo Kaiser",
      "Lukas Ehmann",
      "Christoph Reinders",
      "Bodo Rosenhahn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11355"
  },
  {
    "id": "arXiv:2211.11357",
    "title": "A Tale of Frozen Clouds: Quantifying the Impact of Algorithmic  Complexity Vulnerabilities in Popular Web Servers",
    "abstract": "Algorithmic complexity vulnerabilities are a class of security problems that\nenables attackers to trigger the worst-case complexity of certain algorithms.\nSuch vulnerabilities can be leveraged to deploy low-volume, asymmetric,\nCPU-based denial-of-service (DoS) attacks. Previous work speculates that these\nvulnerabilities are more dangerous in certain web servers, like Node.js, than\nin traditional ones, like Apache. We believe it is of utmost importance to\nunderstand if this is indeed the case or if there are ways to compensate\nagainst such problems using various deployment strategies. To this end, we\nstudy the resilience of popular web servers against CPU-based DoS attacks in\nfour major cloud platforms under realistic deployment conditions. We find that\nthere are indeed significant differences in how various web servers react to an\nattack. However, our results suggest a more nuanced landscape than previously\nbelieved: while event-based systems tend to recover faster from DoS in certain\nscenarios, they also suffer the worst performance degradation overall.\nNevertheless, in some setups, Apache performs worse than event-based systems,\nand there are cloud platforms in which all the considered servers are seriously\nexposed to the attack. We also find that developers can harden their servers\nagainst CPU-based DoS attacks by increasing the number of server instances\nrunning in parallel. This, in turn, can lead to an increased cost of operation\nor a slight degradation of performance in non-DoS conditions.",
    "descriptor": "",
    "authors": [
      "Masudul Hasan Masud Bhuiyan",
      "Cristian-Alexandru Staicu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.11357"
  },
  {
    "id": "arXiv:2211.11359",
    "title": "Challenges and Applications of Automated Extraction of Socio-political  Events from Text (CASE 2022): Workshop and Shared Task Report",
    "abstract": "We provide a summary of the fifth edition of the CASE workshop that is held\nin the scope of EMNLP 2022. The workshop consists of regular papers, two\nkeynotes, working papers of shared task participants, and task overview papers.\nThis workshop has been bringing together all aspects of event information\ncollection across technical and social science fields. In addition to the\nprogress in depth, the submission and acceptance of multimodal approaches show\nthe widening of this interdisciplinary research topic.",
    "descriptor": "\nComments: to appear at CASE 2022 @ EMNLP 2022\n",
    "authors": [
      "Ali H\u00fcrriyeto\u011flu",
      "Hristo Tanev",
      "Vanni Zavarella",
      "Reyyan Yeniterzi",
      "Osman Mutlu",
      "Erdem Y\u00f6r\u00fck"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11359"
  },
  {
    "id": "arXiv:2211.11360",
    "title": "Extended Multilingual Protest News Detection -- Shared Task 1, CASE 2021  and 2022",
    "abstract": "We report results of the CASE 2022 Shared Task 1 on Multilingual Protest\nEvent Detection. This task is a continuation of CASE 2021 that consists of four\nsubtasks that are i) document classification, ii) sentence classification, iii)\nevent sentence coreference identification, and iv) event extraction. The CASE\n2022 extension consists of expanding the test data with more data in previously\navailable languages, namely, English, Hindi, Portuguese, and Spanish, and\nadding new test data in Mandarin, Turkish, and Urdu for Sub-task 1, document\nclassification. The training data from CASE 2021 in English, Portuguese and\nSpanish were utilized. Therefore, predicting document labels in Hindi,\nMandarin, Turkish, and Urdu occurs in a zero-shot setting. The CASE 2022\nworkshop accepts reports on systems developed for predicting test data of CASE\n2021 as well. We observe that the best systems submitted by CASE 2022\nparticipants achieve between 79.71 and 84.06 F1-macro for new languages in a\nzero-shot setting. The winning approaches are mainly ensembling models and\nmerging data in multiple languages. The best two submissions on CASE 2021 data\noutperform submissions from last year for Subtask 1 and Subtask 2 in all\nlanguages. Only the following scenarios were not outperformed by new\nsubmissions on CASE 2021: Subtask 3 Portuguese \\& Subtask 4 English.",
    "descriptor": "\nComments: To appear in CASE 2022 @ EMNLP 2022\n",
    "authors": [
      "Ali H\u00fcrriyeto\u011flu",
      "Osman Mutlu",
      "F\u0131rat Duru\u015fan",
      "Onur Uca",
      "Alaeddin Sel\u00e7uk G\u00fcrel",
      "Benjamin Radford",
      "Yaoyao Dai",
      "Hansi Hettiarachchi",
      "Niklas Stoehr",
      "Tadashi Nomoto",
      "Milena Slavcheva",
      "Francielle Vargas",
      "Aaqib Javid",
      "Fatih Beyhan",
      "Erdem Y\u00f6r\u00fck"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11360"
  },
  {
    "id": "arXiv:2211.11362",
    "title": "Crowdsensing-based Road Damage Detection Challenge (CRDDC-2022)",
    "abstract": "This paper summarizes the Crowdsensing-based Road Damage Detection Challenge\n(CRDDC), a Big Data Cup organized as a part of the IEEE International\nConference on Big Data'2022. The Big Data Cup challenges involve a released\ndataset and a well-defined problem with clear evaluation metrics. The\nchallenges run on a data competition platform that maintains a real-time online\nevaluation system for the participants. In the presented case, the data\nconstitute 47,420 road images collected from India, Japan, the Czech Republic,\nNorway, the United States, and China to propose methods for automatically\ndetecting road damages in these countries. More than 60 teams from 19 countries\nregistered for this competition. The submitted solutions were evaluated using\nfive leaderboards based on performance for unseen test images from the\naforementioned six countries. This paper encapsulates the top 11 solutions\nproposed by these teams. The best-performing model utilizes ensemble learning\nbased on YOLO and Faster-RCNN series models to yield an F1 score of 76% for\ntest data combined from all 6 countries. The paper concludes with a comparison\nof current and past challenges and provides direction for the future.",
    "descriptor": "\nComments: 9 pages 2 figures 5 tables. arXiv admin note: text overlap with arXiv:2011.08740\n",
    "authors": [
      "Deeksha Arya",
      "Hiroya Maeda",
      "Sanjay Kumar Ghosh",
      "Durga Toshniwal",
      "Hiroshi Omata",
      "Takehiro Kashiyama",
      "Yoshihide Sekimoto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11362"
  },
  {
    "id": "arXiv:2211.11363",
    "title": "CBEAF-Adapting: Enhanced Continual Pretraining for Building Chinese  Biomedical Language Model",
    "abstract": "Continual pretraining is a standard way of building a domain-specific\npretrained language model from a general-domain language model. However,\nsequential task training may cause catastrophic forgetting, which affects the\nmodel performance in downstream tasks. In this paper, we propose a continual\npretraining method for the BERT-based model, named CBEAF-Adapting (Chinese\nBiomedical Enhanced Attention-FFN Adapting). Its main idea is to introduce a\nsmall number of attention heads and hidden units inside each self-attention\nlayer and feed-forward network. Using the Chinese biomedical domain as a\nrunning example, we trained a domain-specific language model named\nCBEAF-RoBERTa. We conduct experiments by applying models to downstream tasks.\nThe results demonstrate that with only about 3% of model parameters trained,\nour method could achieve about 0.5%, 2% average performance gain compared to\nthe best performing model in baseline and the domain-specific model,\nPCL-MedBERT, respectively. We also examine the forgetting problem of different\npretraining methods. Our method alleviates the problem by about 13% compared to\nfine-tuning.",
    "descriptor": "",
    "authors": [
      "Yongyu Yan",
      "Kui Xue",
      "Qi Ye",
      "Tong Ruan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11363"
  },
  {
    "id": "arXiv:2211.11367",
    "title": "High-Order Optimization of Gradient Boosted Decision Trees",
    "abstract": "Gradient Boosted Decision Trees (GBDTs) are dominant machine learning\nalgorithms for modeling discrete or tabular data. Unlike neural networks with\nmillions of trainable parameters, GBDTs optimize loss function in an additive\nmanner and have a single trainable parameter per leaf, which makes it easy to\napply high-order optimization of the loss function. In this paper, we introduce\nhigh-order optimization for GBDTs based on numerical optimization theory which\nallows us to construct trees based on high-order derivatives of a given loss\nfunction. In the experiments, we show that high-order optimization has faster\nper-iteration convergence that leads to reduced running time. Our solution can\nbe easily parallelized and run on GPUs with little overhead on the code.\nFinally, we discuss future potential improvements such as automatic\ndifferentiation of arbitrary loss function and combination of GBDTs with neural\nnetworks.",
    "descriptor": "\nComments: NeurIPS 2022 Workshop: Order up! The Benefits of Higher-Order Optimization in Machine Learning\n",
    "authors": [
      "Jean Pachebat",
      "Sergei Ivanov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11367"
  },
  {
    "id": "arXiv:2211.11369",
    "title": "Enterprise Model Library for Business-IT-Alignment",
    "abstract": "The knowledge of the world is passed on through libraries. Accordingly,\ndomain expertise and experiences should also be transferred within an\nenterprise by a knowledge base. Therefore, models are an established medium to\ndescribe good practices for complex systems, processes, and interconnections.\nHowever, there is no structured and detailed approach for a design of an\nenterprise model library. The objective of this work is the reference\narchitecture of a repository for models with function of reuse. It includes the\ndesign of the data structure for filing, the processes for administration and\npossibilities for usage. Our approach enables consistent mapping of\nrequirements into models via meta-data attributes. Furthermore, the adaptation\nof reference architectures in specific use cases as well as a reconciliation of\ninterrelationships is enabled. A case study with industry demonstrates the\npractical benefits of reusing work already done. It provides an organization\nwith systematic access to specifications, standards and guidelines. Thus,\nfurther development is accelerated and supported in a structured manner, while\ncomplexity remains controllable. The presented approach enriches various\nenterprise architecture frameworks. It provides benefits for development based\non models.",
    "descriptor": "",
    "authors": [
      "Peter Hillmann",
      "Diana Schnell",
      "Harald Hagel",
      "Andreas Karcher"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Digital Libraries (cs.DL)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.11369"
  },
  {
    "id": "arXiv:2211.11378",
    "title": "Learning on tree architectures outperforms a convolutional feedforward  network",
    "abstract": "Advanced deep learning architectures consist of tens of fully connected and\nconvolutional hidden layers, which are already extended to hundreds, and are\nfar from their biological realization. Their implausible biological dynamics is\nbased on changing a weight in a non-local manner, as the number of routes\nbetween an output unit and a weight is typically large, using the\nbackpropagation technique. Here, offline and online CIFAR-10 database learning\non 3-layer tree architectures, inspired by experimental-based dendritic tree\nadaptations, outperforms the achievable success rates of the 5-layer\nconvolutional LeNet. Its highly pruning tree backpropagation procedure, where a\nsingle route connects an output unit and a weight, represents an efficient\ndendritic deep learning.",
    "descriptor": "\nComments: 20 pages, 4 figures, 1 table\n",
    "authors": [
      "Yuval Meir",
      "Itamar Ben-Noam",
      "Yarden Tzach",
      "Shiri Hodassman",
      "Ido Kanter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11378"
  },
  {
    "id": "arXiv:2211.11380",
    "title": "Self adaptive global-local feature enhancement for radiology report  generation",
    "abstract": "Automated radiology report generation aims at automatically generating a\ndetailed description of medical images, which can greatly alleviate the\nworkload of radiologists and provide better medical services to remote areas.\nMost existing works pay attention to the holistic impression of medical images,\nfailing to utilize important anatomy information. However, in actual clinical\npractice, radiologists usually locate important anatomical structures, and then\nlook for signs of abnormalities in certain structures and reason the underlying\ndisease. In this paper, we propose a novel framework AGFNet to dynamically fuse\nthe global and anatomy region feature to generate multi-grained radiology\nreport. Firstly, we extract important anatomy region features and global\nfeatures of input Chest X-ray (CXR). Then, with the region features and the\nglobal features as input, our proposed self-adaptive fusion gate module could\ndynamically fuse multi-granularity information. Finally, the captioning\ngenerator generates the radiology reports through multi-granularity features.\nExperiment results illustrate that our model achieved the state-of-the-art\nperformance on two benchmark datasets including the IU X-Ray and MIMIC-CXR.\nFurther analyses also prove that our model is able to leverage the\nmulti-grained information from radiology images and texts so as to help\ngenerate more accurate reports.",
    "descriptor": "",
    "authors": [
      "Yuhao Wang",
      "Kai Wang",
      "Xiaohong Liu",
      "Tianrun Gao",
      "Jingyue Zhang",
      "Guangyu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11380"
  },
  {
    "id": "arXiv:2211.11381",
    "title": "LISA: Localized Image Stylization with Audio via Implicit Neural  Representation",
    "abstract": "We present a novel framework, Localized Image Stylization with Audio (LISA)\nwhich performs audio-driven localized image stylization. Sound often provides\ninformation about the specific context of the scene and is closely related to a\ncertain part of the scene or object. However, existing image stylization works\nhave focused on stylizing the entire image using an image or text input.\nStylizing a particular part of the image based on audio input is natural but\nchallenging. In this work, we propose a framework that a user provides an audio\ninput to localize the sound source in the input image and another for locally\nstylizing the target object or scene. LISA first produces a delicate\nlocalization map with an audio-visual localization network by leveraging CLIP\nembedding space. We then utilize implicit neural representation (INR) along\nwith the predicted localization map to stylize the target object or scene based\non sound information. The proposed INR can manipulate the localized pixel\nvalues to be semantically consistent with the provided audio input. Through a\nseries of experiments, we show that the proposed framework outperforms the\nother audio-guided stylization methods. Moreover, LISA constructs concise\nlocalization maps and naturally manipulates the target object or scene in\naccordance with the given audio input.",
    "descriptor": "",
    "authors": [
      "Seung Hyun Lee",
      "Chanyoung Kim",
      "Wonmin Byeon",
      "Sang Ho Yoon",
      "Jinkyu Kim",
      "Sangpil Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.11381"
  },
  {
    "id": "arXiv:2211.11384",
    "title": "Expander Decomposition in Dynamic Streams",
    "abstract": "In this paper we initiate the study of expander decompositions of a graph\n$G=(V, E)$ in the streaming model of computation. The goal is to find a\npartitioning $\\mathcal{C}$ of vertices $V$ such that the subgraphs of $G$\ninduced by the clusters $C \\in \\mathcal{C}$ are good expanders, while the\nnumber of intercluster edges is small. Expander decompositions are classically\nconstructed by a recursively applying balanced sparse cuts to the input graph.\nIn this paper we give the first implementation of such a recursive sparsest cut\nprocess using small space in the dynamic streaming model.\nOur main algorithmic tool is a new type of cut sparsifier that we refer to as\na power cut sparsifier - it preserves cuts in any given vertex induced subgraph\n(or, any cluster in a fixed partition of $V$) to within a $(\\delta,\n\\epsilon)$-multiplicative/additive error with high probability. The power cut\nsparsifier uses $\\tilde{O}(n/\\epsilon\\delta)$ space and edges, which we show is\nasymptotically tight up to polylogarithmic factors in $n$ for constant\n$\\delta$.",
    "descriptor": "\nComments: 31 pages, 0 figures, to appear in ITCS 2023\n",
    "authors": [
      "Arnold Filtser",
      "Michael Kapralov",
      "Mikhail Makarov"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.11384"
  },
  {
    "id": "arXiv:2211.11386",
    "title": "PS-Transformer: Learning Sparse Photometric Stereo Network using  Self-Attention Mechanism",
    "abstract": "Existing deep calibrated photometric stereo networks basically aggregate\nobservations under different lights based on the pre-defined operations such as\nlinear projection and max pooling. While they are effective with the dense\ncapture, simple first-order operations often fail to capture the high-order\ninteractions among observations under small number of different lights. To\ntackle this issue, this paper presents a deep sparse calibrated photometric\nstereo network named {\\it PS-Transformer} which leverages the learnable\nself-attention mechanism to properly capture the complex inter-image\ninteractions. PS-Transformer builds upon the dual-branch design to explore both\npixel-wise and image-wise features and individual feature is trained with the\nintermediate surface normal supervision to maximize geometric feasibility. A\nnew synthetic dataset named CyclesPS+ is also presented with the comprehensive\nanalysis to successfully train the photometric stereo networks. Extensive\nresults on the publicly available benchmark datasets demonstrate that the\nsurface normal prediction accuracy of the proposed method significantly\noutperforms other state-of-the-art algorithms with the same number of input\nimages and is even comparable to that of dense algorithms which input\n10$\\times$ larger number of images.",
    "descriptor": "\nComments: BMVC2021. Code and Supplementary are available at this https URL\n",
    "authors": [
      "Satoshi Ikehata"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11386"
  },
  {
    "id": "arXiv:2211.11390",
    "title": "State Estimation for Hybrid Locomotion of Driving-Stepping Quadrupeds",
    "abstract": "Fast and versatile locomotion can be achieved with wheeled quadruped robots\nthat drive quickly on flat terrain, but are also able to overcome challenging\nterrain by adapting their body pose and by making steps. In this paper, we\npresent a state estimation approach for four-legged robots with non-steerable\nwheels that enables hybrid driving-stepping locomotion capabilities. We\nformulate a Kalman Filter (KF) for state estimation that integrates driven\nwheels into the filter equations and estimates the robot state (position and\nvelocity) as well as the contribution of driving with wheels to the above\nstate. Our estimation approach allows us to use the control framework of the\nMini Cheetah quadruped robot with minor modifications. We tested our approach\non this robot that we augmented with actively driven wheels in simulation and\nin the real world. The experimental results are available at\nhttps://www.ais.uni-bonn.de/%7Ehosseini/se-dsq .",
    "descriptor": "\nComments: Accepted final version. IEEE International Robotic Computing (IRC), Naples, Italy, December 2022\n",
    "authors": [
      "Mojtaba Hosseini",
      "Diego Rodriguez",
      "Sven Behnke"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.11390"
  },
  {
    "id": "arXiv:2211.11391",
    "title": "Reinforcement Learning-Enhanced Control Barrier Functions for Robot  Manipulators",
    "abstract": "In this paper we present the implementation of a Control Barrier Function\n(CBF) using a quadratic program (QP) formulation that provides obstacle\navoidance for a robotic manipulator arm system. CBF is a control technique that\nhas emerged and developed over the past decade and has been extensively\nexplored in the literature on its mathematical foundations, proof of set\ninvariance and potential applications for a variety of safety-critical control\nsystems. In this work we will look at the design of CBF for the robotic\nmanipulator obstacle avoidance, discuss the selection of the CBF parameters and\npresent a Reinforcement Learning (RL) scheme to assist with finding parameters\nvalues that provide the most efficient trajectory to successfully avoid\ndifferent sized obstacles. We then create a data-set across a range of\nscenarios used to train a Neural-Network (NN) model that can be used within the\ncontrol scheme to allow the system to efficiently adapt to different obstacle\nscenarios. Computer simulations (based on Matlab/Simulink) demonstrate the\neffectiveness of the proposed algorithm.",
    "descriptor": "",
    "authors": [
      "Stephen McIlvanna",
      "Nhat Nguyen Minh",
      "Yuzhu Sun",
      "Mien Van",
      "Wasif Naeem"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.11391"
  },
  {
    "id": "arXiv:2211.11393",
    "title": "TFormer: A throughout fusion transformer for multi-modal skin lesion  diagnosis",
    "abstract": "Multi-modal skin lesion diagnosis (MSLD) has achieved remarkable success by\nmodern computer-aided diagnosis technology based on deep convolutions. However,\nthe information aggregation across modalities in MSLD remains challenging due\nto severity unaligned spatial resolution (dermoscopic image and clinical image)\nand heterogeneous data (dermoscopic image and patients' meta-data). Limited by\nthe intrinsic local attention, most recent MSLD pipelines using pure\nconvolutions struggle to capture representative features in shallow layers,\nthus the fusion across different modalities is usually done at the end of the\npipelines, even at the last layer, leading to an insufficient information\naggregation. To tackle the issue, we introduce a pure transformer-based method,\nwhich we refer to as ``Throughout Fusion Transformer (TFormer)\", for sufficient\ninformation intergration in MSLD. Different from the existing approaches with\nconvolutions, the proposed network leverages transformer as feature extraction\nbackbone, bringing more representative shallow features. We then carefully\ndesign a stack of dual-branch hierarchical multi-modal transformer (HMT) blocks\nto fuse information across different image modalities in a stage-by-stage way.\nWith the aggregated information of image modalities, a multi-modal transformer\npost-fusion (MTP) block is designed to integrate features across image and\nnon-image data. Such a strategy that information of the image modalities is\nfirstly fused then the heterogeneous ones enables us to better divide and\nconquer the two major challenges while ensuring inter-modality dynamics are\neffectively modeled. Experiments conducted on the public Derm7pt dataset\nvalidate the superiority of the proposed method. Our TFormer outperforms other\nstate-of-the-art methods. Ablation experiments also suggest the effectiveness\nof our designs.",
    "descriptor": "",
    "authors": [
      "Yilan Zhang",
      "Fengying Xie",
      "Jianqi Chen",
      "Jie Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11393"
  },
  {
    "id": "arXiv:2211.11394",
    "title": "Learning Implicit Probability Distribution Functions for Symmetric  Orientation Estimation from RGB Images Without Pose Labels",
    "abstract": "Object pose estimation is a necessary prerequisite for autonomous robotic\nmanipulation, but the presence of symmetry increases the complexity of the pose\nestimation task. Existing methods for object pose estimation output a single 6D\npose. Thus, they lack the ability to reason about symmetries. Lately, modeling\nobject orientation as a non-parametric probability distribution on the SO(3)\nmanifold by neural networks has shown impressive results. However, acquiring\nlarge-scale datasets to train pose estimation models remains a bottleneck. To\naddress this limitation, we introduce an automatic pose labeling scheme. Given\nRGB-D images without object pose annotations and 3D object models, we design a\ntwo-stage pipeline consisting of point cloud registration and\nrender-and-compare validation to generate multiple symmetrical\npseudo-ground-truth pose labels for each image. Using the generated pose\nlabels, we train an ImplicitPDF model to estimate the likelihood of an\norientation hypothesis given an RGB image. An efficient hierarchical sampling\nof the SO(3) manifold enables tractable generation of the complete set of\nsymmetries at multiple resolutions. During inference, the most likely\norientation of the target object is estimated using gradient ascent. We\nevaluate the proposed automatic pose labeling scheme and the ImplicitPDF model\non a photorealistic dataset and the T-Less dataset, demonstrating the\nadvantages of the proposed method.",
    "descriptor": "",
    "authors": [
      "Arul Selvam Periyasamy",
      "Luis Denninger",
      "Sven Behnke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.11394"
  },
  {
    "id": "arXiv:2211.11396",
    "title": "A Curriculum-Training-Based Strategy for Distributing Collocation Points  during Physics-Informed Neural Network Training",
    "abstract": "Physics-informed Neural Networks (PINNs) often have, in their loss functions,\nterms based on physical equations and derivatives. In order to evaluate these\nterms, the output solution is sampled using a distribution of collocation\npoints. However, density-based strategies, in which the number of collocation\npoints over the domain increases throughout the training period, do not scale\nwell to multiple spatial dimensions. To remedy this issue, we present here a\ncurriculum-training-based method for lightweight collocation point\ndistributions during network training. We apply this method to a PINN which\nrecovers a full two-dimensional magnetohydrodynamic (MHD) solution from a\npartial sample taken from a baseline MHD simulation. We find that the\ncurriculum collocation point strategy leads to a significant decrease in\ntraining time and simultaneously enhances the quality of the reconstructed\nsolution.",
    "descriptor": "",
    "authors": [
      "Marcus M\u00fcnzer",
      "Chris Bard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Plasma Physics (physics.plasm-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.11396"
  },
  {
    "id": "arXiv:2211.11397",
    "title": "Learning Low-Rank Representations for Model Compression",
    "abstract": "Vector Quantization (VQ) is an appealing model compression method to obtain a\ntiny model with less accuracy loss. While methods to obtain better codebooks\nand codes under fixed clustering dimensionality have been extensively studied,\noptimizations of the vectors in favour of clustering performance are not\ncarefully considered, especially via the reduction of vector dimensionality.\nThis paper reports our recent progress on the combination of dimensionality\ncompression and vector quantization, proposing a Low-Rank Representation Vector\nQuantization ($\\text{LR}^2\\text{VQ}$) method that outperforms previous VQ\nalgorithms in various tasks and architectures. $\\text{LR}^2\\text{VQ}$ joins\nlow-rank representation with subvector clustering to construct a new kind of\nbuilding block that is directly optimized through end-to-end training over the\ntask loss. Our proposed design pattern introduces three hyper-parameters, the\nnumber of clusters $k$, the size of subvectors $m$ and the clustering\ndimensionality $\\tilde{d}$. In our method, the compression ratio could be\ndirectly controlled by $m$, and the final accuracy is solely determined by\n$\\tilde{d}$. We recognize $\\tilde{d}$ as a trade-off between low-rank\napproximation error and clustering error and carry out both theoretical\nanalysis and experimental observations that empower the estimation of the\nproper $\\tilde{d}$ before fine-tunning. With a proper $\\tilde{d}$, we evaluate\n$\\text{LR}^2\\text{VQ}$ with ResNet-18/ResNet-50 on ImageNet classification\ndatasets, achieving 2.8\\%/1.0\\% top-1 accuracy improvements over the current\nstate-of-the-art VQ-based compression algorithms with 43$\\times$/31$\\times$\ncompression factor.",
    "descriptor": "",
    "authors": [
      "Zezhou Zhu",
      "Yucong Zhou",
      "Zhao Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11397"
  },
  {
    "id": "arXiv:2211.11402",
    "title": "An Implicit Parametric Morphable Dental Model",
    "abstract": "3D Morphable models of the human body capture variations among subjects and\nare useful in reconstruction and editing applications. Current dental models\nuse an explicit mesh scene representation and model only the teeth, ignoring\nthe gum. In this work, we present the first parametric 3D morphable dental\nmodel for both teeth and gum. Our model uses an implicit scene representation\nand is learned from rigidly aligned scans. It is based on a component-wise\nrepresentation for each tooth and the gum, together with a learnable latent\ncode for each of such components. It also learns a template shape thus enabling\nseveral applications such as segmentation, interpolation, and tooth\nreplacement. Our reconstruction quality is on par with the most advanced global\nimplicit representations while enabling novel applications. Project page:\nhttps://vcai.mpi-inf.mpg.de/projects/DMM/",
    "descriptor": "",
    "authors": [
      "Congyi Zhang",
      "Mohamed Elgharib",
      "Gereon Fox",
      "Min Gu",
      "Christian Theobalt",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11402"
  },
  {
    "id": "arXiv:2211.11406",
    "title": "Structural Optimization of Factor Graphs for Symbol Detection via  Continuous Clustering and Machine Learning",
    "abstract": "We propose a novel method to optimize the structure of factor graphs for\ngraph-based inference. As an example inference task, we consider symbol\ndetection on linear inter-symbol interference channels. The factor graph\nframework has the potential to yield low-complexity symbol detectors. However,\nthe sum-product algorithm on cyclic factor graphs is suboptimal and its\nperformance is highly sensitive to the underlying graph. Therefore, we optimize\nthe structure of the underlying factor graphs in an end-to-end manner using\nmachine learning. For that purpose, we transform the structural optimization\ninto a clustering problem of low-degree factor nodes that incorporates the\nknown channel model into the optimization. Furthermore, we study the\ncombination of this approach with neural belief propagation, yielding\nnear-maximum a posteriori symbol detection performance for specific channels.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Lukas Rapp",
      "Luca Schmid",
      "Andrej Rode",
      "Laurent Schmalen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.11406"
  },
  {
    "id": "arXiv:2211.11407",
    "title": "RAILD: Towards Leveraging Relation Features for Inductive Link  Prediction In Knowledge Graphs",
    "abstract": "Due to the open world assumption, Knowledge Graphs (KGs) are never complete.\nIn order to address this issue, various Link Prediction (LP) methods are\nproposed so far. Some of these methods are inductive LP models which are\ncapable of learning representations for entities not seen during training.\nHowever, to the best of our knowledge, none of the existing inductive LP models\nfocus on learning representations for unseen relations. In this work, a novel\nRelation Aware Inductive Link preDiction (RAILD) is proposed for KG completion\nwhich learns representations for both unseen entities and unseen relations. In\naddition to leveraging textual literals associated with both entities and\nrelations by employing language models, RAILD also introduces a novel\ngraph-based approach to generate features for relations. Experiments are\nconducted with different existing and newly created challenging benchmark\ndatasets and the results indicate that RAILD leads to performance improvement\nover the state-of-the-art models. Moreover, since there are no existing\ninductive LP models which learn representations for unseen relations, we have\ncreated our own baselines and the results obtained with RAILD also outperform\nthese baselines.",
    "descriptor": "",
    "authors": [
      "Genet Asefa Gesese",
      "Harald Sack",
      "Mehwish Alam"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11407"
  },
  {
    "id": "arXiv:2211.11409",
    "title": "Cost-effective Simulation-based Test Selection in Self-driving Cars  Software",
    "abstract": "Simulation environments are essential for the continuous development of\ncomplex cyber-physical systems such as self-driving cars (SDCs). Previous\nresults on simulation-based testing for SDCs have shown that many automatically\ngenerated tests do not strongly contribute to identification of SDC faults,\nhence do not contribute towards increasing the quality of SDCs. Because running\nsuch \"uninformative\" tests generally leads to a waste of computational\nresources and a drastic increase in the testing cost of SDCs, testers should\navoid them. However, identifying \"uninformative\" tests before running them\nremains an open challenge. Hence, this paper proposes SDCScissor, a framework\nthat leverages Machine Learning (ML) to identify SDC tests that are unlikely to\ndetect faults in the SDC software under test, thus enabling testers to skip\ntheir execution and drastically increase the cost-effectiveness of\nsimulation-based testing of SDCs software. Our evaluation concerning the usage\nof six ML models on two large datasets characterized by 22'652 tests showed\nthat SDC-Scissor achieved a classification F1-score up to 96%. Moreover, our\nresults show that SDC-Scissor outperformed a randomized baseline in identifying\nmore failing tests per time unit.\nWebpage & Video: https://github.com/ChristianBirchler/sdc-scissor",
    "descriptor": "",
    "authors": [
      "Christian Birchler",
      "Nicolas Ganz",
      "Sajad Khatiri",
      "Alessio Gambi",
      "Sebastiano Panichella"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.11409"
  },
  {
    "id": "arXiv:2211.11412",
    "title": "Resource Allocation for Capacity Optimization in Joint Source-Channel  Coding Systems",
    "abstract": "Benefited from the advances of deep learning (DL) techniques, deep joint\nsource-channel coding (JSCC) has shown its great potential to improve the\nperformance of wireless transmission. However, most of the existing works focus\non the DL-based transceiver design of the JSCC model, while ignoring the\nresource allocation problem in wireless systems. In this paper, we consider a\ndownlink resource allocation problem, where a base station (BS) jointly\noptimizes the compression ratio (CR) and power allocation as well as resource\nblock (RB) assignment of each user according to the latency and performance\nconstraints to maximize the number of users that successfully receive their\nrequested content with desired quality. To solve this problem, we first\ndecompose it into two subproblems without loss of optimality. The first\nsubproblem is to minimize the required transmission power for each user under\ngiven RB allocation. We derive the closed-form expression of the optimal\ntransmit power by searching the maximum feasible compression ratio. The second\none aims at maximizing the number of supported users through optimal user-RB\npairing, which we solve by utilizing bisection search as well as Karmarka' s\nalgorithm. Simulation results validate the effectiveness of the proposed\nresource allocation method in terms of the number of satisfied users with given\nresources.",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "Kaiyi Chi",
      "Qianqian Yang",
      "Zhaohui Yang",
      "Yiping Duan",
      "Zhaoyang Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.11412"
  },
  {
    "id": "arXiv:2211.11416",
    "title": "Fairing-PIA: Progressive iterative approximation for fairing curve and  surface generation",
    "abstract": "The fairing curves and surfaces are used extensively in geometric design,\nmodeling, and industrial manufacturing. However, the majority of conventional\nfairing approaches, which lack sufficient parameters to improve fairness, are\nbased on energy minimization problems. In this study, we develop a novel\nprogressive-iterative approximation method for fairing curve and surface\ngeneration (fairing-PIA). Fairing-PIA is an iteration method that can generate\na series of curves (surfaces) by adjusting the control points of B-spline\ncurves (surfaces). In fairing-PIA, each control point is endowed with an\nindividual weight. Thus, the fairing-PIA has many parameters to optimize the\nshapes of curves and surfaces. Not only a fairing curve (surface) can be\ngenerated globally through fairing-PIA, but also the curve (surface) can be\nimproved locally. Moreover, we prove the convergence of the developed\nfairing-PIA and show that the conventional energy minimization fairing model is\na special case of fairing-PIA. Finally, numerical examples indicate that the\nproposed method is effective and efficient.",
    "descriptor": "\nComments: 21 pages, 10 figures\n",
    "authors": [
      "Yini Jiang",
      "Hongwei Lin"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.11416"
  },
  {
    "id": "arXiv:2211.11417",
    "title": "DyNCA: Real-time Dynamic Texture Synthesis Using Neural Cellular  Automata",
    "abstract": "Current Dynamic Texture Synthesis (DyTS) models in the literature can\nsynthesize realistic videos. However, these methods require a slow iterative\noptimization process to synthesize a single fixed-size short video, and they do\nnot offer any post-training control over the synthesis process. We propose\nDynamic Neural Cellular Automata (DyNCA), a framework for real-time and\ncontrollable dynamic texture synthesis. Our method is built upon the recently\nintroduced NCA models, and can synthesize infinitely-long and arbitrary-size\nrealistic texture videos in real-time. We quantitatively and qualitatively\nevaluate our model and show that our synthesized videos appear more realistic\nthan the existing results. We improve the SOTA DyTS performance by $2\\sim 4$\norders of magnitude. Moreover, our model offers several real-time and\ninteractive video controls including motion speed, motion direction, and an\nediting brush tool.",
    "descriptor": "",
    "authors": [
      "Ehsan Pajouheshgar",
      "Yitao Xu",
      "Tong Zhang",
      "Sabine S\u00fcsstrunk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11417"
  },
  {
    "id": "arXiv:2211.11418",
    "title": "L3Cube-HindBERT and DevBERT: Pre-Trained BERT Transformer models for  Devanagari based Hindi and Marathi Languages",
    "abstract": "The monolingual Hindi BERT models currently available on the model hub do not\nperform better than the multi-lingual models on downstream tasks. We present\nL3Cube-HindBERT, a Hindi BERT model pre-trained on Hindi monolingual corpus.\nFurther, since Indic languages, Hindi and Marathi share the Devanagari\nscript, we train a single model for both languages. We release DevBERT, a\nDevanagari BERT model trained on both Marathi and Hindi monolingual datasets.\nWe evaluate these models on downstream Hindi and Marathi text classification\nand named entity recognition tasks. The HindBERT and DevBERT-based models show\nsuperior performance compared to their multi-lingual counterparts. These models\nare shared at https://huggingface.co/l3cube-pune .",
    "descriptor": "",
    "authors": [
      "Raviraj Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11418"
  },
  {
    "id": "arXiv:2211.11419",
    "title": "Sequentially Sampled Chunk Conformer or Streaming End-to-End ASR",
    "abstract": "This paper presents an in-depth study on a Sequentially Sampled Chunk\nConformer, SSC-Conformer, for streaming End-to-End (E2E) ASR. The SSC-Conformer\nfirst demonstrates the significant performance gains from using the\nsequentially sampled chunk-wise multi-head self-attention (SSC-MHSA) in the\nConformer encoder by allowing efficient cross-chunk interactions while keeping\nlinear complexities. Furthermore, it explores taking advantage of chunked\nconvolution to make use of the chunk-wise future context and integrates with\ncasual convolution in the convolution layers to further reduce CER. We verify\nthe proposed SSC-Conformer on the AISHELL-1 benchmark and experimental results\nshow that a state-of-the-art performance for streaming E2E ASR is achieved with\nCER 5.33% without LM rescoring. And, owing to its linear complexity, the\nSSC-Conformer can train with large batch sizes and infer more efficiently.",
    "descriptor": "\nComments: This paper has been submitted to ICASSP 2023\n",
    "authors": [
      "Fangyuan Wang",
      "Xiyuan Wang",
      "Bo Xu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.11419"
  },
  {
    "id": "arXiv:2211.11423",
    "title": "Blur Interpolation Transformer for Real-World Motion from Blur",
    "abstract": "This paper studies the challenging problem of recovering motion from blur,\nalso known as joint deblurring and interpolation or blur temporal\nsuper-resolution. The remaining challenges are twofold: 1) the current methods\nstill leave considerable room for improvement in terms of visual quality even\non the synthetic dataset, and 2) poor generalization to real-world data. To\nthis end, we propose a blur interpolation transformer (BiT) to effectively\nunravel the underlying temporal correlation encoded in blur. Based on\nmulti-scale residual Swin transformer blocks, we introduce dual-end temporal\nsupervision and temporally symmetric ensembling strategies to generate\neffective features for time-varying motion rendering. In addition, we design a\nhybrid camera system to collect the first real-world dataset of one-to-many\nblur-sharp video pairs. Experimental results show that BiT has a significant\ngain over the state-of-the-art methods on the public dataset Adobe240. Besides,\nthe proposed real-world dataset effectively helps the model generalize well to\nreal blurry scenarios.",
    "descriptor": "",
    "authors": [
      "Zhihang Zhong",
      "Mingdeng Cao",
      "Xiang Ji",
      "Yinqiang Zheng",
      "Imari Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11423"
  },
  {
    "id": "arXiv:2211.11424",
    "title": "Unsupervised Domain Adaptation via Deep Hierarchical Optimal Transport",
    "abstract": "Unsupervised domain adaptation is a challenging task that aims to estimate a\ntransferable model for unlabeled target domain by exploiting source labeled\ndata. Optimal Transport (OT) based methods recently have been proven to be a\npromising direction for domain adaptation due to their competitive performance.\nHowever, most of these methods coarsely aligned source and target\ndistributions, leading to the over-aligned problem where the\ncategory-discriminative information is mixed up although domain-invariant\nrepresentations can be learned. In this paper, we propose a Deep Hierarchical\nOptimal Transport method (DeepHOT) for unsupervised domain adaptation. The main\nidea is to use hierarchical optimal transport to learn both domain-invariant\nand category-discriminative representations by mining the rich structural\ncorrelations among domain data. The DeepHOT framework consists of a\ndomain-level OT and an image-level OT, where the latter is used as the ground\ndistance metric for the former. The image-level OT captures structural\nassociations of local image regions that are beneficial to image\nclassification, while the domain-level OT learns domain-invariant\nrepresentations by leveraging the underlying geometry of domains. However, due\nto the high computational complexity, the optimal transport based models are\nlimited in some scenarios. To this end, we propose a robust and efficient\nimplementation of the DeepHOT framework by approximating origin OT with sliced\nWasserstein distance in image-level OT and using a mini-batch unbalanced\noptimal transport for domain-level OT. Extensive experiments show that DeepHOT\nsurpasses the state-of-the-art methods in four benchmark datasets. Code will be\nreleased on GitHub.",
    "descriptor": "\nComments: 9 pages, 3 figures\n",
    "authors": [
      "Yingxue Xu",
      "Guihua Wen",
      "Yang Hu",
      "Pei Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11424"
  },
  {
    "id": "arXiv:2211.11425",
    "title": "Data Leakage and Evaluation Issues in Micro-Expression Analysis",
    "abstract": "Micro-expressions have drawn increasing interest lately due to various\npotential applications. The task is, however, difficult as it incorporates many\nchallenges from the fields of computer vision, machine learning and emotional\nsciences. Due to the spontaneous and subtle characteristics of\nmicro-expressions, the available training and testing data are limited, which\nmake evaluation complex. We show that data leakage and fragmented evaluation\nprotocols are issues among the micro-expression literature. We find that fixing\ndata leaks can drastically reduce model performance, in some cases even making\nthe models perform similarly to a random classifier. To this end, we go through\ncommon pitfalls, propose a new standardized evaluation protocol using facial\naction units with over 2000 micro-expression samples, and provide an open\nsource library that implements the evaluation protocols in a standardized\nmanner. Code will be available in \\url{https://github.com/tvaranka/meb}.",
    "descriptor": "",
    "authors": [
      "Tuomas Varanka",
      "Yante Li",
      "Wei Peng",
      "Guoying Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11425"
  },
  {
    "id": "arXiv:2211.11426",
    "title": "Revealing Hidden Context Bias in Segmentation and Object Detection  through Concept-specific Explanations",
    "abstract": "Applying traditional post-hoc attribution methods to segmentation or object\ndetection predictors offers only limited insights, as the obtained feature\nattribution maps at input level typically resemble the models' predicted\nsegmentation mask or bounding box. In this work, we address the need for more\ninformative explanations for these predictors by proposing the post-hoc\neXplainable Artificial Intelligence method L-CRP to generate explanations that\nautomatically identify and visualize relevant concepts learned, recognized and\nused by the model during inference as well as precisely locate them in input\nspace. Our method therefore goes beyond singular input-level attribution maps\nand, as an approach based on the recently published Concept Relevance\nPropagation technique, is efficiently applicable to state-of-the-art black-box\narchitectures in segmentation and object detection, such as DeepLabV3+ and\nYOLOv6, among others. We verify the faithfulness of our proposed technique by\nquantitatively comparing different concept attribution methods, and discuss the\neffect on explanation complexity on popular datasets such as CityScapes, Pascal\nVOC and MS COCO 2017. The ability to precisely locate and communicate concepts\nis used to reveal and verify the use of background features, thereby\nhighlighting possible biases of the model.",
    "descriptor": "",
    "authors": [
      "Maximilian Dreyer",
      "Reduan Achtibat",
      "Thomas Wiegand",
      "Wojciech Samek",
      "Sebastian Lapuschkin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11426"
  },
  {
    "id": "arXiv:2211.11427",
    "title": "Expectation-Maximization Contrastive Learning for Compact  Video-and-Language Representations",
    "abstract": "Most video-and-language representation learning approaches employ contrastive\nlearning, e.g., CLIP, to project the video and text features into a common\nlatent space according to the semantic similarities of text-video pairs.\nHowever, such learned shared latent spaces are not often optimal, and the\nmodality gap between visual and textual representation can not be fully\neliminated. In this paper, we propose Expectation-Maximization Contrastive\nLearning (EMCL) to learn compact video-and-language representations.\nSpecifically, we use the Expectation-Maximization algorithm to find a compact\nset of bases for the latent space, where the features could be concisely\nrepresented as the linear combinations of these bases. Such feature\ndecomposition of video-and-language representations reduces the rank of the\nlatent space, resulting in increased representing power for the semantics.\nExtensive experiments on three benchmark text-video retrieval datasets prove\nthat our EMCL can learn more discriminative video-and-language representations\nthan previous methods, and significantly outperform previous state-of-the-art\nmethods across all metrics. More encouragingly, the proposed method can be\napplied to boost the performance of existing approaches either as a jointly\ntraining layer or an out-of-the-box inference module with no extra training,\nmaking it easy to be incorporated into any existing methods.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Peng Jin",
      "Jinfa Huang",
      "Fenglin Liu",
      "Xian Wu",
      "Shen Ge",
      "Guoli Song",
      "David A. Clifton",
      "Jie Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11427"
  },
  {
    "id": "arXiv:2211.11432",
    "title": "MATE: Masked Autoencoders are Online 3D Test-Time Learners",
    "abstract": "We propose MATE, the first Test-Time-Training (TTT) method designed for 3D\ndata. It makes deep networks trained in point cloud classification robust to\ndistribution shifts occurring in test data, which could not be anticipated\nduring training. Like existing TTT methods, which focused on classifying 2D\nimages in the presence of distribution shifts at test-time, MATE also leverages\ntest data for adaptation. Its test-time objective is that of a Masked\nAutoencoder: Each test point cloud has a large portion of its points removed\nbefore it is fed to the network, tasked with reconstructing the full point\ncloud. Once the network is updated, it is used to classify the point cloud. We\ntest MATE on several 3D object classification datasets and show that it\nsignificantly improves robustness of deep networks to several types of\ncorruptions commonly occurring in 3D point clouds. Further, we show that MATE\nis very efficient in terms of the fraction of points it needs for the\nadaptation. It can effectively adapt given as few as 5% of tokens of each test\nsample, which reduces its memory footprint and makes it lightweight. We also\nhighlight that MATE achieves competitive performance by adapting sparingly on\nthe test data, which further reduces its computational overhead, making it\nideal for real-time applications.",
    "descriptor": "\nComments: First 3 authors contributed equally\n",
    "authors": [
      "M. Jehanzeb Mirza",
      "Inkyu Shin",
      "Wei Lin",
      "Andreas Schriebl",
      "Kunyang Sun",
      "Jaesung Choe",
      "Horst Possegger",
      "Mateusz Kozinski",
      "In So Kweon",
      "Kun-Jin Yoon",
      "Horst Bischof"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11432"
  },
  {
    "id": "arXiv:2211.11434",
    "title": "Privacy in Practice: Private COVID-19 Detection in X-Ray Images",
    "abstract": "Machine learning (ML) can help fight the COVID-19 pandemic by enabling rapid\nscreening of large volumes of chest X-ray images. To perform such data analysis\nwhile maintaining patient privacy, we create ML models that satisfy\nDifferential Privacy (DP). Previous works exploring private COVID-19 ML models\nare in part based on small or skewed datasets, are lacking in their privacy\nguarantees, and do not investigate practical privacy. In this work, we\ntherefore suggest several improvements to address these open gaps. We account\nfor inherent class imbalances in the data and evaluate the utility-privacy\ntrade-off more extensively and over stricter privacy budgets than in previous\nwork. Our evaluation is supported by empirically estimating practical privacy\nleakage through actual attacks. Based on theory, the introduced DP should help\nlimit and mitigate information leakage threats posed by black-box Membership\nInference Attacks (MIAs). Our practical privacy analysis is the first to test\nthis hypothesis on the COVID-19 detection task. In addition, we also re-examine\nthe evaluation on the MNIST database. Our results indicate that based on the\ntask-dependent threat from MIAs, DP does not always improve practical privacy,\nwhich we show on the COVID-19 task. The results further suggest that with\nincreasing DP guarantees, empirical privacy leakage reaches an early plateau\nand DP therefore appears to have a limited impact on MIA defense. Our findings\nidentify possibilities for better utility-privacy trade-offs, and we thus\nbelieve that empirical attack-specific privacy estimation can play a vital role\nin tuning for practical privacy.",
    "descriptor": "",
    "authors": [
      "Lucas Lange",
      "Maja Schneider",
      "Erhard Rahm"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11434"
  },
  {
    "id": "arXiv:2211.11435",
    "title": "ZigZag: Universal Sampling-free Uncertainty Estimation Through Two-Step  Inference",
    "abstract": "Whereas the ability of deep networks to produce useful predictions on many\nkinds of data has been amply demonstrated, estimating the reliability of these\npredictions remains challenging. Sampling approaches such as MC-Dropout and\nDeep Ensembles have emerged as the most popular ones for this purpose.\nUnfortunately, they require many forward passes at inference time, which slows\nthem down. Sampling-free approaches can be faster but suffer from other\ndrawbacks, such as lower reliability of uncertainty estimates, difficulty of\nuse, and limited applicability to different types of tasks and data.\nIn this work, we introduce a sampling-free approach that is generic and easy\nto deploy, while producing reliable uncertainty estimates on par with\nstate-of-the-art methods at a significantly lower computational cost. It is\npredicated on training the network to produce the same output with and without\nadditional information about that output. At inference time, when no prior\ninformation is given, we use the network's own prediction as the additional\ninformation. We prove that the difference between the two predictions is an\naccurate uncertainty estimate and demonstrate our approach on various types of\ntasks and applications.",
    "descriptor": "",
    "authors": [
      "Nikita Durasov",
      "Nik Dorndorf",
      "Pascal Fua"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11435"
  },
  {
    "id": "arXiv:2211.11436",
    "title": "N-Gram in Swin Transformers for Efficient Lightweight Image  Super-Resolution",
    "abstract": "While some studies have proven that Swin Transformer (SwinT) with window\nself-attention (WSA) is suitable for single image super-resolution (SR), SwinT\nignores the broad regions for reconstructing high-resolution images due to\nwindow and shift size. In addition, many deep learning SR methods suffer from\nintensive computations. To address these problems, we introduce the N-Gram\ncontext to the image domain for the first time in history. We define N-Gram as\nneighboring local windows in SwinT, which differs from text analysis that views\nN-Gram as consecutive characters or words. N-Grams interact with each other by\nsliding-WSA, expanding the regions seen to restore degraded pixels. Using the\nN-Gram context, we propose NGswin, an efficient SR network with SCDP bottleneck\ntaking all outputs of the hierarchical encoder. Experimental results show that\nNGswin achieves competitive performance while keeping an efficient structure,\ncompared with previous leading methods. Moreover, we also improve other\nSwinT-based SR methods with the N-Gram context, thereby building an enhanced\nmodel: SwinIR-NG. Our improved SwinIR-NG outperforms the current best\nlightweight SR approaches and establishes state-of-the-art results. Codes will\nbe available soon.",
    "descriptor": "\nComments: 8 pages (main content) + 14 pages (supplementary content)\n",
    "authors": [
      "Haram Choi",
      "Jeongmin Lee",
      "Jihoon Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11436"
  },
  {
    "id": "arXiv:2211.11439",
    "title": "Place Recognition under Occlusion and Changing Appearance via  Disentangled Representations",
    "abstract": "Place recognition is a critical and challenging task for mobile robots,\naiming to retrieve an image captured at the same place as a query image from a\ndatabase. Existing methods tend to fail while robots move autonomously under\nocclusion (e.g., car, bus, truck) and changing appearance (e.g., illumination\nchanges, seasonal variation). Because they encode the image into only one code,\nentangling place features with appearance and occlusion features. To overcome\nthis limitation, we propose PROCA, an unsupervised approach to decompose the\nimage representation into three codes: a place code used as a descriptor to\nretrieve images, an appearance code that captures appearance properties, and an\nocclusion code that encodes occlusion content. Extensive experiments show that\nour model outperforms the state-of-the-art methods. Our code and data are\navailable at https://github.com/rover-xingyu/PROCA.",
    "descriptor": "",
    "authors": [
      "Yue Chen",
      "Xingyu Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11439"
  },
  {
    "id": "arXiv:2211.11444",
    "title": "(B)LOCKBOX -- Secure Software Architecture with Blockchain Verification",
    "abstract": "According to experts, one third of all IT vulnerabilities today are due to\ninadequate software verification. Internal program processes are not\nsufficiently secured against manipulation by attackers, especially if access\nhas been gained. There is a lack of internal control instances that can monitor\nand control program flows. Especially when a software vulnerability becomes\nknown, quick action is required, whereby the consequences for an individual\napplication are often not foreseeable. With our approach (B)LOCKBOX, software\nbuilding blocks act as verified entities within a transaction-based blockchain\nnetwork. Source Code, binaries and application execution become supervised.\nUnwanted interference and manipulation are prevented by the integrity of the\ndistributed system.",
    "descriptor": "",
    "authors": [
      "Erik Heiland",
      "Peter Hillmann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.11444"
  },
  {
    "id": "arXiv:2211.11445",
    "title": "Revisiting a Privacy-Preserving Location-based Service Protocol using  Edge Computing",
    "abstract": "Location-based services are getting more popular day by day. Finding nearby\nstores, proximity-based marketing, on-road service assistance, etc., are some\nof the services that use location-based services. In location-based services,\nuser information like user identity, user query, and location must be\nprotected. Ma et al. (INFOCOM-BigSecurity 2019) proposed a privacy-preserving\nlocation-based service using Somewhat Homomorphic Encryption (SHE). Their\nprotocol uses edge nodes that compute on SHE encrypted location data and\ndetermines the $k$-nearest points of interest contained in the Location-based\nServer (LBS) without revealing the original user coordinates to LBS, hence,\nensuring privacy of users locations. In this work, we show that the above\nprotocol by Ma et al. has a critical flaw. In particular, we show that their\nsecure comparison protocol has a correctness issue in that it will not lead to\ncorrect comparison. A major consequence of this flaw is that straightforward\napproaches to fix this issue will make their protocol insecure. Namely, the LBS\nwill be able to recover the actual locations of the users in each and every\nquery.",
    "descriptor": "",
    "authors": [
      "Santosh Kumar Upadhyaya",
      "Srinivas Vivek"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.11445"
  },
  {
    "id": "arXiv:2211.11446",
    "title": "SMAUG: Sparse Masked Autoencoder for Efficient Video-Language  Pre-training",
    "abstract": "Video-language pre-training is crucial for learning powerful multi-modal\nrepresentation. However, it typically requires a massive amount of computation.\nIn this paper, we develop SMAUG, an efficient pre-training framework for\nvideo-language models. The foundation component in SMAUG is masked\nautoencoders. Different from prior works which only mask textual inputs, our\nmasking strategy considers both visual and textual modalities, providing a\nbetter cross-modal alignment and saving more pre-training costs. On top of\nthat, we introduce a space-time token sparsification module, which leverages\ncontext information to further select only \"important\" spatial regions and\ntemporal frames for pre-training. Coupling all these designs allows our method\nto enjoy both competitive performances on text-to-video retrieval and video\nquestion answering tasks, and much less pre-training costs by 1.9X or more. For\nexample, our SMAUG only needs about 50 NVIDIA A6000 GPU hours for pre-training\nto attain competitive performances on these two video-language tasks across six\npopular benchmarks.",
    "descriptor": "",
    "authors": [
      "Yuanze Lin",
      "Chen Wei",
      "Huiyu Wang",
      "Alan Yuille",
      "Cihang Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11446"
  },
  {
    "id": "arXiv:2211.11448",
    "title": "Delving StyleGAN Inversion for Image Editing: A Foundation Latent Space  Viewpoint",
    "abstract": "GAN inversion and editing via StyleGAN maps an input image into the embedding\nspaces ($\\mathcal{W}$, $\\mathcal{W^+}$, and $\\mathcal{F}$) to simultaneously\nmaintain image fidelity and meaningful manipulation. From latent space\n$\\mathcal{W}$ to extended latent space $\\mathcal{W^+}$ to feature space\n$\\mathcal{F}$ in StyleGAN, the editability of GAN inversion decreases while its\nreconstruction quality increases. Recent GAN inversion methods typically\nexplore $\\mathcal{W^+}$ and $\\mathcal{F}$ rather than $\\mathcal{W}$ to improve\nreconstruction fidelity while maintaining editability. As $\\mathcal{W^+}$ and\n$\\mathcal{F}$ are derived from $\\mathcal{W}$ that is essentially the foundation\nlatent space of StyleGAN, these GAN inversion methods focusing on\n$\\mathcal{W^+}$ and $\\mathcal{F}$ spaces could be improved by stepping back to\n$\\mathcal{W}$. In this work, we propose to first obtain the precise latent code\nin foundation latent space $\\mathcal{W}$. We introduce contrastive learning to\nalign $\\mathcal{W}$ and the image space for precise latent code discovery. %The\nobtaining process is by using contrastive learning to align $\\mathcal{W}$ and\nthe image space. Then, we leverage a cross-attention encoder to transform the\nobtained latent code in $\\mathcal{W}$ into $\\mathcal{W^+}$ and $\\mathcal{F}$,\naccordingly. Our experiments show that our exploration of the foundation latent\nspace $\\mathcal{W}$ improves the representation ability of latent codes in\n$\\mathcal{W^+}$ and features in $\\mathcal{F}$, which yields state-of-the-art\nreconstruction fidelity and editability results on the standard benchmarks.\nProject page: \\url{https://github.com/KumapowerLIU/CLCAE}.",
    "descriptor": "",
    "authors": [
      "Hongyu Liu",
      "Yibing Song",
      "Qifeng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11448"
  },
  {
    "id": "arXiv:2211.11453",
    "title": "Methodology for Holistic Reference Modeling in Systems Engineering",
    "abstract": "Models in face of increasing complexity support development of new systems\nand enterprises. For an efficient procedure, reference models are adapted in\norder to reach a solution with les overhead which covers all necessary aspects.\nHere, a key challenge is applying a consistent methodology for the descriptions\nof such reference designs. This paper presents a holistic approach to describe\nreference models across different views and levels. Modeling stretches from the\nrequirements and capabilities over their subdivision to services and components\nup to the realization in processes and data structures. Benefits include an\nend-to-end traceability of the capability coverage with performance parameters\nconsidered already at the starting point of the reference design. This enables\nfocused development while considering design constraints and potential\nbottlenecks. We demonstrate the approach on the example of the development of a\nsmart robot. Here, our methodology highly supports transferability of designs\nfor the development of further systems.",
    "descriptor": "",
    "authors": [
      "Dominik Ascher",
      "Erik Heiland",
      "Diana Schnell",
      "Peter Hillmann",
      "Andreas Karcher"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.11453"
  },
  {
    "id": "arXiv:2211.11455",
    "title": "Backdoor Attacks on Multiagent Collaborative Systems",
    "abstract": "Backdoor attacks on reinforcement learning implant a backdoor in a victim\nagent's policy. Once the victim observes the trigger signal, it will switch to\nthe abnormal mode and fail its task. Most of the attacks assume the adversary\ncan arbitrarily modify the victim's observations, which may not be practical.\nOne work proposes to let one adversary agent use its actions to affect its\nopponent in two-agent competitive games, so that the opponent quickly fails\nafter observing certain trigger actions. However, in multiagent collaborative\nsystems, agents may not always be able to observe others. When and how much the\nadversary agent can affect others are uncertain, and we want the adversary\nagent to trigger others for as few times as possible. To solve this problem, we\nfirst design a novel training framework to produce auxiliary rewards that\nmeasure the extent to which the other agents'observations being affected. Then\nwe use the auxiliary rewards to train a trigger policy which enables the\nadversary agent to efficiently affect the others' observations. Given these\naffected observations, we further train the other agents to perform abnormally.\nExtensive experiments demonstrate that the proposed method enables the\nadversary agent to lure the others into the abnormal mode with only a few\nactions.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Shuo Chen",
      "Yue Qiu",
      "Jie Zhang"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.11455"
  },
  {
    "id": "arXiv:2211.11468",
    "title": "Enhancing Crisis-Related Tweet Classification with Entity-Masked  Language Modeling and Multi-Task Learning",
    "abstract": "Social media has become an important information source for crisis management\nand provides quick access to ongoing developments and critical information.\nHowever, classification models suffer from event-related biases and highly\nimbalanced label distributions which still poses a challenging task. To address\nthese challenges, we propose a combination of entity-masked language modeling\nand hierarchical multi-label classification as a multi-task learning problem.\nWe evaluate our method on tweets from the TREC-IS dataset and show an absolute\nperformance gain w.r.t. F1-score of up to 10% for actionable information types.\nMoreover, we found that entity-masking reduces the effect of overfitting to\nin-domain events and enables improvements in cross-event generalization.",
    "descriptor": "\nComments: Accepted at NLP4PI (EMNLP 2022)\n",
    "authors": [
      "Philipp Seeberger",
      "Korbinian Riedhammer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11468"
  },
  {
    "id": "arXiv:2211.11475",
    "title": "Sensing-Assisted Communication in Vehicular Networks with Intelligent  Surface",
    "abstract": "The recent development of integrated sensing and communications (ISAC)\ntechnology offers new opportunities to meet high-throughput and low-latency\ncommunication as well as high-resolution localization requirements in vehicular\nnetworks. However, considering the limited transmit power of the road site\nunits (RSUs) and the relatively small radar cross section (RCS) of vehicles\nwith random reflection coefficients, the power of echo signals may be too weak\nto be utilized for effective target detection and tracking. Moreover,\nhigh-frequency signals usually suffer from large fading loss when penetrating\nvehicles, which seriously degrades the quality of communication services inside\nthe vehicles. To handle this issue, we propose a novel sensing-assisted\ncommunication mechanism by employing an intelligent omni-surface (IOS) on the\nsurface of vehicles to enhance both sensing and communication (S&C)\nperformance. To this end, we first propose a two-stage ISAC protocol, including\nthe joint S&C stage and the communication-only stage, to fulfill more efficient\ncommunication performance improvements benefited from sensing. The achievable\ncommunication rate maximization problem is formulated by jointly optimizing the\ntransmit beamforming, the IOS phase shifts, and the duration of the joint S&C\nstage. However, solving this ISAC optimization problem is highly non-trivial\nsince inaccurate estimation and measurement information renders the achievable\nrate lack of closed-form expression. To handle this issue, we first derive a\nclosed-form expression of the achievable rate under uncertain location\ninformation, and then unveil a sufficient and necessary condition for the\nexistence of the joint S&C stage to offer useful insights for practical system\ndesign. Moreover, two typical scenarios including interference-limited and\nnoise-limited cases are analyzed.",
    "descriptor": "\nComments: 31 Pages. This work has been submitted to the IEEE for possible publication. arXiv admin note: text overlap with arXiv:2211.04200\n",
    "authors": [
      "Kaitao Meng",
      "Qingqing Wu",
      "Wen Chen",
      "Deshi Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.11475"
  },
  {
    "id": "arXiv:2211.11478",
    "title": "Background-Mixed Augmentation for Weakly Supervised Change Detection",
    "abstract": "Change detection (CD) is to decouple object changes (i.e., object missing or\nappearing) from background changes (i.e., environment variations) like light\nand season variations in two images captured in the same scene over a long time\nspan, presenting critical applications in disaster management, urban\ndevelopment, etc. In particular, the endless patterns of background changes\nrequire detectors to have a high generalization against unseen environment\nvariations, making this task significantly challenging. Recent deep\nlearning-based methods develop novel network architectures or optimization\nstrategies with paired-training examples, which do not handle the\ngeneralization issue explicitly and require huge manual pixel-level annotation\nefforts. In this work, for the first attempt in the CD community, we study the\ngeneralization issue of CD from the perspective of data augmentation and\ndevelop a novel weakly supervised training algorithm that only needs\nimage-level labels. Different from general augmentation techniques for\nclassification, we propose the background-mixed augmentation that is\nspecifically designed for change detection by augmenting examples under the\nguidance of a set of background changing images and letting deep CD models see\ndiverse environment variations. Moreover, we propose the augmented & real data\nconsistency loss that encourages the generalization increase significantly. Our\nmethod as a general framework can enhance a wide range of existing deep\nlearning-based detectors. We conduct extensive experiments in two public\ndatasets and enhance four state-of-the-art methods, demonstrating the\nadvantages of",
    "descriptor": "\nComments: conference\n",
    "authors": [
      "Rui Huang",
      "Ruofei Wang",
      "Qing Guo",
      "Jieda Wei",
      "Yuxiang Zhang",
      "Wei Fan",
      "Yang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11478"
  },
  {
    "id": "arXiv:2211.11479",
    "title": "A Dataset for Greek Traditional and Folk Music: Lyra",
    "abstract": "Studying under-represented music traditions under the MIR scope is crucial,\nnot only for developing novel analysis tools, but also for unveiling musical\nfunctions that might prove useful in studying world musics. This paper presents\na dataset for Greek Traditional and Folk music that includes 1570 pieces,\nsumming in around 80 hours of data. The dataset incorporates YouTube\ntimestamped links for retrieving audio and video, along with rich metadata\ninformation with regards to instrumentation, geography and genre, among others.\nThe content has been collected from a Greek documentary series that is\navailable online, where academics present music traditions of Greece with live\nmusic and dance performance during the show, along with discussions about\nsocial, cultural and musicological aspects of the presented music. Therefore,\nthis procedure has resulted in a significant wealth of descriptions regarding a\nvariety of aspects, such as musical genre, places of origin and musical\ninstruments. In addition, the audio recordings were performed under strict\nproduction-level specifications, in terms of recording equipment, leading to\nvery clean and homogeneous audio content. In this work, apart from presenting\nthe dataset in detail, we propose a baseline deep-learning classification\napproach to recognize the involved musicological attributes. The dataset, the\nbaseline classification methods and the models are provided in public\nrepositories. Future directions for further refining the dataset are also\ndiscussed.",
    "descriptor": "",
    "authors": [
      "Charilaos Papaioannou",
      "Ioannis Valiantzas",
      "Theodoros Giannakopoulos",
      "Maximos Kaliakatsos-Papakostas",
      "Alexandros Potamianos"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.11479"
  },
  {
    "id": "arXiv:2211.11482",
    "title": "Applications of statistical causal inference in software engineering",
    "abstract": "This paper reviews existing work in software engineering that applies\nstatistical causal inference methods. These methods aim at estimating causal\neffects from observational data. The review covers 32 papers published between\n2010 and 2022. Our results show that the application of statistical causal\ninference methods is relatively recent and that the corresponding research\ncommunity remains relatively fragmented.",
    "descriptor": "\nComments: 34 pages, 11 tables, 7 figures\n",
    "authors": [
      "Julien Siebert"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11482"
  },
  {
    "id": "arXiv:2211.11483",
    "title": "Deanthropomorphising NLP: Can a Language Model Be Conscious?",
    "abstract": "This work is intended as a voice in the discussion over the recent claims\nthat LaMDA, a pretrained language model based on the Transformer model\narchitecture, is sentient. This claim, if confirmed, would have serious\nramifications in the Natural Language Processing (NLP) community due to\nwide-spread use of similar models. However, here we take the position that such\na language model cannot be sentient, or conscious, and that LaMDA in particular\nexhibits no advances over other similar models that would qualify it. We\njustify this by analysing the Transformer architecture through Integrated\nInformation Theory. We see the claims of consciousness as part of a wider\ntendency to use anthropomorphic language in NLP reporting. Regardless of the\nveracity of the claims, we consider this an opportune moment to take stock of\nprogress in language modelling and consider the ethical implications of the\ntask. In order to make this work helpful for readers outside the NLP community,\nwe also present the necessary background in language modelling.",
    "descriptor": "",
    "authors": [
      "Matthew Shardlow",
      "Piotr Przyby\u0142a"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11483"
  },
  {
    "id": "arXiv:2211.11487",
    "title": "Fine-Grained Scheduling for Containerized HPC Workloads in Kubernetes  Clusters",
    "abstract": "Containerization technology offers lightweight OS-level virtualization, and\nenables portability, reproducibility, and flexibility by packing applications\nwith low performance overhead and low effort to maintain and scale them.\nMoreover, container orchestrators (e.g., Kubernetes) are widely used in the\nCloud to manage large clusters running many containerized applications.\nHowever, scheduling policies that consider the performance nuances of\ncontainerized High Performance Computing (HPC) workloads have not been\nwell-explored yet. This paper conducts fine-grained scheduling policies for\ncontainerized HPC workloads in Kubernetes clusters, focusing especially on\npartitioning each job into a suitable multi-container deployment according to\nthe application profile. We implement our scheduling schemes on different\nlayers of management (application and infrastructure), so that each component\nhas its own focus and algorithms but still collaborates with others. Our\nresults show that our fine-grained scheduling policies outperform baseline and\nbaseline with CPU/memory affinity enabled policies, reducing the overall\nresponse time by 35% and 19%, respectively, and also improving the makespan by\n34% and 11%, respectively. They also provide better usability and flexibility\nto specify HPC workloads than other comparable HPC Cloud frameworks, while\nproviding better scheduling efficiency thanks to their multi-layered approach.",
    "descriptor": "\nComments: HPCC2022\n",
    "authors": [
      "Peini Liu",
      "Jordi Guitart"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.11487"
  },
  {
    "id": "arXiv:2211.11489",
    "title": "Efficient Generalization Improvement Guided by Random Weight  Perturbation",
    "abstract": "To fully uncover the great potential of deep neural networks (DNNs), various\nlearning algorithms have been developed to improve the model's generalization\nability. Recently, sharpness-aware minimization (SAM) establishes a generic\nscheme for generalization improvements by minimizing the sharpness measure\nwithin a small neighborhood and achieves state-of-the-art performance. However,\nSAM requires two consecutive gradient evaluations for solving the min-max\nproblem and inevitably doubles the training time. In this paper, we resort to\nfilter-wise random weight perturbations (RWP) to decouple the nested gradients\nin SAM. Different from the small adversarial perturbations in SAM, RWP is\nsofter and allows a much larger magnitude of perturbations. Specifically, we\njointly optimize the loss function with random perturbations and the original\nloss function: the former guides the network towards a wider flat region while\nthe latter helps recover the necessary local information. These two loss terms\nare complementary to each other and mutually independent. Hence, the\ncorresponding gradients can be efficiently computed in parallel, enabling\nnearly the same training speed as regular training. As a result, we achieve\nvery competitive performance on CIFAR and remarkably better performance on\nImageNet (e.g. $\\mathbf{ +1.1\\%}$) compared with SAM, but always require half\nof the training time. The code is released at https://github.com/nblt/RWP.",
    "descriptor": "",
    "authors": [
      "Tao Li",
      "Weihao Yan",
      "Zehao Lei",
      "Yingwen Wu",
      "Kun Fang",
      "Ming Yang",
      "Xiaolin Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11489"
  },
  {
    "id": "arXiv:2211.11491",
    "title": "Self-Adaptive, Dynamic, Integrated Statistical and Information Theory  Learning",
    "abstract": "The paper analyses and serves with a positioning of various error measures\napplied in neural network training and identifies that there is no best of\nmeasure, although there is a set of measures with changing superiorities in\ndifferent learning situations. An outstanding, remarkable measure called\n$E_{Exp}$ published by Silva and his research partners represents a research\ndirection to combine more measures successfully with fixed importance weighting\nduring learning. The main idea of the paper is to go far beyond and to\nintegrate this relative importance into the neural network training\nalgorithm(s) realized through a novel error measure called $E_{ExpAbs}$. This\napproach is included into the Levenberg-Marquardt training algorithm, so, a\nnovel version of it is also introduced, resulting a self-adaptive, dynamic\nlearning algorithm. This dynamism does not has positive effects on the resulted\nmodel accuracy only, but also on the training process itself. The described\ncomprehensive algorithm tests proved that the proposed, novel algorithm\nintegrates dynamically the two big worlds of statistics and information theory\nthat is the key novelty of the paper.",
    "descriptor": "\nComments: 62 pages, 30 figures, original article\n",
    "authors": [
      "Zsolt J\u00e1nos Viharos",
      "\u00c1gnes Sz\u0171cs"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.11491"
  },
  {
    "id": "arXiv:2211.11492",
    "title": "ClipCrop: Conditioned Cropping Driven by Vision-Language Model",
    "abstract": "Image cropping has progressed tremendously under the data-driven paradigm.\nHowever, current approaches do not account for the intentions of the user,\nwhich is an issue especially when the composition of the input image is\ncomplex. Moreover, labeling of cropping data is costly and hence the amount of\ndata is limited, leading to poor generalization performance of current\nalgorithms in the wild. In this work, we take advantage of vision-language\nmodels as a foundation for creating robust and user-intentional cropping\nalgorithms. By adapting a transformer decoder with a pre-trained CLIP-based\ndetection model, OWL-ViT, we develop a method to perform cropping with a text\nor image query that reflects the user's intention as guidance. In addition, our\npipeline design allows the model to learn text-conditioned aesthetic cropping\nwith a small cropping dataset, while inheriting the open-vocabulary ability\nacquired from millions of text-image pairs. We validate our model through\nextensive experiments on existing datasets as well as a new cropping test set\nwe compiled that is characterized by content ambiguity.",
    "descriptor": "",
    "authors": [
      "Zhihang Zhong",
      "Mingxi Cheng",
      "Zhirong Wu",
      "Yuhui Yuan",
      "Yinqiang Zheng",
      "Ji Li",
      "Han Hu",
      "Stephen Lin",
      "Yoichi Sato",
      "Imari Sato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11492"
  },
  {
    "id": "arXiv:2211.11493",
    "title": "Extension of Quasi-Overlap and Quasi-Grouping Functions Defined on  Bounded Lattices Via Retractions",
    "abstract": "In this paper, we propose a method of extending quasi-overlap and grouping\nfunctions defined on a sublattice $ M $ of a bounded lattice $ L $ to this\nlattice considering a more general version of sublattice definition, introduced\nby Palmeira and Bedregral.",
    "descriptor": "",
    "authors": [
      "Ana Shirley Monteiro",
      "Regivan Santiago",
      "Benjam\u00edn Bedregal",
      "Juscelino Ara\u00fajo",
      "Eduardo Palmeira"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.11493"
  },
  {
    "id": "arXiv:2211.11495",
    "title": "Global misinformation spillovers in the online vaccination debate before  and during COVID-19",
    "abstract": "Anti-vaccination views pervade online social media, fueling distrust in\nscientific expertise and increasing vaccine-hesitant individuals. While\nprevious studies focused on specific countries, the COVID-19 pandemic brought\nthe vaccination discourse worldwide, underpinning the need to tackle\nlow-credible information flows on a global scale to design effective\ncountermeasures. Here, we leverage 316 million vaccine-related Twitter messages\nin 18 languages, from October 2019 to March 2021, to quantify misinformation\nflows between users exposed to anti-vaccination (no-vax) content. We find that,\nduring the pandemic, no-vax communities became more central in the\ncountry-specific debates and their cross-border connections strengthened,\nrevealing a global Twitter anti-vaccination network. U.S. users are central in\nthis network, while Russian users also become net exporters of misinformation\nduring vaccination roll-out. Interestingly, we find that Twitter's content\nmoderation efforts, and in particular the suspension of users following the\nJanuary 6th U.S. Capitol attack, had a worldwide impact in reducing\nmisinformation spread about vaccines. These findings may help public health\ninstitutions and social media platforms to mitigate the spread of\nhealth-related, low-credible information by revealing vulnerable online\ncommunities.",
    "descriptor": "",
    "authors": [
      "Jacopo Lenti",
      "Kyriaki Kalimeri",
      "Andr\u00e9 Panisson",
      "Daniela Paolotti",
      "Michele Tizzani",
      "Yelena Mejova",
      "Michele Starnini"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.11495"
  },
  {
    "id": "arXiv:2211.11500",
    "title": "Compositional Scene Modeling with Global Object-Centric Representations",
    "abstract": "The appearance of the same object may vary in different scene images due to\nperspectives and occlusions between objects. Humans can easily identify the\nsame object, even if occlusions exist, by completing the occluded parts based\non its canonical image in the memory. Achieving this ability is still a\nchallenge for machine learning, especially under the unsupervised learning\nsetting. Inspired by such an ability of humans, this paper proposes a\ncompositional scene modeling method to infer global representations of\ncanonical images of objects without any supervision. The representation of each\nobject is divided into an intrinsic part, which characterizes globally\ninvariant information (i.e. canonical representation of an object), and an\nextrinsic part, which characterizes scene-dependent information (e.g., position\nand size). To infer the intrinsic representation of each object, we employ a\npatch-matching strategy to align the representation of a potentially occluded\nobject with the canonical representations of objects, and sample the most\nprobable canonical representation based on the category of object determined by\namortized variational inference. Extensive experiments are conducted on four\nobject-centric learning benchmarks, and experimental results demonstrate that\nthe proposed method not only outperforms state-of-the-arts in terms of\nsegmentation and reconstruction, but also achieves good global object\nidentification performance.",
    "descriptor": "",
    "authors": [
      "Tonglin Chen",
      "Bin Li",
      "Zhimeng Shen",
      "Xiangyang Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11500"
  },
  {
    "id": "arXiv:2211.11501",
    "title": "DS-1000: A Natural and Reliable Benchmark for Data Science Code  Generation",
    "abstract": "We introduce DS-1000, a code generation benchmark with a thousand data\nscience problems spanning seven Python libraries, such as NumPy and Pandas.\nCompared to prior works, DS-1000 incorporates three core features. First, our\nproblems reflect diverse, realistic, and practical use cases since we collected\nthem from StackOverflow. Second, our automatic evaluation is highly specific\n(reliable) -- across all Codex-002-predicted solutions that our evaluation\naccept, only 1.8% of them are incorrect; we achieve this with multi-criteria\nmetrics, checking both functional correctness by running test cases and\nsurface-form constraints by restricting API usages or keywords. Finally, we\nproactively defend against memorization by slightly modifying our problems to\nbe different from the original StackOverflow source; consequently, models\ncannot answer them correctly by memorizing the solutions from pre-training. The\ncurrent best public system (Codex-002) achieves 43.3% accuracy, leaving ample\nroom for improvement. We release our benchmark at\nhttps://ds1000-code-gen.github.io.",
    "descriptor": "",
    "authors": [
      "Yuhang Lai",
      "Chengxi Li",
      "Yiming Wang",
      "Tianyi Zhang",
      "Ruiqi Zhong",
      "Luke Zettlemoyer",
      "Scott Wen-tau Yih",
      "Daniel Fried",
      "Sida Wang",
      "Tao Yu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11501"
  },
  {
    "id": "arXiv:2211.11502",
    "title": "Differentiable Physics-based Greenhouse Simulation",
    "abstract": "We present a differentiable greenhouse simulation model based on physical\nprocesses whose parameters can be obtained by training from real data. The\nphysics-based simulation model is fully interpretable and is able to do state\nprediction for both climate and crop dynamics in the greenhouse over very a\nlong time horizon. The model works by constructing a system of linear\ndifferential equations and solving them to obtain the next state. We propose a\nprocedure to solve the differential equations, handle the problem of missing\nunobservable states in the data, and train the model efficiently. Our\nexperiment shows the procedure is effective. The model improves significantly\nafter training and can simulate a greenhouse that grows cucumbers accurately.",
    "descriptor": "\nComments: Accepted at the Machine Learning and the Physical Sciences workshop, NeurIPS 2022. 7 pages, 2 figures\n",
    "authors": [
      "Nhat M. Nguyen",
      "Hieu T. Tran",
      "Minh V. Duong",
      "Hanh Bui",
      "Kenneth Tran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.11502"
  },
  {
    "id": "arXiv:2211.11505",
    "title": "Local-to-Global Registration for Bundle-Adjusting Neural Radiance Fields",
    "abstract": "Neural Radiance Fields (NeRF) have achieved photorealistic novel views\nsynthesis; however, the requirement of accurate camera poses limits its\napplication. Despite analysis-by-synthesis extensions for jointly learning\nneural 3D representations and registering camera frames exist, they are\nsusceptible to suboptimal solutions if poorly initialized. We propose L2G-NeRF,\na Local-to-Global registration method for bundle-adjusting Neural Radiance\nFields: first, a pixel-wise flexible alignment, followed by a frame-wise\nconstrained parametric alignment. Pixel-wise local alignment is learned in an\nunsupervised way via a deep network which optimizes photometric reconstruction\nerrors. Frame-wise global alignment is performed using differentiable parameter\nestimation solvers on the pixel-wise correspondences to find a global\ntransformation. Experiments on synthetic and real-world data show that our\nmethod outperforms the current state-of-the-art in terms of high-fidelity\nreconstruction and resolving large camera pose misalignment. Our module is an\neasy-to-use plugin that can be applied to NeRF variants and other neural field\napplications. The Code and supplementary materials are available at\nhttps://rover-xingyu.github.io/L2G-NeRF/.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2104.06405 by other authors\n",
    "authors": [
      "Yue Chen",
      "Xingyu Chen",
      "Xuan Wang",
      "Qi Zhang",
      "Yu Guo",
      "Ying Shan",
      "Fei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11505"
  },
  {
    "id": "arXiv:2211.11512",
    "title": "Bursting the Burden Bubble? An Assessment of Sharma et al.'s  Counterfactual-based Fairness Metric",
    "abstract": "Machine learning has seen an increase in negative publicity in recent years,\ndue to biased, unfair, and uninterpretable models. There is a rising interest\nin making machine learning models more fair for unprivileged communities, such\nas women or people of color. Metrics are needed to evaluate the fairness of a\nmodel. A novel metric for evaluating fairness between groups is Burden, which\nuses counterfactuals to approximate the average distance of negatively\nclassified individuals in a group to the decision boundary of the model. The\ngoal of this study is to compare Burden to statistical parity, a well-known\nfairness metric, and discover Burden's advantages and disadvantages. We do this\nby calculating the Burden and statistical parity of a sensitive attribute in\nthree datasets: two synthetic datasets are created to display differences\nbetween the two metrics, and one real-world dataset is used. We show that\nBurden can show unfairness where statistical parity can not, and that the two\nmetrics can even disagree on which group is treated unfairly. We conclude that\nBurden is a valuable metric, but does not replace statistical parity: it rather\nis valuable to use both.",
    "descriptor": "\nComments: 11 pages, 3 figures, conference: BNAIC/BeNeLearn (this https URL)\n",
    "authors": [
      "Yochem van Rosmalen",
      "Florian van der Steen",
      "Sebastiaan Jans",
      "Daan van der Weijden"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.11512"
  },
  {
    "id": "arXiv:2211.11514",
    "title": "ProSFDA: Prompt Learning based Source-free Domain Adaptation for Medical  Image Segmentation",
    "abstract": "The domain discrepancy existed between medical images acquired in different\nsituations renders a major hurdle in deploying pre-trained medical image\nsegmentation models for clinical use. Since it is less possible to distribute\ntraining data with the pre-trained model due to the huge data size and privacy\nconcern, source-free unsupervised domain adaptation (SFDA) has recently been\nincreasingly studied based on either pseudo labels or prior knowledge. However,\nthe image features and probability maps used by pseudo label-based SFDA and the\nconsistent prior assumption and the prior prediction network used by\nprior-guided SFDA may become less reliable when the domain discrepancy is\nlarge. In this paper, we propose a \\textbf{Pro}mpt learning based \\textbf{SFDA}\n(\\textbf{ProSFDA}) method for medical image segmentation, which aims to improve\nthe quality of domain adaption by minimizing explicitly the domain discrepancy.\nSpecifically, in the prompt learning stage, we estimate source-domain images\nvia adding a domain-aware prompt to target-domain images, then optimize the\nprompt via minimizing the statistic alignment loss, and thereby prompt the\nsource model to generate reliable predictions on (altered) target-domain\nimages. In the feature alignment stage, we also align the features of\ntarget-domain images and their styles-augmented counterparts to optimize the\nsource model, and hence push the model to extract compact features. We evaluate\nour ProSFDA on two multi-domain medical image segmentation benchmarks. Our\nresults indicate that the proposed ProSFDA outperforms substantially other SFDA\nmethods and is even comparable to UDA methods. Code will be available at\n\\url{https://github.com/ShishuaiHu/ProSFDA}.",
    "descriptor": "",
    "authors": [
      "Shishuai Hu",
      "Zehui Liao",
      "Yong Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11514"
  },
  {
    "id": "arXiv:2211.11516",
    "title": "Secondary constructions of vectorial $p$-ary weakly regular bent  functions",
    "abstract": "In \\cite{Bapic, Tang, Zheng} a new method for the secondary construction of\nvectorial/Boolean bent functions via the so-called $(P_U)$ property was\nintroduced. In 2018, Qi et al. generalized the methods in \\cite{Tang} for the\nconstruction of $p$-ary weakly regular bent functions. The objective of this\npaper is to further generalize these constructions, following the ideas in\n\\cite{Bapic, Zheng}, for secondary constructions of vectorial $p$-ary weakly\nregular bent and plateaued functions. We also present some infinite families of\nsuch functions via the $p$-ary Maiorana-McFarland class. Additionally, we give\nanother characterization of the $(P_U)$ property for the $p$-ary case via\nsecond-order derivatives, as it was done for the Boolean case in \\cite{Zheng}.",
    "descriptor": "",
    "authors": [
      "Amar Bapi\u0107"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.11516"
  },
  {
    "id": "arXiv:2211.11518",
    "title": "Evaluating Web Search Engines Results for Personalization and User  Tracking",
    "abstract": "Recently, light has been shed on the trend of personalization, which comes\ninto play whenever different search results are being tailored for a group of\nusers who have issued the same search query. The unpalatable fact that myriads\nof search results are being manipulated has perturbed a horde of people. With\nregards to that, personalization can be instrumental in spurring the Filter\nBubble effects, which revolves around the inability of certain users to gain\naccess to the typified contents that are allegedly irrelevant per the search\nengine's algorithm.\nIn harmony with that, there is a wealth of research on this area. Each of\nthese has relied on using techniques revolving around creating Google accounts\nthat differ in one feature and issuing identical search queries from each\naccount. The search results are often compared to determine whether those\nresults are going to vary per account. Thereupon, we have conducted six\nexperiments that aim to closely inspect and spot the patterns of\npersonalization in search results. In a like manner, we are going to examine\nhow the search results are going to vary accordingly. In all of the tasks,\nthree different metrics are going to be measured, namely, the number of total\nhits, the first hit, and the correlation between hits. Those experiments are\ncentered around fulfilling the following tasks. Firstly, setting up four VPNs\nthat are located at different geographic locations and comparing the search\nresults with those obtained in the UAE. Secondly, performing the search while\nlogging in and out of a Google account. Thirdly, searching while connecting to\ndifferent networks: home, phone, and university networks. Fourthly, using\ndifferent search engines to issue the search queries. Fifthly, using different\nweb browsers to carry out the search process. Finally, creating and training\nsix Google accounts.",
    "descriptor": "",
    "authors": [
      "Shamma Rashed",
      "Tasnim Said",
      "Amal Abdulrahman",
      "Arsiema Yohannes",
      "Monther Aldwairi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.11518"
  },
  {
    "id": "arXiv:2211.11520",
    "title": "Demo Abstract: Real-Time Out-of-Distribution Detection on a Mobile Robot",
    "abstract": "In a cyber-physical system such as an autonomous vehicle (AV), machine\nlearning (ML) models can be used to navigate and identify objects that may\ninterfere with the vehicle's operation. However, ML models are unlikely to make\naccurate decisions when presented with data outside their training\ndistribution. Out-of-distribution (OOD) detection can act as a safety monitor\nfor ML models by identifying such samples at run time. However, in safety\ncritical systems like AVs, OOD detection needs to satisfy real-time constraints\nin addition to functional requirements. In this demonstration, we use a mobile\nrobot as a surrogate for an AV and use an OOD detector to identify potentially\nhazardous samples. The robot navigates a miniature town using image data and a\nYOLO object detection network. We show that our OOD detector is capable of\nidentifying OOD images in real-time on an embedded platform concurrently\nperforming object detection and lane following. We also show that it can be\nused to successfully stop the vehicle in the presence of unknown, novel\nsamples.",
    "descriptor": "\nComments: 3 pages, 5 figures, RTSS 2022\n",
    "authors": [
      "Michael Yuhas",
      "Arvind Easwaran"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11520"
  },
  {
    "id": "arXiv:2211.11521",
    "title": "Un discours et un public \"Gilets Jaunes\" au coeur du Grand D\u00e9bat  National? Combinaison des approches IA et textom\u00e9triques pour l'analyse de  discours des plateformes \"Grand D\u00e9bat National\" et \"Vrai d\u00e9bat\"",
    "abstract": "In this contribution, we propose to analyze the statements coming from two\n''civic tech'' platforms-the governmental platform, ''Grand D{\\'e}bat\nNational'' and, its political and algorithmic response proposed by a Yellow\nVest collective, ''Vrai D{\\'e}bat''-, by confronting two families of algorithms\ndedicated to text analysis. We propose to implement, on the one hand, proven\napproaches in textual data analysis (Reinert/Iramuteq Method) which have\nrecently shown their interest in the analysis of very large corpora and, on the\nother hand, new methods resulting from the crossroads of the computer worlds,\nartificial intelligence and automatic language processing. We will examine the\nmethodological solutions for qualifying the social properties of speakers about\nwhom we have little direct information. Finally, we will attempt to present\nsome research questions at the crossroads of the political sociology of public\nopinion and data science, which such a confrontation opens up.",
    "descriptor": "\nComments: in French language. JADT 2020, Jun 2020, Toulouse, France\n",
    "authors": [
      "Suignard Philippe"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11521"
  },
  {
    "id": "arXiv:2211.11523",
    "title": "Revisiting the Internet of Things: New Trends, Opportunities and Grand  Challenges",
    "abstract": "The Internet of Things (IoT) has brought the dream of ubiquitous data access\nfrom physical environments into reality. IoT embeds sensors and actuators in\nphysical objects so that they can communicate and exchange data between\nthemselves to improve efficiency along with enabling real-time intelligent\nservices and offering better quality of life to people. The number of deployed\nIoT devices has rapidly grown in the past five years in a way that makes IoT\nthe most disruptive technology in recent history. In this paper, we reevaluate\nthe position of IoT in our life and provide deep insights on its enabling\ntechnologies, applications, rising trends and grand challenges. The paper also\nhighlights the role of artificial intelligence to make IoT the top\ntransformative technology that has been ever developed in human history.",
    "descriptor": "",
    "authors": [
      "Khalid Elgazzar",
      "Haytham Khalil",
      "Taghreed Alghamdi",
      "Ahmed Badr",
      "Ghadeer Abdelkader",
      "Abdelrahman Elewah",
      "Rajkumar Buyya"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.11523"
  },
  {
    "id": "arXiv:2211.11524",
    "title": "Conversion-Based Dynamic-Creative-Optimization in Native Advertising",
    "abstract": "Yahoo Gemini native advertising marketplace serves billions of impressions\ndaily, to hundreds millions of unique users, and reaches a yearly revenue of\nmany hundreds of millions USDs. Powering Gemini native models for predicting\nadvertise (ad) event probabilities, such as conversions and clicks, is OFFSET -\na feature enhanced collaborative-filtering (CF) based event prediction\nalgorithm. The predicted probabilities are then used in Gemini native auctions\nto determine which ads to present for every serving event (impression). Dynamic\ncreative optimization (DCO) is a recent Gemini native product that was launched\ntwo years ago and is increasingly gaining more attention from advertisers. The\nDCO product enables advertisers to issue several assets per each native ad\nattribute, creating multiple combinations for each DCO ad. Since different\ncombinations may appeal to different crowds, it may be beneficial to present\ncertain combinations more frequently than others to maximize revenue while\nkeeping advertisers and users satisfied. The initial DCO offer was to optimize\nclick-through rates (CTR), however as the marketplace shifts more towards\nconversion based campaigns, advertisers also ask for a {conversion based\nsolution. To accommodate this request, we present a post-auction solution,\nwhere DCO ads combinations are favored according to their predicted conversion\nrate (CVR). The predictions are provided by an auxiliary OFFSET based\ncombination CVR prediction model, and used to generate the combination\ndistributions for DCO ad rendering during serving time. An online evaluation of\nthis explore-exploit solution, via online bucket A/B testing, serving Gemini\nnative DCO traffic, showed a 53.5% CVR lift, when compared to a control bucket\nserving all combinations uniformly at random.",
    "descriptor": "\nComments: Accepted to IEEE Big Data 2022 conference\n",
    "authors": [
      "Yohay Kaplan",
      "Yair Koren",
      "Alex Shtoff",
      "Tomer Shadi",
      "Oren Somekh"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11524"
  },
  {
    "id": "arXiv:2211.11525",
    "title": "Quantinar: a blockchain p2p ecosystem for honest scientific research",
    "abstract": "Living in the Information Age, the power of data and correct statistical\nanalysis has never been more prevalent. Academics, practitioners and many other\nprofessionals nowadays require an accurate application of quantitative methods.\nThough many branches are subject to a crisis of integrity, which is shown in\nimproper use of statistical models, $p$-hacking, HARKing or failure to\nreplicate results. We propose the use of a peer-to-peer education network,\nQuantinar, to spread quantitative analysis knowledge embedded with code in the\nform of Quantlets. The integration of blockchain technology makes Quantinar a\ndecentralised autonomous organisation (DAO) that ensures fully transparent and\nreproducible scientific research.",
    "descriptor": "",
    "authors": [
      "Raul Bag",
      "Bruno Spilak",
      "Julian Winkel",
      "Wolfgang Karl H\u00e4rdle"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.11525"
  },
  {
    "id": "arXiv:2211.11526",
    "title": "Variable-Based Fault Localization via Enhanced Decision Tree",
    "abstract": "Fault localization, aiming at localizing the root cause of the bug under\nrepair, has been a longstanding research topic. Although many approaches have\nbeen proposed in the last decades, most of the existing studies work at\ncoarse-grained statement or method levels with very limited insights about how\nto repair the bug (granularity problem), but few studies target the\nfiner-grained fault localization. In this paper, we target the granularity\nproblem and propose a novel finer-grained variable-level fault localization\ntechnique. Specifically, we design a program-dependency-enhanced decision tree\nmodel to boost the identification of fault-relevant variables via\ndiscriminating failed and passed test cases based on the variable values. To\nevaluate the effectiveness of our approach, we have implemented it in a tool\ncalled VARDT and conducted an extensive study over the Defects4J benchmark. The\nresults show that VARDT outperforms the state-of-the-art fault localization\napproaches with at least 247.8% improvements in terms of bugs located at Top-1,\nand the average improvements are 330.5%.\nBesides, to investigate whether our finer-grained fault localization result\ncan further improve the effectiveness of downstream APR techniques, we have\nadapted VARDT to the application of patch filtering, where VARDT outperforms\nthe state-of-the-art PATCH-SIM by filtering 26.0% more incorrect patches. The\nresults demonstrate the effectiveness of our approach and it also provides a\nnew way of thinking for improving automatic program repair techniques.",
    "descriptor": "",
    "authors": [
      "Jiajun Jiang",
      "Yumeng Wang",
      "Junjie Chen",
      "Delin Lv",
      "Mengjiao Liu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.11526"
  },
  {
    "id": "arXiv:2211.11527",
    "title": "TIER-A: Denoising Learning Framework for Information Extraction",
    "abstract": "With the development of deep neural language models, great progress has been\nmade in information extraction recently. However, deep learning models often\noverfit on noisy data points, leading to poor performance. In this work, we\nexamine the role of information entropy in the overfitting process and draw a\nkey insight that overfitting is a process of overconfidence and entropy\ndecreasing. Motivated by such properties, we propose a simple yet effective\nco-regularization joint-training framework TIER-A, Aggregation Joint-training\nFramework with Temperature Calibration and Information Entropy Regularization.\nOur framework consists of several neural models with identical structures.\nThese models are jointly trained and we avoid overfitting by introducing\ntemperature and information entropy regularization. Extensive experiments on\ntwo widely-used but noisy datasets, TACRED and CoNLL03, demonstrate the\ncorrectness of our assumption and the effectiveness of our framework.",
    "descriptor": "",
    "authors": [
      "Yongkang Li",
      "Ming Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11527"
  },
  {
    "id": "arXiv:2211.11528",
    "title": "Machine Learning enabled models for YouTube Ranking Mechanism and Views  Prediction",
    "abstract": "With the continuous increase of internet usage in todays time, everyone is\ninfluenced by this source of the power of technology. Due to this, the rise of\napplications and games Is unstoppable. A major percentage of our population\nuses these applications for multiple purposes. These range from education,\ncommunication, news, entertainment, and many more. Out of this, the application\nthat is making sure that the world stays in touch with each other and with\ncurrent affairs is social media. Social media applications have seen a boom in\nthe last 10 years with the introduction of smartphones and the internet being\navailable at affordable prices. Applications like Twitch and Youtube are some\nof the best platforms for producing content and expressing their talent as\nwell. It is the goal of every content creator to post the best and most\nreliable content so that they can gain recognition. It is important to know the\nmethods of achieving popularity easily, which is what this paper proposes to\nbring to the spotlight. There should be certain parameters based on which the\nreach of content could be multiplied by a good factor. The proposed research\nwork aims to identify and estimate the reach, popularity, and views of a\nYouTube video by using certain features using machine learning and AI\ntechniques. A ranking system would also be used keeping the trending videos in\nconsideration. This would eventually help the content creator know how\nauthentic their content is and healthy competition to make better content\nbefore uploading the video on the platform will be ensured.",
    "descriptor": "\nComments: The Paper has been ACCEPTED at the \"2nd International Conference on Computing and Communication Networks(ICCCN-2022)\". This paper will be published by AIP publishing and DOI will be issued later on\n",
    "authors": [
      "Vandit Gupta",
      "Akshit Diwan",
      "Chaitanya Chadha",
      "Ashish Khanna",
      "Deepak Gupta"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11528"
  },
  {
    "id": "arXiv:2211.11530",
    "title": "Open-Set Object Detection Using Classification-free Object Proposal and  Instance-level Contrastive Learning with Appendix",
    "abstract": "Detecting both known and unknown objects is a fundamental skill for robot\nmanipulation in unstructured environments. Open-set object detection (OSOD) is\na promising direction to handle the problem consisting of two subtasks: objects\nand background separation, and open-set object classification. In this paper,\nwe present Openset RCNN to address the challenging OSOD. To disambiguate\nunknown objects and background in the first subtask, we propose to use\nclassification-free region proposal network (CF-RPN) which estimates the\nobjectness score of each region purely using cues from object's location and\nshape preventing overfitting to the training categories. To identify unknown\nobjects in the second subtask, we propose to represent them using the\ncomplementary region of known categories in a latent space which is\naccomplished by a prototype learning network (PLN). PLN performs instance-level\ncontrastive learning to encode proposals to a latent space and builds a compact\nregion centering with a prototype for each known category. Further, we note\nthat the detection performance of unknown objects can not be unbiasedly\nevaluated on the situation that commonly used object detection datasets are not\nfully annotated. Thus, a new benchmark is introduced by reorganizing\nGraspNet-1billion, a robotic grasp pose detection dataset with complete\nannotation. Extensive experiments demonstrate the merits of our method. We\nfinally show that our Openset RCNN can endow the robot with an open-set\nperception ability to support robotic rearrangement tasks in cluttered\nenvironments. More details can be found in\nhttps://sites.google.com/view/openest-rcnn/",
    "descriptor": "\nComments: Submit to IEEE Robotics and Automation Letters\n",
    "authors": [
      "Zhongxiang Zhou",
      "Yifei Yang",
      "Yue Wang",
      "Rong Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.11530"
  },
  {
    "id": "arXiv:2211.11534",
    "title": "How Fraudster Detection Contributes to Robust Recommendation",
    "abstract": "The adversarial robustness of recommendation systems under node injection\nattacks has received considerable research attention. Recently, a robust\nrecommendation system GraphRfi was proposed, and it was shown that GraphRfi\ncould successfully mitigate the effects of injected fake users in the system.\nUnfortunately, we demonstrate that GraphRfi is still vulnerable to attacks due\nto the supervised nature of its fraudster detection component. Specifically, we\npropose a new attack metaC against GraphRfi, and further analyze why GraphRfi\nfails under such an attack. Based on the insights we obtained from the\nvulnerability analysis, we build a new robust recommendation system PDR by\nre-designing the fraudster detection component. Comprehensive experiments show\nthat our defense approach outperforms other benchmark methods under attacks.\nOverall, our research demonstrates an effective framework of integrating\nfraudster detection into recommendation to achieve adversarial robustness.",
    "descriptor": "\nComments: Submitted to AAAI'2023\n",
    "authors": [
      "Yuni Lai",
      "Kai Zhou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11534"
  },
  {
    "id": "arXiv:2211.11535",
    "title": "Preliminary Bias Results in Search Engines",
    "abstract": "This report aims to report my thesis progress so far. My work attempts to\nshow the differences in the perspectives of two search engines, Bing and Google\non several selected controversial topics. In this work, we try to make a\ndistinction on the viewpoints of Bing \\& Google by using sentiment as well as\nthe ranking of the document returned from these two search engines on the same\nqueries, these queries are related mainly to controversial topics. You can find\nthe methods we used with experimental results below.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2112.12802\n",
    "authors": [
      "Gizem Gezici"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.11535"
  },
  {
    "id": "arXiv:2211.11540",
    "title": "A Framework for Auditable Synthetic Data Generation",
    "abstract": "Synthetic data has gained significant momentum thanks to sophisticated\nmachine learning tools that enable the synthesis of high-dimensional datasets.\nHowever, many generation techniques do not give the data controller control\nover what statistical patterns are captured, leading to concerns over privacy\nprotection. While synthetic records are not linked to a particular real-world\nindividual, they can reveal information about users indirectly which may be\nunacceptable for data owners. There is thus a need to empirically verify the\nprivacy of synthetic data -- a particularly challenging task in\nhigh-dimensional data. In this paper we present a general framework for\nsynthetic data generation that gives data controllers full control over which\nstatistical properties the synthetic data ought to preserve, what exact\ninformation loss is acceptable, and how to quantify it. The benefits of the\napproach are that (1) one can generate synthetic data that results in high\nutility for a given task, while (2) empirically validating that only statistics\nconsidered safe by the data curator are used to generate the data. We thus show\nthe potential for synthetic data to be an effective means of releasing\nconfidential data safely, while retaining useful information for analysts.",
    "descriptor": "",
    "authors": [
      "Florimond Houssiau",
      "Samuel N. Cohen",
      "Lukasz Szpruch",
      "Owen Daniel",
      "Michaela G. Lawrence",
      "Robin Mitra",
      "Henry Wilde",
      "Callum Mole"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.11540"
  },
  {
    "id": "arXiv:2211.11542",
    "title": "Efficient Second-Order Plane Adjustment",
    "abstract": "Planes are generally used in 3D reconstruction for depth sensors, such as\nRGB-D cameras and LiDARs. This paper focuses on the problem of estimating the\noptimal planes and sensor poses to minimize the point-to-plane distance. The\nresulting least-squares problem is referred to as plane adjustment (PA) in the\nliterature, which is the counterpart of bundle adjustment (BA) in visual\nreconstruction. Iterative methods are adopted to solve these least-squares\nproblems. Typically, Newton's method is rarely used for a large-scale\nleast-squares problem, due to the high computational complexity of the Hessian\nmatrix. Instead, methods using an approximation of the Hessian matrix, such as\nthe Levenberg-Marquardt (LM) method, are generally adopted. This paper\nchallenges this ingrained idea. We adopt the Newton's method to efficiently\nsolve the PA problem. Specifically, given poses, the optimal planes have\nclose-form solutions. Thus we can eliminate planes from the cost function,\nwhich significantly reduces the number of variables. Furthermore, as the\noptimal planes are functions of poses, this method actually ensures that the\noptimal planes for the current estimated poses can be obtained at each\niteration, which benefits the convergence. The difficulty lies in how to\nefficiently compute the Hessian matrix and the gradient of the resulting cost.\nThis paper provides an efficient solution. Empirical evaluation shows that our\nalgorithm converges significantly faster than the widely used LM algorithm.",
    "descriptor": "",
    "authors": [
      "Lipu Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.11542"
  },
  {
    "id": "arXiv:2211.11544",
    "title": "Ain't No Stopping Us Monitoring Now",
    "abstract": "Not all properties are monitorable. This is a well-known fact, and it means\nthere exist properties that cannot be fully verified at runtime. However, given\na non-monitorable property, a monitor can still be synthesised, but it could\nend up in a state where no verdict will ever be concluded on the satisfaction\n(resp., violation) of the property. For this reason, non-monitorable properties\nare usually discarded. In this paper, we carry out an in-depth analysis on\nmonitorability, and how non-monitorable properties can still be partially\nverified. We present our theoretical results at a semantic level, without\nfocusing on a specific formalism. Then, we show how our theory can be applied\nto achieve partial runtime verification of Linear Temporal Logic (LTL).",
    "descriptor": "",
    "authors": [
      "Luca Ciccone",
      "Francesco Dagnino",
      "Angelo Ferrando"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.11544"
  },
  {
    "id": "arXiv:2211.11546",
    "title": "PartAL: Efficient Partial Active Learning in Multi-Task Visual Settings",
    "abstract": "Multi-task learning is central to many real-world applications.\nUnfortunately, obtaining labelled data for all tasks is time-consuming,\nchallenging, and expensive. Active Learning (AL) can be used to reduce this\nburden. Existing techniques typically involve picking images to be annotated\nand providing annotations for all tasks.\nIn this paper, we show that it is more effective to select not only the\nimages to be annotated but also a subset of tasks for which to provide\nannotations at each AL iteration. Furthermore, the annotations that are\nprovided can be used to guess pseudo-labels for the tasks that remain\nunannotated. We demonstrate the effectiveness of our approach on several\npopular multi-task datasets.",
    "descriptor": "",
    "authors": [
      "Nikita Durasov",
      "Nik Dorndorf",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11546"
  },
  {
    "id": "arXiv:2211.11548",
    "title": "Survey of Query-based Text Summarization",
    "abstract": "Query-based text summarization is an important real world problem that\nrequires to condense the prolix text data into a summary under the guidance of\nthe query information provided by users. The topic has been studied for a long\ntime and there are many existing interesting research related to query-based\ntext summarization. Yet much of the work is not systematically surveyed. This\nsurvey aims at summarizing some interesting work in query-based text\nsummarization methods as well as related generic text summarization methods.\nNot all taxonomies in this paper exist the related work to the best of our\nknowledge and some analysis will be presented.",
    "descriptor": "",
    "authors": [
      "Hang Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11548"
  },
  {
    "id": "arXiv:2211.11550",
    "title": "Refactoring = Substitution + Rewriting",
    "abstract": "We present an approach to describing refactorings that abstracts away from\nparticular refactorings to classes of similar transformations, and presents an\nimplementation of these that works by substitution and subsequent rewriting.\nSubstitution is language-independent under this approach, while the rewrites\nembody language-specific aspects. Intriguingly, it also goes back to work on\nAPI migration by Huiqing Li and the first author, and sets refactoring in that\ngeneral context.",
    "descriptor": "\nComments: 6pp\n",
    "authors": [
      "Simon Thompson",
      "D\u00e1niel Horp\u00e1csi"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.11550"
  },
  {
    "id": "arXiv:2211.11551",
    "title": "Evolutionary Strategies for the Design of Binary Linear Codes",
    "abstract": "The design of binary error-correcting codes is a challenging optimization\nproblem with several applications in telecommunications and storage, which has\nalso been addressed with metaheuristic techniques and evolutionary algorithms.\nStill, all these efforts focused on optimizing the minimum distance of\nunrestricted binary codes, i.e., with no constraints on their linearity, which\nis a desirable property for efficient implementations. In this paper, we\npresent an Evolutionary Strategy (ES) algorithm that explores only the subset\nof linear codes of a fixed length and dimension. To that end, we represent the\ncandidate solutions as binary matrices and devise variation operators that\npreserve their ranks. Our experiments show that up to length $n=14$, our ES\nalways converges to an optimal solution with a full success rate, and the\nevolved codes are all inequivalent to the Best-Known Linear Code (BKLC) given\nby MAGMA. On the other hand, for larger lengths, both the success rate of the\nES as well as the diversity of the evolved codes start to drop, with the\nextreme case of $(16,8,5)$ codes which all turn out to be equivalent to MAGMA's\nBKLC.",
    "descriptor": "\nComments: 15 pages, 3 figures, 3 tables\n",
    "authors": [
      "Claude Carlet",
      "Luca Mariot",
      "Luca Manzoni",
      "Stjepan Picek"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Cryptography and Security (cs.CR)",
      "Discrete Mathematics (cs.DM)",
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.11551"
  },
  {
    "id": "arXiv:2211.11554",
    "title": "Programming by Example and Text-to-Code Translation for Conversational  Code Generation",
    "abstract": "Dialogue systems is an increasingly popular task of natural language\nprocessing. However, the dialogue paths tend to be deterministic, restricted to\nthe system rails, regardless of the given request or input text. Recent\nadvances in program synthesis have led to systems which can synthesize programs\nfrom very general search spaces, e.g. Programming by Example, and to systems\nwith very accessible interfaces for writing programs, e.g. text-to-code\ntranslation, but have not achieved both of these qualities in the same system.\nWe propose Modular Programs for Text-guided Hierarchical Synthesis (MPaTHS), a\nmethod for integrating Programming by Example and text-to-code systems which\noffers an accessible natural language interface for synthesizing general\nprograms. We present a program representation that allows our method to be\napplied to the problem of task-oriented dialogue. Finally, we demo MPaTHS using\nour program representation.",
    "descriptor": "\nComments: 13 pages, 2 figures, conference preprint\n",
    "authors": [
      "Eli Whitehouse",
      "William Gerard",
      "Yauhen Klimovich",
      "Marc Franco-Salvador"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11554"
  },
  {
    "id": "arXiv:2211.11559",
    "title": "Visual Programming: Compositional visual reasoning without training",
    "abstract": "We present VISPROG, a neuro-symbolic approach to solving complex and\ncompositional visual tasks given natural language instructions. VISPROG avoids\nthe need for any task-specific training. Instead, it uses the in-context\nlearning ability of large language models to generate python-like modular\nprograms, which are then executed to get both the solution and a comprehensive\nand interpretable rationale. Each line of the generated program may invoke one\nof several off-the-shelf computer vision models, image processing routines, or\npython functions to produce intermediate outputs that may be consumed by\nsubsequent parts of the program. We demonstrate the flexibility of VISPROG on 4\ndiverse tasks - compositional visual question answering, zero-shot reasoning on\nimage pairs, factual knowledge object tagging, and language-guided image\nediting. We believe neuro-symbolic approaches like VISPROG are an exciting\navenue to easily and effectively expand the scope of AI systems to serve the\nlong tail of complex tasks that people may wish to perform.",
    "descriptor": "",
    "authors": [
      "Tanmay Gupta",
      "Aniruddha Kembhavi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11559"
  },
  {
    "id": "arXiv:2211.11561",
    "title": "Sharpness-Aware Training for Accurate Inference on Noisy DNN  Accelerators",
    "abstract": "Energy-efficient deep neural network (DNN) accelerators are prone to\nnon-idealities that degrade DNN performance at inference time. To mitigate such\ndegradation, existing methods typically add perturbations to the DNN weights\nduring training to simulate inference on noisy hardware. However, this often\nrequires knowledge about the target hardware and leads to a trade-off between\nDNN performance and robustness, decreasing the former to increase the latter.\nIn this work, we show that applying sharpness-aware training by optimizing for\nboth the loss value and the loss sharpness significantly improves robustness to\nnoisy hardware at inference time while also increasing DNN performance. We\nfurther motivate our results by showing a high correlation between loss\nsharpness and model robustness. We show superior performance compared to\ninjecting noise during training and aggressive weight clipping on multiple\narchitectures, optimizers, datasets, and training regimes without relying on\nany assumptions about the target hardware. This is observed on a generic noise\nmodel as well as on accurate noise simulations from real hardware.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Gon\u00e7alo Mordido",
      "Sarath Chandar",
      "Fran\u00e7ois Leduc-Primeau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11561"
  },
  {
    "id": "arXiv:2211.11562",
    "title": "Blockchain Technology: A tool to solve the challenges of education  sector in developing countries",
    "abstract": "The education system is getting diversified, challenged, and blended for the\noverwhelming advancement of disruptive technology. The core purpose of this\nchapter is to visualize the probable solutions of the modern education system\nusing blockchain technology. The entire chapter has been discussed on the basis\nof present solution and projection of future inventions to smoothen the\neducation system. The fourth industrial revolution (4IR) is changing our\nexperiences in terms of education and other lifestyle. Delivering lectures,\ninteracting between learners and educations, evaluating learning outcomes, and\nverifying educational credentials might be smoother, easier, faster, cheaper,\nand jollier than before. Blockchain technology can contribute to the education\nprovider to tackle all those existing problems to create a comfortable learning\nenvironment to all irrespective to their economic backgrounds and geographic\nlocation. How this technology can contribute to improve Reviewing recent\ninventions in this technology, the chapter explains some of the strategies to\ngo beyond the ongoing projects around the world. A set of models are arranged\nto enable the readers mind for future inventions in the realm of educationists.\nKeywords: -Blockchain, 4IR, educators, learning outcome.",
    "descriptor": "",
    "authors": [
      "Md Aminul Islam"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.11562"
  },
  {
    "id": "arXiv:2211.11565",
    "title": "IEEE Big Data Cup 2022: Privacy Preserving Matching of Encrypted Images  with Deep Learning",
    "abstract": "Smart sensors, devices and systems deployed in smart cities have brought\nimproved physical protections to their citizens. Enhanced crime prevention, and\nfire and life safety protection are achieved through these technologies that\nperform motion detection, threat and actors profiling, and real-time alerts.\nHowever, an important requirement in these increasingly prevalent deployments\nis the preservation of privacy and enforcement of protection of personal\nidentifiable information. Thus, strong encryption and anonymization techniques\nshould be applied to the collected data. In this IEEE Big Data Cup 2022\nchallenge, different masking, encoding and homomorphic encryption techniques\nwere applied to the images to protect the privacy of their contents.\nParticipants are required to develop detection solutions to perform privacy\npreserving matching of these images. In this paper, we describe our solution\nwhich is based on state-of-the-art deep convolutional neural networks and\nvarious data augmentation techniques. Our solution achieved 1st place at the\nIEEE Big Data Cup 2022: Privacy Preserving Matching of Encrypted Images\nChallenge.",
    "descriptor": "\nComments: Keywords: privacy preservation, privacy enhancing, masking, encoding, homomorphic encryption, deep learning, convolutional neural networks\n",
    "authors": [
      "Vrizlynn L. L. Thing"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.11565"
  },
  {
    "id": "arXiv:2211.11568",
    "title": "Age of Information in a SWIPT and URLLC enabled Wireless Communications  System",
    "abstract": "This paper estimates the freshness of the information in a wireless relay\ncommunication system that employs simultaneous wireless information and power\ntransfer (SWIPT) operating under ultra-reliable low-latency communication\n(URLLC) constraints. The Age of Information (AoI) metric calculates the time\ndifference between the current time and the timestamp of the most recent update\nreceived by the receiver is used here to estimate the freshness of information.\nThe short packet communication scheme is used to fulfil the reliability and\nlatency requirements of the proposed wireless network and its performance is\nanalysed using finite block length theory. In addition, by utilising novel\napproximation approaches, expressions for the average AoI (AAoI) of the\nproposed system are derived. Finally, numerical analysis is used to evaluate\nand validate derived results.",
    "descriptor": "",
    "authors": [
      "Chathuranga M. Wijerathna Basnayaka",
      "Dushantha Nalin K. Jayakody",
      "Tharindu D. Ponnimbaduge Perera",
      "M\u00e1rio Marques da Silva"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.11568"
  },
  {
    "id": "arXiv:2211.11570",
    "title": "2CET-GAN: Pixel-Level GAN Model for Human Facial Expression Transfer",
    "abstract": "Recent studies have used GAN to transfer expressions between human faces.\nHowever, existing models have many flaws: relying on emotion labels, lacking\ncontinuous expressions, and failing to capture the expression details. To\naddress these limitations, we propose a novel CycleGAN- and InfoGAN-based\nnetwork called 2 Cycles Expression Transfer GAN (2CET-GAN), which can learn\ncontinuous expression transfer without using emotion labels. The experiment\nshows our network can generate diverse and high-quality expressions and can\ngeneralize to unknown identities. To the best of our knowledge, we are among\nthe first to successfully use an unsupervised approach to disentangle\nexpression representation from identities at the pixel level.",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Xiaohang Hu",
      "Nuha Aldausari",
      "Gelareh Mohammadi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11570"
  },
  {
    "id": "arXiv:2211.11571",
    "title": "SLLEN: Semantic-aware Low-light Image Enhancement Network",
    "abstract": "How to effectively explore semantic feature is vital for low-light image\nenhancement (LLE). Existing methods usually utilize the semantic feature that\nis only drawn from the semantic map produced by high-level semantic\nsegmentation network (SSN). However, if the semantic map is not accurately\nestimated, it would affect the high-level semantic feature (HSF) extraction,\nwhich accordingly interferes with LLE. In this paper, we develop a simple yet\neffective two-branch semantic-aware LLE network (SLLEN) that neatly integrates\nthe random intermediate embedding feature (IEF) (i.e., the information\nextracted from the intermediate layer of semantic segmentation network)\ntogether with the HSF into a unified framework for better LLE. Specifically,\nfor one branch, we utilize an attention mechanism to integrate HSF into\nlow-level feature. For the other branch, we extract IEF to guide the adjustment\nof low-level feature using nonlinear transformation manner. Finally,\nsemantic-aware features obtained from two branches are fused and decoded for\nimage enhancement. It is worth mentioning that IEF has some randomness compared\nto HSF despite their similarity on semantic characteristics, thus its\nintroduction can allow network to learn more possibilities by leveraging the\nlatent relationships between the low-level feature and semantic feature, just\nlike the famous saying \"God rolls the dice\" in Physics Nobel Prize 2022.\nComparisons between the proposed SLLEN and other state-of-the-art techniques\ndemonstrate the superiority of SLLEN with respect to LLE quality over all the\ncomparable alternatives.",
    "descriptor": "",
    "authors": [
      "Mingye Ju",
      "Charles A. Guo",
      "Chuheng Chen",
      "Jinshan Pan",
      "Jinhui Tang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11571"
  },
  {
    "id": "arXiv:2211.11572",
    "title": "Detect Only What You Specify : Object Detection with Linguistic Target",
    "abstract": "Object detection is a computer vision task of predicting a set of bounding\nboxes and category labels for each object of interest in a given image. The\ncategory is related to a linguistic symbol such as 'dog' or 'person' and there\nshould be relationships among them. However the object detector only learns to\nclassify the categories and does not treat them as the linguistic symbols.\nMulti-modal models often use the pre-trained object detector to extract object\nfeatures from the image, but the models are separated from the detector and the\nextracted visual features does not change with their linguistic input. We\nrethink the object detection as a vision-and-language reasoning task. We then\npropose targeted detection task, where detection targets are given by a natural\nlanguage and the goal of the task is to detect only all the target objects in a\ngiven image. There are no detection if the target is not given. Commonly used\nmodern object detectors have many hand-designed components like anchor and it\nis difficult to fuse the textual inputs into the complex pipeline. We thus\npropose Language-Targeted Detector (LTD) for the targeted detection based on a\nrecently proposed Transformer-based detector. LTD is a encoder-decoder\narchitecture and our conditional decoder allows the model to reason about the\nencoded image with the textual input as the linguistic context. We evaluate\ndetection performances of LTD on COCO object detection dataset and also show\nthat our model improves the detection results with the textual input grounding\nto the visual object.",
    "descriptor": "",
    "authors": [
      "Moyuru Yamada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11572"
  },
  {
    "id": "arXiv:2211.11573",
    "title": "Higher-Order, Data-Parallel Structured Deduction",
    "abstract": "State-of-the-art Datalog engines include expressive features such as ADTs\n(structured heap values), stratified aggregation and negation, various\nprimitive operations, and the opportunity for further extension using FFIs.\nCurrent parallelization approaches for state-of-art Datalogs target\nshared-memory locking data-structures using conventional multi-threading, or\nuse the map-reduce model for distributed computing. Furthermore, current\nstate-of-art approaches cannot scale to formal systems which pervasively\nmanipulate structured data due to their lack of indexing for structured data\nstored in the heap.\nIn this paper, we describe a new approach to data-parallel structured\ndeduction that involves a key semantic extension of Datalog to permit\nfirst-class facts and higher-order relations via defunctionalization, an\nimplementation approach that enables parallelism uniformly both across sets of\ndisjoint facts and over individual facts with nested structure. We detail a\ncore language, $DL_s$, whose key invariant (subfact closure) ensures that each\nsubfact is materialized as a top-class fact. We extend $DL_s$ to Slog, a\nfully-featured language whose forms facilitate leveraging subfact closure to\nrapidly implement expressive, high-performance formal systems. We demonstrate\nSlog by building a family of control-flow analyses from abstract machines,\nsystematically, along with several implementations of classical type systems\n(such as STLC and LF). We performed experiments on EC2, Azure, and ALCF's Theta\nat up to 1000 threads, showing orders-of-magnitude scalability improvements\nversus competing state-of-art systems.",
    "descriptor": "",
    "authors": [
      "Thomas Gilray",
      "Arash Sahebolamri",
      "Sidharth Kumar",
      "Kristopher Micinski"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.11573"
  },
  {
    "id": "arXiv:2211.11576",
    "title": "Imputation of Missing Streamflow Data at Multiple Gauging Stations in  Benin Republic",
    "abstract": "Streamflow observation data is vital for flood monitoring, agricultural, and\nsettlement planning. However, such streamflow data are commonly plagued with\nmissing observations due to various causes such as harsh environmental\nconditions and constrained operational resources. This problem is often more\npervasive in under-resourced areas such as Sub-Saharan Africa. In this work, we\nreconstruct streamflow time series data through bias correction of the GEOGloWS\nECMWF streamflow service (GESS) forecasts at ten river gauging stations in\nBenin Republic. We perform bias correction by fitting Quantile Mapping,\nGaussian Process, and Elastic Net regression in a constrained training period.\nWe show by simulating missingness in a testing period that GESS forecasts have\na significant bias that results in low predictive skill over the ten Beninese\nstations. Our findings suggest that overall bias correction by Elastic Net and\nGaussian Process regression achieves superior skill relative to traditional\nimputation by Random Forest, k-Nearest Neighbour, and GESS lookup. The findings\nof this work provide a basis for integrating global GESS streamflow data into\noperational early-warning decision-making systems (e.g., flood alert) in\ncountries vulnerable to drought and flooding due to extreme weather events.",
    "descriptor": "\nComments: AAAI 2022 Fall Symposium: The Role of AI in Responding to Climate Challenges, Nov 17-19, 2022\n",
    "authors": [
      "Rendani Mbuvha",
      "Julien Yise Peniel Adounkpe",
      "Wilson Tsakane Mongwe",
      "Mandela Houngnibo",
      "Nathaniel Newlands",
      "Tshilidzi Marwala"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.11576"
  },
  {
    "id": "arXiv:2211.11577",
    "title": "Data Privacy in Multi-Cloud: An Enhanced Data Fragmentation Framework",
    "abstract": "Data splitting preserves privacy by partitioning data into various fragments\nto be stored remotely and shared. It supports most data operations because data\ncan be stored in clear as opposed to methods that rely on cryptography.\nHowever, majority of existing data splitting techniques do not consider data\nalready in the multi-cloud. This leads to unnecessary use of resources to\nre-split data into fragments. This work proposes a data splitting framework\nthat leverages on existing data in the multi-cloud. It improves data splitting\nmechanisms by reducing the number of splitting operations and resulting\nfragments. Therefore, decreasing the number of storage locations a data owner\nmanages. Broadcasts queries locate third-party data fragments to avoid costly\noperations when splitting data. This work examines considerations for the use\nof third-party fragments and application to existing data splitting techniques.\nThe proposed framework was also applied to an existing data splitting mechanism\nto complement its capabilities.",
    "descriptor": "\nComments: Keywords: Data Storage, Multi-Cloud, Cloud Security, Privacy Preservation, Privacy Enhancing, Data Splitting; this https URL\n",
    "authors": [
      "Randolph Loh",
      "Vrizlynn L. L. Thing"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.11577"
  },
  {
    "id": "arXiv:2211.11579",
    "title": "Dynamic Conditional Imitation Learning for Autonomous Driving",
    "abstract": "Conditional imitation learning (CIL) trains deep neural networks, in an\nend-to-end manner, to mimic human driving. This approach has demonstrated\nsuitable vehicle control when following roads, avoiding obstacles, or taking\nspecific turns at intersections to reach a destination. Unfortunately,\nperformance dramatically decreases when deployed to unseen environments and is\ninconsistent against varying weather conditions. Most importantly, the current\nCIL fails to avoid static road blockages. In this work, we propose a solution\nto those deficiencies. First, we fuse the laser scanner with the regular camera\nstreams, at the features level, to overcome the generalization and consistency\nchallenges. Second, we introduce a new efficient Occupancy Grid Mapping (OGM)\nmethod along with new algorithms for road blockages avoidance and global route\nplanning. Consequently, our proposed method dynamically detects partial and\nfull road blockages, and guides the controlled vehicle to another route to\nreach the destination. Following the original CIL work, we demonstrated the\neffectiveness of our proposal on CARLA simulator urban driving benchmark. Our\nexperiments showed that our model improved consistency against weather\nconditions by four times and autonomous driving success rate generalization by\n52%. Furthermore, our global route planner improved the driving success rate by\n37%. Our proposed road blockages avoidance algorithm improved the driving\nsuccess rate by 27%. Finally, the average kilometers traveled before a\ncollision with a static object increased by 1.5 times. The main source code can\nbe reached at https://heshameraqi.github.io/dynamic_cil_autonomous_driving.",
    "descriptor": "\nComments: 14 pages, 11 figures, 7 tables\n",
    "authors": [
      "Hesham M. Eraqi",
      "Mohamed N. Moustafa",
      "Jens Honer"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11579"
  },
  {
    "id": "arXiv:2211.11581",
    "title": "Quantifying Electricity Demand for 100% Electrified Transportation in  New York City",
    "abstract": "Envisioning a future 100% electrified transportation sector, this paper\nproposes a model framework that uses socio-economic, demographic, and\ngeographic data to estimate electric energy demand from commuter traffic.\nAdditionally, we explore the possible mode choices of each individual, which\nallows to create mode-mix scenarios for the entire population. We quantify the\nelectric energy demand for each scenario using technical specifications of\nstate-of-the-art battery and electric drives technology in combination with\ndifferent charging scenarios. Using data sets for New York City, our results\nhighlight the need for infrastructure investments, the usefulness of flexible\ncharging policies and the positive impact of incentivizing micromobility and\nmass-transit options. Our model and results are publicly available as\ninteractive Dashboard under tecnyc.herokuapp.com.",
    "descriptor": "",
    "authors": [
      "Jingrong Zhang",
      "Amber Jiang",
      "Brian Newborn",
      "Sara Kou",
      "Robert Mieth"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.11581"
  },
  {
    "id": "arXiv:2211.11583",
    "title": "Recommending Related Products Using Graph Neural Networks in Directed  Graphs",
    "abstract": "Related product recommendation (RPR) is pivotal to the success of any\ne-commerce service. In this paper, we deal with the problem of recommending\nrelated products i.e., given a query product, we would like to suggest top-k\nproducts that have high likelihood to be bought together with it. Our problem\nimplicitly assumes asymmetry i.e., for a phone, we would like to recommend a\nsuitable phone case, but for a phone case, it may not be apt to recommend a\nphone because customers typically would purchase a phone case only while owning\na phone. We also do not limit ourselves to complementary or substitute product\nrecommendation. For example, for a specific night wear t-shirt, we can suggest\nsimilar t-shirts as well as track pants. So, the notion of relatedness is\nsubjective to the query product and dependent on customer preferences. Further,\nvarious factors such as product price, availability lead to presence of\nselection bias in the historical purchase data, that needs to be controlled for\nwhile training related product recommendations model. These challenges are\northogonal to each other deeming our problem nontrivial. To address these, we\npropose DAEMON, a novel Graph Neural Network (GNN) based framework for related\nproduct recommendation, wherein the problem is formulated as a node\nrecommendation task on a directed product graph. In order to capture product\nasymmetry, we employ an asymmetric loss function and learn dual embeddings for\neach product, by appropriately aggregating features from its neighborhood.\nDAEMON leverages multi-modal data sources such as catalog metadata, browse\nbehavioral logs to mitigate selection bias and generate recommendations for\ncold-start products. Extensive offline experiments show that DAEMON outperforms\nstate-of-the-art baselines by 30-160% in terms of HitRate and MRR for the node\nrecommendation task.",
    "descriptor": "\nComments: This work was accepted in ECML PKDD 2022\n",
    "authors": [
      "Srinivas Virinchi",
      "Anoop Saladi",
      "Abhirup Mondal"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11583"
  },
  {
    "id": "arXiv:2211.11584",
    "title": "Dialogs Re-enacted Across Languages",
    "abstract": "To support machine learning of cross-language prosodic mappings and other\nways to improve speech-to-speech translation, we present a protocol for\ncollecting closely matched pairs of utterances across languages, a description\nof the resulting data collection, and some observations and musings. This\nreport is intended for 1) people using the corpus, 2) people extending the\ncorpus, and 3) people designing similar collections of bilingual dialog data.",
    "descriptor": "",
    "authors": [
      "Nigel G. Ward",
      "Jonathan E. Avila",
      "Emilia Rivas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.11584"
  },
  {
    "id": "arXiv:2211.11586",
    "title": "Random-LTD: Random and Layerwise Token Dropping Brings Efficient  Training for Large-scale Transformers",
    "abstract": "Large-scale transformer models have become the de-facto architectures for\nvarious machine learning applications, e.g., CV and NLP. However, those large\nmodels also introduce prohibitive training costs. To mitigate this issue, we\npropose a novel random and layerwise token dropping method (random-LTD), which\nskips the computation of a subset of the input tokens at all middle layers.\nParticularly, random-LTD achieves considerable speedups and comparable accuracy\nas the standard training baseline. Compared to other token dropping methods,\nrandom-LTD does not require (1) any importance score-based metrics, (2) any\nspecial token treatment (e.g., [CLS]), and (3) many layers in full sequence\nlength training except the first and the last layers. Besides, a new LayerToken\nlearning rate schedule is proposed for pretraining problems that resolve the\nheavy tuning requirement for our proposed training mechanism. Finally, we\ndemonstrate that random-LTD can be applied to broader applications, including\nGPT and BERT pretraining as well as ViT and GPT finetuning tasks. Our results\nshow that random-LTD can save about 33.3% theoretical compute cost and 25.6%\nwall-clock training time while achieving similar zero-shot evaluations on\nGPT-31.3B as compared to baseline.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Zhewei Yao",
      "Xiaoxia Wu",
      "Conglong Li",
      "Connor Holmes",
      "Minjia Zhang",
      "Cheng Li",
      "Yuxiong He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11586"
  },
  {
    "id": "arXiv:2211.11587",
    "title": "Timely Target Tracking in Cognitive Radar Networks",
    "abstract": "We consider a scenario where a fusion center must decide which updates to\nreceive during each update period in a communication-limited cognitive radar\nnetwork. When each radar node in the network only is able to obtain noisy state\nmeasurements for a subset of the targets, the fusion center may not receive\nupdates on every target during each update period. The solution for the\nselection problem at the fusion center is not well suited for sequential\nlearning frameworks. We derive an Age of Information-inspired track sensitive\nmetric to inform node selection in such a network and compare it against\nless-informed techniques.",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "William W. Howard",
      "Charles E. Thornton",
      "R. Michael Buehrer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.11587"
  },
  {
    "id": "arXiv:2211.11589",
    "title": "Conjugate Product Graphs for Globally Optimal 2D-3D Shape Matching",
    "abstract": "We consider the problem of finding a continuous and non-rigid matching\nbetween a 2D contour and a 3D mesh. While such problems can be solved to global\noptimality by finding a shortest path in the product graph between both shapes,\nexisting solutions heavily rely on unrealistic prior assumptions to avoid\ndegenerate solutions (e.g. knowledge to which region of the 3D shape each point\nof the 2D contour is matched). To address this, we propose a novel 2D-3D shape\nmatching formalism based on the conjugate product graph between the 2D contour\nand the 3D shape. Doing so allows us for the first time to consider\nhigher-order costs, i.e. defined for edge chains, as opposed to costs defined\nfor single edges. This offers substantially more flexibility, which we utilise\nto incorporate a local rigidity prior. By doing so, we effectively circumvent\ndegenerate solutions and thereby obtain smoother and more realistic matchings,\neven when using only a one-dimensional feature descriptor. Overall, our method\nfinds globally optimal and continuous 2D-3D matchings, has the same asymptotic\ncomplexity as previous solutions, produces state-of-the-art results for shape\nmatching and is even capable of matching partial shapes.",
    "descriptor": "",
    "authors": [
      "Paul Roetzer",
      "Zorah L\u00e4hner",
      "Florian Bernard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11589"
  },
  {
    "id": "arXiv:2211.11591",
    "title": "DPD-fVAE: Synthetic Data Generation Using Federated Variational  Autoencoders With Differentially-Private Decoder",
    "abstract": "Federated learning (FL) is getting increased attention for processing\nsensitive, distributed datasets common to domains such as healthcare. Instead\nof directly training classification models on these datasets, recent works have\nconsidered training data generators capable of synthesising a new dataset which\nis not protected by any privacy restrictions. Thus, the synthetic data can be\nmade available to anyone, which enables further evaluation of machine learning\narchitectures and research questions off-site. As an additional layer of\nprivacy-preservation, differential privacy can be introduced into the training\nprocess. We propose DPD-fVAE, a federated Variational Autoencoder with\nDifferentially-Private Decoder, to synthesise a new, labelled dataset for\nsubsequent machine learning tasks. By synchronising only the decoder component\nwith FL, we can reduce the privacy cost per epoch and thus enable better data\ngenerators. In our evaluation on MNIST, Fashion-MNIST and CelebA, we show the\nbenefits of DPD-fVAE and report competitive performance to related work in\nterms of Fr\\'echet Inception Distance and accuracy of classifiers trained on\nthe synthesised dataset.",
    "descriptor": "",
    "authors": [
      "Bjarne Pfitzner",
      "Bert Arnrich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11591"
  },
  {
    "id": "arXiv:2211.11592",
    "title": "Guided Depth Super-Resolution by Deep Anisotropic Diffusion",
    "abstract": "Performing super-resolution of a depth image using the guidance from an RGB\nimage is a problem that concerns several fields, such as robotics, medical\nimaging, and remote sensing. While deep learning methods have achieved good\nresults in this problem, recent work highlighted the value of combining modern\nmethods with more formal frameworks. In this work, we propose a novel approach\nwhich combines guided anisotropic diffusion with a deep convolutional network\nand advances the state of the art for guided depth super-resolution. The edge\ntransferring/enhancing properties of the diffusion are boosted by the\ncontextual reasoning capabilities of modern networks, and a strict adjustment\nstep guarantees perfect adherence to the source image. We achieve unprecedented\nresults in three commonly used benchmarks for guided depth super-resolution.\nThe performance gain compared to other methods is the largest at larger scales,\nsuch as x32 scaling. Code for the proposed method will be made available to\npromote reproducibility of our results.",
    "descriptor": "",
    "authors": [
      "Nando Metzger",
      "Rodrigo Caye Daudt",
      "Konrad Schindler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11592"
  },
  {
    "id": "arXiv:2211.11593",
    "title": "Investigating methods to improve photovoltaic thermal models at  second-to-minute timescales",
    "abstract": "This paper presents a range of methods to improve the accuracy of\nequation-based thermal models of PV modules at second-to-minute timescales. We\npresent an RC-equivalent conceptual model for PV modules, where wind effects\nare captured. We show how the thermal time constant $\\tau$ of PV modules can be\ndetermined from measured data, and subsequently used to make static thermal\nmodels dynamic by applying the Exponential Weighted Mean (EWM) approach to\nirradiance and wind signals. On average, $\\tau$ is $6.3 \\pm 1~$min for\nfixed-mount PV systems. Based on this conceptual model, the Filter- EWM - Mean\nBias Error correction (FEM) methodology is developed. We propose two thermal\nmodels, WM1 and WM2, and compare these against the models of Ross, Sandia, and\nFaiman on twenty-four datasets of fifteen sites, with time resolutions ranging\nfrom 1$~$s to 1$~$h, the majority of these at 1$~$min resolution. The FEM\nmethodology is shown to reduce model errors (RMSE and MAE) on average for all\nsites and models versus the standard steady-state equivalent by -1.1$~$K and\n-0.75$~$K respectively.",
    "descriptor": "\nComments: 24 pages, 11 figures, 8 tables\n",
    "authors": [
      "Bert Herteleer",
      "Anastasios Kladas",
      "Gofran Chowdhury",
      "Francky Catthoor",
      "Jan Cappelle"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.11593"
  },
  {
    "id": "arXiv:2211.11595",
    "title": "Sydr-Fuzz: Continuous Hybrid Fuzzing and Dynamic Analysis for Security  Development Lifecycle",
    "abstract": "Nowadays automated dynamic analysis frameworks for continuous testing are in\nhigh demand to ensure software safety and satisfy the security development\nlifecycle~(SDL) requirements. The security bug hunting efficiency of\ncutting-edge hybrid fuzzing techniques outperforms widely utilized\ncoverage-guided fuzzing. We propose an enhanced dynamic analysis pipeline to\nleverage productivity of automated bug detection based on hybrid fuzzing. We\nimplement the proposed pipeline in the continuous fuzzing toolset Sydr-Fuzz\nwhich is powered by hybrid fuzzing orchestrator, integrating our DSE tool Sydr\nwith libFuzzer and AFL++. Sydr-Fuzz also incorporates security predicate\ncheckers, crash triaging tool Casr, and utilities for corpus minimization and\ncoverage gathering. The benchmarking of our hybrid fuzzer against alternative\nstate-of-the-art solutions demonstrates its superiority over coverage-guided\nfuzzers while remaining on the same level with advanced hybrid fuzzers.\nFurthermore, we approve the relevance of our approach by discovering 85 new\nreal-world software flaws within the OSS-Sydr-Fuzz project. Finally, we open\nCasr source code to the community to facilitate examination of the existing\ncrashes.",
    "descriptor": "",
    "authors": [
      "Alexey Vishnyakov",
      "Daniil Kuts",
      "Vlada Logunova",
      "Darya Parygina",
      "Eli Kobrin",
      "Georgy Savidov",
      "Andrey Fedotov"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.11595"
  },
  {
    "id": "arXiv:2211.11596",
    "title": "Forecasting Unobserved Node States with spatio-temporal Graph Neural  Networks",
    "abstract": "Forecasting future states of sensors is key to solving tasks like weather\nprediction, route planning, and many others when dealing with networks of\nsensors. But complete spatial coverage of sensors is generally unavailable and\nwould practically be infeasible due to limitations in budget and other\nresources during deployment and maintenance. Currently existing approaches\nusing machine learning are limited to the spatial locations where data was\nobserved, causing limitations to downstream tasks. Inspired by the recent surge\nof Graph Neural Networks for spatio-temporal data processing, we investigate\nwhether these can also forecast the state of locations with no sensors\navailable. For this purpose, we develop a framework, named Forecasting\nUnobserved Node States (FUNS), that allows forecasting the state at entirely\nunobserved locations based on spatio-temporal correlations and the graph\ninductive bias. FUNS serves as a blueprint for optimizing models only on\nobserved data and demonstrates good generalization capabilities for predicting\nthe state at entirely unobserved locations during the testing stage. Our\nframework can be combined with any spatio-temporal Graph Neural Network, that\nexploits spatio-temporal correlations with surrounding observed locations by\nusing the network's graph structure. Our employed model builds on a previous\nmodel by also allowing us to exploit prior knowledge about locations of\ninterest, e.g. the road type. Our empirical evaluation of both simulated and\nreal-world datasets demonstrates that Graph Neural Networks are well-suited for\nthis task.",
    "descriptor": "",
    "authors": [
      "Andreas Roth",
      "Thomas Liebig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11596"
  },
  {
    "id": "arXiv:2211.11602",
    "title": "Improving Multimodal Interactive Agents with Reinforcement Learning from  Human Feedback",
    "abstract": "An important goal in artificial intelligence is to create agents that can\nboth interact naturally with humans and learn from their feedback. Here we\ndemonstrate how to use reinforcement learning from human feedback (RLHF) to\nimprove upon simulated, embodied agents trained to a base level of competency\nwith imitation learning. First, we collected data of humans interacting with\nagents in a simulated 3D world. We then asked annotators to record moments\nwhere they believed that agents either progressed toward or regressed from\ntheir human-instructed goal. Using this annotation data we leveraged a novel\nmethod - which we call \"Inter-temporal Bradley-Terry\" (IBT) modelling - to\nbuild a reward model that captures human judgments. Agents trained to optimise\nrewards delivered from IBT reward models improved with respect to all of our\nmetrics, including subsequent human judgment during live interactions with\nagents. Altogether our results demonstrate how one can successfully leverage\nhuman judgments to improve agent behaviour, allowing us to use reinforcement\nlearning in complex, embodied domains without programmatic reward functions.\nVideos of agent behaviour may be found at https://youtu.be/v_Z9F2_eKk4.",
    "descriptor": "",
    "authors": [
      "Josh Abramson",
      "Arun Ahuja",
      "Federico Carnevale",
      "Petko Georgiev",
      "Alex Goldin",
      "Alden Hung",
      "Jessica Landon",
      "Jirka Lhotka",
      "Timothy Lillicrap",
      "Alistair Muldal",
      "George Powell",
      "Adam Santoro",
      "Guy Scully",
      "Sanjana Srivastava",
      "Tamara von Glehn",
      "Greg Wayne",
      "Nathaniel Wong",
      "Chen Yan",
      "Rui Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.11602"
  },
  {
    "id": "arXiv:2211.11603",
    "title": "Model-based Trajectory Stitching for Improved Offline Reinforcement  Learning",
    "abstract": "In many real-world applications, collecting large and high-quality datasets\nmay be too costly or impractical. Offline reinforcement learning (RL) aims to\ninfer an optimal decision-making policy from a fixed set of data. Getting the\nmost information from historical data is then vital for good performance once\nthe policy is deployed. We propose a model-based data augmentation strategy,\nTrajectory Stitching (TS), to improve the quality of sub-optimal historical\ntrajectories. TS introduces unseen actions joining previously disconnected\nstates: using a probabilistic notion of state reachability, it effectively\n`stitches' together parts of the historical demonstrations to generate new,\nhigher quality ones. A stitching event consists of a transition between a pair\nof observed states through a synthetic and highly probable action. New actions\nare introduced only when they are expected to be beneficial, according to an\nestimated state-value function. We show that using this data augmentation\nstrategy jointly with behavioural cloning (BC) leads to improvements over the\nbehaviour-cloned policy from the original dataset. Improving over the BC policy\ncould then be used as a launchpad for online RL through planning and\ndemonstration-guided RL.",
    "descriptor": "\nComments: Offline RL Workshop at Neural Information Processing Systems, 2022\n",
    "authors": [
      "Charles A. Hepburn",
      "Giovanni Montana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.11603"
  },
  {
    "id": "arXiv:2211.11607",
    "title": "Semantic Segmentation for Fully Automated Macrofouling Analysis on  Coatings after Field Exposure",
    "abstract": "Biofouling is a major challenge for sustainable shipping, filter membranes,\nheat exchangers, and medical devices. The development of fouling-resistant\ncoatings requires the evaluation of their effectiveness. Such an evaluation is\nusually based on the assessment of fouling progression after different exposure\ntimes to the target medium (e.g., salt water). The manual assessment of\nmacrofouling requires expert knowledge about local fouling communities due to\nhigh variances in phenotypical appearance, has single-image sampling\ninaccuracies for certain species, and lacks spatial information. Here we\npresent an approach for automatic image-based macrofouling analysis. We created\na dataset with dense labels prepared from field panel images and propose a\nconvolutional network (adapted U-Net) for the semantic segmentation of\ndifferent macrofouling classes. The establishment of macrofouling localization\nallows for the generation of a successional model which enables the\ndetermination of direct surface attachment and in-depth epibiotic studies.",
    "descriptor": "\nComments: 33 pages, 10 figures\n",
    "authors": [
      "Lutz M. K. Krause",
      "Emily Manderfeld",
      "Patricia Gnutt",
      "Louisa Vogler",
      "Ann Wassick",
      "Kailey Richard",
      "Marco Rudolph",
      "Kelli Z. Hunsucker",
      "Geoffrey W. Swain",
      "Bodo Rosenhahn",
      "Axel Rosenhahn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11607"
  },
  {
    "id": "arXiv:2211.11608",
    "title": "Immersion and Invariance-based Coding for Privacy in Remote Anomaly  Detection",
    "abstract": "We present a framework for the design of coding mechanisms that allow\nremotely operating anomaly detectors in a privacy-preserving manner. We\nconsider the following problem setup. A remote station seeks to identify\nanomalies based on system input-output signals transmitted over communication\nnetworks. However, it is not desired to disclose true data of the system\noperation as it can be used to infer private information. To prevent\nadversaries from eavesdropping on the network or at the remote station itself\nto access private data, we propose a privacy-preserving coding scheme to\ndistort signals before transmission. As a next step, we design a new anomaly\ndetector that runs on distorted signals and produces distorted diagnostics\nsignals, and a decoding scheme that allows extracting true diagnostics data\nfrom distorted signals without error. The proposed scheme is built on the\nsynergy of matrix encryption and system Immersion and Invariance (I&I) tools\nfrom control theory. The idea is to immerse the anomaly detector into a\nhigher-dimensional system (the so-called target system). The dynamics of the\ntarget system is designed such that: the trajectories of the original anomaly\ndetector are immersed/embedded in its trajectories, it works on randomly\nencoded input-output signals, and produces an encoded version of the original\nanomaly detector alarm signals, which are decoded to extract the original alarm\nat the user side. We show that the proposed privacy-preserving scheme provides\nthe same anomaly detection performance as standard Kalman filter-based\nchi-squared anomaly detectors while revealing no information about system data.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2211.03698\n",
    "authors": [
      "Haleh Hayati",
      "Nathan van de Wouw",
      "Carlos Murguia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.11608"
  },
  {
    "id": "arXiv:2211.11609",
    "title": "Deformable Voxel Grids for Shape Comparisons",
    "abstract": "We present Deformable Voxel Grids (DVGs) for 3D shapes comparison and\nprocessing. It consists of a voxel grid which is deformed to approximate the\nsilhouette of a shape, via energy-minimization. By interpreting the DVG as a\nlocal coordinates system, it provides a better embedding space than a regular\nvoxel grid, since it is adapted to the geometry of the shape. It also allows to\ndeform the shape by moving the control points of the DVG, in a similar manner\nto the Free Form Deformation, but with easier interpretability of the control\npoints positions. After proposing a computation scheme of the energies\ncompatible with meshes and pointclouds, we demonstrate the use of DVGs in a\nvariety of applications: correspondences via cubification, style transfer,\nshape retrieval and PCA deformations. The first two require no learning and can\nbe readily run on any shapes in a matter of minutes on modest hardware. As for\nthe last two, they require to first optimize DVGs on a collection of shapes,\nwhich amounts to a pre-processing step. Then, determining PCA coordinates is\nstraightforward and brings a few parameters to deform a shape.",
    "descriptor": "",
    "authors": [
      "Rapha\u00ebl Groscot",
      "Laurent D. Cohen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.11609"
  },
  {
    "id": "arXiv:2211.11610",
    "title": "Tensor4D : Efficient Neural 4D Decomposition for High-fidelity Dynamic  Reconstruction and Rendering",
    "abstract": "We present Tensor4D, an efficient yet effective approach to dynamic scene\nmodeling. The key of our solution is an efficient 4D tensor decomposition\nmethod so that the dynamic scene can be directly represented as a 4D\nspatio-temporal tensor. To tackle the accompanying memory issue, we decompose\nthe 4D tensor hierarchically by projecting it first into three time-aware\nvolumes and then nine compact feature planes. In this way, spatial information\nover time can be simultaneously captured in a compact and memory-efficient\nmanner. When applying Tensor4D for dynamic scene reconstruction and rendering,\nwe further factorize the 4D fields to different scales in the sense that\nstructural motions and dynamic detailed changes can be learned from coarse to\nfine. The effectiveness of our method is validated on both synthetic and\nreal-world scenes. Extensive experiments show that our method is able to\nachieve high-quality dynamic reconstruction and rendering from sparse-view\ncamera rigs or even a monocular camera. The code and dataset will be released\nat https://liuyebin.com/tensor4d/tensor4d.html.",
    "descriptor": "",
    "authors": [
      "Ruizhi Shao",
      "Zerong Zheng",
      "Hanzhang Tu",
      "Boning Liu",
      "Hongwen Zhang",
      "Yebin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11610"
  },
  {
    "id": "arXiv:2211.11612",
    "title": "Plug and Play Active Learning for Object Detection",
    "abstract": "Annotating data for supervised learning is expensive and tedious, and we want\nto do as little of it as possible. To make the most of a given \"annotation\nbudget\" we can turn to active learning (AL) which aims to identify the most\ninformative samples in a dataset for annotation. Active learning algorithms are\ntypically uncertainty-based or diversity-based. Both have seen success in image\nclassification, but fall short when it comes to object detection. We\nhypothesise that this is because: (1) it is difficult to quantify uncertainty\nfor object detection as it consists of both localisation and classification,\nwhere some classes are harder to localise, and others are harder to classify;\n(2) it is difficult to measure similarities for diversity-based AL when images\ncontain different numbers of objects. We propose a two-stage active learning\nalgorithm Plug and Play Active Learning (PPAL) that overcomes these\ndifficulties. It consists of (1) Difficulty Calibrated Uncertainty Sampling, in\nwhich we used a category-wise difficulty coefficient that takes both\nclassification and localisation into account to re-weight object uncertainties\nfor uncertainty-based sampling; (2) Category Conditioned Matching Similarity to\ncompute the similarities of multi-instance images as ensembles of their\ninstance similarities. PPAL is highly generalisable because it makes no change\nto model architectures or detector training pipelines. We benchmark PPAL on the\nMS-COCO and Pascal VOC datasets using different detector architectures and show\nthat our method outperforms the prior state-of-the-art. Code is available at\nhttps://github.com/ChenhongyiYang/PPAL",
    "descriptor": "",
    "authors": [
      "Chenhongyi Yang",
      "Lichao Huang",
      "Elliot J. Crowley"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11612"
  },
  {
    "id": "arXiv:2211.11616",
    "title": "Learning Heterogeneous Agent Cooperation via Multiagent League Training",
    "abstract": "Many multiagent systems in the real world include multiple types of agents\nwith different abilities and functionality. Such heterogeneous multiagent\nsystems have significant practical advantages. However, they also come with\nchallenges compared with homogeneous systems for multiagent reinforcement\nlearning, such as the non-stationary problem and the policy version iteration\nissue. This work proposes a general-purpose reinforcement learning algorithm\nnamed as Heterogeneous League Training (HLT) to address heterogeneous\nmultiagent problems. HLT keeps track of a pool of policies that agents have\nexplored during training, gathering a league of heterogeneous policies to\nfacilitate future policy optimization. Moreover, a hyper-network is introduced\nto increase the diversity of agent behaviors when collaborating with teammates\nhaving different levels of cooperation skills. We use heterogeneous benchmark\ntasks to demonstrate that (1) HLT promotes the success rate in cooperative\nheterogeneous tasks; (2) HLT is an effective approach to solving the policy\nversion iteration problem; (3) HLT provides a practical way to assess the\ndifficulty of learning each role in a heterogeneous team.",
    "descriptor": "",
    "authors": [
      "Qingxu Fu",
      "Xiaolin Ai",
      "Jianqiang Yi",
      "Tenghai Qiu",
      "Wanmai Yuan",
      "Zhiqiang Pu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11616"
  },
  {
    "id": "arXiv:2211.11617",
    "title": "CGoDial: A Large-Scale Benchmark for Chinese Goal-oriented Dialog  Evaluation",
    "abstract": "Practical dialog systems need to deal with various knowledge sources, noisy\nuser expressions, and the shortage of annotated data. To better solve the above\nproblems, we propose CGoDial, new challenging and comprehensive Chinese\nbenchmark for multi-domain Goal-oriented Dialog evaluation. It contains 96,763\ndialog sessions and 574,949 dialog turns totally, covering three datasets with\ndifferent knowledge sources: 1) a slot-based dialog (SBD) dataset with\ntable-formed knowledge, 2) a flow-based dialog (FBD) dataset with tree-formed\nknowledge, and a retrieval-based dialog (RBD) dataset with candidate-formed\nknowledge. To bridge the gap between academic benchmarks and spoken dialog\nscenarios, we either collect data from real conversations or add spoken\nfeatures to existing datasets via crowd-sourcing. The proposed experimental\nsettings include the combinations of training with either the entire training\nset or a few-shot training set, and testing with either the standard test set\nor a hard test subset, which can assess model capabilities in terms of general\nprediction, fast adaptability and reliable robustness.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Yinpei Dai",
      "Wanwei He",
      "Bowen Li",
      "Yuchuan Wu",
      "Zheng Cao",
      "Zhongqi An",
      "Jian Sun",
      "Yongbin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11617"
  },
  {
    "id": "arXiv:2211.11620",
    "title": "Simultaneously Updating All Persistence Values in Reinforcement Learning",
    "abstract": "In reinforcement learning, the performance of learning agents is highly\nsensitive to the choice of time discretization. Agents acting at high\nfrequencies have the best control opportunities, along with some drawbacks,\nsuch as possible inefficient exploration and vanishing of the action\nadvantages. The repetition of the actions, i.e., action persistence, comes into\nhelp, as it allows the agent to visit wider regions of the state space and\nimprove the estimation of the action effects. In this work, we derive a novel\nAll-Persistence Bellman Operator, which allows an effective use of both the\nlow-persistence experience, by decomposition into sub-transition, and the\nhigh-persistence experience, thanks to the introduction of a suitable bootstrap\nprocedure. In this way, we employ transitions collected at any time scale to\nupdate simultaneously the action values of the considered persistence set. We\nprove the contraction property of the All-Persistence Bellman Operator and,\nbased on it, we extend classic Q-learning and DQN. After providing a study on\nthe effects of persistence, we experimentally evaluate our approach in both\ntabular contexts and more challenging frameworks, including some Atari games.",
    "descriptor": "",
    "authors": [
      "Luca Sabbioni",
      "Luca Al Daire",
      "Lorenzo Bisi",
      "Alberto Maria Metelli",
      "Marcello Restelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11620"
  },
  {
    "id": "arXiv:2211.11623",
    "title": "Linear Stability Hypothesis and Rank Stratification for Nonlinear Models",
    "abstract": "Models with nonlinear architectures/parameterizations such as deep neural\nnetworks (DNNs) are well known for their mysteriously good generalization\nperformance at overparameterization. In this work, we tackle this mystery from\na novel perspective focusing on the transition of the target recovery/fitting\naccuracy as a function of the training data size. We propose a rank\nstratification for general nonlinear models to uncover a model rank as an\n\"effective size of parameters\" for each function in the function space of the\ncorresponding model. Moreover, we establish a linear stability theory proving\nthat a target function almost surely becomes linearly stable when the training\ndata size equals its model rank. Supported by our experiments, we propose a\nlinear stability hypothesis that linearly stable functions are preferred by\nnonlinear training. By these results, model rank of a target function predicts\na minimal training data size for its successful recovery. Specifically for the\nmatrix factorization model and DNNs of fully-connected or convolutional\narchitectures, our rank stratification shows that the model rank for specific\ntarget functions can be much lower than the size of model parameters. This\nresult predicts the target recovery capability even at heavy\noverparameterization for these nonlinear models as demonstrated quantitatively\nby our experiments. Overall, our work provides a unified framework with\nquantitative prediction power to understand the mysterious target recovery\nbehavior at overparameterization for general nonlinear models.",
    "descriptor": "",
    "authors": [
      "Yaoyu Zhang",
      "Zhongwang Zhang",
      "Leyang Zhang",
      "Zhiwei Bai",
      "Tao Luo",
      "Zhi-Qin John Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.11623"
  },
  {
    "id": "arXiv:2211.11629",
    "title": "PVT++: A Simple End-to-End Latency-Aware Visual Tracking Framework",
    "abstract": "Visual object tracking is an essential capability of intelligent robots. Most\nexisting approaches have ignored the online latency that can cause severe\nperformance degradation during real-world processing. Especially for unmanned\naerial vehicle, where robust tracking is more challenging and onboard\ncomputation is limited, latency issue could be fatal. In this work, we present\na simple framework for end-to-end latency-aware tracking, i.e., end-to-end\npredictive visual tracking (PVT++). PVT++ is capable of turning most\nleading-edge trackers into predictive trackers by appending an online\npredictor. Unlike existing solutions that use model-based approaches, our\nframework is learnable, such that it can take not only motion information as\ninput but it can also take advantage of visual cues or a combination of both.\nMoreover, since PVT++ is end-to-end optimizable, it can further boost the\nlatency-aware tracking performance by joint training. Additionally, this work\npresents an extended latency-aware evaluation benchmark for assessing an\nany-speed tracker in the online setting. Empirical results on robotic platform\nfrom aerial perspective show that PVT++ can achieve up to 60% performance gain\non various trackers and exhibit better robustness than prior model-based\nsolution, largely mitigating the degradation brought by latency. Code and\nmodels will be made public.",
    "descriptor": "\nComments: 18 pages, 10 figures\n",
    "authors": [
      "Bowen Li",
      "Ziyuan Huang",
      "Junjie Ye",
      "Yiming Li",
      "Sebastian Scherer",
      "Hang Zhao",
      "Changhong Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11629"
  },
  {
    "id": "arXiv:2211.11630",
    "title": "Improved Touchless Respiratory Rate Sensing",
    "abstract": "Recently, remote respiratory rate measurement techniques gained much\nattention as they were developed to overcome the limitations of device-based\nclassical methods and manual counting. Many approaches for RR extraction from\nthe video stream of the visible light camera were proposed, including the pixel\nintensity changes method. In this paper, we propose a new method for 1D profile\ncreation for pixel intensity changes-based method, which significantly\nincreases the algorithm's performance. Additional accuracy gain is obtained via\na new method of motion signals grouping presented in this work. We introduce\nseveral changes to the standard pipeline, which enables real-time continuous RR\nmonitoring and allows applications in the human-computer interaction systems.\nEvaluation results on two internal and one public datasets showed 0.7 BPM, 0.6\nBPM, and 1.4 BPM MAE, respectively.",
    "descriptor": "\nComments: 5 pages, 1 figure, 2 tables. This work was presented on the IMET 2022 workshop on Haptics, AI and RRI\n",
    "authors": [
      "Petro Franchuk",
      "Tetiana Yezerska"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.11630"
  },
  {
    "id": "arXiv:2211.11635",
    "title": "Understanding and Improving Visual Prompting: A Label-Mapping  Perspective",
    "abstract": "We revisit and advance visual prompting (VP), an input prompting technique\nfor vision tasks. VP can reprogram a fixed, pre-trained source model to\naccomplish downstream tasks in the target domain by simply incorporating\nuniversal prompts (in terms of input perturbation patterns) into downstream\ndata points. Yet, it remains elusive why VP stays effective even given a\nruleless label mapping (LM) between the source classes and the target classes.\nInspired by the above, we ask: How is LM interrelated with VP? And how to\nexploit such a relationship to improve its accuracy on target tasks? We peer\ninto the influence of LM on VP and provide an affirmative answer that a better\n'quality' of LM (assessed by mapping precision and explanation) can\nconsistently improve the effectiveness of VP. This is in contrast to the prior\nart where the factor of LM was missing. To optimize LM, we propose a new VP\nframework, termed ILM-VP (iterative label mapping-based visual prompting),\nwhich automatically re-maps the source labels to the target labels and\nprogressively improves the target task accuracy of VP. Further, when using a\ncontrastive language-image pretrained (CLIP) model, we propose to integrate an\nLM process to assist the text prompt selection of CLIP and to improve the\ntarget task accuracy. Extensive experiments demonstrate that our proposal\nsignificantly outperforms state-of-the-art VP methods. As highlighted below, we\nshow that when reprogramming an ImageNet-pretrained ResNet-18 to 13 target\ntasks, our method outperforms baselines by a substantial margin, e.g., 7.9% and\n6.7% accuracy improvements in transfer learning to the target Flowers102 and\nCIFAR100 datasets. Besides, our proposal on CLIP-based VP provides 13.7% and\n7.1% accuracy improvements on Flowers102 and DTD respectively. Our code is\navailable at https://github.com/OPTML-Group/ILM-VP.",
    "descriptor": "",
    "authors": [
      "Aochuan Chen",
      "Yuguang Yao",
      "Pin-Yu Chen",
      "Yihua Zhang",
      "Sijia Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11635"
  },
  {
    "id": "arXiv:2211.11636",
    "title": "Dwelling Type Classification for Disaster Risk Assessment Using  Satellite Imagery",
    "abstract": "Vulnerability and risk assessment of neighborhoods is essential for effective\ndisaster preparedness. Existing traditional systems, due to dependency on\ntime-consuming and cost-intensive field surveying, do not provide a scalable\nway to decipher warnings and assess the precise extent of the risk at a\nhyper-local level. In this work, machine learning was used to automate the\nprocess of identifying dwellings and their type to build a potentially more\neffective disaster vulnerability assessment system. First, satellite imageries\nof low-income settlements and vulnerable areas in India were used to identify 7\ndifferent dwelling types. Specifically, we formulated the dwelling type\nclassification as a semantic segmentation task and trained a U-net based neural\nnetwork model, namely TernausNet, with the data we collected. Then a risk score\nassessment model was employed, using the determined dwelling type along with an\ninundation model of the regions. The entire pipeline was deployed to multiple\nlocations prior to natural hazards in India in 2020. Post hoc ground-truth data\nfrom those regions was collected to validate the efficacy of this model which\nshowed promising performance. This work can aid disaster response organizations\nand communities at risk by providing household-level risk information that can\ninform preemptive actions.",
    "descriptor": "\nComments: Accepted for presentation in AI+HADR workshop, Neurips 2022\n",
    "authors": [
      "Md Nasir",
      "Tina Sederholm",
      "Anshu Sharma",
      "Sundeep Reddy Mallu",
      "Sumedh Ranjan Ghatage",
      "Rahul Dodhia",
      "Juan Lavista Ferres"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11636"
  },
  {
    "id": "arXiv:2211.11638",
    "title": "Normalizing Flow with Variational Latent Representation",
    "abstract": "Normalizing flow (NF) has gained popularity over traditional maximum\nlikelihood based methods due to its strong capability to model complex data\ndistributions. However, the standard approach, which maps the observed data to\na normal distribution, has difficulty in handling data distributions with\nmultiple relatively isolated modes. To overcome this issue, we propose a new\nframework based on variational latent representation to improve the practical\nperformance of NF. The idea is to replace the standard normal latent variable\nwith a more general latent representation, jointly learned via Variational\nBayes. For example, by taking the latent representation as a discrete sequence,\nour framework can learn a Transformer model that generates the latent sequence\nand an NF model that generates continuous data distribution conditioned on the\nsequence. The resulting method is significantly more powerful than the standard\nnormalization flow approach for generating data distributions with multiple\nmodes. Extensive experiments have shown the advantages of NF with variational\nlatent representation.",
    "descriptor": "\nComments: 24 pages, 7 figures\n",
    "authors": [
      "Hanze Dong",
      "Shizhe Diao",
      "Weizhong Zhang",
      "Tong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.11638"
  },
  {
    "id": "arXiv:2211.11643",
    "title": "Parametric information geometry with the package Geomstats",
    "abstract": "We introduce the information geometry module of the Python package Geomstats.\nThe module first implements Fisher-Rao Riemannian manifolds of widely used\nparametric families of probability distributions, such as normal, gamma, beta,\nDirichlet distributions, and more. The module further gives the Fisher-Rao\nRiemannian geometry of any parametric family of distributions of interest,\ngiven a parameterized probability density function as input. The implemented\nRiemannian geometry tools allow users to compare, average, interpolate between\ndistributions inside a given family. Importantly, such capabilities open the\ndoor to statistics and machine learning on probability distributions. We\npresent the object-oriented implementation of the module along with\nillustrative examples and show how it can be used to perform learning on\nmanifolds of parametric probability distributions.",
    "descriptor": "",
    "authors": [
      "Alice Le Brigant",
      "Jules Deschamps",
      "Antoine Collas",
      "Nina Miolane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2211.11643"
  },
  {
    "id": "arXiv:2211.11644",
    "title": "Optimization-Based Control for Dynamic Legged Robots",
    "abstract": "In a world designed for legs, quadrupeds, bipeds, and humanoids have the\nopportunity to impact emerging robotics applications from logistics, to\nagriculture, to home assistance. The goal of this survey is to cover the recent\nprogress toward these applications that has been driven by model-based\noptimization for the real-time generation and control of movement. The majority\nof the research community has converged on the idea of generating locomotion\ncontrol laws by solving an optimal control problem (OCP) in either a\nmodel-based or data-driven manner. However, solving the most general of these\nproblems online remains intractable due to complexities from intermittent\nunidirectional contacts with the environment, and from the many degrees of\nfreedom of legged robots. This survey covers methods that have been pursued to\nmake these OCPs computationally tractable, with specific focus on how\nenvironmental contacts are treated, how the model can be simplified, and how\nthese choices affect the numerical solution methods employed. The survey\nfocuses on model-based optimization, covering its recent use in a stand alone\nfashion, and suggesting avenues for combination with learning-based\nformulations to further accelerate progress in this growing field.",
    "descriptor": "\nComments: submitted for initial review; comments welcome\n",
    "authors": [
      "Patrick M. Wensing",
      "Michael Posa",
      "Yue Hu",
      "Adrien Escande",
      "Nicolas Mansard",
      "Andrea Del Prete"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.11644"
  },
  {
    "id": "arXiv:2211.11646",
    "title": "NeRF-RPN: A general framework for object detection in NeRFs",
    "abstract": "This paper presents the first significant object detection framework,\nNeRF-RPN, which directly operates on NeRF. Given a pre-trained NeRF model,\nNeRF-RPN aims to detect all bounding boxes of objects in a scene. By exploiting\na novel voxel representation that incorporates multi-scale 3D neural volumetric\nfeatures, we demonstrate it is possible to regress the 3D bounding boxes of\nobjects in NeRF directly without rendering the NeRF at any viewpoint. NeRF-RPN\nis a general framework and can be applied to detect objects without class\nlabels. We experimented the NeRF-RPN with various backbone architectures, RPN\nhead designs and loss functions. All of them can be trained in an end-to-end\nmanner to estimate high quality 3D bounding boxes. To facilitate future\nresearch in object detection for NeRF, we built a new benchmark dataset which\nconsists of both synthetic and real-world data with careful labeling and clean\nup. Please watch the \\href{https://youtu.be/M8_4Ih1CJjE}{video} for visualizing\nthe 3D region proposals by our NeRF-RPN. Code and dataset will be made\navailable.",
    "descriptor": "",
    "authors": [
      "Benran Hu",
      "Junkai Huang",
      "Yichen Liu",
      "Yu-Wing Tai",
      "Chi-Keung Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11646"
  },
  {
    "id": "arXiv:2211.11647",
    "title": "Benchmarking Edge Computing Devices for Grape Bunches and Trunks  Detection using Accelerated Object Detection Single Shot MultiBox Deep  Learning Models",
    "abstract": "Purpose: Visual perception enables robots to perceive the environment. Visual\ndata is processed using computer vision algorithms that are usually\ntime-expensive and require powerful devices to process the visual data in\nreal-time, which is unfeasible for open-field robots with limited energy. This\nwork benchmarks the performance of different heterogeneous platforms for object\ndetection in real-time. This research benchmarks three architectures: embedded\nGPU -- Graphical Processing Units (such as NVIDIA Jetson Nano 2 GB and 4 GB,\nand NVIDIA Jetson TX2), TPU -- Tensor Processing Unit (such as Coral Dev Board\nTPU), and DPU -- Deep Learning Processor Unit (such as in AMD-Xilinx ZCU104\nDevelopment Board, and AMD-Xilinx Kria KV260 Starter Kit). Method: The authors\nused the RetinaNet ResNet-50 fine-tuned using the natural VineSet dataset.\nAfter the trained model was converted and compiled for target-specific hardware\nformats to improve the execution efficiency. Conclusions and Results: The\nplatforms were assessed in terms of performance of the evaluation metrics and\nefficiency (time of inference). Graphical Processing Units (GPUs) were the\nslowest devices, running at 3 FPS to 5 FPS, and Field Programmable Gate Arrays\n(FPGAs) were the fastest devices, running at 14 FPS to 25 FPS. The efficiency\nof the Tensor Processing Unit (TPU) is irrelevant and similar to NVIDIA Jetson\nTX2. TPU and GPU are the most power-efficient, consuming about 5W. The\nperformance differences, in the evaluation metrics, across devices are\nirrelevant and have an F1 of about 70 % and mean Average Precision (mAP) of\nabout 60 %.",
    "descriptor": "",
    "authors": [
      "Sandro Costa Magalh\u00e3es",
      "Filipe Neves Santos",
      "Pedro Machado",
      "Ant\u00f3nio Paulo Moreira",
      "Jorge Dias"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.11647"
  },
  {
    "id": "arXiv:2211.11649",
    "title": "Implicit Training of Energy Model for Structure Prediction",
    "abstract": "Most deep learning research has focused on developing new model and training\nprocedures. On the other hand the training objective has usually been\nrestricted to combinations of standard losses. When the objective aligns well\nwith the evaluation metric, this is not a major issue. However when dealing\nwith complex structured outputs, the ideal objective can be hard to optimize\nand the efficacy of usual objectives as a proxy for the true objective can be\nquestionable. In this work, we argue that the existing inference network based\nstructure prediction methods ( Tu and Gimpel 2018; Tu, Pang, and Gimpel 2020)\nare indirectly learning to optimize a dynamic loss objective parameterized by\nthe energy model. We then explore using implicit-gradient based technique to\nlearn the corresponding dynamic objectives. Our experiments show that\nimplicitly learning a dynamic loss landscape is an effective method for\nimproving model performance in structure prediction.",
    "descriptor": "\nComments: AAAI\n",
    "authors": [
      "Shiv Shankar",
      "Vihari Piratla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11649"
  },
  {
    "id": "arXiv:2211.11650",
    "title": "Differentiable Meta logical Programming",
    "abstract": "Deep learning uses an increasing amount of computation and data to solve very\nspecific problems. By stark contrast, human minds solve a wide range of\nproblems using a fixed amount of computation and limited experience. One\nability that seems crucial to this kind of general intelligence is\nmeta-reasoning, i.e., our ability to reason about reasoning. To make deep\nlearning do more from less, we propose the differentiable logical meta\ninterpreter (DLMI). The key idea is to realize a meta-interpreter using\ndifferentiable forward-chaining reasoning in first-order logic. This directly\nallows DLMI to reason and even learn about its own operations. This is\ndifferent from performing object-level deep reasoning and learning, which\nrefers in some way to entities external to the system. In contrast, DLMI is\nable to reflect or introspect, i.e., to shift from meta-reasoning to\nobject-level reasoning and vice versa. Among many other experimental\nevaluations, we illustrate this behavior using the novel task of \"repairing\nKandinsky patterns,\" i.e., how to edit the objects in an image so that it\nagrees with a given logical concept.",
    "descriptor": "",
    "authors": [
      "Zihan Ye",
      "Hikaru Shindo",
      "Devendra Singh Dhami",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11650"
  },
  {
    "id": "arXiv:2211.11656",
    "title": "Sequential Informed Federated Unlearning: Efficient and Provable Client  Unlearning in Federated Optimization",
    "abstract": "The aim of Machine Unlearning (MU) is to provide theoretical guarantees on\nthe removal of the contribution of a given data point from a training\nprocedure. Federated Unlearning (FU) consists in extending MU to unlearn a\ngiven client's contribution from a federated training routine. Current FU\napproaches are generally not scalable, and do not come with sound theoretical\nquantification of the effectiveness of unlearning. In this work we present\nInformed Federated Unlearning (IFU), a novel efficient and quantifiable FU\napproach. Upon unlearning request from a given client, IFU identifies the\noptimal FL iteration from which FL has to be reinitialized, with unlearning\nguarantees obtained through a randomized perturbation mechanism. The theory of\nIFU is also extended to account for sequential unlearning requests.\nExperimental results on different tasks and dataset show that IFU leads to more\nefficient unlearning procedures as compared to basic re-training and\nstate-of-the-art FU approaches.",
    "descriptor": "",
    "authors": [
      "Yann Fraboni",
      "Richard Vidal",
      "Laetitia Kameni",
      "Marco Lorenzi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11656"
  },
  {
    "id": "arXiv:2211.11658",
    "title": "Binary $t_1$-Deletion-$t_2$-Insertion-Burst Correcting Codes and Codes  Correcting a Burst of Deletions",
    "abstract": "We first give a construction of binary $t_1$-deletion-$t_2$-insertion-burst\ncorrecting codes with redundancy at most $\\log(n)+(t_1-t_2-1)\\log\\log(n)+O(1)$,\nwhere $t_1\\ge 2t_2$. Then we give an improved construction of binary codes\ncapable of correcting a burst of $4$ non-consecutive deletions, whose\nredundancy is reduced from $7\\log(n)+2\\log\\log(n)+O(1)$ to\n$4\\log(n)+6\\log\\log(n)+O(1)$. Lastly, by connecting non-binary\n$b$-burst-deletion correcting codes with binary\n$2b$-deletion-$b$-insertion-burst correcting codes, we give a new construction\nof non-binary $b$-burst-deletion correcting codes with redundancy at most\n$\\log(n)+(b-1)\\log\\log(n)+O(1)$. This construction is different from previous\nresults.",
    "descriptor": "",
    "authors": [
      "Zuo Ye",
      "Ohad Elishco"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.11658"
  },
  {
    "id": "arXiv:2211.11659",
    "title": "Formal Abstractions for Packet Scheduling",
    "abstract": "This paper studies PIFO trees from a programming language perspective. PIFO\ntrees are a recently proposed model for programmable packet schedulers. They\ncan express a wide range of scheduling algorithms including strict priority,\nweighted fair queueing, hierarchical schemes, and more. However, their semantic\nproperties are not well understood. We formalize the syntax and semantics of\nPIFO trees in terms of an operational model. We also develop an alternate\nsemantics in terms of permutations on lists of packets, prove theorems\ncharacterizing expressiveness, and develop an embedding algorithm for\nreplicating the behavior of one with another. We present a prototype\nimplementation of PIFO trees in OCaml and relate its behavior to a hardware\nswitch on a variety of standard and novel scheduling algorithms.",
    "descriptor": "\nComments: 25 pages, 12 figures\n",
    "authors": [
      "Anshuman Mohan",
      "Yunhe Liu",
      "Nate Foster",
      "Tobias Kapp\u00e9",
      "Dexter Kozen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.11659"
  },
  {
    "id": "arXiv:2211.11662",
    "title": "Mutually-Regularized Dual Collaborative Variational Auto-encoder for  Recommendation Systems",
    "abstract": "Recently, user-oriented auto-encoders (UAEs) have been widely used in\nrecommender systems to learn semantic representations of users based on their\nhistorical ratings. However, since latent item variables are not modeled in\nUAE, it is difficult to utilize the widely available item content information\nwhen ratings are sparse. In addition, whenever new items arrive, we need to\nwait for collecting rating data for these items and retrain the UAE from\nscratch, which is inefficient in practice. Aiming to address the above two\nproblems simultaneously, we propose a mutually-regularized dual collaborative\nvariational auto-encoder (MD-CVAE) for recommendation. First, by replacing\nrandomly initialized last layer weights of the vanilla UAE with stacked latent\nitem embeddings, MD-CVAE integrates two heterogeneous information sources,\ni.e., item content and user ratings, into the same principled variational\nframework where the weights of UAE are regularized by item content such that\nconvergence to a non-optima due to data sparsity can be avoided. In addition,\nthe regularization is mutual in that user ratings can also help the dual item\ncontent module learn more recommendation-oriented item content embeddings.\nFinally, we propose a symmetric inference strategy for MD-CVAE where the first\nlayer weights of the UAE encoder are tied to the latent item embeddings of the\nUAE decoder. Through this strategy, no retraining is required to recommend\nnewly introduced items. Empirical studies show the effectiveness of MD-CVAE in\nboth normal and cold-start scenarios. Codes are available at\nhttps://github.com/yaochenzhu/MD-CVAE.",
    "descriptor": "",
    "authors": [
      "Yaochen Zhu",
      "Zhenzhong Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.11662"
  },
  {
    "id": "arXiv:2211.11665",
    "title": "Representational dissimilarity metric spaces for stochastic neural  networks",
    "abstract": "Quantifying similarity between neural representations -- e.g. hidden layer\nactivation vectors -- is a perennial problem in deep learning and neuroscience\nresearch. Existing methods compare deterministic responses (e.g. artificial\nnetworks that lack stochastic layers) or averaged responses (e.g.,\ntrial-averaged firing rates in biological data). However, these measures of\ndeterministic representational similarity ignore the scale and geometric\nstructure of noise, both of which play important roles in neural computation.\nTo rectify this, we generalize previously proposed shape metrics (Williams et\nal. 2021) to quantify differences in stochastic representations. These new\ndistances satisfy the triangle inequality, and thus can be used as a rigorous\nbasis for many supervised and unsupervised analyses. Leveraging this novel\nframework, we find that the stochastic geometries of neurobiological\nrepresentations of oriented visual gratings and naturalistic scenes\nrespectively resemble untrained and trained deep network representations.\nFurther, we are able to more accurately predict certain network attributes\n(e.g. training hyperparameters) from its position in stochastic (versus\ndeterministic) shape space.",
    "descriptor": "",
    "authors": [
      "Lyndon R. Duong",
      "Jingyang Zhou",
      "Josue Nassar",
      "Jules Berman",
      "Jeroen Olieslagers",
      "Alex H. Williams"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2211.11665"
  },
  {
    "id": "arXiv:2211.11674",
    "title": "Shape, Pose, and Appearance from a Single Image via Bootstrapped  Radiance Field Inversion",
    "abstract": "Neural Radiance Fields (NeRF) coupled with GANs represent a promising\ndirection in the area of 3D reconstruction from a single view, owing to their\nability to efficiently model arbitrary topologies. Recent work in this area,\nhowever, has mostly focused on synthetic datasets where exact ground-truth\nposes are known, and has overlooked pose estimation, which is important for\ncertain downstream applications such as augmented reality (AR) and robotics. We\nintroduce a principled end-to-end reconstruction framework for natural images,\nwhere accurate ground-truth poses are not available. Our approach recovers an\nSDF-parameterized 3D shape, pose, and appearance from a single image of an\nobject, without exploiting multiple views during training. More specifically,\nwe leverage an unconditional 3D-aware generator, to which we apply a hybrid\ninversion scheme where a model produces a first guess of the solution which is\nthen refined via optimization. Our framework can de-render an image in as few\nas 10 steps, enabling its use in practical scenarios. We demonstrate\nstate-of-the-art results on a variety of real and synthetic benchmarks.",
    "descriptor": "",
    "authors": [
      "Dario Pavllo",
      "David Joseph Tan",
      "Marie-Julie Rakotosaona",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11674"
  },
  {
    "id": "arXiv:2211.11678",
    "title": "Measuring Harmful Representations in Scandinavian Language Models",
    "abstract": "Scandinavian countries are perceived as role-models when it comes to gender\nequality. With the advent of pre-trained language models and their widespread\nusage, we investigate to what extent gender-based harmful and toxic content\nexist in selected Scandinavian language models. We examine nine models,\ncovering Danish, Swedish, and Norwegian, by manually creating template-based\nsentences and probing the models for completion. We evaluate the completions\nusing two methods for measuring harmful and toxic completions and provide a\nthorough analysis of the results. We show that Scandinavian pre-trained\nlanguage models contain harmful and gender-based stereotypes with similar\nvalues across all languages. This finding goes against the general expectations\nrelated to gender equality in Scandinavian countries and shows the possible\nproblematic outcomes of using such models in real-world settings.",
    "descriptor": "\nComments: Accepted at the 5th workshop on Natural Language Processing and Computational Social Science (NLP+CSS) at EMNLP 2022 in Abu Dhabi, Dec 7 2022\n",
    "authors": [
      "Samia Touileb",
      "Debora Nozza"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11678"
  },
  {
    "id": "arXiv:2211.11679",
    "title": "Mean Shift Mask Transformer for Unseen Object Instance Segmentation",
    "abstract": "Segmenting unseen objects is a critical task in many different domains. For\nexample, a robot may need to grasp an unseen object, which means it needs to\nvisually separate this object from the background and/or other objects. Mean\nshift clustering is a common method in object segmentation tasks. However, the\ntraditional mean shift clustering algorithm is not easily integrated into an\nend-to-end neural network training pipeline. In this work, we propose the Mean\nShift Mask Transformer (MSMFormer), a new transformer architecture that\nsimulates the von Mises-Fisher (vMF) mean shift clustering algorithm, allowing\nfor the joint training and inference of both the feature extractor and the\nclustering. Its central component is a hypersphere attention mechanism, which\nupdates object queries on a hypersphere. To illustrate the effectiveness of our\nmethod, we apply MSMFormer to Unseen Object Instance Segmentation, which yields\na new state-of-the-art of 87.3 Boundary F-meansure on the real-world Object\nClutter Indoor Dataset (OCID). Code is available at\nhttps://github.com/YoungSean/UnseenObjectsWithMeanShift",
    "descriptor": "\nComments: 10 figures\n",
    "authors": [
      "Yangxiao Lu",
      "Yuqiao Chen",
      "Nicholas Ruozzi",
      "Yu Xiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.11679"
  },
  {
    "id": "arXiv:2211.11680",
    "title": "Constructing Effective Machine Learning Models for the Sciences: A  Multidisciplinary Perspective",
    "abstract": "Learning from data has led to substantial advances in a multitude of\ndisciplines, including text and multimedia search, speech recognition, and\nautonomous-vehicle navigation. Can machine learning enable similar leaps in the\nnatural and social sciences? This is certainly the expectation in many\nscientific fields and recent years have seen a plethora of applications of\nnon-linear models to a wide range of datasets. However, flexible non-linear\nsolutions will not always improve upon manually adding transforms and\ninteractions between variables to linear regression models. We discuss how to\nrecognize this before constructing a data-driven model and how such analysis\ncan help us move to intrinsically interpretable regression models. Furthermore,\nfor a variety of applications in the natural and social sciences we demonstrate\nwhy improvements may be seen with more complex regression models and why they\nmay not.",
    "descriptor": "",
    "authors": [
      "Alice E. A. Allen",
      "Alexandre Tkatchenko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.11680"
  },
  {
    "id": "arXiv:2211.11681",
    "title": "Multiresolution kernel matrix algebra",
    "abstract": "We propose a sparse arithmetic for kernel matrices, enabling efficient\nscattered data analysis. The compression of kernel matrices by means of\nsamplets yields sparse matrices such that assembly, addition, and\nmultiplication of these matrices can be performed with essentially linear cost.\nSince the inverse of a kernel matrix is compressible, too, we have also fast\naccess to the inverse kernel matrix by employing exact sparse selected\ninversion techniques. As a consequence, we can rapidly evaluate series\nexpansions and contour integrals to access, numerically and approximately in a\ndata-sparse format, more complicated matrix functions such as $A^\\alpha$ and\n$\\exp(A)$. By exploiting the matrix arithmetic, also efficient Gaussian process\nlearning algorithms for spatial statistics can be realized. Numerical results\nare presented to quantify and quality our findings.",
    "descriptor": "",
    "authors": [
      "H. Harbrecht",
      "M. Multerer",
      "O. Schenk",
      "Ch. Schwab"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11681"
  },
  {
    "id": "arXiv:2211.11682",
    "title": "PointCLIP V2: Adapting CLIP for Powerful 3D Open-world Learning",
    "abstract": "Contrastive Language-Image Pre-training (CLIP) has shown promising open-world\nperformance on 2D image tasks, while its transferred capacity on 3D point\nclouds, i.e., PointCLIP, is still far from satisfactory. In this work, we\npropose PointCLIP V2, a powerful 3D open-world learner, to fully unleash the\npotential of CLIP on 3D point cloud data. First, we introduce a realistic shape\nprojection module to generate more realistic depth maps for CLIP's visual\nencoder, which is quite efficient and narrows the domain gap between projected\npoint clouds with natural images. Second, we leverage large-scale language\nmodels to automatically design a more descriptive 3D-semantic prompt for CLIP's\ntextual encoder, instead of the previous hand-crafted one. Without introducing\nany training in 3D domains, our approach significantly surpasses PointCLIP by\n+42.90%, +40.44%, and +28.75% accuracy on three datasets for zero-shot 3D\nclassification. Furthermore, PointCLIP V2 can be extended to few-shot\nclassification, zero-shot part segmentation, and zero-shot 3D object detection\nin a simple manner, demonstrating our superior generalization ability for 3D\nopen-world learning. Code will be available at\nhttps://github.com/yangyangyang127/PointCLIP_V2.",
    "descriptor": "",
    "authors": [
      "Xiangyang Zhu",
      "Renrui Zhang",
      "Bowei He",
      "Ziyao Zeng",
      "Shanghang Zhang",
      "Peng Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11682"
  },
  {
    "id": "arXiv:2211.11687",
    "title": "Unsupervised Echocardiography Registration through Patch-based MLPs and  Transformers",
    "abstract": "Image registration is an essential but challenging task in medical image\ncomputing, especially for echocardiography, where the anatomical structures are\nrelatively noisy compared to other imaging modalities. Traditional\n(non-learning) registration approaches rely on the iterative optimization of a\nsimilarity metric which is usually costly in time complexity. In recent years,\nconvolutional neural network (CNN) based image registration methods have shown\ngood effectiveness. In the meantime, recent studies show that the\nattention-based model (e.g., Transformer) can bring superior performance in\npattern recognition tasks. In contrast, whether the superior performance of the\nTransformer comes from the long-winded architecture or is attributed to the use\nof patches for dividing the inputs is unclear yet. This work introduces three\npatch-based frameworks for image registration using MLPs and transformers. We\nprovide experiments on 2D-echocardiography registration to answer the former\nquestion partially and provide a benchmark solution. Our results on a large\npublic 2D echocardiography dataset show that the patch-based MLP/Transformer\nmodel can be effectively used for unsupervised echocardiography registration.\nThey demonstrate comparable and even better registration performance than a\npopular CNN registration model. In particular, patch-based models better\npreserve volume changes in terms of Jacobian determinants, thus generating\nrobust registration fields with less unrealistic deformation. Our results\ndemonstrate that patch-based learning methods, whether with attention or not,\ncan perform high-performance unsupervised registration tasks with adequate time\nand space complexity. Our codes are available\nhttps://gitlab.inria.fr/epione/mlp\\_transformer\\_registration",
    "descriptor": "",
    "authors": [
      "Zihao Wang",
      "Yingyu Yang",
      "Maxime Sermesant",
      "Herve Delingette"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11687"
  },
  {
    "id": "arXiv:2211.11690",
    "title": "Learn to explain yourself, when you can: Equipping Concept Bottleneck  Models with the ability to abstain on their concept predictions",
    "abstract": "The Concept Bottleneck Models (CBMs) of Koh et al. [2020] provide a means to\nensure that a neural network based classifier bases its predictions solely on\nhuman understandable concepts. The concept labels, or rationales as we refer to\nthem, are learned by the concept labeling component of the CBM. Another\ncomponent learns to predict the target classification label from these\npredicted concept labels. Unfortunately, these models are heavily reliant on\nhuman provided concept labels for each datapoint. To enable CBMs to behave\nrobustly when these labels are not readily available, we show how to equip them\nwith the ability to abstain from predicting concepts when the concept labeling\ncomponent is uncertain. In other words, our model learns to provide rationales\nfor its predictions, but only whenever it is sure the rationale is correct.",
    "descriptor": "",
    "authors": [
      "Joshua Lockhart",
      "Daniele Magazzeni",
      "Manuela Veloso"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11690"
  },
  {
    "id": "arXiv:2211.11692",
    "title": "TinyQMIX: Distributed Access Control for mMTC via Multi-agent  Reinforcement Learning",
    "abstract": "Distributed access control is a crucial component for massive machine type\ncommunication (mMTC). In this communication scenario, centralized resource\nallocation is not scalable because resource configurations have to be sent\nfrequently from the base station to a massive number of devices. We investigate\ndistributed reinforcement learning for resource selection without relying on\ncentralized control. Another important feature of mMTC is the sporadic and\ndynamic change of traffic. Existing studies on distributed access control\nassume that traffic load is static or they are able to gradually adapt to the\ndynamic traffic. We minimize the adaptation period by training TinyQMIX, which\nis a lightweight multi-agent deep reinforcement learning model, to learn a\ndistributed wireless resource selection policy under various traffic patterns\nbefore deployment. Therefore, the trained agents are able to quickly adapt to\ndynamic traffic and provide low access delay. Numerical results are presented\nto support our claims.",
    "descriptor": "\nComments: 6 pages, 4 figures, presented at VTC Fall 2022\n",
    "authors": [
      "Tien Thanh Le",
      "Yusheng Ji",
      "John C.S Lui"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.11692"
  },
  {
    "id": "arXiv:2211.11693",
    "title": "Lattice Problems Beyond Polynomial Time",
    "abstract": "We study the complexity of lattice problems in a world where algorithms,\nreductions, and protocols can run in superpolynomial time, revisiting four\nfoundational results: two worst-case to average-case reductions and two\nprotocols. We also show a novel protocol.\n1. We prove that secret-key cryptography exists if\n$\\widetilde{O}(\\sqrt{n})$-approximate SVP is hard for $2^{\\varepsilon n}$-time\nalgorithms. I.e., we extend to our setting (Micciancio and Regev's improved\nversion of) Ajtai's celebrated polynomial-time worst-case to average-case\nreduction from $\\widetilde{O}(n)$-approximate SVP to SIS.\n2. We prove that public-key cryptography exists if\n$\\widetilde{O}(n)$-approximate SVP is hard for $2^{\\varepsilon n}$-time\nalgorithms. This extends to our setting Regev's celebrated polynomial-time\nworst-case to average-case reduction from $\\widetilde{O}(n^{1.5})$-approximate\nSVP to LWE. In fact, Regev's reduction is quantum, but ours is classical,\ngeneralizing Peikert's polynomial-time classical reduction from\n$\\widetilde{O}(n^2)$-approximate SVP.\n3. We show a $2^{\\varepsilon n}$-time coAM protocol for $O(1)$-approximate\nCVP, generalizing the celebrated polynomial-time protocol for $O(\\sqrt{n/\\log\nn})$-CVP due to Goldreich and Goldwasser. These results show\ncomplexity-theoretic barriers to extending the recent line of fine-grained\nhardness results for CVP and SVP to larger approximation factors. (This result\nalso extends to arbitrary norms.)\n4. We show a $2^{\\varepsilon n}$-time co-non-deterministic protocol for\n$O(\\sqrt{\\log n})$-approximate SVP, generalizing the (also celebrated!)\npolynomial-time protocol for $O(\\sqrt{n})$-CVP due to Aharonov and Regev.\n5. We give a novel coMA protocol for $O(1)$-approximate CVP with a\n$2^{\\varepsilon n}$-time verifier.\nAll of the results described above are special cases of more general theorems\nthat achieve time-approximation factor tradeoffs.",
    "descriptor": "",
    "authors": [
      "Divesh Aggarwal",
      "Huck Bennett",
      "Zvika Brakerski",
      "Alexander Golovnev",
      "Rajendra Kumar",
      "Zeyong Li",
      "Spencer Peters",
      "Noah Stephens-Davidowitz",
      "Vinod Vaikuntanathan"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.11693"
  },
  {
    "id": "arXiv:2211.11694",
    "title": "Exploring Discrete Diffusion Models for Image Captioning",
    "abstract": "The image captioning task is typically realized by an auto-regressive method\nthat decodes the text tokens one by one. We present a diffusion-based\ncaptioning model, dubbed the name DDCap, to allow more decoding flexibility.\nUnlike image generation, where the output is continuous and redundant with a\nfixed length, texts in image captions are categorical and short with varied\nlengths. Therefore, naively applying the discrete diffusion model to text\ndecoding does not work well, as shown in our experiments. To address the\nperformance gap, we propose several key techniques including best-first\ninference, concentrated attention mask, text length prediction, and image-free\ntraining. On COCO without additional caption pre-training, it achieves a CIDEr\nscore of 117.8, which is +5.0 higher than the auto-regressive baseline with the\nsame architecture in the controlled setting. It also performs +26.8 higher\nCIDEr score than the auto-regressive baseline (230.3 v.s.203.5) on a caption\ninfilling task. With 4M vision-language pre-training images and the base-sized\nmodel, we reach a CIDEr score of 125.1 on COCO, which is competitive to the\nbest well-developed auto-regressive frameworks. The code is available at\nhttps://github.com/buxiangzhiren/DDCap.",
    "descriptor": "",
    "authors": [
      "Zixin Zhu",
      "Yixuan Wei",
      "Jianfeng Wang",
      "Zhe Gan",
      "Zheng Zhang",
      "Le Wang",
      "Gang Hua",
      "Lijuan Wang",
      "Zicheng Liu",
      "Han Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11694"
  },
  {
    "id": "arXiv:2211.11695",
    "title": "Disentangled Representation Learning",
    "abstract": "Disentangled Representation Learning (DRL) aims to learn a model capable of\nidentifying and disentangling the underlying factors hidden in the observable\ndata in representation form. The process of separating underlying factors of\nvariation into variables with semantic meaning benefits in learning explainable\nrepresentations of data, which imitates the meaningful understanding process of\nhumans when observing an object or relation. As a general learning strategy,\nDRL has demonstrated its power in improving the model explainability,\ncontrolability, robustness, as well as generalization capacity in a wide range\nof scenarios such as computer vision, natural language processing, data mining\netc. In this article, we comprehensively review DRL from various aspects\nincluding motivations, definitions, methodologies, evaluations, applications\nand model designs. We discuss works on DRL based on two well-recognized\ndefinitions, i.e., Intuitive Definition and Group Theory Definition. We further\ncategorize the methodologies for DRL into four groups, i.e., Traditional\nStatistical Approaches, Variational Auto-encoder Based Approaches, Generative\nAdversarial Networks Based Approaches, Hierarchical Approaches and Other\nApproaches. We also analyze principles to design different DRL models that may\nbenefit different tasks in practical applications. Finally, we point out\nchallenges in DRL as well as potential research directions deserving future\ninvestigations. We believe this work may provide insights for promoting the DRL\nresearch in the community.",
    "descriptor": "\nComments: 22 pages,9 figures\n",
    "authors": [
      "Xin Wang",
      "Hong Chen",
      "Si'ao Tang",
      "Zihao Wu",
      "Wenwu Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11695"
  },
  {
    "id": "arXiv:2211.11699",
    "title": "Explaining Random Forests using Bipolar Argumentation and Markov  Networks (Technical Report)",
    "abstract": "Random forests are decision tree ensembles that can be used to solve a\nvariety of machine learning problems. However, as the number of trees and their\nindividual size can be large, their decision making process is often\nincomprehensible. In order to reason about the decision process, we propose\nrepresenting it as an argumentation problem. We generalize sufficient and\nnecessary argumentative explanations using a Markov network encoding, discuss\nthe relevance of these explanations and establish relationships to families of\nabductive explanations from the literature. As the complexity of the\nexplanation problems is high, we discuss a probabilistic approximation\nalgorithm and present first experimental results.",
    "descriptor": "\nComments: Accepted for presentation at AAAI 2023. Contains appendix with proofs and additional details about experiments\n",
    "authors": [
      "Nico Potyka",
      "Xiang Yin",
      "Francesca Toni"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.11699"
  },
  {
    "id": "arXiv:2211.11701",
    "title": "Perceiver-VL: Efficient Vision-and-Language Modeling with Iterative  Latent Attention",
    "abstract": "We present Perceiver-VL, a vision-and-language framework that efficiently\nhandles high-dimensional multimodal inputs such as long videos and text.\nPowered by the iterative latent cross-attention of Perceiver, our framework\nscales with linear complexity, in contrast to the quadratic complexity of\nself-attention used in many state-of-the-art transformer-based models. To\nfurther improve the efficiency of our framework, we also study applying\nLayerDrop on cross-attention layers and introduce a mixed-stream architecture\nfor cross-modal retrieval. We evaluate Perceiver-VL on diverse video-text and\nimage-text benchmarks, where Perceiver-VL achieves the lowest GFLOPs and\nlatency while maintaining competitive performance. In addition, we also provide\ncomprehensive analyses of various aspects of our framework, including\npretraining data, scalability of latent size and input size, dropping\ncross-attention layers at inference to reduce latency, modality aggregation\nstrategy, positional encoding, and weight initialization strategy. Our code and\ncheckpoints are available at: https://github.com/zinengtang/Perceiver_VL",
    "descriptor": "\nComments: WACV 2023 (first two authors contributed equally)\n",
    "authors": [
      "Zineng Tang",
      "Jaemin Cho",
      "Jie Lei",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11701"
  },
  {
    "id": "arXiv:2211.11703",
    "title": "Continually learning new languages",
    "abstract": "Multilingual speech recognition with neural networks is often implemented\nwith batch-learning, when all of the languages are available before training.\nAn ability to add new languages after the prior training sessions can be\neconomically beneficial, but the main challenge is catastrophic forgetting. In\nthis work, we combine the qualities of weight factorization, transfer learning\nand Elastic Weight Consolidation in order to counter catastrophic forgetting\nand facilitate learning new languages quickly. Such combination allowed us to\neliminate catastrophic forgetting while still achieving performance for the new\nlanguages comparable with having all languages at once, in experiments of\nlearning from an initial 10 languages to achieve 27 languages",
    "descriptor": "\nComments: Submitted to ICCASP 2023\n",
    "authors": [
      "Ngoc-Quan Pham",
      "Jan Niehues",
      "Alexander Waibel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.11703"
  },
  {
    "id": "arXiv:2211.11704",
    "title": "ESLAM: Efficient Dense SLAM System Based on Hybrid Representation of  Signed Distance Fields",
    "abstract": "We present ESLAM, an efficient implicit neural representation method for\nSimultaneous Localization and Mapping (SLAM). ESLAM reads RGB-D frames with\nunknown camera poses in a sequential manner and incrementally reconstructs the\nscene representation while estimating the current camera position in the scene.\nWe incorporate the latest advances in Neural Radiance Fields (NeRF) into a SLAM\nsystem, resulting in an efficient and accurate dense visual SLAM method. Our\nscene representation consists of multi-scale axis-aligned perpendicular feature\nplanes and shallow decoders that, for each point in the continuous space,\ndecode the interpolated features into Truncated Signed Distance Field (TSDF)\nand RGB values. Our extensive experiments on two standard and recent datasets,\nReplica and ScanNet, show that ESLAM improves the accuracy of 3D reconstruction\nand camera localization of state-of-the-art dense visual SLAM methods by more\nthan 50%, while it runs up to $\\times$10 faster and does not require any\npre-training.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Mohammad Mahdi Johari",
      "Camilla Carta",
      "Fran\u00e7ois Fleuret"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11704"
  },
  {
    "id": "arXiv:2211.11711",
    "title": "CLAWSAT: Towards Both Robust and Accurate Code Models",
    "abstract": "We integrate contrastive learning (CL) with adversarial learning to\nco-optimize the robustness and accuracy of code models. Different from existing\nworks, we show that code obfuscation, a standard code transformation operation,\nprovides novel means to generate complementary `views' of a code that enable us\nto achieve both robust and accurate code models. To the best of our knowledge,\nthis is the first systematic study to explore and exploit the robustness and\naccuracy benefits of (multi-view) code obfuscations in code models.\nSpecifically, we first adopt adversarial codes as robustness-promoting views in\nCL at the self-supervised pre-training phase. This yields improved robustness\nand transferability for downstream tasks. Next, at the supervised fine-tuning\nstage, we show that adversarial training with a proper temporally-staggered\nschedule of adversarial code generation can further improve robustness and\naccuracy of the pre-trained code model. Built on the above two modules, we\ndevelop CLAWSAT, a novel self-supervised learning (SSL) framework for code by\nintegrating $\\underline{\\textrm{CL}}$ with $\\underline{\\textrm{a}}$dversarial\nvie$\\underline{\\textrm{w}}$s (CLAW) with $\\underline{\\textrm{s}}$taggered\n$\\underline{\\textrm{a}}$dversarial $\\underline{\\textrm{t}}$raining (SAT). On\nevaluating three downstream tasks across Python and Java, we show that CLAWSAT\nconsistently yields the best robustness and accuracy ($\\textit{e.g.}$ 11$\\%$ in\nrobustness and 6$\\%$ in accuracy on the code summarization task in Python). We\nadditionally demonstrate the effectiveness of adversarial learning in CLAW by\nanalyzing the characteristics of the loss landscape and interpretability of the\npre-trained models.",
    "descriptor": "",
    "authors": [
      "Jinghan Jia",
      "Shashank Srikant",
      "Tamara Mitrovska",
      "Chuang Gan",
      "Shiyu Chang",
      "Sijia Liu",
      "Una-May O'Reilly"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.11711"
  },
  {
    "id": "arXiv:2211.11718",
    "title": "Private Counting of Distinct and k-Occurring Items in Time Windows",
    "abstract": "In this work, we study the task of estimating the numbers of distinct and\n$k$-occurring items in a time window under the constraint of differential\nprivacy (DP). We consider several variants depending on whether the queries are\non general time windows (between times $t_1$ and $t_2$), or are restricted to\nbeing cumulative (between times $1$ and $t_2$), and depending on whether the DP\nneighboring relation is event-level or the more stringent item-level. We obtain\nnearly tight upper and lower bounds on the errors of DP algorithms for these\nproblems. En route, we obtain an event-level DP algorithm for estimating, at\neach time step, the number of distinct items seen over the last $W$ updates\nwith error polylogarithmic in $W$; this answers an open question of Bolot et\nal. (ICDT 2013).",
    "descriptor": "\nComments: To appear in ITCS 2023\n",
    "authors": [
      "Badih Ghazi",
      "Ravi Kumar",
      "Pasin Manurangsi",
      "Jelani Nelson"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.11718"
  },
  {
    "id": "arXiv:2211.11719",
    "title": "First Steps Toward Understanding the Extrapolation of Nonlinear Models  to Unseen Domains",
    "abstract": "Real-world machine learning applications often involve deploying neural\nnetworks to domains that are not seen in the training time. Hence, we need to\nunderstand the extrapolation of nonlinear models -- under what conditions on\nthe distributions and function class, models can be guaranteed to extrapolate\nto new test distributions. The question is very challenging because even\ntwo-layer neural networks cannot be guaranteed to extrapolate outside the\nsupport of the training distribution without further assumptions on the domain\nshift. This paper makes some initial steps towards analyzing the extrapolation\nof nonlinear models for structured domain shift. We primarily consider settings\nwhere the marginal distribution of each coordinate of the data (or subset of\ncoordinates) do not shift significantly across the training and test\ndistributions, but the joint distribution may have a much bigger shift. We\nprove that the family of nonlinear models of the form $f(x)=\\sum f_i(x_i)$,\nwhere $f_i$ is an arbitrary function on the subset of features $x_i$, can\nextrapolate to unseen distributions, if the covariance of the features is\nwell-conditioned. To the best of our knowledge, this is the first result that\ngoes beyond linear models and the bounded density ratio assumption, even though\nthe assumptions on the distribution shift and function class are stylized.",
    "descriptor": "",
    "authors": [
      "Kefan Dong",
      "Tengyu Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.11719"
  },
  {
    "id": "arXiv:2211.11720",
    "title": "Multitask Vision-Language Prompt Tuning",
    "abstract": "Prompt Tuning, conditioning on task-specific learned prompt vectors, has\nemerged as a data-efficient and parameter-efficient method for adapting large\npretrained vision-language models to multiple downstream tasks. However,\nexisting approaches usually consider learning prompt vectors for each task\nindependently from scratch, thereby failing to exploit the rich shareable\nknowledge across different vision-language tasks. In this paper, we propose\nmultitask vision-language prompt tuning (MVLPT), which incorporates cross-task\nknowledge into prompt tuning for vision-language models. Specifically, (i) we\ndemonstrate the effectiveness of learning a single transferable prompt from\nmultiple source tasks to initialize the prompt for each target task; (ii) we\nshow many target tasks can benefit each other from sharing prompt vectors and\nthus can be jointly learned via multitask prompt tuning. We benchmark the\nproposed MVLPT using three representative prompt tuning methods, namely text\nprompt tuning, visual prompt tuning, and the unified vision-language prompt\ntuning. Results in 20 vision tasks demonstrate that the proposed approach\noutperforms all single-task baseline prompt tuning methods, setting the new\nstate-of-the-art on the few-shot ELEVATER benchmarks and cross-task\ngeneralization benchmarks. To understand where the cross-task knowledge is most\neffective, we also conduct a large-scale study on task transferability with 20\nvision tasks in 400 combinations for each prompt tuning method. It shows that\nthe most performant MVLPT for each prompt tuning method prefers different task\ncombinations and many tasks can benefit each other, depending on their visual\nsimilarity and label similarity. Code is available at\nhttps://github.com/sIncerass/MVLPT.",
    "descriptor": "",
    "authors": [
      "Sheng Shen",
      "Shijia Yang",
      "Tianjun Zhang",
      "Bohan Zhai",
      "Joseph E. Gonzalez",
      "Kurt Keutzer",
      "Trevor Darrell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11720"
  },
  {
    "id": "arXiv:2211.11721",
    "title": "The Berlekamp-Massey Algorithm revisited",
    "abstract": "We propose a slight modification of the Berlekamp-Massey Algorithm for\nobtaining the minimal polynomial of a given linearly recurrent sequence. Such a\nmodification enables to explain it in a simpler way and to adapt it to lazy\nevaluation.",
    "descriptor": "\nComments: in English and French versions\n",
    "authors": [
      "Nadia Ben Atti",
      "Gema M. Diaz--Toca",
      "Henri Lombardi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2211.11721"
  },
  {
    "id": "arXiv:2211.11724",
    "title": "Legal and Political Stance Detection of SCOTUS Language",
    "abstract": "We analyze publicly available US Supreme Court documents using automated\nstance detection. In the first phase of our work, we investigate the extent to\nwhich the Court's public-facing language is political. We propose and calculate\ntwo distinct ideology metrics of SCOTUS justices using oral argument\ntranscripts. We then compare these language-based metrics to existing social\nscientific measures of the ideology of the Supreme Court and the public.\nThrough this cross-disciplinary analysis, we find that justices who are more\nresponsive to public opinion tend to express their ideology during oral\narguments. This observation provides a new kind of evidence in favor of the\nattitudinal change hypothesis of Supreme Court justice behavior. As a natural\nextension of this political stance detection, we propose the more specialized\ntask of legal stance detection with our new dataset SC-stance, which matches\nwritten opinions to legal questions. We find competitive performance on this\ndataset using language adapters trained on legal documents.",
    "descriptor": "\nComments: Natural Legal Language Processing Workshop at EMNLP 2022\n",
    "authors": [
      "Noah Bergam",
      "Emily Allaway",
      "Kathleen McKeown"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11724"
  },
  {
    "id": "arXiv:2211.11726",
    "title": "A Cut-Matching Game for Constant-Hop Expanders",
    "abstract": "This paper provides a cut-strategy that produces constant-hop expanders in\nthe well-known cut-matching game framework.\nConstant-hop expanders strengthen expanders with constant conductance by\nguaranteeing that any demand can be (obliviously) routed along constant-hop\npaths - in contrast to the $\\Omega(\\log n)$-hop routes in expanders.\nCut-matching games for expanders are key tools for obtaining\nclose-to-linear-time approximation algorithms for many hard problems, including\nfinding (balanced or approximately-largest) sparse cuts, certifying the\nexpansion of a graph by embedding an (explicit) expander, as well as computing\nexpander decompositions, hierarchical cut decompositions, oblivious routings,\nmulti-cuts, and multicommodity flows. The cut-matching game provided in this\npaper is crucial in extending this versatile and powerful machinery to\nconstant-hop expanders. It is also a key ingredient towards close-to-linear\ntime algorithms for computing a constant approximation of multicommodity-flows\nand multi-cuts - the approximation factor being a constant relies on the\nexpanders being constant-hop.",
    "descriptor": "",
    "authors": [
      "Bernhard Haeupler",
      "Jonas Huebotter",
      "Mohsen Ghaffari"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.11726"
  },
  {
    "id": "arXiv:2211.11727",
    "title": "A Simple Parametric Classification Baseline for Generalized Category  Discovery",
    "abstract": "Generalized category discovery (GCD) is a problem setting where the goal is\nto discover novel categories within an unlabelled dataset using the knowledge\nlearned from a set of labelled samples. Recent works in GCD argue that a\nnon-parametric classifier formed using semi-supervised $k$-means can outperform\nstrong baselines which use parametric classifiers as it can alleviate the\nover-fitting to seen categories in the labelled set. In this paper, we revisit\nthe reason that makes previous parametric classifiers fail to recognise new\nclasses for GCD. By investigating the design choices of parametric classifiers\nfrom the perspective of model architecture, representation learning, and\nclassifier learning, we conclude that the less discriminative representations\nand unreliable pseudo-labelling strategy are key factors that make parametric\nclassifiers lag behind non-parametric ones. Motivated by our investigation, we\npresent a simple yet effective parametric classification baseline that\noutperforms the previous best methods by a large margin on multiple popular GCD\nbenchmarks. We hope the investigations and the simple baseline can serve as a\ncornerstone to facilitate future studies. Our code is available at:\nhttps://github.com/CVMI-Lab/SimGCD.",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Xin Wen",
      "Bingchen Zhao",
      "Xiaojuan Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11727"
  },
  {
    "id": "arXiv:2211.11733",
    "title": "Teaching Structured Vision&Language Concepts to Vision&Language Models",
    "abstract": "Vision and Language (VL) models have demonstrated remarkable zero-shot\nperformance in a variety of tasks. However, some aspects of complex language\nunderstanding still remain a challenge. We introduce the collective notion of\nStructured Vision&Language Concepts (SVLC) which includes object attributes,\nrelations, and states which are present in the text and visible in the image.\nRecent studies have shown that even the best VL models struggle with SVLC. A\npossible way of fixing this issue is by collecting dedicated datasets for\nteaching each SVLC type, yet this might be expensive and time-consuming.\nInstead, we propose a more elegant data-driven approach for enhancing VL\nmodels' understanding of SVLCs that makes more effective use of existing VL\npre-training datasets and does not require any additional data. While automatic\nunderstanding of image structure still remains largely unsolved, language\nstructure is much better modeled and understood, allowing for its effective\nutilization in teaching VL models. In this paper, we propose various techniques\nbased on language structure understanding that can be used to manipulate the\ntextual part of off-the-shelf paired VL datasets. VL models trained with the\nupdated data exhibit a significant improvement of up to 15% in their SVLC\nunderstanding with only a mild degradation in their zero-shot capabilities both\nwhen training from scratch or fine-tuning a pre-trained model.",
    "descriptor": "",
    "authors": [
      "Sivan Doveh",
      "Assaf Arbelle",
      "Sivan Harary",
      "Rameswar Panda",
      "Roei Herzig",
      "Eli Schwartz",
      "Donghyun Kim",
      "Raja Giryes",
      "Rogerio Feris",
      "Shimon Ullman",
      "Leonid Karlinsky"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11733"
  },
  {
    "id": "arXiv:2211.11734",
    "title": "PLIKS: A Pseudo-Linear Inverse Kinematic Solver for 3D Human Body  Estimation",
    "abstract": "We consider the problem of reconstructing a 3D mesh of the human body from a\nsingle 2D image as a model-in-the-loop optimization problem. Existing\napproaches often regress the shape, pose, and translation parameters of a\nparametric statistical model assuming a weak-perspective camera. In contrast,\nwe first estimate 2D pixel-aligned vertices in image space and propose PLIKS\n(Pseudo-Linear Inverse Kinematic Solver) to regress the model parameters by\nminimizing a linear least squares problem. PLIKS is a linearized formulation of\nthe parametric SMPL model, which provides an optimal pose and shape solution\nfrom an adequate initialization. Our method is based on analytically\ncalculating an initial pose estimate from the network predicted 3D mesh\nfollowed by PLIKS to obtain an optimal solution for the given constraints. As\nour framework makes use of 2D pixel-aligned maps, it is inherently robust to\npartial occlusion. To demonstrate the performance of the proposed approach, we\npresent quantitative evaluations which confirm that PLIKS achieves more\naccurate reconstruction with greater than 10% improvement compared to other\nstate-of-the-art methods with respect to the standard 3D human pose and shape\nbenchmarks while also obtaining a reconstruction error improvement of 12.9 mm\non the newer AGORA dataset.",
    "descriptor": "",
    "authors": [
      "Karthik Shetty",
      "Annette Birkhold",
      "Srikrishna Jaganathan",
      "Norbert Strobel",
      "Markus Kowarschik",
      "Andreas Maier",
      "Bernhard Egger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11734"
  },
  {
    "id": "arXiv:2211.11736",
    "title": "Robotic Skill Acquisition via Instruction Augmentation with  Vision-Language Models",
    "abstract": "In recent years, much progress has been made in learning robotic manipulation\npolicies that follow natural language instructions. Such methods typically\nlearn from corpora of robot-language data that was either collected with\nspecific tasks in mind or expensively re-labelled by humans with rich language\ndescriptions in hindsight. Recently, large-scale pretrained vision-language\nmodels (VLMs) like CLIP or ViLD have been applied to robotics for learning\nrepresentations and scene descriptors. Can these pretrained models serve as\nautomatic labelers for robot data, effectively importing Internet-scale\nknowledge into existing datasets to make them useful even for tasks that are\nnot reflected in their ground truth annotations? To accomplish this, we\nintroduce Data-driven Instruction Augmentation for Language-conditioned control\n(DIAL): we utilize semi-supervised language labels leveraging the semantic\nunderstanding of CLIP to propagate knowledge onto large datasets of unlabelled\ndemonstration data and then train language-conditioned policies on the\naugmented datasets. This method enables cheaper acquisition of useful language\ndescriptions compared to expensive human labels, allowing for more efficient\nlabel coverage of large-scale datasets. We apply DIAL to a challenging\nreal-world robotic manipulation domain where 96.5% of the 80,000 demonstrations\ndo not contain crowd-sourced language annotations. DIAL enables imitation\nlearning policies to acquire new capabilities and generalize to 60 novel\ninstructions unseen in the original dataset.",
    "descriptor": "",
    "authors": [
      "Ted Xiao",
      "Harris Chan",
      "Pierre Sermanet",
      "Ayzaan Wahid",
      "Anthony Brohan",
      "Karol Hausman",
      "Sergey Levine",
      "Jonathan Tompson"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11736"
  },
  {
    "id": "arXiv:2211.11737",
    "title": "Algorithmic Applications of Hypergraph and Partition Containers",
    "abstract": "We present a general method to convert algorithms into faster algorithms for\nalmost-regular input instances. Informally, an almost-regular input is an input\nin which the maximum degree is larger than the average degree by at most a\nconstant factor. This family of inputs vastly generalizes several families of\ninputs for which we commonly have improved algorithms, including bounded-degree\ninputs and random inputs. It also generalizes families of inputs for which we\ndon't usually have faster algorithms, including regular-inputs of arbitrarily\nhigh degree and very dense inputs. We apply our method to achieve breakthroughs\nin exact algorithms for several central NP-Complete problems including $k$-SAT,\nGraph Coloring, and Maximum Independent Set.\nOur main tool is the first algorithmic application of the relatively new\nHypergraph Container Method (Saxton and Thomason 2015, Balogh, Morris and\nSamotij 2015). This recent breakthrough, which generalizes an earlier version\nfor graphs (Kleitman and Winston 1982, Sapozhenko 2001), has been used\nextensively in recent years in extremal combinatorics. An important component\nof our work is the generalization of (hyper-)graph containers to Partition\nContainers.",
    "descriptor": "",
    "authors": [
      "Or Zamir"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.11737"
  },
  {
    "id": "arXiv:2211.11738",
    "title": "SPARF: Neural Radiance Fields from Sparse and Noisy Poses",
    "abstract": "Neural Radiance Field (NeRF) has recently emerged as a powerful\nrepresentation to synthesize photorealistic novel views. While showing\nimpressive performance, it relies on the availability of dense input views with\nhighly accurate camera poses, thus limiting its application in real-world\nscenarios. In this work, we introduce Sparse Pose Adjusting Radiance Field\n(SPARF), to address the challenge of novel-view synthesis given only few\nwide-baseline input images (as low as 3) with noisy camera poses. Our approach\nexploits multi-view geometry constraints in order to jointly learn the NeRF and\nrefine the camera poses. By relying on pixel matches extracted between the\ninput views, our multi-view correspondence objective enforces the optimized\nscene and camera poses to converge to a global and geometrically accurate\nsolution. Our depth consistency loss further encourages the reconstructed scene\nto be consistent from any viewpoint. Our approach sets a new state of the art\nin the sparse-view regime on multiple challenging datasets.",
    "descriptor": "\nComments: Code will be released upon publication\n",
    "authors": [
      "Prune Truong",
      "Marie-Julie Rakotosaona",
      "Fabian Manhardt",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11738"
  },
  {
    "id": "arXiv:2211.11740",
    "title": "SpeechNet: Weakly Supervised, End-to-End Speech Recognition at  Industrial Scale",
    "abstract": "End-to-end automatic speech recognition systems represent the state of the\nart, but they rely on thousands of hours of manually annotated speech for\ntraining, as well as heavyweight computation for inference. Of course, this\nimpedes commercialization since most companies lack vast human and\ncomputational resources. In this paper, we explore training and deploying an\nASR system in the label-scarce, compute-limited setting. To reduce human labor,\nwe use a third-party ASR system as a weak supervision source, supplemented with\nlabeling functions derived from implicit user feedback. To accelerate\ninference, we propose to route production-time queries across a pool of CUDA\ngraphs of varying input lengths, the distribution of which best matches the\ntraffic's. Compared to our third-party ASR, we achieve a relative improvement\nin word-error rate of 8% and a speedup of 600%. Our system, called SpeechNet,\ncurrently serves 12 million queries per day on our voice-enabled smart\ntelevision. To our knowledge, this is the first time a large-scale,\nWav2vec-based deployment has been described in the academic literature.",
    "descriptor": "\nComments: Accepted to EMNLP 2022 Industry Track; 9 pages, 7 figures\n",
    "authors": [
      "Raphael Tang",
      "Karun Kumar",
      "Gefei Yang",
      "Akshat Pandey",
      "Yajie Mao",
      "Vladislav Belyaev",
      "Madhuri Emmadi",
      "Craig Murray",
      "Ferhan Ture",
      "Jimmy Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.11740"
  },
  {
    "id": "arXiv:2211.11741",
    "title": "Sensor Placement for Online Fault Diagnosis",
    "abstract": "Fault diagnosis is the problem of determining a set of faulty system\ncomponents that explain discrepancies between observed and expected behavior.\nDue to the intrinsic relation between observations and sensors placed on a\nsystem, sensors' fault diagnosis and placement are mutually dependent.\nConsequently, it is imperative to solve the fault diagnosis and sensor\nplacement problems jointly. One approach to modeling systems for fault\ndiagnosis uses answer set programming (ASP). We present a model-based approach\nto sensor placement for active diagnosis using ASP, where the secondary\nobjective is to reduce the number of sensors used. The proposed method finds\nlocations for system sensors with around 500 components in a few minutes. To\naddress larger systems, we propose a notion of modularity such that it is\npossible to treat each module as a separate system and solve the sensor\nplacement problem for each module independently. Additionally, we provide a\nfixpoint algorithm for determining the modules of a system.",
    "descriptor": "",
    "authors": [
      "Dhananjay Raju",
      "Georgios Bakirtzis",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.11741"
  },
  {
    "id": "arXiv:2211.11742",
    "title": "SceneComposer: Any-Level Semantic Image Synthesis",
    "abstract": "We propose a new framework for conditional image synthesis from semantic\nlayouts of any precision levels, ranging from pure text to a 2D semantic canvas\nwith precise shapes. More specifically, the input layout consists of one or\nmore semantic regions with free-form text descriptions and adjustable precision\nlevels, which can be set based on the desired controllability. The framework\nnaturally reduces to text-to-image (T2I) at the lowest level with no shape\ninformation, and it becomes segmentation-to-image (S2I) at the highest level.\nBy supporting the levels in-between, our framework is flexible in assisting\nusers of different drawing expertise and at different stages of their creative\nworkflow. We introduce several novel techniques to address the challenges\ncoming with this new setup, including a pipeline for collecting training data;\na precision-encoded mask pyramid and a text feature map representation to\njointly encode precision level, semantics, and composition information; and a\nmulti-scale guided diffusion model to synthesize images. To evaluate the\nproposed method, we collect a test dataset containing user-drawn layouts with\ndiverse scenes and styles. Experimental results show that the proposed method\ncan generate high-quality images following the layout at given precision, and\ncompares favorably against existing methods. Project page\n\\url{https://zengxianyu.github.io/scenec/}",
    "descriptor": "",
    "authors": [
      "Yu Zeng",
      "Zhe Lin",
      "Jianming Zhang",
      "Qing Liu",
      "John Collomosse",
      "Jason Kuen",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11742"
  },
  {
    "id": "arXiv:2211.11743",
    "title": "SinFusion: Training Diffusion Models on a Single Image or Video",
    "abstract": "Diffusion models exhibited tremendous progress in image and video generation,\nexceeding GANs in quality and diversity. However, they are usually trained on\nvery large datasets and are not naturally adapted to manipulate a given input\nimage or video. In this paper we show how this can be resolved by training a\ndiffusion model on a single input image or video. Our image/video-specific\ndiffusion model (SinFusion) learns the appearance and dynamics of the single\nimage or video, while utilizing the conditioning capabilities of diffusion\nmodels. It can solve a wide array of image/video-specific manipulation tasks.\nIn particular, our model can learn from few frames the motion and dynamics of a\nsingle input video. It can then generate diverse new video samples of the same\ndynamic scene, extrapolate short videos into long ones (both forward and\nbackward in time) and perform video upsampling. When trained on a single image,\nour model shows comparable performance and capabilities to previous\nsingle-image models in various image manipulation tasks.",
    "descriptor": "\nComments: Project Page: this https URL\n",
    "authors": [
      "Yaniv Nikankin",
      "Niv Haim",
      "Michal Irani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11743"
  },
  {
    "id": "arXiv:2211.11744",
    "title": "Visual Dexterity: In-hand Dexterous Manipulation from Depth",
    "abstract": "In-hand object reorientation is necessary for performing many dexterous\nmanipulation tasks, such as tool use in unstructured environments that remain\nbeyond the reach of current robots. Prior works built reorientation systems\nthat assume one or many of the following specific circumstances: reorienting\nonly specific objects with simple shapes, limited range of reorientation, slow\nor quasistatic manipulation, the need for specialized and costly sensor suites,\nsimulation-only results, and other constraints which make the system infeasible\nfor real-world deployment. We overcome these limitations and present a general\nobject reorientation controller that is trained using reinforcement learning in\nsimulation and evaluated in the real world. Our system uses readings from a\nsingle commodity depth camera to dynamically reorient complex objects by any\namount in real time. The controller generalizes to novel objects not used\nduring training. It is successful in the most challenging test: the ability to\nreorient objects in the air held by a downward-facing hand that must counteract\ngravity during reorientation. The results demonstrate that the policy transfer\nfrom simulation to the real world can be accomplished even for dynamic and\ncontact-rich tasks. Lastly, our hardware only uses open-source components that\ncost less than five thousand dollars. Such construction makes it possible to\nreplicate the work and democratize future research in dexterous manipulation.\nVideos are available at:\nhttps://taochenshh.github.io/projects/visual-dexterity.",
    "descriptor": "",
    "authors": [
      "Tao Chen",
      "Megha Tippur",
      "Siyang Wu",
      "Vikash Kumar",
      "Edward Adelson",
      "Pulkit Agrawal"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.11744"
  },
  {
    "id": "arXiv:2211.11746",
    "title": "Last-Mile Embodied Visual Navigation",
    "abstract": "Realistic long-horizon tasks like image-goal navigation involve exploratory\nand exploitative phases. Assigned with an image of the goal, an embodied agent\nmust explore to discover the goal, i.e., search efficiently using learned\npriors. Once the goal is discovered, the agent must accurately calibrate the\nlast-mile of navigation to the goal. As with any robust system, switches\nbetween exploratory goal discovery and exploitative last-mile navigation enable\nbetter recovery from errors. Following these intuitive guide rails, we propose\nSLING to improve the performance of existing image-goal navigation systems.\nEntirely complementing prior methods, we focus on last-mile navigation and\nleverage the underlying geometric structure of the problem with neural\ndescriptors. With simple but effective switches, we can easily connect SLING\nwith heuristic, reinforcement learning, and neural modular policies. On a\nstandardized image-goal navigation benchmark (Hahn et al. 2021), we improve\nperformance across policies, scenes, and episode complexity, raising the\nstate-of-the-art from 45% to 55% success rate. Beyond photorealistic\nsimulation, we conduct real-robot experiments in three physical scenes and find\nthese improvements to transfer well to real environments.",
    "descriptor": "\nComments: Accepted at CoRL 2022. Code and results available at this https URL\n",
    "authors": [
      "Justin Wasserman",
      "Karmesh Yadav",
      "Girish Chowdhary",
      "Abhinav Gupta",
      "Unnat Jain"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.11746"
  },
  {
    "id": "arXiv:1906.07012",
    "title": "Beam Entropy of 5G Cellular Millimetre-Wave Channels",
    "abstract": "In this paper, we obtain and study typical beam entropy values for millimetre\nwave (mm-wave) channel models using the NYUSIM simulator for frequencies up to\n100 GHz for fifth generation (5G) and beyond 5G cellular communication systems.\nThe beam entropy is used to quantify sparse MIMO channel randomness in\nbeamspace. Lower relative beam entropy channels are suitable for\nmemory-assisted statistically-ranked (MarS) and hybrid radio frequency (RF)\nbeam training algorithms. High beam entropies can potentially be advantageous\nfor low overhead secured radio communications by generating cryptographic keys\nbased on channel randomness in beamspace, especially for sparse multiple input\nmultiple output (MIMO) channels. Urban micro (UMi), urban macro (UMa) and rural\nmacro (RMa) cellular scenarios have been investigated in this work for 28, 60,\n73 and 100 GHz.",
    "descriptor": "\nComments: Under peer-review for IEEE VTC Fall 2019\n",
    "authors": [
      "Krishan Kumar Tiwari",
      "Eckhard Grass",
      "John S. Thompson",
      "Rolf Kraemer"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1906.07012"
  },
  {
    "id": "arXiv:2211.10441",
    "title": "Rastreo muscular m\u00f3vil usando magnetomicrometr\u00eda -- traducci\u00f3n al  espa\u00f1ol del articulo \"Untethered Muscle Tracking Using Magnetomicrometry\"  por el autor Cameron R. Taylor",
    "abstract": "Muscle tissue drives nearly all movement in the animal kingdom, providing\npower, mobility, and dexterity. Technologies for measuring muscle tissue\nmotion, such as sonomicrometry, fluoromicrometry, and ultrasound, have\nsignificantly advanced our understanding of biomechanics. Yet, the field lacks\nthe ability to monitor muscle tissue motion for animal behavior outside the\nlab. Towards addressing this issue, we previously introduced magnetomicrometry,\na method that uses magnetic beads to wirelessly monitor muscle tissue length\nchanges, and we validated magnetomicrometry via tightly-controlled in situ\ntesting. In this study we validate the accuracy of magnetomicrometry against\nfluoromicrometry during untethered running in an in vivo turkey model. We\ndemonstrate real-time muscle tissue length tracking of the freely-moving\nturkeys executing various motor activities, including ramp ascent and descent,\nvertical ascent and descent, and free roaming movement. Given the demonstrated\ncapacity of magnetomicrometry to track muscle movement in untethered animals,\nwe feel that this technique will enable new scientific explorations and an\nimproved understanding of muscle function. -- -- El tejido muscular es el motor\nde casi todos los movimientos del reino animal, ya que proporciona fuerza,\nmovilidad y destreza. Las tecnolog\\'ias para medir el movimiento del tejido\nmuscular, como la sonomicrometr\\'ia, la fluoromicrometr\\'ia y el ultrasonido,\nhan avanzado considerablemente la comprensi\\'on de la biomec\\'anica. Sin\nembargo, este campo carece de la capacidad de rastrear el movimiento del tejido\nmuscular en el comportamiento animal fuera del laboratorio. Para abordar este\nproblema, presentamos previamente la magnetomicrometr\\'ia, un m\\'etodo que\nutiliza peque\\~nos imanes para rastrear de forma inal\\'ambrica los cambios de\nlongitud del tejido muscular, y validamos la magnetomicrometr\\'ia mediante\npruebas estrechamente controladas in situ. En este estudio validamos la\nprecisi\\'on de la magnetomicrometr\\'ia en comparaci\\'on con la\nfluoromicrometr\\'ia usando un modelo de pavo in vivo mientras corre libremente.\nDemostramos el rastreo en tiempo real de la longitud del tejido muscular de los\npavos que se mueven libremente ejecutando varias actividades motoras,\nincluyendo el ascenso y el descenso en rampa, el ascenso y el descenso\nvertical, y el movimiento libre. Dada la capacidad demostrada de la\nmagnetomicrometr\\'ia para rastrear el movimiento muscular en animales en un\ncontexto m\\'ovil, creemos que esta t\\'ecnica permitir\\'a nuevas exploraciones\ncient\\'ificas y una mejor comprensi\\'on de la funci\\'on muscular.",
    "descriptor": "\nComments: in Spanish language. Translation of the postprint, with the published version in English appended to the end of the PDF. Shared First Authorship: Cameron R. Taylor and Seong Ho Yeon; Shared Senior and Corresponding Authorship: Thomas J. Roberts and Hugh M. Herr\n",
    "authors": [
      "Cameron R. Taylor",
      "Seong Ho Yeon",
      "William H. Clark",
      "Ellen G. Clarrissimeaux",
      "Mary Kate O'Donnell",
      "Thomas J. Roberts",
      "Hugh M. Herr"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.10441"
  },
  {
    "id": "arXiv:2211.10442",
    "title": "Deep learning methods for drug response prediction in cancer:  predominant and emerging trends",
    "abstract": "Cancer claims millions of lives yearly worldwide. While many therapies have\nbeen made available in recent years, by in large cancer remains unsolved.\nExploiting computational predictive models to study and treat cancer holds\ngreat promise in improving drug development and personalized design of\ntreatment plans, ultimately suppressing tumors, alleviating suffering, and\nprolonging lives of patients. A wave of recent papers demonstrates promising\nresults in predicting cancer response to drug treatments while utilizing deep\nlearning methods. These papers investigate diverse data representations, neural\nnetwork architectures, learning methodologies, and evaluations schemes.\nHowever, deciphering promising predominant and emerging trends is difficult due\nto the variety of explored methods and lack of standardized framework for\ncomparing drug response prediction models. To obtain a comprehensive landscape\nof deep learning methods, we conducted an extensive search and analysis of deep\nlearning models that predict the response to single drug treatments. A total of\n60 deep learning-based models have been curated and summary plots were\ngenerated. Based on the analysis, observable patterns and prevalence of methods\nhave been revealed. This review allows to better understand the current state\nof the field and identify major challenges and promising solution paths.",
    "descriptor": "",
    "authors": [
      "Alexander Partin",
      "Thomas S. Brettin",
      "Yitan Zhu",
      "Oleksandr Narykov",
      "Austin Clyde",
      "Jamie Overbeek",
      "Rick L. Stevens"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10442"
  },
  {
    "id": "arXiv:2211.10444",
    "title": "Neural Fields for Fast and Scalable Interpolation of Geophysical Ocean  Variables",
    "abstract": "Optimal Interpolation (OI) is a widely used, highly trusted algorithm for\ninterpolation and reconstruction problems in geosciences. With the influx of\nmore satellite missions, we have access to more and more observations and it is\nbecoming more pertinent to take advantage of these observations in applications\nsuch as forecasting and reanalysis. With the increase in the volume of\navailable data, scalability remains an issue for standard OI and it prevents\nmany practitioners from effectively and efficiently taking advantage of these\nlarge sums of data to learn the model hyperparameters. In this work, we\nleverage recent advances in Neural Fields (NerFs) as an alternative to the OI\nframework where we show how they can be easily applied to standard\nreconstruction problems in physical oceanography. We illustrate the relevance\nof NerFs for gap-filling of sparse measurements of sea surface height (SSH) via\nsatellite altimetry and demonstrate how NerFs are scalable with comparable\nresults to the standard OI. We find that NerFs are a practical set of methods\nthat can be readily applied to geoscience interpolation problems and we\nanticipate a wider adoption in the future.",
    "descriptor": "\nComments: Machine Learning and the Physical Sciences workshop, NeurIPS 2022\n",
    "authors": [
      "J. Emmanuel Johnson",
      "Redouane Lguensat",
      "Ronan Fablet",
      "Emmanuel Cosme",
      "Julien Le Sommer"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10444"
  },
  {
    "id": "arXiv:2211.10475",
    "title": "Turning Silver into Gold: Domain Adaptation with Noisy Labels for  Wearable Cardio-Respiratory Fitness Prediction",
    "abstract": "Deep learning models have shown great promise in various healthcare\napplications. However, most models are developed and validated on small-scale\ndatasets, as collecting high-quality (gold-standard) labels for health\napplications is often costly and time-consuming. As a result, these models may\nsuffer from overfitting and not generalize well to unseen data. At the same\ntime, an extensive amount of data with imprecise labels (silver-standard) is\nstarting to be generally available, as collected from inexpensive wearables\nlike accelerometers and electrocardiography sensors. These currently\nunderutilized datasets and labels can be leveraged to produce more accurate\nclinical models. In this work, we propose UDAMA, a novel model with two key\ncomponents: Unsupervised Domain Adaptation and Multi-discriminator Adversarial\ntraining, which leverage noisy data from source domain (the silver-standard\ndataset) to improve gold-standard modeling. We validate our framework on the\nchallenging task of predicting lab-measured maximal oxygen consumption\n(VO$_{2}$max), the benchmark metric of cardio-respiratory fitness, using\nfree-living wearable sensor data from two cohort studies as inputs. Our\nexperiments show that the proposed framework achieves the best performance of\ncorr = 0.665 $\\pm$ 0.04, paving the way for accurate fitness estimation at\nscale.",
    "descriptor": "\nComments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 5 pages\n",
    "authors": [
      "Yu Wu",
      "Dimitris Spathis",
      "Hong Jia",
      "Ignacio Perez-Pozuelo",
      "Tomas I. Gonzales",
      "Soren Brage",
      "Nicholas Wareham",
      "Cecilia Mascolo"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10475"
  },
  {
    "id": "arXiv:2211.10502",
    "title": "A Mathematical Programming Approach to Optimal Classification Forests",
    "abstract": "In this paper we propose a novel mathematical optimization based methodology\nto construct classification forests. A given number of trees are simultaneously\nconstructed, each of them providing a predicted class for each of the\nobservations in the training dataset. An observation is then classified to its\nmost frequently predicted class. We give a mixed integer linear programming\nformulation for the problem. We report the results of our computational\nexperiments. Our proposed method outperforms state-of-the-art tree-based\nclassification methods on several standard datasets.",
    "descriptor": "\nComments: 9 pages, 3 figures\n",
    "authors": [
      "V\u00edctor Blanco",
      "Alberto Jap\u00f3n",
      "Justo Puerto",
      "Peter Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10502"
  },
  {
    "id": "arXiv:2211.10508",
    "title": "Distributionally Robust Survival Analysis: A Novel Fairness Loss Without  Demographics",
    "abstract": "We propose a general approach for training survival analysis models that\nminimizes a worst-case error across all subpopulations that are large enough\n(occurring with at least a user-specified minimum probability). This approach\nuses a training loss function that does not know any demographic information to\ntreat as sensitive. Despite this, we demonstrate that our proposed approach\noften scores better on recently established fairness metrics (without a\nsignificant drop in prediction accuracy) compared to various baselines,\nincluding ones which directly use sensitive demographic information in their\ntraining loss. Our code is available at: https://github.com/discovershu/DRO_COX",
    "descriptor": "\nComments: Machine Learning for Health (ML4H 2022)\n",
    "authors": [
      "Shu Hu",
      "George H. Chen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10508"
  },
  {
    "id": "arXiv:2211.10515",
    "title": "Curiosity in hindsight",
    "abstract": "Consider the exploration in sparse-reward or reward-free environments, such\nas Montezuma's Revenge. The curiosity-driven paradigm dictates an intuitive\ntechnique: At each step, the agent is rewarded for how much the realized\noutcome differs from their predicted outcome. However, using predictive error\nas intrinsic motivation is prone to fail in stochastic environments, as the\nagent may become hopelessly drawn to high-entropy areas of the state-action\nspace, such as a noisy TV. Therefore it is important to distinguish between\naspects of world dynamics that are inherently predictable and aspects that are\ninherently unpredictable: The former should constitute a source of intrinsic\nreward, whereas the latter should not. In this work, we study a natural\nsolution derived from structural causal models of the world: Our key idea is to\nlearn representations of the future that capture precisely the unpredictable\naspects of each outcome -- not any more, not any less -- which we use as\nadditional input for predictions, such that intrinsic rewards do vanish in the\nlimit. First, we propose incorporating such hindsight representations into the\nagent's model to disentangle \"noise\" from \"novelty\", yielding Curiosity in\nHindsight: a simple and scalable generalization of curiosity that is robust to\nall types of stochasticity. Second, we implement this framework as a drop-in\nmodification of any prediction-based exploration bonus, and instantiate it for\nthe recently introduced BYOL-Explore algorithm as a prime example, resulting in\nthe noise-robust \"BYOL-Hindsight\". Third, we illustrate its behavior under\nvarious stochasticities in a grid world, and find improvements over\nBYOL-Explore in hard-exploration Atari games with sticky actions. Importantly,\nwe show SOTA results in exploring Montezuma with sticky actions, while\npreserving performance in the non-sticky setting.",
    "descriptor": "",
    "authors": [
      "Daniel Jarrett",
      "Corentin Tallec",
      "Florent Altch\u00e9",
      "Thomas Mesnard",
      "R\u00e9mi Munos",
      "Michal Valko"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10515"
  },
  {
    "id": "arXiv:2211.10525",
    "title": "Differentiable Uncalibrated Imaging",
    "abstract": "We propose a differentiable imaging framework to address uncertainty in\nmeasurement coordinates such as sensor locations and projection angles. We\nformulate the problem as measurement interpolation at unknown nodes supervised\nthrough the forward operator. To solve it we apply implicit neural networks,\nalso known as neural fields, which are naturally differentiable with respect to\nthe input coordinates. We also develop differentiable spline interpolators\nwhich perform as well as neural networks, require less time to optimize and\nhave well-understood properties. Differentiability is key as it allows us to\njointly fit a measurement representation, optimize over the uncertain\nmeasurement coordinates, and perform image reconstruction which in turn ensures\nconsistent calibration. We apply our approach to 2D and 3D computed tomography\nand show that it produces improved reconstructions compared to baselines that\ndo not account for the lack of calibration. The flexibility of the proposed\nframework makes it easy to apply to almost arbitrary imaging problems.",
    "descriptor": "",
    "authors": [
      "Sidharth Gupta",
      "Konik Kothari",
      "Valentin Debarnot",
      "Ivan Dokmani\u0107"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10525"
  },
  {
    "id": "arXiv:2211.10539",
    "title": "Impact of visual assistance for automated audio captioning",
    "abstract": "We study the impact of visual assistance for automated audio captioning.\nUtilizing multi-encoder transformer architectures, which have previously been\nemployed to introduce vision-related information in the context of sound event\ndetection, we analyze the usefulness of incorporating a variety of pretrained\nfeatures.\nWe perform experiments on a YouTube-based audiovisual data set and\ninvestigate the effect of applying the considered transfer learning technique\nin terms of a variety of captioning metrics.\nWe find that only one of the considered kinds of pretrained features provides\nconsistent improvements, while the others do not provide any noteworthy gains\nat all. Interestingly, the outcomes of prior research efforts indicate that the\nexact opposite is true in the case of sound event detection, leading us to\nconclude that the optimal choice of visual embeddings is strongly dependent on\nthe task at hand.\nMore specifically, visual features focusing on semantics appear appropriate\nin the context of automated audio captioning, while for sound event detection,\ntime information seems to be more important.",
    "descriptor": "\nComments: Submitted to 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\n",
    "authors": [
      "Wim Boes",
      "Hugo Van hamme"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.10539"
  },
  {
    "id": "arXiv:2211.10555",
    "title": "Noise-Resilient Quantum Power Flow",
    "abstract": "Quantum power flow (QPF) provides inspiring directions for tackling power\nflow's computational burdens leveraging quantum computing. However, existing\nQPF methods are mainly based on noise-sensitive quantum algorithms, whose\npractical utilization is significantly hindered by the limited capability of\ntoday's noisy-intermediate-scale quantum (NISQ) devices. This paper devises a\nNISQ-QPF algorithm, which enables power flow calculation on noisy quantum\ncomputers. The main contributions include: (1) a variational quantum circuit\n(VQC)-based AC power flow formulation, which enables QPF using short-depth\nquantum circuits; (2) noise-resilient QPF solvers based on the variational\nquantum linear solver (VQLS) and modified fast decoupled power flow; (3) a\npractical NISQ-QPF framework for implementable and reliable power flow analysis\non noisy quantum machines. Promising case studies validate the effectiveness\nand accuracy of NISQ-QPF on IBM's real, noisy quantum devices.",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "Fei Feng",
      "Yifan Zhou",
      "Peng Zhang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.10555"
  },
  {
    "id": "arXiv:2211.10565",
    "title": "Filterbank Learning for Small-Footprint Keyword Spotting Robust to Noise",
    "abstract": "In the context of keyword spotting (KWS), the replacement of handcrafted\nspeech features by learnable features has not yielded superior KWS performance.\nIn this study, we demonstrate that filterbank learning outperforms handcrafted\nspeech features for KWS whenever the number of filterbank channels is severely\ndecreased. Reducing the number of channels might yield certain KWS performance\ndrop, but also a substantial energy consumption reduction, which is key when\ndeploying common always-on KWS on low-resource devices. Experimental results on\na noisy version of the Google Speech Commands Dataset show that filterbank\nlearning adapts to noise characteristics to provide a higher degree of\nrobustness to noise, especially when dropout is integrated. Thus, switching\nfrom typically used 40-channel log-Mel features to 8-channel learned features\nleads to a relative KWS accuracy loss of only 3.5% while simultaneously\nachieving a 6.3x energy consumption reduction.",
    "descriptor": "",
    "authors": [
      "Iv\u00e1n L\u00f3pez-Espejo",
      "Ram C. M. C. Shekar",
      "Zheng-Hua Tan",
      "Jesper Jensen",
      "John H. L. Hansen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.10565"
  },
  {
    "id": "arXiv:2211.10568",
    "title": "Multi-Speaker Expressive Speech Synthesis via Multiple Factors  Decoupling",
    "abstract": "This paper aims to synthesize target speaker's speech with desired speaking\nstyle and emotion by transferring the style and emotion from reference speech\nrecorded by other speakers. Specifically, we address this challenging problem\nwith a two-stage framework composed of a text-to-style-and-emotion (Text2SE)\nmodule and a style-and-emotion-to-wave (SE2Wave) module, bridging by neural\nbottleneck (BN) features. To further solve the multi-factor (speaker timbre,\nspeaking style and emotion) decoupling problem, we adopt the multi-label binary\nvector (MBV) and mutual information (MI) minimization to respectively\ndiscretize the extracted embeddings and disentangle these highly entangled\nfactors in both Text2SE and SE2Wave modules. Moreover, we introduce a\nsemi-supervised training strategy to leverage data from multiple speakers,\nincluding emotion-labelled data, style-labelled data, and unlabeled data. To\nbetter transfer the fine-grained expressiveness from references to the target\nspeaker in the non-parallel transfer, we introduce a reference-candidate pool\nand propose an attention based reference selection approach. Extensive\nexperiments demonstrate the good design of our model.",
    "descriptor": "\nComments: Submitted to ICASSP2023\n",
    "authors": [
      "Xinfa Zhu",
      "Yi Lei",
      "Kun Song",
      "Yongmao Zhang",
      "Tao Li",
      "Lei Xie"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.10568"
  },
  {
    "id": "arXiv:2211.10591",
    "title": "A Stochastic Second-Order Proximal Method for Distributed Optimization",
    "abstract": "In this paper, we propose a distributed stochastic second-order proximal\nmethod that enables agents in a network to cooperatively minimize the sum of\ntheir local loss functions without any centralized coordination. The proposed\nalgorithm, referred to as St-SoPro, incorporates a decentralized second-order\napproximation into an augmented Lagrangian function, and then randomly samples\nthe local gradients and Hessian matrices of the agents, so that it is\ncomputationally and memory-wise efficient, particularly for large-scale\noptimization problems. We show that for globally restricted strongly convex\nproblems, the expected optimality error of St-SoPro asymptotically drops below\nan explicit error bound at a linear rate, and the error bound can be\narbitrarily small with proper parameter settings. Simulations over real machine\nlearning datasets demonstrate that St-SoPro outperforms several\nstate-of-the-art distributed stochastic first-order methods in terms of\nconvergence speed as well as computation and communication costs.",
    "descriptor": "\nComments: 6 pages, 8 figures\n",
    "authors": [
      "Chenyang Qiu",
      "Shanying Zhu",
      "Zichong Ou",
      "Jie Lu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.10591"
  },
  {
    "id": "arXiv:2211.10650",
    "title": "Modified steady discrete unified gas kinetic scheme for multiscale  radiative heat transfer",
    "abstract": "In this work, a steady discrete unified gas kinetic scheme (SDUGKS) is\nproposed to solve the steady radiative transfer equation (RTE), which is an\nimprovement of the original SDUGKS [X. F. Zhou et al., J. Comput. Phys. 423,\n109767 (2020)]. The trapezoidal rule other than the rectangular rule used in\nthe original SDUGKS is adopted in the proposed method in the reconstruction of\nenergy flux across cell interface, just as the unsteady DUGKS. By this way, the\ncharacteristic line length of the modified SDUGKS establishes a relationship\nwith the Courant-Friedrichs-Lewy (CFL) number in the DUGKS, which guarantees\nthe accuracy of the modified SDUGKS. Furthermore, the characteristic line\nlength is no longer limited by the extinction coefficient like in original\nSDUGKS. As a result, the modified SDUGKS is more accurate and robust than\noriginal SDUGKS, and more efficient than the DUGKS for steady radiation\nproblems. Furthermore, the smooth linear interpolation and the van Leer limiter\nare used for problems with smooth and discontinuous optical thicknesses,\nrespectively. Several numerical tests with optical thickness varying from\noptical thin to thick are conducted to validate the present scheme. Numerical\nresults demonstrate that the modified SDUGKS can serve as an effective tool in\nthe study of multiscale steady radiative heat transfer in participating media.",
    "descriptor": "\nComments: 23pages,16 figures,2 tables\n",
    "authors": [
      "Xinliang Song",
      "Yue Zhang",
      "Xiafeng Zhou",
      "Chuang Zhang",
      "Zhaoli Guo"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.10650"
  },
  {
    "id": "arXiv:2211.10669",
    "title": "Littlewood-Richardson coefficients and Kostka number",
    "abstract": "Littlewood-Richardson (LR) coefficients and Kostka Numbers appear in\nrepresentation theory and combinatorics related to GLn . It is known that\nKostka numbers can be represented as special Littlewood-Rischardson\ncoefficient. In this paper, we show how one can represent LR coefficient in\nterms of Kostka numbers, and use the formulation to give a polynomial time\nalgorithm for the same, hence showing that they belong to the same class of\ndecision problems.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Sagar Shrivastava"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Representation Theory (math.RT)"
    ],
    "url": "https://arxiv.org/abs/2211.10669"
  },
  {
    "id": "arXiv:2211.10687",
    "title": "Towards a modeling class for port-Hamiltonian systems with time-delay",
    "abstract": "The framework of port-Hamiltonian (pH) systems is a powerful and broadly\napplicable modeling paradigm. In this paper, we extend the scope of pH systems\nto time-delay systems. Our definition of a delay pH system is motivated by\ninvestigating the Kalman-Yakubovich-Popov inequality on the corresponding\ninfinite-dimensional operator equation. Moreover, we show that delay pH systems\nare passive and closed under interconnection. We describe an explicit way to\nconstruct a Lyapunov-Krasovskii functional and discuss implications for delayed\nfeedback.",
    "descriptor": "",
    "authors": [
      "Tobias Breiten",
      "Dorothea Hinsen",
      "Benjamin Unger"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.10687"
  },
  {
    "id": "arXiv:2211.10690",
    "title": "convoHER2: A Deep Neural Network for Multi-Stage Classification of HER2  Breast Cancer",
    "abstract": "Generally, human epidermal growth factor 2 (HER2) breast cancer is more\naggressive than other kinds of breast cancer. Currently, HER2 breast cancer is\ndetected using expensive medical tests are most expensive. Therefore, the aim\nof this study was to develop a computational model named convoHER2 for\ndetecting HER2 breast cancer with image data using convolution neural network\n(CNN). Hematoxylin and eosin (H&E) and immunohistochemical (IHC) stained images\nhas been used as raw data from the Bayesian information criterion (BIC)\nbenchmark dataset. This dataset consists of 4873 images of H&E and IHC. Among\nall images of the dataset, 3896 and 977 images are applied to train and test\nthe convoHER2 model, respectively. As all the images are in high resolution, we\nresize them so that we can feed them in our convoHER2 model. The cancerous\nsamples images are classified into four classes based on the stage of the\ncancer (0+, 1+, 2+, 3+). The convoHER2 model is able to detect HER2 cancer and\nits grade with accuracy 85% and 88% using H&E images and IHC images,\nrespectively. The outcomes of this study determined that the HER2 cancer\ndetecting rates of the convoHER2 model are much enough to provide better\ndiagnosis to the patient for recovering their HER2 breast cancer in future.",
    "descriptor": "",
    "authors": [
      "M. F. Mridha",
      "Md. Kishor Morol",
      "Md. Asraf Ali",
      "Md Sakib Hossain Shovon"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10690"
  },
  {
    "id": "arXiv:2211.10747",
    "title": "Towards good validation metrics for generative models in offline  model-based optimisation",
    "abstract": "In this work we propose a principled evaluation framework for model-based\noptimisation to measure how well a generative model can extrapolate. We achieve\nthis by interpreting the training and validation splits as draws from their\nrespective `truncated' ground truth distributions, where examples in the\nvalidation set contain scores much larger than those in the training set. Model\nselection is performed on the validation set for some prescribed validation\nmetric. A major research question however is in determining what validation\nmetric correlates best with the expected value of generated candidates with\nrespect to the ground truth oracle; work towards answering this question can\ntranslate to large economic gains since it is expensive to evaluate the ground\ntruth oracle in the real world. We compare various validation metrics for\ngenerative adversarial networks using our framework. We also discuss\nlimitations with our framework with respect to existing datasets and how\nprogress can be made to mitigate them.",
    "descriptor": "",
    "authors": [
      "Christopher Beckham",
      "Alexandre Piche",
      "David Vazquez",
      "Christopher Pal"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10747"
  },
  {
    "id": "arXiv:2211.10748",
    "title": "Delay-aware Backpressure Routing Using Graph Neural Networks",
    "abstract": "We propose a throughput-optimal biased backpressure (BP) algorithm for\nrouting, where the bias is learned through a graph neural network that seeks to\nminimize end-to-end delay. Classical BP routing provides a simple yet powerful\ndistributed solution for resource allocation in wireless multi-hop networks but\nhas poor delay performance. A low-cost approach to improve this delay\nperformance is to favor shorter paths by incorporating pre-defined biases in\nthe BP computation, such as a bias based on the shortest path (hop) distance to\nthe destination. In this work, we improve upon the widely-used metric of hop\ndistance (and its variants) for the shortest path bias by introducing a bias\nbased on the link duty cycle, which we predict using a graph convolutional\nneural network. Numerical results show that our approach can improve the delay\nperformance compared to classical BP and existing BP alternatives based on\npre-defined bias while being adaptive to interference density. In terms of\ncomplexity, our distributed implementation only introduces a one-time overhead\n(linear in the number of devices in the network) compared to classical BP, and\na constant overhead compared to the lowest-complexity existing bias-based BP\nalgorithms.",
    "descriptor": "\nComments: 5 pages, 5 figures, submitted to IEEE ICASSP 2023\n",
    "authors": [
      "Zhongyuan Zhao",
      "Bojan Radojicic",
      "Gunjan Verma",
      "Ananthram Swami",
      "Santiago Segarra"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10748"
  },
  {
    "id": "arXiv:2211.10777",
    "title": "Non-Coherent Over-the-Air Decentralized Stochastic Gradient Descent",
    "abstract": "This paper proposes a Decentralized Stochastic Gradient Descent (DSGD)\nalgorithm to solve distributed machine-learning tasks over wirelessly-connected\nsystems, without the coordination of a base station. It combines local\nstochastic gradient descent steps with a Non-Coherent Over-The-Air (NCOTA)\nconsensus scheme at the receivers, that enables concurrent transmissions by\nleveraging the waveform superposition properties of the wireless channels. With\nNCOTA, local optimization signals are mapped to a mixture of orthogonal\npreamble sequences and transmitted concurrently over the wireless channel under\nhalf-duplex constraints. Consensus is estimated by non-coherently combining the\nreceived signals with the preamble sequences and mitigating the impact of noise\nand fading via a consensus stepsize. NCOTA-DSGD operates without channel state\ninformation (typically used in over-the-air computation schemes for channel\ninversion) and leverages the channel pathloss to mix signals, without explicit\nknowledge of the mixing weights (typically known in consensus-based\noptimization). It is shown that, with a suitable tuning of decreasing consensus\nand learning stepsizes, the error (measured as Euclidean distance) between the\nlocal and globally optimum models vanishes with rate $\\mathcal O(k^{-1/4})$\nafter $k$ iterations. NCOTA-DSGD is evaluated numerically by solving an image\nclassification task on the MNIST dataset, cast as a regularized cross-entropy\nloss minimization. Numerical results depict faster convergence vis-\\`a-vis\nrunning time than implementations of the classical DSGD algorithm over digital\nand analog orthogonal channels, when the number of learning devices is large,\nunder stringent delay constraints.",
    "descriptor": "\nComments: Submitted to the IEEE Transactions on Signal Processing\n",
    "authors": [
      "Nicolo Michelusi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10777"
  },
  {
    "id": "arXiv:2211.10790",
    "title": "Simple and Effective Augmentation Methods for CSI Based Indoor  Localization",
    "abstract": "Indoor localization is a challenging task. There is no robust and\nalmost-universal approach, in contrast to outdoor environments where GPS is\ndominant. Recently, machine learning (ML) has emerged as the most promising\napproach for achieving accurate indoor localization, yet its main challenge is\nthe requirement for large datasets to train the neural networks. The data\ncollection procedure is costly and laborious as the procedure requires\nextensive measurements and labeling processes for different indoor\nenvironments. The situation can be improved by Data Augmentation (DA), which is\na general framework to enlarge the datasets for ML, making ML systems more\nrobust and increases their generalization capabilities. In this paper, we\npropose two simple yet surprisingly effective DA algorithms for channel state\ninformation (CSI) based indoor localization motivated by physical\nconsiderations. We show that the required number of measurements for a given\naccuracy requirement may be decreased by an order of magnitude. Specifically,\nwe demonstrate the algorithms' effectiveness by experiments conducted with a\nmeasured indoor WiFi measurement dataset: as little as 10% of the original\ndataset size is enough to get the same performance of the original dataset. We\nalso showed that, if we further augment the dataset with proposed techniques we\nget better test accuracy more than three-fold.",
    "descriptor": "",
    "authors": [
      "Omer Gokalp Serbetci",
      "Ju-Hyung Lee",
      "Daoud Burghal",
      "Andreas F. Molisch"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10790"
  },
  {
    "id": "arXiv:2211.10798",
    "title": "Input-to-State Stability of a Bilevel Proximal Gradient Descent  Algorithm",
    "abstract": "This paper studies convergence properties of inexact iterative solution\nschemes for bilevel optimization problems. Bilevel optimization problems emerge\nin control-aware design optimization, where the system design parameters are\noptimized in the outer loop and a discrete-time control trajectory is optimized\nin the inner loop, but also arise in other domains including machine learning.\nIn the paper an interconnection of proximal gradient algorithms is proposed to\nsolve the inner loop and outer loop optimization problems in the setting of\ncontrol-aware design optimization and robustness is analyzed from a\ncontrol-theoretic perspective. By employing input-to-state stability arguments,\nconditions are derived that ensure convergence of the interconnected scheme to\nthe optimal solution for a class of the bilevel optimization problem.",
    "descriptor": "\nComments: Submitted to 2023 IFAC World Congress\n",
    "authors": [
      "Torbj\u00f8rn Cunis Ilya Kolmanovsky"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.10798"
  },
  {
    "id": "arXiv:2211.10805",
    "title": "On the Pointwise Behavior of Recursive Partitioning and Its Implications  for Heterogeneous Causal Effect Estimation",
    "abstract": "Decision tree learning is increasingly being used for pointwise inference.\nImportant applications include causal heterogenous treatment effects and\ndynamic policy decisions, as well as conditional quantile regression and design\nof experiments, where tree estimation and inference is conducted at specific\nvalues of the covariates. In this paper, we call into question the use of\ndecision trees (trained by adaptive recursive partitioning) for such purposes\nby demonstrating that they can fail to achieve polynomial rates of convergence\nin uniform norm, even with pruning. Instead, the convergence may be\npoly-logarithmic or, in some important special cases, such as honest regression\ntrees, fail completely. We show that random forests can remedy the situation,\nturning poor performing trees into nearly optimal procedures, at the cost of\nlosing interpretability and introducing two additional tuning parameters. The\ntwo hallmarks of random forests, subsampling and the random feature selection\nmechanism, are seen to each distinctively contribute to achieving nearly\noptimal performance for the model class considered.",
    "descriptor": "",
    "authors": [
      "Mattias D. Cattaneo",
      "Jason M. Klusowski",
      "Peter M. Tian"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2211.10805"
  },
  {
    "id": "arXiv:2211.10853",
    "title": "Demon in the machine: learning to extract work and absorb entropy from  fluctuating nanosystems",
    "abstract": "We use Monte Carlo and genetic algorithms to train neural-network\nfeedback-control protocols for simulated fluctuating nanosystems. These\nprotocols convert the information obtained by the feedback process into heat or\nwork, allowing the extraction of work from a colloidal particle pulled by an\noptical trap and the absorption of entropy by an Ising model undergoing\nmagnetization reversal. The learning framework requires no prior knowledge of\nthe system, depends only upon measurements that are accessible experimentally,\nand scales to systems of considerable complexity. It could be used in the\nlaboratory to learn protocols for fluctuating nanosystems that convert\nmeasurement information into stored work or heat.",
    "descriptor": "",
    "authors": [
      "Stephen Whitelam"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.10853"
  },
  {
    "id": "arXiv:2211.10884",
    "title": "Multi-scale Digital Twin: Developing a fast and physics-informed  surrogate model for groundwater contamination with uncertain climate models",
    "abstract": "Soil and groundwater contamination is a pervasive problem at thousands of\nlocations across the world. Contaminated sites often require decades to\nremediate or to monitor natural attenuation. Climate change exacerbates the\nlong-term site management problem because extreme precipitation and/or shifts\nin precipitation/evapotranspiration regimes could re-mobilize contaminants and\nproliferate affected groundwater. To quickly assess the spatiotemporal\nvariations of groundwater contamination under uncertain climate disturbances,\nwe developed a physics-informed machine learning surrogate model using U-Net\nenhanced Fourier Neural Operator (U-FNO) to solve Partial Differential\nEquations (PDEs) of groundwater flow and transport simulations at the site\nscale.We develop a combined loss function that includes both data-driven\nfactors and physical boundary constraints at multiple spatiotemporal scales.\nOur U-FNOs can reliably predict the spatiotemporal variations of groundwater\nflow and contaminant transport properties from 1954 to 2100 with realistic\nclimate projections. In parallel, we develop a convolutional autoencoder\ncombined with online clustering to reduce the dimensionality of the vast\nhistorical and projected climate data by quantifying climatic region\nsimilarities across the United States. The ML-based unique climate clusters\nprovide climate projections for the surrogate modeling and help return reliable\nfuture recharge rate projections immediately without querying large climate\ndatasets. In all, this Multi-scale Digital Twin work can advance the field of\nenvironmental remediation under climate change.",
    "descriptor": "\nComments: 5 pages, 2 figures, 1 table, Machine Learning and the Physical Sciences workshop, NeurIPS 2022\n",
    "authors": [
      "Lijing Wang",
      "Takuya Kurihana",
      "Aurelien Meray",
      "Ilijana Mastilovic",
      "Satyarth Praveen",
      "Zexuan Xu",
      "Milad Memarzadeh",
      "Alexander Lavin",
      "Haruko Wainwright"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10884"
  },
  {
    "id": "arXiv:2211.10942",
    "title": "On the convergence analysis of DCA",
    "abstract": "In this paper, we propose a clean and general proof framework to establish\nthe convergence analysis of the Difference-of-Convex (DC) programming algorithm\n(DCA) for both standard DC program and convex constrained DC program. We first\ndiscuss suitable assumptions for the well-definiteness of DCA. Then, we focus\non the convergence analysis of DCA, in particular, the global convergence of\nthe sequence $\\{x^k\\}$ generated by DCA under the Lojasiewicz subgradient\ninequality and the Kurdyka-Lojasiewicz property respectively. Moreover, the\nconvergence rate for the sequences $\\{f(x^k)\\}$ and $\\{\\|x^k-x^*\\|\\}$ are also\ninvestigated. We hope that the proof framework presented in this article will\nbe a useful tool to conveniently establish the convergence analysis for many\nvariants of DCA and new DCA-type algorithms.",
    "descriptor": "",
    "authors": [
      "Yi-Shuai Niu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.10942"
  },
  {
    "id": "arXiv:2211.10965",
    "title": "Persistence of the Omicron variant of SARS-CoV-2 in Australia: The  impact of fluctuating social distancing",
    "abstract": "We modelled emergence and spread of the Omicron variant of SARS-CoV-2 in\nAustralia between December 2021 and June 2022. This pandemic stage exhibited a\ndiverse epidemiological profile with emergence of co-circulating sub-lineages\nof Omicron, further complicated by differences in social distancing behaviour\nwhich varied over time. Our study delineated distinct phases of the\nOmicron-associated pandemic stage, and retrospectively quantified the adoption\nof social distancing measures, fluctuating over different time periods in\nresponse to the observable incidence dynamics. We also modelled the\ncorresponding disease burden, in terms of hospitalisations, intensive care unit\noccupancy, and mortality. Supported by good agreement between simulated and\nactual health data, our study revealed that the nonlinear dynamics observed in\nthe daily incidence and disease burden were determined not only by introduction\nof sub-lineages of Omicron, but also by the fluctuating adoption of social\ndistancing measures. Our high-resolution model can be used in design and\nevaluation of public health interventions during future crises.",
    "descriptor": "\nComments: 30 pages, 12 figures, source code: this https URL\n",
    "authors": [
      "Sheryl L. Chang",
      "Quang Dang Nguyen",
      "Alexandra Martiniuk",
      "Vitali Sintchenko",
      "Tania C. Sorrell",
      "Mikhail Prokopenko"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.10965"
  },
  {
    "id": "arXiv:2211.10968",
    "title": "Statistical Optimality of Divide and Conquer Kernel-based Functional  Linear Regression",
    "abstract": "Previous analysis of regularized functional linear regression in a\nreproducing kernel Hilbert space (RKHS) typically requires the target function\nto be contained in this kernel space. This paper studies the convergence\nperformance of divide-and-conquer estimators in the scenario that the target\nfunction does not necessarily reside in the underlying RKHS. As a\ndecomposition-based scalable approach, the divide-and-conquer estimators of\nfunctional linear regression can substantially reduce the algorithmic\ncomplexities in time and memory. We develop an integral operator approach to\nestablish sharp finite sample upper bounds for prediction with\ndivide-and-conquer estimators under various regularity conditions of\nexplanatory variables and target function. We also prove the asymptotic\noptimality of the derived rates by building the mini-max lower bounds. Finally,\nwe consider the convergence of noiseless estimators and show that the rates can\nbe arbitrarily fast under mild conditions.",
    "descriptor": "",
    "authors": [
      "Jiading Liu",
      "Lei Shi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10968"
  },
  {
    "id": "arXiv:2211.10976",
    "title": "Federated deep transfer learning for EEG decoding using multiple BCI  tasks",
    "abstract": "Deep learning has been successful in BCI decoding. However, it is very\ndata-hungry and requires pooling data from multiple sources. EEG data from\nvarious sources decrease the decoding performance due to negative transfer.\nRecently, transfer learning for EEG decoding has been suggested as a remedy and\nbecome subject to recent BCI competitions (e.g. BEETL), but there are two\ncomplications in combining data from many subjects. First, privacy is not\nprotected as highly personal brain data needs to be shared (and copied across\nincreasingly tight information governance boundaries). Moreover, BCI data are\ncollected from different sources and are often based on different BCI tasks,\nwhich has been thought to limit their reusability. Here, we demonstrate a\nfederated deep transfer learning technique, the Multi-dataset Federated\nSeparate-Common-Separate Network (MF-SCSN) based on our previous work of SCSN,\nwhich integrates privacy-preserving properties into deep transfer learning to\nutilise data sets with different tasks. This framework trains a BCI decoder\nusing different source data sets obtained from different imagery tasks (e.g.\nsome data sets with hands and feet, vs others with single hands and tongue,\netc). Therefore, by introducing privacy-preserving transfer learning\ntechniques, we unlock the reusability and scalability of existing BCI data\nsets. We evaluated our federated transfer learning method on the NeurIPS 2021\nBEETL competition BCI task. The proposed architecture outperformed the baseline\ndecoder by 3%. Moreover, compared with the baseline and other transfer learning\nalgorithms, our method protects the privacy of the brain data from different\ndata centres.",
    "descriptor": "\nComments: 4 pages, 3 figures\n",
    "authors": [
      "Xiaoxi Wei",
      "A. Aldo Faisal"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10976"
  },
  {
    "id": "arXiv:2211.10984",
    "title": "DAQE: Enhancing the Quality of Compressed Images by Finding the Secret  of Defocus",
    "abstract": "Image defocus is inherent in the physics of image formation caused by the\noptical aberration of lenses, providing plentiful information on image quality.\nUnfortunately, the existing quality enhancement approaches for compressed\nimages neglect the inherent characteristic of defocus, resulting in inferior\nperformance. This paper finds that in compressed images, the significantly\ndefocused regions are with better compression quality and two regions with\ndifferent defocus values possess diverse texture patterns. These findings\nmotivate our defocus-aware quality enhancement (DAQE) approach. Specifically,\nwe propose a novel dynamic region-based deep learning architecture of the DAQE\napproach, which considers the region-wise defocus difference of compressed\nimages in two aspects. (1) The DAQE approach employs fewer computational\nresources to enhance the quality of significantly defocused regions, while more\nresources on enhancing the quality of other regions; (2) The DAQE approach\nlearns to separately enhance diverse texture patterns for the regions with\ndifferent defocus values, such that texture-wise one-on-one enhancement can be\nachieved. Extensive experiments validate the superiority of our DAQE approach\nin terms of quality enhancement and resource-saving, compared with other\nstate-of-the-art approaches.",
    "descriptor": "",
    "authors": [
      "Qunliang Xing",
      "Mai Xu",
      "Xin Deng",
      "Yichen Guo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10984"
  },
  {
    "id": "arXiv:2211.11003",
    "title": "Unadjusted Hamiltonian MCMC with Stratified Monte Carlo Time Integration",
    "abstract": "A novel unadjusted Hamiltonian Monte Carlo (uHMC) algorithm is suggested that\nuses a stratified Monte Carlo (SMC) time integrator for the underlying\nHamiltonian dynamics in place of the usual Verlet time integrator. For target\ndistributions of the form $\\mu(dx) \\propto e^{-U(x)} dx$ where $U: \\mathbb{R}^d\n\\to \\mathbb{R}_{\\ge 0}$ is both $K$-strongly convex and $L$-gradient Lipschitz,\nand initial distributions $\\nu$ with finite second moment, coupling proofs\nreveal that an $\\varepsilon$-accurate approximation of the target distribution\n$\\mu$ in $L^2$-Wasserstein distance $\\boldsymbol{\\mathcal{W}}^2$ can be\nachieved by the uHMC algorithm with SMC time integration using\n$O\\left((d/K)^{1/3} (L/K)^{5/3} \\varepsilon^{-2/3} \\log(\n\\boldsymbol{\\mathcal{W}}^2(\\mu, \\nu) / \\varepsilon)^+\\right)$ gradient\nevaluations; whereas without any additional assumptions the corresponding\ncomplexity of the uHMC algorithm with Verlet time integration is in general\n$O\\left((d/K)^{1/2} (L/K)^2 \\varepsilon^{-1} \\log(\n\\boldsymbol{\\mathcal{W}}^2(\\mu, \\nu) / \\varepsilon)^+ \\right)$. The SMC time\nintegrator involves a minor modification to Verlet, and hence, is easy to\nimplement.",
    "descriptor": "\nComments: 25 pages, 2 figures\n",
    "authors": [
      "Nawaf Bou-Rabee",
      "Milo Marsden"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.11003"
  },
  {
    "id": "arXiv:2211.11025",
    "title": "Self-supervised iRegNet for the Registration of Longitudinal Brain MRI  of Diffuse Glioma Patients",
    "abstract": "Reliable and accurate registration of patient-specific brain magnetic\nresonance imaging (MRI) scans containing pathologies is challenging due to\ntissue appearance changes. This paper describes our contribution to the\nRegistration of the longitudinal brain MRI task of the Brain Tumor Sequence\nRegistration Challenge 2022 (BraTS-Reg 2022). We developed an enhanced\nunsupervised learning-based method that extends the iRegNet. In particular,\nincorporating an unsupervised learning-based paradigm as well as several minor\nmodifications to the network pipeline, allows the enhanced iRegNet method to\nachieve respectable results. Experimental findings show that the enhanced\nself-supervised model is able to improve the initial mean median registration\nabsolute error (MAE) from 8.20 (7.62) mm to the lowest value of 3.51 (3.50) for\nthe training set while achieving an MAE of 2.93 (1.63) mm for the validation\nset. Additional qualitative validation of this study was conducted through\noverlaying pre-post MRI pairs before and after the de-formable registration.\nThe proposed method scored 5th place during the testing phase of the MICCAI\nBraTS-Reg 2022 challenge. The docker image to reproduce our BraTS-Reg\nsubmission results will be publicly available.",
    "descriptor": "\nComments: Accepted in the MICCAI BraTS-Reg 2022 Challenge (as part of the BrainLes workshop proceedings distributed by Springer LNCS)\n",
    "authors": [
      "Ramy A. Zeineldin",
      "Mohamed E. Karar",
      "Franziska Mathis-Ullrich",
      "Oliver Burgert"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11025"
  },
  {
    "id": "arXiv:2211.11028",
    "title": "Algorithmic Decision-Making Safeguarded by Human Knowledge",
    "abstract": "Commercial AI solutions provide analysts and managers with data-driven\nbusiness intelligence for a wide range of decisions, such as demand forecasting\nand pricing. However, human analysts may have their own insights and\nexperiences about the decision-making that is at odds with the algorithmic\nrecommendation. In view of such a conflict, we provide a general analytical\nframework to study the augmentation of algorithmic decisions with human\nknowledge: the analyst uses the knowledge to set a guardrail by which the\nalgorithmic decision is clipped if the algorithmic output is out of bound, and\nseems unreasonable. We study the conditions under which the augmentation is\nbeneficial relative to the raw algorithmic decision. We show that when the\nalgorithmic decision is asymptotically optimal with large data, the\nnon-data-driven human guardrail usually provides no benefit. However, we point\nout three common pitfalls of the algorithmic decision: (1) lack of domain\nknowledge, such as the market competition, (2) model misspecification, and (3)\ndata contamination. In these cases, even with sufficient data, the augmentation\nfrom human knowledge can still improve the performance of the algorithmic\ndecision.",
    "descriptor": "",
    "authors": [
      "Ningyuan Chen",
      "Ming Hu",
      "Wenhao Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11028"
  },
  {
    "id": "arXiv:2211.11043",
    "title": "Revealing Robust Oil and Gas Company Macro-Strategies using Deep  Multi-Agent Reinforcement Learning",
    "abstract": "The energy transition potentially poses an existential risk for major\ninternational oil companies (IOCs) if they fail to adapt to low-carbon business\nmodels. Projections of energy futures, however, are met with diverging\nassumptions on its scale and pace, causing disagreement among IOC\ndecision-makers and their stakeholders over what the business model of an\nincumbent fossil fuel company should be. In this work, we used deep multi-agent\nreinforcement learning to solve an energy systems wargame wherein players\nsimulate IOC decision-making, including hydrocarbon and low-carbon investments\ndecisions, dividend policies, and capital structure measures, through an\nuncertain energy transition to explore critical and non-linear governance\nquestions, from leveraged transitions to reserve replacements. Adversarial play\nfacilitated by state-of-the-art algorithms revealed decision-making strategies\nrobust to energy transition uncertainty and against multiple IOCs. In all\ngames, robust strategies emerged in the form of low-carbon business models as a\nresult of early transition-oriented movement. IOCs adopting such strategies\noutperformed business-as-usual and delayed transition strategies regardless of\nhydrocarbon demand projections. In addition to maximizing value, these\nstrategies benefit greater society by contributing substantial amounts of\ncapital necessary to accelerate the global low-carbon energy transition. Our\nfindings point towards the need for lenders and investors to effectively\nmobilize transition-oriented finance and engage with IOCs to ensure responsible\nreallocation of capital towards low-carbon business models that would enable\nthe emergence of fossil fuel incumbents as future low-carbon leaders.",
    "descriptor": "",
    "authors": [
      "Dylan Radovic",
      "Lucas Kruitwagen",
      "Christian Schroeder de Witt",
      "Ben Caldecott",
      "Shane Tomlinson",
      "Mark Workman"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11043"
  },
  {
    "id": "arXiv:2211.11058",
    "title": "Convolutional Filtering on Sampled Manifolds",
    "abstract": "The increasing availability of geometric data has motivated the need for\ninformation processing over non-Euclidean domains modeled as manifolds. The\nbuilding block for information processing architectures with desirable\ntheoretical properties such as invariance and stability is convolutional\nfiltering. Manifold convolutional filters are defined from the manifold\ndiffusion sequence, constructed by successive applications of the\nLaplace-Beltrami operator to manifold signals. However, the continuous manifold\nmodel can only be accessed by sampling discrete points and building an\napproximate graph model from the sampled manifold. Effective linear information\nprocessing on the manifold requires quantifying the error incurred when\napproximating manifold convolutions with graph convolutions. In this paper, we\nderive a non-asymptotic error bound for this approximation, showing that\nconvolutional filtering on the sampled manifold converges to continuous\nmanifold filtering. Our findings are further demonstrated empirically on a\nproblem of navigation control.",
    "descriptor": "\nComments: 7 pages, 4 figures, submitted to ICASSP 2023\n",
    "authors": [
      "Zhiyang Wang",
      "Luana Ruiz",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11058"
  },
  {
    "id": "arXiv:2211.11060",
    "title": "Simultaneously Learning Robust Audio Embeddings and balanced Hash codes  for Query-by-Example",
    "abstract": "Audio fingerprinting systems must efficiently and robustly identify query\nsnippets in an extensive database. To this end, state-of-the-art systems use\ndeep learning to generate compact audio fingerprints. These systems deploy\nindexing methods, which quantize fingerprints to hash codes in an unsupervised\nmanner to expedite the search. However, these methods generate imbalanced hash\ncodes, leading to their suboptimal performance. Therefore, we propose a\nself-supervised learning framework to compute fingerprints and balanced hash\ncodes in an end-to-end manner to achieve both fast and accurate retrieval\nperformance. We model hash codes as a balanced clustering process, which we\nregard as an instance of the optimal transport problem. Experimental results\nindicate that the proposed approach improves retrieval efficiency while\npreserving high accuracy, particularly at high distortion levels, compared to\nthe competing methods. Moreover, our system is efficient and scalable in\ncomputational load and memory storage.",
    "descriptor": "\nComments: Submitted to ICASSP2023\n",
    "authors": [
      "Anup Singh",
      "Kris Demuynck",
      "Vipul Arora"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.11060"
  },
  {
    "id": "arXiv:2211.11103",
    "title": "Approximate Uncertainty Propagation for Continuous Gaussian Process  Dynamical Systems",
    "abstract": "When learning continuous dynamical systems with Gaussian Processes, computing\ntrajectories requires repeatedly mapping the distributions of uncertain states\nthrough the distribution of learned nonlinear functions, which is generally\nintractable. Since sampling-based approaches are computationally expensive, we\nconsider approximations of the output and trajectory distributions. We show\nthat existing methods make an incorrect implicit independence assumption and\nunderestimate the model-induced uncertainty. We propose a piecewise linear\napproximation of the GP model yielding a class of numerical solvers for\nefficient uncertainty estimates matching sampling-based methods.",
    "descriptor": "\nComments: 9 Pages, 4 Figures\n",
    "authors": [
      "Steffen Ridderbusch",
      "Sina Ober-Bl\u00f6baum",
      "Paul Goulart"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.11103"
  },
  {
    "id": "arXiv:2211.11144",
    "title": "Coarse-Super-Resolution-Fine Network (CoSF-Net): A Unified End-to-End  Neural Network for 4D-MRI with Simultaneous Motion Estimation and  Super-Resolution",
    "abstract": "Four-dimensional magnetic resonance imaging (4D-MRI) is an emerging technique\nfor tumor motion management in image-guided radiation therapy (IGRT). However,\ncurrent 4D-MRI suffers from low spatial resolution and strong motion artifacts\nowing to the long acquisition time and patients' respiratory variations; these\nlimitations, if not managed properly, can adversely affect treatment planning\nand delivery in IGRT. Herein, we developed a novel deep learning framework\ncalled the coarse-super-resolution-fine network (CoSF-Net) to achieve\nsimultaneous motion estimation and super-resolution in a unified model. We\ndesigned CoSF-Net by fully excavating the inherent properties of 4D-MRI, with\nconsideration of limited and imperfectly matched training datasets. We\nconducted extensive experiments on multiple real patient datasets to verify the\nfeasibility and robustness of the developed network. Compared with existing\nnetworks and three state-of-the-art conventional algorithms, CoSF-Net not only\naccurately estimated the deformable vector fields between the respiratory\nphases of 4D-MRI but also simultaneously improved the spatial resolution of\n4D-MRI with enhanced anatomic features, yielding 4D-MR images with high\nspatiotemporal resolution.",
    "descriptor": "",
    "authors": [
      "Shaohua Zhi",
      "Yinghui Wang",
      "Haonan Xiao",
      "Ti Bai",
      "Hong Ge",
      "Bing Li",
      "Chenyang Liu",
      "Wen Li",
      "Tian Li",
      "Jing Cai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11144"
  },
  {
    "id": "arXiv:2211.11170",
    "title": "The loss of the property of locality of the kernel in high-dimensional  Gaussian process regression on the example of the fitting of molecular  potential energy surfaces",
    "abstract": "Kernel based methods including Gaussian process regression (GPR) and\ngenerally kernel ridge regression (KRR) have been finding increasing use in\ncomputational chemistry, including the fitting of potential energy surfaces and\ndensity functionals in high-dimensional feature spaces. Kernels of the Matern\nfamily such as Gaussian-like kernels (basis functions) are often used, which\nallows imparting them the meaning of covariance functions and formulating GPR\nas an estimator of the mean of a Gaussian distribution. The notion of locality\nof the kernel is critical for this interpretation. It is also critical to the\nformulation of multi-zeta type basis functions widely used in computational\nchemistry We show, on the example of fitting of molecular potential energy\nsurfaces of increasing dimensionality, the practical disappearance of the\nproperty of locality of a Gaussian-like kernel in high dimensionality. We also\nformulate a multi-zeta approach to the kernel and show that it significantly\nimproves the quality of regression in low dimensionality but loses any\nadvantage in high dimensionality, which is attributed to the loss of the\nproperty of locality.",
    "descriptor": "",
    "authors": [
      "Sergei Manzhos",
      "Manabu Ihara"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.11170"
  },
  {
    "id": "arXiv:2211.11184",
    "title": "Limit distribution theory for $f$-Divergences",
    "abstract": "$f$-divergences, which quantify discrepancy between probability\ndistributions, are ubiquitous in information theory, machine learning, and\nstatistics. While there are numerous methods for estimating $f$-divergences\nfrom data, a limit distribution theory, which quantifies fluctuations of the\nestimation error, is largely obscure. As limit theorems are pivotal for valid\nstatistical inference, to close this gap, we develop a general methodology for\nderiving distributional limits for $f$-divergences based on the functional\ndelta method and Hadamard directional differentiability. Focusing on four\nprominent $f$-divergences -- Kullback-Leibler divergence, $\\chi^2$ divergence,\nsquared Hellinger distance, and total variation distance -- we identify\nsufficient conditions on the population distributions for the existence of\ndistributional limits and characterize the limiting variables. These results\nare used to derive one- and two-sample limit theorems for Gaussian-smoothed\n$f$-divergences, both under the null and the alternative. Finally, an\napplication of the limit distribution theory to auditing differential privacy\nis proposed and analyzed for significance level and power against local\nalternatives.",
    "descriptor": "",
    "authors": [
      "Sreejith Sreekumar",
      "Ziv Goldfeld",
      "Kengo Kato"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.11184"
  },
  {
    "id": "arXiv:2211.11194",
    "title": "Some Numerical Simulations Based on Dacorogna Example Functions in Favor  of Morrey Conjecture",
    "abstract": "Morrey Conjecture deals with two properties of functions which are known as\nquasi-convexity and rank-one convexity. It is well established that every\nfunction satisfying the quasi-convexity property also satisfies rank-one\nconvexity. Morrey (1952) conjectured that the reversed implication will not\nalways hold. In 1992, Vladimir Sverak found a counterexample to prove that\nMorrey Conjecture is true in three dimensional case. The planar case remains,\nhowever, open and interesting because of its connections to complex analysis,\nharmonic analysis, geometric function theory, probability, martingales,\ndifferential inclusions and planar non-linear elasticity. Checking analytically\nthese notions is a very difficult task as the quasi-convexity criterion is of\nnon-local type, especially for vector-valued functions. That's why we perform\nsome numerical simulations based on a gradient descent algorithm using\nDacorogna and Marcellini example functions. Our numerical results indicate that\nMorrey Conjecture holds true.",
    "descriptor": "",
    "authors": [
      "Xinghao Dong",
      "Koffi Enakoutsa"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.11194"
  },
  {
    "id": "arXiv:2211.11204",
    "title": "Sharpened Uncertainty Principle",
    "abstract": "For any finite group $G$, any finite $G$-set $X$ and any field $F$, we\nconsider the vector space $F^X$ of all functions from $X$ to $F$. When $FG$ is\nsemisimple and splitting, we find a specific basis $\\widehat X$ of $F^X$,\nconstruct the Fourier transform: $F^X\\to F^{\\widehat X}$, $f\\mapsto\\widehat f$,\nand define the rank support $\\mbox{rk-supp}(\\widehat f)$; we prove that\n$\\mbox{rk-supp}(\\widehat f)=\\dim FGf$, where $FGf$ is the submodule of the\npermutation module $FX$ generated by the element $f=\\sum_{x\\in X}f(x)x$. Next,\nextending a sharpened uncertainty principle for abelian finite groups by Feng,\nHollmann, and Xiang [9] to the above extensive framework, for any field $F$,\nany transitive $G$-set $X$ and $0\\neq f\\in F^X$ we prove that: $$\n|{\\rm supp}(f)|\\cdot \\dim FGf \\geq |X|+|{\\rm supp}(f)|-|X_{{\\rm supp}(f)}|,\n$$ where ${\\rm supp}(f)$ is the support of $f$, and $X_{{\\rm supp}(f)}$ is a\nblock of $X$ associated with the subset ${\\rm supp}(f)$ such that ${\\rm\nsupp}(f)$ is a disjoint union of some translations of it. Then many (sharpened\nor classical) versions of finite-dimensional uncertainty principle are derived\nas corollaries.",
    "descriptor": "",
    "authors": [
      "Yun Fan"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.11204"
  },
  {
    "id": "arXiv:2211.11214",
    "title": "DiffBP: Generative Diffusion of 3D Molecules for Target Protein Binding",
    "abstract": "Generating molecules that bind to specific proteins is an important but\nchallenging task in drug discovery. Previous works usually generate atoms in an\nauto-regressive way, where element types and 3D coordinates of atoms are\ngenerated one by one. However, in real-world molecular systems, the\ninteractions among atoms in an entire molecule are global, leading to the\nenergy function pair-coupled among atoms. With such energy-based consideration,\nthe modeling of probability should be based on joint distributions, rather than\nsequentially conditional ones. Thus, the unnatural sequentially auto-regressive\nmodeling of molecule generation is likely to violate the physical rules, thus\nresulting in poor properties of the generated molecules. In this work, a\ngenerative diffusion model for molecular 3D structures based on target proteins\nas contextual constraints is established, at a full-atom level in a\nnon-autoregressive way. Given a designated 3D protein binding site, our model\nlearns the generative process that denoises both element types and 3D\ncoordinates of an entire molecule, with an equivariant network. Experimentally,\nthe proposed method shows competitive performance compared with prevailing\nworks in terms of high affinity with proteins and appropriate molecule sizes as\nwell as other drug properties such as drug-likeness of the generated molecules.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Haitao Lin",
      "Yufei Huang",
      "Meng Liu",
      "Xuanjing Li",
      "Shuiwang Ji",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11214"
  },
  {
    "id": "arXiv:2211.11222",
    "title": "Embedding a Differentiable Mel-cepstral Synthesis Filter to a Neural  Speech Synthesis System",
    "abstract": "This paper integrates a classic mel-cepstral synthesis filter into a modern\nneural speech synthesis system towards end-to-end controllable speech\nsynthesis. Since the mel-cepstral synthesis filter is explicitly embedded in\nneural waveform models in the proposed system, both voice characteristics and\nthe pitch of synthesized speech are highly controlled via a frequency warping\nparameter and fundamental frequency, respectively. We implement the\nmel-cepstral synthesis filter as a differentiable and GPU-friendly module to\nenable the acoustic and waveform models in the proposed system to be\nsimultaneously optimized in an end-to-end manner. Experiments show that the\nproposed system improves speech quality from a baseline system maintaining\ncontrollability. The core PyTorch modules used in the experiments will be\npublicly available on GitHub.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Takenori Yoshimura",
      "Shinji Takaki",
      "Kazuhiro Nakamura",
      "Keiichiro Oura",
      "Yukiya Hono",
      "Kei Hashimoto",
      "Yoshihiko Nankaku",
      "Keiichi Tokuda"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.11222"
  },
  {
    "id": "arXiv:2211.11258",
    "title": "Feedback Design for Devising Optimal Epidemic Control Policies",
    "abstract": "For reliable epidemic monitoring and control, this paper proposes a feedback\nmechanism design to effectively cope with data and model uncertainties. Using\npast epidemiological data, we describe methods to estimate the parameters of\ngeneral epidemic models. Because the data could be noisy, the estimated\nparameters may not be accurate. Therefore, under uncertain parameters and noisy\nmeasurements, we provide an observer design method for robust state estimation.\nThen, using the estimated model and state, we devise optimal control policies\nby minimizing a predicted cost functional. Finally, the effectiveness of the\nproposed method is demonstrated through its implementation on a modified SIR\nepidemic model.",
    "descriptor": "",
    "authors": [
      "Muhammad Umar B. Niazi",
      "Philip E. Par\u00e9",
      "Karl H. Johansson"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.11258"
  },
  {
    "id": "arXiv:2211.11275",
    "title": "VATLM: Visual-Audio-Text Pre-Training with Unified Masked Prediction for  Speech Representation Learning",
    "abstract": "Although speech is a simple and effective way for humans to communicate with\nthe outside world, a more realistic speech interaction contains multimodal\ninformation, e.g., vision, text. How to design a unified framework to integrate\ndifferent modal information and leverage different resources (e.g.,\nvisual-audio pairs, audio-text pairs, unlabeled speech, and unlabeled text) to\nfacilitate speech representation learning was not well explored. In this paper,\nwe propose a unified cross-modal representation learning framework VATLM\n(Visual-Audio-Text Language Model). The proposed VATLM employs a unified\nbackbone network to model the modality-independent information and utilizes\nthree simple modality-dependent modules to preprocess visual, speech, and text\ninputs. In order to integrate these three modalities into one shared semantic\nspace, VATLM is optimized with a masked prediction task of unified tokens,\ngiven by our proposed unified tokenizer. We evaluate the pre-trained VATLM on\naudio-visual related downstream tasks, including audio-visual speech\nrecognition (AVSR), visual speech recognition (VSR) tasks. Results show that\nthe proposed VATLM outperforms previous the state-of-the-art models, such as\naudio-visual pre-trained AV-HuBERT model, and analysis also demonstrates that\nVATLM is capable of aligning different modalities into the same space. To\nfacilitate future research, we release the code and pre-trained models at\nhttps://aka.ms/vatlm.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Qiushi Zhu",
      "Long Zhou",
      "Ziqiang Zhang",
      "Shujie Liu",
      "Binxing Jiao",
      "Jie Zhang",
      "Lirong Dai",
      "Daxin Jiang",
      "Jinyu Li",
      "Furu Wei"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.11275"
  },
  {
    "id": "arXiv:2211.11278",
    "title": "An Optimal k Nearest Neighbours Ensemble for Classification Based on  Extended Neighbourhood Rule with Features subspace",
    "abstract": "To minimize the effect of outliers, kNN ensembles identify a set of closest\nobservations to a new sample point to estimate its unknown class by using\nmajority voting in the labels of the training instances in the neighbourhood.\nOrdinary kNN based procedures determine k closest training observations in the\nneighbourhood region (enclosed by a sphere) by using a distance formula. The k\nnearest neighbours procedure may not work in a situation where sample points in\nthe test data follow the pattern of the nearest observations that lie on a\ncertain path not contained in the given sphere of nearest neighbours.\nFurthermore, these methods combine hundreds of base kNN learners and many of\nthem might have high classification errors thereby resulting in poor ensembles.\nTo overcome these problems, an optimal extended neighbourhood rule based\nensemble is proposed where the neighbours are determined in k steps. It starts\nfrom the first nearest sample point to the unseen observation. The second\nnearest data point is identified that is closest to the previously selected\ndata point. This process is continued until the required number of the k\nobservations are obtained. Each base model in the ensemble is constructed on a\nbootstrap sample in conjunction with a random subset of features. After\nbuilding a sufficiently large number of base models, the optimal models are\nthen selected based on their performance on out-of-bag (OOB) data.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Amjad Ali",
      "Muhammad Hamraz",
      "Dost Muhammad Khan",
      "Saeed Aldahmani",
      "Zardad Khan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11278"
  },
  {
    "id": "arXiv:2211.11336",
    "title": "Orientation recognition and correction of Cardiac MRI with deep neural  network",
    "abstract": "In this paper, the problem of orientation correction in cardiac MRI images is\ninvestigated and a framework for orientation recognition via deep neural\nnetworks is proposed. For multi-modality MRI, we introduce a transfer learning\nstrategy to transfer our proposed model from single modality to multi-modality.\nWe embed the proposed network into the orientation correction command-line\ntool, which can implement orientation correction on 2D DICOM and 3D NIFTI\nimages. Our source code, network models and tools are available at\nhttps://github.com/Jy-stdio/MSCMR_orient/",
    "descriptor": "",
    "authors": [
      "Jiyao Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11336"
  },
  {
    "id": "arXiv:2211.11368",
    "title": "Precise Asymptotics for Spectral Methods in Mixed Generalized Linear  Models",
    "abstract": "In a mixed generalized linear model, the objective is to learn multiple\nsignals from unlabeled observations: each sample comes from exactly one signal,\nbut it is not known which one. We consider the prototypical problem of\nestimating two statistically independent signals in a mixed generalized linear\nmodel with Gaussian covariates. Spectral methods are a popular class of\nestimators which output the top two eigenvectors of a suitable data-dependent\nmatrix. However, despite the wide applicability, their design is still obtained\nvia heuristic considerations, and the number of samples $n$ needed to guarantee\nrecovery is super-linear in the signal dimension $d$. In this paper, we develop\nexact asymptotics on spectral methods in the challenging proportional regime in\nwhich $n, d$ grow large and their ratio converges to a finite constant. By\ndoing so, we are able to optimize the design of the spectral method, and\ncombine it with a simple linear estimator, in order to minimize the estimation\nerror. Our characterization exploits a mix of tools from random matrices, free\nprobability and the theory of approximate message passing algorithms. Numerical\nsimulations for mixed linear regression and phase retrieval display the\nadvantage enabled by our analysis over existing designs of spectral methods.",
    "descriptor": "",
    "authors": [
      "Yihan Zhang",
      "Marco Mondelli",
      "Ramji Venkataramanan"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.11368"
  },
  {
    "id": "arXiv:2211.11379",
    "title": "Modelling spatiotemporal turbulent dynamics with the convolutional  autoencoder echo state network",
    "abstract": "The spatiotemporal dynamics of turbulent flows is chaotic and difficult to\npredict. This makes the design of accurate and stable reduced-order models\nchallenging. The overarching objective of this paper is to propose a nonlinear\ndecomposition of the turbulent state for a reduced-order representation of the\ndynamics. We divide the turbulent flow into a spatial problem and a temporal\nproblem. First, we compute the latent space, which is the manifold onto which\nthe turbulent dynamics live (i.e., it is a numerical approximation of the\nturbulent attractor). The latent space is found by a series of nonlinear\nfiltering operations, which are performed by a convolutional autoencoder (CAE).\nThe CAE provides the decomposition in space. Second, we predict the time\nevolution of the turbulent state in the latent space, which is performed by an\necho state network (ESN). The ESN provides the decomposition in time. Third, by\nassembling the CAE and the ESN, we obtain an autonomous dynamical system: the\nconvolutional autoncoder echo state network (CAE-ESN). This is the\nreduced-order model of the turbulent flow. We test the CAE-ESN on a\ntwo-dimensional flow. We show that, after training, the CAE-ESN (i) finds a\nlatent-space representation of the turbulent flow that has less than 1% of the\ndegrees of freedom than the physical space; (ii) time-accurately and\nstatistically predicts the flow in both quasiperiodic and turbulent regimes;\n(iii) is robust for different flow regimes (Reynolds numbers); and (iv) takes\nless than 1% of computational time to predict the turbulent flow than solving\nthe governing equations. This work opens up new possibilities for nonlinear\ndecompositions and reduced-order modelling of turbulent flows from data.",
    "descriptor": "",
    "authors": [
      "Alberto Racca",
      "Nguyen Anh Khoa Doan",
      "Luca Magri"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2211.11379"
  },
  {
    "id": "arXiv:2211.11382",
    "title": "Bias and Refinement of Multiscale Mean Field Models",
    "abstract": "Mean field approximation is a powerful technique which has been used in many\nsettings to study large-scale stochastic systems. In the case of two-timescale\nsystems, the approximation is obtained by a combination of scaling arguments\nand the use of the averaging principle. This paper analyzes the approximation\nerror of this `average' mean field model for a two-timescale model\n$(\\boldsymbol{X}, \\boldsymbol{Y})$, where the slow component $\\boldsymbol{X}$\ndescribes a population of interacting particles which is fully coupled with a\nrapidly changing environment $\\boldsymbol{Y}$. The model is parametrized by a\nscaling factor $N$, e.g. the population size, which as $N$ gets large decreases\nthe jump size of the slow component in contrast to the unchanged dynamics of\nthe fast component. We show that under relatively mild conditions the `average'\nmean field approximation has a bias of order $O(1/N)$ compared to\n$\\mathbb{E}[\\boldsymbol{X}]$. This holds true under any continuous performance\nmetric in the transient regime as well as for the steady-state if the model is\nexponentially stable. To go one step further, we derive a bias correction term\nfor the steady-state from which we define a new approximation called the\nrefined `average' mean field approximation whose bias is of order $O(1/N^2)$.\nThis refined `average' mean field approximation allows computing an accurate\napproximation even for small scaling factors, i.e., $N\\approx 10 -50$. We\nillustrate the developed framework and accuracy results through an application\nto a random access CSMA model.",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Sebastian Allmeier",
      "Nicolas Gast"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2211.11382"
  },
  {
    "id": "arXiv:2211.11403",
    "title": "Time-reversal equivariant neural network potential and Hamiltonian for  magnetic materials",
    "abstract": "This work presents Time-reversal Equivariant Neural Network (TENN) framework.\nWith TENN, the time-reversal symmetry is considered in the equivariant neural\nnetwork (ENN), which generalizes the ENN to consider physical quantities\nrelated to time-reversal symmetry such as spin and velocity of atoms. TENN-e3,\nas the time-reversal-extension of E(3) equivariant neural network, is developed\nto keep the Time-reversal E(3) equivariant with consideration of whether to\ninclude the spin-orbit effect for both collinear and non-collinear magnetic\nmoments situations for magnetic material. TENN-e3 can construct spin neural\nnetwork potential and the Hamiltonian of magnetic material from ab-initio\ncalculations. Time-reversal-E(3)-equivariant convolutions for interactions of\nspinor and geometric tensors are employed in TENN-e3. Compared to the popular\nENN, TENN-e3 can describe the complex spin-lattice coupling with high accuracy\nand keep time-reversal symmetry which is not preserved in the existing\nE(3)-equivariant model. Also, the Hamiltonian of magnetic material with\ntime-reversal symmetry can be built with TENN-e3. TENN paves a new way to\nspin-lattice dynamics simulations over long-time scales and electronic\nstructure calculations of large-scale magnetic materials.",
    "descriptor": "\nComments: 15 pages,2 figures and 2 tables\n",
    "authors": [
      "Hongyu Yu",
      "Yang Zhong",
      "Junyi Ji",
      "Xingao Gong",
      "Hongjun Xiang"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.11403"
  },
  {
    "id": "arXiv:2211.11404",
    "title": "Approximating a Laplacian Prior for Joint State and Model Estimation  within an UKF",
    "abstract": "A major challenge in state estimation with model-based observers are\nlow-quality models that lack of relevant dynamics. We address this issue by\nsimultaneously estimating the system's states and its model uncertainties by a\nsquare root UKF. Concretely, we extend the state by the parameter vector of a\nlinear combination containing suitable functions that approximate the lacking\ndynamics. Presuming that only a few dynamical terms are relevant, the parameter\nvector is claimed to be sparse. In Bayesian setting, properties like sparsity\nare expressed by a prior distribution. One common choice for sparsity is a\nLaplace distribution. However, due to some disadvantages of a Laplacian prior,\nthe regularized horseshoe distribution, a Gaussian that approximately features\nsparsity, is applied. Results exhibit small estimation errors with model\nimprovements detected by an automated model reduction technique.",
    "descriptor": "\nComments: This work has been submitted to IFAC for possible publication\n",
    "authors": [
      "Ricarda-Samantha G\u00f6tte",
      "Julia Timmermann"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.11404"
  },
  {
    "id": "arXiv:2211.11410",
    "title": "Treedepth vs circumference",
    "abstract": "The circumference of a graph $G$ is the length of a longest cycle in $G$, or\n$+\\infty$ if $G$ has no cycle. Birmel\\'e (2003) showed that the treewidth of a\ngraph $G$ is at most its circumference minus one. We strengthen this result for\n$2$-connected graphs as follows: If $G$ is $2$-connected, then its treedepth is\nat most its circumference. The bound is best possible and improves on an\nearlier quadratic upper bound due to Marshall and Wood (2015).",
    "descriptor": "",
    "authors": [
      "Marcin Bria\u0144ski",
      "Gwena\u00ebl Joret",
      "Konrad Majewski",
      "Piotr Micek",
      "Micha\u0142",
      "T. Seweryn",
      "Roohani Sharma"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.11410"
  },
  {
    "id": "arXiv:2211.11460",
    "title": "Motor Imagery Decoding Using Ensemble Curriculum Learning and  Collaborative Training",
    "abstract": "Objective: In this work, we study the problem of cross-subject motor imagery\n(MI) decoding from electroenchephalography (EEG) data. Multi-subject EEG\ndatasets present several kinds of domain shifts due to various inter-individual\ndifferences (e.g. brain anatomy, personality and cognitive profile). These\ndomain shifts render multi-subject training a challenging task and also impede\nrobust cross-subject generalization. Method: We propose a two-stage model\nensemble architecture, built with multiple feature extractors (first stage) and\na shared classifier (second stage), which we train end-to-end with two loss\nterms. The first loss applies curriculum learning, forcing each feature\nextractor to specialize to a subset of the training subjects and promoting\nfeature diversity. The second loss is an intra-ensemble distillation objective\nthat allows collaborative exchange of knowledge between the models of the\nensemble. Results: We compare our method against several state-of-the-art\ntechniques, conducting subject-independent experiments on two large MI\ndatasets, namely Physionet and OpenBMI. Our algorithm outperforms all of the\nmethods in both 5-fold cross-validation and leave-one-subject-out evaluation\nsettings, using a substantially lower number of trainable parameters.\nConclusion: We demonstrate that our model ensembling approach combining the\npowers of curriculum learning and collaborative training, leads to high\nlearning capacity and robust performance. Significance: Our work addresses the\nissue of domain shifts in multi-subject EEG datasets, paving the way for\ncalibration-free BCI systems.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. Code: this https URL\n",
    "authors": [
      "Georgios Zoumpourlis",
      "Ioannis Patras"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11460"
  },
  {
    "id": "arXiv:2211.11461",
    "title": "Exhaustive Symbolic Regression",
    "abstract": "Symbolic Regression (SR) algorithms learn analytic expressions which both\naccurately fit data and, unlike traditional machine-learning approaches, are\nhighly interpretable. Conventional SR suffers from two fundamental issues which\nwe address in this work. First, since the number of possible equations grows\nexponentially with complexity, typical SR methods search the space\nstochastically and hence do not necessarily find the best function. In many\ncases, the target problems of SR are sufficiently simple that a brute-force\napproach is not only feasible, but desirable. Second, the criteria used to\nselect the equation which optimally balances accuracy with simplicity have been\nvariable and poorly motivated. To address these issues we introduce a new\nmethod for SR -- Exhaustive Symbolic Regression (ESR) -- which systematically\nand efficiently considers all possible equations and is therefore guaranteed to\nfind not only the true optimum but also a complete function ranking. Utilising\nthe minimum description length principle, we introduce a principled method for\ncombining these preferences into a single objective statistic. To illustrate\nthe power of ESR we apply it to a catalogue of cosmic chronometers and the\nPantheon+ sample of supernovae to learn the Hubble rate as a function of\nredshift, finding $\\sim$40 functions (out of 5.2 million considered) that fit\nthe data more economically than the Friedmann equation. These low-redshift data\ntherefore do not necessarily prefer a $\\Lambda$CDM expansion history, and\ntraditional SR algorithms that return only the Pareto-front, even if they found\nthis successfully, would not locate $\\Lambda$CDM. We make our code and full\nequation sets publicly available.",
    "descriptor": "\nComments: 14 pages, 6 figures, 2 tables. Submitted to IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
    "authors": [
      "Deaglan J. Bartlett",
      "Harry Desmond",
      "Pedro G. Ferreira"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11461"
  },
  {
    "id": "arXiv:2211.11462",
    "title": "3D Detection and Characterisation of ALMA Sources through Deep Learning",
    "abstract": "We present a Deep-Learning (DL) pipeline developed for the detection and\ncharacterization of astronomical sources within simulated Atacama Large\nMillimeter/submillimeter Array (ALMA) data cubes. The pipeline is composed of\nsix DL models: a Convolutional Autoencoder for source detection within the\nspatial domain of the integrated data cubes, a Recurrent Neural Network (RNN)\nfor denoising and peak detection within the frequency domain, and four Residual\nNeural Networks (ResNets) for source characterization. The combination of\nspatial and frequency information improves completeness while decreasing\nspurious signal detection. To train and test the pipeline, we developed a\nsimulation algorithm able to generate realistic ALMA observations, i.e. both\nsky model and dirty cubes. The algorithm simulates always a central source\nsurrounded by fainter ones scattered within the cube. Some sources were\nspatially superimposed in order to test the pipeline deblending capabilities.\nThe detection performances of the pipeline were compared to those of other\nmethods and significant improvements in performances were achieved. Source\nmorphologies are detected with subpixel accuracies obtaining mean residual\nerrors of $10^{-3}$ pixel ($0.1$ mas) and $10^{-1}$ mJy/beam on positions and\nflux estimations, respectively. Projection angles and flux densities are also\nrecovered within $10\\%$ of the true values for $80\\%$ and $73\\%$ of all sources\nin the test set, respectively. While our pipeline is fine-tuned for ALMA data,\nthe technique is applicable to other interferometric observatories, as SKA,\nLOFAR, VLBI, and VLTI.",
    "descriptor": "",
    "authors": [
      "Michele Delli Veneri",
      "Lukasz Tychoniec",
      "Fabrizia Guglielmetti",
      "Giuseppe Longo",
      "Eric Villard"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11462"
  },
  {
    "id": "arXiv:2211.11477",
    "title": "Exceptional scattered sequences",
    "abstract": "The concept of scattered polynomials is generalized to those of exceptional\nscattered sequences which are shown to be the natural algebraic counterpart of\n$\\mathbb{F}_{q^n}$-linear MRD codes. The first infinite family in the first\nnontrivial case is also provided and equivalence issues are considered. As a\nbyproduct, a new infinite family of MRD codes is obtained.",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Daniele Bartoli",
      "Giuseppe Marino",
      "Alessandro Neri",
      "Lara Vicino"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.11477"
  },
  {
    "id": "arXiv:2211.11499",
    "title": "Effects of Kerr nonlinearity in physical unclonable functions",
    "abstract": "We address the question of whether the presence of Kerr nonlinearity in\nmultiple-scattering optical media offers any advantage with respect to the\ndesign of physical unclonable functions. Our results suggest that under certain\nconditions, nonlinear physical unclonable functions can be more robust against\nthe potential cloning of the medium, relative to their linear counterparts that\nhave been exploited in the context of various cryptographic applications.",
    "descriptor": "",
    "authors": [
      "Georgios M. Nikolopoulos"
    ],
    "subjectives": [
      "Optics (physics.optics)",
      "Cryptography and Security (cs.CR)",
      "Applied Physics (physics.app-ph)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.11499"
  },
  {
    "id": "arXiv:2211.11509",
    "title": "Segmentation, Classification, and Quality Assessment of UW-OCTA Images  for the Diagnosis of Diabetic Retinopathy",
    "abstract": "Diabetic Retinopathy (DR) is a severe complication of diabetes that can cause\nblindness. Although effective treatments exist (notably laser) to slow the\nprogression of the disease and prevent blindness, the best treatment remains\nprevention through regular check-ups (at least once a year) with an\nophthalmologist. Optical Coherence Tomography Angiography (OCTA) allows for the\nvisualization of the retinal vascularization, and the choroid at the\nmicrovascular level in great detail. This allows doctors to diagnose DR with\nmore precision. In recent years, algorithms for DR diagnosis have emerged along\nwith the development of deep learning and the improvement of computer hardware.\nHowever, these usually focus on retina photography. There are no current\nmethods that can automatically analyze DR using Ultra-Wide OCTA (UW-OCTA). The\nDiabetic Retinopathy Analysis Challenge 2022 (DRAC22) provides a standardized\nUW-OCTA dataset to train and test the effectiveness of various algorithms on\nthree tasks: lesions segmentation, quality assessment, and DR grading. In this\npaper, we will present our solutions for the three tasks of the DRAC22\nchallenge. The obtained results are promising and have allowed us to position\nourselves in the TOP 5 of the segmentation task, the TOP 4 of the quality\nassessment task, and the TOP 3 of the DR grading task. The code is available at\n\\url{https://github.com/Mostafa-EHD/Diabetic_Retinopathy_OCTA}.",
    "descriptor": "",
    "authors": [
      "Yihao Li",
      "Rachid Zeghlache",
      "Ikram Brahim",
      "Hui Xu",
      "Yubo Tan",
      "Pierre-Henri Conze",
      "Mathieu Lamard",
      "Gwenol\u00e9 Quellec",
      "Mostafa El Habib Daho"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11509"
  },
  {
    "id": "arXiv:2211.11513",
    "title": "DSLOB: A Synthetic Limit Order Book Dataset for Benchmarking Forecasting  Algorithms under Distributional Shift",
    "abstract": "In electronic trading markets, limit order books (LOBs) provide information\nabout pending buy/sell orders at various price levels for a given security.\nRecently, there has been a growing interest in using LOB data for resolving\ndownstream machine learning tasks (e.g., forecasting). However, dealing with\nout-of-distribution (OOD) LOB data is challenging since distributional shifts\nare unlabeled in current publicly available LOB datasets. Therefore, it is\ncritical to build a synthetic LOB dataset with labeled OOD samples serving as a\ntestbed for developing models that generalize well to unseen scenarios. In this\nwork, we utilize a multi-agent market simulator to build a synthetic LOB\ndataset, named DSLOB, with and without market stress scenarios, which allows\nfor the design of controlled distributional shift benchmarking. Using the\nproposed synthetic dataset, we provide a holistic analysis on the forecasting\nperformance of three different state-of-the-art forecasting methods. Our\nresults reflect the need for increased researcher efforts to develop algorithms\nwith robustness to distributional shifts in high-frequency time series data.",
    "descriptor": "\nComments: 11 pages, 5 figures, already accepted by NeurIPS 2022 Distribution Shifts Workshop\n",
    "authors": [
      "Defu Cao",
      "Yousef El-Laham",
      "Loc Trinh",
      "Svitlana Vyetrenko",
      "Yan Liu"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11513"
  },
  {
    "id": "arXiv:2211.11533",
    "title": "Linear Modeling of the Glass Transition Temperature of the system  SiO2-Na2O-CaO",
    "abstract": "This work aimed to mathematically model the glass transition temperature\n(Tg), one of the most important parameters regarding the behavior of slag,\nresponsible for the sudden change in thermomechanical properties of\nnon-crystalline materials, by the chemical composition of the SiO2-Na2O-CaO\nsystem, widely applicable in the production of glasses and constituent of iron,\nmagnesium and aluminum metallurgy slags. The SciGlass database was used to\nprovide data for mathematical modeling through the Python programming language,\nusing the method of least squares. A new equation was established, called P\nModel, and it presented a lower mean absolute error and lower standard\ndeviation of absolute errors in relation to 3 equations in the literature. The\nraised equation provides significant results in the mathematical modeling of Tg\nby the chemical system SiO2-Na2O-CaO, valid for the limits of the data used in\nthe mathematical modeling.",
    "descriptor": "\nComments: 5 pages, 3 figures, 2 tables\n",
    "authors": [
      "Patrick dos Anjos",
      "Lucas A. Quaresma",
      "Marcelo L. P. Machado"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Programming Languages (cs.PL)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.11533"
  },
  {
    "id": "arXiv:2211.11543",
    "title": "Leveraging Orbital Information and Atomic Feature in Deep Learning Model",
    "abstract": "Predicting material properties base on micro structure of materials has long\nbeen a challenging problem. Recently many deep learning methods have been\ndeveloped for material property prediction. In this study, we propose a crystal\nrepresentation learning framework, Orbital CrystalNet, OCrystalNet, which\nconsists of two parts: atomic descriptor generation and graph representation\nlearning. In OCrystalNet, we first incorporate orbital field matrix (OFM) and\natomic features to construct OFM-feature atomic descriptor, and then the atomic\ndescriptor is used as atom embedding in the atom-bond message passing module\nwhich takes advantage of the topological structure of crystal graphs to learn\ncrystal representation. To demonstrate the capabilities of OCrystalNet we\nperformed a number of prediction tasks on Material Project dataset and JARVIS\ndataset and compared our model with other baselines and state of art methods.\nTo further present the effectiveness of OCrystalNet, we conducted ablation\nstudy and case study of our model. The results show that our model have various\nadvantages over other state of art models.",
    "descriptor": "",
    "authors": [
      "Xiangrui Yang"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11543"
  },
  {
    "id": "arXiv:2211.11545",
    "title": "A Pilot Study of Sidewalk Equity in Seattle Using Crowdsourced Sidewalk  Assessment Data",
    "abstract": "We examine the potential of using large-scale open crowdsourced sidewalk data\nfrom Project Sidewalk to study the distribution and condition of sidewalks in\nSeattle, WA. While potentially noisier than professionally gathered sidewalk\ndatasets, crowdsourced data enables large, cross-regional studies that would be\notherwise expensive and difficult to manage. As an initial case study, we\nexamine spatial patterns of sidewalk quality in Seattle and their relationship\nto racial diversity, income level, built density, and transit modes. We close\nwith a reflection on our approach, key limitations, and opportunities for\nfuture work.",
    "descriptor": "\nComments: Workshop paper presented at \"The 1st ASSETS'22 Workshop on The Future or urban Accessibility (UrbanAccess'22)\"\n",
    "authors": [
      "Chu Li",
      "Lisa Orii",
      "Mikey Saugstad",
      "Stephen J. Mooney",
      "Yochai Eisenberg",
      "Delphine Labb\u00e9",
      "Joy Hammel",
      "Jon E. Froehlich"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.11545"
  },
  {
    "id": "arXiv:2211.11557",
    "title": "Decomposing 3D Neuroimaging into 2+1D Processing for Schizophrenia  Recognition",
    "abstract": "Deep learning has been successfully applied to recognizing both natural\nimages and medical images. However, there remains a gap in recognizing 3D\nneuroimaging data, especially for psychiatric diseases such as schizophrenia\nand depression that have no visible alteration in specific slices. In this\nstudy, we propose to process the 3D data by a 2+1D framework so that we can\nexploit the powerful deep 2D Convolutional Neural Network (CNN) networks\npre-trained on the huge ImageNet dataset for 3D neuroimaging recognition.\nSpecifically, 3D volumes of Magnetic Resonance Imaging (MRI) metrics (grey\nmatter, white matter, and cerebrospinal fluid) are decomposed to 2D slices\naccording to neighboring voxel positions and inputted to 2D CNN models\npre-trained on the ImageNet to extract feature maps from three views (axial,\ncoronal, and sagittal). Global pooling is applied to remove redundant\ninformation as the activation patterns are sparsely distributed over feature\nmaps. Channel-wise and slice-wise convolutions are proposed to aggregate the\ncontextual information in the third view dimension unprocessed by the 2D CNN\nmodel. Multi-metric and multi-view information are fused for final prediction.\nOur approach outperforms handcrafted feature-based machine learning, deep\nfeature approach with a support vector machine (SVM) classifier and 3D CNN\nmodels trained from scratch with better cross-validation results on publicly\navailable Northwestern University Schizophrenia Dataset and the results are\nreplicated on another independent dataset.",
    "descriptor": "",
    "authors": [
      "Mengjiao Hu",
      "Xudong Jiang",
      "Kang Sim",
      "Juan Helen Zhou",
      "Cuntai Guan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11557"
  },
  {
    "id": "arXiv:2211.11564",
    "title": "Adaptive Constraint Partition based Optimization Framework for  Large-scale Integer Linear Programming(Student Abstract)",
    "abstract": "Integer programming problems (IPs) are challenging to be solved efficiently\ndue to the NP-hardness, especially for large-scale IPs. To solve this type of\nIPs, Large neighborhood search (LNS) uses an initial feasible solution and\niteratively improves it by searching a large neighborhood around the current\nsolution. However, LNS easily steps into local optima and ignores the\ncorrelation between variables to be optimized, leading to compromised\nperformance. This paper presents a general adaptive constraint partition-based\noptimization framework (ACP) for large-scale IPs that can efficiently use any\nexisting optimization solver as a subroutine. Specifically, ACP first randomly\npartitions the constraints into blocks, where the number of blocks is\nadaptively adjusted to avoid local optima. Then, ACP uses a subroutine solver\nto optimize the decision variables in a randomly selected block of constraints\nto enhance the variable correlation. ACP is compared with LNS framework with\ndifferent subroutine solvers on four IPs and a real-world IP. The experimental\nresults demonstrate that in specified wall-clock time ACP shows better\nperformance than SCIP and Gurobi.",
    "descriptor": "\nComments: To be published in AAAI2023 Student Abstract\n",
    "authors": [
      "Huigen Ye",
      "Hongyan Wang",
      "Hua Xu",
      "Chengming Wang",
      "Yu Jiang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11564"
  },
  {
    "id": "arXiv:2211.11567",
    "title": "Neural networks trained with SGD learn distributions of increasing  complexity",
    "abstract": "The ability of deep neural networks to generalise well even when they\ninterpolate their training data has been explained using various \"simplicity\nbiases\". These theories postulate that neural networks avoid overfitting by\nfirst learning simple functions, say a linear classifier, before learning more\ncomplex, non-linear functions. Meanwhile, data structure is also recognised as\na key ingredient for good generalisation, yet its role in simplicity biases is\nnot yet understood. Here, we show that neural networks trained using stochastic\ngradient descent initially classify their inputs using lower-order input\nstatistics, like mean and covariance, and exploit higher-order statistics only\nlater during training. We first demonstrate this distributional simplicity bias\n(DSB) in a solvable model of a neural network trained on synthetic data. We\nempirically demonstrate DSB in a range of deep convolutional networks and\nvisual transformers trained on CIFAR10, and show that it even holds in networks\npre-trained on ImageNet. We discuss the relation of DSB to other simplicity\nbiases and consider its implications for the principle of Gaussian universality\nin learning.",
    "descriptor": "\nComments: Source code available at this https URL\n",
    "authors": [
      "Maria Refinetti",
      "Alessandro Ingrosso",
      "Sebastian Goldt"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11567"
  },
  {
    "id": "arXiv:2211.11626",
    "title": "Representability of the Direct Sum of $q$-Matroids",
    "abstract": "$q$-Matroids are the $q$-analogue of matroids. In this short note we consider\nthe direct sum of $q$-matroids, as introduced recently in the literature. We\nshow that the direct sum of representable $q$-matroids may not be\nrepresentable. It remains an open question whether representability of the\ndirect sum can be characterized by the given $q$-matroids.",
    "descriptor": "",
    "authors": [
      "Heide Gluesing-Luerssen",
      "Benjamin Jany"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.11626"
  },
  {
    "id": "arXiv:2211.11657",
    "title": "On It\u00f4-Taylor expansion for stochastic differential equations with  Markovian switching and its application in $\u03b3\\in\\{n/2:n  \\in\\mathbb{N}\\}$-order scheme",
    "abstract": "The coefficients of the stochastic differential equations with Markovian\nswitching (SDEwMS) additionally depend on a Markov chain and there is no notion\nof differentiating such functions with respect to the Markov chain. In\nparticular, this implies that the It\\^o-Taylor expansion for SDEwMS is not a\nstraightforward extension of the It\\^o-Taylor expansion for stochastic\ndifferential equations (SDEs). Further, higher-order numerical schemes for\nSDEwMS are not available in the literature, perhaps because of the absence of\nthe It\\^o-Taylor expansion. In this article, first, we overcome these\nchallenges and derive the It\\^o-Taylor expansion for SDEwMS, under some\nsuitable regularity assumptions on the coefficients, by developing new\ntechniques. Secondly, we demonstrate an application of our first result on the\nIt\\^o-Taylor expansion in the numerical approximations of SDEwMS. We derive an\nexplicit scheme for SDEwMS using the It\\^o-Taylor expansion and show that the\nstrong rate of convergence of our scheme is equal to\n$\\gamma\\in\\{n/2:n\\in\\mathbb{N}\\}$ under some suitable Lipschitz-type conditions\non the coefficients and their derivatives. It is worth mentioning that\ndesigning and analysis of the It\\^o-Taylor expansion and the\n$\\gamma\\in\\{n/2:n\\in\\mathbb{N}\\}$-order scheme for SDEwMS become much more\ncomplex and involved due to the entangling of continuous dynamics and discrete\nevents. Finally, our results coincide with the corresponding results on SDEs\nwhen the state of the Markov chain is a singleton set.",
    "descriptor": "\nComments: 53\n",
    "authors": [
      "Tejinder Kumar",
      "Chaman Kumar"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.11657"
  },
  {
    "id": "arXiv:2211.11673",
    "title": "Asymptotically Normal Estimation of Local Latent Network Curvature",
    "abstract": "Network data, commonly used throughout the physical, social, and biological\nsciences, consist of nodes (individuals) and the edges (interactions) between\nthem. One way to represent the complex, high-dimensional structure in network\ndata is to embed the graph into a low-dimensional geometric space. Curvature of\nthis space, in particular, provides insights about structure in the graph, such\nas the propensity to form triangles or present tree-like structure.",
    "descriptor": "\nComments: 77 pages\n",
    "authors": [
      "Steven Wilkins-Reeves",
      "Tyler McCormick"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.11673"
  },
  {
    "id": "arXiv:2211.11685",
    "title": "Finite Model Properties for Residuated Semigroups",
    "abstract": "We have a quick look at various finite model properties for residuated\nsemigroups. In particular, we solve Problem 19.17 from Relation Algebras by\nGames by Hirsch and Hodkinson.",
    "descriptor": "",
    "authors": [
      "Szabolcs Mikul\u00e1s"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.11685"
  },
  {
    "id": "arXiv:2211.11691",
    "title": "Deep Signature Algorithm for Path-Dependent American option pricing",
    "abstract": "In this work, we study the deep signature algorithms for path-dependent\nFBSDEs with reflections. We follow the backward scheme in [Hur\\'e-Pham-Warin.\nMathematics of Computation 89, no. 324 (2020)] for state-dependent FBSDEs with\nreflections, and combine it with the signature layer to solve American type\noption pricing problems while the payoff function depends on the whole paths of\nthe underlying forward stock process. We prove the convergence analysis of our\nnumerical algorithm and provide numerical example for Amerasian option under\nthe Black-Scholes model.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Erhan Bayraktar",
      "Qi Feng",
      "Zhaoyu Zhang"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)",
      "Mathematical Finance (q-fin.MF)"
    ],
    "url": "https://arxiv.org/abs/2211.11691"
  },
  {
    "id": "arXiv:2211.11700",
    "title": "High-Dimensional Undirected Graphical Models for Arbitrary Mixed Data",
    "abstract": "Graphical models are an important tool in exploring relationships between\nvariables in complex, multivariate data. Methods for learning such graphical\nmodels are well developed in the case where all variables are either continuous\nor discrete, including in high-dimensions. However, in many applications data\nspan variables of different types (e.g. continuous, count, binary, ordinal,\netc.), whose principled joint analysis is nontrivial. Latent Gaussian copula\nmodels, in which all variables are modeled as transformations of underlying\njointly Gaussian variables, represent a useful approach. Recent advances have\nshown how the binary-continuous case can be tackled, but the general mixed\nvariable type regime remains challenging. In this work, we make the simple yet\nuseful observation that classical ideas concerning polychoric and polyserial\ncorrelations can be leveraged in a latent Gaussian copula framework. Building\non this observation we propose flexible and scalable methodology for data with\nvariables of entirely general mixed type. We study the key properties of the\napproaches theoretically and empirically, via extensive simulations as well an\nillustrative application to data from the UK Biobank concerning COVID-19 risk\nfactors.",
    "descriptor": "\nComments: 17 pages, 2 Figures\n",
    "authors": [
      "Konstantin G\u00f6bler",
      "Anne Miloschewski",
      "Mathias Drton",
      "Sach Mukherjee"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.11700"
  },
  {
    "id": "arXiv:2211.11706",
    "title": "Long time behavior of solutions to the generalized Boussinesq equation  in Sobolev spaces",
    "abstract": "In this paper, we study the generalized Boussinesq equation to model the\nwater wave problem with surface tension. First, we investigate the initial\nvalue problem in the Sobolev spaces. We derive some conditions under which the\nsolutions of this equation are global or blow-up in time, and next, we extend\nour results to the Bessel potential spaces. The asymptotic behavior of the\nsolutions is also determined. The non-existence of solitary waves for some\nparameters is proved using Pohozaev-type identities. We generate solitary wave\nsolutions of generalized Boussinesq equation using the Petviashvili iteration\nmethod numerically. In order to investigate the time evolution of solutions to\nthe generalized Boussinesq equation, we propose the Fourier pseudo-spectral\nnumerical method. After studying the time evolution of the single solitary\nwave, we focus on the gap interval where neither a global existence nor a\nblow-up result has been established theoretically. Our numerical results\nsuccessfully fill the gaps left by the theoretical ones.",
    "descriptor": "",
    "authors": [
      "Amin Esfahani",
      "Gulcin M. Muslu"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.11706"
  },
  {
    "id": "arXiv:2211.11710",
    "title": "Adaptive Stochastic Optimisation of Nonconvex Composite Objectives",
    "abstract": "In this paper, we propose and analyse a family of generalised stochastic\ncomposite mirror descent algorithms. With adaptive step sizes, the proposed\nalgorithms converge without requiring prior knowledge of the problem. Combined\nwith an entropy-like update-generating function, these algorithms perform\ngradient descent in the space equipped with the maximum norm, which allows us\nto exploit the low-dimensional structure of the decision sets for\nhigh-dimensional problems. Together with a sampling method based on the\nRademacher distribution and variance reduction techniques, the proposed\nalgorithms guarantee a logarithmic complexity dependence on dimensionality for\nzeroth-order optimisation problems.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2208.04579\n",
    "authors": [
      "Weijia Shao",
      "Fikret Sivrikaya",
      "Sahin Albayrak"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11710"
  },
  {
    "id": "arXiv:1605.04711",
    "title": "Ternary Weight Networks",
    "abstract": "Comments: 5 pages, 3 fitures, conference",
    "descriptor": "\nComments: 5 pages, 3 fitures, conference\n",
    "authors": [
      "Fengfu Li",
      "Bin Liu",
      "Xiaoxing Wang",
      "Bo Zhang",
      "Junchi Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1605.04711"
  },
  {
    "id": "arXiv:1803.09941",
    "title": "Iteration complexity of first-order augmented Lagrangian methods for  convex conic programming",
    "abstract": "Comments: accepted by SIAM Journal on Optimization",
    "descriptor": "\nComments: accepted by SIAM Journal on Optimization\n",
    "authors": [
      "Zhaosong Lu",
      "Zirui Zhou"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1803.09941"
  },
  {
    "id": "arXiv:1810.03711",
    "title": "A Hybrid Approach for Trajectory Control Design",
    "abstract": "Comments: 9 pages, 11 figures",
    "descriptor": "\nComments: 9 pages, 11 figures\n",
    "authors": [
      "Luigi Freda",
      "Mario Gianni",
      "Fiora Pirri"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1810.03711"
  },
  {
    "id": "arXiv:1907.05168",
    "title": "Graph product structure for non-minor-closed classes",
    "abstract": "Comments: v2 Cosmetic improvements and a corrected bound for (layered-)(tree)width in Theorems 2, 9, 11, and Corollaries 1, 3, 4, 6, 12. v3 Complete restructure. v4 Major revision, improved constants for 1-planar and d-map graphs. v5 Clarifications and corrections suggested by referee",
    "descriptor": "\nComments: v2 Cosmetic improvements and a corrected bound for (layered-)(tree)width in Theorems 2, 9, 11, and Corollaries 1, 3, 4, 6, 12. v3 Complete restructure. v4 Major revision, improved constants for 1-planar and d-map graphs. v5 Clarifications and corrections suggested by referee\n",
    "authors": [
      "Vida Dujmovi\u0107",
      "Pat Morin",
      "David R. Wood"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/1907.05168"
  },
  {
    "id": "arXiv:1909.00099",
    "title": "Strong convergence of an adaptive time-stepping Milstein method for SDEs  with monotone coefficients",
    "abstract": "Comments: 30 pages, 3 figures",
    "descriptor": "\nComments: 30 pages, 3 figures\n",
    "authors": [
      "C\u00f3nall Kelly",
      "Gabriel Lord",
      "Fandi Sun"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1909.00099"
  },
  {
    "id": "arXiv:1909.01095",
    "title": "Defining the scope of AI regulations",
    "abstract": "Comments: Forthcoming in Law, Innovation and Technology, Volume 15, Issue 1. A previous version of this paper was titled \"A legal definition of AI\". The current version has been completely revised",
    "descriptor": "\nComments: Forthcoming in Law, Innovation and Technology, Volume 15, Issue 1. A previous version of this paper was titled \"A legal definition of AI\". The current version has been completely revised\n",
    "authors": [
      "Jonas Schuett"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/1909.01095"
  },
  {
    "id": "arXiv:1912.08735",
    "title": "AirLift: A Fast and Comprehensive Technique for Remapping Alignments  between Reference Genomes",
    "abstract": "AirLift: A Fast and Comprehensive Technique for Remapping Alignments  between Reference Genomes",
    "descriptor": "",
    "authors": [
      "Jeremie S. Kim",
      "Can Firtina",
      "Meryem Banu Cavlak",
      "Damla Senol Cali",
      "Mohammed Alser",
      "Nastaran Hajinazar",
      "Can Alkan",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/1912.08735"
  },
  {
    "id": "arXiv:2004.04243",
    "title": "Error correction and extraction in request dialogs",
    "abstract": "Comments: 10 pages, 8 figures, 3 tables, forthcoming in ICNLSP 2022",
    "descriptor": "\nComments: 10 pages, 8 figures, 3 tables, forthcoming in ICNLSP 2022\n",
    "authors": [
      "Stefan Constantin",
      "Alex Waibel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2004.04243"
  },
  {
    "id": "arXiv:2004.08380",
    "title": "Completeness of Nominal PROPs",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1904.07534",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1904.07534\n",
    "authors": [
      "Samuel Balco",
      "Alexander Kurz"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2004.08380"
  },
  {
    "id": "arXiv:2007.00197",
    "title": "Overcoming Concept Shift in Domain-Aware Settings through Consolidated  Internal Distributions",
    "abstract": "Overcoming Concept Shift in Domain-Aware Settings through Consolidated  Internal Distributions",
    "descriptor": "",
    "authors": [
      "Mohammad Rostami",
      "Aram Galstyan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.00197"
  },
  {
    "id": "arXiv:2007.04281",
    "title": "Reconfigurable Intelligent Surfaces Empowered THz Communication in LEO  Satellite Networks",
    "abstract": "Comments: To appear in IEEE Access",
    "descriptor": "\nComments: To appear in IEEE Access\n",
    "authors": [
      "K\u00fcr\u015fat Tekb\u0131y\u0131k",
      "G\u00fcne\u015f Karabulut Kurt",
      "Ali R\u0131za Ekti",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2007.04281"
  },
  {
    "id": "arXiv:2007.11838",
    "title": "PClean: Bayesian Data Cleaning at Scale with Domain-Specific  Probabilistic Programming",
    "abstract": "Comments: Published version",
    "descriptor": "\nComments: Published version\n",
    "authors": [
      "Alexander K. Lew",
      "Monica Agrawal",
      "David Sontag",
      "Vikash K. Mansinghka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.11838"
  },
  {
    "id": "arXiv:2008.05984",
    "title": "Meta Learning MPC using Finite-Dimensional Gaussian Process  Approximations",
    "abstract": "Meta Learning MPC using Finite-Dimensional Gaussian Process  Approximations",
    "descriptor": "",
    "authors": [
      "Elena Arcari",
      "Andrea Carron",
      "Melanie N. Zeilinger"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2008.05984"
  },
  {
    "id": "arXiv:2008.08975",
    "title": "Co-Design to Enable User-Friendly Tools to Assess the Impact of Future  Mobility Solutions",
    "abstract": "Comments: Accepted for publication in the IEEE Transactions of Network Science and Engineering. arXiv admin note: text overlap with arXiv:2003.04739, arXiv:1910.07714",
    "descriptor": "\nComments: Accepted for publication in the IEEE Transactions of Network Science and Engineering. arXiv admin note: text overlap with arXiv:2003.04739, arXiv:1910.07714\n",
    "authors": [
      "Gioele Zardini",
      "Nicolas Lanzetti",
      "Andrea Censi",
      "Emilio Frazzoli",
      "Marco Pavone"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2008.08975"
  },
  {
    "id": "arXiv:2008.12566",
    "title": "A Framework for Improving Scholarly Neural Network Diagrams",
    "abstract": "Comments: 51 pages, 13 tables, 18 figures",
    "descriptor": "\nComments: 51 pages, 13 tables, 18 figures\n",
    "authors": [
      "Guy Clarke Marshall",
      "Andr\u00e9 Freitas",
      "Caroline Jay"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2008.12566"
  },
  {
    "id": "arXiv:2009.14794",
    "title": "Rethinking Attention with Performers",
    "abstract": "Comments: Published as a conference paper + oral presentation at ICLR 2021. 38 pages. See this https URL for protein language model code, and this https URL for Performer code. See this https URL for Google AI Blog",
    "descriptor": "\nComments: Published as a conference paper + oral presentation at ICLR 2021. 38 pages. See this https URL for protein language model code, and this https URL for Performer code. See this https URL for Google AI Blog\n",
    "authors": [
      "Krzysztof Choromanski",
      "Valerii Likhosherstov",
      "David Dohan",
      "Xingyou Song",
      "Andreea Gane",
      "Tamas Sarlos",
      "Peter Hawkins",
      "Jared Davis",
      "Afroz Mohiuddin",
      "Lukasz Kaiser",
      "David Belanger",
      "Lucy Colwell",
      "Adrian Weller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.14794"
  },
  {
    "id": "arXiv:2010.03815",
    "title": "A Comparative Study on Effects of Original and Pseudo Labels for Weakly  Supervised Learning for Car Localization Problem",
    "abstract": "Comments: Need to improve the results",
    "descriptor": "\nComments: Need to improve the results\n",
    "authors": [
      "Cenk Bircanoglu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.03815"
  },
  {
    "id": "arXiv:2010.12190",
    "title": "Towards Robust Neural Networks via Orthogonal Diversity",
    "abstract": "Towards Robust Neural Networks via Orthogonal Diversity",
    "descriptor": "",
    "authors": [
      "Kun Fang",
      "Qinghua Tao",
      "Yingwen Wu",
      "Tao Li",
      "Jia Cai",
      "Feipeng Cai",
      "Xiaolin Huang",
      "Jie Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.12190"
  },
  {
    "id": "arXiv:2011.02291",
    "title": "Evolving test instances of the Hamiltonian completion problem",
    "abstract": "Evolving test instances of the Hamiltonian completion problem",
    "descriptor": "",
    "authors": [
      "Thibault Lechien",
      "Jorik Jooken",
      "Patrick De Causmaecker"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2011.02291"
  },
  {
    "id": "arXiv:2011.07995",
    "title": "Detection of masses and architectural distortions in digital breast  tomosynthesis: a publicly available dataset of 5,060 patients and a deep  learning model",
    "abstract": "Detection of masses and architectural distortions in digital breast  tomosynthesis: a publicly available dataset of 5,060 patients and a deep  learning model",
    "descriptor": "",
    "authors": [
      "Mateusz Buda",
      "Ashirbani Saha",
      "Ruth Walsh",
      "Sujata Ghate",
      "Nianyi Li",
      "Albert \u015awi\u0119cicki",
      "Joseph Y. Lo",
      "Maciej A. Mazurowski"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.07995"
  },
  {
    "id": "arXiv:2011.08020",
    "title": "Resource theory of heat and work with non-commuting charges",
    "abstract": "Comments: 38 pages, 5 figures; v3 is the accepted journal version, title is shortened and more explanations and references added in many places",
    "descriptor": "\nComments: 38 pages, 5 figures; v3 is the accepted journal version, title is shortened and more explanations and references added in many places\n",
    "authors": [
      "Zahra Baghali Khanian",
      "Manabendra Nath Bera",
      "Arnau Riera",
      "Maciej Lewenstein",
      "Andreas Winter"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2011.08020"
  },
  {
    "id": "arXiv:2101.01519",
    "title": "Handling Hard Affine SDP Shape Constraints in RKHSs",
    "abstract": "Handling Hard Affine SDP Shape Constraints in RKHSs",
    "descriptor": "",
    "authors": [
      "Pierre-Cyril Aubin-Frankowski",
      "Zoltan Szabo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2101.01519"
  },
  {
    "id": "arXiv:2101.03735",
    "title": "Optimizing Biomanufacturing Harvesting Decisions under Limited  Historical Data",
    "abstract": "Comments: 38 pages, 6 figures",
    "descriptor": "\nComments: 38 pages, 6 figures\n",
    "authors": [
      "Bo Wang",
      "Wei Xie",
      "Tugce Martagan",
      "Alp Akcay",
      "Bram van Ravenstein"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.03735"
  },
  {
    "id": "arXiv:2101.11906",
    "title": "Development of a Vertex Finding Algorithm using Recurrent Neural Network",
    "abstract": "Comments: 16 pages, 9 figures",
    "descriptor": "\nComments: 16 pages, 9 figures\n",
    "authors": [
      "Kiichi Goto",
      "Taikan Suehara",
      "Tamaki Yoshioka",
      "Masakazu Kurata",
      "Hajime Nagahara",
      "Yuta Nakashima",
      "Noriko Takemura",
      "Masako Iwasaki"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2101.11906"
  },
  {
    "id": "arXiv:2103.02300",
    "title": "Combating District Heating Bottlenecks Using Load Control",
    "abstract": "Combating District Heating Bottlenecks Using Load Control",
    "descriptor": "",
    "authors": [
      "Felix Agner",
      "Pauline Kergus",
      "Richard Pates",
      "Anders Rantzer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.02300"
  },
  {
    "id": "arXiv:2103.02662",
    "title": "Deep Clustering by Semantic Contrastive Learning",
    "abstract": "Deep Clustering by Semantic Contrastive Learning",
    "descriptor": "",
    "authors": [
      "Jiabo Huang",
      "Shaogang Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.02662"
  },
  {
    "id": "arXiv:2103.14482",
    "title": "Converse extensionality and apartness",
    "abstract": "Comments: Fixed some more typos",
    "descriptor": "\nComments: Fixed some more typos\n",
    "authors": [
      "Benno van den Berg",
      "Robert Passmann"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2103.14482"
  },
  {
    "id": "arXiv:2104.02415",
    "title": "Multi-Robot Pickup and Delivery via Distributed Resource Allocation",
    "abstract": "Multi-Robot Pickup and Delivery via Distributed Resource Allocation",
    "descriptor": "",
    "authors": [
      "Andrea Camisa",
      "Andrea Testa",
      "Giuseppe Notarstefano"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2104.02415"
  },
  {
    "id": "arXiv:2104.03591",
    "title": "Unitary Subgroup Testing",
    "abstract": "Unitary Subgroup Testing",
    "descriptor": "",
    "authors": [
      "Zvika Brakerski",
      "Devika Sharma",
      "Guy Weissenberg"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2104.03591"
  },
  {
    "id": "arXiv:2104.03813",
    "title": "Can Differential Privacy Practically Protect Collaborative Deep Learning  Inference for the Internet of Things?",
    "abstract": "Comments: Accepted in Wireless Networks",
    "descriptor": "\nComments: Accepted in Wireless Networks\n",
    "authors": [
      "Jihyeon Ryu",
      "Yifeng Zheng",
      "Yansong Gao",
      "Sharif Abuadbba",
      "Junyaup Kim",
      "Dongho Won",
      "Surya Nepal",
      "Hyoungshick Kim",
      "Cong Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2104.03813"
  },
  {
    "id": "arXiv:2104.05065",
    "title": "The algebraic structure of the densification and the sparsification  tasks for CSPs",
    "abstract": "The algebraic structure of the densification and the sparsification  tasks for CSPs",
    "descriptor": "",
    "authors": [
      "Rustem Takhanov"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.05065"
  },
  {
    "id": "arXiv:2104.14856",
    "title": "Decidability of Two Truly Concurrent Equivalences for Finite Bounded  Petri Nets",
    "abstract": "Decidability of Two Truly Concurrent Equivalences for Finite Bounded  Petri Nets",
    "descriptor": "",
    "authors": [
      "Arnaldo Cesco",
      "Roberto Gorrieri"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.14856"
  },
  {
    "id": "arXiv:2105.01977",
    "title": "Limits and consistency of non-local and graph approximations to the  Eikonal equation",
    "abstract": "Limits and consistency of non-local and graph approximations to the  Eikonal equation",
    "descriptor": "",
    "authors": [
      "Jalal Fadili",
      "Nicolas Forcadel",
      "Thi Tuyen Nguyen",
      "Rita Zantout"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2105.01977"
  },
  {
    "id": "arXiv:2105.06194",
    "title": "Geometric Model Checking of Continuous Space",
    "abstract": "Geometric Model Checking of Continuous Space",
    "descriptor": "",
    "authors": [
      "Nick Bezhanishvili",
      "Vincenzo Ciancia",
      "David Gabelaia",
      "Gianluca Grilletti",
      "Diego Latella",
      "Mieke Massink"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2105.06194"
  },
  {
    "id": "arXiv:2105.07597",
    "title": "Variational Bandwidth Auto-encoder for Hybrid Recommender Systems",
    "abstract": "Variational Bandwidth Auto-encoder for Hybrid Recommender Systems",
    "descriptor": "",
    "authors": [
      "Yaochen Zhu",
      "Zhenzhong Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2105.07597"
  },
  {
    "id": "arXiv:2105.07761",
    "title": "Efficient Off-Policy Q-Learning for Data-Based Discrete-Time LQR  Problems",
    "abstract": "Efficient Off-Policy Q-Learning for Data-Based Discrete-Time LQR  Problems",
    "descriptor": "",
    "authors": [
      "Victor G. Lopez",
      "Mohammad Alsalti",
      "Matthias A. M\u00fcller"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.07761"
  },
  {
    "id": "arXiv:2105.11166",
    "title": "AirNet: Neural Network Transmission over the Air",
    "abstract": "AirNet: Neural Network Transmission over the Air",
    "descriptor": "",
    "authors": [
      "Mikolaj Jankowski",
      "Deniz Gunduz",
      "Krystian Mikolajczyk"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.11166"
  },
  {
    "id": "arXiv:2106.02700",
    "title": "A Discrete Variational Derivation of Accelerated Methods in Optimization",
    "abstract": "Comments: 33 pages, 11 figures",
    "descriptor": "\nComments: 33 pages, 11 figures\n",
    "authors": [
      "C\u00e9dric M. Campos",
      "Alejandro Mahillo",
      "David Mart\u00edn de Diego"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Differential Geometry (math.DG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.02700"
  },
  {
    "id": "arXiv:2106.03812",
    "title": "Neural Monge Map estimation and its applications",
    "abstract": "Neural Monge Map estimation and its applications",
    "descriptor": "",
    "authors": [
      "Jiaojiao Fan",
      "Shu Liu",
      "Shaojun Ma",
      "Haomin Zhou",
      "Yongxin Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.03812"
  },
  {
    "id": "arXiv:2106.06607",
    "title": "Invariance Principle Meets Information Bottleneck for  Out-of-Distribution Generalization",
    "abstract": "Invariance Principle Meets Information Bottleneck for  Out-of-Distribution Generalization",
    "descriptor": "",
    "authors": [
      "Kartik Ahuja",
      "Ethan Caballero",
      "Dinghuai Zhang",
      "Jean-Christophe Gagnon-Audet",
      "Yoshua Bengio",
      "Ioannis Mitliagkas",
      "Irina Rish"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.06607"
  },
  {
    "id": "arXiv:2106.10637",
    "title": "More than Encoder: Introducing Transformer Decoder to Upsample",
    "abstract": "Comments: 19 pages, 7 figures",
    "descriptor": "\nComments: 19 pages, 7 figures\n",
    "authors": [
      "Yijiang Li",
      "Wentian Cai",
      "Ying Gao",
      "Xiping Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.10637"
  },
  {
    "id": "arXiv:2106.10989",
    "title": "ImageNet Pre-training also Transfers Non-Robustness",
    "abstract": "Comments: Accepted by AAAI2023",
    "descriptor": "\nComments: Accepted by AAAI2023\n",
    "authors": [
      "Jiaming Zhang",
      "Jitao Sang",
      "Qi Yi",
      "Yunfan Yang",
      "Huiwen Dong",
      "Jian Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.10989"
  },
  {
    "id": "arXiv:2106.15791",
    "title": "Distributionally Robust Learning with Stable Adversarial Training",
    "abstract": "Comments: Accepted by Transactions on Knowledge and Data Engineering. Extension of AAAI paper (arXiv:2006.04414v2). arXiv admin note: substantial text overlap with arXiv:2006.04414",
    "descriptor": "\nComments: Accepted by Transactions on Knowledge and Data Engineering. Extension of AAAI paper (arXiv:2006.04414v2). arXiv admin note: substantial text overlap with arXiv:2006.04414\n",
    "authors": [
      "Jiashuo Liu",
      "Zheyan Shen",
      "Peng Cui",
      "Linjun Zhou",
      "Kun Kuang",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.15791"
  },
  {
    "id": "arXiv:2107.06961",
    "title": "On complete classes of valuated matroids",
    "abstract": "Comments: 53 pages, 13 figures. An extended abstract appeared in SODA 2022",
    "descriptor": "\nComments: 53 pages, 13 figures. An extended abstract appeared in SODA 2022\n",
    "authors": [
      "Edin Husi\u0107",
      "Georg Loho",
      "Ben Smith",
      "L\u00e1szl\u00f3 A. V\u00e9gh"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Computer Science and Game Theory (cs.GT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.06961"
  },
  {
    "id": "arXiv:2107.13058",
    "title": "On-Demand Delivery from Stores: Dynamic Dispatching and Routing with  Random Demand",
    "abstract": "On-Demand Delivery from Stores: Dynamic Dispatching and Routing with  Random Demand",
    "descriptor": "",
    "authors": [
      "Sheng Liu",
      "Zhixing Luo"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2107.13058"
  },
  {
    "id": "arXiv:2108.01152",
    "title": "Maximizing and Satisficing in Multi-armed Bandits with Graph Information",
    "abstract": "Maximizing and Satisficing in Multi-armed Bandits with Graph Information",
    "descriptor": "",
    "authors": [
      "Parth K.Thaker",
      "Mohit Malu",
      "Nikhil Rao",
      "Gautam Dasarathy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2108.01152"
  },
  {
    "id": "arXiv:2108.02697",
    "title": "A tight local algorithm for the minimum dominating set problem in  outerplanar graphs",
    "abstract": "Comments: Accepted to DISC 2021",
    "descriptor": "\nComments: Accepted to DISC 2021\n",
    "authors": [
      "Marthe Bonamy",
      "Linda Cook",
      "Carla Groenland",
      "Alexandra Wesolek"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2108.02697"
  },
  {
    "id": "arXiv:2108.06932",
    "title": "Polyp-PVT: Polyp Segmentation with Pyramid Vision Transformers",
    "abstract": "Comments: Technical Report",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Bo Dong",
      "Wenhai Wang",
      "Deng-Ping Fan",
      "Jinpeng Li",
      "Huazhu Fu",
      "Ling Shao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.06932"
  },
  {
    "id": "arXiv:2108.12734",
    "title": "Deep Dive into Semi-Supervised ELBO for Improving Classification  Performance",
    "abstract": "Comments: Under Review",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Fahim Faisal Niloy",
      "M. Ashraful Amin",
      "AKM Mahbubur Rahman",
      "Amin Ahsan Ali"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.12734"
  },
  {
    "id": "arXiv:2109.12525",
    "title": "Preconditioning for finite element methods with strain smoothing",
    "abstract": "Comments: 23 pages, 8 figures",
    "descriptor": "\nComments: 23 pages, 8 figures\n",
    "authors": [
      "Chaemin Lee",
      "Jongho Park"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.12525"
  },
  {
    "id": "arXiv:2110.00827",
    "title": "Deterministic Algorithms for the Hidden Subgroup Problem",
    "abstract": "Deterministic Algorithms for the Hidden Subgroup Problem",
    "descriptor": "",
    "authors": [
      "Zekun Ye",
      "Lvzhou Li"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.00827"
  },
  {
    "id": "arXiv:2110.08611",
    "title": "Deep Active Learning by Leveraging Training Dynamics",
    "abstract": "Comments: Accepted by NeurIPS 2022",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Haonan Wang",
      "Wei Huang",
      "Ziwei Wu",
      "Andrew Margenot",
      "Hanghang Tong",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08611"
  },
  {
    "id": "arXiv:2111.02926",
    "title": "OpenFWI: Large-Scale Multi-Structural Benchmark Datasets for Seismic  Full Waveform Inversion",
    "abstract": "Comments: This manuscript has been accepted by NeurIPS 2022 dataset and benchmark track",
    "descriptor": "\nComments: This manuscript has been accepted by NeurIPS 2022 dataset and benchmark track\n",
    "authors": [
      "Chengyuan Deng",
      "Shihang Feng",
      "Hanchen Wang",
      "Xitong Zhang",
      "Peng Jin",
      "Yinan Feng",
      "Qili Zeng",
      "Yinpeng Chen",
      "Youzuo Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.02926"
  },
  {
    "id": "arXiv:2111.06021",
    "title": "Probabilistic Contrastive Learning for Domain Adaptation",
    "abstract": "Comments: 12 pages,4 figures",
    "descriptor": "\nComments: 12 pages,4 figures\n",
    "authors": [
      "Junjie Li",
      "Yixin Zhang",
      "Zilei Wang",
      "Keyu Tu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.06021"
  },
  {
    "id": "arXiv:2111.08164",
    "title": "Recent Advances in Neural-symbolic Systems: A Survey",
    "abstract": "Recent Advances in Neural-symbolic Systems: A Survey",
    "descriptor": "",
    "authors": [
      "Dongran Yu",
      "Bo Yang",
      "Dayou Liu",
      "Hui Wang",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08164"
  },
  {
    "id": "arXiv:2111.08823",
    "title": "Meta-Auto-Decoder for Solving Parametric Partial Differential Equations",
    "abstract": "Meta-Auto-Decoder for Solving Parametric Partial Differential Equations",
    "descriptor": "",
    "authors": [
      "Xiang Huang",
      "Zhanhong Ye",
      "Hongsheng Liu",
      "Beiji Shi",
      "Zidong Wang",
      "Kang Yang",
      "Yang Li",
      "Bingya Weng",
      "Min Wang",
      "Haotian Chu",
      "Fan Yu",
      "Bei Hua",
      "Lei Chen",
      "Bin Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2111.08823"
  },
  {
    "id": "arXiv:2111.10698",
    "title": "Towards Graph Self-Supervised Learning with Contrastive Adjusted Zooming",
    "abstract": "Towards Graph Self-Supervised Learning with Contrastive Adjusted Zooming",
    "descriptor": "",
    "authors": [
      "Yizhen Zheng",
      "Ming Jin",
      "Shirui Pan",
      "Yuan-Fang Li",
      "Hao Peng",
      "Ming Li",
      "Zhao Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.10698"
  },
  {
    "id": "arXiv:2111.11000",
    "title": "PRISM: A Hierarchical Intrusion Detection Architecture for Large-Scale  Cyber Networks",
    "abstract": "PRISM: A Hierarchical Intrusion Detection Architecture for Large-Scale  Cyber Networks",
    "descriptor": "",
    "authors": [
      "Yahya Javed",
      "Mosab A. Khayat",
      "Ali A. Elghariani",
      "Arif Ghafoor"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.11000"
  },
  {
    "id": "arXiv:2111.11140",
    "title": "Novel ways of enumerating restrained dominating sets of cycles",
    "abstract": "Novel ways of enumerating restrained dominating sets of cycles",
    "descriptor": "",
    "authors": [
      "Sushmita Paul",
      "Ratanjeet Pratap Chauhan",
      "Srinibas Swain"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2111.11140"
  },
  {
    "id": "arXiv:2111.11294",
    "title": "Scaling Law for Recommendation Models: Towards General-purpose User  Representations",
    "abstract": "Comments: Accepted at AAAI 2023. This version includes the technical appendix",
    "descriptor": "\nComments: Accepted at AAAI 2023. This version includes the technical appendix\n",
    "authors": [
      "Kyuyong Shin",
      "Hanock Kwak",
      "Su Young Kim",
      "Max Nihlen Ramstrom",
      "Jisu Jeong",
      "Jung-Woo Ha",
      "Kyung-Min Kim"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.11294"
  },
  {
    "id": "arXiv:2111.12273",
    "title": "Sharpness-aware Quantization for Deep Neural Networks",
    "abstract": "Comments: Tech report",
    "descriptor": "\nComments: Tech report\n",
    "authors": [
      "Jing Liu",
      "Jianfei Cai",
      "Bohan Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12273"
  },
  {
    "id": "arXiv:2111.12663",
    "title": "PointPCA: Point Cloud Objective Quality Assessment Using PCA-Based  Descriptors",
    "abstract": "Comments: 10 pages, 4 figures, 3 tables",
    "descriptor": "\nComments: 10 pages, 4 figures, 3 tables\n",
    "authors": [
      "Evangelos Alexiou",
      "Xuemei Zhou",
      "Irene Viola",
      "Pablo Cesar"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2111.12663"
  },
  {
    "id": "arXiv:2112.03860",
    "title": "Differentiable Gaussianization Layers for Inverse Problems Regularized  by Deep Generative Models",
    "abstract": "Comments: 33 pages, 21 figures, 11 tables",
    "descriptor": "\nComments: 33 pages, 21 figures, 11 tables\n",
    "authors": [
      "Dongzhuo Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03860"
  },
  {
    "id": "arXiv:2112.05941",
    "title": "Learning Efficient Policies for Picking Entangled Wire Harnesses: A  Solution to Industrial Bin Picking",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Xinyi Zhang",
      "Yukiyasu Domae",
      "Weiwei Wan",
      "Kensuke Harada"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.05941"
  },
  {
    "id": "arXiv:2112.12371",
    "title": "DENSE: Data-Free One-Shot Federated Learning",
    "abstract": "Comments: Accepted by NeurIPS 2022",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Jie Zhang",
      "Chen Chen",
      "Bo Li",
      "Lingjuan Lyu",
      "Shuang Wu",
      "Shouhong Ding",
      "Chunhua Shen",
      "Chao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12371"
  },
  {
    "id": "arXiv:2201.01787",
    "title": "Does Entity Abstraction Help Generative Transformers Reason?",
    "abstract": "Comments: TMLR 2022; 28 pages; 9 tables; 1 figure",
    "descriptor": "\nComments: TMLR 2022; 28 pages; 9 tables; 1 figure\n",
    "authors": [
      "Nicolas Gontier",
      "Siva Reddy",
      "Christopher Pal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.01787"
  },
  {
    "id": "arXiv:2201.02088",
    "title": "Deep Causal Reasoning for Recommendations",
    "abstract": "Deep Causal Reasoning for Recommendations",
    "descriptor": "",
    "authors": [
      "Yaochen Zhu",
      "Jing Yi",
      "Jiayi Xie",
      "Zhenzhong Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2201.02088"
  },
  {
    "id": "arXiv:2201.02496",
    "title": "Tower-Complete Problems in Contraction-Free Substructural Logics",
    "abstract": "Comments: The full version of the paper accepted to CSL 2023",
    "descriptor": "\nComments: The full version of the paper accepted to CSL 2023\n",
    "authors": [
      "Hiromi Tanaka"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2201.02496"
  },
  {
    "id": "arXiv:2201.02901",
    "title": "A FEAST SVDsolver based on Chebyshev--Jackson series for computing  partial singular triplets of large matrices",
    "abstract": "Comments: 33, 5 figures",
    "descriptor": "\nComments: 33, 5 figures\n",
    "authors": [
      "Zhongxiao Jia",
      "Kailiang Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.02901"
  },
  {
    "id": "arXiv:2201.03103",
    "title": "Dual Seminorms, Ergodic Coefficients and Semicontraction Theory",
    "abstract": "Dual Seminorms, Ergodic Coefficients and Semicontraction Theory",
    "descriptor": "",
    "authors": [
      "Giulia De Pasquale",
      "Kevin D. Smith",
      "Francesco Bullo",
      "Maria Elena Valcher"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2201.03103"
  },
  {
    "id": "arXiv:2201.06545",
    "title": "OntoDSumm : Ontology based Tweet Summarization for Disaster Events",
    "abstract": "OntoDSumm : Ontology based Tweet Summarization for Disaster Events",
    "descriptor": "",
    "authors": [
      "Piyush Kumar Garg",
      "Roshni Chakraborty",
      "Sourav Kumar Dandapat"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2201.06545"
  },
  {
    "id": "arXiv:2201.08066",
    "title": "NLP Methods in Host-based Intrusion Detection Systems: A Systematic  Review and Future Directions",
    "abstract": "NLP Methods in Host-based Intrusion Detection Systems: A Systematic  Review and Future Directions",
    "descriptor": "",
    "authors": [
      "Zarrin Tasnim Sworna",
      "Zahra Mousavi",
      "Muhammad Ali Babar"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.08066"
  },
  {
    "id": "arXiv:2201.08504",
    "title": "Deep reinforcement learning under signal temporal logic constraints  using Lagrangian relaxation",
    "abstract": "Comments: 16 pages, 20 figures, accepted for IEEE Access",
    "descriptor": "\nComments: 16 pages, 20 figures, accepted for IEEE Access\n",
    "authors": [
      "Junya Ikemoto",
      "Toshimitsu Ushio"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.08504"
  },
  {
    "id": "arXiv:2201.11582",
    "title": "GUDN: A novel guide network with label reinforcement strategy for  extreme multi-label text classification",
    "abstract": "Comments: 12 pages, 6 figures",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Qing Wang",
      "Jia Zhu",
      "Hongji Shu",
      "Kwame Omono Asamoah",
      "Jianyang Shi",
      "Cong Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.11582"
  },
  {
    "id": "arXiv:2201.11676",
    "title": "Monitoring Model Deterioration with Explainable Uncertainty Estimation  via Non-parametric Bootstrap",
    "abstract": "Comments: 7+6 pages",
    "descriptor": "\nComments: 7+6 pages\n",
    "authors": [
      "Carlos Mougan",
      "Dan Saattrup Nielsen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.11676"
  },
  {
    "id": "arXiv:2201.11808",
    "title": "LAP: An Attention-Based Module for Faithful Interpretation and Knowledge  Injection in Convolutional Neural Networks",
    "abstract": "LAP: An Attention-Based Module for Faithful Interpretation and Knowledge  Injection in Convolutional Neural Networks",
    "descriptor": "",
    "authors": [
      "Rassa Ghavami Modegh",
      "Ahmad Salimi",
      "Alireza Dizaji",
      "Hamid R. Rabiee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11808"
  },
  {
    "id": "arXiv:2201.11965",
    "title": "Provably Efficient Primal-Dual Reinforcement Learning for CMDPs with  Non-stationary Objectives and Constraints",
    "abstract": "Comments: 32 pages, AAAI 2023",
    "descriptor": "\nComments: 32 pages, AAAI 2023\n",
    "authors": [
      "Yuhao Ding",
      "Javad Lavaei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11965"
  },
  {
    "id": "arXiv:2201.12094",
    "title": "Leveraging Inlier Correspondences Proportion for Point Cloud  Registration",
    "abstract": "Leveraging Inlier Correspondences Proportion for Point Cloud  Registration",
    "descriptor": "",
    "authors": [
      "Lifa Zhu",
      "Haining Guan",
      "Changwei Lin",
      "Renmin Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12094"
  },
  {
    "id": "arXiv:2201.12513",
    "title": "The Geography of Facebook Groups in the United States",
    "abstract": "Comments: To be presented at AAAI ICWSM '23. Replication data is available at this https URL",
    "descriptor": "\nComments: To be presented at AAAI ICWSM '23. Replication data is available at this https URL\n",
    "authors": [
      "Ama\u00e7 Herda\u011fdelen",
      "Lada Adamic",
      "Bogdan State"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2201.12513"
  },
  {
    "id": "arXiv:2201.12826",
    "title": "Optimizing Gradient-driven Criteria in Network Sparsity",
    "abstract": "Comments: 11 pages, 4 figures",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Yuxin Zhang",
      "Mingbao Lin",
      "Mengzhao Chen",
      "Fei Chao",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12826"
  },
  {
    "id": "arXiv:2201.13250",
    "title": "Differentiating and Integrating ZX Diagrams with Applications to Quantum  Machine Learning",
    "abstract": "Comments: 37 pages, 3 authors now, more results",
    "descriptor": "\nComments: 37 pages, 3 authors now, more results\n",
    "authors": [
      "Quanlong Wang",
      "Richie Yeung",
      "Mark Koch"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.13250"
  },
  {
    "id": "arXiv:2202.03999",
    "title": "A general framework for quantifying uncertainty at scale",
    "abstract": "Comments: 19 pages, 6 figures, 1 table",
    "descriptor": "\nComments: 19 pages, 6 figures, 1 table\n",
    "authors": [
      "Ionut-Gabriel Farcas",
      "Gabriele Merlo",
      "Frank Jenko"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Plasma Physics (physics.plasm-ph)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.03999"
  },
  {
    "id": "arXiv:2202.04235",
    "title": "Towards Compositional Adversarial Robustness: Generalizing Adversarial  Training to Composite Semantic Perturbations",
    "abstract": "Towards Compositional Adversarial Robustness: Generalizing Adversarial  Training to Composite Semantic Perturbations",
    "descriptor": "",
    "authors": [
      "Lei Hsiung",
      "Yun-Yun Tsai",
      "Pin-Yu Chen",
      "Tsung-Yi Ho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.04235"
  },
  {
    "id": "arXiv:2202.04777",
    "title": "Exact Solutions of a Deep Linear Network",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Liu Ziyin",
      "Botao Li",
      "Xiangming Meng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04777"
  },
  {
    "id": "arXiv:2202.06533",
    "title": "An Introduction to Neural Data Compression",
    "abstract": "An Introduction to Neural Data Compression",
    "descriptor": "",
    "authors": [
      "Yibo Yang",
      "Stephan Mandt",
      "Lucas Theis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.06533"
  },
  {
    "id": "arXiv:2202.07122",
    "title": "Gigahertz Sub-Landauer Momentum Computing",
    "abstract": "Comments: 18 pages, 11 figures, 5 appendices; this http URL",
    "descriptor": "\nComments: 18 pages, 11 figures, 5 appendices; this http URL\n",
    "authors": [
      "Kyle J. Ray",
      "James P. Crutchfield"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Emerging Technologies (cs.ET)",
      "Dynamical Systems (math.DS)",
      "Chaotic Dynamics (nlin.CD)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.07122"
  },
  {
    "id": "arXiv:2202.07464",
    "title": "Excitement Surfeited Turns to Errors: Deep Learning Testing Framework  Based on Excitable Neurons",
    "abstract": "Comments: 32 pages",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Haibo Jin",
      "Ruoxi Chen",
      "Haibin Zheng",
      "Jinyin Chen",
      "Yao Cheng",
      "Yue Yu",
      "Xianglong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07464"
  },
  {
    "id": "arXiv:2202.07778",
    "title": "Beyond Deterministic Translation for Unsupervised Domain Adaptation",
    "abstract": "Comments: Accepted at BMVC 2022. Code is available at this https URL",
    "descriptor": "\nComments: Accepted at BMVC 2022. Code is available at this https URL\n",
    "authors": [
      "Eleni Chiou",
      "Eleftheria Panagiotaki",
      "Iasonas Kokkinos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07778"
  },
  {
    "id": "arXiv:2202.08235",
    "title": "Data Augmentation for Deep Graph Learning: A Survey",
    "abstract": "Comments: Accepted by SIGKDD Explorations Paper list: this https URL",
    "descriptor": "\nComments: Accepted by SIGKDD Explorations Paper list: this https URL\n",
    "authors": [
      "Kaize Ding",
      "Zhe Xu",
      "Hanghang Tong",
      "Huan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08235"
  },
  {
    "id": "arXiv:2202.09115",
    "title": "Towards Simple and Accurate Human Pose Estimation with Stair Network",
    "abstract": "Comments: The paper has been accepted by IEEE Transactions on Emerging Topics in Computational Intelligence",
    "descriptor": "\nComments: The paper has been accepted by IEEE Transactions on Emerging Topics in Computational Intelligence\n",
    "authors": [
      "Chenru Jiang",
      "Kaizhu Huang",
      "Shufei Zhang",
      "Shufei Zhang",
      "Jimin Xiao",
      "Zhenxing Niu",
      "Amir Hussain"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.09115"
  },
  {
    "id": "arXiv:2202.10553",
    "title": "Guidelines and Evaluation of Clinical Explainable AI in Medical Image  Analysis",
    "abstract": "Comments: Code: this http URL, Supplementary Material S1 and S2: this https URL",
    "descriptor": "\nComments: Code: this http URL, Supplementary Material S1 and S2: this https URL\n",
    "authors": [
      "Weina Jin",
      "Xiaoxiao Li",
      "Mostafa Fatehi",
      "Ghassan Hamarneh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.10553"
  },
  {
    "id": "arXiv:2202.10746",
    "title": "CD-ROM: Complemented Deep-Reduced Order Model",
    "abstract": "Comments: Submitted to the Journal of Computational Physics",
    "descriptor": "\nComments: Submitted to the Journal of Computational Physics\n",
    "authors": [
      "Emmanuel Menier",
      "Michele Alessandro Bucci",
      "Mouadh Yagoubi",
      "Lionel Mathelin",
      "Marc Schoenauer"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.10746"
  },
  {
    "id": "arXiv:2202.10977",
    "title": "Organ Shape Sensing using Pneumatically Attachable Flexible Rails in  Robotic-Assisted Laparoscopic Surgery",
    "abstract": "Comments: 9 pages, 11 figures",
    "descriptor": "\nComments: 9 pages, 11 figures\n",
    "authors": [
      "Aoife McDonald-Bowyer",
      "Sol\u00e8ne Dietsch",
      "Emmanouil Dimitrakakis",
      "Joanna M Coote",
      "Lukas Lindenroth",
      "Danail Stoyanov",
      "Agostino Stilli"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.10977"
  },
  {
    "id": "arXiv:2202.12278",
    "title": "Learning Stochastic Dynamics with Statistics-Informed Neural Network",
    "abstract": "Learning Stochastic Dynamics with Statistics-Informed Neural Network",
    "descriptor": "",
    "authors": [
      "Yuanran Zhu",
      "Yu-Hang Tang",
      "Changho Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Artificial Intelligence (cs.AI)",
      "Dynamical Systems (math.DS)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.12278"
  },
  {
    "id": "arXiv:2202.12309",
    "title": "Parthenon -- a performance portable block-structured adaptive mesh  refinement framework",
    "abstract": "Comments: 17 pages, 11 figures, accepted for publication in IJHPCA, Codes available at this https URL",
    "descriptor": "\nComments: 17 pages, 11 figures, accepted for publication in IJHPCA, Codes available at this https URL\n",
    "authors": [
      "Philipp Grete",
      "Joshua C. Dolence",
      "Jonah M. Miller",
      "Joshua Brown",
      "Ben Ryan",
      "Andrew Gaspar",
      "Forrest Glines",
      "Sriram Swaminarayan",
      "Jonas Lippuner",
      "Clell J. Solomon",
      "Galen Shipman",
      "Christoph Junghans",
      "Daniel Holladay",
      "James M. Stone",
      "Luke F. Roberts"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)"
    ],
    "url": "https://arxiv.org/abs/2202.12309"
  },
  {
    "id": "arXiv:2202.12938",
    "title": "Assessing the State of Self-Supervised Human Activity Recognition using  Wearables",
    "abstract": "Comments: updated",
    "descriptor": "\nComments: updated\n",
    "authors": [
      "Harish Haresamudram",
      "Irfan Essa",
      "Thomas Pl\u00f6tz"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12938"
  },
  {
    "id": "arXiv:2202.13677",
    "title": "The Complexity of Evaluating nfer",
    "abstract": "The Complexity of Evaluating nfer",
    "descriptor": "",
    "authors": [
      "Sean Kauffman",
      "Martin Zimmermann"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.13677"
  },
  {
    "id": "arXiv:2203.00949",
    "title": "GAP: Differentially Private Graph Neural Networks with Aggregation  Perturbation",
    "abstract": "Comments: Accepted at USENIX Security '23",
    "descriptor": "\nComments: Accepted at USENIX Security '23\n",
    "authors": [
      "Sina Sajadmanesh",
      "Ali Shahin Shamsabadi",
      "Aur\u00e9lien Bellet",
      "Daniel Gatica-Perez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.00949"
  },
  {
    "id": "arXiv:2203.01644",
    "title": "UDAAN: Machine Learning based Post-Editing tool for Document Translation",
    "abstract": "Comments: Demo paper at CoDS-COMAD 2023. Vist project website at this https URL",
    "descriptor": "\nComments: Demo paper at CoDS-COMAD 2023. Vist project website at this https URL\n",
    "authors": [
      "Ayush Maheshwari",
      "Ajay Ravindran",
      "Venkatapathy Subramanian",
      "Ganesh Ramakrishnan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.01644"
  },
  {
    "id": "arXiv:2203.02836",
    "title": "Recursive Monte Carlo and Variational Inference with Auxiliary Variables",
    "abstract": "Comments: version published at UAI",
    "descriptor": "\nComments: version published at UAI\n",
    "authors": [
      "Alexander K. Lew",
      "Marco Cusumano-Towner",
      "Vikash K. Mansinghka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2203.02836"
  },
  {
    "id": "arXiv:2203.03821",
    "title": "CF-ViT: A General Coarse-to-Fine Method for Vision Transformer",
    "abstract": "Comments: Accepted by AAAI 2023",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Mengzhao Chen",
      "Mingbao Lin",
      "Ke Li",
      "Yunhang Shen",
      "Yongjian Wu",
      "Fei Chao",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03821"
  },
  {
    "id": "arXiv:2203.05242",
    "title": "Conditional Synthetic Data Generation for Personal Thermal Comfort  Models",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2109.06486",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2109.06486\n",
    "authors": [
      "Hari Prasanna Das",
      "Costas J. Spanos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.05242"
  },
  {
    "id": "arXiv:2203.08176",
    "title": "SemiPFL: Personalized Semi-Supervised Federated Learning Framework for  Edge Intelligence",
    "abstract": "SemiPFL: Personalized Semi-Supervised Federated Learning Framework for  Edge Intelligence",
    "descriptor": "",
    "authors": [
      "Arvin Tashakori",
      "Wenwen Zhang",
      "Z. Jane Wang",
      "Peyman Servati"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.08176"
  },
  {
    "id": "arXiv:2203.08921",
    "title": "Hybrid Pixel-Unshuffled Network for Lightweight Image Super-Resolution",
    "abstract": "Hybrid Pixel-Unshuffled Network for Lightweight Image Super-Resolution",
    "descriptor": "",
    "authors": [
      "Bin Sun",
      "Yulun Zhang",
      "Songyao Jiang",
      "Yun Fu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08921"
  },
  {
    "id": "arXiv:2203.10766",
    "title": "An In-Depth Comparative Analysis of Cloud Block Storage Workloads:  Findings and Implications",
    "abstract": "Comments: 30 pages. Accepted by ACM Transactions on Storage",
    "descriptor": "\nComments: 30 pages. Accepted by ACM Transactions on Storage\n",
    "authors": [
      "Jinhong Li",
      "Qiuping Wang",
      "Patrick P. C. Lee",
      "Chao Shi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.10766"
  },
  {
    "id": "arXiv:2203.10774",
    "title": "Fictitious Play with Maximin Initialization",
    "abstract": "Fictitious Play with Maximin Initialization",
    "descriptor": "",
    "authors": [
      "Sam Ganzfried"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2203.10774"
  },
  {
    "id": "arXiv:2203.10846",
    "title": "Data-driven predictive control in a stochastic setting: a unified  framework",
    "abstract": "Comments: 17 pages, 12 figures",
    "descriptor": "\nComments: 17 pages, 12 figures\n",
    "authors": [
      "Valentina Breschi",
      "Alessandro Chiuso",
      "Simone Formentin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.10846"
  },
  {
    "id": "arXiv:2203.12285",
    "title": "Towards Effective Clustered Federated Learning: A Peer-to-peer Framework  with Adaptive Neighbor Matching",
    "abstract": "Comments: Published in IEEE Transactions on Big Data, 2022",
    "descriptor": "\nComments: Published in IEEE Transactions on Big Data, 2022\n",
    "authors": [
      "Zexi Li",
      "Jiaxun Lu",
      "Shuang Luo",
      "Didi Zhu",
      "Yunfeng Shao",
      "Yinchuan Li",
      "Zhimeng Zhang",
      "Yongheng Wang",
      "Chao Wu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.12285"
  },
  {
    "id": "arXiv:2203.15574",
    "title": "Quantum compiling with variational instruction set for accurate and fast  quantum computing",
    "abstract": "Comments: 7 pages, 4 figures",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Ying Lu",
      "Peng-Fei Zhou",
      "Shao-Ming Fei",
      "Shi-Ju Ran"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.15574"
  },
  {
    "id": "arXiv:2203.16217",
    "title": "Improved Convergence Rate of Stochastic Gradient Langevin Dynamics with  Variance Reduction and its Application to Optimization",
    "abstract": "Improved Convergence Rate of Stochastic Gradient Langevin Dynamics with  Variance Reduction and its Application to Optimization",
    "descriptor": "",
    "authors": [
      "Yuri Kinoshita",
      "Taiji Suzuki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.16217"
  },
  {
    "id": "arXiv:2204.00453",
    "title": "Optimal Management of a Smart Port with Shore-Connection and Hydrogen  Supplying by Stochastic Model Predictive Control",
    "abstract": "Optimal Management of a Smart Port with Shore-Connection and Hydrogen  Supplying by Stochastic Model Predictive Control",
    "descriptor": "",
    "authors": [
      "Francesco Conte",
      "Fabio D'Agostino",
      "Daniele Kaza",
      "Stefano Massucco",
      "Gianluca Natrella",
      "Federico Silvestro"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.00453"
  },
  {
    "id": "arXiv:2204.00466",
    "title": "Improved Soft-aided Decoding of Product Codes with Dynamic Reliability  Scores",
    "abstract": "Improved Soft-aided Decoding of Product Codes with Dynamic Reliability  Scores",
    "descriptor": "",
    "authors": [
      "Sisi Miao",
      "Lukas Rapp",
      "Laurent Schmalen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.00466"
  },
  {
    "id": "arXiv:2204.00943",
    "title": "Efficient Convolutional Neural Networks on Raspberry Pi for Image  Classification",
    "abstract": "Efficient Convolutional Neural Networks on Raspberry Pi for Image  Classification",
    "descriptor": "",
    "authors": [
      "Rui-Yang Ju",
      "Ting-Yu Lin",
      "Jia-Hao Jian",
      "Jen-Shiun Chiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.00943"
  },
  {
    "id": "arXiv:2204.01089",
    "title": "VRKG4Rec: Virtual Relational Knowledge Graphs for Recommendation",
    "abstract": "VRKG4Rec: Virtual Relational Knowledge Graphs for Recommendation",
    "descriptor": "",
    "authors": [
      "Lingyun Lu",
      "Bang Wang",
      "Zizhuo Zhang",
      "Shenghao Liu",
      "Han Xu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.01089"
  },
  {
    "id": "arXiv:2204.01244",
    "title": "Dynamic Focus-aware Positional Queries for Semantic Segmentation",
    "abstract": "Comments: Tech report",
    "descriptor": "\nComments: Tech report\n",
    "authors": [
      "Haoyu He",
      "Jianfei Cai",
      "Zizheng Pan",
      "Jing Liu",
      "Jing Zhang",
      "Dacheng Tao",
      "Bohan Zhuang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.01244"
  },
  {
    "id": "arXiv:2204.03974",
    "title": "A General Framework for Hierarchical Redundancy Resolution Under  Arbitrary Constraints",
    "abstract": "Comments: Submitted to Transactions on Robotics (T-RO). Currently under the second round of review",
    "descriptor": "\nComments: Submitted to Transactions on Robotics (T-RO). Currently under the second round of review\n",
    "authors": [
      "Mario D. Fiore",
      "Gaetano Meli",
      "Anton Ziese",
      "Bruno Siciliano",
      "Ciro Natale"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.03974"
  },
  {
    "id": "arXiv:2204.04440",
    "title": "Are Two Heads the Same as One? Identifying Disparate Treatment in Fair  Neural Networks",
    "abstract": "Comments: Accepted at NeurIPS 2022",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Michael Lohaus",
      "Matth\u00e4us Kleindessner",
      "Krishnaram Kenthapadi",
      "Francesco Locatello",
      "Chris Russell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.04440"
  },
  {
    "id": "arXiv:2204.04853",
    "title": "Neural Lagrangian Schr\u00f6dinger Bridge",
    "abstract": "Neural Lagrangian Schr\u00f6dinger Bridge",
    "descriptor": "",
    "authors": [
      "Takeshi Koshizuka",
      "Issei Sato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2204.04853"
  },
  {
    "id": "arXiv:2204.05351",
    "title": "Graph Ordering Attention Networks",
    "abstract": "Comments: Accepted at AAAI 2023",
    "descriptor": "\nComments: Accepted at AAAI 2023\n",
    "authors": [
      "Michail Chatzianastasis",
      "Johannes F. Lutzeyer",
      "George Dasoulas",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05351"
  },
  {
    "id": "arXiv:2204.07110",
    "title": "Generative power of a protein language model trained on multiple  sequence alignments",
    "abstract": "Comments: 46 pages, 20 figures, 6 tables",
    "descriptor": "\nComments: 46 pages, 20 figures, 6 tables\n",
    "authors": [
      "Damiano Sgarbossa",
      "Umberto Lupo",
      "Anne-Florence Bitbol"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2204.07110"
  },
  {
    "id": "arXiv:2204.07196",
    "title": "Testing distributional assumptions of learning algorithms",
    "abstract": "Testing distributional assumptions of learning algorithms",
    "descriptor": "",
    "authors": [
      "Ronitt Rubinfeld",
      "Arsen Vasilyan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.07196"
  },
  {
    "id": "arXiv:2204.07417",
    "title": "Safe Reinforcement Learning Using Black-Box Reachability Analysis",
    "abstract": "Comments: This paper is accepted at IEEE Robotics and Automation Letters and International Conference on Robotics and Automation (ICRA)",
    "descriptor": "\nComments: This paper is accepted at IEEE Robotics and Automation Letters and International Conference on Robotics and Automation (ICRA)\n",
    "authors": [
      "Mahmoud Selim",
      "Amr Alanwar",
      "Shreyas Kousik",
      "Grace Gao",
      "Marco Pavone",
      "Karl H. Johansson"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.07417"
  },
  {
    "id": "arXiv:2204.07971",
    "title": "On strong avoiding games",
    "abstract": "Comments: 23 pages",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Milo\u0161 Stojakovi\u0107",
      "Jelena Stratijev"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2204.07971"
  },
  {
    "id": "arXiv:2204.08319",
    "title": "Backward Reachability Analysis for Neural Feedback Loops",
    "abstract": "Comments: 8 pages, 5 figures",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Nicholas Rober",
      "Michael Everett",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.08319"
  },
  {
    "id": "arXiv:2204.08765",
    "title": "Speech Dereverberation with A Reverberation Time Shortening Target",
    "abstract": "Comments: Submitted to ICASSP 2023",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Rui Zhou",
      "Wenye Zhu",
      "Xiaofei Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.08765"
  },
  {
    "id": "arXiv:2204.09035",
    "title": "Massively Parallel Computation on Embedded Planar Graphs",
    "abstract": "Comments: To appear at SODA 2023",
    "descriptor": "\nComments: To appear at SODA 2023\n",
    "authors": [
      "Jacob Holm",
      "Jakub T\u011btek"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.09035"
  },
  {
    "id": "arXiv:2204.09093",
    "title": "Behind the Machine's Gaze: Neural Networks with Biologically-inspired  Constraints Exhibit Human-like Visual Attention",
    "abstract": "Comments: 31 pages, 14 figures, 4 tables",
    "descriptor": "\nComments: 31 pages, 14 figures, 4 tables\n",
    "authors": [
      "Leo Schwinn",
      "Doina Precup",
      "Bj\u00f6rn Eskofier",
      "Dario Zanca"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.09093"
  },
  {
    "id": "arXiv:2204.09810",
    "title": "Deep transfer operator learning for partial differential equations under  conditional shift",
    "abstract": "Comments: 33 pages, 9 figures",
    "descriptor": "\nComments: 33 pages, 9 figures\n",
    "authors": [
      "Somdatta Goswami",
      "Katiana Kontolati",
      "Michael D. Shields",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.09810"
  },
  {
    "id": "arXiv:2204.11695",
    "title": "Estimation of Reliable Proposal Quality for Temporal Action Detection",
    "abstract": "Comments: Accepted to ACM Multimedia 2022",
    "descriptor": "\nComments: Accepted to ACM Multimedia 2022\n",
    "authors": [
      "Junshan Hu",
      "Chaoxu guo",
      "Liansheng Zhuang",
      "Biao Wang",
      "Tiezheng Ge",
      "Yuning Jiang",
      "Houqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.11695"
  },
  {
    "id": "arXiv:2204.13281",
    "title": "Efficient Autonomous Navigation for Terrestrial Insect-Machine Hybrid  Systems",
    "abstract": "Comments: Demonstration video can be found at this http URL",
    "descriptor": "\nComments: Demonstration video can be found at this http URL\n",
    "authors": [
      "Huu Duoc Nguyen",
      "Van Than Dung",
      "Hirotaka Sato",
      "T. Thang Vo-Doan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.13281"
  },
  {
    "id": "arXiv:2205.03202",
    "title": "Perseus: A Simple and Optimal High-Order Method for Variational  Inequalities",
    "abstract": "Comments: Improve the paper writing significantly; 38 pages",
    "descriptor": "\nComments: Improve the paper writing significantly; 38 pages\n",
    "authors": [
      "Tianyi Lin",
      "Michael. I. Jordan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.03202"
  },
  {
    "id": "arXiv:2205.03883",
    "title": "WKGM: Weight-K-space Generative Model for Parallel Imaging  Reconstruction",
    "abstract": "Comments: 11pages, 12 figures",
    "descriptor": "\nComments: 11pages, 12 figures\n",
    "authors": [
      "Zongjiang Tu",
      "Die Liu",
      "Xiaoqing Wang",
      "Chen Jiang",
      "Minghui Zhang",
      "Shanshan Wang",
      "Qiegen Liu",
      "Dong Liang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.03883"
  },
  {
    "id": "arXiv:2205.05862",
    "title": "AdaVAE: Exploring Adaptive GPT-2s in Variational Auto-Encoders for  Language Modeling",
    "abstract": "AdaVAE: Exploring Adaptive GPT-2s in Variational Auto-Encoders for  Language Modeling",
    "descriptor": "",
    "authors": [
      "Haoqin Tu",
      "Zhongliang Yang",
      "Jinshuai Yang",
      "Yongfeng Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.05862"
  },
  {
    "id": "arXiv:2205.08996",
    "title": "A general framework for optimising cost-effectiveness of pandemic  response under partial intervention measures",
    "abstract": "A general framework for optimising cost-effectiveness of pandemic  response under partial intervention measures",
    "descriptor": "",
    "authors": [
      "Quang Dang Nguyen",
      "Mikhail Prokopenko"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "General Economics (econ.GN)",
      "Physics and Society (physics.soc-ph)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2205.08996"
  },
  {
    "id": "arXiv:2205.09180",
    "title": "LeRaC: Learning Rate Curriculum",
    "abstract": "Comments: Main paper + supplementary",
    "descriptor": "\nComments: Main paper + supplementary\n",
    "authors": [
      "Florinel-Alin Croitoru",
      "Nicolae-Catalin Ristea",
      "Radu Tudor Ionescu",
      "Nicu Sebe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09180"
  },
  {
    "id": "arXiv:2205.10327",
    "title": "What's the Harm? Sharp Bounds on the Fraction Negatively Affected by  Treatment",
    "abstract": "What's the Harm? Sharp Bounds on the Fraction Negatively Affected by  Treatment",
    "descriptor": "",
    "authors": [
      "Nathan Kallus"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.10327"
  },
  {
    "id": "arXiv:2205.10498",
    "title": "Named Entity Linking with Entity Representation by Multiple Embeddings",
    "abstract": "Comments: 12 pages, 14 figures, 2 tables",
    "descriptor": "\nComments: 12 pages, 14 figures, 2 tables\n",
    "authors": [
      "Oleg Vasilyev",
      "Alex Dauenhauer",
      "Vedant Dharnidharka",
      "John Bohannon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.10498"
  },
  {
    "id": "arXiv:2205.10655",
    "title": "Swept-Angle Synthetic Wavelength Interferometry",
    "abstract": "Swept-Angle Synthetic Wavelength Interferometry",
    "descriptor": "",
    "authors": [
      "Alankar Kotwal",
      "Anat Levin",
      "Ioannis Gkioulekas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2205.10655"
  },
  {
    "id": "arXiv:2205.11083",
    "title": "Deep Digging into the Generalization of Self-supervised Monocular Depth  Estimation",
    "abstract": "Comments: Accepted to AAAI 2023",
    "descriptor": "\nComments: Accepted to AAAI 2023\n",
    "authors": [
      "Jinwoo Bae",
      "Sungho Moon",
      "Sunghoon Im"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11083"
  },
  {
    "id": "arXiv:2205.11184",
    "title": "An Evaluation Study of Intrinsic Motivation Techniques applied to  Reinforcement Learning over Hard Exploration Environments",
    "abstract": "Comments: 21 pages, 5 figures, 5 tables",
    "descriptor": "\nComments: 21 pages, 5 figures, 5 tables\n",
    "authors": [
      "Alain Andres",
      "Esther Villar-Rodriguez",
      "Javier Del Ser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.11184"
  },
  {
    "id": "arXiv:2205.12021",
    "title": "PatchNR: Learning from Very Few Images by Patch Normalizing Flow  Regularization",
    "abstract": "PatchNR: Learning from Very Few Images by Patch Normalizing Flow  Regularization",
    "descriptor": "",
    "authors": [
      "Fabian Altekr\u00fcger",
      "Alexander Denker",
      "Paul Hagemann",
      "Johannes Hertrich",
      "Peter Maass",
      "Gabriele Steidl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2205.12021"
  },
  {
    "id": "arXiv:2205.12735",
    "title": "Inductive Learning of Complex Knowledge from Raw Data",
    "abstract": "Inductive Learning of Complex Knowledge from Raw Data",
    "descriptor": "",
    "authors": [
      "Daniel Cunnington",
      "Mark Law",
      "Jorge Lobo",
      "Alessandra Russo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.12735"
  },
  {
    "id": "arXiv:2205.12870",
    "title": "Open-Domain Sign Language Translation Learned from Online Video",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Bowen Shi",
      "Diane Brentari",
      "Greg Shakhnarovich",
      "Karen Livescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12870"
  },
  {
    "id": "arXiv:2205.13341",
    "title": "QUIC-FL: Quick Unbiased Compression for Federated Learning",
    "abstract": "QUIC-FL: Quick Unbiased Compression for Federated Learning",
    "descriptor": "",
    "authors": [
      "Ran Ben Basat",
      "Shay Vargaftik",
      "Amit Portnoy",
      "Gil Einziger",
      "Yaniv Ben-Itzhak",
      "Michael Mitzenmacher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.13341"
  },
  {
    "id": "arXiv:2205.13872",
    "title": "Self-Admitted Technical Debt in the Embedded Systems Industry: An  Exploratory Case Study",
    "abstract": "Self-Admitted Technical Debt in the Embedded Systems Industry: An  Exploratory Case Study",
    "descriptor": "",
    "authors": [
      "Yikun Li",
      "Mohamed Soliman",
      "Paris Avgeriou",
      "Lou Somers"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2205.13872"
  },
  {
    "id": "arXiv:2205.14312",
    "title": "Fine-Grained Buy-Many Mechanisms Are Not Much Better Than Bundling",
    "abstract": "Fine-Grained Buy-Many Mechanisms Are Not Much Better Than Bundling",
    "descriptor": "",
    "authors": [
      "Sepehr Assadi",
      "Vikram Kher",
      "George Li",
      "Ariel Schvartzman"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2205.14312"
  },
  {
    "id": "arXiv:2205.15494",
    "title": "Certifying Some Distributional Fairness with Subpopulation Decomposition",
    "abstract": "Comments: NeurIPS 2022, 38 pages, 11 pages for the main text",
    "descriptor": "\nComments: NeurIPS 2022, 38 pages, 11 pages for the main text\n",
    "authors": [
      "Mintong Kang",
      "Linyi Li",
      "Maurice Weber",
      "Yang Liu",
      "Ce Zhang",
      "Bo Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2205.15494"
  },
  {
    "id": "arXiv:2205.16001",
    "title": "On the Usefulness of Embeddings, Clusters and Strings for Text Generator  Evaluation",
    "abstract": "Comments: Tiago Pimentel and Clara Meister contributed equally to this work",
    "descriptor": "\nComments: Tiago Pimentel and Clara Meister contributed equally to this work\n",
    "authors": [
      "Tiago Pimentel",
      "Clara Meister",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.16001"
  },
  {
    "id": "arXiv:2206.00260",
    "title": "Multi-block Min-max Bilevel Optimization with Applications in Multi-task  Deep AUC Maximization",
    "abstract": "Multi-block Min-max Bilevel Optimization with Applications in Multi-task  Deep AUC Maximization",
    "descriptor": "",
    "authors": [
      "Quanqi Hu",
      "Yongjian Zhong",
      "Tianbao Yang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.00260"
  },
  {
    "id": "arXiv:2206.01136",
    "title": "Transforming medical imaging with Transformers? A comparative review of  key properties, current progresses, and future perspectives",
    "abstract": "Transforming medical imaging with Transformers? A comparative review of  key properties, current progresses, and future perspectives",
    "descriptor": "",
    "authors": [
      "Jun Li",
      "Junyu Chen",
      "Yucheng Tang",
      "Ce Wang",
      "Bennett A. Landman",
      "S. Kevin Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01136"
  },
  {
    "id": "arXiv:2206.01163",
    "title": "Invertible Neural Networks for Graph Prediction",
    "abstract": "Comments: Accepted at IEEE Journal on Selected Areas in Information Theory (JSAIT)---Special Issue Deep Learning for Inverse Problems",
    "descriptor": "\nComments: Accepted at IEEE Journal on Selected Areas in Information Theory (JSAIT)---Special Issue Deep Learning for Inverse Problems\n",
    "authors": [
      "Chen Xu",
      "Xiuyuan Cheng",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01163"
  },
  {
    "id": "arXiv:2206.02095",
    "title": "ARC -- Actor Residual Critic for Adversarial Imitation Learning",
    "abstract": "ARC -- Actor Residual Critic for Adversarial Imitation Learning",
    "descriptor": "",
    "authors": [
      "Ankur Deka",
      "Changliu Liu",
      "Katia Sycara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.02095"
  },
  {
    "id": "arXiv:2206.02570",
    "title": "RODIAN: Robustified Median",
    "abstract": "RODIAN: Robustified Median",
    "descriptor": "",
    "authors": [
      "Seong Hun Lee",
      "Javier Civera"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Data Structures and Algorithms (cs.DS)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.02570"
  },
  {
    "id": "arXiv:2206.02916",
    "title": "Remember the Past: Distilling Datasets into Addressable Memories for  Neural Networks",
    "abstract": "Remember the Past: Distilling Datasets into Addressable Memories for  Neural Networks",
    "descriptor": "",
    "authors": [
      "Zhiwei Deng",
      "Olga Russakovsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02916"
  },
  {
    "id": "arXiv:2206.03314",
    "title": "Integrating Random Effects in Deep Neural Networks",
    "abstract": "Comments: 53 pages, 9 figures",
    "descriptor": "\nComments: 53 pages, 9 figures\n",
    "authors": [
      "Giora Simchoni",
      "Saharon Rosset"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03314"
  },
  {
    "id": "arXiv:2206.03671",
    "title": "COVIDx CXR-3: A Large-Scale, Open-Source Benchmark Dataset of Chest  X-ray Images for Computer-Aided COVID-19 Diagnostics",
    "abstract": "Comments: 5 pages, MED-NeurIPS 2022 workshop",
    "descriptor": "\nComments: 5 pages, MED-NeurIPS 2022 workshop\n",
    "authors": [
      "Maya Pavlova",
      "Tia Tuinstra",
      "Hossein Aboutalebi",
      "Andy Zhao",
      "Hayden Gunraj",
      "Alexander Wong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03671"
  },
  {
    "id": "arXiv:2206.04635",
    "title": "Optimal Design of Energy-Harvesting Hybrid VLC-RF Networks",
    "abstract": "Optimal Design of Energy-Harvesting Hybrid VLC-RF Networks",
    "descriptor": "",
    "authors": [
      "Amir Hossein Fahim Raouf",
      "Chethan Kumar Anjinappa",
      "Ismail Guvenc"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.04635"
  },
  {
    "id": "arXiv:2206.04882",
    "title": "$\\mathsf{G^2Retro}$: Two-Step Graph Generative Models for Retrosynthesis  Prediction",
    "abstract": "$\\mathsf{G^2Retro}$: Two-Step Graph Generative Models for Retrosynthesis  Prediction",
    "descriptor": "",
    "authors": [
      "Ziqi Chen",
      "Oluwatosin R. Ayinde",
      "James R. Fuchs",
      "Huan Sun",
      "Xia Ning"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2206.04882"
  },
  {
    "id": "arXiv:2206.05514",
    "title": "Toward Real-world Single Image Deraining: A New Benchmark and Beyond",
    "abstract": "Toward Real-world Single Image Deraining: A New Benchmark and Beyond",
    "descriptor": "",
    "authors": [
      "Wei Li",
      "Qiming Zhang",
      "Jing Zhang",
      "Zhen Huang",
      "Xinmei Tian",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.05514"
  },
  {
    "id": "arXiv:2206.06270",
    "title": "Near-Optimal Sample Complexity Bounds for Constrained MDPs",
    "abstract": "Comments: NeurIPS'22",
    "descriptor": "\nComments: NeurIPS'22\n",
    "authors": [
      "Sharan Vaswani",
      "Lin F. Yang",
      "Csaba Szepesv\u00e1ri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.06270"
  },
  {
    "id": "arXiv:2206.07687",
    "title": "Structured Sparsity Learning for Efficient Video Super-Resolution",
    "abstract": "Structured Sparsity Learning for Efficient Video Super-Resolution",
    "descriptor": "",
    "authors": [
      "Bin Xia",
      "Jingwen He",
      "Yulun Zhang",
      "Yitong Wang",
      "Yapeng Tian",
      "Wenming Yang",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2206.07687"
  },
  {
    "id": "arXiv:2206.08885",
    "title": "Incorporating intratumoral heterogeneity into weakly-supervised deep  learning models via variance pooling",
    "abstract": "Comments: MICCAI 2022",
    "descriptor": "\nComments: MICCAI 2022\n",
    "authors": [
      "Iain Carmichael",
      "Andrew H. Song",
      "Richard J. Chen",
      "Drew F.K. Williamson",
      "Tiffany Y. Chen",
      "Faisal Mahmood"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2206.08885"
  },
  {
    "id": "arXiv:2206.10885",
    "title": "KiloNeuS: A Versatile Neural Implicit Surface Representation for  Real-Time Rendering",
    "abstract": "Comments: 9 pages, 8 figures",
    "descriptor": "\nComments: 9 pages, 8 figures\n",
    "authors": [
      "Stefano Esposito",
      "Daniele Baieri",
      "Stefan Zellmann",
      "Andr\u00e9 Hinkenjann",
      "Emanuele Rodol\u00e0"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10885"
  },
  {
    "id": "arXiv:2206.11693",
    "title": "Learning Agile Skills via Adversarial Imitation of Rough Partial  Demonstrations",
    "abstract": "Learning Agile Skills via Adversarial Imitation of Rough Partial  Demonstrations",
    "descriptor": "",
    "authors": [
      "Chenhao Li",
      "Marin Vlastelica",
      "Sebastian Blaes",
      "Jonas Frey",
      "Felix Grimminger",
      "Georg Martius"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.11693"
  },
  {
    "id": "arXiv:2206.11752",
    "title": "CLAMP: Prompt-based Contrastive Learning for Connecting Language and  Animal Pose",
    "abstract": "CLAMP: Prompt-based Contrastive Learning for Connecting Language and  Animal Pose",
    "descriptor": "",
    "authors": [
      "Xu Zhang",
      "Wen Wang",
      "Zhe Chen",
      "Yufei Xu",
      "Jing Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.11752"
  },
  {
    "id": "arXiv:2206.11828",
    "title": "On the Complexity of Problems on Tree-structured Graphs",
    "abstract": "On the Complexity of Problems on Tree-structured Graphs",
    "descriptor": "",
    "authors": [
      "Hans L. Bodlaender",
      "Carla Groenland",
      "Hugo Jacob",
      "Marcin Pilipczuk",
      "Michal Pilipczuk"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2206.11828"
  },
  {
    "id": "arXiv:2206.11832",
    "title": "On the parameterized complexity of computing tree-partitions",
    "abstract": "On the parameterized complexity of computing tree-partitions",
    "descriptor": "",
    "authors": [
      "Hans L. Bodlaender",
      "Carla Groenland",
      "Hugo Jacob"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2206.11832"
  },
  {
    "id": "arXiv:2206.13397",
    "title": "Generative Modelling With Inverse Heat Dissipation",
    "abstract": "Generative Modelling With Inverse Heat Dissipation",
    "descriptor": "",
    "authors": [
      "Severi Rissanen",
      "Markus Heinonen",
      "Arno Solin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.13397"
  },
  {
    "id": "arXiv:2206.14390",
    "title": "Diet Code Is Healthy: Simplifying Programs for Pre-trained Models of  Code",
    "abstract": "Comments: Accepted to be published in ESEC/FSE 2022",
    "descriptor": "\nComments: Accepted to be published in ESEC/FSE 2022\n",
    "authors": [
      "Zhaowei Zhang",
      "Hongyu Zhang",
      "Beijun Shen",
      "Xiaodong Gu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2206.14390"
  },
  {
    "id": "arXiv:2207.01127",
    "title": "DecisioNet: A Binary-Tree Structured Neural Network",
    "abstract": "Comments: The paper has been accepted to the ACCV2022 conference. A short summary video about the paper can be found at this https URL",
    "descriptor": "\nComments: The paper has been accepted to the ACCV2022 conference. A short summary video about the paper can be found at this https URL\n",
    "authors": [
      "Noam Gottlieb",
      "Michael Werman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.01127"
  },
  {
    "id": "arXiv:2207.01814",
    "title": "Multimodal Frame-Scoring Transformer for Video Summarization",
    "abstract": "Multimodal Frame-Scoring Transformer for Video Summarization",
    "descriptor": "",
    "authors": [
      "Jeiyoon Park",
      "Kiho Kwoun",
      "Chanhee Lee",
      "Heuiseok Lim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.01814"
  },
  {
    "id": "arXiv:2207.01991",
    "title": "Conflicting Interactions Among Protection Mechanisms for Machine  Learning Models",
    "abstract": "Comments: To appear in AAAI 2023; this is an extended technical report. 11 tables, 3 figures",
    "descriptor": "\nComments: To appear in AAAI 2023; this is an extended technical report. 11 tables, 3 figures\n",
    "authors": [
      "Sebastian Szyller",
      "N. Asokan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.01991"
  },
  {
    "id": "arXiv:2207.02625",
    "title": "$L_2$BN: Enhancing Batch Normalization by Equalizing the $L_2$ Norms of  Features",
    "abstract": "$L_2$BN: Enhancing Batch Normalization by Equalizing the $L_2$ Norms of  Features",
    "descriptor": "",
    "authors": [
      "Zhennan Wang",
      "Kehan Li",
      "Runyi Yu",
      "Yian Zhao",
      "Pengchong Qiao",
      "Fan Xu",
      "Guoli Song",
      "Jie Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.02625"
  },
  {
    "id": "arXiv:2207.05221",
    "title": "Language Models (Mostly) Know What They Know",
    "abstract": "Comments: 23+17 pages; refs added, typos fixed",
    "descriptor": "\nComments: 23+17 pages; refs added, typos fixed\n",
    "authors": [
      "Saurav Kadavath",
      "Tom Conerly",
      "Amanda Askell",
      "Tom Henighan",
      "Dawn Drain",
      "Ethan Perez",
      "Nicholas Schiefer",
      "Zac Hatfield-Dodds",
      "Nova DasSarma",
      "Eli Tran-Johnson",
      "Scott Johnston",
      "Sheer El-Showk",
      "Andy Jones",
      "Nelson Elhage",
      "Tristan Hume",
      "Anna Chen",
      "Yuntao Bai",
      "Sam Bowman",
      "Stanislav Fort",
      "Deep Ganguli",
      "Danny Hernandez",
      "Josh Jacobson",
      "Jackson Kernion",
      "Shauna Kravec",
      "Liane Lovitt",
      "Kamal Ndousse",
      "Catherine Olsson",
      "Sam Ringer",
      "Dario Amodei",
      "Tom Brown",
      "Jack Clark",
      "Nicholas Joseph",
      "Ben Mann",
      "Sam McCandlish",
      "Chris Olah",
      "Jared Kaplan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.05221"
  },
  {
    "id": "arXiv:2207.05817",
    "title": "OSLAT: Open Set Label Attention Transformer for Medical Entity Retrieval  and Span Extraction",
    "abstract": "Comments: 18 pages, 2 figures, Camera-Ready for ML4H 2022 (Proceedings Track)",
    "descriptor": "\nComments: 18 pages, 2 figures, Camera-Ready for ML4H 2022 (Proceedings Track)\n",
    "authors": [
      "Raymond Li",
      "Ilya Valmianski",
      "Li Deng",
      "Xavier Amatriain",
      "Anitha Kannan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.05817"
  },
  {
    "id": "arXiv:2207.05978",
    "title": "Enhanced Security and Privacy via Fragmented Federated Learning",
    "abstract": "Comments: IEEE Transactions on Neural Networks and Learning Systems (To Appear)",
    "descriptor": "\nComments: IEEE Transactions on Neural Networks and Learning Systems (To Appear)\n",
    "authors": [
      "Najeeb Moharram Jebreel",
      "Josep Domingo-Ferrer",
      "Alberto Blanco-Justicia",
      "David Sanchez"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.05978"
  },
  {
    "id": "arXiv:2207.10248",
    "title": "Can locational disparity of prosumer energy optimization due to inverter  rules be limited?",
    "abstract": "Can locational disparity of prosumer energy optimization due to inverter  rules be limited?",
    "descriptor": "",
    "authors": [
      "Md Umar Hashmi",
      "Deepjyoti Deka",
      "Ana Bu\u0161i\u0107",
      "Dirk Van Hertem"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.10248"
  },
  {
    "id": "arXiv:2207.10862",
    "title": "Contrastive Self-Supervised Learning Leads to Higher Adversarial  Susceptibility",
    "abstract": "Comments: 8 pages, 3 figures, to appear at AAAI-2023",
    "descriptor": "\nComments: 8 pages, 3 figures, to appear at AAAI-2023\n",
    "authors": [
      "Rohit Gupta",
      "Naveed Akhtar",
      "Ajmal Mian",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.10862"
  },
  {
    "id": "arXiv:2207.11124",
    "title": "Predictors for high frequency processes based on rational polynomials  approximation of periodic exponentials",
    "abstract": "Predictors for high frequency processes based on rational polynomials  approximation of periodic exponentials",
    "descriptor": "",
    "authors": [
      "Nikolai Dokuchaev"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2207.11124"
  },
  {
    "id": "arXiv:2207.11192",
    "title": "Progressive Deblurring of Diffusion Models for Coarse-to-Fine Image  Synthesis",
    "abstract": "Comments: NeurIPS 2022 SBM workshop",
    "descriptor": "\nComments: NeurIPS 2022 SBM workshop\n",
    "authors": [
      "Sangyun Lee",
      "Hyungjin Chung",
      "Jaehyeon Kim",
      "Jong Chul Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11192"
  },
  {
    "id": "arXiv:2207.14024",
    "title": "Safety-Enhanced Autonomous Driving Using Interpretable Sensor Fusion  Transformer",
    "abstract": "Comments: Accepted at CoRL 2022",
    "descriptor": "\nComments: Accepted at CoRL 2022\n",
    "authors": [
      "Hao Shao",
      "Letian Wang",
      "RuoBing Chen",
      "Hongsheng Li",
      "Yu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.14024"
  },
  {
    "id": "arXiv:2207.14465",
    "title": "Fine-grained Retrieval Prompt Tuning",
    "abstract": "Fine-grained Retrieval Prompt Tuning",
    "descriptor": "",
    "authors": [
      "Shijie Wang",
      "Jianlong Chang",
      "Zhihui Wang",
      "Haojie Li",
      "Wanli Ouyang",
      "Qi Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.14465"
  },
  {
    "id": "arXiv:2207.14626",
    "title": "Restoring Vision in Adverse Weather Conditions with Patch-Based  Denoising Diffusion Models",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Ozan \u00d6zdenizci",
      "Robert Legenstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.14626"
  },
  {
    "id": "arXiv:2208.00277",
    "title": "MobileNeRF: Exploiting the Polygon Rasterization Pipeline for Efficient  Neural Field Rendering on Mobile Architectures",
    "abstract": "Comments: Project page: this https URL, code: this https URL",
    "descriptor": "\nComments: Project page: this https URL, code: this https URL\n",
    "authors": [
      "Zhiqin Chen",
      "Thomas Funkhouser",
      "Peter Hedman",
      "Andrea Tagliasacchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.00277"
  },
  {
    "id": "arXiv:2208.00800",
    "title": "GANDSE: Generative Adversarial Network based Design Space Exploration  for Neural Network Accelerator Design",
    "abstract": "Comments: Published in ACM Transactions on Design Automation of Electronic Systems",
    "descriptor": "\nComments: Published in ACM Transactions on Design Automation of Electronic Systems\n",
    "authors": [
      "Lang Feng",
      "Wenjian Liu",
      "Chuliang Guo",
      "Ke Tang",
      "Cheng Zhuo",
      "Zhongfeng Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2208.00800"
  },
  {
    "id": "arXiv:2208.01739",
    "title": "Reconstructing Sparse Multiplex Networks with Application to Covert  Networks",
    "abstract": "Reconstructing Sparse Multiplex Networks with Application to Covert  Networks",
    "descriptor": "",
    "authors": [
      "Jin-Zhu Yu",
      "Mincheng Wu",
      "Gisela Bichler",
      "Felipe Aros-Vera",
      "Jianxi Gao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.01739"
  },
  {
    "id": "arXiv:2208.04664",
    "title": "Application of federated learning in manufacturing",
    "abstract": "Comments: 8 pages, 15 figures, Submitted at IEEE conference I4Tech2022",
    "descriptor": "\nComments: 8 pages, 15 figures, Submitted at IEEE conference I4Tech2022\n",
    "authors": [
      "Vinit Hegiste",
      "Tatjana Legler",
      "Martin Ruskowski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.04664"
  },
  {
    "id": "arXiv:2208.05008",
    "title": "Natural Language Processing for Systems Engineering: Automatic  Generation of Systems Modelling Language Diagrams",
    "abstract": "Comments: 29 pages, 5 figures",
    "descriptor": "\nComments: 29 pages, 5 figures\n",
    "authors": [
      "Shaohong Zhong",
      "Andrea Scarinci",
      "Alice Cicirello"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.05008"
  },
  {
    "id": "arXiv:2208.05130",
    "title": "PROFET: Profiling-based CNN Training Latency Prophet for GPU Cloud  Instances",
    "abstract": "Comments: 9 pages",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Sungjae Lee",
      "Yoonseo Hur",
      "Subin Park",
      "Kyungyong Lee"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.05130"
  },
  {
    "id": "arXiv:2208.06222",
    "title": "Scale-free and Task-agnostic Attack: Generating Photo-realistic  Adversarial Patterns with Patch Quilting Generator",
    "abstract": "Scale-free and Task-agnostic Attack: Generating Photo-realistic  Adversarial Patterns with Patch Quilting Generator",
    "descriptor": "",
    "authors": [
      "Xiangbo Gao",
      "Cheng Luo",
      "Qinliang Lin",
      "Weicheng Xie",
      "Minmin Liu",
      "Linlin Shen",
      "Keerthy Kusumam",
      "Siyang Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2208.06222"
  },
  {
    "id": "arXiv:2208.06646",
    "title": "Modeling Network-level Traffic Flow Transitions on Sparse Data",
    "abstract": "Comments: 9 pages + 3 pages appendix. Accepted by SIGKDD 2022",
    "descriptor": "\nComments: 9 pages + 3 pages appendix. Accepted by SIGKDD 2022\n",
    "authors": [
      "Xiaoliang Lei",
      "Hao Mei",
      "Bin Shi",
      "Hua Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.06646"
  },
  {
    "id": "arXiv:2208.07303",
    "title": "A Simulation Study of Passing Drivers' Responses to the Autonomous  Truck-Mounted Attenuator System in Road Maintenance",
    "abstract": "Comments: Accepted by TRR journal on Nov 21th",
    "descriptor": "\nComments: Accepted by TRR journal on Nov 21th\n",
    "authors": [
      "Yu Li",
      "Bill Wang",
      "William Li",
      "Ruwen Qin"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.07303"
  },
  {
    "id": "arXiv:2208.07313",
    "title": "Task Oriented Video Coding: A Survey",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2201.10162, arXiv:2001.03004, arXiv:2001.03569, arXiv:2110.09241, arXiv:2203.05890, arXiv:2203.05927, arXiv:2106.03511, arXiv:2001.02915, arXiv:2102.01307, arXiv:1812.10067, arXiv:2203.05944, arXiv:2201.02689, arXiv:2105.12653, arXiv:2112.10948, arXiv:1803.05788 by other authors",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2201.10162, arXiv:2001.03004, arXiv:2001.03569, arXiv:2110.09241, arXiv:2203.05890, arXiv:2203.05927, arXiv:2106.03511, arXiv:2001.02915, arXiv:2102.01307, arXiv:1812.10067, arXiv:2203.05944, arXiv:2201.02689, arXiv:2105.12653, arXiv:2112.10948, arXiv:1803.05788 by other authors\n",
    "authors": [
      "Daniel Wood"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.07313"
  },
  {
    "id": "arXiv:2208.07777",
    "title": "An Adaptive Repeated-Intersection-Reduction Local Search for the Maximum  Independent Set Problem",
    "abstract": "Comments: 11 pages, 0 figures",
    "descriptor": "\nComments: 11 pages, 0 figures\n",
    "authors": [
      "Enqiang Zhu",
      "Yu Zhang",
      "Chanjuan Liu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.07777"
  },
  {
    "id": "arXiv:2208.08161",
    "title": "KAM -- a Kernel Attention Module for Emotion Classification with EEG  Data",
    "abstract": "Comments: This preprint has not undergone peer review. The updated version is accepted by MICCAI2022 workshop: iMIMIC - Interpretability of Machine Intelligence in Medical Image Computing",
    "descriptor": "\nComments: This preprint has not undergone peer review. The updated version is accepted by MICCAI2022 workshop: iMIMIC - Interpretability of Machine Intelligence in Medical Image Computing\n",
    "authors": [
      "Dongyang Kuang",
      "Craig Michoski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.08161"
  },
  {
    "id": "arXiv:2208.08386",
    "title": "Neural Embeddings for Text",
    "abstract": "Comments: 27 pages, 18 figures, 19 tables, appendixes A-H",
    "descriptor": "\nComments: 27 pages, 18 figures, 19 tables, appendixes A-H\n",
    "authors": [
      "Oleg Vasilyev",
      "John Bohannon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.08386"
  },
  {
    "id": "arXiv:2208.09725",
    "title": "On Robustness in Nonconvex Optimization with Application to Defense  Planning",
    "abstract": "On Robustness in Nonconvex Optimization with Application to Defense  Planning",
    "descriptor": "",
    "authors": [
      "Johannes O. Royset"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09725"
  },
  {
    "id": "arXiv:2208.10159",
    "title": "Prompt-Matched Semantic Segmentation",
    "abstract": "Prompt-Matched Semantic Segmentation",
    "descriptor": "",
    "authors": [
      "Lingbo Liu",
      "Jianlong Chang",
      "Bruce X.B. Yu",
      "Liang Lin",
      "Qi Tian",
      "Chang-Wen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.10159"
  },
  {
    "id": "arXiv:2208.11228",
    "title": "Why Deep Learning's Performance Data Are Misleading",
    "abstract": "Comments: 6 pages, 2 figures",
    "descriptor": "\nComments: 6 pages, 2 figures\n",
    "authors": [
      "Juyang Weng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.11228"
  },
  {
    "id": "arXiv:2208.11469",
    "title": "ProbGraph: High-Performance and High-Accuracy Graph Mining with  Probabilistic Set Representations",
    "abstract": "Comments: Best Paper Award at ACM/IEEE Supercomputing'22 (SC22)",
    "descriptor": "\nComments: Best Paper Award at ACM/IEEE Supercomputing'22 (SC22)\n",
    "authors": [
      "Maciej Besta",
      "Cesare Miglioli",
      "Paolo Sylos Labini",
      "Jakub T\u011btek",
      "Patrick Iff",
      "Raghavendra Kanakagiri",
      "Saleh Ashkboos",
      "Kacper Janda",
      "Michal Podstawski",
      "Grzegorz Kwasniewski",
      "Niels Gleinig",
      "Flavio Vella",
      "Onur Mutlu",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2208.11469"
  },
  {
    "id": "arXiv:2208.14348",
    "title": "Ergodic Secrecy Rate of Optimal Source-Destination Pair Selection in  Frequency-Selective Fading",
    "abstract": "Comments: 16 pages, 6 figures, submitted to IEEE Transactions on Vehicular Technology",
    "descriptor": "\nComments: 16 pages, 6 figures, submitted to IEEE Transactions on Vehicular Technology\n",
    "authors": [
      "Shashi Bhushan Kotwal",
      "Chinmoy Kundu",
      "Sudhakar Modem",
      "Ankit Dubey",
      "Mark F. Flanagan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.14348"
  },
  {
    "id": "arXiv:2209.00302",
    "title": "Progressive Fusion for Multimodal Integration",
    "abstract": "Progressive Fusion for Multimodal Integration",
    "descriptor": "",
    "authors": [
      "Shiv Shankar",
      "Laure Thompson",
      "Madalina Fiterau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2209.00302"
  },
  {
    "id": "arXiv:2209.02001",
    "title": "On free energy barriers in Gaussian priors and failure of cold start  MCMC for high-dimensional unimodal distributions",
    "abstract": "Comments: 27 pages, 5 figures, to appear in Philosophical Transactions of the Royal Society A",
    "descriptor": "\nComments: 27 pages, 5 figures, to appear in Philosophical Transactions of the Royal Society A\n",
    "authors": [
      "Afonso S. Bandeira",
      "Antoine Maillard",
      "Richard Nickl",
      "Sven Wang"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.02001"
  },
  {
    "id": "arXiv:2209.03714",
    "title": "Visual Grounding of Inter-lingual Word-Embeddings",
    "abstract": "Comments: - added more results - paper accepted to appear at UM-IoS workshop, EMNLP 2022",
    "descriptor": "\nComments: - added more results - paper accepted to appear at UM-IoS workshop, EMNLP 2022\n",
    "authors": [
      "Wafaa Mohammed",
      "Hassan Shahmohammadi",
      "Hendrik P. A. Lensch",
      "R. Harald Baayen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.03714"
  },
  {
    "id": "arXiv:2209.03950",
    "title": "Opponent Indifference in Rating Systems: A Theoretical Case for Sonas",
    "abstract": "Comments: ITCS 2023",
    "descriptor": "\nComments: ITCS 2023\n",
    "authors": [
      "Greg Bodwin",
      "Forest Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2209.03950"
  },
  {
    "id": "arXiv:2209.04013",
    "title": "Trajectory Range Visibility",
    "abstract": "Trajectory Range Visibility",
    "descriptor": "",
    "authors": [
      "Seyed Mohammad Hussein Kazemi",
      "Arash Vaezi",
      "Mohammad Ghodsi"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2209.04013"
  },
  {
    "id": "arXiv:2209.04265",
    "title": "Routing Planning for Last-Mile Deliveries Using Mobile Parcel Lockers: A  Hybrid Q-Learning Network Approach",
    "abstract": "Comments: 76 pages, 18 figures. This paper has been submitted to Transportation Research Part E: Logistics and Transportation Review (Manuscript Number: TRE-D-22-01261)",
    "descriptor": "\nComments: 76 pages, 18 figures. This paper has been submitted to Transportation Research Part E: Logistics and Transportation Review (Manuscript Number: TRE-D-22-01261)\n",
    "authors": [
      "Yubin Liu",
      "Qiming Ye",
      "Jose Escribano-Macias",
      "Yuxiang Feng",
      "Eduardo Candela",
      "Panagiotis Angeloudis"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.04265"
  },
  {
    "id": "arXiv:2209.04394",
    "title": "Fair Matrix Factorisation for Large-Scale Recommender Systems",
    "abstract": "Comments: Extended version of the paper presented at FAccTRec 2022",
    "descriptor": "\nComments: Extended version of the paper presented at FAccTRec 2022\n",
    "authors": [
      "Riku Togashi",
      "Kenshi Abe"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2209.04394"
  },
  {
    "id": "arXiv:2209.04874",
    "title": "Doctors vs. Nurses: Understanding the Great Divide in Vaccine Hesitancy  among Healthcare Workers",
    "abstract": "Comments: Accepted for publication in Proceedings of the 8th Special Session on Intelligent Data Mining of 2022 IEEE International Conference on Big Data, 2022",
    "descriptor": "\nComments: Accepted for publication in Proceedings of the 8th Special Session on Intelligent Data Mining of 2022 IEEE International Conference on Big Data, 2022\n",
    "authors": [
      "Sajid Hussain Rafi Ahamed",
      "Shahid Shakil",
      "Hanjia Lyu",
      "Xinping Zhang",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2209.04874"
  },
  {
    "id": "arXiv:2209.04933",
    "title": "Dimensionality Reduction using Elastic Measures",
    "abstract": "Dimensionality Reduction using Elastic Measures",
    "descriptor": "",
    "authors": [
      "J. Derek Tucker",
      "Matthew T. Martinez",
      "Jose M. Laborde"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Differential Geometry (math.DG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2209.04933"
  },
  {
    "id": "arXiv:2209.05095",
    "title": "FBG-Based Online Learning and 3-D Shape Control of Unmodeled Continuum  and Soft Robots in Unstructured Environments",
    "abstract": "FBG-Based Online Learning and 3-D Shape Control of Unmodeled Continuum  and Soft Robots in Unstructured Environments",
    "descriptor": "",
    "authors": [
      "Yiang Lu",
      "Wei Chen",
      "Bo Lu",
      "Jianshu Zhou",
      "Zhi Chen",
      "Qi Dou",
      "Yun-Hui Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.05095"
  },
  {
    "id": "arXiv:2209.07636",
    "title": "Improving Language Model Prompting in Support of Semi-autonomous Task  Learning",
    "abstract": "Comments: Accepted to ACS 2022 (poster)",
    "descriptor": "\nComments: Accepted to ACS 2022 (poster)\n",
    "authors": [
      "James R. Kirk",
      "Robert E. Wray",
      "Peter Lindes",
      "John E. Laird"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.07636"
  },
  {
    "id": "arXiv:2209.07667",
    "title": "Can There be Art Without an Artist?",
    "abstract": "Comments: Accepted at NeurIPS 2022 Workshop on Human Evaluation of Generative Models",
    "descriptor": "\nComments: Accepted at NeurIPS 2022 Workshop on Human Evaluation of Generative Models\n",
    "authors": [
      "Avijit Ghosh",
      "Genoveva Fossas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07667"
  },
  {
    "id": "arXiv:2209.07778",
    "title": "Spatial-then-Temporal Self-Supervised Learning for Video Correspondence",
    "abstract": "Spatial-then-Temporal Self-Supervised Learning for Video Correspondence",
    "descriptor": "",
    "authors": [
      "Rui Li",
      "Dong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07778"
  },
  {
    "id": "arXiv:2209.08415",
    "title": "Grammars over the Lambek Calculus with Permutation: Recognizing Power  and Connection to Branching Vector Addition Systems with States",
    "abstract": "Grammars over the Lambek Calculus with Permutation: Recognizing Power  and Connection to Branching Vector Addition Systems with States",
    "descriptor": "",
    "authors": [
      "Tikhon Pshenitsyn"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2209.08415"
  },
  {
    "id": "arXiv:2209.09209",
    "title": "Discriminative Sampling of Proposals in Self-Supervised Transformers for  Weakly Supervised Object Localization",
    "abstract": "Discriminative Sampling of Proposals in Self-Supervised Transformers for  Weakly Supervised Object Localization",
    "descriptor": "",
    "authors": [
      "Shakeeb Murtaza",
      "Soufiane Belharbi",
      "Marco Pedersoli",
      "Aydin Sarraf",
      "Eric Granger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.09209"
  },
  {
    "id": "arXiv:2209.09616",
    "title": "Provably Uncertainty-Guided Universal Domain Adaptation",
    "abstract": "Comments: 13 pages. arXiv admin note: text overlap with arXiv:2207.09280",
    "descriptor": "\nComments: 13 pages. arXiv admin note: text overlap with arXiv:2207.09280\n",
    "authors": [
      "Yifan Wang",
      "Lin Zhang",
      "Ran Song",
      "Lin Ma",
      "Wei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.09616"
  },
  {
    "id": "arXiv:2209.10222",
    "title": "Fairness Reprogramming",
    "abstract": "Fairness Reprogramming",
    "descriptor": "",
    "authors": [
      "Guanhua Zhang",
      "Yihua Zhang",
      "Yang Zhang",
      "Wenqi Fan",
      "Qing Li",
      "Sijia Liu",
      "Shiyu Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2209.10222"
  },
  {
    "id": "arXiv:2209.10585",
    "title": "Grape Cold Hardiness Prediction via Multi-Task Learning",
    "abstract": "Comments: 6 pages, 2 figures, accepted at IAAI-23",
    "descriptor": "\nComments: 6 pages, 2 figures, accepted at IAAI-23\n",
    "authors": [
      "Aseem Saxena",
      "Paola Pesantez-Cabrera",
      "Rohan Ballapragada",
      "Kin-Ho Lam",
      "Markus Keller",
      "Alan Fern"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.10585"
  },
  {
    "id": "arXiv:2209.11908",
    "title": "Fast Lifelong Adaptive Inverse Reinforcement Learning from  Demonstrations",
    "abstract": "Fast Lifelong Adaptive Inverse Reinforcement Learning from  Demonstrations",
    "descriptor": "",
    "authors": [
      "Letian Chen",
      "Sravan Jayanthi",
      "Rohan Paleja",
      "Daniel Martin",
      "Viacheslav Zakharov",
      "Matthew Gombolay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.11908"
  },
  {
    "id": "arXiv:2209.12226",
    "title": "Re-contextualizing Fairness in NLP: The Case of India",
    "abstract": "Comments: Accepted to AACL-IJCNLP 2022",
    "descriptor": "\nComments: Accepted to AACL-IJCNLP 2022\n",
    "authors": [
      "Shaily Bhatt",
      "Sunipa Dev",
      "Partha Talukdar",
      "Shachi Dave",
      "Vinodkumar Prabhakaran"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2209.12226"
  },
  {
    "id": "arXiv:2209.13094",
    "title": "Efficient Noise Filtration of Images by Low-Rank Singular Vector  Approximations of Geodesics' Gramian Matrix",
    "abstract": "Comments: 19 pages, 3 figures, submitted to ACM Transactions on Architecture and Code Optimization",
    "descriptor": "\nComments: 19 pages, 3 figures, submitted to ACM Transactions on Architecture and Code Optimization\n",
    "authors": [
      "Kelum Gajamannage",
      "Yonggi Park",
      "Sunil Mathur"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.13094"
  },
  {
    "id": "arXiv:2209.13476",
    "title": "Mine yOur owN Anatomy: Revisiting Medical Image Segmentation with  Extremely Limited Labels",
    "abstract": "Mine yOur owN Anatomy: Revisiting Medical Image Segmentation with  Extremely Limited Labels",
    "descriptor": "",
    "authors": [
      "Chenyu You",
      "Weicheng Dai",
      "Fenglin Liu",
      "Haoran Su",
      "Xiaoran Zhang",
      "Xiaoxiao Li",
      "David A. Clifton",
      "Lawrence Staib",
      "James S. Duncan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.13476"
  },
  {
    "id": "arXiv:2209.14076",
    "title": "Backward Reachability Analysis of Neural Feedback Loops: Techniques for  Linear and Nonlinear Systems",
    "abstract": "Comments: 17 pages, 15 figures. Journal extension of arXiv:2204.08319",
    "descriptor": "\nComments: 17 pages, 15 figures. Journal extension of arXiv:2204.08319\n",
    "authors": [
      "Nicholas Rober",
      "Sydney M. Katz",
      "Chelsea Sidrane",
      "Esen Yel",
      "Michael Everett",
      "Mykel J. Kochenderfer",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.14076"
  },
  {
    "id": "arXiv:2209.14087",
    "title": "Adaptive Out-Orientations with Applications",
    "abstract": "Adaptive Out-Orientations with Applications",
    "descriptor": "",
    "authors": [
      "Aleksander B. G. Christiansen",
      "Jacob Holm",
      "Ivor van der Hoog",
      "Eva Rotenberg",
      "Chris Schwiegelshohn"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2209.14087"
  },
  {
    "id": "arXiv:2209.14788",
    "title": "Using models of baseline gameplay to design for physical rehabilitation",
    "abstract": "Comments: 19 pages, 10 figures",
    "descriptor": "\nComments: 19 pages, 10 figures\n",
    "authors": [
      "Antoine Loriette",
      "Baptiste Caramiaux",
      "Sebastian Stein",
      "John H. Williamson"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2209.14788"
  },
  {
    "id": "arXiv:2209.14941",
    "title": "EDA: Explicit Text-Decoupling and Dense Alignment for 3D Visual  Grounding",
    "abstract": "Comments: 16 pages with 5 pages of supplementary material",
    "descriptor": "\nComments: 16 pages with 5 pages of supplementary material\n",
    "authors": [
      "Yanmin Wu",
      "Xinhua Cheng",
      "Renrui Zhang",
      "Zesen Cheng",
      "Jian Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.14941"
  },
  {
    "id": "arXiv:2209.15090",
    "title": "Enforcing Hard Constraints with Soft Barriers: Safe Reinforcement  Learning in Unknown Stochastic Environments",
    "abstract": "Comments: fix typos, updated paper writing",
    "descriptor": "\nComments: fix typos, updated paper writing\n",
    "authors": [
      "Yixuan Wang",
      "Simon Sinong Zhan",
      "Ruochen Jiao",
      "Zhilu Wang",
      "Wanxin Jin",
      "Zhuoran Yang",
      "Zhaoran Wang",
      "Chao Huang",
      "Qi Zhu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.15090"
  },
  {
    "id": "arXiv:2209.15180",
    "title": "SCI: A spectrum concentrated implicit neural compression for biomedical  data",
    "abstract": "Comments: accepted to AAAI2023",
    "descriptor": "\nComments: accepted to AAAI2023\n",
    "authors": [
      "Runzhao Yang",
      "Tingxiong Xiao",
      "Yuxiao Cheng",
      "Qianni Cao",
      "Jinyuan Qu",
      "Jinli Suo",
      "Qionghai Dai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.15180"
  },
  {
    "id": "arXiv:2209.15428",
    "title": "PyPose: A Library for Robot Learning with Physics-based Optimization",
    "abstract": "Comments: this https URL",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Chen Wang",
      "Dasong Gao",
      "Kuan Xu",
      "Junyi Geng",
      "Yaoyu Hu",
      "Yuheng Qiu",
      "Bowen Li",
      "Fan Yang",
      "Brady Moon",
      "Abhinav Pandey",
      "Aryan",
      "Jiahe Xu",
      "Tianhao Wu",
      "Haonan He",
      "Daning Huang",
      "Zhongqiang Ren",
      "Shibo Zhao",
      "Taimeng Fu",
      "Pranay Reddy",
      "Xiao Lin",
      "Wenshan Wang",
      "Jingnan Shi",
      "Rajat Talak",
      "Kun Cao",
      "Yi Du",
      "Han Wang",
      "Huai Yu",
      "Shanzhao Wang",
      "Siyu Chen",
      "Ananth Kashyap",
      "Rohan Bandaru",
      "Karthik Dantu",
      "Jiajun Wu",
      "Lihua Xie",
      "Luca Carlone",
      "Marco Hutter",
      "Sebastian Scherer"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.15428"
  },
  {
    "id": "arXiv:2210.00006",
    "title": "A graph neural network approach to automated model building in cryo-EM  maps",
    "abstract": "A graph neural network approach to automated model building in cryo-EM  maps",
    "descriptor": "",
    "authors": [
      "Kiarash Jamali",
      "Dari Kimanius",
      "Sjors H.W. Scheres"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2210.00006"
  },
  {
    "id": "arXiv:2210.00123",
    "title": "Multi-Robot Motion Planning for Unit Discs with Revolving Areas",
    "abstract": "Multi-Robot Motion Planning for Unit Discs with Revolving Areas",
    "descriptor": "",
    "authors": [
      "Pankaj K. Agarwal",
      "Tzvika Geft",
      "Dan Halperin",
      "Erin Taylor"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2210.00123"
  },
  {
    "id": "arXiv:2210.00462",
    "title": "Improved Stein Variational Gradient Descent with Importance Weights",
    "abstract": "Comments: 27 pages",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Lukang Sun",
      "Peter Richt\u00e1rik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2210.00462"
  },
  {
    "id": "arXiv:2210.00706",
    "title": "Information-Theoretic Analysis of Unsupervised Domain Adaptation",
    "abstract": "Information-Theoretic Analysis of Unsupervised Domain Adaptation",
    "descriptor": "",
    "authors": [
      "Ziqiao Wang",
      "Yongyi Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00706"
  },
  {
    "id": "arXiv:2210.00939",
    "title": "Improving Sample Quality of Diffusion Models Using Self-Attention  Guidance",
    "abstract": "Comments: Project Page: this https URL",
    "descriptor": "\nComments: Project Page: this https URL\n",
    "authors": [
      "Susung Hong",
      "Gyuseong Lee",
      "Wooseok Jang",
      "Seungryong Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00939"
  },
  {
    "id": "arXiv:2210.00953",
    "title": "Bias and Extrapolation in Markovian Linear Stochastic Approximation with  Constant Stepsizes",
    "abstract": "Bias and Extrapolation in Markovian Linear Stochastic Approximation with  Constant Stepsizes",
    "descriptor": "",
    "authors": [
      "Dongyan Huo",
      "Yudong Chen",
      "Qiaomin Xie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.00953"
  },
  {
    "id": "arXiv:2210.01032",
    "title": "A New Hip Fracture Risk Index Derived from FEA-Computed Proximal Femur  Fracture Loads and Energies-to-Failure",
    "abstract": "Comments: 27 pages, 4 figures",
    "descriptor": "\nComments: 27 pages, 4 figures\n",
    "authors": [
      "Xuewei Cao",
      "Joyce H Keyak",
      "Sigurdur Sigurdsson",
      "Chen Zhao",
      "Weihua Zhou",
      "Anqi Liu",
      "Thomas Lang",
      "Hong-Wen Deng",
      "Vilmundur Gudnason",
      "Qiuying Sha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.01032"
  },
  {
    "id": "arXiv:2210.01055",
    "title": "CLIP2Point: Transfer CLIP to Point Cloud Classification with Image-Depth  Pre-training",
    "abstract": "CLIP2Point: Transfer CLIP to Point Cloud Classification with Image-Depth  Pre-training",
    "descriptor": "",
    "authors": [
      "Tianyu Huang",
      "Bowen Dong",
      "Yunhan Yang",
      "Xiaoshui Huang",
      "Rynson W.H. Lau",
      "Wanli Ouyang",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.01055"
  },
  {
    "id": "arXiv:2210.01257",
    "title": "Regularized linear convolutional networks inherit frequency sensitivity  from image statistics",
    "abstract": "Comments: Comments welcome! V2: Title updated to more precisely reflect our results, conjecture on non-commutative generalized H\\\"older upgraded to Lemma 4.11, and as a consequence restrictions on Theorem 4.9 removed, more datasets, more variable frequency statistics and more CNN architectures",
    "descriptor": "\nComments: Comments welcome! V2: Title updated to more precisely reflect our results, conjecture on non-commutative generalized H\\\"older upgraded to Lemma 4.11, and as a consequence restrictions on Theorem 4.9 removed, more datasets, more variable frequency statistics and more CNN architectures\n",
    "authors": [
      "Charles Godfrey",
      "Elise Bishoff",
      "Myles Mckay",
      "Davis Brown",
      "Grayson Jorgenson",
      "Henry Kvinge",
      "Eleanor Byler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.01257"
  },
  {
    "id": "arXiv:2210.01343",
    "title": "The Surprising Computational Power of Nondeterministic Stack RNNs",
    "abstract": "Comments: 21 pages, 8 figures. Under review for ICLR 2023 (revised version)",
    "descriptor": "\nComments: 21 pages, 8 figures. Under review for ICLR 2023 (revised version)\n",
    "authors": [
      "Brian DuSell",
      "David Chiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.01343"
  },
  {
    "id": "arXiv:2210.01400",
    "title": "Linear Convergence of Natural Policy Gradient Methods with Log-Linear  Policies",
    "abstract": "Comments: This version updates the references, provides technical contribution comparison and adds a conclusion and discussion section",
    "descriptor": "\nComments: This version updates the references, provides technical contribution comparison and adds a conclusion and discussion section\n",
    "authors": [
      "Rui Yuan",
      "Simon S. Du",
      "Robert M. Gower",
      "Alessandro Lazaric",
      "Lin Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.01400"
  },
  {
    "id": "arXiv:2210.01407",
    "title": "Homotopy-based training of NeuralODEs for accurate dynamics discovery",
    "abstract": "Comments: 12 pages, 6 figures, submitted to ICLR2023",
    "descriptor": "\nComments: 12 pages, 6 figures, submitted to ICLR2023\n",
    "authors": [
      "Joon-Hyuk Ko",
      "Hankyul Koh",
      "Nojun Park",
      "Wonho Jhe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.01407"
  },
  {
    "id": "arXiv:2210.02063",
    "title": "Improving Sentiment Analysis By Emotion Lexicon Approach on Vietnamese  Texts",
    "abstract": "Comments: Accepted at the International Conference on Asian Language Processing (IALP 2022)",
    "descriptor": "\nComments: Accepted at the International Conference on Asian Language Processing (IALP 2022)\n",
    "authors": [
      "An Long Doan",
      "Son T. Luu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02063"
  },
  {
    "id": "arXiv:2210.02271",
    "title": "Extending Conformal Prediction to Hidden Markov Models with Exact  Validity via de Finetti's Theorem for Markov Chains",
    "abstract": "Extending Conformal Prediction to Hidden Markov Models with Exact  Validity via de Finetti's Theorem for Markov Chains",
    "descriptor": "",
    "authors": [
      "Buddhika Nettasinghe",
      "Samrat Chatterjee",
      "Ramakrishna Tipireddy",
      "Mahantesh Halappanavar"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.02271"
  },
  {
    "id": "arXiv:2210.02441",
    "title": "Ask Me Anything: A simple strategy for prompting language models",
    "abstract": "Ask Me Anything: A simple strategy for prompting language models",
    "descriptor": "",
    "authors": [
      "Simran Arora",
      "Avanika Narayan",
      "Mayee F. Chen",
      "Laurel Orr",
      "Neel Guha",
      "Kush Bhatia",
      "Ines Chami",
      "Frederic Sala",
      "Christopher R\u00e9"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.02441"
  },
  {
    "id": "arXiv:2210.03274",
    "title": "TCNL: Transparent and Controllable Network Learning Via Embedding  Human-Guided Concepts",
    "abstract": "TCNL: Transparent and Controllable Network Learning Via Embedding  Human-Guided Concepts",
    "descriptor": "",
    "authors": [
      "Zhihao Wang",
      "Chuang Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03274"
  },
  {
    "id": "arXiv:2210.04872",
    "title": "Sequential Neural Score Estimation: Likelihood-Free Inference with  Conditional Score Based Diffusion Models",
    "abstract": "Sequential Neural Score Estimation: Likelihood-Free Inference with  Conditional Score Based Diffusion Models",
    "descriptor": "",
    "authors": [
      "Louis Sharrock",
      "Jack Simons",
      "Song Liu",
      "Mark Beaumont"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04872"
  },
  {
    "id": "arXiv:2210.05150",
    "title": "DHRL: A Graph-Based Approach for Long-Horizon and Sparse Hierarchical  Reinforcement Learning",
    "abstract": "Comments: Accepted to NeurIPS 2022 (Selected as Oral)",
    "descriptor": "\nComments: Accepted to NeurIPS 2022 (Selected as Oral)\n",
    "authors": [
      "Seungjae Lee",
      "Jigang Kim",
      "Inkyu Jang",
      "H. Jin Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.05150"
  },
  {
    "id": "arXiv:2210.05328",
    "title": "Reciprocity in Directed Hypergraphs: Measures, Findings, and Generators",
    "abstract": "Comments: The extended version of the ICDM 2022 paper with the same title. 31 pages, 8 figures",
    "descriptor": "\nComments: The extended version of the ICDM 2022 paper with the same title. 31 pages, 8 figures\n",
    "authors": [
      "Sunwoo Kim",
      "Minyoung Choe",
      "Jaemin Yoo",
      "Kijung Shin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.05328"
  },
  {
    "id": "arXiv:2210.05944",
    "title": "ACSeg: Adaptive Conceptualization for Unsupervised Semantic Segmentation",
    "abstract": "ACSeg: Adaptive Conceptualization for Unsupervised Semantic Segmentation",
    "descriptor": "",
    "authors": [
      "Kehan Li",
      "Zhennan Wang",
      "Zesen Cheng",
      "Runyi Yu",
      "Yian Zhao",
      "Guoli Song",
      "Chang Liu",
      "Li Yuan",
      "Jie Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.05944"
  },
  {
    "id": "arXiv:2210.06134",
    "title": "Identity, Crimes, and Law Enforcement in the Metaverse",
    "abstract": "Identity, Crimes, and Law Enforcement in the Metaverse",
    "descriptor": "",
    "authors": [
      "Hua Xuan Qin",
      "Yuyang Wang",
      "Pan Hui"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.06134"
  },
  {
    "id": "arXiv:2210.07105",
    "title": "CORL: Research-oriented Deep Offline Reinforcement Learning Library",
    "abstract": "Comments: Accepted at 3rd Offline Reinforcement Learning Workshop at Neural Information Processing Systems, 2022",
    "descriptor": "\nComments: Accepted at 3rd Offline Reinforcement Learning Workshop at Neural Information Processing Systems, 2022\n",
    "authors": [
      "Denis Tarasov",
      "Alexander Nikulin",
      "Dmitry Akimov",
      "Vladislav Kurenkov",
      "Sergey Kolesnikov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.07105"
  },
  {
    "id": "arXiv:2210.07321",
    "title": "Machine Generated Text: A Comprehensive Survey of Threat Models and  Detection Methods",
    "abstract": "Comments: Manuscript submitted to ACM Special Session on Trustworthy AI. 2022/11/19 - Updated references",
    "descriptor": "\nComments: Manuscript submitted to ACM Special Session on Trustworthy AI. 2022/11/19 - Updated references\n",
    "authors": [
      "Evan Crothers",
      "Nathalie Japkowicz",
      "Herna Viktor"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07321"
  },
  {
    "id": "arXiv:2210.07363",
    "title": "The Power of Multi-Step Vizing Chains",
    "abstract": "Comments: 42 pages, 3 figures",
    "descriptor": "\nComments: 42 pages, 3 figures\n",
    "authors": [
      "Aleksander B G Christiansen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.07363"
  },
  {
    "id": "arXiv:2210.08336",
    "title": "Decoupling Deep Learning for Interpretable Image Recognition",
    "abstract": "Decoupling Deep Learning for Interpretable Image Recognition",
    "descriptor": "",
    "authors": [
      "Yitao Peng",
      "Yihang Liu",
      "Longzhen Yang",
      "Lianghua He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08336"
  },
  {
    "id": "arXiv:2210.08398",
    "title": "SPIDR: SDF-based Neural Point Fields for Illumination and Deformation",
    "abstract": "Comments: Project page: this https URL",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Ruofan Liang",
      "Jiahao Zhang",
      "Haoda Li",
      "Chen Yang",
      "Yushi Guan",
      "Nandita Vijaykumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.08398"
  },
  {
    "id": "arXiv:2210.08519",
    "title": "Fuzzy Positive Learning for Semi-supervised Semantic Segmentation",
    "abstract": "Fuzzy Positive Learning for Semi-supervised Semantic Segmentation",
    "descriptor": "",
    "authors": [
      "Pengchong Qiao",
      "Zhidan Wei",
      "Yu Wang",
      "Zhennan Wang",
      "Guoli Song",
      "Fan Xu",
      "Xiangyang Ji",
      "Chang Liu",
      "Jie Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08519"
  },
  {
    "id": "arXiv:2210.09049",
    "title": "SpanProto: A Two-stage Span-based Prototypical Network for Few-shot  Named Entity Recognition",
    "abstract": "SpanProto: A Two-stage Span-based Prototypical Network for Few-shot  Named Entity Recognition",
    "descriptor": "",
    "authors": [
      "Jianing Wang",
      "Chengcheng Han",
      "Chengyu Wang",
      "Chuanqi Tan",
      "Minghui Qiu",
      "Songfang Huang",
      "Jun Huang",
      "Ming Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.09049"
  },
  {
    "id": "arXiv:2210.09884",
    "title": "Is Dogecoin a Viable Investment? Insights from Network and Bubble  Effects",
    "abstract": "Is Dogecoin a Viable Investment? Insights from Network and Bubble  Effects",
    "descriptor": "",
    "authors": [
      "Ruoxin Xiao",
      "Xinyu Ying",
      "Hengxu Li",
      "Kexin Liu"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.09884"
  },
  {
    "id": "arXiv:2210.11060",
    "title": "Doc2Bot: Accessing Heterogeneous Documents via Conversational Bots",
    "abstract": "Comments: 17 pages, 14 figures. Accepted by Findings of EMNLP 2022",
    "descriptor": "\nComments: 17 pages, 14 figures. Accepted by Findings of EMNLP 2022\n",
    "authors": [
      "Haomin Fu",
      "Yeqin Zhang",
      "Haiyang Yu",
      "Jian Sun",
      "Fei Huang",
      "Luo Si",
      "Yongbin Li",
      "Cam-Tu Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11060"
  },
  {
    "id": "arXiv:2210.11643",
    "title": "All Politics is Local: Redistricting via Local Fairness",
    "abstract": "All Politics is Local: Redistricting via Local Fairness",
    "descriptor": "",
    "authors": [
      "Shao-Heng Ko",
      "Erin Taylor",
      "Pankaj K. Agarwal",
      "Kamesh Munagala"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.11643"
  },
  {
    "id": "arXiv:2210.11693",
    "title": "Amos: An Adam-style Optimizer with Adaptive Weight Decay towards  Model-Oriented Scale",
    "abstract": "Amos: An Adam-style Optimizer with Adaptive Weight Decay towards  Model-Oriented Scale",
    "descriptor": "",
    "authors": [
      "Ran Tian",
      "Ankur P. Parikh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11693"
  },
  {
    "id": "arXiv:2210.11879",
    "title": "GLCC: A General Framework for Graph-level Clustering",
    "abstract": "Comments: Accepted by Proceedings of the AAAI Conference on Artificial Intelligence (AAAI 2023)",
    "descriptor": "\nComments: Accepted by Proceedings of the AAAI Conference on Artificial Intelligence (AAAI 2023)\n",
    "authors": [
      "Wei Ju",
      "Yiyang Gu",
      "Binqi Chen",
      "Gongbo Sun",
      "Yifang Qin",
      "Xingyuming Liu",
      "Xiao Luo",
      "Ming Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.11879"
  },
  {
    "id": "arXiv:2210.11942",
    "title": "Oracles & Followers: Stackelberg Equilibria in Deep Multi-Agent  Reinforcement Learning",
    "abstract": "Oracles & Followers: Stackelberg Equilibria in Deep Multi-Agent  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Matthias Gerstgrasser",
      "David C. Parkes"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2210.11942"
  },
  {
    "id": "arXiv:2210.12243",
    "title": "Short rainbow cycles for families of matchings and triangles",
    "abstract": "Comments: 7 pages",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "He Guo"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.12243"
  },
  {
    "id": "arXiv:2210.12587",
    "title": "Model ensemble instead of prompt fusion: a sample-specific knowledge  transfer method for few-shot prompt tuning",
    "abstract": "Model ensemble instead of prompt fusion: a sample-specific knowledge  transfer method for few-shot prompt tuning",
    "descriptor": "",
    "authors": [
      "Xiangyu Peng",
      "Chen Xing",
      "Prafulla Kumar Choubey",
      "Chien-Sheng Wu",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.12587"
  },
  {
    "id": "arXiv:2210.12689",
    "title": "Face Emotion Recognization Using Dataset Augmentation Based on Neural  Network",
    "abstract": "Comments: 5 pages, 8 figures, 3 tables",
    "descriptor": "\nComments: 5 pages, 8 figures, 3 tables\n",
    "authors": [
      "Mengyu Rao",
      "Ruyi Bao",
      "Liangshun Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.12689"
  },
  {
    "id": "arXiv:2210.12860",
    "title": "Explicit Second-Order Min-Max Optimization Methods with Optimal  Convergence Guarantee",
    "abstract": "Comments: 31 pages, 12 figures; Change the optimality notion to a more standard restricted gap function",
    "descriptor": "\nComments: 31 pages, 12 figures; Change the optimality notion to a more standard restricted gap function\n",
    "authors": [
      "Tianyi Lin",
      "Panayotis Mertikopoulos",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.12860"
  },
  {
    "id": "arXiv:2210.13512",
    "title": "Provably Learning Diverse Features in Multi-View Data with Midpoint  Mixup",
    "abstract": "Comments: 38 pages, 2 figures",
    "descriptor": "\nComments: 38 pages, 2 figures\n",
    "authors": [
      "Muthu Chidambaram",
      "Xiang Wang",
      "Chenwei Wu",
      "Rong Ge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.13512"
  },
  {
    "id": "arXiv:2210.13931",
    "title": "An Optimal Stochastic Algorithm for Decentralized Nonconvex Finite-sum  Optimization",
    "abstract": "Comments: We correct the definition of $\\Phi_t$ on page 5, which does not affect the result",
    "descriptor": "\nComments: We correct the definition of $\\Phi_t$ on page 5, which does not affect the result\n",
    "authors": [
      "Luo Luo",
      "Haishan Ye"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.13931"
  },
  {
    "id": "arXiv:2210.14064",
    "title": "Learning Low Dimensional State Spaces with Overparameterized Recurrent  Neural Network",
    "abstract": "Comments: preprint, 9 pages, 2 figures plus supplementary",
    "descriptor": "\nComments: preprint, 9 pages, 2 figures plus supplementary\n",
    "authors": [
      "Edo Cohen-Karlik",
      "Itamar Menuhin-Gruman",
      "Nadav Cohen",
      "Raja Giryes",
      "Amir Globerson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.14064"
  },
  {
    "id": "arXiv:2210.14145",
    "title": "GlassesGAN: Eyewear Personalization using Synthetic Appearance Discovery  and Targeted Subspace Modeling",
    "abstract": "Comments: 18 pages, 18 figures, 3 tables",
    "descriptor": "\nComments: 18 pages, 18 figures, 3 tables\n",
    "authors": [
      "Richard Plesh",
      "Peter Peer",
      "Vitomir \u0160truc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.14145"
  },
  {
    "id": "arXiv:2210.14163",
    "title": "Multi-Granularity Cross-Modality Representation Learning for Named  Entity Recognition on Social Media",
    "abstract": "Comments: We have reconducted experiments of the paper, but found that there were fatal errors in our datasets leading to the wrong results and analyses. Therefore, we have to withdraw the paper to ensure the authenticity of science. We are very sorry",
    "descriptor": "\nComments: We have reconducted experiments of the paper, but found that there were fatal errors in our datasets leading to the wrong results and analyses. Therefore, we have to withdraw the paper to ensure the authenticity of science. We are very sorry\n",
    "authors": [
      "Peipei Liu",
      "Gaosheng Wang",
      "Hong Li",
      "Jie Liu",
      "Yimo Ren",
      "Hongsong Zhu",
      "Limin Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.14163"
  },
  {
    "id": "arXiv:2210.14502",
    "title": "SentBS: Sentence-level Beam Search for Controllable Summarization",
    "abstract": "Comments: 10 pages, 1 figure, accepted by EMNLP 2022",
    "descriptor": "\nComments: 10 pages, 1 figure, accepted by EMNLP 2022\n",
    "authors": [
      "Chenhui Shen",
      "Liying Cheng",
      "Lidong Bing",
      "Yang You",
      "Luo Si"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.14502"
  },
  {
    "id": "arXiv:2210.16065",
    "title": "Polarization and reliability of news sources in Wikipedia",
    "abstract": "Comments: 15pages, 10 figures",
    "descriptor": "\nComments: 15pages, 10 figures\n",
    "authors": [
      "Puyu Yang",
      "Giovanni Colavizza"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2210.16065"
  },
  {
    "id": "arXiv:2210.17239",
    "title": "RIS-Based Steerable Beamforming Antenna with Near-Field Eigenmode Feeder",
    "abstract": "RIS-Based Steerable Beamforming Antenna with Near-Field Eigenmode Feeder",
    "descriptor": "",
    "authors": [
      "Krishan K. Tiwari",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2210.17239"
  },
  {
    "id": "arXiv:2210.17429",
    "title": "The power of the Binary Value Principle",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Yaroslav Alekseev",
      "Edward A. Hirsch"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.17429"
  },
  {
    "id": "arXiv:2211.00550",
    "title": "GLINKX: A Scalable Unified Framework For Homophilous and Heterophilous  Graphs",
    "abstract": "GLINKX: A Scalable Unified Framework For Homophilous and Heterophilous  Graphs",
    "descriptor": "",
    "authors": [
      "Marios Papachristou",
      "Rishab Goel",
      "Frank Portman",
      "Matthew Miller",
      "Rong Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.00550"
  },
  {
    "id": "arXiv:2211.00860",
    "title": "Insight into cloud processes from unsupervised classification with a  rotationally invariant autoencoder",
    "abstract": "Comments: 5 pages, 3 figures, the 36th conference on Neural Information Processing Systems (NeurIPS) Machine Learning and the Physical Sciences workshop",
    "descriptor": "\nComments: 5 pages, 3 figures, the 36th conference on Neural Information Processing Systems (NeurIPS) Machine Learning and the Physical Sciences workshop\n",
    "authors": [
      "Takuya Kurihana",
      "James Franke",
      "Ian Foster",
      "Ziwei Wang",
      "Elisabeth Moyer"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00860"
  },
  {
    "id": "arXiv:2211.01052",
    "title": "Offline RL With Realistic Datasets: Heteroskedasticity and Support  Constraints",
    "abstract": "Offline RL With Realistic Datasets: Heteroskedasticity and Support  Constraints",
    "descriptor": "",
    "authors": [
      "Anikait Singh",
      "Aviral Kumar",
      "Quan Vuong",
      "Yevgen Chebotar",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.01052"
  },
  {
    "id": "arXiv:2211.01138",
    "title": "Local Differentially Private Frequency Estimation based on Learned  Sketches",
    "abstract": "Local Differentially Private Frequency Estimation based on Learned  Sketches",
    "descriptor": "",
    "authors": [
      "Meifan Zhang",
      "Sixin Lin",
      "Lihua Yin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.01138"
  },
  {
    "id": "arXiv:2211.01201",
    "title": "Human alignment of neural network representations",
    "abstract": "Human alignment of neural network representations",
    "descriptor": "",
    "authors": [
      "Lukas Muttenthaler",
      "Jonas Dippel",
      "Lorenz Linhardt",
      "Robert A. Vandermeulen",
      "Simon Kornblith"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2211.01201"
  },
  {
    "id": "arXiv:2211.01602",
    "title": "Optimal Behavior Prior: Data-Efficient Human Models for Improved  Human-AI Collaboration",
    "abstract": "Comments: Presented at the NeurIPS 2022 Human in the Loop Learning (HiLL) Workshop",
    "descriptor": "\nComments: Presented at the NeurIPS 2022 Human in the Loop Learning (HiLL) Workshop\n",
    "authors": [
      "Mesut Yang",
      "Micah Carroll",
      "Anca Dragan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.01602"
  },
  {
    "id": "arXiv:2211.01747",
    "title": "Methodology for Simulation-based Comparison of Algorithms for  Distributed Mutual Exclusion",
    "abstract": "Comments: Updated references, title and contents",
    "descriptor": "\nComments: Updated references, title and contents\n",
    "authors": [
      "Filip De Turck"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.01747"
  },
  {
    "id": "arXiv:2211.01827",
    "title": "Demo: LE3D: A Privacy-preserving Lightweight Data Drift Detection  Framework",
    "abstract": "Comments: IEEE CCNC 2023, Las Vegas, USA",
    "descriptor": "\nComments: IEEE CCNC 2023, Las Vegas, USA\n",
    "authors": [
      "Ioannis Mavromatis",
      "Aftab Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.01827"
  },
  {
    "id": "arXiv:2211.02480",
    "title": "Characterization of optimal binary linear codes with one-dimensional  hull",
    "abstract": "Characterization of optimal binary linear codes with one-dimensional  hull",
    "descriptor": "",
    "authors": [
      "Shitao Li",
      "Minjia Shi",
      "Jon-Lark Kim"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.02480"
  },
  {
    "id": "arXiv:2211.03079",
    "title": "A Framework for Designing Efficient Deep Learning-Based Genomic  Basecallers",
    "abstract": "A Framework for Designing Efficient Deep Learning-Based Genomic  Basecallers",
    "descriptor": "",
    "authors": [
      "Gagandeep Singh",
      "Mohammed Alser",
      "Alireza Khodamoradi",
      "Kristof Denolf",
      "Can Firtina",
      "Meryem Banu Cavlak",
      "Henk Corporaal",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2211.03079"
  },
  {
    "id": "arXiv:2211.03318",
    "title": "Fixing Model Bugs with Natural Language Patches",
    "abstract": "Comments: Accepted at EMNLP 2022 [Fixed fig-1]",
    "descriptor": "\nComments: Accepted at EMNLP 2022 [Fixed fig-1]\n",
    "authors": [
      "Shikhar Murty",
      "Christopher D. Manning",
      "Scott Lundberg",
      "Marco Tulio Ribeiro"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.03318"
  },
  {
    "id": "arXiv:2211.03602",
    "title": "Retention Time Prediction for Chromatographic Enantioseparation by  Quantile Geometry-enhanced Graph Neural Network",
    "abstract": "Retention Time Prediction for Chromatographic Enantioseparation by  Quantile Geometry-enhanced Graph Neural Network",
    "descriptor": "",
    "authors": [
      "Hao Xu",
      "Jinglong Lin",
      "Dongxiao Zhang",
      "Fanyang Mo"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.03602"
  },
  {
    "id": "arXiv:2211.04047",
    "title": "DNN Filter for Bias Reduction in Distribution-to-Distribution Scan  Matching",
    "abstract": "DNN Filter for Bias Reduction in Distribution-to-Distribution Scan  Matching",
    "descriptor": "",
    "authors": [
      "Matthew McDermott",
      "Jason Rife"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04047"
  },
  {
    "id": "arXiv:2211.04607",
    "title": "First principles physics-informed neural network for quantum  wavefunctions and eigenvalue surfaces",
    "abstract": "First principles physics-informed neural network for quantum  wavefunctions and eigenvalue surfaces",
    "descriptor": "",
    "authors": [
      "Marios Mattheakis",
      "Gabriel R. Schleder",
      "Daniel T. Larson",
      "Efthimios Kaxiras"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.04607"
  },
  {
    "id": "arXiv:2211.05105",
    "title": "Safe Latent Diffusion: Mitigating Inappropriate Degeneration in  Diffusion Models",
    "abstract": "Safe Latent Diffusion: Mitigating Inappropriate Degeneration in  Diffusion Models",
    "descriptor": "",
    "authors": [
      "Patrick Schramowski",
      "Manuel Brack",
      "Bj\u00f6rn Deiseroth",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05105"
  },
  {
    "id": "arXiv:2211.05364",
    "title": "Efficient Unsupervised Video Object Segmentation Network Based on Motion  Guidance",
    "abstract": "Comments: The 10th International Conference on Information Systems and Computing Technology",
    "descriptor": "\nComments: The 10th International Conference on Information Systems and Computing Technology\n",
    "authors": [
      "Chao Hu",
      "Liqiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05364"
  },
  {
    "id": "arXiv:2211.05410",
    "title": "Robust Smart Home Face Recognition under Starving Federated Data",
    "abstract": "Comments: 11 pages, 12 figures, 7 tables, accepted as a conference paper at IEEE UV 2022, Boston, USA",
    "descriptor": "\nComments: 11 pages, 12 figures, 7 tables, accepted as a conference paper at IEEE UV 2022, Boston, USA\n",
    "authors": [
      "Jaechul Roh",
      "Yajun Fang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.05410"
  },
  {
    "id": "arXiv:2211.05554",
    "title": "Robust Federated Learning against both Data Heterogeneity and Poisoning  Attack via Aggregation Optimization",
    "abstract": "Robust Federated Learning against both Data Heterogeneity and Poisoning  Attack via Aggregation Optimization",
    "descriptor": "",
    "authors": [
      "Yueqi Xie",
      "Weizhong Zhang",
      "Renjie Pi",
      "Fangzhao Wu",
      "Qifeng Chen",
      "Xing Xie",
      "Sunghun Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.05554"
  },
  {
    "id": "arXiv:2211.05705",
    "title": "DiaASQ : A Benchmark of Conversational Aspect-based Sentiment Quadruple  Analysis",
    "abstract": "DiaASQ : A Benchmark of Conversational Aspect-based Sentiment Quadruple  Analysis",
    "descriptor": "",
    "authors": [
      "Bobo Li",
      "Hao Fei",
      "Fei Li",
      "Yuhan Wu",
      "Jinsong Zhang",
      "Shengqiong Wu",
      "Jingye Li",
      "Yijiang Liu",
      "Lizi Liao",
      "Tat-Seng Chua",
      "Donghong Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05705"
  },
  {
    "id": "arXiv:2211.05913",
    "title": "Twitter Spam and False Accounts Prevalence, Detection and  Characterization: A Survey",
    "abstract": "Comments: Submitted to First Monday",
    "descriptor": "\nComments: Submitted to First Monday\n",
    "authors": [
      "Emilio Ferrara"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.05913"
  },
  {
    "id": "arXiv:2211.05995",
    "title": "In-game Toxic Language Detection: Shared Task and Attention Residuals",
    "abstract": "Comments: Accepted at AAAI 2023 Poster",
    "descriptor": "\nComments: Accepted at AAAI 2023 Poster\n",
    "authors": [
      "Yuanzhe Jia",
      "Weixuan Wu",
      "Feiqi Cao",
      "Soyeon Caren Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05995"
  },
  {
    "id": "arXiv:2211.06475",
    "title": "High-Level Synthesis for Packet-Processing Pipelines",
    "abstract": "High-Level Synthesis for Packet-Processing Pipelines",
    "descriptor": "",
    "authors": [
      "Xiangyu Gao",
      "Divya Raghunathan",
      "Ruijie Fang",
      "Tao Wang",
      "Xiaotong Zhu",
      "Anirudh Sivaraman",
      "Srinivas Narayana",
      "Aarti Gupta"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.06475"
  },
  {
    "id": "arXiv:2211.06490",
    "title": "A Non-Volatile All-Spin Non-Binary Matrix Multiplier: An Efficient  Hardware Accelerator for Machine Learning",
    "abstract": "Comments: A slightly shorter version of this article has been accepted for publication in IEEE Transactions on Electron Devices. The replacement corrects some errors in the previously uploaded version",
    "descriptor": "\nComments: A slightly shorter version of this article has been accepted for publication in IEEE Transactions on Electron Devices. The replacement corrects some errors in the previously uploaded version\n",
    "authors": [
      "Rahnuma Rahman",
      "Supriyo Bandyopadhyay"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Systems and Control (eess.SY)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.06490"
  },
  {
    "id": "arXiv:2211.06552",
    "title": "Collecting Interactive Multi-modal Datasets for Grounded Language  Understanding",
    "abstract": "Collecting Interactive Multi-modal Datasets for Grounded Language  Understanding",
    "descriptor": "",
    "authors": [
      "Shrestha Mohanty",
      "Negar Arabzadeh",
      "Milagro Teruel",
      "Yuxuan Sun",
      "Artem Zholus",
      "Alexey Skrynnik",
      "Mikhail Burtsev",
      "Kavya Srinet",
      "Aleksandr Panov",
      "Arthur Szlam",
      "Marc-Alexandre C\u00f4t\u00e9",
      "Julia Kiseleva"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.06552"
  },
  {
    "id": "arXiv:2211.06560",
    "title": "ThreshNet: Segmentation Refinement Inspired by Region-Specific  Thresholding",
    "abstract": "Comments: 16 pages, 12 figures, 7 tables (Added supplementary material)",
    "descriptor": "\nComments: 16 pages, 12 figures, 7 tables (Added supplementary material)\n",
    "authors": [
      "Savinay Nagendra",
      "Chaopeng Shen",
      "Daniel Kifer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.06560"
  },
  {
    "id": "arXiv:2211.06588",
    "title": "DEYO: DETR with YOLO for Step-by-Step Object Detection",
    "abstract": "DEYO: DETR with YOLO for Step-by-Step Object Detection",
    "descriptor": "",
    "authors": [
      "Haodong Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.06588"
  },
  {
    "id": "arXiv:2211.06597",
    "title": "OpenGait: Revisiting Gait Recognition Toward Better Practicality",
    "abstract": "OpenGait: Revisiting Gait Recognition Toward Better Practicality",
    "descriptor": "",
    "authors": [
      "Chao Fan",
      "Junhao Liang",
      "Chuanfu Shen",
      "Saihui Hou",
      "Yongzhen Huang",
      "Shiqi Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.06597"
  },
  {
    "id": "arXiv:2211.06671",
    "title": "Open Higher-Order Logic (Long Version)",
    "abstract": "Open Higher-Order Logic (Long Version)",
    "descriptor": "",
    "authors": [
      "Ugo Dal Lago",
      "Francesco Gavazzo",
      "Alexis Ghyselen"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.06671"
  },
  {
    "id": "arXiv:2211.06679",
    "title": "AltCLIP: Altering the Language Encoder in CLIP for Extended Language  Capabilities",
    "abstract": "AltCLIP: Altering the Language Encoder in CLIP for Extended Language  Capabilities",
    "descriptor": "",
    "authors": [
      "Zhongzhi Chen",
      "Guang Liu",
      "Bo-Wen Zhang",
      "Fulong Ye",
      "Qinghong Yang",
      "Ledell Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.06679"
  },
  {
    "id": "arXiv:2211.06982",
    "title": "FullPack: Full Vector Utilization for Sub-Byte Quantized Inference on  General Purpose CPUs",
    "abstract": "FullPack: Full Vector Utilization for Sub-Byte Quantized Inference on  General Purpose CPUs",
    "descriptor": "",
    "authors": [
      "Hossein Katebi",
      "Navidreza Asadi",
      "Maziar Goudarzi"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.06982"
  },
  {
    "id": "arXiv:2211.07344",
    "title": "On Parsing as Tagging",
    "abstract": "Comments: Will appear in Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    "descriptor": "\nComments: Will appear in Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing\n",
    "authors": [
      "Afra Amini",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.07344"
  },
  {
    "id": "arXiv:2211.07354",
    "title": "Iterative Learning Control -- Deep Dive",
    "abstract": "Comments: Poster presented at LLRF Workshop 2022 (LLRF2022, arXiv:2208.13680)",
    "descriptor": "\nComments: Poster presented at LLRF Workshop 2022 (LLRF2022, arXiv:2208.13680)\n",
    "authors": [
      "Shane Rupert Koscielniak"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.07354"
  },
  {
    "id": "arXiv:2211.07365",
    "title": "Detecting Line Segments in Motion-blurred Images with Events",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Huai Yu",
      "Hao Li",
      "Wen Yang",
      "Lei Yu",
      "Gui-Song Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07365"
  },
  {
    "id": "arXiv:2211.07447",
    "title": "Deep Autoregressive Regression",
    "abstract": "Deep Autoregressive Regression",
    "descriptor": "",
    "authors": [
      "Adam Khakhar",
      "Jacob Buckman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07447"
  },
  {
    "id": "arXiv:2211.07454",
    "title": "LGN-Net: Local-Global Normality Network for Video Anomaly Detection",
    "abstract": "Comments: Under Review in IEEE TCSVT",
    "descriptor": "\nComments: Under Review in IEEE TCSVT\n",
    "authors": [
      "Mengyang Zhao",
      "Xinhua Zeng",
      "Jing Liu",
      "Di Li",
      "Chengxin Pang",
      "Yang Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07454"
  },
  {
    "id": "arXiv:2211.07587",
    "title": "Artificial neural networks for predicting the viscosity of  lead-containing glasses",
    "abstract": "Comments: 6 pages, 5 figures, 2 tables",
    "descriptor": "\nComments: 6 pages, 5 figures, 2 tables\n",
    "authors": [
      "Patrick dos Anjos",
      "Lucas A. Quaresma",
      "Marcelo L. P. Machado"
    ],
    "subjectives": [
      "Soft Condensed Matter (cond-mat.soft)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.07587"
  },
  {
    "id": "arXiv:2211.07767",
    "title": "Learning to Optimize with Stochastic Dominance Constraints",
    "abstract": "Comments: 24 pages, 44 figures",
    "descriptor": "\nComments: 24 pages, 44 figures\n",
    "authors": [
      "Hanjun Dai",
      "Yuan Xue",
      "Niao He",
      "Bethany Wang",
      "Na Li",
      "Dale Schuurmans",
      "Bo Dai"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.07767"
  },
  {
    "id": "arXiv:2211.07791",
    "title": "Differentially-Private Dynamic Average Consensus",
    "abstract": "Comments: IEEE CDC. arXiv admin note: substantial text overlap with arXiv:2210.16395; text overlap with arXiv:2209.01486",
    "descriptor": "\nComments: IEEE CDC. arXiv admin note: substantial text overlap with arXiv:2210.16395; text overlap with arXiv:2209.01486\n",
    "authors": [
      "Yongqiang Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.07791"
  },
  {
    "id": "arXiv:2211.07797",
    "title": "Energy Storage Price Arbitrage via Opportunity Value Function Prediction",
    "abstract": "Energy Storage Price Arbitrage via Opportunity Value Function Prediction",
    "descriptor": "",
    "authors": [
      "Ningkun Zheng",
      "Xiaoxiang Liu",
      "Bolun Xu",
      "Yuanyuan Shi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07797"
  },
  {
    "id": "arXiv:2211.07893",
    "title": "Federated Learning for Healthcare Domain - Pipeline, Applications and  Challenges",
    "abstract": "Comments: ACM Transactions on Computing for Healthcare, Vol. 3, No. 4, Article 40. Publication date: October 2022",
    "descriptor": "\nComments: ACM Transactions on Computing for Healthcare, Vol. 3, No. 4, Article 40. Publication date: October 2022\n",
    "authors": [
      "Madhura Joshi",
      "Ankit Pal",
      "Malaikannan Sankarasubbu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.07893"
  },
  {
    "id": "arXiv:2211.07897",
    "title": "Notes on Aharoni's rainbow cycle conjecture",
    "abstract": "Comments: 12 pages, 0 figures. Minor changes. Also added an exact result for the 3 colour case of Question 2.5",
    "descriptor": "\nComments: 12 pages, 0 figures. Minor changes. Also added an exact result for the 3 colour case of Question 2.5\n",
    "authors": [
      "Katie Clinch",
      "Jackson Goerner",
      "Tony Huynh",
      "Freddie Illingworth"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.07897"
  },
  {
    "id": "arXiv:2211.08332",
    "title": "Versatile Diffusion: Text, Images and Variations All in One Diffusion  Model",
    "abstract": "Comments: Github link: this https URL",
    "descriptor": "\nComments: Github link: this https URL\n",
    "authors": [
      "Xingqian Xu",
      "Zhangyang Wang",
      "Eric Zhang",
      "Kai Wang",
      "Humphrey Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08332"
  },
  {
    "id": "arXiv:2211.08398",
    "title": "Structured Knowledge Distillation Towards Efficient and Compact  Multi-View 3D Detection",
    "abstract": "Comments: Codes will be released if this paper is accepted",
    "descriptor": "\nComments: Codes will be released if this paper is accepted\n",
    "authors": [
      "Linfeng Zhang",
      "Yukang Shi",
      "Hung-Shuo Tai",
      "Zhipeng Zhang",
      "Yuan He",
      "Ke Wang",
      "Kaisheng Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08398"
  },
  {
    "id": "arXiv:2211.08512",
    "title": "N2V2 -- Fixing Noise2Void Checkerboard Artifacts with Modified Sampling  Strategies and a Tweaked Network Architecture",
    "abstract": "Comments: 16 pages, 7 figures, 5 page supplement, 4 supplementary figures, accepted at BIC workshop at ECCV 2022",
    "descriptor": "\nComments: 16 pages, 7 figures, 5 page supplement, 4 supplementary figures, accepted at BIC workshop at ECCV 2022\n",
    "authors": [
      "Eva H\u00f6ck",
      "Tim-Oliver Buchholz",
      "Anselm Brachmann",
      "Florian Jug",
      "Alexander Freytag"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08512"
  },
  {
    "id": "arXiv:2211.08544",
    "title": "Exploiting the Partly Scratch-off Lottery Ticket for Quantization-Aware  Training",
    "abstract": "Exploiting the Partly Scratch-off Lottery Ticket for Quantization-Aware  Training",
    "descriptor": "",
    "authors": [
      "Yunshan Zhong",
      "Mingbao Lin",
      "Yuxin Zhang",
      "Gongrui Nan",
      "Fei Chao",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08544"
  },
  {
    "id": "arXiv:2211.08583",
    "title": "Empirical Study on Optimizer Selection for Out-of-Distribution  Generalization",
    "abstract": "Comments: NeurIPS2022 Workshop on Distribution Shifts (DistShift)",
    "descriptor": "\nComments: NeurIPS2022 Workshop on Distribution Shifts (DistShift)\n",
    "authors": [
      "Hiroki Naganuma",
      "Kartik Ahuja",
      "Shiro Takagi",
      "Tetsuya Motokawa",
      "Rio Yokota",
      "Kohta Ishikawa",
      "Ikuro Sato",
      "Ioannis Mitliagkas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08583"
  },
  {
    "id": "arXiv:2211.08584",
    "title": "Toward expanding the scope of radiology report summarization to multiple  anatomies and modalities",
    "abstract": "Comments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 14 pages",
    "descriptor": "\nComments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 14 pages\n",
    "authors": [
      "Jean-Benoit Delbrouck",
      "Maya Varma",
      "Curtis P. Langlotz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08584"
  },
  {
    "id": "arXiv:2211.08608",
    "title": "LightDepth: A Resource Efficient Depth Estimation Approach for Dealing  with Ground Truth Sparsity via Curriculum Learning",
    "abstract": "Comments: 13 pages, 4 figures",
    "descriptor": "\nComments: 13 pages, 4 figures\n",
    "authors": [
      "Fatemeh Karimi",
      "Amir Mehrpanah",
      "Reza Rawassizadeh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08608"
  },
  {
    "id": "arXiv:2211.08609",
    "title": "R-Pred: Two-Stage Motion Prediction Via Tube-Query Attention-Based  Trajectory Refinement",
    "abstract": "R-Pred: Two-Stage Motion Prediction Via Tube-Query Attention-Based  Trajectory Refinement",
    "descriptor": "",
    "authors": [
      "Sehwan Choi",
      "Jungho Kim",
      "Junyong Yun",
      "Jun Won Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08609"
  },
  {
    "id": "arXiv:2211.08657",
    "title": "Person Text-Image Matching via Text-Feature Interpretability Embedding  and External Attack Node Implantation",
    "abstract": "Person Text-Image Matching via Text-Feature Interpretability Embedding  and External Attack Node Implantation",
    "descriptor": "",
    "authors": [
      "Fan Li",
      "Hang Zhou",
      "Huafeng Li",
      "Yafei Zhang",
      "Zhengtao Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08657"
  },
  {
    "id": "arXiv:2211.08705",
    "title": "Resource Allocation of Federated Learning for the Metaverse with Mobile  Augmented Reality",
    "abstract": "Comments: Journal version of 2022 IEEE 42nd International Conference on Distributed Computing Systems (ICDCS) paper: arXiv:2209.14900; i.e., this https URL",
    "descriptor": "\nComments: Journal version of 2022 IEEE 42nd International Conference on Distributed Computing Systems (ICDCS) paper: arXiv:2209.14900; i.e., this https URL\n",
    "authors": [
      "Xinyu Zhou",
      "Chang Liu",
      "Jun Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.08705"
  },
  {
    "id": "arXiv:2211.08761",
    "title": "Separable PINN: Mitigating the Curse of Dimensionality in  Physics-Informed Neural Networks",
    "abstract": "Comments: To appear in NeurIPS 2022 Workshop on The Symbiosis of Deep Learning and Differential Equations (DLDE) - II, 12 pages, 5 figures",
    "descriptor": "\nComments: To appear in NeurIPS 2022 Workshop on The Symbiosis of Deep Learning and Differential Equations (DLDE) - II, 12 pages, 5 figures\n",
    "authors": [
      "Junwoo Cho",
      "Seungtae Nam",
      "Hyunmo Yang",
      "Seok-Bae Yun",
      "Youngjoon Hong",
      "Eunbyung Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08761"
  },
  {
    "id": "arXiv:2211.08778",
    "title": "A Combinational Multi-Kernel Decoder for Polar Codes",
    "abstract": "A Combinational Multi-Kernel Decoder for Polar Codes",
    "descriptor": "",
    "authors": [
      "Hossein Rezaei",
      "Nandana Rajatheva",
      "Matti Latva-aho"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Hardware Architecture (cs.AR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.08778"
  },
  {
    "id": "arXiv:2211.08796",
    "title": "Model Based Residual Policy Learning with Applications to Antenna  Control",
    "abstract": "Model Based Residual Policy Learning with Applications to Antenna  Control",
    "descriptor": "",
    "authors": [
      "Viktor Eriksson M\u00f6llerstedt",
      "Alessio Russo",
      "Maxime Bouton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.08796"
  },
  {
    "id": "arXiv:2211.08824",
    "title": "SMILEtrack: SiMIlarity LEarning for Multiple Object Tracking",
    "abstract": "Comments: 9 pages, 6 figures",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Yu-Hsiang Wang",
      "Jun-Wei Hsieh",
      "Ping-Yang Chen",
      "Ming-Ching Chang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08824"
  },
  {
    "id": "arXiv:2211.08892",
    "title": "Fast Graph Generation via Spectral Diffusion",
    "abstract": "Fast Graph Generation via Spectral Diffusion",
    "descriptor": "",
    "authors": [
      "Tianze Luo",
      "Zhanfeng Mo",
      "Sinno Jialin Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08892"
  },
  {
    "id": "arXiv:2211.09174",
    "title": "CASPR: Customer Activity Sequence-based Prediction and Representation",
    "abstract": "Comments: Presented at the Table Representation Learning Workshop, NeurIPS 2022, New Orleans. Authors listed in random order",
    "descriptor": "\nComments: Presented at the Table Representation Learning Workshop, NeurIPS 2022, New Orleans. Authors listed in random order\n",
    "authors": [
      "Pin-Jung Chen",
      "Sahil Bhatnagar",
      "Damian Konrad Kowalczyk",
      "Mayank Shrivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.09174"
  },
  {
    "id": "arXiv:2211.09253",
    "title": "Beurling-Selberg Extremization for Dual-Blind Deconvolution Recovery in  Joint Radar-Communications",
    "abstract": "Comments: 7 pages, 2 figures",
    "descriptor": "\nComments: 7 pages, 2 figures\n",
    "authors": [
      "Jonathan Monsalve",
      "Edwin Vargas",
      "Kumar Vijay Mishra",
      "Brian M. Sadler",
      "Henry Arguello"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Functional Analysis (math.FA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.09253"
  },
  {
    "id": "arXiv:2211.09487",
    "title": "Towards Trace-based Deductive Verification (Tech Report)",
    "abstract": "Comments: 24 pages",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Richard Bubel",
      "Dilian Gurov",
      "Reiner H\u00e4hnle",
      "Marco Scaletta"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.09487"
  },
  {
    "id": "arXiv:2211.09510",
    "title": "Self-supervised Trajectory Representation Learning with Temporal  Regularities and Travel Semantics",
    "abstract": "Comments: Accepted by ICDE 2023",
    "descriptor": "\nComments: Accepted by ICDE 2023\n",
    "authors": [
      "Jiawei Jiang",
      "Dayan Pan",
      "Houxing Ren",
      "Xiaohan Jiang",
      "Chao Li",
      "Jingyuan Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09510"
  },
  {
    "id": "arXiv:2211.09591",
    "title": "Personal Privacy Protection Problems in the Digital Age",
    "abstract": "Comments: 9 pages, 3 figures",
    "descriptor": "\nComments: 9 pages, 3 figures\n",
    "authors": [
      "Zhiheng Yi",
      "Xiaoli Chen"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.09591"
  },
  {
    "id": "arXiv:2211.09783",
    "title": "UniSumm: Unified Few-shot Summarization with Multi-Task Pre-Training and  Prefix-Tuning",
    "abstract": "UniSumm: Unified Few-shot Summarization with Multi-Task Pre-Training and  Prefix-Tuning",
    "descriptor": "",
    "authors": [
      "Yulong Chen",
      "Yang Liu",
      "Ruochen Xu",
      "Ziyi Yang",
      "Chenguang Zhu",
      "Michael Zeng",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.09783"
  },
  {
    "id": "arXiv:2211.09787",
    "title": "Auction-based Operation in LEO Satellite Systems for High-Efficiency  Communications",
    "abstract": "Auction-based Operation in LEO Satellite Systems for High-Efficiency  Communications",
    "descriptor": "",
    "authors": [
      "Lin Cheng",
      "Bernardo A. Huberman"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.09787"
  },
  {
    "id": "arXiv:2211.09807",
    "title": "Towards All-in-one Pre-training via Maximizing Multi-modal Mutual  Information",
    "abstract": "Towards All-in-one Pre-training via Maximizing Multi-modal Mutual  Information",
    "descriptor": "",
    "authors": [
      "Weijie Su",
      "Xizhou Zhu",
      "Chenxin Tao",
      "Lewei Lu",
      "Bin Li",
      "Gao Huang",
      "Yu Qiao",
      "Xiaogang Wang",
      "Jie Zhou",
      "Jifeng Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09807"
  },
  {
    "id": "arXiv:2211.09861",
    "title": "Self-Supervised Visual Representation Learning via Residual Momentum",
    "abstract": "Comments: 18 pages, 16 figures",
    "descriptor": "\nComments: 18 pages, 16 figures\n",
    "authors": [
      "Trung X. Pham",
      "Axi Niu",
      "Zhang Kang",
      "Sultan Rizky Madjid",
      "Ji Woo Hong",
      "Daehyeok Kim",
      "Joshua Tian Jin Tee",
      "Chang D. Yoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09861"
  },
  {
    "id": "arXiv:2211.10085",
    "title": "Identifying Unique Causal Network from Nonstationary Time Series",
    "abstract": "Comments: This manuscript are submitted so that other researchers can follow",
    "descriptor": "\nComments: This manuscript are submitted so that other researchers can follow\n",
    "authors": [
      "Mingyu Kang",
      "Duxin Chen",
      "Ning Meng",
      "Gang Yan",
      "Wenwu Yu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10085"
  },
  {
    "id": "arXiv:2211.10155",
    "title": "Structured Pruning Adapters",
    "abstract": "Comments: 12 pages, 9 figures, 4 tables",
    "descriptor": "\nComments: 12 pages, 9 figures, 4 tables\n",
    "authors": [
      "Lukas Hedegaard",
      "Aman Alok",
      "Juby Jose",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10155"
  },
  {
    "id": "arXiv:2211.10156",
    "title": "DETRDistill: A Universal Knowledge Distillation Framework for  DETR-families",
    "abstract": "Comments: 10 pages, 5 figures",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Jiahao Chang",
      "Shuo Wang",
      "Guangkai Xu",
      "Zehui Chen",
      "Chenhongyi Yang",
      "Feng Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10156"
  },
  {
    "id": "arXiv:2211.10298",
    "title": "Reinforcement Learning Methods for Wordle: A POMDP/Adaptive Control  Approach",
    "abstract": "Reinforcement Learning Methods for Wordle: A POMDP/Adaptive Control  Approach",
    "descriptor": "",
    "authors": [
      "Siddhant Bhambri",
      "Amrita Bhattacharjee",
      "Dimitri Bertsekas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10298"
  },
  {
    "id": "arXiv:2211.10400",
    "title": "On Weakly Hausdorff Spaces and Locally Strongly Sober Spaces",
    "abstract": "Comments: 16 pages; fixed proof of Proposition 4.4",
    "descriptor": "\nComments: 16 pages; fixed proof of Proposition 4.4\n",
    "authors": [
      "Jean Goubault-Larrecq"
    ],
    "subjectives": [
      "General Topology (math.GN)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.10400"
  },
  {
    "id": "arXiv:2211.10412",
    "title": "Video Unsupervised Domain Adaptation with Deep Learning: A Comprehensive  Survey",
    "abstract": "Comments: Survey on Video Unsupervised Domain Adaptation (VUDA), 16 pages, 1 figure, 8 tables",
    "descriptor": "\nComments: Survey on Video Unsupervised Domain Adaptation (VUDA), 16 pages, 1 figure, 8 tables\n",
    "authors": [
      "Yuecong Xu",
      "Haozhi Cao",
      "Zhenghua Chen",
      "Xiaoli Li",
      "Lihua Xie",
      "Jianfei Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10412"
  }
]
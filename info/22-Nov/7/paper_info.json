[
  {
    "id": "arXiv:2211.02050",
    "title": "An Adaptive Batch Normalization in Deep Learning",
    "abstract": "Batch Normalization (BN) is a way to accelerate and stabilize training in\ndeep convolutional neural networks. However, the BN works continuously within\nthe network structure, although some training data may not always require it.\nIn this research work, we propose a threshold-based adaptive BN approach that\nseparates the data that requires the BN and data that does not require it. The\nexperimental evaluation demonstrates that proposed approach achieves better\nperformance mostly in small batch sizes than the traditional BN using MNIST,\nFashion-MNIST, CIFAR-10, and CIFAR-100. It also reduces the occurrence of\ninternal variable transformation to increase network stability",
    "descriptor": "\nComments: 7 pages,6 figures\n",
    "authors": [
      "Wael Alsobhi",
      "Tarik Alafif",
      "Alaa Abdel-Hakim",
      "Weiwei Zong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02050"
  },
  {
    "id": "arXiv:2211.02052",
    "title": "Theta-Resonance: A Single-Step Reinforcement Learning Method for Design  Space Exploration",
    "abstract": "Given an environment (e.g., a simulator) for evaluating samples in a\nspecified design space and a set of weighted evaluation metrics -- one can use\nTheta-Resonance, a single-step Markov Decision Process (MDP), to train an\nintelligent agent producing progressively more optimal samples. In\nTheta-Resonance, a neural network consumes a constant input tensor and produces\na policy as a set of conditional probability density functions (PDFs) for\nsampling each design dimension. We specialize existing policy gradient\nalgorithms in deep reinforcement learning (D-RL) in order to use evaluation\nfeedback (in terms of cost, penalty or reward) to update our policy network\nwith robust algorithmic stability and minimal design evaluations. We study\nmultiple neural architectures (for our policy network) within the context of a\nsimple SoC design space and propose a method of constructing synthetic space\nexploration problems to compare and improve design space exploration (DSE)\nalgorithms. Although we only present categorical design spaces, we also outline\nhow to use Theta-Resonance in order to explore continuous and mixed\ncontinuous-discrete design spaces.",
    "descriptor": "",
    "authors": [
      "Masood S. Mortazavi",
      "Tiancheng Qin",
      "Ning Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.02052"
  },
  {
    "id": "arXiv:2211.02069",
    "title": "LMentry: A Language Model Benchmark of Elementary Language Tasks",
    "abstract": "As the performance of large language models rapidly improves, benchmarks are\ngetting larger and more complex as well. We present LMentry, a benchmark that\navoids this \"arms race\" by focusing on a compact set of tasks that are trivial\nto humans, e.g. writing a sentence containing a specific word, identifying\nwhich words in a list belong to a specific category, or choosing which of two\nwords is longer. LMentry is specifically designed to provide quick and\ninterpretable insights into the capabilities and robustness of large language\nmodels. Our experiments reveal a wide variety of failure cases that, while\nimmediately obvious to humans, pose a considerable challenge for large language\nmodels, including OpenAI's latest 175B-parameter instruction-tuned model,\nTextDavinci002. LMentry complements contemporary evaluation approaches of large\nlanguage models, providing a quick, automatic, and easy-to-run \"unit test\",\nwithout resorting to large benchmark suites of complex tasks.",
    "descriptor": "\nComments: 24 pages, 2 figures\n",
    "authors": [
      "Avia Efrat",
      "Or Honovich",
      "Omer Levy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02069"
  },
  {
    "id": "arXiv:2211.02075",
    "title": "An interactive visualisation for all 2x2 real matrices, with  applications to conveying the dynamics of iterative eigenvalue algorithms",
    "abstract": "We present two interactive visualisations of 2x2 real matrices, which we call\nv1 and v2. v1 is only valid for PSD matrices, and uses the spectral theorem in\na trivial way -- we use it as a warm-up. By contrast, v2 is valid for *all* 2x2\nreal matrices, and is based on the lesser known theory of Lie Sphere Geometry.\nWe show that the dynamics of iterative eigenvalue algorithms can be illustrated\nusing both. v2 has the advantage that it simultaneously depicts many properties\nof a matrix, all of which are relevant to the study of eigenvalue algorithms.\nExamples of the properties of a matrix that v2 can depict are its Jordan Normal\nForm and orthogonal similarity class, as well as whether it is triangular,\nsymmetric or orthogonal. Despite its richness, using v2 interactively seems\nrather intuitive.",
    "descriptor": "",
    "authors": [
      "Ran Gutin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.02075"
  },
  {
    "id": "arXiv:2211.02077",
    "title": "Scaling Multimodal Pre-Training via Cross-Modality Gradient  Harmonization",
    "abstract": "Self-supervised pre-training recently demonstrates success on large-scale\nmultimodal data, and state-of-the-art contrastive learning methods often\nenforce the feature consistency from cross-modality inputs, such as video/audio\nor video/text pairs. Despite its convenience to formulate and leverage in\npractice, such cross-modality alignment (CMA) is only a weak and noisy\nsupervision, since two modalities can be semantically misaligned even they are\ntemporally aligned. For example, even in the commonly adopted instructional\nvideos, a speaker can sometimes refer to something that is not visually present\nin the current frame; and the semantic misalignment would only be more\nunpredictable for the raw videos from the internet. We conjecture that might\ncause conflicts and biases among modalities, and may hence prohibit CMA from\nscaling up to training with larger and more heterogeneous data. This paper\nfirst verifies our conjecture by observing that, even in the latest VATT\npre-training using only instructional videos, there exist strong gradient\nconflicts between different CMA losses within the same video, audio, text\ntriplet, indicating them as the noisy source of supervision. We then propose to\nharmonize such gradients, via two techniques: (i) cross-modality gradient\nrealignment: modifying different CMA loss gradients for each sample triplet, so\nthat their gradient directions are more aligned; and (ii) gradient-based\ncurriculum learning: leveraging the gradient conflict information on an\nindicator of sample noisiness, to develop a curriculum learning strategy to\nprioritize training on less noisy sample triplets. Applying those techniques to\npre-training VATT on the HowTo100M dataset, we consistently improve its\nperformance on different downstream tasks. Moreover, we are able to scale VATT\npre-training to more complicated non-narrative Youtube8M dataset to further\nimprove the state-of-the-arts.",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Junru Wu",
      "Yi Liang",
      "Feng Han",
      "Hassan Akbari",
      "Zhangyang Wang",
      "Cong Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.02077"
  },
  {
    "id": "arXiv:2211.02089",
    "title": "Group Cohesion in Multi-Agent Scenarios as an Emergent Behavior",
    "abstract": "In this paper, we elaborate on the design and discuss the results of a\nmulti-agent simulation that we have developed using the PSI cognitive\narchitecture. We demonstrate that imbuing agents with intrinsic needs for group\naffiliation, certainty and competence will lead to the emergence of social\nbehavior among agents. This behavior expresses itself in altruism toward\nin-group agents and adversarial tendencies toward out-group agents. Our\nsimulation also shows how parameterization can have dramatic effects on agent\nbehavior. Introducing an out-group bias, for example, not only made agents\nbehave aggressively toward members of the other group, but it also increased\nin-group cohesion. Similarly, environmental and situational factors facilitated\nthe emergence of outliers: agents from adversarial groups becoming close\nfriends.\nOverall, this simulation showcases the power of psychological frameworks, in\ngeneral, and the PSI paradigm, in particular, to bring about human-like\nbehavioral patterns in an emergent fashion.",
    "descriptor": "",
    "authors": [
      "Gianluca Georg Alois Volkmer",
      "Nabil Alsabah"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.02089"
  },
  {
    "id": "arXiv:2211.02091",
    "title": "Fairness in Federated Learning via Core-Stability",
    "abstract": "Federated learning provides an effective paradigm to jointly optimize a model\nbenefited from rich distributed data while protecting data privacy.\nNonetheless, the heterogeneity nature of distributed data makes it challenging\nto define and ensure fairness among local agents. For instance, it is\nintuitively \"unfair\" for agents with data of high quality to sacrifice their\nperformance due to other agents with low quality data. Currently popular\negalitarian and weighted equity-based fairness measures suffer from the\naforementioned pitfall. In this work, we aim to formally represent this problem\nand address these fairness issues using concepts from co-operative game theory\nand social choice theory. We model the task of learning a shared predictor in\nthe federated setting as a fair public decision making problem, and then define\nthe notion of core-stable fairness: Given $N$ agents, there is no subset of\nagents $S$ that can benefit significantly by forming a coalition among\nthemselves based on their utilities $U_N$ and $U_S$ (i.e., $\\frac{|S|}{N} U_S\n\\geq U_N$). Core-stable predictors are robust to low quality local data from\nsome agents, and additionally they satisfy Proportionality and\nPareto-optimality, two well sought-after fairness and efficiency notions within\nsocial choice. We then propose an efficient federated learning protocol CoreFed\nto optimize a core stable predictor. CoreFed determines a core-stable predictor\nwhen the loss functions of the agents are convex. CoreFed also determines\napproximate core-stable predictors when the loss functions are not convex, like\nsmooth neural networks. We further show the existence of core-stable predictors\nin more general settings using Kakutani's fixed point theorem. Finally, we\nempirically validate our analysis on two real-world datasets, and we show that\nCoreFed achieves higher core-stability fairness than FedAvg while having\nsimilar accuracy.",
    "descriptor": "\nComments: NeurIPS 2022; code: this https URL&name=supplementary_material\n",
    "authors": [
      "Bhaskar Ray Chaudhury",
      "Linyi Li",
      "Mintong Kang",
      "Bo Li",
      "Ruta Mehta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.02091"
  },
  {
    "id": "arXiv:2211.02092",
    "title": "Making Machine Learning Datasets and Models FAIR for HPC: A Methodology  and Case Study",
    "abstract": "The FAIR Guiding Principles aim to improve the findability, accessibility,\ninteroperability, and reusability of digital content by making them both human\nand machine actionable. However, these principles have not yet been broadly\nadopted in the domain of machine learning-based program analyses and\noptimizations for High-Performance Computing (HPC). In this paper, we design a\nmethodology to make HPC datasets and machine learning models FAIR after\ninvestigating existing FAIRness assessment and improvement techniques. Our\nmethodology includes a comprehensive, quantitative assessment for elected data,\nfollowed by concrete, actionable suggestions to improve FAIRness with respect\nto common issues related to persistent identifiers, rich metadata descriptions,\nlicense and provenance information. Moreover, we select a representative\ntraining dataset to evaluate our methodology. The experiment shows the\nmethodology can effectively improve the dataset and model's FAIRness from an\ninitial score of 19.1% to the final score of 83.0%.",
    "descriptor": "",
    "authors": [
      "Pei-Hung Lin",
      "Chunhua Liao",
      "Winson Chen",
      "Tristan Vanderbruggen",
      "Murali Emani",
      "Hailu Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.02092"
  },
  {
    "id": "arXiv:2211.02093",
    "title": "Domain Adaptation under Missingness Shift",
    "abstract": "Rates of missing data often depend on record-keeping policies and thus may\nchange across times and locations, even when the underlying features are\ncomparatively stable. In this paper, we introduce the problem of Domain\nAdaptation under Missingness Shift (DAMS). Here, (labeled) source data and\n(unlabeled) target data would be exchangeable but for different missing data\nmechanisms. We show that when missing data indicators are available, DAMS can\nreduce to covariate shift. Focusing on the setting where missing data\nindicators are absent, we establish the following theoretical results for\nunderreporting completely at random: (i) covariate shift is violated\n(adaptation is required); (ii) the optimal source predictor can perform worse\non the target domain than a constant one; (iii) the optimal target predictor\ncan be identified, even when the missingness rates themselves are not; and (iv)\nfor linear models, a simple analytic adjustment yields consistent estimates of\nthe optimal target parameters. In experiments on synthetic and semi-synthetic\ndata, we demonstrate the promise of our methods when assumptions hold. Finally,\nwe discuss a rich family of future extensions.",
    "descriptor": "",
    "authors": [
      "Helen Zhou",
      "Sivaraman Balakrishnan",
      "Zachary C. Lipton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.02093"
  },
  {
    "id": "arXiv:2211.02098",
    "title": "Overcoming Barriers to Skill Injection in Language Modeling: Case Study  in Arithmetic",
    "abstract": "Through their transfer learning abilities, highly-parameterized large\npre-trained language models have dominated the NLP landscape for a multitude of\ndownstream language tasks. Though linguistically proficient, the inability of\nthese models to incorporate the learning of non-linguistic entities (numerals\nand arithmetic reasoning) limits their usage for tasks that require numeric\ncomprehension or strict mathematical reasoning. However, as we illustrate in\nthis paper, building a general purpose language model that also happens to be\nproficient in mathematical reasoning is not as straight-forward as training it\non a numeric dataset. In this work, we develop a novel framework that enables\nlanguage models to be mathematically proficient while retaining their\nlinguistic prowess. Specifically, we offer information-theoretic interventions\nto overcome the catastrophic forgetting of linguistic skills that occurs while\ninjecting non-linguistic skills into language models.",
    "descriptor": "\nComments: NeurIPS 2022: Math-AI Workshop\n",
    "authors": [
      "Mandar Sharma",
      "Nikhil Muralidhar",
      "Naren Ramakrishnan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02098"
  },
  {
    "id": "arXiv:2211.02100",
    "title": "Contrastive Value Learning: Implicit Models for Simple Offline RL",
    "abstract": "Model-based reinforcement learning (RL) methods are appealing in the offline\nsetting because they allow an agent to reason about the consequences of actions\nwithout interacting with the environment. Prior methods learn a 1-step dynamics\nmodel, which predicts the next state given the current state and action. These\nmodels do not immediately tell the agent which actions to take, but must be\nintegrated into a larger RL framework. Can we model the environment dynamics in\na different way, such that the learned model does directly indicate the value\nof each action? In this paper, we propose Contrastive Value Learning (CVL),\nwhich learns an implicit, multi-step model of the environment dynamics. This\nmodel can be learned without access to reward functions, but nonetheless can be\nused to directly estimate the value of each action, without requiring any TD\nlearning. Because this model represents the multi-step transitions implicitly,\nit avoids having to predict high-dimensional observations and thus scales to\nhigh-dimensional tasks. Our experiments demonstrate that CVL outperforms prior\noffline RL methods on complex continuous control benchmarks.",
    "descriptor": "\nComments: Deep Reinforcement Learning Workshop, NeurIPS 2022\n",
    "authors": [
      "Bogdan Mazoure",
      "Benjamin Eysenbach",
      "Ofir Nachum",
      "Jonathan Tompson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.02100"
  },
  {
    "id": "arXiv:2211.02106",
    "title": "Federated Hypergradient Descent",
    "abstract": "In this work, we explore combining automatic hyperparameter tuning and\noptimization for federated learning (FL) in an online, one-shot procedure. We\napply a principled approach on a method for adaptive client learning rate,\nnumber of local steps, and batch size. In our federated learning applications,\nour primary motivations are minimizing communication budget as well as local\ncomputational resources in the training pipeline. Conventionally,\nhyperparameter tuning methods involve at least some degree of trial-and-error,\nwhich is known to be sample inefficient. In order to address our motivations,\nwe propose FATHOM (Federated AuTomatic Hyperparameter OptiMization) as a\none-shot online procedure. We investigate the challenges and solutions of\nderiving analytical gradients with respect to the hyperparameters of interest.\nOur approach is inspired by the fact that, with the exception of local data, we\nhave full knowledge of all components involved in our training process, and\nthis fact can be exploited in our algorithm impactfully. We show that FATHOM is\nmore communication efficient than Federated Averaging (FedAvg) with optimized,\nstatic valued hyperparameters, and is also more computationally efficient\noverall. As a communication efficient, one-shot online procedure, FATHOM solves\nthe bottleneck of costly communication and limited local computation, by\neliminating a potentially wasteful tuning process, and by optimizing the\nhyperparamters adaptively throughout the training procedure without\ntrial-and-error. We show our numerical results through extensive empirical\nexperiments with the Federated EMNIST-62 (FEMNIST) and Federated Stack Overflow\n(FSO) datasets, using FedJAX as our baseline framework.",
    "descriptor": "",
    "authors": [
      "Andrew K Kan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02106"
  },
  {
    "id": "arXiv:2211.02107",
    "title": "Variable Parameter Analysis for Scheduling One Machine",
    "abstract": "In contrast to the fixed parameter analysis (FPA), in the variable parameter\nanalysis (VPA) the value of the target problem parameter is not fixed, it\nrather depends on the structure of a given problem instance and tends to have a\nfavorable asymptotic behavior when the size of the input increases. While\napplying the VPA to an intractable optimization problem with $n$ objects, the\nexponential-time dependence in enumeration of the feasible solution set is\nattributed solely to the variable parameter $\\nu$, $\\nu<<n$. As opposed to the\nFPA, the VPA does not imply any restriction on some problem parameters, it\nrather takes an advantage of a favorable nature of the problem, which permits\nto reduce the cost of enumeration of the solution space. Our main technical\ncontribution is a variable parameter algorithm for a strongly\n$\\mathsf{NP}$-hard single-machine scheduling problem to minimize maximum job\nlateness. The target variable parameter $\\nu$ is the number of jobs with some\nspecific characteristics, the ``emerging'' ones. The solution process is\nseparated in two phases. At phase 1 a partial solution including $n-\\nu$\nnon-emerging jobs is constructed in a low degree polynomial time. At phase 2\nless than $\\nu!$ permutations of the $\\nu$ emerging jobs are considered. Each\nof them are incorporated into the partial schedule of phase 1. Doe to the\nresults of an earlier conducted experimental study, $\\nu/n$ varied from $1/4$\nfor small problem instances to $1/10$ for the largest tested problem instances,\nso that that the ratio becomes closer to 0 for large $n$s.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2103.09900\n",
    "authors": [
      "Nodari Vakhania"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.02107"
  },
  {
    "id": "arXiv:2211.02108",
    "title": "Sky-image-based solar forecasting using deep learning with  multi-location data: training models locally, globally or via transfer  learning?",
    "abstract": "Solar forecasting from ground-based sky images using deep learning models has\nshown great promise in reducing the uncertainty in solar power generation. One\nof the biggest challenges for training deep learning models is the availability\nof labeled datasets. With more and more sky image datasets open sourced in\nrecent years, the development of accurate and reliable solar forecasting\nmethods has seen a huge growth in potential. In this study, we explore three\ndifferent training strategies for deep-learning-based solar forecasting models\nby leveraging three heterogeneous datasets collected around the world with\ndrastically different climate patterns. Specifically, we compare the\nperformance of models trained individually based on local datasets (local\nmodels) and models trained jointly based on the fusion of multiple datasets\nfrom different locations (global models), and we further examine the knowledge\ntransfer from pre-trained solar forecasting models to a new dataset of interest\n(transfer learning models). The results suggest that the local models work well\nwhen deployed locally, but significant errors are observed for the scale of the\nprediction when applied offsite. The global model can adapt well to individual\nlocations, while the possible increase in training efforts need to be taken\ninto account. Pre-training models on a large and diversified source dataset and\ntransferring to a local target dataset generally achieves superior performance\nover the other two training strategies. Transfer learning brings the most\nbenefits when there are limited local data. With 80% less training data, it can\nachieve 1% improvement over the local baseline model trained using the entire\ndataset. Therefore, we call on the efforts from the solar forecasting community\nto contribute to a global dataset containing a massive amount of imagery and\ndisplaying diversified samples with a range of sky conditions.",
    "descriptor": "",
    "authors": [
      "Yuhao Nie",
      "Quentin Paletta",
      "Andea Scotta",
      "Luis Martin Pomares",
      "Guillaume Arbod",
      "Sgouris Sgouridis",
      "Joan Lasenby",
      "Adam Brandt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.02108"
  },
  {
    "id": "arXiv:2211.02111",
    "title": "Translated Skip Connections -- Expanding the Receptive Fields of Fully  Convolutional Neural Networks",
    "abstract": "The effective receptive field of a fully convolutional neural network is an\nimportant consideration when designing an architecture, as it defines the\nportion of the input visible to each convolutional kernel. We propose a neural\nnetwork module, extending traditional skip connections, called the translated\nskip connection. Translated skip connections geometrically increase the\nreceptive field of an architecture with negligible impact on both the size of\nthe parameter space and computational complexity. By embedding translated skip\nconnections into a benchmark architecture, we demonstrate that our module\nmatches or outperforms four other approaches to expanding the effective\nreceptive fields of fully convolutional neural networks. We confirm this result\nacross five contemporary image segmentation datasets from disparate domains,\nincluding the detection of COVID-19 infection, segmentation of aerial imagery,\ncommon object segmentation, and segmentation for self-driving cars.",
    "descriptor": "\nComments: 5 pages, 2 figures, 1 table, published at the 2022 IEEE International Conference on Image Processing\n",
    "authors": [
      "Joshua Bruton",
      "Hairong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.02111"
  },
  {
    "id": "arXiv:2211.02115",
    "title": "Abstract Images Have Different Levels of Retrievability Per Reverse  Image Search Engine",
    "abstract": "Much computer vision research has focused on natural images, but technical\ndocuments typically consist of abstract images, such as charts, drawings,\ndiagrams, and schematics. How well do general web search engines discover\nabstract images? Recent advancements in computer vision and machine learning\nhave led to the rise of reverse image search engines. Where conventional search\nengines accept a text query and return a set of document results, including\nimages, a reverse image search accepts an image as a query and returns a set of\nimages as results. This paper evaluates how well common reverse image search\nengines discover abstract images. We conducted an experiment leveraging images\nfrom Wikimedia Commons, a website known to be well indexed by Baidu, Bing,\nGoogle, and Yandex. We measure how difficult an image is to find again\n(retrievability), what percentage of images returned are relevant (precision),\nand the average number of results a visitor must review before finding the\nsubmitted image (mean reciprocal rank). When trying to discover the same image\nagain among similar images, Yandex performs best. When searching for pages\ncontaining a specific image, Google and Yandex outperform the others when\ndiscovering photographs with precision scores ranging from 0.8191 to 0.8297,\nrespectively. In both of these cases, Google and Yandex perform better with\nnatural images than with abstract ones achieving a difference in retrievability\nas high as 54\\% between images in these categories. These results affect anyone\napplying common web search engines to search for technical documents that use\nabstract images.",
    "descriptor": "\nComments: 20 pages; 7 figures; to be published in the proceedings of the Drawings and abstract Imagery: Representation and Analysis (DIRA) Workshop from ECCV 2022\n",
    "authors": [
      "Shawn M. Jones",
      "Diane Oyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.02115"
  },
  {
    "id": "arXiv:2211.02119",
    "title": "Handwritten Arabic Character Recognition for Children Writ-ing Using  Convolutional Neural Network and Stroke Identification",
    "abstract": "Automatic Arabic handwritten recognition is one of the recently studied\nproblems in the field of Machine Learning. Unlike Latin languages, Arabic is a\nSemitic language that forms a harder challenge, especially with variability of\npatterns caused by factors such as writer age. Most of the studies focused on\nadults, with only one recent study on children. Moreover, much of the recent\nMachine Learning methods focused on using Convolutional Neural Networks, a\npowerful class of neural networks that can extract complex features from\nimages. In this paper we propose a convolutional neural network (CNN) model\nthat recognizes children handwriting with an accuracy of 91% on the Hijja\ndataset, a recent dataset built by collecting images of the Arabic characters\nwritten by children, and 97% on Arabic Handwritten Character Dataset. The\nresults showed a good improvement over the proposed model from the Hijja\ndataset authors, yet it reveals a bigger challenge to solve for children Arabic\nhandwritten character recognition. Moreover, we proposed a new approach using\nmulti models instead of single model based on the number of strokes in a\ncharacter, and merged Hijja with AHCD which reached an averaged prediction\naccuracy of 96%.",
    "descriptor": "\nComments: 17\n",
    "authors": [
      "Mais Alheraki",
      "Rawan Al-Matham",
      "Hend Al-Khalifa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.02119"
  },
  {
    "id": "arXiv:2211.02125",
    "title": "Graph-Based Multi-Camera Soccer Player Tracker",
    "abstract": "The paper presents a multi-camera tracking method intended for tracking\nsoccer players in long shot video recordings from multiple calibrated cameras\ninstalled around the playing field. The large distance to the camera makes it\ndifficult to visually distinguish individual players, which adversely affects\nthe performance of traditional solutions relying on the appearance of tracked\nobjects. Our method focuses on individual player dynamics and interactions\nbetween neighborhood players to improve tracking performance. To overcome the\ndifficulty of reliably merging detections from multiple cameras in the presence\nof calibration errors, we propose the novel tracking approach, where the\ntracker operates directly on raw detection heat maps from multiple cameras. Our\nmodel is trained on a large synthetic dataset generated using Google Research\nFootball Environment and fine-tuned using real-world data to reduce costs\ninvolved with ground truth preparation.",
    "descriptor": "",
    "authors": [
      "Jacek Komorowski",
      "Grzegorz Kurzejamski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02125"
  },
  {
    "id": "arXiv:2211.02126",
    "title": "Validated Byzantine Asynchronous Multidimensional Approximate Agreement",
    "abstract": "Consider an asynchronous system where each node begins with some point in\n$\\mathbb{R}^m$. Given some fixed $\\epsilon > 0$, we wish to have every\nnonfaulty node eventually output a point in $\\mathbb{R}^m$, where all outputs\nare within distance $\\epsilon$ of each other, and are within the convex hull of\nthe original nonfaulty inputs. This problem, when some of the nodes are\nadversarial, is known as the ``Byzantine Asynchronous Multidimensional\nApproximate Agreement'' problem.\nPrevious landmark work by Mendes et al. and Vaidya et al. presented two\nsolutions to the problem. Both of these solutions require exponential\ncomputation by each node in each round. Furthermore, the work provides a lower\nbound showing that it is impossible to solve the task of approximate agreement\nif $n\\leq (m+2)t$, and thus the protocols assume that $n>(m+2)t$.\nWe present a Byzantine Asynchronous Multidimensional Approximate Agreement\nprotocol in the validated setting of Cachin et al. Our protocol terminates\nafter a logarithmic number of rounds, and requires only polynomial computation\nin each round. Furthermore, it is resilient to $t<\\frac{n}{3}$ Byzantine nodes,\nwhich we prove to be optimal in the validated setting. In other words, working\non the task in the validated setting allows us to significantly improve on\nprevious works in several significant metrics. In addition, the techniques\npresented in this paper can easily yield a protocol in the original\nnon-validated setting which requires exponential computation only in the first\nround, and polynomial computation in every subsequent round.",
    "descriptor": "",
    "authors": [
      "Maya Dotan",
      "Gilad Stern",
      "Aviv Zohar"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.02126"
  },
  {
    "id": "arXiv:2211.02127",
    "title": "Scalable Multi-Agent Reinforcement Learning through Intelligent  Information Aggregation",
    "abstract": "We consider the problem of multi-agent navigation and collision avoidance\nwhen observations are limited to the local neighborhood of each agent. We\npropose InforMARL, a novel architecture for multi-agent reinforcement learning\n(MARL) which uses local information intelligently to compute paths for all the\nagents in a decentralized manner. Specifically, InforMARL aggregates\ninformation about the local neighborhood of agents for both the actor and the\ncritic using a graph neural network and can be used in conjunction with any\nstandard MARL algorithm. We show that (1) in training, InforMARL has better\nsample efficiency and performance than baseline approaches, despite using less\ninformation, and (2) in testing, it scales well to environments with arbitrary\nnumbers of agents and obstacles.",
    "descriptor": "\nComments: 11 pages, 5 figures, 2 tables, 3 pages appendix, Code: this https URL\n",
    "authors": [
      "Siddharth Nayak",
      "Kenneth Choi",
      "Wenqi Ding",
      "Sydney Dolan",
      "Karthik Gopalakrishnan",
      "Hamsa Balakrishnan"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.02127"
  },
  {
    "id": "arXiv:2211.02128",
    "title": "Efficient Information Sharing in ICT Supply Chain Social Network via  Table Structure Recognition",
    "abstract": "The global Information and Communications Technology (ICT) supply chain is a\ncomplex network consisting of all types of participants. It is often formulated\nas a Social Network to discuss the supply chain network's relations,\nproperties, and development in supply chain management. Information sharing\nplays a crucial role in improving the efficiency of the supply chain, and\ndatasheets are the most common data format to describe e-component commodities\nin the ICT supply chain because of human readability. However, with the surging\nnumber of electronic documents, it has been far beyond the capacity of human\nreaders, and it is also challenging to process tabular data automatically\nbecause of the complex table structures and heterogeneous layouts. Table\nStructure Recognition (TSR) aims to represent tables with complex structures in\na machine-interpretable format so that the tabular data can be processed\nautomatically. In this paper, we formulate TSR as an object detection problem\nand propose to generate an intuitive representation of a complex table\nstructure to enable structuring of the tabular data related to the commodities.\nTo cope with border-less and small layouts, we propose a cost-sensitive loss\nfunction by considering the detection difficulty of each class. Besides, we\npropose a novel anchor generation method using the character of tables that\ncolumns in a table should share an identical height, and rows in a table should\nshare the same width. We implement our proposed method based on Faster-RCNN and\nachieve 94.79% on mean Average Precision (AP), and consistently improve more\nthan 1.5% AP for different benchmark models.",
    "descriptor": "\nComments: Globecom 2022\n",
    "authors": [
      "Bin Xiao",
      "Yakup Akkaya",
      "Murat Simsek",
      "Burak Kantarci",
      "Ala Abu Alkheir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.02128"
  },
  {
    "id": "arXiv:2211.02130",
    "title": "A 3D-Shape Similarity-based Contrastive Approach to Molecular  Representation Learning",
    "abstract": "Molecular shape and geometry dictate key biophysical recognition processes,\nyet many graph neural networks disregard 3D information for molecular property\nprediction. Here, we propose a new contrastive-learning procedure for graph\nneural networks, Molecular Contrastive Learning from Shape Similarity\n(MolCLaSS), that implicitly learns a three-dimensional representation. Rather\nthan directly encoding or targeting three-dimensional poses, MolCLaSS matches a\nsimilarity objective based on Gaussian overlays to learn a meaningful\nrepresentation of molecular shape. We demonstrate how this framework naturally\ncaptures key aspects of three-dimensionality that two-dimensional\nrepresentations cannot and provides an inductive framework for scaffold\nhopping.",
    "descriptor": "",
    "authors": [
      "Austin Atsango",
      "Nathaniel L. Diamant",
      "Ziqing Lu",
      "Tommaso Biancalani",
      "Gabriele Scalia",
      "Kangway V. Chuang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.02130"
  },
  {
    "id": "arXiv:2211.02131",
    "title": "Safe Real-World Autonomous Driving by Learning to Predict and Plan with  a Mixture of Experts",
    "abstract": "The goal of autonomous vehicles is to navigate public roads safely and\ncomfortably. To enforce safety, traditional planning approaches rely on\nhandcrafted rules to generate trajectories. Machine learning-based systems, on\nthe other hand, scale with data and are able to learn more complex behaviors.\nHowever, they often ignore that agents and self-driving vehicle trajectory\ndistributions can be leveraged to improve safety. In this paper, we propose\nmodeling a distribution over multiple future trajectories for both the\nself-driving vehicle and other road agents, using a unified neural network\narchitecture for prediction and planning. During inference, we select the\nplanning trajectory that minimizes a cost taking into account safety and the\npredicted probabilities. Our approach does not depend on any rule-based\nplanners for trajectory generation or optimization, improves with more training\ndata and is simple to implement. We extensively evaluate our method through a\nrealistic simulator and show that the predicted trajectory distribution\ncorresponds to different driving profiles. We also successfully deploy it on a\nself-driving vehicle on urban public roads, confirming that it drives safely\nwithout compromising comfort. The code for training and testing our model on a\npublic prediction dataset and the video of the road test are available at\nhttps://woven.mobi/safepathnet",
    "descriptor": "",
    "authors": [
      "Stefano Pini",
      "Christian S. Perone",
      "Aayush Ahuja",
      "Ana Sofia Rufino Ferreira",
      "Moritz Niendorf",
      "Sergey Zagoruyko"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02131"
  },
  {
    "id": "arXiv:2211.02136",
    "title": "Logographic Information Aids Learning Better Representations for Natural  Language Inference",
    "abstract": "Statistical language models conventionally implement representation learning\nbased on the contextual distribution of words or other formal units, whereas\nany information related to the logographic features of written text are often\nignored, assuming they should be retrieved relying on the cooccurence\nstatistics. On the other hand, as language models become larger and require\nmore data to learn reliable representations, such assumptions may start to fall\nback, especially under conditions of data sparsity. Many languages, including\nChinese and Vietnamese, use logographic writing systems where surface forms are\nrepresented as a visual organization of smaller graphemic units, which often\ncontain many semantic cues. In this paper, we present a novel study which\nexplores the benefits of providing language models with logographic information\nin learning better semantic representations. We test our hypothesis in the\nnatural language inference (NLI) task by evaluating the benefit of computing\nmulti-modal representations that combine contextual information with glyph\ninformation. Our evaluation results in six languages with different typology\nand writing systems suggest significant benefits of using multi-modal\nembeddings in languages with logograhic systems, especially for words with less\noccurence statistics.",
    "descriptor": "\nComments: accepted by aacl findings\n",
    "authors": [
      "Zijian Jin",
      "Duygu Ataman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.02136"
  },
  {
    "id": "arXiv:2211.02138",
    "title": "Book Cover Synthesis from the Summary",
    "abstract": "The cover is the face of a book and is a point of attraction for the readers.\nDesigning book covers is an essential task in the publishing industry. One of\nthe main challenges in creating a book cover is representing the theme of the\nbook's content in a single image. In this research, we explore ways to produce\na book cover using artificial intelligence based on the fact that there exists\na relationship between the summary of the book and its cover. Our key\nmotivation is the application of text-to-image synthesis methods to generate\nimages from given text or captions. We explore several existing text-to-image\nconversion techniques for this purpose and propose an approach to exploit these\nframeworks for producing book covers from provided summaries. We construct a\ndataset of English books that contains a large number of samples of summaries\nof existing books and their cover images. In this paper, we describe our\napproach to collecting, organizing, and pre-processing the dataset to use it\nfor training models. We apply different text-to-image synthesis techniques to\ngenerate book covers from the summary and exhibit the results in this paper.",
    "descriptor": "\nComments: Accepted as a full paper in AICCSA2022 (19th ACS/IEEE International Conference on Computer Systems and Applications)\n",
    "authors": [
      "Emdadul Haque",
      "Md. Faraz Kabir Khan",
      "Mohammad Imrul Jubair",
      "Jarin Anjum",
      "Abrar Zahir Niloy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02138"
  },
  {
    "id": "arXiv:2211.02139",
    "title": "Can Querying for Bias Leak Protected Attributes? Achieving Privacy With  Smooth Sensitivity",
    "abstract": "Existing regulations prohibit model developers from accessing protected\nattributes (gender, race, etc.), often resulting in fairness assessments on\npopulations without knowing their protected groups. In such scenarios,\ninstitutions often adopt a separation between the model developers (who train\nmodels with no access to the protected attributes) and a compliance team (who\nmay have access to the entire dataset for auditing purpose). However, the model\ndevelopers might be allowed to test their models for bias by querying the\ncompliance team for group fairness metrics. In this paper, we first demonstrate\nthat simply querying for fairness metrics, such as statistical parity and\nequalized odds can leak the protected attributes of individuals to the model\ndevelopers. We demonstrate that there always exist strategies by which the\nmodel developers can identify the protected attribute of a targeted individual\nin the test dataset from just a single query. In particular, we show that one\ncan reconstruct the protected attributes of all the individuals from O(Nk log\nn/Nk) queries when Nk<<n using techniques from compressed sensing (n: size of\nthe test dataset, Nk: size of smallest group). Our results pose an interesting\ndebate in algorithmic fairness: should querying for fairness metrics be viewed\nas a neutral-valued solution to ensure compliance with regulations? Or, does it\nconstitute a violation of regulations and privacy if the number of queries\nanswered is enough for the model developers to identify the protected\nattributes of specific individuals? To address this supposed violation, we also\npropose Attribute-Conceal, a novel technique that achieves differential privacy\nby calibrating noise to the smooth sensitivity of our bias query, outperforming\nnaive techniques such as Laplace mechanism. We also include experimental\nresults on the Adult dataset and synthetic data (broad range of parameters).",
    "descriptor": "\nComments: Accepted at NeurIPS 2022 workshop on Algorithmic Fairness through the Lens of Causality and Privacy\n",
    "authors": [
      "Faisal Hamman",
      "Jiahao Chen",
      "Sanghamitra Dutta"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02139"
  },
  {
    "id": "arXiv:2211.02141",
    "title": "Shapes2Toon: Generating Cartoon Characters from Simple Geometric Shapes",
    "abstract": "Cartoons are an important part of our entertainment culture. Though drawing a\ncartoon is not for everyone, creating it using an arrangement of basic\ngeometric primitives that approximates that character is a fairly frequent\ntechnique in art. The key motivation behind this technique is that human bodies\n- as well as cartoon figures - can be split down into various basic geometric\nprimitives. Numerous tutorials are available that demonstrate how to draw\nfigures using an appropriate arrangement of fundamental shapes, thus assisting\nus in creating cartoon characters. This technique is very beneficial for\nchildren in terms of teaching them how to draw cartoons. In this paper, we\ndevelop a tool - shape2toon - that aims to automate this approach by utilizing\na generative adversarial network which combines geometric primitives (i.e.\ncircles) and generate a cartoon figure (i.e. Mickey Mouse) depending on the\ngiven approximation. For this purpose, we created a dataset of geometrically\nrepresented cartoon characters. We apply an image-to-image translation\ntechnique on our dataset and report the results in this paper. The experimental\nresults show that our system can generate cartoon characters from input layout\nof geometric shapes. In addition, we demonstrate a web-based tool as a\npractical implication of our work.",
    "descriptor": "\nComments: Accepted as a full paper in AICCSA2022 (19th ACS/IEEE International Conference on Computer Systems and Applications)\n",
    "authors": [
      "Simanta Deb Turja",
      "Mohammad Imrul Jubair",
      "Md. Shafiur Rahman",
      "Md. Hasib Al Zadid",
      "Mohtasim Hossain Shovon",
      "Md. Faraz Kabir Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02141"
  },
  {
    "id": "arXiv:2211.02143",
    "title": "Sports Camera Pose Refinement Using an Evolution Strategy",
    "abstract": "This paper presents a robust end-to-end method for sports cameras extrinsic\nparameters optimization using a novel evolution strategy. First, we developed a\nneural network architecture for an edge or area-based segmentation of a sports\nfield. Secondly, we implemented the evolution strategy, which purpose is to\nrefine extrinsic camera parameters given a single, segmented sports field\nimage. Experimental comparison with state-of-the-art camera pose refinement\nmethods on real-world data demonstrates the superiority of the proposed\nalgorithm. We also perform an ablation study and propose a way to generalize\nthe method to additionally refine the intrinsic camera matrix.",
    "descriptor": "\nComments: Conference paper at 2022 IEEE Congress on Evolutionary Computation (CEC)\n",
    "authors": [
      "Grzegorz Rype\u015b\u0107",
      "Grzegorz Kurzejamski",
      "Jacek Komorowski"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.02143"
  },
  {
    "id": "arXiv:2211.02144",
    "title": "No Agreement Without Loss: Learning and Social Choice in Peer Review",
    "abstract": "In peer review systems, reviewers are often asked to evaluate various\nfeatures of submissions, such as technical quality or novelty. A score is given\nto each of the predefined features and based on these the reviewer has to\nprovide an overall quantitative recommendation. However, reviewers differ in\nhow much they value different features. It may be assumed that each reviewer\nhas her own mapping from a set of criteria scores (score vectors) to a\nrecommendation, and that different reviewers have different mappings in mind.\nRecently, Noothigattu, Shah and Procaccia introduced a novel framework for\nobtaining an aggregated mapping by means of Empirical Risk Minimization based\non $L(p,q)$ loss functions, and studied its axiomatic properties in the sense\nof social choice theory. We provide a body of new results about this framework.\nOn the one hand we study a trade-off between strategy-proofness and the ability\nof the method to properly capture agreements of the majority of reviewers. On\nthe other hand, we show that dropping a certain unrealistic assumption makes\nthe previously reported results to be no longer valid. Moreover, in the general\ncase, strategy-proofness fails dramatically in the sense that a reviewer is\nable to make significant changes to the solution in her favor by arbitrarily\nsmall changes to their true beliefs. In particular, no approximate version of\nstrategy-proofness is possible in this general setting since the method is not\neven continuous w.r.t. the data. Finally we propose a modified aggregation\nalgorithm which is continuous and show that it has good axiomatic properties.",
    "descriptor": "\nComments: preprint submitted to a conference\n",
    "authors": [
      "Pablo Barcel\u00f3",
      "Mauricio Duarte",
      "Crist\u00f3bal Rojas",
      "Tomasz Steifer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02144"
  },
  {
    "id": "arXiv:2211.02145",
    "title": "FactorMatte: Redefining Video Matting for Re-Composition Tasks",
    "abstract": "We propose \"factor matting\", an alternative formulation of the video matting\nproblem in terms of counterfactual video synthesis that is better suited for\nre-composition tasks. The goal of factor matting is to separate the contents of\nvideo into independent components, each visualizing a counterfactual version of\nthe scene where contents of other components have been removed. We show that\nfactor matting maps well to a more general Bayesian framing of the matting\nproblem that accounts for complex conditional interactions between layers.\nBased on this observation, we present a method for solving the factor matting\nproblem that produces useful decompositions even for video with complex\ncross-layer interactions like splashes, shadows, and reflections. Our method is\ntrained per-video and requires neither pre-training on external large datasets,\nnor knowledge about the 3D structure of the scene. We conduct extensive\nexperiments, and show that our method not only can disentangle scenes with\ncomplex interactions, but also outperforms top methods on existing tasks such\nas classical video matting and background subtraction. In addition, we\ndemonstrate the benefits of our approach on a range of downstream tasks. Please\nrefer to our project webpage for more details: https://factormatte.github.io",
    "descriptor": "\nComments: Project webpage: this https URL\n",
    "authors": [
      "Zeqi Gu",
      "Wenqi Xian",
      "Noah Snavely",
      "Abe Davis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02145"
  },
  {
    "id": "arXiv:2211.02146",
    "title": "Robust Time Series Chain Discovery with Incremental Nearest Neighbors",
    "abstract": "Time series motif discovery has been a fundamental task to identify\nmeaningful repeated patterns in time series. Recently, time series chains were\nintroduced as an expansion of time series motifs to identify the continuous\nevolving patterns in time series data. Informally, a time series chain (TSC) is\na temporally ordered set of time series subsequences, in which every\nsubsequence is similar to the one that precedes it, but the last and the first\ncan be arbitrarily dissimilar. TSCs are shown to be able to reveal latent\ncontinuous evolving trends in the time series, and identify precursors of\nunusual events in complex systems. Despite its promising interpretability,\nunfortunately, we have observed that existing TSC definitions lack the ability\nto accurately cover the evolving part of a time series: the discovered chains\ncan be easily cut by noise and can include non-evolving patterns, making them\nimpractical in real-world applications. Inspired by a recent work that tracks\nhow the nearest neighbor of a time series subsequence changes over time, we\nintroduce a new TSC definition which is much more robust to noise in the data,\nin the sense that they can better locate the evolving patterns while excluding\nthe non-evolving ones. We further propose two new quality metrics to rank the\ndiscovered chains. With extensive empirical evaluations, we demonstrate that\nthe proposed TSC definition is significantly more robust to noise than the\nstate of the art, and the top ranked chains discovered can reveal meaningful\nregularities in a variety of real world datasets.",
    "descriptor": "\nComments: Accepted to ICDM 2022. This is an extended version of the paper\n",
    "authors": [
      "Li Zhang",
      "Yan Zhu",
      "Yifeng Gao",
      "Jessica Lin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.02146"
  },
  {
    "id": "arXiv:2211.02147",
    "title": "A Survey on Reinforcement Learning in Aviation Applications",
    "abstract": "Compared with model-based control and optimization methods, reinforcement\nlearning (RL) provides a data-driven, learning-based framework to formulate and\nsolve sequential decision-making problems. The RL framework has become\npromising due to largely improved data availability and computing power in the\naviation industry. Many aviation-based applications can be formulated or\ntreated as sequential decision-making problems. Some of them are offline\nplanning problems, while others need to be solved online and are\nsafety-critical. In this survey paper, we first describe standard RL\nformulations and solutions. Then we survey the landscape of existing RL-based\napplications in aviation. Finally, we summarize the paper, identify the\ntechnical gaps, and suggest future directions of RL research in aviation.",
    "descriptor": "",
    "authors": [
      "Pouria Razzaghi",
      "Amin Tabrizian",
      "Wei Guo",
      "Shulu Chen",
      "Abenezer Taye",
      "Ellis Thompson",
      "Alexis Bregeon",
      "Ali Baheri",
      "Peng Wei"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02147"
  },
  {
    "id": "arXiv:2211.02150",
    "title": "3D Reconstruction of Multiple Objects by mmWave Radar on UAV",
    "abstract": "In this paper, we explore the feasibility of utilizing a mmWave radar sensor\ninstalled on a UAV to reconstruct the 3D shapes of multiple objects in a space.\nThe UAV hovers at various locations in the space, and its onboard radar senor\ncollects raw radar data via scanning the space with Synthetic Aperture Radar\n(SAR) operation. The radar data is sent to a deep neural network model, which\noutputs the point cloud reconstruction of the multiple objects in the space. We\nevaluate two different models. Model 1 is our recently proposed 3DRIMR/R2P\nmodel, and Model 2 is formed by adding a segmentation stage in the processing\npipeline of Model 1. Our experiments have demonstrated that both models are\npromising in solving the multiple object reconstruction problem. We also show\nthat Model 2, despite producing denser and smoother point clouds, can lead to\nhigher reconstruction loss or even loss of objects. In addition, we find that\nboth models are robust to the highly noisy radar data obtained by unstable SAR\noperation due to the instability or vibration of a small UAV hovering at its\nintended scanning point. Our exploratory study has shown a promising direction\nof applying mmWave radar sensing in 3D object reconstruction.",
    "descriptor": "",
    "authors": [
      "Yue Sun",
      "Zhuoming Huang",
      "Honggang Zhang",
      "Xiaohui Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.02150"
  },
  {
    "id": "arXiv:2211.02151",
    "title": "Decomposing Counterfactual Explanations for Consequential Decision  Making",
    "abstract": "The goal of algorithmic recourse is to reverse unfavorable decisions (e.g.,\nfrom loan denial to approval) under automated decision making by suggesting\nactionable feature changes (e.g., reduce the number of credit cards). To\ngenerate low-cost recourse the majority of methods work under the assumption\nthat the features are independently manipulable (IMF). To address the feature\ndependency issue the recourse problem is usually studied through the causal\nrecourse paradigm. However, it is well known that strong assumptions, as\nencoded in causal models and structural equations, hinder the applicability of\nthese methods in complex domains where causal dependency structures are\nambiguous. In this work, we develop \\texttt{DEAR} (DisEntangling Algorithmic\nRecourse), a novel and practical recourse framework that bridges the gap\nbetween the IMF and the strong causal assumptions. \\texttt{DEAR} generates\nrecourses by disentangling the latent representation of co-varying features\nfrom a subset of promising recourse features to capture the main practical\nrecourse desiderata. Our experiments on real-world data corroborate our\ntheoretically motivated recourse model and highlight our framework's ability to\nprovide reliable, low-cost recourse in the presence of feature dependencies.",
    "descriptor": "",
    "authors": [
      "Martin Pawelczyk",
      "Lea Tiyavorabun",
      "Gjergji Kasneci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.02151"
  },
  {
    "id": "arXiv:2211.02161",
    "title": "Privacy-preserving Deep Learning based Record Linkage",
    "abstract": "Deep learning-based linkage of records across different databases is becoming\nincreasingly useful in data integration and mining applications to discover new\ninsights from multiple sources of data. However, due to privacy and\nconfidentiality concerns, organisations often are not willing or allowed to\nshare their sensitive data with any external parties, thus making it\nchallenging to build/train deep learning models for record linkage across\ndifferent organizations' databases. To overcome this limitation, we propose the\nfirst deep learning-based multi-party privacy-preserving record linkage (PPRL)\nprotocol that can be used to link sensitive databases held by multiple\ndifferent organisations. In our approach, each database owner first trains a\nlocal deep learning model, which is then uploaded to a secure environment and\nsecurely aggregated to create a global model. The global model is then used by\na linkage unit to distinguish unlabelled record pairs as matches and\nnon-matches. We utilise differential privacy to achieve provable privacy\nprotection against re-identification attacks. We evaluate the linkage quality\nand scalability of our approach using several large real-world databases,\nshowing that it can achieve high linkage quality while providing sufficient\nprivacy protection against existing attacks.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Thilina Ranbaduge",
      "Dinusha Vatsalan",
      "Ming Ding"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02161"
  },
  {
    "id": "arXiv:2211.02162",
    "title": "Time-aware Prompting for Text Generation",
    "abstract": "In this paper, we study the effects of incorporating timestamps, such as\ndocument creation dates, into generation systems. Two types of time-aware\nprompts are investigated: (1) textual prompts that encode document timestamps\nin natural language sentences; and (2) linear prompts that convert timestamps\ninto continuous vectors. To explore extrapolation to future data points, we\nfurther introduce a new data-to-text generation dataset, TempWikiBio,\ncontaining more than 4 millions of chronologically ordered revisions of\nbiographical articles from English Wikipedia, each paired with structured\npersonal profiles. Through data-to-text generation on TempWikiBio, text-to-text\ngeneration on the content transfer dataset, and summarization on XSum, we show\nthat linear prompts on encoder and textual prompts improve the generation\nquality on all datasets. Despite having less performance drop when testing on\ndata drawn from a later time, linear prompts focus more on non-temporal\ninformation and are less sensitive to the given timestamps, according to human\nevaluations and sensitivity analyses. Meanwhile, textual prompts establish the\nassociation between the given timestamps and the output dates, yielding more\nfactual temporal information in the output.",
    "descriptor": "\nComments: EMNLP 2022 Findings (short paper)\n",
    "authors": [
      "Shuyang Cao",
      "Lu Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.02162"
  },
  {
    "id": "arXiv:2211.02166",
    "title": "A $k$-additive Choquet integral-based approach to approximate the SHAP  values for local interpretability in machine learning",
    "abstract": "Besides accuracy, recent studies on machine learning models have been\naddressing the question on how the obtained results can be interpreted. Indeed,\nwhile complex machine learning models are able to provide very good results in\nterms of accuracy even in challenging applications, it is difficult to\ninterpret them. Aiming at providing some interpretability for such models, one\nof the most famous methods, called SHAP, borrows the Shapley value concept from\ngame theory in order to locally explain the predicted outcome of an instance of\ninterest. As the SHAP values calculation needs previous computations on all\npossible coalitions of attributes, its computational cost can be very high.\nTherefore, a SHAP-based method called Kernel SHAP adopts an efficient strategy\nthat approximate such values with less computational effort. In this paper, we\nalso address local interpretability in machine learning based on Shapley\nvalues. Firstly, we provide a straightforward formulation of a SHAP-based\nmethod for local interpretability by using the Choquet integral, which leads to\nboth Shapley values and Shapley interaction indices. Moreover, we also adopt\nthe concept of $k$-additive games from game theory, which contributes to reduce\nthe computational effort when estimating the SHAP values. The obtained results\nattest that our proposal needs less computations on coalitions of attributes to\napproximate the SHAP values.",
    "descriptor": "",
    "authors": [
      "Guilherme Dean Pelegrina",
      "Leonardo Tomazeli Duarte",
      "Michel Grabisch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02166"
  },
  {
    "id": "arXiv:2211.02167",
    "title": "Hardware/Software co-design with ADC-Less In-memory Computing Hardware  for Spiking Neural Networks",
    "abstract": "Spiking Neural Networks (SNNs) are bio-plausible models that hold great\npotential for realizing energy-efficient implementations of sequential tasks on\nresource-constrained edge devices. However, commercial edge platforms based on\nstandard GPUs are not optimized to deploy SNNs, resulting in high energy and\nlatency. While analog In-Memory Computing (IMC) platforms can serve as\nenergy-efficient inference engines, they are accursed by the immense energy,\nlatency, and area requirements of high-precision ADCs (HP-ADC), overshadowing\nthe benefits of in-memory computations. We propose a hardware/software\nco-design methodology to deploy SNNs into an ADC-Less IMC architecture using\nsense-amplifiers as 1-bit ADCs replacing conventional HP-ADCs and alleviating\nthe above issues. Our proposed framework incurs minimal accuracy degradation by\nperforming hardware-aware training and is able to scale beyond simple image\nclassification tasks to more complex sequential regression tasks. Experiments\non complex tasks of optical flow estimation and gesture recognition show that\nprogressively increasing the hardware awareness during SNN training allows the\nmodel to adapt and learn the errors due to the non-idealities associated with\nADC-Less IMC. Also, the proposed ADC-Less IMC offers significant energy and\nlatency improvements, $2-7\\times$ and $8.9-24.6\\times$, respectively, depending\non the SNN model and the workload, compared to HP-ADC IMC.",
    "descriptor": "\nComments: 12 pages, 13 figures\n",
    "authors": [
      "Marco Paul E. Apolinario",
      "Adarsh Kumar Kosta",
      "Utkarsh Saxena",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Hardware Architecture (cs.AR)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2211.02167"
  },
  {
    "id": "arXiv:2211.02174",
    "title": "Can RBMs be trained with zero step contrastive divergence?",
    "abstract": "Restricted Boltzmann Machines (RBMs) are probabilistic generative models that\ncan be trained by maximum likelihood in principle, but are usually trained by\nan approximate algorithm called Contrastive Divergence (CD) in practice. In\ngeneral, a CD-k algorithm estimates an average with respect to the model\ndistribution using a sample obtained from a k-step Markov Chain Monte Carlo\nAlgorithm (e.g., block Gibbs sampling) starting from some initial\nconfiguration. Choices of k typically vary from 1 to 100. This technical report\nexplores if it's possible to leverage a simple approximate sampling algorithm\nwith a modified version of CD in order to train an RBM with k=0. As usual, the\nmethod is illustrated on MNIST.",
    "descriptor": "",
    "authors": [
      "Charles K. Fisher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02174"
  },
  {
    "id": "arXiv:2211.02175",
    "title": "Large Scale Real-World Multi-Person Tracking",
    "abstract": "This paper presents a new large scale multi-person tracking dataset --\n\\texttt{PersonPath22}, which is over an order of magnitude larger than\ncurrently available high quality multi-object tracking datasets such as MOT17,\nHiEve, and MOT20 datasets. The lack of large scale training and test data for\nthis task has limited the community's ability to understand the performance of\ntheir tracking systems on a wide range of scenarios and conditions such as\nvariations in person density, actions being performed, weather, and time of\nday. \\texttt{PersonPath22} dataset was specifically sourced to provide a wide\nvariety of these conditions and our annotations include rich meta-data such\nthat the performance of a tracker can be evaluated along these different\ndimensions. The lack of training data has also limited the ability to perform\nend-to-end training of tracking systems. As such, the highest performing\ntracking systems all rely on strong detectors trained on external image\ndatasets. We hope that the release of this dataset will enable new lines of\nresearch that take advantage of large scale video based training data.",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Bing Shuai",
      "Alessandro Bergamo",
      "Uta Buechler",
      "Andrew Berneshawi",
      "Alyssa Boden",
      "Joseph Tighe"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02175"
  },
  {
    "id": "arXiv:2211.02176",
    "title": "Connected k-Center and k-Diameter Clustering",
    "abstract": "Motivated by an application from geodesy, we introduce a novel clustering\nproblem which is a $k$-center (or k-diameter) problem with a side constraint.\nFor the side constraint, we are given an undirected connectivity graph $G$ on\nthe input points, and a clustering is now only feasible if every cluster\ninduces a connected subgraph in $G$. We call the resulting problems the\nconnected $k$-center problem and the connected $k$-diameter problem.\nWe prove several results on the complexity and approximability of these\nproblems. Our main result is an $O(\\log^2{k})$-approximation algorithm for the\nconnected $k$-center and the connected $k$-diameter problem. For Euclidean\nmetrics and metrics with constant doubling dimension, the approximation factor\nof this algorithm improves to $O(1)$. We also consider the special cases that\nthe connectivity graph is a line or a tree. For the line we give optimal\npolynomial-time algorithms and for the case that the connectivity graph is a\ntree, we either give an optimal polynomial-time algorithm or a\n$2$-approximation algorithm for all variants of our model. We complement our\nupper bounds by several lower bounds.",
    "descriptor": "",
    "authors": [
      "Lukas Drexler",
      "Jan Eube",
      "Kelin Luo",
      "Heiko R\u00f6glin",
      "Melanie Schmidt",
      "Julian Wargalla"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.02176"
  },
  {
    "id": "arXiv:2211.02177",
    "title": "MUSTACHE: Multi-Step-Ahead Predictions for Cache Eviction",
    "abstract": "In this work, we propose MUSTACHE, a new page cache replacement algorithm\nwhose logic is learned from observed memory access requests rather than fixed\nlike existing policies. We formulate the page request prediction problem as a\ncategorical time series forecasting task. Then, our method queries the learned\npage request forecaster to obtain the next $k$ predicted page memory references\nto better approximate the optimal B\\'el\\'ady's replacement algorithm. We\nimplement several forecasting techniques using advanced deep learning\narchitectures and integrate the best-performing one into an existing\nopen-source cache simulator. Experiments run on benchmark datasets show that\nMUSTACHE outperforms the best page replacement heuristic (i.e., exact LRU),\nimproving the cache hit ratio by 1.9% and reducing the number of reads/writes\nrequired to handle cache misses by 18.4% and 10.3%.",
    "descriptor": "",
    "authors": [
      "Gabriele Tolomei",
      "Lorenzo Takanen",
      "Fabio Pinelli"
    ],
    "subjectives": [
      "Operating Systems (cs.OS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02177"
  },
  {
    "id": "arXiv:2211.02178",
    "title": "Zero-shot Video Moment Retrieval With Off-the-Shelf Models",
    "abstract": "For the majority of the machine learning community, the expensive nature of\ncollecting high-quality human-annotated data and the inability to efficiently\nfinetune very large state-of-the-art pretrained models on limited compute are\nmajor bottlenecks for building models for new tasks. We propose a zero-shot\nsimple approach for one such task, Video Moment Retrieval (VMR), that does not\nperform any additional finetuning and simply repurposes off-the-shelf models\ntrained on other tasks. Our three-step approach consists of moment proposal,\nmoment-query matching and postprocessing, all using only off-the-shelf models.\nOn the QVHighlights benchmark for VMR, we vastly improve performance of\nprevious zero-shot approaches by at least 2.5x on all metrics and reduce the\ngap between zero-shot and state-of-the-art supervised by over 74%. Further, we\nalso show that our zero-shot approach beats non-pretrained supervised models on\nthe Recall metrics and comes very close on mAP metrics; and that it also\nperforms better than the best pretrained supervised model on shorter moments.\nFinally, we ablate and analyze our results and propose interesting future\ndirections.",
    "descriptor": "\nComments: Accepted to the NeurIPS 2022 Workshop on Transfer Learning for NLP (TL4NLP). 12 pages, 5 figures\n",
    "authors": [
      "Anuj Diwan",
      "Puyuan Peng",
      "Raymond J. Mooney"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.02178"
  },
  {
    "id": "arXiv:2211.02179",
    "title": "Verifying RISC-V Physical Memory Protection",
    "abstract": "We formally verify an open-source hardware implementation of physical memory\nprotection (PMP) in RISC-V, which is a standard feature used for memory\nisolation in security critical systems such as the Keystone trusted execution\nenvironment. PMP provides per-hardware-thread machine-mode control registers\nthat specify the access privileges for physical memory regions. We first\nformalize the functional property of the PMP rules based on the RISC-V ISA\nmanual. Then, we use the LIME tool to translate an open-source implementation\nof the PMP hardware module written in Chisel to the UCLID5 formal verification\nlanguage. We encode the formal specification in UCLID5 and verify the\nfunctional correctness of the hardware. This is an initial effort towards\nverifying the Keystone framework, where the trusted computing base (TCB) relies\non PMP to provide security guarantees such as integrity and confidentiality.",
    "descriptor": "\nComments: SECRISC-V 2019 Workshop\n",
    "authors": [
      "Kevin Cheang",
      "Cameron Rasmussen",
      "Dayeol Lee",
      "David W. Kohlbrenner",
      "Krste Asanovi\u0107",
      "Sanjit A. Seshia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.02179"
  },
  {
    "id": "arXiv:2211.02185",
    "title": "Deep Learning based Defect classification and detection in SEM images: A  Mask R-CNN approach",
    "abstract": "In this research work, we have demonstrated the application of Mask-RCNN\n(Regional Convolutional Neural Network), a deep-learning algorithm for computer\nvision and specifically object detection, to semiconductor defect inspection\ndomain. Stochastic defect detection and classification during semiconductor\nmanufacturing has grown to be a challenging task as we continuously shrink\ncircuit pattern dimensions (e.g., for pitches less than 32 nm). Defect\ninspection and analysis by state-of-the-art optical and e-beam inspection tools\nis generally driven by some rule-based techniques, which in turn often causes\nto misclassification and thereby necessitating human expert intervention. In\nthis work, we have revisited and extended our previous deep learning-based\ndefect classification and detection method towards improved defect instance\nsegmentation in SEM images with precise extent of defect as well as generating\na mask for each defect category/instance. This also enables to extract and\ncalibrate each segmented mask and quantify the pixels that make up each mask,\nwhich in turn enables us to count each categorical defect instances as well as\nto calculate the surface area in terms of pixels. We are aiming at detecting\nand segmenting different types of inter-class stochastic defect patterns such\nas bridge, break, and line collapse as well as to differentiate accurately\nbetween intra-class multi-categorical defect bridge scenarios (as\nthin/single/multi-line/horizontal/non-horizontal) for aggressive pitches as\nwell as thin resists (High NA applications). Our proposed approach demonstrates\nits effectiveness both quantitatively and qualitatively.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2206.13505\n",
    "authors": [
      "Bappaditya Dey",
      "Enrique Dehaerne",
      "Kasem Khalil",
      "Sandip Halder",
      "Philippe Leray",
      "Magdy A. Bayoumi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.02185"
  },
  {
    "id": "arXiv:2211.02188",
    "title": "Web Archiving as Entertainment",
    "abstract": "We want to make web archiving entertaining so that it can be enjoyed like a\nspectator sport. To this end, we have been working on a proof of concept that\ninvolves gamification of the web archiving process and integrating video games\nand web archiving. Our vision for this proof of concept involves a web\narchiving live stream and a gaming live stream. We are creating web archiving\nlive streams that make the web archiving process more transparent to viewers by\nlive streaming the web archiving and replay sessions to video game live\nstreaming platforms like Twitch, Facebook Gaming, and YouTube. We also want to\nlive stream gameplay from games where the gameplay is influenced by web\narchiving and replay performance. So far we have created web archiving live\nstreams that show the web archiving and replay sessions for two web archive\ncrawlers and gaming live streams that show gameplay influenced by the web\narchiving performance from the web archiving live stream. We have also applied\nthe gaming concept of speedruns, where a player attempts to complete a game as\nquickly as possible. This could make a web archiving live stream more\nentertaining, because we can have a competition between two crawlers to see\nwhich crawler is faster at archiving a set of URIs.",
    "descriptor": "\nComments: This is an extended version of a paper from ICADL 2022. 20 pages and 10 figures\n",
    "authors": [
      "Travis Reid",
      "Michael L. Nelson",
      "Michele C. Weigle"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2211.02188"
  },
  {
    "id": "arXiv:2211.02193",
    "title": "Benchmarking Quality-Diversity Algorithms on Neuroevolution for  Reinforcement Learning",
    "abstract": "We present a Quality-Diversity benchmark suite for Deep Neuroevolution in\nReinforcement Learning domains for robot control. The suite includes the\ndefinition of tasks, environments, behavioral descriptors, and fitness. We\nspecify different benchmarks based on the complexity of both the task and the\nagent controlled by a deep neural network. The benchmark uses standard\nQuality-Diversity metrics, including coverage, QD-score, maximum fitness, and\nan archive profile metric to quantify the relation between coverage and\nfitness. We also present how to quantify the robustness of the solutions with\nrespect to environmental stochasticity by introducing corrected versions of the\nsame metrics. We believe that our benchmark is a valuable tool for the\ncommunity to compare and improve their findings. The source code is available\nonline: https://github.com/adaptive-intelligent-robotics/QDax",
    "descriptor": "\nComments: Accepted at GECCO Workshop on Quality Diversity Algorithm Benchmarks\n",
    "authors": [
      "Manon Flageat",
      "Bryan Lim",
      "Luca Grillotti",
      "Maxime Allard",
      "Sim\u00f3n C. Smith",
      "Antoine Cully"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.02193"
  },
  {
    "id": "arXiv:2211.02195",
    "title": "Learning to Rank Graph-based Application Objects on Heterogeneous  Memories",
    "abstract": "Persistent Memory (PMEM), also known as Non-Volatile Memory (NVM), can\ndeliver higher density and lower cost per bit when compared with DRAM. Its main\ndrawback is that it is typically slower than DRAM. On the other hand, DRAM has\nscalability problems due to its cost and energy consumption. Soon, PMEM will\nlikely coexist with DRAM in computer systems but the biggest challenge is to\nknow which data to allocate on each type of memory. This paper describes a\nmethodology for identifying and characterizing application objects that have\nthe most influence on the application's performance using Intel Optane DC\nPersistent Memory. In the first part of our work, we built a tool that\nautomates the profiling and analysis of application objects. In the second\npart, we build a machine learning model to predict the most critical object\nwithin large-scale graph-based applications. Our results show that using\nisolated features does not bring the same benefit compared to using a carefully\nchosen set of features. By performing data placement using our predictive\nmodel, we can reduce the execution time degradation by 12\\% (average) and 30\\%\n(max) when compared to the baseline's approach based on LLC misses indicator.",
    "descriptor": "",
    "authors": [
      "Diego Moura",
      "Vinicius Petrucci",
      "Daniel Mosse"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02195"
  },
  {
    "id": "arXiv:2211.02200",
    "title": "Miko Team: Deep Learning Approach for Legal Question Answering in ALQAC  2022",
    "abstract": "We introduce efficient deep learning-based methods for legal document\nprocessing including Legal Document Retrieval and Legal Question Answering\ntasks in the Automated Legal Question Answering Competition (ALQAC 2022). In\nthis competition, we achieve 1\\textsuperscript{st} place in the first task and\n3\\textsuperscript{rd} place in the second task. Our method is based on the\nXLM-RoBERTa model that is pre-trained from a large amount of unlabeled corpus\nbefore fine-tuning to the specific tasks. The experimental results showed that\nour method works well in legal retrieval information tasks with limited labeled\ndata. Besides, this method can be applied to other information retrieval tasks\nin low-resource languages.",
    "descriptor": "",
    "authors": [
      "Hieu Nguyen Van",
      "Dat Nguyen",
      "Phuong Minh Nguyen",
      "Minh Le Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.02200"
  },
  {
    "id": "arXiv:2211.02201",
    "title": "Learning Tool Morphology for Contact-Rich Manipulation Tasks with  Differentiable Simulation",
    "abstract": "When humans perform contact-rich manipulation tasks, customized tools are\noften necessary and play an important role in simplifying the task. For\ninstance, in our daily life, we use various utensils for handling food, such as\nknives, forks and spoons. Similarly, customized tools for robots may enable\nthem to more easily perform a variety of tasks. Here, we present an end-to-end\nframework to automatically learn tool morphology for contact-rich manipulation\ntasks by leveraging differentiable physics simulators. Previous work approached\nthis problem by introducing manually constructed priors that required detailed\nspecification of object 3D model, grasp pose and task description to facilitate\nthe search or optimization. In our approach, we instead only need to define the\nobjective with respect to the task performance and enable learning a robust\nmorphology by randomizing the task variations. The optimization is made\ntractable by casting this as a continual learning problem. We demonstrate the\neffectiveness of our method for designing new tools in several scenarios such\nas winding ropes, flipping a box and pushing peas onto a scoop in simulation.\nWe also validate that the shapes discovered by our method help real robots\nsucceed in these scenarios.",
    "descriptor": "",
    "authors": [
      "Mengxi Li",
      "Rika Antonova",
      "Dorsa Sadigh",
      "Jeannette Bohg"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02201"
  },
  {
    "id": "arXiv:2211.02206",
    "title": "Soft Masking for Cost-Constrained Channel Pruning",
    "abstract": "Structured channel pruning has been shown to significantly accelerate\ninference time for convolution neural networks (CNNs) on modern hardware, with\na relatively minor loss of network accuracy. Recent works permanently zero\nthese channels during training, which we observe to significantly hamper final\naccuracy, particularly as the fraction of the network being pruned increases.\nWe propose Soft Masking for cost-constrained Channel Pruning (SMCP) to allow\npruned channels to adaptively return to the network while simultaneously\npruning towards a target cost constraint. By adding a soft mask\nre-parameterization of the weights and channel pruning from the perspective of\nremoving input channels, we allow gradient updates to previously pruned\nchannels and the opportunity for the channels to later return to the network.\nWe then formulate input channel pruning as a global resource allocation\nproblem. Our method outperforms prior works on both the ImageNet classification\nand PASCAL VOC detection datasets.",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Ryan Humble",
      "Maying Shen",
      "Jorge Albericio Latorre",
      "Eric Darve1",
      "Jose M. Alvarez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02206"
  },
  {
    "id": "arXiv:2211.02208",
    "title": "Automated Logging Drone: A Computer Vision Drone Implementation",
    "abstract": "In recent years, Artificial Intelligence (AI) and Computer Vision (CV) have\nbecome the pinnacle of technology with new developments seemingly every day.\nThis technology along with more powerful drone technology have made autonomous\nsurveillance more sought after. Here an overview of the Automated Logging Drone\n(ALD) project is presented along with examples of how this project can be used\nwith more refining and added features.",
    "descriptor": "",
    "authors": [
      "Aaron Yagnik",
      "Adrian S.-W. Tam"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.02208"
  },
  {
    "id": "arXiv:2211.02212",
    "title": "Distributed Linear Bandits under Communication Constraints",
    "abstract": "We consider distributed linear bandits where $M$ agents learn collaboratively\nto minimize the overall cumulative regret incurred by all agents. Information\nexchange is facilitated by a central server, and both the uplink and downlink\ncommunications are carried over channels with fixed capacity, which limits the\namount of information that can be transmitted in each use of the channels. We\ninvestigate the regret-communication trade-off by (i) establishing\ninformation-theoretic lower bounds on the required communications (in terms of\nbits) for achieving a sublinear regret order; (ii) developing an efficient\nalgorithm that achieves the minimum sublinear regret order offered by\ncentralized learning using the minimum order of communications dictated by the\ninformation-theoretic lower bounds. For sparse linear bandits, we show a\nvariant of the proposed algorithm offers better regret-communication trade-off\nby leveraging the sparsity of the problem.",
    "descriptor": "",
    "authors": [
      "Sudeep Salgia",
      "Qing Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02212"
  },
  {
    "id": "arXiv:2211.02213",
    "title": "SSDA-YOLO: Semi-supervised Domain Adaptive YOLO for Cross-Domain Object  Detection",
    "abstract": "Domain adaptive object detection (DAOD) aims to alleviate transfer\nperformance degradation caused by the cross-domain discrepancy. However, most\nexisting DAOD methods are dominated by computationally intensive two-stage\ndetectors, which are not the first choice for industrial applications. In this\npaper, we propose a novel semi-supervised domain adaptive YOLO (SSDA-YOLO)\nbased method to improve cross-domain detection performance by integrating the\ncompact one-stage detector YOLOv5 with domain adaptation. Specifically, we\nadapt the knowledge distillation framework with the Mean Teacher model to\nassist the student model in obtaining instance-level features of the unlabeled\ntarget domain. We also utilize the scene style transfer to cross-generate\npseudo images in different domains for remedying image-level differences. In\naddition, an intuitive consistency loss is proposed to further align\ncross-domain predictions. We evaluate our proposed SSDA-YOLO on public\nbenchmarks including PascalVOC, Clipart1k, Cityscapes, and Foggy Cityscapes.\nMoreover, to verify its generalization, we conduct experiments on yawning\ndetection datasets collected from various classrooms. The results show\nconsiderable improvements of our method in these DAOD tasks. Our code is\navailable on \\url{https://github.com/hnuzhy/SSDA-YOLO}.",
    "descriptor": "\nComments: submitted to CVIU\n",
    "authors": [
      "Huayi Zhou",
      "Fei Jiang",
      "Hongtao Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02213"
  },
  {
    "id": "arXiv:2211.02219",
    "title": "Understanding and Mitigating Overfitting in Prompt Tuning for  Vision-Language Models",
    "abstract": "Pre-trained Vision-Language Models (VLMs) such as CLIP have shown impressive\ngeneralization capability in downstream vision tasks with appropriate text\nprompts. Instead of designing prompts manually, Context Optimization (CoOp) has\nbeen recently proposed to learn continuous prompts using task-specific training\ndata. Despite the performance improvements on downstream tasks, several studies\nhave reported that CoOp suffers from the overfitting issue in two aspects: (i)\nthe test accuracy on base classes first gets better and then gets worse during\ntraining; (ii) the test accuracy on novel classes keeps decreasing. However,\nnone of the existing studies can understand and mitigate such overfitting\nproblem effectively. In this paper, we first explore the cause of overfitting\nby analyzing the gradient flow. Comparative experiments reveal that CoOp favors\ngeneralizable and spurious features in the early and later training stages\nrespectively, leading to the non-overfitting and overfitting phenomenon. Given\nthose observations, we propose Subspace Prompt Tuning (SubPT) to project the\ngradients in back-propagation onto the low-rank subspace spanned by the\nearly-stage gradient flow eigenvectors during the entire training process, and\nsuccessfully eliminate the overfitting problem. Besides, we equip CoOp with\nNovel Feature Learner (NFL) to enhance the generalization ability of the\nlearned prompts onto novel categories beyond the training set, needless of\nimage training data. Extensive experiments on 11 classification datasets\ndemonstrate that SubPT+NFL consistently boost the performance of CoOp and\noutperform the state-of-the-art approach CoCoOp. Experiments on more\nchallenging vision downstream tasks including open-vocabulary object detection\nand zero-shot semantic segmentation also verify the effectiveness of the\nproposed method. Codes can be found at https://tinyurl.com/mpe64f89.",
    "descriptor": "",
    "authors": [
      "Chengcheng Ma",
      "Yang Liu",
      "Jiankang Deng",
      "LingXi Xie",
      "Weiming Dong",
      "Changsheng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02219"
  },
  {
    "id": "arXiv:2211.02222",
    "title": "The Benefits of Model-Based Generalization in Reinforcement Learning",
    "abstract": "Model-Based Reinforcement Learning (RL) is widely believed to have the\npotential to improve sample efficiency by allowing an agent to synthesize large\namounts of imagined experience. Experience Replay (ER) can be considered a\nsimple kind of model, which has proved extremely effective at improving the\nstability and efficiency of deep RL. In principle, a learned parametric model\ncould improve on ER by generalizing from real experience to augment the dataset\nwith additional plausible experience. However, owing to the many design choices\ninvolved in empirically successful algorithms, it can be very hard to establish\nwhere the benefits are actually coming from. Here, we provide theoretical and\nempirical insight into when, and how, we can expect data generated by a learned\nmodel to be useful. First, we provide a general theorem motivating how learning\na model as an intermediate step can narrow down the set of possible value\nfunctions more than learning a value function directly from data using the\nBellman equation. Second, we provide an illustrative example showing\nempirically how a similar effect occurs in a more concrete setting with neural\nnetwork function approximation. Finally, we provide extensive experiments\nshowing the benefit of model-based learning for online RL in environments with\ncombinatorial complexity, but factored structure that allows a learned model to\ngeneralize. In these experiments, we take care to control for other factors in\norder to isolate, insofar as possible, the benefit of using experience\ngenerated by a learned model relative to ER alone.",
    "descriptor": "",
    "authors": [
      "Kenny Young",
      "Aditya Ramesh",
      "Louis Kirsch",
      "J\u00fcrgen Schmidhuber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02222"
  },
  {
    "id": "arXiv:2211.02223",
    "title": "Adversarial Defense via Neural Oscillation inspired Gradient Masking",
    "abstract": "Spiking neural networks (SNNs) attract great attention due to their low power\nconsumption, low latency, and biological plausibility. As they are widely\ndeployed in neuromorphic devices for low-power brain-inspired computing,\nsecurity issues become increasingly important. However, compared to deep neural\nnetworks (DNNs), SNNs currently lack specifically designed defense methods\nagainst adversarial attacks. Inspired by neural membrane potential oscillation,\nwe propose a novel neural model that incorporates the bio-inspired oscillation\nmechanism to enhance the security of SNNs. Our experiments show that SNNs with\nneural oscillation neurons have better resistance to adversarial attacks than\nordinary SNNs with LIF neurons on kinds of architectures and datasets.\nFurthermore, we propose a defense method that changes model's gradients by\nreplacing the form of oscillation, which hides the original training gradients\nand confuses the attacker into using gradients of 'fake' neurons to generate\ninvalid adversarial samples. Our experiments suggest that the proposed defense\nmethod can effectively resist both single-step and iterative attacks with\ncomparable defense effectiveness and much less computational costs than\nadversarial training methods on DNNs. To the best of our knowledge, this is the\nfirst work that establishes adversarial defense through masking surrogate\ngradients on SNNs.",
    "descriptor": "",
    "authors": [
      "Chunming Jiang",
      "Yilei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.02223"
  },
  {
    "id": "arXiv:2211.02225",
    "title": "Automated Vehicle Highway Merging: Motion Planning via Adaptive  Interactive Mixed-Integer MPC",
    "abstract": "A new motion planning framework for automated highway merging is presented in\nthis paper. To plan the merge and predict the motion of the neighboring\nvehicle, the ego automated vehicle solves a joint optimization of both vehicle\ncosts over a receding horizon. The non-convex nature of feasible regions and\nlane discipline is handled by introducing integer decision variables resulting\nin a mixed integer quadratic programming (MIQP) formulation of the model\npredictive control (MPC) problem. Furthermore, the ego uses an inverse optimal\ncontrol approach to impute the weights of neighboring vehicle cost by observing\nthe neighbor's recent motion and adapts its solution accordingly. We call this\nadaptive interactive mixed integer MPC (aiMPC). Simulation results show the\neffectiveness of the proposed framework.",
    "descriptor": "\nComments: Submitted to American Control Conference\n",
    "authors": [
      "Viranjan Bhattacharyya",
      "Ardalan Vahidi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.02225"
  },
  {
    "id": "arXiv:2211.02231",
    "title": "Residual Skill Policies: Learning an Adaptable Skill-based Action Space  for Reinforcement Learning for Robotics",
    "abstract": "Skill-based reinforcement learning (RL) has emerged as a promising strategy\nto leverage prior knowledge for accelerated robot learning. Skills are\ntypically extracted from expert demonstrations and are embedded into a latent\nspace from which they can be sampled as actions by a high-level RL agent.\nHowever, this skill space is expansive, and not all skills are relevant for a\ngiven robot state, making exploration difficult. Furthermore, the downstream RL\nagent is limited to learning structurally similar tasks to those used to\nconstruct the skill space. We firstly propose accelerating exploration in the\nskill space using state-conditioned generative models to directly bias the\nhigh-level agent towards only sampling skills relevant to a given state based\non prior experience. Next, we propose a low-level residual policy for\nfine-grained skill adaptation enabling downstream RL agents to adapt to unseen\ntask variations. Finally, we validate our approach across four challenging\nmanipulation tasks that differ from those used to build the skill space,\ndemonstrating our ability to learn across task variations while significantly\naccelerating exploration, outperforming prior works. Code and videos are\navailable on our project website: https://krishanrana.github.io/reskill.",
    "descriptor": "\nComments: 6th Conference on Robot Learning (CoRL), 2022\n",
    "authors": [
      "Krishan Rana",
      "Ming Xu",
      "Brendan Tidd",
      "Michael Milford",
      "Niko S\u00fcnderhauf"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02231"
  },
  {
    "id": "arXiv:2211.02232",
    "title": "Collaborative Bi-Aggregation for Directed Graph Embedding",
    "abstract": "Directed graphs model asymmetric relationships between nodes and research on\ndirected graph embedding is of great significance in downstream graph analysis\nand inference. Learning source and target embedding of nodes separately to\npreserve edge asymmetry has become the dominant approach, but also poses\nchallenge for learning representations of low or even zero in/out degree nodes\nthat are ubiquitous in sparse graphs. In this paper, a collaborative\nbi-directional aggregation method (COBA) for directed graphs embedding is\nproposed by introducing spatial-based graph convolution. Firstly, the source\nand target embeddings of the central node are learned by aggregating from the\ncounterparts of the source and target neighbors, respectively; Secondly, the\nsource/target embeddings of the zero in/out degree central nodes are enhanced\nby aggregating the counterparts of opposite-directional neighbors (i.e.\ntarget/source neighbors); Finally, source and target embeddings of the same\nnode are correlated to achieve collaborative aggregation. Extensive experiments\non real-world datasets demonstrate that the COBA comprehensively outperforms\nstate-of-the-art methods on multiple tasks and meanwhile validates the\neffectiveness of proposed aggregation strategies.",
    "descriptor": "",
    "authors": [
      "Linsong Liu",
      "Kejia Chen",
      "Zheng Liu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.02232"
  },
  {
    "id": "arXiv:2211.02233",
    "title": "Improved Adaptive Algorithm for Scalable Active Learning with Weak  Labeler",
    "abstract": "Active learning with strong and weak labelers considers a practical setting\nwhere we have access to both costly but accurate strong labelers and inaccurate\nbut cheap predictions provided by weak labelers. We study this problem in the\nstreaming setting, where decisions must be taken \\textit{online}. We design a\nnovel algorithmic template, Weak Labeler Active Cover (WL-AC), that is able to\nrobustly leverage the lower quality weak labelers to reduce the query\ncomplexity while retaining the desired level of accuracy. Prior active learning\nalgorithms with access to weak labelers learn a difference classifier which\npredicts where the weak labels differ from strong labelers; this requires the\nstrong assumption of realizability of the difference classifier (Zhang and\nChaudhuri,2015). WL-AC bypasses this \\textit{realizability} assumption and thus\nis applicable to many real-world scenarios such as random corrupted weak labels\nand high dimensional family of difference classifiers (\\textit{e.g.,} deep\nneural nets). Moreover, WL-AC cleverly trades off evaluating the quality with\nfull exploitation of weak labelers, which allows to convert any active learning\nstrategy to one that can leverage weak labelers. We provide an instantiation of\nthis template that achieves the optimal query complexity for any given weak\nlabeler, without knowing its accuracy a-priori. Empirically, we propose an\ninstantiation of the WL-AC template that can be efficiently implemented for\nlarge-scale models (\\textit{e.g}., deep neural nets) and show its effectiveness\non the corrupted-MNIST dataset by significantly reducing the number of labels\nwhile keeping the same accuracy as in passive learning.",
    "descriptor": "",
    "authors": [
      "Yifang Chen",
      "Karthik Sankararaman",
      "Alessandro Lazaric",
      "Matteo Pirotta",
      "Dmytro Karamshuk",
      "Qifan Wang",
      "Karishma Mandyam",
      "Sinong Wang",
      "Han Fang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.02233"
  },
  {
    "id": "arXiv:2211.02234",
    "title": "A Latent Space Model for HLA Compatibility Networks in Kidney  Transplantation",
    "abstract": "Kidney transplantation is the preferred treatment for people suffering from\nend-stage renal disease. Successful kidney transplants still fail over time,\nknown as graft failure; however, the time to graft failure, or graft survival\ntime, can vary significantly between different recipients. A significant\nbiological factor affecting graft survival times is the compatibility between\nthe human leukocyte antigens (HLAs) of the donor and recipient. We propose to\nmodel HLA compatibility using a network, where the nodes denote different HLAs\nof the donor and recipient, and edge weights denote compatibilities of the\nHLAs, which can be positive or negative. The network is indirectly observed, as\nthe edge weights are estimated from transplant outcomes rather than directly\nobserved. We propose a latent space model for such indirectly-observed weighted\nand signed networks. We demonstrate that our latent space model can not only\nresult in more accurate estimates of HLA compatibilities, but can also be\nincorporated into survival analysis models to improve accuracy for the\ndownstream task of predicting graft survival times.",
    "descriptor": "\nComments: This work has been accepted to BIBM 2022\n",
    "authors": [
      "Zhipeng Huang",
      "Kevin S. Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.02234"
  },
  {
    "id": "arXiv:2211.02240",
    "title": "DaI: Decrypt and Infer the Quality of Real-Time Video Streaming",
    "abstract": "Inferring the quality of network services is the vital basis of optimization\nfor network operators. However, prevailing real-time video streaming\napplications adopt encryption for security, leaving it a problem to extract\nQuality of Service (QoS) indicators of real-time video. In this paper, we\npropose DaI, a traffic-based real-time video quality estimator. DaI can\npartially decrypt the encrypted real-time video data and applies machine\nlearning methods to estimate key objective Quality of Experience (QoE) metrics\nof real-time video. According to the experimental results, DaI can estimate\nobjective QoE metrics with an average accuracy of 79%.",
    "descriptor": "",
    "authors": [
      "Sheng Cheng"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.02240"
  },
  {
    "id": "arXiv:2211.02242",
    "title": "Asymptotical Cooperative Cruise Fault Tolerant Control for Multiple  High-speed Trains with State Constraints",
    "abstract": "This paper investigates the asymptotical cooperative cruise fault tolerant\ncontrol problem for multiple high-speed trains consisting of multiple carriages\nin the presence of actuator faults. A distributed state-fault observer\nutilizing the structural information of faults is designed to achieve\nasymptotical estimation of states and faults of each carriage. The observer\ndoes not rely on choice of control input, and thus it is separated from\ncontroller design. Based on the estimated values of states and faults, a\ndistributed fault tolerance controller is designed to realize asymptotical\ncooperative cruise control of trains under the dual constraints of ensuring\nboth position difference and velocity difference of adjacent trains in\nspecified ranges throughout the whole process.",
    "descriptor": "\nComments: 12 pages, 9 figures\n",
    "authors": [
      "Zhixin Zhang",
      "Zhiyong Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.02242"
  },
  {
    "id": "arXiv:2211.02243",
    "title": "Mixline: A Hybrid Reinforcement Learning Framework for Long-horizon  Bimanual Coffee Stirring Task",
    "abstract": "Bimanual activities like coffee stirring, which require coordination of dual\narms, are common in daily life and intractable to learn by robots. Adopting\nreinforcement learning to learn these tasks is a promising topic since it\nenables the robot to explore how dual arms coordinate together to accomplish\nthe same task. However, this field has two main challenges: coordination\nmechanism and long-horizon task decomposition. Therefore, we propose the\nMixline method to learn sub-tasks separately via the online algorithm and then\ncompose them together based on the generated data through the offline\nalgorithm. We constructed a learning environment based on the GPU-accelerated\nIsaac Gym. In our work, the bimanual robot successfully learned to grasp, hold\nand lift the spoon and cup, insert them together and stir the coffee. The\nproposed method has the potential to be extended to other long-horizon bimanual\ntasks.",
    "descriptor": "\nComments: 10 pages, conference\n",
    "authors": [
      "Zheng Sun",
      "Zhiqi Wang",
      "Junjia Liu",
      "Miao Li",
      "Fei Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.02243"
  },
  {
    "id": "arXiv:2211.02244",
    "title": "Low-cost Thermal Mapping for Concrete Heat Monitoring",
    "abstract": "Robotics has been widely applied in smart construction for generating the\ndigital twin or for autonomous inspection of construction sites. For example,\nfor thermal inspection during concrete curing, continual monitoring of the\nconcrete temperature is required to ensure concrete strength and to avoid\ncracks. However, buildings are typically too large to be monitored by\ninstalling fixed thermal cameras, and post-processing is required to compute\nthe accumulated heat of each measurement point. Thus, by using an autonomous\nmonitoring system with the capability of long-term thermal mapping at a large\nconstruction site, both cost-effectiveness and a precise safety margin of the\ncuring period estimation can be acquired. Therefore, this study proposes a\nlow-cost thermal mapping system consisting of a 2D range scanner attached to a\nconsumer-level inertial measurement unit and a thermal camera for automated\nheat monitoring in construction using mobile robots.",
    "descriptor": "\nComments: 4 pages, 5 figures, 2022 ICRA Workshop\n",
    "authors": [
      "Alex Junho Lee",
      "Younggun Cho",
      "Hyun Myung"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.02244"
  },
  {
    "id": "arXiv:2211.02245",
    "title": "Unintended Memorization and Timing Attacks in Named Entity Recognition  Models",
    "abstract": "Named entity recognition models (NER), are widely used for identifying named\nentities (e.g., individuals, locations, and other information) in text\ndocuments. Machine learning based NER models are increasingly being applied in\nprivacy-sensitive applications that need automatic and scalable identification\nof sensitive information to redact text for data sharing. In this paper, we\nstudy the setting when NER models are available as a black-box service for\nidentifying sensitive information in user documents and show that these models\nare vulnerable to membership inference on their training datasets. With updated\npre-trained NER models from spaCy, we demonstrate two distinct membership\nattacks on these models. Our first attack capitalizes on unintended\nmemorization in the NER's underlying neural network, a phenomenon NNs are known\nto be vulnerable to. Our second attack leverages a timing side-channel to\ntarget NER models that maintain vocabularies constructed from the training\ndata. We show that different functional paths of words within the training\ndataset in contrast to words not previously seen have measurable differences in\nexecution time. Revealing membership status of training samples has clear\nprivacy implications, e.g., in text redaction, sensitive words or phrases to be\nfound and removed, are at risk of being detected in the training dataset. Our\nexperimental evaluation includes the redaction of both password and health\ndata, presenting both security risks and privacy/regulatory issues. This is\nexacerbated by results that show memorization with only a single phrase. We\nachieved 70% AUC in our first attack on a text redaction use-case. We also show\noverwhelming success in the timing attack with 99.23% AUC. Finally we discuss\npotential mitigation approaches to realize the safe use of NER models in light\nof the privacy and security implications of membership inference attacks.",
    "descriptor": "\nComments: This is the full version of the paper with the same title accepted for publication in the Proceedings of the 23rd Privacy Enhancing Technologies Symposium, PETS 2023\n",
    "authors": [
      "Rana Salal Ali",
      "Benjamin Zi Hao Zhao",
      "Hassan Jameel Asghar",
      "Tham Nguyen",
      "Ian David Wood",
      "Dali Kaafar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02245"
  },
  {
    "id": "arXiv:2211.02246",
    "title": "DatChain -- Blockchain implementation in Data transfer for IoT Devices",
    "abstract": "Currently, the IoT ecosystem is comprised of fully connected smart devices\nthat exchange data to provide more automated, precise, and fast decisions. This\nidealised situation can only be accomplished if a system for data transactions\nis processed efficiently and security is ensured with high scalability and\npracticability. The integrity of data must be maintained during the exchange or\ntransfer of data between entities. We propose to make a application called\nDatChain that responds to the above situation. The application stores data\nsensed by the Iot sensors in the backend after encrypting it and when the data\nis required for any purpose it can be exchanged using a suitable blockchain\nnetwork that can keep up with the transfer rate even at high traffic in a\nsecure environment.",
    "descriptor": "\nComments: Keywords - Blockchain, Internet of Things, IOTA, Tangle, Data transfer, IoT Data Analytics\n",
    "authors": [
      "Om Rajput",
      "Suyash Nigam",
      "Dr. M.J. Chowdhury",
      "Dr. Kayalvizhi Jayavel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.02246"
  },
  {
    "id": "arXiv:2211.02250",
    "title": "Real-Time Target Sound Extraction",
    "abstract": "We present the first neural network model to achieve real-time and streaming\ntarget sound extraction. To accomplish this, we propose Waveformer, an\nencoder-decoder architecture with a stack of dilated causal convolution layers\nas the encoder, and a transformer decoder layer as the decoder. This hybrid\narchitecture uses dilated causal convolutions for processing large receptive\nfields in a computationally efficient manner, while also benefiting from the\nperformance transformer-based architectures provide. Our evaluations show as\nmuch as 2.2-3.3 dB improvement in SI-SNRi compared to the prior models for this\ntask while having a 1.2-4x smaller model size and a 1.5-2x lower runtime.\nOpen-source code and datasets: https://github.com/vb000/Waveformer",
    "descriptor": "",
    "authors": [
      "Bandhav Veluri",
      "Justin Chan",
      "Malek Itani",
      "Tuochao Chen",
      "Takuya Yoshioka",
      "Shyamnath Gollakota"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.02250"
  },
  {
    "id": "arXiv:2211.02254",
    "title": "How Does Adaptive Optimization Impact Local Neural Network Geometry?",
    "abstract": "Adaptive optimization methods are well known to achieve superior convergence\nrelative to vanilla gradient methods. The traditional viewpoint in\noptimization, particularly in convex optimization, explains this improved\nperformance by arguing that, unlike vanilla gradient schemes, adaptive\nalgorithms mimic the behavior of a second-order method by adapting to the\nglobal geometry of the loss function. We argue that in the context of neural\nnetwork optimization, this traditional viewpoint is insufficient. Instead, we\nadvocate for a local trajectory analysis. For iterate trajectories produced by\nrunning a generic optimization algorithm OPT, we introduce\n$R^{\\text{OPT}}_{\\text{med}}$, a statistic that is analogous to the condition\nnumber of the loss Hessian evaluated at the iterates. Through extensive\nexperiments, we show that adaptive methods such as Adam bias the trajectories\ntowards regions where $R^{\\text{Adam}}_{\\text{med}}$ is small, where one might\nexpect faster convergence. By contrast, vanilla gradient methods like SGD bias\nthe trajectories towards regions where $R^{\\text{SGD}}_{\\text{med}}$ is\ncomparatively large. We complement these empirical observations with a\ntheoretical result that provably demonstrates this phenomenon in the simplified\nsetting of a two-layer linear network. We view our findings as evidence for the\nneed of a new explanation of the success of adaptive methods, one that is\ndifferent than the conventional wisdom.",
    "descriptor": "",
    "authors": [
      "Kaiqi Jiang",
      "Dhruv Malik",
      "Yuanzhi Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.02254"
  },
  {
    "id": "arXiv:2211.02255",
    "title": "Spectral Regularization: an Inductive Bias for Sequence Modeling",
    "abstract": "Various forms of regularization in learning tasks strive for different\nnotions of simplicity. This paper presents a spectral regularization technique,\nwhich attaches a unique inductive bias to sequence modeling based on an\nintuitive concept of simplicity defined in the Chomsky hierarchy. From\nfundamental connections between Hankel matrices and regular grammars, we\npropose to use the trace norm of the Hankel matrix, the tightest convex\nrelaxation of its rank, as the spectral regularizer. To cope with the fact that\nthe Hankel matrix is bi-infinite, we propose an unbiased stochastic estimator\nfor its trace norm. Ultimately, we demonstrate experimental results on Tomita\ngrammars, which exhibit the potential benefits of spectral regularization and\nvalidate the proposed stochastic estimator.",
    "descriptor": "\nComments: LearnAut paper in 2022 (this https URL)\n",
    "authors": [
      "Kaiwen Hou",
      "Guillaume Rabusseau"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.02255"
  },
  {
    "id": "arXiv:2211.02257",
    "title": "Certification with an NP Oracle",
    "abstract": "In the certification problem, the algorithm is given a function $f$ with\ncertificate complexity $k$ and an input $x^\\star$, and the goal is to find a\ncertificate of size $\\le \\text{poly}(k)$ for $f$'s value at $x^\\star$. This\nproblem is in $\\mathsf{NP}^{\\mathsf{NP}}$, and assuming $\\mathsf{P} \\ne\n\\mathsf{NP}$, is not in $\\mathsf{P}$. Prior works, dating back to Valiant in\n1984, have therefore sought to design efficient algorithms by imposing\nassumptions on $f$ such as monotonicity.\nOur first result is a $\\mathsf{BPP}^{\\mathsf{NP}}$ algorithm for the general\nproblem. The key ingredient is a new notion of the balanced influence of\nvariables, a natural variant of influence that corrects for the bias of the\nfunction. Balanced influences can be accurately estimated via uniform\ngeneration, and classic $\\mathsf{BPP}^{\\mathsf{NP}}$ algorithms are known for\nthe latter task.\nWe then consider certification with stricter instance-wise guarantees: for\neach $x^\\star$, find a certificate whose size scales with that of the smallest\ncertificate for $x^\\star$. In sharp contrast with our first result, we show\nthat this problem is $\\mathsf{NP}^{\\mathsf{NP}}$-hard even to approximate. We\nobtain an optimal inapproximability ratio, adding to a small handful of\nproblems in the higher levels of the polynomial hierarchy for which optimal\ninapproximability is known. Our proof involves the novel use of bit-fixing\ndispersers for gap amplification.",
    "descriptor": "\nComments: 25 pages, 2 figures, ITCS 2023\n",
    "authors": [
      "Guy Blanc",
      "Caleb Koch",
      "Jane Lange",
      "Carmen Strassle",
      "Li-Yang Tan"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.02257"
  },
  {
    "id": "arXiv:2211.02263",
    "title": "Impact Learning: A Learning Method from Features Impact and Competition",
    "abstract": "Machine learning is the study of computer algorithms that can automatically\nimprove based on data and experience. Machine learning algorithms build a model\nfrom sample data, called training data, to make predictions or judgments\nwithout being explicitly programmed to do so. A variety of wellknown machine\nlearning algorithms have been developed for use in the field of computer\nscience to analyze data. This paper introduced a new machine learning algorithm\ncalled impact learning. Impact learning is a supervised learning algorithm that\ncan be consolidated in both classification and regression problems. It can\nfurthermore manifest its superiority in analyzing competitive data. This\nalgorithm is remarkable for learning from the competitive situation and the\ncompetition comes from the effects of autonomous features. It is prepared by\nthe impacts of the highlights from the intrinsic rate of natural increase\n(RNI). We, moreover, manifest the prevalence of the impact learning over the\nconventional machine learning algorithm.",
    "descriptor": "",
    "authors": [
      "Nusrat Jahan Prottasha",
      "Saydul Akbar Murad",
      "Abu Jafar Md Muzahid",
      "Masud Rana",
      "Md Kowsher",
      "Apurba Adhikary",
      "Sujit Biswas",
      "Anupam Kumar Bairagi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.02263"
  },
  {
    "id": "arXiv:2211.02265",
    "title": "Experiences from Using Code Explanations Generated by Large Language  Models in a Web Software Development E-Book",
    "abstract": "Advances in natural language processing have resulted in large language\nmodels (LLMs) that are capable of generating understandable and sensible\nwritten text. Recent versions of these models, such as OpenAI Codex and GPT-3,\ncan generate code and code explanations. However, it is unclear whether and how\nstudents might engage with such explanations. In this paper, we report on our\nexperiences generating multiple code explanation types using LLMs and\nintegrating them into an interactive e-book on web software development. We\nmodified the e-book to make LLM-generated code explanations accessible through\nbuttons next to code snippets in the materials, which allowed us to track the\nuse of the explanations as well as to ask for feedback on their utility. Three\ndifferent types of explanations were available for students for each\nexplainable code snippet; a line-by-line explanation, a list of important\nconcepts, and a high-level summary of the code. Our preliminary results show\nthat all varieties of explanations were viewed by students and that the\nmajority of students perceived the code explanations as helpful to them.\nHowever, student engagement appeared to vary by code snippet complexity,\nexplanation type, and code snippet length. Drawing on our experiences, we\ndiscuss future directions for integrating explanations generated by LLMs into\nexisting computer science classrooms.",
    "descriptor": "",
    "authors": [
      "Stephen MacNeil",
      "Andrew Tran",
      "Arto Hellas",
      "Joanne Kim",
      "Sami Sarsa",
      "Paul Denny",
      "Seth Bernstein",
      "Juho Leinonen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.02265"
  },
  {
    "id": "arXiv:2211.02266",
    "title": "Rescuing the End-user systems from Vulnerable Applications using  Virtualization Techniques",
    "abstract": "In systems owned by normal end-users, many times security attacks are mounted\nby sneaking in malicious applications or exploiting existing software\nvulnerabilities through security non-conforming actions of users.\nVirtualization approaches can address this problem by providing a quarantine\nenvironment for applications, malicious devices, and device drivers, which are\nmostly used as entry points for security attacks. However, the existing methods\nto provide quarantine environments using virtualization are not transparent to\nthe user, both in terms of application interface transparency and file system\ntransparency. Further, software configuration level solutions like remote\ndesktops and remote application access mechanisms combined with shared file\nsystems do not meet the user transparency and security requirements. We propose\nqOS, a VM-based solution combined with certain OS extensions to meet the\nsecurity requirements of end-point systems owned by normal users, in a\ntransparent and efficient manner. We demonstrate the efficacy of qOS by\nempirically evaluating the prototype implementation in the Linux+KVM system in\nterms of efficiency, security, and user transparency.",
    "descriptor": "\nComments: 14 pages, 9 figures\n",
    "authors": [
      "Vinayak Trivedi",
      "Tushar Gurjar",
      "Sumaiya Shaikh",
      "Saketh Maddamsetty",
      "Debadatta Mishra"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Operating Systems (cs.OS)"
    ],
    "url": "https://arxiv.org/abs/2211.02266"
  },
  {
    "id": "arXiv:2211.02269",
    "title": "Late Fusion with Triplet Margin Objective for Multimodal Ideology  Prediction and Analysis",
    "abstract": "Prior work on ideology prediction has largely focused on single modalities,\ni.e., text or images. In this work, we introduce the task of multimodal\nideology prediction, where a model predicts binary or five-point scale\nideological leanings, given a text-image pair with political content. We first\ncollect five new large-scale datasets with English documents and images along\nwith their ideological leanings, covering news articles from a wide range of US\nmainstream media and social media posts from Reddit and Twitter. We conduct\nin-depth analyses of news articles and reveal differences in image content and\nusage across the political spectrum. Furthermore, we perform extensive\nexperiments and ablation studies, demonstrating the effectiveness of targeted\npretraining objectives on different model components. Our best-performing\nmodel, a late-fusion architecture pretrained with a triplet objective over\nmultimodal content, outperforms the state-of-the-art text-only model by almost\n4% and a strong multimodal baseline with no pretraining by over 3%.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Changyuan Qiu",
      "Winston Wu",
      "Xinliang Frederick Zhang",
      "Lu Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.02269"
  },
  {
    "id": "arXiv:2211.02272",
    "title": "Logits are predictive of network type",
    "abstract": "We show that it is possible to predict which deep network has generated a\ngiven logit vector with accuracy well above chance. We utilize a number of\nnetworks on a dataset, initialized with random weights or pretrained weights,\nas well as fine-tuned networks. A classifier is then trained on the logit\nvectors of the trained set of this dataset to map the logit vector to the\nnetwork index that has generated it. The classifier is then evaluated on the\ntest set of the dataset. Results are better with randomly initialized networks,\nbut also generalize to pretrained networks as well as fine-tuned ones.\nClassification accuracy is higher using unnormalized logits than normalized\nones. We find that there is little transfer when applying a classifier to the\nsame networks but with different sets of weights. In addition to help better\nunderstand deep networks and the way they encode uncertainty, we anticipate our\nfinding to be useful in some applications (e.g. tailoring an adversarial attack\nfor a certain type of network). Code is available at\nhttps://github.com/aliborji/logits.",
    "descriptor": "",
    "authors": [
      "Ali Borji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02272"
  },
  {
    "id": "arXiv:2211.02274",
    "title": "Rally and WebScience: A Platform and Toolkit for Browser-Based Research  on Technology and Society Problems",
    "abstract": "Empirical technology and society research is in a methodological crisis.\nProblems increasingly involve closed platforms, targeted content, and\ncontext-specific behavior. Prevailing research methods, such as surveys, tasks,\nand web crawls, pose design and ecological validity limitations.\nDeploying studies in participant browsers and devices is a promising\ndirection. These vantage points can observe individualized experiences and\nimplement UI interventions in real settings.\nWe survey scholarship that uses these methods, annotating 284 sampled papers.\nOur analysis demonstrates their potential, but also recurring implementation\nbarriers and shortcomings.\nWe then present Rally and sdkName, a platform and toolkit for browser-based\nresearch. These systems lower implementation barriers and advance the science\nof measuring online behavior.\nFinally, we evaluate Rally and sdkName against our design goals. We report\nresults from a one-month pilot study on news engagement, analyzing 4,466,200\nwebpage visits from 1,817 participants. We also present observations from\ninterviews with researchers using these systems.",
    "descriptor": "",
    "authors": [
      "Anne Kohlbrenner",
      "Ben Kaiser",
      "Kartikeya Kandula. Rebecca Weiss",
      "Jonathan Mayer",
      "Ted Han",
      "Robert Helmer"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.02274"
  },
  {
    "id": "arXiv:2211.02281",
    "title": "An Efficient FPGA-based Accelerator for Deep Forest",
    "abstract": "Deep Forest is a prominent machine learning algorithm known for its high\naccuracy in forecasting. Compared with deep neural networks, Deep Forest has\nalmost no multiplication operations and has better performance on small\ndatasets. However, due to the deep structure and large forest quantity, it\nsuffers from large amounts of calculation and memory consumption. In this\npaper, an efficient hardware accelerator is proposed for deep forest models,\nwhich is also the first work to implement Deep Forest on FPGA. Firstly, a\ndelicate node computing unit (NCU) is designed to improve inference speed.\nSecondly, based on NCU, an efficient architecture and an adaptive dataflow are\nproposed, in order to alleviate the problem of node computing imbalance in the\nclassification process. Moreover, an optimized storage scheme in this design\nalso improves hardware utilization and power efficiency. The proposed design is\nimplemented on an FPGA board, Intel Stratix V, and it is evaluated by two\ntypical datasets, ADULT and Face Mask Detection. The experimental results show\nthat the proposed design can achieve around 40x speedup compared to that on a\n40 cores high performance x86 CPU.",
    "descriptor": "\nComments: 5 pages, 5 figures, conference\n",
    "authors": [
      "Mingyu Zhu",
      "Jiapeng Luo",
      "Wendong Mao",
      "Zhongfeng Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.02281"
  },
  {
    "id": "arXiv:2211.02283",
    "title": "Wireless Deep Speech Semantic Transmission",
    "abstract": "In this paper, we propose a new class of high-efficiency semantic coded\ntransmission methods for end-to-end speech transmission over wireless channels.\nWe name the whole system as deep speech semantic transmission (DSST).\nSpecifically, we introduce a nonlinear transform to map the speech source to\nsemantic latent space and feed semantic features into source-channel encoder to\ngenerate the channel-input sequence. Guided by the variational modeling idea,\nwe build an entropy model on the latent space to estimate the importance\ndiversity among semantic feature embeddings. Accordingly, these semantic\nfeatures of different importance can be allocated with different coding rates\nreasonably, which maximizes the system coding gain. Furthermore, we introduce a\nchannel signal-to-noise ratio (SNR) adaptation mechanism such that a single\nmodel can be applied over various channel states. The end-to-end optimization\nof our model leads to a flexible rate-distortion (RD) trade-off, supporting\nversatile wireless speech semantic transmission. Experimental results verify\nthat our DSST system clearly outperforms current engineered speech transmission\nsystems on both objective and subjective metrics. Compared with existing neural\nspeech semantic transmission methods, our model saves up to 75% of channel\nbandwidth costs when achieving the same quality. An intuitive comparison of\naudio demos can be found at https://ximoo123.github.io/DSST.",
    "descriptor": "",
    "authors": [
      "Zixuan Xiao",
      "Shengshi Yao",
      "Jincheng Dai",
      "Sixian Wang",
      "Kai Niu",
      "Ping Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Theory (cs.IT)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.02283"
  },
  {
    "id": "arXiv:2211.02284",
    "title": "Unsupervised Visual Representation Learning via Mutual Information  Regularized Assignment",
    "abstract": "This paper proposes Mutual Information Regularized Assignment (MIRA), a\npseudo-labeling algorithm for unsupervised representation learning inspired by\ninformation maximization. We formulate online pseudo-labeling as an\noptimization problem to find pseudo-labels that maximize the mutual information\nbetween the label and data while being close to a given model probability. We\nderive a fixed-point iteration method and prove its convergence to the optimal\nsolution. In contrast to baselines, MIRA combined with pseudo-label prediction\nenables a simple yet effective clustering-based representation learning without\nincorporating extra training techniques or artificial constraints such as\nsampling strategy, equipartition constraints, etc. With relatively small\ntraining epochs, representation learned by MIRA achieves state-of-the-art\nperformance on various downstream tasks, including the linear/k-NN evaluation\nand transfer learning. Especially, with only 400 epochs, our method applied to\nImageNet dataset with ResNet-50 architecture achieves 75.6% linear evaluation\naccuracy.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Dong Hoon Lee",
      "Sungik Choi",
      "Hyunwoo Kim",
      "Sae-Young Chung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02284"
  },
  {
    "id": "arXiv:2211.02286",
    "title": "Rethinking Storage Management for Data Processing Pipelines in Cloud  Data Centers",
    "abstract": "Data processing frameworks such as Apache Beam and Apache Spark are used for\na wide range of applications, from logs analysis to data preparation for DNN\ntraining. It is thus unsurprising that there has been a large amount of work on\noptimizing these frameworks, including their storage management. The shift to\ncloud computing requires optimization across all pipelines concurrently running\nacross a cluster. In this paper, we look at one specific instance of this\nproblem: placement of I/O-intensive temporary intermediate data on SSD and HDD.\nEfficient data placement is challenging since I/O density is usually unknown at\nthe time data needs to be placed. Additionally, external factors such as load\nvariability, job preemption, or job priorities can impact job completion times,\nwhich ultimately affect the I/O density of the temporary files in the workload.\nIn this paper, we envision that machine learning can be used to solve this\nproblem. We analyze production logs from Google's data centers for a range of\ndata processing pipelines. Our analysis shows that I/O density may be\npredictable. This suggests that learning-based strategies, if crafted\ncarefully, could extract predictive features for I/O density of temporary files\ninvolved in various transformations, which could be used to improve the\nefficiency of storage management in data processing pipelines.",
    "descriptor": "",
    "authors": [
      "Ubaid Ullah Hafeez",
      "Martin Maas",
      "Mustafa Uysal",
      "Richard McDougall"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.02286"
  },
  {
    "id": "arXiv:2211.02291",
    "title": "SelecMix: Debiased Learning by Contradicting-pair Sampling",
    "abstract": "Neural networks trained with ERM (empirical risk minimization) sometimes\nlearn unintended decision rules, in particular when their training data is\nbiased, i.e., when training labels are strongly correlated with undesirable\nfeatures. To prevent a network from learning such features, recent methods\naugment training data such that examples displaying spurious correlations\n(i.e., bias-aligned examples) become a minority, whereas the other,\nbias-conflicting examples become prevalent. However, these approaches are\nsometimes difficult to train and scale to real-world data because they rely on\ngenerative models or disentangled representations. We propose an alternative\nbased on mixup, a popular augmentation that creates convex combinations of\ntraining examples. Our method, coined SelecMix, applies mixup to contradicting\npairs of examples, defined as showing either (i) the same label but dissimilar\nbiased features, or (ii) different labels but similar biased features.\nIdentifying such pairs requires comparing examples with respect to unknown\nbiased features. For this, we utilize an auxiliary contrastive model with the\npopular heuristic that biased features are learned preferentially during\ntraining. Experiments on standard benchmarks demonstrate the effectiveness of\nthe method, in particular when label noise complicates the identification of\nbias-conflicting examples.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Inwoo Hwang",
      "Sangjun Lee",
      "Yunhyeok Kwak",
      "Seong Joon Oh",
      "Damien Teney",
      "Jin-Hwa Kim",
      "Byoung-Tak Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02291"
  },
  {
    "id": "arXiv:2211.02293",
    "title": "Automating Vascular Shunt Insertion with the dVRK Surgical Robot",
    "abstract": "Vascular shunt insertion is a fundamental surgical procedure used to\ntemporarily restore blood flow to tissues. It is often performed in the field\nafter major trauma. We formulate a problem of automated vascular shunt\ninsertion and propose a pipeline to perform Automated Vascular Shunt Insertion\n(AVSI) using a da Vinci Research Kit. The pipeline uses a learned visual model\nto estimate the locus of the vessel rim, plans a grasp on the rim, and moves to\ngrasp at that point. The first robot gripper then pulls the rim to stretch open\nthe vessel with a dilation motion. The second robot gripper then proceeds to\ninsert a shunt into the vessel phantom (a model of the blood vessel) with a\nchamfer tilt followed by a screw motion. Results suggest that AVSI achieves a\nhigh success rate even with tight tolerances and varying vessel orientations up\nto 30{\\deg}. Supplementary material, dataset, videos, and visualizations can be\nfound at https://sites.google.com/berkeley.edu/autolab-avsi.",
    "descriptor": "",
    "authors": [
      "Karthik Dharmarajan",
      "Will Panitch",
      "Muyan Jiang",
      "Kishore Srinivas",
      "Baiyu Shi",
      "Yahav Avigal",
      "Huang Huang",
      "Thomas Low",
      "Danyal Fer",
      "Ken Goldberg"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.02293"
  },
  {
    "id": "arXiv:2211.02295",
    "title": "Experiment of Multi-UAV Full-Duplex System Equipped with Directional  Antennas",
    "abstract": "One of the key enablers for the realization of a variety of unmanned aerial\nvehicle (UAV)-based systems is the high-performance communication system\nlinking many UAVs and ground station. We have proposed a spectrum-efficient\nfull-duplex directional-antennas-equipped multi-UAV communication system with\nlow hardware complexity to address the issues of low spectrum efficiency caused\nby co-channel interference in areal channels. In this paper, by using the\nprototype system including UAVs and ground station, field experiments are\ncarried out to confirm the feasibility and effectiveness of the proposed\nsystem's key feature, i.e., co-channel interference cancellation among UAVs by\ndirectional antennas and UAV relative position control, instead of\nenergy-consuming dedicated self-interference cancellers on UAVs in traditional\nfull-duplex systems. Both uplink and downlink performance are tested.\nSpecially, in downlink experiment, channel power of interference between a pair\nof two UAVs is measured when UAVs are in different positional relationships.\nThe experiment results agree well with the designs and confirm that the\nproposed system can greatly improve the system performance.",
    "descriptor": "\nComments: The paper was accepted by IEEE Consumer Communications & Networking Conference (CCNC) 2023\n",
    "authors": [
      "Tao Yu",
      "Kento Kajiwara",
      "Kiyomichi Araki",
      "Kei Sakaguchi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.02295"
  },
  {
    "id": "arXiv:2211.02296",
    "title": "Decentralized Federated Reinforcement Learning for User-Centric Dynamic  TFDD Control",
    "abstract": "The explosive growth of dynamic and heterogeneous data traffic brings great\nchallenges for 5G and beyond mobile networks. To enhance the network capacity\nand reliability, we propose a learning-based dynamic time-frequency division\nduplexing (D-TFDD) scheme that adaptively allocates the uplink and downlink\ntime-frequency resources of base stations (BSs) to meet the asymmetric and\nheterogeneous traffic demands while alleviating the inter-cell interference. We\nformulate the problem as a decentralized partially observable Markov decision\nprocess (Dec-POMDP) that maximizes the long-term expected sum rate under the\nusers' packet dropping ratio constraints. In order to jointly optimize the\nglobal resources in a decentralized manner, we propose a federated\nreinforcement learning (RL) algorithm named federated Wolpertinger deep\ndeterministic policy gradient (FWDDPG) algorithm. The BSs decide their local\ntime-frequency configurations through RL algorithms and achieve global training\nvia exchanging local RL models with their neighbors under a decentralized\nfederated learning framework. Specifically, to deal with the large-scale\ndiscrete action space of each BS, we adopt a DDPG-based algorithm to generate\nactions in a continuous space, and then utilize Wolpertinger policy to reduce\nthe mapping errors from continuous action space back to discrete action space.\nSimulation results demonstrate the superiority of our proposed algorithm to\nbenchmark algorithms with respect to system sum rate.",
    "descriptor": "",
    "authors": [
      "Ziyan Yin",
      "Zhe Wang",
      "Jun Li",
      "Ming Ding",
      "Wen Chen",
      "Shi Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.02296"
  },
  {
    "id": "arXiv:2211.02299",
    "title": "GARNet: Global-Aware Multi-View 3D Reconstruction Network and the  Cost-Performance Tradeoff",
    "abstract": "Deep learning technology has made great progress in multi-view 3D\nreconstruction tasks. At present, most mainstream solutions establish the\nmapping between views and shape of an object by assembling the networks of 2D\nencoder and 3D decoder as the basic structure while they adopt different\napproaches to obtain aggregation of features from several views. Among them,\nthe methods using attention-based fusion perform better and more stable than\nthe others, however, they still have an obvious shortcoming -- the strong\nindependence of each view during predicting the weights for merging leads to a\nlack of adaption of the global state. In this paper, we propose a global-aware\nattention-based fusion approach that builds the correlation between each branch\nand the global to provide a comprehensive foundation for weights inference. In\norder to enhance the ability of the network, we introduce a novel loss function\nto supervise the shape overall and propose a dynamic two-stage training\nstrategy that can effectively adapt to all reconstructors with attention-based\nfusion. Experiments on ShapeNet verify that our method outperforms existing\nSOTA methods while the amount of parameters is far less than the same type of\nalgorithm, Pix2Vox++. Furthermore, we propose a view-reduction method based on\nmaximizing diversity and discuss the cost-performance tradeoff of our model to\nachieve a better performance when facing heavy input amount and limited\ncomputational cost.",
    "descriptor": "",
    "authors": [
      "Zhenwei Zhu",
      "Liying Yang",
      "Xuxin Lin",
      "Chaohao Jiang",
      "Ning Li",
      "Lin Yang",
      "Yanyan Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02299"
  },
  {
    "id": "arXiv:2211.02300",
    "title": "Elimination of Non-Novel Segments at Multi-Scale for Few-Shot  Segmentation",
    "abstract": "Few-shot segmentation aims to devise a generalizing model that segments query\nimages from unseen classes during training with the guidance of a few support\nimages whose class tally with the class of the query. There exist two\ndomain-specific problems mentioned in the previous works, namely spatial\ninconsistency and bias towards seen classes. Taking the former problem into\naccount, our method compares the support feature map with the query feature map\nat multi scales to become scale-agnostic. As a solution to the latter problem,\na supervised model, called as base learner, is trained on available classes to\naccurately identify pixels belonging to seen classes. Hence, subsequent meta\nlearner has a chance to discard areas belonging to seen classes with the help\nof an ensemble learning model that coordinates meta learner with the base\nlearner. We simultaneously address these two vital problems for the first time\nand achieve state-of-the-art performances on both PASCAL-5i and COCO-20i\ndatasets.",
    "descriptor": "\nComments: Accepted to WACV 2023\n",
    "authors": [
      "Alper Kayaba\u015f\u0131",
      "G\u00fclin T\u00fcfekci",
      "\u0130lkay Ulusoy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02300"
  },
  {
    "id": "arXiv:2211.02301",
    "title": "Binaural Rendering of Ambisonic Signals by Neural Networks",
    "abstract": "Binaural rendering of ambisonic signals is of broad interest to virtual\nreality and immersive media. Conventional methods often require manually\nmeasured Head-Related Transfer Functions (HRTFs). To address this issue, we\ncollect a paired ambisonic-binaural dataset and propose a deep learning\nframework in an end-to-end manner. Experimental results show that neural\nnetworks outperform the conventional method in objective metrics and achieve\ncomparable subjective metrics. To validate the proposed framework, we\nexperimentally explore different settings of the input features, model\nstructures, output features, and loss functions. Our proposed system achieves\nan SDR of 7.32 and MOSs of 3.83, 3.58, 3.87, 3.58 in quality, timbre,\nlocalization, and immersion dimensions.",
    "descriptor": "",
    "authors": [
      "Yin Zhu",
      "Qiuqiang Kong",
      "Junjie Shi",
      "Shilei Liu",
      "Xuzhou Ye",
      "Ju-chiang Wang",
      "Junping Zhang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.02301"
  },
  {
    "id": "arXiv:2211.02303",
    "title": "MultiWOZ-DF -- A Dataflow implementation of the MultiWOZ dataset",
    "abstract": "Semantic Machines (SM) have introduced the use of the dataflow (DF) paradigm\nto dialogue modelling, using computational graphs to hierarchically represent\nuser requests, data, and the dialogue history [Semantic Machines et al. 2020].\nAlthough the main focus of that paper was the SMCalFlow dataset (to date, the\nonly dataset with \"native\" DF annotations), they also reported some results of\nan experiment using a transformed version of the commonly used MultiWOZ dataset\n[Budzianowski et al. 2018] into a DF format. In this paper, we expand the\nexperiments using DF for the MultiWOZ dataset, exploring some additional\nexperimental set-ups. The code and instructions to reproduce the experiments\nreported here have been released. The contributions of this paper are: 1.) A DF\nimplementation capable of executing MultiWOZ dialogues; 2.) Several versions of\nconversion of MultiWOZ into a DF format are presented; 3.) Experimental results\non state match and translation accuracy.",
    "descriptor": "",
    "authors": [
      "Joram Meron",
      "Victor Guimar\u00e3es"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.02303"
  },
  {
    "id": "arXiv:2211.02307",
    "title": "Domain Adaptive Video Semantic Segmentation via Cross-Domain Moving  Object Mixing",
    "abstract": "The network trained for domain adaptation is prone to bias toward the\neasy-to-transfer classes. Since the ground truth label on the target domain is\nunavailable during training, the bias problem leads to skewed predictions,\nforgetting to predict hard-to-transfer classes. To address this problem, we\npropose Cross-domain Moving Object Mixing (CMOM) that cuts several objects,\nincluding hard-to-transfer classes, in the source domain video clip and pastes\nthem into the target domain video clip. Unlike image-level domain adaptation,\nthe temporal context should be maintained to mix moving objects in two\ndifferent videos. Therefore, we design CMOM to mix with consecutive video\nframes, so that unrealistic movements are not occurring. We additionally\npropose Feature Alignment with Temporal Context (FATC) to enhance target domain\nfeature discriminability. FATC exploits the robust source domain features,\nwhich are trained with ground truth labels, to learn discriminative target\ndomain features in an unsupervised manner by filtering unreliable predictions\nwith temporal consensus. We demonstrate the effectiveness of the proposed\napproaches through extensive experiments. In particular, our model reaches mIoU\nof 53.81% on VIPER to Cityscapes-Seq benchmark and mIoU of 56.31% on\nSYNTHIA-Seq to Cityscapes-Seq benchmark, surpassing the state-of-the-art\nmethods by large margins.",
    "descriptor": "\nComments: Accepted to WACV 2023\n",
    "authors": [
      "Kyusik Cho",
      "Suhyeon Lee",
      "Hongje Seong",
      "Euntai Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02307"
  },
  {
    "id": "arXiv:2211.02319",
    "title": "Evaluating a distance function",
    "abstract": "Computing the distance function to some surface or line is a problem that\noccurs very frequently. There are several ways of computing a relevant\napproximation of this function, using for example technique originating from\nthe approximation of Hamilton Jacobi problems, or the fast sweeping method.\nHere we make a link with some elliptic problem and propose a very fast way to\napproximate the distance function.",
    "descriptor": "",
    "authors": [
      "R\u00e9mi Abgrall"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.02319"
  },
  {
    "id": "arXiv:2211.02320",
    "title": "Aircraft Ground Taxiing Deduction and Conflict Early Warning Method  Based on Control Command Information",
    "abstract": "Aircraft taxiing conflict is a threat to the safety of airport operations,\nmainly due to the human error in control command infor-mation. In order to\nsolve the problem, The aircraft taxiing deduction and conflict early warning\nmethod based on control order information is proposed. This method does not\nneed additional equipment and operating costs, and is completely based on\nhis-torical data and control command information. When the aircraft taxiing\ncommand is given, the future route information will be deduced, and the\nprobability of conflict with other taxiing aircraft will be calculated to\nachieve conflict detection and early warning of different levels. The method is\nvalidated by the aircraft taxi data from real airports. The results show that\nthe method can effectively predict the aircraft taxiing process, and can\nprovide early warning of possible conflicts. Due to the advantages of low cost\nand high accuracy, this method has the potential to be applied to airport\noperation decision support system.",
    "descriptor": "",
    "authors": [
      "Jingchang Zhuge",
      "Huiyuan Liang",
      "Yiming Zhang",
      "Shichao Li",
      "Xinyu Yang",
      "Jun Wu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.02320"
  },
  {
    "id": "arXiv:2211.02321",
    "title": "OSIC: A New One-Stage Image Captioner Coined",
    "abstract": "Mainstream image caption models are usually two-stage captioners, i.e.,\ncalculating object features by pre-trained detector, and feeding them into a\nlanguage model to generate text descriptions. However, such an operation will\ncause a task-based information gap to decrease the performance, since the\nobject features in detection task are suboptimal representation and cannot\nprovide all necessary information for subsequent text generation. Besides,\nobject features are usually represented by the last layer features that lose\nthe local details of input images. In this paper, we propose a novel One-Stage\nImage Captioner (OSIC) with dynamic multi-sight learning, which directly\ntransforms input image into descriptive sentences in one stage. As a result,\nthe task-based information gap can be greatly reduced. To obtain rich features,\nwe use the Swin Transformer to calculate multi-level features, and then feed\nthem into a novel dynamic multi-sight embedding module to exploit both global\nstructure and local texture of input images. To enhance the global modeling of\nencoder for caption, we propose a new dual-dimensional refining module to\nnon-locally model the interaction of the embedded features. Finally, OSIC can\nobtain rich and useful information to improve the image caption task. Extensive\ncomparisons on benchmark MS-COCO dataset verified the superior performance of\nour method.",
    "descriptor": "",
    "authors": [
      "Bo Wang",
      "Zhao Zhang",
      "Mingbo Zhao",
      "Xiaojie Jin",
      "Mingliang Xu",
      "Meng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02321"
  },
  {
    "id": "arXiv:2211.02330",
    "title": "This is not the End: Rethinking Serverless Function Termination",
    "abstract": "Elastic scaling is one of the central benefits provided by serverless\nplatforms, and requires that they scale resource up and down in response to\nchanging workloads. Serverless platforms scale-down resources by terminating\npreviously launched instances (which are containers or processes). The\nserverless programming model ensures that terminating instances is safe\nassuming all application code running on the instance has either completed or\ntimed out. Safety thus depends on the serverless platform's correctly\ndetermining that application processing is complete.\nIn this paper, we start with the observation that current serverless\nplatforms do not account for pending asynchronous I/O operations when\ndetermining whether application processing is complete. These platforms are\nthus unsafe when executing programs that use asynchronous I/O, and incorrectly\ndeciding that application processing has terminated can result in data\ninconsistency when these platforms are used. We show that the reason for this\nproblem is that current serverless semantics couple termination and response\ngeneration in serverless applications. We address this problem by proposing an\nextension to current semantics that decouples response generation and\ntermination, and demonstrate the efficacy and benefits of our proposal by\nextending OpenWhisk, an open source serverless platform.",
    "descriptor": "",
    "authors": [
      "Kalev Alpernas",
      "Aurojit Panda",
      "Mooly Sagiv"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.02330"
  },
  {
    "id": "arXiv:2211.02332",
    "title": "Once-for-All Sequence Compression for Self-Supervised Speech Models",
    "abstract": "The sequence length along the time axis is often the dominant factor of the\ncomputational cost of self-supervised speech models. Works have been proposed\nto reduce the sequence length for lowering the computational cost. However,\ndifferent downstream tasks have different tolerance of sequence compressing, so\na model that produces a fixed compressing rate may not fit all tasks. In this\nwork, we introduce a once-for-all (OFA) sequence compression framework for\nself-supervised speech models that supports a continuous range of compressing\nrates. The framework is evaluated on various tasks, showing marginal\ndegradation compared to the fixed compressing rate variants with a smooth\nperformance-efficiency trade-off. We further explore adaptive compressing rate\nlearning, demonstrating the ability to select task-specific preferred frame\nperiods without needing a grid search.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Hsuan-Jui Chen",
      "Yen Meng",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.02332"
  },
  {
    "id": "arXiv:2211.02336",
    "title": "Improving Speech Prosody of Audiobook Text-to-Speech Synthesis with  Acoustic and Textual Contexts",
    "abstract": "We present a multi-speaker Japanese audiobook text-to-speech (TTS) system\nthat leverages multimodal context information of preceding acoustic context and\nbilateral textual context to improve the prosody of synthetic speech. Previous\nwork either uses unilateral or single-modality context, which does not fully\nrepresent the context information. The proposed method uses an acoustic context\nencoder and a textual context encoder to aggregate context information and\nfeeds it to the TTS model, which enables the model to predict context-dependent\nprosody. We conducted comprehensive objective and subjective evaluations on a\nmulti-speaker Japanese audiobook dataset. Experimental results demonstrate that\nthe proposed method significantly outperforms two previous works. Additionally,\nwe present insights about the different choices of context - modalities,\nlateral information and length - for audiobook TTS that have never been\ndiscussed in the literature before.",
    "descriptor": "",
    "authors": [
      "Detai Xin",
      "Sharath Adavanne",
      "Federico Ang",
      "Ashish Kulkarni",
      "Shinnosuke Takamichi",
      "Hiroshi Saruwatari"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.02336"
  },
  {
    "id": "arXiv:2211.02337",
    "title": "UV R-CNN: Stable and Efficient Dense Human Pose Estimation",
    "abstract": "Dense pose estimation is a dense 3D prediction task for instance-level human\nanalysis, aiming to map human pixels from an RGB image to a 3D surface of the\nhuman body. Due to a large amount of surface point regression, the training\nprocess appears to be easy to collapse compared to other region-based human\ninstance analyzing tasks. By analyzing the loss formulation of the existing\ndense pose estimation model, we introduce a novel point regression loss\nfunction, named Dense Points} loss to stable the training progress, and a new\nbalanced loss weighting strategy to handle the multi-task losses. With the\nabove novelties, we propose a brand new architecture, named UV R-CNN. Without\nauxiliary supervision and external knowledge from other tasks, UV R-CNN can\nhandle many complicated issues in dense pose model training progress, achieving\n65.0% $AP_{gps}$ and 66.1% $AP_{gpsm}$ on the DensePose-COCO validation subset\nwith ResNet-50-FPN feature extractor, competitive among the state-of-the-art\ndense human pose estimation methods.",
    "descriptor": "\nComments: 9pages, 4 figures\n",
    "authors": [
      "Wenhe Jia",
      "Yilin Zhou",
      "Xuhan Zhu",
      "Mengjie Hu",
      "Chun Liu",
      "Qing Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02337"
  },
  {
    "id": "arXiv:2211.02341",
    "title": "Better Call Saltzer \\& Schroeder: A Retrospective Security Analysis of  SolarWinds \\& Log4j",
    "abstract": "Saltzer \\& Schroeder's principles aim to bring security to the design of\ncomputer systems. We investigate SolarWinds Orion update and Log4j to unpack\nthe intersections where observance of these principles could have mitigated the\nembedded vulnerabilities. The common principles that were not observed include\n\\emph{fail safe defaults}, \\emph{economy of mechanism}, \\emph{complete\nmediation} and \\emph{least privilege}. Then we explore the literature on secure\nsoftware development interventions for developers to identify usable analysis\ntools and frameworks that can contribute towards improved observance of these\nprinciples. We focus on a system wide view of access of codes, checking access\npaths and aiding application developers with safe libraries along with an\nappropriate security task list for functionalities.",
    "descriptor": "",
    "authors": [
      "Partha Das Chowdhury",
      "Mohammad Thai",
      "Awais Rashid"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.02341"
  },
  {
    "id": "arXiv:2211.02348",
    "title": "A General Purpose Neural Architecture for Geospatial Systems",
    "abstract": "Geospatial Information Systems are used by researchers and Humanitarian\nAssistance and Disaster Response (HADR) practitioners to support a wide variety\nof important applications. However, collaboration between these actors is\ndifficult due to the heterogeneous nature of geospatial data modalities (e.g.,\nmulti-spectral images of various resolutions, timeseries, weather data) and\ndiversity of tasks (e.g., regression of human activity indicators or detecting\nforest fires). In this work, we present a roadmap towards the construction of a\ngeneral-purpose neural architecture (GPNA) with a geospatial inductive bias,\npre-trained on large amounts of unlabelled earth observation data in a\nself-supervised manner. We envision how such a model may facilitate cooperation\nbetween members of the community. We show preliminary results on the first step\nof the roadmap, where we instantiate an architecture that can process a wide\nvariety of geospatial data modalities and demonstrate that it can achieve\ncompetitive performance with domain-specific architectures on tasks relating to\nthe U.N.'s Sustainable Development Goals.",
    "descriptor": "\nComments: Presented at AI + HADR Workshop at NeurIPS 2022\n",
    "authors": [
      "Nasim Rahaman",
      "Martin Weiss",
      "Frederik Tr\u00e4uble",
      "Francesco Locatello",
      "Alexandre Lacoste",
      "Yoshua Bengio",
      "Chris Pal",
      "Li Erran Li",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.02348"
  },
  {
    "id": "arXiv:2211.02351",
    "title": "Management and Detection System for Medical Surgical Equipment",
    "abstract": "Retained surgical bodies (RSB) are any foreign bodies left inside the patient\nafter a medical procedure. RSB is often caused by human mistakes or\nmiscommunication between medical staff during the procedure. Infection, medical\ncomplications, and even death are possible consequences of RSB, and it is a\nsignificant risk for patients, hospitals, and surgical staff. In this paper. we\ndescribe the engineering process we have done to explore the design space,\ndefine a feasible solution, and simulate, verify, and validate a\nstate-of-the-art Cyber-Physical System that can significantly decrease the\nincidence of RSB and thus increase patients' survivability rate. This system\nmight save patients' suffering and lives and reduce medical staff negligence\nlawsuits while improving the hospital's reputation. The paper illustrates each\nstep of the process with examples and describes the chosen solution in detail.",
    "descriptor": "",
    "authors": [
      "Alexandra Hadar",
      "Natan Levy",
      "Michael Winokur"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.02351"
  },
  {
    "id": "arXiv:2211.02352",
    "title": "Dynamic Resource Allocation Method for Load Balance Scheduling over  Cloud Data Center Networks",
    "abstract": "The cloud datacenter has numerous hosts as well as application requests where\nresources are dynamic. The demands placed on the resource allocation are\ndiverse. These factors could lead to load imbalances, which affect scheduling\nefficiency and resource utilization. A scheduling method called Dynamic\nResource Allocation for Load Balancing (DRALB) is proposed. The proposed\nsolution constitutes two steps: First, the load manager analyzes the resource\nrequirements such as CPU, Memory, Energy and Bandwidth usage and allocates an\nappropriate number of VMs for each application. Second, the resource\ninformation is collected and updated where resources are sorted into four\nqueues according to the loads of resources i.e. CPU intensive, Memory\nintensive, Energy intensive and Bandwidth intensive. We demonstarate that\nSLA-aware scheduling not only facilitates the cloud consumers by resources\navailability and improves throughput, response time etc. but also maximizes the\ncloud profits with less resource utilization and SLA (Service Level Agreement)\nviolation penalties. This method is based on diversity of clients applications\nand searching the optimal resources for the particular deployment. Experiments\nwere carried out based on following parameters i.e. average response time;\nresource utilization, SLA violation rate and load balancing. The experimental\nresults demonstrate that this method can reduce the wastage of resources and\nreduces the traffic upto 44.89 and 58.49 in the network.",
    "descriptor": "",
    "authors": [
      "Sakshi Chhabra",
      "Ashutosh Kumar Singh"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.02352"
  },
  {
    "id": "arXiv:2211.02356",
    "title": "Did your child get disturbed by an inappropriate advertisement on  YouTube?",
    "abstract": "YouTube is a popular video platform for sharing creative content and ideas,\ntargeting different demographics. Adults, older children, and young children\nare all avid viewers of YouTube videos. Meanwhile, countless young-kid-oriented\nchannels have produced numerous instructional and age appropriate videos for\nyoung children. However, inappropriate content for young children, such as\nviolent or sexually suggestive content, still exists. And children lack the\nability to decide whether a video is appropriate for them or not, which then\ncauses a huge risk to children's mental health. Prior works have focused on\nidentifying YouTube videos that are inappropriate for children. However, these\nworks ignore that not only the actual video content influences children, but\nalso the advertisements that are shown with those videos.\nIn this paper, we quantify the influence of inappropriate advertisements on\nYouTube videos that are appropriate for young children to watch. We analyze the\nadvertising patterns of 24.6 K diverse YouTube videos appropriate for young\nchildren. We find that 9.9% of the 4.6 K unique advertisements shown on these\n24.6 K videos contain inappropriate content for young children. Moreover, we\nobserve that 26.9% of all the 24.6 K appropriate videos include at least one ad\nthat is inappropriate for young children. Additionally, we publicly release our\ndatasets and provide recommendations about how to address this issue.",
    "descriptor": "\nComments: In Proceedings of KDD Undergraduate Consortium (KDD-UC 2022)\n",
    "authors": [
      "Jeffrey Liu",
      "Rajat Tandon",
      "Uma Durairaj",
      "Jiani Guo",
      "Spencer Zahabizadeh",
      "Sanjana Ilango",
      "Jeremy Tang",
      "Neelesh Gupta",
      "Zoe Zhou",
      "Jelena Mirkovic"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.02356"
  },
  {
    "id": "arXiv:2211.02357",
    "title": "Toward Transactive Control of Coupled Electric Power and District  Heating Networks",
    "abstract": "Although electric power networks and district heating networks are physically\ncoupled, they are not operated in a coordinated manner. With increasing\npenetration of renewable energy sources, a coordinated market-based operation\nof the two networks can yield significant advantages, as reduced need for grid\nreinforcements, by optimizing the power flows in the coupled systems.\nTransactive control has been developed as a promising approach based on market\nand control mechanisms to coordinate supply and demand in energy systems, which\nwhen applied to power systems is being referred to as transactive energy.\nHowever, this approach has not been fully investigated in the context of\nmarket-based operation of coupled electric power and district heating networks.\nTherefore, this paper proposes a transactive control approach to coordinate\nflexible producers and consumers while taking into account the operational\naspects of both networks, for the benefit of all participants and considering\ntheir privacy. A nonlinear model predictive control approach is applied in this\nwork to maximize the social welfare of both networks, taking into account\nsystem operational limits, while reducing losses and considering system\ndynamics and forecasted power supply and demand of inflexible producers and\nconsumers. A subtle approximation of the operational optimization problem is\nused to enable the practical application of the proposed approach in real time.\nThe presented technique is implemented, tested, and demonstrated in a realistic\ntest system, illustrating its benefits.",
    "descriptor": "\nComments: 35 pages, 16 Figures\n",
    "authors": [
      "Jona Maurer",
      "Nicolai Tschuch",
      "Stefan Krebs",
      "Kankar Bhattacharya",
      "Claudio Ca\u00f1izares",
      "S\u00f6ren Hohmann"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.02357"
  },
  {
    "id": "arXiv:2211.02363",
    "title": "Neural RELAGGS",
    "abstract": "Multi-relational databases are the basis of most consolidated data\ncollections in science and industry today. Most learning and mining algorithms,\nhowever, require data to be represented in a propositional form. While there is\na variety of specialized machine learning algorithms that can operate directly\non multi-relational data sets, propositionalization algorithms transform\nmulti-relational databases into propositional data sets, thereby allowing the\napplication of traditional machine learning and data mining algorithms without\ntheir modification. One prominent propositionalization algorithm is RELAGGS by\nKrogel and Wrobel, which transforms the data by nested aggregations. We propose\na new neural network based algorithm in the spirit of RELAGGS that employs\ntrainable composite aggregate functions instead of the static aggregate\nfunctions used in the original approach. In this way, we can jointly train the\npropositionalization with the prediction model, or, alternatively, use the\nlearned aggegrations as embeddings in other algorithms. We demonstrate the\nincreased predictive performance by comparing N-RELAGGS with RELAGGS and\nmultiple other state-of-the-art algorithms.",
    "descriptor": "\nComments: Submitted to Machine Learning Journal\n",
    "authors": [
      "Lukas Pensel",
      "Stefan Kramer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.02363"
  },
  {
    "id": "arXiv:2211.02365",
    "title": "On Robustness for the Skolem, Positivity and Ultimate Positivity  Problems",
    "abstract": "The Skolem problem is a long-standing open problem in linear dynamical\nsystems: can a linear recurrence sequence (LRS) ever reach 0 from a given\ninitial configuration? Similarly, the positivity problem asks whether the LRS\nstays positive from an initial configuration. Deciding Skolem (or positivity)\nhas been open for half a century: the best known decidability results are for\nLRS with special properties (e.g., low order recurrences). But these problems\nare easier for ``uninitialized'' variants, where the initial configuration is\nnot fixed but can vary arbitrarily: checking if there is an initial\nconfiguration from which the LRS stays positive can be decided in polynomial\ntime (Tiwari in 2004, Braverman in 2006).\nIn this paper, we consider problems that lie between the initialized and\nuninitialized variant. More precisely, we ask if 0 (resp. negative numbers) can\nbe avoided from every initial configuration in a neighborhood of a given\ninitial configuration. This can be considered as a robust variant of the Skolem\n(resp. positivity) problem. We show that these problems lie at the frontier of\ndecidability: if the neighbourhood is given as part of the input, then robust\nSkolem and robust positivity are Diophantine hard, i.e., solving either would\nentail major breakthrough in Diophantine approximations, as happens for\n(non-robust) positivity. However, if one asks whether such a neighbourhood\nexists, then the problems turn out to be decidable with PSPACE complexity.\nOur techniques also allow us to tackle robustness for ultimate positivity,\nwhich asks whether there is a bound on the number of steps after which the LRS\nremains positive. There are two variants depending on whether we ask for a\n``uniform'' bound on this number of steps. For the non-uniform variant, when\nthe neighbourhood is open, the problem turns out to be tractable, even when the\nneighbourhood is given as input.",
    "descriptor": "\nComments: Extended version of conference paper which appeared in the proceedings of STACS'22\n",
    "authors": [
      "S. Akshay",
      "Hugo Bazille",
      "Blaise Genest",
      "Mihir Vahanwala"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.02365"
  },
  {
    "id": "arXiv:2211.02366",
    "title": "SPEAKER VGG CCT: Cross-corpus Speech Emotion Recognition with Speaker  Embedding and Vision Transformers",
    "abstract": "In recent years, Speech Emotion Recognition (SER) has been investigated\nmainly transforming the speech signal into spectrograms that are then\nclassified using Convolutional Neural Networks pretrained on generic images and\nfine tuned with spectrograms. In this paper, we start from the general idea\nabove and develop a new learning solution for SER, which is based on Compact\nConvolutional Transformers (CCTs) combined with a speaker embedding. With CCTs,\nthe learning power of Vision Transformers (ViT) is combined with a diminished\nneed for large volume of data as made possible by the convolution. This is\nimportant in SER, where large corpora of data are usually not available. The\nspeaker embedding allows the network to extract an identity representation of\nthe speaker, which is then integrated by means of a self-attention mechanism\nwith the features that the CCT extracts from the spectrogram. Overall, the\nsolution is capable of operating in real-time showing promising results in a\ncross-corpus scenario, where training and test datasets are kept separate.\nExperiments have been performed on several benchmarks in a cross-corpus setting\nas rarely used in the literature, with results that are comparable or superior\nto those obtained with state-of-the-art network architectures. Our code is\navailable at https://github.com/JabuMlDev/Speaker-VGG-CCT.",
    "descriptor": "",
    "authors": [
      "A. Arezzo",
      "S. Berretti"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.02366"
  },
  {
    "id": "arXiv:2211.02369",
    "title": "A Jigsaw Puzzle Solver-based Attack on Block-wise Image Encryption for  Privacy-preserving DNNs",
    "abstract": "Privacy-preserving deep neural networks (DNNs) have been proposed for\nprotecting data privacy in the cloud server. Although several encryption\nschemes for visually protection have been proposed for privacy-preserving DNNs,\nseveral attacks enable to restore visual information from encrypted images. On\nthe other hand, it has been confirmed that the block-wise image encryption\nscheme which utilizes block and pixel shuffling is robust against several\nattacks. In this paper, we propose a jigsaw puzzle solver-based attack to\nrestore visual information from encrypted images including block and pixel\nshuffling. In experiments, images encrypted by using the block-wise image\nencryption are mostly restored by using the proposed attack.",
    "descriptor": "\nComments: To be appeared in IWAIT2023\n",
    "authors": [
      "Tatsuya Chuman",
      "Hitoshi Kiya"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.02369"
  },
  {
    "id": "arXiv:2211.02372",
    "title": "Path Planning Using Wassertein Distributionally Robust Deep Q-learning",
    "abstract": "We investigate the problem of risk averse robot path planning using the deep\nreinforcement learning and distributionally robust optimization perspectives.\nOur problem formulation involves modelling the robot as a stochastic linear\ndynamical system, assuming that a collection of process noise samples is\navailable. We cast the risk averse motion planning problem as a Markov decision\nprocess and propose a continuous reward function design that explicitly takes\ninto account the risk of collision with obstacles while encouraging the robot's\nmotion towards the goal. We learn the risk-averse robot control actions through\nLipschitz approximated Wasserstein distributionally robust deep Q-learning to\nhedge against the noise uncertainty. The learned control actions result in a\nsafe and risk averse trajectory from the source to the goal, avoiding all the\nobstacles. Various supporting numerical simulations are presented to\ndemonstrate our proposed approach.",
    "descriptor": "",
    "authors": [
      "Cem Alpturk",
      "Venkatraman Renganathan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.02372"
  },
  {
    "id": "arXiv:2211.02375",
    "title": "Conformal Quantitative Predictive Monitoring of STL Requirements for  Stochastic Processes",
    "abstract": "We consider the problem of predictive monitoring (PM), i.e., predicting at\nruntime the satisfaction of a desired property from the current system's state.\nDue to its relevance for runtime safety assurance and online control, PM\nmethods need to be efficient to enable timely interventions against predicted\nviolations, while providing correctness guarantees. We introduce\n\\textit{quantitative predictive monitoring (QPM)}, the first PM method to\nsupport stochastic processes and rich specifications given in Signal Temporal\nLogic (STL). Unlike most of the existing PM techniques that predict whether or\nnot some property $\\phi$ is satisfied, QPM provides a quantitative measure of\nsatisfaction by predicting the quantitative (aka robust) STL semantics of\n$\\phi$. QPM derives prediction intervals that are highly efficient to compute\nand with probabilistic guarantees, in that the intervals cover with arbitrary\nprobability the STL robustness values relative to the stochastic evolution of\nthe system. To do so, we take a machine-learning approach and leverage recent\nadvances in conformal inference for quantile regression, thereby avoiding\nexpensive Monte-Carlo simulations at runtime to estimate the intervals. We also\nshow how our monitors can be combined in a compositional manner to handle\ncomposite formulas, without retraining the predictors nor sacrificing the\nguarantees. We demonstrate the effectiveness and scalability of QPM over a\nbenchmark of four discrete-time stochastic processes with varying degrees of\ncomplexity.",
    "descriptor": "",
    "authors": [
      "Francesca Cairoli",
      "Nicola Paoletti",
      "Luca Bortolussi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.02375"
  },
  {
    "id": "arXiv:2211.02378",
    "title": "A survey on scheduling and mapping techniques in 3D Network-on-chip",
    "abstract": "Network-on-Chips (NoCs) have been widely employed in the design of\nmultiprocessor system-on-chips (MPSoCs) as a scalable communication solution.\nNoCs enable communications between on-chip Intellectual Property (IP) cores and\nallow those cores to achieve higher performance by outsourcing their\ncommunication tasks. Mapping and Scheduling methodologies are key elements in\nassigning application tasks, allocating the tasks to the IPs, and organising\ncommunication among them to achieve some specified objectives. The goal of this\npaper is to present a detailed state-of-the-art of research in the field of\nmapping and scheduling of applications on 3D NoC, classifying the works based\non several dimensions and giving some potential research directions.",
    "descriptor": "",
    "authors": [
      "Simran Preet Kaur",
      "Manojit Ghose",
      "Ananya Pathak",
      "Rutuja Patole"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.02378"
  },
  {
    "id": "arXiv:2211.02385",
    "title": "Efficient evaluation of the error probability for pilot-assisted URLLC  with Massive MIMO",
    "abstract": "We propose a numerically efficient method for evaluating the random-coding\nunion bound with parameter $s$ on the error probability achievable in the\nfinite-blocklength regime by a pilot-assisted transmission scheme employing\nGaussian codebooks and operating over a memoryless block-fading channel. Our\nmethod relies on the saddlepoint approximation, which, differently from\nprevious results reported for similar scenarios, is performed with respect to\nthe number of fading blocks (a.k.a. diversity branches) spanned by each\ncodeword, instead of the number of channel uses per block. This different\napproach avoids a costly numerical averaging of the error probability over the\nrealizations of the fading process and of its pilot-based estimate at the\nreceiver and results in a significant reduction of the number of channel\nrealizations required to estimate the error probability accurately. Our\nnumerical experiments for both single-antenna communication links and massive\nmultiple-input multiple-output (MIMO) networks show that, when two or more\ndiversity branches are available, the error probability can be estimated\naccurately with the saddlepoint approximation with respect to the number of\nfading blocks using a numerical method that requires about two orders of\nmagnitude fewer Monte-Carlo samples than with the saddlepoint approximation\nwith respect to the number of channel uses per block.",
    "descriptor": "",
    "authors": [
      "A. Oguz Kislal",
      "Alejandro Lancho",
      "Giuseppe Durisi",
      "Erik Str\u00f6m"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.02385"
  },
  {
    "id": "arXiv:2211.02386",
    "title": "PP-YOLOE-R: An Efficient Anchor-Free Rotated Object Detector",
    "abstract": "Arbitrary-oriented object detection is a fundamental task in visual scenes\ninvolving aerial images and scene text. In this report, we present PP-YOLOE-R,\nan efficient anchor-free rotated object detector based on PP-YOLOE. We\nintroduce a bag of useful tricks in PP-YOLOE-R to improve detection precision\nwith marginal extra parameters and computational cost. As a result,\nPP-YOLOE-R-l and PP-YOLOE-R-x achieve 78.14 and 78.28 mAP respectively on DOTA\n1.0 dataset with single-scale training and testing, which outperform almost all\nother rotated object detectors. With multi-scale training and testing,\nPP-YOLOE-R-l and PP-YOLOE-R-x further improve the detection precision to 80.02\nand 80.73 mAP. In this case, PP-YOLOE-R-x surpasses all anchor-free methods and\ndemonstrates competitive performance to state-of-the-art anchor-based two-stage\nmodels. Further, PP-YOLOE-R is deployment friendly and PP-YOLOE-R-s/m/l/x can\nreach 69.8/55.1/48.3/37.1 FPS respectively on RTX 2080 Ti with TensorRT and\nFP16-precision. Source code and pre-trained models are available at\nhttps://github.com/PaddlePaddle/PaddleDetection, which is powered by\nhttps://github.com/PaddlePaddle/Paddle.",
    "descriptor": "\nComments: 6 pages, 2 figures, 3 tables\n",
    "authors": [
      "Xinxin Wang",
      "Guanzhong Wang",
      "Qingqing Dang",
      "Yi Liu",
      "Xiaoguang Hu",
      "Dianhai Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02386"
  },
  {
    "id": "arXiv:2211.02392",
    "title": "Patch DCT vs LeNet",
    "abstract": "This paper compares the performance of a NN taking the output of a DCT\n(Discrete Cosine Transform) of an image patch with leNet for classifying MNIST\nhand written digits. The basis functions underlying the DCT bear a passing\nresemblance to some of the learned basis function of the Visual Transformer but\nare an order of magnitude faster to apply.",
    "descriptor": "\nComments: 3 pages, 5 figures, appendix for pytorch code defn. Paper argues basis functions are close to as good as convolution nets and that learning custom basis function on large datasets is just pissing away electricity\n",
    "authors": [
      "David Sinclair"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02392"
  },
  {
    "id": "arXiv:2211.02394",
    "title": "Online Matching with Set Delay",
    "abstract": "We initiate the study of online problems with set delay, where the delay cost\nat any given time is an arbitrary function of the set of pending requests. In\nparticular, we study the online min-cost perfect matching with set delay\n(MPMD-Set) problem, which generalises the online min-cost perfect matching with\ndelay (MPMD) problem introduced by Emek et al. (STOC 2016). In MPMD, $m$\nrequests arrive over time in a metric space of $n$ points. When a request\narrives the algorithm must choose to either match or delay the request. The\ngoal is to create a perfect matching of all requests while minimising the sum\nof distances between matched requests, and the total delay costs incurred by\neach of the requests. In contrast to previous work we study MPMD-Set in the\nnon-clairvoyant setting, where the algorithm does not know the future delay\ncosts. We first show no algorithm is competitive in $n$ or $m$. We then study\nthe natural special case of size-based delay where the delay is a\nnon-decreasing function of the number of unmatched requests. Our main result is\nthe first non-clairvoyant algorithms for online min-cost perfect matching with\nsize-based delay that are competitive in terms of $m$. In fact, these are the\nfirst non-clairvoyant algorithms for any variant of MPMD. Furthermore, we prove\na lower bound of $\\Omega(n)$ for any deterministic algorithm and $\\Omega(\\log\nn)$ for any randomised algorithm. These lower bounds also hold for clairvoyant\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Lindsey Deryckere",
      "Seeun William Umboh"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.02394"
  },
  {
    "id": "arXiv:2211.02396",
    "title": "Rethinking the positive role of cluster structure in complex networks  for link prediction tasks",
    "abstract": "Clustering is a fundamental problem in network analysis that finds closely\nconnected groups of nodes and separates them from other nodes in the graph,\nwhile link prediction is to predict whether two nodes in a network are likely\nto have a link. The definition of both naturally determines that clustering\nmust play a positive role in obtaining accurate link prediction tasks. Yet\nresearchers have long ignored or used inappropriate ways to undermine this\npositive relationship. In this article, We construct a simple but efficient\nclustering-driven link prediction framework(ClusterLP), with the goal of\ndirectly exploiting the cluster structures to obtain connections between nodes\nas accurately as possible in both undirected graphs and directed graphs.\nSpecifically, we propose that it is easier to establish links between nodes\nwith similar representation vectors and cluster tendencies in undirected\ngraphs, while nodes in a directed graphs can more easily point to nodes similar\nto their representation vectors and have greater influence in their own\ncluster. We customized the implementation of ClusterLP for undirected and\ndirected graphs, respectively, and the experimental results using multiple\nreal-world networks on the link prediction task showed that our models is\nhighly competitive with existing baseline models. The code implementation of\nClusterLP and baselines we use are available at\nhttps://github.com/ZINUX1998/ClusterLP.",
    "descriptor": "\nComments: 15 pages, 7 figures. arXiv admin note: text overlap with arXiv:1503.03578, arXiv:2207.07399, arXiv:1905.09570, arXiv:2205.14651 by other authors\n",
    "authors": [
      "Shanfan Zhang",
      "Wenjiao Zhang",
      "Zhan Bu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.02396"
  },
  {
    "id": "arXiv:2211.02404",
    "title": "Tensor Robust PCA with Nonconvex and Nonlocal Regularization",
    "abstract": "Tensor robust principal component analysis (TRPCA) is a promising way for\nlow-rank tensor recovery, which minimizes the convex surrogate of tensor rank\nby shrinking each tensor singular values equally. However, for real-world\nvisual data, large singular values represent more signifiant information than\nsmall singular values. In this paper, we propose a nonconvex TRPCA (N-TRPCA)\nmodel based on the tensor adjustable logarithmic norm. Unlike TRPCA, our\nN-TRPCA can adaptively shrink small singular values more and shrink large\nsingular values less. In addition, TRPCA assumes that the whole data tensor is\nof low rank. This assumption is hardly satisfied in practice for natural visual\ndata, restricting the capability of TRPCA to recover the edges and texture\ndetails from noisy images and videos. To this end, we integrate nonlocal\nself-similarity into N-TRPCA, and further develop a nonconvex and nonlocal\nTRPCA (NN-TRPCA) model. Specifically, similar nonlocal patches are grouped as a\ntensor and then each group tensor is recovered by our N-TRPCA. Since the\npatches in one group are highly correlated, all group tensors have strong\nlow-rank property, leading to an improvement of recovery performance.\nExperimental results demonstrate that the proposed NN-TRPCA outperforms some\nexisting TRPCA methods in visual data recovery. The demo code is available at\nhttps://github.com/qguo2010/NN-TRPCA.",
    "descriptor": "\nComments: 19 pages, 7 figures\n",
    "authors": [
      "Xiaoyu Geng",
      "Qiang Guo",
      "Shuaixiong Hui",
      "Caiming Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02404"
  },
  {
    "id": "arXiv:2211.02405",
    "title": "Explainable Information Retrieval: A Survey",
    "abstract": "Explainable information retrieval is an emerging research area aiming to make\ntransparent and trustworthy information retrieval systems. Given the increasing\nuse of complex machine learning models in search systems, explainability is\nessential in building and auditing responsible information retrieval models.\nThis survey fills a vital gap in the otherwise topically diverse literature of\nexplainable information retrieval. It categorizes and discusses recent\nexplainability methods developed for different application domains in\ninformation retrieval, providing a common framework and unifying perspectives.\nIn addition, it reflects on the common concern of evaluating explanations and\nhighlights open challenges and opportunities.",
    "descriptor": "\nComments: 35 pages, 10 figures. Under review\n",
    "authors": [
      "Avishek Anand",
      "Lijun Lyu",
      "Maximilian Idahl",
      "Yumeng Wang",
      "Jonas Wallat",
      "Zijian Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.02405"
  },
  {
    "id": "arXiv:2211.02408",
    "title": "Rickrolling the Artist: Injecting Invisible Backdoors into Text-Guided  Image Generation Models",
    "abstract": "While text-to-image synthesis currently enjoys great popularity among\nresearchers and the general public, the security of these models has been\nneglected so far. Many text-guided image generation models rely on pre-trained\ntext encoders from external sources, and their users trust that the retrieved\nmodels will behave as promised. Unfortunately, this might not be the case. We\nintroduce backdoor attacks against text-guided generative models and\ndemonstrate that their text encoders pose a major tampering risk. Our attacks\nonly slightly alter an encoder so that no suspicious model behavior is apparent\nfor image generations with clean prompts. By then inserting a single non-Latin\ncharacter into the prompt, the adversary can trigger the model to either\ngenerate images with pre-defined attributes or images following a hidden,\npotentially malicious description. We empirically demonstrate the high\neffectiveness of our attacks on Stable Diffusion and highlight that the\ninjection process of a single backdoor takes less than two minutes. Besides\nphrasing our approach solely as an attack, it can also force an encoder to\nforget phrases related to certain concepts, such as nudity or violence, and\nhelp to make image generation safer.",
    "descriptor": "\nComments: 25 pages, 16 figures, 5 tables\n",
    "authors": [
      "Lukas Struppek",
      "Dominik Hintersdorf",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02408"
  },
  {
    "id": "arXiv:2211.02409",
    "title": "The Sustainable Development Goals and Aerospace Engineering: A critical  note through Artificial Intelligence",
    "abstract": "The 2030 Agenda of the United Nations (UN) revolves around the Sustainable\nDevelopment Goals (SDGs). A critical step towards that objective is identifying\nwhether scientific production aligns with the SDGs' achievement. To assess\nthis, funders and research managers need to manually estimate the impact of\ntheir funding agenda on the SDGs, focusing on accuracy, scalability, and\nobjectiveness. With this objective in mind, in this work, we develop ASDG, an\neasy-to-use artificial-intelligence (AI)-based model for automatically\nidentifying the potential impact of scientific papers on the UN SDGs. As a\ndemonstrator of ASDG, we analyze the alignment of recent aerospace publications\nwith the SDGs. The Aerospace data set analyzed in this paper consists of\napproximately 820,000 papers published in English from 2011 to 2020 and indexed\nin the Scopus database. The most-contributed SDGs are 7 (on clean energy), 9\n(on industry), 11 (on sustainable cities) and 13 (on climate action). The\nestablishment of the SDGs by the UN in the middle of the 2010 decade did not\nsignificantly affect the data. However, we find clear discrepancies among\ncountries, likely indicative of different priorities. Also, different trends\ncan be seen in the most and least cited papers, with clear differences in some\nSDGs. Finally, the number of abstracts the code cannot identify is decreasing\nwith time, possibly showing the scientific community's awareness of SDG.",
    "descriptor": "",
    "authors": [
      "Alejandro S\u00e1nchez-Roncero",
      "\u00d2scar Garibo-i-Ortsa",
      "J. Alberto Conejero",
      "Hamidreza Eivazi",
      "Ferm\u00edn Mallor",
      "Emelie Rosenberg",
      "Francesco Fuso-Nerini",
      "Javier Garc\u00eda-Mart\u00ednez",
      "Ricardo Vinuesa",
      "Sergio Hoyas"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2211.02409"
  },
  {
    "id": "arXiv:2211.02412",
    "title": "Emergent Quantized Communication",
    "abstract": "The field of emergent communication aims to understand the characteristics of\ncommunication as it emerges from artificial agents solving tasks that require\ninformation exchange. Communication with discrete messages is considered a\ndesired characteristic, for both scientific and applied reasons. However,\ntraining a multi-agent system with discrete communication is not\nstraightforward, requiring either reinforcement learning algorithms or relaxing\nthe discreteness requirement via a continuous approximation such as the\nGumbel-softmax. Both these solutions result in poor performance compared to\nfully continuous communication. In this work, we propose an alternative\napproach to achieve discrete communication -- quantization of communicated\nmessages. Using message quantization allows us to train the model end-to-end,\nachieving superior performance in multiple setups. Moreover, quantization is a\nnatural framework that runs the gamut from continuous to discrete\ncommunication. Thus, it sets the ground for a broader view of multi-agent\ncommunication in the deep learning era.",
    "descriptor": "",
    "authors": [
      "Boaz Carmeli",
      "Ron Meir",
      "Yonatan Belinkov"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.02412"
  },
  {
    "id": "arXiv:2211.02415",
    "title": "Multilingual Name Entity Recognition and Intent Classification Employing  Deep Learning Architectures",
    "abstract": "Named Entity Recognition and Intent Classification are among the most\nimportant subfields of the field of Natural Language Processing. Recent\nresearch has lead to the development of faster, more sophisticated and\nefficient models to tackle the problems posed by those two tasks. In this work\nwe explore the effectiveness of two separate families of Deep Learning networks\nfor those tasks: Bidirectional Long Short-Term networks and Transformer-based\nnetworks. The models were trained and tested on the ATIS benchmark dataset for\nboth English and Greek languages. The purpose of this paper is to present a\ncomparative study of the two groups of networks for both languages and showcase\nthe results of our experiments. The models, being the current state-of-the-art,\nyielded impressive results and achieved high performance.",
    "descriptor": "\nComments: 24 pages, 5 figures, 11 tables, dataset available\n",
    "authors": [
      "Sofia Rizou",
      "Antonia Paflioti",
      "Angelos Theofilatos",
      "Athena Vakali",
      "George Sarigiannidis",
      "Konstantinos Ch. Chatzisavvas"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.02415"
  },
  {
    "id": "arXiv:2211.02416",
    "title": "Rethinking the transfer learning for FCN based polyp segmentation in  colonoscopy",
    "abstract": "Besides the complex nature of colonoscopy frames with intrinsic frame\nformation artefacts such as light reflections and the diversity of polyp\ntypes/shapes, the publicly available polyp segmentation training datasets are\nlimited, small and imbalanced. In this case, the automated polyp segmentation\nusing a deep neural network remains an open challenge due to the overfitting of\ntraining on small datasets. We proposed a simple yet effective polyp\nsegmentation pipeline that couples the segmentation (FCN) and classification\n(CNN) tasks. We find the effectiveness of interactive weight transfer between\ndense and coarse vision tasks that mitigates the overfitting in learning. And\nIt motivates us to design a new training scheme within our segmentation\npipeline. Our method is evaluated on CVC-EndoSceneStill and Kvasir-SEG\ndatasets. It achieves 4.34% and 5.70% Polyp-IoU improvements compared to the\nstate-of-the-art methods on the EndoSceneStill and Kvasir-SEG datasets,\nrespectively.",
    "descriptor": "\nComments: 11 pages, 10 figures, submit version\n",
    "authors": [
      "Yan Wen",
      "Lei Zhang",
      "Xiangli Meng",
      "Xujiong Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02416"
  },
  {
    "id": "arXiv:2211.02421",
    "title": "On the Interplay between TLS Certificates and QUIC Performance",
    "abstract": "In this paper, we revisit the performance of the QUIC connection setup and\nrelate the design choices for fast and secure connections to common Web\ndeployments. We analyze over 1M Web domains with 272k QUIC-enabled services and\nfind two worrying results. First, current practices of creating, providing, and\nfetching Web certificates undermine reduced round trip times during the\nconnection setup since sizes of 35% of server certificates exceed the\namplification limit. Second, non-standard server implementations lead to larger\namplification factors than QUIC permits, which increase even further in IP\nspoofing scenarios. We present guidance for all involved stakeholders to\nimprove the situation.",
    "descriptor": "\nComments: camera-ready\n",
    "authors": [
      "Marcin Nawrocki",
      "Pouyan Fotouhi Tehrani",
      "Raphael Hiesgen",
      "Jonas M\u00fccke",
      "Thomas C. Schmidt",
      "Matthias W\u00e4hlisch"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.02421"
  },
  {
    "id": "arXiv:2211.02423",
    "title": "CLSE: Corpus of Linguistically Significant Entities",
    "abstract": "One of the biggest challenges of natural language generation (NLG) is the\nproper handling of named entities. Named entities are a common source of\ngrammar mistakes such as wrong prepositions, wrong article handling, or\nincorrect entity inflection. Without factoring linguistic representation, such\nerrors are often underrepresented when evaluating on a small set of arbitrarily\npicked argument values, or when translating a dataset from a linguistically\nsimpler language, like English, to a linguistically complex language, like\nRussian. However, for some applications, broadly precise grammatical\ncorrectness is critical -- native speakers may find entity-related grammar\nerrors silly, jarring, or even offensive.\nTo enable the creation of more linguistically diverse NLG datasets, we\nrelease a Corpus of Linguistically Significant Entities (CLSE) annotated by\nlinguist experts. The corpus includes 34 languages and covers 74 different\nsemantic types to support various applications from airline ticketing to video\ngames. To demonstrate one possible use of CLSE, we produce an augmented version\nof the Schema-Guided Dialog Dataset, SGD-CLSE. Using the CLSE's entities and a\nsmall number of human translations, we create a linguistically representative\nNLG evaluation benchmark in three languages: French (high-resource), Marathi\n(low-resource), and Russian (highly inflected language). We establish quality\nbaselines for neural, template-based, and hybrid NLG systems and discuss the\nstrengths and weaknesses of each approach.",
    "descriptor": "\nComments: Proceedings of the 2nd Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2022) at EMNLP 2022\n",
    "authors": [
      "Aleksandr Chuklin",
      "Justin Zhao",
      "Mihir Kale"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.02423"
  },
  {
    "id": "arXiv:2211.02429",
    "title": "Dealing with Abbreviations in the Slovenian Biographical Lexicon",
    "abstract": "Abbreviations present a significant challenge for NLP systems because they\ncause tokenization and out-of-vocabulary errors. They can also make the text\nless readable, especially in reference printed books, where they are\nextensively used. Abbreviations are especially problematic in low-resource\nsettings, where systems are less robust to begin with. In this paper, we\npropose a new method for addressing the problems caused by a high density of\ndomain-specific abbreviations in a text. We apply this method to the case of a\nSlovenian biographical lexicon and evaluate it on a newly developed\ngold-standard dataset of 51 Slovenian biographies. Our abbreviation\nidentification method performs significantly better than commonly used ad-hoc\nsolutions, especially at identifying unseen abbreviations. We also propose and\npresent the results of a method for expanding the identified abbreviations in\ncontext.",
    "descriptor": "\nComments: To be presented at The 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP 2022)\n",
    "authors": [
      "Angel Daza",
      "Antske Fokkens",
      "Toma\u017e Erjavec"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.02429"
  },
  {
    "id": "arXiv:2211.02432",
    "title": "RCDPT: Radar-Camera fusion Dense Prediction Transformer",
    "abstract": "Recently, transformer networks have outperformed traditional deep neural\nnetworks in natural language processing and show a large potential in many\ncomputer vision tasks compared to convolutional backbones. In the original\ntransformer, readout tokens are used as designated vectors for aggregating\ninformation from other tokens. However, the performance of using readout tokens\nin a vision transformer is limited. Therefore, we propose a novel fusion\nstrategy to integrate radar data into a dense prediction transformer network by\nreassembling camera representations with radar representations. Instead of\nusing readout tokens, radar representations contribute additional depth\ninformation to a monocular depth estimation model and improve performance. We\nfurther investigate different fusion approaches that are commonly used for\nintegrating additional modality in a dense prediction transformer network. The\nexperiments are conducted on the nuScenes dataset, which includes camera\nimages, lidar, and radar data. The results show that our proposed method yields\nbetter performance than the commonly used fusion strategies and outperforms\nexisting convolutional depth estimation models that fuse camera images and\nradar.",
    "descriptor": "\nComments: 5 pages, 2 figures and 1 table\n",
    "authors": [
      "Chen-Chou Lo",
      "Patrick Vandewalle"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.02432"
  },
  {
    "id": "arXiv:2211.02435",
    "title": "Advanced Automatic Code Generation for Multiple Relaxation-Time Lattice  Boltzmann Methods",
    "abstract": "The scientific code generation package lbmpy supports the automated design\nand the efficient implementation of lattice Boltzmann methods (LBMs) through\nmetaprogramming. It is based on a new, concise calculus for describing multiple\nrelaxation-time LBMs, including techniques that enable the numerically\nadvantageous subtraction of the constant background component from the\npopulations. These techniques are generalized to a wide range of collision\nspaces and equilibrium distributions. The article contains an overview of\nlbmpy's front-end and its code generation pipeline, which implements the new\nLBM calculus by means of symbolic formula manipulation tools and\nobject-oriented programming. The generated codes have only a minimal number of\narithmetic operations. Their automatic derivation rests on two novel Chimera\ntransforms that have been specifically developed for efficiently computing raw\nand central moments. Information contained in the symbolic representation of\nthe methods is further exploited in a customized sequence of algebraic\nsimplifications, further reducing computational cost. When combined, these\nalgebraic transformations lead to concise and compact numerical kernels.\nSpecifically, with these optimizations, the advanced central moment- and\ncumulant-based methods can be realized with only little additional cost as when\ncompared with the simple BGK method. The effectiveness and flexibility of the\nnew lbmpy code generation system is demonstrated in simulating Taylor-Green\nvortex decay and the automatic derivation of an LBM algorithm to solve the\nshallow water equations.",
    "descriptor": "\nComments: 23 pages, 6 figures\n",
    "authors": [
      "Frederik Hennig",
      "Markus Holzer",
      "Ulrich R\u00fcde"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.02435"
  },
  {
    "id": "arXiv:2211.02443",
    "title": "Robotic Assembly Control Reconfiguration Based on Transfer Reinforcement  Learning for Objects with Different Geometric Features",
    "abstract": "Robotic force-based compliance control is a preferred approach to achieve\nhigh-precision assembly tasks. When the geometric features of assembly objects\nare asymmetric or irregular, reinforcement learning (RL) agents are gradually\nincorporated into the compliance controller to adapt to complex force-pose\nmapping which is hard to model analytically. Since force-pose mapping is\nstrongly dependent on geometric features, a compliance controller is only\noptimal for current geometric features. To reduce the learning cost of assembly\nobjects with different geometric features, this paper is devoted to answering\nhow to reconfigure existing controllers for new assembly objects with different\ngeometric features. In this paper, model-based parameters are first\nreconfigured based on the proposed Equivalent Theory of Compliance Law (ETCL).\nThen the RL agent is transferred based on the proposed Weighted Dimensional\nPolicy Distillation (WDPD) method. The experiment results demonstrate that the\ncontrol reconfiguration method costs less time and achieves better control\nperformance, which confirms the validity of proposed methods.",
    "descriptor": "",
    "authors": [
      "Yuhang Gai",
      "Bing Wang",
      "Jiwen Zhang",
      "Dan Wu",
      "Ken Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.02443"
  },
  {
    "id": "arXiv:2211.02445",
    "title": "Lidar-level localization with radar? The CFEAR approach to accurate,  fast and robust large-scale radar odometry in diverse environments",
    "abstract": "This paper presents an accurate, highly efficient, and learning-free method\nfor large-scale odometry estimation using spinning radar, empirically found to\ngeneralize well across very diverse environments -- outdoors, from urban to\nwoodland, and indoors in warehouses and mines - without changing parameters.\nOur method integrates motion compensation within a sweep with one-to-many scan\nregistration that minimizes distances between nearby oriented surface points\nand mitigates outliers with a robust loss function. Extending our previous\napproach CFEAR, we present an in-depth investigation on a wider range of data\nsets, quantifying the importance of filtering, resolution, registration cost\nand loss functions, keyframe history, and motion compensation. We present a new\nsolving strategy and configuration that overcomes previous issues with sparsity\nand bias, and improves our state-of-the-art by 38%, thus, surprisingly,\noutperforming radar SLAM and approaching lidar SLAM. The most accurate\nconfiguration achieves 1.09% error at 5Hz on the Oxford benchmark, and the\nfastest achieves 1.79% error at 160Hz.",
    "descriptor": "\nComments: Accepted for publication in Transactions on Robotics\n",
    "authors": [
      "Daniel Adolfsson",
      "Martin Magnusson",
      "Anas Alhashimi",
      "Achim J. Lilienthal",
      "Henrik Andreasson"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.02445"
  },
  {
    "id": "arXiv:2211.02447",
    "title": "Applications of transcendental number theory to decision problems for  hypergeometric sequences",
    "abstract": "A rational-valued sequence is hypergeometric if it satisfies a first-order\nlinear recurrence relation with polynomial coefficients. In this note we\ndiscuss two decision problems, the membership and threshold problems, for\nhypergeometric sequences. The former problem asks whether a chosen target is in\nthe orbit of a given sequence, whilst the latter asks whether every term in a\nsequence is bounded from below by a given value.\nWe establish decidability results for restricted variants of these two\ndecision problems with an approach via transcendental number theory. Our\ncontributions include the following: the membership and threshold problems are\nboth decidable for the class of rational-valued hypergeometric sequences with\nGaussian integer parameters.",
    "descriptor": "",
    "authors": [
      "George Kenison"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2211.02447"
  },
  {
    "id": "arXiv:2211.02448",
    "title": "NoreSpeech: Knowledge Distillation based Conditional Diffusion Model for  Noise-robust Expressive TTS",
    "abstract": "Expressive text-to-speech (TTS) can synthesize a new speaking style by\nimiating prosody and timbre from a reference audio, which faces the following\nchallenges: (1) The highly dynamic prosody information in the reference audio\nis difficult to extract, especially, when the reference audio contains\nbackground noise. (2) The TTS systems should have good generalization for\nunseen speaking styles. In this paper, we present a\n\\textbf{no}ise-\\textbf{r}obust \\textbf{e}xpressive TTS model (NoreSpeech),\nwhich can robustly transfer speaking style in a noisy reference utterance to\nsynthesized speech. Specifically, our NoreSpeech includes several components:\n(1) a novel DiffStyle module, which leverages powerful probabilistic denoising\ndiffusion models to learn noise-agnostic speaking style features from a teacher\nmodel by knowledge distillation; (2) a VQ-VAE block, which maps the style\nfeatures into a controllable quantized latent space for improving the\ngeneralization of style transfer; and (3) a straight-forward but effective\nparameter-free text-style alignment module, which enables NoreSpeech to\ntransfer style to a textual input from a length-mismatched reference utterance.\nExperiments demonstrate that NoreSpeech is more effective than previous\nexpressive TTS models in noise environments. Audio samples and code are\navailable at:\n\\href{this http URL}{this http URL}",
    "descriptor": "\nComments: Submitted to ICASSP2023\n",
    "authors": [
      "Dongchao Yang",
      "Songxiang Liu",
      "Jianwei Yu",
      "Helin Wang",
      "Chao Weng",
      "Yuexian Zou"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.02448"
  },
  {
    "id": "arXiv:2211.02451",
    "title": "Collaborative Multiobjective Evolutionary Algorithms in search of better  Pareto Fronts. An application to trading systems",
    "abstract": "Technical indicators use graphic representations of data sets by applying\nvarious mathematical formulas to financial time series of prices. These\nformulas comprise a set of rules and parameters whose values are not\nnecessarily known and depend on many factors: the market in which it operates,\nthe size of the time window, and others. This paper focuses on the real-time\noptimization of the parameters applied for analyzing time series of data. In\nparticular, we optimize the parameters of technical and financial indicators\nand propose other applications, such as glucose time series. We propose the\ncombination of several Multi-objective Evolutionary Algorithms (MOEAs). Unlike\nother approaches, this paper applies a set of different MOEAs, collaborating to\nconstruct a global Pareto Set of solutions. Solutions for financial problems\nseek high returns with minimal risk. The optimization process is continuous and\noccurs at the same frequency as the investment time interval. This technique\npermits the application of non-dominated solutions obtained with different\nMOEAs simultaneously. Experimental results show that this technique increases\nthe returns of the commonly used Buy \\& Hold strategy and other multi-objective\nstrategies, even for daily operations.",
    "descriptor": "",
    "authors": [
      "Francisco J. Soltero",
      "Pablo Fern\u00e1ndez-Blanco",
      "J. Ignacio Hidalgo"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.02451"
  },
  {
    "id": "arXiv:2211.02452",
    "title": "Agent-update Models",
    "abstract": "In dynamic epistemic logic (Van Ditmarsch et al., 2008) it is customary to\nuse an action model (Baltag and Moss, 2004; Baltag et al., 1998) to describe\ndifferent views of a single action. In this article, action models are extended\nto add or remove agents, we call these agent-update models. This can be done\nselectively so that only some specified agents get information of the update,\nwhich can be used to model several interesting examples such as private update\nand deception, studied earlier by Baltag and Moss (2004); Sakama (2015); Van\nDitmarsch et al. (2012). The product update of a Kripke model by an action\nmodel is an abbreviated way of describing the transformed Kripke model which is\nthe result of performing the action. This is extended to a sum-product update\nof a Kripke model by an agent-update model in the new setting. We show that\ndynamic doxastic logic with action modalities, now based on agent-update\nmodels, continues to have a sound and complete proof system. We have simple\ndecision procedures for model checking and validity.",
    "descriptor": "",
    "authors": [
      "Shikha Singh",
      "Kamal Lodaya",
      "Deepak Khemani"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.02452"
  },
  {
    "id": "arXiv:2211.02459",
    "title": "PCQA-GRAPHPOINT: Efficients Deep-Based Graph Metric For Point Cloud  Quality Assessment",
    "abstract": "Following the advent of immersive technologies and the increasing interest in\nrepresenting interactive geometrical format, 3D Point Clouds (PC) have emerged\nas a promising solution and effective means to display 3D visual information.\nIn addition to other challenges in immersive applications, objective and\nsubjective quality assessments of compressed 3D content remain open problems\nand an area of research interest. Yet most of the efforts in the research area\nignore the local geometrical structures between points representation. In this\npaper, we overcome this limitation by introducing a novel and efficient\nobjective metric for Point Clouds Quality Assessment, by learning local\nintrinsic dependencies using Graph Neural Network (GNN). To evaluate the\nperformance of our method, two well-known datasets have been used. The results\ndemonstrate the effectiveness and reliability of our solution compared to\nstate-of-the-art metrics.",
    "descriptor": "",
    "authors": [
      "Marouane Tliba",
      "Aladine Chetouani",
      "Giuseppe Valenzise",
      "Frederic Dufaux"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.02459"
  },
  {
    "id": "arXiv:2211.02466",
    "title": "Network Aware Compute and Memory Allocation in Optically Composable Data  Centres with Deep Reinforcement Learning and Graph Neural Networks",
    "abstract": "Resource-disaggregated data centre architectures promise a means of pooling\nresources remotely within data centres, allowing for both more flexibility and\nresource efficiency underlying the increasingly important\ninfrastructure-as-a-service business. This can be accomplished by means of\nusing an optically circuit switched backbone in the data centre network (DCN);\nproviding the required bandwidth and latency guarantees to ensure reliable\nperformance when applications are run across non-local resource pools. However,\nresource allocation in this scenario requires both server-level \\emph{and}\nnetwork-level resource to be co-allocated to requests. The online nature and\nunderlying combinatorial complexity of this problem, alongside the typical\nscale of DCN topologies, makes exact solutions impossible and heuristic based\nsolutions sub-optimal or non-intuitive to design. We demonstrate that\n\\emph{deep reinforcement learning}, where the policy is modelled by a\n\\emph{graph neural network} can be used to learn effective \\emph{network-aware}\nand \\emph{topologically-scalable} allocation policies end-to-end. Compared to\nstate-of-the-art heuristics for network-aware resource allocation, the method\nachieves up to $20\\%$ higher acceptance ratio; can achieve the same acceptance\nratio as the best performing heuristic with $3\\times$ less networking resources\navailable and can maintain all-around performance when directly applied (with\nno further training) to DCN topologies with $10^2\\times$ more servers than the\ntopologies seen during training.",
    "descriptor": "\nComments: 10 pages + 1 appendix page, 8 figures\n",
    "authors": [
      "Zacharaya Shabka",
      "Georgios Zervas"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02466"
  },
  {
    "id": "arXiv:2211.02468",
    "title": "Improving Adversarial Robustness to Sensitivity and Invariance Attacks  with Deep Metric Learning",
    "abstract": "Intentionally crafted adversarial samples have effectively exploited\nweaknesses in deep neural networks. A standard method in adversarial robustness\nassumes a framework to defend against samples crafted by minimally perturbing a\nsample such that its corresponding model output changes. These sensitivity\nattacks exploit the model's sensitivity toward task-irrelevant features.\nAnother form of adversarial sample can be crafted via invariance attacks, which\nexploit the model underestimating the importance of relevant features. Previous\nliterature has indicated a tradeoff in defending against both attack types\nwithin a strictly L_p bounded defense. To promote robustness toward both types\nof attacks beyond Euclidean distance metrics, we use metric learning to frame\nadversarial regularization as an optimal transport problem. Our preliminary\nresults indicate that regularizing over invariant perturbations in our\nframework improves both invariant and sensitivity defense.",
    "descriptor": "\nComments: v1\n",
    "authors": [
      "Anaelia Ovalle",
      "Evan Czyzycki",
      "Cho-Jui Hsieh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.02468"
  },
  {
    "id": "arXiv:2211.02477",
    "title": "SMAuC -- The Scientific Multi-Authorship Corpus",
    "abstract": "With an ever-growing number of new publications each day, scientific writing\nposes an interesting domain for authorship analysis of both single-author and\nmulti-author documents. Unfortunately, most existing corpora lack either\nmaterial from the science domain or the required metadata. Hence, we present\nSMAuC, a new metadata-rich corpus designed specifically for authorship analysis\nin scientific writing. With more than three million publications from various\nscientific disciplines, SMAuC is the largest openly available corpus for\nauthorship analysis to date. It combines a wide and diverse range of scientific\ntexts from the humanities and natural sciences with rich and curated metadata,\nincluding unique and carefully disambiguated author IDs. We hope SMAuC will\ncontribute significantly to advancing the field of authorship analysis in the\nscience domain.",
    "descriptor": "",
    "authors": [
      "Philipp Sauer",
      "Janek Bevendorff",
      "Lukas Gienapp",
      "Wolfgang Kircheis",
      "Erik K\u00f6rner",
      "Benno Stein",
      "Martin Potthast"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2211.02477"
  },
  {
    "id": "arXiv:2211.02480",
    "title": "Characterization of optimal binary linear codes with one-dimensional  hull",
    "abstract": "The hull of a linear code over finite fields is the intersection of the code\nand its dual. Linear codes with small hulls have been widely studied due to\ntheir applications in computational complexity and information protection. In\nthis paper, we study some properties of binary linear codes with\none-dimensional hull, and establish their relation with binary LCD codes. Some\ninteresting inequalities are thus obtained. We determine the exact value of\n$d_{one}(n,k)$ for $k\\in\\{1,3,4,n-5,n-4,n-3,n-2,n-1\\}$ or $14\\leq n\\leq 24$,\nwhere $d_{one}(n,k)$ denotes the largest minimum weight among all binary linear\n$[n,k]$ codes with one-dimensional hull. We partially determine the value of\n$d_{one}(n,k)$ for $k=5$ or $25\\leq n\\leq 30$. As an application, we construct\nsome entanglement-assisted quantum error-correcting codes (EAQECCs).",
    "descriptor": "",
    "authors": [
      "Shitao Li",
      "Minjia Shi",
      "Jon-Lark Kim"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.02480"
  },
  {
    "id": "arXiv:2211.02483",
    "title": "Continuous Prompt Tuning Based Textual Entailment Model for E-commerce  Entity Typing",
    "abstract": "The explosion of e-commerce has caused the need for processing and analysis\nof product titles, like entity typing in product titles. However, the rapid\nactivity in e-commerce has led to the rapid emergence of new entities, which is\ndifficult to be solved by general entity typing. Besides, product titles in\ne-commerce have very different language styles from text data in general\ndomain. In order to handle new entities in product titles and address the\nspecial language styles problem of product titles in e-commerce domain, we\npropose our textual entailment model with continuous prompt tuning based\nhypotheses and fusion embeddings for e-commerce entity typing. First, we\nreformulate the entity typing task into a textual entailment problem to handle\nnew entities that are not present during training. Second, we design a model to\nautomatically generate textual entailment hypotheses using a continuous prompt\ntuning method, which can generate better textual entailment hypotheses without\nmanual design. Third, we utilize the fusion embeddings of BERT embedding and\nCharacterBERT embedding with a two-layer MLP classifier to solve the problem\nthat the language styles of product titles in e-commerce are different from\nthat of general domain. To analyze the effect of each contribution, we compare\nthe performance of entity typing and textual entailment model, and conduct\nablation studies on continuous prompt tuning and fusion embeddings. We also\nevaluate the impact of different prompt template initialization for the\ncontinuous prompt tuning. We show our proposed model improves the average F1\nscore by around 2% compared to the baseline BERT entity typing model.",
    "descriptor": "",
    "authors": [
      "Yibo Wang",
      "Congying Xia",
      "Guan Wang",
      "Philip Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.02483"
  },
  {
    "id": "arXiv:2211.02484",
    "title": "An improved high-order method for elliptic multiscale problems",
    "abstract": "In this work, we propose a high-order multiscale method for an elliptic model\nproblem with rough and possibly highly oscillatory coefficients. Convergence\nrates of higher order are obtained using the regularity of the right-hand side\nonly. Hence, no restrictive assumptions on the coefficient, the domain, or the\nexact solution are required. In the spirit of the Localized Orthogonal\nDecomposition, the method constructs coarse problem-adapted ansatz spaces by\nsolving auxiliary problems on local subdomains. More precisely, our approach is\nbased on the strategy presented by Maier [SIAM J. Numer. Anal. 59(2), 2021].\nThe unique selling point of the proposed method is an improved localization\nstrategy curing the effect of deteriorating errors with respect to the mesh\nsize when the local subdomains are not large enough. We present a rigorous a\npriori error analysis and demonstrate the performance of the method in a series\nof numerical experiments.",
    "descriptor": "\nComments: 18 pages, 4 figures\n",
    "authors": [
      "Zhaonan Dong",
      "Moritz Hauck",
      "Roland Maier"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.02484"
  },
  {
    "id": "arXiv:2211.02487",
    "title": "Flows for Flows: Training Normalizing Flows Between Arbitrary  Distributions with Maximum Likelihood Estimation",
    "abstract": "Normalizing flows are constructed from a base distribution with a known\ndensity and a diffeomorphism with a tractable Jacobian. The base density of a\nnormalizing flow can be parameterised by a different normalizing flow, thus\nallowing maps to be found between arbitrary distributions. We demonstrate and\nexplore the utility of this approach and show it is particularly interesting in\nthe case of conditional normalizing flows and for introducing optimal transport\nconstraints on maps that are constructed using normalizing flows.",
    "descriptor": "",
    "authors": [
      "Samuel Klein",
      "John Andrew Raine",
      "Tobias Golling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02487"
  },
  {
    "id": "arXiv:2211.02499",
    "title": "A Weakly-Supervised Streaming Multilingual Speech Model with Truly  Zero-Shot Capability",
    "abstract": "In this paper, we introduce our work of building a Streaming Multilingual\nSpeech Model (SM2), which can transcribe or translate multiple spoken languages\ninto texts of the target language. The backbone of SM2 is Transformer\nTransducer, which has high streaming capability. Instead of human labeled\nspeech translation (ST) data, SM2 models are trained using weakly supervised\ndata generated by converting the transcriptions in speech recognition corpora\nwith a machine translation service. With 351 thousand hours of anonymized\nspeech training data from 25 languages, SM2 models achieve comparable or even\nbetter ST quality than some recent popular large-scale non-streaming speech\nmodels. More importantly, we show that SM2 has the truly zero-shot capability\nwhen expanding to new target languages, yielding high quality ST results for\n{source-speech, target-text} pairs that are not seen during training.",
    "descriptor": "\nComments: submitted to ICASSP 2023\n",
    "authors": [
      "Jian Xue",
      "Peidong Wang",
      "Jinyu Li",
      "Eric Sun"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.02499"
  },
  {
    "id": "arXiv:2211.02501",
    "title": "Weisfeiler and Leman go Hyperbolic: Learning Distance Preserving Node  Representations",
    "abstract": "In recent years, graph neural networks (GNNs) have emerged as a promising\ntool for solving machine learning problems on graphs. Most GNNs are members of\nthe family of message passing neural networks (MPNNs). There is a close\nconnection between these models and the Weisfeiler-Leman (WL) test of\nisomorphism, an algorithm that can successfully test isomorphism for a broad\nclass of graphs. Recently, much research has focused on measuring the\nexpressive power of GNNs. For instance, it has been shown that standard MPNNs\nare at most as powerful as WL in terms of distinguishing non-isomorphic graphs.\nHowever, these studies have largely ignored the distances between the\nrepresentations of nodes/graphs which are of paramount importance for learning\ntasks. In this paper, we define a distance function between nodes which is\nbased on the hierarchy produced by the WL algorithm, and propose a model that\nlearns representations which preserve those distances between nodes. Since the\nemerging hierarchy corresponds to a tree, to learn these representations, we\ncapitalize on recent advances in the field of hyperbolic neural networks. We\nempirically evaluate the proposed model on standard node and graph\nclassification datasets where it achieves competitive performance with\nstate-of-the-art models.",
    "descriptor": "",
    "authors": [
      "Giannis Nikolentzos",
      "Michail Chatzianastasis",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02501"
  },
  {
    "id": "arXiv:2211.02504",
    "title": "Geometry-Complete Perceptron Networks for 3D Molecular Graphs",
    "abstract": "The field of geometric deep learning has had a profound impact on the\ndevelopment of innovative and powerful graph neural network architectures.\nDisciplines such as computer vision and computational biology have benefited\nsignificantly from such methodological advances, which has led to breakthroughs\nin scientific domains such as protein structure prediction and design. In this\nwork, we introduce GCPNet, a new geometry-complete, SE(3)-equivariant graph\nneural network designed for 3D graph representation learning. We demonstrate\nthe state-of-the-art utility and expressiveness of our method on six\nindependent datasets designed for three distinct geometric tasks:\nprotein-ligand binding affinity prediction, protein structure ranking, and\nNewtonian many-body systems modeling. Our results suggest that GCPNet is a\npowerful, general method for capturing complex geometric and physical\ninteractions within 3D graphs for downstream prediction tasks. The source code,\ndata, and instructions to train new models or reproduce our results are freely\navailable on GitHub.",
    "descriptor": "\nComments: 7 pages, 1 figure, 3 tables. Under review. Code available at this https URL\n",
    "authors": [
      "Alex Morehead",
      "Jianlin Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)",
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.02504"
  },
  {
    "id": "arXiv:2211.02508",
    "title": "A weighted Hybridizable Discontinuous Galerkin method for  drift-diffusion problems",
    "abstract": "In this work we propose a weighted hybridizable discontinuous Galerkin method\n(W-HDG) for drift-diffusion problems. By using specific exponential weights\nwhen computing the $L^2$ product in each cell of the discretization, we are\nable to replicate the behavior of the Slotboom change of variables, and\neliminate the drift term from the local matrix contributions. We show that the\nproposed numerical scheme is well-posed, and numerically validates that it has\nthe same properties of classical HDG methods, including optimal convergence,\nand superconvergence of postprocessed solutions. For polynomial degree zero,\ndimension one, and vanishing HDG stabilization parameter, W-HDG coincides with\nthe Scharfetter-Gummel stabilized finite volume scheme (i.e., it produces the\nsame system matrix). The use of local exponential weights generalizes the\nScharfetter-Gummel stabilization (the state-of-the-art for Finite Volume\ndiscretization of transport-dominated problems) to arbitrary high-order\napproximations.",
    "descriptor": "\nComments: 27 pages, 4 figures, 4 tables\n",
    "authors": [
      "Wenyu Lei",
      "Stefano Piani",
      "Patricio Farrell",
      "Nella Rotundo",
      "Luca Heltai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.02508"
  },
  {
    "id": "arXiv:2211.02516",
    "title": "Singlularity Avoidance with Application to Online Trajectory  Optimization for Serial Manipulators",
    "abstract": "This work proposes a novel singularity avoidance approach for real-time\ntrajectory optimization based on known singular configurations. The focus of\nthis work lies on analyzing kinematically singular configurations for three\nrobots with different kinematic structures, i.e., the Comau Racer 7-1.4, the\nKUKA LBR iiwa R820, and the Franka Emika Panda, and exploiting these\nconfigurations in form of tailored potential functions for singularity\navoidance. Monte Carlo simulations of the proposed method and the commonly used\nmanipulability maximization approach are performed for comparison. The\nnumerical results show that the average computing time can be reduced and\nshorter trajectories in both time and path length are obtained with the\nproposed approach",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "Florian Beck",
      "Minh Nhat Vu",
      "Christian Hartl-Nesic",
      "Andreas Kugi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.02516"
  },
  {
    "id": "arXiv:2211.02519",
    "title": "BERT for Long Documents: A Case Study of Automated ICD Coding",
    "abstract": "Transformer models have achieved great success across many NLP problems.\nHowever, previous studies in automated ICD coding concluded that these models\nfail to outperform some of the earlier solutions such as CNN-based models. In\nthis paper we challenge this conclusion. We present a simple and scalable\nmethod to process long text with the existing transformer models such as BERT.\nWe show that this method significantly improves the previous results reported\nfor transformer models in ICD coding, and is able to outperform one of the\nprominent CNN-based methods.",
    "descriptor": "",
    "authors": [
      "Arash Afkanpour",
      "Shabir Adeel",
      "Hansenclever Bassani",
      "Arkady Epshteyn",
      "Hongbo Fan",
      "Isaac Jones",
      "Mahan Malihi",
      "Adrian Nauth",
      "Raj Sinha",
      "Sanjana Woonna",
      "Shiva Zamani",
      "Elli Kanal",
      "Mikhail Fomitchev",
      "Donny Cheung"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02519"
  },
  {
    "id": "arXiv:2211.02524",
    "title": "Open Multi-Access Network Platform with Dynamic Task Offloading and  Intelligent Resource Monitoring",
    "abstract": "We constructed an open multi-access network platform using open-source\nhardware and software. The open multi-access network platform is characterized\nby the flexible utilization of network functions, integral management and\ncontrol of wired and wireless access networks, zero-touch provisioning,\nintelligent resource monitoring, and dynamic task offloading. We also propose\nan application-driven dynamic task offloading that utilizes intelligent\nresource monitoring to ensure effective task processing in edge and cloud\nservers. For this purpose, we developed a mobile application and server\napplications for the open multi-access network platform. To investigate the\nfeasibility and availability of our developed platform, we experimentally and\nanalytically evaluated the effectiveness of application-driven dynamic task\noffloading and intelligent resource monitoring. The experimental results\ndemonstrated that application-driven dynamic task offloading could reduce\nreal-time task response time and traffic over metro and core networks.",
    "descriptor": "",
    "authors": [
      "Takuji Tachibana",
      "Kazuki Sawada",
      "Hiroyuki Fujii",
      "Ryo Maruyama",
      "Tomonori Yamada",
      "Masaaki Fujii",
      "Toshimichi Fukuda"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.02524"
  },
  {
    "id": "arXiv:2211.02529",
    "title": "An Image-Space Split-Rendering Approach to Accelerate Low-Powered  Virtual Reality",
    "abstract": "Virtual Reality systems provide many opportunities for scientific research\nand consumer enjoyment; however, they are more demanding than traditional\ndesktop applications and require a wired connection to desktops in order to\nenjoy maximum quality. Standalone options that are not connected to computers\nexist, yet they are powered by mobile GPUs, which provide limited power in\ncomparison to desktop rendering. Alternative approaches to improve performance\non mobile devices use server rendering to render frames for a client and treat\nthe client largely as a display device. However, current streaming solutions\nlargely suffer from high end-to-end latency due to processing and networking\nrequirements, as well as underutilization of the client. We propose a networked\nsplit-rendering approach to achieve faster end-to-end image presentation rates\non the mobile device while preserving image quality. Our proposed solution uses\nan image-space division of labour between the server-side GPU and the mobile\nclient, and achieves a significantly faster runtime than client-only rendering\nand than using a thin-client approach, which is mostly reliant on the server.",
    "descriptor": "",
    "authors": [
      "Ville Cantory",
      "Nathan Ringo"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.02529"
  },
  {
    "id": "arXiv:2211.02530",
    "title": "Automatic classification of deformable shapes",
    "abstract": "Let $\\mathcal{D}$ be a dataset of smooth 3D-surfaces, partitioned into\ndisjoint classes $\\mathit{CL}_j$, $j= 1, \\ldots, k$. We show how optimized\ndiffeomorphic registration applied to large numbers of pairs $S,S' \\in\n\\mathcal{D}$ can provide descriptive feature vectors to implement automatic\nclassification on $\\mathcal{D}$, and generate classifiers invariant by rigid\nmotions in $\\mathbb{R}^3$. To enhance accuracy of automatic classification, we\nenrich the smallest classes $\\mathit{CL}_j$ by diffeomorphic interpolation of\nsmooth surfaces between pairs $S,S' \\in \\mathit{CL}_j$. We also implement small\nrandom perturbations of surfaces $S\\in \\mathit{CL}_j$ by random flows of smooth\ndiffeomorphisms $F_t:\\mathbb{R}^3 \\to \\mathbb{R}^3$. Finally, we test our\nautomatic classification methods on a cardiology data base of discretized\nmitral valve surfaces.",
    "descriptor": "\nComments: 29 pages; 8 figures; one table\n",
    "authors": [
      "Hossein Dabirian",
      "Radmir Sultamuratov",
      "James Herring",
      "Carlos El Tallawi",
      "William Zoghbi",
      "Andreas Mang",
      "Robert Azencott"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.02530"
  },
  {
    "id": "arXiv:2211.02533",
    "title": "A Transformer-Based Substitute Recommendation Model Incorporating Weakly  Supervised Customer Behavior Data",
    "abstract": "The substitute-based recommendation is widely used in E-commerce to provide\nbetter alternatives to customers. However, existing research typically uses the\ncustomer behavior signals like co-view and view-but-purchase-another to capture\nthe substitute relationship. Despite its intuitive soundness, we find that such\nan approach might ignore the functionality and characteristics of products. In\nthis paper, we adapt substitute recommendation into language matching problem\nby taking product title description as model input to consider product\nfunctionality. We design a new transformation method to de-noise the signals\nderived from production data. In addition, we consider multilingual support\nfrom the engineering point of view. Our proposed end-to-end transformer-based\nmodel achieves both successes from offline and online experiments. The proposed\nmodel has been deployed in a large-scale E-commerce website for 11 marketplaces\nin 6 languages. Our proposed model is demonstrated to increase revenue by 19%\nbased on an online A/B experiment.",
    "descriptor": "\nComments: 6 pages, 3 figures, 5 tables, accepted in 21st IEEE International Conference on Machine Learning and Applications\n",
    "authors": [
      "Wenting Ye",
      "Hongfei Yang",
      "Shuai Zhao",
      "Haoyang Fang",
      "Xingjian Shi",
      "Naveen Neppalli"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02533"
  },
  {
    "id": "arXiv:2211.02536",
    "title": "Biased Self-supervised learning for ASR",
    "abstract": "Self-supervised learning via masked prediction pre-training (MPPT) has shown\nimpressive performance on a range of speech-processing tasks. This paper\nproposes a method to bias self-supervised learning towards a specific task. The\ncore idea is to slightly finetune the model that is used to obtain the target\nsequence. This leads to better performance and a substantial increase in\ntraining speed. Furthermore, this paper proposes a variant of MPPT that allows\nlow-footprint streaming models to be trained effectively by computing the MPPT\nloss on masked and unmasked frames. These approaches are evaluated for\nautomatic speech recognition on the Librispeech corpus, where 100 hours of data\nserved as the labelled data and 860 hours as the unlabelled data. The biased\ntraining outperforms the unbiased training by 15.5% after 250k updates and\n23.8% after 100k updates on test-other. For the streaming models, the\npre-training approach yields a reduction in word error rate of 44.1%.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Florian L. Kreyssig",
      "Yangyang Shi",
      "Jinxi Guo",
      "Leda Sari",
      "Abdelrahman Mohamed",
      "Philip C. Woodland"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.02536"
  },
  {
    "id": "arXiv:2211.02537",
    "title": "Machine Learning Challenges of Biological Factors in Insect Image Data",
    "abstract": "The BIOSCAN project, led by the International Barcode of Life Consortium,\nseeks to study changes in biodiversity on a global scale. One component of the\nproject is focused on studying the species interaction and dynamics of all\ninsects. In addition to genetically barcoding insects, over 1.5 million images\nper year will be collected, each needing taxonomic classification. With the\nimmense volume of incoming images, relying solely on expert taxonomists to\nlabel the images would be impossible; however, artificial intelligence and\ncomputer vision technology may offer a viable high-throughput solution.\nAdditional tasks including manually weighing individual insects to determine\nbiomass, remain tedious and costly. Here again, computer vision may offer an\nefficient and compelling alternative. While the use of computer vision methods\nis appealing for addressing these problems, significant challenges resulting\nfrom biological factors present themselves. These challenges are formulated in\nthe context of machine learning in this paper.",
    "descriptor": "\nComments: 4 pages, 3 figures. Submitted to the Journal of Computational Vision and Imaging Systems\n",
    "authors": [
      "Nicholas Pellegrino",
      "Zahra Gharaee",
      "Paul Fieguth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2211.02537"
  },
  {
    "id": "arXiv:2211.02538",
    "title": "An information theoretic vulnerability metric for data integrity attacks  on smart grids",
    "abstract": "A novel metric that describes the vulnerability of the measurements in power\nsystems to data integrity attacks is proposed. The new metric, coined\nvulnerability index (VuIx), leverages information theoretic measures to assess\nthe attack effect on the fundamental limits of the disruption and detection\ntradeoff. The result of computing the VuIx of the measurements in the system\nyields an ordering of their vulnerability based on the level of exposure to\ndata integrity attacks. This new framework is used to assess the measurement\nvulnerability of IEEE 9-bus and 30-bus test systems and it is observed that\npower injection measurements are overwhelmingly more vulnerable to data\nintegrity attacks than power flow measurements. A detailed numerical evaluation\nof the VuIx values for IEEE test systems is provided.",
    "descriptor": "\nComments: 7 pages, 10 figures, submitted to IET Smart Grid. arXiv admin note: substantial text overlap with arXiv:2207.06973\n",
    "authors": [
      "Xiuzhen Ye",
      "I\u00f1aki Esnaola",
      "Samir M. Perlaza",
      "Robert F. Harrison"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.02538"
  },
  {
    "id": "arXiv:2211.02541",
    "title": "Generation of Chinese classical poetry based on pre-trained model",
    "abstract": "In order to test whether artificial intelligence can create qualified\nclassical poetry like humans, the author proposes a study of Chinese classical\npoetry generation based on a pre-trained model. This paper mainly tries to use\nBART and other pre training models, proposes FS2TEXT and RR2TEXT to generate\nmetrical poetry text and even specific style poetry text, and solves the\nproblem that the user's writing intention gradually reduces the relevance of\nthe generated poetry text.\nIn order to test the model's results, the authors selected ancient poets, by\ncombining it with BART's poetic model work, developed a set of AI poetry Turing\nproblems, it was reviewed by a group of poets and poetry writing researchers.\nThere were more than 600 participants, and the final results showed that,\nhigh-level poetry lovers can't distinguish between AI activity and human\nactivity, this indicates that the author's working methods are not\nsignificantly different from human activities. The model of poetry generation\nstudied by the author generalizes works that cannot be distinguished from those\nof advanced scholars.\nThe number of modern Chinese poets has reached 5 million. However, many\nmodern Chinese poets lack language ability and skills as a result of their\nchildhood learning. However, many modern poets have no creative inspiration,\nand the author's model can help them. They can look at this model when they\nchoose words and phrases and they can write works based on the poems they\nalready have, and they can write their own poems. The importance of poetry lies\nin the author's thoughts and reflections. It doesn't matter how good AI poetry\nis. The only thing that matters is for people to see and inspire them.",
    "descriptor": "\nComments: 8 pages,2 figures\n",
    "authors": [
      "Ziyao Wang",
      "Lujin Guan",
      "Guanyu Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.02541"
  },
  {
    "id": "arXiv:2211.02545",
    "title": "GoRela: Go Relative for Viewpoint-Invariant Motion Forecasting",
    "abstract": "The task of motion forecasting is critical for self-driving vehicles (SDVs)\nto be able to plan a safe maneuver. Towards this goal, modern approaches reason\nabout the map, the agents' past trajectories and their interactions in order to\nproduce accurate forecasts. The predominant approach has been to encode the map\nand other agents in the reference frame of each target agent. However, this\napproach is computationally expensive for multi-agent prediction as inference\nneeds to be run for each agent. To tackle the scaling challenge, the solution\nthus far has been to encode all agents and the map in a shared coordinate frame\n(e.g., the SDV frame). However, this is sample inefficient and vulnerable to\ndomain shift (e.g., when the SDV visits uncommon states). In contrast, in this\npaper, we propose an efficient shared encoding for all agents and the map\nwithout sacrificing accuracy or generalization. Towards this goal, we leverage\npair-wise relative positional encodings to represent geometric relationships\nbetween the agents and the map elements in a heterogeneous spatial graph. This\nparameterization allows us to be invariant to scene viewpoint, and save online\ncomputation by re-using map embeddings computed offline. Our decoder is also\nviewpoint agnostic, predicting agent goals on the lane graph to enable diverse\nand context-aware multimodal prediction. We demonstrate the effectiveness of\nour approach on the urban Argoverse 2 benchmark as well as a novel highway\ndataset.",
    "descriptor": "",
    "authors": [
      "Alexander Cui",
      "Sergio Casas",
      "Kelvin Wong",
      "Simon Suo",
      "Raquel Urtasun"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.02545"
  },
  {
    "id": "arXiv:2211.02558",
    "title": "A Data-Driven Slip Estimation Approach for Effective Braking Control  under Varying Road Conditions",
    "abstract": "The performances of braking control systems for robotic platforms, e.g.,\nassisted and autonomous vehicles, airplanes and drones, are deeply influenced\nby the road-tire friction experienced during the maneuver. Therefore, the\navailability of accurate estimation algorithms is of major importance in the\ndevelopment of advanced control schemes. The focus of this paper is on the\nestimation problem. In particular, a novel estimation algorithm is proposed,\nbased on a multi-layer neural network. The training is based on a synthetic\ndata set, derived from a widely used friction model. The open loop performances\nof the proposed algorithm are evaluated in a number of simulated scenarios.\nMoreover, different control schemes are used to test the closed loop scenario,\nwhere the estimated optimal slip is used as the set-point. The experimental\nresults and the comparison with a model based baseline show that the proposed\napproach can provide an effective best slip estimation.",
    "descriptor": "",
    "authors": [
      "F. Crocetti",
      "G. Costante",
      "M.L. Fravolini",
      "P. Valigi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.02558"
  },
  {
    "id": "arXiv:2211.02561",
    "title": "An Improved Time Feedforward Connections Recurrent Neural Networks",
    "abstract": "Recurrent Neural Networks (RNNs) have been widely applied to deal with\ntemporal problems, such as flood forecasting and financial data processing. On\nthe one hand, traditional RNNs models amplify the gradient issue due to the\nstrict time serial dependency, making it difficult to realize a long-term\nmemory function. On the other hand, RNNs cells are highly complex, which will\nsignificantly increase computational complexity and cause waste of\ncomputational resources during model training. In this paper, an improved Time\nFeedforward Connections Recurrent Neural Networks (TFC-RNNs) model was first\nproposed to address the gradient issue. A parallel branch was introduced for\nthe hidden state at time t-2 to be directly transferred to time t without the\nnonlinear transformation at time t-1. This is effective in improving the\nlong-term dependence of RNNs. Then, a novel cell structure named Single Gate\nRecurrent Unit (SGRU) was presented. This cell structure can reduce the number\nof parameters for RNNs cell, consequently reducing the computational\ncomplexity. Next, applying SGRU to TFC-RNNs as a new TFC-SGRU model solves the\nabove two difficulties. Finally, the performance of our proposed TFC-SGRU was\nverified through several experiments in terms of long-term memory and\nanti-interference capabilities. Experimental results demonstrated that our\nproposed TFC-SGRU model can capture helpful information with time step 1500 and\neffectively filter out the noise. The TFC-SGRU model accuracy is better than\nthe LSTM and GRU models regarding language processing ability.",
    "descriptor": "",
    "authors": [
      "Jin Wang",
      "Yongsong Zou",
      "Se-Jung Lim"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02561"
  },
  {
    "id": "arXiv:2211.02562",
    "title": "Space-time finite element methods for distributed optimal control of the  wave equation",
    "abstract": "We consider space-time tracking type distributed optimal control problems for\nthe wave equation in the space-time domain $Q:= \\Omega \\times (0,T) \\subset\n{\\mathbb{R}}^{n+1}$, where the control is assumed to be in the energy space\n$[H_{0;,0}^{1,1}(Q)]^*$, rather than in $L^2(Q)$ which is more common. While\nthe latter ensures a unique state in the Sobolev space $H^{1,1}_{0;0,}(Q)$,\nthis does not define a solution isomorphism. Hence we use an appropriate state\nspace $X$ such that the wave operator becomes an isomorphism from $X$ onto\n$[H_{0;,0}^{1,1}(Q)]^*$. Using space-time finite element spaces of piecewise\nlinear continuous basis functions on completely unstructured but shape regular\nsimplicial meshes, we derive a priori estimates for the error\n$\\|\\widetilde{u}_{\\varrho h}-\\overline{u}\\|_{L^2(Q)}$ between the computed\nspace-time finite element solution $\\widetilde{u}_{\\varrho h}$ and the target\nfunction $\\overline{u}$ with respect to the regularization parameter $\\varrho$,\nand the space-time finite element mesh-size $h$, depending on the regularity of\nthe desired state $\\overline{u}$. These estimates lead to the optimal choice\n$\\varrho=h^2$ in order to define the regularization parameter $\\varrho$ for a\ngiven space-time finite element mesh size $h$, or to determine the required\nmesh size $h$ when $\\varrho$ is a given constant representing the costs of the\ncontrol. The theoretical results will be supported by numerical examples with\ntargets of different regularities, including discontinuous targets.\nFurthermore, an adaptive space-time finite element scheme is proposed and\nnumerically analyzed.",
    "descriptor": "",
    "authors": [
      "Richard L\u00f6scher",
      "Olaf Steinbach"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.02562"
  },
  {
    "id": "arXiv:2211.02563",
    "title": "A Comparison of SVM against Pre-trained Language Models (PLMs) for Text  Classification Tasks",
    "abstract": "The emergence of pre-trained language models (PLMs) has shown great success\nin many Natural Language Processing (NLP) tasks including text classification.\nDue to the minimal to no feature engineering required when using these models,\nPLMs are becoming the de facto choice for any NLP task. However, for\ndomain-specific corpora (e.g., financial, legal, and industrial), fine-tuning a\npre-trained model for a specific task has shown to provide a performance\nimprovement. In this paper, we compare the performance of four different PLMs\non three public domain-free datasets and a real-world dataset containing\ndomain-specific words, against a simple SVM linear classifier with TFIDF\nvectorized text. The experimental results on the four datasets show that using\nPLMs, even fine-tuned, do not provide significant gain over the linear SVM\nclassifier. Hence, we recommend that for text classification tasks, traditional\nSVM along with careful feature engineering can pro-vide a cheaper and superior\nperformance than PLMs.",
    "descriptor": "",
    "authors": [
      "Yasmen Wahba",
      "Nazim Madhavji",
      "John Steinbacher"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02563"
  },
  {
    "id": "arXiv:2211.02567",
    "title": "KB4VA: A Knowledge Base of Visualization Designs for Visual Analytics",
    "abstract": "Visual analytics (VA) systems have been widely used to facilitate\ndecision-making and analytical reasoning in various application domains. VA\ninvolves visual designs, interaction designs, and data mining, which is a\nsystematic and complex paradigm. In this work, we focus on the design of\neffective visualizations for complex data and analytical tasks, which is a\ncritical step in designing a VA system. This step is challenging because it\nrequires extensive knowledge about domain problems and visualization to design\neffective encodings. Existing visualization designs published in top venues are\nvaluable resources to inspire designs for problems with similar data structures\nand tasks. However, those designs are hard to understand, parse, and retrieve\ndue to the lack of specifications. To address this problem, we build KB4VA, a\nknowledge base of visualization designs in VA systems with comprehensive labels\nabout their analytical tasks and visual encodings. Our labeling scheme is\ninspired by a workshop study with 12 VA researchers to learn user requirements\nin understanding and retrieving professional visualization designs in VA\nsystems. The theme extends Vega-Lite specifications for describing advanced and\ncomposited visualization designs in a declarative manner, thus facilitating\nhuman understanding and automatic indexing. To demonstrate the usefulness of\nour knowledge base, we present a user study about design inspirations for VA\ntasks. In summary, our work opens new perspectives for enhancing the\naccessibility and reusability of professional visualization designs.",
    "descriptor": "",
    "authors": [
      "Dazhen Deng",
      "Aoyu Wu",
      "Haotian Li",
      "Ji Lan",
      "Yong Wang",
      "Huamin Qu",
      "Yingcai Wu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.02567"
  },
  {
    "id": "arXiv:2211.02570",
    "title": "The 'Problem' of Human Label Variation: On Ground Truth in Data,  Modeling and Evaluation",
    "abstract": "Human variation in labeling is often considered noise. Annotation projects\nfor machine learning (ML) aim at minimizing human label variation, with the\nassumption to maximize data quality and in turn optimize and maximize machine\nlearning metrics. However, this conventional practice assumes that there exists\na ground truth, and neglects that there exists genuine human variation in\nlabeling due to disagreement, subjectivity in annotation or multiple plausible\nanswers. In this position paper, we argue that this big open problem of human\nlabel variation persists and critically needs more attention to move our field\nforward. This is because human label variation impacts all stages of the ML\npipeline: data, modeling and evaluation. However, few works consider all of\nthese dimensions jointly; and existing research is fragmented. We reconcile\ndifferent previously proposed notions of human label variation, provide a\nrepository of publicly-available datasets with un-aggregated labels, depict\napproaches proposed so far, identify gaps and suggest ways forward. As datasets\nare becoming increasingly available, we hope that this synthesized view on the\n'problem' will lead to an open discussion on possible strategies to devise\nfundamentally new directions.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Barbara Plank"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02570"
  },
  {
    "id": "arXiv:2211.02571",
    "title": "Benchmark of Bayesian Optimization and Metaheuristics for Control  Engineering Tuning Problems with Crash Constraints",
    "abstract": "Controller tuning based on black-box optimization allows to automatically\ntune performance-critical parameters w.r.t. mostly arbitrary high-level\nclosed-loop control objectives. However, a comprehensive benchmark of different\nblack-box optimizers for control engineering problems has not yet been\nconducted. Therefore, in this contribution, 11 different versions of Bayesian\noptimization (BO) are compared with seven metaheuristics and other baselines on\na set of ten deterministic simulative single-objective tuning problems in\ncontrol. Results indicate that deterministic noise, low multimodality, and\nsubstantial areas with infeasible parametrizations (crash constraints)\ncharacterize control engineering tuning problems. Therefore, a flexible method\nto handle crash constraints with BO is presented. A resulting increase in\nsample efficiency is shown in comparison to standard BO. Furthermore, benchmark\nresults indicate that pattern search (PS) performs best on a budget of 25 d\nobjective function evaluations and a problem dimensionality d of d = 2.\nBayesian adaptive direct search, a combination of BO and PS, is shown to be\nmost sample efficient for 3 <= d <= 5. Using these optimizers instead of random\nsearch increases controller performance by on average 6.6% and up to 16.1%.",
    "descriptor": "\nComments: 13 pages, 9 figures\n",
    "authors": [
      "David Stenger",
      "Dirk Abel"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.02571"
  },
  {
    "id": "arXiv:2211.02574",
    "title": "Pushing AI to Wireless Network Edge: An Overview on Integrated Sensing,  Communication, and Computation towards 6G",
    "abstract": "Pushing artificial intelligence (AI) from central cloud to network edge has\nreached board consensus in both industry and academia for materializing the\nvision of artificial intelligence of things (AIoT) in the sixth-generation (6G)\nera. This gives rise to an emerging research area known as edge intelligence,\nwhich concerns the distillation of human-like intelligence from the huge amount\nof data scattered at wireless network edge. In general, realizing edge\nintelligence corresponds to the process of sensing, communication, and\ncomputation, which are coupled ingredients for data generation, exchanging, and\nprocessing, respectively. However, conventional wireless networks design the\nsensing, communication, and computation separately in a task-agnostic manner,\nwhich encounters difficulties in accommodating the stringent demands of\nultra-low latency, ultra-high reliability, and high capacity in emerging AI\napplications such as auto-driving. This thus prompts a new design paradigm of\nseamless integrated sensing, communication, and computation (ISCC) in a\ntask-oriented manner, which comprehensively accounts for the use of the data in\nthe downstream AI applications. In view of its growing interest, this article\nprovides a timely overview of ISCC for edge intelligence by introducing its\nbasic concept, design challenges, and enabling techniques, surveying the\nstate-of-the-art development, and shedding light on the road ahead.",
    "descriptor": "",
    "authors": [
      "Guangxu Zhu",
      "Zhonghao Lyu",
      "Xiang Jiao",
      "Peixi Liu",
      "Mingzhe Chen",
      "Jie Xu",
      "Shuguang Cui",
      "Ping Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.02574"
  },
  {
    "id": "arXiv:2211.02578",
    "title": "Data Models for Dataset Drift Controls in Machine Learning With Images",
    "abstract": "Camera images are ubiquitous in machine learning research. They also play a\ncentral role in the delivery of important services spanning medicine and\nenvironmental surveying. However, the application of machine learning models in\nthese domains has been limited because of robustness concerns. A primary\nfailure mode are performance drops due to differences between the training and\ndeployment data. While there are methods to prospectively validate the\nrobustness of machine learning models to such dataset drifts, existing\napproaches do not account for explicit models of the primary object of\ninterest: the data. This makes it difficult to create physically faithful drift\ntest cases or to provide specifications of data models that should be avoided\nwhen deploying a machine learning model. In this study, we demonstrate how\nthese shortcomings can be overcome by pairing machine learning robustness\nvalidation with physical optics. We examine the role raw sensor data and\ndifferentiable data models can play in controlling performance risks related to\nimage dataset drift. The findings are distilled into three applications. First,\ndrift synthesis enables the controlled generation of physically faithful drift\ntest cases. The experiments presented here show that the average decrease in\nmodel performance is ten to four times less severe than under post-hoc\naugmentation testing. Second, the gradient connection between task and data\nmodels allows for drift forensics that can be used to specify\nperformance-sensitive data models which should be avoided during deployment of\na machine learning model. Third, drift adjustment opens up the possibility for\nprocessing adjustments in the face of drift. This can lead to speed up and\nstabilization of classifier training at a margin of up to 20% in validation\naccuracy. A guide to access the open code and datasets is available at\nhttps://github.com/aiaudit-org/raw2logit.",
    "descriptor": "\nComments: LO and MA contributed equally\n",
    "authors": [
      "Luis Oala",
      "Marco Aversa",
      "Gabriel Nobis",
      "Kurt Willis",
      "Yoan Neuenschwander",
      "Mich\u00e8le Buck",
      "Christian Matek",
      "Jerome Extermann",
      "Enrico Pomarico",
      "Wojciech Samek",
      "Roderick Murray-Smith",
      "Christoph Clausen",
      "Bruno Sanguinetti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02578"
  },
  {
    "id": "arXiv:2211.02579",
    "title": "V2X Misbehavior in Maneuver Sharing and Coordination Service:  Considerations for Standardization",
    "abstract": "Connected and Automated Vehicles (CAV) use sensors and wireless communication\nto improve road safety and efficiency. However, attackers may target\nVehicle-to-Everything (V2X) communication. Indeed, an attacker may send\nauthenticated-but-wrong data to send false location information, alert\nincorrect events, or report a bogus object endangering safety of other CAVs.\nStandardization Development Organizations (SDO) are currently working on\ndeveloping security standards against such attacks. Unfortunately, current\nstandardization efforts do not include misbehavior specifications for advanced\nV2X services such as Maneuver Sharing and Coordination Service (MSCS). This\nwork assesses the security of MSC Messages (MSCM) and proposes inputs for\nconsideration in existing standards.",
    "descriptor": "\nComments: 7 pages, 4 figures, 4 tables, IEEE CSCN 2022. arXiv admin note: text overlap with arXiv:2112.02184\n",
    "authors": [
      "Jean-Philippe Monteuuis",
      "Jonathan Petit",
      "Mohammad Raashid Ansari",
      "Cong Chen",
      "Seung Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.02579"
  },
  {
    "id": "arXiv:2211.02580",
    "title": "Evaluating and Improving Factuality in Multimodal Abstractive  Summarization",
    "abstract": "Current metrics for evaluating factuality for abstractive document\nsummarization have achieved high correlations with human judgment, but they do\nnot account for the vision modality and thus are not adequate for\nvision-and-language summarization. We propose CLIPBERTScore, a simple weighted\ncombination of CLIPScore and BERTScore to leverage the robustness and strong\nfactuality detection performance between image-summary and document-summary,\nrespectively. Next, due to the lack of meta-evaluation benchmarks to evaluate\nthe quality of multimodal factuality metrics, we collect human judgments of\nfactuality with respect to documents and images. We show that this simple\ncombination of two metrics in the zero-shot setting achieves higher\ncorrelations than existing factuality metrics for document summarization,\noutperforms an existing multimodal summarization metric, and performs\ncompetitively with strong multimodal factuality metrics specifically fine-tuned\nfor the task. Our thorough analysis demonstrates the robustness and high\ncorrelation of CLIPBERTScore and its components on four factuality\nmetric-evaluation benchmarks. Finally, we demonstrate two practical downstream\napplications of our CLIPBERTScore metric: for selecting important images to\nfocus on during training, and as a reward for reinforcement learning to improve\nfactuality of multimodal summary generation w.r.t automatic and human\nevaluation. Our data and code are publicly available at\nhttps://github.com/meetdavidwan/faithful-multimodal-summ",
    "descriptor": "\nComments: EMNLP 2022 (17 pages)\n",
    "authors": [
      "David Wan",
      "Mohit Bansal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02580"
  },
  {
    "id": "arXiv:2211.02585",
    "title": "Material Named Entity Recognition (MNER) for Knowledge-driven Materials  Using Deep Learning Approach",
    "abstract": "The scientific literature contains a wealth of cutting-edge knowledge in the\nfield of materials science, as well as useful data (e.g., numerical data from\nexperimental results, material properties and structure). These data are\ncritical for data-driven machine learning (ML) and deep learning (DL) methods\nto accelerate material discovery. Due to the large and growing number of\npublications, it is difficult for humans to manually retrieve and retain this\nknowledge. In this context, we investigate a deep neural network model based on\nBi-LSTM to retrieve knowledge from published scientific articles. The proposed\ndeep neural network-based model achieves an f-1 score of \\~97\\% for the\nMaterial Named Entity Recognition (MNER) task. The study addresses motivation,\nrelevant work, methodology, hyperparameters, and overall performance\nevaluation. The analysis provides insight into the results of the experiment\nand points to future directions for current research.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "M. Saef Ullah Miah",
      "Junaida Sulaiman"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.02585"
  },
  {
    "id": "arXiv:2211.02590",
    "title": "Modeling Temporal Data as Continuous Functions with Process Diffusion",
    "abstract": "Temporal data like time series are often observed at irregular intervals\nwhich is a challenging setting for existing machine learning methods. To tackle\nthis problem, we view such data as samples from some underlying continuous\nfunction. We then define a diffusion-based generative model that adds noise\nfrom a predefined stochastic process while preserving the continuity of the\nresulting underlying function. A neural network is trained to reverse this\nprocess which allows us to sample new realizations from the learned\ndistribution. We define suitable stochastic processes as noise sources and\nintroduce novel denoising and score-matching models on processes. Further, we\nshow how to apply this approach to the multivariate probabilistic forecasting\nand imputation tasks. Through our extensive experiments, we demonstrate that\nour method outperforms previous models on synthetic and real-world datasets.",
    "descriptor": "",
    "authors": [
      "Marin Bilo\u0161",
      "Kashif Rasul",
      "Anderson Schneider",
      "Yuriy Nevmyvaka",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02590"
  },
  {
    "id": "arXiv:2211.02592",
    "title": "A Large-Scale Study of a Sleep Tracking and Improving Device with  Closed-loop and Personalized Real-time Acoustic Stimulation",
    "abstract": "Various intervention therapies ranging from pharmaceutical to hi-tech\ntailored solutions have been available to treat difficulty in falling asleep\ncommonly caused by insomnia in modern life. However, current techniques largely\nremain ill-suited, ineffective, and unreliable due to their lack of precise\nreal-time sleep tracking, in-time feedback on the therapies, an ability to keep\npeople asleep during the night, and a large-scale effectiveness evaluation.\nHere, we introduce a novel sleep aid system, called Earable, that can\ncontinuously sense multiple head-based physiological signals and simultaneously\nenable closed-loop auditory stimulation to entrain brain activities in time for\neffective sleep promotion. We develop the system in a lightweight, comfortable,\nand user-friendly headband with a comprehensive set of algorithms and dedicated\nown-designed audio stimuli. We conducted multiple protocols from 883 sleep\nstudies on 377 subjects (241 women, 119 men) wearing either a gold-standard\ndevice (PSG), Earable, or both concurrently. We demonstrate that our system\nachieves (1) a strong correlation (0.89 +/- 0.03) between the physiological\nsignals acquired by Earable and those from the gold-standard PSG, (2) an 87.8\n+/- 5.3% agreement on sleep scoring using our automatic real-time sleep staging\nalgorithm with the consensus scored by three sleep technicians, and (3) a\nsuccessful non-pharmacological stimulation alternative to effectively shorten\nthe duration of sleep falling by 24.1 +/- 0.1 minutes. These results show that\nthe efficacy of Earable exceeds existing techniques in intentions to promote\nfast falling asleep, track sleep state accurately, and achieve high social\nacceptance for real-time closed-loop personalized neuromodulation-based home\nsleep care.",
    "descriptor": "\nComments: 33 pages, 8 figures\n",
    "authors": [
      "Anh Nguyen",
      "Galen Pogoncheff",
      "Ban Xuan Dong",
      "Nam Bui",
      "Hoang Truong",
      "Nhat Pham",
      "Linh Nguyen",
      "Hoang Huu Nguyen",
      "Sy Duong-Quy",
      "Sangtae Ha",
      "Tam Vu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.02592"
  },
  {
    "id": "arXiv:2211.02597",
    "title": "Autonomous Medical Needle Steering In Vivo",
    "abstract": "The use of needles to access sites within organs is fundamental to many\ninterventional medical procedures both for diagnosis and treatment. Safe and\naccurate navigation of a needle through living tissue to an intra-tissue target\nis currently often challenging or infeasible due to the presence of anatomical\nobstacles in the tissue, high levels of uncertainty, and natural tissue motion\n(e.g., due to breathing). Medical robots capable of automating needle-based\nprocedures in vivo have the potential to overcome these challenges and enable\nan enhanced level of patient care and safety. In this paper, we show the first\nmedical robot that autonomously navigates a needle inside living tissue around\nanatomical obstacles to an intra-tissue target. Our system leverages an aiming\ndevice and a laser-patterned highly flexible steerable needle, a type of needle\ncapable of maneuvering along curvilinear trajectories to avoid obstacles. The\nautonomous robot accounts for anatomical obstacles and uncertainty in living\ntissue/needle interaction with replanning and control and accounts for\nrespiratory motion by defining safe insertion time windows during the breathing\ncycle. We apply the system to lung biopsy, which is critical in the diagnosis\nof lung cancer, the leading cause of cancer-related death in the United States.\nWe demonstrate successful performance of our system in multiple in vivo porcine\nstudies and also demonstrate that our approach leveraging autonomous needle\nsteering outperforms a standard manual clinical technique for lung nodule\naccess.",
    "descriptor": "\nComments: 22 pages, 6 figures\n",
    "authors": [
      "Alan Kuntz",
      "Maxwell Emerson",
      "Tayfun Efe Ertop",
      "Inbar Fried",
      "Mengyu Fu",
      "Janine Hoelscher",
      "Margaret Rox",
      "Jason Akulian",
      "Erin A. Gillaspie",
      "Yueh Z. Lee",
      "Fabien Maldonado",
      "Robert J. Webster III",
      "Ron Alterovitz"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.02597"
  },
  {
    "id": "arXiv:2211.02598",
    "title": "A Ferroelectric Tunnel Junction-based Integrate-and-Fire Neuron",
    "abstract": "Event-based neuromorphic systems provide a low-power solution by using\nartificial neurons and synapses to process data asynchronously in the form of\nspikes. Ferroelectric Tunnel Junctions (FTJs) are ultra low-power memory\ndevices and are well-suited to be integrated in these systems. Here, we present\na hybrid FTJ-CMOS Integrate-and-Fire neuron which constitutes a fundamental\nbuilding block for new-generation neuromorphic networks for edge computing. We\ndemonstrate electrically tunable neural dynamics achievable by tuning the\nswitching of the FTJ device.",
    "descriptor": "",
    "authors": [
      "Paolo Gibertini",
      "Luca Fehlings",
      "Suzanne Lancaster",
      "Quang Duong",
      "Thomas Mikolajick",
      "Catherine Dubourdieu",
      "Stefan Slesazeck",
      "Erika Covi",
      "Veeresh Deshpande"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.02598"
  },
  {
    "id": "arXiv:2211.02608",
    "title": "Knowledge Retrieval With Functional Object-Oriented Networks",
    "abstract": "In this experiment, three different search algorithms are implemented for the\npurpose of extracting a task tree from a large knowledge graph, known as the\nFunctional Object-Oriented Network (FOON). Using a universal FOON, which\ncontains knowledge extracted by annotating online cooking videos, and a desired\ngoal, a task tree can be retrieved. The process of searching the universal FOON\nfor task tree retrieval is tested using iterative deepening search and greedy\nbest-first search with two different heuristic functions. The performance of\nthese three algorithms is analyzed and compared. The results of the experiment\nshow that iterative deepening performs strongly overall. However, different\nheuristics in an informed search proved to be beneficial for certain\nsituations.",
    "descriptor": "\nComments: 3 pages, 1 figure\n",
    "authors": [
      "Shawn Diaz"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)"
    ],
    "url": "https://arxiv.org/abs/2211.02608"
  },
  {
    "id": "arXiv:2211.02612",
    "title": "Reservoir Computing via Quantum Recurrent Neural Networks",
    "abstract": "Recent developments in quantum computing and machine learning have propelled\nthe interdisciplinary study of quantum machine learning. Sequential modeling is\nan important task with high scientific and commercial value. Existing VQC or\nQNN-based methods require significant computational resources to perform the\ngradient-based optimization of a larger number of quantum circuit parameters.\nThe major drawback is that such quantum gradient calculation requires a large\namount of circuit evaluation, posing challenges in current near-term quantum\nhardware and simulation software. In this work, we approach sequential modeling\nby applying a reservoir computing (RC) framework to quantum recurrent neural\nnetworks (QRNN-RC) that are based on classical RNN, LSTM and GRU. The main idea\nto this RC approach is that the QRNN with randomly initialized weights is\ntreated as a dynamical system and only the final classical linear layer is\ntrained. Our numerical simulations show that the QRNN-RC can reach results\ncomparable to fully trained QRNN models for several function approximation and\ntime series prediction tasks. Since the QRNN training complexity is\nsignificantly reduced, the proposed model trains notably faster. In this work\nwe also compare to corresponding classical RNN-based RC implementations and\nshow that the quantum version learns faster by requiring fewer training epochs\nin most cases. Our results demonstrate a new possibility to utilize quantum\nneural network for sequential modeling with greater quantum hardware\nefficiency, an important design consideration for noisy intermediate-scale\nquantum (NISQ) computers.",
    "descriptor": "",
    "authors": [
      "Samuel Yen-Chi Chen",
      "Daniel Fry",
      "Amol Deshmukh",
      "Vladimir Rastunkov",
      "Charlee Stefanski"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.02612"
  },
  {
    "id": "arXiv:2211.02614",
    "title": "Efficient Extrinsic Calibration of Multi-Sensor 3D LiDAR Systems for  Autonomous Vehicles using Static Objects Information",
    "abstract": "For an autonomous vehicle, the ability to sense its surroundings and to build\nan overall representation of the environment by fusing different sensor data\nstreams is fundamental. To this end, the poses of all sensors need to be\naccurately determined. Traditional calibration methods are based on: 1) using\ntargets specifically designed for calibration purposes in controlled\nenvironments, 2) optimizing a quality metric of the point clouds collected\nwhile traversing an unknown but static environment, or 3) optimizing the match\namong per-sensor incremental motion observations along a motion path fulfilling\nspecial requirements. In real scenarios, however, the online applicability of\nthese methods can be limited, as they are typically highly dynamic, contain\ndegenerate paths, and require fast computations. In this paper, we propose an\napproach that tackles some of these challenges by formulating the calibration\nproblem as a joint but structured optimization problem of all sensor\ncalibrations that takes as input a summary of the point cloud information\nconsisting of ground points and pole detections. We demonstrate the efficiency\nand quality of the results of the proposed approach in a set of experiments\nwith LiDAR simulation and real data from an urban trip.",
    "descriptor": "\nComments: 8 pages, 12 figures, The 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems\n",
    "authors": [
      "Brahayam Ponton",
      "Magda Ferri",
      "Lars Koenig",
      "Marcus Bartels"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.02614"
  },
  {
    "id": "arXiv:2211.02633",
    "title": "A Theoretical Study on Solving Continual Learning",
    "abstract": "Continual learning (CL) learns a sequence of tasks incrementally. There are\ntwo popular CL settings, class incremental learning (CIL) and task incremental\nlearning (TIL). A major challenge of CL is catastrophic forgetting (CF). While\na number of techniques are already available to effectively overcome CF for\nTIL, CIL remains to be highly challenging. So far, little theoretical study has\nbeen done to provide a principled guidance on how to solve the CIL problem.\nThis paper performs such a study. It first shows that probabilistically, the\nCIL problem can be decomposed into two sub-problems: Within-task Prediction\n(WP) and Task-id Prediction (TP). It further proves that TP is correlated with\nout-of-distribution (OOD) detection, which connects CIL and OOD detection. The\nkey conclusion of this study is that regardless of whether WP and TP or OOD\ndetection are defined explicitly or implicitly by a CIL algorithm, good WP and\ngood TP or OOD detection are necessary and sufficient for good CIL\nperformances. Additionally, TIL is simply WP. Based on the theoretical result,\nnew CIL methods are also designed, which outperform strong baselines in both\nCIL and TIL settings by a large margin.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Gyuhak Kim",
      "Changnan Xiao",
      "Tatsuya Konishi",
      "Zixuan Ke",
      "Bing Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02633"
  },
  {
    "id": "arXiv:2211.02643",
    "title": "A Transformer Architecture for Online Gesture Recognition of  Mathematical Expressions",
    "abstract": "The Transformer architecture is shown to provide a powerful framework as an\nend-to-end model for building expression trees from online handwritten gestures\ncorresponding to glyph strokes. In particular, the attention mechanism was\nsuccessfully used to encode, learn and enforce the underlying syntax of\nexpressions creating latent representations that are correctly decoded to the\nexact mathematical expression tree, providing robustness to ablated inputs and\nunseen glyphs. For the first time, the encoder is fed with spatio-temporal data\ntokens potentially forming an infinitely large vocabulary, which finds\napplications beyond that of online gesture recognition. A new supervised\ndataset of online handwriting gestures is provided for training models on\ngeneric handwriting recognition tasks and a new metric is proposed for the\nevaluation of the syntactic correctness of the output expression trees. A small\nTransformer model suitable for edge inference was successfully trained to an\naverage normalised Levenshtein accuracy of 94%, resulting in valid postfix RPN\ntree representation for 94% of predictions.",
    "descriptor": "\nComments: 12 pages, 3 Figures, 4 Tables\n",
    "authors": [
      "Mirco Ramo",
      "Gu\u00e9nol\u00e9 C.M. Silvestre"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02643"
  },
  {
    "id": "arXiv:2211.02646",
    "title": "Robustness of Fusion-based Multimodal Classifiers to Cross-Modal Content  Dilutions",
    "abstract": "As multimodal learning finds applications in a wide variety of high-stakes\nsocietal tasks, investigating their robustness becomes important. Existing work\nhas focused on understanding the robustness of vision-and-language models to\nimperceptible variations on benchmark tasks. In this work, we investigate the\nrobustness of multimodal classifiers to cross-modal dilutions - a plausible\nvariation. We develop a model that, given a multimodal (image + text) input,\ngenerates additional dilution text that (a) maintains relevance and topical\ncoherence with the image and existing text, and (b) when added to the original\ntext, leads to misclassification of the multimodal input. Via experiments on\nCrisis Humanitarianism and Sentiment Detection tasks, we find that the\nperformance of task-specific fusion-based multimodal classifiers drops by 23.3%\nand 22.5%, respectively, in the presence of dilutions generated by our model.\nMetric-based comparisons with several baselines and human evaluations indicate\nthat our dilutions show higher relevance and topical coherence, while\nsimultaneously being more effective at demonstrating the brittleness of the\nmultimodal classifiers. Our work aims to highlight and encourage further\nresearch on the robustness of deep multimodal models to realistic variations,\nespecially in human-facing societal applications. The code and other resources\nare available at https://claws-lab.github.io/multimodal-robustness/.",
    "descriptor": "\nComments: Accepted at the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP); Full Paper (Oral)\n",
    "authors": [
      "Gaurav Verma",
      "Vishwa Vinay",
      "Ryan A. Rossi",
      "Srijan Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.02646"
  },
  {
    "id": "arXiv:2211.02647",
    "title": "Neural Grasp Distance Fields for Robot Manipulation",
    "abstract": "We formulate grasp learning as a neural field and present Neural Grasp\nDistance Fields (NGDF). Here, the input is a 6D pose of a robot end effector\nand output is a distance to a continuous manifold of valid grasps for an\nobject. In contrast to current approaches that predict a set of discrete\ncandidate grasps, the distance-based NGDF representation is easily interpreted\nas a cost, and minimizing this cost produces a successful grasp pose. This\ngrasp distance cost can be incorporated directly into a trajectory optimizer\nfor joint optimization with other costs such as trajectory smoothness and\ncollision avoidance. During optimization, as the various costs are balanced and\nminimized, the grasp target is allowed to smoothly vary, as the learned grasp\nfield is continuous. In simulation benchmarks with a Franka arm, we find that\njoint grasping and planning with NGDF outperforms baselines by 63% execution\nsuccess while generalizing to unseen query poses and unseen object shapes.\nProject page: https://sites.google.com/view/neural-grasp-distance-fields.",
    "descriptor": "",
    "authors": [
      "Thomas Weng",
      "David Held",
      "Franziska Meier",
      "Mustafa Mukadam"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.02647"
  },
  {
    "id": "arXiv:2211.02648",
    "title": "HoloLens 2 Sensor Streaming",
    "abstract": "We present a HoloLens 2 server application for streaming device data via TCP\nin real time. The server can stream data from the four grayscale cameras, depth\nsensor, IMU, front RGB camera, microphone, head tracking, eye tracking, and\nhand tracking. Each sent data frame has a timestamp and, optionally, the\ninstantaneous pose of the device in 3D space. The server allows downloading\ndevice calibration data, such as camera intrinsics, and can be integrated into\nUnity projects as a plugin, with support for basic upstream capabilities. To\nachieve real time video streaming at full frame rate, we leverage the video\nencoding capabilities of the HoloLens 2. Finally, we present a Python library\nfor receiving and decoding the data, which includes utilities that facilitate\npassing the data to other libraries. The source code, Python demos, and\nprecompiled binaries are available at https://github.com/jdibenes/hl2ss.",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Juan C. Dibene",
      "Enrique Dunn"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.02648"
  },
  {
    "id": "arXiv:2211.02650",
    "title": "Self-Adapting Noise-Contrastive Estimation for Energy-Based Models",
    "abstract": "Training energy-based models (EBMs) with noise-contrastive estimation (NCE)\nis theoretically feasible but practically challenging. Effective learning\nrequires the noise distribution to be approximately similar to the target\ndistribution, especially in high-dimensional domains. Previous works have\nexplored modelling the noise distribution as a separate generative model, and\nthen concurrently training this noise model with the EBM. While this method\nallows for more effective noise-contrastive estimation, it comes at the cost of\nextra memory and training complexity. Instead, this thesis proposes a\nself-adapting NCE algorithm which uses static instances of the EBM along its\ntraining trajectory as the noise distribution. During training, these static\ninstances progressively converge to the target distribution, thereby\ncircumventing the need to simultaneously train an auxiliary noise model.\nMoreover, we express this self-adapting NCE algorithm in the framework of\nBregman divergences and show that it is a generalization of maximum likelihood\nlearning for EBMs. The performance of our algorithm is evaluated across a range\nof noise update intervals, and experimental results show that shorter update\nintervals are conducive to higher synthesis quality.",
    "descriptor": "\nComments: MSc thesis submitted to Tsinghua University in July 2022\n",
    "authors": [
      "Nathaniel Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02650"
  },
  {
    "id": "arXiv:2211.02652",
    "title": "AntFuzzer: A Grey-Box Fuzzing Framework for EOSIO Smart Contracts",
    "abstract": "In the past few years, several attacks against the vulnerabilities of EOSIO\nsmart contracts have caused severe financial losses to this prevalent\nblockchain platform. As a lightweight test-generation approach, grey-box\nfuzzing can open up the possibility of improving the security of EOSIO smart\ncontracts. However, developing a practical grey-box fuzzer for EOSIO smart\ncontracts from scratch is time-consuming and requires a deep understanding of\nEOSIO internals. In this work, we proposed AntFuzzer, the first highly\nextensible grey-box fuzzing framework for EOSIO smart contracts. AntFuzzer\nimplements a novel approach that interfaces AFL to conduct AFL-style grey-box\nfuzzing on EOSIO smart contracts. Compared to black-box fuzzing tools,\nAntFuzzer can effectively trigger those hard-to-cover branches. It achieved an\nimprovement in code coverage on 37.5% of smart contracts in our benchmark\ndataset. AntFuzzer provides unified interfaces for users to easily develop new\ndetection plugins for continually emerging vulnerabilities. We have implemented\n6 detection plugins on AntFuzzer to detect major vulnerabilities of EOSIO smart\ncontracts. In our large-scale fuzzing experiments on 4,616 real-world smart\ncontracts, AntFuzzer successfully detected 741 vulnerabilities. The results\ndemonstrate the effectiveness and efficiency of AntFuzzer and our detection pl",
    "descriptor": "",
    "authors": [
      "Jianfei Zhou",
      "Tianxing Jiang",
      "Shuwei Song",
      "Ting Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.02652"
  },
  {
    "id": "arXiv:2211.02051",
    "title": "Fearless Steps Challenge Phase-1 Evaluation Plan",
    "abstract": "The Fearless Steps Challenge 2019 Phase-1 (FSC-P1) is the inaugural Challenge\nof the Fearless Steps Initiative hosted by the Center for Robust Speech Systems\n(CRSS) at the University of Texas at Dallas. The goal of this Challenge is to\nevaluate the performance of state-of-the-art speech and language systems for\nlarge task-oriented teams with naturalistic audio in challenging environments.\nResearchers may select to participate in any single or multiple of these\nchallenge tasks. Researchers may also choose to employ the FEARLESS STEPS\ncorpus for other related speech applications. All participants are encouraged\nto submit their solutions and results for consideration in the ISCA\nINTERSPEECH-2019 special session.",
    "descriptor": "\nComments: Document Generated in February 2019 for conducting the Fearless Steps Challenge Phase-1 and its associated ISCA Interspeech-2019 Special Session\n",
    "authors": [
      "Aditya Joglekar",
      "John H.L. Hansen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.02051"
  },
  {
    "id": "arXiv:2211.02073",
    "title": "Quantum Protocol for Decision Making and Verifying Truthfulness among  $N$-quantum Parties: Solution and Extension of the Quantum Coin Flipping Game",
    "abstract": "We devised a protocol that allows two parties, who may malfunction or\nintentionally convey incorrect information in communication through a quantum\nchannel, to verify each other's measurements and agree on each other's results.\nThis has particular relevance in a modified version of the quantum coin\nflipping game where the possibility of the players cheating is now removed.\nFurthermore, the analysis is extended to $N$-parties communicating with each\nother, where we propose multiple solutions for the verification of each\nplayer's measurement. The results in the $N$-party scenario could have\nparticular relevance for the implementation of future quantum networks, where\nverification of quantum information is a necessity.",
    "descriptor": "",
    "authors": [
      "Kazuki Ikeda",
      "Adam Lowe"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.02073"
  },
  {
    "id": "arXiv:2211.02081",
    "title": "A system design approach toward integrated cryogenic quantum control  systems",
    "abstract": "In this paper, we provide a system level perspective on the design of control\nelectronics for large scale quantum systems. Quantum computing systems with\nhigh-fidelity control and readout, coherent coupling, calibrated gates, and\nreconfigurable circuits with low error rates are expected to have superior\nquantum volumes. Cryogenic CMOS plays a crucial role in the realization of\nscalable quantum computers, by minimizing the feature size, lowering the cost,\npower consumption, and implementing low latency error correction. Our approach\ntoward achieving scalable feed-back based control systems includes the design\nof memory based arbitrary waveform generators (AWG's), wide band radio\nfrequency analog to digital converters, integrated amplifier chain, and state\ndiscriminators that can be synchronized with gate sequences. Digitally assisted\ndesigns, when implemented in an advanced CMOS node such as 7 nm can reap the\nbenefits of low power due to scaling. A qubit readout chain demands several\namplification stages before the digitizer. We propose the co-integration of our\nin-house developed InP HEMT LNAs with CMOS LNA stages to achieve the required\ngain at the digitizer input with minimal area. Our approach using high\nimpedance matching between the HEMT LNA and the cryogenic CMOS receiver can\nrelax the design constraints of an inverter-based CMOS LNA, paving the way\ntoward a fully integrated qubit readout chain. The qubit state discriminator\nconsists of a digital signal processor that computes the qubit state from the\ndigitizer output and a pre-determined threshold. The proposed system realizes\nfeedback-based optimal control for error mitigation and reduction of the\nrequired data rate through the serial interface to room temperature\nelectronics.",
    "descriptor": "",
    "authors": [
      "Mridula Prathapan",
      "Peter Mueller",
      "David Heim",
      "Maria Vittoria Oropallo",
      "Matthias Braendli",
      "Pier Andrea Francese",
      "Marcel Kossel",
      "Andrea Ruffino",
      "Cezar Zota",
      "Eunjung Cha",
      "Thomas Morf"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.02081"
  },
  {
    "id": "arXiv:2211.02105",
    "title": "Geometry and convergence of natural policy gradient methods",
    "abstract": "We study the convergence of several natural policy gradient (NPG) methods in\ninfinite-horizon discounted Markov decision processes with regular policy\nparametrizations. For a variety of NPGs and reward functions we show that the\ntrajectories in state-action space are solutions of gradient flows with respect\nto Hessian geometries, based on which we obtain global convergence guarantees\nand convergence rates. In particular, we show linear convergence for\nunregularized and regularized NPG flows with the metrics proposed by Kakade and\nMorimura and co-authors by observing that these arise from the Hessian\ngeometries of conditional entropy and entropy respectively. Further, we obtain\nsublinear convergence rates for Hessian geometries arising from other convex\nfunctions like log-barriers. Finally, we interpret the discrete-time NPG\nmethods with regularized rewards as inexact Newton methods if the NPG is\ndefined with respect to the Hessian geometry of the regularizer. This yields\nlocal quadratic convergence rates of these methods for step size equal to the\npenalization strength.",
    "descriptor": "\nComments: 33 pages, 5 figures, under review\n",
    "authors": [
      "Johannes M\u00fcller",
      "Guido Mont\u00fafar"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.02105"
  },
  {
    "id": "arXiv:2211.02110",
    "title": "Attitude Trajectory Optimization and Momentum Conservation with Control  Moment Gyroscopes",
    "abstract": "In this work, we develop a numerically tractable trajectory optimization\nproblem for rest-to-rest attitude transfers with CMG-driven spacecraft. First,\nwe adapt a specialized dynamical model which avoids many of the numerical\nchallenges (singularities) introduced by common dynamical approximations. To\nformulate and solve our specialized trajectory optimization problem, we design\na locally stabilizing Linear Quadratic (LQ) regulator on the system's\nconfiguration manifold then lift it into the ambient state space to produce\nsuitable terminal and running LQ cost functionals. Finally, we examine the\nperformance benefits and drawbacks of solutions to this optimization problem\nvia the PRONTO solver and find significant improvements in maneuver time,\nterminal state accuracy, and total control effort. This analysis also\nhighlights a critical shortcoming for objective functions which penalize only\nthe norm of the control input rather than electrical power usage.",
    "descriptor": "\nComments: 8 pages, 6 figures, IFAC 2023 conference submission\n",
    "authors": [
      "Thomas L. Dearing",
      "John Hauser",
      "Christopher Petersen",
      "Marco M. Nicotra",
      "Xudong Chen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.02110"
  },
  {
    "id": "arXiv:2211.02133",
    "title": "Streaming Audio-Visual Speech Recognition with Alignment Regularization",
    "abstract": "Recognizing a word shortly after it is spoken is an important requirement for\nautomatic speech recognition (ASR) systems in real-world scenarios. As a\nresult, a large body of work on streaming audio-only ASR models has been\npresented in the literature. However, streaming audio-visual automatic speech\nrecognition (AV-ASR) has received little attention in earlier works. In this\nwork, we propose a streaming AV-ASR system based on a hybrid connectionist\ntemporal classification (CTC)/attention neural network architecture. The audio\nand the visual encoder neural networks are both based on the conformer\narchitecture, which is made streamable using chunk-wise self-attention (CSA)\nand causal convolution. Streaming recognition with a decoder neural network is\nrealized by using the triggered attention technique, which performs\ntime-synchronous decoding with joint CTC/attention scoring. For frame-level ASR\ncriteria, such as CTC, a synchronized response from the audio and visual\nencoders is critical for a joint AV decision making process. In this work, we\npropose a novel alignment regularization technique that promotes\nsynchronization of the audio and visual encoder, which in turn results in\nbetter word error rates (WERs) at all SNR levels for streaming and offline\nAV-ASR models. The proposed AV-ASR model achieves WERs of 2.0% and 2.6% on the\nLip Reading Sentences 3 (LRS3) dataset in an offline and online setup,\nrespectively, which both present state-of-the-art results when no external\ntraining data are used.",
    "descriptor": "\nComments: Submitted to ICASSP2023\n",
    "authors": [
      "Pingchuan Ma",
      "Niko Moritz",
      "Stavros Petridis",
      "Christian Fuegen",
      "Maja Pantic"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.02133"
  },
  {
    "id": "arXiv:2211.02142",
    "title": "Improving Semi-supervised Deep Learning by using Automatic Thresholding  to Deal with Out of Distribution Data for COVID-19 Detection using Chest  X-ray Images",
    "abstract": "Semi-supervised learning (SSL) leverages both labeled and unlabeled data for\ntraining models when the labeled data is limited and the unlabeled data is\nvast. Frequently, the unlabeled data is more widely available than the labeled\ndata, hence this data is used to improve the level of generalization of a model\nwhen the labeled data is scarce. However, in real-world settings unlabeled data\nmight depict a different distribution than the labeled dataset distribution.\nThis is known as distribution mismatch. Such problem generally occurs when the\nsource of unlabeled data is different from the labeled data. For instance, in\nthe medical imaging domain, when training a COVID-19 detector using chest X-ray\nimages, different unlabeled datasets sampled from different hospitals might be\nused. In this work, we propose an automatic thresholding method to filter\nout-of-distribution data in the unlabeled dataset. We use the Mahalanobis\ndistance between the labeled and unlabeled datasets using the feature space\nbuilt by a pre-trained Image-net Feature Extractor (FE) to score each unlabeled\nobservation. We test two simple automatic thresholding methods in the context\nof training a COVID-19 detector using chest X-ray images. The tested methods\nprovide an automatic manner to define what unlabeled data to preserve when\ntraining a semi-supervised deep learning architecture.",
    "descriptor": "",
    "authors": [
      "Isaac Benavides-Mata",
      "Saul Calderon-Ramirez"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02142"
  },
  {
    "id": "arXiv:2211.02163",
    "title": "A Riemannian ADMM",
    "abstract": "We consider a class of Riemannian optimization problems where the objective\nis the sum of a smooth function and a nonsmooth function, considered in the\nambient space. This class of problems finds important applications in machine\nlearning and statistics such as the sparse principal component analysis, sparse\nspectral clustering, and orthogonal dictionary learning. We propose a\nRiemannian alternating direction method of multipliers (ADMM) to solve this\nclass of problems. Our algorithm adopts easily computable steps in each\niteration. The iteration complexity of the proposed algorithm for obtaining an\n$\\epsilon$-stationary point is analyzed under mild assumptions. To the best of\nour knowledge, this is the first Riemannian ADMM with provable convergence\nguarantee for solving Riemannian optimization problem with nonsmooth objective.\nNumerical experiments are conducted to demonstrate the advantage of the\nproposed method.",
    "descriptor": "",
    "authors": [
      "Jiaxiang Li",
      "Shiqian Ma",
      "Tejes Srivastava"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02163"
  },
  {
    "id": "arXiv:2211.02165",
    "title": "Twenty-Five Years of Advances in Beamforming: From Convex and Nonconvex  Optimization to Learning Techniques",
    "abstract": "Beamforming is a signal processing technique to steer, shape, and focus an\nelectromagnetic wave using an array of sensors toward a desired direction. It\nhas been used in several engineering applications such as radar, sonar,\nacoustics, astronomy, seismology, medical imaging, and communications. With the\nadvances in multi-antenna technologies largely for radar and communications,\nthere has been a great interest on beamformer design mostly relying on\nconvex/nonconvex optimization. Recently, machine learning is being leveraged\nfor obtaining attractive solutions to more complex beamforming problems. This\narticle captures the evolution of beamforming in the last twenty-five years\nfrom convex-to-nonconvex optimization and optimization-to-learning approaches.\nIt provides a glimpse of this important signal processing technique into a\nvariety of transmit-receive architectures, propagation zones, paths, and\nconventional/emerging applications.",
    "descriptor": "",
    "authors": [
      "Ahmet M. Elbir",
      "Kumar Vijay Mishra",
      "Sergiy A. Vorobyov",
      "Robert W. Heath Jr"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.02165"
  },
  {
    "id": "arXiv:2211.02218",
    "title": "Fully Bayesian inference for latent variable Gaussian process models",
    "abstract": "Real engineering and scientific applications often involve one or more\nqualitative inputs. Standard Gaussian processes (GPs), however, cannot directly\naccommodate qualitative inputs. The recently introduced latent variable\nGaussian process (LVGP) overcomes this issue by first mapping each qualitative\nfactor to underlying latent variables (LVs), and then uses any standard GP\ncovariance function over these LVs. The LVs are estimated similarly to the\nother GP hyperparameters through maximum likelihood estimation, and then\nplugged into the prediction expressions. However, this plug-in approach will\nnot account for uncertainty in estimation of the LVs, which can be significant\nespecially with limited training data. In this work, we develop a fully\nBayesian approach for the LVGP model and for visualizing the effects of the\nqualitative inputs via their LVs. We also develop approximations for scaling up\nLVGPs and fully Bayesian inference for the LVGP hyperparameters. We conduct\nnumerical studies comparing plug-in inference against fully Bayesian inference\nover a few engineering models and material design applications. In contrast to\nprevious studies on standard GP modeling that have largely concluded that a\nfully Bayesian treatment offers limited improvements, our results show that for\nLVGP modeling it offers significant improvements in prediction accuracy and\nuncertainty quantification over the plug-in approach.",
    "descriptor": "",
    "authors": [
      "Suraj Yerramilli",
      "Akshay Iyer",
      "Wei Chen",
      "Daniel W. Apley"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02218"
  },
  {
    "id": "arXiv:2211.02227",
    "title": "Integrated Parameter-Efficient Tuning for General-Purpose Audio Models",
    "abstract": "The advent of hyper-scale and general-purpose pre-trained models is shifting\nthe paradigm of building task-specific models for target tasks. In the field of\naudio research, task-agnostic pre-trained models with high transferability and\nadaptability have achieved state-of-the-art performances through fine-tuning\nfor downstream tasks. Nevertheless, re-training all the parameters of these\nmassive models entails an enormous amount of time and cost, along with a huge\ncarbon footprint. To overcome these limitations, the present study explores and\napplies efficient transfer learning methods in the audio domain. We also\npropose an integrated parameter-efficient tuning (IPET) framework by\naggregating the embedding prompt (a prompt-based learning approach), and the\nadapter (an effective transfer learning method). We demonstrate the efficacy of\nthe proposed framework using two backbone pre-trained audio models with\ndifferent characteristics: the audio spectrogram transformer and wav2vec 2.0.\nThe proposed IPET framework exhibits remarkable performance compared to\nfine-tuning method with fewer trainable parameters in four downstream tasks:\nsound event classification, music genre classification, keyword spotting, and\nspeaker verification. Furthermore, the authors identify and analyze the\nshortcomings of the IPET framework, providing lessons and research directions\nfor parameter efficient tuning in the audio domain.",
    "descriptor": "\nComments: 5 pages, 3 figures, submit to ICASSP2023\n",
    "authors": [
      "Ju-ho Kim",
      "Jungwoo Heo",
      "Hyun-seo Shin",
      "Chan-yeong Lim",
      "Ha-Jin Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.02227"
  },
  {
    "id": "arXiv:2211.02235",
    "title": "Materials Property Prediction with Uncertainty Quantification: A  Benchmark Study",
    "abstract": "Uncertainty quantification (UQ) has increasing importance in building robust\nhigh-performance and generalizable materials property prediction models. It can\nalso be used in active learning to train better models by focusing on getting\nnew training data from uncertain regions. There are several categories of UQ\nmethods each considering different types of uncertainty sources. Here we\nconduct a comprehensive evaluation on the UQ methods for graph neural network\nbased materials property prediction and evaluate how they truly reflect the\nuncertainty that we want in error bound estimation or active learning. Our\nexperimental results over four crystal materials datasets (including formation\nenergy, adsorption energy, total energy, and band gap properties) show that the\npopular ensemble methods for uncertainty estimation is NOT the best choice for\nUQ in materials property prediction. For the convenience of the community, all\nthe source code and data sets can be accessed freely at\n\\url{https://github.com/usccolumbia/materialsUQ}.",
    "descriptor": "",
    "authors": [
      "Daniel Varivoda",
      "Rongzhi Dong",
      "Sadman Sadeed Omee",
      "Jianjun Hu"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02235"
  },
  {
    "id": "arXiv:2211.02239",
    "title": "Towards Asteroid Detection in Microlensing Surveys with Deep Learning",
    "abstract": "Asteroids are an indelible part of most astronomical surveys though only a\nfew surveys are dedicated to their detection. Over the years, high cadence\nmicrolensing surveys have amassed several terabytes of data while scanning\nprimarily the Galactic Bulge and Magellanic Clouds for microlensing events and\nthus provide a treasure trove of opportunities for scientific data mining. In\nparticular, numerous asteroids have been observed by visual inspection of\nselected images. This paper presents novel deep learning-based solutions for\nthe recovery and discovery of asteroids in the microlensing data gathered by\nthe MOA project. Asteroid tracklets can be clearly seen by combining all the\nobservations on a given night and these tracklets inform the structure of the\ndataset. Known asteroids were identified within these composite images and used\nfor creating the labelled datasets required for supervised learning. Several\ncustom CNN models were developed to identify images with asteroid tracklets.\nModel ensembling was then employed to reduce the variance in the predictions as\nwell as to improve the generalisation error, achieving a recall of 97.67%.\nFurthermore, the YOLOv4 object detector was trained to localize asteroid\ntracklets, achieving a mean Average Precision (mAP) of 90.97%. These trained\nnetworks will be applied to 16 years of MOA archival data to find both known\nand unknown asteroids that have been observed by the survey over the years. The\nmethodologies developed can be adapted for use by other surveys for asteroid\nrecovery and discovery.",
    "descriptor": "\nComments: 11 pages, 10 figures, submitted to Astronomy and Computing\n",
    "authors": [
      "Preeti Cowan",
      "Ian A. Bond",
      "Napoleon H. Reyes"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02239"
  },
  {
    "id": "arXiv:2211.02247",
    "title": "Music Mixing Style Transfer: A Contrastive Learning Approach to  Disentangle Audio Effects",
    "abstract": "We propose an end-to-end music mixing style transfer system that converts the\nmixing style of an input multitrack to that of a reference song. This is\nachieved with an encoder pre-trained with a contrastive objective to extract\nonly audio effects related information from a reference music recording. All\nour models are trained in a self-supervised manner from an already-processed\nwet multitrack dataset with an effective data preprocessing method that\nalleviates the data scarcity of obtaining unprocessed dry data. We analyze the\nproposed encoder for the disentanglement capability of audio effects and also\nvalidate its performance for mixing style transfer through both objective and\nsubjective evaluations. From the results, we show the proposed system not only\nconverts the mixing style of multitrack audio close to a reference but is also\nrobust with mixture-wise style transfer upon using a music source separation\nmodel.",
    "descriptor": "",
    "authors": [
      "Junghyun Koo",
      "Marco A. Martinez-Ramirez",
      "Wei-Hsiang Liao",
      "Stefan Uhlich",
      "Kyogu Lee",
      "Yuki Mitsufuji"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.02247"
  },
  {
    "id": "arXiv:2211.02256",
    "title": "ISA-Net: Improved spatial attention network for PET-CT tumor  segmentation",
    "abstract": "Achieving accurate and automated tumor segmentation plays an important role\nin both clinical practice and radiomics research. Segmentation in medicine is\nnow often performed manually by experts, which is a laborious, expensive and\nerror-prone task. Manual annotation relies heavily on the experience and\nknowledge of these experts. In addition, there is much intra- and interobserver\nvariation. Therefore, it is of great significance to develop a method that can\nautomatically segment tumor target regions. In this paper, we propose a deep\nlearning segmentation method based on multimodal positron emission\ntomography-computed tomography (PET-CT), which combines the high sensitivity of\nPET and the precise anatomical information of CT. We design an improved spatial\nattention network(ISA-Net) to increase the accuracy of PET or CT in detecting\ntumors, which uses multi-scale convolution operation to extract feature\ninformation and can highlight the tumor region location information and\nsuppress the non-tumor region location information. In addition, our network\nuses dual-channel inputs in the coding stage and fuses them in the decoding\nstage, which can take advantage of the differences and complementarities\nbetween PET and CT. We validated the proposed ISA-Net method on two clinical\ndatasets, a soft tissue sarcoma(STS) and a head and neck tumor(HECKTOR)\ndataset, and compared with other attention methods for tumor segmentation. The\nDSC score of 0.8378 on STS dataset and 0.8076 on HECKTOR dataset show that\nISA-Net method achieves better segmentation performance and has better\ngeneralization. Conclusions: The method proposed in this paper is based on\nmulti-modal medical image tumor segmentation, which can effectively utilize the\ndifference and complementarity of different modes. The method can also be\napplied to other multi-modal data or single-modal data by proper adjustment.",
    "descriptor": "",
    "authors": [
      "Zhengyong Huang",
      "Sijuan Zou",
      "Guoshuai Wang",
      "Zixiang Chen",
      "Hao Shen",
      "Haiyan Wang",
      "Na Zhang",
      "Lu Zhang",
      "Fan Yang",
      "Haining Wangg",
      "Dong Liang",
      "Tianye Niu",
      "Xiaohua Zhuc",
      "Zhanli Hua"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02256"
  },
  {
    "id": "arXiv:2211.02261",
    "title": "Seismic-phase detection using multiple deep learning models for global  and local representations of waveforms",
    "abstract": "The detection of earthquakes is a fundamental prerequisite for seismology and\ncontributes to various research areas, such as forecasting earthquakes and\nunderstanding the crust/mantle structure. Recent advances in machine learning\ntechnologies have enabled the automatic detection of earthquakes from waveform\ndata. In particular, various state-of-the-art deep-learning methods have been\napplied to this endeavour. In this study, we proposed and tested a novel phase\ndetection method employing deep learning, which is based on a standard\nconvolutional neural network in a new framework. The novelty of the proposed\nmethod is its separate explicit learning strategy for global and local\nrepresentations of waveforms, which enhances its robustness and flexibility.\nPrior to modelling the proposed method, we identified local representations of\nthe waveform by the multiple clustering of waveforms, in which the data points\nwere optimally partitioned. Based on this result, we considered a global\nrepresentation and two local representations of the waveform. Subsequently,\ndifferent phase detection models were trained for each global and local\nrepresentation. For a new waveform, the overall phase probability was evaluated\nas a product of the phase probabilities of each model. This additional\ninformation on local representations makes the proposed method robust to noise,\nwhich is demonstrated by its application to the test data. Furthermore, an\napplication to seismic swarm data demonstrated the robust performance of the\nproposed method compared with those of other deep learning methods. Finally, in\nan application to low-frequency earthquakes, we demonstrated the flexibility of\nthe proposed method, which is readily adaptable for the detection of\nlow-frequency earthquakes by retraining only a local model.",
    "descriptor": "",
    "authors": [
      "Tomoki Tokuda",
      "Hiromichi Nagao"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02261"
  },
  {
    "id": "arXiv:2211.02278",
    "title": "A Deep Learning Approach to Generating Photospheric Vector Magnetograms  of Solar Active Regions for SOHO/MDI Using SDO/HMI and BBSO Data",
    "abstract": "Solar activity is usually caused by the evolution of solar magnetic fields.\nMagnetic field parameters derived from photospheric vector magnetograms of\nsolar active regions have been used to analyze and forecast eruptive events\nsuch as solar flares and coronal mass ejections. Unfortunately, the most recent\nsolar cycle 24 was relatively weak with few large flares, though it is the only\nsolar cycle in which consistent time-sequence vector magnetograms have been\navailable through the Helioseismic and Magnetic Imager (HMI) on board the Solar\nDynamics Observatory (SDO) since its launch in 2010. In this paper, we look\ninto another major instrument, namely the Michelson Doppler Imager (MDI) on\nboard the Solar and Heliospheric Observatory (SOHO) from 1996 to 2010. The data\narchive of SOHO/MDI covers more active solar cycle 23 with many large flares.\nHowever, SOHO/MDI data only has line-of-sight (LOS) magnetograms. We propose a\nnew deep learning method, named MagNet, to learn from combined LOS\nmagnetograms, Bx and By taken by SDO/HMI along with H-alpha observations\ncollected by the Big Bear Solar Observatory (BBSO), and to generate vector\ncomponents Bx' and By', which would form vector magnetograms with observed LOS\ndata. In this way, we can expand the availability of vector magnetograms to the\nperiod from 1996 to present. Experimental results demonstrate the good\nperformance of the proposed method. To our knowledge, this is the first time\nthat deep learning has been used to generate photospheric vector magnetograms\nof solar active regions for SOHO/MDI using SDO/HMI and H-alpha data.",
    "descriptor": "\nComments: 15 pages, 6 figures\n",
    "authors": [
      "Haodi Jiang",
      "Qin Li",
      "Zhihang Hu",
      "Nian Liu",
      "Yasser Abduallah",
      "Ju Jing",
      "Genwei Zhang",
      "Yan Xu",
      "Wynne Hsu",
      "Jason T. L. Wang",
      "Haimin Wang"
    ],
    "subjectives": [
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02278"
  },
  {
    "id": "arXiv:2211.02285",
    "title": "Unexploitable games and unbeatable strategies",
    "abstract": "Imitation is a simple behavior which uses successful actions of others in\norder to handle one's tasks. Because success of imitation generally depends on\nwhether profit of an imitating agent coincides with those of other agents or\nnot, game theory is suitable for specifying situations where imitation can be\nsuccessful. One of the concepts describing successfulness of imitation in\nrepeated two-player symmetric games is unbeatability. For infinitely repeated\ntwo-player symmetric games, a necessary and sufficient condition for some\nimitation strategy to be unbeatable was specified. However, situations where\nimitation can be unbeatable in multi-player games are still not clear. In order\nto analyze successfulness of imitation in multi-player situations, here we\nintroduce a class of totally symmetric games called unexploitable games, which\nis a natural extension of two-player symmetric games without exploitation\ncycles. We then prove that, for infinitely repeated unexploitable games, there\nexist unbeatable imitation strategies. Furthermore, we also prove that, for\ninfinitely repeated non-trivial unexploitable games, there exist unbeatable\nzero-determinant strategies, which unilaterally enforce some relationships on\npayoffs of players. These claims are demonstrated in the public goods game,\nwhich is the simplest unexploitable game. These results show that there are\nsituations where imitation can be unbeatable even in multi-player games.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Masahiko Ueda"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.02285"
  },
  {
    "id": "arXiv:2211.02289",
    "title": "CochlScene: Acquisition of acoustic scene data using crowdsourcing",
    "abstract": "This paper describes a pipeline for collecting acoustic scene data by using\ncrowdsourcing. The detailed process of crowdsourcing is explained, including\nplanning, validation criteria, and actual user interfaces. As a result of data\ncollection, we present CochlScene, a novel dataset for acoustic scene\nclassification. Our dataset consists of 76k samples collected from 831\nparticipants in 13 acoustic scenes. We also propose a manual data split of\ntraining, validation, and test sets to increase the reliability of the\nevaluation results. Finally, we provide a baseline system for future research.",
    "descriptor": "\nComments: Accept by APSIPA ASC 2022, 5 pages, 2 figures\n",
    "authors": [
      "Il-Young Jeong",
      "Jeongsoo Park"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.02289"
  },
  {
    "id": "arXiv:2211.02315",
    "title": "Spatial-Temporal Convolutional Attention for Mapping Functional Brain  Networks",
    "abstract": "Using functional magnetic resonance imaging (fMRI) and deep learning to\nexplore functional brain networks (FBNs) has attracted many researchers.\nHowever, most of these studies are still based on the temporal correlation\nbetween the sources and voxel signals, and lack of researches on the dynamics\nof brain function. Due to the widespread local correlations in the volumes,\nFBNs can be generated directly in the spatial domain in a self-supervised\nmanner by using spatial-wise attention (SA), and the resulting FBNs has a\nhigher spatial similarity with templates compared to the classical method.\nTherefore, we proposed a novel Spatial-Temporal Convolutional Attention (STCA)\nmodel to discover the dynamic FBNs by using the sliding windows. To validate\nthe performance of the proposed method, we evaluate the approach on HCP-rest\ndataset. The results indicate that STCA can be used to discover FBNs in a\ndynamic way which provide a novel approach to better understand human brain.",
    "descriptor": "\nComments: 5 pages, 5 figures, submitted to 20th IEEE International Symposium on Biomedical Imaging (ISBI 2023)\n",
    "authors": [
      "Yiheng Liu",
      "Enjie Ge",
      "Ning Qiang",
      "Tianming Liu",
      "Bao Ge"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.02315"
  },
  {
    "id": "arXiv:2211.02316",
    "title": "A numerical study of vortex nucleation in 2D rotating Bose-Einstein  condensates",
    "abstract": "This article introduces a new numerical method for the minimization under\nconstraints of a discrete energy modeling multicomponents rotating\nBose-Einstein condensates in the regime of strong confinement and with\nrotation. Moreover, we consider both segregation and coexistence regimes\nbetween the components. The method includes a discretization of a continuous\nenergy in space dimension 2 and a gradient algorithm with adaptive time step\nand projection for the minimization. It is well known that, depending on the\nregime, the minimizers may display different structures, sometimes with\nvorticity (from singly quantized vortices, to vortex sheets and giant holes).\nIn order to study numerically the structures of the minimizers, we introduce in\nthis paper a numerical algorithm for the computation of the indices of the\nvortices, as well as an algorithm for the computation of the indices of vortex\nsheets. Several computations are carried out, to illustrate the efficiency of\nthe method, to cover different physical cases, to validate recent theoretical\nresults as well as to support conjectures. Moreover, we compare this method\nwith an alternative method from the literature.",
    "descriptor": "",
    "authors": [
      "Guillaume Dujardin",
      "Ingrid Lacroix-Violet",
      "Anthony Nahas"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.02316"
  },
  {
    "id": "arXiv:2211.02322",
    "title": "Density Steering by Power Moments",
    "abstract": "This paper considers the problem of steering an arbitrary initial probability\ndensity function to an arbitrary terminal one, where the system dynamics is\ngoverned by a first-order linear stochastic difference equation. It is a\ngeneralization of the conventional stochastic control problem where the\nuncertainty of the system state is usually characterized by a Gaussian\ndistribution. We propose to use the power moments to turn the\ninfinite-dimensional problem into a finite-dimensional one and to present an\nempirical control scheme. By the designed control law, the moment sequence of\nthe controls at each time step is positive, which ensures the existence of the\ncontrol for the moment system. We then realize the control at each time step as\na function in analytic form by a convex optimization scheme, for which the\nexistence and uniqueness of the solution have been proved in our previous\npaper. Two numerical examples are given to validate our proposed algorithm.",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "Guangyu Wu",
      "Anders Lindquist"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.02322"
  },
  {
    "id": "arXiv:2211.02329",
    "title": "Minimal codewords in Norm-Trace codes",
    "abstract": "In this paper, we consider the affine variety codes obtained evaluating the\npolynomials $by=a_kx^k+\\dots+a_1x+a_0$, $b,a_i\\in\\mathbb{F}_{q^r}$, at the\naffine $\\F_{q^r}$-rational points of the Norm-Trace curve. In particular, we\ninvestigate the weight distribution and the set of minimal codewords. Our\napproach, which uses tools of algebraic geometry, is based on the study of the\nabsolutely irreducibility of certain algebraic varieties.",
    "descriptor": "",
    "authors": [
      "Daniele Bartoli",
      "Matteo Bonini",
      "Marco Timpanella"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.02329"
  },
  {
    "id": "arXiv:2211.02333",
    "title": "Minimum Latency Training of Sequence Transducers for Streaming  End-to-End Speech Recognition",
    "abstract": "Sequence transducers, such as the RNN-T and the Conformer-T, are one of the\nmost promising models of end-to-end speech recognition, especially in streaming\nscenarios where both latency and accuracy are important. Although various\nmethods, such as alignment-restricted training and FastEmit, have been studied\nto reduce the latency, latency reduction is often accompanied with a\nsignificant degradation in accuracy. We argue that this suboptimal performance\nmight be caused because none of the prior methods explicitly model and reduce\nthe latency. In this paper, we propose a new training method to explicitly\nmodel and reduce the latency of sequence transducer models. First, we define\nthe expected latency at each diagonal line on the lattice, and show that its\ngradient can be computed efficiently within the forward-backward algorithm.\nThen we augment the transducer loss with this expected latency, so that an\noptimal trade-off between latency and accuracy is achieved. Experimental\nresults on the WSJ dataset show that the proposed minimum latency training\nreduces the latency of causal Conformer-T from 220 ms to 27 ms within a WER\ndegradation of 0.7%, and outperforms conventional alignment-restricted training\n(110 ms) and FastEmit (67 ms) methods.",
    "descriptor": "\nComments: Presented at INTERSPEECH 2022\n",
    "authors": [
      "Yusuke Shinohara",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.02333"
  },
  {
    "id": "arXiv:2211.02346",
    "title": "Improving mean-field network percolation models with neighbourhood  information and their limitations on highly modular, highly dispersed  networks",
    "abstract": "Mean field theory models of percolation on networks provide analytical\npredictions of how networks behave under node or edge removal, but these models\nare not always accurate. Here, we evaluate how well existing models predict\nnetwork robustness and provide a new model that includes information about the\ntree-likeness of each node's local neighbourhood. Testing predictions using\nreal-world network data, we show that our new model significantly outperforms\nothers in prediction accuracy for random node and edge removal. We provide\nevidence that all discussed models are poor in predicting networks with highly\nmodular structure with dispersed modules, identifying this as a general\nlimitation of mean-field percolation models.",
    "descriptor": "\nComments: 13 pages, 8 figures. Supplementary Materials: 10 pages, 1 table, 5 figures\n",
    "authors": [
      "Chris Jones",
      "Karoline Wiesner"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.02346"
  },
  {
    "id": "arXiv:2211.02350",
    "title": "Tierkreis: A Dataflow Framework for Hybrid Quantum-Classical Computing",
    "abstract": "We present Tierkreis, a higher-order dataflow graph program representation\nand runtime designed for compositional, quantum-classical hybrid algorithms.\nThe design of the system is motivated by the remote nature of quantum\ncomputers, the need for hybrid algorithms to involve cloud and distributed\ncomputing, and the long-running nature of these algorithms. The graph-based\nrepresentation reflects how designers reason about and visualise algorithms,\nand allows automatic parallelism and asynchronicity. A strong, static type\nsystem and higher-order semantics allow for high expressivity and\ncompositionality in the program. The flexible runtime protocol enables\nthird-party developers to add functionality using any language or environment.\nWith Tierkreis, quantum software developers can easily build, visualise,\nverify, test, and debug complex hybrid workflows, and immediately deploy them\nto the cloud or a custom distributed environment.",
    "descriptor": "\nComments: Submitted to SC22 Workshop: Quantum Computing Software\n",
    "authors": [
      "Seyon Sivarajah",
      "Lukas Heidemann",
      "Alan Lawrence",
      "Ross Duncan"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.02350"
  },
  {
    "id": "arXiv:2211.02364",
    "title": "Visualising spatio-temporal health data: the importance of capturing the  4th dimension",
    "abstract": "Confronted by a rapidly evolving health threat, such as an infectious disease\noutbreak, it is essential that decision-makers are able to comprehend the\ncomplex dynamics not just in space but also in the 4th dimension, time. In this\npaper this is addressed by a novel visualisation tool, referred to as the\nDynamic Health Atlas web app, which is designed specifically for displaying the\nspatial evolution of data over time while simultaneously acknowledging its\nuncertainty. It is an interactive and open-source web app, coded predominantly\nin JavaScript, in which the geospatial and temporal data are displayed\nside-by-side. The first of two case studies of this visualisation tool relates\nto an outbreak of canine gastroenteric disease in the United Kingdom, where\nmany veterinary practices experienced an unusually high case incidence. The\nsecond study concerns the predicted COVID-19 reproduction number along with\nincidence and prevalence forecasts in each local authority district in the\nUnited Kingdom. These studies demonstrate the effectiveness of the Dynamic\nHealth Atlas web app at conveying geospatial and temporal dynamics along with\ntheir corresponding uncertainties.",
    "descriptor": "\nComments: 4 Figures, 27 pages\n",
    "authors": [
      "Alison C. Hale",
      "Charlotte Appleton",
      "P.-J. M. Noble",
      "Gina L. Pinchbeck",
      "Barry Rowlingson",
      "Peter J. Diggle",
      "Alan D. Radford",
      "Christopher P. Jewell"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.02364"
  },
  {
    "id": "arXiv:2211.02377",
    "title": "Black-box Coreset Variational Inference",
    "abstract": "Recent advances in coreset methods have shown that a selection of\nrepresentative datapoints can replace massive volumes of data for Bayesian\ninference, preserving the relevant statistical information and significantly\naccelerating subsequent downstream tasks. Existing variational coreset\nconstructions rely on either selecting subsets of the observed datapoints, or\njointly performing approximate inference and optimizing pseudodata in the\nobserved space akin to inducing points methods in Gaussian Processes. So far,\nboth approaches are limited by complexities in evaluating their objectives for\ngeneral purpose models, and require generating samples from a typically\nintractable posterior over the coreset throughout inference and testing. In\nthis work, we present a black-box variational inference framework for coresets\nthat overcomes these constraints and enables principled application of\nvariational coresets to intractable models, such as Bayesian neural networks.\nWe apply our techniques to supervised learning problems, and compare them with\nexisting approaches in the literature for data summarization and inference.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Dionysis Manousakas",
      "Hippolyt Ritter",
      "Theofanis Karaletsos"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02377"
  },
  {
    "id": "arXiv:2211.02397",
    "title": "Analysing Diffusion-based Generative Approaches versus Discriminative  Approaches for Speech Restoration",
    "abstract": "Diffusion-based generative models have had a high impact on the computer\nvision and speech processing communities these past years. Besides data\ngeneration tasks, they have also been employed for data restoration tasks like\nspeech enhancement and dereverberation. While discriminative models have\ntraditionally been argued to be more powerful e.g. for speech enhancement,\ngenerative diffusion approaches have recently been shown to narrow this\nperformance gap considerably. In this paper, we systematically compare the\nperformance of generative diffusion models and discriminative approaches on\ndifferent speech restoration tasks. For this, we extend our prior contributions\non diffusion-based speech enhancement in the complex time-frequency domain to\nthe task of bandwith extension. We then compare it to a discriminatively\ntrained neural network with the same network architecture on three restoration\ntasks, namely speech denoising, dereverberation and bandwidth extension. We\nobserve that the generative approach performs globally better than its\ndiscriminative counterpart on all tasks, with the strongest benefit for\nnon-additive distortion models, like in dereverberation and bandwidth\nextension. Code and audio examples can be found online at\nhttps://uhh.de/inf-sp-sgmsemultitask",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Jean-Marie Lemercier",
      "Julius Richter",
      "Simon Welker",
      "Timo Gerkmann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.02397"
  },
  {
    "id": "arXiv:2211.02400",
    "title": "Fighting the scanner effect in brain MRI segmentation with a progressive  level-of-detail network trained on multi-site data",
    "abstract": "Many clinical and research studies of the human brain require an accurate\nstructural MRI segmentation. While traditional atlas-based methods can be\napplied to volumes from any acquisition site, recent deep learning algorithms\nensure very high accuracy only when tested on data from the same sites\nexploited in training (i.e., internal data). The performance degradation\nexperienced on external data (i.e., unseen volumes from unseen sites) is due to\nthe inter-site variabilities in intensity distributions induced by different MR\nscanner models, acquisition parameters, and unique artefacts. To mitigate this\nsite-dependency, often referred to as the scanner effect, we propose LOD-Brain,\na 3D convolutional neural network with progressive levels-of-detail (LOD) able\nto segment brain data from any site. Coarser network levels are responsible to\nlearn a robust anatomical prior useful for identifying brain structures and\ntheir locations, while finer levels refine the model to handle site-specific\nintensity distributions and anatomical variations. We ensure robustness across\nsites by training the model on an unprecedented rich dataset aggregating data\nfrom open repositories: almost 27,000 T1w volumes from around 160 acquisition\nsites, at 1.5 - 3T, from a population spanning from 8 to 90 years old.\nExtensive tests demonstrate that LOD-Brain produces state-of-the-art results,\nwith no significant difference in performance between internal and external\nsites, and robust to challenging anatomical variations. Its portability opens\nthe way for large scale application across different healthcare institutions,\npatient populations, and imaging technology manufacturers. Code, model, and\ndemo are available at the project website.",
    "descriptor": "",
    "authors": [
      "Michele Svanera",
      "Mattia Savardi",
      "Alberto Signoroni",
      "Sergio Benini",
      "Lars Muckli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02400"
  },
  {
    "id": "arXiv:2211.02403",
    "title": "The Path to Autonomous Learners",
    "abstract": "In this paper, we present a new theoretical approach for enabling domain\nknowledge acquisition by intelligent systems. We introduce a hybrid model that\nstarts with minimal input knowledge in the form of an upper ontology of\nconcepts, stores and reasons over this knowledge through a knowledge graph\ndatabase and learns new information through a Logic Neural Network. We study\nthe behavior of this architecture when handling new data and show that the\nfinal system is capable of enriching its current knowledge as well as extending\nit to new domains.",
    "descriptor": "",
    "authors": [
      "Hanna Abi Akl"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.02403"
  },
  {
    "id": "arXiv:2211.02419",
    "title": "High-Resolution Boundary Detection for Medical Image Segmentation with  Piece-Wise Two-Sample T-Test Augmented Loss",
    "abstract": "Deep learning methods have contributed substantially to the rapid advancement\nof medical image segmentation, the quality of which relies on the suitable\ndesign of loss functions. Popular loss functions, including the cross-entropy\nand dice losses, often fall short of boundary detection, thereby limiting\nhigh-resolution downstream applications such as automated diagnoses and\nprocedures. We developed a novel loss function that is tailored to reflect the\nboundary information to enhance the boundary detection. As the contrast between\nsegmentation and background regions along the classification boundary naturally\ninduces heterogeneity over the pixels, we propose the piece-wise two-sample\nt-test augmented (PTA) loss that is infused with the statistical test for such\nheterogeneity. We demonstrate the improved boundary detection power of the PTA\nloss compared to benchmark losses without a t-test component.",
    "descriptor": "",
    "authors": [
      "Yucong Lin",
      "Jinhua Su",
      "Yuhang Li",
      "Yuhao Wei",
      "Hanchao Yan",
      "Saining Zhang",
      "Jiaan Luo",
      "Danni Ai",
      "Hong Song",
      "Jingfan Fan",
      "Tianyu Fu",
      "Deqiang Xiao",
      "Feifei Wang",
      "Jue Hou",
      "Jian Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02419"
  },
  {
    "id": "arXiv:2211.02420",
    "title": "Spatially Selective Deep Non-linear Filters for Speaker Extraction",
    "abstract": "In a scenario with multiple persons talking simultaneously, the spatial\ncharacteristics of the signals are the most distinct feature for extracting the\ntarget signal. In this work, we develop a deep joint spatial-spectral\nnon-linear filter that can be steered in an arbitrary target direction. For\nthis we propose a simple and effective conditioning mechanism, which sets the\ninitial state of the filter's recurrent layers based on the target direction.\nWe show that this scheme is more effective than the baseline approach and\nincreases the flexibility of the filter at no performance cost. The resulting\nspatially selective non-linear filters can also be used for speech separation\nof an arbitrary number of speakers and enable very accurate multi-speaker\nlocalization as we demonstrate in this paper.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Kristina Tesch",
      "Timo Gerkmann"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.02420"
  },
  {
    "id": "arXiv:2211.02475",
    "title": "Generalizability of Deep Adult Lung Segmentation Models to the Pediatric  Population: A Retrospective Study",
    "abstract": "Lung segmentation in chest X-rays (CXRs) is an important prerequisite for\nimproving the specificity of diagnoses of cardiopulmonary diseases in a\nclinical decision support system. Current deep learning (DL) models for lung\nsegmentation are trained and evaluated on CXR datasets in which the\nradiographic projections are captured predominantly from the adult population.\nHowever, the shape of the lungs is reported to be significantly different for\npediatrics across the developmental stages from infancy to adulthood. This\nmight result in age-related data domain shifts that would adversely impact lung\nsegmentation performance when the models trained on the adult population are\ndeployed for pediatric lung segmentation. In this work, our goal is to analyze\nthe generalizability of deep adult lung segmentation models to the pediatric\npopulation and improve performance through a systematic combinatorial approach\nconsisting of CXR modality-specific weight initializations, stacked\ngeneralization, and an ensemble of the stacked generalization models. Novel\nevaluation metrics consisting of Mean Lung Contour Distance and Average Hash\nScore are proposed in addition to the Multi-scale Structural Similarity Index\nMeasure, Intersection of Union, and Dice metrics to evaluate segmentation\nperformance. We observed a significant improvement (p < 0.05) in cross-domain\ngeneralization through our combinatorial approach. This study could serve as a\nparadigm to analyze the cross-domain generalizability of deep segmentation\nmodels for other medical imaging modalities and applications.",
    "descriptor": "\nComments: 11 pages, 7 figures, and 8 tables\n",
    "authors": [
      "Sivaramakrishnan Rajaraman",
      "Feng Yang",
      "Ghada Zamzmi",
      "Zhiyun Xue",
      "Sameer Antani"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02475"
  },
  {
    "id": "arXiv:2211.02476",
    "title": "Sparse Gaussian Process Hyperparameters: Optimize or Integrate?",
    "abstract": "The kernel function and its hyperparameters are the central model selection\nchoice in a Gaussian proces (Rasmussen and Williams, 2006). Typically, the\nhyperparameters of the kernel are chosen by maximising the marginal likelihood,\nan approach known as Type-II maximum likelihood (ML-II). However, ML-II does\nnot account for hyperparameter uncertainty, and it is well-known that this can\nlead to severely biased estimates and an underestimation of predictive\nuncertainty. While there are several works which employ a fully Bayesian\ncharacterisation of GPs, relatively few propose such approaches for the sparse\nGPs paradigm. In this work we propose an algorithm for sparse Gaussian process\nregression which leverages MCMC to sample from the hyperparameter posterior\nwithin the variational inducing point framework of Titsias (2009). This work is\nclosely related to Hensman et al. (2015b) but side-steps the need to sample the\ninducing points, thereby significantly improving sampling efficiency in the\nGaussian likelihood case. We compare this scheme against natural baselines in\nliterature along with stochastic variational GPs (SVGPs) along with an\nextensive computational analysis.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Vidhi Lalchand",
      "Wessel P. Bruinsma",
      "David R. Burt",
      "Carl E. Rasmussen"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.02476"
  },
  {
    "id": "arXiv:2211.02478",
    "title": "Concentration inequalities for leave-one-out cross validation",
    "abstract": "In this article we prove that estimator stability is enough to show that\nleave-one-out cross validation is a sound procedure, by providing concentration\nbounds in a general framework. In particular, we provide concentration bounds\nbeyond Lipschitz continuity assumptions on the loss or on the estimator. In\norder to obtain our results, we rely on random variables with distribution\nsatisfying the logarithmic Sobolev inequality, providing us a relatively rich\nclass of distributions. We illustrate our method by considering several\ninteresting examples, including linear regression, kernel density estimation,\nand stabilized / truncated estimators such as stabilized kernel regression.",
    "descriptor": "",
    "authors": [
      "Benny Avelin",
      "Lauri Viitasaari"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.02478"
  },
  {
    "id": "arXiv:2211.02486",
    "title": "Decorrelation with conditional normalizing flows",
    "abstract": "The sensitivity of many physics analyses can be enhanced by constructing\ndiscriminants that preferentially select signal events. Such discriminants\nbecome much more useful if they are uncorrelated with a set of protected\nattributes. In this paper we show a normalizing flow conditioned on the\nprotected attributes can be used to find a decorrelated representation for any\ndiscriminant. As a normalizing flow is invertible the separation power of the\nresulting discriminant will be unchanged at any fixed value of the protected\nattributes. We demonstrate the efficacy of our approach by building supervised\njet taggers that produce almost no sculpting in the mass distribution of the\nbackground.",
    "descriptor": "",
    "authors": [
      "Samuel Klein",
      "Tobias Golling"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02486"
  },
  {
    "id": "arXiv:2211.02489",
    "title": "Sampling Rate Offset Estimation and Compensation for Distributed  Adaptive Node-Specific Signal Estimation in Wireless Acoustic Sensor Networks",
    "abstract": "Sampling rate offsets (SROs) between devices in a heterogeneous wireless\nacoustic sensor network (WASN) can hinder the ability of distributed adaptive\nalgorithms to perform as intended when they rely on coherent signal processing.\nIn this paper, we present an SRO estimation and compensation method to allow\nthe deployment of the distributed adaptive node-specific signal estimation\n(DANSE) algorithm in WASNs composed of asynchronous devices. The signals\navailable at each node are first utilised in a coherence-drift-based method to\nblindly estimate SROs which are then compensated for via phase shifts in the\nfrequency domain. A modification of the weighted overlap-add (WOLA)\nimplementation of DANSE is introduced to account for SRO-induced full-sample\ndrifts, permitting per-sample signal transmission via an approximation of the\nWOLA process as a time-domain convolution. The performance of the proposed\nalgorithm is evaluated in the context of distributed noise reduction for the\nestimation of a target speech signal in an asynchronous WASN.",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Paul Didier",
      "Toon van Waterschoot",
      "Simon Doclo",
      "Marc Moonen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.02489"
  },
  {
    "id": "arXiv:2211.02506",
    "title": "Neural Feature Predictor and Discriminative Residual Coding for  Low-Bitrate Speech Coding",
    "abstract": "Low and ultra-low-bitrate neural speech coding achieves unprecedented coding\ngain by generating speech signals from compact speech features. This paper\nintroduces additional coding efficiency in neural speech coding by reducing the\ntemporal redundancy existing in the frame-level feature sequence via a\nrecurrent neural predictor. The prediction can achieve a low-entropy residual\nrepresentation, which we discriminatively code based on their contribution to\nthe signal reconstruction. The harmonization of feature prediction and\ndiscriminative coding results in a dynamic bit allocation algorithm that spends\nmore bits on unpredictable but rare events. As a result, we develop a scalable,\nlightweight, low-latency, and low-bitrate neural speech coding system. We\ndemonstrate the advantage of the proposed methods using the LPCNet as a neural\nvocoder. While the proposed method guarantees causality in its prediction, the\nsubjective tests and feature space analysis show that our model achieves\nsuperior coding efficiency compared to LPCNet and Lyra V2 in the very low\nbitrates.",
    "descriptor": "",
    "authors": [
      "Haici Yang",
      "Wootaek Lim",
      "Minje Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.02506"
  },
  {
    "id": "arXiv:2211.02507",
    "title": "Dilations and information flow axioms in categorical probability",
    "abstract": "We study the positivity and causality axioms for Markov categories as\nproperties of dilations and information flow in Markov categories, and in\nvariations thereof for arbitrary semicartesian monoidal categories. These help\nus show that being a positive Markov category is merely an additional property\nof a symmetric monoidal category (rather than extra structure). We also\ncharacterize the positivity of representable Markov categories and prove that\ncausality implies positivity, but not conversely. Finally, we note that\npositivity fails for quasi-Borel spaces and interpret this failure as a privacy\nproperty of probabilistic name generation.",
    "descriptor": "\nComments: 42 pages\n",
    "authors": [
      "Tobias Fritz",
      "Tom\u00e1\u0161 Gonda",
      "Nicholas Gauguin Houghton-Larsen",
      "Paolo Perrone",
      "Dario Stein"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Information Theory (cs.IT)",
      "Logic in Computer Science (cs.LO)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.02507"
  },
  {
    "id": "arXiv:2211.02525",
    "title": "Steiner connectivity problems in hypergraphs",
    "abstract": "We say that a tree $T$ is an $S$-Steiner tree if $S \\subseteq V(T)$ and a\nhypergraph is an $S$-Steiner hypertree if it can be trimmed to an $S$-Steiner\ntree. We prove that it is NP-hard to decide, given a hypergraph $\\mathcal{H}$\nand some $S \\subseteq V(\\mathcal{H})$, whether there is a subhypergraph of\n$\\mathcal{H}$ which is an $S$-Steiner hypertree. As corollaries, we give two\nnegative results for two Steiner orientation problems in hypergraphs. Firstly,\nwe show that it is NP-hard to decide, given a hypergraph $\\mathcal{H}$, some $r\n\\in V(\\mathcal{H})$ and some $S \\subseteq V(\\mathcal{H})$, whether this\nhypergraph has an orientation in which every vertex of $S$ is reachable from\n$r$. Secondly, we show that it is NP-hard to decide, given a hypergraph\n$\\mathcal{H}$ and some $S \\subseteq V(\\mathcal{H})$, whether this hypergraph\nhas an orientation in which any two vertices in $S$ are mutually reachable from\neach other. This answers a longstanding open question of the Egerv\\'ary\nResearch group. On the positive side, we show that the problem of finding a\nSteiner hypertree and the first orientation problem can be solved in polynomial\ntime if the number of terminals $|S|$ is fixed.",
    "descriptor": "",
    "authors": [
      "Florian H\u00f6rsch",
      "Zolt\u00e1n Szigeti"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.02525"
  },
  {
    "id": "arXiv:2211.02527",
    "title": "Cold Diffusion for Speech Enhancement",
    "abstract": "Diffusion models have recently shown promising results for difficult\nenhancement tasks such as the conditional and unconditional restoration of\nnatural images and audio signals. In this work, we explore the possibility of\nleveraging a recently proposed advanced iterative diffusion model, namely cold\ndiffusion, to recover clean speech signals from noisy signals. The unique\nmathematical properties of the sampling process from cold diffusion could be\nutilized to restore high-quality samples from arbitrary degradations. Based on\nthese properties, we propose an improved training algorithm and objective to\nhelp the model generalize better during the sampling process. We verify our\nproposed framework by investigating two model architectures. Experimental\nresults on benchmark speech enhancement dataset VoiceBank-DEMAND demonstrate\nthe strong performance of the proposed approach compared to representative\ndiscriminative models and diffusion-based enhancement models.",
    "descriptor": "\nComments: 5 pages, 1 figure, 1 table, 3 algorithms. Submitted to ICASSP 2023\n",
    "authors": [
      "Hao Yen",
      "Fran\u00e7ois G. Germain",
      "Gordon Wichern",
      "Jonathan Le Roux"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.02527"
  },
  {
    "id": "arXiv:2211.02542",
    "title": "Self-Supervised Learning for Speech Enhancement through Synthesis",
    "abstract": "Modern speech enhancement (SE) networks typically implement noise suppression\nthrough time-frequency masking, latent representation masking, or\ndiscriminative signal prediction. In contrast, some recent works explore SE via\ngenerative speech synthesis, where the system's output is synthesized by a\nneural vocoder after an inherently lossy feature-denoising step. In this paper,\nwe propose a denoising vocoder (DeVo) approach, where a vocoder accepts noisy\nrepresentations and learns to directly synthesize clean speech. We leverage\nrich representations from self-supervised learning (SSL) speech models to\ndiscover relevant features. We conduct a candidate search across 15 potential\nSSL front-ends and subsequently train our vocoder adversarially with the best\nSSL configuration. Additionally, we demonstrate a causal version capable of\nrunning on streaming audio with 10ms latency and minimal performance\ndegradation. Finally, we conduct both objective evaluations and subjective\nlistening studies to show our system improves objective metrics and outperforms\nan existing state-of-the-art SE model subjectively.",
    "descriptor": "",
    "authors": [
      "Bryce Irvin",
      "Marko Stamenovic",
      "Mikolaj Kegler",
      "Li-Chia Yang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.02542"
  },
  {
    "id": "arXiv:2211.02556",
    "title": "Pangu-Weather: A 3D High-Resolution Model for Fast and Accurate Global  Weather Forecast",
    "abstract": "In this paper, we present Pangu-Weather, a deep learning based system for\nfast and accurate global weather forecast. For this purpose, we establish a\ndata-driven environment by downloading $43$ years of hourly global weather data\nfrom the 5th generation of ECMWF reanalysis (ERA5) data and train a few deep\nneural networks with about $256$ million parameters in total. The spatial\nresolution of forecast is $0.25^\\circ\\times0.25^\\circ$, comparable to the ECMWF\nIntegrated Forecast Systems (IFS). More importantly, for the first time, an\nAI-based method outperforms state-of-the-art numerical weather prediction (NWP)\nmethods in terms of accuracy (latitude-weighted RMSE and ACC) of all factors\n(e.g., geopotential, specific humidity, wind speed, temperature, etc.) and in\nall time ranges (from one hour to one week). There are two key strategies to\nimprove the prediction accuracy: (i) designing a 3D Earth Specific Transformer\n(3DEST) architecture that formulates the height (pressure level) information\ninto cubic data, and (ii) applying a hierarchical temporal aggregation\nalgorithm to alleviate cumulative forecast errors. In deterministic forecast,\nPangu-Weather shows great advantages for short to medium-range forecast (i.e.,\nforecast time ranges from one hour to one week). Pangu-Weather supports a wide\nrange of downstream forecast scenarios, including extreme weather forecast\n(e.g., tropical cyclone tracking) and large-member ensemble forecast in\nreal-time. Pangu-Weather not only ends the debate on whether AI-based methods\ncan surpass conventional NWP methods, but also reveals novel directions for\nimproving deep learning weather forecast systems.",
    "descriptor": "\nComments: 19 pages, 13 figures: the first ever AI-based method that outperforms traditional numerical weather prediction methods\n",
    "authors": [
      "Kaifeng Bi",
      "Lingxi Xie",
      "Hengheng Zhang",
      "Xin Chen",
      "Xiaotao Gu",
      "Qi Tian"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02556"
  },
  {
    "id": "arXiv:2211.02566",
    "title": "scikit-fda: A Python Package for Functional Data Analysis",
    "abstract": "The library scikit-fda is a Python package for Functional Data Analysis\n(FDA). It provides a comprehensive set of tools for representation,\npreprocessing, and exploratory analysis of functional data. The library is\nbuilt upon and integrated in Python's scientific ecosystem. In particular, it\nconforms to the scikit-learn application programming interface so as to take\nadvantage of the functionality for machine learning provided by this package:\npipelines, model selection, and hyperparameter tuning, among others. The\nscikit-fda package has been released as free and open-source software under a\n3-Clause BSD license and is open to contributions from the FDA community. The\nlibrary's extensive documentation includes step-by-step tutorials and detailed\nexamples of use.",
    "descriptor": "",
    "authors": [
      "Carlos Ramos-Carre\u00f1o",
      "Jos\u00e9 Luis Torrecilla",
      "Miguel Carbajo-Berrocal",
      "Pablo Marcos",
      "Alberto Su\u00e1rez"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Machine Learning (cs.LG)",
      "Mathematical Software (cs.MS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.02566"
  },
  {
    "id": "arXiv:2211.02577",
    "title": "CCATMos: Convolutional Context-aware Transformer Network for  Non-intrusive Speech Quality Assessment",
    "abstract": "Speech quality assessment has been a critical component in many voice\ncommunication related applications such as telephony and online conferencing.\nTraditional intrusive speech quality assessment requires the clean reference of\nthe degraded utterance to provide an accurate quality measurement. This\nrequirement limits the usability of these methods in real-world scenarios. On\nthe other hand, non-intrusive subjective measurement is the ``golden standard\"\nin evaluating speech quality as human listeners can intrinsically evaluate the\nquality of any degraded speech with ease. In this paper, we propose a novel\nend-to-end model structure called Convolutional Context-Aware Transformer\n(CCAT) network to predict the mean opinion score (MOS) of human raters. We\nevaluate our model on three MOS-annotated datasets spanning multiple languages\nand distortion types and submit our results to the ConferencingSpeech 2022\nChallenge. Our experiments show that CCAT provides promising MOS predictions\ncompared to current state-of-art non-intrusive speech assessment models with\naverage Pearson correlation coefficient (PCC) increasing from 0.530 to 0.697\nand average RMSE decreasing from 0.768 to 0.570 compared to the baseline model\non the challenge evaluation test set.",
    "descriptor": "",
    "authors": [
      "Yuchen Liu",
      "Li-Chia Yang",
      "Alex Pawlicki",
      "Marko Stamenovic"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.02577"
  },
  {
    "id": "arXiv:2211.02600",
    "title": "Improving the Predictive Performances of $k$ Nearest Neighbors Learning  by Efficient Variable Selection",
    "abstract": "This paper computationally demonstrates a sharp improvement in predictive\nperformance for $k$ nearest neighbors thanks to an efficient forward selection\nof the predictor variables. We show both simulated and real-world data that\nthis novel repeatedly approaches outperformance regression models under\nstepwise selection",
    "descriptor": "\nComments: 11 pages, 7 figures\n",
    "authors": [
      "Eddie Pei",
      "Ernest Fokoue"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02600"
  },
  {
    "id": "arXiv:2211.02619",
    "title": "HYDRA-HGR: A Hybrid Transformer-based Architecture for Fusion of  Macroscopic and Microscopic Neural Drive Information",
    "abstract": "Development of advance surface Electromyogram (sEMG)-based Human-Machine\nInterface (HMI) systems is of paramount importance to pave the way towards\nemergence of futuristic Cyber-Physical-Human (CPH) worlds. In this context, the\nmain focus of recent literature was on development of different Deep Neural\nNetwork (DNN)-based architectures that perform Hand Gesture Recognition (HGR)\nat a macroscopic level (i.e., directly from sEMG signals). At the same time,\nadvancements in acquisition of High-Density sEMG signals (HD-sEMG) have\nresulted in a surge of significant interest on sEMG decomposition techniques to\nextract microscopic neural drive information. However, due to complexities of\nsEMG decomposition and added computational overhead, HGR at microscopic level\nis less explored than its aforementioned DNN-based counterparts. In this\nregard, we propose the HYDRA-HGR framework, which is a hybrid model that\nsimultaneously extracts a set of temporal and spatial features through its two\nindependent Vision Transformer (ViT)-based parallel architectures (the so\ncalled Macro and Micro paths). The Macro Path is trained directly on the\npre-processed HD-sEMG signals, while the Micro path is fed with the p-to-p\nvalues of the extracted Motor Unit Action Potentials (MUAPs) of each source.\nExtracted features at macroscopic and microscopic levels are then coupled via a\nFully Connected (FC) fusion layer. We evaluate the proposed hybrid HYDRA-HGR\nframework through a recently released HD-sEMG dataset, and show that it\nsignificantly outperforms its stand-alone counterparts. The proposed HYDRA-HGR\nframework achieves average accuracy of 94.86% for the 250 ms window size, which\nis 5.52% and 8.22% higher than that of the Macro and Micro paths, respectively.",
    "descriptor": "",
    "authors": [
      "Mansooreh Montazerin",
      "Elahe Rahimian",
      "Farnoosh Naderkhani",
      "S. Farokh Atashzar",
      "Hamid Alinejad-Rokny",
      "Arash Mohammadi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02619"
  },
  {
    "id": "arXiv:2211.02620",
    "title": "Time Series Synthesis via Multi-scale Patch-based Generation of Wavelet  Scalogram",
    "abstract": "A framework is proposed for the unconditional generation of synthetic time\nseries based on learning from a single sample in low-data regime case. The\nframework aims at capturing the distribution of patches in wavelet scalogram of\ntime series using single image generative models and producing realistic\nwavelet coefficients for the generation of synthetic time series. It is\ndemonstrated that the framework is effective with respect to fidelity and\ndiversity for time series with insignificant to no trends. Also, the\nperformance is more promising for generating samples with the same duration\n(reshuffling) rather than longer ones (retargeting).",
    "descriptor": "\nComments: 8 pages, 3 figures, 2 tables\n",
    "authors": [
      "Amir Kazemi",
      "Hadi Meidani"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2211.02620"
  },
  {
    "id": "arXiv:2211.02622",
    "title": "PhysioGait: Context-Aware Physiological Context Modeling for Person  Re-identification Attack on Wearable Sensing",
    "abstract": "Person re-identification is a critical privacy breach in publicly shared\nhealthcare data. We investigate the possibility of a new type of privacy threat\non publicly shared privacy insensitive large scale wearable sensing data. In\nthis paper, we investigate user specific biometric signatures in terms of two\ncontextual biometric traits, physiological (photoplethysmography and\nelectrodermal activity) and physical (accelerometer) contexts. In this regard,\nwe propose PhysioGait, a context-aware physiological signal model that consists\nof a Multi-Modal Siamese Convolutional Neural Network (mmSNN) which learns the\nspatial and temporal information individually and performs sensor fusion in a\nSiamese cost with the objective of predicting a person's identity. We evaluated\nPhysioGait attack model using 4 real-time collected datasets (3-data under IRB\n#HP-00064387 and one publicly available data) and two combined datasets\nachieving 89% - 93% accuracy of re-identifying persons.",
    "descriptor": "\nComments: Accepted in IEEE MSN 2022. arXiv admin note: substantial text overlap with arXiv:2106.11900\n",
    "authors": [
      "James O Sullivan",
      "Mohammad Arif Ul Alam"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02622"
  },
  {
    "id": "arXiv:2211.02624",
    "title": "Spatial Graph Signal Interpolation with an Application for Merging BCI  Datasets with Various Dimensionalities",
    "abstract": "BCI Motor Imagery datasets usually are small and have different electrodes\nsetups. When training a Deep Neural Network, one may want to capitalize on all\nthese datasets to increase the amount of data available and hence obtain good\ngeneralization results. To this end, we introduce a spatial graph signal\ninterpolation technique, that allows to interpolate efficiently multiple\nelectrodes. We conduct a set of experiments with five BCI Motor Imagery\ndatasets comparing the proposed interpolation with spherical splines\ninterpolation. We believe that this work provides novel ideas on how to\nleverage graphs to interpolate electrodes and on how to homogenize multiple\ndatasets.",
    "descriptor": "\nComments: Submitted to the 2023 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2023)\n",
    "authors": [
      "Yassine El Ouahidi",
      "Lucas Drumetz",
      "Giulia Lioi",
      "Nicolas Farrugia",
      "Bastien Pasdeloup",
      "Vincent Gripon"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02624"
  },
  {
    "id": "arXiv:2211.02625",
    "title": "MAEEG: Masked Auto-encoder for EEG Representation Learning",
    "abstract": "Decoding information from bio-signals such as EEG, using machine learning has\nbeen a challenge due to the small data-sets and difficulty to obtain labels. We\npropose a reconstruction-based self-supervised learning model, the masked\nauto-encoder for EEG (MAEEG), for learning EEG representations by learning to\nreconstruct the masked EEG features using a transformer architecture. We found\nthat MAEEG can learn representations that significantly improve sleep stage\nclassification (~5% accuracy increase) when only a small number of labels are\ngiven. We also found that input sample lengths and different ways of masking\nduring reconstruction-based SSL pretraining have a huge effect on downstream\nmodel performance. Specifically, learning to reconstruct a larger proportion\nand more concentrated masked signal results in better performance on sleep\nclassification. Our findings provide insight into how reconstruction-based SSL\ncould help representation learning for EEG.",
    "descriptor": "\nComments: 10 pages, 5 figures, accepted by Workshop on Learning from Time Series for Health, NeurIPS2022 as poster presentation\n",
    "authors": [
      "Hsiang-Yun Sherry Chien",
      "Hanlin Goh",
      "Christopher M. Sandino",
      "Joseph Y. Cheng"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02625"
  },
  {
    "id": "arXiv:2211.02626",
    "title": "Leveraging Statistical Shape Priors in GAN-based ECG Synthesis",
    "abstract": "Due to the difficulty of collecting electrocardiogram (ECG) data during\nemergency situations, ECG data generation is an efficient solution for dealing\nwith highly imbalanced ECG training datasets. However, due to the complex\ndynamics of ECG signals, the synthesis of such signals is a challenging task.\nIn this paper, we present a novel approach for ECG signal generation based on\nGenerative Adversarial Networks (GANs). Our approach combines GANs with\nstatistical ECG data modeling to leverage prior knowledge about ECG dynamics in\nthe generation process. To validate the proposed approach, we present\nexperiments using ECG signals from the MIT-BIH arrhythmia database. The\nobtained results show the benefits of modeling temporal and amplitude\nvariations of ECG signals as 2-D shapes in generating realistic signals and\nalso improving the performance of state-of-the-art arrhythmia classification\nbaselines.",
    "descriptor": "\nComments: 6 figures, 26 pages\n",
    "authors": [
      "Nour Neifar",
      "Achraf Ben-Hamadou",
      "Afef Mdhaffar",
      "Mohamed Jmaiel",
      "Bernd Freisleben"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02626"
  },
  {
    "id": "arXiv:2211.02627",
    "title": "An IoT Cloud and Big Data Architecture for the Maintenance of Home  Appliances",
    "abstract": "Billions of interconnected Internet of Things (IoT) sensors and devices\ncollect tremendous amounts of data from real-world scenarios. Big data is\ngenerating increasing interest in a wide range of industries. Once data is\nanalyzed through compute-intensive Machine Learning (ML) methods, it can derive\ncritical business value for organizations. Powerfulplatforms are essential to\nhandle and process such massive collections of information cost-effectively and\nconveniently. This work introduces a distributed and scalable platform\narchitecture that can be deployed for efficient real-world big data collection\nand analytics. The proposed system was tested with a case study for Predictive\nMaintenance of Home Appliances, where current and vibration sensors with high\nacquisition frequency were connected to washing machines and refrigerators. The\nintroduced platform was used to collect, store, and analyze the data. The\nexperimental results demonstrated that the presented system could be\nadvantageous for tackling real-world IoT scenarios in a cost-effective and\nlocal approach.",
    "descriptor": "\nComments: 6 pages, 6 figures, IECON 2022\n",
    "authors": [
      "Pedro Chaves",
      "Tiago Fonseca",
      "Luis Lino Ferreira",
      "Bernardo Cabral",
      "Orlando Sousa",
      "Andre Oliveira",
      "Jorge Landeck"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02627"
  },
  {
    "id": "arXiv:2211.02629",
    "title": "Multi-view Multi-label Fine-grained Emotion Decoding from Human Brain  Activity",
    "abstract": "Decoding emotional states from human brain activity plays an important role\nin brain-computer interfaces. Existing emotion decoding methods still have two\nmain limitations: one is only decoding a single emotion category from a brain\nactivity pattern and the decoded emotion categories are coarse-grained, which\nis inconsistent with the complex emotional expression of human; the other is\nignoring the discrepancy of emotion expression between the left and right\nhemispheres of human brain. In this paper, we propose a novel multi-view\nmulti-label hybrid model for fine-grained emotion decoding (up to 80 emotion\ncategories) which can learn the expressive neural representations and\npredicting multiple emotional states simultaneously. Specifically, the\ngenerative component of our hybrid model is parametrized by a multi-view\nvariational auto-encoder, in which we regard the brain activity of left and\nright hemispheres and their difference as three distinct views, and use the\nproduct of expert mechanism in its inference network. The discriminative\ncomponent of our hybrid model is implemented by a multi-label classification\nnetwork with an asymmetric focal loss. For more accurate emotion decoding, we\nfirst adopt a label-aware module for emotion-specific neural representations\nlearning and then model the dependency of emotional states by a masked\nself-attention mechanism. Extensive experiments on two visually evoked\nemotional datasets show the superiority of our method.",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Neural Networks and Learning Systems\n",
    "authors": [
      "Kaicheng Fu",
      "Changde Du",
      "Shengpei Wang",
      "Huiguang He"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2211.02629"
  },
  {
    "id": "arXiv:2211.02630",
    "title": "Recursive Estimation of User Intent from Noninvasive  Electroencephalography using Discriminative Models",
    "abstract": "We study the problem of inferring user intent from noninvasive\nelectroencephalography (EEG) to restore communication for people with severe\nspeech and physical impairments (SSPI). The focus of this work is improving the\nestimation of posterior symbol probabilities in a typing task. At each\niteration of the typing procedure, a subset of symbols is chosen for the next\nquery based on the current probability estimate. Evidence about the user's\nresponse is collected from event-related potentials (ERP) in order to update\nsymbol probabilities, until one symbol exceeds a predefined confidence\nthreshold. We provide a graphical model describing this task, and derive a\nrecursive Bayesian update rule based on a discriminative probability over label\nvectors for each query, which we approximate using a neural network classifier.\nWe evaluate the proposed method in a simulated typing task and show that it\noutperforms previous approaches based on generative modeling.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Niklas Smedemark-Margulies",
      "Basak Celik",
      "Tales Imbiriba",
      "Aziz Kocanaogullari",
      "Deniz Erdogmus"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02630"
  },
  {
    "id": "arXiv:2211.02631",
    "title": "Data-driven design of fault diagnosis for three-phase PWM rectifier  using random forests technique with transient synthetic features",
    "abstract": "A three-phase pulse-width modulation (PWM) rectifier can usually maintain\noperation when open-circuit faults occur in insulated-gate bipolar transistors\n(IGBTs), which will lead the system to be unstable and unsafe. Aiming at this\nproblem, based on random forests with transient synthetic features, a\ndata-driven online fault diagnosis method is proposed to locate the\nopen-circuit faults of IGBTs timely and effectively in this study. Firstly, by\nanalysing the open-circuit fault features of IGBTs in the three-phase PWM\nrectifier, it is found that the occurrence of the fault features is related to\nthe fault location and time, and the fault features do not always appear\nimmediately with the occurrence of the fault. Secondly, different data-driven\nfault diagnosis methods are compared and evaluated, the performance of random\nforests algorithm is better than that of support vector machine or artificial\nneural networks. Meanwhile, the accuracy of fault diagnosis classifier trained\nby transient synthetic features is higher than that trained by original\nfeatures. Also, the random forests fault diagnosis classifier trained by\nmultiplicative features is the best with fault diagnosis accuracy can reach\n98.32%. Finally, the online fault diagnosis experiments are carried out and the\nresults demonstrate the effectiveness of the proposed method, which can\naccurately locate the open-circuit faults in IGBTs while ensuring system\nsafety.",
    "descriptor": "\nComments: IET Power Electronics\n",
    "authors": [
      "Lei Kou",
      "Chuang Liu",
      "Guo-wei Cai",
      "Jia-ning Zhou",
      "Quan-de Yuan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.02631"
  },
  {
    "id": "arXiv:2211.02632",
    "title": "Fault Diagnosis for Power Electronics Converters based on Deep  Feedforward Network and Wavelet Compression",
    "abstract": "A fault diagnosis method for power electronics converters based on deep\nfeedforward network and wavelet compression is proposed in this paper. The\ntransient historical data after wavelet compression are used to realize the\ntraining of fault diagnosis classifier. Firstly, the correlation analysis of\nthe voltage or current data running in various fault states is performed to\nremove the redundant features and the sampling point. Secondly, the wavelet\ntransform is used to remove the redundant data of the features, and then the\ntraining sample data is greatly compressed. The deep feedforward network is\ntrained by the low frequency component of the features, while the training\nspeed is greatly accelerated. The average accuracy of fault diagnosis\nclassifier can reach over 97%. Finally, the fault diagnosis classifier is\ntested, and final diagnosis result is determined by multiple-groups transient\ndata, by which the reliability of diagnosis results is improved. The\nexperimental result proves that the classifier has strong generalization\nability and can accurately locate the open-circuit faults in IGBTs.",
    "descriptor": "\nComments: Electric Power Systems Research\n",
    "authors": [
      "Lei Kou",
      "Chuang Liu",
      "Guowei Cai",
      "Zhe Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02632"
  },
  {
    "id": "arXiv:2211.02636",
    "title": "Towards Alzheimer's Disease Progression Assessment: A Review of Machine  Learning Methods",
    "abstract": "Alzheimer's Disease (AD), as the most devastating neurodegenerative disease\nworldwide, has reached nearly 10 million new cases annually. Current technology\nprovides unprecedented opportunities to study the progression and etiology of\nthis disease with the advanced in imaging techniques. With the recent emergence\nof a society driven by big data and machine learning (ML), researchers have\nexerted considerable effort to summarize recent advances in ML-based AD\ndiagnosis. Here, we outline some of the most prevalent and recent ML models for\nassessing the progression of AD and provide insights on the challenges,\nopportunities, and future directions that could be advantageous to future\nresearch in AD using ML.",
    "descriptor": "\nComments: 16 pages, 3 figures\n",
    "authors": [
      "Zibin Zhao"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.02636"
  },
  {
    "id": "arXiv:2211.02637",
    "title": "Emotion Recognition With Temporarily Localized 'Emotional Events' in  Naturalistic Context",
    "abstract": "Emotion recognition using EEG signals is an emerging area of research due to\nits broad applicability in BCI. Emotional feelings are hard to stimulate in the\nlab. Emotions do not last long, yet they need enough context to be perceived\nand felt. However, most EEG-related emotion databases either suffer from\nemotionally irrelevant details (due to prolonged duration stimulus) or have\nminimal context doubting the feeling of any emotion using the stimulus. We\ntried to reduce the impact of this trade-off by designing an experiment in\nwhich participants are free to report their emotional feelings simultaneously\nwatching the emotional stimulus. We called these reported emotional feelings\n\"Emotional Events\" in our Dataset on Emotion with Naturalistic Stimuli (DENS).\nWe used EEG signals to classify emotional events on different combinations of\nValence(V) and Arousal(A) dimensions and compared the results with benchmark\ndatasets of DEAP and SEED. STFT is used for feature extraction and used in the\nclassification model consisting of CNN-LSTM hybrid layers. We achieved\nsignificantly higher accuracy with our data compared to DEEP and SEED data. We\nconclude that having precise information about emotional feelings improves the\nclassification accuracy compared to long-duration EEG signals which might be\ncontaminated by mind-wandering.",
    "descriptor": "",
    "authors": [
      "Mohammad Asif",
      "Sudhakar Mishra",
      "Majithia Tejas Vinodbhai",
      "Uma Shanker Tiwary"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02637"
  },
  {
    "id": "arXiv:2211.02638",
    "title": "A Knowledge Distillation Framework For Enhancing Ear-EEG Based Sleep  Staging With Scalp-EEG Data",
    "abstract": "Sleep plays a crucial role in the well-being of human lives. Traditional\nsleep studies using Polysomnography are associated with discomfort and often\nlower sleep quality caused by the acquisition setup. Previous works have\nfocused on developing less obtrusive methods to conduct high-quality sleep\nstudies, and ear-EEG is among popular alternatives. However, the performance of\nsleep staging based on ear-EEG is still inferior to scalp-EEG based sleep\nstaging. In order to address the performance gap between scalp-EEG and ear-EEG\nbased sleep staging, we propose a cross-modal knowledge distillation strategy,\nwhich is a domain adaptation approach. Our experiments and analysis validate\nthe effectiveness of the proposed approach with existing architectures, where\nit enhances the accuracy of the ear-EEG based sleep staging by 3.46% and\nCohen's kappa coefficient by a margin of 0.038.",
    "descriptor": "\nComments: Code available at : this https URL\n",
    "authors": [
      "Mithunjha Anandakumar",
      "Jathurshan Pradeepkumar",
      "Simon L. Kappel",
      "Chamira U. S. Edussooriya",
      "Anjula C. De Silva"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02638"
  },
  {
    "id": "arXiv:2211.02639",
    "title": "PIPPI2021: An Approach to Automated Diagnosis and Texture Analysis of  the Fetal Liver & Placenta in Fetal Growth Restriction",
    "abstract": "Fetal growth restriction (FGR) is a prevalent pregnancy condition\ncharacterised by failure of the fetus to reach its genetically predetermined\ngrowth potential. We explore the application of model fitting techniques,\nlinear regression machine learning models, deep learning regression, and\nHaralick textured features from multi-contrast MRI for multi-fetal organ\nanalysis of FGR. We employed T2 relaxometry and diffusion-weighted MRI datasets\n(using a combined T2-diffusion scan) for 12 normally grown and 12 FGR\ngestational age (GA) matched pregnancies. We applied the Intravoxel Incoherent\nMotion Model and novel multi-compartment models for MRI fetal analysis, which\nexhibit potential to provide a multi-organ FGR assessment, overcoming the\nlimitations of empirical indicators - such as abnormal artery Doppler findings\n- to evaluate placental dysfunction. The placenta and fetal liver presented key\ndifferentiators between FGR and normal controls (decreased perfusion, abnormal\nfetal blood motion and reduced fetal blood oxygenation. This may be associated\nwith the preferential shunting of the fetal blood towards the fetal brain.\nThese features were further explored to determine their role in assessing FGR\nseverity, by employing simple machine learning models to predict FGR diagnosis\n(100\\% accuracy in test data, n=5), GA at delivery, time from MRI scan to\ndelivery, and baby weight. Moreover, we explored the use of deep learning to\nregress the latter three variables. Image texture analysis of the fetal organs\ndemonstrated prominent textural variations in the placental perfusion fractions\nmaps between the groups (p$<$0.0009), and spatial differences in the incoherent\nfetal capillary blood motion in the liver (p$<$0.009). This research serves as\na proof-of-concept, investigating the effect of FGR on fetal organs.",
    "descriptor": "",
    "authors": [
      "Aya Mutaz Zeidan",
      "Paula Ramirez Gilliland",
      "Ashay Patel",
      "Zhanchong Ou",
      "Dimitra Flouri",
      "Nada Mufti",
      "Kasia Maksym",
      "Rosalind Aughwane",
      "Sebastien Ourselin",
      "Anna David",
      "Andrew Melbourne"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02639"
  },
  {
    "id": "arXiv:2211.02641",
    "title": "Graph Neural Networks on SPD Manifolds for Motor Imagery Classification:  A Perspective from the Time-Frequency Analysis",
    "abstract": "Motor imagery (MI) classification is one of the most widely-concern research\ntopics in Electroencephalography (EEG)-based brain-computer interfaces (BCIs)\nwith extensive industry value. The MI-EEG classifiers' tendency has changed\nfundamentally over the past twenty years, while classifiers' performance is\ngradually increasing. In particular, owing to the need for characterizing\nsignals' non-Euclidean inherence, the first geometric deep learning (GDL)\nframework, Tensor-CSPNet, has recently emerged in the BCI study. In essence,\nTensor-CSPNet is a deep learning-based classifier on the second-order\nstatistics of EEGs. In contrast to the first-order statistics, using these\nsecond-order statistics is the classical treatment of EEG signals, and the\ndiscriminative information contained in these second-order statistics is\nadequate for MI-EEG classification. In this study, we present another GDL\nclassifier for MI-EEG classification called Graph-CSPNet, using graph-based\ntechniques to simultaneously characterize the EEG signals in both the time and\nfrequency domains. It is realized from the perspective of the time-frequency\nanalysis that profoundly influences signal processing and BCI studies. Contrary\nto Tensor-CSPNet, the architecture of Graph-CSPNet is further simplified with\nmore flexibility to cope with variable time-frequency resolution for signal\nsegmentation to capture the localized fluctuations. In the experiments,\nGraph-CSPNet is evaluated on subject-specific scenarios from two well-used\nMI-EEG datasets and produces near-optimal classification accuracies.",
    "descriptor": "\nComments: 16 pages, 5 figures, 9 Tables; This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Ce Ju",
      "Cuntai Guan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02641"
  },
  {
    "id": "arXiv:2211.02642",
    "title": "A Meta-GNN approach to personalized seizure detection and classification",
    "abstract": "In this paper, we propose a personalized seizure detection and classification\nframework that quickly adapts to a specific patient from limited seizure\nsamples. We achieve this by combining two novel paradigms that have recently\nseen much success in a wide variety of real-world applications: graph neural\nnetworks (GNN), and meta-learning. We train a Meta-GNN based classifier that\nlearns a global model from a set of training patients such that this global\nmodel can eventually be adapted to a new unseen patient using very limited\nsamples. We apply our approach on the TUSZ-dataset, one of the largest and\npublicly available benchmark datasets for epilepsy. We show that our method\noutperforms the baselines by reaching 82.7% on accuracy and 82.08% on F1 score\nafter only 20 iterations on new unseen patients.",
    "descriptor": "",
    "authors": [
      "Abdellah Rahmani",
      "Arun Venkitaraman",
      "Pascal Frossard"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02642"
  },
  {
    "id": "arXiv:2211.02645",
    "title": "Safe Zeroth-Order Convex Optimization Using Quadratic Local  Approximations",
    "abstract": "We address black-box convex optimization problems, where the objective and\nconstraint functions are not explicitly known but can be sampled within the\nfeasible set. The challenge is thus to generate a sequence of feasible points\nconverging towards an optimal solution. By leveraging the knowledge of the\nsmoothness properties of the objective and constraint functions, we propose a\nnovel zeroth-order method, SZO-QQ, that iteratively computes quadratic\napproximations of the constraint functions, constructs local feasible sets and\noptimizes over them. We prove convergence of the sequence of the objective\nvalues generated at each iteration to the minimum. Through experiments, we show\nthat our method can achieve faster convergence compared with state-of-the-art\nzeroth-order approaches to convex optimization.",
    "descriptor": "",
    "authors": [
      "Baiwei Guo",
      "Yuning Jiang",
      "Maryam Kamgarpour",
      "Giancarlo Ferrari Trecate"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.02645"
  },
  {
    "id": "arXiv:1907.08083",
    "title": "Laptop Theft in a University Setting can be Avoided with Warnings",
    "abstract": "Comments: The results in this paper are erroneous. Due to selection bias, the results are not statistically significant",
    "descriptor": "\nComments: The results in this paper are erroneous. Due to selection bias, the results are not statistically significant\n",
    "authors": [
      "Azqa Nadeem",
      "Marianne Junger"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/1907.08083"
  },
  {
    "id": "arXiv:1910.02138",
    "title": "A Method of EV Detour-to-Recharge Behavior Modeling and Charging Station  Deployment",
    "abstract": "A Method of EV Detour-to-Recharge Behavior Modeling and Charging Station  Deployment",
    "descriptor": "",
    "authors": [
      "Tianshu Ouyang",
      "Jiahong Cai",
      "Yuxuan Gao",
      "Xinyan He",
      "Huimiao Chen",
      "Kexin Hang"
    ],
    "subjectives": [
      "Other Computer Science (cs.OH)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1910.02138"
  },
  {
    "id": "arXiv:2001.04383",
    "title": "MIP*=RE",
    "abstract": "Comments: 223 pages. v3: Typos corrected, minor improvements to presentation",
    "descriptor": "\nComments: 223 pages. v3: Typos corrected, minor improvements to presentation\n",
    "authors": [
      "Zhengfeng Ji",
      "Anand Natarajan",
      "Thomas Vidick",
      "John Wright",
      "Henry Yuen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Operator Algebras (math.OA)"
    ],
    "url": "https://arxiv.org/abs/2001.04383"
  },
  {
    "id": "arXiv:2004.09677",
    "title": "Approximate exploitability: Learning a best response in large games",
    "abstract": "Approximate exploitability: Learning a best response in large games",
    "descriptor": "",
    "authors": [
      "Finbarr Timbers",
      "Nolan Bard",
      "Edward Lockhart",
      "Marc Lanctot",
      "Martin Schmid",
      "Neil Burch",
      "Julian Schrittwieser",
      "Thomas Hubert",
      "Michael Bowling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.09677"
  },
  {
    "id": "arXiv:2010.07604",
    "title": "Sequential Likelihood-Free Inference with Neural Proposal",
    "abstract": "Sequential Likelihood-Free Inference with Neural Proposal",
    "descriptor": "",
    "authors": [
      "Dongjun Kim",
      "Kyungwoo Song",
      "YoonYeong Kim",
      "Yongjin Shin",
      "Wanmo Kang",
      "Il-Chul Moon",
      "Weonyoung Joo"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.07604"
  },
  {
    "id": "arXiv:2102.06196",
    "title": "Approximation Methods for Geometric Regulation",
    "abstract": "Comments: 27 pages, 1 figure",
    "descriptor": "\nComments: 27 pages, 1 figure\n",
    "authors": [
      "Eugenio Aulisa",
      "David S. Gilliam"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2102.06196"
  },
  {
    "id": "arXiv:2102.07770",
    "title": "Neural Posterior Regularization for Likelihood-Free Inference",
    "abstract": "Neural Posterior Regularization for Likelihood-Free Inference",
    "descriptor": "",
    "authors": [
      "Dongjun Kim",
      "Kyungwoo Song",
      "Seungjae Shin",
      "Wanmo Kang",
      "Il-Chul Moon",
      "Weonyoung Joo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.07770"
  },
  {
    "id": "arXiv:2103.00053",
    "title": "PURSUhInT: In Search of Informative Hint Points Based on Layer  Clustering for Knowledge Distillation",
    "abstract": "Comments: Our codes are published on Code Ocean, where the link to our codes is: this https URL",
    "descriptor": "\nComments: Our codes are published on Code Ocean, where the link to our codes is: this https URL\n",
    "authors": [
      "Reyhan Kevser Keser",
      "Aydin Ayanzadeh",
      "Omid Abdollahi Aghdam",
      "Caglar Kilcioglu",
      "Behcet Ugur Toreyin",
      "Nazim Kemal Ure"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.00053"
  },
  {
    "id": "arXiv:2103.01955",
    "title": "The Surprising Effectiveness of PPO in Cooperative, Multi-Agent Games",
    "abstract": "Comments: This paper has been accepted by NeurIPS 2022 Datasets and Benchmarks",
    "descriptor": "\nComments: This paper has been accepted by NeurIPS 2022 Datasets and Benchmarks\n",
    "authors": [
      "Chao Yu",
      "Akash Velu",
      "Eugene Vinitsky",
      "Jiaxuan Gao",
      "Yu Wang",
      "Alexandre Bayen",
      "Yi Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2103.01955"
  },
  {
    "id": "arXiv:2104.13915",
    "title": "Deep Learning for Rheumatoid Arthritis: Joint Detection and Damage  Scoring in X-rays",
    "abstract": "Comments: Presented at the Workshop on AI for Public Health at ICLR 2021",
    "descriptor": "\nComments: Presented at the Workshop on AI for Public Health at ICLR 2021\n",
    "authors": [
      "Krzysztof Maziarz",
      "Anna Krason",
      "Zbigniew Wojna"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.13915"
  },
  {
    "id": "arXiv:2105.02172",
    "title": "Goodness of Causal Fit",
    "abstract": "Comments: This second version has major changes. Most notably, it introduces what we call the hospitality of a node and defines GCF in terms of hospitalities",
    "descriptor": "\nComments: This second version has major changes. Most notably, it introduces what we call the hospitality of a node and defines GCF in terms of hospitalities\n",
    "authors": [
      "Robert R. Tucci"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.02172"
  },
  {
    "id": "arXiv:2105.14261",
    "title": "Computing with Infinite Objects: the Gray Code Case",
    "abstract": "Computing with Infinite Objects: the Gray Code Case",
    "descriptor": "",
    "authors": [
      "Dieter Spreen",
      "Ulrich Berger"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2105.14261"
  },
  {
    "id": "arXiv:2106.01741",
    "title": "Lifetime policy reuse and the importance of task capacity",
    "abstract": "Lifetime policy reuse and the importance of task capacity",
    "descriptor": "",
    "authors": [
      "David M. Bossens",
      "Adam J. Sobey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2106.01741"
  },
  {
    "id": "arXiv:2106.03425",
    "title": "An Algorithmic Meta-Theorem for Graph Modification to Planarity and FOL",
    "abstract": "An Algorithmic Meta-Theorem for Graph Modification to Planarity and FOL",
    "descriptor": "",
    "authors": [
      "Fedor V. Fomin",
      "Petr A. Golovach",
      "Giannos Stamoulis",
      "Dimitrios M. Thilikos"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2106.03425"
  },
  {
    "id": "arXiv:2106.10895",
    "title": "Posets with Interfaces as a Model for Concurrency",
    "abstract": "Posets with Interfaces as a Model for Concurrency",
    "descriptor": "",
    "authors": [
      "Uli Fahrenberg",
      "Christian Johansen",
      "Georg Struth",
      "Krzysztof Ziemia\u0144ski"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2106.10895"
  },
  {
    "id": "arXiv:2109.04995",
    "title": "A Systematic Review of Extended Reality (XR) for Understanding and  Augmenting Vision Loss",
    "abstract": "A Systematic Review of Extended Reality (XR) for Understanding and  Augmenting Vision Loss",
    "descriptor": "",
    "authors": [
      "Justin Kasowski",
      "Byron A. Johnson",
      "Ryan Neydavood",
      "Anvitha Akkaraju",
      "Michael Beyeler"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.04995"
  },
  {
    "id": "arXiv:2110.00244",
    "title": "Lightweight Transformer in Federated Setting for Human Activity  Recognition",
    "abstract": "Comments: Submitted to Journal of Biomedical Informatics",
    "descriptor": "\nComments: Submitted to Journal of Biomedical Informatics\n",
    "authors": [
      "Ali Raza",
      "Kim Phuc Tran",
      "Ludovic Koehl",
      "Shujun Li",
      "Xianyi Zeng",
      "Khaled Benzaidi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.00244"
  },
  {
    "id": "arXiv:2110.00504",
    "title": "Adwords with Unknown Budgets and Beyond",
    "abstract": "Adwords with Unknown Budgets and Beyond",
    "descriptor": "",
    "authors": [
      "Rajan Udwani"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.00504"
  },
  {
    "id": "arXiv:2110.11133",
    "title": "Newton-Type Methods For Simultaneous Matrix Diagonalization",
    "abstract": "Comments: Calcolo, Springer Verlag, 2022",
    "descriptor": "\nComments: Calcolo, Springer Verlag, 2022\n",
    "authors": [
      "Rima Khouja",
      "Bernard Mourrain",
      "Jean-Claude Yakoubsohn"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.11133"
  },
  {
    "id": "arXiv:2110.11333",
    "title": "Detecting Anti-Vaccine Users on Twitter",
    "abstract": "Detecting Anti-Vaccine Users on Twitter",
    "descriptor": "",
    "authors": [
      "Matheus Schmitz",
      "Goran Muri\u0107",
      "Keith Burghardt"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.11333"
  },
  {
    "id": "arXiv:2110.12661",
    "title": "ZerO Initialization: Initializing Neural Networks with only Zeros and  Ones",
    "abstract": "ZerO Initialization: Initializing Neural Networks with only Zeros and  Ones",
    "descriptor": "",
    "authors": [
      "Jiawei Zhao",
      "Florian Sch\u00e4fer",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.12661"
  },
  {
    "id": "arXiv:2111.00107",
    "title": "The Golden Rule as a Heuristic to Measure the Fairness of Texts Using  Machine Learning",
    "abstract": "The Golden Rule as a Heuristic to Measure the Fairness of Texts Using  Machine Learning",
    "descriptor": "",
    "authors": [
      "Ahmed Izzidien",
      "David Stillwell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.00107"
  },
  {
    "id": "arXiv:2111.01108",
    "title": "Resource-Efficient Federated Learning",
    "abstract": "Comments: Accepted to appear in ACM EuroSys 2023",
    "descriptor": "\nComments: Accepted to appear in ACM EuroSys 2023\n",
    "authors": [
      "Ahmed M. Abdelmoniem",
      "Atal Narayan Sahu",
      "Marco Canini",
      "Suhaib A. Fahmy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2111.01108"
  },
  {
    "id": "arXiv:2111.02755",
    "title": "Compound Logics for Modification Problems",
    "abstract": "Compound Logics for Modification Problems",
    "descriptor": "",
    "authors": [
      "Fedor V. Fomin",
      "Petr A. Golovach",
      "Ignasi Sau",
      "Giannos Stamoulis",
      "Dimitrios M. Thilikos"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Logic in Computer Science (cs.LO)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.02755"
  },
  {
    "id": "arXiv:2111.03151",
    "title": "Foundations of Transaction Fee Mechanism Design",
    "abstract": "Foundations of Transaction Fee Mechanism Design",
    "descriptor": "",
    "authors": [
      "Hao Chung",
      "Elaine Shi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2111.03151"
  },
  {
    "id": "arXiv:2111.12493",
    "title": "Time and Memory Efficient Parallel Algorithm for Structural Graph  Summaries and two Extensions to Incremental Summarization and  $k$-Bisimulation for Long $k$-Chaining",
    "abstract": "Time and Memory Efficient Parallel Algorithm for Structural Graph  Summaries and two Extensions to Incremental Summarization and  $k$-Bisimulation for Long $k$-Chaining",
    "descriptor": "",
    "authors": [
      "Till Blume",
      "Jannik Rau",
      "David Richerby",
      "Ansgar Scherp"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2111.12493"
  },
  {
    "id": "arXiv:2112.08321",
    "title": "Know Thy Strengths: Comprehensive Dialogue State Tracking Diagnostics",
    "abstract": "Comments: EMNLP2022",
    "descriptor": "\nComments: EMNLP2022\n",
    "authors": [
      "Hyundong Cho",
      "Chinnadhurai Sankar",
      "Christopher Lin",
      "Kaushik Ram Sadagopan",
      "Shahin Shayandeh",
      "Asli Celikyilmaz",
      "Jonathan May",
      "Ahmad Beirami"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.08321"
  },
  {
    "id": "arXiv:2112.09802",
    "title": "Automated Domain Discovery from Multiple Sources to Improve Zero-Shot  Generalization",
    "abstract": "Automated Domain Discovery from Multiple Sources to Improve Zero-Shot  Generalization",
    "descriptor": "",
    "authors": [
      "Kowshik Thopalli",
      "Sameeksha Katoch",
      "Pavan Turaga",
      "Jayaraman J. Thiagarajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.09802"
  },
  {
    "id": "arXiv:2112.10028",
    "title": "A Distance-Based Side-Channel Attack in Non Uniform Cache and Possible  Defenses",
    "abstract": "A Distance-Based Side-Channel Attack in Non Uniform Cache and Possible  Defenses",
    "descriptor": "",
    "authors": [
      "Farabi Mahmud",
      "Sungkeun Kim",
      "Harpreet Singh Chawla",
      "Pritam Majumder",
      "Jiayi Huang",
      "Chia-Che Tsai",
      "Eun Jung Kim",
      "Abdullah Muzahid"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2112.10028"
  },
  {
    "id": "arXiv:2201.05119",
    "title": "Pushing the limits of self-supervised ResNets: Can we outperform  supervised learning without labels on ImageNet?",
    "abstract": "Pushing the limits of self-supervised ResNets: Can we outperform  supervised learning without labels on ImageNet?",
    "descriptor": "",
    "authors": [
      "Nenad Tomasev",
      "Ioana Bica",
      "Brian McWilliams",
      "Lars Buesing",
      "Razvan Pascanu",
      "Charles Blundell",
      "Jovana Mitrovic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.05119"
  },
  {
    "id": "arXiv:2201.09490",
    "title": "Dual Preference Distribution Learning for Item Recommendation",
    "abstract": "Comments: 23 pages, 7 figures. This manuscript has been accepted by ACM Transactions on Information Systems",
    "descriptor": "\nComments: 23 pages, 7 figures. This manuscript has been accepted by ACM Transactions on Information Systems\n",
    "authors": [
      "Xue Dong",
      "Xuemeng Song",
      "Na Zheng",
      "Yinwei Wei",
      "Zhongzhou Zhao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2201.09490"
  },
  {
    "id": "arXiv:2201.12855",
    "title": "AI-Augmented Business Process Management Systems: A Research Manifesto",
    "abstract": "Comments: 19 pages, 1 figure",
    "descriptor": "\nComments: 19 pages, 1 figure\n",
    "authors": [
      "Marlon Dumas",
      "Fabiana Fournier",
      "Lior Limonad",
      "Andrea Marrella",
      "Marco Montali",
      "Jana-Rebecca Rehse",
      "Rafael Accorsi",
      "Diego Calvanese",
      "Giuseppe De Giacomo",
      "Dirk Fahland",
      "Avigdor Gal",
      "Marcello La Rosa",
      "Hagen V\u00f6lzer",
      "Ingo Weber"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.12855"
  },
  {
    "id": "arXiv:2202.04773",
    "title": "A Neural Network Model of Continual Learning with Cognitive Control",
    "abstract": "Comments: 7 pages, 5 figures, paper accepted as a talk to CogSci 2022 (this https URL)",
    "descriptor": "\nComments: 7 pages, 5 figures, paper accepted as a talk to CogSci 2022 (this https URL)\n",
    "authors": [
      "Jacob Russin",
      "Maryam Zolfaghar",
      "Seongmin A. Park",
      "Erie Boorman",
      "Randall C. O'Reilly"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.04773"
  },
  {
    "id": "arXiv:2202.05452",
    "title": "Information Design for Differential Privacy",
    "abstract": "Information Design for Differential Privacy",
    "descriptor": "",
    "authors": [
      "Ian M. Schmutte",
      "Nathan Yoder"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.05452"
  },
  {
    "id": "arXiv:2202.09215",
    "title": "\"Who Is Next in Line?'' On the Significance of Knowing the Arrival Order  in Bayesian Online Settings",
    "abstract": "\"Who Is Next in Line?'' On the Significance of Knowing the Arrival Order  in Bayesian Online Settings",
    "descriptor": "",
    "authors": [
      "Tomer Ezra",
      "Michal Feldman",
      "Nick Gravin",
      "Zhihao Gavin Tang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.09215"
  },
  {
    "id": "arXiv:2202.10589",
    "title": "Off-Policy Confidence Interval Estimation with Confounded Markov  Decision Process",
    "abstract": "Off-Policy Confidence Interval Estimation with Confounded Markov  Decision Process",
    "descriptor": "",
    "authors": [
      "Chengchun Shi",
      "Jin Zhu",
      "Ye Shen",
      "Shikai Luo",
      "Hongtu Zhu",
      "Rui Song"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.10589"
  },
  {
    "id": "arXiv:2202.10688",
    "title": "Graph Lifelong Learning: A Survey",
    "abstract": "Comments: 19 pages, 4 figures",
    "descriptor": "\nComments: 19 pages, 4 figures\n",
    "authors": [
      "Falih Gozi Febrinanto",
      "Feng Xia",
      "Kristen Moore",
      "Chandra Thapa",
      "Charu Aggarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.10688"
  },
  {
    "id": "arXiv:2202.10890",
    "title": "HiP: Hierarchical Perceiver",
    "abstract": "HiP: Hierarchical Perceiver",
    "descriptor": "",
    "authors": [
      "Joao Carreira",
      "Skanda Koppula",
      "Daniel Zoran",
      "Adria Recasens",
      "Catalin Ionescu",
      "Olivier Henaff",
      "Evan Shelhamer",
      "Relja Arandjelovic",
      "Matt Botvinick",
      "Oriol Vinyals",
      "Karen Simonyan",
      "Andrew Zisserman",
      "Andrew Jaegle"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.10890"
  },
  {
    "id": "arXiv:2203.00479",
    "title": "Uncertainty Estimation for Computed Tomography with a Linearised Deep  Image Prior",
    "abstract": "Uncertainty Estimation for Computed Tomography with a Linearised Deep  Image Prior",
    "descriptor": "",
    "authors": [
      "Javier Antor\u00e1n",
      "Riccardo Barbano",
      "Johannes Leuschner",
      "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato",
      "Bangti Jin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.00479"
  },
  {
    "id": "arXiv:2203.00508",
    "title": "Reconfigurable Intelligent Surface-Aided Spectrum Sharing Coexisting  with Multiple Primary Networks",
    "abstract": "Reconfigurable Intelligent Surface-Aided Spectrum Sharing Coexisting  with Multiple Primary Networks",
    "descriptor": "",
    "authors": [
      "Zhong Tian",
      "Zhengchuan Chen",
      "Min Wang",
      "Yunjian Jia",
      "Wanli Wen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.00508"
  },
  {
    "id": "arXiv:2203.01845",
    "title": "MooAFEM: An object oriented Matlab code for higher-order adaptive FEM  for (nonlinear) elliptic PDEs",
    "abstract": "MooAFEM: An object oriented Matlab code for higher-order adaptive FEM  for (nonlinear) elliptic PDEs",
    "descriptor": "",
    "authors": [
      "Michael Innerberger",
      "Dirk Praetorius"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2203.01845"
  },
  {
    "id": "arXiv:2203.02576",
    "title": "Machine Learning Simulates Agent-Based Model Towards Policy",
    "abstract": "Comments: 32 pages, 9 tables, 3 figures",
    "descriptor": "\nComments: 32 pages, 9 tables, 3 figures\n",
    "authors": [
      "Bernardo Alves Furtado",
      "Gustavo Onofre Andre\u00e3o"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2203.02576"
  },
  {
    "id": "arXiv:2203.03406",
    "title": "Geodetic convexity and Kneser graphs",
    "abstract": "Comments: 1 figure",
    "descriptor": "\nComments: 1 figure\n",
    "authors": [
      "Marcos Bedo",
      "Jo\u00e3o V. S. Leite",
      "Rodolfo A. Oliveira",
      "F\u00e1bio Protti"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2203.03406"
  },
  {
    "id": "arXiv:2203.03451",
    "title": "Black-Box Safety Validation of Autonomous Systems: A Multi-Fidelity  Reinforcement Learning Approach",
    "abstract": "Comments: 8 pages, 6 figures, 2 Algorithms, submitted to the 2023 American Controls Conference, San Diego, CA, USA",
    "descriptor": "\nComments: 8 pages, 6 figures, 2 Algorithms, submitted to the 2023 American Controls Conference, San Diego, CA, USA\n",
    "authors": [
      "Jared J. Beard",
      "Ali Baheri"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.03451"
  },
  {
    "id": "arXiv:2203.03854",
    "title": "Metaverse: Security and Privacy Concerns",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Ruoyu Zhao",
      "Yushu Zhang",
      "Youwen Zhu",
      "Rushi Lan",
      "Zhongyun Hua"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2203.03854"
  },
  {
    "id": "arXiv:2203.03929",
    "title": "Quantifying Privacy Risks of Masked Language Models Using Membership  Inference Attacks",
    "abstract": "Quantifying Privacy Risks of Masked Language Models Using Membership  Inference Attacks",
    "descriptor": "",
    "authors": [
      "Fatemehsadat Mireshghallah",
      "Kartik Goyal",
      "Archit Uniyal",
      "Taylor Berg-Kirkpatrick",
      "Reza Shokri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.03929"
  },
  {
    "id": "arXiv:2203.06361",
    "title": "Preserving Lagrangian structure in data-driven reduced-order modeling of  large-scale dynamical systems",
    "abstract": "Preserving Lagrangian structure in data-driven reduced-order modeling of  large-scale dynamical systems",
    "descriptor": "",
    "authors": [
      "Harsh Sharma",
      "Boris Kramer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.06361"
  },
  {
    "id": "arXiv:2203.07429",
    "title": "Planar Bipedal Locomotion with Nonlinear Model Predictive Control:  Online Gait Generation using Whole-Body Dynamics",
    "abstract": "Comments: 8 pages, 6 figures, accepted to Humanoids 2022",
    "descriptor": "\nComments: 8 pages, 6 figures, accepted to Humanoids 2022\n",
    "authors": [
      "Manuel Y. Galliker",
      "Noel Csomay-Shanklin",
      "Ruben Grandia",
      "Andrew J. Taylor",
      "Farbod Farshidian",
      "Marco Hutter",
      "Aaron D. Ames"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.07429"
  },
  {
    "id": "arXiv:2203.10800",
    "title": "Graph Neural Networks for Wireless Communications: From Theory to  Practice",
    "abstract": "Graph Neural Networks for Wireless Communications: From Theory to  Practice",
    "descriptor": "",
    "authors": [
      "Yifei Shen",
      "Jun Zhang",
      "S.H. Song",
      "Khaled B. Letaief"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.10800"
  },
  {
    "id": "arXiv:2204.00318",
    "title": "Towards gain tuning for numerical KKL observers",
    "abstract": "Towards gain tuning for numerical KKL observers",
    "descriptor": "",
    "authors": [
      "Mona Buisson-Fenet",
      "Lukas Bahr",
      "Valery Morgenthaler",
      "Florent Di Meglio"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.00318"
  },
  {
    "id": "arXiv:2204.07619",
    "title": "Transfer Importance Sampling -- How Testing Automated Vehicles in  Multiple Test Setups Helps With the Bias-Variance Tradeoff",
    "abstract": "Comments: 6 pages, 5 figures, 1 table",
    "descriptor": "\nComments: 6 pages, 5 figures, 1 table\n",
    "authors": [
      "Max Winkelmann",
      "Constantin Vasconi",
      "Steffen M\u00fcller"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.07619"
  },
  {
    "id": "arXiv:2204.09472",
    "title": "Modeling and Executing Production Processes with Capabilities and Skills  using Ontologies and BPMN",
    "abstract": "Comments: \\c{opyright} 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "descriptor": "\nComments: \\c{opyright} 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Aljosha K\u00f6cher",
      "Luis Miguel Vieira da Silva",
      "Alexander Fay"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.09472"
  },
  {
    "id": "arXiv:2204.11817",
    "title": "Translation between Molecules and Natural Language",
    "abstract": "Comments: Accepted at EMNLP 2022. Data and code can be found on [Github](this https URL)",
    "descriptor": "\nComments: Accepted at EMNLP 2022. Data and code can be found on [Github](this https URL)\n",
    "authors": [
      "Carl Edwards",
      "Tuan Lai",
      "Kevin Ros",
      "Garrett Honke",
      "Kyunghyun Cho",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.11817"
  },
  {
    "id": "arXiv:2204.12736",
    "title": "A Multi-Head Convolutional Neural Network With Multi-path Attention  improves Image Denoising",
    "abstract": "A Multi-Head Convolutional Neural Network With Multi-path Attention  improves Image Denoising",
    "descriptor": "",
    "authors": [
      "Jiahong Zhang",
      "Meijun Qu",
      "Ye Wang",
      "Lihong Cao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2204.12736"
  },
  {
    "id": "arXiv:2204.12908",
    "title": "Capabilities and Skills in Manufacturing: A Survey Over the Last Decade  of ETFA",
    "abstract": "Comments: \\c{opyright} 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "descriptor": "\nComments: \\c{opyright} 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Roman Froschauer",
      "Aljosha K\u00f6cher",
      "Kristof Meixner",
      "Siwara Schmitt",
      "Fabian Spitzer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.12908"
  },
  {
    "id": "arXiv:2204.14264",
    "title": "Polyglot Prompt: Multilingual Multitask PrompTraining",
    "abstract": "Comments: EMNLP 2022 (Main Conference)",
    "descriptor": "\nComments: EMNLP 2022 (Main Conference)\n",
    "authors": [
      "Jinlan Fu",
      "See-Kiong Ng",
      "Pengfei Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.14264"
  },
  {
    "id": "arXiv:2205.01382",
    "title": "A Mapping Approach to Convert MTPs into a Capability and Skill Ontology",
    "abstract": "Comments: \\c{opyright} 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "descriptor": "\nComments: \\c{opyright} 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Aljosha K\u00f6cher",
      "Lasse Beers",
      "Alexander Fay"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2205.01382"
  },
  {
    "id": "arXiv:2205.01447",
    "title": "Model-Free Opponent Shaping",
    "abstract": "Comments: ICML 2022 camera ready version. Code: this https URL",
    "descriptor": "\nComments: ICML 2022 camera ready version. Code: this https URL\n",
    "authors": [
      "Chris Lu",
      "Timon Willi",
      "Christian Schroeder de Witt",
      "Jakob Foerster"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2205.01447"
  },
  {
    "id": "arXiv:2205.02561",
    "title": "LDSA: Learning Dynamic Subtask Assignment in Cooperative Multi-Agent  Reinforcement Learning",
    "abstract": "LDSA: Learning Dynamic Subtask Assignment in Cooperative Multi-Agent  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Mingyu Yang",
      "Jian Zhao",
      "Xunhan Hu",
      "Wengang Zhou",
      "Jiangcheng Zhu",
      "Houqiang Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.02561"
  },
  {
    "id": "arXiv:2205.06027",
    "title": "Algorithm Families for Computing Information-Theoretic Forms of Strong  Converse Exponents in Channel Coding and Lossy Source Coding",
    "abstract": "Comments: 77 pages, 9 figures",
    "descriptor": "\nComments: 77 pages, 9 figures\n",
    "authors": [
      "Yutaka Jitsumatsu",
      "Yasutada Oohama"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.06027"
  },
  {
    "id": "arXiv:2205.10347",
    "title": "Diverse super-resolution with pretrained deep hiererarchical VAEs",
    "abstract": "Comments: 21 pages , 5 figures",
    "descriptor": "\nComments: 21 pages , 5 figures\n",
    "authors": [
      "Jean Prost",
      "Antoine Houdard",
      "Nicolas Papadakis",
      "Andr\u00e9s Almansa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2205.10347"
  },
  {
    "id": "arXiv:2205.11180",
    "title": "Distributed Downlink Precoding and Equalization in Satellite Swarms",
    "abstract": "Comments: 32 pages, 12 figures, submitted to IEEE Transactions on Wireless Communications. arXiv admin note: text overlap with arXiv:2112.08791",
    "descriptor": "\nComments: 32 pages, 12 figures, submitted to IEEE Transactions on Wireless Communications. arXiv admin note: text overlap with arXiv:2112.08791\n",
    "authors": [
      "Maik R\u00f6per",
      "Bho Matthiesen",
      "Dirk W\u00fcbben",
      "Petar Popovski",
      "Armin Dekorsy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.11180"
  },
  {
    "id": "arXiv:2205.12410",
    "title": "AdaMix: Mixture-of-Adaptations for Parameter-efficient Model Tuning",
    "abstract": "Comments: Accepted by EMNLP 2022",
    "descriptor": "\nComments: Accepted by EMNLP 2022\n",
    "authors": [
      "Yaqing Wang",
      "Sahaj Agarwal",
      "Subhabrata Mukherjee",
      "Xiaodong Liu",
      "Jing Gao",
      "Ahmed Hassan Awadallah",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12410"
  },
  {
    "id": "arXiv:2205.12496",
    "title": "Teaching Broad Reasoning Skills for Multi-Step QA by Generating Hard  Contexts",
    "abstract": "Comments: Accepted at EMNLP'22",
    "descriptor": "\nComments: Accepted at EMNLP'22\n",
    "authors": [
      "Harsh Trivedi",
      "Niranjan Balasubramanian",
      "Tushar Khot",
      "Ashish Sabharwal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.12496"
  },
  {
    "id": "arXiv:2205.12506",
    "title": "Memorization in NLP Fine-tuning Methods",
    "abstract": "Memorization in NLP Fine-tuning Methods",
    "descriptor": "",
    "authors": [
      "Fatemehsadat Mireshghallah",
      "Archit Uniyal",
      "Tianhao Wang",
      "David Evans",
      "Taylor Berg-Kirkpatrick"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12506"
  },
  {
    "id": "arXiv:2206.00272",
    "title": "Vision GNN: An Image is Worth Graph of Nodes",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Kai Han",
      "Yunhe Wang",
      "Jianyuan Guo",
      "Yehui Tang",
      "Enhua Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00272"
  },
  {
    "id": "arXiv:2206.00614",
    "title": "Dual-stream spatiotemporal networks with feature sharing for monitoring  animals in the home cage",
    "abstract": "Dual-stream spatiotemporal networks with feature sharing for monitoring  animals in the home cage",
    "descriptor": "",
    "authors": [
      "Ezechukwu I. Nwokedi",
      "Rasneer S. Bains",
      "Luc Bidaut",
      "Xujiong Ye",
      "Sara Wells",
      "James M. Brown"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00614"
  },
  {
    "id": "arXiv:2206.02622",
    "title": "Hardware-accelerated Mars Sample Localization via deep transfer learning  from photorealistic simulations",
    "abstract": "Comments: Preprint version only. Final version at IEEE Xplore. Accepted for IEEE Robotics and Automation Letters",
    "descriptor": "\nComments: Preprint version only. Final version at IEEE Xplore. Accepted for IEEE Robotics and Automation Letters\n",
    "authors": [
      "Ra\u00fal Castilla-Arquillo",
      "Carlos Jes\u00fas P\u00e9rez-del-Pulgar",
      "Gonzalo Jes\u00fas Paz-Delgado",
      "Levin Gerdes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.02622"
  },
  {
    "id": "arXiv:2206.02676",
    "title": "The structured distance to singularity of a symmetric tridiagonal  Toeplitz matrix",
    "abstract": "Comments: 16 pages, 5 Figures",
    "descriptor": "\nComments: 16 pages, 5 Figures\n",
    "authors": [
      "Silvia Noschese"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.02676"
  },
  {
    "id": "arXiv:2206.03726",
    "title": "Hub-Pathway: Transfer Learning from A Hub of Pre-trained Models",
    "abstract": "Comments: Accepted by NeurIPS 2022",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Yang Shu",
      "Zhangjie Cao",
      "Ziyang Zhang",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03726"
  },
  {
    "id": "arXiv:2206.05086",
    "title": "Finite Model Theory and Proof Complexity revisited: Distinguishing  graphs in Choiceless Polynomial Time and the Extended Polynomial Calculus",
    "abstract": "Comments: Full version of a paper to appear at CSL 2023",
    "descriptor": "\nComments: Full version of a paper to appear at CSL 2023\n",
    "authors": [
      "Benedikt Pago"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2206.05086"
  },
  {
    "id": "arXiv:2206.06731",
    "title": "Learning Dense Features for Point Cloud Registration Using a Graph  Attention Network",
    "abstract": "Comments: 15 pages, 3 figures",
    "descriptor": "\nComments: 15 pages, 3 figures\n",
    "authors": [
      "Quoc Vinh Lai Dang",
      "Sarvar Hussain Nengroo",
      "Hojun Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06731"
  },
  {
    "id": "arXiv:2206.07304",
    "title": "Knowledge Management System with NLP-Assisted Annotations: A Brief  Survey and Outlook",
    "abstract": "Comments: Proceeding of CIKM Workshop 2022",
    "descriptor": "\nComments: Proceeding of CIKM Workshop 2022\n",
    "authors": [
      "Baihan Lin"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.07304"
  },
  {
    "id": "arXiv:2206.08917",
    "title": "The Open Catalyst 2022 (OC22) Dataset and Challenges for Oxide  Electrocatalysts",
    "abstract": "Comments: 48 pages, 14 figures",
    "descriptor": "\nComments: 48 pages, 14 figures\n",
    "authors": [
      "Richard Tran",
      "Janice Lan",
      "Muhammed Shuaibi",
      "Brandon M. Wood",
      "Siddharth Goyal",
      "Abhishek Das",
      "Javier Heras-Domingo",
      "Adeesh Kolluru",
      "Ammar Rizvi",
      "Nima Shoghi",
      "Anuroop Sriram",
      "Felix Therrien",
      "Jehad Abed",
      "Oleksandr Voznyy",
      "Edward H. Sargent",
      "Zachary Ulissi",
      "C. Lawrence Zitnick"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2206.08917"
  },
  {
    "id": "arXiv:2206.09611",
    "title": "SJ-HD^2R: Selective Joint High Dynamic Range and Denoising Imaging for  Dynamic Scenes",
    "abstract": "SJ-HD^2R: Selective Joint High Dynamic Range and Denoising Imaging for  Dynamic Scenes",
    "descriptor": "",
    "authors": [
      "Wei Li",
      "Shuai Xiao",
      "Tianhong Dai",
      "Shanxin Yuan",
      "Tao Wang",
      "Cheng Li",
      "Fenglong Song"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09611"
  },
  {
    "id": "arXiv:2206.10048",
    "title": "FedER: Federated Learning through Experience Replay and  Privacy-Preserving Data Synthesis",
    "abstract": "Comments: Paper submitted to TMI (under review)",
    "descriptor": "\nComments: Paper submitted to TMI (under review)\n",
    "authors": [
      "Matteo Pennisi",
      "Federica Proietto Salanitri",
      "Giovanni Bellitto",
      "Bruno Casella",
      "Marco Aldinucci",
      "Simone Palazzo",
      "Concetto Spampinato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.10048"
  },
  {
    "id": "arXiv:2207.06214",
    "title": "Is one annotation enough? A data-centric image classification benchmark  for noisy and ambiguous label estimation",
    "abstract": "Comments: Accepted at NeurIPS 2022, Benchmark and Dataset Track, Code and Link to data available at this https URL",
    "descriptor": "\nComments: Accepted at NeurIPS 2022, Benchmark and Dataset Track, Code and Link to data available at this https URL\n",
    "authors": [
      "Lars Schmarje",
      "Vasco Grossmann",
      "Claudius Zelenka",
      "Sabine Dippel",
      "Rainer Kiko",
      "Mariusz Oszust",
      "Matti Pastell",
      "Jenny Stracke",
      "Anna Valros",
      "Nina Volkmann",
      "Reinhard Koch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.06214"
  },
  {
    "id": "arXiv:2207.08597",
    "title": "FunQG: Molecular Representation Learning Via Quotient Graphs",
    "abstract": "FunQG: Molecular Representation Learning Via Quotient Graphs",
    "descriptor": "",
    "authors": [
      "Hossein Hajiabolhassan",
      "Zahra Taheri",
      "Ali Hojatnia",
      "Yavar Taheri Yeganeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2207.08597"
  },
  {
    "id": "arXiv:2207.11184",
    "title": "Multi-Faceted Distillation of Base-Novel Commonality for Few-shot Object  Detection",
    "abstract": "Comments: Accepted to ECCV 2022",
    "descriptor": "\nComments: Accepted to ECCV 2022\n",
    "authors": [
      "Shuang Wu",
      "Wenjie Pei",
      "Dianwen Mei",
      "Fanglin Chen",
      "Jiandong Tian",
      "Guangming Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11184"
  },
  {
    "id": "arXiv:2207.11205",
    "title": "Toward a Generic Mapping Language for Transformations between RDF and  Data Interchange Formats",
    "abstract": "Comments: \\c{opyright} 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "descriptor": "\nComments: \\c{opyright} 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Aljosha K\u00f6cher",
      "Artan Markaj",
      "Alexander Fay"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.11205"
  },
  {
    "id": "arXiv:2208.02205",
    "title": "Large-scale Building Damage Assessment using a Novel Hierarchical  Transformer Architecture on Satellite Images",
    "abstract": "Large-scale Building Damage Assessment using a Novel Hierarchical  Transformer Architecture on Satellite Images",
    "descriptor": "",
    "authors": [
      "Navjot Kaur",
      "Cheng-Chun Lee",
      "Ali Mostafavi",
      "Ali Mahdavi-Amiri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.02205"
  },
  {
    "id": "arXiv:2208.05334",
    "title": "Verification of the busy-forbidden protocol (using an extension of the  cones and foci framework)",
    "abstract": "Verification of the busy-forbidden protocol (using an extension of the  cones and foci framework)",
    "descriptor": "",
    "authors": [
      "P.H.M. van Spaendonck"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2208.05334"
  },
  {
    "id": "arXiv:2208.07185",
    "title": "A Multi-Criteria Metaheuristic Algorithm for Distributed Optimization of  Electric Energy Storage",
    "abstract": "A Multi-Criteria Metaheuristic Algorithm for Distributed Optimization of  Electric Energy Storage",
    "descriptor": "",
    "authors": [
      "Rico Schrage",
      "Paul Hendrik Tiemann",
      "Astrid Nie\u00dfe"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2208.07185"
  },
  {
    "id": "arXiv:2208.11511",
    "title": "A Graph Convolution for Signed Directed Graphs",
    "abstract": "Comments: Preprint version",
    "descriptor": "\nComments: Preprint version\n",
    "authors": [
      "Taewook Ko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.11511"
  },
  {
    "id": "arXiv:2208.11948",
    "title": "Learning to Construct 3D Building Wireframes from 3D Line Clouds",
    "abstract": "Comments: 10 pages, 6 figures",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Yicheng Luo",
      "Jing Ren",
      "Xuefei Zhe",
      "Di Kang",
      "Yajing Xu",
      "Peter Wonka",
      "Linchao Bao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.11948"
  },
  {
    "id": "arXiv:2208.12152",
    "title": "Supervised Dimensionality Reduction and Image Classification Utilizing  Convolutional Autoencoders",
    "abstract": "Comments: to be submitted",
    "descriptor": "\nComments: to be submitted\n",
    "authors": [
      "Ioannis A. Nellas",
      "Sotiris K. Tasoulis",
      "Vassilis P. Plagianakos",
      "Spiros V. Georgakopoulos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2208.12152"
  },
  {
    "id": "arXiv:2208.12156",
    "title": "Deep neural networks for fast acquisition of aortic 3D pressure and  velocity flow fields",
    "abstract": "Comments: 22 pages, 19 figures",
    "descriptor": "\nComments: 22 pages, 19 figures\n",
    "authors": [
      "Endrit Pajaziti",
      "Javier Montalt-Tordera",
      "Claudio Capelli",
      "Raphael Sivera",
      "Emilie Sauvage",
      "Silvia Schievano",
      "Vivek Muthurangu"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.12156"
  },
  {
    "id": "arXiv:2209.02570",
    "title": "When Privacy Meets Partial Information: A Refined Analysis of  Differentially Private Bandits",
    "abstract": "Comments: Appears in NeurIPS 2022. From v1, the minimax lower bound for linear bandits is changed to $O(\\max(d \\sqrt{T}, d/\\epsilon))$",
    "descriptor": "\nComments: Appears in NeurIPS 2022. From v1, the minimax lower bound for linear bandits is changed to $O(\\max(d \\sqrt{T}, d/\\epsilon))$\n",
    "authors": [
      "Achraf Azize",
      "Debabrota Basu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.02570"
  },
  {
    "id": "arXiv:2209.02948",
    "title": "Assessing Software Privacy using the Privacy Flow-Graph",
    "abstract": "Comments: Accepted at International Workshop on Mining Software Repositories Applications for Privacy and Security (MSR4P&S) 2022",
    "descriptor": "\nComments: Accepted at International Workshop on Mining Software Repositories Applications for Privacy and Security (MSR4P&S) 2022\n",
    "authors": [
      "Feiyang Tang",
      "Bjarte M. \u00d8stvold"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2209.02948"
  },
  {
    "id": "arXiv:2209.04012",
    "title": "From Shapley Values to Generalized Additive Models and back",
    "abstract": "From Shapley Values to Generalized Additive Models and back",
    "descriptor": "",
    "authors": [
      "Sebastian Bordt",
      "Ulrike von Luxburg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.04012"
  },
  {
    "id": "arXiv:2209.04254",
    "title": "Shapley value-based approaches to explain the robustness of classifiers  in machine learning",
    "abstract": "Shapley value-based approaches to explain the robustness of classifiers  in machine learning",
    "descriptor": "",
    "authors": [
      "Guilherme Dean Pelegrina",
      "Sajid Siraj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.04254"
  },
  {
    "id": "arXiv:2209.05849",
    "title": "Weight-based Channel-model Matrix Framework provides a reasonable  solution for EEG-based cross-dataset emotion recognition",
    "abstract": "Comments: 18 pages, 12 figures, 8 tables",
    "descriptor": "\nComments: 18 pages, 12 figures, 8 tables\n",
    "authors": [
      "Huayu Chen",
      "Huanhuan He",
      "Jing Zhu",
      "Shuting Sun",
      "Jianxiu Li",
      "Xuexiao Shao",
      "Junxiang Li",
      "Xiaowei Li",
      "Bin Hu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.05849"
  },
  {
    "id": "arXiv:2209.06414",
    "title": "Behavioral Theory for Stochastic Systems? A Data-driven Journey from  Willems to Wiener and Back Again",
    "abstract": "Comments: 30 pages, 8 figures",
    "descriptor": "\nComments: 30 pages, 8 figures\n",
    "authors": [
      "Timm Faulwasser",
      "Ruchuan Ou",
      "Guanru Pan",
      "Philipp Schmitz",
      "Karl Worthmann"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2209.06414"
  },
  {
    "id": "arXiv:2209.07714",
    "title": "Variational quantum algorithm for measurement extraction from the  Navier-Stokes, Einstein, Maxwell, B-type, Lin-Tsien, Camassa-Holm, DSW, H-S,  KdV-B, non-homogeneous KdV, generalized KdV, KdV, translational KdV, sKdV,  B-L and Airy equations",
    "abstract": "Comments: V2, 191 pages, 115 figures",
    "descriptor": "\nComments: V2, 191 pages, 115 figures\n",
    "authors": [
      "Pete Rigas"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2209.07714"
  },
  {
    "id": "arXiv:2209.08418",
    "title": "Sample-based Uncertainty Quantification with a Single Deterministic  Neural Network",
    "abstract": "Comments: 16 pages, 17 figures, 2 tables. Accepted by the 14th International Conference on Neural Computation Theory and Applications (NCTA 2022) held as part of IJCCI 2022, October 24-26, 2022, Valletta, Malta",
    "descriptor": "\nComments: 16 pages, 17 figures, 2 tables. Accepted by the 14th International Conference on Neural Computation Theory and Applications (NCTA 2022) held as part of IJCCI 2022, October 24-26, 2022, Valletta, Malta\n",
    "authors": [
      "Takuya Kanazawa",
      "Chetan Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.08418"
  },
  {
    "id": "arXiv:2209.11934",
    "title": "The Online Knapsack Problem with Departures",
    "abstract": "The Online Knapsack Problem with Departures",
    "descriptor": "",
    "authors": [
      "Bo Sun",
      "Lin Yang",
      "Mohammad Hajiesmaili",
      "Adam Wierman",
      "John C.S. Lui",
      "Don Towsley",
      "Danny H.K. Tsang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2209.11934"
  },
  {
    "id": "arXiv:2210.01427",
    "title": "Accurate Image Restoration with Attention Retractable Transformer",
    "abstract": "Comments: Discuss more related works. Code and models are available at this https URL",
    "descriptor": "\nComments: Discuss more related works. Code and models are available at this https URL\n",
    "authors": [
      "Jiale Zhang",
      "Yulun Zhang",
      "Jinjin Gu",
      "Yongbing Zhang",
      "Linghe Kong",
      "Xin Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.01427"
  },
  {
    "id": "arXiv:2210.02291",
    "title": "Progressive Denoising Model for Fine-Grained Text-to-Image Generation",
    "abstract": "Comments: Technique report. arXiv admin note: text overlap with arXiv:2206.10789 by other authors",
    "descriptor": "\nComments: Technique report. arXiv admin note: text overlap with arXiv:2206.10789 by other authors\n",
    "authors": [
      "Zhengcong Fei",
      "Mingyuan Fan",
      "Junshi Huang",
      "Xiaoming Wei",
      "Xiaolin Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.02291"
  },
  {
    "id": "arXiv:2210.02419",
    "title": "Explanation Uncertainty with Decision Boundary Awareness",
    "abstract": "Explanation Uncertainty with Decision Boundary Awareness",
    "descriptor": "",
    "authors": [
      "Davin Hill",
      "Aria Masoomi",
      "Sandesh Ghimire",
      "Max Torop",
      "Jennifer Dy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02419"
  },
  {
    "id": "arXiv:2210.03422",
    "title": "SpaceQA: Answering Questions about the Design of Space Missions and  Space Craft Concepts",
    "abstract": "Comments: In proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2022)",
    "descriptor": "\nComments: In proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2022)\n",
    "authors": [
      "Andr\u00e9s Garc\u00eda-Silva",
      "Cristian Berr\u00edo",
      "Jos\u00e9 Manuel G\u00f3mez-P\u00e9rez",
      "Jos\u00e9 Antonio Mart\u00ednez-Heras",
      "Alessandro Donati",
      "Ilaria Roma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03422"
  },
  {
    "id": "arXiv:2210.03427",
    "title": "Generating Quizzes to Support Training on Quality Management and  Assurance in Space Science and Engineering",
    "abstract": "Comments: In Proceedings of the 15th International Natural Language Generation Conference (INLG 2022)",
    "descriptor": "\nComments: In Proceedings of the 15th International Natural Language Generation Conference (INLG 2022)\n",
    "authors": [
      "Andr\u00e9s Garc\u00eda-Silva",
      "Cristian Berr\u00edo",
      "Jos\u00e9 Manuel G\u00f3mez-P\u00e9rez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03427"
  },
  {
    "id": "arXiv:2210.05164",
    "title": "Tight Error Bounds for Nonnegative Orthogonality Constraints and Exact  Penalties",
    "abstract": "Tight Error Bounds for Nonnegative Orthogonality Constraints and Exact  Penalties",
    "descriptor": "",
    "authors": [
      "Xiaojun Chen",
      "Yifan He",
      "Zaikun Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.05164"
  },
  {
    "id": "arXiv:2210.06464",
    "title": "Predictive Querying for Autoregressive Neural Sequence Models",
    "abstract": "Comments: Oral Presentation at the Intl. Conference on Neural Information Processing Systems (NeurIPS 2022)",
    "descriptor": "\nComments: Oral Presentation at the Intl. Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Alex Boyd",
      "Sam Showalter",
      "Stephan Mandt",
      "Padhraic Smyth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.06464"
  },
  {
    "id": "arXiv:2210.08326",
    "title": "Distributionally Robust Causal Inference with Observational Data",
    "abstract": "Distributionally Robust Causal Inference with Observational Data",
    "descriptor": "",
    "authors": [
      "Dimitris Bertsimas",
      "Kosuke Imai",
      "Michael Lingzhi Li"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.08326"
  },
  {
    "id": "arXiv:2210.09510",
    "title": "Personalization of CTC Speech Recognition Models using Contextual  Adapters and Adaptive Boosting",
    "abstract": "Comments: To appear in SLT 2022",
    "descriptor": "\nComments: To appear in SLT 2022\n",
    "authors": [
      "Saket Dingliwal",
      "Monica Sunkara",
      "Sravan Bodapati",
      "Srikanth Ronanki",
      "Jeff Farris",
      "Katrin Kirchhoff"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.09510"
  },
  {
    "id": "arXiv:2210.10638",
    "title": "Digital Human Interactive Recommendation Decision-Making Based on  Reinforcement Learning",
    "abstract": "Comments: 9 pages, 1 figure, 1 table, the paper has been accepted and this is the final camera-ready for NeurIPS 2022 Workshop on Human in the Loop Learning, this https URL",
    "descriptor": "\nComments: 9 pages, 1 figure, 1 table, the paper has been accepted and this is the final camera-ready for NeurIPS 2022 Workshop on Human in the Loop Learning, this https URL\n",
    "authors": [
      "Xiong Junwu",
      "Xiaoyun Feng",
      "YunZhou Shi",
      "James Zhang",
      "Zhongzhou Zhao",
      "Wei Zhou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10638"
  },
  {
    "id": "arXiv:2210.11089",
    "title": "Speech Dereverberation with a Reverberation Time Shortening Target",
    "abstract": "Comments: This article is a modified version of the previous article",
    "descriptor": "\nComments: This article is a modified version of the previous article\n",
    "authors": [
      "Rui Zhou",
      "Wenye Zhu",
      "Xiaofei Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.11089"
  },
  {
    "id": "arXiv:2210.13668",
    "title": "ConnectedUNets++: Mass Segmentation from Whole Mammographic Images",
    "abstract": "Comments: Results are to be updated",
    "descriptor": "\nComments: Results are to be updated\n",
    "authors": [
      "Prithul Sarker",
      "Sushmita Sarker",
      "George Bebis",
      "Alireza Tavakkoli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.13668"
  },
  {
    "id": "arXiv:2210.13712",
    "title": "Parameter-Efficient Legal Domain Adaptation",
    "abstract": "Comments: Accepted into the 2022 NLLP workshop",
    "descriptor": "\nComments: Accepted into the 2022 NLLP workshop\n",
    "authors": [
      "Jonathan Li",
      "Rohan Bhambhoria",
      "Xiaodan Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.13712"
  },
  {
    "id": "arXiv:2210.13769",
    "title": "GlobalFlowNet: Video Stabilization using Deep Distilled Global Motion  Estimates",
    "abstract": "Comments: Accepted in WACV 2023",
    "descriptor": "\nComments: Accepted in WACV 2023\n",
    "authors": [
      "Jerin Geo James",
      "Devansh Jain",
      "Ajit Rajwade"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.13769"
  },
  {
    "id": "arXiv:2210.14136",
    "title": "PolyHope: Two-Level Hope Speech Detection from Tweets",
    "abstract": "Comments: 20 pages, 9 figures",
    "descriptor": "\nComments: 20 pages, 9 figures\n",
    "authors": [
      "Fazlourrahman Balouchzahi",
      "Grigori Sidorov",
      "Alexander Gelbukh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.14136"
  },
  {
    "id": "arXiv:2210.14871",
    "title": "Impact of the 2022 OSTP Memo: A Bibliometric Analysis of U.S. Federally  Funded Publications, 2017-2021",
    "abstract": "Comments: 27 pages, including Appendix. 11 figures, 6 tables",
    "descriptor": "\nComments: 27 pages, including Appendix. 11 figures, 6 tables\n",
    "authors": [
      "Eric Schares"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2210.14871"
  },
  {
    "id": "arXiv:2210.15137",
    "title": "ScoreMix: A Scalable Augmentation Strategy for Training GANs with  Limited Data",
    "abstract": "ScoreMix: A Scalable Augmentation Strategy for Training GANs with  Limited Data",
    "descriptor": "",
    "authors": [
      "Jie Cao",
      "Mandi Luo",
      "Junchi Yu",
      "Ming-Hsuan Yang",
      "Ran He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.15137"
  },
  {
    "id": "arXiv:2210.16302",
    "title": "AGReE: A system for generating Automated Grammar Reading Exercises",
    "abstract": "Comments: Accepted to EMNLP 2022 Demonstration Track",
    "descriptor": "\nComments: Accepted to EMNLP 2022 Demonstration Track\n",
    "authors": [
      "Sophia Chan",
      "Swapna Somasundaran",
      "Debanjan Ghosh",
      "Mengxuan Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.16302"
  },
  {
    "id": "arXiv:2210.16952",
    "title": "Transfer Learning with Synthetic Corpora for Spatial Role Labeling and  Reasoning",
    "abstract": "Comments: The 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP 2022)",
    "descriptor": "\nComments: The 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP 2022)\n",
    "authors": [
      "Roshanak Mirzaee",
      "Parisa Kordjamshidi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.16952"
  },
  {
    "id": "arXiv:2210.16982",
    "title": "Computation of parabolic cylinder functions having complex argument",
    "abstract": "Computation of parabolic cylinder functions having complex argument",
    "descriptor": "",
    "authors": [
      "T. M. Dunster",
      "A. Gil",
      "J. Segura"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Classical Analysis and ODEs (math.CA)"
    ],
    "url": "https://arxiv.org/abs/2210.16982"
  },
  {
    "id": "arXiv:2211.00224",
    "title": "SOLAR: A Highly Optimized Data Loading Framework for Distributed  Training of CNN-based Scientific Surrogates",
    "abstract": "Comments: 14 pages, 15 figures, 5 tables, submitted to VLDB '23",
    "descriptor": "\nComments: 14 pages, 15 figures, 5 tables, submitted to VLDB '23\n",
    "authors": [
      "Baixi Sun",
      "Xiaodong Yu",
      "Chengming Zhang",
      "Jiannan Tian",
      "Sian Jin",
      "Kamil Iskra",
      "Tao Zhou",
      "Tekin Bicer",
      "Pete Beckman",
      "Dingwen Tao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00224"
  },
  {
    "id": "arXiv:2211.00677",
    "title": "Semi-Supervised Domain Adaptation for Cross-Survey Galaxy Morphology  Classification and Anomaly Detection",
    "abstract": "Comments: 3 figures, 1 table; accepted to Machine Learning and the Physical Sciences - Workshop at the 36th conference on Neural Information Processing Systems (NeurIPS)",
    "descriptor": "\nComments: 3 figures, 1 table; accepted to Machine Learning and the Physical Sciences - Workshop at the 36th conference on Neural Information Processing Systems (NeurIPS)\n",
    "authors": [
      "Aleksandra \u0106iprijanovi\u0107",
      "Ashia Lewis",
      "Kevin Pedro",
      "Sandeep Madireddy",
      "Brian Nord",
      "Gabriel N. Perdue",
      "Stefan Wild"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00677"
  },
  {
    "id": "arXiv:2211.00768",
    "title": "Why is Winoground Hard? Investigating Failures in Visuolinguistic  Compositionality",
    "abstract": "Comments: Accepted at EMNLP 2022. We release our annotation and code at this https URL . 15 pages, 3 figures",
    "descriptor": "\nComments: Accepted at EMNLP 2022. We release our annotation and code at this https URL . 15 pages, 3 figures\n",
    "authors": [
      "Anuj Diwan",
      "Layne Berry",
      "Eunsol Choi",
      "David Harwath",
      "Kyle Mahowald"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00768"
  },
  {
    "id": "arXiv:2211.00819",
    "title": "Interpretable estimation of the risk of heart failure hospitalization  from a 30-second electrocardiogram",
    "abstract": "Comments: 4 pages, 4 figures",
    "descriptor": "\nComments: 4 pages, 4 figures\n",
    "authors": [
      "Sergio Gonz\u00e1lez",
      "Wan-Ting Hsieh",
      "Davide Burba",
      "Trista Pei-Chun Chen",
      "Chun-Li Wang",
      "Victor Chien-Chia Wu",
      "Shang-Hung Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.00819"
  },
  {
    "id": "arXiv:2211.00859",
    "title": "SufrinNet: Toward Sufficient Cross-View Interaction for Stereo Image  Enhancement in The Dark",
    "abstract": "SufrinNet: Toward Sufficient Cross-View Interaction for Stereo Image  Enhancement in The Dark",
    "descriptor": "",
    "authors": [
      "Huan Zheng",
      "Zhao Zhang",
      "Jicong Fan",
      "Richang Hong",
      "Yi Yang",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00859"
  },
  {
    "id": "arXiv:2211.01016",
    "title": "Holographic-Type Communication for Digital Twin: A Learning-based  Auction Approach",
    "abstract": "Comments: 6 pages",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "XiuYu Zhang",
      "Minrui Xu",
      "Rui Tan",
      "Dusit Niyato"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.01016"
  },
  {
    "id": "arXiv:2211.01214",
    "title": "Time-aware Random Walk Diffusion to Improve Dynamic Graph Learning",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Jong-whi Lee",
      "Jinhong Jung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01214"
  },
  {
    "id": "arXiv:2211.01223",
    "title": "Audio Language Modeling using Perceptually-Guided Discrete  Representations",
    "abstract": "Audio Language Modeling using Perceptually-Guided Discrete  Representations",
    "descriptor": "",
    "authors": [
      "Felix Kreuk",
      "Yaniv Taigman",
      "Adam Polyak",
      "Jade Copet",
      "Gabriel Synnaeve",
      "Alexandre D\u00e9fossez",
      "Yossi Adi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.01223"
  },
  {
    "id": "arXiv:2211.01288",
    "title": "Characterizing Intrinsic Compositionality in Transformers with Tree  Projections",
    "abstract": "Comments: Fixed title and metadata",
    "descriptor": "\nComments: Fixed title and metadata\n",
    "authors": [
      "Shikhar Murty",
      "Pratyusha Sharma",
      "Jacob Andreas",
      "Christopher D. Manning"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01288"
  },
  {
    "id": "arXiv:2211.01323",
    "title": "Generation of Anonymous Chest Radiographs Using Latent Diffusion Models  for Training Thoracic Abnormality Classification Systems",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Kai Packh\u00e4user",
      "Lukas Folle",
      "Florian Thamm",
      "Andreas Maier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01323"
  },
  {
    "id": "arXiv:2211.01427",
    "title": "TextCraft: Zero-Shot Generation of High-Fidelity and Diverse Shapes from  Text",
    "abstract": "TextCraft: Zero-Shot Generation of High-Fidelity and Diverse Shapes from  Text",
    "descriptor": "",
    "authors": [
      "Aditya Sanghi",
      "Rao Fu",
      "Vivian Liu",
      "Karl Willis",
      "Hooman Shayani",
      "Amir Hosein Khasahmadi",
      "Srinath Sridhar",
      "Daniel Ritchie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01427"
  },
  {
    "id": "arXiv:2211.01444",
    "title": "Pseudorandom (Function-Like) Quantum State Generators: New Definitions  and Applications",
    "abstract": "Pseudorandom (Function-Like) Quantum State Generators: New Definitions  and Applications",
    "descriptor": "",
    "authors": [
      "Prabhanjan Ananth",
      "Aditya Gulati",
      "Luowen Qian",
      "Henry Yuen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.01444"
  },
  {
    "id": "arXiv:2211.01538",
    "title": "$D^2$SLAM: Decentralized and Distributed Collaborative Visual-inertial  SLAM System for Aerial Swarm",
    "abstract": "$D^2$SLAM: Decentralized and Distributed Collaborative Visual-inertial  SLAM System for Aerial Swarm",
    "descriptor": "",
    "authors": [
      "Hao Xu",
      "Peize Liu",
      "Xinyi Chen",
      "Shaojie Shen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.01538"
  },
  {
    "id": "arXiv:2211.01542",
    "title": "Continual Learning of Neural Machine Translation within Low Forgetting  Risk Regions",
    "abstract": "Comments: EMNLP 2022 Main Conference Long Paper",
    "descriptor": "\nComments: EMNLP 2022 Main Conference Long Paper\n",
    "authors": [
      "Shuhao Gu",
      "Bojie Hu",
      "Yang Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01542"
  },
  {
    "id": "arXiv:2211.01645",
    "title": "Towards federated multivariate statistical process control (FedMSPC)",
    "abstract": "Towards federated multivariate statistical process control (FedMSPC)",
    "descriptor": "",
    "authors": [
      "Du Nguyen Duy",
      "David Gabauer",
      "Ramin Nikzad-Langerodi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.01645"
  },
  {
    "id": "arXiv:2211.01665",
    "title": "From Auditable Quantum Authentication to Best-of-Both-Worlds Multiparty  Quantum Computation with Public Verifiable Identifiable Abort",
    "abstract": "From Auditable Quantum Authentication to Best-of-Both-Worlds Multiparty  Quantum Computation with Public Verifiable Identifiable Abort",
    "descriptor": "",
    "authors": [
      "Mi-Ying Huang",
      "Er-Cheng Tang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.01665"
  },
  {
    "id": "arXiv:2211.01676",
    "title": "Repeatable Random Permutation Set",
    "abstract": "Repeatable Random Permutation Set",
    "descriptor": "",
    "authors": [
      "Wenran Yang",
      "Yong Deng"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.01676"
  },
  {
    "id": "arXiv:2211.01777",
    "title": "Evaluating a Synthetic Image Dataset Generated with Stable Diffusion",
    "abstract": "Evaluating a Synthetic Image Dataset Generated with Stable Diffusion",
    "descriptor": "",
    "authors": [
      "Andreas St\u00f6ckl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01777"
  },
  {
    "id": "arXiv:2211.01779",
    "title": "Exploring explicit coarse-grained structure in artificial neural  networks",
    "abstract": "Exploring explicit coarse-grained structure in artificial neural  networks",
    "descriptor": "",
    "authors": [
      "Xi-Ci Yang",
      "Z. Y. Xie",
      "Xiao-Tao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.01779"
  },
  {
    "id": "arXiv:2211.01977",
    "title": "Galois Groups of Linear Difference-Differential Equations",
    "abstract": "Comments: 32 pages",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Ruyong Feng",
      "Wei Lu"
    ],
    "subjectives": [
      "Rings and Algebras (math.RA)",
      "Symbolic Computation (cs.SC)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2211.01977"
  }
]
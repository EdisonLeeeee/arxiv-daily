[
  {
    "id": "arXiv:2211.05118",
    "title": "Mapping Out the HPC Dependency Chaos",
    "abstract": "High Performance Computing~(HPC) software stacks have become complex, with\nthe dependencies of some applications numbering in the hundreds. Packaging,\ndistributing, and administering software stacks of that scale is a complex\nundertaking anywhere. HPC systems deal with esoteric compilers, hardware, and a\npanoply of uncommon combinations. In this paper, we explore the mechanisms\navailable for packaging software to find its own dependencies in the context of\na taxonomy of software distribution, and discuss their benefits and pitfalls.\nWe discuss workarounds for some common problems caused by using these composed\nstacks and introduce Shrinkwrap: A solution to producing binaries that directly\nload their dependencies from precise locations and in a precise order. Beyond\nsimplifying the use of the binaries, this approach also speeds up loading as\nmuch as 7x for a large dynamically-linked MPI application in our evaluation.",
    "descriptor": "\nComments: Presented at SuperComputing 2022 (this https URL)\n",
    "authors": [
      "Farid Zakaria",
      "Thomas R. W. Scogland",
      "Todd Gamblin",
      "Carlos Maltzhan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2211.05118"
  },
  {
    "id": "arXiv:2211.05119",
    "title": "The $[1,0]$-twisted generalized Reed-Solomon code",
    "abstract": "In this paper, we not only give the parity check matrix for the\n$[1,0]$-twisted generalized Reed-Solomon (in short, TGRS) code, but also\ndetermine the weight distribution. Especially, we show that the $[1,0]$-TGRS\ncode is not GRS or EGRS. Furthermore, we present a sufficient and necessary\ncondition for any punctured code of the $[1,0]$-TGRS code to be\nself-orthogonal, and then construct several classes of self-dual or almost\nself-dual $[1,0]$-TGRS codes. Finally, basing on these self-dual or almost\nself-dual $[1,0]$-TGRS codes, we obtain some LCD $[1,0]$-TGRS codes.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2211.04511\n",
    "authors": [
      "Canze Zhu",
      "Qunying Liao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.05119"
  },
  {
    "id": "arXiv:2211.05120",
    "title": "Deep Learning based Computer Vision Methods for Complex Traffic  Environments Perception: A Review",
    "abstract": "Computer vision applications in intelligent transportation systems (ITS) and\nautonomous driving (AD) have gravitated towards deep neural network\narchitectures in recent years. While performance seems to be improving on\nbenchmark datasets, many real-world challenges are yet to be adequately\nconsidered in research. This paper conducted an extensive literature review on\nthe applications of computer vision in ITS and AD, and discusses challenges\nrelated to data, models, and complex urban environments. The data challenges\nare associated with the collection and labeling of training data and its\nrelevance to real world conditions, bias inherent in datasets, the high volume\nof data needed to be processed, and privacy concerns. Deep learning (DL) models\nare commonly too complex for real-time processing on embedded hardware, lack\nexplainability and generalizability, and are hard to test in real-world\nsettings. Complex urban traffic environments have irregular lighting and\nocclusions, and surveillance cameras can be mounted at a variety of angles,\ngather dirt, shake in the wind, while the traffic conditions are highly\nheterogeneous, with violation of rules and complex interactions in crowded\nscenarios. Some representative applications that suffer from these problems are\ntraffic flow estimation, congestion detection, autonomous driving perception,\nvehicle interaction, and edge computing for practical deployment. The possible\nways of dealing with the challenges are also explored while prioritizing\npractical deployment.",
    "descriptor": "",
    "authors": [
      "Talha Azfar",
      "Jinlong Li",
      "Hongkai Yu",
      "Ruey Long Cheu",
      "Yisheng Lv",
      "Ruimin Ke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.05120"
  },
  {
    "id": "arXiv:2211.05123",
    "title": "Up to 58 Tets/Hex to untangle Hex meshes",
    "abstract": "The request for high-quality solutions continually grows in a world where\nmore and more tasks are executed through computers. This also counts for fields\nsuch as engineering, computer graphics, etc., which use meshes to solve their\nproblems. A mesh is a combination of some elementary elements, for which\nhexahedral elements are a good choice thanks to their superior numerical\nfeatures. The solutions reached using these meshes depend on the quality of the\nelements making up the mesh. The problem is that these individual elements can\ntake on a shape which prevents accurate computations. Such elements are\nconsidered to be invalid. To allow users to get accurate results, the shape of\nthese elements must therefore be changed to be considered valid. In this work,\nwe combine the results of two papers to scan a mesh, identify possible invalid\nelements and then change the shape of these elements to make them valid. With\nthis combination, we end up with a working algorithm. But there is room for\nimprovement, which is why we introduce multiple improvements to speed up the\nalgorithm as well as make it more robust. We then test our algorithm and\ncompare it to another approach. This work, therefore, introduces a new\nefficient and robust approach to untangle invalid meshes.",
    "descriptor": "\nComments: 34 pages, 17 figures, Bachelorthesis\n",
    "authors": [
      "Luca Schaller"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.05123"
  },
  {
    "id": "arXiv:2211.05125",
    "title": "ChromoSkein: Untangling Three-Dimensional Chromatin Fiber With a  Web-Based Visualization Framework",
    "abstract": "We present ChromoSkein, a web-based tool for visualizing three-dimensional\nchromatin models. The spatial organization of chromatin is essential to its\nfunction. Experimental methods, namely Hi-C, reveal the spatial conformation\nbut output a 2D matrix representation. Biologists leverage simulation to bring\nthis information back to 3D, assembling a 3D chromatin shape prediction using\nthe 2D matrices as constraints. Our overview of existing chromatin\nvisualization software shows that the available tools limit the utility of 3D\nthrough ineffective shading and a lack of advanced interactions. We designed\nChromoSkein to encourage analytical work directly with the 3D representation.\nOur tool features a 3D view that supports understanding the shape of the highly\ntangled chromatin fiber and the spatial relationships of its parts. Users can\nexplore and filter the 3D model using two interactions. First, they can manage\nocclusion both by toggling the visibility of semantic parts and by adding\ncutting planes. Second, they can segment the model through the creation of\ncustom selections. To complement the 3D view, we link the spatial\nrepresentation with non-spatial genomic data, such as 2D Hi-C maps and 1D\ngenomic signals. We demonstrate the utility of ChromoSkein in two exemplary use\ncases that examine functional genomic loci in the spatial context of\nchromosomes and the whole genome.",
    "descriptor": "",
    "authors": [
      "Mat\u00fa\u0161 Tal\u010d\u00edk",
      "Filip Op\u00e1len\u00fd",
      "Tereza Clarence",
      "Katar\u00edna Furmanov\u00e1",
      "Jan By\u0161ka",
      "Barbora Kozl\u00edkov\u00e1",
      "David Kou\u0159il"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.05125"
  },
  {
    "id": "arXiv:2211.05151",
    "title": "QCNN: Quadrature Convolutional Neural Network with Application to  Unstructured Data Compression",
    "abstract": "We present a new convolution layer for deep learning architectures which we\ncall QuadConv -- an approximation to continuous convolution via quadrature. Our\noperator is developed explicitly for use on unstructured data, and accomplishes\nthis by learning a continuous kernel that can be sampled at arbitrary\nlocations. In the setting of neural compression, we show that a QuadConv-based\nautoencoder, resulting in a Quadrature Convolutional Neural Network (QCNN), can\nmatch the performance of standard discrete convolutions on structured uniform\ndata, as in CNNs, and maintain this accuracy on unstructured data.",
    "descriptor": "\nComments: 17 pages, 14 figures\n",
    "authors": [
      "Kevin Doherty",
      "Cooper Simpson",
      "Stephen Becker",
      "Alireza Doostan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.05151"
  },
  {
    "id": "arXiv:2211.05156",
    "title": "Efficient Zero-shot Event Extraction with Context-Definition Alignment",
    "abstract": "Event extraction (EE) is the task of identifying interested event mentions\nfrom text. Conventional efforts mainly focus on the supervised setting.\nHowever, these supervised models cannot generalize to event types out of the\npre-defined ontology. To fill this gap, many efforts have been devoted to the\nzero-shot EE problem. This paper follows the trend of modeling event-type\nsemantics but moves one step further. We argue that using the static embedding\nof the event type name might not be enough because a single word could be\nambiguous, and we need a sentence to define the type semantics accurately. To\nmodel the definition semantics, we use two separate transformer models to\nproject the contextualized event mentions and corresponding definitions into\nthe same embedding space and then minimize their embedding distance via\ncontrastive learning. On top of that, we also propose a warming phase to help\nthe model learn the minor difference between similar definitions. We name our\napproach Zero-shot Event extraction with Definition (ZED). Experiments on the\nMAVEN dataset show that our model significantly outperforms all previous\nzero-shot EE methods with fast inference speed due to the disjoint design.\nFurther experiments also show that ZED can be easily applied to the few-shot\nsetting when the annotation is available and consistently outperforms baseline\nsupervised methods.",
    "descriptor": "\nComments: Accepted by EMNLP 2022 findings\n",
    "authors": [
      "Hongming Zhang",
      "Wenlin Yao",
      "Dong Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05156"
  },
  {
    "id": "arXiv:2211.05163",
    "title": "Multimodal Dyadic Impression Recognition via Listener Adaptive  Cross-Domain Fusion",
    "abstract": "As a sub-branch of affective computing, impression recognition, e.g.,\nperception of speaker characteristics such as warmth or competence, is\npotentially a critical part of both human-human conversations and spoken\ndialogue systems. Most research has studied impressions only from the behaviors\nexpressed by the speaker or the response from the listener, yet ignored their\nlatent connection. In this paper, we perform impression recognition using a\nproposed listener adaptive cross-domain architecture, which consists of a\nlistener adaptation function to model the causality between speaker and\nlistener behaviors and a cross-domain fusion function to strengthen their\nconnection. The experimental evaluation on the dyadic IMPRESSION dataset\nverified the efficacy of our method, producing concordance correlation\ncoefficients of 78.8% and 77.5% in the competence and warmth dimensions,\noutperforming previous studies. The proposed method is expected to be\ngeneralized to similar dyadic interaction scenarios.",
    "descriptor": "\nComments: submitted to ICASSP2023. arXiv admin note: substantial text overlap with arXiv:2203.13932\n",
    "authors": [
      "Yuanchao Li",
      "Peter Bell",
      "Catherine Lai"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.05163"
  },
  {
    "id": "arXiv:2211.05165",
    "title": "Uni-Parser: Unified Semantic Parser for Question Answering on Knowledge  Base and Database",
    "abstract": "Parsing natural language questions into executable logical forms is a useful\nand interpretable way to perform question answering on structured data such as\nknowledge bases (KB) or databases (DB). However, existing approaches on\nsemantic parsing cannot adapt to both modalities, as they suffer from the\nexponential growth of the logical form candidates and can hardly generalize to\nunseen data. In this work, we propose Uni-Parser, a unified semantic parser for\nquestion answering (QA) on both KB and DB. We introduce the primitive (relation\nand entity in KB, and table name, column name and cell value in DB) as an\nessential element in our framework. The number of primitives grows linearly\nwith the number of retrieved relations in KB and DB, preventing us from dealing\nwith exponential logic form candidates. We leverage the generator to predict\nfinal logical forms by altering and composing topranked primitives with\ndifferent operations (e.g. select, where, count). With sufficiently pruned\nsearch space by a contrastive primitive ranker, the generator is empowered to\ncapture the composition of primitives enhancing its generalization ability. We\nachieve competitive results on multiple KB and DB QA benchmarks more\nefficiently, especially in the compositional and zero-shot settings.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Ye Liu",
      "Semih Yavuz",
      "Rui Meng",
      "Dragomir Radev",
      "Caiming Xiong",
      "Yingbo Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.05165"
  },
  {
    "id": "arXiv:2211.05166",
    "title": "Grammatical Error Correction: A Survey of the State of the Art",
    "abstract": "Grammatical Error Correction (GEC) is the task of automatically detecting and\ncorrecting errors in text. The task not only includes the correction of\ngrammatical errors, such as missing prepositions and mismatched subject-verb\nagreement, but also orthographic and semantic errors, such as misspellings and\nword choice errors respectively. The field has seen significant progress in the\nlast decade, motivated in part by a series of five shared tasks, which drove\nthe development of rule-based methods, statistical classifiers, statistical\nmachine translation, and finally neural machine translation systems which\nrepresent the current dominant state of the art. In this survey paper, we\ncondense the field into a single article and first outline some of the\nlinguistic challenges of the task, introduce the most popular datasets that are\navailable to researchers (for both English and other languages), and summarise\nthe various methods and techniques that have been developed with a particular\nfocus on artificial error generation. We next describe the many different\napproaches to evaluation as well as concerns surrounding metric reliability,\nespecially in relation to subjective human judgements, before concluding with\nan overview of recent progress and suggestions for future work and remaining\nchallenges. We hope that this survey will serve as comprehensive resource for\nresearchers who are new to the field or who want to be kept apprised of recent\ndevelopments.",
    "descriptor": "",
    "authors": [
      "Christopher Bryant",
      "Zheng Yuan",
      "Muhammad Reza Qorib",
      "Hannan Cao",
      "Hwee Tou Ng",
      "Ted Briscoe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.05166"
  },
  {
    "id": "arXiv:2211.05170",
    "title": "Streaming algorithms for the missing item finding problem",
    "abstract": "Many problems on data streams have been studied at two extremes of\ndifficulty: either allowing randomized algorithms, in the static setting (where\nthey should err with bounded probability on the worst case stream); or when\nonly deterministic and infallible algorithms are required. Some recent works\nhave considered the adversarial setting, in which a randomized streaming\nalgorithm must succeed even on data streams provided by an adaptive adversary\nthat can see the intermediate outputs of the algorithm.\nIn order to better understand the differences between these models, we study\na streaming task called \"Missing Item Finding\". In this problem, for $r < n$,\none is given a data stream $a_1,\\ldots,a_r$ of elements in $[n]$, (possibly\nwith repetitions), and must output some $x \\in [n]$ which does not equal any of\nthe $a_i$. We prove that, for $r = n^{\\Theta(1)}$ and $\\delta =\n1/\\mathrm{poly}(n)$, the space required for randomized algorithms that solve\nthis problem in the static setting with error $\\delta$ is\n$\\Theta(\\mathrm{polylog}(n))$; for algorithms in the adversarial setting with\nerror $\\delta$, $\\Theta((1 + r^2 / n) \\mathrm{polylog}(n))$; and for\ndeterministic algorithms, $\\Theta(r / \\mathrm{polylog}(n))$. Because our\nadversarially robust algorithm relies on free access to a string of $O(r \\log\nn)$ random bits, we investigate a \"random start\" model of streaming algorithms\nwhere all random bits used are included in the space cost. Here we find a\nconditional lower bound on the space usage, which depends on the space that\nwould be needed for a pseudo-deterministic algorithm to solve the problem. We\nalso prove an $\\Omega(r / \\mathrm{polylog}(n))$ lower bound for the space\nneeded by a streaming algorithm with $< 1/2^{\\mathrm{polylog}(n)}$ error\nagainst \"white-box\" adversaries that can see the internal state of the\nalgorithm, but not predict its future random decisions.",
    "descriptor": "\nComments: 34 pages, 6 figures, Full version of a paper accepted to SODA 2023\n",
    "authors": [
      "Manuel Stoeckl"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.05170"
  },
  {
    "id": "arXiv:2211.05178",
    "title": "Fully-dynamic-to-incremental reductions with known deletion order (e.g.  sliding window)",
    "abstract": "Dynamic algorithms come in three main flavors: $\\mathit{incremental}$\n(insertions-only), $\\mathit{decremental}$ (deletions-only), or $\\mathit{fully}$\n$\\mathit{dynamic}$ (both insertions and deletions). Fully dynamic is the holy\ngrail of dynamic algorithm design; it is obviously more general than the other\ntwo, but is it strictly harder? Several works managed to reduce fully dynamic\nto the incremental or decremental models by taking advantage of either specific\nstructure of the incremental/decremental algorithms (e.g. [HK99, HLT01, BKS12,\nADKKP16]), or specific order of insertions/deletions (e.g.\n[AW14,HKNS15,KPP16]). Our goal in this work is to get a black-box\nfully-to-incremental reduction that is as general as possible. We find that the\nfollowing conditions are necessary:\n$\\bullet$ The incremental algorithm must have a worst-case (rather than\namortized) running time guarantee.\n$\\bullet$ The reduction must work in what we call the\n$\\mathit{deletions}$-$\\mathit{look}$-$\\mathit{ahead}$ $\\mathit{model}$, where\nthe order of deletions among current elements is known in advance. A notable\npractical example is the \"sliding window\" (FIFO) order of updates.\nUnder those conditions, we design:\n$\\bullet$ A simple, practical, amortized-fully-dynamic to\nworst-case-incremental reduction with a $\\log(T)$-factor overhead on the\nrunning time, where $T$ is the total number of updates.\n$\\bullet$ A theoretical worst-case-fully-dynamic to worst-case-incremental\nreduction with a $\\mathsf{polylog}(T)$-factor overhead on the running time.",
    "descriptor": "",
    "authors": [
      "Binghui Peng",
      "Aviad Rubinstein"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.05178"
  },
  {
    "id": "arXiv:2211.05179",
    "title": "Variational Characterization of Monotone Nonlinear Eigenvector Problems  and Geometry of Self-Consistent-Field Iteration",
    "abstract": "This paper concerns a class of monotone eigenvalue problems with eigenvector\nnonlinearities (mNEPv). The mNEPv is encountered in applications such as the\ncomputation of joint numerical radius of matrices, best rank-one approximation\nof third-order partial symmetric tensors, and distance to singularity for\ndissipative Hamiltonian differential-algebraic equations. We first present a\nvariational characterization of the mNEPv. Based on the variational\ncharacterization, we provide a geometric interpretation of the\nself-consistent-field (SCF) iterations for solving the mNEPv, prove the global\nconvergence of the SCF, and devise an accelerated SCF. Numerical examples from\na variety of applications demonstrate the theoretical properties and\ncomputational efficiency of the SCF and its acceleration.",
    "descriptor": "",
    "authors": [
      "Zhaojun Bai",
      "Ding Lu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.05179"
  },
  {
    "id": "arXiv:2211.05180",
    "title": "A comparison of several AI techniques for authorship attribution on  Romanian texts",
    "abstract": "Determining the author of a text is a difficult task. Here we compare\nmultiple AI techniques for classifying literary texts written by multiple\nauthors by taking into account a limited number of speech parts (prepositions,\nadverbs, and conjunctions). We also introduce a new dataset composed of texts\nwritten in the Romanian language on which we have run the algorithms. The\ncompared methods are Artificial Neural Networks, Support Vector Machines, Multi\nExpression Programming, Decision Trees with C5.0, and k-Nearest Neighbour.\nNumerical experiments show, first of all, that the problem is difficult, but\nsome algorithms are able to generate decent errors on the test set.",
    "descriptor": "",
    "authors": [
      "Sanda Maria Avram",
      "Mihai Oltean"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.05180"
  },
  {
    "id": "arXiv:2211.05182",
    "title": "Modeling Motivational Interviewing Strategies On An Online Peer-to-Peer  Counseling Platform",
    "abstract": "Millions of people participate in online peer-to-peer support sessions, yet\nthere has been little prior research on systematic psychology-based evaluations\nof fine-grained peer-counselor behavior in relation to client satisfaction.\nThis paper seeks to bridge this gap by mapping peer-counselor chat-messages to\nmotivational interviewing (MI) techniques. We annotate 14,797 utterances from\n734 chat conversations using 17 MI techniques and introduce four new\ninterviewing codes such as chit-chat and inappropriate to account for the\nunique conversational patterns observed on online platforms. We automate the\nprocess of labeling peer-counselor responses to MI techniques by fine-tuning\nlarge domain-specific language models and then use these automated measures to\ninvestigate the behavior of the peer counselors via correlational studies.\nSpecifically, we study the impact of MI techniques on the conversation ratings\nto investigate the techniques that predict clients' satisfaction with their\ncounseling sessions. When counselors use techniques such as reflection and\naffirmation, clients are more satisfied. Examining volunteer counselors' change\nin usage of techniques suggest that counselors learn to use more introduction\nand open questions as they gain experience. This work provides a deeper\nunderstanding of the use of motivational interviewing techniques on\npeer-to-peer counselor platforms and sheds light on how to build better\ntraining programs for volunteer counselors on online platforms.",
    "descriptor": "\nComments: Accepted at CSCW 2022\n",
    "authors": [
      "Raj Sanjay Shah",
      "Faye Holt",
      "Shirley Anugrah Hayati",
      "Aastha Agarwal",
      "Yi-Chia Wang",
      "Robert E. Kraut",
      "Diyi Yang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.05182"
  },
  {
    "id": "arXiv:2211.05183",
    "title": "An Empirical Study on Clustering Pretrained Embeddings: Is Deep Strictly  Better?",
    "abstract": "Recent research in clustering face embeddings has found that unsupervised,\nshallow, heuristic-based methods -- including $k$-means and hierarchical\nagglomerative clustering -- underperform supervised, deep, inductive methods.\nWhile the reported improvements are indeed impressive, experiments are mostly\nlimited to face datasets, where the clustered embeddings are highly\ndiscriminative or well-separated by class (Recall@1 above 90% and often nearing\nceiling), and the experimental methodology seemingly favors the deep methods.\nWe conduct a large-scale empirical study of 17 clustering methods across three\ndatasets and obtain several robust findings. Notably, deep methods are\nsurprisingly fragile for embeddings with more uncertainty, where they match or\neven perform worse than shallow, heuristic-based methods. When embeddings are\nhighly discriminative, deep methods do outperform the baselines, consistent\nwith past results, but the margin between methods is much smaller than\npreviously reported. We believe our benchmarks broaden the scope of supervised\nclustering methods beyond the face domain and can serve as a foundation on\nwhich these methods could be improved. To enable reproducibility, we include\nall necessary details in the appendices, and plan to release the code.",
    "descriptor": "",
    "authors": [
      "Tyler R. Scott",
      "Ting Liu",
      "Michael C. Mozer",
      "Andrew C. Gallagher"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05183"
  },
  {
    "id": "arXiv:2211.05184",
    "title": "Are All Edges Necessary? A Unified Framework for Graph Purification",
    "abstract": "Graph Neural Networks (GNNs) as deep learning models working on\ngraph-structure data have achieved advanced performance in many works. However,\nit has been proved repeatedly that, not all edges in a graph are necessary for\nthe training of machine learning models. In other words, some of the\nconnections between nodes may bring redundant or even misleading information to\ndownstream tasks. In this paper, we try to provide a method to drop edges in\norder to purify the graph data from a new perspective. Specifically, it is a\nframework to purify graphs with the least loss of information, under which the\ncore problems are how to better evaluate the edges and how to delete the\nrelatively redundant edges with the least loss of information. To address the\nabove two problems, we propose several measurements for the evaluation and\ndifferent judges and filters for the edge deletion. We also introduce a\nresidual-iteration strategy and a surrogate model for measurements requiring\nunknown information. The experimental results show that our proposed\nmeasurements for KL divergence with constraints to maintain the connectivity of\nthe graph and delete edges in an iterative way can find out the most edges\nwhile keeping the performance of GNNs. What's more, further experiments show\nthat this method also achieves the best defense performance against adversarial\nattacks.",
    "descriptor": "",
    "authors": [
      "Zishan Gu",
      "Jintang Li",
      "Liang Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05184"
  },
  {
    "id": "arXiv:2211.05187",
    "title": "Training a Vision Transformer from scratch in less than 24 hours with 1  GPU",
    "abstract": "Transformers have become central to recent advances in computer vision.\nHowever, training a vision Transformer (ViT) model from scratch can be resource\nintensive and time consuming. In this paper, we aim to explore approaches to\nreduce the training costs of ViT models. We introduce some algorithmic\nimprovements to enable training a ViT model from scratch with limited hardware\n(1 GPU) and time (24 hours) resources. First, we propose an efficient approach\nto add locality to the ViT architecture. Second, we develop a new image size\ncurriculum learning strategy, which allows to reduce the number of patches\nextracted from each image at the beginning of the training. Finally, we propose\na new variant of the popular ImageNet1k benchmark by adding hardware and time\nconstraints. We evaluate our contributions on this benchmark, and show they can\nsignificantly improve performances given the proposed training budget. We will\nshare the code in https://github.com/BorealisAI/efficient-vit-training.",
    "descriptor": "\nComments: 7 pages, 2 figures, 1 table, published in \"Has it Trained Yet? Workshop at the Conference on Neural Information Processing Systems (NeurIPS 2022)\"\n",
    "authors": [
      "Saghar Irandoust",
      "Thibaut Durand",
      "Yunduz Rakhmangulova",
      "Wenjie Zi",
      "Hossein Hajimirsadeghi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05187"
  },
  {
    "id": "arXiv:2211.05189",
    "title": "From NetLogo Modeling of Deterministic Random Walk to the Identification  of Asymmetric Saturation Time in Random Graphs",
    "abstract": "Interactive programming environments are powerful tools for promoting\ninnovative network thinking, teaching complexity science, and exploring\nemergent phenomena. This paper reports on our recent development of the\ndeterministic random walk model in NetLogo, a leading platform for\ncomputational thinking, eco-system thinking, and multi-agent cross-platform\nprogramming environment. The deterministic random walk is foundational to\nmodeling dynamical processes on complex networks. Inspired by the temporal\nvisualizations offered in NetLogo, we investigated the relationship between\nnetwork topology and diffusion saturation time for the deterministic random\nwalk model. Our analysis uncovers that in Erdos-Renyi graphs, the saturation\ntime exhibits an asymmetric pattern with a considerable probability of\noccurrence. This behavior occurs when the hubs, defined as nodes with\nrelatively higher number of connections, emerge in Erdos-Renyi graphs. Yet, our\nanalysis yields that the Barabasi-Albert model hubs stabilize the the\nconvergence time of the deterministic random walk model. These findings\nstrongly suggest that depending on the dynamical process running on complex\nnetworks, complementing characteristics other than the degree need to be taken\ninto account for considering a node as a hub. We have made our development\nopen-source, available to the public at no cost at\nhttps://github.com/bravandi/NetLogo-Dynamical-Processes.",
    "descriptor": "",
    "authors": [
      "Ayan Chatterjee",
      "Qingtao Cao",
      "Amirhossein Sajadi",
      "Babak Ravandi"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.05189"
  },
  {
    "id": "arXiv:2211.05190",
    "title": "Towards Reasoning-Aware Explainable VQA",
    "abstract": "The domain of joint vision-language understanding, especially in the context\nof reasoning in Visual Question Answering (VQA) models, has garnered\nsignificant attention in the recent past. While most of the existing VQA models\nfocus on improving the accuracy of VQA, the way models arrive at an answer is\noftentimes a black box. As a step towards making the VQA task more explainable\nand interpretable, our method is built upon the SOTA VQA framework by\naugmenting it with an end-to-end explanation generation module. In this paper,\nwe investigate two network architectures, including Long Short-Term Memory\n(LSTM) and Transformer decoder, as the explanation generator. Our method\ngenerates human-readable textual explanations while maintaining SOTA VQA\naccuracy on the GQA-REX (77.49%) and VQA-E (71.48%) datasets. Approximately\n65.16% of the generated explanations are approved by humans as valid. Roughly\n60.5% of the generated explanations are valid and lead to the correct answers.",
    "descriptor": "",
    "authors": [
      "Rakesh Vaideeswaran",
      "Feng Gao",
      "Abhinav Mathur",
      "Govind Thattai"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05190"
  },
  {
    "id": "arXiv:2211.05198",
    "title": "Collateral facilitation in humans and language models",
    "abstract": "Are the predictions of humans and language models affected by similar things?\nResearch suggests that while comprehending language, humans make predictions\nabout upcoming words, with more predictable words being processed more easily.\nHowever, evidence also shows that humans display a similar processing advantage\nfor highly anomalous words when these words are semantically related to the\npreceding context or to the most probable continuation. Using stimuli from 3\npsycholinguistic experiments, we find that this is also almost always also the\ncase for 8 contemporary transformer language models (BERT, ALBERT, RoBERTa,\nXLM-R, GPT-2, GPT-Neo, GPT-J, and XGLM). We then discuss the implications of\nthis phenomenon for our understanding of both human language comprehension and\nthe predictions made by language models.",
    "descriptor": "\nComments: Accepted at CoNLL 2022\n",
    "authors": [
      "James A. Michaelov",
      "Benjamin K. Bergen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.05198"
  },
  {
    "id": "arXiv:2211.05199",
    "title": "An Open, Multi-Platform Software Architecture for Online Education in  the Metaverse",
    "abstract": "Use of online platforms for education is a vibrant and growing arena,\nincorporating a variety of software platforms and technologies, including\nvarious modalities of extended reality. We present our Enhanced Reality\nTeaching Concierge, an open networking hub architected to enable efficient and\neasy connectivity between a wide variety of services or applications to a wide\nvariety of clients, designed to showcase 3D for academic purposes across web\ntechnologies, virtual reality, and even virtual worlds. The agnostic nature of\nthe system, paired with efficient architecture, and simple and open protocols\nfurnishes an ecosystem that can easily be tailored to maximize the innate\ncharacteristics of each 3D display environment while sharing common data and\ncontrol systems with the ultimate goal of a seamless, expandable, nimble\neducation metaverse.",
    "descriptor": "\nComments: 4 pages, 3 figures; In The 27th International Conference on 3D Web Technology (Web3D 2022). ACM, New York, NY, USA\n",
    "authors": [
      "S. Lombeyda",
      "S. G. Djorgovski",
      "A. Tran",
      "J. Liu",
      "A. Noyes",
      "S. Fomina"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Physics Education (physics.ed-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.05199"
  },
  {
    "id": "arXiv:2211.05200",
    "title": "Affordance detection with Dynamic-Tree Capsule Networks",
    "abstract": "Affordance detection from visual input is a fundamental step in autonomous\nrobotic manipulation. Existing solutions to the problem of affordance detection\nrely on convolutional neural networks. However, these networks do not consider\nthe spatial arrangement of the input data and miss parts-to-whole\nrelationships. Therefore, they fall short when confronted with novel,\npreviously unseen object instances or new viewpoints. One solution to overcome\nsuch limitations can be to resort to capsule networks. In this paper, we\nintroduce the first affordance detection network based on dynamic\ntree-structured capsules for sparse 3D point clouds. We show that our\ncapsule-based network outperforms current state-of-the-art models on viewpoint\ninvariance and parts-segmentation of new object instances through a novel\ndataset we only used for evaluation and it is publicly available from\ngithub.com/gipfelen/DTCG-Net. In the experimental evaluation we will show that\nour algorithm is superior to current affordance detection methods when faced\nwith grasping previously unseen objects thanks to our Capsule Network enforcing\na parts-to-whole representation.",
    "descriptor": "\nComments: IEEE-RAS International Conference on Humanoid Robots (Humanoids 2022)\n",
    "authors": [
      "Antonio Rodr\u00edguez-S\u00e1nchez",
      "Simon Haller-Seeber",
      "David Peer",
      "Chris Engelhardt",
      "Jakob Mittelberger",
      "Matteo Saveriano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.05200"
  },
  {
    "id": "arXiv:2211.05201",
    "title": "HilMeMe: A Human-in-the-Loop Machine Translation Evaluation Metric  Looking into Multi-Word Expressions",
    "abstract": "With the fast development of Machine Translation (MT) systems, especially the\nnew boost from Neural MT (NMT) models, the MT output quality has reached a new\nlevel of accuracy. However, many researchers criticised that the current\npopular evaluation metrics such as BLEU can not correctly distinguish the\nstate-of-the-art NMT systems regarding quality differences. In this short\npaper, we describe the design and implementation of a linguistically motivated\nhuman-in-the-loop evaluation metric looking into idiomatic and terminological\nMulti-word Expressions (MWEs). MWEs have played a bottleneck in many Natural\nLanguage Processing (NLP) tasks including MT. MWEs can be used as one of the\nmain factors to distinguish different MT systems by looking into their\ncapabilities in recognising and translating MWEs in an accurate and meaning\nequivalent manner.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2105.03311\n",
    "authors": [
      "Lifeng Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.05201"
  },
  {
    "id": "arXiv:2211.05203",
    "title": "Data-driven Cyberattack Synthesis against Network Control Systems",
    "abstract": "Network Control Systems (NCSs) pose unique vulnerabilities to cyberattacks\ndue to a heavy reliance on communication channels. These channels can be\nsusceptible to eavesdropping, false data injection (FDI), and denial of service\n(DoS). As a result, smarter cyberattacks can employ a combination of techniques\nto cause degradation of the considered NCS performance. We consider a white-box\ncyberattack synthesis technique in which the attacker initially eavesdrops to\ngather system data, and constructs equivalent system model. We utilize the\nequivalent model to synthesize hybrid cyberattacks -- a combination of FDI and\nDoS attacks against the NCS. Reachable sets for the equivalent NCS model\nprovide rapid, real-time directives towards selecting NCS agents to be\nattacked. The devised method provides a significantly more realistic approach\ntoward cyberattack synthesis against NCSs with unknown parameters. We\ndemonstrate the proposed method using a multi-aerial vehicle formation control\nscenario.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Omanshu Thapliyal",
      "Inseok Hwang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.05203"
  },
  {
    "id": "arXiv:2211.05206",
    "title": "It's TEEtime: Bringing User Sovereignty to Smartphones",
    "abstract": "The majority of smartphones either run iOS or Android operating systems. This\nhas created two distinct ecosystems largely controlled by Apple and Google -\nthey dictate which applications can run, how they run, and what kind of phone\nresources they can access. Barring some exceptions in Android where different\nphone manufacturers may have influence, users, developers, and governments are\nleft with little control. Specifically, users need to entrust their security\nand privacy to OS vendors and accept the functionality constraints they impose.\nGiven the wide use of Android and iOS, immediately leaving these ecosystems is\nnot practical, except in niche application areas. In this work, we propose a\nnew smartphone architecture that securely transfers the control over the\nsmartphone back to the users while maintaining compatibility with the existing\nsmartphone ecosystems. Our architecture, named TEEtime, is based on ARMv8 and\nimplements novel, TEE-based, resource and interrupt isolation mechanisms which\nallow the users to flexibly choose which resources (including peripherals) to\ndedicate to different isolated domains, namely, to legacy OSs and to user's\nproprietary software. We show the feasibility of our design by implementing a\nprototype of TEEtime on an ARM emulator.",
    "descriptor": "",
    "authors": [
      "Friederike Groschupp",
      "Mark Kuhne",
      "Moritz Schneider",
      "Ivan Puddu",
      "Shweta Shinde",
      "Srdjan Capkun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.05206"
  },
  {
    "id": "arXiv:2211.05207",
    "title": "Mapping the Ictal-Interictal-Injury Continuum Using Interpretable  Machine Learning",
    "abstract": "IMPORTANCE: An interpretable machine learning model can provide faithful\nexplanations of each prediction and yet maintain higher performance than its\nblack box counterpart.\nOBJECTIVE: To design an interpretable machine learning model which accurately\npredicts EEG protopatterns while providing an explanation of its predictions\nwith assistance of a specialized GUI. To map the cEEG latent features to a 2D\nspace in order to visualize the ictal-interictal-injury continuum and gain\ninsight into its high-dimensional structure.\nDESIGN, SETTING, AND PARTICIPANTS: 50,697 50-second cEEG samples from 2,711\nICU patients collected between July 2006 and March 2020 at Massachusetts\nGeneral Hospital. Samples were labeled as one of 6 EEG activities by domain\nexperts, with 124 different experts providing annotations.\nMAIN OUTCOMES AND MEASURES: Our neural network is interpretable because it\nuses case-based reasoning: it compares a new EEG reading to a set of learned\nprototypical EEG samples from the training dataset. Interpretability was\nmeasured with task-specific neighborhood agreement statistics. Discriminatory\nperformance was evaluated with AUROC and AUPRC.\nRESULTS: The model achieves AUROCs of 0.87, 0.93, 0.96, 0.92, 0.93, 0.80 for\nclasses Seizure, LPD, GPD, LRDA, GRDA, Other respectively. This performance is\nstatistically significantly higher than that of the corresponding\nuninterpretable (black box) model with p<0.0001. Videos of the\nictal-interictal-injury continuum are provided.\nCONCLUSION AND RELEVANCE: Our interpretable model and GUI can act as a\nreference for practitioners who work with cEEG patterns. We can now better\nunderstand the relationships between different types of cEEG patterns. In the\nfuture, this system may allow for targeted intervention and training in\nclinical settings. It could also be used for re-confirming or providing\nadditional information for diagnostics.",
    "descriptor": "\nComments: 16 pages, draft to be submitted for peer review\n",
    "authors": [
      "Alina Jade Barnett",
      "Zhicheng Guo",
      "Jin Jing",
      "Wendong Ge",
      "Cynthia Rudin",
      "M. Brandon Westover"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05207"
  },
  {
    "id": "arXiv:2211.05213",
    "title": "Flaky Performances when Pretraining on Relational Databases",
    "abstract": "We explore the downstream task performances for graph neural network (GNN)\nself-supervised learning (SSL) methods trained on subgraphs extracted from\nrelational databases (RDBs). Intuitively, this joint use of SSL and GNNs should\nallow to leverage more of the available data, which could translate to better\nresults. However, we found that naively porting contrastive SSL techniques can\ncause ``negative transfer'': linear evaluation on fixed representations from a\npretrained model performs worse than on representations from the\nrandomly-initialized model. Based on the conjecture that contrastive SSL\nconflicts with the message passing layers of the GNN, we propose InfoNode: a\ncontrastive loss aiming to maximize the mutual information between a node's\ninitial- and final-layer representation. The primary empirical results support\nour conjecture and the effectiveness of InfoNode.",
    "descriptor": "",
    "authors": [
      "Shengchao Liu",
      "David Vazquez",
      "Jian Tang",
      "Pierre-Andr\u00e9 No\u00ebl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05213"
  },
  {
    "id": "arXiv:2211.05215",
    "title": "Content-Diverse Comparisons improve IQA",
    "abstract": "Image quality assessment (IQA) forms a natural and often straightforward\nundertaking for humans, yet effective automation of the task remains highly\nchallenging. Recent metrics from the deep learning community commonly compare\nimage pairs during training to improve upon traditional metrics such as PSNR or\nSSIM. However, current comparisons ignore the fact that image content affects\nquality assessment as comparisons only occur between images of similar content.\nThis restricts the diversity and number of image pairs that the model is\nexposed to during training. In this paper, we strive to enrich these\ncomparisons with content diversity. Firstly, we relax comparison constraints,\nand compare pairs of images with differing content. This increases the variety\nof available comparisons. Secondly, we introduce listwise comparisons to\nprovide a holistic view to the model. By including differentiable regularizers,\nderived from correlation coefficients, models can better adjust predicted\nscores relative to one another. Evaluation on multiple benchmarks, covering a\nwide range of distortions and image content, shows the effectiveness of our\nlearning scheme for training image quality assessment models.",
    "descriptor": "\nComments: Accepted at British Machine Vision Conference (BMVC) 2022\n",
    "authors": [
      "William Thong",
      "Jose Costa Pereira",
      "Sarah Parisot",
      "Ales Leonardis",
      "Steven McDonagh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05215"
  },
  {
    "id": "arXiv:2211.05217",
    "title": "Smaller Low-Depth Circuits for Kronecker Powers",
    "abstract": "We give new, smaller constructions of constant-depth linear circuits for\ncomputing any matrix which is the Kronecker power of a fixed matrix. A standard\nargument (e.g., the mixed product property of Kronecker products, or a\ngeneralization of the Fast Walsh-Hadamard transform) shows that any such $N\n\\times N$ matrix has a depth-2 circuit of size $O(N^{1.5})$. We improve on this\nfor all such matrices, and especially for some such matrices of particular\ninterest:\n- For any integer $q > 1$ and any matrix which is the Kronecker power of a\nfixed $q \\times q$ matrix, we construct a depth-2 circuit of size $O(N^{1.5 -\na_q})$, where $a_q > 0$ is a positive constant depending only on $q$. No bound\nbeating size $O(N^{1.5})$ was previously known for any $q>2$.\n- For the case $q=2$, i.e., for any matrix which is the Kronecker power of a\nfixed $2 \\times 2$ matrix, we construct a depth-2 circuit of size\n$O(N^{1.446})$, improving the prior best size $O(N^{1.493})$ [Alman, 2021].\n- For the Walsh-Hadamard transform, we construct a depth-2 circuit of size\n$O(N^{1.443})$, improving the prior best size $O(N^{1.476})$ [Alman, 2021].\n- For the disjointness matrix (the communication matrix of set disjointness,\nor equivalently, the matrix for the linear transform that evaluates a\nmultilinear polynomial on all $0/1$ inputs), we construct a depth-2 circuit of\nsize $O(N^{1.258})$, improving the prior best size $O(N^{1.272})$ [Jukna and\nSergeev, 2013].\nOur constructions also generalize to improving the standard construction for\nany depth $\\leq O(\\log N)$. Our main technical tool is an improved way to\nconvert a nontrivial circuit for any matrix into a circuit for its Kronecker\npowers. Our new bounds provably could not be achieved using the approaches of\nprior work.",
    "descriptor": "\nComments: 36 pages, to appear in the 34th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA 2023)\n",
    "authors": [
      "Josh Alman",
      "Yunfeng Guan",
      "Ashwin Padaki"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.05217"
  },
  {
    "id": "arXiv:2211.05222",
    "title": "ViSE: Vision-Based 3D Real-Time Shape Estimation of Continuously  Deformable Robots",
    "abstract": "The precise control of soft and continuum robots requires knowledge of their\nshape. The shape of these robots has, in contrast to classical rigid robots,\ninfinite degrees of freedom. To partially reconstruct the shape, proprioceptive\ntechniques use built-in sensors resulting in inaccurate results and increased\nfabrication complexity. Exteroceptive methods so far rely on placing reflective\nmarkers on all tracked components and triangulating their position using\nmultiple motion-tracking cameras. Tracking systems are expensive and infeasible\nfor deformable robots interacting with the environment due to marker occlusion\nand damage. Here, we present a regression approach for 3D shape estimation\nusing a convolutional neural network. The proposed approach takes advantage of\ndata-driven supervised learning and is capable of real-time marker-less shape\nestimation during inference. Two images of a robotic system are taken\nsimultaneously at 25 Hz from two different perspectives, and are fed to the\nnetwork, which returns for each pair the parameterized shape. The proposed\napproach outperforms marker-less state-of-the-art methods by a maximum of 4.4\\%\nin estimation accuracy while at the same time being more robust and requiring\nno prior knowledge of the shape. The approach can be easily implemented due to\nonly requiring two color cameras without depth and not needing an explicit\ncalibration of the extrinsic parameters. Evaluations on two types of soft\nrobotic arms and a soft robotic fish demonstrate our method's accuracy and\nversatility on highly deformable systems in real-time. The robust performance\nof the approach against different scene modifications (camera alignment and\nbrightness) suggests its generalizability to a wider range of experimental\nsetups, which will benefit downstream tasks such as robotic grasping and\nmanipulation.",
    "descriptor": "",
    "authors": [
      "Hehui Zheng",
      "Sebastian Pinzello",
      "Barnabas Gavin Cangan",
      "Thomas Buchner",
      "Robert K. Katzschmann"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.05222"
  },
  {
    "id": "arXiv:2211.05223",
    "title": "Aperiodic Sampled-Data Distributed Observer Design",
    "abstract": "This paper deals with state estimation of linear systems using distributed\nobservers with local sampled-data measurement and aperiodic communication. Each\nobserver node perceives partial information of the system to be observed but\ndoes not satisfy the observability condition. Consequently, distributed\nobservers are designed to estimate the state of the to-be-observed system by\ntime-varying sampling and asynchronous communication. Additionally, explicit\nupper bounds on allowable sampling periods for convergent estimation errors are\ngiven. Finally, a numerical example is provided to illustrate the validity of\nthe theoretical results.",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Shimin Wang",
      "Zhan Shua",
      "Tongwen Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.05223"
  },
  {
    "id": "arXiv:2211.05227",
    "title": "Automatic Creativity Measurement in Scratch Programs Across Modalities",
    "abstract": "Promoting creativity is considered an important goal of education, but\ncreativity is notoriously hard to measure.In this paper, we make the journey\nfromdefining a formal measure of creativity that is efficientlycomputable to\napplying the measure in a practical domain. The measure is general and relies\non coretheoretical concepts in creativity theory, namely fluency, flexibility,\nand originality, integratingwith prior cognitive science literature. We adapted\nthe general measure for projects in the popular visual programming language\nScratch.We designed a machine learning model for predicting the creativity of\nScratch projects, trained and evaluated on human expert creativity assessments\nin an extensive user study. Our results show that opinions about creativity in\nScratch varied widely across experts. The automatic creativity assessment\naligned with the assessment of the human experts more than the experts agreed\nwith each other. This is a first step in providing computational models for\nmeasuring creativity that can be applied to educational technologies, and to\nscale up the benefit of creativity education in schools.",
    "descriptor": "",
    "authors": [
      "Anastasia Kovalkov",
      "Benjamin Paa\u00dfen",
      "Avi Segal",
      "Niels Pinkwart",
      "Kobi Gal"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05227"
  },
  {
    "id": "arXiv:2211.05228",
    "title": "FIXED: Frustratingly Easy Domain Generalization with Mixup",
    "abstract": "Domain generalization (DG) aims to learn a generalizable model from multiple\ntraining domains such that it can perform well on unseen target domains. A\npopular strategy is to augment training data to benefit generalization through\nmethods such as Mixup~\\cite{zhang2018mixup}. While the vanilla Mixup can be\ndirectly applied, theoretical and empirical investigations uncover several\nshortcomings that limit its performance. Firstly, Mixup cannot effectively\nidentify the domain and class information that can be used for learning\ninvariant representations. Secondly, Mixup may introduce synthetic noisy data\npoints via random interpolation, which lowers its discrimination capability.\nBased on the analysis, we propose a simple yet effective enhancement for\nMixup-based DG, namely domain-invariant Feature mIXup (FIX). It learns\ndomain-invariant representations for Mixup. To further enhance discrimination,\nwe leverage existing techniques to enlarge margins among classes to further\npropose the domain-invariant Feature MIXup with Enhanced Discrimination (FIXED)\napproach. We present theoretical insights about guarantees on its\neffectiveness. Extensive experiments on seven public datasets across two\nmodalities including image classification (Digits-DG, PACS, Office-Home) and\ntime series (DSADS, PAMAP2, UCI-HAR, and USC-HAD) demonstrate that our approach\nsignificantly outperforms nine state-of-the-art related methods, beating the\nbest performing baseline by 6.5\\% on average in terms of test accuracy.",
    "descriptor": "\nComments: Technical report; code for DG at: this https URL\n",
    "authors": [
      "Wang Lu",
      "Jindong Wang",
      "Han Yu",
      "Lei Huang",
      "Xiang Zhang",
      "Yiqiang Chen",
      "Xing Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05228"
  },
  {
    "id": "arXiv:2211.05229",
    "title": "Automatic Number Plate Recognition (ANPR) with YOLOv3-CNN",
    "abstract": "We present a YOLOv3-CNN pipeline for detecting vehicles, segregation of\nnumber plates, and local storage of final recognized characters. Vehicle\nidentification is performed under various image correction schemes to determine\nthe effect of environmental factors (angle of perception, luminosity,\nmotion-blurring, and multi-line custom font etc.). A YOLOv3 object detection\nmodel was trained to identify vehicles from a dataset of traffic images. A\nsecond YOLOv3 layer was trained to identify number plates from vehicle images.\nBased upon correction schemes, individual characters were segregated and\nverified against real-time data to calculate accuracy of this approach. While\ncharacters under direct view were recognized accurately, some numberplates\naffected by environmental factors had reduced levels of accuracy. We summarize\nthe results under various environmental factors against real-time data and\nproduce an overall accuracy of the pipeline model.",
    "descriptor": "\nComments: 29 pages, 4 figures, 2 tables\n",
    "authors": [
      "Rajdeep Adak",
      "Abhishek Kumbhar",
      "Rajas Pathare",
      "Sagar Gowda"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.05229"
  },
  {
    "id": "arXiv:2211.05231",
    "title": "Biologically-Inspired Continual Learning of Human Motion Sequences",
    "abstract": "This work proposes a model for continual learning on tasks involving temporal\nsequences, specifically, human motions. It improves on a recently proposed\nbrain-inspired replay model (BI-R) by building a biologically-inspired\nconditional temporal variational autoencoder (BI-CTVAE), which instantiates a\nlatent mixture-of-Gaussians for class representation. We investigate a novel\ncontinual-learning-to-generate (CL2Gen) scenario where the model generates\nmotion sequences of different classes. The generative accuracy of the model is\ntested over a set of tasks. The final classification accuracy of BI-CTVAE on a\nhuman motion dataset after sequentially learning all action classes is 78%,\nwhich is 63% higher than using no-replay, and only 5.4% lower than a\nstate-of-the-art offline trained GRU model.",
    "descriptor": "",
    "authors": [
      "Joachim Ott",
      "Shih-Chii Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05231"
  },
  {
    "id": "arXiv:2211.05232",
    "title": "MuMIC -- Multimodal Embedding for Multi-label Image Classification with  Tempered Sigmoid",
    "abstract": "Multi-label image classification is a foundational topic in various domains.\nMultimodal learning approaches have recently achieved outstanding results in\nimage representation and single-label image classification. For instance,\nContrastive Language-Image Pretraining (CLIP) demonstrates impressive\nimage-text representation learning abilities and is robust to natural\ndistribution shifts. This success inspires us to leverage multimodal learning\nfor multi-label classification tasks, and benefit from contrastively learnt\npretrained models. We propose the Multimodal Multi-label Image Classification\n(MuMIC) framework, which utilizes a hardness-aware tempered sigmoid based\nBinary Cross Entropy loss function, thus enables the optimization on\nmulti-label objectives and transfer learning on CLIP. MuMIC is capable of\nproviding high classification performance, handling real-world noisy data,\nsupporting zero-shot predictions, and producing domain-specific image\nembeddings. In this study, a total of 120 image classes are defined, and more\nthan 140K positive annotations are collected on approximately 60K Booking.com\nimages. The final MuMIC model is deployed on Booking.com Content Intelligence\nPlatform, and it outperforms other state-of-the-art models with 85.6% GAP@10\nand 83.8% GAP on all 120 classes, as well as a 90.1% macro mAP score across 32\nmajority classes. We summarize the modeling choices which are extensively\ntested through ablation studies. To the best of our knowledge, we are the first\nto adapt contrastively learnt multimodal pretraining for real-world multi-label\nimage classification problems, and the innovation can be transferred to other\ndomains.",
    "descriptor": "",
    "authors": [
      "Fengjun Wang",
      "Sarai Mizrachi",
      "Moran Beladev",
      "Guy Nadav",
      "Gil Amsalem",
      "Karen Lastmann Assaraf",
      "Hadas Harush Boker"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05232"
  },
  {
    "id": "arXiv:2211.05233",
    "title": "Plausibility Verification For 3D Object Detectors Using Energy-Based  Optimization",
    "abstract": "Environmental perception obtained via object detectors have no predictable\nsafety layer encoded into their model schema, which creates the question of\ntrustworthiness about the system's prediction. As can be seen from recent\nadversarial attacks, most of the current object detection networks are\nvulnerable to input tampering, which in the real world could compromise the\nsafety of autonomous vehicles. The problem would be amplified even more when\nuncertainty errors could not propagate into the submodules, if these are not a\npart of the end-to-end system design. To address these concerns, a parallel\nmodule which verifies the predictions of the object proposals coming out of\nDeep Neural Networks are required. This work aims to verify 3D object proposals\nfrom MonoRUn model by proposing a plausibility framework that leverages cross\nsensor streams to reduce false positives. The verification metric being\nproposed uses prior knowledge in the form of four different energy functions,\neach utilizing a certain prior to output an energy value leading to a\nplausibility justification for the hypothesis under consideration. We also\nemploy a novel two-step schema to improve the optimization of the composite\nenergy function representing the energy model.",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Abhishek Vivekanandan",
      "Niels Maier",
      "J. Marius Zoellner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05233"
  },
  {
    "id": "arXiv:2211.05234",
    "title": "Generating Clear Images From Images With Distortions Caused by Adverse  Weather Using Generative Adversarial Networks",
    "abstract": "We presented a method for improving computer vision tasks on images affected\nby adverse weather conditions, including distortions caused by adherent\nraindrops. Overcoming the challenge of applying computer vision to images\naffected by adverse weather conditions is essential for autonomous vehicles\nutilizing RGB cameras. For this purpose, we trained an appropriate generative\nadversarial network and showed that it was effective at removing the effect of\nthe distortions, in the context of image reconstruction and computer vision\ntasks. We showed that object recognition, a vital task for autonomous driving\nvehicles, is completely impaired by the distortions and occlusions caused by\nadherent raindrops and that performance can be restored by our de-raining\nmodel. The approach described in this paper could be applied to all adverse\nweather conditions.",
    "descriptor": "\nComments: 14 pages, 8 figures. arXiv admin note: text overlap with arXiv:2112.11245\n",
    "authors": [
      "Nuriel Shalom Mor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05234"
  },
  {
    "id": "arXiv:2211.05236",
    "title": "Okapi: Generalising Better by Making Statistical Matches Match",
    "abstract": "We propose Okapi, a simple, efficient, and general method for robust\nsemi-supervised learning based on online statistical matching. Our method uses\na nearest-neighbours-based matching procedure to generate cross-domain views\nfor a consistency loss, while eliminating statistical outliers. In order to\nperform the online matching in a runtime- and memory-efficient way, we draw\nupon the self-supervised literature and combine a memory bank with a\nslow-moving momentum encoder. The consistency loss is applied within the\nfeature space, rather than on the predictive distribution, making the method\nagnostic to both the modality and the task in question. We experiment on the\nWILDS 2.0 datasets Sagawa et al., which significantly expands the range of\nmodalities, applications, and shifts available for studying and benchmarking\nreal-world unsupervised adaptation. Contrary to Sagawa et al., we show that it\nis in fact possible to leverage additional unlabelled data to improve upon\nempirical risk minimisation (ERM) results with the right method. Our method\noutperforms the baseline methods in terms of out-of-distribution (OOD)\ngeneralisation on the iWildCam (a multi-class classification task) and\nPovertyMap (a regression task) image datasets as well as the CivilComments (a\nbinary classification task) text dataset. Furthermore, from a qualitative\nperspective, we show the matches obtained from the learned encoder are strongly\nsemantically related. Code for our paper is publicly available at\nhttps://github.com/wearepal/okapi/.",
    "descriptor": "\nComments: Proceeding of NeurIPS 2022\n",
    "authors": [
      "Myles Bartlett",
      "Sara Romiti",
      "Viktoriia Sharmanska",
      "Novi Quadrianto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05236"
  },
  {
    "id": "arXiv:2211.05237",
    "title": "SimuShips -- A High Resolution Simulation Dataset for Ship Detection  with Precise Annotations",
    "abstract": "Obstacle detection is a fundamental capability of an autonomous maritime\nsurface vessel (AMSV). State-of-the-art obstacle detection algorithms are based\non convolutional neural networks (CNNs). While CNNs provide higher detection\naccuracy and fast detection speed, they require enormous amounts of data for\ntheir training. In particular, the availability of domain-specific datasets is\na challenge for obstacle detection. The difficulty in conducting onsite\nexperiments limits the collection of maritime datasets. Owing to the logistic\ncost of conducting on-site operations, simulation tools provide a safe and\ncost-efficient alternative for data collection. In this work, we introduce\nSimuShips, a publicly available simulation-based dataset for maritime\nenvironments. Our dataset consists of 9471 high-resolution (1920x1080) images\nwhich include a wide range of obstacle types, atmospheric and illumination\nconditions along with occlusion, scale and visible proportion variations. We\nprovide annotations in the form of bounding boxes. In addition, we conduct\nexperiments with YOLOv5 to test the viability of simulation data. Our\nexperiments indicate that the combination of real and simulated images improves\nthe recall for all classes by 2.9%.",
    "descriptor": "",
    "authors": [
      "Minahil Raza",
      "Hanna Prokopova",
      "Samir Huseynzade",
      "Sepinoud Azimi",
      "Sebastien Lafond"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.05237"
  },
  {
    "id": "arXiv:2211.05239",
    "title": "RecD: Deduplication for End-to-End Deep Learning Recommendation Model  Training Infrastructure",
    "abstract": "We present RecD (Recommendation Deduplication), a suite of end-to-end\ninfrastructure optimizations across the Deep Learning Recommendation Model\n(DLRM) training pipeline. RecD addresses immense storage, preprocessing, and\ntraining overheads caused by feature duplication inherent in industry-scale\nDLRM training datasets. Feature duplication arises because DLRM datasets are\ngenerated from interactions. While each user session can generate multiple\ntraining samples, many features' values do not change across these samples. We\ndemonstrate how RecD exploits this property, end-to-end, across a deployed\ntraining pipeline. RecD optimizes data generation pipelines to decrease dataset\nstorage and preprocessing resource demands and to maximize duplication within a\ntraining batch. RecD introduces a new tensor format, InverseKeyedJaggedTensors\n(IKJTs), to deduplicate feature values in each batch. We show how DLRM model\narchitectures can leverage IKJTs to drastically increase training throughput.\nRecD improves the training and preprocessing throughput and storage efficiency\nby up to 2.49x, 1.79x, and 3.71x, respectively, in an industry-scale DLRM\ntraining system.",
    "descriptor": "",
    "authors": [
      "Mark Zhao",
      "Dhruv Choudhary",
      "Devashish Tyagi",
      "Ajay Somani",
      "Max Kaplan",
      "Sung-Han Lin",
      "Sarunya Summa",
      "Jongsoo Park",
      "Aarti Basant",
      "Niket Agarwal",
      "Carole-Jean Wu",
      "Christos Kozyrakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Retrieval (cs.IR)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2211.05239"
  },
  {
    "id": "arXiv:2211.05243",
    "title": "Vision-based navigation and obstacle avoidance via deep reinforcement  learning",
    "abstract": "Development of navigation algorithms is essential for the successful\ndeployment of robots in rapidly changing hazardous environments for which prior\nknowledge of configuration is often limited or unavailable. Use of traditional\npath-planning algorithms, which are based on localization and require detailed\nobstacle maps with goal locations, is not possible. In this regard,\nvision-based algorithms hold great promise, as visual information can be\nreadily acquired by a robot's onboard sensors and provides a much richer source\nof information from which deep neural networks can extract complex patterns.\nDeep reinforcement learning has been used to achieve vision-based robot\nnavigation. However, the efficacy of these algorithms in environments with\ndynamic obstacles and high variation in the configuration space has not been\nthoroughly investigated. In this paper, we employ a deep Dyna-Q learning\nalgorithm for room evacuation and obstacle avoidance in partially observable\nenvironments based on low-resolution raw image data from an onboard camera. We\nexplore the performance of a robotic agent in environments containing no\nobstacles, convex obstacles, and concave obstacles, both static and dynamic.\nObstacles and the exit are initialized in random positions at the start of each\nepisode of reinforcement learning. Overall, we show that our algorithm and\ntraining approach can generalize learning for collision-free evacuation of\nenvironments with complex obstacle configurations. It is evident that the agent\ncan navigate to a goal location while avoiding multiple static and dynamic\nobstacles, and can escape from a concave obstacle while searching for and\nnavigating to the exit.",
    "descriptor": "",
    "authors": [
      "Paul Blum",
      "Peter Crowley",
      "George Lykotrafitis"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.05243"
  },
  {
    "id": "arXiv:2211.05244",
    "title": "Deep Learning for Time Series Anomaly Detection: A Survey",
    "abstract": "Time series anomaly detection has applications in a wide range of research\nfields and applications, including manufacturing and healthcare. The presence\nof anomalies can indicate novel or unexpected events, such as production\nfaults, system defects, or heart fluttering, and is therefore of particular\ninterest. The large size and complex patterns of time series have led\nresearchers to develop specialised deep learning models for detecting anomalous\npatterns. This survey focuses on providing structured and comprehensive\nstate-of-the-art time series anomaly detection models through the use of deep\nlearning. It providing a taxonomy based on the factors that divide anomaly\ndetection models into different categories. Aside from describing the basic\nanomaly detection technique for each category, the advantages and limitations\nare also discussed. Furthermore, this study includes examples of deep anomaly\ndetection in time series across various application domains in recent years. It\nfinally summarises open issues in research and challenges faced while adopting\ndeep anomaly detection models.",
    "descriptor": "",
    "authors": [
      "Zahra Zamanzadeh Darban",
      "Geoffrey I. Webb",
      "Shirui Pan",
      "Charu C. Aggarwal",
      "Mahsa Salehi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.05244"
  },
  {
    "id": "arXiv:2211.05249",
    "title": "QuerySnout: Automating the Discovery of Attribute Inference Attacks  against Query-Based Systems",
    "abstract": "Although query-based systems (QBS) have become one of the main solutions to\nshare data anonymously, building QBSes that robustly protect the privacy of\nindividuals contributing to the dataset is a hard problem. Theoretical\nsolutions relying on differential privacy guarantees are difficult to implement\ncorrectly with reasonable accuracy, while ad-hoc solutions might contain\nunknown vulnerabilities. Evaluating the privacy provided by QBSes must thus be\ndone by evaluating the accuracy of a wide range of privacy attacks. However,\nexisting attacks require time and expertise to develop, need to be manually\ntailored to the specific systems attacked, and are limited in scope. In this\npaper, we develop QuerySnout (QS), the first method to automatically discover\nvulnerabilities in QBSes. QS takes as input a target record and the QBS as a\nblack box, analyzes its behavior on one or more datasets, and outputs a\nmultiset of queries together with a rule to combine answers to them in order to\nreveal the sensitive attribute of the target record. QS uses evolutionary\nsearch techniques based on a novel mutation operator to find a multiset of\nqueries susceptible to lead to an attack, and a machine learning classifier to\ninfer the sensitive attribute from answers to the queries selected. We showcase\nthe versatility of QS by applying it to two attack scenarios, three real-world\ndatasets, and a variety of protection mechanisms. We show the attacks found by\nQS to consistently equate or outperform, sometimes by a large margin, the best\nattacks from the literature. We finally show how QS can be extended to QBSes\nthat require a budget, and apply QS to a simple QBS based on the Laplace\nmechanism. Taken together, our results show how powerful and accurate attacks\nagainst QBSes can already be found by an automated system, allowing for highly\ncomplex QBSes to be automatically tested \"at the pressing of a button\".",
    "descriptor": "\nComments: Published at the ACM CCS 2022 conference. This is an extended version that includes the Appendix\n",
    "authors": [
      "Ana-Maria Cretu",
      "Florimond Houssiau",
      "Antoine Cully",
      "Yves-Alexandre de Montjoye"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.05249"
  },
  {
    "id": "arXiv:2211.05251",
    "title": "A Graph-Based Approach to Generate Energy-Optimal Robot Trajectories in  Polynomial Environments",
    "abstract": "As robotic systems continue to address emerging issues in areas such as\nlogistics, mobility, manufacturing, and disaster response, it is increasingly\nimportant to rapidly generate safe and energy-efficient trajectories. In this\narticle, we present a new approach to plan energy-optimal trajectories through\ncluttered environments containing polygonal obstacles. In particular, we\ndevelop a method to quickly generate optimal trajectories for a\ndouble-integrator system, and we show that optimal path planning reduces to an\ninteger program. To find an efficient solution, we present a distance-informed\nprefix search to efficiently generate optimal trajectories for a large class of\nenvironments. We demonstrate that our approach, while matching the performance\nof RRT* and Probabilistic Road Maps in terms of path length, outperforms both\nin terms of energy cost and computational time by up to an order of magnitude.\nWe also demonstrate that our approach yields implementable trajectories in an\nexperiment with a Crazyflie quadrotor.",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Logan E. Beaver",
      "Roberto Tron",
      "Christos G. Cassandras"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.05251"
  },
  {
    "id": "arXiv:2211.05257",
    "title": "Single-Fingered Reconfigurable Robotic Gripper With a Folding Mechanism  for Narrow Working Spaces",
    "abstract": "This letter proposes a novel single-fingered reconfigurable robotic gripper\nfor grasping objects in narrow working spaces. The finger of the developed\ngripper realizes two configurations, namely, the insertion and grasping modes,\nusing only a single motor. In the insertion mode, the finger assumes a thin\nshape such that it can insert its tip into a narrow space. The grasping mode of\nthe finger is activated through a folding mechanism. Mode switching can be\nachieved in two ways: switching the mode actively by a motor, or combining\npassive rotation of the fingertip through contact with the support surface and\nactive motorized construction of the claw. The latter approach is effective\nwhen it is unclear how much finger insertion is required for a specific task.\nThe structure provides a simple control scheme. The performance of the proposed\nrobotic gripper design and control methodology was experimentally evaluated.\nThe minimum width of the insertion space required to grasp an object is 4 mm (1\nmm, when using a strategy).",
    "descriptor": "\nComments: This study was presented at IROS 2022\n",
    "authors": [
      "Toshihiro Nishimura",
      "Yosuke Suzuki",
      "Tokuo Tsuji",
      "Tetsuyou Watanabe"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.05257"
  },
  {
    "id": "arXiv:2211.05259",
    "title": "Complexity of solving a system of difference constraints with variables  restricted to a finite set",
    "abstract": "Fishburn developed an algorithm to solve a system of $m$ difference\nconstraints whose $n$ unknowns must take values from a set with $k$ real\nnumbers [Solving a system of difference constraints with variables restricted\nto a finite set, Inform Process Lett 82 (3) (2002) 143--144]. We provide an\nimplementation of Fishburn's algorithm that runs in $O(n+km)$ time.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Santiago Cifuentes",
      "Francisco J. Soulignac",
      "Pablo Terlisky"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.05259"
  },
  {
    "id": "arXiv:2211.05262",
    "title": "Stabilizing Machine Learning Prediction of Dynamics: Noise and  Noise-inspired Regularization",
    "abstract": "Recent work has shown that machine learning (ML) models can be trained to\naccurately forecast the dynamics of unknown chaotic dynamical systems. Such ML\nmodels can be used to produce both short-term predictions of the state\nevolution and long-term predictions of the statistical patterns of the dynamics\n(``climate''). Both of these tasks can be accomplished by employing a feedback\nloop, whereby the model is trained to predict forward one time step, then the\ntrained model is iterated for multiple time steps with its output used as the\ninput. In the absence of mitigating techniques, however, this technique can\nresult in artificially rapid error growth, leading to inaccurate predictions\nand/or climate instability. In this article, we systematically examine the\ntechnique of adding noise to the ML model input during training as a means to\npromote stability and improve prediction accuracy. Furthermore, we introduce\nLinearized Multi-Noise Training (LMNT), a regularization technique that\ndeterministically approximates the effect of many small, independent noise\nrealizations added to the model input during training. Our case study uses\nreservoir computing, a machine-learning method using recurrent neural networks,\nto predict the spatiotemporal chaotic Kuramoto-Sivashinsky equation. We find\nthat reservoir computers trained with noise or with LMNT produce climate\npredictions that appear to be indefinitely stable and have a climate very\nsimilar to the true system, while reservoir computers trained without\nregularization are unstable. Compared with other types of regularization that\nyield stability in some cases, we find that both short-term and climate\npredictions from reservoir computers trained with noise or with LMNT are\nsubstantially more accurate. Finally, we show that the deterministic aspect of\nour LMNT regularization facilitates fast hyperparameter tuning when compared to\ntraining with noise.",
    "descriptor": "\nComments: 39 pages, 8 figures, 5 tables\n",
    "authors": [
      "Alexander Wikner",
      "Brian R. Hunt",
      "Joseph Harvey",
      "Michelle Girvan",
      "Edward Ott"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2211.05262"
  },
  {
    "id": "arXiv:2211.05263",
    "title": "Sensing and Control of Friction Mode for Contact Area Variable Surfaces  (Friction-variable Surface Structure)",
    "abstract": "Robotic hands with soft surfaces can perform stable grasping, but the high\nfriction of the soft surfaces makes it difficult to release objects, or to\nperform operations that require sliding. To solve this issue, we previously\ndeveloped a contact area variable surface (CAVS), whose friction changed\naccording to the load. However, only our fundamental results were previously\npresented, with detailed analyses not provided. In this study, we first\ninvestigated the CAVS friction anisotropy, and demonstrated that the\nlongitudinal direction exhibited a larger ratio of friction change. Next, we\nproposed a sensible CAVS, capable of providing a variable-friction mechanism,\nand tested its sensing and control systems in operations requiring switching\nbetween sliding and stable-grasping modes. Friction sensing was performed using\nan embedded camera, and we developed a gripper using the sensible CAVS,\nconsidering the CAVS friction anisotropy. In CAVS, the low-friction mode\ncorresponds to a small grasping force, while the high-friction mode corresponds\nto a greater grasping force. Therefore, by controlling only the friction mode,\nthe gripper mode can be set to either the sliding or stable-grasping mode.\nBased on this feature, a methodology for controlling the contact mode was\nconstructed. We demonstrated a manipulation involving sliding and stable\ngrasping, and thus verified the efficacy of the developed sensible CAVS.",
    "descriptor": "",
    "authors": [
      "Seita Nojiri",
      "Akihiko Yamaguchi",
      "Yosuke Suzuki",
      "Tokuo Tsuji",
      "Tetsuyou Watanabe"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.05263"
  },
  {
    "id": "arXiv:2211.05266",
    "title": "Certified Numerical Real Root Isolation of Zero-dimensional Multivariate  Real Nonlinear Systems",
    "abstract": "Using the local geometrical properties of a given zero-dimensional square\nmultivariate nonlinear system inside a box, we provide a simple but effective\nand new criterion for the uniqueness and the existence of a real simple zero of\nthe system inside the box. Based on the result, we design an algorithm based on\nsubdivision and interval arithmetics to isolate all the real zeros of a general\nreal nonlinear system inside a given box. Our method is complete for systems\nwith only finite isolated simple real zeros inside a box. A termination\nprecision is given for general zero-dimensional systems. Multiple zeros of the\nsystem are output in bounded boxes. A variety of benchmarks show the\neffectivity and efficiency of our implementation (in C++). It works for\npolynomial systems with Bezout bound more than 100 million. It also works for\nnon-polynomial nonlinear systems. We also discuss the limitations of our\nmethod.",
    "descriptor": "",
    "authors": [
      "Jin-San Cheng",
      "Junyi Wen"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2211.05266"
  },
  {
    "id": "arXiv:2211.05267",
    "title": "Detecting Elevated Air Pollution Levels by Monitoring Web Search  Queries: Deep Learning-Based Time Series Forecasting",
    "abstract": "Real-time air pollution monitoring is a valuable tool for public health and\nenvironmental surveillance. In recent years, there has been a dramatic increase\nin air pollution forecasting and monitoring research using artificial neural\nnetworks (ANNs). Most of the prior work relied on modeling pollutant\nconcentrations collected from ground-based monitors and meteorological data for\nlong-term forecasting of outdoor ozone, oxides of nitrogen, and PM2.5. Given\nthat traditional, highly sophisticated air quality monitors are expensive and\nare not universally available, these models cannot adequately serve those not\nliving near pollutant monitoring sites. Furthermore, because prior models were\nbuilt on physical measurement data collected from sensors, they may not be\nsuitable for predicting public health effects experienced from pollution\nexposure. This study aims to develop and validate models to nowcast the\nobserved pollution levels using Web search data, which is publicly available in\nnear real-time from major search engines. We developed novel machine\nlearning-based models using both traditional supervised classification methods\nand state-of-the-art deep learning methods to detect elevated air pollution\nlevels at the US city level, by using generally available meteorological data\nand aggregate Web-based search volume data derived from Google Trends. We\nvalidated the performance of these methods by predicting three critical air\npollutants (ozone (O3), nitrogen dioxide (NO2), and fine particulate matter\n(PM2.5)), across ten major U.S. metropolitan statistical areas (MSAs) in 2017\nand 2018.",
    "descriptor": "",
    "authors": [
      "Chen Lin",
      "Safoora Yousefi",
      "Elvis Kahoro",
      "Payam Karisani",
      "Donghai Liang",
      "Jeremy Sarnat",
      "Eugene Agichtein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.05267"
  },
  {
    "id": "arXiv:2211.05272",
    "title": "GAPartNet: Cross-Category Domain-Generalizable Object Perception and  Manipulation via Generalizable and Actionable Parts",
    "abstract": "Perceiving and manipulating objects in a generalizable way has been actively\nstudied by the computer vision and robotics communities, where cross-category\ngeneralizable manipulation skills are highly desired yet underexplored. In this\nwork, we propose to learn such generalizable perception and manipulation via\nGeneralizable and Actionable Parts (GAParts). By identifying and defining 9\nGAPart classes (e.g. buttons, handles, etc), we show that our part-centric\napproach allows our method to learn object perception and manipulation skills\nfrom seen object categories and directly generalize to unseen categories.\nFollowing the GAPart definition, we construct a large-scale part-centric\ninteractive dataset, GAPartNet, where rich, part-level annotations (semantics,\nposes) are provided for 1166 objects and 8489 part instances. Based on\nGAPartNet, we investigate three cross-category tasks: part segmentation, part\npose estimation, and part-based object manipulation. Given the large domain\ngaps between seen and unseen object categories, we propose a strong 3D\nsegmentation method from the perspective of domain generalization by\nintegrating adversarial learning techniques. Our method outperforms all\nexisting methods by a large margin, no matter on seen or unseen categories.\nFurthermore, with part segmentation and pose estimation results, we leverage\nthe GAPart pose definition to design part-based manipulation heuristics that\ncan generalize well to unseen object categories in both simulation and real\nworld. The dataset and code will be released.",
    "descriptor": "",
    "authors": [
      "Haoran Geng",
      "Helin Xu",
      "Chengyang Zhao",
      "Chao Xu",
      "Li Yi",
      "Siyuan Huang",
      "He Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05272"
  },
  {
    "id": "arXiv:2211.05273",
    "title": "BERT-Based Combination of Convolutional and Recurrent Neural Network for  Indonesian Sentiment Analysis",
    "abstract": "Sentiment analysis is the computational study of opinions and emotions\nex-pressed in text. Deep learning is a model that is currently producing\nstate-of-the-art in various application domains, including sentiment analysis.\nMany researchers are using a hybrid approach that combines different deep\nlearning models and has been shown to improve model performance. In sentiment\nanalysis, input in text data is first converted into a numerical\nrepresentation. The standard method used to obtain a text representation is the\nfine-tuned embedding method. However, this method does not pay attention to\neach word's context in the sentence. Therefore, the Bidirectional Encoder\nRepresentation from Transformer (BERT) model is used to obtain text\nrepresentations based on the context and position of words in sentences. This\nresearch extends the previous hybrid deep learning using BERT representation\nfor Indonesian sentiment analysis. Our simulation shows that the BERT\nrepresentation improves the accuracies of all hybrid architectures. The\nBERT-based LSTM-CNN also reaches slightly better accuracies than other\nBERT-based hybrid architectures.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Hendri Murfi",
      "Syamsyuriani",
      "Theresia Gowandi",
      "Gianinna Ardaneswari",
      "Siti Nurrohmah"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05273"
  },
  {
    "id": "arXiv:2211.05274",
    "title": "Average-Case Complexity of Tensor Decomposition for Low-Degree  Polynomials",
    "abstract": "Suppose we are given an $n$-dimensional order-3 symmetric tensor $T \\in\n(\\mathbb{R}^n)^{\\otimes 3}$ that is the sum of $r$ random rank-1 terms. The\nproblem of recovering the rank-1 components is possible in principle when $r\n\\lesssim n^2$ but polynomial-time algorithms are only known in the regime $r\n\\ll n^{3/2}$. Similar \"statistical-computational gaps\" occur in many\nhigh-dimensional inference tasks, and in recent years there has been a flurry\nof work on explaining the apparent computational hardness in these problems by\nproving lower bounds against restricted (yet powerful) models of computation\nsuch as statistical queries (SQ), sum-of-squares (SoS), and low-degree\npolynomials (LDP). However, no such prior work exists for tensor decomposition,\nlargely because its hardness does not appear to be explained by a \"planted\nversus null\" testing problem.\nWe consider a model for random order-3 tensor decomposition where one\ncomponent is slightly larger in norm than the rest (to break symmetry), and the\ncomponents are drawn uniformly from the hypercube. We resolve the computational\ncomplexity in the LDP model: $O(\\log n)$-degree polynomial functions of the\ntensor entries can accurately estimate the largest component when $r \\ll\nn^{3/2}$ but fail to do so when $r \\gg n^{3/2}$. This provides rigorous\nevidence suggesting that the best known algorithms for tensor decomposition\ncannot be improved, at least by known approaches. A natural extension of the\nresult holds for tensors of any fixed order $k \\ge 3$, in which case the LDP\nthreshold is $r \\sim n^{k/2}$.",
    "descriptor": "\nComments: 42 pages\n",
    "authors": [
      "Alexander S. Wein"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.05274"
  },
  {
    "id": "arXiv:2211.05276",
    "title": "PhotoFourier: A Photonic Joint Transform Correlator-Based Neural Network  Accelerator",
    "abstract": "The last few years have seen a lot of work to address the challenge of\nlow-latency and high-throughput convolutional neural network inference.\nIntegrated photonics has the potential to dramatically accelerate neural\nnetworks because of its low-latency nature. Combined with the concept of Joint\nTransform Correlator (JTC), the computationally expensive convolution functions\ncan be computed instantaneously (time of flight of light) with almost no cost.\nThis 'free' convolution computation provides the theoretical basis of the\nproposed PhotoFourier JTC-based CNN accelerator. PhotoFourier addresses a\nmyriad of challenges posed by on-chip photonic computing in the Fourier domain\nincluding 1D lenses and high-cost optoelectronic conversions. The proposed\nPhotoFourier accelerator achieves more than 28X better energy-delay product\ncompared to state-of-art photonic neural network accelerators.",
    "descriptor": "\nComments: 12 pages, 13 figures, accepted in HPCA 2023\n",
    "authors": [
      "Shurui Li",
      "Hangbo Yang",
      "Chee Wei Wong",
      "Volker J. Sorger",
      "Puneet Gupta"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05276"
  },
  {
    "id": "arXiv:2211.05278",
    "title": "Network Security Roadmap",
    "abstract": "Users may already have some perception of provided security based on\nexperience with earlier generations. To maintain the stability and coherent\nintegration of 5G services, it is imperative that security and privacy features\nprevalent in earlier generations are also present in 5G. However, it is not\nsufficient just to provide the same security features as in the legacy systems\ndue to the new threat model introduced by the integration of new technologies\nlike SDN, virtualization and SBA. 5G systems are expected to be more\nservice-oriented. This suggests there will be an additional emphasis on\nsecurity and privacy requirements that spawn from the new dimension of\nservice-oriented security architecture.",
    "descriptor": "",
    "authors": [
      "Praveen Kumar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.05278"
  },
  {
    "id": "arXiv:2211.05281",
    "title": "Directed Isoperimetric Theorems for Boolean Functions on the Hypergrid  and an $\\widetilde{O}(n\\sqrt{d})$ Monotonicity Tester",
    "abstract": "The problem of testing monotonicity for Boolean functions on the hypergrid,\n$f:[n]^d \\to \\{0,1\\}$ is a classic topic in property testing. When $n=2$, the\ndomain is the hypercube. For the hypercube case, a breakthrough result of\nKhot-Minzer-Safra (FOCS 2015) gave a non-adaptive, one-sided tester making\n$\\widetilde{O}(\\varepsilon^{-2}\\sqrt{d})$ queries. Up to polylog $d$ and\n$\\varepsilon$ factors, this bound matches the\n$\\widetilde{\\Omega}(\\sqrt{d})$-query non-adaptive lower bound\n(Chen-De-Servedio-Tan (STOC 2015), Chen-Waingarten-Xie (STOC 2017)). For any $n\n> 2$, the optimal non-adaptive complexity was unknown. A previous result of the\nauthors achieves a $\\widetilde{O}(d^{5/6})$-query upper bound (SODA 2020),\nquite far from the $\\sqrt{d}$ bound for the hypercube.\nIn this paper, we resolve the non-adaptive complexity of monotonicity testing\nfor all constant $n$, up to $\\text{poly}(\\varepsilon^{-1}\\log d)$ factors.\nSpecifically, we give a non-adaptive, one-sided monotonicity tester making\n$\\widetilde{O}(\\varepsilon^{-2}n\\sqrt{d})$ queries. From a technical\nstandpoint, we prove new directed isoperimetric theorems over the hypergrid\n$[n]^d$. These results generalize the celebrated directed Talagrand\ninequalities that were only known for the hypercube.",
    "descriptor": "",
    "authors": [
      "Hadley Black",
      "Deeparnab Chakrabarty",
      "C. Seshadhri"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.05281"
  },
  {
    "id": "arXiv:2211.05284",
    "title": "FormLM: Recommending Creation Ideas for Online Forms by Modelling  Semantic and Structural Information",
    "abstract": "Online forms are widely used to collect data from human and have a\nmulti-billion market. Many software products provide online services for\ncreating semi-structured forms where questions and descriptions are organized\nby pre-defined structures. However, the design and creation process of forms is\nstill tedious and requires expert knowledge. To assist form designers, in this\nwork we present FormLM to model online forms (by enhancing pre-trained language\nmodel with form structural information) and recommend form creation ideas\n(including question / options recommendations and block type suggestion). For\nmodel training and evaluation, we collect the first public online form dataset\nwith 62K online forms. Experiment results show that FormLM significantly\noutperforms general-purpose language models on all tasks, with an improvement\nby 4.71 on Question Recommendation and 10.6 on Block Type Suggestion in terms\nof ROUGE-1 and Macro-F1, respectively.",
    "descriptor": "\nComments: 17 pages, EMNLP 2022 Main Conference\n",
    "authors": [
      "Yijia Shao",
      "Mengyu Zhou",
      "Yifan Zhong",
      "Tao Wu",
      "Hongwei Han",
      "Shi Han",
      "Gideon Huang",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05284"
  },
  {
    "id": "arXiv:2211.05286",
    "title": "Deep Learning Methods for Software Requirement Classification: A  Performance Study on the PURE dataset",
    "abstract": "Requirement engineering (RE) is the first and the most important step in\nsoftware production and development. The RE is aimed to specify software\nrequirements. One of the tasks in RE is the categorization of software\nrequirements as functional and non-functional requirements. The functional\nrequirements (FR) show the responsibilities of the system while non-functional\nrequirements represent the quality factors of software. Discrimination between\nFR and NFR is a challenging task. Nowadays Deep Learning (DL) has entered all\nfields of engineering and has increased accuracy and reduced time in their\nimplementation process. In this paper, we use deep learning for the\nclassification of software requirements. Five prominent DL algorithms are\ntrained for classifying requirements. Also, two voting classification\nalgorithms are utilized for creating ensemble classifiers based on five DL\nmethods. The PURE, a repository of Software Requirement Specification (SRS)\ndocuments, is selected for our experiments. We created a dataset from PURE\nwhich contains 4661 requirements where 2617 requirements are functional and the\nremaining are non-functional. Our methods are applied to the dataset and their\nperformance analysis is reported. The results show that the performance of deep\nlearning models is satisfactory and the voting mechanisms provide better\nresults.",
    "descriptor": "",
    "authors": [
      "Fatemeh Khayashi",
      "Behnaz Jamasb",
      "Reza Akbari",
      "Pirooz Shamsinejadbabaki"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.05286"
  },
  {
    "id": "arXiv:2211.05288",
    "title": "The Friendship Paradox and Social Network Participation",
    "abstract": "The friendship paradox implies that a person will, on average, have fewer\nfriends than their friends do. Prior work has shown how the friendship paradox\ncan lead to perception biases regarding behaviors that correlate with the\nnumber of friends: for example, people tend to perceive their friends as being\nmore socially engaged than they are. Here, we investigate the consequences of\nthis type of social comparison in the conceptual setting of content creation\n(\"sharing\") in an online social network. Suppose people compare the amount of\nfeedback that their content receives to the amount of feedback that their\nfriends' content receives, and suppose they modify their sharing behavior as a\nresult of that comparison. How does that impact overall sharing on the social\nnetwork over time? We run simulations over model-generated synthetic networks,\nassuming initially uniform sharing and feedback rates. Thus, people's initial\nmodifications of their sharing behavior in response to social comparisons are\nentirely driven by the friendship paradox. These modifications induce\ninhomogeneities in sharing rates that can further alter perception biases. If\npeople's responses to social comparisons are monotonic (i.e., the larger the\ndisparity, the larger the modification in sharing behavior), our simulations\nsuggest that overall sharing in the network gradually declines. Meanwhile,\nconvex responses can sustain or grow overall sharing in the network. We focus\nentirely on synthetic graphs in the present work and have not yet extended our\nsimulations to real-world network topologies. Nevertheless, we do discuss\npractical implications, such as how interventions can be tailored to sustain\nlong-term sharing, even in the presence of adverse social-comparison effects.",
    "descriptor": "\nComments: 10 pages, 15 figures\n",
    "authors": [
      "Ahmed Medhat",
      "Shankar Iyer"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.05288"
  },
  {
    "id": "arXiv:2211.05289",
    "title": "Combating Health Misinformation in Social Media: Characterization,  Detection, Intervention, and Open Issues",
    "abstract": "Social media has been one of the main information consumption sources for the\npublic, allowing people to seek and spread information more quickly and easily.\nHowever, the rise of various social media platforms also enables the\nproliferation of online misinformation. In particular, misinformation in the\nhealth domain has significant impacts on our society such as the COVID-19\ninfodemic. Therefore, health misinformation in social media has become an\nemerging research direction that attracts increasing attention from researchers\nof different disciplines. Compared to misinformation in other domains, the key\ndifferences of health misinformation include the potential of causing actual\nharm to humans' bodies and even lives, the hardness to identify for normal\npeople, and the deep connection with medical science. In addition, health\nmisinformation on social media has distinct characteristics from conventional\nchannels such as television on multiple dimensions including the generation,\ndissemination, and consumption paradigms. Because of the uniqueness and\nimportance of combating health misinformation in social media, we conduct this\nsurvey to further facilitate interdisciplinary research on this problem. In\nthis survey, we present a comprehensive review of existing research about\nonline health misinformation in different disciplines. Furthermore, we also\nsystematically organize the related literature from three perspectives:\ncharacterization, detection, and intervention. Lastly, we conduct a deep\ndiscussion on the pressing open issues of combating health misinformation in\nsocial media and provide future directions for multidisciplinary researchers.",
    "descriptor": "\nComments: 31 pages, 241 references\n",
    "authors": [
      "Canyu Chen",
      "Haoran Wang",
      "Matthew Shapiro",
      "Yunyu Xiao",
      "Fei Wang",
      "Kai Shu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.05289"
  },
  {
    "id": "arXiv:2211.05290",
    "title": "Equivariant Contrastive Learning for Sequential Recommendation",
    "abstract": "Contrastive learning (CL) benefits the training of sequential recommendation\nmodels with informative self-supervision signals. Existing solutions apply\ngeneral sequential data augmentation strategies to generate positive pairs and\nencourage their representations to be invariant. However, due to the inherent\nproperties of user behavior sequences, some augmentation strategies, such as\nitem substitution, can lead to changes in user intent. Learning\nindiscriminately invariant representations for all augmentation strategies\nmight be sub-optimal. Therefore, we propose Equivariant Contrastive Learning\nfor Sequential Recommendation (ECL-SR), which endows SR models with great\ndiscriminative power, making the learned user behavior representations\nsensitive to invasive augmentations (e.g., item substitution) and insensitive\nto mild augmentations (e.g., feature-level dropout masking). In detail, we use\nthe conditional discriminator to capture differences in behavior due to item\nsubstitution, which encourages the user behavior encoder to be equivariant to\ninvasive augmentations. Comprehensive experiments on four benchmark datasets\nshow that the proposed ECL-SR framework achieves competitive performance\ncompared to state-of-the-art SR models. The source code will be released.",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Peilin Zhou",
      "Jingqi Gao",
      "Yueqi Xie",
      "Qichen Ye",
      "Yining Hua",
      "Sunghun Kim"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.05290"
  },
  {
    "id": "arXiv:2211.05293",
    "title": "Streaming Euclidean Max-Cut: Dimension vs Data Reduction",
    "abstract": "Max-Cut is a fundamental problem that has been studied extensively in various\nsettings. We study Euclidean Max-Cut, where the input is a set of points in\n$\\mathbb{R}^d$, in the model of dynamic geometric streams, that is, the input\nis $X\\subseteq [\\Delta]^d$ presented as a sequence of point insertions and\ndeletions. Previous results by Frahling and Sohler [STOC'05] only address the\nlow-dimensional regime, as their $(1+\\epsilon)$-approximation algorithm uses\nspace $\\exp(d)$. We design the first streaming algorithms that use space\n$\\mathrm{poly}(d)$, and are thus suitable for a high dimension $d$.\nWe tackle this challenge of high dimension using two well-known approaches.\nThe first one is via \\emph{dimension reduction}, where we show that target\ndimension $\\mathrm{poly}(\\epsilon^{-1})$ suffices for the Johnson-Lindenstrauss\ntransform to preserve Max-Cut within factor $(1 \\pm \\epsilon)$. This result\nextends the applicability of the prior work (algorithm with $\\exp(d)$-space)\nalso to high dimension. The second approach is \\emph{data reduction}, based on\nimportance sampling. We implement this scheme in streaming by employing a\nrandomly-shifted quadtree. While this is a well-known method to construct a\ntree embedding, a key feature of our algorithm is that the distortion\n$O(d\\log\\Delta)$ affects only the space requirement\n$\\mathrm{poly}(\\epsilon^{-1} d\\log\\Delta)$, and not the approximation ratio\n$1+\\epsilon$. These results are in line with the growing interest and recent\nresults on streaming (and other) algorithms for high dimension.",
    "descriptor": "",
    "authors": [
      "Yu Chen",
      "Shaofeng H.-C. Jiang",
      "Robert Krauthgamer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.05293"
  },
  {
    "id": "arXiv:2211.05294",
    "title": "Artificial Neural Network Solver for Time-Dependent Fokker-Planck  Equations",
    "abstract": "Stochastic differential equations play an important role in various\napplications when modeling systems that have either random perturbations or\nchaotic dynamics at faster time scales. The time evolution of the probability\ndistribution of a stochastic differential equation is described by the\nFokker-Planck equation, which is a second order parabolic partial differential\nequation. Previous work combined artificial neural network and Monte Carlo data\nto solve stationary Fokker-Planck equations. This paper extends this approach\nto time dependent Fokker-Planck equations. The focus is on the investigation of\nalgorithms for training a neural network that has multi-scale loss functions.\nAdditionally, a new approach for collocation point sampling is proposed. A few\n1D and 2D numerical examples are demonstrated.",
    "descriptor": "",
    "authors": [
      "Yao Li",
      "Caleb Meredith"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.05294"
  },
  {
    "id": "arXiv:2211.05295",
    "title": "Harmonizing Output Imbalance for semantic segmentation on  extremely-imbalanced input data",
    "abstract": "Semantic segmentation is a high level computer vision task that assigns a\nlabel for each pixel of an image. It is challengeful to deal with\nextremely-imbalanced data in which the ratio of target ixels to background\npixels is lower than 1:1000. Such severe input imbalance leads to output\nimbalance for poor model training. This paper considers three issues for\nextremely-imbalanced data: inspired by the region based loss, an implicit\nmeasure for the output imbalance is proposed, and an adaptive algorithm is\ndesigned for guiding the output imbalance hyperparameter selection; then it is\ngeneralized to distribution based loss for dealing with output imbalance; and\nfinally a compound loss with our adaptive hyperparameter selection alogorithm\ncan keep the consistency of training and inference for harmonizing the output\nimbalance. With four popular deep architectures on our private dataset with\nthree input imbalance scales and three public datasets, extensive experiments\ndemonstrate the ompetitive/promising performance of the proposed method.",
    "descriptor": "\nComments: 18 pages, 13 figures, 2 appendixes\n",
    "authors": [
      "Jianye Yi",
      "Xiaopin Zhong",
      "Weixiang Liu",
      "Zongze Wu",
      "Yuanlong Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.05295"
  },
  {
    "id": "arXiv:2211.05296",
    "title": "Learning Cross-view Geo-localization Embeddings via Dynamic Weighted  Decorrelation Regularization",
    "abstract": "Cross-view geo-localization aims to spot images of the same location shot\nfrom two platforms, e.g., the drone platform and the satellite platform.\nExisting methods usually focus on optimizing the distance between one embedding\nwith others in the feature space, while neglecting the redundancy of the\nembedding itself. In this paper, we argue that the low redundancy is also of\nimportance, which motivates the model to mine more diverse patterns. To verify\nthis point, we introduce a simple yet effective regularization, i.e., Dynamic\nWeighted Decorrelation Regularization (DWDR), to explicitly encourage networks\nto learn independent embedding channels. As the name implies, DWDR regresses\nthe embedding correlation coefficient matrix to a sparse matrix, i.e., the\nidentity matrix, with dynamic weights. The dynamic weights are applied to focus\non still correlated channels during training. Besides, we propose a cross-view\nsymmetric sampling strategy, which keeps the example balance between different\nplatforms. Albeit simple, the proposed method has achieved competitive results\non three large-scale benchmarks, i.e., University-1652, CVUSA and CVACT.\nMoreover, under the harsh circumstance, e.g., the extremely short feature of 64\ndimensions, the proposed method surpasses the baseline model by a clear margin.",
    "descriptor": "",
    "authors": [
      "Tingyu Wang",
      "Zhedong Zheng",
      "Zunjie Zhu",
      "Yuhan Gao",
      "Yi Yang",
      "Chenggang Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05296"
  },
  {
    "id": "arXiv:2211.05297",
    "title": "Coordinating CAV Swarms at Intersections with a Deep Learning Model",
    "abstract": "Connected and automated vehicles (CAVs) are viewed as a special kind of\nrobots that have the potential to significantly improve the safety and\nefficiency of traffic. In contrast to many swarm robotics studies that are\ndemonstrated in labs by employing a small number of robots, CAV studies aims to\nachieve cooperative driving of unceasing robot swarm flows. However, how to get\nthe optimal passing order of such robot swarm flows even for a signal-free\nintersection is an NP-hard problem (specifically, enumerating based algorithm\ntakes days to find the optimal solution to a 20-CAV scenario). Here, we\nintroduce a novel cooperative driving algorithm (AlphaOrder) that combines\noffline deep learning and online tree searching to find a near-optimal passing\norder in real-time. AlphaOrder builds a pointer network model from solved\nscenarios and generates near-optimal passing orders instantaneously for new\nscenarios. Furthermore, our approach provides a general approach to managing\npreemptive resource sharing between swarm robotics (e.g., scheduling multiple\nautomated guided vehicles (AGVs) and unmanned aerial vehicles (UAVs) at\nconflicting areas",
    "descriptor": "",
    "authors": [
      "Jiawei Zhang",
      "Shen Li",
      "Li Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.05297"
  },
  {
    "id": "arXiv:2211.05299",
    "title": "Prior-enhanced Temporal Action Localization using Subject-aware Spatial  Attention",
    "abstract": "Temporal action localization (TAL) aims to detect the boundary and identify\nthe class of each action instance in a long untrimmed video. Current approaches\ntreat video frames homogeneously, and tend to give background and key objects\nexcessive attention. This limits their sensitivity to localize action\nboundaries. To this end, we propose a prior-enhanced temporal action\nlocalization method (PETAL), which only takes in RGB input and incorporates\naction subjects as priors. This proposal leverages action subjects' information\nwith a plug-and-play subject-aware spatial attention module (SA-SAM) to\ngenerate an aggregated and subject-prioritized representation. Experimental\nresults on THUMOS-14 and ActivityNet-1.3 datasets demonstrate that the proposed\nPETAL achieves competitive performance using only RGB features, e.g., boosting\nmAP by 2.41% or 0.25% over the state-of-the-art approach that uses RGB features\nor with additional optical flow features on the THUMOS-14 dataset.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Yifan Liu",
      "Youbao Tang",
      "Ning Zhang",
      "Ruei-Sung Lin",
      "Haoqian Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05299"
  },
  {
    "id": "arXiv:2211.05303",
    "title": "1-degree-of-freedom Robotic Gripper With Infinite Self-Twist Function",
    "abstract": "This study proposed a novel robotic gripper that can achieve grasping and\ninfinite wrist twisting motions using a single actuator. The gripper is\nequipped with a differential gear mechanism that allows switching between the\ngrasping and twisting motions according to the magnitude of the tip force\napplied to the finger. The grasping motion is activated when the tip force is\nbelow a set value, and the wrist twisting motion is activated when the tip\nforce exceeds this value. \"Twist grasping,\" a special grasping mode that allows\nthe wrapping of a flexible thin object around the fingers of the gripper, can\nbe achieved by the twisting motion. Twist grasping is effective for handling\nobjects with flexible thin parts, such as laminated packaging pouches, that are\ndifficult to grasp using conventional antipodal grasping. In this study, the\ngripper design is presented, and twist grasping is analyzed. The gripper\nperformance is experimentally validated.",
    "descriptor": "",
    "authors": [
      "Toshihiro Nishimura",
      "Yosuke Suzuki",
      "Tokuo Tsuji",
      "Tetsuyou Watanabe"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.05303"
  },
  {
    "id": "arXiv:2211.05304",
    "title": "Contrastive Self-Supervised Learning for Skeleton Representations",
    "abstract": "Human skeleton point clouds are commonly used to automatically classify and\npredict the behaviour of others. In this paper, we use a contrastive\nself-supervised learning method, SimCLR, to learn representations that capture\nthe semantics of skeleton point clouds. This work focuses on systematically\nevaluating the effects that different algorithmic decisions (including\naugmentations, dataset partitioning and backbone architecture) have on the\nlearned skeleton representations. To pre-train the representations, we\nnormalise six existing datasets to obtain more than 40 million skeleton frames.\nWe evaluate the quality of the learned representations with three downstream\ntasks: skeleton reconstruction, motion prediction, and activity classification.\nOur results demonstrate the importance of 1) combining spatial and temporal\naugmentations, 2) including additional datasets for encoder training, and 3)\nand using a graph neural network as an encoder.",
    "descriptor": "\nComments: 8 pages, 2 figures, 4 tables. Accepted at the NeurIPS 2022 Workshop: Self-Supervised Learning - Theory and Practice\n",
    "authors": [
      "Nico Lingg",
      "Miguel Sarabia",
      "Luca Zappella",
      "Barry-John Theobald"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05304"
  },
  {
    "id": "arXiv:2211.05307",
    "title": "Winner Determination Algorithms for Graph Games with Matching Structures",
    "abstract": "Cram, Domineering, and Arc Kayles are well-studied combinatorial games. They\nare interpreted as edge-selecting-type games on graphs, and the selected edges\nduring a game form a matching. In this paper, we define a generalized game\ncalled Colored Arc Kayles, which includes these games. Colored Arc Kayles is\nplayed on a graph whose edges are colored in black, white, or gray, and black\n(resp., white) edges can be selected only by the black (resp., white) player,\nalthough gray edges can be selected by both black and white players. We first\nobserve that the winner determination for Colored Arc Kayles can be done in\n$O^*(2^n)$ time by a simple algorithm, where $n$ is the order of a graph. We\nthen focus on the vertex cover number, which is linearly related to the number\nof turns, and show that Colored Arc Kayles, BW-Arc Kayles, and Arc Kayles are\nsolved in time $O^*(1.4143^{\\tau^2+3.17\\tau})$, $O^*(1.3161^{\\tau^2+4{\\tau}})$,\nand $O^*(1.1893^{\\tau^2+6.34{\\tau}})$, respectively, where $\\tau$ is the vertex\ncover number. Furthermore, we present an $O^*((n/\\nu+1)^{\\nu})$-time algorithm\nfor Arc Kayles, where $\\nu$ is neighborhood diversity. We finally show that Arc\nKayles on trees can be solved in $O^* (2^{n/2})(=O(1.4143^n))$ time, which\nimproves $O^*(3^{n/3})(=O(1.4423^n))$ by a direct adjustment of the analysis of\nBodlaender et al.'s $O^*(3^{n/3})$-time algorithm for Node Kayles.",
    "descriptor": "\nComments: 13 pages, 5 figures\n",
    "authors": [
      "Tesshu Hanaka",
      "Hironori Kiya",
      "Hirotaka Ono",
      "Kanae Yoshiwatari"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.05307"
  },
  {
    "id": "arXiv:2211.05308",
    "title": "Cancer-Net BCa: Breast Cancer Pathologic Complete Response Prediction  using Volumetric Deep Radiomic Features from Synthetic Correlated Diffusion  Imaging",
    "abstract": "Breast cancer is the second most common type of cancer in women in Canada and\nthe United States, representing over 25% of all new female cancer cases.\nNeoadjuvant chemotherapy treatment has recently risen in usage as it may result\nin a patient having a pathologic complete response (pCR), and it can shrink\ninoperable breast cancer tumors prior to surgery so that the tumor becomes\noperable, but it is difficult to predict a patient's pathologic response to\nneoadjuvant chemotherapy. In this paper, we investigate the efficacy of\nleveraging learnt volumetric deep features from a newly introduced magnetic\nresonance imaging (MRI) modality called synthetic correlated diffusion imaging\n(CDI$^s$) for the purpose of pCR prediction. More specifically, we leverage a\nvolumetric convolutional neural network to learn volumetric deep radiomic\nfeatures from a pre-treatment cohort and construct a predictor based on the\nlearnt features using the post-treatment response. As the first study to\nexplore the utility of CDI$^s$ within a deep learning perspective for clinical\ndecision support, we evaluated the proposed approach using the ACRIN-6698 study\nagainst those learnt using gold-standard imaging modalities, and found that the\nproposed approach can provide enhanced pCR prediction performance and thus may\nbe a useful tool to aid oncologists in improving recommendation of treatment of\npatients. Subsequently, this approach to leverage volumetric deep radiomic\nfeatures (which we name Cancer-Net BCa) can be further extended to other\napplications of CDI$^s$ in the cancer domain to further improve prediction\nperformance.",
    "descriptor": "",
    "authors": [
      "Chi-en Amy Tai",
      "Nedim Hodzic",
      "Nic Flanagan",
      "Hayden Gunraj",
      "Alexander Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05308"
  },
  {
    "id": "arXiv:2211.05309",
    "title": "Generic Cryo-CMOS Device Modeling and EDACompatible Platform for  Reliable Cryogenic IC Design",
    "abstract": "The capability of data processing in quantum computers relies on the\nCMOS-based cryogenic control and storage systems. This paper outlines the\nestablishment of the generic cryogenic CMOS database in which key electrical\nparameters and the transfer characteristics of MOSFETs are characterized as\nfunctions of device size, temperature /frequency responses, and\nvariation/mismatch statistics. Thanks to the process design kit generated from\nthe cryoCMOS compact model, the cryogenic 4 kb SRAM and 5-bit flash ADC are\ndesigned, and their performance at low temperatures are readily evaluated and\noptimized on the EDAcompatible platform, hence laying a solid foundation for\npractical large-scale quantum computer design.",
    "descriptor": "",
    "authors": [
      "Zewei Wang",
      "Zhidong Tang",
      "Yumeng Yuan",
      "Ao Guo",
      "Xin Luo",
      "Renhe Chen",
      "Chengwei Cao",
      "Linlin Liu",
      "Zhenghang Zhi",
      "Weican Wu",
      "Yingjia Guo",
      "Yongqi Hu",
      "Liujiang Yu",
      "Ganbing Shang",
      "Jing Chen",
      "Jianshi Tang",
      "Shaojian Hu",
      "Shoumian Chen",
      "Yuhang Zhao",
      "Xufeng Kou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.05309"
  },
  {
    "id": "arXiv:2211.05311",
    "title": "When is Realizability Sufficient for Off-Policy Reinforcement Learning?",
    "abstract": "Model-free algorithms for reinforcement learning typically require a\ncondition called Bellman completeness in order to successfully operate\noff-policy with function approximation, unless additional conditions are met.\nHowever, Bellman completeness is a requirement that is much stronger than\nrealizability and that is deemed to be too strong to hold in practice. In this\nwork, we relax this structural assumption and analyze the statistical\ncomplexity of off-policy reinforcement learning when only realizability holds\nfor the prescribed function class.\nWe establish finite-sample guarantees for off-policy reinforcement learning\nthat are free of the approximation error term known as inherent Bellman error,\nand that depend on the interplay of three factors. The first two are well-know:\nthey are the metric entropy of the function class and the concentrability\ncoefficient that represents the cost of learning off-policy. The third factor\nis new, and it measures the violation of Bellman completeness, namely the\nmis-alignment between the chosen function class and its image through the\nBellman operator.\nIn essence, these error bounds establish that off-policy reinforcement\nlearning remains statistically viable even in absence of Bellman completeness,\nand characterize the intermediate situation between the favorable Bellman\ncomplete setting and the worst-case scenario where exponential lower bounds are\nin force. Our analysis directly applies to the solution found by temporal\ndifference algorithms when they converge.",
    "descriptor": "\nComments: Initial submission - feedback highly welcome\n",
    "authors": [
      "Andrea Zanette"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05311"
  },
  {
    "id": "arXiv:2211.05314",
    "title": "DiSC: Differential Spectral Clustering of Features",
    "abstract": "Selecting subsets of features that differentiate between two conditions is a\nkey task in a broad range of scientific domains. In many applications, the\nfeatures of interest form clusters with similar effects on the data at hand. To\nrecover such clusters we develop DiSC, a data-driven approach for detecting\ngroups of features that differentiate between conditions. For each condition,\nwe construct a graph whose nodes correspond to the features and whose weights\nare functions of the similarity between them for that condition. We then apply\na spectral approach to compute subsets of nodes whose connectivity differs\nsignificantly between the condition-specific feature graphs. On the theoretical\nfront, we analyze our approach with a toy example based on the stochastic block\nmodel. We evaluate DiSC on a variety of datasets, including MNIST,\nhyperspectral imaging, simulated scRNA-seq and task fMRI, and demonstrate that\nDiSC uncovers features that better differentiate between conditions compared to\ncompeting methods.",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Ram Dyuthi Sristi",
      "Gal Mishne",
      "Ariel Jaffe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.05314"
  },
  {
    "id": "arXiv:2211.05319",
    "title": "Few-shot Classification with Hypersphere Modeling of Prototypes",
    "abstract": "Metric-based meta-learning is one of the de facto standards in few-shot\nlearning. It composes of representation learning and metrics calculation\ndesigns. Previous works construct class representations in different ways,\nvarying from mean output embedding to covariance and distributions. However,\nusing embeddings in space lacks expressivity and cannot capture class\ninformation robustly, while statistical complex modeling poses difficulty to\nmetric designs. In this work, we use tensor fields (``areas'') to model classes\nfrom the geometrical perspective for few-shot learning. We present a simple and\neffective method, dubbed hypersphere prototypes (HyperProto), where class\ninformation is represented by hyperspheres with dynamic sizes with two sets of\nlearnable parameters: the hypersphere's center and the radius. Extending from\npoints to areas, hyperspheres are much more expressive than embeddings.\nMoreover, it is more convenient to perform metric-based classification with\nhypersphere prototypes than statistical modeling, as we only need to calculate\nthe distance from a data point to the surface of the hypersphere. Following\nthis idea, we also develop two variants of prototypes under other measurements.\nExtensive experiments and analysis on few-shot learning tasks across NLP and CV\nand comparison with 20+ competitive baselines demonstrate the effectiveness of\nour approach.",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Ning Ding",
      "Yulin Chen",
      "Ganqu Cui",
      "Xiaobin Wang",
      "Hai-Tao Zheng",
      "Zhiyuan Liu",
      "Pengjun Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05319"
  },
  {
    "id": "arXiv:2211.05321",
    "title": "Fairness and bias correction in machine learning for depression  prediction: results from four different study populations",
    "abstract": "A significant level of stigma and inequality exists in mental healthcare,\nespecially in under-served populations, which spreads through collected data.\nWhen not properly accounted for, machine learning (ML) models learned from data\ncan reinforce the structural biases already present in society. Here, we\npresent a systematic study of bias in ML models designed to predict depression\nin four different case studies covering different countries and populations. We\nfind that standard ML approaches show regularly biased behaviors. However, we\nshow that standard mitigation techniques, and our own post-hoc method, can be\neffective in reducing the level of unfair bias. We provide practical\nrecommendations to develop ML models for depression risk prediction with\nincreased fairness and trust in the real world. No single best ML model for\ndepression prediction provides equality of outcomes. This emphasizes the\nimportance of analyzing fairness during model selection and transparent\nreporting about the impact of debiasing interventions.",
    "descriptor": "\nComments: 21 pages, 4 figures\n",
    "authors": [
      "Vien Ngoc Dang",
      "Anna Cascarano",
      "Rosa H. Mulder",
      "Charlotte Cecil",
      "Maria A. Zuluaga",
      "Jer\u00f3nimo Hern\u00e1ndez-Gonz\u00e1lez",
      "Karim Lekadir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.05321"
  },
  {
    "id": "arXiv:2211.05322",
    "title": "On Optimizing the Communication of Model Parallelism",
    "abstract": "We study a novel and important communication pattern in large-scale\nmodel-parallel deep learning (DL), which we call cross-mesh resharding. This\npattern emerges when the two paradigms of model parallelism - intra-operator\nand inter-operator parallelism - are combined to support large models on large\nclusters. In cross-mesh resharding, a sharded tensor needs to be sent from a\nsource device mesh to a destination device mesh, on which the tensor may be\ndistributed with the same or different layouts. We formalize this as a\nmany-to-many multicast communication problem, and show that existing approaches\neither are sub-optimal or do not generalize to different network topologies or\ntensor layouts, which result from different model architectures and parallelism\nstrategies. We then propose two contributions to address cross-mesh resharding:\nan efficient broadcast-based communication system, and an\n\"overlapping-friendly\" pipeline schedule. On microbenchmarks, our overall\nsystem outperforms existing ones by up to 10x across various tensor and mesh\nlayouts. On end-to-end training of two large models, GPT-3 and U-Transformer,\nwe improve throughput by 10% and 50%, respectively.",
    "descriptor": "",
    "authors": [
      "Yonghao Zhuang",
      "Hexu Zhao",
      "Lianmin Zheng",
      "Zhuohan Li",
      "Eric P. Xing",
      "Qirong Ho",
      "Joseph E. Gonzalez",
      "Ion Stoica",
      "Hao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.05322"
  },
  {
    "id": "arXiv:2211.05325",
    "title": "Parameterized Complexity of Weighted Local Hamiltonian Problems and the  Quantum Exponential Time Hypothesis",
    "abstract": "We study a parameterized version of the local Hamiltonian problem, called the\nweighted local Hamiltonian problem, where the relevant quantum states are\nsuperpositions of computational basis states of Hamming weight $k$. The Hamming\nweight constraint can have a physical interpretation as a constraint on the\nnumber of excitations allowed or particle number in a system. We prove that\nthis problem is in QW[1], the first level of the quantum weft hierarchy and\nthat it is hard for QM[1], the quantum analogue of M[1]. Our results show that\nthis problem cannot be fixed-parameter quantum tractable (FPQT) unless certain\nnatural quantum analogue of the exponential time hypothesis (ETH) is false.",
    "descriptor": "\nComments: 37 pages, 10 figures\n",
    "authors": [
      "Michael J. Bremner",
      "Zhengfeng Ji",
      "Xingjian Li",
      "Luke Mathieson",
      "Mauro E.S. Morales"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.05325"
  },
  {
    "id": "arXiv:2211.05327",
    "title": "Ultraverse: Efficient Retroactive Operation for Attack Recovery in  Database Systems and Web Frameworks",
    "abstract": "Retroactive operation is an operation that changes a past operation in a\nseries of committed ones (e.g., cancelling the past insertion of '5' into a\nqueue committed at t=3). Retroactive operation has many important security\napplications such as attack recovery or private data removal (e.g., for GDPR\ncompliance). While prior efforts designed retroactive algorithms for low-level\ndata structures (e.g., queue, set), none explored retroactive operation for\nhigher levels, such as database systems or web applications. This is\nchallenging, because: (i) SQL semantics of database systems is complex; (ii)\ndata records can flow through various web application components, such as\nHTML's DOM trees, server-side user request handlers, and client-side JavaScript\ncode. We propose Ultraverse, the first retroactive operation framework\ncomprised of two components: a database system and a web application framework.\nThe former enables users to retroactively change committed SQL queries; the\nlatter does the same for web applications with preserving correctness of\napplication semantics. Our experimental results show that Ultraverse achieves\n10.5x~693.3x speedup on retroactive database update compared to a regular\nDBMS's flashback and redo.",
    "descriptor": "",
    "authors": [
      "Ronny Ko",
      "Chuan Xiao",
      "Makoto Onizuka",
      "Yihe Huang",
      "Zhiqiang Lin"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.05327"
  },
  {
    "id": "arXiv:2211.05335",
    "title": "Scalable Modular Synthetic Data Generation for Advancing Aerial Autonomy",
    "abstract": "Harnessing the benefits of drones for urban innovation at scale requires\nreliable aerial autonomy. One major barrier to advancing aerial autonomy has\nbeen collecting large-scale aerial datasets for training machine learning\nmodels. Due to costly and time-consuming real-world data collection through\ndeploying drones, there has been an increasing shift towards using synthetic\ndata for training models in drone applications. However, to increase\ngeneralizability of trained policies on synthetic data, incorporating domain\nrandomization into the data generation workflow for addressing the sim-to-real\nproblem becomes crucial. Current synthetic data generation tools either lack\ndomain randomization or rely heavily on manual workload or real samples for\nconfiguring and generating diverse realistic simulation scenes. These\ndependencies limit scalability of the data generation workflow. Accordingly,\nthere is a major challenge in balancing generalizability and scalability in\nsynthetic data generation. To address these gaps, we introduce a modular\nscalable data generation workflow tailored to aerial autonomy applications. To\ngenerate realistic configurations of simulation scenes while increasing\ndiversity, we present an adaptive layered domain randomization approach that\ncreates a type-agnostic distribution space for assets over the base map of the\nenvironments before pose generation for drone trajectory. We leverage\nhigh-level scene structures to automatically place assets in valid\nconfigurations and then extend the diversity through obstacle generation and\nglobal parameter randomization. We demonstrate the effectiveness of our method\nin automatically generating diverse configurations and datasets and show its\npotential for downstream performance optimization. Our work contributes to\ngenerating enhanced benchmark datasets for training models that can generalize\nbetter to real-world situations.",
    "descriptor": "\nComments: 22 pages, 10 figures\n",
    "authors": [
      "Mehrnaz Sabet",
      "Praveen Palanisamy",
      "Sakshi Mishra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.05335"
  },
  {
    "id": "arXiv:2211.05337",
    "title": "Spatiotemporal k-means",
    "abstract": "Spatiotemporal data is readily available due to emerging sensor and data\nacquisition technologies that track the positions of moving objects of\ninterest. Spatiotemporal clustering addresses the need to efficiently discover\npatterns and trends in moving object behavior without human supervision. One\napplication of interest is the discovery of moving clusters, where clusters\nhave a static identity, but their location and content can change over time. We\npropose a two phase spatiotemporal clustering method called spatiotemporal\nk-means (STKM) that is able to analyze the multi-scale relationships within\nspatiotemporal data. Phase 1 of STKM frames the moving cluster problem as the\nminimization of an objective function unified over space and time. It outputs\nthe short-term associations between objects and is uniquely able to track\ndynamic cluster centers with minimal parameter tuning and without\npost-processing. Phase 2 outputs the long-term associations and can be applied\nto any method that provides a cluster label for each object at every point in\ntime. We evaluate STKM against baseline methods on a recently developed\nbenchmark dataset and show that STKM outperforms existing methods, particularly\nin the low-data domain, with significant performance improvements demonstrated\nfor common evaluation metrics on the moving cluster problem.",
    "descriptor": "\nComments: 14 pages, 7 figures\n",
    "authors": [
      "Olga Dorabiala",
      "Jennifer Webster",
      "Nathan Kutz",
      "Aleksandr Aravkin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05337"
  },
  {
    "id": "arXiv:2211.05338",
    "title": "Job Scheduling in Datacenters using Constraint Controlled RL",
    "abstract": "This paper studies a model for online job scheduling in green datacenters. In\ngreen datacenters, resource availability depends on the power supply from the\nrenewables. Intermittent power supply from renewables leads to intermittent\nresource availability, inducing job delays (and associated costs). Green\ndatacenter operators must intelligently manage their workloads and available\npower supply to extract maximum benefits. The scheduler's objective is to\nschedule jobs on a set of resources to maximize the total value (revenue) while\nminimizing the overall job delay. A trade-off exists between achieving high job\nvalue on the one hand and low expected delays on the other. Hence, the aims of\nachieving high rewards and low costs are in opposition. In addition, datacenter\noperators often prioritize multiple objectives, including high system\nutilization and job completion. To accomplish the opposing goals of maximizing\ntotal job value and minimizing job delays, we apply the\nProportional-Integral-Derivative (PID) Lagrangian methods in Deep Reinforcement\nLearning to job scheduling problem in the green datacenter environment.\nLagrangian methods are widely used algorithms for constrained optimization\nproblems. We adopt a controls perspective to learn the Lagrange multiplier with\nproportional, integral, and derivative control, achieving favorable learning\ndynamics. Feedback control defines cost terms for the learning agent, monitors\nthe cost limits during training, and continuously adjusts the learning\nparameters to achieve stable performance. Our experiments demonstrate improved\nperformance compared to scheduling policies without the PID Lagrangian methods.\nExperimental results illustrate the effectiveness of the Constraint Controlled\nReinforcement Learning (CoCoRL) scheduler that simultaneously satisfies\nmultiple objectives.",
    "descriptor": "\nComments: under submission\n",
    "authors": [
      "Vanamala Venkataswamy"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05338"
  },
  {
    "id": "arXiv:2211.05339",
    "title": "Writing summary for the state-of-the-art methods for big data clustering  in distributed environment",
    "abstract": "Big Data processing systems handle huge unstructured and structured data to\nstore, process, and analyze through cluster analysis which helps in identifying\nunseen patterns to find the relationships between them. Clustering analysis\nover the shared machines in big data technologies helps in deriving the\nrelations and making decisions using data in context. It can handle every form\nof raw, tabular data along with structured, semi-structured, and unstructured\ndata. The data doesn't have to possess linearity property. It can reflect\nassociative and correlative patterns and groupings. The main contribution and\nfindings of this paper are to gather and summarize the recent big data\nclustering techniques, and their strengths, and weaknesses in any distributed\nenvironment.",
    "descriptor": "\nComments: 4 Pages\n",
    "authors": [
      "Dipesh Gyawali"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.05339"
  },
  {
    "id": "arXiv:2211.05340",
    "title": "Multistatic Sensing of Passive Targets Using 6G Cellular Infrastructure",
    "abstract": "Sensing using cellular infrastructure may be one of the defining feature of\nsixth generation (6G) wireless systems. Wideband 6G communication channels\noperating at higher frequency bands (upper mmWave bands) are better modeled\nusing clustered geometric channel models. In this paper, we propose methods for\ndetection of passive targets and estimating their position using communication\ndeployment without any assistance from the target. A novel AI architecture\ncalled CsiSenseNet is developed for this purpose. We analyze the resolution,\ncoverage and position uncertainty for practical indoor deployments. Using the\nproposed method, we show that human sized target can be sensed with high\naccuracy and sub-meter positioning errors in a practical indoor deployment\nscenario.",
    "descriptor": "\nComments: Submitted to ICC2023\n",
    "authors": [
      "Vijaya Yajnanarayana",
      "Henk Wymeersch"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.05340"
  },
  {
    "id": "arXiv:2211.05342",
    "title": "Set based velocity shaping for robotic manipulators",
    "abstract": "We develop a new framework for trajectory planning on predefined paths, for\ngeneral N-link manipulators. Different from previous approaches generating\nopen-loop minimum time controllers or pre-tuned motion profiles by\ntime-scaling, we establish analytic algorithms that recover all initial\nconditions that can be driven to the desirable target set while adhering to\nenvironment constraints. More technologically relevant, we characterise\nfamilies of corresponding safe state-feedback controllers with several\ndesirable properties. A key enabler in our framework is the introduction of a\nstate feedback template, that induces ordering properties between trajectories\nof the resulting closed-loop system. The proposed structure allows working on\nthe nonlinear system directly in both the analysis and synthesis problems. Both\noffline computations and online implementation are scalable with respect to the\nnumber of links of the manipulator. The results can potentially be used in a\nseries of challenging problems: Numerical experiments on a commercial robotic\nmanipulator demonstrate that efficient online implementation is possible.",
    "descriptor": "\nComments: 13 pages 8 figures\n",
    "authors": [
      "Ryan McGovern",
      "Nikolaos Athanasopolous",
      "Se\u00e1n McLoone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.05342"
  },
  {
    "id": "arXiv:2211.05343",
    "title": "Not Just Plain Text! Fuel Document-Level Relation Extraction with  Explicit Syntax Refinement and Subsentence Modeling",
    "abstract": "Document-level relation extraction (DocRE) aims to identify semantic labels\namong entities within a single document. One major challenge of DocRE is to dig\ndecisive details regarding a specific entity pair from long text. However, in\nmany cases, only a fraction of text carries required information, even in the\nmanually labeled supporting evidence. To better capture and exploit instructive\ninformation, we propose a novel expLicit syntAx Refinement and Subsentence\nmOdeliNg based framework (LARSON). By introducing extra syntactic information,\nLARSON can model subsentences of arbitrary granularity and efficiently screen\ninstructive ones. Moreover, we incorporate refined syntax into text\nrepresentations which further improves the performance of LARSON. Experimental\nresults on three benchmark datasets (DocRED, CDR, and GDA) demonstrate that\nLARSON significantly outperforms existing methods.",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Zhichao Duan",
      "Xiuxing Li",
      "Zhenyu Li",
      "Zhuo Wang",
      "Jianyong Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05343"
  },
  {
    "id": "arXiv:2211.05344",
    "title": "LERT: A Linguistically-motivated Pre-trained Language Model",
    "abstract": "Pre-trained Language Model (PLM) has become a representative foundation model\nin the natural language processing field. Most PLMs are trained with\nlinguistic-agnostic pre-training tasks on the surface form of the text, such as\nthe masked language model (MLM). To further empower the PLMs with richer\nlinguistic features, in this paper, we aim to propose a simple but effective\nway to learn linguistic features for pre-trained language models. We propose\nLERT, a pre-trained language model that is trained on three types of linguistic\nfeatures along with the original MLM pre-training task, using a\nlinguistically-informed pre-training (LIP) strategy. We carried out extensive\nexperiments on ten Chinese NLU tasks, and the experimental results show that\nLERT could bring significant improvements over various comparable baselines.\nFurthermore, we also conduct analytical experiments in various linguistic\naspects, and the results prove that the design of LERT is valid and effective.\nResources are available at https://github.com/ymcui/LERT",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Yiming Cui",
      "Wanxiang Che",
      "Shijin Wang",
      "Ting Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05344"
  },
  {
    "id": "arXiv:2211.05345",
    "title": "Finding Triangles and Other Small Subgraphs in Geometric Intersection  Graphs",
    "abstract": "We consider problems related to finding short cycles, small cliques, small\nindependent sets, and small subgraphs in geometric intersection graphs. We\nobtain a plethora of new results. For example:\n* For the intersection graph of $n$ line segments in the plane, we give\nalgorithms to find a 3-cycle in $O(n^{1.408})$ time, a size-3 independent set\nin $O(n^{1.652})$ time, a 4-clique in near-$O(n^{24/13})$ time, and a\n$k$-clique (or any $k$-vertex induced subgraph) in $O(n^{0.565k+O(1)})$ time\nfor any constant $k$; we can also compute the girth in near-$O(n^{3/2})$ time.\n* For the intersection graph of $n$ axis-aligned boxes in a constant\ndimension $d$, we give algorithms to find a 3-cycle in $O(n^{1.408})$ time for\nany $d$, a 4-clique (or any 4-vertex induced subgraph) in $O(n^{1.715})$ time\nfor any $d$, a size-4 independent set in near-$O(n^{3/2})$ time for any $d$, a\nsize-5 independent set in near-$O(n^{4/3})$ time for $d=2$, and a $k$-clique\n(or any $k$-vertex induced subgraph) in $O(n^{0.429k+O(1)})$ time for any $d$\nand any constant $k$.\n* For the intersection graph of $n$ fat objects in any constant dimension\n$d$, we give an algorithm to find any $k$-vertex (non-induced) subgraph in\n$O(n\\log n)$ time for any constant $k$, generalizing a result by Kaplan, Klost,\nMulzer, Roddity, Seiferth, and Sharir (1999) for 3-cycles in 2D disk graphs.\nA variety of techniques is used, including geometric range searching,\nbiclique covers, \"high-low\" tricks, graph degeneracy and separators, and\nshifted quadtrees. We also prove a near-$\\Omega(n^{4/3})$ conditional lower\nbound for finding a size-4 independent set for boxes.",
    "descriptor": "\nComments: To appear in SODA 2023\n",
    "authors": [
      "Timothy M. Chan"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.05345"
  },
  {
    "id": "arXiv:2211.05346",
    "title": "RARE: Renewable Energy Aware Resource Management in Datacenters",
    "abstract": "The exponential growth in demand for digital services drives massive\ndatacenter energy consumption and negative environmental impacts. Promoting\nsustainable solutions to pressing energy and digital infrastructure challenges\nis crucial. Several hyperscale cloud providers have announced plans to power\ntheir datacenters using renewable energy. However, integrating renewables to\npower the datacenters is challenging because the power generation is\nintermittent, necessitating approaches to tackle power supply variability. Hand\nengineering domain-specific heuristics-based schedulers to meet specific\nobjective functions in such complex dynamic green datacenter environments is\ntime-consuming, expensive, and requires extensive tuning by domain experts. The\ngreen datacenters need smart systems and system software to employ multiple\nrenewable energy sources (wind and solar) by intelligently adapting computing\nto renewable energy generation. We present RARE (Renewable energy Aware\nREsource management), a Deep Reinforcement Learning (DRL) job scheduler that\nautomatically learns effective job scheduling policies while continually\nadapting to datacenters' complex dynamic environment. The resulting DRL\nscheduler performs better than heuristic scheduling policies with different\nworkloads and adapts to the intermittent power supply from renewables. We\ndemonstrate DRL scheduler system design parameters that, when tuned correctly,\nproduce better performance. Finally, we demonstrate that the DRL scheduler can\nlearn from and improve upon existing heuristic policies using Offline Learning.",
    "descriptor": "\nComments: Accepted at JSSPP-2022\n",
    "authors": [
      "Vanamala Venkataswamy",
      "Jake Grigsby",
      "Andrew Grimshaw",
      "Yanjun Qi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.05346"
  },
  {
    "id": "arXiv:2211.05347",
    "title": "Mitigating Forgetting in Online Continual Learning via Contrasting  Semantically Distinct Augmentations",
    "abstract": "Online continual learning (OCL) aims to enable model learning from a\nnon-stationary data stream to continuously acquire new knowledge as well as\nretain the learnt one, under the constraints of having limited system size and\ncomputational cost, in which the main challenge comes from the \"catastrophic\nforgetting\" issue -- the inability to well remember the learnt knowledge while\nlearning the new ones. With the specific focus on the class-incremental OCL\nscenario, i.e. OCL for classification, the recent advance incorporates the\ncontrastive learning technique for learning more generalised feature\nrepresentation to achieve the state-of-the-art performance but is still unable\nto fully resolve the catastrophic forgetting. In this paper, we follow the\nstrategy of adopting contrastive learning but further introduce the\nsemantically distinct augmentation technique, in which it leverages strong\naugmentation to generate more data samples, and we show that considering these\nsamples semantically different from their original classes (thus being related\nto the out-of-distribution samples) in the contrastive learning mechanism\ncontributes to alleviate forgetting and facilitate model stability. Moreover,\nin addition to contrastive learning, the typical classification mechanism and\nobjective (i.e. softmax classifier and cross-entropy loss) are included in our\nmodel design for faster convergence and utilising the label information, but\nparticularly equipped with a sampling strategy to tackle the tendency of\nfavouring the new classes (i.e. model bias towards the recently learnt\nclasses). Upon conducting extensive experiments on CIFAR-10, CIFAR-100, and\nMini-Imagenet datasets, our proposed method is shown to achieve superior\nperformance against various baselines.",
    "descriptor": "",
    "authors": [
      "Sheng-Feng Yu",
      "Wei-Chen Chiu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05347"
  },
  {
    "id": "arXiv:2211.05350",
    "title": "The entropy rate of Linear Additive Markov Processes",
    "abstract": "This work derives a theoretical value for the entropy of a Linear Additive\nMarkov Process (LAMP), an expressive model able to generate sequences with a\ngiven autocorrelation structure. While a first-order Markov Chain model\ngenerates new values by conditioning on the current state, the LAMP model takes\nthe transition state from the sequence's history according to some distribution\nwhich does not have to be bounded. The LAMP model captures complex\nrelationships and long-range dependencies in data with similar expressibility\nto a higher-order Markov process. While a higher-order Markov process has a\npolynomial parameter space, a LAMP model is characterised only by a probability\ndistribution and the transition matrix of an underlying first-order Markov\nChain. We prove that the theoretical entropy rate of a LAMP is equivalent to\nthe theoretical entropy rate of the underlying first-order Markov Chain. This\nsurprising result is explained by the randomness introduced by the random\nprocess which selects the LAMP transitioning state, and provides a tool to\nmodel complex dependencies in data while retaining useful theoretical results.\nWe use the LAMP model to estimate the entropy rate of the LastFM, BrightKite,\nWikispeedia and Reuters-21578 datasets. We compare estimates calculated using\nfrequency probability estimates, a first-order Markov model and the LAMP model,\nand consider two approaches to ensuring the transition matrix is irreducible.\nIn most cases the LAMP entropy rates are lower than those of the alternatives,\nsuggesting that LAMP model is better at accommodating structural dependencies\nin the processes.",
    "descriptor": "\nComments: 8 pages, code available on Github\n",
    "authors": [
      "Bridget Smart",
      "Matthew Roughan",
      "Lewis Mitchell"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2211.05350"
  },
  {
    "id": "arXiv:2211.05351",
    "title": "Biomedical Multi-hop Question Answering Using Knowledge Graph Embeddings  and Language Models",
    "abstract": "Biomedical knowledge graphs (KG) are heterogenous networks consisting of\nbiological entities as nodes and relations between them as edges. These\nentities and relations are extracted from millions of research papers and\nunified in a single resource. The goal of biomedical multi-hop\nquestion-answering over knowledge graph (KGQA) is to help biologist and\nscientist to get valuable insights by asking questions in natural language.\nRelevant answers can be found by first understanding the question and then\nquerying the KG for right set of nodes and relationships to arrive at an\nanswer. To model the question, language models such as RoBERTa and BioBERT are\nused to understand context from natural language question. One of the\nchallenges in KGQA is missing links in the KG. Knowledge graph embeddings (KGE)\nhelp to overcome this problem by encoding nodes and edges in a dense and more\nefficient way. In this paper, we use a publicly available KG called Hetionet\nwhich is an integrative network of biomedical knowledge assembled from 29\ndifferent databases of genes, compounds, diseases, and more. We have enriched\nthis KG dataset by creating a multi-hop biomedical question-answering dataset\nin natural language for testing the biomedical multi-hop question-answering\nsystem and this dataset will be made available to the research community. The\nmajor contribution of this research is an integrated system that combines\nlanguage models with KG embeddings to give highly relevant answers to free-form\nquestions asked by biologists in an intuitive interface. Biomedical multi-hop\nquestion-answering system is tested on this data and results are highly\nencouraging.",
    "descriptor": "",
    "authors": [
      "Dattaraj J. Rao",
      "Shraddha S. Mane",
      "Mukta A. Paliwal"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.05351"
  },
  {
    "id": "arXiv:2211.05352",
    "title": "3D-CSL: self-supervised 3D context similarity learning for  Near-Duplicate Video Retrieval",
    "abstract": "In this paper, we introduce 3D-CSL, a compact pipeline for Near-Duplicate\nVideo Retrieval (NDVR), and explore a novel self-supervised learning strategy\nfor video similarity learning. Most previous methods only extract video spatial\nfeatures from frames separately and then design kinds of complex mechanisms to\nlearn the temporal correlations among frame features. However, parts of\nspatiotemporal dependencies have already been lost. To address this, our 3D-CSL\nextracts global spatiotemporal dependencies in videos end-to-end with a 3D\ntransformer and find a good balance between efficiency and effectiveness by\nmatching on clip-level. Furthermore, we propose a two-stage self-supervised\nsimilarity learning strategy to optimize the entire network. Firstly, we\npropose PredMAE to pretrain the 3D transformer with video prediction task;\nSecondly, ShotMix, a novel video-specific augmentation, and FCS loss, a novel\ntriplet loss, are proposed further promote the similarity learning results. The\nexperiments on FIVR-200K and CC_WEB_VIDEO demonstrate the superiority and\nreliability of our method, which achieves the state-of-the-art performance on\nclip-level NDVR.",
    "descriptor": "",
    "authors": [
      "Rui Deng",
      "Qian Wu",
      "Yuke Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05352"
  },
  {
    "id": "arXiv:2211.05359",
    "title": "A Reliable and Low Latency Synchronizing Middleware for Co-simulation of  a Heterogeneous Multi-Robot Systems",
    "abstract": "Search and rescue, wildfire monitoring, and flood/hurricane impact assessment\nare mission-critical services for recent IoT networks. Communication\nsynchronization, dependability, and minimal communication jitter are major\nsimulation and system issues for the time-based physics-based ROS simulator,\nevent-based network-based wireless simulator, and complex dynamics of mobile\nand heterogeneous IoT devices deployed in actual environments. Simulating a\nheterogeneous multi-robot system before deployment is difficult due to\nsynchronizing physics (robotics) and network simulators. Due to its\nmaster-based architecture, most TCP/IP-based synchronization middlewares use\nROS1. A real-time ROS2 architecture with masterless packet discovery\nsynchronizes robotics and wireless network simulations. A velocity-aware\nTransmission Control Protocol (TCP) technique for ground and aerial robots\nusing Data Distribution Service (DDS) publish-subscribe transport minimizes\npacket loss, synchronization, transmission, and communication jitters. Gazebo\nand NS-3 simulate and test. Simulator-agnostic middleware. LOS/NLOS and TCP/UDP\nprotocols tested our ROS2-based synchronization middleware for packet loss\nprobability and average latency. A thorough ablation research replaced NS-3\nwith EMANE, a real-time wireless network simulator, and masterless ROS2 with\nmaster-based ROS1. Finally, we tested network synchronization and jitter using\none aerial drone (Duckiedrone) and two ground vehicles (TurtleBot3 Burger) on\ndifferent terrains in masterless (ROS2) and master-enabled (ROS1) clusters. Our\nmiddleware shows that a large-scale IoT infrastructure with a diverse set of\nstationary and robotic devices can achieve low-latency communications (12% and\n11% reduction in simulation and real) while meeting mission-critical\napplication reliability (10% and 15% packet loss reduction) and high-fidelity\nrequirements.",
    "descriptor": "",
    "authors": [
      "Emon Dey",
      "Mikolaj Walczak",
      "Mohammad Saeid Anwar",
      "Nirmalya Roy"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.05359"
  },
  {
    "id": "arXiv:2211.05361",
    "title": "Safety-Constrained Policy Transfer with Successor Features",
    "abstract": "In this work, we focus on the problem of safe policy transfer in\nreinforcement learning: we seek to leverage existing policies when learning a\nnew task with specified constraints. This problem is important for\nsafety-critical applications where interactions are costly and unconstrained\npolicies can lead to undesirable or dangerous outcomes, e.g., with physical\nrobots that interact with humans. We propose a Constrained Markov Decision\nProcess (CMDP) formulation that simultaneously enables the transfer of policies\nand adherence to safety constraints. Our formulation cleanly separates task\ngoals from safety considerations and permits the specification of a wide\nvariety of constraints. Our approach relies on a novel extension of generalized\npolicy improvement to constrained settings via a Lagrangian formulation. We\ndevise a dual optimization algorithm that estimates the optimal dual variable\nof a target task, thus enabling safe transfer of policies derived from\nsuccessor features learned on source tasks. Our experiments in simulated\ndomains show that our approach is effective; it visits unsafe states less\nfrequently and outperforms alternative state-of-the-art methods when taking\nsafety constraints into account.",
    "descriptor": "",
    "authors": [
      "Zeyu Feng",
      "Bowen Zhang",
      "Jianxin Bi",
      "Harold Soh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05361"
  },
  {
    "id": "arXiv:2211.05363",
    "title": "EMOFAKE: An Initial Dataset For Emotion Fake Audio Detection",
    "abstract": "There are already some datasets used for fake audio detection, such as the\nASVspoof and ADD datasets. However, these databases do not consider a situation\nthat the emotion of the audio has been changed from one to another, while other\ninformation (e.g. speaker identity and content) remains the same. Changing\nemotions often leads to semantic changes. This may be a great threat to social\nstability. Therefore, this paper reports our progress in developing such an\nemotion fake audio detection dataset involving changing emotion state of the\noriginal audio. The dataset is named EmoFake. The fake audio in EmoFake is\ngenerated using the state-of-the-art emotion voice conversion models. Some\nbenchmark experiments are conducted on this dataset. The results show that our\ndesigned dataset poses a challenge to the LCNN and RawNet2 baseline models of\nASVspoof 2021.",
    "descriptor": "",
    "authors": [
      "Yan Zhao",
      "Jiangyan Yi",
      "Jianhua Tao",
      "Chenglong Wang",
      "Chu Yuan Zhang",
      "Tao Wang",
      "Yongfeng Dong"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.05363"
  },
  {
    "id": "arXiv:2211.05364",
    "title": "Efficient Unsupervised Video Object Segmentation Network Based on Motion  Guidance",
    "abstract": "Considerable unsupervised video object segmentation algorithms based on deep\nlearning have the problem of substantive model parameters and computation,\nwhich significantly limits the application of the algorithm in practice. This\npaper proposes a video object segmentation network based on motion guidance,\nconsiderably reducing the number of model parameters and computation and\nimproving the video object segmentation performance. The model comprises a\ndual-stream network, motion guidance module, and multi-scale progressive fusion\nmodule. Specifically, RGB images and optical flow estimation are fed into\ndual-stream network to extract object appearance features and motion features.\nThen, the motion guidance module extracts the semantic information from the\nmotion features through local attention, which guides the appearance features\nto learn rich semantic information. Finally, the multi-scale progressive fusion\nmodule obtains the output features at each stage of the dual-stream network. It\ngradually integrates the deep features into the shallow ones yet improves the\nedge segmentation effect. In this paper, numerous evaluations are conducted on\nthree standard datasets, and the experimental results prove the superior\nperformance of the proposed method.",
    "descriptor": "",
    "authors": [
      "Chao Hu",
      "Liqiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05364"
  },
  {
    "id": "arXiv:2211.05368",
    "title": "A Comprehensive Survey on Distributed Training of Graph Neural Networks",
    "abstract": "Graph neural networks (GNNs) have been demonstrated to be a powerful\nalgorithmic model in broad application fields for their effectiveness in\nlearning over graphs. To scale GNN training up for large-scale and ever-growing\ngraphs, the most promising solution is distributed training which distributes\nthe workload of training across multiple computing nodes. However, the\nworkflows, computational patterns, communication patterns, and optimization\ntechniques of distributed GNN training remain preliminarily understood. In this\npaper, we provide a comprehensive survey of distributed GNN training by\ninvestigating various optimization techniques used in distributed GNN training.\nFirst, distributed GNN training is classified into several categories according\nto their workflows. In addition, their computational patterns and communication\npatterns, as well as the optimization techniques proposed by recent work are\nintroduced. Second, the software frameworks and hardware platforms of\ndistributed GNN training are also introduced for a deeper understanding. Third,\ndistributed GNN training is compared with distributed training of deep neural\nnetworks, emphasizing the uniqueness of distributed GNN training. Finally,\ninteresting issues and opportunities in this field are discussed.",
    "descriptor": "\nComments: Under review at Proceedings of the IEEE\n",
    "authors": [
      "Haiyang Lin",
      "Mingyu Yan",
      "Xiaochun Ye",
      "Dongrui Fan",
      "Shirui Pan",
      "Wenguang Chen",
      "Yuan Xie"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05368"
  },
  {
    "id": "arXiv:2211.05369",
    "title": "Decomposing the Fundamentals of Creepy Stories",
    "abstract": "Fear is a universal concept; people crave it in urban legends, scary movies,\nand modern stories. Open questions remain, however, about why these stories are\nscary and more generally what scares people. In this study, we explore these\nquestions by analyzing tens of thousands of scary stories on forums (known as\nsubreddits) in a social media website, Reddit. We first explore how writing\nstyles have evolved to keep these stories fresh before we analyze the stable\ncore techniques writers use to make stories scary. We find that writers have\nchanged the themes of their stories over years from haunted houses to\nschool-related themes, body horror, and diseases. Yet some features remain\nstable; words associated with pseudo-human nouns, such as clown or devil are\nmore common in scary stories than baselines. In addition, we collect a range of\ndatasets that annotate sentences containing fear. We use these data to develop\na high-accuracy fear detection neural network model, which is used to quantify\nwhere people express fear in scary stories. We find that sentences describing\nfear, and words most often seen in scary stories, spike at particular points in\na story, possibly as a way to keep the readers on the edge of their seats until\nthe story's conclusion. These results provide a new understanding of how\nauthors cater to their readers, and how fear may manifest in stories.",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Sakshi Goel",
      "Haripriya Dharmala",
      "Yuchen Zhang",
      "Keith Burghardt"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.05369"
  },
  {
    "id": "arXiv:2211.05371",
    "title": "MSDT: Masked Language Model Scoring Defense in Text Domain",
    "abstract": "Pre-trained language models allowed us to process downstream tasks with the\nhelp of fine-tuning, which aids the model to achieve fairly high accuracy in\nvarious Natural Language Processing (NLP) tasks. Such easily-downloaded\nlanguage models from various websites empowered the public users as well as\nsome major institutions to give a momentum to their real-life application.\nHowever, it was recently proven that models become extremely vulnerable when\nthey are backdoor attacked with trigger-inserted poisoned datasets by malicious\nusers. The attackers then redistribute the victim models to the public to\nattract other users to use them, where the models tend to misclassify when\ncertain triggers are detected within the training sample. In this paper, we\nwill introduce a novel improved textual backdoor defense method, named MSDT,\nthat outperforms the current existing defensive algorithms in specific\ndatasets. The experimental results illustrate that our method can be effective\nand constructive in terms of defending against backdoor attack in text domain.\nCode is available at https://github.com/jcroh0508/MSDT.",
    "descriptor": "\nComments: 5 pages, 1 figure, 4 tables, accepted as a conference paper at IEEE UV 2022, Boston, USA\n",
    "authors": [
      "Jaechul Roh",
      "Minhao Cheng",
      "Yajun Fang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05371"
  },
  {
    "id": "arXiv:2211.05372",
    "title": "Multi-Scenario Bimetric-Balanced IoT Resource Allocation: An  Evolutionary Approach",
    "abstract": "In this paper, we allocate IoT devices as resources for smart services with\ntime-constrained resource requirements. The allocation method named as BRAD can\nwork under multiple resource scenarios with diverse resource richnesses,\navailabilities and costs, such as the intelligent healthcare system deployed by\nHarbin Institute of Technology (HIT-IHC). The allocation aims for\nbimetric-balancing under the multi-scenario case, i.e., the profit and cost\nassociated with service satisfaction are jointly optimised and balanced wisely.\nBesides, we abstract IoT devices as digital objects (DO) to make them easier to\ninteract with during resource allocation. Considering that the problem is\nNP-Hard and the optimisation objective is not differentiable, we utilise Grey\nWolf Optimisation (GWO) algorithm as the model optimiser. Specifically, we\ntackle the deficiencies of GWO and significantly improve its performance by\nintroducing three new mechanisms to form the BRAD-GWA algorithm. Comprehensive\nexperiments are conducted on realistic HIT-IHC IoT testbeds and several\nalgorithms are compared, including the allocation method originally used by\nHIT-IHC system to verify the effectiveness of the BRAD-GWA. The BRAD-GWA\nachieves a 3.14 times and 29.6% objective reduction compared with the HIT-IHC\nand the original GWO algorithm, respectively.",
    "descriptor": "\nComments: Accepted by IEEE HPCC 2022\n",
    "authors": [
      "Jiashu Wu",
      "Hao Dai",
      "Yang Wang",
      "Zhiying Tu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.05372"
  },
  {
    "id": "arXiv:2211.05375",
    "title": "Electroadhesive Auxetics as Programmable Layer Jamming Skins for  Formable Crust Shape Displays",
    "abstract": "Shape displays are a class of haptic devices that enable whole-hand haptic\nexploration of 3D surfaces. However, their scalability is limited by the\nmechanical complexity and high cost of traditional actuator arrays. In this\npaper, we propose using electroadhesive auxetic skins as a strain-limiting\nlayer to create programmable shape change in a continuous (\"formable crust\")\nshape display. Auxetic skins are manufactured as flexible printed circuit\nboards with dielectric-laminated electrodes on each auxetic unit cell (AUC),\nusing monolithic fabrication to lower cost and assembly time. By layering\nmultiple sheets and applying a voltage between electrodes on subsequent layers,\nelectroadhesion locks individual AUCs, achieving a maximum in-plane stiffness\nvariation of 7.6x with a power consumption of 50 uW/AUC. We first characterize\nan individual AUC and compare results to a kinematic model. We then validate\nthe ability of a 5x5 AUC array to actively modify its own axial and transverse\nstiffness. Finally, we demonstrate this array in a continuous shape display as\na strain-limiting skin to programmatically modulate the shape output of an\ninflatable LDPE pouch. Integrating electroadhesion with auxetics enables new\ncapabilities for scalable, low-profile, and low-power control of flexible\nrobotic systems.",
    "descriptor": "\nComments: Submitted to IEEE International Conference on Robotics and Automation (ICRA 2023)\n",
    "authors": [
      "Ahad M. Rauf",
      "Jack S. Bernardo",
      "Sean Follmer"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.05375"
  },
  {
    "id": "arXiv:2211.05385",
    "title": "GANStrument: Adversarial Instrument Sound Synthesis with Pitch-invariant  Instance Conditioning",
    "abstract": "We propose GANStrument, a generative adversarial model for instrument sound\nsynthesis. Given a one-shot sound as input, it is able to generate pitched\ninstrument sounds that reflect the timbre of the input within an interactive\ntime. By exploiting instance conditioning, GANStrument achieves better fidelity\nand diversity of synthesized sounds and generalization ability to various\ninputs. In addition, we introduce an adversarial training scheme for a\npitch-invariant feature extractor that significantly improves the pitch\naccuracy and timbre consistency. Experimental results show that GANStrument\noutperforms strong baselines that do not use instance conditioning in terms of\ngeneration quality and input editability. Qualitative examples are available\nonline.",
    "descriptor": "\nComments: 5 pages, 4 figures, Audio examples: this https URL\n",
    "authors": [
      "Gaku Narita",
      "Junichi Shimizu",
      "Taketo Akama"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.05385"
  },
  {
    "id": "arXiv:2211.05392",
    "title": "EvEntS ReaLM: Event Reasoning of Entity States via Language Models",
    "abstract": "This paper investigates models of event implications. Specifically, how well\nmodels predict entity state-changes, by targeting their understanding of\nphysical attributes. Nominally, Large Language models (LLM) have been exposed\nto procedural knowledge about how objects interact, yet our benchmarking shows\nthey fail to reason about the world. Conversely, we also demonstrate that\nexisting approaches often misrepresent the surprising abilities of LLMs via\nimproper task encodings and that proper model prompting can dramatically\nimprove performance of reported baseline results across multiple tasks. In\nparticular, our results indicate that our prompting technique is especially\nuseful for unseen attributes (out-of-domain) or when only limited data is\navailable.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Evangelia Spiliopoulou",
      "Artidoro Pagnoni",
      "Yonatan Bisk",
      "Eduard Hovy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05392"
  },
  {
    "id": "arXiv:2211.05396",
    "title": "Learning Visual Representation of Underwater Acoustic Imagery Using  Transformer-Based Style Transfer Method",
    "abstract": "Underwater automatic target recognition (UATR) has been a challenging\nresearch topic in ocean engineering. Although deep learning brings\nopportunities for target recognition on land and in the air, underwater target\nrecognition techniques based on deep learning have lagged due to sensor\nperformance and the size of trainable data. This letter proposed a framework\nfor learning the visual representation of underwater acoustic imageries, which\ntakes a transformer-based style transfer model as the main body. It could\nreplace the low-level texture features of optical images with the visual\nfeatures of underwater acoustic imageries while preserving their raw high-level\nsemantic content. The proposed framework could fully use the rich optical image\ndataset to generate a pseudo-acoustic image dataset and use it as the initial\nsample to train the underwater acoustic target recognition model. The\nexperiments select the dual-frequency identification sonar (DIDSON) as the\nunderwater acoustic data source and also take fish, the most common marine\ncreature, as the research subject. Experimental results show that the proposed\nmethod could generate high-quality and high-fidelity pseudo-acoustic samples,\nachieve the purpose of acoustic data enhancement and provide support for the\nunderwater acoustic-optical images domain transfer research.",
    "descriptor": "\nComments: 11 pages, 9 figures, conference\n",
    "authors": [
      "Xiaoteng Zhou",
      "Changli Yu",
      "Shihao Yuan",
      "Xin Yuan",
      "Hangchi Yu",
      "Citong Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.05396"
  },
  {
    "id": "arXiv:2211.05400",
    "title": "onlineFGO: Online Continuous-Time Factor Graph Optimization with  Time-Centric Multi-Sensor Fusion for Robust Localization in Large-Scale  Environments",
    "abstract": "Accurate and consistent vehicle localization in urban areas is challenging\ndue to the large-scale and complicated environments. In this paper, we propose\nonlineFGO, a novel time-centric graph-optimization-based localization method\nthat fuses multiple sensor measurements with the continuous-time trajectory\nrepresentation for vehicle localization tasks. We generalize the graph\nconstruction independent of any spatial sensor measurements by creating the\nstates deterministically on time. As the trajectory representation in\ncontinuous-time enables querying states at arbitrary times, incoming sensor\nmeasurements can be factorized on the graph without requiring state alignment.\nWe integrate different GNSS observations: pseudorange, deltarange, and\ntime-differenced carrier phase (TDCP) to ensure global reference and fuse the\nrelative motion from a LiDAR-odometry to improve the localization consistency\nwhile GNSS observations are not available. Experiments on general performance,\neffects of different factors, and hyper-parameter settings are conducted in a\nreal-world measurement campaign in Aachen city that contains different urban\nscenarios. Our results show an average 2D error of 0.99m and consistent state\nestimation in urban scenarios.",
    "descriptor": "\nComments: 7 Pages, 7 Figures, Submitted to The International Conference on Robotics and Automation (ICRA) 2023\n",
    "authors": [
      "Haoming Zhang",
      "Felix Widmayer",
      "Lars L\u00fcnnemann",
      "Dirk Abel"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.05400"
  },
  {
    "id": "arXiv:2211.05403",
    "title": "Zebra: Deeply Integrating System-Level Provenance Search and Tracking  for Efficient Attack Investigation",
    "abstract": "System auditing has emerged as a key approach for monitoring system call\nevents and investigating sophisticated attacks. Based on the collected audit\nlogs, research has proposed to search for attack patterns or track the causal\ndependencies of system events to reveal the attack sequence. However, existing\napproaches either cannot reveal long-range attack sequences or suffer from the\ndependency explosion problem due to a lack of focus on attack-relevant parts,\nand thus are insufficient for investigating complex attacks.\nTo bridge the gap, we propose Zebra, a system that synergistically integrates\nattack pattern search and causal dependency tracking for efficient attack\ninvestigation. With Zebra, security analysts can alternate between search and\ntracking to reveal the entire attack sequence in a progressive, user-guided\nmanner, while mitigating the dependency explosion problem by prioritizing the\nattack-relevant parts. To enable this, Zebra provides (1) an expressive and\nconcise domain-specific language, Tstl, for performing various types of search\nand tracking analyses, and (2) an optimized language execution engine for\nefficient execution over a big amount of auditing data. Evaluations on a broad\nset of attack cases demonstrate the effectiveness of Zebra in facilitating a\ntimely attack investigation.",
    "descriptor": "",
    "authors": [
      "Xinyu Yang",
      "Haoyuan Liu",
      "Ziyu Wang",
      "Peng Gao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.05403"
  },
  {
    "id": "arXiv:2211.05405",
    "title": "VieCap4H - VLSP 2021: ObjectAoA -- Enhancing performance of Object  Relation Transformer with Attention on Attention for Vietnamese image  captioning",
    "abstract": "Image captioning is currently a challenging task that requires the ability to\nboth understand visual information and use human language to describe this\nvisual information in the image. In this paper, we propose an efficient way to\nimprove the image understanding ability of transformer-based method by\nextending Object Relation Transformer architecture with Attention on Attention\nmechanism. Experiments on the VieCap4H dataset show that our proposed method\nsignificantly outperforms its original structure on both the public test and\nprivate test of the Image Captioning shared task held by VLSP.",
    "descriptor": "\nComments: Accepted for publishing at the VNU Journal of Science: Computer Science and Communication Engineering\n",
    "authors": [
      "Nghia Hieu Nguyen",
      "Duong T.D. Vo",
      "Minh-Quan Ha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05405"
  },
  {
    "id": "arXiv:2211.05407",
    "title": "UIT-HWDB: Using Transferring Method to Construct A Novel Benchmark for  Evaluating Unconstrained Handwriting Image Recognition in Vietnamese",
    "abstract": "Recognizing handwriting images is challenging due to the vast variation in\nwriting style across many people and distinct linguistic aspects of writing\nlanguages. In Vietnamese, besides the modern Latin characters, there are accent\nand letter marks together with characters that draw confusion to\nstate-of-the-art handwriting recognition methods. Moreover, as a low-resource\nlanguage, there are not many datasets for researching handwriting recognition\nin Vietnamese, which makes handwriting recognition in this language have a\nbarrier for researchers to approach. Recent works evaluated offline handwriting\nrecognition methods in Vietnamese using images from an online handwriting\ndataset constructed by connecting pen stroke coordinates without further\nprocessing. This approach obviously can not measure the ability of recognition\nmethods effectively, as it is trivial and may be lack of features that are\nessential in offline handwriting images. Therefore, in this paper, we propose\nthe Transferring method to construct a handwriting image dataset that\nassociates crucial natural attributes required for offline handwriting images.\nUsing our method, we provide a first high-quality synthetic dataset which is\ncomplex and natural for efficiently evaluating handwriting recognition methods.\nIn addition, we conduct experiments with various state-of-the-art methods to\nfigure out the challenge to reach the solution for handwriting recognition in\nVietnamese.",
    "descriptor": "\nComments: Accepted for publishing at the 16th International Conference on Computing and Communication Technologies (RIVF)\n",
    "authors": [
      "Nghia Hieu Nguyen",
      "Duong T.D. Vo",
      "Kiet Van Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05407"
  },
  {
    "id": "arXiv:2211.05410",
    "title": "Stay Home Safe with Starving Federated Data",
    "abstract": "Over the past few years, the field of adversarial attack received numerous\nattention from various researchers with the help of successful attack success\nrate against well-known deep neural networks that were acknowledged to achieve\nhigh classification ability in various tasks. However, majority of the\nexperiments were completed under a single model, which we believe it may not be\nan ideal case in a real-life situation. In this paper, we introduce a novel\nfederated adversarial training method for smart home face recognition, named\nFLATS, where we observed some interesting findings that may not be easily\nnoticed in a traditional adversarial attack to federated learning experiments.\nBy applying different variations to the hyperparameters, we have spotted that\nour method can make the global model to be robust given a starving federated\nenvironment. Our code can be found on https://github.com/jcroh0508/FLATS.",
    "descriptor": "\nComments: 11 pages, 12 figures, 7 tables, accepted as a conference paper at IEEE UV 2022, Boston, USA\n",
    "authors": [
      "Jaechul Roh",
      "Yajun Fang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.05410"
  },
  {
    "id": "arXiv:2211.05412",
    "title": "Desire Backpropagation: A Lightweight Training Algorithm for Multi-Layer  Spiking Neural Networks based on Spike-Timing-Dependent Plasticity",
    "abstract": "Spiking neural networks (SNN) are a viable alternative to conventional\nartificial neural networks when energy efficiency and computational complexity\nare of importance. A major advantage of SNNs is their binary information\ntransfer through spike trains. The training of SNN has, however, been a\nchallenge, since neuron models are non-differentiable and traditional\ngradient-based backpropagation algorithms cannot be applied directly.\nFurthermore, spike-timing-dependent plasticity (STDP), albeit being a\nspike-based learning rule, updates weights locally and does not optimize for\nthe output error of the network. We present desire backpropagation, a method to\nderive the desired spike activity of neurons from the output error. The loss\nfunction can then be evaluated locally for every neuron. Incorporating the\ndesire values into the STDP weight update leads to global error minimization\nand increasing classification accuracy. At the same time, the neuron dynamics\nand computational efficiency of STDP are maintained, making it a spike-based\nsupervised learning rule. We trained three-layer networks to classify MNIST and\nFashion-MNIST images and reached an accuracy of 98.41% and 87.56%,\nrespectively. Furthermore, we show that desire backpropagation is\ncomputationally less complex than backpropagation in traditional neural\nnetworks.",
    "descriptor": "",
    "authors": [
      "Daniel Gerlinghoff",
      "Tao Luo",
      "Rick Siow Mong Goh",
      "Weng-Fai Wong"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2211.05412"
  },
  {
    "id": "arXiv:2211.05414",
    "title": "ADEPT: A DEbiasing PrompT Framework",
    "abstract": "Several works have proven that finetuning is an applicable approach for\ndebiasing contextualized word embeddings. Similarly, discrete prompts with\nsemantic meanings have shown to be effective in debiasing tasks. With unfixed\nmathematical representation at the token level, continuous prompts usually\nsurpass discrete ones at providing a pre-trained language model (PLM) with\nadditional task-specific information. Despite this, relatively few efforts have\nbeen made to debias PLMs by prompt tuning with continuous prompts compared to\nits discrete counterpart. Furthermore, for most debiasing methods that alter a\nPLM's original parameters, a major problem is the need to not only decrease the\nbias in the PLM but also to ensure that the PLM does not lose its\nrepresentation ability. Finetuning methods typically have a hard time\nmaintaining this balance, as they tend to violently remove meanings of\nattribute words. In this paper, we propose ADEPT, a method to debias PLMs using\nprompt tuning while maintaining the delicate balance between removing biases\nand ensuring representation ability. To achieve this, we propose a new training\ncriterion inspired by manifold learning and equip it with an explicit debiasing\nterm to optimize prompt tuning. In addition, we conduct several experiments\nwith regard to the reliability, quality, and quantity of a previously proposed\nattribute training corpus in order to obtain a clearer prototype of a certain\nattribute, which indicates the attribute's position and relative distances to\nother words on the manifold. We evaluate ADEPT on several widely acknowledged\ndebiasing benchmarks and downstream tasks, and find that it achieves\ncompetitive results while maintaining (and in some cases even improving) the\nPLM's representation ability. We further visualize words' correlation before\nand after debiasing a PLM, and give some possible explanations for the visible\neffects.",
    "descriptor": "",
    "authors": [
      "Ke Yang",
      "Charles Yu",
      "Yi Fung",
      "Manling Li",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05414"
  },
  {
    "id": "arXiv:2211.05416",
    "title": "Wikidata-lite for Knowledge Extraction and Exploration",
    "abstract": "Wikidata is the largest collaborative general knowledge graph supported by a\nworldwide community. It includes many helpful topics for knowledge exploration\nand data science applications. However, due to the enormous size of Wikidata,\nit is challenging to retrieve a large amount of data with millions of results,\nmake complex queries requiring large aggregation operations, or access too many\nstatement references. This paper introduces our preliminary works on\nWikidata-lite, a toolkit to build a database offline for knowledge extraction\nand exploration, e.g., retrieving item information, statements, provenances, or\nsearching entities by their keywords and attributes. Wikidata-lite has high\nperformance and memory efficiency, much faster than the official Wikidata\nSPARQL endpoint for big queries. The Wikidata-lite repository is available at\nhttps://github.com/phucty/wikidb.",
    "descriptor": "\nComments: 3 pages, workshop paper\n",
    "authors": [
      "Phuc Nguyen",
      "Hideaki Takeda"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.05416"
  },
  {
    "id": "arXiv:2211.05417",
    "title": "Can Transformers Reason in Fragments of Natural Language?",
    "abstract": "State-of-the-art deep-learning-based approaches to Natural Language\nProcessing (NLP) are credited with various capabilities that involve reasoning\nwith natural language texts. In this paper we carry out a large-scale empirical\nstudy investigating the detection of formally valid inferences in controlled\nfragments of natural language for which the satisfiability problem becomes\nincreasingly complex. We find that, while transformer-based language models\nperform surprisingly well in these scenarios, a deeper analysis re-veals that\nthey appear to overfit to superficial patterns in the data rather than\nacquiring the logical principles governing the reasoning in these fragments.",
    "descriptor": "\nComments: Accepted to EMNLP 2022\n",
    "authors": [
      "Viktor Schlegel",
      "Kamen V. Pavlov",
      "Ian Pratt-Hartmann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.05417"
  },
  {
    "id": "arXiv:2211.05423",
    "title": "A metaheuristic multi-objective interaction-aware feature selection  method",
    "abstract": "Multi-objective feature selection is one of the most significant issues in\nthe field of pattern recognition. It is challenging because it maximizes the\nclassification performance and, at the same time, minimizes the number of\nselected features, and the mentioned two objectives are usually conflicting. To\nachieve a better Pareto optimal solution, metaheuristic optimization methods\nare widely used in many studies. However, the main drawback is the exploration\nof a large search space. Another problem with multi-objective feature selection\napproaches is the interaction between features. Selecting correlated features\nhas negative effect on classification performance. To tackle these problems, we\npresent a novel multi-objective feature selection method that has several\nadvantages. Firstly, it considers the interaction between features using an\nadvanced probability scheme. Secondly, it is based on the Pareto Archived\nEvolution Strategy (PAES) method that has several advantages such as simplicity\nand its speed in exploring the solution space. However, we improve the\nstructure of PAES in such a way that generates the offsprings, intelligently.\nThus, the proposed method utilizes the introduced probability scheme to produce\nmore promising offsprings. Finally, it is equipped with a novel strategy that\nguides it to find the optimum number of features through the process of\nevolution. The experimental results show a significant improvement in finding\nthe optimal Pareto front compared to state-of-the-art methods on different\nreal-world datasets.",
    "descriptor": "",
    "authors": [
      "Motahare Namakin",
      "Modjtaba Rouhani",
      "Mostafa Sabzekar"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.05423"
  },
  {
    "id": "arXiv:2211.05427",
    "title": "On the Privacy Risks of Algorithmic Recourse",
    "abstract": "As predictive models are increasingly being employed to make consequential\ndecisions, there is a growing emphasis on developing techniques that can\nprovide algorithmic recourse to affected individuals. While such recourses can\nbe immensely beneficial to affected individuals, potential adversaries could\nalso exploit these recourses to compromise privacy. In this work, we make the\nfirst attempt at investigating if and how an adversary can leverage recourses\nto infer private information about the underlying model's training data. To\nthis end, we propose a series of novel membership inference attacks which\nleverage algorithmic recourse. More specifically, we extend the prior\nliterature on membership inference attacks to the recourse setting by\nleveraging the distances between data instances and their corresponding\ncounterfactuals output by state-of-the-art recourse methods. Extensive\nexperimentation with real world and synthetic datasets demonstrates significant\nprivacy leakage through recourses. Our work establishes unintended privacy\nleakage as an important risk in the widespread adoption of recourse methods.",
    "descriptor": "",
    "authors": [
      "Martin Pawelczyk",
      "Himabindu Lakkaraju",
      "Seth Neel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.05427"
  },
  {
    "id": "arXiv:2211.05428",
    "title": "A Modular 3-Degree-of-Freedom Force Sensor for Robot-assisted Minimally  Invasive Surgery Research",
    "abstract": "Effective force modulation during tissue manipulation is important for\nensuring safe robot-assisted minimally invasive surgery (RMIS). Strict\nrequirements for in-vivo distal force sensing have led to prior sensor designs\nthat trade off ease of manufacture and integration against force measurement\naccuracy along the tool axis. These limitations have made collecting\nhigh-quality 3-degree-of-freedom (3-DoF) bimanual force data in RMIS\ninaccessible to researchers. We present a modular and manufacturable 3-DoF\nforce sensor that integrates easily with an existing RMIS tool. We achieve this\nby relaxing biocompatibility and sterilizability requirements while utilizing\ncommercial load cells and common electromechanical fabrication techniques. The\nsensor has a range of +-5 N axially and +-3 N laterally with average root mean\nsquare errors(RMSEs) of below 0.15 N in all directions. During teleoperated\nmock tissue manipulation tasks, a pair of jaw-mounted sensors achieved average\nRMSEs of below 0.15 N in all directions. For grip force, it achieved an RMSE of\n0.156 N. The sensor has sufficient accuracy within the range of forces found in\ndelicate manipulation tasks, with potential use in bimanual haptic feedback and\nrobotic force control. As an open-source design, the sensors can be adapted to\nsuit additional robotic applications outside of RMIS.",
    "descriptor": "\nComments: 8 pages, 11 figures\n",
    "authors": [
      "Zonghe Chua",
      "Allison M. Okamura"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.05428"
  },
  {
    "id": "arXiv:2211.05429",
    "title": "DrawMon: A Distributed System for Detection of Atypical Sketch Content  in Concurrent Pictionary Games",
    "abstract": "Pictionary, the popular sketch-based guessing game, provides an opportunity\nto analyze shared goal cooperative game play in restricted communication\nsettings. However, some players occasionally draw atypical sketch content.\nWhile such content is occasionally relevant in the game context, it sometimes\nrepresents a rule violation and impairs the game experience. To address such\nsituations in a timely and scalable manner, we introduce DrawMon, a novel\ndistributed framework for automatic detection of atypical sketch content in\nconcurrently occurring Pictionary game sessions. We build specialized online\ninterfaces to collect game session data and annotate atypical sketch content,\nresulting in AtyPict, the first ever atypical sketch content dataset. We use\nAtyPict to train CanvasNet, a deep neural atypical content detection network.\nWe utilize CanvasNet as a core component of DrawMon. Our analysis of post\ndeployment game session data indicates DrawMon's effectiveness for scalable\nmonitoring and atypical sketch content detection. Beyond Pictionary, our\ncontributions also serve as a design guide for customized atypical content\nresponse systems involving shared and interactive whiteboards. Code and\ndatasets are available at https://drawm0n.github.io.",
    "descriptor": "\nComments: Presented at ACM Multimedia 2022. For project page and dataset, visit this https URL\n",
    "authors": [
      "Nikhil Bansal",
      "Kartik Gupta",
      "Kiruthika Kannan",
      "Sivani Pentapati",
      "Ravi Kiran Sarvadevabhatla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.05429"
  },
  {
    "id": "arXiv:2211.05432",
    "title": "Speech Enhancement with Fullband-Subband Cross-Attention Network",
    "abstract": "FullSubNet has shown its promising performance on speech enhancement by\nutilizing both fullband and subband information. However, the relationship\nbetween fullband and subband in FullSubNet is achieved by simply concatenating\nthe output of fullband model and subband units. It only supplements the subband\nunits with a small quantity of global information and has not considered the\ninteraction between fullband and subband. This paper proposes a\nfullband-subband cross-attention (FSCA) module to interactively fuse the global\nand local information and applies it to FullSubNet. This new framework is\ncalled as FS-CANet. Moreover, different from FullSubNet, the proposed FS-CANet\noptimize the fullband extractor by temporal convolutional network (TCN) blocks\nto further reduce the model size. Experimental results on DNS Challenge -\nInterspeech 2021 dataset show that the proposed FS-CANet outperforms other\nstate-of-the-art speech enhancement approaches, and demonstrate the\neffectiveness of fullband-subband cross-attention.",
    "descriptor": "\nComments: Accepted by InterSpeech 2022. arXiv admin note: text overlap with arXiv:2203.12188\n",
    "authors": [
      "Jun Chen",
      "Wei Rao",
      "Zilin Wang",
      "Zhiyong Wu",
      "Yannan Wang",
      "Tao Yu",
      "Shidong Shang",
      "Helen Meng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.05432"
  },
  {
    "id": "arXiv:2211.05433",
    "title": "A classification performance evaluation measure considering data  separability",
    "abstract": "Machine learning and deep learning classification models are data-driven, and\nthe model and the data jointly determine their classification performance. It\nis biased to evaluate the model's performance only based on the classifier\naccuracy while ignoring the data separability. Sometimes, the model exhibits\nexcellent accuracy, which might be attributed to its testing on highly\nseparable data. Most of the current studies on data separability measures are\ndefined based on the distance between sample points, but this has been\ndemonstrated to fail in several circumstances. In this paper, we propose a new\nseparability measure--the rate of separability (RS), which is based on the data\ncoding rate. We validate its effectiveness as a supplement to the separability\nmeasure by comparing it to four other distance-based measures on synthetic\ndatasets. Then, we demonstrate the positive correlation between the proposed\nmeasure and recognition accuracy in a multi-task scenario constructed from a\nreal dataset. Finally, we discuss the methods for evaluating the classification\nperformance of machine learning and deep learning models considering data\nseparability.",
    "descriptor": "",
    "authors": [
      "Lingyan Xue",
      "Xinyu Zhang",
      "Weidong Jiang",
      "Kai Huo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.05433"
  },
  {
    "id": "arXiv:2211.05434",
    "title": "Multi-Agent Contracts",
    "abstract": "We study a natural combinatorial single-principal multi-agent contract design\nproblem, in which a principal motivates a team of agents to exert effort toward\na given task. At the heart of our model is a reward function, which maps the\nagent efforts to an expected reward of the principal. We seek to design\ncomputationally efficient algorithms for finding optimal (or near-optimal)\nlinear contracts for reward functions that belong to the complement-free\nhierarchy.\nOur first main result gives constant-factor approximation algorithms for\nsubmodular and XOS reward functions, with value and demand oracles,\nrespectively. It relies on an unconventional use of ``prices'' and\n(approximate) demand queries for selecting the set of agents that the principal\nshould contract with, and exploits a novel scaling property of XOS functions\nand their marginals, which may be of independent interest.\nOur second main result is an $\\Omega(\\sqrt{n})$ impossibility for settings\nwith $n$ agents and subadditive reward functions, even with demand oracle\naccess. A striking feature of this impossibility is that it applies to\nsubadditive functions that are constant-factor close to submodular. This\npresents a surprising departure from previous literature, e.g., on\ncombinatorial auctions.",
    "descriptor": "",
    "authors": [
      "Paul Duetting",
      "Tomer Ezra",
      "Michal Feldman",
      "Thomas Kesselheim"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.05434"
  },
  {
    "id": "arXiv:2211.05441",
    "title": "Semantic Learning and Emulation Based Cross-platform Binary  Vulnerability Seeker",
    "abstract": "Clone detection is widely exploited for software vulnerability search. The\napproaches based on source code analysis cannot be applied to binary clone\ndetection because the same source code can produce significantly different\nbinaries. In this paper, we present BinSeeker, a cross-platform binary seeker\nthat integrates semantic learning and emulation. With the help of the labeled\nsemantic flow graph, BinSeeker can quickly identify M candidate functions that\nare most similar to the vulnerability from the target binary. The value of M is\nrelatively large so this semantic learning procedure essentially eliminates\nthose functions that are very unlikely to have the vulnerability. Then,\nsemantic emulation is conducted on these M candidates to obtain their dynamic\nsignature sequences. By comparing signature sequences, BinSeeker produces top-N\nfunctions that exhibit most similar behavior to that of the vulnerability. With\nfast filtering of semantic learning and accurate comparison of semantic\nemulation, BinSeeker seeks vulnerability precisely with little overhead. The\nexperiments on six widely used programs with fifteen known CVE vulnerabilities\ndemonstrate that BinSeeker outperforms three state-of-the-art tools Genius,\nGemini and CACompare. Regarding search accuracy, BinSeeker achieves an MRR\nvalue of 0.65 in the target programs, whereas the MRR values by Genius, Gemini\nand CACompare are 0.17, 0.07 and 0.42, respectively. If we consider ranking a\nfunction with the targeted vulnerability in the top-5 as accurate, BinSeeker\nachieves the accuracy of 93.33 percent, while the accuracy of the other three\ntools is merely 33.33, 13.33 and 53.33 percent, respectively. Such accuracy is\nachieved with 0.27s on average to determine whether the target binary function\ncontains a known vulnerability, and the time for the other three tools are\n1.57s, 0.15s and 0.98s, respectively.",
    "descriptor": "\nComments: This paper appeared in IEEE Transactions on Software Engineering\n",
    "authors": [
      "Jian Gao",
      "Yu Jiang",
      "Zhe Liu",
      "Xin Yang",
      "Cong Wang",
      "Xun Jiao",
      "Zijiang Yang",
      "Jiaguang Sun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.05441"
  },
  {
    "id": "arXiv:2211.05446",
    "title": "Privacy-Utility Balanced Voice De-Identification Using Adversarial  Examples",
    "abstract": "Faced with the threat of identity leakage during voice data publishing, users\nare engaged in a privacy-utility dilemma when enjoying convenient voice\nservices. Existing studies employ direct modification or text-based\nre-synthesis to de-identify users' voices, but resulting in inconsistent\naudibility in the presence of human participants. In this paper, we propose a\nvoice de-identification system, which uses adversarial examples to balance the\nprivacy and utility of voice services. Instead of typical additive examples\ninducing perceivable distortions, we design a novel convolutional adversarial\nexample that modulates perturbations into real-world room impulse responses.\nBenefit from this, our system could preserve user identity from exposure by\nAutomatic Speaker Identification (ASI) while remaining the voice perceptual\nquality for non-intrusive de-identification. Moreover, our system learns a\ncompact speaker distribution through a conditional variational auto-encoder to\nsample diverse target embeddings on demand. Combining diverse target generation\nand input-specific perturbation construction, our system enables any-to-any\nidentify transformation for adaptive de-identification. Experimental results\nshow that our system could achieve 98% and 79% successful de-identification on\nmainstream ASIs and commercial systems with an objective Mel cepstral\ndistortion of 4.31dB and a subjective mean opinion score of 4.48.",
    "descriptor": "",
    "authors": [
      "Meng Chen",
      "Li Lu",
      "Jiadi Yu",
      "Yingying Chen",
      "Zhongjie Ba",
      "Feng Lin",
      "Kui Ren"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.05446"
  },
  {
    "id": "arXiv:2211.05448",
    "title": "On the Capacity of \"Beam-Pointing'' Channels with Block Memory and  Feedback: The Binary Case",
    "abstract": "Millimeter-wave (mmWave) communication is one of the key enablers for 5G\nsystems as it provides larger system bandwidth and the possibility of packing\nnumerous antennas in a small form factor for highly directional communication.\nIn order to materialize the potentially very high beamforming gain, the\ntransmitter and receiver beams need to be aligned. Practically, the\nAngle-of-Departure (AoD) remains almost constant over numerous consecutive time\nslots, which presents a state-dependent channel with memory. In addition, the\nbackscatter signal can be modeled as a (causal) generalized feedback. The\ncapacity of such channels with memory is generally an open problem in\ninformation theory. Towards solving this difficult problem, we consider a ``toy\nmodel'', consisting of a binary state-dependent (BSD) channel with in-block\nmemory (iBM) [1] and one unit-delayed feedback. The capacity of this model\nunder the peak transmission cost constraint is characterized by an iterative\nclosed-form expression. We propose a capacity-achieving scheme where the\ntransmitted signal carries information and meanwhile uniformly and randomly\nprobes the beams with the help of feedback.",
    "descriptor": "\nComments: 7 pages, 2 figures, this paper has been accepted by the 2022 Asilomar Conference on Signals, Systems, and Computers\n",
    "authors": [
      "Siyao Li",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.05448"
  },
  {
    "id": "arXiv:2211.05452",
    "title": "Towards Human-Centred Explainability Benchmarks For Text Classification",
    "abstract": "Progress on many Natural Language Processing (NLP) tasks, such as text\nclassification, is driven by objective, reproducible and scalable evaluation\nvia publicly available benchmarks. However, these are not always representative\nof real-world scenarios where text classifiers are employed, such as sentiment\nanalysis or misinformation detection. In this position paper, we put forward\ntwo points that aim to alleviate this problem. First, we propose to extend text\nclassification benchmarks to evaluate the explainability of text classifiers.\nWe review challenges associated with objectively evaluating the capabilities to\nproduce valid explanations which leads us to the second main point: We propose\nto ground these benchmarks in human-centred applications, for example by using\nsocial media, gamification or to learn explainability metrics from human\njudgements.",
    "descriptor": "\nComments: Accepted at NeatClass @ ICSWSM 2022\n",
    "authors": [
      "Viktor Schlegel",
      "Erick Mendez-Guzman",
      "Riza Batista-Navarro"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05452"
  },
  {
    "id": "arXiv:2211.05453",
    "title": "A noise based novel strategy for faster SNN training",
    "abstract": "Spiking neural networks (SNNs) are receiving increasing attention due to\ntheir low power consumption and strong bio-plausibility. Optimization of SNNs\nis a challenging task. Two main methods, artificial neural network (ANN)-to-SNN\nconversion and spike-based backpropagation (BP), both have their advantages and\nlimitations. For ANN-to-SNN conversion, it requires a long inference time to\napproximate the accuracy of ANN, thus diminishing the benefits of SNN. With\nspike-based BP, training high-precision SNNs typically consumes dozens of times\nmore computational resources and time than their ANN counterparts. In this\npaper, we propose a novel SNN training approach that combines the benefits of\nthe two methods. We first train a single-step SNN by approximating the neural\npotential distribution with random noise, then convert the single-step SNN to a\nmulti-step SNN losslessly. The introduction of Gaussian distributed noise leads\nto a significant gain in accuracy after conversion. The results show that our\nmethod considerably reduces the training and inference times of SNNs while\nmaintaining their high accuracy. Compared to the previous two methods, ours can\nreduce training time by 65%-75% and achieves more than 100 times faster\ninference speed. We also argue that the neuron model augmented with noise makes\nit more bio-plausible.",
    "descriptor": "",
    "authors": [
      "Chunming Jiang",
      "Yilei Zhang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05453"
  },
  {
    "id": "arXiv:2211.05455",
    "title": "Benchmark for Models Predicting Human Behavior in Gap Acceptance  Scenarios",
    "abstract": "Autonomous vehicles currently suffer from a time-inefficient driving style\ncaused by uncertainty about human behavior in traffic interactions. Accurate\nand reliable prediction models enabling more efficient trajectory planning\ncould make autonomous vehicles more assertive in such interactions. However,\nthe evaluation of such models is commonly oversimplistic, ignoring the\nasymmetric importance of prediction errors and the heterogeneity of the\ndatasets used for testing. We examine the potential of recasting interactions\nbetween vehicles as gap acceptance scenarios and evaluating models in this\nstructured environment. To that end, we develop a framework facilitating the\nevaluation of any model, by any metric, and in any scenario. We then apply this\nframework to state-of-the-art prediction models, which all show themselves to\nbe unreliable in the most safety-critical situations.",
    "descriptor": "\nComments: 11 pages, 5 figures, submitted to IEEE Transactions on Intelligent Vehicles\n",
    "authors": [
      "Julian Frederik Schumann",
      "Jens Kober",
      "Arkady Zgonnikov"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05455"
  },
  {
    "id": "arXiv:2211.05456",
    "title": "Review of Methods for Handling Class-Imbalanced in Classification  Problems",
    "abstract": "Learning classifiers using skewed or imbalanced datasets can occasionally\nlead to classification issues; this is a serious issue. In some cases, one\nclass contains the majority of examples while the other, which is frequently\nthe more important class, is nevertheless represented by a smaller proportion\nof examples. Using this kind of data could make many carefully designed\nmachine-learning systems ineffective. High training fidelity was a term used to\ndescribe biases vs. all other instances of the class. The best approach to all\npossible remedies to this issue is typically to gain from the minority class.\nThe article examines the most widely used methods for addressing the problem of\nlearning with a class imbalance, including data-level, algorithm-level, hybrid,\ncost-sensitive learning, and deep learning, etc. including their advantages and\nlimitations. The efficiency and performance of the classifier are assessed\nusing a myriad of evaluation metrics.",
    "descriptor": "",
    "authors": [
      "Satyendra Singh Rawat",
      "Amit Kumar Mishra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05456"
  },
  {
    "id": "arXiv:2211.05457",
    "title": "Syntax-Guided Domain Adaptation for Aspect-based Sentiment Analysis",
    "abstract": "Aspect-based sentiment analysis (ABSA) aims at extracting opinionated aspect\nterms in review texts and determining their sentiment polarities, which is\nwidely studied in both academia and industry. As a fine-grained classification\ntask, the annotation cost is extremely high. Domain adaptation is a popular\nsolution to alleviate the data deficiency issue in new domains by transferring\ncommon knowledge across domains. Most cross-domain ABSA studies are based on\nstructure correspondence learning (SCL), and use pivot features to construct\nauxiliary tasks for narrowing down the gap between domains. However, their\npivot-based auxiliary tasks can only transfer knowledge of aspect terms but not\nsentiment, limiting the performance of existing models. In this work, we\npropose a novel Syntax-guided Domain Adaptation Model, named SDAM, for more\neffective cross-domain ABSA. SDAM exploits syntactic structure similarities for\nbuilding pseudo training instances, during which aspect terms of target domain\nare explicitly related to sentiment polarities. Besides, we propose a\nsyntax-based BERT mask language model for further capturing domain-invariant\nfeatures. Finally, to alleviate the sentiment inconsistency issue in multi-gram\naspect terms, we introduce a span-based joint aspect term and sentiment\nanalysis module into the cross-domain End2End ABSA. Experiments on five\nbenchmark datasets show that our model consistently outperforms the\nstate-of-the-art baselines with respect to Micro-F1 metric for the cross-domain\nEnd2End ABSA task.",
    "descriptor": "",
    "authors": [
      "Anguo Dong",
      "Cuiyun Gao",
      "Yan Jia",
      "Qing Liao",
      "Xuan Wang",
      "Lei Wang",
      "Jing Xiao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.05457"
  },
  {
    "id": "arXiv:2211.05472",
    "title": "A rate-compatible solution to the set reconciliation problem",
    "abstract": "We consider a set reconciliation setting in which two parties hold similar\nsets which they would like to reconcile In particular, we focus on set\nreconciliation based on invertible Bloom lookup tables (IBLTs), a probabilistic\ndata structure inspired by Bloom filters but allowing for more complex\noperations. IBLT-based set reconciliation schemes have the advantage of\nexhibiting a low complexity, however, the schemes available in literature are\nknown to be far from optimal in terms of communication complexity (overhead).\nThe inefficiency of IBLT-based set reconciliation can be attributed to two\nfacts. First, it requires an estimate of the cardinality of the set difference\nbetween the sets, which implies an increase in overhead. Second, in order to\ncope with errors in the aforementioned estimation of the cardinality of the set\ndifference, IBLT schemes in literature make a worst-case assumption and\noversize the data structures, thus further increasing the overhead. In this\nwork, we present a novel IBLT-based set reconciliation protocol that does not\nrequire estimating the cardinality of the set difference. The scheme we propose\nrelies on what we term multi-edge-type (MET) IBLTs. The simulation results\nshown in this paper show that the novel scheme outperforms previous IBLT-based\napproaches to set reconciliation",
    "descriptor": "\nComments: Submitted for review\n",
    "authors": [
      "Francisco L\u00e1zaro",
      "Bal\u00e1zs Matuz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Databases (cs.DB)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.05472"
  },
  {
    "id": "arXiv:2211.05474",
    "title": "An O(loglog n)-Approximation for Submodular Facility Location",
    "abstract": "In the Submodular Facility Location problem (SFL) we are given a collection\nof $n$ clients and $m$ facilities in a metric space. A feasible solution\nconsists of an assignment of each client to some facility. For each client, one\nhas to pay the distance to the associated facility. Furthermore, for each\nfacility $f$ to which we assign the subset of clients $S^f$, one has to pay the\nopening cost $g(S^f)$, where $g(\\cdot)$ is a monotone submodular function with\n$g(\\emptyset)=0$.\nSFL is APX-hard since it includes the classical (metric uncapacitated)\nFacility Location problem (with uniform facility costs) as a special case.\nSvitkina and Tardos [SODA'06] gave the current-best $O(\\log n)$ approximation\nalgorithm for SFL. The same authors pose the open problem whether SFL admits a\nconstant approximation and provide such an approximation for a very restricted\nspecial case of the problem.\nWe make some progress towards the solution of the above open problem by\npresenting an $O(\\log\\log n)$ approximation. Our approach is rather flexible\nand can be easily extended to generalizations and variants of SFL. In more\ndetail, we achieve the same approximation factor for the practically relevant\ngeneralizations of SFL where the opening cost of each facility $f$ is of the\nform $p_f+g(S^f)$ or $w_f\\cdot g(S^f)$, where $p_f,w_f \\geq 0$ are input\nvalues.\nWe also obtain an improved approximation algorithm for the related Universal\nStochastic Facility Location problem. In this problem one is given a classical\n(metric) facility location instance and has to a priori assign each client to\nsome facility. Then a subset of active clients is sampled from some given\ndistribution, and one has to pay (a posteriori) only the connection and opening\ncosts induced by the active clients. The expected opening cost of each facility\n$f$ can be modelled with a submodular function of the set of clients assigned\nto $f$.",
    "descriptor": "\nComments: 24 pages, 1 algorithm, 1 figure\n",
    "authors": [
      "Fateme Abbasi",
      "Marek Adamczyk",
      "Miguel Bosch-Calvo",
      "Jaros\u0142aw Byrka",
      "Fabrizio Grandoni",
      "Krzysztof Sornat",
      "Antoine Tinguely"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.05474"
  },
  {
    "id": "arXiv:2211.05481",
    "title": "Event-Triggered Intermittent Prescribed Performance Control for  Spacecraft Attitude Reorientation",
    "abstract": "This paper focuses on the issue of how to realize spacecraft attitude control\nwith guaranteed performance while conspicuously reducing the actuator acting\nfrequency simultaneously. The prescribed performance control (PPC) scheme is\noften employed for the control with guaranteed performance. However,\nconventional PPC controllers are designed from the perspective of continuous\nsystem, which contradicts the \"discrete\" control logic in actual spacecraft\ncontrol system, and such a problem limited the application value of PPC scheme\nin actual applications. In order to significantly lower the actuator acting\nfrequency while still maintaining the desired performance, a composite\nevent-trigger mechanism is proposed for this issue, turning off the actuator\nand eliminating unnecessary control output under appropriate conditions.\nFurther, the proposed composite event-trigger mechanism is combined with a\nprescribed performance control scheme, constructing a complete controller\nstructure for solving the presented issue. Meanwhile, a special performance\nfunction is designed to provide mild transition process. Based on the proposed\nscheme, a specific backstepping controller is further developed as a\nvalidation. Finally, numerical simulation results are presented to validate the\neffectiveness of the proposed scheme.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Jiakun Lei",
      "Tao Meng",
      "Kun Wang",
      "Weijia Wang",
      "Zhonghe Jin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.05481"
  },
  {
    "id": "arXiv:2211.05483",
    "title": "Unsupervised Deep Learning-based clustering for Human Activity  Recognition",
    "abstract": "One of the main problems in applying deep learning techniques to recognize\nactivities of daily living (ADLs) based on inertial sensors is the lack of\nappropriately large labelled datasets to train deep learning-based models. A\nlarge amount of data would be available due to the wide spread of mobile\ndevices equipped with inertial sensors that can collect data to recognize human\nactivities. Unfortunately, this data is not labelled. The paper proposes DISC\n(Deep Inertial Sensory Clustering), a DL-based clustering architecture that\nautomatically labels multi-dimensional inertial signals. In particular, the\narchitecture combines a recurrent AutoEncoder and a clustering criterion to\npredict unlabelled human activities-related signals. The proposed architecture\nis evaluated on three publicly available HAR datasets and compared with four\nwell-known end-to-end deep clustering approaches. The experiments demonstrate\nthe effectiveness of DISC on both clustering accuracy and normalized mutual\ninformation metrics.",
    "descriptor": "\nComments: 2022 IEEE 12th International Conference on Consumer Electronics (ICCE-Berlin)\n",
    "authors": [
      "Hamza Amrani",
      "Daniela Micucci",
      "Paolo Napoletano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05483"
  },
  {
    "id": "arXiv:2211.05485",
    "title": "Understanding Text Classification Data and Models Using Aggregated Input  Salience",
    "abstract": "Realizing when a model is right for a wrong reason is not trivial and\nrequires a significant effort by model developers. In some cases, an input\nsalience method, which highlights the most important parts of the input, may\nreveal problematic reasoning. But scrutinizing highlights over many data\ninstances is tedious and often infeasible. Furthermore, analyzing examples in\nisolation does not reveal general patterns in the data or in the model's\nbehavior.In this paper we aim to address these issues and go from understanding\nsingle examples to understanding entire datasets and models. The methodology we\npropose is based on aggregated salience maps. Using this methodology we address\nmultiple distinct but common model developer needs by showing how problematic\ndata and model behavior can be identified -- a necessary first step for\nimproving the model.",
    "descriptor": "",
    "authors": [
      "Sebastian Ebert",
      "Alice Shoshana Jakobovits",
      "Katja Filippova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05485"
  },
  {
    "id": "arXiv:2211.05486",
    "title": "HSGNet: Object Re-identification with Hierarchical Similarity Graph  Network",
    "abstract": "Object re-identification method is made up of backbone network, feature\naggregation, and loss function. However, most backbone networks lack a special\nmechanism to handle rich scale variations and mine discriminative feature\nrepresentations. In this paper, we firstly design a hierarchical similarity\ngraph module (HSGM) to reduce the conflict of backbone and re-identification\nnetworks. The designed HSGM builds a rich hierarchical graph to mine the\nmapping relationships between global-local and local-local. Secondly, we divide\nthe feature map along with the spatial and channel directions in each\nhierarchical graph. The HSGM applies the spatial features and channel features\nextracted from different locations as nodes, respectively, and utilizes the\nsimilarity scores between nodes to construct spatial and channel similarity\ngraphs. During the learning process of HSGM, we utilize a learnable parameter\nto re-optimize the importance of each position, as well as evaluate the\ncorrelation between different nodes. Thirdly, we develop a novel hierarchical\nsimilarity graph network (HSGNet) by embedding the HSGM in the backbone\nnetwork. Furthermore, HSGM can be easily embedded into backbone networks of any\ndepth to improve object re-identification ability. Finally, extensive\nexperiments on three large-scale object datasets demonstrate that the proposed\nHSGNet is superior to state-of-the-art object re-identification approaches.",
    "descriptor": "",
    "authors": [
      "Fei Shen",
      "Mengwan Wei",
      "Junchi Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05486"
  },
  {
    "id": "arXiv:2211.05488",
    "title": "ClassPruning: Speed Up Image Restoration Networks by Dynamic N:M Pruning",
    "abstract": "Image restoration tasks have achieved tremendous performance improvements\nwith the rapid advancement of deep neural networks. However, most prevalent\ndeep learning models perform inference statically, ignoring that different\nimages have varying restoration difficulties and lightly degraded images can be\nwell restored by slimmer subnetworks. To this end, we propose a new solution\npipeline dubbed ClassPruning that utilizes networks with different capabilities\nto process images with varying restoration difficulties. In particular, we use\na lightweight classifier to identify the image restoration difficulty, and then\nthe sparse subnetworks with different capabilities can be sampled based on\npredicted difficulty by performing dynamic N:M fine-grained structured pruning\non base restoration networks. We further propose a novel training strategy\nalong with two additional loss terms to stabilize training and improve\nperformance. Experiments demonstrate that ClassPruning can help existing\nmethods save approximately 40% FLOPs while maintaining performance.",
    "descriptor": "",
    "authors": [
      "Yang Zhou",
      "Yuda Song",
      "Hui Qian",
      "Xin Du"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05488"
  },
  {
    "id": "arXiv:2211.05489",
    "title": "Reconstruction and analysis of negatively buoyant jets with  interpretable machine learning",
    "abstract": "In this paper, negatively inclined buoyant jets, which appear during the\ndischarge of wastewater from processes such as desalination, are observed. To\nminimize harmful effects and assess environmental impact, a detailed numerical\ninvestigation is necessary. The selection of appropriate geometry and working\nconditions for minimizing such effects often requires numerous experiments and\nnumerical simulations. For this reason, the application of machine learning\nmodels is proposed. Several models including Support Vector Regression,\nArtificial Neural Networks, Random Forests, XGBoost, CatBoost and LightGBM were\ntrained. The dataset was built with numerous OpenFOAM simulations, which were\nvalidated by experimental data from previous research. The best prediction was\nobtained by Artificial Neural Network with an average of R2 0.98 and RMSE 0.28.\nIn order to understand the working of the machine learning model and the\ninfluence of all parameters on the geometrical characteristics of inclined\nbuoyant jets, the SHAP feature interpretation method was used.",
    "descriptor": "",
    "authors": [
      "Marta Alvir",
      "Luka Grb\u010di\u0107",
      "Ante Sikirica",
      "Lado Kranj\u010devi\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Fluid Dynamics (physics.flu-dyn)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.05489"
  },
  {
    "id": "arXiv:2211.05494",
    "title": "Two conjectures on the Stokes complex in three dimensions on Freudenthal  meshes",
    "abstract": "In recent years a great deal of attention has been paid to discretizations of\nthe incompressible Stokes equations that exactly preserve the incompressibility\nconstraint. These are of substantial interest because these discretizations are\npressure-robust, i.e. the error estimates for the velocity do not depend on the\nerror in the pressure. Similar considerations arise in nearly incompressible\nlinear elastic solids. Conforming discretizations with this property are now\nwell understood in two dimensions, but remain poorly understood in three\ndimensions. In this work we state two conjectures on this subject. The first is\nthat the Scott-Vogelius element pair is inf-sup stable on uniform meshes for\nvelocity degree $k \\ge 4$; the best result available in the literature is for\n$k \\ge 6$. The second is that there exists a stable space decomposition of the\nkernel of the divergence for $k \\ge 5$. We present numerical evidence\nsupporting our conjectures.",
    "descriptor": "",
    "authors": [
      "Patrick E. Farrell",
      "Lawrence Mitchell",
      "L. Ridgway Scott"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.05494"
  },
  {
    "id": "arXiv:2211.05495",
    "title": "Adaptive Real Time Exploration and Optimization for Safety-Critical  Systems",
    "abstract": "We consider the problem of decision-making under uncertainty in an\nenvironment with safety constraints. Many business and industrial applications\nrely on real-time optimization with changing inputs to improve key performance\nindicators. In the case of unknown environmental characteristics, real-time\noptimization becomes challenging, particularly for the satisfaction of safety\nconstraints. We propose the ARTEO algorithm, where we cast multi-armed bandits\nas a mathematical programming problem subject to safety constraints and learn\nthe environmental characteristics through changes in optimization inputs and\nthrough exploration. We quantify the uncertainty in unknown characteristics by\nusing Gaussian processes and incorporate it into the utility function as a\ncontribution which drives exploration. We adaptively control the size of this\ncontribution using a heuristic in accordance with the requirements of the\nenvironment. We guarantee the safety of our algorithm with a high probability\nthrough confidence bounds constructed under the regularity assumptions of\nGaussian processes. Compared to existing safe-learning approaches, our\nalgorithm does not require an exclusive exploration phase and follows the\noptimization goals even in the explored points, which makes it suitable for\nsafety-critical systems. We demonstrate the safety and efficiency of our\napproach with two experiments: an industrial process and an online bid\noptimization benchmark problem.",
    "descriptor": "",
    "authors": [
      "Buse Sibel Korkmaz",
      "Mehmet Mercang\u00f6z",
      "Marta Zag\u00f3rowska"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.05495"
  },
  {
    "id": "arXiv:2211.05496",
    "title": "Error bound analysis of the stochastic parareal algorithm",
    "abstract": "Stochastic parareal (SParareal) is a probabilistic variant of the popular\nparallel-in-time algorithm known as parareal. Similarly to parareal, it\ncombines fine- and coarse-grained solutions to an ordinary differential\nequation (ODE) using a predictor-corrector (PC) scheme. The key difference is\nthat carefully chosen random perturbations are added to the PC to try to\naccelerate the location of a stochastic solution to the ODE. In this paper, we\nderive superlinear and linear mean-square error bounds for SParareal applied to\nnonlinear systems of ODEs using different types of perturbations. We illustrate\nthese bounds numerically on a linear system of ODEs and a scalar nonlinear ODE,\nshowing a good match between theory and numerics.",
    "descriptor": "",
    "authors": [
      "Kamran Pentland",
      "Massimiliano Tamborrino",
      "T. J. Sullivan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.05496"
  },
  {
    "id": "arXiv:2211.05497",
    "title": "Effect of Device Mismatches in Differential Oscillatory Neural Networks",
    "abstract": "Analog implementation of Oscillatory Neural Networks (ONNs) has the potential\nto implement fast and ultra-low-power computing capabilities. One of the\ndrawbacks of analog implementation is component mismatches which cause\ndesynchronization and instability in ONNs. Emerging devices like memristors and\nVO2 are particularly prone to variations. In this paper, we study the effect of\ncomponent mismatches on the performance of differential ONNs (DONNs).\nMismatches were considered in two main blocks: differential oscillatory neurons\nand synaptic circuits. To measure DONN tolerance to mismatches in each block,\nperformance was evaluated with mismatches being present separately in each\nblock. Memristor-bridge circuits with four memristors were used as the synaptic\ncircuits. The differential oscillatory neurons were based on VO2-devices. The\nsimulation results showed that DONN performance was more vulnerable to\nmismatches in the components of the differential oscillatory neurons than to\nmismatches in the synaptic circuits. DONNs were found to tolerate up to 20%\nmismatches in the memristance of the synaptic circuits. However, mismatches in\nthe differential oscillatory neurons resulted in non-uniformity of the natural\nfrequencies, causing desynchronization and instability. Simulations showed that\n0.5% relative standard deviation (RSD) in natural frequencies can reduce DONN\nperformance dramatically. In addition, sensitivity analyses showed that the\nhigh threshold voltage of VO2-devices is the most sensitive parameter for\nfrequency non-uniformity and desynchronization.",
    "descriptor": "\nComments: accepted for IEEE TCASI\n",
    "authors": [
      "Jafar Shamsi",
      "Mar\u00eda Jos\u00e9 Avedillo",
      "Bernab\u00e9 Linares-Barranco",
      "Teresa Serrano-Gotarredona"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.05497"
  },
  {
    "id": "arXiv:2211.05499",
    "title": "DisPositioNet: Disentangled Pose and Identity in Semantic Image  Manipulation",
    "abstract": "Graph representation of objects and their relations in a scene, known as a\nscene graph, provides a precise and discernible interface to manipulate a scene\nby modifying the nodes or the edges in the graph. Although existing works have\nshown promising results in modifying the placement and pose of objects, scene\nmanipulation often leads to losing some visual characteristics like the\nappearance or identity of objects. In this work, we propose DisPositioNet, a\nmodel that learns a disentangled representation for each object for the task of\nimage manipulation using scene graphs in a self-supervised manner. Our\nframework enables the disentanglement of the variational latent embeddings as\nwell as the feature representation in the graph. In addition to producing more\nrealistic images due to the decomposition of features like pose and identity,\nour method takes advantage of the probabilistic sampling in the intermediate\nfeatures to generate more diverse images in object replacement or addition\ntasks. The results of our experiments show that disentangling the feature\nrepresentations in the latent manifold of the model outperforms the previous\nworks qualitatively and quantitatively on two public benchmarks. Project Page:\nhttps://scenegenie.github.io/DispositioNet/",
    "descriptor": "\nComments: Accepted to BMVC 2022\n",
    "authors": [
      "Azade Farshad",
      "Yousef Yeganeh",
      "Helisa Dhamo",
      "Federico Tombari",
      "Nassir Navab"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05499"
  },
  {
    "id": "arXiv:2211.05500",
    "title": "Reinforcement Learning in an Adaptable Chess Environment for Detecting  Human-understandable Concepts",
    "abstract": "Self-trained autonomous agents developed using machine learning are showing\ngreat promise in a variety of control settings, perhaps most remarkably in\napplications involving autonomous vehicles. The main challenge associated with\nself-learned agents in the form of deep neural networks, is their black-box\nnature: it is impossible for humans to interpret deep neural networks.\nTherefore, humans cannot directly interpret the actions of deep neural network\nbased agents, or foresee their robustness in different scenarios. In this work,\nwe demonstrate a method for probing which concepts self-learning agents\ninternalise in the course of their training. For demonstration, we use a chess\nplaying agent in a fast and light environment developed specifically to be\nsuitable for research groups without access to enormous computational resources\nor machine learning models.",
    "descriptor": "\nComments: For associated code, see this https URL\n",
    "authors": [
      "Patrik Hammersborg",
      "Inga Str\u00fcmke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.05500"
  },
  {
    "id": "arXiv:2211.05503",
    "title": "MoNET: Tackle State Momentum via Noise-Enhanced Training for Dialogue  State Tracking",
    "abstract": "Dialogue state tracking (DST) aims to convert the dialogue history into\ndialogue states which consist of slot-value pairs. As condensed structural\ninformation memorizing all history information, the dialogue state in the last\nturn is typically adopted as the input for predicting the current state by DST\nmodels. However, these models tend to keep the predicted slot values unchanged,\nwhich is defined as state momentum in this paper. Specifically, the models\nstruggle to update slot values that need to be changed and correct wrongly\npredicted slot values in the last turn. To this end, we propose MoNET to tackle\nstate momentum via noise-enhanced training. First, the previous state of each\nturn in the training data is noised via replacing some of its slot values.\nThen, the noised previous state is used as the input to learn to predict the\ncurrent state, improving the model's ability to update and correct slot values.\nFurthermore, a contrastive context matching framework is designed to narrow the\nrepresentation distance between a state and its corresponding noised variant,\nwhich reduces the impact of noised state and makes the model better understand\nthe dialogue history. Experimental results on MultiWOZ datasets show that MoNET\noutperforms previous DST methods. Ablations and analysis verify the\neffectiveness of MoNET in alleviating state momentum and improving anti-noise\nability.",
    "descriptor": "\nComments: 8 pages, 6 figures, 3 tables\n",
    "authors": [
      "Haoning Zhang",
      "Junwei Bao",
      "Haipeng Sun",
      "Youzheng Wu",
      "Wenye Li",
      "Shuguang Cui",
      "Xiaodong He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05503"
  },
  {
    "id": "arXiv:2211.05507",
    "title": "Experimental analysis regarding the influence of iris segmentation on  the recognition rate",
    "abstract": "In this study the authors will look at the detection and segmentation of the\niris and its influence on the overall performance of the iris-biometric tool\nchain. The authors will examine whether the segmentation accuracy, based on\nconformance with a ground truth, can serve as a predictor for the overall\nperformance of the iris-biometric tool chain. That is: If the segmentation\naccuracy is improved will this always improve the overall performance?\nFurthermore, the authors will systematically evaluate the influence of\nsegmentation parameters, pupillary and limbic boundary and normalisation centre\n(based on Daugman's rubbersheet model), on the rest of the iris-biometric tool\nchain. The authors will investigate if accurately finding these parameters is\nimportant and how consistency, that is, extracting the same exact region of the\niris during segmenting, influences the overall performance.",
    "descriptor": "\nComments: Published at IET Biometrics\n",
    "authors": [
      "Heinz Hofbauer",
      "Fernando Alonso-Fernandez",
      "Josef Bigun",
      "Andreas Uhl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.05507"
  },
  {
    "id": "arXiv:2211.05509",
    "title": "Discrepancy Minimization via Regularization",
    "abstract": "We introduce a new algorithmic framework for discrepancy minimization based\non regularization. We demonstrate how varying the regularizer allows us to\nre-interpret several breakthrough works in algorithmic discrepancy, ranging\nfrom Spencer's theorem [Spencer 1985, Bansal 2010] to Banaszczyk's bounds\n[Banaszczyk 1998, Bansal-Dadush-Garg 2016]. Using our techniques, we also show\nthat the Beck-Fiala and Koml\\'os conjectures are true in a new regime of\npseudorandom instances.",
    "descriptor": "\nComments: SODA 2023\n",
    "authors": [
      "Lucas Pesenti",
      "Adrian Vladu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.05509"
  },
  {
    "id": "arXiv:2211.05513",
    "title": "Coding Schemes Based on Reed-Muller Codes for $(d,\\infty)$-RLL  Input-Constrained Channels",
    "abstract": "The paper considers coding schemes derived from Reed-Muller (RM) codes, for\ntransmission over input-constrained memoryless channels. Our focus is on the\n$(d,\\infty)$-runlength limited (RLL) constraint, which mandates that any pair\nof successive $1$s be separated by at least $d$ $0$s. In our study, we first\nconsider $(d,\\infty)$-RLL subcodes of RM codes, taking the coordinates of the\nRM codes to be in the standard lexicographic ordering. We show, via a simple\nconstruction, that RM codes of rate $R$ have linear $(d,\\infty)$-RLL subcodes\nof rate $R\\cdot{2^{-\\left \\lceil \\log_2(d+1)\\right \\rceil}}$. We then show that\nour construction is essentially rate-optimal, by deriving an upper bound on the\nrates of linear $(d,\\infty)$-RLL subcodes of RM codes of rate $R$. Next, for\nthe special case when $d=1$, we prove the existence of potentially non-linear\n$(1,\\infty)$-RLL subcodes that achieve a rate of\n$\\max\\left(0,R-\\frac38\\right)$. This, for $R > 3/4$, beats the $R/2$ rate\nobtainable from linear subcodes. We further derive upper bounds on the rates of\n$(1,\\infty)$-RLL subcodes, not necessarily linear, of a certain canonical\nsequence of RM codes of rate $R$. We then shift our attention to settings where\nthe coordinates of the RM code are not ordered according to the lexicographic\nordering, and derive rate upper bounds for linear $(d,\\infty)$-RLL subcodes in\nthese cases as well. Finally, we present a new two-stage constrained coding\nscheme, again using RM codes of rate $R$, which outperforms any linear coding\nscheme using $(d,\\infty)$-RLL subcodes, for values of $R$ close to $1$.",
    "descriptor": "\nComments: 38 pages, 7 figures, submitted to the IEEE Transactions on Information Theory. arXiv admin note: text overlap with arXiv:2205.04153\n",
    "authors": [
      "V. Arvind Rameshwar",
      "Navin Kashyap"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.05513"
  },
  {
    "id": "arXiv:2211.05516",
    "title": "Training and Serving Machine Learning Models at Scale",
    "abstract": "In recent years, Web services are becoming more and more intelligent (e.g.,\nin understanding user preferences) thanks to the integration of components that\nrely on Machine Learning (ML). Before users can interact (inference phase) with\nan ML-based service (ML-Service), the underlying ML model must learn (training\nphase) from existing data, a process that requires long-lasting batch\ncomputations. The management of these two, diverse phases is complex and\nmeeting time and quality requirements can hardly be done with manual\napproaches.\nThis paper highlights some of the major issues in managing ML-services in\nboth training and inference modes and presents some initial solutions that are\nable to meet set requirements with minimum user inputs. A preliminary\nevaluation demonstrates that our solutions allow these systems to become more\nefficient and predictable with respect to their response time and accuracy.",
    "descriptor": "",
    "authors": [
      "Luciano Baresi",
      "Giovanni Quattrocchi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.05516"
  },
  {
    "id": "arXiv:2211.05520",
    "title": "Unravelling the Performance of Physics-informed Graph Neural Networks  for Dynamical Systems",
    "abstract": "Recently, graph neural networks have been gaining a lot of attention to\nsimulate dynamical systems due to their inductive nature leading to zero-shot\ngeneralizability. Similarly, physics-informed inductive biases in deep-learning\nframeworks have been shown to give superior performance in learning the\ndynamics of physical systems. There is a growing volume of literature that\nattempts to combine these two approaches. Here, we evaluate the performance of\nthirteen different graph neural networks, namely, Hamiltonian and Lagrangian\ngraph neural networks, graph neural ODE, and their variants with explicit\nconstraints and different architectures. We briefly explain the theoretical\nformulation highlighting the similarities and differences in the inductive\nbiases and graph architecture of these systems. We evaluate these models on\nspring, pendulum, gravitational, and 3D deformable solid systems to compare the\nperformance in terms of rollout error, conserved quantities such as energy and\nmomentum, and generalizability to unseen system sizes. Our study demonstrates\nthat GNNs with additional inductive biases, such as explicit constraints and\ndecoupling of kinetic and potential energies, exhibit significantly enhanced\nperformance. Further, all the physics-informed GNNs exhibit zero-shot\ngeneralizability to system sizes an order of magnitude larger than the training\nsystem, thus providing a promising route to simulate large-scale realistic\nsystems.",
    "descriptor": "\nComments: Accepted at 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Abishek Thangamuthu",
      "Gunjan Kumar",
      "Suresh Bishnoi",
      "Ravinder Bhattoo",
      "N M Anoop Krishnan",
      "Sayan Ranu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.05520"
  },
  {
    "id": "arXiv:2211.05521",
    "title": "Zero-shot Visual Commonsense Immorality Prediction",
    "abstract": "Artificial intelligence is currently powering diverse real-world\napplications. These applications have shown promising performance, but raise\ncomplicated ethical issues, i.e. how to embed ethics to make AI applications\nbehave morally. One way toward moral AI systems is by imitating human prosocial\nbehavior and encouraging some form of good behavior in systems. However,\nlearning such normative ethics (especially from images) is challenging mainly\ndue to a lack of data and labeling complexity. Here, we propose a model that\npredicts visual commonsense immorality in a zero-shot manner. We train our\nmodel with an ETHICS dataset (a pair of text and morality annotation) via a\nCLIP-based image-text joint embedding. In a testing phase, the immorality of an\nunseen image is predicted. We evaluate our model with existing moral/immoral\nimage datasets and show fair prediction performance consistent with human\nintuitions. Further, we create a visual commonsense immorality benchmark with\nmore general and extensive immoral visual contents. Codes and dataset are\navailable at\nhttps://github.com/ku-vai/Zero-shot-Visual-Commonsense-Immorality-Prediction.\nNote that this paper might contain images and descriptions that are offensive\nin nature.",
    "descriptor": "\nComments: BMVC2022\n",
    "authors": [
      "Yujin Jeong",
      "Seongbeom Park",
      "Suhong Moon",
      "Jinkyu Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.05521"
  },
  {
    "id": "arXiv:2211.05522",
    "title": "Distributed Precoding Design for Multi-Group Multicasting in Cell-Free  Massive MIMO",
    "abstract": "We consider multi-group multicast precoding designs for cell-free massive\nmultiple-input multiple-output (MIMO) systems. To optimize the transmit and\nreceive beamforming strategies, we focus on minimizing the sum of the maximum\nmean squared errors (MSEs) over the multicast groups, which is then\napproximated with the sum MSE to simplify the computation and signaling. We\nadopt an iterative bi-directional training scheme with uplink and downlink\nprecoded pilots to cooperatively design the multi-group multicast precoders at\neach base station and the combiners at each user equipment in a distributed\nfashion. An additional group-specific uplink training resource is introduced,\nwhich entirely eliminates the need for backhaul signaling for channel state\ninformation (CSI) exchange. We also propose a simpler distributed precoding\ndesign based solely on group-specific pilots, which can be useful in the case\nof scarce training resources. Numerical results show that the proposed\ndistributed methods greatly outperform conventional cell-free massive MIMO\nprecoding designs that rely solely on local CSI.",
    "descriptor": "\nComments: To be presented at GLOBECOM 2022, Dec. 2022\n",
    "authors": [
      "Bikshapathi Gouda",
      "Italo Atzeni",
      "Antti T\u00f6lli"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.05522"
  },
  {
    "id": "arXiv:2211.05523",
    "title": "Impact of Adversarial Training on Robustness and Generalizability of  Language Models",
    "abstract": "Adversarial training is widely acknowledged as the most effective defense\nagainst adversarial attacks. However, it is also well established that\nachieving both robustness and generalization in adversarially trained models\ninvolves a trade-off. The goal of this work is to provide an in depth\ncomparison of different approaches for adversarial training in language models.\nSpecifically, we study the effect of pre-training data augmentation as well as\ntraining time input perturbations vs. embedding space perturbations on the\nrobustness and generalization of BERT-like language models. Our findings\nsuggest that better robustness can be achieved by pre-training data\naugmentation or by training with input space perturbation. However, training\nwith embedding space perturbation significantly improves generalization. A\nlinguistic correlation analysis of neurons of the learned models reveal that\nthe improved generalization is due to `more specialized' neurons. To the best\nof our knowledge, this is the first work to carry out a deep qualitative\nanalysis of different methods of generating adversarial examples in adversarial\ntraining of language models.",
    "descriptor": "",
    "authors": [
      "Enes Altinisik",
      "Hassan Sajjad",
      "Husrev Taha Sencar",
      "Safa Messaoud",
      "Sanjay Chawla"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.05523"
  },
  {
    "id": "arXiv:2211.05525",
    "title": "MGiaD: Multigrid in all dimensions. Efficiency and robustness by  coarsening in resolution and channel dimensions",
    "abstract": "Current state-of-the-art deep neural networks for image classification are\nmade up of 10 - 100 million learnable weights and are therefore inherently\nprone to overfitting. The complexity of the weight count can be seen as a\nfunction of the number of channels, the spatial extent of the input and the\nnumber of layers of the network. Due to the use of convolutional layers the\nscaling of weight complexity is usually linear with regards to the resolution\ndimensions, but remains quadratic with respect to the number of channels.\nActive research in recent years in terms of using multigrid inspired ideas in\ndeep neural networks have shown that on one hand a significant number of\nweights can be saved by appropriate weight sharing and on the other that a\nhierarchical structure in the channel dimension can improve the weight\ncomplexity to linear. In this work, we combine these multigrid ideas to\nintroduce a joint framework of multigrid inspired architectures, that exploit\nmultigrid structures in all relevant dimensions to achieve linear weight\ncomplexity scaling and drastically reduced weight counts. Our experiments show\nthat this structured reduction in weight count is able to reduce overfitting\nand thus shows improved performance over state-of-the-art ResNet architectures\non typical image classification benchmarks at lower network complexity.",
    "descriptor": "",
    "authors": [
      "Antonia van Betteray",
      "Matthias Rottmann",
      "Karsten Kahl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05525"
  },
  {
    "id": "arXiv:2211.05527",
    "title": "Massive MIMO Channel Measurement Data Set for Localization and  Communication",
    "abstract": "Channel state information (CSI) needs to be estimated for reliable and\nefficient communication, however, location information is hidden inside and can\nbe further exploited. This article presents a detailed description of a Massive\nMulti-Input Multi-Output (MaMIMO) testbed and provides a set of experimental\nlocation-labelled CSI data. In this article, we focus on the design of the\nhardware and software of a MaMIMO testbed for gathering multiple CSI data sets.\nWe also show this data can be used for learning-based localization and enhanced\ncommunication research. The data set presented in this work is made fully\navailable to the research community. We show a CSI-based joint communication\nand sensing processing pipeline can be evaluated and designed based on the\ncollected data set. Specifically, the localization output obtained by a\nconvolutional neural network (CNN) trained on the data sets is used to schedule\nusers for improving the spectral efficiency (SE) of the communication system.\nFinally, we pose promising directions on further exploiting this data set and\ncreating future data sets.",
    "descriptor": "\nComments: 7 pages, 3 figures, 1 table\n",
    "authors": [
      "Achiel Colpaert",
      "Sibren De Bast",
      "Andrea P. Guevara",
      "Zhuangzhuang Cui",
      "Sofie Pollin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.05527"
  },
  {
    "id": "arXiv:2211.05528",
    "title": "Cherry Hypothesis: Identifying the Cherry on the Cake for Dynamic  Networks",
    "abstract": "Dynamic networks have been extensively explored as they can considerably\nimprove the model's representation power with acceptable computational cost.\nThe common practice in implementing dynamic networks is to convert given static\nlayers into fully dynamic ones where all parameters are dynamic and vary with\nthe input. Recent studies empirically show the trend that the more dynamic\nlayers contribute to ever-increasing performance. However, such a fully dynamic\nsetting 1) may cause redundant parameters and high deployment costs, limiting\nthe applicability of dynamic networks to a broader range of tasks and models,\nand more importantly, 2) contradicts the previous discovery in the human brain\nthat \\textit{when human brains process an attention-demanding task, only\npartial neurons in the task-specific areas are activated by the input, while\nthe rest neurons leave in a baseline state.} Critically, there is no effort to\nunderstand and resolve the above contradictory finding, leaving the primal\nquestion -- to make the computational parameters fully dynamic or not? --\nunanswered. The main contributions of our work are challenging the basic\ncommonsense in dynamic networks, and, proposing and validating the\n\\textsc{cherry hypothesis} -- \\textit{A fully dynamic network contains a subset\nof dynamic parameters that when transforming other dynamic parameters into\nstatic ones, can maintain or even exceed the performance of the original\nnetwork.} Technically, we propose a brain-inspired partially dynamic network,\nnamely PAD-Net, to transform the redundant dynamic parameters into static ones.\nAlso, we further design Iterative Mode Partition to partition the dynamic- and\nstatic-subnet, which alleviates the redundancy in traditional fully dynamic\nnetworks. Our hypothesis and method are comprehensively supported by\nlarge-scale experiments with typical advanced dynamic methods.",
    "descriptor": "",
    "authors": [
      "Shwai He",
      "Liang Ding",
      "Daize Dong",
      "Boan Liu",
      "Fuqiang Yu",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05528"
  },
  {
    "id": "arXiv:2211.05529",
    "title": "Less Carbon Footprint in Edge Computing by Joint Task Offloading and  Energy Sharing",
    "abstract": "In sprite the state-of-the-art, significantly reducing carbon footprint (CF)\nin communications systems remains urgent. We address this challenge in the\ncontext of edge computing. The carbon intensity of electricity supply largely\nvaries spatially as well as temporally. This, together with energy sharing via\na battery management system (BMS), justifies the potential of CF-oriented task\noffloading, by redistributing the computational tasks in time and space. In\nthis paper, we consider optimal task scheduling and offloading, as well as\nbattery charging to minimize the total CF. We formulate this CF minimization\nproblem as an integer linear programming model. However, we demonstrate that,\nvia a graph-based reformulation, the problem can be cast as a minimum-cost flow\nproblem. This finding reveals that global optimum can be admitted in polynomial\ntime. Numerical results using real-world data show that optimization can reduce\nup to 83.3% of the total CF.",
    "descriptor": "",
    "authors": [
      "Zhanwei Yu",
      "Yi Zhao",
      "Tao Deng",
      "Lei You",
      "Di Yuan"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.05529"
  },
  {
    "id": "arXiv:2211.05530",
    "title": "Side-Informed Steganography for JPEG Images by Modeling Decompressed  Images",
    "abstract": "Side-informed steganography has always been among the most secure approaches\nin the field. However, a majority of existing methods for JPEG images use the\nside information, here the rounding error, in a heuristic way. For the first\ntime, we show that the usefulness of the rounding error comes from its\ncovariance with the embedding changes. Unfortunately, this covariance between\ncontinuous and discrete variables is not analytically available. An estimate of\nthe covariance is proposed, which allows to model steganography as a change in\nthe variance of DCT coefficients. Since steganalysis today is best performed in\nthe spatial domain, we derive a likelihood ratio test to preserve a model of a\ndecompressed JPEG image. The proposed method then bounds the power of this test\nby minimizing the Kullback-Leibler divergence between the cover and stego\ndistributions. We experimentally demonstrate in two popular datasets that it\nachieves state-of-the-art performance against deep learning detectors.\nMoreover, by considering a different pixel variance estimator for images\ncompressed with Quality Factor 100, even greater improvements are obtained.",
    "descriptor": "\nComments: 13 pages, 7 figures, 1 table, submitted to IEEE Transactions on Information Forensics & Security\n",
    "authors": [
      "Jan Butora",
      "Patrick Bas"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Cryptography and Security (cs.CR)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.05530"
  },
  {
    "id": "arXiv:2211.05531",
    "title": "SWTF: Sparse Weighted Temporal Fusion for Drone-Based Activity  Recognition",
    "abstract": "Drone-camera based human activity recognition (HAR) has received significant\nattention from the computer vision research community in the past few years. A\nrobust and efficient HAR system has a pivotal role in fields like video\nsurveillance, crowd behavior analysis, sports analysis, and human-computer\ninteraction. What makes it challenging are the complex poses, understanding\ndifferent viewpoints, and the environmental scenarios where the action is\ntaking place. To address such complexities, in this paper, we propose a novel\nSparse Weighted Temporal Fusion (SWTF) module to utilize sparsely sampled video\nframes for obtaining global weighted temporal fusion outcome. The proposed SWTF\nis divided into two components. First, a temporal segment network that sparsely\nsamples a given set of frames. Second, weighted temporal fusion, that\nincorporates a fusion of feature maps derived from optical flow, with raw RGB\nimages. This is followed by base-network, which comprises a convolutional\nneural network module along with fully connected layers that provide us with\nactivity recognition. The SWTF network can be used as a plug-in module to the\nexisting deep CNN architectures, for optimizing them to learn temporal\ninformation by eliminating the need for a separate temporal stream. It has been\nevaluated on three publicly available benchmark datasets, namely Okutama,\nMOD20, and Drone-Action. The proposed model has received an accuracy of 72.76%,\n92.56%, and 78.86% on the respective datasets thereby surpassing the previous\nstate-of-the-art performances by a significant margin.",
    "descriptor": "",
    "authors": [
      "Santosh Kumar Yadav",
      "Esha Pahwa",
      "Achleshwar Luthra",
      "Kamlesh Tiwari",
      "Hari Mohan Pandey",
      "Peter Corcoran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05531"
  },
  {
    "id": "arXiv:2211.05533",
    "title": "GREENER: Graph Neural Networks for News Media Profiling",
    "abstract": "We study the problem of profiling news media on the Web with respect to their\nfactuality of reporting and bias. This is an important but under-studied\nproblem related to disinformation and \"fake news\" detection, but it addresses\nthe issue at a coarser granularity compared to looking at an individual article\nor an individual claim. This is useful as it allows to profile entire media\noutlets in advance. Unlike previous work, which has focused primarily on text\n(e.g.,~on the text of the articles published by the target website, or on the\ntextual description in their social media profiles or in Wikipedia), here our\nmain focus is on modeling the similarity between media outlets based on the\noverlap of their audience. This is motivated by homophily considerations,\ni.e.,~the tendency of people to have connections to people with similar\ninterests, which we extend to media, hypothesizing that similar types of media\nwould be read by similar kinds of users. In particular, we propose GREENER\n(GRaph nEural nEtwork for News mEdia pRofiling), a model that builds a graph of\ninter-media connections based on their audience overlap, and then uses graph\nneural networks to represent each medium. We find that such representations are\nquite useful for predicting the factuality and the bias of news media outlets,\nyielding improvements over state-of-the-art results reported on two datasets.\nWhen augmented with conventionally used representations obtained from news\narticles, Twitter, YouTube, Facebook, and Wikipedia, prediction accuracy is\nfound to improve by 2.5-27 macro-F1 points for the two tasks.",
    "descriptor": "",
    "authors": [
      "Panayot Panayotov",
      "Utsav Shukla",
      "Husrev Taha Sencar",
      "Mohamed Nabeel",
      "Preslav Nakov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05533"
  },
  {
    "id": "arXiv:2211.05536",
    "title": "Data-based Transfer Stabilization in Linear Systems",
    "abstract": "In this note, we present a novel framework for transferring the knowledge\nfrom one system (source) to design a stabilizing controller for a second system\n(target). Our motivation stems from the hypothesis that abundant data can be\ncollected from the source system, whereas the data from the target system is\nscarce. We consider both cases where data collected from the source system is\nnoiseless and noisy. For each case, by leveraging the data collected from the\nsource system and a priori knowledge on the maximum distance of the two\nsystems, we provide a controller that stabilizes the actual target system. In\nparticular, the controller can be obtained by solving a set of linear matrix\ninequalities (LMIs). Feasibility of those LMIs is discussed in details. We\ncomplement our theoretical findings by two numerical case studies of low-order\nand high-order systems.",
    "descriptor": "",
    "authors": [
      "Lidong Li",
      "Claudio De Persis",
      "Pietro Tesi",
      "Nima Monshizadeh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.05536"
  },
  {
    "id": "arXiv:2211.05543",
    "title": "Vis2Mus: Exploring Multimodal Representation Mapping for Controllable  Music Generation",
    "abstract": "In this study, we explore the representation mapping from the domain of\nvisual arts to the domain of music, with which we can use visual arts as an\neffective handle to control music generation. Unlike most studies in multimodal\nrepresentation learning that are purely data-driven, we adopt an\nanalysis-by-synthesis approach that combines deep music representation learning\nwith user studies. Such an approach enables us to discover\n\\textit{interpretable} representation mapping without a huge amount of paired\ndata. In particular, we discover that visual-to-music mapping has a nice\nproperty similar to equivariant. In other words, we can use various image\ntransformations, say, changing brightness, changing contrast, style transfer,\nto control the corresponding transformations in the music domain. In addition,\nwe released the Vis2Mus system as a controllable interface for symbolic music\ngeneration.",
    "descriptor": "\nComments: Submitted to ICASSP 2023. GitHub repo: this https URL\n",
    "authors": [
      "Runbang Zhang",
      "Yixiao Zhang",
      "Kai Shao",
      "Ying Shan",
      "Gus Xia"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.05543"
  },
  {
    "id": "arXiv:2211.05544",
    "title": "Near-infrared and visible-light periocular recognition with Gabor  features using frequency-adaptive automatic eye detection",
    "abstract": "Periocular recognition has gained attention recently due to demands of\nincreased robustness of face or iris in less controlled scenarios. We present a\nnew system for eye detection based on complex symmetry filters, which has the\nadvantage of not needing training. Also, separability of the filters allows\nfaster detection via one-dimensional convolutions. This system is used as input\nto a periocular algorithm based on retinotopic sampling grids and Gabor\nspectrum decomposition. The evaluation framework is composed of six databases\nacquired both with near-infrared and visible sensors. The experimental setup is\ncomplemented with four iris matchers, used for fusion experiments. The eye\ndetection system presented shows very high accuracy with near-infrared data,\nand a reasonable good accuracy with one visible database. Regarding the\nperiocular system, it exhibits great robustness to small errors in locating the\neye centre, as well as to scale changes of the input image. The density of the\nsampling grid can also be reduced without sacrificing accuracy. Lastly, despite\nthe poorer performance of the iris matchers with visible data, fusion with the\nperiocular system can provide an improvement of more than 20%. The six\ndatabases used have been manually annotated, with the annotation made publicly\navailable.",
    "descriptor": "\nComments: Published at IET Biometrics\n",
    "authors": [
      "Fernando Alonso-Fernandez",
      "Josef Bigun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.05544"
  },
  {
    "id": "arXiv:2211.05547",
    "title": "Column Generation for Optimization Problems in Communication Networks",
    "abstract": "Numerous communication networks are emerging to serve the various demands and\nimprove the quality of service. Heterogeneous users have different requirements\non quality metrics such as delay and service efficiency. Besides, the networks\nare equipped with different types and amounts of resources, and how to\nefficiently optimize the usage of such limited resources to serve more users is\nthe key issue for communication networks. One powerful mathematical\noptimization mechanism to solve the above issue is column generation (CG),\nwhich can deal with the optimization problems with complicating constraints and\nblock angular structures. In this paper, we first review the preliminaries of\nCG. Further, the branch-and-price (BP) algorithm is elaborated, which is\ndesigned by embedding CG into the branch-and-bound scheme to efficiently obtain\nthe optimal solution. The applications of CG and BP in various communication\nnetworks are then provided, such as space-air-ground networks and\ndevice-to-device networks. In short, our goal is to help readers refine the\napplications of the CG optimization tool in terms of problem formulation and\nsolution. We also discuss the possible challenges and prospective directions\nwhen applying CG in the communication networks.",
    "descriptor": "",
    "authors": [
      "Ziye Jia",
      "Qihui Wu",
      "Chao Dong",
      "Chau Yuen",
      "Zhu Han"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.05547"
  },
  {
    "id": "arXiv:2211.05551",
    "title": "Causal Counterfactuals for Improving the Robustness of Reinforcement  Learning",
    "abstract": "Reinforcement learning (RL) is applied in a wide variety of fields. RL\nenables agents to learn tasks autonomously by interacting with the environment.\nThe more critical the tasks are, the higher the demand for the robustness of\nthe RL systems. Causal RL combines RL and causal inference to make RL more\nrobust. Causal RL agents use a causal representation to capture the invariant\ncausal mechanisms that can be transferred from one task to another. Currently,\nthere is limited research in Causal RL, and existing solutions are usually not\ncomplete or feasible for real-world applications. In this work, we propose\nCausalCF, the first complete Causal RL solution incorporating ideas from Causal\nCuriosity and CoPhy. Causal Curiosity provides an approach for using\ninterventions, and CoPhy is modified to enable the RL agent to perform\ncounterfactuals. We apply CausalCF to complex robotic tasks and show that it\nimproves the RL agent's robustness using a realistic simulation environment\ncalled CausalWorld.",
    "descriptor": "",
    "authors": [
      "Tom He",
      "Jasmina Gajcin",
      "Ivana Dusparic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.05551"
  },
  {
    "id": "arXiv:2211.05552",
    "title": "Information-Theoretic Foundations of DNA Data Storage",
    "abstract": "Due to its longevity and enormous information density, DNA is an attractive\nmedium for archival data storage. Thanks to rapid technological advances, DNA\nstorage is becoming practically feasible, as demonstrated by a number of\nexperimental storage systems, making it a promising solution for our society's\nincreasing need of data storage. While in living things, DNA molecules can\nconsist of millions of nucleotides, due to technological constraints, in\npractice, data is stored on many short DNA molecules, which are preserved in a\nDNA pool and cannot be spatially ordered. Moreover, imperfections in\nsequencing, synthesis, and handling, as well as DNA decay during storage,\nintroduce random noise into the system, making the task of reliably storing and\nretrieving information in DNA challenging. This unique setup raises a natural\ninformation-theoretic question: how much information can be reliably stored on\nand reconstructed from millions of short noisy sequences? The goal of this\nmonograph is to address this question by discussing the fundamental limits of\nstoring information on DNA. Motivated by current technological constraints on\nDNA synthesis and sequencing, we propose a probabilistic channel model that\ncaptures three key distinctive aspects of the DNA storage systems: (1) the data\nis written onto many short DNA molecules that are stored in an unordered\nfashion; (2) the molecules are corrupted by noise and (3) the data is read by\nrandomly sampling from the DNA pool. Our goal is to investigate the impact of\neach of these key aspects on the capacity of the DNA storage system. Rather\nthan focusing on coding-theoretic considerations and computationally efficient\nencoding and decoding, we aim to build an information-theoretic foundation for\nthe analysis of these channels, developing tools for achievability and converse\narguments.",
    "descriptor": "\nComments: Preprint of a monograph published in Foundations and Trends in Communications and Information Theory\n",
    "authors": [
      "Ilan Shomorony",
      "Reinhard Heckel"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.05552"
  },
  {
    "id": "arXiv:2211.05554",
    "title": "Optimizing Server-side Aggregation For Robust Federated Learning via  Subspace Training",
    "abstract": "Non-IID data distribution across clients and poisoning attacks are two main\nchallenges in real-world federated learning systems. While both of them have\nattracted great research interest with specific strategies developed, no known\nsolution manages to address them in a unified framework. To jointly overcome\nboth challenges, we propose SmartFL, a generic approach that optimizes the\nserver-side aggregation process with a small clean server-collected proxy\ndataset (e.g., around one hundred samples, 0.2% of the dataset) via a subspace\ntraining technique. Specifically, the aggregation weight of each participating\nclient at each round is optimized using the server-collected proxy data, which\nis essentially the optimization of the global model in the convex hull spanned\nby client models. Since at each round, the number of tunable parameters\noptimized on the server side equals the number of participating clients (thus\nindependent of the model size), we are able to train a global model with\nmassive parameters using only a small amount of proxy data. We provide\ntheoretical analyses of the convergence and generalization capacity for\nSmartFL. Empirically, SmartFL achieves state-of-the-art performance on both\nfederated learning with non-IID data distribution and federated learning with\nmalicious clients. The source code will be released.",
    "descriptor": "",
    "authors": [
      "Yueqi Xie",
      "Weizhong Zhang",
      "Renjie Pi",
      "Fangzhao Wu",
      "Qifeng Chen",
      "Xing Xie",
      "Sunghun Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.05554"
  },
  {
    "id": "arXiv:2211.05555",
    "title": "Real time A* Adaptive Action Set Footstep Planning with Human Locomotion  Energy Approximations Considering Angle Difference for Heuristic Function",
    "abstract": "The problem of navigating a bipedal robot to a desired destination in various\nenvironments is very important. However, it is very difficult to solve the\nnavigation problem in real time because the computation time is very long due\nto the nature of the biped robot having a high degree of freedom. In order to\novercome this, many scientists suggested navigation through the footstep\nplanning. Usually footstep planning use the shortest distance or angles as the\nobjective function based on the A * algorithm. Recently, the energy required\nfor human walking, which is widely used in human dynamics, approximated by a\npolynomial function is proposed as a better cost function that explains the\nmovement of the bipedal robot. In addition, for the real time navigation, using\nthe action set of the A * algorithm not fixed, but the number changing\naccording to the situation, so that the computation time does not increase much\nand the methods of considering the collision with the external environment are\nsuggested as a practical method. In this thesis, polynomial function\napproximating the energy required for human walking is adopted as a cost\nfunction, and heuristic function considering the angular difference between the\nrobot and the destination which is not shown in the previous studies is newly\nproposed and proved. In addition, a new method to integrate the adaptive\nbehavior set and energy related to human walking is proposed. Furthermore,\nefficient collision avoidance method and a method to reduce the local minimum\nproblem is proposed in this framework. Finally, footstep planning algorithm\nwith all of these features into the mapping algorithm and the walking algorithm\nto solve the navigation problem is validated with simulation and real robot.",
    "descriptor": "\nComments: Master's Degree Thesis\n",
    "authors": [
      "Joon-Ha Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.05555"
  },
  {
    "id": "arXiv:2211.05560",
    "title": "Finite basis physics-informed neural networks as a Schwarz domain  decomposition method",
    "abstract": "Physics-informed neural networks (PINNs) [4, 10] are an approach for solving\nboundary value problems based on differential equations (PDEs). The key idea of\nPINNs is to use a neural network to approximate the solution to the PDE and to\nincorporate the residual of the PDE as well as boundary conditions into its\nloss function when training it. This provides a simple and mesh-free approach\nfor solving problems relating to PDEs. However, a key limitation of PINNs is\ntheir lack of accuracy and efficiency when solving problems with larger domains\nand more complex, multi-scale solutions. In a more recent approach, finite\nbasis physics-informed neural networks (FBPINNs) [8] use ideas from domain\ndecomposition to accelerate the learning process of PINNs and improve their\naccuracy. In this work, we show how Schwarz-like additive, multiplicative, and\nhybrid iteration methods for training FBPINNs can be developed. We present\nnumerical experiments on the influence of these different training strategies\non convergence and accuracy. Furthermore, we propose and evaluate a preliminary\nimplementation of coarse space correction for FBPINNs.",
    "descriptor": "",
    "authors": [
      "Victorita Dolean",
      "Alexander Heinlein",
      "Siddhartha Mishra",
      "Ben Moseley"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.05560"
  },
  {
    "id": "arXiv:2211.05561",
    "title": "Estimating Soft Labels for Out-of-Domain Intent Detection",
    "abstract": "Out-of-Domain (OOD) intent detection is important for practical dialog\nsystems. To alleviate the issue of lacking OOD training samples, some works\npropose synthesizing pseudo OOD samples and directly assigning one-hot OOD\nlabels to these pseudo samples. However, these one-hot labels introduce noises\nto the training process because some hard pseudo OOD samples may coincide with\nIn-Domain (IND) intents. In this paper, we propose an adaptive soft pseudo\nlabeling (ASoul) method that can estimate soft labels for pseudo OOD samples\nwhen training OOD detectors. Semantic connections between pseudo OOD samples\nand IND intents are captured using an embedding graph. A co-training framework\nis further introduced to produce resulting soft labels following the smoothness\nassumption, i.e., close samples are likely to have similar labels. Extensive\nexperiments on three benchmark datasets show that ASoul consistently improves\nthe OOD detection performance and outperforms various competitive baselines.",
    "descriptor": "\nComments: EMNLP2022 Main Track Long Paper (Oral presentation)\n",
    "authors": [
      "Hao Lang",
      "Yinhe Zheng",
      "Jian Sun",
      "Fei Huang",
      "Luo Si",
      "Yongbin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05561"
  },
  {
    "id": "arXiv:2211.05562",
    "title": "Robust Security Energy Efficiency Optimization for RIS-Aided Cell-Free  Networks with Multiple Eavesdroppers",
    "abstract": "In this paper, we investigate the energy efficiency (EE) problem under\nreconfigurable intelligent surface (RIS)-aided secure cell-free networks, where\nmultiple legitimate users and eavesdroppers (Eves) exist. We formulate a\nmax-min secure EE optimization problem by jointly designing the distributed\nactive beamforming and artificial noise at base stations as well as the passive\nbeamforming at RISs under practical constraints. To deal with it, we first\ndivide the original optimization problem into two sub-ones, and then propose an\niterative optimization algorithm to solve each sub-problem based on the\nfractional programming, constrained convex-convex procedure (CCCP) and\nsemi-definite programming (SDP) techniques. After that, these two sub-problems\nare alternatively solved until convergence, and the final solutions are\nobtained. Next, we extend to the imperfect channel state information of the\nEves' links, and investigate the robust SEE beamforming optimization problem by\nbringing the outage probability constraints. Based on this, we first transform\nthe uncertain outage probability constraints into the certain ones by the\nbernstein-type inequality and sphere boundary techniques, and then propose an\nalternatively iterative algorithm to obtain the solutions of the original\nproblem based on the S-procedure, successive convex approximation, CCCP and SDP\ntechniques. Finally, the simulation results are conducted to show the\neffectiveness of the proposed schemes.",
    "descriptor": "",
    "authors": [
      "Wanming Hao",
      "Junjie Li",
      "Gangcan Sun",
      "Chongwen Huang",
      "Ming Zeng",
      "Octavia A. Dobre",
      "Chau Yuen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.05562"
  },
  {
    "id": "arXiv:2211.05565",
    "title": "Computer Vision on X-ray Data in Industrial Production and Security  Applications: A survey",
    "abstract": "X-ray imaging technology has been used for decades in clinical tasks to\nreveal the internal condition of different organs, and in recent years, it has\nbecome more common in other areas such as industry, security, and geography.\nThe recent development of computer vision and machine learning techniques has\nalso made it easier to automatically process X-ray images and several machine\nlearning-based object (anomaly) detection, classification, and segmentation\nmethods have been recently employed in X-ray image analysis. Due to the high\npotential of deep learning in related image processing applications, it has\nbeen used in most of the studies. This survey reviews the recent research on\nusing computer vision and machine learning for X-ray analysis in industrial\nproduction and security applications and covers the applications, techniques,\nevaluation metrics, datasets, and performance comparison of those techniques on\npublicly available datasets. We also highlight some drawbacks in the published\nresearch and give recommendations for future research in computer vision-based\nX-ray analysis.",
    "descriptor": "\nComments: 32pages, 19 figures, 11 tables. A literature review paper. Journal\n",
    "authors": [
      "Mehdi Rafiei",
      "Jenni Raitoharju",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05565"
  },
  {
    "id": "arXiv:2211.05566",
    "title": "Secure State Estimation against Sparse Attacks on a Time-varying Set of  Sensors",
    "abstract": "This paper studies the problem of secure state estimation of a linear\ntime-invariant (LTI) system with bounded noise in the presence of sparse\nattacks on an unknown, time-varying set of sensors. In other words, at each\ntime, the attacker has the freedom to choose an arbitrary set of no more that\n$p$ sensors and manipulate their measurements without restraint. To this end,\nwe propose a secure state estimation scheme and guarantee a bounded estimation\nerror subject to $2p$-sparse observability and a mild, technical assumption\nthat the system matrix has no degenerate eigenvalues. The proposed scheme\ncomprises a design of decentralized observer for each sensor based on the local\nobservable subspace decomposition. At each time step, the local estimates of\nsensors are fused by solving an optimization problem to obtain a secure\nestimation, which is then followed by a local detection-and-resetting process\nof the decentralized observers. The estimation error is shown to be\nupper-bounded by a constant which is determined only by the system parameters\nand noise magnitudes. Moreover, we optimize the detector threshold to ensure\nthat the benign sensors do not trigger the detector. The efficacy of the\nproposed algorithm is demonstrated by its application on a benchmark example of\nIEEE 14-bus system.",
    "descriptor": "",
    "authors": [
      "Zishuo Li",
      "Muhammad Umar B. Niazi",
      "Changxin Liu",
      "Yilin Mo",
      "Karl H. Johansson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.05566"
  },
  {
    "id": "arXiv:2211.05567",
    "title": "Partial Differential Equations Meet Deep Neural Networks: A Survey",
    "abstract": "Many problems in science and engineering can be represented by a set of\npartial differential equations (PDEs) through mathematical modeling.\nMechanism-based computation following PDEs has long been an essential paradigm\nfor studying topics such as computational fluid dynamics, multiphysics\nsimulation, molecular dynamics, or even dynamical systems. It is a vibrant\nmulti-disciplinary field of increasing importance and with extraordinary\npotential. At the same time, solving PDEs efficiently has been a long-standing\nchallenge. Generally, except for a few differential equations for which\nanalytical solutions are directly available, many more equations must rely on\nnumerical approaches such as the finite difference method, finite element\nmethod, finite volume method, and boundary element method to be solved\napproximately. These numerical methods usually divide a continuous problem\ndomain into discrete points and then concentrate on solving the system at each\nof those points. Though the effectiveness of these traditional numerical\nmethods, the vast number of iterative operations accompanying each step forward\nsignificantly reduces the efficiency. Recently, another equally important\nparadigm, data-based computation represented by deep learning, has emerged as\nan effective means of solving PDEs. Surprisingly, a comprehensive review for\nthis interesting subfield is still lacking. This survey aims to categorize and\nreview the current progress on Deep Neural Networks (DNNs) for PDEs. We discuss\nthe literature published in this subfield over the past decades and present\nthem in a common taxonomy, followed by an overview and classification of\napplications of these related methods in scientific research and engineering\nscenarios. The origin, developing history, character, sort, as well as the\nfuture trends in each potential direction of this subfield are also introduced.",
    "descriptor": "",
    "authors": [
      "Shudong Huang",
      "Wentao Feng",
      "Chenwei Tang",
      "Jiancheng Lv"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.05567"
  },
  {
    "id": "arXiv:2211.05568",
    "title": "Unbiased Supervised Contrastive Learning",
    "abstract": "Many datasets are biased, namely they contain easy-to-learn features that are\nhighly correlated with the target class only in the dataset but not in the true\nunderlying distribution of the data. For this reason, learning unbiased models\nfrom biased data has become a very relevant research topic in the last years.\nIn this work, we tackle the problem of learning representations that are robust\nto biases. We first present a margin-based theoretical framework that allows us\nto clarify why recent contrastive losses (InfoNCE, SupCon, etc.) can fail when\ndealing with biased data. Based on that, we derive a novel formulation of the\nsupervised contrastive loss (epsilon-SupInfoNCE), providing more accurate\ncontrol of the minimal distance between positive and negative samples.\nFurthermore, thanks to our theoretical framework, we also propose FairKL, a new\ndebiasing regularization loss, that works well even with extremely biased data.\nWe validate the proposed losses on standard vision datasets including CIFAR10,\nCIFAR100, and ImageNet, and we assess the debiasing capability of FairKL with\nepsilon-SupInfoNCE, reaching state-of-the-art performance on a number of biased\ndatasets, including real instances of biases in the wild.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Carlo Alberto Barbano",
      "Benoit Dufumier",
      "Enzo Tartaglione",
      "Marco Grangetto",
      "Pietro Gori"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.05568"
  },
  {
    "id": "arXiv:2211.05572",
    "title": "Modular Robots: extending the capabilities of one robot",
    "abstract": "For a robot to be perfect and enter the everyday life of humans,like\ncomputers did, it needs to move from special-purpose robots to general-purpose.\nSo, the idea of modularity is considered in this project.Thus, any type of task\nthat falls in the 4 D's of Robotization: Dull, Dirty, Dangerous and Dear can be\nachieved by adding a module to the robot.",
    "descriptor": "",
    "authors": [
      "Aymen Rachdi",
      "Fedi Zrelli",
      "Amine Kammmoun"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.05572"
  },
  {
    "id": "arXiv:2211.05574",
    "title": "Filtration-Domination in Bifiltered Graphs",
    "abstract": "Bifiltered graphs are a versatile tool for modelling relations between data\npoints across multiple grades of a two-dimensional scale. They are especially\npopular in topological data analysis, where the homological properties of the\ninduced clique complexes are studied. To reduce the large size of these clique\ncomplexes, we identify filtration-dominated edges of the graph, whose removal\npreserves the relevant topological properties. We give two algorithms to detect\nfiltration-dominated edges in a bifiltered graph and analyze their complexity.\nThese two algorithms work directly on the bifiltered graph, without first\nextracting the clique complexes, which are generally much bigger. We present\nextensive experimental evaluation which shows that in most cases, more than 90%\nof the edges can be removed. In turn, we demonstrate that this often leads to a\nsubstantial speedup, and reduction in the memory usage, of the computational\npipeline of multiparameter topological data analysis.",
    "descriptor": "",
    "authors": [
      "\u00c1ngel Javier Alonso",
      "Michael Kerber",
      "Siddharth Pritam"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2211.05574"
  },
  {
    "id": "arXiv:2211.05575",
    "title": "Mobile Robot Motion Control Using a Combination of Fuzzy Logic Method  and Kinematic Model",
    "abstract": "Mobile robots have been widely used in various aspects of human life. When a\nrobot moves between different positions in the working area to perform the\ntask, controlling motion to follow a pre-defined path is the primary task of a\nmobile robot. Furthermore, the robot must remain at its desired speed to\ncooperate with other agents. This paper presents a development of a motion\ncontroller, in which the fuzzy logic method is combined with a kinematic model\nof a differential drive robot. The simulation results are compared well with\nexperimental results indicate that the method is effective and applicable for\nactual mobile robots.",
    "descriptor": "",
    "authors": [
      "Anh-Tu Nguyen",
      "Van-Truong Nguyen",
      "Xuan-Thuan Nguyen",
      "Cong-Thanh Vu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.05575"
  },
  {
    "id": "arXiv:2211.05579",
    "title": "Computer-Aided Modelling of the Bilingual Word Indices to the  Ninth-Century Uchitel'noe evangelie",
    "abstract": "The development of bilingual dictionaries to medieval translations presents\ndiverse difficulties. These result from two types of philological\ncircumstances: a) the asymmetry between the source language and the target\nlanguage; and b) the varying available sources of both the original and\ntranslated texts. In particular, the full critical edition of Tihova of\nConstantine of Preslav's Uchitel'noe evangelie ('Didactic Gospel') gives a\nrelatively good idea of the Old Church Slavonic translation but not of its\nGreek source text. This is due to the fact that Cramer's edition of the catenae\n- used as the parallel text in it - is based on several codices whose text does\nnot fully coincide with the Slavonic. This leads to the addition of the\nnewly-discovered parallels from Byzantine manuscripts and John Chrysostom's\nhomilies. Our approach to these issues is a step-wise process with two main\ngoals: a) to facilitate the philological annotation of input data and b) to\nconsider the manifestations of the mentioned challenges, first, separately in\norder to simplify their resolution, and, then, in their combination. We\ndemonstrate how we model various types of asymmetric translation correlates and\nthe variability resulting from the pluralism of sources. We also demonstrate\nhow all these constructions are being modelled and processed into the final\nindices. Our approach is designed with generalisation in mind and is intended\nto be applicable also for other translations from Greek into Old Church\nSlavonic.",
    "descriptor": "\nComments: Presented at 1st International Workshop on Digital Platforms and Resources for Access to Literary Heritage, held in conjunction with 26th International Conference on Theory and Practice of Digital Libraries, 20-23 September 2022, Padua, Italy\n",
    "authors": [
      "Martin Ruskov",
      "Lora Taseva"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05579"
  },
  {
    "id": "arXiv:2211.05580",
    "title": "Hyperbolic Cosine Transformer for LiDAR 3D Object Detection",
    "abstract": "Recently, Transformer has achieved great success in computer vision. However,\nit is constrained because the spatial and temporal complexity grows\nquadratically with the number of large points in 3D object detection\napplications. Previous point-wise methods are suffering from time consumption\nand limited receptive fields to capture information among points. In this\npaper, we propose a two-stage hyperbolic cosine transformer (ChTR3D) for 3D\nobject detection from LiDAR point clouds. The proposed ChTR3D refines proposals\nby applying cosh-attention in linear computation complexity to encode rich\ncontextual relationships among points. The cosh-attention module reduces the\nspace and time complexity of the attention operation. The traditional softmax\noperation is replaced by non-negative ReLU activation and\nhyperbolic-cosine-based operator with re-weighting mechanism. Extensive\nexperiments on the widely used KITTI dataset demonstrate that, compared with\nvanilla attention, the cosh-attention significantly improves the inference\nspeed with competitive performance. Experiment results show that, among\ntwo-stage state-of-the-art methods using point-level features, the proposed\nChTR3D is the fastest one.",
    "descriptor": "\nComments: 8 pages, 5 figures and 3 tables. This paper possibly publicated on the IEEE Robotics and Automation Letters\n",
    "authors": [
      "Jigang Tong",
      "Fanhang Yang",
      "Sen Yang",
      "Enzeng Dong",
      "Shengzhi Du",
      "Xing Wang",
      "Xianlin Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05580"
  },
  {
    "id": "arXiv:2211.05583",
    "title": "Towards automatic generation of Piping and Instrumentation Diagrams  (P&IDs) with Artificial Intelligence",
    "abstract": "Developing Piping and Instrumentation Diagrams (P&IDs) is a crucial step\nduring the development of chemical processes. Currently, this is a tedious,\nmanual, and time-consuming task. We propose a novel, completely data-driven\nmethod for the prediction of control structures. Our methodology is inspired by\nend-to-end transformer-based human language translation models. We cast the\ncontrol structure prediction as a translation task where Process Flow Diagrams\n(PFDs) are translated to P&IDs. To use established transformer-based language\ntranslation models, we represent the P&IDs and PFDs as strings using our\nrecently proposed SFILES 2.0 notation. Model training is performed in a\ntransfer learning approach. Firstly, we pre-train our model using generated\nP&IDs to learn the grammatical structure of the process diagrams. Thereafter,\nthe model is fine-tuned leveraging transfer learning on real P&IDs. The model\nachieved a top-5 accuracy of 74.8% on 10,000 generated P&IDs and 89.2% on\n100,000 generated P&IDs. These promising results show great potential for\nAI-assisted process engineering. The tests on a dataset of 312 real P&IDs\nindicate the need of a larger P&IDs dataset for industry applications.",
    "descriptor": "",
    "authors": [
      "Edwin Hirtreiter",
      "Lukas Schulze Balhorn",
      "Artur M. Schweidtmann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.05583"
  },
  {
    "id": "arXiv:2211.05584",
    "title": "Exploring Robustness of Prefix Tuning in Noisy Data: A Case Study in  Financial Sentiment Analysis",
    "abstract": "The invention of transformer-based models such as BERT, GPT, and RoBERTa has\nenabled researchers and financial companies to finetune these powerful models\nand use them in different downstream tasks to achieve state-of-the-art\nperformance. Recently, a lightweight alternative (approximately 0.1% - 3% of\nthe original model parameters) to fine-tuning, known as prefix tuning has been\nintroduced. This method freezes the model parameters and only updates the\nprefix to achieve performance comparable to full fine-tuning. Prefix tuning\nenables researchers and financial practitioners to achieve similar results with\nmuch fewer parameters. In this paper, we explore the robustness of prefix\ntuning when facing noisy data. Our experiments demonstrate that fine-tuning is\nmore robust to noise than prefix tuning -- the latter method faces a\nsignificant decrease in performance on most corrupted data sets with increasing\nnoise levels. Furthermore, prefix tuning has high variances in the F1 scores\ncompared to fine-tuning in many corruption methods. We strongly advocate that\ncaution should be carefully taken when applying the state-of-the-art prefix\ntuning method to noisy data.",
    "descriptor": "\nComments: Accepted at the FinNLP workshop part of the EMNLP 2022 conference\n",
    "authors": [
      "Sudhandar Balakrishnan",
      "Yihao Fang",
      "Xioadan Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05584"
  },
  {
    "id": "arXiv:2211.05588",
    "title": "Watching the News: Towards VideoQA Models that can Read",
    "abstract": "Video Question Answering methods focus on commonsense reasoning and visual\ncognition of objects or persons and their interactions over time. Current\nVideoQA approaches ignore the textual information present in the video.\nInstead, we argue that textual information is complementary to the action and\nprovides essential contextualisation cues to the reasoning process. To this\nend, we propose a novel VideoQA task that requires reading and understanding\nthe text in the video. To explore this direction, we focus on news videos and\nrequire QA systems to comprehend and answer questions about the topics\npresented by combining visual and textual cues in the video. We introduce the\n``NewsVideoQA'' dataset that comprises more than $8,600$ QA pairs on $3,000+$\nnews videos obtained from diverse news channels from around the world. We\ndemonstrate the limitations of current Scene Text VQA and VideoQA methods and\npropose ways to incorporate scene text information into VideoQA methods.",
    "descriptor": "",
    "authors": [
      "Soumya Jahagirdar",
      "Minesh Mathew",
      "Dimosthenis Karatzas",
      "C. V. Jawahar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05588"
  },
  {
    "id": "arXiv:2211.05590",
    "title": "A Practical Introduction to Side-Channel Extraction of Deep Neural  Network Parameters",
    "abstract": "Model extraction is a major threat for embedded deep neural network models\nthat leverages an extended attack surface. Indeed, by physically accessing a\ndevice, an adversary may exploit side-channel leakages to extract critical\ninformation of a model (i.e., its architecture or internal parameters).\nDifferent adversarial objectives are possible including a fidelity-based\nscenario where the architecture and parameters are precisely extracted (model\ncloning). We focus this work on software implementation of deep neural networks\nembedded in a high-end 32-bit microcontroller (Cortex-M7) and expose several\nchallenges related to fidelity-based parameters extraction through side-channel\nanalysis, from the basic multiplication operation to the feed-forward\nconnection through the layers. To precisely extract the value of parameters\nrepresented in the single-precision floating point IEEE-754 standard, we\npropose an iterative process that is evaluated with both simulations and traces\nfrom a Cortex-M7 target. To our knowledge, this work is the first to target\nsuch an high-end 32-bit platform. Importantly, we raise and discuss the\nremaining challenges for the complete extraction of a deep neural network\nmodel, more particularly the critical case of biases.",
    "descriptor": "\nComments: Accepted at Smart Card Research and Advanced Application Conference (CARDIS 2022)\n",
    "authors": [
      "Raphael Joud",
      "Pierre-Alain Moellic",
      "Simon Pontie",
      "Jean-Baptiste Rigaud"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05590"
  },
  {
    "id": "arXiv:2211.05594",
    "title": "A Brief Survey on Representation Learning based Graph Dimensionality  Reduction Techniques",
    "abstract": "Dimensionality reduction techniques map data represented on higher dimensions\nonto lower dimensions with varying degrees of information loss. Graph\ndimensionality reduction techniques adopt the same principle of providing\nlatent representations of the graph structure with minor adaptations to the\noutput representations along with the input data. There exist several cutting\nedge techniques that are efficient at generating embeddings from graph data and\nprojecting them onto low dimensional latent spaces. Due to variations in the\noperational philosophy, the benefits of a particular graph dimensionality\nreduction technique might not prove advantageous to every scenario or rather\nevery dataset. As a result, some techniques are efficient at representing the\nrelationship between nodes at lower dimensions, while others are good at\nencapsulating the entire graph structure on low dimensional space. We present\nthis survey to outline the benefits as well as problems associated with the\nexisting graph dimensionality reduction techniques. We also attempted to\nconnect the dots regarding the potential improvements to some of the\ntechniques. This survey could be helpful for upcoming researchers interested in\nexploring the usage of graph representation learning to effectively produce\nlow-dimensional graph embeddings with varying degrees of granularity.",
    "descriptor": "",
    "authors": [
      "Akhil Pandey Akella"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05594"
  },
  {
    "id": "arXiv:2211.05596",
    "title": "Prompt Learning for Domain Adaptation in Task-Oriented Dialogue",
    "abstract": "Conversation designers continue to face significant obstacles when creating\nproduction quality task-oriented dialogue systems. The complexity and cost\ninvolved in schema development and data collection is often a major barrier for\nsuch designers, limiting their ability to create natural, user-friendly\nexperiences. We frame the classification of user intent as the generation of a\ncanonical form, a lightweight semantic representation using natural language.\nWe show that canonical forms offer a promising alternative to traditional\nmethods for intent classification. By tuning soft prompts for a frozen large\nlanguage model, we show that canonical forms generalize very well to new,\nunseen domains in a zero- or few-shot setting. The method is also\nsample-efficient, reducing the complexity and effort of developing new\ntask-oriented dialogue domains.",
    "descriptor": "\nComments: Accepted for publication at SereTOD Workshop - EMNLP 2022\n",
    "authors": [
      "Makesh Narsimhan Sreedhar",
      "Christopher Parisien"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.05596"
  },
  {
    "id": "arXiv:2211.05597",
    "title": "Perfectly predicting ICU length of stay: too good to be true",
    "abstract": "A paper of Alsinglawi et al was recently accepted and published in Scientific\nReports. In this paper, the authors aim to predict length of stay (LOS),\ndiscretized into either long (> 7 days) or short stays (< 7 days), of lung\ncancer patients in an ICU department using various machine learning techniques.\nThe authors claim to achieve perfect results with an Area Under the Receiver\nOperating Characteristic curve (AUROC) of 100% with a Random Forest (RF)\nclassifier with ADASYN class balancing over sampling technique, which if\naccurate could have significant implications for hospital management. However,\nwe have identified several methodological flaws within the manuscript which\ncause the results to be overly optimistic and would have serious consequences\nif used in a clinical practice. Moreover, the reporting of the methodology is\nunclear and many important details are missing from the manuscript, which makes\nreproduction extremely difficult. We highlight the effect these oversights have\nhad on the result and provide a more believable result of 88.91% AUROC when\nthese oversights are corrected.",
    "descriptor": "\nComments: 3 pages, 1 figure, 2 tables\n",
    "authors": [
      "Sandeep Ramachandra",
      "Gilles Vandewiele",
      "David Vander Mijnsbrugge",
      "Femke Ongenae",
      "Sofie Van Hoecke"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.05597"
  },
  {
    "id": "arXiv:2211.05598",
    "title": "Using contradictions to improve QA systems",
    "abstract": "Ensuring the safety of question answering (QA) systems is critical for\ndeploying them in biomedical and scientific domains. One approach to improving\nthese systems uses natural language inference (NLI) to determine whether\nanswers are supported, or entailed, by some background context. However, these\nsystems are vulnerable to supporting an answer with a source that is wrong or\nmisleading. Our work proposes a critical approach by selecting answers based on\nwhether they have been contradicted by some background context. We evaluate\nthis system on multiple choice and extractive QA and find that while the\ncontradiction-based systems are competitive with and often better than\nentailment-only systems, models that incorporate contradiction, entailment, and\nQA model confidence scores together are the best. Based on this result, we\nexplore unique opportunities for leveraging contradiction-based approaches such\nfor improving interpretability and selecting better answers.",
    "descriptor": "\nComments: Submitted to EMNLP 2022\n",
    "authors": [
      "Domenic Rosati"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05598"
  },
  {
    "id": "arXiv:2211.05599",
    "title": "Moving beyond word lists: towards abstractive topic labels for  human-like topics of scientific documents",
    "abstract": "Topic models represent groups of documents as a list of words (the topic\nlabels). This work asks whether an alternative approach to topic labeling can\nbe developed that is closer to a natural language description of a topic than a\nword list. To this end, we present an approach to generating human-like topic\nlabels using abstractive multi-document summarization (MDS). We investigate our\napproach with an exploratory case study. We model topics in citation sentences\nin order to understand what further research needs to be done to fully\noperationalize MDS for topic labeling. Our case study shows that in addition to\nmore human-like topics there are additional advantages to evaluation by using\nclustering and summarization measures instead of topic model measures. However,\nwe find that there are several developments needed before we can design a\nwell-powered study to evaluate MDS for topic modeling fully. Namely, improving\ncluster cohesion, improving the factuality and faithfulness of MDS, and\nincreasing the number of documents that might be supported by MDS. We present a\nnumber of ideas on how these can be tackled and conclude with some thoughts on\nhow topic modeling can also be used to improve MDS in general.",
    "descriptor": "\nComments: Accepted to WIESP @ AACL-IJCNLP\n",
    "authors": [
      "Domenic Rosati"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05599"
  },
  {
    "id": "arXiv:2211.05600",
    "title": "Bound-preserving discontinuous Galerkin methods with modified Patankar  time integrations for chemical reacting flows",
    "abstract": "In this paper, we develop bound-preserving discontinuous Galerkin (DG)\nmethods for chemical reactive flows. There are several difficulties in\nconstructing suitable numerical schemes. First of all, the density and internal\nenergy are positive, and the mass fraction of each species is between 0 and 1.\nSecondly, due to the rapid reaction rate, the system may contain stiff sources,\nand the strong-stability-preserving explicit Runge-Kutta method may result in\nlimited time step sizes. To obtain physically relevant numerical\napproximations, we apply the bound-preserving technique to the DG methods. For\ntime discretization, we apply the modified Runge-Kutta/multi-step Patankar\nmethods, which are explicit for the flux while implicit for the source. Such\nmethods can handle stiff sources with relatively large time steps, preserve the\npositivity of the target variables, and keep the summation of the mass\nfractions to be 1. Finally, it is not straightforward to combine the\nbound-preserving DG methods and the Patankar time integrations. The\npositivity-preserving technique for DG method requires positive numerical\napproximations at the cell interfaces, while Patankar methods can keep the\npositivity of the pre-selected point-values of the target variables. To match\nthe degree of freedom, we use $Q^k$ polynomials on rectangular meshes for\nproblems in two space dimensions. To evolve in time, we first read the\npolynomials at the Gaussian points. Then suitable slope limiters can be applied\nto enforce the positivity of the solutions at those points, which can be\npreserved by the Patankar methods, leading to positive updated numerical cell\naverages. In addition, we use another slope limiter to get positive solutions\nused for the bound-preserving technique for the flux.",
    "descriptor": "",
    "authors": [
      "Fangyao Zhu",
      "Juntao Huang",
      "Yang Yang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.05600"
  },
  {
    "id": "arXiv:2211.05601",
    "title": "Online Stochastic Variational Gaussian Process Mapping for Large-Scale  SLAM in Real Time",
    "abstract": "Autonomous underwater vehicles (AUVs) are becoming standard tools for\nunderwater exploration and seabed mapping in both scientific and industrial\napplications \\cite{graham2022rapid, stenius2022system}. Their capacity to dive\nuntethered allows them to reach areas inaccessible to surface vessels and to\ncollect data more closely to the seafloor, regardless of the water depth.\nHowever, their navigation autonomy remains bounded by the accuracy of their\ndead reckoning (DR) estimate of their global position, severely limited in the\nabsence of a priori maps of the area and GPS signal. Global localization\nsystems equivalent to the later exists for the underwater domain, such as LBL\nor USBL. However they involve expensive external infrastructure and their\nreliability decreases with the distance to the AUV, making them unsuitable for\ndeep sea surveys.",
    "descriptor": "",
    "authors": [
      "Ignacio Torroba",
      "Marco Chella",
      "Aldo Teran",
      "Niklas Rolleberg",
      "John Folkesson"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05601"
  },
  {
    "id": "arXiv:2211.05604",
    "title": "An Inclusive Notion of Text",
    "abstract": "Natural language processing researchers develop models of grammar, meaning\nand human communication based on written text. Due to task and data\ndifferences, what is considered text can vary substantially across studies. A\nconceptual framework for systematically capturing these differences is lacking.\nWe argue that clarity on the notion of text is crucial for reproducible and\ngeneralizable NLP. Towards that goal, we propose common terminology to discuss\nthe production and transformation of textual data, and introduce a two-tier\ntaxonomy of linguistic and non-linguistic elements that are available in\ntextual sources and can be used in NLP modeling. We apply this taxonomy to\nsurvey existing work that extends the notion of text beyond the conservative\nlanguage-centered view. We outline key desiderata and challenges of the\nemerging inclusive approach to text in NLP, and suggest systematic\ncommunity-level reporting as a crucial next step to consolidate the discussion.",
    "descriptor": "",
    "authors": [
      "Ilia Kuznetsov",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05604"
  },
  {
    "id": "arXiv:2211.05608",
    "title": "Taylor Expansion Finitely Simulates $\u03b2$-Reduction",
    "abstract": "Originating in Girard's Linear logic, Ehrhard and Regnier's Taylor expansion\nof $\\lambda$-terms has been broadly used as a tool to approximate the terms of\nseveral variants of the $\\lambda$-calculus. Many results arise from a\nCommutation theorem relating the normal form of the Taylor expansion of a term\nto its B\\\"ohm tree. This led us to consider extending this formalism to the\ninfinitary $\\lambda$-calculus, since the $\\Lambda_{\\infty}^{001}$ version of\nthis calculus has B\\\"ohm trees as normal forms and seems to be the ideal\nframework to reformulate the Commutation theorem.\nWe give a (co-)inductive presentation of $\\Lambda_{\\infty}^{001}$. We define\na Taylor expansion on this calculus, and state that the infinitary\n$\\beta$-reduction can be simulated through this Taylor expansion. The target\nlanguage is the usual resource calculus, and in particular the resource\nreduction remains finite, confluent and terminating. Finally, we state the\ngeneralised Commutation theorem and use our results to provide simple proofs of\nsome normalisation and confluence properties in the infinitary\n$\\lambda$-calculus.",
    "descriptor": "\nComments: 40 pages. To be submitted to Logical Methods in Computer Science\n",
    "authors": [
      "R\u00e9my Cerda",
      "Lionel Vaux Auclair"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.05608"
  },
  {
    "id": "arXiv:2211.05610",
    "title": "BERT on a Data Diet: Finding Important Examples by Gradient-Based  Pruning",
    "abstract": "Current pre-trained language models rely on large datasets for achieving\nstate-of-the-art performance. However, past research has shown that not all\nexamples in a dataset are equally important during training. In fact, it is\nsometimes possible to prune a considerable fraction of the training set while\nmaintaining the test performance. Established on standard vision benchmarks,\ntwo gradient-based scoring metrics for finding important examples are GraNd and\nits estimated version, EL2N. In this work, we employ these two metrics for the\nfirst time in NLP. We demonstrate that these metrics need to be computed after\nat least one epoch of fine-tuning and they are not reliable in early steps.\nFurthermore, we show that by pruning a small portion of the examples with the\nhighest GraNd/EL2N scores, we can not only preserve the test accuracy, but also\nsurpass it. This paper details adjustments and implementation choices which\nenable GraNd and EL2N to be applied to NLP.",
    "descriptor": "\nComments: ENLSP @ NeurIPS2022\n",
    "authors": [
      "Mohsen Fayyaz",
      "Ehsan Aghazadeh",
      "Ali Modarressi",
      "Mohammad Taher Pilehvar",
      "Yadollah Yaghoobzadeh",
      "Samira Ebrahimi Kahou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05610"
  },
  {
    "id": "arXiv:2211.05612",
    "title": "Power Grid Congestion Management via Topology Optimization with  AlphaZero",
    "abstract": "The energy sector is facing rapid changes in the transition towards clean\nrenewable sources. However, the growing share of volatile, fluctuating\nrenewable generation such as wind or solar energy has already led to an\nincrease in power grid congestion and network security concerns. Grid operators\nmitigate these by modifying either generation or demand (redispatching,\ncurtailment, flexible loads). Unfortunately, redispatching of fossil generators\nleads to excessive grid operation costs and higher emissions, which is in\ndirect opposition to the decarbonization of the energy sector. In this paper,\nwe propose an AlphaZero-based grid topology optimization agent as a non-costly,\ncarbon-free congestion management alternative. Our experimental evaluation\nconfirms the potential of topology optimization for power grid operation,\nachieves a reduction of the average amount of required redispatching by 60%,\nand shows the interoperability with traditional congestion management methods.\nOur approach also ranked 1st in the WCCI 2022 Learning to Run a Power Network\n(L2RPN) competition. Based on our findings, we identify and discuss open\nresearch problems as well as technical challenges for a productive system on a\nreal power grid.",
    "descriptor": "",
    "authors": [
      "Matthias Dorfer",
      "Anton R. Fuxj\u00e4ger",
      "Kristian Kozak",
      "Patrick M. Blies",
      "Marcel Wasserer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05612"
  },
  {
    "id": "arXiv:2211.05613",
    "title": "Adjustment formulas for learning causal steady-state models from  closed-loop operational data",
    "abstract": "Steady-state models which have been learned from historical operational data\nmay be unfit for model-based optimization unless correlations in the training\ndata which are introduced by control are accounted for. Using recent results\nfrom work on structural dynamical causal models, we derive a formula for\nadjusting for this control confounding, enabling the estimation of a causal\nsteady-state model from closed-loop steady-state data. The formula assumes that\nthe available data have been gathered under some fixed control law. It works by\nestimating and taking into account the disturbance which the controller is\ntrying to counteract, and enables learning from data gathered under both\nfeedforward and feedback control.",
    "descriptor": "\nComments: 8 pages, 3 figures. This work has been submitted to IFAC for possible publication\n",
    "authors": [
      "Kristian L\u00f8vland",
      "Bjarne Grimstad",
      "Lars Struen Imsland"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.05613"
  },
  {
    "id": "arXiv:2211.05617",
    "title": "Debiasing Methods for Fairer Neural Models in Vision and Language  Research: A Survey",
    "abstract": "Despite being responsible for state-of-the-art results in several computer\nvision and natural language processing tasks, neural networks have faced harsh\ncriticism due to some of their current shortcomings. One of them is that neural\nnetworks are correlation machines prone to model biases within the data instead\nof focusing on actual useful causal relationships. This problem is particularly\nserious in application domains affected by aspects such as race, gender, and\nage. To prevent models from incurring on unfair decision-making, the AI\ncommunity has concentrated efforts in correcting algorithmic biases, giving\nrise to the research area now widely known as fairness in AI. In this survey\npaper, we provide an in-depth overview of the main debiasing methods for\nfairness-aware neural networks in the context of vision and language research.\nWe propose a novel taxonomy to better organize the literature on debiasing\nmethods for fairness, and we discuss the current challenges, trends, and\nimportant future work directions for the interested researcher and\npractitioner.",
    "descriptor": "\nComments: Submitted to ACM Computing Surveys - Special Issue on Trustworthy AI\n",
    "authors": [
      "Ot\u00e1vio Parraga",
      "Martin D. More",
      "Christian M. Oliveira",
      "Nathan S. Gavenski",
      "Lucas S. Kupssinsk\u00fc",
      "Adilson Medronha",
      "Luis V. Moura",
      "Gabriel S. Sim\u00f5es",
      "Rodrigo C. Barros"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.05617"
  },
  {
    "id": "arXiv:2211.05623",
    "title": "A high order discontinuous Galerkin method for the recovery of the  conductivity in Electrical Impedance Tomography",
    "abstract": "In this work, we develop an efficient high order discontinuous Galerkin (DG)\nmethod for solving the Electrical Impedance Tomography (EIT). EIT is a highly\nnonlinear ill-posed inverse problem where the interior conductivity of an\nobject is recovered from the surface measurements of voltage and current flux.\nWe first propose a new optimization problem based on the recovery of the\nconductivity from the Dirichlet-to-Neumann map to minimize the mismatch between\nthe predicted current and the measured current on the boundary. And we further\nprove the existence of the minimizer. Numerically the optimization problem is\nsolved by a third order DG method with quadratic polynomials. Numerical results\nfor several two-dimensional problems with both single and multiple inclusions\nare demonstrated to show the high accurate and efficient of the proposed high\norder DG method. A problem with discontinuous background is also presented to\nshow the advantage of DG method over other conventional methods.",
    "descriptor": "",
    "authors": [
      "Xiaosheng Li",
      "Wei Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.05623"
  },
  {
    "id": "arXiv:2211.05624",
    "title": "Improving the Robustness of Neural Multiplication Units with Reversible  Stochasticity",
    "abstract": "Multilayer Perceptrons struggle to learn certain simple arithmetic tasks.\nSpecialist neural modules for arithmetic can outperform classical architectures\nwith gains in extrapolation, interpretability and convergence speeds, but are\nhighly sensitive to the training range. In this paper, we show that Neural\nMultiplication Units (NMUs) are unable to reliably learn tasks as simple as\nmultiplying two inputs when given different training ranges. Causes of failure\nare linked to inductive and input biases which encourage convergence to\nsolutions in undesirable optima. A solution, the stochastic NMU (sNMU), is\nproposed to apply reversible stochasticity, encouraging avoidance of such\noptima whilst converging to the true solution. Empirically, we show that\nstochasticity provides improved robustness with the potential to improve\nlearned representations of upstream networks for numerical and image tasks.",
    "descriptor": "\nComments: 26 pages (10 page main body)\n",
    "authors": [
      "Bhumika Mistry",
      "Katayoun Farrahi",
      "Jonathon Hare"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.05624"
  },
  {
    "id": "arXiv:2211.05627",
    "title": "Representing LLVM-IR in a Code Property Graph",
    "abstract": "In the past years, a number of static application security testing tools have\nbeen proposed which make use of so-called code property graphs, a graph model\nwhich keeps rich information about the source code while enabling its user to\nwrite language-agnostic analyses. However, they suffer from several\nshortcomings. They work mostly on source code and exclude the analysis of\nthird-party dependencies if they are only available as compiled binaries.\nFurthermore, they are limited in their analysis to whether an individual\nprogramming language is supported or not. While often support for\nwell-established languages such as C/C++ or Java is included, languages that\nare still heavily evolving, such as Rust, are not considered because of the\nconstant changes in the language design. To overcome these limitations, we\nextend an open source implementation of a code property graph to support\nLLVM-IR which can be used as output by many compilers and binary lifters. In\nthis paper, we discuss how we address challenges that arise when mapping\nconcepts of an intermediate representation to a CPG. At the same time, we\noptimize the resulting graph to be minimal and close to the representation of\nequivalent source code. Our evaluation indicates that existing analyses can be\nreused without modifications and that the performance requirements are\ncomparable to operating on source code. This makes the approach suitable for an\nanalysis of large-scale projects.",
    "descriptor": "\nComments: To be published in: 25th Information Security Conference (ISC) 2022\n",
    "authors": [
      "Alexander K\u00fcchler",
      "Christian Banse"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.05627"
  },
  {
    "id": "arXiv:2211.05629",
    "title": "Haven't I Seen You Before? Assessing Identity Leakage in Synthetic  Irises",
    "abstract": "Generative Adversarial Networks (GANs) have proven to be a preferred method\nof synthesizing fake images of objects, such as faces, animals, and\nautomobiles. It is not surprising these models can also generate ISO-compliant,\nyet synthetic iris images, which can be used to augment training data for iris\nmatchers and liveness detectors. In this work, we trained one of the most\nrecent GAN models (StyleGAN3) to generate fake iris images with two primary\ngoals: (i) to understand the GAN's ability to produce \"never-before-seen\"\nirises, and (ii) to investigate the phenomenon of identity leakage as a\nfunction of the GAN's training time. Previous work has shown that personal\nbiometric data can inadvertently flow from training data into synthetic\nsamples, raising a privacy concern for subjects who accidentally appear in the\ntraining dataset. This paper presents analysis for three different iris\nmatchers at varying points in the GAN training process to diagnose where and\nwhen authentic training samples are in jeopardy of leaking through the\ngenerative process. Our results show that while most synthetic samples do not\nshow signs of identity leakage, a handful of generated samples match authentic\n(training) samples nearly perfectly, with consensus across all matchers. In\norder to prioritize privacy, security, and trust in the machine learning model\ndevelopment process, the research community must strike a delicate balance\nbetween the benefits of using synthetic data and the corresponding threats\nagainst privacy from potential identity leakage.",
    "descriptor": "\nComments: Presented at IJCB 2022 Special Session on Synthetic Data in Biometrics\n",
    "authors": [
      "Patrick Tinsley",
      "Adam Czajka",
      "Patrick Flynn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05629"
  },
  {
    "id": "arXiv:2211.05630",
    "title": "Quorum Systems in Permissionless Network",
    "abstract": "Fail-prone systems, and their quorum systems, are useful tools for the design\nof distributed algorithms. However, fail-prone systems as studied so far\nrequire every process to know the full system membership in order to guarantee\nsafety through globally intersecting quorums. Thus, they are of little help in\nan open, permissionless setting, where such knowledge may not be available. We\npropose to generalize the theory of fail-prone systems to make it applicable to\npermissionless systems. We do so by enabling processes not only to make\nassumptions about failures, but also to make assumptions about the assumptions\nof other processes. Thus, by transitivity, processes that do not even know of\nany common process may nevertheless have intersecting quorums and solve, for\nexample, reliable broadcast. Our model generalizes existing models such as the\nclassic fail-prone system model [Malkhi and Reiter, 1998] and the asymmetric\nfail-prone system model [Cachin and Tackmann, OPODIS 2019]. Moreover, it gives\na characterization with standard formalism of the model used by the Stellar\nblockchain.",
    "descriptor": "",
    "authors": [
      "Christian Cachin",
      "Giuliano Losa",
      "Luca Zanolini"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.05630"
  },
  {
    "id": "arXiv:2211.05631",
    "title": "Backdoor Defense via Suppressing Model Shortcuts",
    "abstract": "Recent studies have demonstrated that deep neural networks (DNNs) are\nvulnerable to backdoor attacks during the training process. Specifically, the\nadversaries intend to embed hidden backdoors in DNNs so that malicious model\npredictions can be activated through pre-defined trigger patterns. In this\npaper, we explore the backdoor mechanism from the angle of the model structure.\nWe select the skip connection for discussions, inspired by the understanding\nthat it helps the learning of model `shortcuts' where backdoor triggers are\nusually easier to be learned. Specifically, we demonstrate that the attack\nsuccess rate (ASR) decreases significantly when reducing the outputs of some\nkey skip connections. Based on this observation, we design a simple yet\neffective backdoor removal method by suppressing the skip connections in\ncritical layers selected by our method. We also implement fine-tuning on these\nlayers to recover high benign accuracy and to further reduce ASR. Extensive\nexperiments on benchmark datasets verify the effectiveness of our method.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Sheng Yang",
      "Yiming Li",
      "Yong Jiang",
      "Shu-Tao Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05631"
  },
  {
    "id": "arXiv:2211.05635",
    "title": "Generalized Wardrop Equilibrium for Charging Station Selection and Route  Choice of Electric Vehicles in Joint Power Distribution and Transportation  Networks",
    "abstract": "This paper presents the equilibrium analysis of a game composed of\nheterogeneous electric vehicles (EVs) and a power distribution system operator\n(DSO) as players in the game, and charging station operators (CSOs) and a\ntransportation network operator (TNO) as coordinators. Each EV tries to pick a\ncharging station as its destination and a route to get there at the same time.\nHowever, the traffic and electrical load congestion on the roads and charging\nstations lead to the interdependencies between the optimal decisions of EVs. In\naddition, CSOs and the TNO need to apply some tolling to control such\ncongestion. On the other hand, the pricing in charging stations depends on\nreal-time distributional locational marginal pricing, which is determined by\nthe DSO after solving the optimal power flow over the power distribution\nnetwork. This paper also takes into account the local and the\ncoupling/infrastructure constraints of EVs as well as transportation and\ndistribution networks. This problem is modeled as a generalized aggregative\ngame, and then a decentralized learning method is proposed to obtain an\nequilibrium point of the game, which is known as variational generalized\nWardrop equilibrium. The existence of such an equilibrium point and the\nconvergence of the proposed algorithm to it are theoretically proven. The\nproposed decentralized learning method is scalable and privacy-preserving for\nEVs. We undertake numerical studies on the Savannah city model and the IEEE\n33-bus distribution network and investigate the impact of various\ncharacteristics on demand and prices.",
    "descriptor": "\nComments: Under review at IEEE Transactions on Control of Network Systems\n",
    "authors": [
      "Babak Ghaffarzadeh Bakhshayesh",
      "Hamed Kebriaei"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.05635"
  },
  {
    "id": "arXiv:2211.05636",
    "title": "Rare Wildlife Recognition with Self-Supervised Representation Learning",
    "abstract": "Automated animal censuses with aerial imagery are a vital ingredient towards\nwildlife conservation. Recent models are generally based on supervised learning\nand thus require vast amounts of training data. Due to their scarcity and\nminuscule size, annotating animals in aerial imagery is a highly tedious\nprocess. In this project, we present a methodology to reduce the amount of\nrequired training data by resorting to self-supervised pretraining. In detail,\nwe examine a combination of recent contrastive learning methodologies like\nMomentum Contrast (MoCo) and Cross-Level Instance-Group Discrimination (CLD) to\ncondition our model on the aerial images without the requirement for labels. We\nshow that a combination of MoCo, CLD, and geometric augmentations outperforms\nconventional models pretrained on ImageNet by a large margin. Meanwhile,\nstrategies for smoothing label or prediction distribution in supervised\nlearning have been proven useful in preventing the model from overfitting. We\ncombine the self-supervised contrastive models with image mixup strategies and\nfind that it is useful for learning more robust visual representations.\nCrucially, our methods still yield favorable results even if we reduce the\nnumber of training animals to just 10%, at which point our best model scores\ndouble the recall of the baseline at similar precision. This effectively allows\nreducing the number of required annotations to a fraction while still being\nable to train high-accuracy models in such highly challenging settings.",
    "descriptor": "\nComments: A dissertation submitted to attain the degree of Master of Sciences of ETH Zurich in August 2021. Code is available at: this https URL\n",
    "authors": [
      "Xiaochen Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05636"
  },
  {
    "id": "arXiv:2211.05637",
    "title": "Description Graphs, Matrix-Power Stabilizations and Graph Isomorphism in  Polynomial Time",
    "abstract": "It is confirmed in this work that the graph isomorphism can be tested in\npolynomial time, which resolves a longstanding problem in the theory of\ncomputation. The contributions are in three phases as follows.\n1. A description graph $\\tilde{A}$ to a given graph $A$ is introduced so that\nlabels to vertices and edges of $\\tilde{A}$ indicate the identical or different\namounts of walks of any sort in any length between vertices in $A$. Three\nprocesses are then developed to obtain description graphs. They reveal\nrelations among matrix power, spectral decomposition and adjoint matrices,\nwhich is of independent interest.\n2. We show that the stabilization of description graphs can be implemented\nvia matrix-power stabilization, a new approach to distinguish vertices and\nedges to graphs. The approach is proven to be equivalent in the partition of\nvertices to Weisfeiler-Lehman (WL for short) process. The specific\nSquare-and-Substitution (SaS) process is more succinct than WL process.\nThe vertex partitions to our stable graphs are proven to be \\emph{strongly}\nequitable partitions, which is important in the proofs of our main conclusion.\nSome properties on stable graphs are also explored.\n3. A class of graphs named binding graphs is proposed and proven to be\ngraph-isomorphism complete. The vertex partition to the stable graph of a\nbinding graph is the automorphism partition, which allows us to confirm\ngraph-isomorphism problem is in complexity class $\\mathtt{P}$. Since the\nbinding graph to a graph is so simple in construction, our approach can be\nreadily applied in practice.",
    "descriptor": "",
    "authors": [
      "Rui Xue"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.05637"
  },
  {
    "id": "arXiv:2211.05638",
    "title": "Untargeted Backdoor Attack against Object Detection",
    "abstract": "Recent studies revealed that deep neural networks (DNNs) are exposed to\nbackdoor threats when training with third-party resources (such as training\nsamples or backbones). The backdoored model has promising performance in\npredicting benign samples, whereas its predictions can be maliciously\nmanipulated by adversaries based on activating its backdoors with pre-defined\ntrigger patterns. Currently, most of the existing backdoor attacks were\nconducted on the image classification under the targeted manner. In this paper,\nwe reveal that these threats could also happen in object detection, posing\nthreatening risks to many mission-critical applications ($e.g.$, pedestrian\ndetection and intelligent surveillance systems). Specifically, we design a\nsimple yet effective poison-only backdoor attack in an untargeted manner, based\non task characteristics. We show that, once the backdoor is embedded into the\ntarget model by our attack, it can trick the model to lose detection of any\nobject stamped with our trigger patterns. We conduct extensive experiments on\nthe benchmark dataset, showing its effectiveness in both digital and\nphysical-world settings and its resistance to potential defenses.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Chengxiao Luo",
      "Yiming Li",
      "Yong Jiang",
      "Shu-Tao Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05638"
  },
  {
    "id": "arXiv:2211.05640",
    "title": "UAV Traffic Management : A Survey On Communication Security",
    "abstract": "Unmanned Aerial Systems (UAS) have a wide variety of applications, and their\ndevelopment in terms of capabilities is continuously evolving. Many missions\nperformed by an Unmanned Aerial Vehicle (UAV) require flying in public\nairspace. This requires very high safety standards, similar to those mandatory\nin commercial civil aviation. A safe UAV Traffic Management (UTM) requires\nseveral communication links between aircraft, their pilots and UTM systems. The\nintegrity of these communication links is critical for the safety of\noperations. Several security requirements also have to be met on each of these\nlinks. Unfortunately, current cryptographic standards used over the internet\nare most often not suitable to UAS due to their limited resources and dynamic\nnature. This survey discusses the security required for every communication\nlink in order to enable a safe traffic management. Research works focusing on\nthe security of communication links using cryptographic primitives are then\npresented and discussed. Authentication protocols developed for UAVs or other\nconstrained systems are compared and evaluated as solutions for UAS security.\nSymmetrical alternatives to the AES algorithm are also presented. Works to\nsecure current UTM protocols such as ADS-B and RemoteID are discussed. The\nanalysis reveals a need for the development of a complete secure architecture\nable to provide authentication and integrity to external systems (other\naircraft, UTM systems...).",
    "descriptor": "",
    "authors": [
      "Ridwane Aissaoui",
      "Jean-Christophe Deneuville",
      "Christophe Guerber",
      "Alain Pirovano"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.05640"
  },
  {
    "id": "arXiv:2211.05641",
    "title": "Regression as Classification: Influence of Task Formulation on Neural  Network Features",
    "abstract": "Neural networks can be trained to solve regression problems by using\ngradient-based methods to minimize the square loss. However, practitioners\noften prefer to reformulate regression as a classification problem, observing\nthat training on the cross entropy loss results in better performance. By\nfocusing on two-layer ReLU networks, which can be fully characterized by\nmeasures over their feature space, we explore how the implicit bias induced by\ngradient-based optimization could partly explain the above phenomenon. We\nprovide theoretical evidence that the regression formulation yields a measure\nwhose support can differ greatly from that for classification, in the case of\none-dimensional data. Our proposed optimal supports correspond directly to the\nfeatures learned by the input layer of the network. The different nature of\nthese supports sheds light on possible optimization difficulties the square\nloss could encounter during training, and we present empirical results\nillustrating this phenomenon.",
    "descriptor": "",
    "authors": [
      "Lawrence Stewart",
      "Francis Bach",
      "Quentin Berthet",
      "Jean-Philippe Vert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.05641"
  },
  {
    "id": "arXiv:2211.05642",
    "title": "Normal reconstruction from specularity in the endoscopic setting",
    "abstract": "We show that for a plane imaged by an endoscope the specular isophotes are\nconcentric circles on the scene plane, which appear as nested ellipses in the\nimage. We show that these ellipses can be detected and used to estimate the\nplane's normal direction, forming a normal reconstruction method, which we\nvalidate on simulated data. In practice, the anatomical surfaces visible in\nendoscopic images are locally planar. We use our method to show that the\nsurface normal can thus be reconstructed for each of the numerous specularities\ntypically visible on moist tissues. We show results on laparoscopic and\ncolonoscopic images.",
    "descriptor": "",
    "authors": [
      "Karim Makki",
      "Adrien Bartoli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05642"
  },
  {
    "id": "arXiv:2211.05654",
    "title": "Efficient Joint Detection and Multiple Object Tracking with Spatially  Aware Transformer",
    "abstract": "We propose a light-weight and highly efficient Joint Detection and Tracking\npipeline for the task of Multi-Object Tracking using a fully-transformer\narchitecture. It is a modified version of TransTrack, which overcomes the\ncomputational bottleneck associated with its design, and at the same time,\nachieves state-of-the-art MOTA score of 73.20%. The model design is driven by a\ntransformer based backbone instead of CNN, which is highly scalable with the\ninput resolution. We also propose a drop-in replacement for Feed Forward\nNetwork of transformer encoder layer, by using Butterfly Transform Operation to\nperform channel fusion and depth-wise convolution to learn spatial context\nwithin the feature maps, otherwise missing within the attention maps of the\ntransformer. As a result of our modifications, we reduce the overall model size\nof TransTrack by 58.73% and the complexity by 78.72%. Therefore, we expect our\ndesign to provide novel perspectives for architecture optimization in future\nresearch related to multi-object tracking.",
    "descriptor": "",
    "authors": [
      "Siddharth Sagar Nijhawan",
      "Leo Hoshikawa",
      "Atsushi Irie",
      "Masakazu Yoshimura",
      "Junji Otsuka",
      "Takeshi Ohashi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05654"
  },
  {
    "id": "arXiv:2211.05655",
    "title": "DisentQA: Disentangling Parametric and Contextual Knowledge with  Counterfactual Question Answering",
    "abstract": "Question answering models commonly have access to two sources of \"knowledge\"\nduring inference time: (1) parametric knowledge - the factual knowledge encoded\nin the model weights, and (2) contextual knowledge - external knowledge (e.g.,\na Wikipedia passage) given to the model to generate a grounded answer. Having\nthese two sources of knowledge entangled together is a core issue for\ngenerative QA models as it is unclear whether the answer stems from the given\nnon-parametric knowledge or not. This unclarity has implications on issues of\ntrust, interpretability and factuality. In this work, we propose a new paradigm\nin which QA models are trained to disentangle the two sources of knowledge.\nUsing counterfactual data augmentation, we introduce a model that predicts two\nanswers for a given question: one based on given contextual knowledge and one\nbased on parametric knowledge. Our experiments on the Natural Questions dataset\nshow that this approach improves the performance of QA models by making them\nmore robust to knowledge conflicts between the two knowledge sources, while\ngenerating useful disentangled answers.",
    "descriptor": "\nComments: 12 pages, 2 figures\n",
    "authors": [
      "Ella Neeman",
      "Roee Aharoni",
      "Or Honovich",
      "Leshem Choshen",
      "Idan Szpektor",
      "Omri Abend"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05655"
  },
  {
    "id": "arXiv:2211.05656",
    "title": "Probabilistically Robust PAC Learning",
    "abstract": "Recently, Robey et al. propose a notion of probabilistic robustness, which,\nat a high-level, requires a classifier to be robust to most but not all\nperturbations. They show that for certain hypothesis classes where proper\nlearning under worst-case robustness is \\textit{not} possible, proper learning\nunder probabilistic robustness \\textit{is} possible with sample complexity\nexponentially smaller than in the worst-case robustness setting. This motivates\nthe question of whether proper learning under probabilistic robustness is\nalways possible. In this paper, we show that this is \\textit{not} the case. We\nexhibit examples of hypothesis classes $\\mathcal{H}$ with finite VC dimension\nthat are \\textit{not} probabilistically robustly PAC learnable with\n\\textit{any} proper learning rule. However, if we compare the output of the\nlearner to the best hypothesis for a slightly \\textit{stronger} level of\nprobabilistic robustness, we show that not only is proper learning\n\\textit{always} possible, but it is possible via empirical risk minimization.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "VInod Raman",
      "Unique Subedi",
      "Ambuj Tewari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.05656"
  },
  {
    "id": "arXiv:2211.05657",
    "title": "Stochastic Network Calculus with Localized Application of Martingales",
    "abstract": "Stochastic Network Calculus is a probabilistic method to compute performance\nbounds in networks, such as end-to-end delays. It relies on the analysis of\nstochastic processes using formalism of (Deterministic) Network Calculus.\nHowever, unlike the deterministic theory, the computed bounds are usually very\nloose compared to the simulation. This is mainly due to the intensive use of\nthe Boole's inequality. On the other hand, analyses based on martingales can\nachieve tight bounds, but until now, they have not been applied to sequences of\nservers. In this paper, we improve the accuracy of Stochastic Network Calculus\nby combining this martingale analysis with a recent Stochastic Network Calculus\nresults based on the Pay-Multiplexing-Only-Once property, well-known from the\nDeterministic Network calculus. We exhibit a non-trivial class of networks that\ncan benefit from this analysis and compare our bounds with simulation.",
    "descriptor": "",
    "authors": [
      "Anne Bouillard"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.05657"
  },
  {
    "id": "arXiv:2211.05659",
    "title": "Finding Critical Nodes in Interdependent Networks with SAT and ILP  Solvers",
    "abstract": "Infrastructure systems, such as power systems, often experience cascading\nfailures. Modeling an infrastructure system as a collection of interdependent\nnetworks has recently received attention as a way to explain cascading\nfailures. In this study, we propose an approach to find the set of critical\nnodes in an interdependent network. For an integer k, we say that a set of k\nnodes is critical if the initial failures of these k nodes result in the most\nsevere cascading failure among all sets of k nodes. This approach adopts the\nseminal model of interdependent networks proposed by Buldyrev et al., in which\nnew link failures occur in a network if the connectivity is lost in the paired\nnetwork. The problem of finding critical nodes is NP-hard; thus the aim of the\napproach is to accurately solve the problem in feasible time for moderate-size\nproblem instances. The proposed approach consists of two phases. In the first\nphase, the maximum number of failure propagation stages is computed by\nrepeatedly solving the Boolean satisfiability problem. This number is then used\nin the second phase, where the set of critical nodes is computed using integer\nlinear programming. The results of applying this approach to a variety of\nproblem instances demonstrate that the approach is feasible for up to at least\n30 nodes and can be used as the baseline to compare the performance of\nheuristic solutions.",
    "descriptor": "",
    "authors": [
      "Kyozo Hida",
      "Tatsuhiro Tsuchiya"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.05659"
  },
  {
    "id": "arXiv:2211.05662",
    "title": "Warmup and Transfer Knowledge-Based Federated Learning Approach for IoT  Continuous Authentication",
    "abstract": "Continuous behavioural authentication methods add a unique layer of security\nby allowing individuals to verify their unique identity when accessing a\ndevice. Maintaining session authenticity is now feasible by monitoring users'\nbehaviour while interacting with a mobile or Internet of Things (IoT) device,\nmaking credential theft and session hijacking ineffective. Such a technique is\nmade possible by integrating the power of artificial intelligence and Machine\nLearning (ML). Most of the literature focuses on training machine learning for\nthe user by transmitting their data to an external server, subject to private\nuser data exposure to threats. In this paper, we propose a novel Federated\nLearning (FL) approach that protects the anonymity of user data and maintains\nthe security of his data. We present a warmup approach that provides a\nsignificant accuracy increase. In addition, we leverage the transfer learning\ntechnique based on feature extraction to boost the models' performance. Our\nextensive experiments based on four datasets: MNIST, FEMNIST, CIFAR-10 and\nUMDAA-02-FD, show a significant increase in user authentication accuracy while\nmaintaining user privacy and data security.",
    "descriptor": "",
    "authors": [
      "Mohamad Wazzeh",
      "Hakima Ould-Slimane",
      "Chamseddine Talhi",
      "Azzam Mourad",
      "Mohsen Guizani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.05662"
  },
  {
    "id": "arXiv:2211.05667",
    "title": "Does the explanation satisfy your needs?: A unified view of properties  of explanations",
    "abstract": "Interpretability provides a means for humans to verify aspects of machine\nlearning (ML) models and empower human+ML teaming in situations where the task\ncannot be fully automated. Different contexts require explanations with\ndifferent properties. For example, the kind of explanation required to\ndetermine if an early cardiac arrest warning system is ready to be integrated\ninto a care setting is very different from the type of explanation required for\na loan applicant to help determine the actions they might need to take to make\ntheir application successful.\nUnfortunately, there is a lack of standardization when it comes to properties\nof explanations: different papers may use the same term to mean different\nquantities, and different terms to mean the same quantity. This lack of a\nstandardized terminology and categorization of the properties of ML\nexplanations prevents us from both rigorously comparing interpretable machine\nlearning methods and identifying what properties are needed in what contexts.\nIn this work, we survey properties defined in interpretable machine learning\npapers, synthesize them based on what they actually measure, and describe the\ntrade-offs between different formulations of these properties. In doing so, we\nenable more informed selection of task-appropriate formulations of explanation\nproperties as well as standardization for future work in interpretable machine\nlearning.",
    "descriptor": "\nComments: Short version accepted at NeurIPS 2022 workshops on Progress and Challenges in Building Trustworthy Embodied AI and Trustworthy and Socially Responsible Machine Learning\n",
    "authors": [
      "Zixi Chen",
      "Varshini Subhash",
      "Marton Havasi",
      "Weiwei Pan",
      "Finale Doshi-Velez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05667"
  },
  {
    "id": "arXiv:2211.05673",
    "title": "BERT in Plutarch's Shadows",
    "abstract": "The extensive surviving corpus of the ancient scholar Plutarch of Chaeronea\n(ca. 45-120 CE) also contains several texts which, according to current\nscholarly opinion, did not originate with him and are therefore attributed to\nan anonymous author Pseudo-Plutarch. These include, in particular, the work\nPlacita Philosophorum (Quotations and Opinions of the Ancient Philosophers),\nwhich is extremely important for the history of ancient philosophy. Little is\nknown about the identity of that anonymous author and its relation to other\nauthors from the same period. This paper presents a BERT language model for\nAncient Greek. The model discovers previously unknown statistical properties\nrelevant to these literary, philosophical, and historical problems and can shed\nnew light on this authorship question. In particular, the Placita\nPhilosophorum, together with one of the other Pseudo-Plutarch texts, shows\nsimilarities with the texts written by authors from an Alexandrian context\n(2nd/3rd century CE).",
    "descriptor": "",
    "authors": [
      "Ivan P. Yamshchikov",
      "Alexey Tikhonov",
      "Yorgos Pantis",
      "Charlotte Schubert",
      "J\u00fcrgen Jost"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05673"
  },
  {
    "id": "arXiv:2211.05675",
    "title": "Causal Modeling of Soil Processes for Improved Generalization",
    "abstract": "Measuring and monitoring soil organic carbon is critical for agricultural\nproductivity and for addressing critical environmental problems. Soil organic\ncarbon not only enriches nutrition in soil, but also has a gamut of co-benefits\nsuch as improving water storage and limiting physical erosion. Despite a litany\nof work in soil organic carbon estimation, current approaches do not generalize\nwell across soil conditions and management practices. We empirically show that\nexplicit modeling of cause-and-effect relationships among the soil processes\nimproves the out-of-distribution generalizability of prediction models. We\nprovide a comparative analysis of soil organic carbon estimation models where\nthe skeleton is estimated using causal discovery methods. Our framework provide\nan average improvement of 81% in test mean squared error and 52% in test mean\nabsolute error.",
    "descriptor": "\nComments: NeurIPS 2022 Workshop Tackling Climate Change with Machine Learning\n",
    "authors": [
      "Somya Sharma",
      "Swati Sharma",
      "Andy Neal",
      "Sara Malvar",
      "Eduardo Rodrigues",
      "John Crawford",
      "Emre Kiciman",
      "Ranveer Chandra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.05675"
  },
  {
    "id": "arXiv:2211.05677",
    "title": "Multivariate compactly supported $C^\\infty$ functions by subdivision",
    "abstract": "This paper discusses the generation of multivariate $C^\\infty$ functions with\ncompact small supports by subdivision schemes. Following the construction of\nsuch a univariate function, called \\emph{Up-function}, by a non-stationary\nscheme based on masks of {spline subdivision schemes} of growing degrees, we\nterm the multivariate functions we generate Up-like functions. We generate them\nby non-stationary schemes based on masks of box-splines of growing supports. To\nanalyze the convergence and smoothness of these non-stationary schemes, we\ndevelop new tools which apply to a wider class of schemes than the class we\nstudy. With our method for achieving small compact supports, we obtain, in the\nunivariate case, Up-like functions with supports $[0, 1 +\\epsilon ]$ in\ncomparison to the support $[0, 2] $ of the Up-function. Examples of univariate\nand bivariate Up-like functions are given. As in the univariate case, the\nconstruction of Up-like functions can motivate the generation of $C^\\infty$\ncompactly supported wavelets of small support in any dimension.",
    "descriptor": "",
    "authors": [
      "Maria Charina",
      "Costanza Conti",
      "Nira Dyn"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.05677"
  },
  {
    "id": "arXiv:2211.05682",
    "title": "FlowDNS: Correlating Netflow and DNS Streams at Scale",
    "abstract": "Knowing customer's interests, e.g. which Video-On-Demand (VoD) or Social\nNetwork services they are using, helps telecommunication companies with better\nnetwork planning to enhance the performance exactly where the customer's\ninterests lie, and also offer the customers relevant commercial packages.\nHowever, with the increasing deployment of CDNs by different services,\nidentification, and attribution of the traffic on network-layer information\nalone becomes a challenge: If multiple services are using the same CDN\nprovider, they cannot be easily distinguished based on IP prefixes alone.\nTherefore, it is crucial to go beyond pure network-layer information for\ntraffic attribution. In this work, we leverage real-time DNS responses gathered\nby the clients' default DNS resolvers. Having these DNS responses and\ncorrelating them with network-layer headers, we are able to translate\nCDN-hosted domains to the actual services they belong to. We design a\ncorrelation system for this purpose and deploy it at a large European ISP. With\nour system, we can correlate an average of 81.7% of the traffic with the\ncorresponding services, without any loss on our live data streams. Our\ncorrelation results also show that 0.5% of the daily traffic contains\nmalformatted, spamming, or phishing domain names. Moreover, ISPs can correlate\nthe results with their BGP information to find more details about the origin\nand destination of the traffic. We plan to publish our correlation software for\nother researchers or network operators to use.",
    "descriptor": "",
    "authors": [
      "Aniss Maghsoudlou",
      "Oliver Gasser",
      "Ingmar Poese",
      "Anja Feldmann"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.05682"
  },
  {
    "id": "arXiv:2211.05695",
    "title": "A new data structure for efficient search on isovists",
    "abstract": "Spatial data structures allow to make efficient queries on Geographical\nInformation Systems (GIS). Spatial queries involve the geometry of the data,\nsuch as points, lines, or polygons. For instance, a spatial query could poll\nfor the nearest restaurants from a given location. Spatial queries can be\nsolved exhaustively by going through the entire data, which is prohibitive as\nthe number of data points increases. In this article, we are interested in\nmaking efficient queries on infinitely long geometrical shapes. For instance,\nangular sectors, defined as the intersection of two half-spaces, are infinitely\nlong. However, regular spatial data structures are not adapted to these\ngeometrical shapes. We propose a new method allowing to make efficient spatial\nqueries on angular sectors (i.e. whether a point is inside an angular sector).\nIt builds a R-tree from the dual space of angular sectors. An extensive\nevaluation shows our method is faster than using a regular R-tree.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Florent Gr\u00e9lard",
      "Mehdi Ayadi",
      "Mihaela Scuturici",
      "Serge Miguet"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.05695"
  },
  {
    "id": "arXiv:2211.05696",
    "title": "A sufficient condition for $k$-contraction in Lurie systems",
    "abstract": "We consider a Lurie system obtained via a connection of a linear\ntime-invariant system and a nonlinear feedback function. Such systems often\nhave more than a single equilibrium and are thus not contractive with respect\nto any norm. We derive a new sufficient condition for $k$-contraction of a\nLurie system. For $k=1$, our sufficient condition reduces to the standard\nstability condition based on the bounded real lemma and a small gain condition.\nFor $k=2$, our condition guarantees well-ordered asymptotic behaviour of the\nclosed-loop system: every bounded solution converges to an equilibrium, which\nis not necessarily unique. We demonstrate our results by deriving a sufficient\ncondition for $k$-contractivity of a networked system.",
    "descriptor": "",
    "authors": [
      "Ron Ofir",
      "Alexander Ovseevich",
      "Michael Margaliot"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.05696"
  },
  {
    "id": "arXiv:2211.05697",
    "title": "Bayesian hierarchical modelling for battery lifetime early prediction",
    "abstract": "Accurate prediction of battery health is essential for real-world system\nmanagement and lab-based experiment design. However, building a life-prediction\nmodel from different cycling conditions is still a challenge. Large lifetime\nvariability results from both cycling conditions and initial manufacturing\nvariability, and this -- along with the limited experimental resources usually\navailable for each cycling condition -- makes data-driven lifetime prediction\nchallenging. Here, a hierarchical Bayesian linear model is proposed for battery\nlife prediction, combining both individual cell features (reflecting\nmanufacturing variability) with population-wide features (reflecting the impact\nof cycling conditions on the population average). The individual features were\ncollected from the first 100 cycles of data, which is around 5-10% of lifetime.\nThe model is able to predict end of life with a root mean square error of 3.2\ndays and mean absolute percentage error of 8.6%, measured through 5-fold\ncross-validation, overperforming the baseline (non-hierarchical) model by\naround 12-13%.",
    "descriptor": "\nComments: 7 pages, 8 figures\n",
    "authors": [
      "Zihao Zhou",
      "David A. Howey"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05697"
  },
  {
    "id": "arXiv:2211.05700",
    "title": "Translating proofs from an impredicative type system to a predicative  one",
    "abstract": "As the development of formal proofs is a time-consuming task, it is important\nto devise ways of sharing the already written proofs to prevent wasting time\nredoing them. One of the challenges in this domain is to translate proofs\nwritten in proof assistants based on impredicative logics, such as Coq, Matita\nand the HOL family, to proof assistants based on predicative logics like Agda,\nwhenever impredicativity is not used in an essential way. In this paper we\npresent an algorithm to do such a translation between a core impredicative type\nsystem and a core predicative one allowing prenex universe polymorphism like in\nAgda. It consists in trying to turn a potentially impredicative term into a\nuniverse polymorphic term as general as possible. The use of universe\npolymorphism is justified by the fact that mapping an impredicative universe to\na fixed predicative one is not sufficient in most cases. During the algorithm,\nwe need to solve unification problems modulo the max-successor algebra on\nuniverse levels. But, in this algebra, there are solvable problems having no\nmost general solution. We however provide an incomplete algorithm whose\nsolutions, when it succeeds, are most general ones. The proposed translation is\nof course partial, but in practice allows one to translate many proofs that do\nnot use impredicativity in an essential way. Indeed, it was implemented in the\ntool Predicativize and then used to translate semi-automatically many\nnon-trivial developments from Matita's arithmetic library to Agda, including\nBertrand's Postulate and Fermat's Little Theorem, which were not available in\nAgda yet.",
    "descriptor": "\nComments: This is the long version of a paper accepted for publication at CSL 2023\n",
    "authors": [
      "Thiago Felicissimo",
      "Fr\u00e9d\u00e9ric Blanqui",
      "Ashish Kumar Barnawal"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.05700"
  },
  {
    "id": "arXiv:2211.05702",
    "title": "A Primer on Zadoff Chu Sequences",
    "abstract": "Zadoff Chu (ZC) sequences are the primary manifestation of spread spectrum in\nmodern cellular systems including LTE and 5G NR, displacing PN and Walsh\nsequences which were the mainstays of 3G cellular (WCDMA and cdma2000) and\nIS-95. ZC sequences are complex sequences with unit amplitude and particular\nphase shifts, as opposed to Walsh and PN codes which are real and binary\nvalued, most commonly $\\pm 1$ when used in communication systems. ZC sequences\nhave a number of remarkable and desirable properties. Because of these uniquely\ndesirable properties, they are used for many key functions in current cellular\nsystems, and are likely to be prevalent in future cellular systems as well.",
    "descriptor": "\nComments: Tutorial article, not submitted for publication\n",
    "authors": [
      "Jeffrey G. Andrews"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.05702"
  },
  {
    "id": "arXiv:2211.05705",
    "title": "DiaASQ: A Benchmark of Conversational Aspect-based Sentiment Quadruple  Analysis",
    "abstract": "The rapid development of aspect-based sentiment analysis (ABSA) within recent\ndecades shows great potential for real-world society. The current ABSA works,\nhowever, are mostly limited to the scenario of a single text piece, leaving the\nstudy in dialogue contexts unexplored. In this work, we introduce a novel task\nof conversational aspect-based sentiment quadruple analysis, namely DiaASQ,\naiming to detect the sentiment quadruple of target-aspect-opinion-sentiment in\na dialogue. DiaASQ bridges the gap between fine-grained sentiment analysis and\nconversational opinion mining. We manually construct a large-scale,\nhigh-quality Chinese dataset and also obtain the English version dataset via\nmanual translation. We deliberately propose a neural model to benchmark the\ntask. It advances in effectively performing end-to-end quadruple prediction and\nmanages to incorporate rich dialogue-specific and discourse feature\nrepresentations for better cross-utterance quadruple extraction. We finally\npoint out several potential future works to facilitate the follow-up research\nof this new task. The DiaASQ data is open at https://github.com/unikcc/DiaASQ",
    "descriptor": "",
    "authors": [
      "Bobo Li",
      "Hao Fei",
      "Yuhan Wu",
      "Jinsong Zhang",
      "Shengqiong Wu",
      "Jingye Li",
      "Yijiang Liu",
      "Lizi Liao",
      "Tat-Seng Chua",
      "Fei Li",
      "Donghong Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05705"
  },
  {
    "id": "arXiv:2211.05709",
    "title": "AnimeRun: 2D Animation Visual Correspondence from Open Source 3D Movies",
    "abstract": "Existing correspondence datasets for two-dimensional (2D) cartoon suffer from\nsimple frame composition and monotonic movements, making them insufficient to\nsimulate real animations. In this work, we present a new 2D animation visual\ncorrespondence dataset, AnimeRun, by converting open source three-dimensional\n(3D) movies to full scenes in 2D style, including simultaneous moving\nbackground and interactions of multiple subjects. Our analyses show that the\nproposed dataset not only resembles real anime more in image composition, but\nalso possesses richer and more complex motion patterns compared to existing\ndatasets. With this dataset, we establish a comprehensive benchmark by\nevaluating several existing optical flow and segment matching methods, and\nanalyze shortcomings of these methods on animation data. Data, code and other\nsupplementary materials are available at\nhttps://lisiyao21.github.io/projects/AnimeRun.",
    "descriptor": "\nComments: Accepted by NeurIPS 2022 Track on Dataset and Benchmark\n",
    "authors": [
      "Li Siyao",
      "Yuhang Li",
      "Bo Li",
      "Chao Dong",
      "Ziwei Liu",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05709"
  },
  {
    "id": "arXiv:2211.05712",
    "title": "Early Performance Results on 4th Gen Intel(R) Xeon (R) Scalable  Processors with DDR and Intel(R) Xeon(R) processors, codenamed Sapphire  Rapids with HBM",
    "abstract": "The Crossroads supercomputer was designed to simulate some of the most\ncomplex physical devices in the world. These simulations routinely require 1/2\npetabyte or more of system memory running on thousands of compute nodes for\nmonths at a time on the most powerful supercomputers. Improvements in time to\nsolutions for these workloads can have major impact on our mission\ncapabilities. In this paper we present early results of representative\napplication workloads on 4th Gen Intel Xeon and Intel Xeon Processors codenamed\nSapphire Rapids with HBM. These results demonstrate an extremely promising\n8.57x improvement (node to node) over our prior generation Intel Broadwell\n(BDW) based HPC systems. No code modifications were required to achieve this\nspeedup, providing a compelling path forward toward major reductions in time to\nsolution and the complexity of physical systems that can be simulated in the\nfuture.",
    "descriptor": "",
    "authors": [
      "Galen M. Shipman",
      "Sriram Swaminarayan",
      "Gary Grider",
      "Jim Lujan",
      "R. Joseph Zerr"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.05712"
  },
  {
    "id": "arXiv:2211.05716",
    "title": "Resource-Aware Heterogeneous Federated Learning using Neural  Architecture Search",
    "abstract": "Federated Learning (FL) is extensively used to train AI/ML models in\ndistributed and privacy-preserving settings. Participant edge devices in FL\nsystems typically contain non-independent and identically distributed~(Non-IID)\nprivate data and unevenly distributed computational resources. Preserving user\ndata privacy while optimizing AI/ML models in a heterogeneous federated network\nrequires us to address data heterogeneity and system/resource heterogeneity.\nHence, we propose \\underline{R}esource-\\underline{a}ware \\underline{F}ederated\n\\underline{L}earning~(RaFL) to address these challenges. RaFL allocates\nresource-aware models to edge devices using Neural Architecture Search~(NAS)\nand allows heterogeneous model architecture deployment by knowledge extraction\nand fusion. Integrating NAS into FL enables on-demand customized model\ndeployment for resource-diverse edge devices. Furthermore, we propose a\nmulti-model architecture fusion scheme allowing the aggregation of the\ndistributed learning results. Results demonstrate RaFL's superior resource\nefficiency compared to SoTA.",
    "descriptor": "",
    "authors": [
      "Sixing Yu",
      "Phuong Nguyen",
      "Waqwoya Abebe",
      "Justin Stanley",
      "Pablo Munoz",
      "Ali Jannesari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05716"
  },
  {
    "id": "arXiv:2211.05717",
    "title": "Privacy-Preserving Machine Learning for Collaborative Data Sharing via  Auto-encoder Latent Space Embeddings",
    "abstract": "Privacy-preserving machine learning in data-sharing processes is an\never-critical task that enables collaborative training of Machine Learning (ML)\nmodels without the need to share the original data sources. It is especially\nrelevant when an organization must assure that sensitive data remains private\nthroughout the whole ML pipeline, i.e., training and inference phases. This\npaper presents an innovative framework that uses Representation Learning via\nautoencoders to generate privacy-preserving embedded data. Thus, organizations\ncan share the data representation to increase machine learning models'\nperformance in scenarios with more than one data source for a shared predictive\ndownstream task.",
    "descriptor": "",
    "authors": [
      "Ana Mar\u00eda Quintero-Ossa",
      "Jes\u00fas Solano",
      "Hern\u00e1n Jarc\u00eda",
      "David Zarruk",
      "Alejandro Correa Bahnsen",
      "Carlos Valencia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.05717"
  },
  {
    "id": "arXiv:2211.05719",
    "title": "MMDialog: A Large-scale Multi-turn Dialogue Dataset Towards Multi-modal  Open-domain Conversation",
    "abstract": "Responding with multi-modal content has been recognized as an essential\ncapability for an intelligent conversational agent. In this paper, we introduce\nthe MMDialog dataset to better facilitate multi-modal conversation. MMDialog is\ncomposed of a curated set of 1.08 million real-world dialogues with 1.53\nmillion unique images across 4,184 topics. MMDialog has two main and unique\nadvantages. First, it is the largest multi-modal conversation dataset by the\nnumber of dialogues by 8x. Second, it contains massive topics to generalize the\nopen-domain. To build engaging dialogue system with this dataset, we propose\nand normalize two response producing tasks based on retrieval and generative\nscenarios. In addition, we build two baselines for above tasks with\nstate-of-the-art techniques and report their experimental performance. We also\npropose a novel evaluation metric MM-Relevance to measure the multi-modal\nresponses. Our dataset and scripts are available in\nhttps://github.com/victorsungo/MMDialog.",
    "descriptor": "",
    "authors": [
      "Jiazhan Feng",
      "Qingfeng Sun",
      "Can Xu",
      "Pu Zhao",
      "Yaming Yang",
      "Chongyang Tao",
      "Dongyan Zhao",
      "Qingwei Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.05719"
  },
  {
    "id": "arXiv:2211.05723",
    "title": "A Python library for nonlinear system identification using Multi-Gene  Genetic Programming algorithm",
    "abstract": "Models can be built directly from input and output data trough a process\nknown as system identification. The Nonlinear AutoRegressive with eXogenous\ninputs (NARMAX) models are among the most used mathematical representations in\nthe area and has many successful applications on data-driven modeling in\ndifferent fields. Such models become extremely large when they have high degree\nof non-linearity and long-term dependencies. Hence, a structure selection\nprocess must be performed to make them parsimonious. In the present paper, it\nis introduced a toolbox in Python that performs the structure selection process\nusing the evolutionary algorithm named Multi-Gene Genetic Programming (MGGP).\nThe toolbox encapsulates basic tools for parameter estimation, simulation and\nvalidation, and it allows the users to customize their evaluation function\nincluding prior knowledge and constraints in the individual structure (gray-box\nidentification).",
    "descriptor": "",
    "authors": [
      "Henrique Carvalho de Castro",
      "Bruno Henrique Groenner Barbosa"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.05723"
  },
  {
    "id": "arXiv:2211.05729",
    "title": "How Does Sharpness-Aware Minimization Minimize Sharpness?",
    "abstract": "Sharpness-Aware Minimization (SAM) is a highly effective regularization\ntechnique for improving the generalization of deep neural networks for various\nsettings. However, the underlying working of SAM remains elusive because of\nvarious intriguing approximations in the theoretical characterizations. SAM\nintends to penalize a notion of sharpness of the model but implements a\ncomputationally efficient variant; moreover, a third notion of sharpness was\nused for proving generalization guarantees. The subtle differences in these\nnotions of sharpness can indeed lead to significantly different empirical\nresults. This paper rigorously nails down the exact sharpness notion that SAM\nregularizes and clarifies the underlying mechanism. We also show that the two\nsteps of approximations in the original motivation of SAM individually lead to\ninaccurate local conclusions, but their combination accidentally reveals the\ncorrect effect, when full-batch gradients are applied. Furthermore, we also\nprove that the stochastic version of SAM in fact regularizes the third notion\nof sharpness mentioned above, which is most likely to be the preferred notion\nfor practical performance. The key mechanism behind this intriguing phenomenon\nis the alignment between the gradient and the top eigenvector of Hessian when\nSAM is applied.",
    "descriptor": "\nComments: 81 pages, 1 figure\n",
    "authors": [
      "Kaiyue Wen",
      "Tengyu Ma",
      "Zhiyuan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.05729"
  },
  {
    "id": "arXiv:2211.05730",
    "title": "NEON: Enabling Efficient Support for Nonlinear Operations in Resistive  RAM-based Neural Network Accelerators",
    "abstract": "Resistive Random-Access Memory (RRAM) is well-suited to accelerate neural\nnetwork (NN) workloads as RRAM-based Processing-in-Memory (PIM) architectures\nnatively support highly-parallel multiply-accumulate (MAC) operations that form\nthe backbone of most NN workloads. Unfortunately, NN workloads such as\ntransformers require support for non-MAC operations (e.g., softmax) that RRAM\ncannot provide natively. Consequently, state-of-the-art works either integrate\nadditional digital logic circuits to support the non-MAC operations or offload\nthe non-MAC operations to CPU/GPU, resulting in significant performance and\nenergy efficiency overheads due to data movement.\nIn this work, we propose NEON, a novel compiler optimization to enable the\nend-to-end execution of the NN workload in RRAM. The key idea of NEON is to\ntransform each non-MAC operation into a lightweight yet highly-accurate neural\nnetwork. Utilizing neural networks to approximate the non-MAC operations\nprovides two advantages: 1) We can exploit the key strength of RRAM, i.e.,\nhighly-parallel MAC operation, to flexibly and efficiently execute non-MAC\noperations in memory. 2) We can simplify RRAM's microarchitecture by\neliminating the additional digital logic circuits while reducing the data\nmovement overheads. Acceleration of the non-MAC operations in memory enables\nNEON to achieve a 2.28x speedup compared to an idealized digital logic-based\nRRAM. We analyze the trade-offs associated with the transformation and\ndemonstrate feasible use cases for NEON across different substrates.",
    "descriptor": "\nComments: 11 pages and 11 figures\n",
    "authors": [
      "Aditya Manglik",
      "Minesh Patel",
      "Haiyu Mao",
      "Behzad Salami",
      "Jisung Park",
      "Lois Orosa",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.05730"
  },
  {
    "id": "arXiv:2211.05732",
    "title": "The Sample Complexity of Online Contract Design",
    "abstract": "We study the hidden-action principal-agent problem in an online setting. In\neach round, the principal posts a contract that specifies the payment to the\nagent based on each outcome. The agent then makes a strategic choice of action\nthat maximizes her own utility, but the action is not directly observable by\nthe principal. The principal observes the outcome and receives utility from the\nagent's choice of action. Based on past observations, the principal dynamically\nadjusts the contracts with the goal of maximizing her utility.\nWe introduce an online learning algorithm and provide an upper bound on its\nStackelberg regret. We show that when the contract space is $[0,1]^m$, the\nStackelberg regret is upper bounded by $\\widetilde O(\\sqrt{m} \\cdot\nT^{1-C/m})$, and lower bounded by $\\Omega(T^{1-1/(m+2)})$. This result shows\nthat exponential-in-$m$ samples are both sufficient and necessary to learn a\nnear-optimal contract, resolving an open problem on the hardness of online\ncontract design. When contracts are restricted to some subset $\\mathcal{F}\n\\subset [0,1]^m$, we define an intrinsic dimension of $\\mathcal{F}$ that\ndepends on the covering number of the spherical code in the space and bound the\nregret in terms of this intrinsic dimension. When $\\mathcal{F}$ is the family\nof linear contracts, the Stackelberg regret grows exactly as $\\Theta(T^{2/3})$.\nThe contract design problem is challenging because the utility function is\ndiscontinuous. Bounding the discretization error in this setting has been an\nopen problem. In this paper, we identify a limited set of directions in which\nthe utility function is continuous, allowing us to design a new discretization\nmethod and bound its error. This approach enables the first upper bound with no\nrestrictions on the contract and action space.",
    "descriptor": "",
    "authors": [
      "Banghua Zhu",
      "Stephen Bates",
      "Zhuoran Yang",
      "Yixin Wang",
      "Jiantao Jiao",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2211.05732"
  },
  {
    "id": "arXiv:2211.05733",
    "title": "RAPIDx: High-performance ReRAM Processing in-Memory Accelerator for  Sequence Alignment",
    "abstract": "Genome sequence alignment is the core of many biological applications. The\nadvancement of sequencing technologies produces a tremendous amount of data,\nmaking sequence alignment a critical bottleneck in bioinformatics analysis. The\nexisting hardware accelerators for alignment suffer from limited on-chip\nmemory, costly data movement, and poorly optimized alignment algorithms. They\ncannot afford to concurrently process the massive amount of data generated by\nsequencing machines. In this paper, we propose a ReRAM-based accelerator,\n\\Designname, using processing in-memory (PIM) for sequence alignment. \\Design\nachieves superior efficiency and performance via software-hardware co-design.\nFirst, we propose an adaptive banded parallelism alignment algorithm suitable\nfor PIM architecture. Compared to the original dynamic programming-based\nalignment, the proposed algorithm significantly reduces the required\ncomplexity, data bit width, and memory footprint at the cost of negligible\naccuracy degradation. Then we propose the efficient PIM architecture that\nimplements the proposed algorithm. The data flow in \\Design achieves four-level\nparallelism and we design an in-situ alignment computation flow in ReRAM,\ndelivering $3.7$-$6.4\\times$ efficiency and throughput improvements compared to\nour previous PIM design, RAPID. The proposed \\Design is reconfigurable to serve\nas a co-processor integrated into existing genome analysis pipeline to boost\nsequence alignment or edit distance calculation. On short-read alignment,\n\\Design delivers $86.9\\times$ and $31.0\\times$ throughput improvements over\nstate-of-the-art CPU and GPU libraries, respectively. As compared to ASIC\naccelerators for long-read alignment, the performance of \\Design is\n$1.3$-$2.0\\times$ higher.",
    "descriptor": "",
    "authors": [
      "Weihong Xu",
      "Saransh Gupta",
      "Niema Moshiri",
      "Tajana Rosing"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.05733"
  },
  {
    "id": "arXiv:2211.05737",
    "title": "Canonical Subproblems for Robot Inverse Kinematics",
    "abstract": "Inverse kinematics of many common types of robot manipulators may be\ndecomposed into canonical subproblems. This paper presents new solution methods\nto six subproblems using a linear algebra approach. The first three\nsubproblems, called the Paden-Kahan subproblems, are Subproblem 1: angle\nbetween a vector on the edge of a cone and a point, Subproblem 2: intersections\nbetween two cones, and Subproblem 3: intersections between a cone and a sphere.\nThe other three subproblems, which have not been extensively covered in the\nliterature, are Subproblem 4: intersections between a cone and a plane,\nSubproblem 5: intersections among three cones, and Subproblem 6: intersections\nin a system of four cones. We present algebraic solutions and geometric\ninterpretations for each subproblem and provide computational performance\ncomparisons. Our approach also finds the least-squares solutions for\nSubproblems 1-4 when the exact solution does not exist. We show that almost all\n6-dof all revolute (6R) robots with known closed-form solutions may be solved\nusing the subproblem decomposition method. For a general 6R robot, subproblem\ndecomposition reduces finding all solutions to a search on a circle or a 2D\ntorus. The software code is available on a publicly accessible repository.",
    "descriptor": "",
    "authors": [
      "Alexander J. Elias",
      "John T. Wen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.05737"
  },
  {
    "id": "arXiv:2211.05739",
    "title": "FedLesScan: Mitigating Stragglers in Serverless Federated Learning",
    "abstract": "Federated Learning (FL) is a machine learning paradigm that enables the\ntraining of a shared global model across distributed clients while keeping the\ntraining data local. While most prior work on designing systems for FL has\nfocused on using stateful always running components, recent work has shown that\ncomponents in an FL system can greatly benefit from the usage of serverless\ncomputing and Function-as-a-Service technologies. To this end, distributed\ntraining of models with severless FL systems can be more resource-efficient and\ncheaper than conventional FL systems. However, serverless FL systems still\nsuffer from the presence of stragglers, i.e., slow clients due to their\nresource and statistical heterogeneity. While several strategies have been\nproposed for mitigating stragglers in FL, most methodologies do not account for\nthe particular characteristics of serverless environments, i.e., cold-starts,\nperformance variations, and the ephemeral stateless nature of the function\ninstances. Towards this, we propose FedLesScan, a novel clustering-based\nsemi-asynchronous training strategy, specifically tailored for serverless FL.\nFedLesScan dynamically adapts to the behaviour of clients and minimizes the\neffect of stragglers on the overall system. We implement our strategy by\nextending an open-source serverless FL system called FedLess. Moreover, we\ncomprehensively evaluate our strategy using the 2nd generation Google Cloud\nFunctions with four datasets and varying percentages of stragglers. Results\nfrom our experiments show that compared to other approaches FedLesScan reduces\ntraining time and cost by an average of 8% and 20% respectively while utilizing\nclients better with an average increase in the effective update ratio of\n17.75%.",
    "descriptor": "\nComments: IEEE BigData 2022\n",
    "authors": [
      "Mohamed Elzohairy",
      "Mohak Chadha",
      "Anshul Jindal",
      "Andreas Grafberger",
      "Jianfeng Gu",
      "Michael Gerndt",
      "Osama Abboud"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05739"
  },
  {
    "id": "arXiv:2211.05750",
    "title": "Nano: Nested Human-in-the-Loop Reward Learning for Few-shot Language  Model Control",
    "abstract": "Pretrained language models have demonstrated extraordinary capabilities in\nlanguage generation. However, real-world tasks often require controlling the\ndistribution of generated text in order to mitigate bias, promote fairness, and\nachieve personalization. Existing techniques for controlling the distribution\nof generated text only work with quantified distributions, which require\npre-defined categories, proportions of the distribution, or an existing corpus\nfollowing the desired distributions. However, many important distributions,\nsuch as personal preferences, are unquantified. In this work, we tackle the\nproblem of generating text following arbitrary distributions (quantified and\nunquantified) by proposing Nano, a few-shot human-in-the-loop training\nalgorithm that continuously learns from human feedback. Nano achieves\nstate-of-the-art results on single topic/attribute as well as quantified\ndistribution control compared to previous works. We also show that Nano is able\nto learn unquantified distributions, achieves personalization, and captures\ndifferences between different individuals' personal preferences with high\nsample efficiency.",
    "descriptor": "",
    "authors": [
      "Xiang Fan",
      "Yiwei Lyu",
      "Paul Pu Liang",
      "Ruslan Salakhutdinov",
      "Louis-Philippe Morency"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05750"
  },
  {
    "id": "arXiv:2211.05753",
    "title": "The Randomized $k$-Server Conjecture is False!",
    "abstract": "We prove a few new lower bounds on the randomized competitive ratio for the\n$k$-server problem and other related problems, resolving some long-standing\nconjectures. In particular, for metrical task systems (MTS) we asympotically\nsettle the competitive ratio and obtain the first improvement to an existential\nlower bound since the introduction of the model 35 years ago (in 1987).\nMore concretely, we show:\n1. There exist $(k+1)$-point metric spaces in which the randomized\ncompetitive ratio for the $k$-server problem is $\\Omega(\\log^2 k)$. This\nrefutes the folklore conjecture (which is known to hold in some families of\nmetrics) that in all metric spaces with at least $k+1$ points, the competitive\nratio is $\\Theta(\\log k)$.\n2. Consequently, there exist $n$-point metric spaces in which the randomized\ncompetitive ratio for MTS is $\\Omega(\\log^2 n)$. This matches the upper bound\nthat holds for all metrics. The previously best existential lower bound was\n$\\Omega(\\log n)$ (which was known to be tight for some families of metrics).\n3. For all $k<n\\in\\mathbb N$, for *all* $n$-point metric spaces the\nrandomized $k$-server competitive ratio is at least $\\Omega(\\log k)$, and\nconsequently the randomized MTS competitive ratio is at least $\\Omega(\\log n)$.\nThese universal lower bounds are asymptotically tight. The previous bounds were\n$\\Omega(\\log k/\\log\\log k)$ and $\\Omega(\\log n/\\log \\log n)$, respectively.\n4. The randomized competitive ratio for the $w$-set metrical service systems\nproblem, and its equivalent width-$w$ layered graph traversal problem, is\n$\\Omega(w^2)$. This slightly improves the previous lower bound and matches the\nrecently discovered upper bound.\n5. Our results imply improved lower bounds for other problems like $k$-taxi,\ndistributed paging and metric allocation.\nThese lower bounds share a common thread, and other than the third bound,\nalso a common construction.",
    "descriptor": "",
    "authors": [
      "S\u00e9bastien Bubeck",
      "Christian Coester",
      "Yuval Rabani"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Metric Geometry (math.MG)"
    ],
    "url": "https://arxiv.org/abs/2211.05753"
  },
  {
    "id": "arXiv:2211.05756",
    "title": "Massively Multilingual ASR on 70 Languages: Tokenization, Architecture,  and Generalization Capabilities",
    "abstract": "End-to-end multilingual ASR has become more appealing because of several\nreasons such as simplifying the training and deployment process and positive\nperformance transfer from high-resource to low-resource languages. However,\nscaling up the number of languages, total hours, and number of unique tokens is\nnot a trivial task. This paper explores large-scale multilingual ASR models on\n70 languages. We inspect two architectures: (1) Shared embedding and output and\n(2) Multiple embedding and output model. In the shared model experiments, we\nshow the importance of tokenization strategy across different languages. Later,\nwe use our optimal tokenization strategy to train multiple embedding and output\nmodel to further improve our result. Our multilingual ASR achieves 13.9%-15.6%\naverage WER relative improvement compared to monolingual models. We show that\nour multilingual ASR generalizes well on an unseen dataset and domain,\nachieving 9.5% and 7.5% WER on Multilingual Librispeech (MLS) with zero-shot\nand finetuning, respectively.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Andros Tjandra",
      "Nayan Singhal",
      "David Zhang",
      "Ozlem Kalinli",
      "Abdelrahman Mohamed",
      "Duc Le",
      "Michael L. Seltzer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.05756"
  },
  {
    "id": "arXiv:2211.05764",
    "title": "DC-Check: A Data-Centric AI checklist to guide the development of  reliable machine learning systems",
    "abstract": "While there have been a number of remarkable breakthroughs in machine\nlearning (ML), much of the focus has been placed on model development. However,\nto truly realize the potential of machine learning in real-world settings,\nadditional aspects must be considered across the ML pipeline. Data-centric AI\nis emerging as a unifying paradigm that could enable such reliable end-to-end\npipelines. However, this remains a nascent area with no standardized framework\nto guide practitioners to the necessary data-centric considerations or to\ncommunicate the design of data-centric driven ML systems. To address this gap,\nwe propose DC-Check, an actionable checklist-style framework to elicit\ndata-centric considerations at different stages of the ML pipeline: Data,\nTraining, Testing, and Deployment. This data-centric lens on development aims\nto promote thoughtfulness and transparency prior to system development.\nAdditionally, we highlight specific data-centric AI challenges and research\nopportunities. DC-Check is aimed at both practitioners and researchers to guide\nday-to-day development. As such, to easily engage with and use DC-Check and\nassociated resources, we provide a DC-Check companion website\n(https://www.vanderschaar-lab.com/dc-check/). The website will also serve as an\nupdated resource as methods and tooling evolve over time.",
    "descriptor": "\nComments: Main paper: 11 pages, supplementary & case studies follow\n",
    "authors": [
      "Nabeel Seedat",
      "Fergus Imrie",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Software Engineering (cs.SE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.05764"
  },
  {
    "id": "arXiv:2211.05766",
    "title": "Heterogeneous Randomized Response for Differential Privacy in Graph  Neural Networks",
    "abstract": "Graph neural networks (GNNs) are susceptible to privacy inference attacks\n(PIAs), given their ability to learn joint representation from features and\nedges among nodes in graph data. To prevent privacy leakages in GNNs, we\npropose a novel heterogeneous randomized response (HeteroRR) mechanism to\nprotect nodes' features and edges against PIAs under differential privacy (DP)\nguarantees without an undue cost of data and model utility in training GNNs.\nOur idea is to balance the importance and sensitivity of nodes' features and\nedges in redistributing the privacy budgets since some features and edges are\nmore sensitive or important to the model utility than others. As a result, we\nderive significantly better randomization probabilities and tighter error\nbounds at both levels of nodes' features and edges departing from existing\napproaches, thus enabling us to maintain high data utility for training GNNs.\nAn extensive theoretical and empirical analysis using benchmark datasets shows\nthat HeteroRR significantly outperforms various baselines in terms of model\nutility under rigorous privacy protection for both nodes' features and edges.\nThat enables us to defend PIAs in DP-preserving GNNs effectively.",
    "descriptor": "\nComments: Accepted in IEEE BigData 2022 (short paper)\n",
    "authors": [
      "Khang Tran",
      "Phung Lai",
      "NhatHai Phan",
      "Issa Khalil",
      "Yao Ma",
      "Abdallah Khreishah",
      "My Thai",
      "Xintao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.05766"
  },
  {
    "id": "arXiv:2211.05769",
    "title": "Steiner Connectivity Augmentation and Splitting-off in Poly-logarithmic  Maximum Flows",
    "abstract": "We give an almost-linear time algorithm for the Steiner connectivity\naugmentation problem: given an undirected graph, find a smallest (or minimum\nweight) set of edges whose addition makes a given set of terminals\n$\\tau$-connected (for any given $\\tau > 0$). The running time of our algorithm\nis dominated by polylogarithmic calls to any maximum flow subroutine; using the\nrecent almost-linear time maximum flow algorithm (Chen et al., FOCS 2022), we\nget an almost-linear running time for our algorithm as well. This is tight up\nto the polylogarithmic factor even for just two terminals. Prior to our work,\nan almost-linear (in fact, near-linear) running time was known only for the\nspecial case of global connectivity augmentation, i.e., when all vertices are\nterminals (Cen et al., STOC 2022).\nWe also extend our algorithm to the closely related Steiner splitting-off\nproblem, where the edges incident on a vertex have to be {\\em split-off} while\nmaintaining the (Steiner) connectivity of a given set of terminals. Prior to\nour work, a nearly-linear time algorithm was known only for the special case of\nglobal connectivity (Cen et al., STOC 2022). The only known generalization\nbeyond global connectivity was to preserve all pairwise connectivities using a\nmuch slower algorithm that makes $n$ calls to an all-pairs maximum flow (or\nGomory-Hu tree) subroutine (Lau and Yung, SICOMP 2013), as against polylog(n)\ncalls to a (single-pair) maximum flow subroutine in this work.",
    "descriptor": "\nComments: To appear in SODA 2023\n",
    "authors": [
      "Ruoxu Cen",
      "William He",
      "Jason Li",
      "Debmalya Panigrahi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.05769"
  },
  {
    "id": "arXiv:2211.05770",
    "title": "StyleNAT: Giving Each Head a New Perspective",
    "abstract": "Image generation has been a long sought-after but challenging task, and\nperforming the generation task in an efficient manner is similarly difficult.\nOften researchers attempt to create a \"one size fits all\" generator, where\nthere are few differences in the parameter space for drastically different\ndatasets. Herein, we present a new transformer-based framework, dubbed\nStyleNAT, targeting high-quality image generation with superior efficiency and\nflexibility. At the core of our model, is a carefully designed framework that\npartitions attention heads to capture local and global information, which is\nachieved through using Neighborhood Attention (NA). With different heads able\nto pay attention to varying receptive fields, the model is able to better\ncombine this information, and adapt, in a highly flexible manner, to the data\nat hand. StyleNAT attains a new SOTA FID score on FFHQ-256 with 2.046, beating\nprior arts with convolutional models such as StyleGAN-XL and transformers such\nas HIT and StyleSwin, and a new transformer SOTA on FFHQ-1024 with an FID score\nof 4.174. These results show a 6.4% improvement on FFHQ-256 scores when\ncompared to StyleGAN-XL with a 28% reduction in the number of parameters and\n56% improvement in sampling throughput. Code and models will be open-sourced at\nhttps://github.com/SHI-Labs/StyleNAT .",
    "descriptor": "",
    "authors": [
      "Steven Walton",
      "Ali Hassani",
      "Xingqian Xu",
      "Zhangyang Wang",
      "Humphrey Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05770"
  },
  {
    "id": "arXiv:2211.05773",
    "title": "Scaling Neural Face Synthesis to High FPS and Low Latency by Neural  Caching",
    "abstract": "Recent neural rendering approaches greatly improve image quality, reaching\nnear photorealism. However, the underlying neural networks have high runtime,\nprecluding telepresence and virtual reality applications that require high\nresolution at low latency. The sequential dependency of layers in deep networks\nmakes their optimization difficult. We break this dependency by caching\ninformation from the previous frame to speed up the processing of the current\none with an implicit warp. The warping with a shallow network reduces latency\nand the caching operations can further be parallelized to improve the frame\nrate. In contrast to existing temporal neural networks, ours is tailored for\nthe task of rendering novel views of faces by conditioning on the change of the\nunderlying surface mesh. We test the approach on view-dependent rendering of 3D\nportrait avatars, as needed for telepresence, on established benchmark\nsequences. Warping reduces latency by 70$\\%$ (from 49.4ms to 14.9ms on\ncommodity GPUs) and scales frame rates accordingly over multiple GPUs while\nreducing image quality by only 1$\\%$, making it suitable as part of end-to-end\nview-dependent 3D teleconferencing applications. Our project page can be found\nat: https://yu-frank.github.io/lowlatency/.",
    "descriptor": "",
    "authors": [
      "Frank Yu",
      "Sid Fels",
      "Helge Rhodin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05773"
  },
  {
    "id": "arXiv:2211.05775",
    "title": "The Dark Side of The Internet of Vehicles: A Survey of the State of IoV  and its Security Vulnerabilities",
    "abstract": "For the smart vehicular network, we studied two technologies to realize it.\nThe first technology is the cooperative scheme which improves capacity by\nproperly combining the V2V and V2I. The second technology is an online learning\nalgorithm which can deal with the beam selection problem in mmWave system. Both\nare effective and can be used in autonomous driving systems. However,\nadvancements in the field of IoV have elicited research in different areas\nrelated to the field. This highlights a critical need to address security and\nprotection challenges as a result of the progression of vehicles and everything\nthat is being transferred to the internet. In addition, to understand exactly\nwhere research is missing regarding IoV, we found that a survey of current\nresearch in the vulnerabilities and threats to general IoT applications. In\naddition to other attacks, we found that DDoS attacks in the form of botnets\nare significant threats to the IoT world. Upon researching which threats and\nvulnerabilities are leveraged in IoV research, the field was severely lacking\nin botnet and DDoS attack research. If developers neglect to address this issue\nbefore interconnected vehicles become a mainstream reality, this discovery can\nhave severe ramifications for the safety of IoV consumers around the globe.",
    "descriptor": "",
    "authors": [
      "Tess Christensen",
      "Sai Bhargav Mandavilli",
      "Chao-Yi Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.05775"
  },
  {
    "id": "arXiv:2211.05776",
    "title": "Fine-Grained Entity Segmentation",
    "abstract": "In dense image segmentation tasks (e.g., semantic, panoptic), existing\nmethods can hardly generalize well to unseen image domains, predefined classes,\nand image resolution & quality variations. Motivated by these observations, we\nconstruct a large-scale entity segmentation dataset to explore fine-grained\nentity segmentation, with a strong focus on open-world and high-quality dense\nsegmentation. The dataset contains images spanning diverse image domains and\nresolutions, along with high-quality mask annotations for training and testing.\nGiven the high-quality and -resolution nature of the dataset, we propose\nCropFormer for high-quality segmentation, which can improve mask prediction\nusing high-res image crops that provide more fine-grained image details than\nthe full image. CropFormer is the first query-based Transformer architecture\nthat can effectively ensemble mask predictions from multiple image crops, by\nlearning queries that can associate the same entities across the full image and\nits crop. With CropFormer, we achieve a significant AP gain of $1.9$ on the\nchallenging fine-grained entity segmentation task. The dataset and code will be\nreleased at this http URL",
    "descriptor": "\nComments: The project webiste: this http URL\n",
    "authors": [
      "Lu Qi",
      "Jason Kuen",
      "Weidong Guo",
      "Tiancheng Shen",
      "Jiuxiang Gu",
      "Wenbo Li",
      "Jiaya Jia",
      "Zhe Lin",
      "Ming-Hsuan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05776"
  },
  {
    "id": "arXiv:2211.05778",
    "title": "InternImage: Exploring Large-Scale Vision Foundation Models with  Deformable Convolutions",
    "abstract": "Compared to the great progress of large-scale vision transformers (ViTs) in\nrecent years, large-scale models based on convolutional neural networks (CNNs)\nare still in an early state. This work presents a new large-scale CNN-based\nfoundation model, termed InternImage, which can obtain the gain from increasing\nparameters and training data like ViTs. Different from the recent CNNs that\nfocus on large dense kernels, InternImage takes deformable convolution as the\ncore operator, so that our model not only has the large effective receptive\nfield required for downstream tasks such as detection and segmentation, but\nalso has the adaptive spatial aggregation conditioned by input and task\ninformation. As a result, the proposed InternImage reduces the strict inductive\nbias of traditional CNNs and makes it possible to learn stronger and more\nrobust patterns with large-scale parameters from massive data like ViTs. The\neffectiveness of our model is proven on challenging benchmarks including\nImageNet, COCO, and ADE20K. It is worth mentioning that InternImage-H achieved\nthe new record 65.4 mAP on COCO test-dev. The code will be released at\nhttps://github.com/OpenGVLab/InternImage.",
    "descriptor": "\nComments: technical report\n",
    "authors": [
      "Wenhai Wang",
      "Jifeng Dai",
      "Zhe Chen",
      "Zhenhang Huang",
      "Zhiqi Li",
      "Xizhou Zhu",
      "Xiaowei Hu",
      "Tong Lu",
      "Lewei Lu",
      "Hongsheng Li",
      "Xiaogang Wang",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05778"
  },
  {
    "id": "arXiv:2211.05781",
    "title": "Demystify Transformers & Convolutions in Modern Image Deep Networks",
    "abstract": "Recent success of vision transformers has inspired a series of vision\nbackbones with novel feature transformation paradigms, which report steady\nperformance gain. Although the novel feature transformation designs are often\nclaimed as the source of gain, some backbones may benefit from advanced\nengineering techniques, which makes it hard to identify the real gain from the\nkey feature transformation operators. In this paper, we aim to identify real\ngain of popular convolution and attention operators and make an in-depth study\nof them. We observe that the main difference among these feature transformation\nmodules, e.g., attention or convolution, lies in the way of spatial feature\naggregation, or the so-called \"spatial token mixer\" (STM). Hence, we first\nelaborate a unified architecture to eliminate the unfair impact of different\nengineering techniques, and then fit STMs into this architecture for\ncomparison. Based on various experiments on upstream/downstream tasks and the\nanalysis of inductive bias, we find that the engineering techniques boost the\nperformance significantly, but the performance gap still exists among different\nSTMs. The detailed analysis also reveals some interesting findings of different\nSTMs, such as effective receptive fields and invariance tests. The code and\ntrained models will be publicly available at\nhttps://github.com/OpenGVLab/STM-Evaluation",
    "descriptor": "",
    "authors": [
      "Jifeng Dai",
      "Min Shi",
      "Weiyun Wang",
      "Sitong Wu",
      "Linjie Xing",
      "Wenhai Wang",
      "Xizhou Zhu",
      "Lewei Lu",
      "Jie Zhou",
      "Xiaogang Wang",
      "Yu Qiao",
      "Xiaowei Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05781"
  },
  {
    "id": "arXiv:2211.05783",
    "title": "Unifying Flow, Stereo and Depth Estimation",
    "abstract": "We present a unified formulation and model for three motion and 3D perception\ntasks: optical flow, rectified stereo matching and unrectified stereo depth\nestimation from posed images. Unlike previous specialized architectures for\neach specific task, we formulate all three tasks as a unified dense\ncorrespondence matching problem, which can be solved with a single model by\ndirectly comparing feature similarities. Such a formulation calls for\ndiscriminative feature representations, which we achieve using a Transformer,\nin particular the cross-attention mechanism. We demonstrate that\ncross-attention enables integration of knowledge from another image via\ncross-view interactions, which greatly improves the quality of the extracted\nfeatures. Our unified model naturally enables cross-task transfer since the\nmodel architecture and parameters are shared across tasks. We outperform RAFT\nwith our unified model on the challenging Sintel dataset, and our final model\nthat uses a few additional task-specific refinement steps outperforms or\ncompares favorably to recent state-of-the-art methods on 10 popular flow,\nstereo and depth datasets, while being simpler and more efficient in terms of\nmodel design and inference speed.",
    "descriptor": "\nComments: Project Page: this https URL, Code: this https URL\n",
    "authors": [
      "Haofei Xu",
      "Jing Zhang",
      "Jianfei Cai",
      "Hamid Rezatofighi",
      "Fisher Yu",
      "Dacheng Tao",
      "Andreas Geiger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05783"
  },
  {
    "id": "arXiv:2110.15684",
    "title": "Fusing ASR Outputs in Joint Training for Speech Emotion Recognition",
    "abstract": "Alongside acoustic information, linguistic features based on speech\ntranscripts have been proven useful in Speech Emotion Recognition (SER).\nHowever, due to the scarcity of emotion labelled data and the difficulty of\nrecognizing emotional speech, it is hard to obtain reliable linguistic features\nand models in this research area. In this paper, we propose to fuse Automatic\nSpeech Recognition (ASR) outputs into the pipeline for joint training SER. The\nrelationship between ASR and SER is understudied, and it is unclear what and\nhow ASR features benefit SER. By examining various ASR outputs and fusion\nmethods, our experiments show that in joint ASR-SER training, incorporating\nboth ASR hidden and text output using a hierarchical co-attention fusion\napproach improves the SER performance the most. On the IEMOCAP corpus, our\napproach achieves 63.4% weighted accuracy, which is close to the baseline\nresults achieved by combining ground-truth transcripts. In addition, we also\npresent novel word error rate analysis on IEMOCAP and layer-difference analysis\nof the Wav2vec 2.0 model to better understand the relationship between ASR and\nSER.",
    "descriptor": "\nComments: Accepted for ICASSP 2022\n",
    "authors": [
      "Yuanchao Li",
      "Peter Bell",
      "Catherine Lai"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.15684"
  },
  {
    "id": "arXiv:2211.02292",
    "title": "Boosting Binary Neural Networks via Dynamic Thresholds Learning",
    "abstract": "Developing lightweight Deep Convolutional Neural Networks (DCNNs) and Vision\nTransformers (ViTs) has become one of the focuses in vision research since the\nlow computational cost is essential for deploying vision models on edge\ndevices. Recently, researchers have explored highly computational efficient\nBinary Neural Networks (BNNs) by binarizing weights and activations of\nFull-precision Neural Networks. However, the binarization process leads to an\nenormous accuracy gap between BNN and its full-precision version. One of the\nprimary reasons is that the Sign function with predefined or learned static\nthresholds limits the representation capacity of binarized architectures since\nsingle-threshold binarization fails to utilize activation distributions. To\novercome this issue, we introduce the statistics of channel information into\nexplicit thresholds learning for the Sign Function dubbed DySign to generate\nvarious thresholds based on input distribution. Our DySign is a straightforward\nmethod to reduce information loss and boost the representative capacity of\nBNNs, which can be flexibly applied to both DCNNs and ViTs (i.e., DyBCNN and\nDyBinaryCCT) to achieve promising performance improvement. As shown in our\nextensive experiments. For DCNNs, DyBCNNs based on two backbones (MobileNetV1\nand ResNet18) achieve 71.2% and 67.4% top1-accuracy on ImageNet dataset,\noutperforming baselines by a large margin (i.e., 1.8% and 1.5% respectively).\nFor ViTs, DyBinaryCCT presents the superiority of the convolutional embedding\nlayer in fully binarized ViTs and achieves 56.1% on the ImageNet dataset, which\nis nearly 9% higher than the baseline.",
    "descriptor": "",
    "authors": [
      "Jiehua Zhang",
      "Xueyang Zhang",
      "Zhuo Su",
      "Zitong Yu",
      "Yanghe Feng",
      "Xin Lu",
      "Matti Pietik\u00e4inen",
      "Li Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.02292"
  },
  {
    "id": "arXiv:2211.05121",
    "title": "Adaptive Multi-Corpora Language Model Training for Speech Recognition",
    "abstract": "Neural network language model (NNLM) plays an essential role in automatic\nspeech recognition (ASR) systems, especially in adaptation tasks when text-only\ndata is available. In practice, an NNLM is typically trained on a combination\nof data sampled from multiple corpora. Thus, the data sampling strategy is\nimportant to the adaptation performance. Most existing works focus on designing\nstatic sampling strategies. However, each corpus may show varying impacts at\ndifferent NNLM training stages. In this paper, we introduce a novel adaptive\nmulti-corpora training algorithm that dynamically learns and adjusts the\nsampling probability of each corpus along the training process. The algorithm\nis robust to corpora sizes and domain relevance. Compared with static sampling\nstrategy baselines, the proposed approach yields remarkable improvement by\nachieving up to relative 7% and 9% word error rate (WER) reductions on\nin-domain and out-of-domain adaptation tasks, respectively.",
    "descriptor": "",
    "authors": [
      "Yingyi Ma",
      "Zhe Liu",
      "Xuedong Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05121"
  },
  {
    "id": "arXiv:2211.05172",
    "title": "Speech separation with large-scale self-supervised learning",
    "abstract": "Self-supervised learning (SSL) methods such as WavLM have shown promising\nspeech separation (SS) results in small-scale simulation-based experiments. In\nthis work, we extend the exploration of the SSL-based SS by massively scaling\nup both the pre-training data (more than 300K hours) and fine-tuning data (10K\nhours). We also investigate various techniques to efficiently integrate the\npre-trained model with the SS network under a limited computation budget,\nincluding a low frame rate SSL model training setup and a fine-tuning scheme\nusing only the part of the pre-trained model. Compared with a supervised\nbaseline and the WavLM-based SS model using feature embeddings obtained with\nthe previously released 94K hours trained WavLM, our proposed model obtains\n15.9% and 11.2% of relative word error rate (WER) reductions, respectively, for\na simulated far-field speech mixture test set. For conversation transcription\non real meeting recordings using continuous speech separation, the proposed\nmodel achieves 6.8% and 10.6% of relative WER reductions over the purely\nsupervised baseline on AMI and ICSI evaluation sets, respectively, while\nreducing the computational cost by 38%.",
    "descriptor": "",
    "authors": [
      "Zhuo Chen",
      "Naoyuki Kanda",
      "Jian Wu",
      "Yu Wu",
      "Xiaofei Wang",
      "Takuya Yoshioka",
      "Jinyu Li",
      "Sunit Sivasankaran",
      "Sefik Emre Eskimez"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.05172"
  },
  {
    "id": "arXiv:2211.05205",
    "title": "Maximum Entropy on the Mean and the Cram\u00e9r Rate Function in  Statistical Estimation and Inverse Problems: Properties, Models, and  Algorithms",
    "abstract": "We explore a method of statistical estimation called Maximum Entropy on the\nMean (MEM) which is based on an information-driven criterion that quantifies\nthe compliance of a given point with a reference prior probability measure. At\nthe core of this approach lies the MEM function which is a partial minimization\nof the Kullback-Leibler divergence over a linear constraint. In many cases, it\nis known that this function admits a simpler representation (known as the\nCram\\'er rate function). Via the connection to exponential families of\nprobability distributions, we study general conditions under which this\nrepresentation holds. We then address how the associated MEM estimator gives\nrise to a wide class of MEM-based regularized linear models for solving inverse\nproblems. Finally, we propose an algorithmic framework to solve these problems\nefficiently based on the Bregman proximal gradient method, alongside proximal\noperators for commonly used reference distributions. The article is\ncomplemented by a software package for experimentation and exploration of the\nMEM approach in applications.",
    "descriptor": "",
    "authors": [
      "Yakov Vaisbourd",
      "Rustum Choksi",
      "Ariel Goodwin",
      "Tim Hoheisel",
      "Carola-Bibiane Sch\u00f6nlieb"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.05205"
  },
  {
    "id": "arXiv:2211.05225",
    "title": "Variational Quantum Kernels with Task-Specific Quantum Metric Learning",
    "abstract": "Quantum kernel methods, i.e., kernel methods with quantum kernels, offer\ndistinct advantages as a hybrid quantum-classical approach to quantum machine\nlearning (QML), including applicability to Noisy Intermediate-Scale Quantum\n(NISQ) devices and usage for solving all types of machine learning problems.\nKernel methods rely on the notion of similarity between points in a higher\n(possibly infinite) dimensional feature space. For machine learning, the notion\nof similarity assumes that points close in the feature space should be close in\nthe machine learning task space. In this paper, we discuss the use of\nvariational quantum kernels with task-specific quantum metric learning to\ngenerate optimal quantum embeddings (a.k.a. quantum feature encodings) that are\nspecific to machine learning tasks. Such task-specific optimal quantum\nembeddings, implicitly supporting feature selection, are valuable not only to\nquantum kernel methods in improving the latter's performance, but they can also\nbe valuable to non-kernel QML methods based on parameterized quantum circuits\n(PQCs) as pretrained embeddings and for transfer learning. This further\ndemonstrates the quantum utility, and quantum advantage (with\nclassically-intractable quantum embeddings), of quantum kernel methods.",
    "descriptor": "",
    "authors": [
      "Daniel T. Chang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05225"
  },
  {
    "id": "arXiv:2211.05226",
    "title": "A kinetic approach to consensus-based segmentation of biomedical images",
    "abstract": "In this work, we apply a kinetic version of a bounded confidence consensus\nmodel to biomedical segmentation problems. In the presented approach,\ntime-dependent information on the microscopic state of each particle/pixel\nincludes its space position and a feature representing a static characteristic\nof the system, i.e. the gray level of each pixel. From the introduced\nmicroscopic model we derive a kinetic formulation of the model. The large time\nbehavior of the system is then computed with the aid of a surrogate\nFokker-Planck approach that can be obtained in the quasi-invariant scaling. We\nexploit the computational efficiency of direct simulation Monte Carlo methods\nfor the obtained Boltzmann-type description of the problem for parameter\nidentification tasks. Based on a suitable loss function measuring the distance\nbetween the ground truth segmentation mask and the evaluated mask, we minimize\nthe introduced segmentation metric for a relevant set of 2D gray-scale images.\nApplications to biomedical segmentation concentrate on different imaging\nresearch contexts.",
    "descriptor": "\nComments: 25 pages, 16 figures\n",
    "authors": [
      "Raffaella Fiamma Cabini",
      "Anna Pichiecchio",
      "Alessandro Lascialfari",
      "Silvia Figini",
      "Mattia Zanella"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05226"
  },
  {
    "id": "arXiv:2211.05235",
    "title": "Improved Prediction of Beta-Amyloid and Tau Burden Using Hippocampal  Surface Multivariate Morphometry Statistics and Sparse Coding",
    "abstract": "Background: Beta-amyloid (A$\\beta$) plaques and tau protein tangles in the\nbrain are the defining 'A' and 'T' hallmarks of Alzheimer's disease (AD), and\ntogether with structural atrophy detectable on brain magnetic resonance imaging\n(MRI) scans as one of the neurodegenerative ('N') biomarkers comprise the ''ATN\nframework'' of AD. Current methods to detect A$\\beta$/tau pathology include\ncerebrospinal fluid (CSF; invasive), positron emission tomography (PET; costly\nand not widely available), and blood-based biomarkers (BBBM; promising but\nmainly still in development).\nObjective: To develop a non-invasive and widely available structural\nMRI-based framework to quantitatively predict the amyloid and tau measurements.\nMethods: With MRI-based hippocampal multivariate morphometry statistics (MMS)\nfeatures, we apply our Patch Analysis-based Surface Correntropy-induced Sparse\ncoding and max-pooling (PASCS-MP) method combined with the ridge regression\nmodel to individual amyloid/tau measure prediction.\nResults: We evaluate our framework on amyloid PET/MRI and tau PET/MRI\ndatasets from the Alzheimer's Disease Neuroimaging Initiative (ADNI). Each\nsubject has one pair consisting of a PET image and MRI scan, collected at about\nthe same time. Experimental results suggest that amyloid/tau measurements\npredicted with our PASCP-MP representations are closer to the real values than\nthe measures derived from other approaches, such as hippocampal surface area,\nvolume, and shape morphometry features based on spherical harmonics (SPHARM).\nConclusion: The MMS-based PASCP-MP is an efficient tool that can bridge\nhippocampal atrophy with amyloid and tau pathology and thus help assess disease\nburden, progression, and treatment effects.",
    "descriptor": "\nComments: 34 pages, 5 figures, 1 table, accepted by the Journal of Alzheimer's Disease\n",
    "authors": [
      "Jianfeng Wu",
      "Yi Su",
      "Wenhui Zhu",
      "Negar Jalili Mallak",
      "Natasha Lepore",
      "Eric M. Reiman",
      "Richard J. Caselli",
      "Paul M. Thompson",
      "Kewei Chen",
      "Yalin Wang"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05235"
  },
  {
    "id": "arXiv:2211.05238",
    "title": "Polarized consensus-based dynamics for optimization and sampling",
    "abstract": "In this paper we propose polarized consensus-based dynamics in order to make\nconsensus-based optimization (CBO) and sampling (CBS) applicable for objective\nfunctions with several global minima or distributions with many modes,\nrespectively. For this, we \"polarize\" the dynamics with a localizing kernel and\nthe resulting model can be viewed as a bounded confidence model for opinion\nformation in the presence of common objective. Instead of being attracted to a\ncommon weighted mean as in the original consensus-based methods, which prevents\nthe detection of more than one minimum or mode, in our method every particle is\nattracted to a weighted mean which gives more weight to nearby particles. The\nresulting dynamics possess mean-field interpretations with Fokker--Planck\nequations that are structurally similar to the ones of original CBO and CBS,\nand we prove that the polarized CBS dynamics is unbiased in case of a Gaussian\ntarget. We also propose a computationally more efficient generalization which\nworks with a predefined number of clusters and improves upon our polarized\nbaseline method for high-dimensional optimization.",
    "descriptor": "",
    "authors": [
      "Leon Bungert",
      "Philipp Wacker",
      "Tim Roith"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.05238"
  },
  {
    "id": "arXiv:2211.05241",
    "title": "Reproducibility in medical image radiomic studies: contribution of  dynamic histogram binning",
    "abstract": "The de facto standard of dynamic histogram binning for radiomic feature\nextraction leads to an elevated sensitivity to fluctuations in annotated\nregions. This may impact the majority of radiomic studies published recently\nand contribute to issues regarding poor reproducibility of radiomic-based\nmachine learning that has led to significant efforts for data harmonization;\nhowever, we believe the issues highlighted here are comparatively neglected,\nbut often remedied by choosing static binning.\nThe field of radiomics has improved through the development of community\nstandards and open-source libraries such as PyRadiomics. But differences in\nimage acquisition, systematic differences between observers' annotations, and\npreprocessing steps still pose challenges. These can change the distribution of\nvoxels altering extracted features and can be exacerbated with dynamic binning.",
    "descriptor": "\nComments: 5 pages, 1 figure, 2 tables\n",
    "authors": [
      "Darryl E. Wright",
      "Cole Cook",
      "Jason Klug",
      "Panagiotis Korfiatis",
      "Timothy L. Kline"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05241"
  },
  {
    "id": "arXiv:2211.05246",
    "title": "A theory of quantum differential equation solvers: limitations and  fast-forwarding",
    "abstract": "We study the limitations and fast-forwarding of quantum algorithms for\nsolving linear ordinary differential equation (ODE) systems with particular\nfocus on non-quantum dynamics, where the coefficient matrix in the ODE is not\nanti-Hermitian or the ODE is inhomogeneous. On the one hand, for generic\nhomogeneous linear ODEs, by proving worst-case lower bounds, we show that\nquantum algorithms suffer from computational overheads due to two types of\n``non-quantumness'': real part gap and non-normality of the coefficient matrix.\nWe then show that ODEs in the absence of both types of ``non-quantumness'' are\nequivalent to quantum dynamics, and reach the conclusion that quantum\nalgorithms for quantum dynamics work best. We generalize our results to the\ninhomogeneous case and find that existing generic quantum ODE solvers cannot be\nsubstantially improved. To obtain these lower bounds, we propose a general\nframework for proving lower bounds on quantum algorithms that are amplifiers,\nmeaning that they amplify the difference between a pair of input quantum\nstates. On the other hand, we show how to fast-forward quantum algorithms for\nsolving special classes of ODEs which leads to improved efficiency. More\nspecifically, we obtain quadratic to exponential improvements in terms of the\nevolution time $T$ and the spectral norm of the coefficient matrix for the\nfollowing classes of ODEs: inhomogeneous ODEs with a negative definite\ncoefficient matrix, inhomogeneous ODEs with a coefficient matrix having an\neigenbasis that can be efficiently prepared on a quantum computer and\neigenvalues that can be efficiently computed classically, and the spatially\ndiscretized inhomogeneous heat equation and advection-diffusion equation. We\ngive fast-forwarding algorithms that are conceptually different from existing\nones in the sense that they neither require time discretization nor solving\nhigh-dimensional linear systems.",
    "descriptor": "\nComments: 51 pages\n",
    "authors": [
      "Dong An",
      "Jin-Peng Liu",
      "Daochen Wang",
      "Qi Zhao"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.05246"
  },
  {
    "id": "arXiv:2211.05256",
    "title": "Power Efficient Video Super-Resolution on Mobile NPUs with Deep  Learning, Mobile AI & AIM 2022 challenge: Report",
    "abstract": "Video super-resolution is one of the most popular tasks on mobile devices,\nbeing widely used for an automatic improvement of low-bitrate and\nlow-resolution video streams. While numerous solutions have been proposed for\nthis problem, they are usually quite computationally demanding, demonstrating\nlow FPS rates and power efficiency on mobile devices. In this Mobile AI\nchallenge, we address this problem and propose the participants to design an\nend-to-end real-time video super-resolution solution for mobile NPUs optimized\nfor low energy consumption. The participants were provided with the REDS\ntraining dataset containing video sequences for a 4X video upscaling task. The\nruntime and power efficiency of all models was evaluated on the powerful\nMediaTek Dimensity 9000 platform with a dedicated AI processing unit capable of\naccelerating floating-point and quantized neural networks. All proposed\nsolutions are fully compatible with the above NPU, demonstrating an up to 500\nFPS rate and 0.2 [Watt / 30 FPS] power consumption. A detailed description of\nall models developed in the challenge is provided in this paper.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2105.08826, arXiv:2105.07809, arXiv:2211.04470, arXiv:2211.03885\n",
    "authors": [
      "Andrey Ignatov",
      "Radu Timofte",
      "Cheng-Ming Chiang",
      "Hsien-Kai Kuo",
      "Yu-Syuan Xu",
      "Man-Yu Lee",
      "Allen Lu",
      "Chia-Ming Cheng",
      "Chih-Cheng Chen",
      "Jia-Ying Yong",
      "Hong-Han Shuai",
      "Wen-Huang Cheng",
      "Zhuang Jia",
      "Tianyu Xu",
      "Yijian Zhang",
      "Long Bao",
      "Heng Sun",
      "Diankai Zhang",
      "Si Gao",
      "Shaoli Liu",
      "Biao Wu",
      "Xiaofeng Zhang",
      "Chengjian Zheng",
      "Kaidi Lu",
      "Ning Wang",
      "Xiao Sun",
      "HaoDong Wu",
      "Xuncheng Liu",
      "Weizhan Zhang",
      "Caixia Yan",
      "Haipeng Du",
      "Qinghua Zheng",
      "Qi Wang",
      "Wangdu Chen",
      "Ran Duan",
      "Ran Duan",
      "Mengdi Sun",
      "Dan Zhu",
      "Guannan Chen",
      "Hojin Cho",
      "Steve Kim",
      "Shijie Yue",
      "Chenghua Li",
      "Zhengyang Zhuge",
      "Wei Chen",
      "Wenxu Wang",
      "Yufeng Zhou",
      "Xiaochen Cai",
      "Hengxing Cai",
      "Kele Xu",
      "Li Liu",
      "Zehua Cheng",
      "Wenyi Lian",
      "Wenjing Lian"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05256"
  },
  {
    "id": "arXiv:2211.05269",
    "title": "A novel GAN-based paradigm for weakly supervised brain tumor  segmentation of MR images",
    "abstract": "Segmentation of regions of interest (ROIs) for identifying abnormalities is a\nleading problem in medical imaging. Using Machine Learning (ML) for this\nproblem generally requires manually annotated ground-truth segmentations,\ndemanding extensive time and resources from radiologists. This work presents a\nnovel weakly supervised approach that utilizes binary image-level labels, which\nare much simpler to acquire, to effectively segment anomalies in medical\nMagnetic Resonance (MR) images without ground truth annotations. We train a\nbinary classifier using these labels and use it to derive seeds indicating\nregions likely and unlikely to contain tumors. These seeds are used to train a\ngenerative adversarial network (GAN) that converts cancerous images to healthy\nvariants, which are then used in conjunction with the seeds to train a ML model\nthat generates effective segmentations. This method produces segmentations that\nachieve Dice coefficients of 0.7903, 0.7868, and 0.7712 on the MICCAI Brain\nTumor Segmentation (BraTS) 2020 dataset for the training, validation, and test\ncohorts respectively. We also propose a weakly supervised means of filtering\nthe segmentations, removing a small subset of poorer segmentations to acquire a\nlarge subset of high quality segmentations. The proposed filtering further\nimproves the Dice coefficients to up to 0.8374, 0.8232, and 0.8136 for\ntraining, validation, and test, respectively.",
    "descriptor": "",
    "authors": [
      "Jay J. Yoo",
      "Khashayar Namdar",
      "Matthias W. Wagner",
      "Liana Nobre",
      "Uri Tabori",
      "Cynthia Hawkins",
      "Birgit B. Ertl-Wagner",
      "Farzad Khalvati"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05269"
  },
  {
    "id": "arXiv:2211.05408",
    "title": "Controlling Moments with Kernel Stein Discrepancies",
    "abstract": "Quantifying the deviation of a probability distribution is challenging when\nthe target distribution is defined by a density with an intractable normalizing\nconstant. The kernel Stein discrepancy (KSD) was proposed to address this\nproblem and has been applied to various tasks including diagnosing approximate\nMCMC samplers and goodness-of-fit testing for unnormalized statistical models.\nThis article investigates a convergence control property of the diffusion\nkernel Stein discrepancy (DKSD), an instance of the KSD proposed by Barp et al.\n(2019). We extend the result of Gorham and Mackey (2017), which showed that the\nKSD controls the bounded-Lipschitz metric, to functions of polynomial growth.\nSpecifically, we prove that the DKSD controls the integral probability metric\ndefined by a class of pseudo-Lipschitz functions, a polynomial generalization\nof Lipschitz functions. We also provide practical sufficient conditions on the\nreproducing kernel for the stated property to hold. In particular, we show that\nthe DKSD detects non-convergence in moments with an appropriate kernel.",
    "descriptor": "\nComments: 49 pages, 19 figures\n",
    "authors": [
      "Heishiro Kanagawa",
      "Arthur Gretton",
      "Lester Mackey"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.05408"
  },
  {
    "id": "arXiv:2211.05409",
    "title": "Radiomics-enhanced Deep Multi-task Learning for Outcome Prediction in  Head and Neck Cancer",
    "abstract": "Outcome prediction is crucial for head and neck cancer patients as it can\nprovide prognostic information for early treatment planning. Radiomics methods\nhave been widely used for outcome prediction from medical images. However,\nthese methods are limited by their reliance on intractable manual segmentation\nof tumor regions. Recently, deep learning methods have been proposed to perform\nend-to-end outcome prediction so as to remove the reliance on manual\nsegmentation. Unfortunately, without segmentation masks, these methods will\ntake the whole image as input, such that makes them difficult to focus on tumor\nregions and potentially unable to fully leverage the prognostic information\nwithin the tumor regions. In this study, we propose a radiomics-enhanced deep\nmulti-task framework for outcome prediction from PET/CT images, in the context\nof HEad and neCK TumOR segmentation and outcome prediction challenge (HECKTOR\n2022). In our framework, our novelty is to incorporate radiomics as an\nenhancement to our recently proposed Deep Multi-task Survival model (DeepMTS).\nThe DeepMTS jointly learns to predict the survival risk scores of patients and\nthe segmentation masks of tumor regions. Radiomics features are extracted from\nthe predicted tumor regions and combined with the predicted survival risk\nscores for final outcome prediction, through which the prognostic information\nin tumor regions can be further leveraged. Our method achieved a C-index of\n0.681 on the testing set, placing the 2nd on the leaderboard with only 0.00068\nlower in C-index than the 1st place.",
    "descriptor": "\nComments: HEad and neCK TumOR segmentation and outcome prediction challenge (HECKTOR 2022)\n",
    "authors": [
      "Mingyuan Meng",
      "Lei Bi",
      "Dagan Feng",
      "Jinman Kim"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05409"
  },
  {
    "id": "arXiv:2211.05420",
    "title": "H&E Stain Normalization using U-Net",
    "abstract": "We propose a novel hematoxylin and eosin (H&E) stain normalization method\nbased on a modified U-Net neural network architecture. Unlike previous\ndeep-learning methods that were often based on generative adversarial networks\n(GANs), we take a teacher-student approach and use paired datasets generated by\na trained CycleGAN to train a U-Net to perform the stain normalization task.\nThrough experiments, we compared our method to two recent competing methods,\nCycleGAN and StainNet, a lightweight approach also based on the teacher-student\nmodel. We found that our method is faster and can process larger images with\nbetter quality compared to CycleGAN. We also compared to StainNet and found\nthat our method delivered quantitatively and qualitatively better results.",
    "descriptor": "\nComments: Accepted to The 22nd IEEE International Conference on BioInformatics and BioEngineering (BIBE), 2022\n",
    "authors": [
      "Chi-Chen Lee",
      "Po-Tsun Paul Kuo",
      "Chi-Han Peng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05420"
  },
  {
    "id": "arXiv:2211.05421",
    "title": "Improving Uncertainty-based Out-of-Distribution Detection for Medical  Image Segmentation",
    "abstract": "Deep Learning models are easily disturbed by variations in the input images\nthat were not seen during training, resulting in unpredictable behaviours. Such\nOut-of-Distribution (OOD) images represent a significant challenge in the\ncontext of medical image analysis, where the range of possible abnormalities is\nextremely wide, including artifacts, unseen pathologies, or different imaging\nprotocols. In this work, we evaluate various uncertainty frameworks to detect\nOOD inputs in the context of Multiple Sclerosis lesions segmentation. By\nimplementing a comprehensive evaluation scheme including 14 sources of OOD of\nvarious nature and strength, we show that methods relying on the predictive\nuncertainty of binary segmentation models often fails in detecting outlying\ninputs. On the contrary, learning to segment anatomical labels alongside\nlesions highly improves the ability to detect OOD inputs.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Benjamin Lambert",
      "Florence Forbes",
      "Senan Doyle",
      "Alan Tucholka",
      "Michel Dojat"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05421"
  },
  {
    "id": "arXiv:2211.05430",
    "title": "Regret Bounds for Noise-Free Cascaded Kernelized Bandits",
    "abstract": "We consider optimizing a function network in the noise-free grey-box setting\nwith RKHS function classes, where the exact intermediate results are\nobservable. We assume that the structure of the network is known (but not the\nunderlying functions comprising it), and we study three types of structures:\n(1) chain: a cascade of scalar-valued functions, (2) multi-output chain: a\ncascade of vector-valued functions, and (3) feed-forward network: a fully\nconnected feed-forward network of scalar-valued functions. We propose a\nsequential upper confidence bound based algorithm GPN-UCB along with a general\ntheoretical upper bound on the cumulative regret. For the Mat\\'ern kernel, we\nadditionally propose a non-adaptive sampling based method along with its\ntheoretical upper bound on the simple regret. We also provide\nalgorithm-independent lower bounds on the simple regret and cumulative regret,\nshowing that GPN-UCB is near-optimal for chains and multi-output chains in\nbroad cases of interest.",
    "descriptor": "\nComments: 35 pages, 8 figures, preprint\n",
    "authors": [
      "Zihan Li",
      "Jonathan Scarlett"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05430"
  },
  {
    "id": "arXiv:2211.05442",
    "title": "Self-supervised learning of audio representations using angular  contrastive loss",
    "abstract": "In Self-Supervised Learning (SSL), various pretext tasks are designed for\nlearning feature representations through contrastive loss. However, previous\nstudies have shown that this loss is less tolerant to semantically similar\nsamples due to the inherent defect of instance discrimination objectives, which\nmay harm the quality of learned feature embeddings used in downstream tasks. To\nimprove the discriminative ability of feature embeddings in SSL, we propose a\nnew loss function called Angular Contrastive Loss (ACL), a linear combination\nof angular margin and contrastive loss. ACL improves contrastive learning by\nexplicitly adding an angular margin between positive and negative augmented\npairs in SSL. Experimental results show that using ACL for both supervised and\nunsupervised learning significantly improves performance. We validated our new\nloss function using the FSDnoisy18k dataset, where we achieved 73.6% and 77.1%\naccuracy in sound event classification using supervised and self-supervised\nlearning, respectively.",
    "descriptor": "",
    "authors": [
      "Shanshan Wang",
      "Soumya Tripathy",
      "Annamaria Mesaros"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.05442"
  },
  {
    "id": "arXiv:2211.05460",
    "title": "Polyominoes and graphs built from Fibonacci words",
    "abstract": "We introduce the $k$-bonacci polyominoes, a new family of polyominoes\nassociated with the binary words avoiding $k$ consecutive $1$'s, also called\ngeneralized $k$-bonacci words. The polyominoes are very entrancing objects,\nconsidered in combinatorics and computer science. The study of polyominoes\ngenerates a rich source of combinatorial ideas. In this paper we study some\nproperties of $k$-bonacci polyominoes. Specifically, we determine their\nrecursive structure and, using this structure, we enumerate them according to\ntheir area, semiperimeter, and length of the corresponding words. We also\nintroduce the $k$-bonacci graphs, then we obtain the generating functions for\nthe total number of vertices and edges, the distribution of the degrees, and\nthe total number of $k$-bonacci graphs that have a Hamiltonian cycle.",
    "descriptor": "\nComments: 16 pages, 8 figures\n",
    "authors": [
      "Sergey Kirgizov",
      "Jos\u00e9 Luis Ram\u00edrez"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.05460"
  },
  {
    "id": "arXiv:2211.05491",
    "title": "Black-Hole Radiation Decoding is Quantum Cryptography",
    "abstract": "We propose to study equivalence relations between phenomena in high-energy\nphysics and the existence of standard cryptographic primitives, and show the\nfirst example where such an equivalence holds. A small number of prior works\nshowed that high-energy phenomena can be explained by cryptographic hardness.\nExamples include using the existence of one-way functions to explain the\nhardness of decoding black-hole Hawking radiation (Harlow and Hayden 2013,\nAaronson 2016), and using pseudorandom quantum states to explain the hardness\nof computing AdS/CFT dictionary (Bouland, Fefferman and Vazirani, 2020).\nIn this work we show, for the former example of black-hole radiation\ndecoding, that it also implies the existence of secure quantum cryptography. In\nfact, we show an existential equivalence between the hardness of black-hole\nradiation decoding and a variety of cryptographic primitives, including\nbit-commitment schemes and oblivious transfer protocols (using quantum\ncommunication). This can be viewed (with proper disclaimers, as we discuss) as\nproviding a physical justification for the existence of secure cryptography. We\nconjecture that such connections may be found in other high-energy physics\nphenomena.",
    "descriptor": "",
    "authors": [
      "Zvika Brakerski"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.05491"
  },
  {
    "id": "arXiv:2211.05548",
    "title": "Dual Multi-scale Mean Teacher Network for Semi-supervised Infection  Segmentation in Chest CT Volume for COVID-19",
    "abstract": "Automated detecting lung infections from computed tomography (CT) data plays\nan important role for combating COVID-19. However, there are still some\nchallenges for developing AI system. 1) Most current COVID-19 infection\nsegmentation methods mainly relied on 2D CT images, which lack 3D sequential\nconstraint. 2) Existing 3D CT segmentation methods focus on single-scale\nrepresentations, which do not achieve the multiple level receptive field sizes\non 3D volume. 3) The emergent breaking out of COVID-19 makes it hard to\nannotate sufficient CT volumes for training deep model. To address these\nissues, we first build a multiple dimensional-attention convolutional neural\nnetwork (MDA-CNN) to aggregate multi-scale information along different\ndimension of input feature maps and impose supervision on multiple predictions\nfrom different CNN layers. Second, we assign this MDA-CNN as a basic network\ninto a novel dual multi-scale mean teacher network (DM${^2}$T-Net) for\nsemi-supervised COVID-19 lung infection segmentation on CT volumes by\nleveraging unlabeled data and exploring the multi-scale information. Our\nDM${^2}$T-Net encourages multiple predictions at different CNN layers from the\nstudent and teacher networks to be consistent for computing a multi-scale\nconsistency loss on unlabeled data, which is then added to the supervised loss\non the labeled data from multiple predictions of MDA-CNN. Third, we collect two\nCOVID-19 segmentation datasets to evaluate our method. The experimental results\nshow that our network consistently outperforms the compared state-of-the-art\nmethods.",
    "descriptor": "\nComments: Codes are available at this https URL; Accepted by Transactions on Cybernetics\n",
    "authors": [
      "Liansheng Wang",
      "Jiacheng Wang",
      "Lei Zhu",
      "Huazhu Fu",
      "Ping Li",
      "Gary Cheng",
      "Zhipeng Feng",
      "Shuo Li",
      "Pheng-Ann Heng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05548"
  },
  {
    "id": "arXiv:2211.05557",
    "title": "Assistive Completion of Agrammatic Aphasic Sentences: A Transfer  Learning Approach using Neurolinguistics-based Synthetic Dataset",
    "abstract": "Damage to the inferior frontal gyrus (Broca's area) can cause agrammatic\naphasia wherein patients, although able to comprehend, lack the ability to form\ncomplete sentences. This inability leads to communication gaps which cause\ndifficulties in their daily lives. The usage of assistive devices can help in\nmitigating these issues and enable the patients to communicate effectively.\nHowever, due to lack of large scale studies of linguistic deficits in aphasia,\nresearch on such assistive technology is relatively limited. In this work, we\npresent two contributions that aim to re-initiate research and development in\nthis field. Firstly, we propose a model that uses linguistic features from\nsmall scale studies on aphasia patients and generates large scale datasets of\nsynthetic aphasic utterances from grammatically correct datasets. We show that\nthe mean length of utterance, the noun/verb ratio, and the simple/complex\nsentence ratio of our synthetic datasets correspond to the reported features of\naphasic speech. Further, we demonstrate how the synthetic datasets may be\nutilized to develop assistive devices for aphasia patients. The pre-trained T5\ntransformer is fine-tuned using the generated dataset to suggest 5 corrected\nsentences given an aphasic utterance as input. We evaluate the efficacy of the\nT5 model using the BLEU and cosine semantic similarity scores. Affirming\nresults with BLEU score of 0.827/1.00 and semantic similarity of 0.904/1.00\nwere obtained. These results provide a strong foundation for the concept that a\nsynthetic dataset based on small scale studies on aphasia can be used to\ndevelop effective assistive technology.",
    "descriptor": "",
    "authors": [
      "Rohit Misra",
      "Sapna S Mishra",
      "Tapan K. Gandhi"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05557"
  },
  {
    "id": "arXiv:2211.05564",
    "title": "Self-supervised learning with bi-label masked speech prediction for  streaming multi-talker speech recognition",
    "abstract": "Self-supervised learning (SSL), which utilizes the input data itself for\nrepresentation learning, has achieved state-of-the-art results for various\ndownstream speech tasks. However, most of the previous studies focused on\noffline single-talker applications, with limited investigations in multi-talker\ncases, especially for streaming scenarios. In this paper, we investigate SSL\nfor streaming multi-talker speech recognition, which generates transcriptions\nof overlapping speakers in a streaming fashion. We first observe that\nconventional SSL techniques do not work well on this task due to the poor\nrepresentation of overlapping speech. We then propose a novel SSL training\nobjective, referred to as bi-label masked speech prediction, which explicitly\npreserves representations of all speakers in overlapping speech. We investigate\nvarious aspects of the proposed system including data configuration and\nquantizer selection. The proposed SSL setup achieves substantially better word\nerror rates on the LibriSpeechMix dataset.",
    "descriptor": "\nComments: submitted to ICASSP 2023\n",
    "authors": [
      "Zili Huang",
      "Zhuo Chen",
      "Naoyuki Kanda",
      "Jian Wu",
      "Yiming Wang",
      "Jinyu Li",
      "Takuya Yoshioka",
      "Xiaofei Wang",
      "Peidong Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.05564"
  },
  {
    "id": "arXiv:2211.05581",
    "title": "Graph-Regularized Tensor Regression: A Domain-Aware Framework for  Interpretable Multi-Way Financial Modelling",
    "abstract": "Analytics of financial data is inherently a Big Data paradigm, as such data\nare collected over many assets, asset classes, countries, and time periods.\nThis represents a challenge for modern machine learning models, as the number\nof model parameters needed to process such data grows exponentially with the\ndata dimensions; an effect known as the Curse-of-Dimensionality. Recently,\nTensor Decomposition (TD) techniques have shown promising results in reducing\nthe computational costs associated with large-dimensional financial models\nwhile achieving comparable performance. However, tensor models are often unable\nto incorporate the underlying economic domain knowledge. To this end, we\ndevelop a novel Graph-Regularized Tensor Regression (GRTR) framework, whereby\nknowledge about cross-asset relations is incorporated into the model in the\nform of a graph Laplacian matrix. This is then used as a regularization tool to\npromote an economically meaningful structure within the model parameters. By\nvirtue of tensor algebra, the proposed framework is shown to be fully\ninterpretable, both coefficient-wise and dimension-wise. The GRTR model is\nvalidated in a multi-way financial forecasting setting and compared against\ncompeting models, and is shown to achieve improved performance at reduced\ncomputational costs. Detailed visualizations are provided to help the reader\ngain an intuitive understanding of the employed tensor operations.",
    "descriptor": "",
    "authors": [
      "Yao Lei Xu",
      "Kriton Konstantinidis",
      "Danilo P. Mandic"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05581"
  },
  {
    "id": "arXiv:2211.05582",
    "title": "The stochastic nature of power-grid frequency in South Africa",
    "abstract": "In this work, we explore two mechanisms that explain non-Gaussian behaviour\nof power-grid frequency recordings in the South African grid. We make use of a\nFokker-Planck approach to power-grid frequency that yields a direct relation\nbetween common model parameters such as inertia, damping, and noise amplitude\nand non-parametric estimations of the same directly from power-grid frequency\nrecordings. We propose two explanations for the non-Gaussian leptokurtic\ndistributions in South Africa: The first based on multiplicative noise in\npower-grid frequency recordings, which we observe in South Africa; The second\nbased on the well-known scheduled and unscheduled load shedding and rolling\nblackouts that beset South Africa. For the first we derive an analytic\nexpression of the effects of multiplicative noise that permits the estimation\nof all statistical moments - and discuss drawbacks in comparison with the data;\nFor the second we employ a simple numerical analysis with a modular power grid\nof South Africa. Both options help understand the statistics of power-grid\nfrequency in South Africa - particularly the presence of heavy tails.",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Leonardo Rydin Gorj\u00e3o",
      "Jacques Maritz"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Systems and Control (eess.SY)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.05582"
  },
  {
    "id": "arXiv:2211.05587",
    "title": "Random density matrices: Analytical results for mean fidelity and  variance of squared Bures distance",
    "abstract": "One of the key issues in quantum information theory related problems concerns\nwith that of distinguishability of quantum states. In this context, Bures\ndistance serves as one of the foremost choices among various distance measures.\nIt also relates to fidelity, which is another quantity of immense importance in\nquantum information theory. In this work, we derive exact results for the\naverage fidelity and variance of the squared Bures distance between a fixed\ndensity matrix and a random density matrix, and also between two independent\nrandom density matrices. These results supplement the recently obtained results\nfor the mean root fidelity and mean of squared Bures distance [Phys. Rev. A\n104, 022438 (2021)]. The availability of both mean and variance also enables us\nto provide a gamma-distribution-based approximation for the probability density\nof the squared Bures distance. The analytical results are corroborated using\nMonte Carlo simulations. Furthermore, we compare our analytical results with\nthe mean and variance of the squared Bures distance between reduced density\nmatrices generated using coupled kicked tops, and a correlated spin chain\nsystem in a random magnetic field. In both cases, we find good agreement.",
    "descriptor": "\nComments: 17 pages, 5 figures, 6 tables\n",
    "authors": [
      "Aritra Laha",
      "Santosh Kumar"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2211.05587"
  },
  {
    "id": "arXiv:2211.05622",
    "title": "SETGen: Scalable and Efficient Template Generation Framework for  Groupwise Medical Image Registration",
    "abstract": "Template generation is a crucial step of groupwise image registration which\ndeforms a group of subjects into a common space. Existing traditional and deep\nlearning-based methods can generate high-quality template images. However, they\nsuffer from substantial time costs or limited application scenarios like fixed\ngroup size. In this paper, we propose an efficient groupwise template\ngenerative framework based on variational autoencoder models utilizing the\narithmetic property of latent representation of input images. We acquire the\nlatent vectors of each input and use the average vector to construct the\ntemplate through the decoder. Therefore, the method can be applied to groups of\nany scale. Secondly, we explore a siamese training scheme that feeds two images\nto the shared-weight twin networks and compares the distances between inputs\nand the generated template to prompt the template to be close to the implicit\ncenter. We conduct experiments on 3D brain MRI scans of groups of different\nsizes. Results show that our framework can achieve comparable and even better\nperformance to baselines, with runtime decreased to seconds.",
    "descriptor": "",
    "authors": [
      "Ziyi He",
      "Albert C. S. Chung"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05622"
  },
  {
    "id": "arXiv:2211.05632",
    "title": "Contexts can be Cheap: Solving Stochastic Contextual Bandits with Linear  Bandit Algorithms",
    "abstract": "In this paper, we address the stochastic contextual linear bandit problem,\nwhere a decision maker is provided a context (a random set of actions drawn\nfrom a distribution). The expected reward of each action is specified by the\ninner product of the action and an unknown parameter. The goal is to design an\nalgorithm that learns to play as close as possible to the unknown optimal\npolicy after a number of action plays. This problem is considered more\nchallenging than the linear bandit problem, which can be viewed as a contextual\nbandit problem with a \\emph{fixed} context. Surprisingly, in this paper, we\nshow that the stochastic contextual problem can be solved as if it is a linear\nbandit problem. In particular, we establish a novel reduction framework that\nconverts every stochastic contextual linear bandit instance to a linear bandit\ninstance, when the context distribution is known. When the context distribution\nis unknown, we establish an algorithm that reduces the stochastic contextual\ninstance to a sequence of linear bandit instances with small misspecifications\nand achieves nearly the same worst-case regret bound as the algorithm that\nsolves the misspecified linear bandit instances.\nAs a consequence, our results imply a $O(d\\sqrt{T\\log T})$ high-probability\nregret bound for contextual linear bandits, making progress in resolving an\nopen problem in (Li et al., 2019), (Li et al., 2021).\nOur reduction framework opens up a new way to approach stochastic contextual\nlinear bandit problems, and enables improved regret bounds in a number of\ninstances including the batch setting, contextual bandits with\nmisspecifications, contextual bandits with sparse unknown parameters, and\ncontextual bandits with adversarial corruption.",
    "descriptor": "",
    "authors": [
      "Osama A. Hanna",
      "Lin F. Yang",
      "Christina Fragouli"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05632"
  },
  {
    "id": "arXiv:2211.05633",
    "title": "Transfer learning and Local interpretable model agnostic based visual  approach in Monkeypox Disease Detection and Classification: A Deep Learning  insights",
    "abstract": "The recent development of Monkeypox disease among various nations poses a\nglobal pandemic threat when the world is still fighting Coronavirus\nDisease-2019 (COVID-19). At its dawn, the slow and steady transmission of\nMonkeypox disease among individuals needs to be addressed seriously. Over the\nyears, Deep learning (DL) based disease prediction has demonstrated true\npotential by providing early, cheap, and affordable diagnosis facilities.\nConsidering this opportunity, we have conducted two studies where we modified\nand tested six distinct deep learning models-VGG16, InceptionResNetV2,\nResNet50, ResNet101, MobileNetV2, and VGG19-using transfer learning approaches.\nOur preliminary computational results show that the proposed modified\nInceptionResNetV2 and MobileNetV2 models perform best by achieving an accuracy\nranging from 93% to 99%. Our findings are reinforced by recent academic work\nthat demonstrates improved performance in constructing multiple disease\ndiagnosis models using transfer learning approaches. Lastly, we further explain\nour model prediction using Local Interpretable Model-Agnostic Explanations\n(LIME), which play an essential role in identifying important features that\ncharacterize the onset of Monkeypox disease.",
    "descriptor": "",
    "authors": [
      "Md Manjurul Ahsan",
      "Tareque Abu Abdullah",
      "Md Shahin Ali",
      "Fatematuj Jahora",
      "Md Khairul Islam",
      "Amin G. Alhashim",
      "Kishor Datta Gupta"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05633"
  },
  {
    "id": "arXiv:2211.05634",
    "title": "Generalization of generative model for neuronal ensemble inference  method",
    "abstract": "Various brain functions that are necessary to maintain life activities\nmaterialize through the interaction of countless neurons. Therefore, it is\nimportant to analyze the structure of functional neuronal network. To elucidate\nthe mechanism of brain function, many studies are being actively conducted on\nthe structure of functional neuronal ensemble and hub, including all areas of\nneuroscience. In addition, recent study suggests that the existence of\nfunctional neuronal ensembles and hubs contributes to the efficiency of\ninformation processing. For these reasons, there is a demand for methods to\ninfer functional neuronal ensembles from neuronal activity data, and methods\nbased on Bayesian inference have been proposed. However, there is a problem in\nmodeling the activity in Bayesian inference. The features of each neuron's\nactivity have non-stationarity depending on physiological experimental\nconditions. As a result, the assumption of stationarity in Bayesian inference\nmodel impedes inference, which leads to destabilization of inference results\nand degradation of inference accuracy. In this study, we extend the\nexpressivity of the model in the previous study and improve it to a soft\nclustering method, which can be applied to activity data with non-stationarity.\nIn addition, for the effectiveness of the method, we apply the developed method\nto synthetic data generated by the leaky-integrate-and-fire model, and discuss\nthe result.",
    "descriptor": "\nComments: 17 pages, 3 figures\n",
    "authors": [
      "Shun Kimura",
      "Koujin Takeda"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Machine Learning (cs.LG)",
      "Biological Physics (physics.bio-ph)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2211.05634"
  },
  {
    "id": "arXiv:2211.05639",
    "title": "Gaussian inference for data-driven state-feedback design of nonlinear  systems",
    "abstract": "Data-driven control of nonlinear systems with rigorous guarantees is a\nchallenging problem as it usually calls for nonconvex optimization and requires\noften knowledge of the true basis functions of the system dynamics. To tackle\nthese drawbacks, this work is based on a data-driven polynomial representation\nof general nonlinear systems exploiting Taylor polynomials. Thereby, we design\nstate-feedback laws that render a known equilibrium point globally\nasymptotically stable while operating with respect to a desired quadratic\nperformance criterion. The calculation of the polynomial state feedback boils\ndown to a single sum-ofsquares optimization problem, and hence to\ncomputationally tractable linear matrix inequalities. Moreover, we examine\nstate-input data in presence of Gaussian noise by Bayesian inference to\novercome the conservatism of deterministic noise characterizations from recent\ndata-driven control approaches for Gaussian noise.",
    "descriptor": "",
    "authors": [
      "Tim Martin",
      "Thomas B. Sch\u00f6n",
      "Frank Allg\u00f6wer"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.05639"
  },
  {
    "id": "arXiv:2211.05651",
    "title": "Complexity of Chess Domination Problems",
    "abstract": "We study different domination problems of attacking and non-attacking rooks\nand queens on polyominoes and polycubes of all dimensions. Our main result\nproves that the problem is NP-complete for non-attacking queens on polyominoes\nand for non-attacking rooks on three-dimensional polycubes. We also analyze\nthese problems on the set of convex polyominoes, for which we conjecture and\ngive some evidence that these domination problems restricted to this subset of\npolyominoes might be NP-complete for both, queens and rooks. We have also\ncomputed new values for classical queen domination problems on chessboards\n(square polyominoes). For our computations, we have translated the problem into\nan integer linear programming instance. Finally, using this computational\nimplementation and the game engine Godot, we have developed a video game of\nminimal domination of queens and rooks on randomly generated polyominoes.",
    "descriptor": "\nComments: 18 pages, 17 figures, 4 tables\n",
    "authors": [
      "Alexis Langlois-R\u00e9millard",
      "Christoph M\u00fc\u00dfig",
      "\u00c9rika R\u00f3ldan"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.05651"
  },
  {
    "id": "arXiv:2211.05658",
    "title": "Multi-objective optimization via evolutionary algorithm (MOVEA) for  high-definition transcranial electrical stimulation of the human brain",
    "abstract": "Transcranial temporal interference stimulation (tTIS) has been reported to be\neffective in stimulating deep brain structures in experimental studies.\nHowever, a computational framework for optimizing the tTIS strategy and\nsimulating the impact of tTIS on the brain is still lacking, as previous\nmethods rely on predefined parameters and hardly adapt to additional\nconstraints. Here, we propose a general framework, namely multi-objective\noptimization via evolutionary algorithm (MOVEA), to solve the nonconvex\noptimization problem for various stimulation techniques, including tTIS and\ntranscranial alternating current stimulation (tACS). By optimizing the\nelectrode montage in a two-stage structure, MOVEA can be compatible with\nadditional constraints (e.g., the number of electrodes, additional avoidance\nregions), and MOVEA can accelerate to obtain the Pareto fronts. These Pareto\nfronts consist of a set of optimal solutions under different requirements,\nsuggesting a trade-off relationship between conflicting objectives, such as\nintensity and focality. Based on MOVEA, we make comprehensive comparisons\nbetween tACS and tTIS in terms of intensity, focality and maneuverability for\ntargets of different depths. Our results show that although the tTIS can only\nobtain a relatively low maximum achievable electric field strength, for\nexample, the maximum intensity of motor area under tTIS is 0.42V /m, while\n0.51V /m under tACS, it helps improve the focality by reducing 60% activated\nvolume outside the target. We further perform ANOVA on the stimulation results\nof eight subjects with tACS and tTIS. Despite the individual differences in\nhead models, our results suggest that tACS has a greater intensity and tTIS has\na higher focality. These findings provide guidance on the choice between tACS\nand tTIS and indicate a great potential in tTIS-based personalized\nneuromodulation. Code will be released soon.",
    "descriptor": "",
    "authors": [
      "Mo Wang",
      "Kexin Lou",
      "Zeming Liu",
      "Pengfei Wei",
      "Quanying Liu"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2211.05658"
  },
  {
    "id": "arXiv:2211.05688",
    "title": "Probabilistic amplitude shaping for continuous-variable quantum key  distribution with discrete modulation",
    "abstract": "To achieve the maximum information transfer and face a possible eavesdropper,\nthe samples transmitted in continuous-variable quantum key distribution\n(CV-QKD) protocols are to be drawn from a continuous Gaussian distribution. As\na matter of fact, in practical implementations the transmitter has a finite\n(power) dynamics and the Gaussian sampling can be only approximated. This\nrequires the quantum protocols to operate at small powers. In this paper, we\nshow that a suitable probabilistic amplitude shaping of a finite set of symbols\nallows to approximate at will the optimal channel capacity also for increasing\naverage powers. We investigate the feasibility of this approach in the\nframework of CV-QKD, propose a protocol employing discrete quadrature amplitude\nmodulation assisted with probabilistic amplitude shaping, and we perform the\ncomplete security analysis in ideal conditions.",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Michele N. Notarnicola",
      "Stefano Olivares",
      "Enrico Forestieri",
      "Luca Pot\u00ec",
      "Marco Secondini"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.05688"
  },
  {
    "id": "arXiv:2211.05690",
    "title": "Robust Model Selection of Non Tree-Structured Gaussian Graphical Models",
    "abstract": "We consider the problem of learning the structure underlying a Gaussian\ngraphical model when the variables (or subsets thereof) are corrupted by\nindependent noise. A recent line of work establishes that even for\ntree-structured graphical models, only partial structure recovery is possible\nand goes on to devise algorithms to identify the structure up to an\n(unavoidable) equivalence class of trees. We extend these results beyond trees\nand consider the model selection problem under noise for non tree-structured\ngraphs, as tree graphs cannot model several real-world scenarios. Although\nunidentifiable, we show that, like the tree-structured graphs, the ambiguity is\nlimited to an equivalence class. This limited ambiguity can help provide\nmeaningful clustering information (even with noise), which is helpful in\ncomputer and social networks, protein-protein interaction networks, and power\nnetworks. Furthermore, we devise an algorithm based on a novel ancestral\ntesting method for recovering the equivalence class. We complement these\nresults with finite sample guarantees for the algorithm in the high-dimensional\nregime.",
    "descriptor": "",
    "authors": [
      "Abrar Zahin",
      "Rajasekhar Anguluri",
      "Oliver Kosut",
      "Lalitha Sankar",
      "Gautam Dasarathy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2211.05690"
  },
  {
    "id": "arXiv:2211.05698",
    "title": "Probabilistic thermal stability prediction through sparsity promoting  transformer representation",
    "abstract": "Pre-trained protein language models have demonstrated significant\napplicability in different protein engineering task. A general usage of these\npre-trained transformer models latent representation is to use a mean pool\nacross residue positions to reduce the feature dimensions to further downstream\ntasks such as predicting bio-physics properties or other functional behaviours.\nIn this paper we provide a two-fold contribution to machine learning (ML)\ndriven drug design. Firstly, we demonstrate the power of sparsity by promoting\npenalization of pre-trained transformer models to secure more robust and\naccurate melting temperature (Tm) prediction of single-chain variable fragments\nwith a mean absolute error of 0.23C. Secondly, we demonstrate the power of\nframing our prediction problem in a probabilistic framework. Specifically, we\nadvocate for the need of adopting probabilistic frameworks especially in the\ncontext of ML driven drug design.",
    "descriptor": "",
    "authors": [
      "Yevgen Zainchkovskyy",
      "Jesper Ferkinghoff-Borg",
      "Anja Bennett",
      "Thomas Egebjerg",
      "Nikolai Lorenzen",
      "Per Jr. Greisen",
      "S\u00f8ren Hauberg",
      "Carsten Stahlhut"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05698"
  },
  {
    "id": "arXiv:2211.05714",
    "title": "Bosonic coding: introduction and use cases",
    "abstract": "Bosonic or continuous-variable coding is a field concerned with robust\nquantum information processing and communication with electromagnetic signals\nor mechanical modes. I review bosonic quantum memories, characterizing them as\neither bosonic stabilizer or bosonic Fock-state codes. I then enumerate various\napplications of bosonic encodings, four of which circumvent no-go theorems due\nto the intrinsic infinite-dimensionality of bosonic systems.",
    "descriptor": "\nComments: 23 pages of text, 3 figures; based on lectures given at the 209th course of the International School of Physics \"Enrico Fermi\"\n",
    "authors": [
      "Victor V. Albert"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.05714"
  },
  {
    "id": "arXiv:2211.05727",
    "title": "A Randomised Subspace Gauss-Newton Method for Nonlinear Least-Squares",
    "abstract": "We propose a Randomised Subspace Gauss-Newton (R-SGN) algorithm for solving\nnonlinear least-squares optimization problems, that uses a sketched Jacobian of\nthe residual in the variable domain and solves a reduced linear least-squares\non each iteration. A sublinear global rate of convergence result is presented\nfor a trust-region variant of R-SGN, with high probability, which matches\ndeterministic counterpart results in the order of the accuracy tolerance.\nPromising preliminary numerical results are presented for R-SGN on logistic\nregression and on nonlinear regression problems from the CUTEst collection.",
    "descriptor": "\nComments: This work first appears in Thirty-seventh International Conference on Machine Learning, 2020, in Workshop on Beyond First Order Methods in ML Systems. this https URL arXiv admin note: text overlap with arXiv:2206.03371\n",
    "authors": [
      "Coralia Cartis",
      "Jaroslav Fowkes",
      "Zhen Shao"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05727"
  },
  {
    "id": "arXiv:2211.05728",
    "title": "Quantum Power Flows: From Theory to Practice",
    "abstract": "Climate change is becoming one of the greatest challenges to the sustainable\ndevelopment of modern society. Renewable energies with low density greatly\ncomplicate the online optimization and control processes, where modern advanced\ncomputational technologies, specifically quantum computing, have significant\npotential to help. In this paper, we discuss applications of quantum computing\nalgorithms toward state-of-the-art smart grid problems. We suggest potential,\nexponential quantum speedup by the use of the Harrow-Hassidim-Lloyd (HHL)\nalgorithms for sparse matrix inversions in power-flow problems. However,\npractical implementations of the algorithm are limited by the noise of quantum\ncircuits, the hardness of realizations of quantum random access memories\n(QRAM), and the depth of the required quantum circuits. We benchmark the\nhardware and software requirements from the state-of-the-art power-flow\nalgorithms, including QRAM requirements from hybrid phonon-transmon systems,\nand explicit gate counting used in HHL for explicit realizations. We also\ndevelop near-term algorithms of power flow by variational quantum circuits and\nimplement real experiments for 6 qubits with a truncated version of power\nflows.",
    "descriptor": "\nComments: 30 pages, many figures\n",
    "authors": [
      "Junyu Liu",
      "Han Zheng",
      "Masanori Hanada",
      "Kanav Setia",
      "Dan Wu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.05728"
  },
  {
    "id": "arXiv:2211.05762",
    "title": "Efficient brain age prediction from 3D MRI volumes using 2D projections",
    "abstract": "Using 3D CNNs on high resolution medical volumes is very computationally\ndemanding, especially for large datasets like the UK Biobank which aims to scan\n100,000 subjects. Here we demonstrate that using 2D CNNs on a few 2D\nprojections (representing mean and standard deviation across axial, sagittal\nand coronal slices) of the 3D volumes leads to reasonable test accuracy when\npredicting the age from brain volumes. Using our approach, one training epoch\nwith 20,324 subjects takes 40 - 70 seconds using a single GPU, which is almost\n100 times faster compared to a small 3D CNN. These results are important for\nresearchers who do not have access to expensive GPU hardware for 3D CNNs.",
    "descriptor": "",
    "authors": [
      "Johan J\u00f6nemo",
      "Muhammad Usman Akbar",
      "Robin K\u00e4mpe",
      "J Paul Hamilton",
      "Anders Eklund"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05762"
  },
  {
    "id": "arXiv:2211.05777",
    "title": "Hybrid quantum neural network for drug response prediction",
    "abstract": "Cancer is one of the leading causes of death worldwide. It is caused by a\nvariety of genetic mutations, which makes every instance of the disease unique.\nSince chemotherapy can have extremely severe side effects, each patient\nrequires a personalized treatment plan. Finding the dosages that maximize the\nbeneficial effects of the drugs and minimize their adverse side effects is\nvital. Deep neural networks automate and improve drug selection. However, they\nrequire a lot of data to be trained on. Therefore, there is a need for\nmachine-learning approaches that require less data. Hybrid quantum neural\nnetworks were shown to provide a potential advantage in problems where training\ndata availability is limited. We propose a novel hybrid quantum neural network\nfor drug response prediction, based on a combination of convolutional, graph\nconvolutional, and deep quantum neural layers of 8 qubits with 363 layers. We\ntest our model on the reduced Genomics of Drug Sensitivity in Cancer dataset\nand show that the hybrid quantum model outperforms its classical analog by 15%\nin predicting IC50 drug effectiveness values. The proposed hybrid quantum\nmachine learning model is a step towards deep quantum data-efficient algorithms\nwith thousands of quantum gates for solving problems in personalized medicine,\nwhere data collection is a challenge.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Asel Sagingalieva",
      "Mohammad Kordzanganeh",
      "Nurbolat Kenbayev",
      "Daria Kosichkina",
      "Tatiana Tomashuk",
      "Alexey Melnikov"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.05777"
  },
  {
    "id": "arXiv:1702.05805",
    "title": "Conditional Lower Bounds for All-Pairs Max-Flow",
    "abstract": "Conditional Lower Bounds for All-Pairs Max-Flow",
    "descriptor": "",
    "authors": [
      "Robert Krauthgamer",
      "Ohad Trabelsi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1702.05805"
  },
  {
    "id": "arXiv:1707.06808",
    "title": "The Complexity Landscape of Fixed-Parameter Directed Steiner Network  Problems",
    "abstract": "Comments: Appeared at the 43rd International Colloquium on Automata, Languages, and Programming (ICALP 2016)",
    "descriptor": "\nComments: Appeared at the 43rd International Colloquium on Automata, Languages, and Programming (ICALP 2016)\n",
    "authors": [
      "Andreas Emil Feldmann",
      "Daniel Marx"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1707.06808"
  },
  {
    "id": "arXiv:1811.07763",
    "title": "Decentralized Exploration in Multi-Armed Bandits -- Extended version",
    "abstract": "Decentralized Exploration in Multi-Armed Bandits -- Extended version",
    "descriptor": "",
    "authors": [
      "Rapha\u00ebl F\u00e9raud",
      "R\u00e9da Alami",
      "Romain Laroche"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1811.07763"
  },
  {
    "id": "arXiv:1811.12231",
    "title": "ImageNet-trained CNNs are biased towards texture; increasing shape bias  improves accuracy and robustness",
    "abstract": "Comments: Accepted at ICLR 2019 (oral)",
    "descriptor": "\nComments: Accepted at ICLR 2019 (oral)\n",
    "authors": [
      "Robert Geirhos",
      "Patricia Rubisch",
      "Claudio Michaelis",
      "Matthias Bethge",
      "Felix A. Wichmann",
      "Wieland Brendel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1811.12231"
  },
  {
    "id": "arXiv:1901.07924",
    "title": "Online Learning with Diverse User Preferences",
    "abstract": "Comments: Some data is missing",
    "descriptor": "\nComments: Some data is missing\n",
    "authors": [
      "Chao Gan",
      "Jing Yang",
      "Ruida Zhou",
      "Cong Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1901.07924"
  },
  {
    "id": "arXiv:1903.07138",
    "title": "A Brain-inspired Algorithm for Training Highly Sparse Neural Networks",
    "abstract": "A Brain-inspired Algorithm for Training Highly Sparse Neural Networks",
    "descriptor": "",
    "authors": [
      "Zahra Atashgahi",
      "Joost Pieterse",
      "Shiwei Liu",
      "Decebal Constantin Mocanu",
      "Raymond Veldhuis",
      "Mykola Pechenizkiy"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1903.07138"
  },
  {
    "id": "arXiv:1907.04752",
    "title": "Sparse Regular Expression Matching",
    "abstract": "Sparse Regular Expression Matching",
    "descriptor": "",
    "authors": [
      "Philip Bille",
      "Inge Li G\u00f8rtz"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1907.04752"
  },
  {
    "id": "arXiv:1911.10737",
    "title": "Nearest Neighbor Sampling of Point Sets using Random Rays",
    "abstract": "Comments: 35 pages, 12 figures, submitted to CAMC special issue, additional content added",
    "descriptor": "\nComments: 35 pages, 12 figures, submitted to CAMC special issue, additional content added\n",
    "authors": [
      "Liangchen Liu",
      "Louis Ly",
      "Colin Macdonald",
      "Yen-Hsi Richard Tsai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1911.10737"
  },
  {
    "id": "arXiv:1912.13309",
    "title": "Learning in Discounted-cost and Average-cost Mean-field Games",
    "abstract": "Comments: 59 pages",
    "descriptor": "\nComments: 59 pages\n",
    "authors": [
      "Berkay Anahtarc\u0131",
      "Can Deha Kar\u0131ks\u0131z",
      "Naci Saldi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/1912.13309"
  },
  {
    "id": "arXiv:2003.11987",
    "title": "Partially Observed Discrete-Time Risk-Sensitive Mean Field Games",
    "abstract": "Comments: 37 pages. arXiv admin note: substantial text overlap with arXiv:1705.02036, arXiv:1808.03929",
    "descriptor": "\nComments: 37 pages. arXiv admin note: substantial text overlap with arXiv:1705.02036, arXiv:1808.03929\n",
    "authors": [
      "Naci Saldi",
      "Tamer Basar",
      "Maxim Raginsky"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2003.11987"
  },
  {
    "id": "arXiv:2003.12151",
    "title": "Q-Learning in Regularized Mean-field Games",
    "abstract": "Comments: 32 pages. arXiv admin note: text overlap with arXiv:1912.13309",
    "descriptor": "\nComments: 32 pages. arXiv admin note: text overlap with arXiv:1912.13309\n",
    "authors": [
      "Berkay Anahtarci",
      "Can Deha Kariksiz",
      "Naci Saldi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2003.12151"
  },
  {
    "id": "arXiv:2006.14167",
    "title": "Some approaches used to overcome overestimation in Deep Reinforcement  Learning algorithms",
    "abstract": "Comments: 9 pages, 5 figures",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Rafael Stekolshchik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.14167"
  },
  {
    "id": "arXiv:2012.09226",
    "title": "Optimal transport for vector Gaussian mixture models",
    "abstract": "Optimal transport for vector Gaussian mixture models",
    "descriptor": "",
    "authors": [
      "Jiening Zhu",
      "Kaiming Xu",
      "Allen Tannenbaum"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2012.09226"
  },
  {
    "id": "arXiv:2012.13341",
    "title": "AudioViewer: Learning to Visualize Sounds",
    "abstract": "AudioViewer: Learning to Visualize Sounds",
    "descriptor": "",
    "authors": [
      "Chunjin Song",
      "Yuchi Zhang",
      "Willis Peng",
      "Parmis Mohaghegh",
      "Bastian Wandt",
      "Helge Rhodin"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2012.13341"
  },
  {
    "id": "arXiv:2102.10095",
    "title": "Brownian bridge expansions for L\u00e9vy area approximations and particular  values of the Riemann zeta function",
    "abstract": "Comments: 28 pages, 4 figures, 2 tables, published version",
    "descriptor": "\nComments: 28 pages, 4 figures, 2 tables, published version\n",
    "authors": [
      "James Foster",
      "Karen Habermann"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2102.10095"
  },
  {
    "id": "arXiv:2103.08413",
    "title": "Megha: Decentralized Global Fair Scheduling for Federated Clusters",
    "abstract": "Comments: 10 pages, 12 figures, conference paper",
    "descriptor": "\nComments: 10 pages, 12 figures, conference paper\n",
    "authors": [
      "Meghana Thiyyakat",
      "Subramaniam Kalambur",
      "Dinkar Sitaram"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2103.08413"
  },
  {
    "id": "arXiv:2103.12450",
    "title": "Are Neural Language Models Good Plagiarists? A Benchmark for Neural  Paraphrase Detection",
    "abstract": "Are Neural Language Models Good Plagiarists? A Benchmark for Neural  Paraphrase Detection",
    "descriptor": "",
    "authors": [
      "Jan Philip Wahle",
      "Terry Ruas",
      "Norman Meuschke",
      "Bela Gipp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2103.12450"
  },
  {
    "id": "arXiv:2103.15206",
    "title": "Knowledge, beliefs, attitudes and perceived risk about COVID-19 vaccine  and determinants of COVID-19 vaccine acceptance in Bangladesh",
    "abstract": "Comments: Accepted by PLOS ONE: this https URL",
    "descriptor": "\nComments: Accepted by PLOS ONE: this https URL\n",
    "authors": [
      "Sultan Mahmud",
      "Md. Mohsin",
      "Ijaz Ahmed Khan",
      "Ashraf Uddin Mian",
      "Miah Akib Zaman"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.15206"
  },
  {
    "id": "arXiv:2104.08101",
    "title": "Embedding Dependencies Between Wind Farms in Distributionally Robust  Optimal Power Flow",
    "abstract": "Embedding Dependencies Between Wind Farms in Distributionally Robust  Optimal Power Flow",
    "descriptor": "",
    "authors": [
      "Adriano Arrigo",
      "Jalal Kazempour",
      "Zacharie De Gr\u00e8ve",
      "Jean-Fran\u00e7ois Toubeau",
      "Fran\u00e7ois Vall\u00e9e"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.08101"
  },
  {
    "id": "arXiv:2104.10004",
    "title": "Toward the Prevention of Privacy Threats: How Can We Persuade Our Social  Network Platform Users?",
    "abstract": "Comments: HCIS accepted version",
    "descriptor": "\nComments: HCIS accepted version\n",
    "authors": [
      "Ramon Ruiz-Dolz",
      "Jose Alemany",
      "Stella Heras",
      "Ana Garc\u00eda-Fornes"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2104.10004"
  },
  {
    "id": "arXiv:2108.01599",
    "title": "A Gaze Data-based Comparative Study to Build a Trustworthy Human-AI  Collaboration in Crash Anticipation",
    "abstract": "Comments: Revised and submitted to International Conference on Transportation and Development (ICTD 2023) on Nov 2022",
    "descriptor": "\nComments: Revised and submitted to International Conference on Transportation and Development (ICTD 2023) on Nov 2022\n",
    "authors": [
      "Yu Li",
      "Muhammad Monjurul Karim",
      "Ruwen Qin"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2108.01599"
  },
  {
    "id": "arXiv:2109.05084",
    "title": "Winding Through: Crowd Navigation via Topological Invariance",
    "abstract": "Comments: Final version to appear at IEEE RA-L",
    "descriptor": "\nComments: Final version to appear at IEEE RA-L\n",
    "authors": [
      "Christoforos Mavrogiannis",
      "Krishna Balasubramanian",
      "Sriyash Poddar",
      "Anush Gandra",
      "Siddhartha S. Srinivasa"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.05084"
  },
  {
    "id": "arXiv:2109.05585",
    "title": "U-Net Convolutional Network for Recognition of Vessels and Materials in  Chemistry Lab",
    "abstract": "Comments: Some models need to be improved to get exact results",
    "descriptor": "\nComments: Some models need to be improved to get exact results\n",
    "authors": [
      "Zhihao Shang",
      "Di Bo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.05585"
  },
  {
    "id": "arXiv:2110.02291",
    "title": "FedDQ: Communication-Efficient Federated Learning with Descending  Quantization",
    "abstract": "Comments: Accepted by IEEE GLOBECOM 2022",
    "descriptor": "\nComments: Accepted by IEEE GLOBECOM 2022\n",
    "authors": [
      "Linping Qu",
      "Shenghui Song",
      "Chi-Ying Tsui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.02291"
  },
  {
    "id": "arXiv:2110.02337",
    "title": "A Reactive Power Market for the Future Grid",
    "abstract": "Comments: 26 pages, 9 figures, 3 tables",
    "descriptor": "\nComments: 26 pages, 9 figures, 3 tables\n",
    "authors": [
      "Adam Potter",
      "Rabab Haider",
      "Giulio Ferro",
      "Michela Robba",
      "Anuradha M. Annaswamy"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "General Economics (econ.GN)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.02337"
  },
  {
    "id": "arXiv:2110.08483",
    "title": "Simplest Streaming Trees",
    "abstract": "Simplest Streaming Trees",
    "descriptor": "",
    "authors": [
      "Haoyin Xu",
      "Jayanta Dey",
      "Sambit Panda",
      "Joshua T. Vogelstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.08483"
  },
  {
    "id": "arXiv:2111.07819",
    "title": "Testing the Generalization of Neural Language Models for COVID-19  Misinformation Detection",
    "abstract": "Testing the Generalization of Neural Language Models for COVID-19  Misinformation Detection",
    "descriptor": "",
    "authors": [
      "Jan Philip Wahle",
      "Nischal Ashok",
      "Terry Ruas",
      "Norman Meuschke",
      "Tirthankar Ghosal",
      "Bela Gipp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.07819"
  },
  {
    "id": "arXiv:2111.12309",
    "title": "RegionCL: Can Simple Region Swapping Contribute to Contrastive Learning?",
    "abstract": "Comments: ECCV2022, 15 pages, 8 figures",
    "descriptor": "\nComments: ECCV2022, 15 pages, 8 figures\n",
    "authors": [
      "Yufei Xu",
      "Qiming Zhang",
      "Jing Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12309"
  },
  {
    "id": "arXiv:2112.10668",
    "title": "Few-shot Learning with Multilingual Language Models",
    "abstract": "Comments: Accepted to EMNLP 2022; 34 pages",
    "descriptor": "\nComments: Accepted to EMNLP 2022; 34 pages\n",
    "authors": [
      "Xi Victoria Lin",
      "Todor Mihaylov",
      "Mikel Artetxe",
      "Tianlu Wang",
      "Shuohui Chen",
      "Daniel Simig",
      "Myle Ott",
      "Naman Goyal",
      "Shruti Bhosale",
      "Jingfei Du",
      "Ramakanth Pasunuru",
      "Sam Shleifer",
      "Punit Singh Koura",
      "Vishrav Chaudhary",
      "Brian O'Horo",
      "Jeff Wang",
      "Luke Zettlemoyer",
      "Zornitsa Kozareva",
      "Mona Diab",
      "Veselin Stoyanov",
      "Xian Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.10668"
  },
  {
    "id": "arXiv:2201.00350",
    "title": "LSTM Architecture for Oil Stocks Prices Prediction",
    "abstract": "Comments: 22 figures, 13 tables, one more section and some part and analysis were added",
    "descriptor": "\nComments: 22 figures, 13 tables, one more section and some part and analysis were added\n",
    "authors": [
      "Javad T. Firouzjaee",
      "Pouriya Khaliliyan"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.00350"
  },
  {
    "id": "arXiv:2201.06300",
    "title": "Coded Distributed Computing with Pre-set Assignments of Data and Output  Functions",
    "abstract": "Comments: This paper was in part accepted to the IEEE Global Communications Conference (Globecom) 2022",
    "descriptor": "\nComments: This paper was in part accepted to the IEEE Global Communications Conference (Globecom) 2022\n",
    "authors": [
      "Yuhan Wang",
      "Youlong Wu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.06300"
  },
  {
    "id": "arXiv:2201.10001",
    "title": "The Enforced Transfer: An Instance-Based Divide-and-Conquer Unsupervised  Domain Adaptation Algorithm",
    "abstract": "The Enforced Transfer: An Instance-Based Divide-and-Conquer Unsupervised  Domain Adaptation Algorithm",
    "descriptor": "",
    "authors": [
      "Ye Gao",
      "Brian Baucom",
      "Karen Rose",
      "Kristina Gordon",
      "Hongning Wang",
      "John Stankovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.10001"
  },
  {
    "id": "arXiv:2201.12204",
    "title": "From data to functa: Your data point is a function and you can treat it  like one",
    "abstract": "From data to functa: Your data point is a function and you can treat it  like one",
    "descriptor": "",
    "authors": [
      "Emilien Dupont",
      "Hyunjik Kim",
      "S. M. Ali Eslami",
      "Danilo Rezende",
      "Dan Rosenbaum"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12204"
  },
  {
    "id": "arXiv:2201.13409",
    "title": "A framework for bilevel optimization that enables stochastic and global  variance reduction algorithms",
    "abstract": "Comments: Accepted at NeurIPS 2022",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Mathieu Dagr\u00e9ou",
      "Pierre Ablin",
      "Samuel Vaiter",
      "Thomas Moreau"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.13409"
  },
  {
    "id": "arXiv:2202.01338",
    "title": "Regression Transformer: Concurrent Conditional Generation and Regression  by Blending Numerical and Textual Tokens",
    "abstract": "Comments: Updated paper, under review; Preliminary version as spotlight talk at ICLR 2022 workshop on Machine Learning for Drug Discovery",
    "descriptor": "\nComments: Updated paper, under review; Preliminary version as spotlight talk at ICLR 2022 workshop on Machine Learning for Drug Discovery\n",
    "authors": [
      "Jannis Born",
      "Matteo Manica"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2202.01338"
  },
  {
    "id": "arXiv:2202.03391",
    "title": "Gradient-Based Learning of Discrete Structured Measurement Operators for  Signal Recovery",
    "abstract": "Comments: The current version of the manuscript has been accepted to IEEE Journal on Selected Areas in Information Theory",
    "descriptor": "\nComments: The current version of the manuscript has been accepted to IEEE Journal on Selected Areas in Information Theory\n",
    "authors": [
      "Jonathan Sauder",
      "Martin Genzel",
      "Peter Jung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.03391"
  },
  {
    "id": "arXiv:2202.04359",
    "title": "Cost-effective Framework for Gradual Domain Adaptation with  Multifidelity",
    "abstract": "Cost-effective Framework for Gradual Domain Adaptation with  Multifidelity",
    "descriptor": "",
    "authors": [
      "Shogo Sagawa",
      "Hideitsu Hino"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04359"
  },
  {
    "id": "arXiv:2202.06768",
    "title": "Probabilistic Embeddings Revisited",
    "abstract": "Probabilistic Embeddings Revisited",
    "descriptor": "",
    "authors": [
      "Ivan Karpukhin",
      "Stanislav Dereka",
      "Sergey Kolesnikov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.06768"
  },
  {
    "id": "arXiv:2202.10525",
    "title": "A Probabilistic Approach to The Perfect Sum Problem",
    "abstract": "Comments: 22 pages, 6 figures",
    "descriptor": "\nComments: 22 pages, 6 figures\n",
    "authors": [
      "Kristof Pusztai"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Applications (stat.AP)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.10525"
  },
  {
    "id": "arXiv:2203.02478",
    "title": "The Sherali-Adams Hierarchy for Promise CSPs through Tensors",
    "abstract": "Comments: Section 6 is subsumed by arXiv:2211.03168; all other sections (apart from Section 7) are subsumed by arXiv:2207.02277",
    "descriptor": "\nComments: Section 6 is subsumed by arXiv:2211.03168; all other sections (apart from Section 7) are subsumed by arXiv:2207.02277\n",
    "authors": [
      "Lorenzo Ciardo",
      "Stanislav \u017divn\u00fd"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.02478"
  },
  {
    "id": "arXiv:2203.03965",
    "title": "Few-Sample Traffic Prediction with Graph Networks using Locale as  Relational Inductive Biases",
    "abstract": "Few-Sample Traffic Prediction with Graph Networks using Locale as  Relational Inductive Biases",
    "descriptor": "",
    "authors": [
      "Mingxi Li",
      "Yihong Tang",
      "Wei Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2203.03965"
  },
  {
    "id": "arXiv:2203.04903",
    "title": "A new implementation of the geometric method for solving the Eady slice  equations",
    "abstract": "Comments: 43 pages, 9 figures",
    "descriptor": "\nComments: 43 pages, 9 figures\n",
    "authors": [
      "Charlie P. Egan",
      "David P. Bourne",
      "Colin J. Cotter",
      "Mike J. P. Cullen",
      "Beatrice Pelloni",
      "Steven M. Roper",
      "Mark Wilkinson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.04903"
  },
  {
    "id": "arXiv:2203.05117",
    "title": "Optimal Methods for Risk Averse Distributed Optimization",
    "abstract": "Optimal Methods for Risk Averse Distributed Optimization",
    "descriptor": "",
    "authors": [
      "Guanghui Lan",
      "Zhe Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.05117"
  },
  {
    "id": "arXiv:2203.10117",
    "title": "On the role of Lip Articulation in Visual Speech Perception",
    "abstract": "Comments: Submitted to ICASSP 2023",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Zakaria Aldeneh",
      "Masha Fedzechkina",
      "Skyler Seto",
      "Katherine Metcalf",
      "Miguel Sarabia",
      "Nicholas Apostoloff",
      "Barry-John Theobald"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.10117"
  },
  {
    "id": "arXiv:2203.14802",
    "title": "\"Born in Rome\" or \"Sleeping Beauty\": Emergence of hashtag popularity on  the Chinese microblog Sina Weibo",
    "abstract": "Comments: Main paper 12 pages, 7 figures. Supplementary information 5 pages, 3 figures",
    "descriptor": "\nComments: Main paper 12 pages, 7 figures. Supplementary information 5 pages, 3 figures\n",
    "authors": [
      "Hao Cui",
      "J\u00e1nos Kert\u00e9sz"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2203.14802"
  },
  {
    "id": "arXiv:2204.01089",
    "title": "VRKG4Rec: Virtual Relational Knowledge Graphs for Recommendation",
    "abstract": "VRKG4Rec: Virtual Relational Knowledge Graphs for Recommendation",
    "descriptor": "",
    "authors": [
      "Lingyun Lu",
      "Bang Wang",
      "Zizhuo Zhang",
      "Shenghao Liu",
      "Han Xu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.01089"
  },
  {
    "id": "arXiv:2204.03393",
    "title": "TOSE: A Fast Capacity Determination Algorithm Based on Random Matrix  Theory",
    "abstract": "Comments: Another version of this paper has been uploaded by another author",
    "descriptor": "\nComments: Another version of this paper has been uploaded by another author\n",
    "authors": [
      "Dandan Jiang",
      "Han Hao",
      "Lu Yang",
      "Xiang Chen",
      "Wei Han",
      "Bo Bai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.03393"
  },
  {
    "id": "arXiv:2204.07143",
    "title": "Neighborhood Attention Transformer",
    "abstract": "Comments: Revision with details on our new Neighborhood Attention Extension (NATTEN), along with analysis on translational equivariance in attention-based models. NATTEN is open-sourced at: this https URL",
    "descriptor": "\nComments: Revision with details on our new Neighborhood Attention Extension (NATTEN), along with analysis on translational equivariance in attention-based models. NATTEN is open-sourced at: this https URL\n",
    "authors": [
      "Ali Hassani",
      "Steven Walton",
      "Jiachen Li",
      "Shen Li",
      "Humphrey Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07143"
  },
  {
    "id": "arXiv:2204.08009",
    "title": "WikiOmnia: generative QA corpus on the whole Russian Wikipedia",
    "abstract": "Comments: Accepted to GEM Workshop, EMNLP 2022",
    "descriptor": "\nComments: Accepted to GEM Workshop, EMNLP 2022\n",
    "authors": [
      "Dina Pisarevskaya",
      "Tatiana Shavrina"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.08009"
  },
  {
    "id": "arXiv:2204.08524",
    "title": "So2Sat POP -- A Curated Benchmark Data Set for Population Estimation  from Space on a Continental Scale",
    "abstract": "So2Sat POP -- A Curated Benchmark Data Set for Population Estimation  from Space on a Continental Scale",
    "descriptor": "",
    "authors": [
      "Sugandha Doda",
      "Yuanyuan Wang",
      "Matthias Kahl",
      "Eike Jens Hoffmann",
      "Kim Ouan",
      "Hannes Taubenb\u00f6ck",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.08524"
  },
  {
    "id": "arXiv:2204.11689",
    "title": "Deep electric field predictions by drift-reduced Braginskii theory with  plasma-neutral interactions based upon experimental images of boundary  turbulence",
    "abstract": "Comments: 6 pages, 3 figures, 2 tables",
    "descriptor": "\nComments: 6 pages, 3 figures, 2 tables\n",
    "authors": [
      "Abhilash Mathews",
      "Jerry Hughes",
      "James Terry",
      "Seung-Gyou Baek"
    ],
    "subjectives": [
      "Plasma Physics (physics.plasm-ph)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2204.11689"
  },
  {
    "id": "arXiv:2204.11894",
    "title": "Properly learning monotone functions via local reconstruction",
    "abstract": "Comments: FOCS 2022",
    "descriptor": "\nComments: FOCS 2022\n",
    "authors": [
      "Jane Lange",
      "Ronitt Rubinfeld",
      "Arsen Vasilyan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.11894"
  },
  {
    "id": "arXiv:2204.12674",
    "title": "A Span-level Bidirectional Network for Aspect Sentiment Triplet  Extraction",
    "abstract": "A Span-level Bidirectional Network for Aspect Sentiment Triplet  Extraction",
    "descriptor": "",
    "authors": [
      "Yuqi Chen",
      "Keming Chen",
      "Xian Sun",
      "Zequn Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.12674"
  },
  {
    "id": "arXiv:2204.13384",
    "title": "D3: A Massive Dataset of Scholarly Metadata for Analyzing the State of  Computer Science Research",
    "abstract": "D3: A Massive Dataset of Scholarly Metadata for Analyzing the State of  Computer Science Research",
    "descriptor": "",
    "authors": [
      "Jan Philip Wahle",
      "Terry Ruas",
      "Saif M. Mohammad",
      "Bela Gipp"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.13384"
  },
  {
    "id": "arXiv:2205.01438",
    "title": "FedGiA: An Efficient Hybrid Algorithm for Federated Learning",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2110.15318; text overlap with arXiv:2204.10607",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2110.15318; text overlap with arXiv:2204.10607\n",
    "authors": [
      "Shenglong Zhou",
      "Geoffrey Ye Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.01438"
  },
  {
    "id": "arXiv:2205.01663",
    "title": "Adversarial Training for High-Stakes Reliability",
    "abstract": "Comments: 30 pages, 7 figures, NeurIPS camera-ready",
    "descriptor": "\nComments: 30 pages, 7 figures, NeurIPS camera-ready\n",
    "authors": [
      "Daniel M. Ziegler",
      "Seraphina Nix",
      "Lawrence Chan",
      "Tim Bauman",
      "Peter Schmidt-Nielsen",
      "Tao Lin",
      "Adam Scherlis",
      "Noa Nabeshima",
      "Ben Weinstein-Raun",
      "Daniel de Haas",
      "Buck Shlegeris",
      "Nate Thomas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.01663"
  },
  {
    "id": "arXiv:2205.01677",
    "title": "ASTROMER: A transformer-based embedding for the representation of light  curves",
    "abstract": "ASTROMER: A transformer-based embedding for the representation of light  curves",
    "descriptor": "",
    "authors": [
      "C. Donoso-Oliva",
      "I. Becker",
      "P. Protopapas",
      "G. Cabrera-Vives",
      "Vishnu M.",
      "Harsh Vardhan"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01677"
  },
  {
    "id": "arXiv:2205.06494",
    "title": "A hybrid data driven-physics constrained Gaussian process regression  framework with deep kernel for uncertainty quantification",
    "abstract": "Comments: 16 pages, 10 figures",
    "descriptor": "\nComments: 16 pages, 10 figures\n",
    "authors": [
      "Cheng Chang",
      "Tieyong Zeng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.06494"
  },
  {
    "id": "arXiv:2205.09174",
    "title": "Cordial Miners: Fast and Efficient Consensus for Every Eventuality",
    "abstract": "Cordial Miners: Fast and Efficient Consensus for Every Eventuality",
    "descriptor": "",
    "authors": [
      "Idit Keidar",
      "Oded Naor",
      "Ehud Shapiro"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2205.09174"
  },
  {
    "id": "arXiv:2205.12216",
    "title": "T-Modules: Translation Modules for Zero-Shot Cross-Modal Machine  Translation",
    "abstract": "T-Modules: Translation Modules for Zero-Shot Cross-Modal Machine  Translation",
    "descriptor": "",
    "authors": [
      "Paul-Ambroise Duquenne",
      "Hongyu Gong",
      "Beno\u00eet Sagot",
      "Holger Schwenk"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12216"
  },
  {
    "id": "arXiv:2205.12514",
    "title": "Machine Translation Robustness to Natural Asemantic Variation",
    "abstract": "Comments: Accepted to EMNLP 2022",
    "descriptor": "\nComments: Accepted to EMNLP 2022\n",
    "authors": [
      "Jacob Bremerman",
      "Xiang Ren",
      "Jonathan May"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12514"
  },
  {
    "id": "arXiv:2205.12755",
    "title": "An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale  Multitask Learning Systems",
    "abstract": "An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale  Multitask Learning Systems",
    "descriptor": "",
    "authors": [
      "Andrea Gesmundo",
      "Jeff Dean"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2205.12755"
  },
  {
    "id": "arXiv:2205.13673",
    "title": "Diffusion of Community Fact-Checked Misinformation on Twitter",
    "abstract": "Diffusion of Community Fact-Checked Misinformation on Twitter",
    "descriptor": "",
    "authors": [
      "Chiara Drolsbach",
      "Nicolas Pr\u00f6llochs"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.13673"
  },
  {
    "id": "arXiv:2205.13684",
    "title": "Learning with Stochastic Orders",
    "abstract": "Comments: Code available at this https URL",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Carles Domingo-Enrich",
      "Yair Schiff",
      "Youssef Mroueh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2205.13684"
  },
  {
    "id": "arXiv:2206.01078",
    "title": "Deep Transformer Q-Networks for Partially Observable Reinforcement  Learning",
    "abstract": "Deep Transformer Q-Networks for Partially Observable Reinforcement  Learning",
    "descriptor": "",
    "authors": [
      "Kevin Esslinger",
      "Robert Platt",
      "Christopher Amato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01078"
  },
  {
    "id": "arXiv:2206.02405",
    "title": "Robust Image Protection Countering Cropping Manipulation",
    "abstract": "Comments: Withdrawn for further modifications",
    "descriptor": "\nComments: Withdrawn for further modifications\n",
    "authors": [
      "Qichao Ying",
      "Hang Zhou",
      "Zhenxing Qian",
      "Sheng Li",
      "Xinpeng Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02405"
  },
  {
    "id": "arXiv:2206.03023",
    "title": "How Far I'll Go: Offline Goal-Conditioned Reinforcement Learning via  $f$-Advantage Regression",
    "abstract": "Comments: NeurIPS 2022. Project website: this https URL",
    "descriptor": "\nComments: NeurIPS 2022. Project website: this https URL\n",
    "authors": [
      "Yecheng Jason Ma",
      "Jason Yan",
      "Dinesh Jayaraman",
      "Osbert Bastani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.03023"
  },
  {
    "id": "arXiv:2206.03043",
    "title": "COVIDx CT-3: A Large-scale, Multinational, Open-Source Benchmark Dataset  for Computer-aided COVID-19 Screening from Chest CT Images",
    "abstract": "Comments: MED-NeurIPS 2022 workshop, 6 pages",
    "descriptor": "\nComments: MED-NeurIPS 2022 workshop, 6 pages\n",
    "authors": [
      "Hayden Gunraj",
      "Tia Tuinstra",
      "Alexander Wong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03043"
  },
  {
    "id": "arXiv:2206.06947",
    "title": "K-Space Transformer for Undersampled MRI Reconstruction",
    "abstract": "K-Space Transformer for Undersampled MRI Reconstruction",
    "descriptor": "",
    "authors": [
      "Ziheng Zhao",
      "Tianjiao Zhang",
      "Weidi Xie",
      "Yanfeng Wang",
      "Ya Zhang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06947"
  },
  {
    "id": "arXiv:2206.07695",
    "title": "VoxGRAF: Fast 3D-Aware Image Synthesis with Sparse Voxel Grids",
    "abstract": "VoxGRAF: Fast 3D-Aware Image Synthesis with Sparse Voxel Grids",
    "descriptor": "",
    "authors": [
      "Katja Schwarz",
      "Axel Sauer",
      "Michael Niemeyer",
      "Yiyi Liao",
      "Andreas Geiger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.07695"
  },
  {
    "id": "arXiv:2206.09343",
    "title": "Analysis of curvature approximations via covariant curl and  incompatibility for Regge metrics",
    "abstract": "Analysis of curvature approximations via covariant curl and  incompatibility for Regge metrics",
    "descriptor": "",
    "authors": [
      "Jay Gopalakrishnan",
      "Michael Neunteufel",
      "Joachim Sch\u00f6berl",
      "Max Wardetzky"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.09343"
  },
  {
    "id": "arXiv:2206.09349",
    "title": "Quantifying Uncertainty In Traffic State Estimation Using Generative  Adversarial Networks",
    "abstract": "Quantifying Uncertainty In Traffic State Estimation Using Generative  Adversarial Networks",
    "descriptor": "",
    "authors": [
      "Zhaobin Mo",
      "Yongjie Fu",
      "Xuan Di"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09349"
  },
  {
    "id": "arXiv:2206.10326",
    "title": "The Metaverse Data Deluge: What Can We Do About It?",
    "abstract": "The Metaverse Data Deluge: What Can We Do About It?",
    "descriptor": "",
    "authors": [
      "Beng Chin Ooi",
      "Gang Chen",
      "Mike Zheng Shou",
      "Kian-Lee Tan",
      "Anthony Tung",
      "Xiaokui Xiao",
      "James Wei Luen Yip",
      "Meihui Zhang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.10326"
  },
  {
    "id": "arXiv:2206.10383",
    "title": "The Complexity of the Co-Occurrence Problem",
    "abstract": "The Complexity of the Co-Occurrence Problem",
    "descriptor": "",
    "authors": [
      "Philip Bille",
      "Inge Li G\u00f8rtz",
      "Tord Stordalen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.10383"
  },
  {
    "id": "arXiv:2206.13838",
    "title": "Inertia Estimation through Covariance Matrix",
    "abstract": "Inertia Estimation through Covariance Matrix",
    "descriptor": "",
    "authors": [
      "Federico Bizzarri",
      "Davide del Giudice",
      "Samuele Grillo",
      "Daniele Linaro",
      "Angelo Brambilla",
      "Federico Milano"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.13838"
  },
  {
    "id": "arXiv:2206.15139",
    "title": "Pump Up Password Security! Evaluating and Enhancing Risk-Based  Authentication on a Real-World Large-Scale Online Service",
    "abstract": "Comments: 35 pages, 18 figures, 7 tables. Data set awarded with Open Data Impact Award 2022 by the German Stifterverband",
    "descriptor": "\nComments: 35 pages, 18 figures, 7 tables. Data set awarded with Open Data Impact Award 2022 by the German Stifterverband\n",
    "authors": [
      "Stephan Wiefling",
      "Paul Ren\u00e9 J\u00f8rgensen",
      "Sigurd Thunem",
      "Luigi Lo Iacono"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.15139"
  },
  {
    "id": "arXiv:2206.15472",
    "title": "On-Device Training Under 256KB Memory",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Ji Lin",
      "Ligeng Zhu",
      "Wei-Ming Chen",
      "Wei-Chen Wang",
      "Chuang Gan",
      "Song Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.15472"
  },
  {
    "id": "arXiv:2207.02277",
    "title": "Hierarchies of Minion Tests for PCSPs through Tensors",
    "abstract": "Comments: Full version of a SODA 2023 paper. Generalises and subsumes all but Sections 6 and 7 of arXiv:2203.02478",
    "descriptor": "\nComments: Full version of a SODA 2023 paper. Generalises and subsumes all but Sections 6 and 7 of arXiv:2203.02478\n",
    "authors": [
      "Lorenzo Ciardo",
      "Stanislav \u017divn\u00fd"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2207.02277"
  },
  {
    "id": "arXiv:2207.04806",
    "title": "Repairing Neural Networks by Leaving the Right Past Behind",
    "abstract": "Comments: 24 pages, 12 figures",
    "descriptor": "\nComments: 24 pages, 12 figures\n",
    "authors": [
      "Ryutaro Tanno",
      "Melanie F. Pradier",
      "Aditya Nori",
      "Yingzhen Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04806"
  },
  {
    "id": "arXiv:2207.05224",
    "title": "Cluster-Based Control of Transition-Independent MDPs",
    "abstract": "Comments: 25 pages, 3 figures",
    "descriptor": "\nComments: 25 pages, 3 figures\n",
    "authors": [
      "Carmel Fiscko",
      "Soummya Kar",
      "Bruno Sinopoli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2207.05224"
  },
  {
    "id": "arXiv:2207.07438",
    "title": "Dynamic Matching with Better-than-2 Approximation in Polylogarithmic  Update Time",
    "abstract": "Comments: Full version of SODA 2023 paper",
    "descriptor": "\nComments: Full version of SODA 2023 paper\n",
    "authors": [
      "Sayan Bhattacharya",
      "Peter Kiss",
      "Thatchaphol Saranurak",
      "David Wajc"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.07438"
  },
  {
    "id": "arXiv:2207.08268",
    "title": "Online Lewis Weight Sampling",
    "abstract": "Comments: To appear in SODA 2023",
    "descriptor": "\nComments: To appear in SODA 2023\n",
    "authors": [
      "David P. Woodruff",
      "Taisuke Yasuda"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.08268"
  },
  {
    "id": "arXiv:2207.08307",
    "title": "An Efficient Randomized Fixed-Precision Algorithm for Tensor Singular  Value Decomposition",
    "abstract": "An Efficient Randomized Fixed-Precision Algorithm for Tensor Singular  Value Decomposition",
    "descriptor": "",
    "authors": [
      "Salman Ahmadi-Asl"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.08307"
  },
  {
    "id": "arXiv:2207.08783",
    "title": "Almost Tight Bounds for Online Facility Location in the Random-Order  Model",
    "abstract": "Comments: To appear in SODA 2023",
    "descriptor": "\nComments: To appear in SODA 2023\n",
    "authors": [
      "Haim Kaplan",
      "David Naori",
      "Danny Raz"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.08783"
  },
  {
    "id": "arXiv:2207.10635",
    "title": "Widespread Underestimation of Sensitivity in Differentially Private  Libraries and How to Fix It",
    "abstract": "Comments: Full version of the paper presented at ACM CCS 2022 and TPDP 2022",
    "descriptor": "\nComments: Full version of the paper presented at ACM CCS 2022 and TPDP 2022\n",
    "authors": [
      "S\u00edlvia Casacuberta",
      "Michael Shoemate",
      "Salil Vadhan",
      "Connor Wagaman"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2207.10635"
  },
  {
    "id": "arXiv:2207.11876",
    "title": "nLMVS-Net: Deep Non-Lambertian Multi-View Stereo",
    "abstract": "Comments: Accepted to WACV 2023",
    "descriptor": "\nComments: Accepted to WACV 2023\n",
    "authors": [
      "Kohei Yamashita",
      "Yuto Enyo",
      "Shohei Nobuhara",
      "Ko Nishino"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11876"
  },
  {
    "id": "arXiv:2207.12080",
    "title": "Intention-Conditioned Long-Term Human Egocentric Action Forecasting @  EGO4D Challenge 2022",
    "abstract": "Comments: Validation report for CVPR@2022 and ECCV@2022 EGO4D LTA Challenge",
    "descriptor": "\nComments: Validation report for CVPR@2022 and ECCV@2022 EGO4D LTA Challenge\n",
    "authors": [
      "Esteve Valls Mascaro",
      "Hyemin Ahn",
      "Dongheui Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.12080"
  },
  {
    "id": "arXiv:2207.12710",
    "title": "Active Learning of Ordinal Embeddings: A User Study on Football Data",
    "abstract": "Comments: 23 pages, 17 figures",
    "descriptor": "\nComments: 23 pages, 17 figures\n",
    "authors": [
      "Christoffer Loeffler",
      "Kion Fallah",
      "Stefano Fenu",
      "Dario Zanca",
      "Bjoern Eskofier",
      "Christopher John Rozell",
      "Christopher Mutschler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.12710"
  },
  {
    "id": "arXiv:2207.13645",
    "title": "Do Quantum Circuit Born Machines Generalize?",
    "abstract": "Do Quantum Circuit Born Machines Generalize?",
    "descriptor": "",
    "authors": [
      "Kaitlin Gili",
      "Mohamed Hibat-Allah",
      "Marta Mauri",
      "Chris Ballance",
      "Alejandro Perdomo-Ortiz"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.13645"
  },
  {
    "id": "arXiv:2208.01440",
    "title": "Viskositas: Viscosity Prediction of Multicomponent Chemical Systems",
    "abstract": "Comments: 16 pages, 7 figures, 5 tables, 1 appendix",
    "descriptor": "\nComments: 16 pages, 7 figures, 5 tables, 1 appendix\n",
    "authors": [
      "Patrick dos Anjos"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.01440"
  },
  {
    "id": "arXiv:2208.03115",
    "title": "Multi-fidelity surrogate modeling using long short-term memory networks",
    "abstract": "Multi-fidelity surrogate modeling using long short-term memory networks",
    "descriptor": "",
    "authors": [
      "Paolo Conti",
      "Mengwu Guo",
      "Andrea Manzoni",
      "Jan S. Hesthaven"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.03115"
  },
  {
    "id": "arXiv:2208.03837",
    "title": "Automatic Security Assessment of GitHub Actions Workflows",
    "abstract": "Automatic Security Assessment of GitHub Actions Workflows",
    "descriptor": "",
    "authors": [
      "Giacomo Benedetti",
      "Luca Verderame",
      "Alessio Merlo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.03837"
  },
  {
    "id": "arXiv:2208.06885",
    "title": "Global Priors Guided Modulation Network for Joint Super-Resolution and  Inverse Tone-Mapping",
    "abstract": "Comments: 10 pages, 7 figures",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Gang He",
      "Shaoyi Long",
      "Li Xu",
      "Chang Wu",
      "Jinjia Zhou",
      "Ming Sun",
      "Xing Wen",
      "Yurong Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2208.06885"
  },
  {
    "id": "arXiv:2208.07216",
    "title": "Class-attention Video Transformer for Engagement Intensity Prediction",
    "abstract": "Comments: 5 figures",
    "descriptor": "\nComments: 5 figures\n",
    "authors": [
      "Xusheng Ai",
      "Victor S. Sheng",
      "Chunhua Li",
      "Zhiming Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.07216"
  },
  {
    "id": "arXiv:2208.07339",
    "title": "LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale",
    "abstract": "Comments: Published at NeurIPS 2022. Camera-ready version",
    "descriptor": "\nComments: Published at NeurIPS 2022. Camera-ready version\n",
    "authors": [
      "Tim Dettmers",
      "Mike Lewis",
      "Younes Belkada",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.07339"
  },
  {
    "id": "arXiv:2208.08056",
    "title": "Sampling Through the Lens of Sequential Decision Making",
    "abstract": "Sampling Through the Lens of Sequential Decision Making",
    "descriptor": "",
    "authors": [
      "Jason Xiaotian Dou",
      "Alvin Qingkai Pan",
      "Runxue Bao",
      "Haiyi Harry Mao",
      "Lei Luo",
      "Zhihong Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2208.08056"
  },
  {
    "id": "arXiv:2208.09099",
    "title": "Scalable Multi-Agent Lab Framework for Lab Optimization",
    "abstract": "Scalable Multi-Agent Lab Framework for Lab Optimization",
    "descriptor": "",
    "authors": [
      "A. Gilad Kusne",
      "Austin McDannald"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.09099"
  },
  {
    "id": "arXiv:2208.09642",
    "title": "Exploring Price Accuracy on Uniswap V3 in Times of Distress",
    "abstract": "Exploring Price Accuracy on Uniswap V3 in Times of Distress",
    "descriptor": "",
    "authors": [
      "Lioba Heimbach",
      "Eric Schertenleib",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Pricing of Securities (q-fin.PR)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2208.09642"
  },
  {
    "id": "arXiv:2208.09992",
    "title": "Efficient construction of canonical polyadic approximations of tensor  networks",
    "abstract": "Comments: 25 pages, 5 figures",
    "descriptor": "\nComments: 25 pages, 5 figures\n",
    "authors": [
      "Karl Pierce",
      "Edward F Valeev"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2208.09992"
  },
  {
    "id": "arXiv:2208.10973",
    "title": "Robust DNN Watermarking via Fixed Embedding Weights with Optimized  Distribution",
    "abstract": "Comments: 13 pages, 4 figures",
    "descriptor": "\nComments: 13 pages, 4 figures\n",
    "authors": [
      "Benedetta Tondi",
      "Andrea Costanzo",
      "Mauro Barni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.10973"
  },
  {
    "id": "arXiv:2208.11838",
    "title": "Learning Task Automata for Reinforcement Learning using Hidden Markov  Models",
    "abstract": "Comments: 14 pages, 7 figures",
    "descriptor": "\nComments: 14 pages, 7 figures\n",
    "authors": [
      "Alessandro Abate",
      "Yousif Almulla",
      "James Fox",
      "David Hyland",
      "Michael Wooldridge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.11838"
  },
  {
    "id": "arXiv:2208.12256",
    "title": "Masked Autoencoders Enable Efficient Knowledge Distillers",
    "abstract": "Masked Autoencoders Enable Efficient Knowledge Distillers",
    "descriptor": "",
    "authors": [
      "Yutong Bai",
      "Zeyu Wang",
      "Junfei Xiao",
      "Chen Wei",
      "Huiyu Wang",
      "Alan Yuille",
      "Yuyin Zhou",
      "Cihang Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.12256"
  },
  {
    "id": "arXiv:2208.14649",
    "title": "Injecting Image Details into CLIP's Feature Space",
    "abstract": "Injecting Image Details into CLIP's Feature Space",
    "descriptor": "",
    "authors": [
      "Zilun Zhang",
      "Cuifeng Shen",
      "Yuan Shen",
      "Huixin Xiong",
      "Xinyu Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.14649"
  },
  {
    "id": "arXiv:2209.02943",
    "title": "Skeleton structure inherent in discrete-time quantum walks",
    "abstract": "Comments: 24 pages, 7 figures",
    "descriptor": "\nComments: 24 pages, 7 figures\n",
    "authors": [
      "Tomoki Yamagami",
      "Etsuo Segawa",
      "Ken'ichiro Tanaka",
      "Takatomo Mihana",
      "Andr\u00e9 R\u00f6hm",
      "Ryoichi Horisaki",
      "Makoto Naruse"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Emerging Technologies (cs.ET)",
      "Probability (math.PR)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2209.02943"
  },
  {
    "id": "arXiv:2209.03561",
    "title": "Video Vision Transformers for Violence Detection",
    "abstract": "Video Vision Transformers for Violence Detection",
    "descriptor": "",
    "authors": [
      "Sanskar Singh",
      "Shivaibhav Dewangan",
      "Ghanta Sai Krishna",
      "Vandit Tyagi",
      "Sainath Reddy",
      "Prathistith Raj Medi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.03561"
  },
  {
    "id": "arXiv:2209.03825",
    "title": "Eigenvalue Mapping-based Semi-implicit Discretization of the Generalized  Super-Twisting Algorithm",
    "abstract": "Eigenvalue Mapping-based Semi-implicit Discretization of the Generalized  Super-Twisting Algorithm",
    "descriptor": "",
    "authors": [
      "Ningning Ding"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.03825"
  },
  {
    "id": "arXiv:2209.04954",
    "title": "Reinforcement Recommendation Reasoning through Knowledge Graphs for  Explanation Path Quality",
    "abstract": "Comments: Accepted for publication in Knowledge-Based Systems (Elsevier)",
    "descriptor": "\nComments: Accepted for publication in Knowledge-Based Systems (Elsevier)\n",
    "authors": [
      "Giacomo Balloccu",
      "Ludovico Boratto",
      "Gianni Fenu",
      "Mirko Marras"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2209.04954"
  },
  {
    "id": "arXiv:2209.05212",
    "title": "Structured Recognition for Generative Models with Explaining Away",
    "abstract": "Structured Recognition for Generative Models with Explaining Away",
    "descriptor": "",
    "authors": [
      "Changmin Yu",
      "Hugo Soulat",
      "Neil Burgess",
      "Maneesh Sahani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2209.05212"
  },
  {
    "id": "arXiv:2209.06865",
    "title": "Sketch of a novel approach to a neural model",
    "abstract": "Sketch of a novel approach to a neural model",
    "descriptor": "",
    "authors": [
      "Gabriele Scheler"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Molecular Networks (q-bio.MN)"
    ],
    "url": "https://arxiv.org/abs/2209.06865"
  },
  {
    "id": "arXiv:2209.08842",
    "title": "Rewarding Episodic Visitation Discrepancy for Exploration in  Reinforcement Learning",
    "abstract": "Comments: 16 pages, 9 figures; Deep RL Workshop NeurIPS 2022",
    "descriptor": "\nComments: 16 pages, 9 figures; Deep RL Workshop NeurIPS 2022\n",
    "authors": [
      "Mingqi Yuan",
      "Bo Li",
      "Xin Jin",
      "Wenjun Zeng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.08842"
  },
  {
    "id": "arXiv:2209.12266",
    "title": "Enforcing safety for vision-based controllers via Control Barrier  Functions and Neural Radiance Fields",
    "abstract": "Enforcing safety for vision-based controllers via Control Barrier  Functions and Neural Radiance Fields",
    "descriptor": "",
    "authors": [
      "Mukun Tong",
      "Charles Dawson",
      "Chuchu Fan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.12266"
  },
  {
    "id": "arXiv:2209.12819",
    "title": "Maker-Breaker is solved in polynomial time on hypergraphs of rank 3",
    "abstract": "Comments: The present updated version of this deposit provides a counterexample to a similar result which was incorrectly claimed recently (arXiv:2209.11202)",
    "descriptor": "\nComments: The present updated version of this deposit provides a counterexample to a similar result which was incorrectly claimed recently (arXiv:2209.11202)\n",
    "authors": [
      "Florian Galliot",
      "Sylvain Gravier",
      "Isabelle Sivignon"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2209.12819"
  },
  {
    "id": "arXiv:2209.14703",
    "title": "Fully Lattice Linear Algorithms",
    "abstract": "Fully Lattice Linear Algorithms",
    "descriptor": "",
    "authors": [
      "Arya Tanmay Gupta",
      "Sandeep S Kulkarni"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2209.14703"
  },
  {
    "id": "arXiv:2209.15001",
    "title": "Dilated Neighborhood Attention Transformer",
    "abstract": "Comments: We open-source our project at: this https URL",
    "descriptor": "\nComments: We open-source our project at: this https URL\n",
    "authors": [
      "Ali Hassani",
      "Humphrey Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.15001"
  },
  {
    "id": "arXiv:2210.02428",
    "title": "Gradual C0: Symbolic Execution for Efficient Gradual Verification",
    "abstract": "Comments: 24 pages without appendix supplement, preprint",
    "descriptor": "\nComments: 24 pages without appendix supplement, preprint\n",
    "authors": [
      "Jenna DiVincenzo",
      "Ian McCormack",
      "Hemant Gouni",
      "Jacob Gorenburg",
      "Mona Zhang",
      "Conrad Zimmerman",
      "Joshua Sunshine",
      "\u00c9ric Tanter",
      "Jonathan Aldrich"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.02428"
  },
  {
    "id": "arXiv:2210.03568",
    "title": "How Large Language Models are Transforming Machine-Paraphrased  Plagiarism",
    "abstract": "How Large Language Models are Transforming Machine-Paraphrased  Plagiarism",
    "descriptor": "",
    "authors": [
      "Jan Philip Wahle",
      "Terry Ruas",
      "Frederic Kirstein",
      "Bela Gipp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03568"
  },
  {
    "id": "arXiv:2210.04284",
    "title": "SparseAdapter: An Easy Approach for Improving the Parameter-Efficiency  of Adapters",
    "abstract": "Comments: Findings of EMNLP 2022",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Shwai He",
      "Liang Ding",
      "Daize Dong",
      "Miao Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04284"
  },
  {
    "id": "arXiv:2210.04296",
    "title": "Regularizing Score-based Models with Score Fokker-Planck Equations",
    "abstract": "Regularizing Score-based Models with Score Fokker-Planck Equations",
    "descriptor": "",
    "authors": [
      "Chieh-Hsin Lai",
      "Yuhta Takida",
      "Naoki Murata",
      "Toshimitsu Uesaka",
      "Yuki Mitsufuji",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04296"
  },
  {
    "id": "arXiv:2210.04365",
    "title": "ELIGN: Expectation Alignment as a Multi-Agent Intrinsic Reward",
    "abstract": "Comments: This paper will be published in Neurips 2022",
    "descriptor": "\nComments: This paper will be published in Neurips 2022\n",
    "authors": [
      "Zixian Ma",
      "Rose Wang",
      "Li Fei-Fei",
      "Michael Bernstein",
      "Ranjay Krishna"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04365"
  },
  {
    "id": "arXiv:2210.04610",
    "title": "Red-Teaming the Stable Diffusion Safety Filter",
    "abstract": "Comments: ML Safety Workshop NeurIPS 2022",
    "descriptor": "\nComments: ML Safety Workshop NeurIPS 2022\n",
    "authors": [
      "Javier Rando",
      "Daniel Paleka",
      "David Lindner",
      "Lennart Heim",
      "Florian Tram\u00e8r"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04610"
  },
  {
    "id": "arXiv:2210.04815",
    "title": "Truncated proposals for scalable and hassle-free simulation-based  inference",
    "abstract": "Truncated proposals for scalable and hassle-free simulation-based  inference",
    "descriptor": "",
    "authors": [
      "Michael Deistler",
      "Pedro J Goncalves",
      "Jakob H Macke"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04815"
  },
  {
    "id": "arXiv:2210.05152",
    "title": "TriangleNet: Edge Prior Augmented Network for Semantic Segmentation  through Cross-Task Consistency",
    "abstract": "TriangleNet: Edge Prior Augmented Network for Semantic Segmentation  through Cross-Task Consistency",
    "descriptor": "",
    "authors": [
      "Dan Zhang",
      "Rui Zheng",
      "Luosang Gadeng",
      "Pei Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.05152"
  },
  {
    "id": "arXiv:2210.07339",
    "title": "Nash Equilibria for Exchangeable Team against Team Games, their Mean  Field Limit, and Role of Common Randomness",
    "abstract": "Nash Equilibria for Exchangeable Team against Team Games, their Mean  Field Limit, and Role of Common Randomness",
    "descriptor": "",
    "authors": [
      "Sina Sanjari",
      "Naci Saldi",
      "Serdar Y\u00fcksel"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.07339"
  },
  {
    "id": "arXiv:2210.08127",
    "title": "Reflections on trusting distributed trust",
    "abstract": "Comments: 8 pages, 3 figures",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Emma Dauterman",
      "Vivian Fang",
      "Natacha Crooks",
      "Raluca Ada Popa"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.08127"
  },
  {
    "id": "arXiv:2210.08635",
    "title": "Tracing Semantic Variation in Slang",
    "abstract": "Comments: Accepted to EMNLP 2022 main conference",
    "descriptor": "\nComments: Accepted to EMNLP 2022 main conference\n",
    "authors": [
      "Zhewei Sun",
      "Yang Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08635"
  },
  {
    "id": "arXiv:2210.09571",
    "title": "On Relations Between Tight Bounds for Symmetric $f$-Divergences and  Binary Divergences",
    "abstract": "Comments: 7 pages",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Tomohiro Nishiyama"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2210.09571"
  },
  {
    "id": "arXiv:2210.09914",
    "title": "Computing MEMs on Repetitive Text Collections",
    "abstract": "Computing MEMs on Repetitive Text Collections",
    "descriptor": "",
    "authors": [
      "Gonzalo Navarro"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.09914"
  },
  {
    "id": "arXiv:2210.10585",
    "title": "The Minimum Wage as an Anchor: Effects on Determinations of Fairness by  Humans and AI",
    "abstract": "The Minimum Wage as an Anchor: Effects on Determinations of Fairness by  Humans and AI",
    "descriptor": "",
    "authors": [
      "Dario G. Soatto"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2210.10585"
  },
  {
    "id": "arXiv:2210.11612",
    "title": "Searching for a higher power in the human evaluation of MT",
    "abstract": "Comments: WMT 2022",
    "descriptor": "\nComments: WMT 2022\n",
    "authors": [
      "Johnny Tian-Zheng Wei",
      "Tom Kocmi",
      "Christian Federmann"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11612"
  },
  {
    "id": "arXiv:2210.12417",
    "title": "SLAMs: Semantic Learning based Activation Map for Weakly Supervised  Semantic Segmentation",
    "abstract": "SLAMs: Semantic Learning based Activation Map for Weakly Supervised  Semantic Segmentation",
    "descriptor": "",
    "authors": [
      "Junliang Chen",
      "Xiaodong Zhao",
      "Minmin Liu",
      "Linlin Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.12417"
  },
  {
    "id": "arXiv:2210.12551",
    "title": "The Schwarz alternating method for the seamless coupling of nonlinear  reduced order models and full order models",
    "abstract": "The Schwarz alternating method for the seamless coupling of nonlinear  reduced order models and full order models",
    "descriptor": "",
    "authors": [
      "Joshua Barnett",
      "Irina Tezaur",
      "Alejandro Mota"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.12551"
  },
  {
    "id": "arXiv:2210.13012",
    "title": "CMU-Net: A Strong ConvMixer-based Medical Ultrasound Image Segmentation  Network",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Fenghe Tang",
      "Lingtao Wang",
      "Chunping Ning",
      "Min Xian",
      "Jianrui Ding"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.13012"
  },
  {
    "id": "arXiv:2210.13905",
    "title": "Confidence-Calibrated Face and Kinship Verification",
    "abstract": "Comments: 11 pages, 7 figures, and 8 tables",
    "descriptor": "\nComments: 11 pages, 7 figures, and 8 tables\n",
    "authors": [
      "Min Xu",
      "Ximiao Zhang",
      "Xiuzhuang Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.13905"
  },
  {
    "id": "arXiv:2210.13952",
    "title": "KnowGL: Knowledge Generation and Linking from Text",
    "abstract": "Comments: AAAI-23 Demo Track",
    "descriptor": "\nComments: AAAI-23 Demo Track\n",
    "authors": [
      "Gaetano Rossiello",
      "Faisal Chowdhury",
      "Nandana Mihindukulasooriya",
      "Owen Cornec",
      "Alfio Gliozzo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.13952"
  },
  {
    "id": "arXiv:2210.13979",
    "title": "Meta-learning Pathologies from Radiology Reports using Variance Aware  Prototypical Networks",
    "abstract": "Comments: EMNLP'22 Industry Track. Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 16 pages",
    "descriptor": "\nComments: EMNLP'22 Industry Track. Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 16 pages\n",
    "authors": [
      "Arijit Sehanobish",
      "Kawshik Kannan",
      "Nabila Abraham",
      "Anasuya Das",
      "Benjamin Odry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.13979"
  },
  {
    "id": "arXiv:2210.14891",
    "title": "Broken Neural Scaling Laws",
    "abstract": "Broken Neural Scaling Laws",
    "descriptor": "",
    "authors": [
      "Ethan Caballero",
      "Kshitij Gupta",
      "Irina Rish",
      "David Krueger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.14891"
  },
  {
    "id": "arXiv:2210.15011",
    "title": "Using Deception in Markov Game to Understand Adversarial Behaviors  through a Capture-The-Flag Environment",
    "abstract": "Comments: Accepted at GameSec 2022",
    "descriptor": "\nComments: Accepted at GameSec 2022\n",
    "authors": [
      "Siddhant Bhambri",
      "Purv Chauhan",
      "Frederico Araujo",
      "Adam Doup\u00e9",
      "Subbarao Kambhampati"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.15011"
  },
  {
    "id": "arXiv:2210.15956",
    "title": "Generalized Laplacian Positional Encoding for Graph Representation  Learning",
    "abstract": "Comments: Accepted at NeurIPS Workshop on Symmetry and Geometry in Neural Representations: Extended Abstract Track 2022",
    "descriptor": "\nComments: Accepted at NeurIPS Workshop on Symmetry and Geometry in Neural Representations: Extended Abstract Track 2022\n",
    "authors": [
      "Sohir Maskey",
      "Ali Parviz",
      "Maximilian Thiessen",
      "Hannes St\u00e4rk",
      "Ylli Sadikaj",
      "Haggai Maron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15956"
  },
  {
    "id": "arXiv:2210.16835",
    "title": "Robust Data Valuation via Variance Reduced Data Shapley",
    "abstract": "Robust Data Valuation via Variance Reduced Data Shapley",
    "descriptor": "",
    "authors": [
      "Mengmeng Wu",
      "Ruoxi Jia",
      "Changle Lin",
      "Wei Huang",
      "Xiangyu Chang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16835"
  },
  {
    "id": "arXiv:2210.17482",
    "title": "Low Complexity Detect and Avoid for Autonomous Agents in Cluttered  Environments",
    "abstract": "Low Complexity Detect and Avoid for Autonomous Agents in Cluttered  Environments",
    "descriptor": "",
    "authors": [
      "Mosab Diab",
      "Mostafa Mohammadkarimi",
      "Raj Thilak Rajan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.17482"
  },
  {
    "id": "arXiv:2211.00107",
    "title": "Where to start? Analyzing the potential value of intermediate models",
    "abstract": "Comments: this https URL",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Leshem Choshen",
      "Elad Venezian",
      "Shachar Don-Yehia",
      "Noam Slonim",
      "Yoav Katz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00107"
  },
  {
    "id": "arXiv:2211.00577",
    "title": "Fine-tuned Generative Adversarial Network-based Model for Medical Images  Super-Resolution",
    "abstract": "Fine-tuned Generative Adversarial Network-based Model for Medical Images  Super-Resolution",
    "descriptor": "",
    "authors": [
      "Alireza Aghelan",
      "Modjtaba Rouhani"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00577"
  },
  {
    "id": "arXiv:2211.00838",
    "title": "Distributed Work Stealing in a Task-Based Dataflow Runtime",
    "abstract": "Distributed Work Stealing in a Task-Based Dataflow Runtime",
    "descriptor": "",
    "authors": [
      "Joseph John",
      "Josh Milthorpe",
      "Peter Strazdins"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.00838"
  },
  {
    "id": "arXiv:2211.00974",
    "title": "Processing Long Legal Documents with Pre-trained Transformers: Modding  LegalBERT and Longformer",
    "abstract": "Comments: 9 pages, long paper at NLLP Workshop 2022 proceedings",
    "descriptor": "\nComments: 9 pages, long paper at NLLP Workshop 2022 proceedings\n",
    "authors": [
      "Dimitris Mamakas",
      "Petros Tsotsi",
      "Ion Androutsopoulos",
      "Ilias Chalkidis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.00974"
  },
  {
    "id": "arXiv:2211.01297",
    "title": "C3SASR: Cheap Causal Convolutions for Self-Attentive Sequential  Recommendation",
    "abstract": "C3SASR: Cheap Causal Convolutions for Self-Attentive Sequential  Recommendation",
    "descriptor": "",
    "authors": [
      "Jiayi Chen",
      "Wen Wu",
      "Liye Shi",
      "Yu Ji",
      "Wenxin Hu",
      "Xi Chen",
      "Wei Zheng",
      "Liang He"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.01297"
  },
  {
    "id": "arXiv:2211.01482",
    "title": "RQUGE: Reference-Free Metric for Evaluating Question Generation by  Answering the Question",
    "abstract": "Comments: 19 pages, 8 figures",
    "descriptor": "\nComments: 19 pages, 8 figures\n",
    "authors": [
      "Alireza Mohammadshahi",
      "Thomas Scialom",
      "Majid Yazdani",
      "Pouya Yanki",
      "Angela Fan",
      "James Henderson",
      "Marzieh Saeidi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01482"
  },
  {
    "id": "arXiv:2211.01487",
    "title": "Multi-vehicle Conflict Resolution in Highly Constrained Spaces by  Merging Optimal Control and Reinforcement Learning",
    "abstract": "Multi-vehicle Conflict Resolution in Highly Constrained Spaces by  Merging Optimal Control and Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Xu Shen",
      "Francesco Borrelli"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.01487"
  },
  {
    "id": "arXiv:2211.01991",
    "title": "Leveraging Fully Observable Policies for Learning under Partial  Observability",
    "abstract": "Comments: Accepted at the 2022 Conference on Robot Learning (CoRL), Auckland, New Zealand",
    "descriptor": "\nComments: Accepted at the 2022 Conference on Robot Learning (CoRL), Auckland, New Zealand\n",
    "authors": [
      "Hai Nguyen",
      "Andrea Baisero",
      "Dian Wang",
      "Christopher Amato",
      "Robert Platt"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01991"
  },
  {
    "id": "arXiv:2211.02369",
    "title": "A Jigsaw Puzzle Solver-based Attack on Block-wise Image Encryption for  Privacy-preserving DNNs",
    "abstract": "Comments: To be appeared in IWAIT2023",
    "descriptor": "\nComments: To be appeared in IWAIT2023\n",
    "authors": [
      "Tatsuya Chuman",
      "Hitoshi Kiya"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.02369"
  },
  {
    "id": "arXiv:2211.02486",
    "title": "Decorrelation with conditional normalizing flows",
    "abstract": "Decorrelation with conditional normalizing flows",
    "descriptor": "",
    "authors": [
      "Samuel Klein",
      "Tobias Golling"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02486"
  },
  {
    "id": "arXiv:2211.02516",
    "title": "Singlularity Avoidance with Application to Online Trajectory  Optimization for Serial Manipulators",
    "abstract": "Comments: 8 pages, 2 figures",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "Florian Beck",
      "Minh Nhat Vu",
      "Christian Hartl-Nesic",
      "Andreas Kugi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.02516"
  },
  {
    "id": "arXiv:2211.02740",
    "title": "Bridging HPC Communities through the Julia Programming Language",
    "abstract": "Comments: 20 pages; improved image quality",
    "descriptor": "\nComments: 20 pages; improved image quality\n",
    "authors": [
      "Valentin Churavy",
      "William F Godoy",
      "Carsten Bauer",
      "Hendrik Ranocha",
      "Michael Schlottke-Lakemper",
      "Ludovic R\u00e4ss",
      "Johannes Blaschke",
      "Mos\u00e8 Giordano",
      "Erik Schnetter",
      "Samuel Omlin",
      "Jeffrey S. Vetter",
      "Alan Edelman"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.02740"
  },
  {
    "id": "arXiv:2211.03157",
    "title": "Examining the Differential Risk from High-level Artificial Intelligence  and the Question of Control",
    "abstract": "Comments: 62 pages",
    "descriptor": "\nComments: 62 pages\n",
    "authors": [
      "Kyle A. Kilian",
      "Christopher J. Ventura",
      "Mark M. Bailey"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.03157"
  },
  {
    "id": "arXiv:2211.03231",
    "title": "Graph Neural Networks for Community Detection on Sparse Graphs",
    "abstract": "Comments: Submitted to ICASSP 2023",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Luana Ruiz",
      "Ningyuan Huang",
      "Soledad Villar"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.03231"
  },
  {
    "id": "arXiv:2211.03553",
    "title": "Learning Causal Representations of Single Cells via Sparse Mechanism  Shift Modeling",
    "abstract": "Learning Causal Representations of Single Cells via Sparse Mechanism  Shift Modeling",
    "descriptor": "",
    "authors": [
      "Romain Lopez",
      "Nata\u0161a Tagasovska",
      "Stephen Ra",
      "Kyunghyn Cho",
      "Jonathan K. Pritchard",
      "Aviv Regev"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.03553"
  },
  {
    "id": "arXiv:2211.03685",
    "title": "On a Network Centrality Maximization Game",
    "abstract": "Comments: 40 pages, 21 figures",
    "descriptor": "\nComments: 40 pages, 21 figures\n",
    "authors": [
      "Costanza Catalano",
      "Maria Castaldo",
      "Giacomo Como",
      "Fabio Fagnani"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.03685"
  },
  {
    "id": "arXiv:2211.03928",
    "title": "Editable Indoor Lighting Estimation",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Henrique Weber",
      "Mathieu Garon",
      "Jean-Fran\u00e7ois Lalonde"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.03928"
  },
  {
    "id": "arXiv:2211.03995",
    "title": "Computing palindromes on a trie in linear time",
    "abstract": "Comments: accepted to ISAAC 2022",
    "descriptor": "\nComments: accepted to ISAAC 2022\n",
    "authors": [
      "Takuya Mieno",
      "Mitsuru Funakoshi",
      "Shunsuke Inenaga"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.03995"
  },
  {
    "id": "arXiv:2211.04071",
    "title": "Improving performance of real-time full-band blind packet-loss  concealment with predictive network",
    "abstract": "Comments: Submitted to ICASSP 2023, 5 pages, 1 figure, 4 tables",
    "descriptor": "\nComments: Submitted to ICASSP 2023, 5 pages, 1 figure, 4 tables\n",
    "authors": [
      "Viet-Anh Nguyen",
      "Anh H. T. Nguyen",
      "Andy W. H. Khong"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.04071"
  },
  {
    "id": "arXiv:2211.04152",
    "title": "Federated Learning Using Three-Operator ADMM",
    "abstract": "Comments: accepted to IEEE Journal of Selected Topics in Signal Processing, 2022",
    "descriptor": "\nComments: accepted to IEEE Journal of Selected Topics in Signal Processing, 2022\n",
    "authors": [
      "Shashi Kant",
      "Jos\u00e9 Mairton B. da Silva Jr.",
      "Gabor Fodor",
      "Bo G\u00f6ransson",
      "Mats Bengtsson",
      "Carlo Fischione"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.04152"
  },
  {
    "id": "arXiv:2211.04391",
    "title": "EVs and ERCOT: Future Adoption Scenarios and Grid Implications",
    "abstract": "Comments: 5 pages, 2 figures, 3 tables, Submitted to IEEE for Power & Energy Society 2023 General Meeting",
    "descriptor": "\nComments: 5 pages, 2 figures, 3 tables, Submitted to IEEE for Power & Energy Society 2023 General Meeting\n",
    "authors": [
      "Kelsey Nelson",
      "Pedro Moura",
      "Javad Mohammadi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.04391"
  },
  {
    "id": "arXiv:2211.04392",
    "title": "Reduced Order Probabilistic Emulation for Physics-Based Thermosphere  Models",
    "abstract": "Reduced Order Probabilistic Emulation for Physics-Based Thermosphere  Models",
    "descriptor": "",
    "authors": [
      "Richard J. Licata",
      "Piyush M. Mehta"
    ],
    "subjectives": [
      "Space Physics (physics.space-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04392"
  },
  {
    "id": "arXiv:2211.04656",
    "title": "MEVID: Multi-view Extended Videos with Identities for Video Person  Re-Identification",
    "abstract": "Comments: This paper was accepted to WACV 2023",
    "descriptor": "\nComments: This paper was accepted to WACV 2023\n",
    "authors": [
      "Daniel Davila",
      "Dawei Du",
      "Bryon Lewis",
      "Christopher Funk",
      "Joseph Van Pelt",
      "Roderick Collins",
      "Kellie Corona",
      "Matt Brown",
      "Scott McCloskey",
      "Anthony Hoogs",
      "Brian Clipp"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04656"
  },
  {
    "id": "arXiv:2211.04693",
    "title": "Deep Explainable Learning with Graph Based Data Assessing and Rule  Reasoning",
    "abstract": "Deep Explainable Learning with Graph Based Data Assessing and Rule  Reasoning",
    "descriptor": "",
    "authors": [
      "Yuanlong Li",
      "Gaopan Huang",
      "Min Zhou",
      "Chuan Fu",
      "Honglin Qiao",
      "Yan He"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04693"
  },
  {
    "id": "arXiv:2211.04755",
    "title": "Towards Global Crop Maps with Transfer Learning",
    "abstract": "Comments: Accepted for publication at Tackling Climate Change with Machine Learning: workshop at NeurIPS 2022",
    "descriptor": "\nComments: Accepted for publication at Tackling Climate Change with Machine Learning: workshop at NeurIPS 2022\n",
    "authors": [
      "Hyun-Woo Jo",
      "Alkiviadis Koukos",
      "Vasileios Sitokonstantinou",
      "Woo-Kyun Lee",
      "Charalampos Kontoes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04755"
  },
  {
    "id": "arXiv:2211.04774",
    "title": "ARNet: Automatic Refinement Network for Noisy Partial Label Learning",
    "abstract": "ARNet: Automatic Refinement Network for Noisy Partial Label Learning",
    "descriptor": "",
    "authors": [
      "Zheng Lian",
      "Mingyu Xu",
      "Lan Chen",
      "Licai Sun",
      "Bin Liu",
      "Jianhua Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04774"
  },
  {
    "id": "arXiv:2211.04971",
    "title": "Understanding Cross-modal Interactions in V&L Models that Generate Scene  Descriptions",
    "abstract": "Understanding Cross-modal Interactions in V&L Models that Generate Scene  Descriptions",
    "descriptor": "",
    "authors": [
      "Michele Cafagna",
      "Kees van Deemter",
      "Albert Gatt"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04971"
  },
  {
    "id": "arXiv:2211.05020",
    "title": "Duality for Neural Networks through Reproducing Kernel Banach Spaces",
    "abstract": "Duality for Neural Networks through Reproducing Kernel Banach Spaces",
    "descriptor": "",
    "authors": [
      "Len Spek",
      "Tjeerd Jan Heeringa",
      "Christoph Brune"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05020"
  },
  {
    "id": "arXiv:2211.05044",
    "title": "What is Wrong with Language Models that Can Not Tell a Story?",
    "abstract": "What is Wrong with Language Models that Can Not Tell a Story?",
    "descriptor": "",
    "authors": [
      "Ivan P. Yamshchikov",
      "Alexey Tikhonov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.05044"
  },
  {
    "id": "arXiv:2211.05053",
    "title": "On Minimizing Tardy Processing Time, Max-Min Skewed Convolution, and  Triangular Structured ILPs",
    "abstract": "Comments: SODA 2023",
    "descriptor": "\nComments: SODA 2023\n",
    "authors": [
      "Kim-Manuel Klein",
      "Adam Polak",
      "Lars Rohwedder"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.05053"
  }
]
[
  {
    "id": "arXiv:2211.08425",
    "title": "A Rigorous Study Of The Deep Taylor Decomposition",
    "abstract": "Saliency methods attempt to explain deep neural networks by highlighting the\nmost salient features of a sample. Some widely used methods are based on a\ntheoretical framework called Deep Taylor Decomposition (DTD), which formalizes\nthe recursive application of the Taylor Theorem to the network's layers.\nHowever, recent work has found these methods to be independent of the network's\ndeeper layers and appear to respond only to lower-level image structure. Here,\nwe investigate the DTD theory to better understand this perplexing behavior and\nfound that the Deep Taylor Decomposition is equivalent to the basic\ngradient$\\times$input method when the Taylor root points (an important\nparameter of the algorithm chosen by the user) are locally constant. If the\nroot points are locally input-dependent, then one can justify any explanation.\nIn this case, the theory is under-constrained. In an empirical evaluation, we\nfind that DTD roots do not lie in the same linear regions as the input -\ncontrary to a fundamental assumption of the Taylor theorem. The theoretical\nfoundations of DTD were cited as a source of reliability for the explanations.\nHowever, our findings urge caution in making such claims.",
    "descriptor": "\nComments: Published in Transactions on Machine Learning Research (TMLR)\n",
    "authors": [
      "Leon Sixt",
      "Tim Landgraf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.08425"
  },
  {
    "id": "arXiv:2211.08426",
    "title": "Automatic penalty and degree continuation for parallel pre-conditioned  mesh curving on virtual geometry",
    "abstract": "We present a distributed parallel mesh curving method for virtual geometry.\nThe main application is to generate large-scale curved meshes on complex\ngeometry suitable for analysis with unstructured high-order methods.\nAccordingly, we devise the technique to generate geometrically accurate meshes\ncomposed of high-quality elements. To this end, we advocate for degree\ncontinuation on a penalty-based second-order optimizer that uses global tight\ntolerances to converge the distortion residuals. To reduce the method memory\nfootprint, waiting time, and energy consumption, we combine three main\ningredients. First, we propose a matrix-free GMRES solver pre-conditioned with\nsuccessive over-relaxation by blocks to reduce the memory footprint three\ntimes. We also propose an adaptive penalty technique, to reduce the number of\nnon-linear iterations. Third, we propose an indicator of the required linear\nsolver tolerance to reduce the number of linear iterations. On thousands of\ncores, the method curves meshes composed of millions of quartic elements\nfeaturing highly stretched elements while matching a virtual topology.",
    "descriptor": "",
    "authors": [
      "Eloi Ruiz-Giron\u00e9s",
      "Xevi Roca"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.08426"
  },
  {
    "id": "arXiv:2211.08427",
    "title": "Conformal marked bisection for local refinement of $n$-dimensional  unstructured simplicial meshes",
    "abstract": "We present an $n$-dimensional marked bisection method for unstructured\nconformal meshes. We devise the method for local refinement in adaptive\n$n$-dimensional applications. To this end, we propose a mesh marking\npre-process and three marked bisection stages. The pre-process marks the\ninitial mesh conformingly. Then, in the first $n-1$ bisections, the method\naccumulates in reverse order a list of new vertices. In the second stage, the\n$n$-th bisection, the method uses the reversed list to cast the bisected\nsimplices as reflected simplices, a simplex type suitable for newest vertex\nbisection. In the final stage, beyond the $n$-th bisection, the method switches\nto newest vertex bisection. To allow this switch, after the second stage, we\ncheck that under uniform bisection the mesh simplices are conformal and\nreflected. These conditions are sufficient to use newest vertex bisection, a\nbisection scheme guaranteeing key advantages for local refinement. Finally, the\nresults show that the proposed bisection is well-suited for local refinement of\nunstructured conformal meshes.",
    "descriptor": "",
    "authors": [
      "Guillem Belda-Ferr\u00edn",
      "Eloi Ruiz-Giron\u00e9s",
      "Abel Gargallo-Peir\u00f3",
      "Xevi Roca"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.08427"
  },
  {
    "id": "arXiv:2211.08429",
    "title": "An Automatic ICD Coding Network Using Partition-Based Label Attention",
    "abstract": "International Classification of Diseases (ICD) is a global medical\nclassification system which provides unique codes for diagnoses and procedures\nappropriate to a patient's clinical record. However, manual coding by human\ncoders is expensive and error-prone. Automatic ICD coding has the potential to\nsolve this problem. With the advancement of deep learning technologies, many\ndeep learning-based methods for automatic ICD coding are being developed. In\nparticular, a label attention mechanism is effective for multi-label\nclassification, i.e., the ICD coding. It effectively obtains the label-specific\nrepresentations from the input clinical records. However, because the existing\nlabel attention mechanism finds key tokens in the entire text at once, the\nimportant information dispersed in each paragraph may be omitted from the\nattention map. To overcome this, we propose a novel neural network architecture\ncomposed of two parts of encoders and two kinds of label attention layers. The\ninput text is segmentally encoded in the former encoder and integrated by the\nfollower. Then, the conventional and partition-based label attention mechanisms\nextract important global and local feature representations. Our classifier\neffectively integrates them to enhance the ICD coding performance. We verified\nthe proposed method using the MIMIC-III, a benchmark dataset of the ICD coding.\nOur results show that our network improves the ICD coding performance based on\nthe partition-based mechanism.",
    "descriptor": "\nComments: 9 pages, 3 figures, 5 tables\n",
    "authors": [
      "Daeseong Kim",
      "Haanju Yoo",
      "Sewon Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.08429"
  },
  {
    "id": "arXiv:2211.08430",
    "title": "Power-law Scaling to Assist with Key Challenges in Artificial  Intelligence",
    "abstract": "Power-law scaling, a central concept in critical phenomena, is found to be\nuseful in deep learning, where optimized test errors on handwritten digit\nexamples converge as a power-law to zero with database size. For rapid decision\nmaking with one training epoch, each example is presented only once to the\ntrained network, the power-law exponent increased with the number of hidden\nlayers. For the largest dataset, the obtained test error was estimated to be in\nthe proximity of state-of-the-art algorithms for large epoch numbers. Power-law\nscaling assists with key challenges found in current artificial intelligence\napplications and facilitates an a priori dataset size estimation to achieve a\ndesired test accuracy. It establishes a benchmark for measuring training\ncomplexity and a quantitative hierarchy of machine learning tasks and\nalgorithms.",
    "descriptor": "\nComments: 30 pages, 5 figures\n",
    "authors": [
      "Yuval Meir",
      "Shira Sardi",
      "Shiri Hodassman",
      "Karin Kisos",
      "Itamar Ben-Noam",
      "Amir Goldental",
      "Ido Kanter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08430"
  },
  {
    "id": "arXiv:2211.08447",
    "title": "SexWEs: Domain-Aware Word Embeddings via Cross-lingual Semantic  Specialisation for Chinese Sexism Detection in Social Media",
    "abstract": "The goal of sexism detection is to mitigate negative online content targeting\ncertain gender groups of people. However, the limited availability of labeled\nsexism-related datasets makes it problematic to identify online sexism for\nlow-resource languages. In this paper, we address the task of automatic sexism\ndetection in social media for one low-resource language -- Chinese. Rather than\ncollecting new sexism data or building cross-lingual transfer learning models,\nwe develop a cross-lingual domain-aware semantic specialisation system in order\nto make the most of existing data. Semantic specialisation is a technique for\nretrofitting pre-trained distributional word vectors by integrating external\nlinguistic knowledge (such as lexico-semantic relations) into the specialised\nfeature space. To do this, we leverage semantic resources for sexism from a\nhigh-resource language (English) to specialise pre-trained word vectors in the\ntarget language (Chinese) to inject domain knowledge. We demonstrate the\nbenefit of our sexist word embeddings (SexWEs) specialised by our framework via\nintrinsic evaluation of word similarity and extrinsic evaluation of sexism\ndetection. Compared with other specialisation approaches and Chinese baseline\nword vectors, our SexWEs shows an average score improvement of 0.033 and 0.064\nin both intrinsic and extrinsic evaluations, respectively. The ablative results\nand visualisation of SexWEs also prove the effectiveness of our framework on\nretrofitting word vectors in low-resource languages. Our code and\nsexism-related word vectors will be publicly available.",
    "descriptor": "\nComments: accepted at ICWSM 2023\n",
    "authors": [
      "Aiqi Jiang",
      "Arkaitz Zubiaga"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.08447"
  },
  {
    "id": "arXiv:2211.08451",
    "title": "kogito: A Commonsense Knowledge Inference Toolkit",
    "abstract": "In this paper, we present kogito, an open-source tool for generating\ncommonsense inferences about situations described in text. kogito provides an\nintuitive and extensible interface to interact with natural language generation\nmodels that can be used for hypothesizing commonsense knowledge inference from\na textual input. In particular, kogito offers several features for targeted,\nmulti-granularity knowledge generation. These include a standardized API for\ntraining and evaluating knowledge models, and generating and filtering\ninferences from them. We also include helper functions for converting natural\nlanguage texts into a format ingestible by knowledge models - intermediate\npipeline stages such as knowledge head extraction from text, heuristic and\nmodel-based knowledge head-relation matching, and an ability to define and use\ncustom knowledge relations. We make the code for kogito available at\nhttps://github.com/epfl-nlp/kogito along with thorough documentation at\nhttps://kogito.readthedocs.io.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Mete Ismayilzada",
      "Antoine Bosselut"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08451"
  },
  {
    "id": "arXiv:2211.08453",
    "title": "Improved techniques for deterministic l2 robustness",
    "abstract": "Training convolutional neural networks (CNNs) with a strict 1-Lipschitz\nconstraint under the $l_{2}$ norm is useful for adversarial robustness,\ninterpretable gradients and stable training. 1-Lipschitz CNNs are usually\ndesigned by enforcing each layer to have an orthogonal Jacobian matrix (for all\ninputs) to prevent the gradients from vanishing during backpropagation.\nHowever, their performance often significantly lags behind that of heuristic\nmethods to enforce Lipschitz constraints where the resulting CNN is not\n\\textit{provably} 1-Lipschitz. In this work, we reduce this gap by introducing\n(a) a procedure to certify robustness of 1-Lipschitz CNNs by replacing the last\nlinear layer with a 1-hidden layer MLP that significantly improves their\nperformance for both standard and provably robust accuracy, (b) a method to\nsignificantly reduce the training time per epoch for Skew Orthogonal\nConvolution (SOC) layers (>30\\% reduction for deeper networks) and (c) a class\nof pooling layers using the mathematical property that the $l_{2}$ distance of\nan input to a manifold is 1-Lipschitz. Using these methods, we significantly\nadvance the state-of-the-art for standard and provable robust accuracies on\nCIFAR-10 (gains of +1.79\\% and +3.82\\%) and similarly on CIFAR-100 (+3.78\\% and\n+4.75\\%) across all networks. Code is available at\n\\url{https://github.com/singlasahil14/improved_l2_robustness}.",
    "descriptor": "\nComments: NeurIPS 2022. arXiv admin note: text overlap with arXiv:2108.04062\n",
    "authors": [
      "Sahil Singla",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08453"
  },
  {
    "id": "arXiv:2211.08458",
    "title": "Latent Bottlenecked Attentive Neural Processes",
    "abstract": "Neural Processes (NPs) are popular methods in meta-learning that can estimate\npredictive uncertainty on target datapoints by conditioning on a context\ndataset. Previous state-of-the-art method Transformer Neural Processes (TNPs)\nachieve strong performance but require quadratic computation with respect to\nthe number of context datapoints, significantly limiting its scalability.\nConversely, existing sub-quadratic NP variants perform significantly worse than\nthat of TNPs. Tackling this issue, we propose Latent Bottlenecked Attentive\nNeural Processes (LBANPs), a new computationally efficient sub-quadratic NP\nvariant, that has a querying computational complexity independent of the number\nof context datapoints. The model encodes the context dataset into a constant\nnumber of latent vectors on which self-attention is performed. When making\npredictions, the model retrieves higher-order information from the context\ndataset via multiple cross-attention mechanisms on the latent vectors. We\nempirically show that LBANPs achieve results competitive with the\nstate-of-the-art on meta-regression, image completion, and contextual\nmulti-armed bandits. We demonstrate that LBANPs can trade-off the computational\ncost and performance according to the number of latent vectors. Finally, we\nshow LBANPs can scale beyond existing attention-based NP variants to larger\ndataset settings.",
    "descriptor": "",
    "authors": [
      "Leo Feng",
      "Hossein Hajimirsadeghi",
      "Yoshua Bengio",
      "Mohamed Osama Ahmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08458"
  },
  {
    "id": "arXiv:2211.08459",
    "title": "CommCSL: Proving Information Flow Security for Concurrent Programs using  Abstract Commutativity",
    "abstract": "Information flow security ensures that the secret data manipulated by a\nprogram does not influence its observable output. Proving information flow\nsecurity is especially challenging for concurrent programs, where operations on\nsecret data may influence the execution time of a thread and, thereby, the\ninterleaving between different threads. Such internal timing channels may\naffect the observable outcome of a program even if an attacker does not observe\nexecution times. Existing verification techniques for information flow security\nin concurrent programs attempt to prove that secret data does not influence the\nrelative timing of threads. However, these techniques are often restrictive\n(for instance because they disallow branching on secret data) and make strong\nassumptions about the execution platform (ignoring caching, processor\ninstructions with data-dependent runtime, and other common features that affect\nexecution time). In this paper, we present a novel verification technique for\nsecure information flow in concurrent programs that lifts these restrictions\nand does not make any assumptions about timing behavior. The key idea is to\nprove that all mutating operations performed on shared data commute, such that\ndifferent thread interleavings do not influence its final value. Crucially,\ncommutativity is required only for an abstraction of the shared data that\ncontains the information that will be leaked to a public output. Abstract\ncommutativity is satisfied by many more operations than standard commutativity,\nwhich makes our technique widely applicable. We formalize our technique in\nCommCSL, a relational concurrent separation logic with support for\ncommutativity-based reasoning, and prove its soundness in Isabelle/HOL. We\nimplemented CommCSL in HyperViper, an automated verifier based on the Viper\nverification infrastructure, and demonstrate its ability to verify challenging\nexamples.",
    "descriptor": "",
    "authors": [
      "Marco Eilers",
      "Thibault Dardinier",
      "Peter M\u00fcller"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.08459"
  },
  {
    "id": "arXiv:2211.08460",
    "title": "ABANICCO: A New Color Space for Multi-Label Pixel Classification and  Color Segmentation",
    "abstract": "In any computer vision task involving color images, a necessary step is\nclassifying pixels according to color and segmenting the respective areas.\nHowever, the development of methods able to successfully complete this task has\nproven challenging, mainly due to the gap between human color perception,\nlinguistic color terms, and digital representation. In this paper, we propose a\nnovel method combining geometric analysis of color theory, fuzzy color spaces,\nand multi-label systems for the automatic classification of pixels according to\n12 standard color categories (Green, Yellow, Light Orange, Deep Orange, Red,\nPink, Purple, Ultramarine, Blue, Teal, Brown, and Neutral). Moreover, we\npresent a robust, unsupervised, unbiased strategy for color naming based on\nstatistics and color theory. ABANICCO was tested against the state of the art\nin color classification and with the standarized ISCC-NBS color system,\nproviding accurate classification and a standard, easily understandable\nalternative for hue naming recognizable by humans and machines. We expect this\nsolution to become the base to successfully tackle a myriad of problems in all\nfields of computer vision, such as region characterization, histopathology\nanalysis, fire detection, product quality prediction, object description, and\nhyperspectral imaging.",
    "descriptor": "\nComments: Working Paper\n",
    "authors": [
      "Laura Nicol\u00e1s-S\u00e1enz",
      "Agapito Ledezma",
      "Javier Pascau",
      "Arrate Mu\u00f1oz-Barrutia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08460"
  },
  {
    "id": "arXiv:2211.08461",
    "title": "Mind Your Bias: A Critical Review of Bias Detection Methods for  Contextual Language Models",
    "abstract": "The awareness and mitigation of biases are of fundamental importance for the\nfair and transparent use of contextual language models, yet they crucially\ndepend on the accurate detection of biases as a precursor. Consequently,\nnumerous bias detection methods have been proposed, which vary in their\napproach, the considered type of bias, and the data used for evaluation.\nHowever, while most detection methods are derived from the word embedding\nassociation test for static word embeddings, the reported results are\nheterogeneous, inconsistent, and ultimately inconclusive. To address this\nissue, we conduct a rigorous analysis and comparison of bias detection methods\nfor contextual language models. Our results show that minor design and\nimplementation decisions (or errors) have a substantial and often significant\nimpact on the derived bias scores. Overall, we find the state of the field to\nbe both worse than previously acknowledged due to systematic and propagated\nerrors in implementations, yet better than anticipated since divergent results\nin the literature homogenize after accounting for implementation errors. Based\non our findings, we conclude with a discussion of paths towards more robust and\nconsistent bias detection methods.",
    "descriptor": "",
    "authors": [
      "Silke Husse",
      "Andreas Spitz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.08461"
  },
  {
    "id": "arXiv:2211.08462",
    "title": "Navigating Connected Memories with a Task-oriented Dialog System",
    "abstract": "Recent years have seen an increasing trend in the volume of personal media\ncaptured by users, thanks to the advent of smartphones and smart glasses,\nresulting in large media collections. Despite conversation being an intuitive\nhuman-computer interface, current efforts focus mostly on single-shot natural\nlanguage based media retrieval to aid users query their media and re-live their\nmemories. This severely limits the search functionality as users can neither\nask follow-up queries nor obtain information without first formulating a\nsingle-turn query.\nIn this work, we propose dialogs for connected memories as a powerful tool to\nempower users to search their media collection through a multi-turn,\ninteractive conversation. Towards this, we collect a new task-oriented dialog\ndataset COMET, which contains $11.5k$ user<->assistant dialogs (totaling $103k$\nutterances), grounded in simulated personal memory graphs. We employ a\nresource-efficient, two-phase data collection pipeline that uses: (1) a novel\nmultimodal dialog simulator that generates synthetic dialog flows grounded in\nmemory graphs, and, (2) manual paraphrasing to obtain natural language\nutterances. We analyze COMET, formulate four main tasks to benchmark meaningful\nprogress, and adopt state-of-the-art language models as strong baselines, in\norder to highlight the multimodal challenges captured by our dataset.",
    "descriptor": "\nComments: 13 pages, 3 tables, 9 figures\n",
    "authors": [
      "Seungwhan Moon",
      "Satwik Kottur",
      "Alborz Geramifard",
      "Babak Damavandi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08462"
  },
  {
    "id": "arXiv:2211.08464",
    "title": "ED-FAITH: Evaluating Dialogue Summarization on Faithfulness",
    "abstract": "Abstractive summarization models typically generate content unfaithful to the\ninput, thus highlighting the significance of evaluating the faithfulness of\ngenerated summaries. Most faithfulness metrics are only evaluated on news\ndomain, can they be transferred to other summarization tasks? In this work, we\nfirst present a systematic study of faithfulness metrics for dialogue\nsummarization. We evaluate common faithfulness metrics on dialogue datasets and\nobserve that most metrics correlate poorly with human judgements despite\nperforming well on news datasets. Given these findings, to improve existing\nmetrics' performance on dialogue summarization, we first finetune on in-domain\ndataset, then apply unlikelihood training on negative samples, and show that\nthey can successfully improve metric performance on dialogue data. Inspired by\nthe strong zero-shot performance of the T0 language model, we further propose\nT0-Score -- a new metric for faithfulness evaluation, which shows consistent\nimprovement against baseline metrics across multiple domains.",
    "descriptor": "",
    "authors": [
      "Sicong Huang",
      "Asli Celikyilmaz",
      "Haoran Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08464"
  },
  {
    "id": "arXiv:2211.08466",
    "title": "Reasoning Circuits: Few-shot Multihop Question Generation with  Structured Rationales",
    "abstract": "Multi-hop Question Generation is the task of generating questions which\nrequire the reader to reason over and combine information spread across\nmultiple passages using several reasoning steps. Chain-of-thought rationale\ngeneration has been shown to improve performance on multi-step reasoning tasks\nand make model predictions more interpretable. However, few-shot performance\ngains from including rationales have been largely observed only in +100B\nlanguage models, and otherwise require large scale manual rationale annotation.\nIn this work, we introduce a new framework for applying chain-of-thought\ninspired structured rationale generation to multi-hop question generation under\na very low supervision regime (8- to 128-shot). We propose to annotate a small\nnumber of examples following our proposed multi-step rationale schema, treating\neach reasoning step as a separate task to be performed by a generative language\nmodel. We show that our framework leads to improved control over the difficulty\nof the generated questions and better performance compared to baselines trained\nwithout rationales, both on automatic evaluation metrics and in human\nevaluation. Importantly, we show that this is achievable with a modest model\nsize.",
    "descriptor": "",
    "authors": [
      "Saurabh Kulshreshtha",
      "Anna Rumshisky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08466"
  },
  {
    "id": "arXiv:2211.08467",
    "title": "Structured Exploration Through Instruction Enhancement for Object  Navigation",
    "abstract": "Finding an object of a specific class in an unseen environment remains an\nunsolved navigation problem. Hence, we propose a hierarchical learning-based\nmethod for object navigation. The top-level is capable of high-level planning,\nand building a memory on a floorplan-level (e.g., which room makes the most\nsense for the agent to visit next, where has the agent already been?). While\nthe lower-level is tasked with efficiently navigating between rooms and looking\nfor objects in them. Instructions can be provided to the agent using a simple\nsynthetic language. The top-level intelligently enhances the instructions in\norder to make the overall task more tractable. Language grounding, mapping\ninstructions to visual observations, is performed by utilizing an additional\nseparate supervised trained goal assessment module. We demonstrate the\neffectiveness of our method on a dynamic configurable domestic environment.",
    "descriptor": "\nComments: Paper accepted to the BNAIC/BeNeLearn 2022 conference\n",
    "authors": [
      "Matthias Hutsebaut-Buysse",
      "Kevin Mets",
      "Tom De Schepper",
      "Steven Latr\u00e9"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08467"
  },
  {
    "id": "arXiv:2211.08469",
    "title": "Deep learning for table detection and structure recognition: A survey",
    "abstract": "Tables are everywhere, from scientific journals, papers, websites, and\nnewspapers all the way to items we buy at the supermarket. Detecting them is\nthus of utmost importance to automatically understanding the content of a\ndocument. The performance of table detection has substantially increased thanks\nto the rapid development of deep learning networks. The goals of this survey\nare to provide a profound comprehension of the major developments in the field\nof Table Detection, offer insight into the different methodologies, and provide\na systematic taxonomy of the different approaches. Furthermore, we provide an\nanalysis of both classic and new applications in the field. Lastly, the\ndatasets and source code of the existing models are organized to provide the\nreader with a compass on this vast literature. Finally, we go over the\narchitecture of utilizing various object detection and table structure\nrecognition methods to create an effective and efficient system, as well as a\nset of development trends to keep up with state-of-the-art algorithms and\nfuture research. We have also set up a public GitHub repository where we will\nbe updating the most recent publications, open data, and source code. The\nGitHub repository is available at\nhttps://github.com/abdoelsayed2016/table-detection-structure-recognition.",
    "descriptor": "",
    "authors": [
      "Mahmoud Kasem",
      "Abdelrahman Abdallah",
      "Alexander Berendeyev",
      "Ebrahem Elkady",
      "Mahmoud Abdalla",
      "Mohamed Mahmoud",
      "Mohamed Hamada",
      "Daniyar Nurseitov",
      "Islam Taj-Eddin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08469"
  },
  {
    "id": "arXiv:2211.08473",
    "title": "On the Compositional Generalization Gap of In-Context Learning",
    "abstract": "Pretrained large generative language models have shown great performance on\nmany tasks, but exhibit low compositional generalization abilities. Scaling\nsuch models has been shown to improve their performance on various NLP tasks\neven just by conditioning them on a few examples to solve the task without any\nfine-tuning (also known as in-context learning). In this work, we look at the\ngap between the in-distribution (ID) and out-of-distribution (OOD) performance\nof such models in semantic parsing tasks with in-context learning. In the ID\nsettings, the demonstrations are from the same split (test or train) that the\nmodel is being evaluated on, and in the OOD settings, they are from the other\nsplit. We look at how the relative generalization gap of in-context learning\nevolves as models are scaled up. We evaluate four model families, OPT, BLOOM,\nCodeGen and Codex on three semantic parsing datasets, CFQ, SCAN and GeoQuery\nwith different number of exemplars, and observe a trend of decreasing relative\ngeneralization gap as models are scaled up.",
    "descriptor": "",
    "authors": [
      "Arian Hosseini",
      "Ankit Vani",
      "Dzmitry Bahdanau",
      "Alessandro Sordoni",
      "Aaron Courville"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08473"
  },
  {
    "id": "arXiv:2211.08474",
    "title": "Resilient Set-based State Estimation for Linear Time-Invariant Systems  Using Zonotopes",
    "abstract": "This paper considers the problem of set-based state estimation for linear\ntime-invariant (LTI) systems under time-varying sensor attacks. Provided that\nthe LTI system is stable and observable via every single sensor and that at\nleast one sensor is uncompromised, we guarantee that the true state is always\ncontained in the estimated set. We use zonotopes to represent these sets for\ncomputational efficiency. However, we show that intelligently designed stealthy\nattacks may cause exponential growth in the algorithm's worst-case complexity.\nWe present several strategies to handle this complexity issue and illustrate\nour resilient zonotope-based state estimation algorithm on a rotating target\nsystem.",
    "descriptor": "",
    "authors": [
      "Muhammad Umar B. Niazi",
      "Amr Alanwar",
      "Michelle S. Chong",
      "Karl Henrik Johansson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.08474"
  },
  {
    "id": "arXiv:2211.08475",
    "title": "AutoDRIVE -- Technical Report",
    "abstract": "This work presents AutoDRIVE, a comprehensive research and education platform\nfor implementing and validating intelligent transportation algorithms\npertaining to vehicular autonomy as well as smart city management. It is an\nopenly accessible platform featuring a 1:14 scale car with realistic drive and\nsteering actuators, redundant sensing modalities, high-performance\ncomputational resources, and standard vehicular lighting system. Additionally,\nthe platform also offers a range of modules for rapid design and development of\nthe infrastructure. The AutoDRIVE platform encompasses Devkit, Simulator and\nTestbed, a harmonious trio to develop, simulate and deploy autonomy algorithms.\nIt is compatible with a variety of software development packages, and supports\nsingle as well as multi-agent paradigms through local and distributed\ncomputing. AutoDRIVE is a product-level implementation, with a vast scope for\ncommercialization. This versatile platform has numerous applications, and they\nare bound to keep increasing as new features are added. This work demonstrates\nfour such applications including autonomous parking, behavioural cloning,\nintersection traversal and smart city management, each exploiting distinct\nfeatures of the platform.",
    "descriptor": "\nComments: This work was a part of 2021 Undergraduate Final Year Project at the Department of Mechatronics Engineering, SRM Institute of Science and Technology\n",
    "authors": [
      "Tanmay Vilas Samak",
      "Chinmay Vilas Samak"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.08475"
  },
  {
    "id": "arXiv:2211.08478",
    "title": "ECCO: Equivalent Circuit Controlled Optimization",
    "abstract": "We propose an adaptive optimization algorithm for solving unconstrained\nscaled gradient flow problems that achieves fast convergence by controlling the\noptimization trajectory shape and the discretization step sizes. Under a broad\nclass of scaling functions, we establish convergence of the proposed approach\nto critical points of smooth objective functions, while demonstrating its\nflexibility and robustness with respect to hyperparameter tuning. First, we\nprove convergence of component-wise scaled gradient flow to a critical point\nunder regularity conditions. We show that this controlled gradient flow\ndynamics is equivalent to the transient response of an electrical circuit,\nallowing for circuit theory concepts to solve the problem. Based on this\nequivalence, we develop two optimization trajectory control schemes based on\nminimizing the charge stored in the circuit: one based on the true Hessian and\none based on an approximate Hessian. While the control schemes are derived from\ncircuit concepts, no circuit knowledge is needed to implement the algorithms.\nTo find the value of the critical point, we propose a time step search routine\nfor forward Euler discretization that controls the local truncation error, a\nmethod adapted from circuit simulation ideas. In simulation we find that the\ntrajectory control outperforms uncontrolled gradient flow, and the error-aware\ndiscretization out-performs line search with the Armijo condition. Our\nalgorithms are evaluated on convex and non-convex test functions, including\nneural networks, with convergence speeds comparable to or exceeding Adam.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Aayushya Agarwal",
      "Carmel Fiscko",
      "Soummya Kar",
      "Larry Pileggi",
      "Bruno Sinopoli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.08478"
  },
  {
    "id": "arXiv:2211.08479",
    "title": "Context-Matched Collage Generation for Underwater Invertebrate Detection",
    "abstract": "The quality and size of training sets often limit the performance of many\nstate of the art object detectors. However, in many scenarios, it can be\ndifficult to collect images for training, not to mention the costs associated\nwith collecting annotations suitable for training these object detectors. For\nthese reasons, on challenging video datasets such as the Dataset for Underwater\nSubstrate and Invertebrate Analysis (DUSIA), budgets may only allow for\ncollecting and providing partial annotations. To aid in the challenges\nassociated with training with limited and partial annotations, we introduce\nContext Matched Collages, which leverage explicit context labels to combine\nunused background examples with existing annotated data to synthesize\nadditional training samples that ultimately improve object detection\nperformance. By combining a set of our generated collage images with the\noriginal training set, we see improved performance using three different object\ndetectors on DUSIA, ultimately achieving state of the art object detection\nperformance on the dataset.",
    "descriptor": "",
    "authors": [
      "R. Austin McEver",
      "Bowen Zhang",
      "B.S. Manjunath"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.08479"
  },
  {
    "id": "arXiv:2211.08480",
    "title": "LiePoseNet: Heterogeneous Loss Function Based on Lie Group for  Significant Speed-up of PoseNet Training Process",
    "abstract": "Visual localization is an essential modern technology for robotics and\ncomputer vision. Popular approaches for solving this task are image-based\nmethods. Nowadays, these methods have low accuracy and a long training time.\nThe reasons are the lack of rigid-body and projective geometry awareness,\nlandmark symmetry, and homogeneous error assumption. We propose a heterogeneous\nloss function based on concentrated Gaussian distribution with the Lie group to\novercome these difficulties. Following our experiment, the proposed method\nallows us to speed up the training process significantly (from 300 to 10\nepochs) with acceptable error values.",
    "descriptor": "\nComments: 6 pages, 5 figures\n",
    "authors": [
      "Mikhail Kurenkov",
      "Ivan Kalinov",
      "Dzmitry Tsetserukou"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.08480"
  },
  {
    "id": "arXiv:2211.08483",
    "title": "Virtually turning robotic manipulators into worn devices: opening new  horizons for wearable assistive robotics",
    "abstract": "Robotic sensorimotor extensions (supernumerary limbs, prosthesis, handheld\ntools) are worn devices used to interact with the nearby environment, whether\nto assist the capabilities of impaired users or to enhance the dexterity of\nindustrial operators. Despite numerous mechanical achievements, embedding these\nrobotics devices remains critical due to their weight and discomfort. To\nemancipate from these mechanical constraints, we propose a new hybrid system\nusing a virtually worn robotic arm in augmented-reality, and a real robotic\nmanipulator servoed on such virtual representation. We aim at bringing an\nillusion of wearing a robotic system while its weight is fully deported,\nthinking that this approach could open new horizons for the study of wearable\nrobotics without any intrinsic impairment of the human movement abilities.",
    "descriptor": "\nComments: 4 pages, 3 figures\n",
    "authors": [
      "Alexis Poignant",
      "Nathanael Jarrasse",
      "Guillaume Morel"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.08483"
  },
  {
    "id": "arXiv:2211.08486",
    "title": "Scalar Invariant Networks with Zero Bias",
    "abstract": "Just like weights, bias terms are the learnable parameters of many popular\nmachine learning models, including neural networks. Biases are believed to\neffectively increase the representational power of neural networks to solve a\nwide range of tasks in computer vision. However, we argue that if we consider\nthe intrinsic distribution of images in the input space as well as some desired\nproperties a model should have from the first principles, biases can be\ncompletely ignored in addressing many image-related tasks, such as image\nclassification. Our observation indicates that zero-bias neural networks could\nperform comparably to neural networks with bias at least on practical image\nclassification tasks. In addition, we prove that zero-bias neural networks\npossess a nice property called scalar (multiplication) invariance, which has\ngreat potential in learning and understanding images captured under poor\nillumination conditions. We then extend scalar invariance to more general cases\nthat allow us to verify certain convex regions of the input space. Our\nexperimental results show that zero-bias models could outperform the\nstate-of-art models by a very large margin (over 60%) when predicting images\nunder a low illumination condition (multiplying a scalar of 0.01); while\nachieving the same-level performance as normal models.",
    "descriptor": "\nComments: 10 pages, 8 figures\n",
    "authors": [
      "Chuqin Geng",
      "Xiaojie Xu",
      "Haolin Ye",
      "Xujie Si"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08486"
  },
  {
    "id": "arXiv:2211.08494",
    "title": "Weighting Experts with Inaccurate Judges",
    "abstract": "We consider the problem of aggregating binary votes from an ensemble of\nexperts to reveal an underlying binary ground truth where each expert votes\ncorrectly with some independent probability. We focus on settings where the\nnumber of agents is too small for asymptotic results to apply, many experts may\nvote correctly with low probability, and there is no central authority who\nknows the experts' competences, or their probabilities of voting correctly. Our\napproach is to designate a second type of agent -- a judge -- to weight the\nexperts to improve overall accuracy. The catch is that the judge has imperfect\ncompetence just like the experts. We demonstrate that having a single minimally\ncompetent judge is often better than having none at all. Using an ensemble of\njudges to weight the experts can provide a better weighting than any single\njudge; even the optimal weighting under the right conditions. As our results\nshow, the ability of the judge(s) to distinguish between competent and\nincompetent experts is paramount. Lastly, given a fixed set of agents with\nunknown competences drawn i.i.d. from a common distribution, we show how the\noptimal split of the agents between judges and experts depends on the\ndistribution.",
    "descriptor": "",
    "authors": [
      "Ben Abramowitz",
      "Nicholas Mattei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2211.08494"
  },
  {
    "id": "arXiv:2211.08501",
    "title": "Social Mechanism Design: A Low-Level Introduction",
    "abstract": "How do we deal with the fact that agents have preferences over both decision\noutcomes and the rules or procedures used to make decisions? If we create rules\nfor aggregating preferences over rules, it would appear that we run into\ninfinite regress with preferences and rules at successively higher \"levels.\"\nThe starting point of our analysis is the claim that infinite regress should\nnot be a problem in practice, as any such preferences will necessarily be\nbounded in complexity and structured coherently in accordance with some\n(possibly latent) normative principles. Our core contributions are (1) the\nidentification of simple, intuitive preference structures at low levels that\ncan be generalized to form the building blocks of preferences at higher levels,\nand (2) the development of algorithms for maximizing the number of agents with\nsuch low-level preferences who will \"accept\" a decision. We analyze algorithms\nfor acceptance maximization in two different domains: asymmetric dichotomous\nchoice and constitutional amendment. In both settings we study the worst-case\nperformance of the appropriate algorithms, and reveal circumstances under which\nuniversal acceptance is possible. In particular, we show that constitutional\namendment procedures proposed recently by Abramowitz, Shapiro, and Talmon\n(2021) can achieve universal acceptance.",
    "descriptor": "",
    "authors": [
      "Ben Abramowitz",
      "Nicholas Mattei"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.08501"
  },
  {
    "id": "arXiv:2211.08502",
    "title": "Active ReLU Linearized Neural Network based Frequency-Constrained Unit  Commitment in Low-Inertia Power Systems",
    "abstract": "Conventional synchronous generators are gradually being replaced by\ninverter-based resources. Such transition introduces more complicated operation\nconditions, and also imposes challenges for system operators on maintaining\nsystem frequency and rate-of-change-of-frequency (RoCoF) security due to\nreduction in system inertia. To ensure the system wide frequency security, this\npaper presents an active rectified linear unit (ReLU) linearized neural network\n(ARLNN) based RoCoF-constrained unit commitment (ARLNN-RCUC) model. A predictor\nis first trained to predict the highest locational RoCoF based on a\nhigh-fidelity simulation dataset. Instead of incorporating the complete trained\nneural network into unit commitment, a ReLU linearization method is implemented\non selected neurons to improve the algorithm efficiency. The effectiveness of\nproposed ARLNN-RCUC model is demonstrated on the IEEE 24-bus system by\nconducting time domain simulation on PSS/E.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2208.08028\n",
    "authors": [
      "Mingjian Tuo",
      "Xingpeng Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.08502"
  },
  {
    "id": "arXiv:2211.08504",
    "title": "APT: Adaptive Perceptual quality based camera Tuning using reinforcement  learning",
    "abstract": "Cameras are increasingly being deployed in cities, enterprises and roads\nworld-wide to enable many applications in public safety, intelligent\ntransportation, retail, healthcare and manufacturing. Often, after initial\ndeployment of the cameras, the environmental conditions and the scenes around\nthese cameras change, and our experiments show that these changes can adversely\nimpact the accuracy of insights from video analytics. This is because the\ncamera parameter settings, though optimal at deployment time, are not the best\nsettings for good-quality video capture as the environmental conditions and\nscenes around a camera change during operation. Capturing poor-quality video\nadversely affects the accuracy of analytics. To mitigate the loss in accuracy\nof insights, we propose a novel, reinforcement-learning based system APT that\ndynamically, and remotely (over 5G networks), tunes the camera parameters, to\nensure a high-quality video capture, which mitigates any loss in accuracy of\nvideo analytics. As a result, such tuning restores the accuracy of insights\nwhen environmental conditions or scene content change. APT uses reinforcement\nlearning, with no-reference perceptual quality estimation as the reward\nfunction. We conducted extensive real-world experiments, where we\nsimultaneously deployed two cameras side-by-side overlooking an enterprise\nparking lot (one camera only has manufacturer-suggested default setting, while\nthe other camera is dynamically tuned by APT during operation). Our experiments\ndemonstrated that due to dynamic tuning by APT, the analytics insights are\nconsistently better at all times of the day: the accuracy of object detection\nvideo analytics application was improved on average by ~ 42%. Since our reward\nfunction is independent of any analytics task, APT can be readily used for\ndifferent video analytics tasks.",
    "descriptor": "",
    "authors": [
      "Sibendu Paul",
      "Kunal Rao",
      "Giuseppe Coviello",
      "Murugan Sankaradas",
      "Oliver Po",
      "Y. Charlie Hu",
      "Srimat Chakradhar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08504"
  },
  {
    "id": "arXiv:2211.08506",
    "title": "ParticleGrid: Enabling Deep Learning using 3D Representation of  Materials",
    "abstract": "From AlexNet to Inception, autoencoders to diffusion models, the development\nof novel and powerful deep learning models and learning algorithms has\nproceeded at breakneck speeds. In part, we believe that rapid iteration of\nmodel architecture and learning techniques by a large community of researchers\nover a common representation of the underlying entities has resulted in\ntransferable deep learning knowledge. As a result, model scale, accuracy,\nfidelity, and compute performance have dramatically increased in computer\nvision and natural language processing. On the other hand, the lack of a common\nrepresentation for chemical structure has hampered similar progress. To enable\ntransferable deep learning, we identify the need for a robust 3-dimensional\nrepresentation of materials such as molecules and crystals. The goal is to\nenable both materials property prediction and materials generation with 3D\nstructures. While computationally costly, such representations can model a\nlarge set of chemical structures. We propose $\\textit{ParticleGrid}$, a\nSIMD-optimized library for 3D structures, that is designed for deep learning\napplications and to seamlessly integrate with deep learning frameworks. Our\nhighly optimized grid generation allows for generating grids on the fly on the\nCPU, reducing storage and GPU compute and memory requirements. We show the\nefficacy of 3D grids generated via $\\textit{ParticleGrid}$ and accurately\npredict molecular energy properties using a 3D convolutional neural network.\nOur model is able to get 0.006 mean square error and nearly match the values\ncalculated using computationally costly density functional theory at a fraction\nof the time.",
    "descriptor": "\nComments: Published in the 2022 IEEE 18th International Conference on eScience (eScience)\n",
    "authors": [
      "Shehtab Zaman",
      "Ethan Ferguson",
      "Cecile Pereira",
      "Denis Akhiyarov",
      "Mauricio Araya-Polo",
      "Kenneth Chiu"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08506"
  },
  {
    "id": "arXiv:2211.08507",
    "title": "Decision-Aware Learning for Optimizing Health Supply Chains",
    "abstract": "We study the problem of allocating limited supply of medical resources in\ndeveloping countries, in particular, Sierra Leone. We address this problem by\ncombining machine learning (to predict demand) with optimization (to optimize\nallocations). A key challenge is the need to align the loss function used to\ntrain the machine learning model with the decision loss associated with the\ndownstream optimization problem. Traditional solutions have limited flexibility\nin the model architecture and scale poorly to large datasets. We propose a\ndecision-aware learning algorithm that uses a novel Taylor expansion of the\noptimal decision loss to derive the machine learning loss. Importantly, our\napproach only requires a simple re-weighting of the training data, ensuring it\nis both flexible and scalable, e.g., we incorporate it into a random forest\ntrained using a multitask learning framework. We apply our framework to\noptimize the distribution of essential medicines in collaboration with\npolicymakers in Sierra Leone; highly uncertain demand and limited budgets\ncurrently result in excessive unmet demand. Out-of-sample results demonstrate\nthat our end-to-end approach can significantly reduce unmet demand across 1040\nhealth facilities throughout Sierra Leone.",
    "descriptor": "\nComments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 8 pages\n",
    "authors": [
      "Tsai-Hsuan Chung",
      "Vahid Rostami",
      "Hamsa Bastani",
      "Osbert Bastani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08507"
  },
  {
    "id": "arXiv:2211.08508",
    "title": "Characterizing and Utilizing the Interplay between Quantum Technologies  and Non-Terrestrial Networks",
    "abstract": "Quantum technologies have been widely recognized as one of the milestones\ntowards the ongoing digital transformation, which will also trigger new\ndisruptive innovations. Quantum technologies encompassing quantum computing,\ncommunications, and sensing offer an interesting set of advantages such as\nunconditional security and ultra-fast computing capabilities. However,\ndeploying quantum services at a global scale requires circumventing the\nlimitations due to the geographical boundaries and terrestrial obstacles, which\ncan be adequately addressed by considering non-terrestrial networks (NTNs). In\nthe recent few years, establishing multi-layer NTNs has been extensively\nstudied to integrate space-airborne-terrestrial communications systems,\nparticularly by the international standardization organizations such as the\nthird-generation partnership project (3GPP) and the international\ntelecommunication union (ITU), in order to support future wireless ecosystems.\nIndeed, amalgamating quantum technologies and NTNs will scale up the quantum\ncommunications ranges and provide unprecedented levels of security and\nprocessing solutions that are safer and faster than the traditional offerings.\nThis paper provides some insights into the interplay between the evolving NTN\narchitectures and quantum technologies with a particular focus on the\nintegration challenges and their potential solutions for enhancing the\nquantum-NTN interoperability among various space-air-ground communications\nnodes. The emphasis is on how the quantum technologies can benefit from\nsatellites and aerial platforms as an integrated network and vice versa.\nMoreover, a set of future research directions and new opportunities are\nidentified.",
    "descriptor": "",
    "authors": [
      "Hayder Al-Hraishawi",
      "Junaid ur Rehman",
      "Mohsen Razavi",
      "Symeon Chatzinotas"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.08508"
  },
  {
    "id": "arXiv:2211.08512",
    "title": "N2V2 -- Fixing Noise2Void Checkerboard Artifacts with Modified Sampling  Strategies and a Tweaked Network Architecture",
    "abstract": "In recent years, neural network based image denoising approaches have\nrevolutionized the analysis of biomedical microscopy data. Self-supervised\nmethods, such as Noise2Void (N2V), are applicable to virtually all noisy\ndatasets, even without dedicated training data being available. Arguably, this\nfacilitated the fast and widespread adoption of N2V throughout the life\nsciences. Unfortunately, the blind-spot training underlying N2V can lead to\nrather visible checkerboard artifacts, thereby reducing the quality of final\npredictions considerably. In this work, we present two modifications to the\nvanilla N2V setup that both help to reduce the unwanted artifacts considerably.\nFirstly, we propose a modified network architecture, i.e., using BlurPool\ninstead of MaxPool layers throughout the used U-Net, rolling back the residual\nU-Net to a non-residual U-Net, and eliminating the skip connections at the\nuppermost U-Net level. Additionally, we propose new replacement strategies to\ndetermine the pixel intensity values that fill in the elected blind-spot\npixels. We validate our modifications on a range of microscopy and natural\nimage data. Based on added synthetic noise from multiple noise types and at\nvarying amplitudes, we show that both proposed modifications push the current\nstate-of-the-art for fully self-supervised image denoising.",
    "descriptor": "\nComments: 16 pages, 7 figures, accepted at BIC workshop at ECCV 2022\n",
    "authors": [
      "Eva H\u00f6ck",
      "Tim-Oliver Buchholz",
      "Anselm Brachmann",
      "Florian Jug",
      "Alexander Freytag"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08512"
  },
  {
    "id": "arXiv:2211.08513",
    "title": "Searching for Carriers of the Diffuse Interstellar Bands Across  Disciplines, using Natural Language Processing",
    "abstract": "The explosion of scientific publications overloads researchers with\ninformation. This is even more dramatic for interdisciplinary studies, where\nseveral fields need to be explored. A tool to help researchers overcome this is\nNatural Language Processing (NLP): a machine-learning (ML) technique that\nallows scientists to automatically synthesize information from many articles.\nAs a practical example, we have used NLP to conduct an interdisciplinary search\nfor compounds that could be carriers for Diffuse Interstellar Bands (DIBs), a\nlong-standing open question in astrophysics. We have trained a NLP model on a\ncorpus of 1.5 million cross-domain articles in open access, and fine-tuned this\nmodel with a corpus of astrophysical publications about DIBs. Our analysis\npoints us toward several molecules, studied primarily in biology, having\ntransitions at the wavelengths of several DIBs and composed of abundant\ninterstellar atoms. Several of these molecules contain chromophores, small\nmolecular groups responsible for the molecule's colour, that could be promising\ncandidate carriers. Identifying viable carriers demonstrates the value of using\nNLP to tackle open scientific questions, in an interdisciplinary manner.",
    "descriptor": "\nComments: Accepted for publication by Journal of Interdisciplinary Methodologies and Issues in Science (JIMIS)\n",
    "authors": [
      "Corentin van den Broek Dobrenan",
      "Frederic Galliano",
      "Jeremy Minton",
      "Viktor Botev",
      "Ronin Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Astrophysics of Galaxies (astro-ph.GA)"
    ],
    "url": "https://arxiv.org/abs/2211.08513"
  },
  {
    "id": "arXiv:2211.08514",
    "title": "Spectral Heuristics Applied to Vertex Reliability",
    "abstract": "The operability of a network concerns its ability to remain operational,\ndespite possible failures in its links or equipment. One may model the network\nthrough a graph to evaluate and increase this operability. Its vertices and\nedges correspond to the users equipment and their connections, respectively. In\nthis article, the problem addressed is identifying the topological change in\nthe graph that leads to a greater increase in the operability of the associated\nnetwork, considering the case in which failure occurs in the network equipment\nonly. More specifically, we propose two spectral heuristics to improve the\nvertex reliability in graphs through a single edge insertion. The performance\nthese heuristics and others that are usually found in the literature are\nevaluated by computational experiments with 22000 graphs of orders 10 up to 20,\ngenerated using the Models Erdos-Renyi, Barabasi-Albert, and Watts-Strogatz.\nFrom the experiments, it can be observed through analysis and application of\nstatistical test, that one of the spectral heuristics presented a superior\nperformance in relation to the others.",
    "descriptor": "\nComments: 7 pages, 2 figures\n",
    "authors": [
      "Carla Silva Oliveira",
      "Fausto Marques Pinheiro Junior",
      "Jose Andre de Moura Brito"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.08514"
  },
  {
    "id": "arXiv:2211.08517",
    "title": "A Hierarchical Deep Neural Network for Detecting Lines of Codes with  Vulnerabilities",
    "abstract": "Software vulnerabilities, caused by unintentional flaws in source codes, are\nthe main root cause of cyberattacks. Source code static analysis has been used\nextensively to detect the unintentional defects, i.e. vulnerabilities,\nintroduced into the source codes by software developers. In this paper, we\npropose a deep learning approach to detect vulnerabilities from their LLVM IR\nrepresentations based on the techniques that have been used in natural language\nprocessing. The proposed approach uses a hierarchical process to first identify\nsource codes with vulnerabilities, and then it identifies the lines of codes\nthat contribute to the vulnerability within the detected source codes. This\nproposed two-step approach reduces the false alarm of detecting vulnerable\nlines. Our extensive experiment on real-world and synthetic codes collected in\nNVD and SARD shows high accuracy (about 98\\%) in detecting source code\nvulnerabilities.",
    "descriptor": "\nComments: 22nd IEEE International Conference on Software, Quality, Reliability, and Security (QRS 2022)\n",
    "authors": [
      "Arash Mahyari"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.08517"
  },
  {
    "id": "arXiv:2211.08518",
    "title": "Parameter-Covariance Maximum Likelihood Estimation",
    "abstract": "Linear time series modelling is dominated by the use of purely autoregressive\nmodels even though incorporating moving average components can greatly improve\nparsimony. We present a convex formulation for vector-ARMA system\nidentification which respects this fundamental property, thus granting access\nto the nice properties afforded by convex programming. The identification\nprocedure is done purely in the time domain which can accommodate\nnon-stationarity through regime switching. As a proof of concept, we present\nexperimental results demonstrating this convex program in action. Next, we show\nhow to adapt the expectation-maximization algorithm to support regime switching\nbehavior.",
    "descriptor": "",
    "authors": [
      "Alex Nguyen-Le",
      "Victor M. Preciado"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.08518"
  },
  {
    "id": "arXiv:2211.08524",
    "title": "Complexity Results for Implication Bases of Convex Geometries",
    "abstract": "A convex geometry is finite zero-closed closure system that satisfies the\nanti-exchange property. Complexity results are given for two open problems\nrelated to representations of convex geometries using implication bases. In\nparticular, the problem of optimizing an implication basis for a convex\ngeometry is shown to be NP-hard by establishing a reduction from the minimum\ncardinality generator problem for general closure systems. Furthermore, even\nthe problem of deciding whether an implication basis defines a convex geometry\nis shown to be co-NP-complete by a reduction from the Boolean tautology\nproblem.",
    "descriptor": "",
    "authors": [
      "Todd Bichoupan"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.08524"
  },
  {
    "id": "arXiv:2211.08525",
    "title": "LEAN-DMKDE: Quantum Latent Density Estimation for Anomaly Detection",
    "abstract": "This paper presents an anomaly detection model that combines the strong\nstatistical foundation of density-estimation-based anomaly detection methods\nwith the representation-learning ability of deep-learning models. The method\ncombines an autoencoder, for learning a low-dimensional representation of the\ndata, with a density-estimation model based on random Fourier features and\ndensity matrices in an end-to-end architecture that can be trained using\ngradient-based optimization techniques. The method predicts a degree of\nnormality for new samples based on the estimated density. A systematic\nexperimental evaluation was performed on different benchmark datasets. The\nexperimental results show that the method performs on par with or outperforms\nother state-of-the-art methods.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Joseph Gallego-Mejia",
      "Oscar Bustos-Brinez",
      "Fabio A. Gonz\u00e1lez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Statistics Theory (math.ST)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.08525"
  },
  {
    "id": "arXiv:2211.08526",
    "title": "Alzheimer's Dementia Detection through Spontaneous Dialogue with  Proactive Robotic Listeners",
    "abstract": "As the aging of society continues to accelerate, Alzheimer's Disease (AD) has\nreceived more and more attention from not only medical but also other fields,\nsuch as computer science, over the past decade. Since speech is considered one\nof the effective ways to diagnose cognitive decline, AD detection from speech\nhas emerged as a hot topic. Nevertheless, such approaches fail to tackle\nseveral key issues: 1) AD is a complex neurocognitive disorder which means it\nis inappropriate to conduct AD detection using utterance information alone\nwhile ignoring dialogue information; 2) Utterances of AD patients contain many\ndisfluencies that affect speech recognition yet are helpful to diagnosis; 3) AD\npatients tend to speak less, causing dialogue breakdown as the disease\nprogresses. This fact leads to a small number of utterances, which may cause\ndetection bias. Therefore, in this paper, we propose a novel AD detection\narchitecture consisting of two major modules: an ensemble AD detector and a\nproactive listener. This architecture can be embedded in the dialogue system of\nconversational robots for healthcare.",
    "descriptor": "\nComments: Accepted for HRI2022 Late-Breaking Report\n",
    "authors": [
      "Yuanchao Li",
      "Catherine Lai",
      "Divesh Lala",
      "Koji Inoue",
      "Tatsuya Kawahara"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.08526"
  },
  {
    "id": "arXiv:2211.08530",
    "title": "Cyber-Attack Event Analysis for EV Charging Stations",
    "abstract": "Safe and secure electric vehicle charging stations (EVCSs) are important in\nsmart transportation infrastructure. The prevalence of EVCSs has rapidly\nincreased over time in response to the rising demand for EV charging. However,\ndevelopments in information and communication technologies (ICT) have made the\ncyber-physical system (CPS) of EVCSs susceptible to cyber-attacks, which might\ndestabilize the infrastructure of the electric grid as well as the environment\nfor charging. This study suggests a 5Ws \\& 1H-based investigation approach to\ndeal with cyber-attack-related incidents due to the incapacity of the current\ninvestigation frameworks to comprehend and handle these mishaps. Also, a\nstochastic anomaly detection system (ADS) is proposed to identify the\nanomalies, abnormal activities, and unusual operations of the station entities\nas a post cyber event analysis.",
    "descriptor": "\nComments: 5 Pages, 2 Figures, 2 Tables, 10 Mathematical Equations, PES GM Conference Paper\n",
    "authors": [
      "Mansi Girdhar",
      "Junho Hong",
      "Yongsik You",
      "Tai-jin Song",
      "Manimaran Govindarasu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.08530"
  },
  {
    "id": "arXiv:2211.08532",
    "title": "Omnidirectional robot modeling and simulation",
    "abstract": "A robot simulation system is a basic need for any robotics application. With\nit, developers' teams of robots can test their algorithms and make initial\ncalibrations without risk of damage to the real robots, assuring safety.\nHowever, building these simulation environments is usually time-consuming work,\nand when considering robot fleets, the simulation reveals to be computing\nexpensive. With it, developers building teams of robots can test their\nalgorithms and make initial calibrations without risk of damage to the real\nrobots, assuring safety. An omnidirectional robot from the 5DPO robotics soccer\nteam served to test this approach. The modeling issue was divided into two\nsteps: modeling the motor's non-linear features and modeling the general\nbehavior of the robot. A proper fitting of the robot was reached, considering\nthe velocity robot's response.",
    "descriptor": "\nComments: Conference proceedings ICARSC; 6 pages\n",
    "authors": [
      "Sandro Costa Magalh\u00e3es",
      "Ant\u00f3nio Paulo Moreira",
      "Paulo Costa"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.08532"
  },
  {
    "id": "arXiv:2211.08533",
    "title": "A Point in the Right Direction: Vector Prediction for Spatially-aware  Self-supervised Volumetric Representation Learning",
    "abstract": "High annotation costs and limited labels for dense 3D medical imaging tasks\nhave recently motivated an assortment of 3D self-supervised pretraining methods\nthat improve transfer learning performance. However, these methods commonly\nlack spatial awareness despite its centrality in enabling effective 3D image\nanalysis. More specifically, position, scale, and orientation are not only\ninformative but also automatically available when generating image crops for\ntraining. Yet, to date, no work has proposed a pretext task that distills all\nkey spatial features. To fulfill this need, we develop a new self-supervised\nmethod, VectorPOSE, which promotes better spatial understanding with two novel\npretext tasks: Vector Prediction (VP) and Boundary-Focused Reconstruction\n(BFR). VP focuses on global spatial concepts (i.e., properties of 3D patches)\nwhile BFR addresses weaknesses of recent reconstruction methods to learn more\neffective local representations. We evaluate VectorPOSE on three 3D medical\nimage segmentation tasks, showing that it often outperforms state-of-the-art\nmethods, especially in limited annotation settings.",
    "descriptor": "",
    "authors": [
      "Yejia Zhang",
      "Pengfei Gu",
      "Nishchal Sapkota",
      "Hao Zheng",
      "Peixian Liang",
      "Danny Z. Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08533"
  },
  {
    "id": "arXiv:2211.08536",
    "title": "Behavior of Hyper-Parameters for Selected Machine Learning Algorithms:  An Empirical Investigation",
    "abstract": "Hyper-parameters (HPs) are an important part of machine learning (ML) model\ndevelopment and can greatly influence performance. This paper studies their\nbehavior for three algorithms: Extreme Gradient Boosting (XGB), Random Forest\n(RF), and Feedforward Neural Network (FFNN) with structured data. Our empirical\ninvestigation examines the qualitative behavior of model performance as the HPs\nvary, quantifies the importance of each HP for different ML algorithms, and\nstability of the performance near the optimal region. Based on the findings, we\npropose a set of guidelines for efficient HP tuning by reducing the search\nspace.",
    "descriptor": "",
    "authors": [
      "Anwesha Bhattacharyya",
      "Joel Vaughan",
      "Vijayan N. Nair"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08536"
  },
  {
    "id": "arXiv:2211.08539",
    "title": "Operationalizing Digital Self Determination",
    "abstract": "We live in an era of datafication, one in which life is increasingly\nquantified and transformed into intelligence for private or public benefit.\nWhen used responsibly, this offers new opportunities for public good. However,\nthree key forms of asymmetry currently limit this potential, especially for\nalready vulnerable and marginalized groups: data asymmetries, information\nasymmetries, and agency asymmetries. These asymmetries limit human potential,\nboth in a practical and psychological sense, leading to feelings of\ndisempowerment and eroding public trust in technology. Existing methods to\nlimit asymmetries (e.g., consent) as well as some alternatives under\nconsideration (data ownership, collective ownership, personal information\nmanagement systems) have limitations to adequately address the challenges at\nhand. A new principle and practice of digital self-determination (DSD) is\ntherefore required.\nDSD is based on existing concepts of self-determination, as articulated in\nsources as varied as Kantian philosophy and the 1966 International Covenant on\nEconomic, Social and Cultural Rights. Updated for the digital age, DSD contains\nseveral key characteristics, including the fact that it has both an individual\nand collective dimension; is designed to especially benefit vulnerable and\nmarginalized groups; and is context-specific (yet also enforceable).\nOperationalizing DSD in this (and other) contexts so as to maximize the\npotential of data while limiting its harms requires a number of steps. In\nparticular, a responsible operationalization of DSD would consider four key\nprongs or categories of action: processes, people and organizations, policies,\nand products and technologies.",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Stefaan G. Verhulst"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.08539"
  },
  {
    "id": "arXiv:2211.08540",
    "title": "VGFlow: Visibility guided Flow Network for Human Reposing",
    "abstract": "The task of human reposing involves generating a realistic image of a person\nstanding in an arbitrary conceivable pose. There are multiple difficulties in\ngenerating perceptually accurate images, and existing methods suffer from\nlimitations in preserving texture, maintaining pattern coherence, respecting\ncloth boundaries, handling occlusions, manipulating skin generation, etc. These\ndifficulties are further exacerbated by the fact that the possible space of\npose orientation for humans is large and variable, the nature of clothing items\nis highly non-rigid, and the diversity in body shape differs largely among the\npopulation. To alleviate these difficulties and synthesize perceptually\naccurate images, we propose VGFlow. Our model uses a visibility-guided flow\nmodule to disentangle the flow into visible and invisible parts of the target\nfor simultaneous texture preservation and style manipulation. Furthermore, to\ntackle distinct body shapes and avoid network artifacts, we also incorporate a\nself-supervised patch-wise \"realness\" loss to improve the output. VGFlow\nachieves state-of-the-art results as observed qualitatively and quantitatively\non different image quality metrics (SSIM, LPIPS, FID).",
    "descriptor": "\nComments: 8 pages, 8 figures, computer vision\n",
    "authors": [
      "Rishabh Jain",
      "Krishna Kumar Singh",
      "Mayur Hemani",
      "Jingwan Lu",
      "Mausooom Sarkar",
      "Duygu Ceylan",
      "Balaji Krishnamurthy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08540"
  },
  {
    "id": "arXiv:2211.08541",
    "title": "GC-GRU-N for Traffic Prediction using Loop Detector Data",
    "abstract": "Because traffic characteristics display stochastic nonlinear spatiotemporal\ndependencies, traffic prediction is a challenging task. In this paper develop a\ngraph convolution gated recurrent unit (GC GRU N) network to extract the\nessential Spatio temporal features. we use Seattle loop detector data\naggregated over 15 minutes and reframe the problem through space and time. The\nmodel performance is compared o benchmark models; Historical Average, Long\nShort Term Memory (LSTM), and Transformers. The proposed model ranked second\nwith the fastest inference time and a very close performance to first place\n(Transformers). Our model also achieves a running time that is six times faster\nthan transformers. Finally, we present a comparative study of our model and the\navailable benchmarks using metrics such as training time, inference time, MAPE,\nMAE and RMSE. Spatial and temporal aspects are also analyzed for each of the\ntrained models.",
    "descriptor": "",
    "authors": [
      "Maged Shoman",
      "Armstrong Aboah",
      "Abdulateef Daud",
      "Yaw Adu-Gyamfi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.08541"
  },
  {
    "id": "arXiv:2211.08542",
    "title": "CXTrack: Improving 3D Point Cloud Tracking with Contextual Information",
    "abstract": "3D single object tracking plays an essential role in many applications, such\nas autonomous driving. It remains a challenging problem due to the large\nappearance variation and the sparsity of points caused by occlusion and limited\nsensor capabilities. Therefore, contextual information across two consecutive\nframes is crucial for effective object tracking. However, points containing\nsuch useful information are often overlooked and cropped out in existing\nmethods, leading to insufficient use of important contextual knowledge. To\naddress this issue, we propose CXTrack, a novel transformer-based network for\n3D object tracking, which exploits ConteXtual information to improve the\ntracking results. Specifically, we design a target-centric transformer network\nthat directly takes point features from two consecutive frames and the previous\nbounding box as input to explore contextual information and implicitly\npropagate target cues. To achieve accurate localization for objects of all\nsizes, we propose a transformer-based localization head with a novel center\nembedding module to distinguish the target from distractors. Extensive\nexperiments on three large-scale datasets, KITTI, nuScenes and Waymo Open\nDataset, show that CXTrack achieves state-of-the-art tracking performance while\nrunning at 29 FPS.",
    "descriptor": "",
    "authors": [
      "Tian-Xing Xu",
      "Yuan-Chen Guo",
      "Yu-Kun Lai",
      "Song-Hai Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08542"
  },
  {
    "id": "arXiv:2211.08543",
    "title": "Demystify Self-Attention in Vision Transformers from a Semantic  Perspective: Analysis and Application",
    "abstract": "Self-attention mechanisms, especially multi-head self-attention (MSA), have\nachieved great success in many fields such as computer vision and natural\nlanguage processing. However, many existing vision transformer (ViT) works\nsimply inherent transformer designs from NLP to adapt vision tasks, while\nignoring the fundamental difference between ``how MSA works in image and\nlanguage settings''. Language naturally contains highly semantic structures\nthat are directly interpretable by humans. Its basic unit (word) is discrete\nwithout redundant information, which readily supports interpretable studies on\nMSA mechanisms of language transformer. In contrast, visual data exhibits a\nfundamentally different structure: Its basic unit (pixel) is a natural\nlow-level representation with significant redundancies in the neighbourhood,\nwhich poses obvious challenges to the interpretability of MSA mechanism in ViT.\nIn this paper, we introduce a typical image processing technique, i.e.,\nscale-invariant feature transforms (SIFTs), which maps low-level\nrepresentations into mid-level spaces, and annotates extensive discrete\nkeypoints with semantically rich information. Next, we construct a weighted\npatch interrelation analysis based on SIFT keypoints to capture the attention\npatterns hidden in patches with different semantic concentrations\nInterestingly, we find this quantitative analysis is not only an effective\ncomplement to the interpretability of MSA mechanisms in ViT, but can also be\napplied to 1) spurious correlation discovery and ``prompting'' during model\ninference, 2) and guided model pre-training acceleration. Experimental results\non both applications show significant advantages over baselines, demonstrating\nthe efficacy of our method.",
    "descriptor": "\nComments: 10 pages, 11 figures\n",
    "authors": [
      "Leijie Wu",
      "Song Guo",
      "Yaohong Ding",
      "Junxiao Wang",
      "Wenchao Xu",
      "Richard Yida Xu",
      "Jie Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08543"
  },
  {
    "id": "arXiv:2211.08544",
    "title": "Exploiting the Partly Scratch-off Lottery Ticket for Quantization-Aware  Training",
    "abstract": "Quantization-aware training (QAT) receives extensive popularity as it well\nretains the performance of quantized networks. In QAT, the contemporary\nexperience is that all quantized weights are updated for an entire training\nprocess. In this paper, this experience is challenged based on an interesting\nphenomenon we observed. Specifically, a large portion of quantized weights\nreaches the optimal quantization level after a few training epochs, which we\nrefer to as the partly scratch-off lottery ticket. This\nstraightforward-yet-valuable observation naturally inspires us to zero out\ngradient calculations of these weights in the remaining training period to\navoid meaningless updating. To effectively find the ticket, we develop a\nheuristic method, dubbed as lottery ticket scratcher (LTS), which freezes a\nweight once the distance between the full-precision one and its quantization\nlevel is smaller than a controllable threshold. Surprisingly, the proposed LTS\ntypically eliminates 30\\%-60\\% weight updating and 15\\%-30\\% FLOPs of the\nbackward pass, while still resulting on par with or even better performance\nthan the compared baseline. For example, compared with the baseline, LTS\nimproves 2-bit ResNet-18 by 1.41\\%, eliminating 56\\% weight updating and 28\\%\nFLOPs of the backward pass.",
    "descriptor": "",
    "authors": [
      "Yunshan Zhong",
      "Mingbao Lin",
      "Yuxin Zhang",
      "Gongrui Nan",
      "Fei Chao",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08544"
  },
  {
    "id": "arXiv:2211.08545",
    "title": "MapQA: A Dataset for Question Answering on Choropleth Maps",
    "abstract": "Choropleth maps are a common visual representation for region-specific\ntabular data and are used in a number of different venues (newspapers,\narticles, etc). These maps are human-readable but are often challenging to deal\nwith when trying to extract data for screen readers, analyses, or other related\ntasks. Recent research into Visual-Question Answering (VQA) has studied\nquestion answering on human-generated charts (ChartQA), such as bar, line, and\npie charts. However, little work has paid attention to understanding maps;\ngeneral VQA models, and ChartQA models, suffer when asked to perform this task.\nTo facilitate and encourage research in this area, we present MapQA, a\nlarge-scale dataset of ~800K question-answer pairs over ~60K map images. Our\ntask tests various levels of map understanding, from surface questions about\nmap styles to complex questions that require reasoning on the underlying data.\nWe present the unique challenges of MapQA that frustrate most strong baseline\nalgorithms designed for ChartQA and general VQA tasks. We also present a novel\nalgorithm, Visual Multi-Output Data Extraction based QA (V-MODEQA) for MapQA.\nV-MODEQA extracts the underlying structured data from a map image with a\nmulti-output model and then performs reasoning on the extracted data. Our\nexperimental results show that V-MODEQA has better overall performance and\nrobustness on MapQA than the state-of-the-art ChartQA and VQA algorithms by\ncapturing the unique properties in map question answering.",
    "descriptor": "",
    "authors": [
      "Shuaichen Chang",
      "David Palzer",
      "Jialin Li",
      "Eric Fosler-Lussier",
      "Ningchuan Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08545"
  },
  {
    "id": "arXiv:2211.08547",
    "title": "ALIGN-MLM: Word Embedding Alignment is Crucial for Multilingual  Pre-training",
    "abstract": "Multilingual pre-trained models exhibit zero-shot cross-lingual transfer,\nwhere a model fine-tuned on a source language achieves surprisingly good\nperformance on a target language. While studies have attempted to understand\ntransfer, they focus only on MLM, and the large number of differences between\nnatural languages makes it hard to disentangle the importance of different\nproperties. In this work, we specifically highlight the importance of word\nembedding alignment by proposing a pre-training objective (ALIGN-MLM) whose\nauxiliary loss guides similar words in different languages to have similar word\nembeddings. ALIGN-MLM either outperforms or matches three widely adopted\nobjectives (MLM, XLM, DICT-MLM) when we evaluate transfer between pairs of\nnatural languages and their counterparts created by systematically modifying\nspecific properties like the script. In particular, ALIGN-MLM outperforms XLM\nand MLM by 35 and 30 F1 points on POS-tagging for transfer between languages\nthat differ both in their script and word order (left-to-right v.s.\nright-to-left). We also show a strong correlation between alignment and\ntransfer for all objectives (e.g., rho=0.727 for XNLI), which together with\nALIGN-MLM's strong performance calls for explicitly aligning word embeddings\nfor multilingual models.",
    "descriptor": "",
    "authors": [
      "Henry Tang",
      "Ameet Deshpande",
      "Karthik Narasimhan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08547"
  },
  {
    "id": "arXiv:2211.08551",
    "title": "On the phase space of fourth-order fiber-orientation tensors",
    "abstract": "Fiber-orientation tensors describe the relevant features of the\nfiber-orientation distribution compactly and are thus ubiquitous in\ninjection-molding simulations and subsequent mechanical analyses. In\nengineering applications to date, the second-order fiber-orientation tensor is\nthe basic quantity of interest, and the fourth-order fiber-orientation tensor\nis obtained via a closure approximation. Unfortunately, such a description\nlimits the predictive capabilities of the modeling process significantly,\nbecause the wealth of possible fourth-order fiber-orientation tensors is not\nexploited by such closures, and the restriction to second-order\nfiber-orientation tensors implies artifacts. Closures based on the second-order\nfiber-orientation tensor face a fundamental problem - which fourth-order\nfiber-orientation tensors can be realized? In the literature, only necessary\nconditions for a fiber-orientation tensor to be connected to a\nfiber-orientation distribution are found. In this article, we show that the\ntypically considered necessary conditions, positive semidefiniteness and a\ntrace condition, are also sufficient for being a fourth-order fiber-orientation\ntensor in the physically relevant case of two and three spatial dimensions.\nMoreover, we show that these conditions are not sufficient in higher\ndimensions. The argument is based on convex duality and a celebrated theorem of\nD. Hilbert (1888) on the decomposability of positive and homogeneous\npolynomials of degree four. The result has numerous implications for modeling\nthe flow and the resulting microstructures of fiber-reinforced composites, in\nparticular for the effective elastic constants of such materials.",
    "descriptor": "",
    "authors": [
      "Julian Karl Bauer",
      "Matti Schneider",
      "Thomas B\u00f6hlke"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.08551"
  },
  {
    "id": "arXiv:2211.08557",
    "title": "Unsupervised Feature Clustering Improves Contrastive Representation  Learning for Medical Image Segmentation",
    "abstract": "Self-supervised instance discrimination is an effective contrastive pretext\ntask to learn feature representations and address limited medical image\nannotations. The idea is to make features of transformed versions of the same\nimages similar while forcing all other augmented images' representations to\ncontrast. However, this instance-based contrastive learning leaves performance\non the table by failing to maximize feature affinity between images with\nsimilar content while counter-productively pushing their representations apart.\nRecent improvements on this paradigm (e.g., leveraging multi-modal data,\ndifferent images in longitudinal studies, spatial correspondences) either\nrelied on additional views or made stringent assumptions about data properties,\nwhich can sacrifice generalizability and applicability. To address this\nchallenge, we propose a new self-supervised contrastive learning method that\nuses unsupervised feature clustering to better select positive and negative\nimage samples. More specifically, we produce pseudo-classes by hierarchically\nclustering features obtained by an auto-encoder in an unsupervised manner, and\nprevent destructive interference during contrastive learning by avoiding the\nselection of negatives from the same pseudo-class. Experiments on 2D skin\ndermoscopic image segmentation and 3D multi-class whole heart CT segmentation\ndemonstrate that our method outperforms state-of-the-art self-supervised\ncontrastive techniques on these tasks.",
    "descriptor": "\nComments: Accepted to 2022 IEEE International Conference on Bioinformatics and Biomedicine (BIBM'22) proceedings\n",
    "authors": [
      "Yejia Zhang",
      "Xinrong Hu",
      "Nishchal Sapkota",
      "Yiyu Shi",
      "Danny Z. Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08557"
  },
  {
    "id": "arXiv:2211.08559",
    "title": "Cross-Domain Self-Supervised Deep Learning for Robust Alzheimer's  Disease Progression Modeling",
    "abstract": "Developing successful artificial intelligence systems in practice depends\nboth on robust deep learning models as well as large high quality data.\nAcquiring and labeling data can become prohibitively expensive and\ntime-consuming in many real-world applications such as clinical disease models.\nSelf-supervised learning has demonstrated great potential in increasing model\naccuracy and robustness in small data regimes. In addition, many clinical\nimaging and disease modeling applications rely heavily on regression of\ncontinuous quantities. However, the applicability of self-supervised learning\nfor these medical-imaging regression tasks has not been extensively studied. In\nthis study, we develop a cross-domain self-supervised learning approach for\ndisease prognostic modeling as a regression problem using 3D images as input.\nWe demonstrate that self-supervised pre-training can improve the prediction of\nAlzheimer's Disease progression from brain MRI. We also show that pre-training\non extended (but not labeled) brain MRI data outperforms pre-training on\nnatural images. We further observe that the highest performance is achieved\nwhen both natural images and extended brain-MRI data are used for pre-training.",
    "descriptor": "",
    "authors": [
      "Saba Dadsetan",
      "Mohsen Hejrati",
      "Shandong Wu",
      "Somaye Hashemifar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08559"
  },
  {
    "id": "arXiv:2211.08563",
    "title": "The wrong direction of Jensen's inequality is algorithmically right",
    "abstract": "Let $\\mathcal{A}$ be an algorithm with expected running time $e^X$,\nconditioned on the value of some random variable $X$. We construct an algorithm\n$\\mathcal{A'}$ with expected running time $O(e^{E[X]})$, that fully executes\n$\\mathcal{A}$. In particular, an algorithm whose running time is a random\nvariable $T$ can be converted to one with expected running time $O(e^{E[\\ln\nT]})$, which is never worse than $O(E[T])$. No information about the\ndistribution of $X$ is required for the construction of $\\mathcal{A}'$.",
    "descriptor": "",
    "authors": [
      "Or Zamir"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.08563"
  },
  {
    "id": "arXiv:2211.08564",
    "title": "ConvFormer: Combining CNN and Transformer for Medical Image Segmentation",
    "abstract": "Convolutional neural network (CNN) based methods have achieved great\nsuccesses in medical image segmentation, but their capability to learn global\nrepresentations is still limited due to using small effective receptive fields\nof convolution operations. Transformer based methods are capable of modelling\nlong-range dependencies of information for capturing global representations,\nyet their ability to model local context is lacking. Integrating CNN and\nTransformer to learn both local and global representations while exploring\nmulti-scale features is instrumental in further improving medical image\nsegmentation. In this paper, we propose a hierarchical CNN and Transformer\nhybrid architecture, called ConvFormer, for medical image segmentation.\nConvFormer is based on several simple yet effective designs. (1) A feed forward\nmodule of Deformable Transformer (DeTrans) is re-designed to introduce local\ninformation, called Enhanced DeTrans. (2) A residual-shaped hybrid stem based\non a combination of convolutions and Enhanced DeTrans is developed to capture\nboth local and global representations to enhance representation ability. (3)\nOur encoder utilizes the residual-shaped hybrid stem in a hierarchical manner\nto generate feature maps in different scales, and an additional Enhanced\nDeTrans encoder with residual connections is built to exploit multi-scale\nfeatures with feature maps of different scales as input. Experiments on several\ndatasets show that our ConvFormer, trained from scratch, outperforms various\nCNN- or Transformer-based architectures, achieving state-of-the-art\nperformance.",
    "descriptor": "",
    "authors": [
      "Pengfei Gu",
      "Yejia Zhang",
      "Chaoli Wang",
      "Danny Z. Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08564"
  },
  {
    "id": "arXiv:2211.08565",
    "title": "Using Auxiliary Information for Person Re-Identification -- A Tutorial  Overview",
    "abstract": "Person re-identification (re-id) is a pivotal task within an intelligent\nsurveillance pipeline and there exist numerous re-id frameworks that achieve\nsatisfactory performance in challenging benchmarks. However, these systems\nstruggle to generate acceptable results when there are significant differences\nbetween the camera views, illumination conditions, or occlusions. This result\ncan be attributed to the deficiency that exists within many recently proposed\nre-id pipelines where they are predominately driven by appearance-based\nfeatures and little attention is paid to other auxiliary information that could\naid the re-id. In this paper, we systematically review the current\nState-Of-The-Art (SOTA) methods in both uni-modal and multimodal person re-id.\nExtending beyond a conceptual framework, we illustrate how the existing SOTA\nmethods can be extended to support these additional auxiliary information and\nquantitatively evaluate the utility of such auxiliary feature information,\nranging from logos printed on the objects carried by the subject or printed on\nthe clothes worn by the subject, through to his or her behavioural\ntrajectories. To the best of our knowledge, this is the first work that\nexplores the fusion of multiple information to generate a more discriminant\nperson descriptor and the principal aim of this paper is to provide a thorough\ntheoretical analysis regarding the implementation of such a framework. In\naddition, using model interpretation techniques, we validate the contributions\nfrom different combinations of the auxiliary information versus the original\nfeatures that the SOTA person re-id models extract. We outline the limitations\nof the proposed approaches and propose future research directions that could be\npursued to advance the area of multi-modal person re-id.",
    "descriptor": "\nComments: Preprint Submitted to Pattern Recognition\n",
    "authors": [
      "Tharindu Fernando",
      "Clinton Fookes",
      "Sridha Sridharan",
      "Dana Michalski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08565"
  },
  {
    "id": "arXiv:2211.08568",
    "title": "Graph Sequential Neural ODE Process for Link Prediction on Dynamic and  Sparse Graphs",
    "abstract": "Link prediction on dynamic graphs is an important task in graph mining.\nExisting approaches based on dynamic graph neural networks (DGNNs) typically\nrequire a significant amount of historical data (interactions over time), which\nis not always available in practice. The missing links over time, which is a\ncommon phenomenon in graph data, further aggravates the issue and thus creates\nextremely sparse and dynamic graphs. To address this problem, we propose a\nnovel method based on the neural process, called Graph Sequential Neural ODE\nProcess (GSNOP). Specifically, GSNOP combines the advantage of the neural\nprocess and neural ordinary differential equation that models the link\nprediction on dynamic graphs as a dynamic-changing stochastic process. By\ndefining a distribution over functions, GSNOP introduces the uncertainty into\nthe predictions, making it generalize to more situations instead of overfitting\nto the sparse data. GSNOP is also agnostic to model structures that can be\nintegrated with any DGNN to consider the chronological and geometrical\ninformation for link prediction. Extensive experiments on three dynamic graph\ndatasets show that GSNOP can significantly improve the performance of existing\nDGNNs and outperform other neural process variants.",
    "descriptor": "\nComments: Accepted by WSDM2023\n",
    "authors": [
      "Linhao Luo",
      "Reza Haffari",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.08568"
  },
  {
    "id": "arXiv:2211.08570",
    "title": "Dynamic-Pix2Pix: Noise Injected cGAN for Modeling Input and Target  Domain Joint Distributions with Limited Training Data",
    "abstract": "Learning to translate images from a source to a target domain with\napplications such as converting simple line drawing to oil painting has\nattracted significant attention. The quality of translated images is directly\nrelated to two crucial issues. First, the consistency of the output\ndistribution with that of the target is essential. Second, the generated output\nshould have a high correlation with the input. Conditional Generative\nAdversarial Networks, cGANs, are the most common models for translating images.\nThe performance of a cGAN drops when we use a limited training dataset. In this\nwork, we increase the Pix2Pix (a form of cGAN) target distribution modeling\nability with the help of dynamic neural network theory. Our model has two\nlearning cycles. The model learns the correlation between input and ground\ntruth in the first cycle. Then, the model's architecture is refined in the\nsecond cycle to learn the target distribution from noise input. These processes\nare executed in each iteration of the training procedure. Helping the cGAN\nlearn the target distribution from noise input results in a better model\ngeneralization during the test time and allows the model to fit almost\nperfectly to the target domain distribution. As a result, our model surpasses\nthe Pix2Pix model in segmenting HC18 and Montgomery's chest x-ray images. Both\nqualitative and Dice scores show the superiority of our model. Although our\nproposed method does not use thousand of additional data for pretraining, it\nproduces comparable results for the in and out-domain generalization compared\nto the state-of-the-art methods.",
    "descriptor": "\nComments: 15 pages, 7 figures\n",
    "authors": [
      "Mohammadreza Naderi",
      "Nader Karimi",
      "Ali Emami",
      "Shahram Shirani",
      "Shadrokh Samavi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08570"
  },
  {
    "id": "arXiv:2211.08572",
    "title": "Bayesian Fixed-Budget Best-Arm Identification",
    "abstract": "Fixed-budget best-arm identification (BAI) is a bandit problem where the\nlearning agent maximizes the probability of identifying the optimal arm after a\nfixed number of observations. In this work, we initiate the study of this\nproblem in the Bayesian setting. We propose a Bayesian elimination algorithm\nand derive an upper bound on the probability that it fails to identify the\noptimal arm. The bound reflects the quality of the prior and is the first such\nbound in this setting. We prove it using a frequentist-like argument, where we\ncarry the prior through, and then integrate out the random bandit instance at\nthe end. Our upper bound asymptotically matches a newly established lower bound\nfor $2$ arms. Our experimental results show that Bayesian elimination is\nsuperior to frequentist methods and competitive with the state-of-the-art\nBayesian algorithms that have no guarantees in our setting.",
    "descriptor": "",
    "authors": [
      "Alexia Atsidakou",
      "Sumeet Katariya",
      "Sujay Sanghavi",
      "Branislav Kveton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.08572"
  },
  {
    "id": "arXiv:2211.08573",
    "title": "Realization of Causal Representation Learning to Adjust Confounding Bias  in Latent Space",
    "abstract": "Applying Deep Learning (DL) models to graphical causal learning has brought\noutstanding effectiveness and efficiency but is still far from widespread use\nin domain sciences. In research of EHR (Electronic Healthcare Records), we\nrealize that some confounding bias inherently exists in the causally formed\ndata, which DL cannot automatically adjust. Trace to the source is because the\nAcyclic Causal Graph can be Multi-Dimensional, so the bias and causal learning\nhappen in two subspaces, which makes it unobservable from the learning process.\nThis paper initially raises the concept of Dimensionality for causal graphs.\nIn our case, the 3-Dimensional DAG (Directed Acyclic Graph) space is defined by\nthe axes of causal variables, the Absolute timeline, and Relative timelines;\nThis is also the essential difference between Causality and Correlation\nproblems.\nWe propose a novel new framework Causal Representation Learning (CRL), to\nrealize Graphical Causal Learning in latent space, which aims to provide\ngeneral solutions for 1) the inherent bias adjustment and 2) the DL causal\nmodels generalization problem. We will also demonstrate the realization of CRL\nwith originally designed architecture and experimentally confirm its\nfeasibility.",
    "descriptor": "",
    "authors": [
      "Jia Li",
      "Xiang Li",
      "Xiaowei Jia",
      "Michael Steinbach",
      "Vipin Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.08573"
  },
  {
    "id": "arXiv:2211.08577",
    "title": "DCT Perceptron Layer: A Transform Domain Approach for Convolution Layer",
    "abstract": "In this paper, we propose a novel Discrete Cosine Transform (DCT)-based\nneural network layer which we call DCT-perceptron to replace the $3\\times3$\nConv2D layers in the Residual neural Network (ResNet). Convolutional filtering\noperations are performed in the DCT domain using element-wise multiplications\nby taking advantage of the Fourier and DCT Convolution theorems. A trainable\nsoft-thresholding layer is used as the nonlinearity in the DCT perceptron.\nCompared to ResNet's Conv2D layer which is spatial-agnostic and\nchannel-specific, the proposed layer is location-specific and channel-specific.\nThe DCT-perceptron layer reduces the number of parameters and multiplications\nsignificantly while maintaining comparable accuracy results of regular ResNets\nin CIFAR-10 and ImageNet-1K. Moreover, the DCT-perceptron layer can be inserted\nwith a batch normalization layer before the global average pooling layer in the\nconventional ResNets as an additional layer to improve classification accuracy.",
    "descriptor": "",
    "authors": [
      "Hongyi Pan",
      "Xin Zhu",
      "Salih Atici",
      "Ahmet Enis Cetin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.08577"
  },
  {
    "id": "arXiv:2211.08583",
    "title": "Empirical Study on Optimizer Selection for Out-of-Distribution  Generalization",
    "abstract": "Modern deep learning systems are fragile and do not generalize well under\ndistribution shifts. While much promising work has been accomplished to address\nthese concerns, a systematic study of the role of optimizers and their\nout-of-distribution generalization performance has not been undertaken. In this\nstudy, we examine the performance of popular first-order optimizers for\ndifferent classes of distributional shift under empirical risk minimization and\ninvariant risk minimization. We address the problem settings for image and text\nclassification using DomainBed, WILDS, and Backgrounds Challenge as\nout-of-distribution datasets for the exhaustive study. We search over a wide\nrange of hyperparameters and examine the classification accuracy\n(in-distribution and out-of-distribution) for over 20,000 models. We arrive at\nthe following findings: i) contrary to conventional wisdom, adaptive optimizers\n(e.g., Adam) perform worse than non-adaptive optimizers (e.g., SGD,\nmomentum-based SGD), ii) in-distribution performance and out-of-distribution\nperformance exhibit three types of behavior depending on the dataset - linear\nreturns, increasing returns, and diminishing returns. We believe these findings\ncan help practitioners choose the right optimizer and know what behavior to\nexpect.",
    "descriptor": "\nComments: NeurIPS2022 Workshop on Distribution Shifts (DistShift)\n",
    "authors": [
      "Hiroki Naganuma",
      "Kartik Ahuja",
      "Ioannis Mitliagkas",
      "Shiro Takagi",
      "Tetsuya Motokawa",
      "Rio Yokota",
      "Kohta Ishikawa",
      "Ikuro Sato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08583"
  },
  {
    "id": "arXiv:2211.08584",
    "title": "Toward expanding the scope of radiology report summarization to multiple  anatomies and modalities",
    "abstract": "Radiology report summarization is a growing area of research. Given the\nFindings and/or Background sections of a radiology report, the goal is to\ngenerate a summary (called an Impression section) that highlights the key\nobservations and conclusions of the radiology study. Recent efforts have\nreleased systems that achieve promising performance as measured by widely used\nsummarization metrics such as BLEU and ROUGE. However, the research area of\nradiology report summarization currently faces important limitations. First,\nmost of the results are reported on private datasets. This limitation prevents\nthe ability to reproduce results and fairly compare different systems and\nsolutions. Secondly, to the best of our knowledge, most research is carried out\non chest X-rays. Sometimes, studies even omit to mention the concerned modality\nand anatomy in the radiology reports used for their experiments. To palliate\nthese limitations, we propose a new dataset of six different modalities and\nanatomies based on the MIMIC-III database. We further release our results and\nthe data splits used to carry out our experiments. Finally, we propose a simple\nreport summarization system that outperforms the previous replicable research\non the existing dataset.",
    "descriptor": "\nComments: Machine Learning For Health (ML4H)\n",
    "authors": [
      "Jean-Benoit Delbrouck",
      "Maya Varma",
      "Curtis P. Langlotz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08584"
  },
  {
    "id": "arXiv:2211.08585",
    "title": "Cyrus2D base: Source Code Base for RoboCup 2D Soccer Simulation League",
    "abstract": "Soccer Simulation 2D League is one of the major leagues of RoboCup\ncompetitions. In a Soccer Simulation 2D (SS2D) game, two teams of 11 players\nand one coach compete against each other. Several base codes have been released\nfor the RoboCup soccer simulation 2D (RCSS2D) community that have promoted the\napplication of multi-agent and AI algorithms in this field. In this paper, we\nintroduce \"Cyrus2D Base\", which is derived from the base code of the RCSS2D\n2021 champion. We merged Gliders2D base V2.6 with the newest version of the\nHelios base. We applied several features of Cyrus2021 to improve the\nperformance and capabilities of this base alongside a Data Extractor to\nfacilitate the implementation of machine learning in the field. We have tested\nthis base code in different teams and scenarios, and the obtained results\ndemonstrate significant improvements in the defensive and offensive strategy of\nthe team.",
    "descriptor": "",
    "authors": [
      "Nader Zare",
      "Omid Amini",
      "Aref Sayareh",
      "Mahtab Sarvmaili",
      "Arad Firouzkouhi",
      "Saba Ramezani Rad",
      "Stan Matwin",
      "Amilcar Soares"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.08585"
  },
  {
    "id": "arXiv:2211.08586",
    "title": "Bandit Algorithms for Prophet Inequality and Pandora's Box",
    "abstract": "The Prophet Inequality and Pandora's Box problems are fundamental stochastic\nproblem with applications in Mechanism Design, Online Algorithms, Stochastic\nOptimization, Optimal Stopping, and Operations Research. A usual assumption in\nthese works is that the probability distributions of the $n$ underlying random\nvariables are given as input to the algorithm. Since in practice these\ndistributions need to be learned, we initiate the study of such stochastic\nproblems in the Multi-Armed Bandits model.\nIn the Multi-Armed Bandits model we interact with $n$ unknown distributions\nover $T$ rounds: in round $t$ we play a policy $x^{(t)}$ and receive a partial\n(bandit) feedback on the performance of $x^{(t)}$. The goal is to minimize the\nregret, which is the difference over $T$ rounds in the total value of the\noptimal algorithm that knows the distributions vs. the total value of our\nalgorithm that learns the distributions from the partial feedback. Our main\nresults give near-optimal $\\tilde{O}(\\mathsf{poly}(n)\\sqrt{T})$ total regret\nalgorithms for both Prophet Inequality and Pandora's Box.\nOur proofs proceed by maintaining confidence intervals on the unknown indices\nof the optimal policy. The exploration-exploitation tradeoff prevents us from\ndirectly refining these confidence intervals, so the main technique is to\ndesign a regret upper bound that is learnable while playing low-regret Bandit\npolicies.",
    "descriptor": "",
    "authors": [
      "Khashayar Gatmiry",
      "Thomas Kesselheim",
      "Sahil Singla",
      "Yifan Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08586"
  },
  {
    "id": "arXiv:2211.08588",
    "title": "Disentangling Task Relations for Few-shot Text Classification via  Self-Supervised Hierarchical Task Clustering",
    "abstract": "Few-Shot Text Classification (FSTC) imitates humans to learn a new text\nclassifier efficiently with only few examples, by leveraging prior knowledge\nfrom historical tasks. However, most prior works assume that all the tasks are\nsampled from a single data source, which cannot adapt to real-world scenarios\nwhere tasks are heterogeneous and lie in different distributions. As such,\nexisting methods may suffer from their globally knowledge-shared mechanisms to\nhandle the task heterogeneity. On the other hand, inherent task relation are\nnot explicitly captured, making task knowledge unorganized and hard to transfer\nto new tasks. Thus, we explore a new FSTC setting where tasks can come from a\ndiverse range of data sources. To address the task heterogeneity, we propose a\nself-supervised hierarchical task clustering (SS-HTC) method. SS-HTC not only\ncustomizes cluster-specific knowledge by dynamically organizing heterogeneous\ntasks into different clusters in hierarchical levels but also disentangles\nunderlying relations between tasks to improve the interpretability. Extensive\nexperiments on five public FSTC benchmark datasets demonstrate the\neffectiveness of SS-HTC.",
    "descriptor": "",
    "authors": [
      "Juan Zha",
      "Zheng Li",
      "Ying Wei",
      "Yu Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08588"
  },
  {
    "id": "arXiv:2211.08593",
    "title": "Composite Consensus-Building Process: Permissible Meeting Analysis and  Compromise Choice Exploration",
    "abstract": "In solving today's social issues, it is necessary to determine solutions that\nare acceptable to all stakeholders and collaborate to apply them. The\nconventional technology of \"permissive meeting analysis\" derives a\nconsensusable choice that falls within everyone's permissible range through\nmathematical analyses; however, it tends to be biased toward the majority in a\ngroup, making it difficult to reach a consensus when a conflict arises. To\nsupport consensus building (defined here as an acceptable compromise that not\neveryone rejects), we developed a composite consensus-building process. The\ndeveloped process addresses this issue by combining permissible meeting\nanalysis with a new \"compromise choice-exploration\" technology, which presents\na consensusable choice that emphasizes fairness and equality among everyone\nwhen permissible meeting analysis fails to do so. When both permissible meeting\nanalysis and compromise choice exploration do not arrive at a consensus, a\nfacility is provided to create a sublated choice among those provided by them.\nThe trial experimental results confirmed that permissive meeting analysis and\ncompromise choice exploration are sufficiently useful for deriving\nconsensusable choices. Furthermore, we found that compromise choice exploration\nis characterized by its ability to derive choices that control the balance\nbetween compromise and fairness. Our proposed composite consensus-building\napproach could be applied in a wide range of situations, from local issues in\nmunicipalities and communities to international issues such as environmental\nprotection and human rights issues. It could also aid in developing digital\ndemocracy and platform cooperativism.",
    "descriptor": "\nComments: 21 pages, 4 figures, 9 tables\n",
    "authors": [
      "Yasuhiro Asa",
      "Takeshi Kato",
      "Ryuji Mine"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2211.08593"
  },
  {
    "id": "arXiv:2211.08594",
    "title": "Orthogonal Polynomials Quadrature Algorithm (OPQA): A Functional  Analytical Approach to Bayesian Inference",
    "abstract": "In this paper, we present the new Orthogonal Polynomials-Quadrature Algorithm\n(OPQA), a parallelizable algorithm that estimates both the posterior and the\nevidence in a Bayesian analysis in one pass by means of a functional analytic\napproach. First, OPQA relates the evidence to an orthogonal projection onto a\nspecial basis of our construct. Second, it lays out a fast and accurate\ncomputational scheme to compute the transform coefficients.\nOPQA can be summarized as follows. First, we consider the $L^2$ space\nassociated with a measure with exponential weights. Then we constuct a\nmultivariate orthogonal basis which is dense in this space, such density being\nguaranteed by the Riesz's Theorem. As we project the square root of the joint\ndistribution onto this basis of our choice, the density of the basis allows us\nto invoke the Parseval Identity, which equates the evidence with the sum of\nsquares of the transform coefficients of this orthogonal projection. To compute\nthose transform coefficients, we propose a computational scheme using\nGauss-Hermite quadrature in higher dimensions. Not only does this approach\navoids the potential high variance problem associated with random sampling\nmethods, it significantly reduces the complexity of the computation and enables\none to speed up the computational speed by parallelization.\nThis new algorithm does not make any assumption about the independence of the\nlatent variable, nor do we assume any knowledge of the prior. It solves for\nboth the evidence and the posterior in one pass. An outline of the theoretical\nproof of the supporting algorithm will be provided.",
    "descriptor": "",
    "authors": [
      "Lilian Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.08594"
  },
  {
    "id": "arXiv:2211.08599",
    "title": "Camera simulation for robot simulation: how important are various camera  model components?",
    "abstract": "Modeling cameras for the simulation of autonomous robotics is critical for\ngenerating synthetic images with appropriate realism to effectively evaluate a\nperception algorithm in simulation. In many cases though, simulated images are\nproduced by traditional rendering techniques that exclude or superficially\nhandle processing steps and aspects encountered in the actual camera pipeline.\nThe purpose of this contribution is to quantify the degree to which the\nexclusion from the camera model of various image generation steps or aspects\naffect the sim-to-real gap in robotics. We investigate what happens if one\nignores aspects tied to processes from within the physical camera, e.g., lens\ndistortion, noise, and signal processing; scene effects, e.g., lighting and\nreflection; and rendering quality. The results of the study demonstrate,\nquantitatively, that large-scale changes to color, scene, and location have far\ngreater impact than model aspects concerned with local, feature-level\nartifacts. Moreover, we show that these scene-level aspects can stem from lens\ndistortion and signal processing, particularly when considering white-balance\nand auto-exposure modeling.",
    "descriptor": "\nComments: 11 pages, 28 figures\n",
    "authors": [
      "Asher Elmquist",
      "Radu Serban",
      "Dan Negrut"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.08599"
  },
  {
    "id": "arXiv:2211.08603",
    "title": "Asynchronous Bayesian Learning over a Network",
    "abstract": "We present a practical asynchronous data fusion model for networked agents to\nperform distributed Bayesian learning without sharing raw data. Our algorithm\nuses a gossip-based approach where pairs of randomly selected agents employ\nunadjusted Langevin dynamics for parameter sampling. We also introduce an\nevent-triggered mechanism to further reduce communication between gossiping\nagents. These mechanisms drastically reduce communication overhead and help\navoid bottlenecks commonly experienced with distributed algorithms. In\naddition, the reduced link utilization by the algorithm is expected to increase\nresiliency to occasional link failure. We establish mathematical guarantees for\nour algorithm and demonstrate its effectiveness via numerical experiments.",
    "descriptor": "",
    "authors": [
      "Kinjal Bhar",
      "He Bai",
      "Jemin George",
      "Carl Busart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.08603"
  },
  {
    "id": "arXiv:2211.08604",
    "title": "PU GNN: Chargeback Fraud Detection in P2E MMORPGs via Graph Attention  Networks with Imbalanced PU Labels",
    "abstract": "The recent advent of play-to-earn (P2E) systems in massively multiplayer\nonline role-playing games (MMORPGs) has made in-game goods interchangeable with\nreal-world values more than ever before. The goods in the P2E MMORPGs can be\ndirectly exchanged with cryptocurrencies such as Bitcoin, Ethereum, or Klaytn\nvia blockchain networks. Unlike traditional in-game goods, once they had been\nwritten to the blockchains, P2E goods cannot be restored by the game operation\nteams even with chargeback fraud such as payment fraud, cancellation, or\nrefund. To tackle the problem, we propose a novel chargeback fraud prediction\nmethod, PU GNN, which leverages graph attention networks with PU loss to\ncapture both the players' in-game behavior with P2E token transaction patterns.\nWith the adoption of modified GraphSMOTE, the proposed model handles the\nimbalanced distribution of labels in chargeback fraud datasets. The conducted\nexperiments on two real-world P2E MMORPG datasets demonstrate that PU GNN\nachieves superior performances over previously suggested methods.",
    "descriptor": "\nComments: Under Review, Industry Track\n",
    "authors": [
      "Jiho Choi",
      "Junghoon Park",
      "Woocheol Kim",
      "Jin-Hyeok Park",
      "Yumin Suh",
      "Minchang Sung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.08604"
  },
  {
    "id": "arXiv:2211.08605",
    "title": "A Dichotomy Theorem for Linear Time Homomorphism Orbit Counting in  Bounded Degeneracy Graphs",
    "abstract": "Counting the number of homomorphisms of a pattern graph H in a large input\ngraph G is a fundamental problem in computer science. There are myriad\napplications of this problem in databases, graph algorithms, and network\nscience. Often, we need more than just the total count. Especially in large\nnetwork analysis, we wish to compute, for each vertex v of G, the number of\nH-homomorphisms that v participates in. This problem is referred to as\nhomomorphism orbit counting, as it relates to the orbits of vertices of H under\nits automorphisms.\nGiven the need for fast algorithms for this problem, we study when\nnear-linear time algorithms are possible. A natural restriction is to assume\nthat the input graph G has bounded degeneracy, a commonly observed property in\nmodern massive networks. Can we characterize the patterns H for which\nhomomorphism orbit counting can be done in linear time?\nWe discover a dichotomy theorem that resolves this problem. For pattern H,\nlet l be the length of the longest induced path between any two vertices of the\nsame orbit (under the automorphisms of H). If l <= 5, then H-homomorphism orbit\ncounting can be done in linear time for bounded degeneracy graphs. If l > 5,\nthen (assuming fine-grained complexity conjectures) there is no near-linear\ntime algorithm for this problem. We build on existing work on dichotomy\ntheorems for counting the total H-homomorphism count. Somewhat surprisingly,\nthere exist (and we characterize) patterns H for which the total homomorphism\ncount can be computed in linear time, but the corresponding orbit counting\nproblem cannot be done in near-linear time.",
    "descriptor": "",
    "authors": [
      "Daniel Paul-Pena",
      "C. Seshadhri"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.08605"
  },
  {
    "id": "arXiv:2211.08608",
    "title": "LightDepth: A Resource Efficient Depth Estimation Approach for Dealing  with Ground Truth Sparsity via Curriculum Learning",
    "abstract": "Advances in neural networks enable tackling complex computer vision tasks\nsuch as depth estimation of outdoor scenes at unprecedented accuracy. Promising\nresearch has been done on depth estimation. However, current efforts are\ncomputationally resource-intensive and do not consider the resource constraints\nof autonomous devices, such as robots and drones. In this work, we present a\nfast and battery-efficient approach for depth estimation. Our approach devises\nmodel-agnostic curriculum-based learning for depth estimation. Our experiments\nshow that the accuracy of our model performs on par with the state-of-the-art\nmodels, while its response time outperforms other models by 71%. All codes are\navailable online at https://github.com/fatemehkarimii/LightDepth.",
    "descriptor": "\nComments: 13 pages, 4 figures\n",
    "authors": [
      "Fatemeh Karimi",
      "Amir Mehrpanah",
      "Reza Rawassizadeh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08608"
  },
  {
    "id": "arXiv:2211.08609",
    "title": "R-Pred: Two-Stage Motion Prediction Via Tube-Query Attention-Based  Trajectory Refinement",
    "abstract": "Predicting the future motion of dynamic agents is of paramount importance to\nensure safety or assess risks in motion planning for autonomous robots. In this\npaper, we propose a two-stage motion prediction method, referred to as R-Pred,\nthat effectively utilizes both the scene and interaction context using a\ncascade of the initial trajectory proposal network and the trajectory\nrefinement network. The initial trajectory proposal network produces M\ntrajectory proposals corresponding to M modes of a future trajectory\ndistribution. The trajectory refinement network enhances each of M proposals\nusing 1) the tube-query scene attention (TQSA) and 2) the proposal-level\ninteraction attention (PIA). TQSA uses tube-queries to aggregate the local\nscene context features pooled from proximity around the trajectory proposals of\ninterest. PIA further enhances the trajectory proposals by modeling inter-agent\ninteractions using a group of trajectory proposals selected based on their\ndistances from neighboring agents. Our experiments conducted on the Argoverse\nand nuScenes datasets demonstrate that the proposed refinement network provides\nsignificant performance improvements compared to the single-stage baseline and\nthat R-Pred achieves state-of-the-art performance in some categories of the\nbenchmark.",
    "descriptor": "",
    "authors": [
      "Sehwan Choi",
      "Jungho Kim",
      "Junyong Yun",
      "Jun Won Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08609"
  },
  {
    "id": "arXiv:2211.08610",
    "title": "CoNFies: Controllable Neural Face Avatars",
    "abstract": "Neural Radiance Fields (NeRF) are compelling techniques for modeling dynamic\n3D scenes from 2D image collections. These volumetric representations would be\nwell suited for synthesizing novel facial expressions but for two problems.\nFirst, deformable NeRFs are object agnostic and model holistic movement of the\nscene: they can replay how the motion changes over time, but they cannot alter\nit in an interpretable way. Second, controllable volumetric representations\ntypically require either time-consuming manual annotations or 3D supervision to\nprovide semantic meaning to the scene. We propose a controllable neural\nrepresentation for face self-portraits (CoNFies), that solves both of these\nproblems within a common framework, and it can rely on automated processing. We\nuse automated facial action recognition (AFAR) to characterize facial\nexpressions as a combination of action units (AU) and their intensities. AUs\nprovide both the semantic locations and control labels for the system. CoNFies\noutperformed competing methods for novel view and expression synthesis in terms\nof visual and anatomic fidelity of expressions.",
    "descriptor": "\nComments: accepted by FG2023\n",
    "authors": [
      "Heng Yu",
      "Koichiro Niinuma",
      "Laszlo A. Jeni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08610"
  },
  {
    "id": "arXiv:2211.08614",
    "title": "H2-Golden-Retriever: Methodology and Tool for an Evidence-Based Hydrogen  Research Grantsmanship",
    "abstract": "Hydrogen is poised to play a major role in decarbonizing the economy. The\nneed to discover, develop, and understand low-cost, high-performance, durable\nmaterials that can help maximize the cost of electrolysis as well as the need\nfor an intelligent tool to make evidence-based Hydrogen research funding\ndecisions relatively easier warranted this study.In this work, we developed H2\nGolden Retriever (H2GR) system for Hydrogen knowledge discovery and\nrepresentation using Natural Language Processing (NLP), Knowledge Graph and\nDecision Intelligence. This system represents a novel methodology encapsulating\nstate-of-the-art technique for evidence-based research grantmanship. Relevant\nHydrogen papers were scraped and indexed from the web and preprocessing was\ndone using noise and stop-words removal, language and spell check, stemming and\nlemmatization. The NLP tasks included Named Entity Recognition using Stanford\nand Spacy NER, topic modeling using Latent Dirichlet Allocation and TF-IDF. The\nKnowledge Graph module was used for the generation of meaningful entities and\ntheir relationships, trends and patterns in relevant H2 papers, thanks to an\nontology of the hydrogen production domain. The Decision Intelligence component\nprovides stakeholders with a simulation environment for cost and quantity\ndependencies. PageRank algorithm was used to rank papers of interest. Random\nsearches were made on the proposed H2GR and the results included a list of\npapers ranked by relevancy score, entities, graphs of relationships between the\nentities, ontology of H2 production and Causal Decision Diagrams showing\ncomponent interactivity. Qualitative assessment was done by the experts and\nH2GR is deemed to function to a satisfactory level.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Paul Seurin",
      "Olusola Olabanjo",
      "Joseph Wiggins",
      "Lorien Pratt",
      "Loveneesh Rana",
      "Rozhin Yasaei",
      "Gregory Renard"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.08614"
  },
  {
    "id": "arXiv:2211.08615",
    "title": "GLFF: Global and Local Feature Fusion for Face Forgery Detection",
    "abstract": "With the rapid development of the deep generative models (such as Generative\nAdversarial Networks and Auto-encoders), AI-synthesized images of human face\nare now of such high qualities that humans can hardly distinguish them from\npristine ones. Although existing detection methods have shown high performance\nin specific evaluation settings, e.g., on images from seen models or on images\nwithout real-world post-processings, they tend to suffer serious performance\ndegradation in real-world scenarios where testing images can be generated by\nmore powerful generation models or combined with various post-processing\noperations. To address this issue, we propose a Global and Local Feature Fusion\n(GLFF) to learn rich and discriminative representations by combining\nmulti-scale global features from the whole image with refined local features\nfrom informative patches for face forgery detection. GLFF fuses information\nfrom two branches: global branch to extract multi-scale semantic features and\nlocal branch to select informative patches for detailed local artifacts\nextraction. Due to the lack of face forgery dataset simulating real-world\napplications for evaluation, we further create a challenging face forgery\ndataset, named DeepFakeFaceForensics (DF$^3$), which contains 6\nstate-of-the-art generation models and a variety of post-processing techniques\nto approach the real-world scenarios. Experimental results demonstrate the\nsuperiority of our method to the state-of-the-art methods on the proposed DF^3\ndataset and three other open-source datasets.",
    "descriptor": "",
    "authors": [
      "Yan Ju",
      "Shan Jia",
      "Jialing Cai",
      "Haiying Guan",
      "Siwei Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08615"
  },
  {
    "id": "arXiv:2211.08622",
    "title": "Impact of Redundancy on Resilience in Distributed Optimization and  Learning",
    "abstract": "This report considers the problem of resilient distributed optimization and\nstochastic learning in a server-based architecture. The system comprises a\nserver and multiple agents, where each agent has its own local cost function.\nThe agents collaborate with the server to find a minimum of the aggregate of\nthe local cost functions. In the context of stochastic learning, the local cost\nof an agent is the loss function computed over the data at that agent. In this\nreport, we consider this problem in a system wherein some of the agents may be\nByzantine faulty and some of the agents may be slow (also called stragglers).\nIn this setting, we investigate the conditions under which it is possible to\nobtain an \"approximate\" solution to the above problem. In particular, we\nintroduce the notion of $(f, r; \\epsilon)$-resilience to characterize how well\nthe true solution is approximated in the presence of up to $f$ Byzantine faulty\nagents, and up to $r$ slow agents (or stragglers) -- smaller $\\epsilon$\nrepresents a better approximation. We also introduce a measure named $(f, r;\n\\epsilon)$-redundancy to characterize the redundancy in the cost functions of\nthe agents. Greater redundancy allows for a better approximation when solving\nthe problem of aggregate cost minimization.\nIn this report, we constructively show (both theoretically and empirically)\nthat $(f, r; \\mathcal{O}(\\epsilon))$-resilience can indeed be achieved in\npractice, given that the local cost functions are sufficiently redundant.",
    "descriptor": "\nComments: 49 pages, 2 figures, 1 table. arXiv admin note: substantial text overlap with arXiv:2110.10858, arXiv:2106.03998\n",
    "authors": [
      "Shuo Liu",
      "Nirupam Gupta",
      "Nitin H. Vaidya"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08622"
  },
  {
    "id": "arXiv:2211.08624",
    "title": "Leveraging Heteroscedastic Uncertainty in Learning Complex Spectral  Mapping for Single-channel Speech Enhancement",
    "abstract": "Most speech enhancement (SE) models learn a point estimate, and do not make\nuse of uncertainty estimation in the learning process. In this paper, we show\nthat modeling heteroscedastic uncertainty by minimizing a multivariate Gaussian\nnegative log-likelihood (NLL) improves SE performance at no extra cost. During\ntraining, our approach augments a model learning complex spectral mapping with\na temporary submodel to predict the covariance of the enhancement error at each\ntime-frequency bin. Due to unrestricted heteroscedastic uncertainty, the\ncovariance introduces an undersampling effect, detrimental to SE performance.\nTo mitigate undersampling, our approach inflates the uncertainty lower bound\nand weights each loss component with their uncertainty, effectively\ncompensating severely undersampled components with more penalties. Our\nmultivariate setting reveals common covariance assumptions such as scalar and\ndiagonal matrices. By weakening these assumptions, we show that the NLL\nachieves superior performance compared to popular losses including the mean\nsquared error (MSE), mean absolute error (MAE), and scale-invariant\nsignal-to-distortion ratio (SI-SDR).",
    "descriptor": "\nComments: 5 pages. Submitted to ICASSP 2023\n",
    "authors": [
      "Kuan-Lin Chen",
      "Daniel D. E. Wong",
      "Ke Tan",
      "Buye Xu",
      "Anurag Kumar",
      "Vamsi Krishna Ithapu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.08624"
  },
  {
    "id": "arXiv:2211.08626",
    "title": "Wireless Communication Using Metal Reflectors: Reflection Modelling and  Experimental Verification",
    "abstract": "Wireless communication using fully passive metal reflectors is a promising\ntechnique for coverage expansion, signal enhancement, rank improvement and\nblind-zone compensation, thanks to its appealing features including zero energy\nconsumption, ultra low cost, signaling- and maintenance-free, easy deployment\nand full compatibility with existing and future wireless systems. However, a\nprevalent understanding for reflection by metal plates is based on Snell's Law,\ni.e., signal can only be received when the observation angle equals to the\nincident angle, which is valid only when the electrical dimension of the metal\nplate is extremely large. In this paper, we rigorously derive a general\nreflection model that is applicable to metal reflectors of any size, any\norientation, and any linear polarization. The derived model is given compactly\nin terms of the radar cross section (RCS) of the metal plate, as a function of\nits physical dimensions and orientation vectors, as well as the wave\npolarization and the wave deflection vector, i.e., the change of direction from\nthe incident wave direction to the observation direction. Furthermore,\nexperimental results based on actual field measurements are provided to\nvalidate the accuracy of our developed model and demonstrate the great\npotential of communications using metal reflectors.",
    "descriptor": "",
    "authors": [
      "Zhi Yu",
      "Chao Feng",
      "Yong Zeng",
      "Teng Li",
      "Shi Jin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.08626"
  },
  {
    "id": "arXiv:2211.08628",
    "title": "Longitudinal Analysis of Heart Rate and Physical Activity Collected from  Smartwatches",
    "abstract": "Smartwatches (SWs) can continuously and autonomously monitor vital signs,\nincluding heart rates and physical activities involving wrist movement. The\nmonitoring capability of SWs has several key health benefits arising from their\nrole in preventive and diagnostic medicine. Current research, however, has not\nexplored many of these opportunities, including longitudinal studies. In our\nwork, we gathered longitudinal data points, e.g., heart rate and physical\nactivity, from various brands of SWs worn by 1,014 users. Our analysis shows\nthree common heart rate patterns during sleep but two common patterns during\nthe day. We find that heart rate and physical activities are higher in summer\nand the first month of the new year compared to other months. Moreover,\nphysical activities are reduced on weekends compared with weekdays.\nInterestingly, the highest peak of physical activity is during the evening.",
    "descriptor": "\nComments: 22 pages, 13 figures\n",
    "authors": [
      "Fatemeh Karimi",
      "Zohre Amoozgar",
      "Reza Reiazi",
      "Mehdi Hosseinzadeh",
      "Reza Rawassizadeh"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.08628"
  },
  {
    "id": "arXiv:2211.08633",
    "title": "MT Metrics Correlate with Human Ratings of Simultaneous Speech  Translation",
    "abstract": "There have been several studies on the correlation between human ratings and\nmetrics such as BLEU, chrF2 and COMET in machine translation. Most, if not all\nconsider full-sentence translation. It is unclear whether human ratings of\nsimultaneous speech translation Continuous Rating (CR) correlate with these\nmetrics or not. Therefore, we conduct an extensive correlation analysis of CR\nand the aforementioned automatic metrics on evaluations of candidate systems at\nEnglish-German simultaneous speech translation task at IWSLT 2022. Our studies\nreveal that the offline MT metrics correlate with CR and can be reliably used\nfor evaluating machine translation in the simultaneous mode, with some\nlimitations on the test set size. This implies that automatic metrics can be\nused as proxies for CR, thereby alleviating the need for human evaluation.",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Dominik Mach\u00e1\u010dek",
      "Ond\u0159ej Bojar",
      "Raj Dabre"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08633"
  },
  {
    "id": "arXiv:2211.08634",
    "title": "Semantic keypoint extraction for scanned animals using  multi-depth-camera systems",
    "abstract": "Keypoint annotation in point clouds is an important task for 3D\nreconstruction, object tracking and alignment, in particular in deformable or\nmoving scenes. In the context of agriculture robotics, it is a critical task\nfor livestock automation to work toward condition assessment or behaviour\nrecognition. In this work, we propose a novel approach for semantic keypoint\nannotation in point clouds, by reformulating the keypoint extraction as a\nregression problem of the distance between the keypoints and the rest of the\npoint cloud. We use the distance on the point cloud manifold mapped into a\nradial basis function (RBF), which is then learned using an encoder-decoder\narchitecture. Special consideration is given to the data augmentation specific\nto multi-depth-camera systems by considering noise over the extrinsic\ncalibration and camera frame dropout. Additionally, we investigate\ncomputationally efficient non-rigid deformation methods that can be applied to\nanimal point clouds. Our method is tested on data collected in the field, on\nmoving beef cattle, with a calibrated system of multiple hardware-synchronised\nRGB-D cameras.",
    "descriptor": "",
    "authors": [
      "Raphael Falque",
      "Teresa Vidal-Calleja",
      "Alen Alempijevic"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08634"
  },
  {
    "id": "arXiv:2211.08635",
    "title": "One-bit mmWave MIMO Channel Estimation using Deep Generative Networks",
    "abstract": "As future wireless systems trend towards higher carrier frequencies and large\nantenna arrays, receivers with one-bit analog-to-digital converters (ADCs) are\nbeing explored owing to their reduced power consumption. However, the\ncombination of large antenna arrays and one-bit ADCs makes channel estimation\nchallenging. In this paper, we formulate channel estimation from a limited\nnumber of one-bit quantized pilot measurements as an inverse problem and\nreconstruct the channel by optimizing the input vector of a pre-trained deep\ngenerative model with the objective of maximizing a novel correlation-based\nloss function. We observe that deep generative priors adapted to the underlying\nchannel model significantly outperform Bernoulli-Gaussian Approximate Message\nPassing (BG-GAMP), while a single generative model that uses a conditional\ninput to distinguish between Line-of-Sight (LOS) and Non-Line-of-Sight (NLOS)\nchannel realizations outperforms BG-GAMP on LOS channels and achieves\ncomparable performance on NLOS channels in terms of the normalized channel\nreconstruction error.",
    "descriptor": "\nComments: 6 pages, 4 figures, submitted to IEEE ICC 2023 in the MLC track. arXiv admin note: substantial text overlap with arXiv:2205.12445\n",
    "authors": [
      "Akash Doshi",
      "Jeffrey G. Andrews"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.08635"
  },
  {
    "id": "arXiv:2211.08636",
    "title": "Cooperative Energy and Time-Optimal Lane Change Maneuvers with Minimal  Highway Traffic Disruption",
    "abstract": "We derive optimal control policies for a Connected Automated Vehicle (CAV)\nand cooperating neighboring CAVs to carry out a lane change maneuver consisting\nof a longitudinal phase where the CAV properly positions itself relative to the\ncooperating neighbors and a lateral phase where it safely changes lanes. In\ncontrast to prior work on this problem, where the CAV \"selfishly\" only seeks to\nminimize its maneuver time, we seek to ensure that the fast-lane traffic flow\nis minimally disrupted (through a properly defined metric). Additionally, when\nperforming lane-changing maneuvers, we optimally select the cooperating\nvehicles from a set of feasible neighboring vehicles and experimentally show\nthat the highway throughput is improved compared to the baseline case of\nhuman-driven vehicles changing lanes with no cooperation. When feasible\nsolutions do not exist for a given maximal allowable disruption, we include a\ntime relaxation method trading off a longer maneuver time with reduced\ndisruption. Our analysis is also extended to multiple sequential maneuvers.\nSimulation results show the effectiveness of our controllers in terms of safety\nguarantees and up to 16% and 90% average throughput and maneuver time\nimprovement respectively when compared to maneuvers with no cooperation.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2203.17102\n",
    "authors": [
      "Andres S. Chavez Armijos",
      "Anni Li",
      "Christos G. Cassandras",
      "Yasir K. Al-Nadawi",
      "Hidekazu Araki",
      "Behdad Chalaki",
      "Ehsan Moradi-Pari",
      "Hossein Nourkhiz Mahjoub",
      "Vaishnav Tadiparthi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.08636"
  },
  {
    "id": "arXiv:2211.08639",
    "title": "Hierarchical Dynamic Image Harmonization",
    "abstract": "Image harmonization is a critical task in computer vision, which aims to\nadjust the fore-ground to make it compatible with the back-ground. Recent works\nmainly focus on using global transformation (i.e., normalization and color\ncurve rendering) to achieve visual consistency. However, these model ignore\nlocal consistency and their model size limit their harmonization ability on\nedge devices. Inspired by the dynamic deep networks that adapt the model\nstructures or parameters conditioned on the inputs, we propose a hierarchical\ndynamic network (HDNet) for efficient image harmonization to adapt the model\nparameters and features from local to global view for better feature\ntransformation. Specifically, local dynamics (LD) and mask-aware global\ndynamics (MGD) are applied. LD enables features of different channels and\npositions to change adaptively and improve the representation ability of\ngeometric transformation through structural information learning. MGD learns\nthe representations of fore- and back-ground regions and correlations to global\nharmonization. Experiments show that the proposed HDNet reduces more than 80\\%\nparameters compared with previous methods but still achieves the\nstate-of-the-art performance on the popular iHarmony4 dataset. Our code is\navaliable in https://github.com/chenhaoxing/HDNet.",
    "descriptor": "",
    "authors": [
      "Haoxing Chen",
      "Zhangxuan Gu",
      "Yaohui Li",
      "Jun Lan",
      "Changhua Meng",
      "Weiqiang Wang",
      "Huaxiong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.08639"
  },
  {
    "id": "arXiv:2211.08643",
    "title": "Keep Your Friends Close & Enemies Farther: Debiasing Contrastive  Learning with Spatial Priors in 3D Radiology Images",
    "abstract": "Understanding of spatial attributes is central to effective 3D radiology\nimage analysis where crop-based learning is the de facto standard. Given an\nimage patch, its core spatial properties (e.g., position & orientation) provide\nhelpful priors on expected object sizes, appearances, and structures through\ninherent anatomical consistencies. Spatial correspondences, in particular, can\neffectively gauge semantic similarities between inter-image regions, while\ntheir approximate extraction requires no annotations or overbearing\ncomputational costs. However, recent 3D contrastive learning approaches either\nneglect correspondences or fail to maximally capitalize on them. To this end,\nwe propose an extensible 3D contrastive framework (Spade, for Spatial\nDebiasing) that leverages extracted correspondences to select more effective\npositive & negative samples for representation learning. Our method learns both\nglobally invariant and locally equivariant representations with downstream\nsegmentation in mind. We also propose separate selection strategies for global\n& local scopes that tailor to their respective representational requirements.\nCompared to recent state-of-the-art approaches, Spade shows notable\nimprovements on three downstream segmentation tasks (CT Abdominal Organ, CT\nHeart, MR Heart).",
    "descriptor": "\nComments: Accepted to 2022 IEEE International Conference on Bioinformatics and Biomedicine (BIBM'22)\n",
    "authors": [
      "Yejia Zhang",
      "Nishchal Sapkota",
      "Pengfei Gu",
      "Yaopeng Peng",
      "Hao Zheng",
      "Danny Z. Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08643"
  },
  {
    "id": "arXiv:2211.08644",
    "title": "Coronavirus statistics causes emotional bias: a social media text mining  perspective",
    "abstract": "While COVID-19 has impacted humans for a long time, people search the web for\npandemic-related information, causing anxiety. From a theoretic perspective,\nprevious studies have confirmed that the number of COVID-19 cases can cause\nnegative emotions, but how statistics of different dimensions, such as the\nnumber of imported cases, the number of local cases, and the number of\ngovernment-designated lockdown zones, stimulate people's emotions requires\ndetailed understanding. In order to obtain the views of people on COVID-19,\nthis paper first proposes a deep learning model which classifies texts related\nto the pandemic from text data with place labels. Next, it conducts a sentiment\nanalysis based on multi-task learning. Finally, it carries out a fixed-effect\npanel regression with outputs of the sentiment analysis. The performance of the\nalgorithm shows a promising result. The empirical study demonstrates while the\nnumber of local cases is positively associated with risk perception, the number\nof imported cases is negatively associated with confidence levels, which\nexplains why citizens tend to ascribe the protracted pandemic to foreign\nfactors. Besides, this study finds that previous pandemic hits cities recover\nslowly from the suffering, while local governments' spending on healthcare can\nimprove the situation. Our study illustrates the reasons for risk perception\nand confidence based on different sources of statistical information due to\ncognitive bias. It complements the knowledge related to epidemic information.\nIt also contributes to a framework that combines sentiment analysis using\nadvanced deep learning technology with the empirical regression method.",
    "descriptor": "",
    "authors": [
      "Linjiang Guo",
      "Zijian Feng",
      "Yuxue Chi",
      "Mingzhu Wang",
      "Yijun Liu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.08644"
  },
  {
    "id": "arXiv:2211.08648",
    "title": "Efficiently Answering Quality Constrained Shortest Distance Queries in  Large Graphs",
    "abstract": "The shortest-path distance is a fundamental concept in graph analytics and\nhas been extensively studied in the literature. In many real-world\napplications, quality constraints are naturally associated with edges in the\ngraphs and finding the shortest distance between two vertices $s$ and $t$ along\nonly valid edges (i.e., edges that satisfy a given quality constraint) is also\ncritical. In this paper, we investigate this novel and important problem of\nquality constraint shortest distance queries. We propose an efficient index\nstructure based on 2-hop labeling approaches. Supported by a path dominance\nrelationship incorporating both quality and length information, we demonstrate\nthe minimal property of the new index. An efficient query processing algorithm\nis also developed. Extensive experimental studies over real-life datasets\ndemonstrates efficiency and effectiveness of our techniques.",
    "descriptor": "",
    "authors": [
      "You Peng",
      "Zhuo Ma",
      "Wenjie Zhang",
      "Xuemin Lin",
      "Ying Zhang",
      "Xiaoshuang Chen"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.08648"
  },
  {
    "id": "arXiv:2211.08650",
    "title": "Deep Intention-Aware Network for Click-Through Rate Prediction",
    "abstract": "E-commerce platforms provide entrances for customers to enter mini-apps that\ncan meet their specific shopping requirements. Trigger items displayed on\nentrance icons can attract more entering. However, conventional\nClick-Through-Rate (CTR) prediction models, which ignore user instant interest\nin trigger item, fail to be applied to the new recommendation scenario dubbed\nTrigger-Induced Recommendation in Mini-Apps (TIRA). Moreover, due to the high\nstickiness of customers to mini-apps, we argue that existing trigger-based\nmethods that over-emphasize the importance of trigger items, are undesired for\nTIRA, since a large portion of customer entries are because of their routine\nshopping habits instead of triggers. We identify that the key to TIRA is to\nextract customers' personalized entering intention and weigh the impact of\ntriggers based on this intention. To achieve this goal, we convert CTR\nprediction for TIRA into a separate estimation form, and present Deep\nIntention-Aware Network (DIAN) with three key elements: 1) Intent Net that\nestimates user's entering intention, i.e., whether he/she is affected by the\ntrigger or by the habits; 2) Trigger-Aware Net and 3) Trigger-Free Net that\nestimate CTRs given user's intention is to the trigger-item and the mini-app\nrespectively. Following a joint learning way, DIAN can both accurately predict\nuser intention and dynamically balance the results of trigger-free and\ntrigger-based recommendations based on the estimated intention. Experiments\nshow that DIAN advances state-of-the-art performance in a large real-world\ndataset, and brings a 9.39% lift of online Item Page View and 4.74% CTR for\nJuhuasuan, a famous mini-app of Taobao.",
    "descriptor": "\nComments: Recommender system in Taobao\n",
    "authors": [
      "Yaxian Xia",
      "Yi Cao",
      "Sihao Hu",
      "Tong Liu",
      "Lingling Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08650"
  },
  {
    "id": "arXiv:2211.08651",
    "title": "Using explainability to design physics-aware CNNs for solving subsurface  inverse problems",
    "abstract": "We present a novel method of using explainability techniques to design\nphysics-aware neural networks. We demonstrate our approach by developing a\nconvolutional neural network (CNN) for solving an inverse problem for shallow\nsubsurface imaging. Although CNNs have gained popularity in recent years across\nmany fields, the development of CNNs remains an art, as there are no clear\nguidelines regarding the selection of hyperparameters that will yield the best\nnetwork. While optimization algorithms may be used to select hyperparameters\nautomatically, these methods focus on developing networks with high predictive\naccuracy while disregarding model explainability (descriptive accuracy).\nHowever, the field of Explainable Artificial Intelligence (XAI) addresses the\nabsence of model explainability by providing tools that allow developers to\nevaluate the internal logic of neural networks. In this study, we use the\nexplainability methods Score-CAM and Deep SHAP to select hyperparameters, such\nas kernel sizes and network depth, to develop a physics-aware CNN for shallow\nsubsurface imaging. We begin with a relatively deep Encoder-Decoder network,\nwhich uses surface wave dispersion images as inputs and generates 2D shear wave\nvelocity subsurface images as outputs. Through model explanations, we\nultimately find that a shallow CNN using two convolutional layers with an\natypical kernel size of 3x1 yields comparable predictive accuracy but with\nincreased descriptive accuracy. We also show that explainability methods can be\nused to evaluate the network's complexity and decision-making. We believe this\nmethod can be used to develop neural networks with high predictive accuracy\nwhile also providing inherent explainability.",
    "descriptor": "\nComments: 26 pages, 14 figures, 4 tables\n",
    "authors": [
      "Jodie Crocker",
      "Krishna Kumar",
      "Brady R. Cox"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.08651"
  },
  {
    "id": "arXiv:2211.08653",
    "title": "#maskUp: Selective Attribute Encryption for Sensitive Vocalization for  English language on Social Media Platforms",
    "abstract": "Social media has become a platform for people to stand up and raise their\nvoices against social and criminal acts. Vocalization of such information has\nallowed the investigation and identification of criminals. However, revealing\nsuch sensitive information may jeopardize the victim's safety. We propose\n#maskUp, a safe method for information communication in a secure fashion to the\nrelevant authorities, discouraging potential bullying of the victim. This would\nensure security by conserving their privacy through natural language processing\nsupplemented with selective encryption for sensitive attribute masking. To our\nknowledge, this is the first work that aims to protect the privacy of the\nvictims by masking their private details as well as emboldening them to come\nforward to report crimes. The use of masking technology allows only binding\nauthorities to view/un-mask this data. We construct and evaluate the proposed\nmethodology on continual learning tasks, allowing practical implementation of\nthe same in a real-world scenario. #maskUp successfully demonstrates this\nintegration on sample datasets validating the presented objective.",
    "descriptor": "\nComments: Awarded Second Runner's up in the Research and Reports track at #ShowYourSkill (Coursera)\n",
    "authors": [
      "Supriti Vijay",
      "Aman Priyanshu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08653"
  },
  {
    "id": "arXiv:2211.08655",
    "title": "Compositional Approximately Bisimilar Abstractions of Interconnected  Systems",
    "abstract": "This paper formulates and studies the concepts of approximate (alternating)\nbisimulation relations characterizing equivalence relations between\ninterconnected systems and their abstractions. These equivalence relations\nguarantee that the symbolic model conserves the original model's dynamics. We\ndevelop a compositional approach for abstraction-based controller synthesis by\nrelying on the notions of approximate composition and incremental\ninput-to-state stability. In particular, given a large-scale system consisting\nof interconnected components, we provide conditions under which the concept of\napproximate (alternating) simulation relation is preserved when going from the\nsubsystems to the large-scale interconnected system. The engineering relevance\nof the theoretical results has been evaluated through an application in traffic\ncongestion control.",
    "descriptor": "\nComments: 9,2\n",
    "authors": [
      "Belamfedel Alaoui Sadek",
      "Saharsh",
      "Pushpak Jagtap",
      "Adnane Saoud"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.08655"
  },
  {
    "id": "arXiv:2211.08656",
    "title": "Complexes from Complexes: Finite Element Complexes in Three Dimensions",
    "abstract": "Finite element Hessian, elasticity, and divdiv complexes are systematically\nderived via Bernstein-Gelfand-Gelfand (BGG) framework developed by Arnold and\nHu [Complexes from complexes. {\\em Found. Comput. Math.}, 2021]. Our\nconstruction is built on three major tools: smooth finite element de Rham\ncomplexes, the $t-n$ decomposition approach for constructing div-conforming\nelements, and the trace complexes and corresponding 2D finite element\ncomplexes. Two reduction operators are introduced to solve the mis-match of\ncontinuity of the BGG diagram in the continuous level.",
    "descriptor": "\nComments: 44 pages\n",
    "authors": [
      "Long Chen",
      "Xuehai Huang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.08656"
  },
  {
    "id": "arXiv:2211.08657",
    "title": "Person Text-Image Matching via Text-Featur Interpretability Embedding  and External Attack Node Implantation",
    "abstract": "Person text-image matching, also known as textbased person search, aims to\nretrieve images of specific pedestrians using text descriptions. Although\nperson text-image matching has made great research progress, existing methods\nstill face two challenges. First, the lack of interpretability of text features\nmakes it challenging to effectively align them with their corresponding image\nfeatures. Second, the same pedestrian image often corresponds to multiple\ndifferent text descriptions, and a single text description can correspond to\nmultiple different images of the same identity. The diversity of text\ndescriptions and images makes it difficult for a network to extract robust\nfeatures that match the two modalities. To address these problems, we propose a\nperson text-image matching method by embedding text-feature interpretability\nand an external attack node. Specifically, we improve the interpretability of\ntext features by providing them with consistent semantic information with image\nfeatures to achieve the alignment of text and describe image region features.To\naddress the challenges posed by the diversity of text and the corresponding\nperson images, we treat the variation caused by diversity to features as caused\nby perturbation information and propose a novel adversarial attack and defense\nmethod to solve it. In the model design, graph convolution is used as the basic\nframework for feature representation and the adversarial attacks caused by text\nand image diversity on feature extraction is simulated by implanting an\nadditional attack node in the graph convolution layer to improve the robustness\nof the model against text and image diversity. Extensive experiments\ndemonstrate the effectiveness and superiority of text-pedestrian image matching\nover existing methods. The source code of the method is published at",
    "descriptor": "",
    "authors": [
      "Fan Li",
      "Hang Zhou",
      "Huafeng Li",
      "Yafei Zhang",
      "Zhengtao Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08657"
  },
  {
    "id": "arXiv:2211.08661",
    "title": "SETAR-Tree: A Novel and Accurate Tree Algorithm for Global Time Series  Forecasting",
    "abstract": "Threshold Autoregressive (TAR) models have been widely used by statisticians\nfor non-linear time series forecasting during the past few decades, due to\ntheir simplicity and mathematical properties. On the other hand, in the\nforecasting community, general-purpose tree-based regression algorithms\n(forests, gradient-boosting) have become popular recently due to their ease of\nuse and accuracy. In this paper, we explore the close connections between TAR\nmodels and regression trees. These enable us to use the rich methodology from\nthe literature on TAR models to define a hierarchical TAR model as a regression\ntree that trains globally across series, which we call SETAR-Tree. In contrast\nto the general-purpose tree-based models that do not primarily focus on\nforecasting, and calculate averages at the leaf nodes, we introduce a new\nforecasting-specific tree algorithm that trains global Pooled Regression (PR)\nmodels in the leaves allowing the models to learn cross-series information and\nalso uses some time-series-specific splitting and stopping procedures. The\ndepth of the tree is controlled by conducting a statistical linearity test\ncommonly employed in TAR models, as well as measuring the error reduction\npercentage at each node split. Thus, the proposed tree model requires minimal\nexternal hyperparameter tuning and provides competitive results under its\ndefault configuration. We also use this tree algorithm to develop a forest\nwhere the forecasts provided by a collection of diverse SETAR-Trees are\ncombined during the forecasting process. In our evaluation on eight publicly\navailable datasets, the proposed tree and forest models are able to achieve\nsignificantly higher accuracy than a set of state-of-the-art tree-based\nalgorithms and forecasting benchmarks across four evaluation metrics.",
    "descriptor": "\nComments: 38 pages, 2 figures, 7 tables\n",
    "authors": [
      "Rakshitha Godahewa",
      "Geoffrey I. Webb",
      "Daniel Schmidt",
      "Christoph Bergmeir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.08661"
  },
  {
    "id": "arXiv:2211.08666",
    "title": "Revisiting Training-free NAS Metrics: An Efficient Training-based Method",
    "abstract": "Recent neural architecture search (NAS) works proposed training-free metrics\nto rank networks which largely reduced the search cost in NAS. In this paper,\nwe revisit these training-free metrics and find that: (1) the number of\nparameters (\\#Param), which is the most straightforward training-free metric,\nis overlooked in previous works but is surprisingly effective, (2) recent\ntraining-free metrics largely rely on the \\#Param information to rank networks.\nOur experiments show that the performance of recent training-free metrics drops\ndramatically when the \\#Param information is not available. Motivated by these\nobservations, we argue that metrics less correlated with the \\#Param are\ndesired to provide additional information for NAS. We propose a light-weight\ntraining-based metric which has a weak correlation with the \\#Param while\nachieving better performance than training-free metrics at a lower search cost.\nSpecifically, on DARTS search space, our method completes searching directly on\nImageNet in only 2.6 GPU hours and achieves a top-1/top-5 error rate of\n24.1\\%/7.1\\%, which is competitive among state-of-the-art NAS methods. Codes\nare available at \\url{https://github.com/taoyang1122/Revisit_TrainingFree_NAS}",
    "descriptor": "\nComments: Accepted to WACV2023\n",
    "authors": [
      "Taojiannan Yang",
      "Linjie Yang",
      "Xiaojie Jin",
      "Chen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08666"
  },
  {
    "id": "arXiv:2211.08667",
    "title": "County-level Algorithmic Audit of Racial Bias in Twitter's Home Timeline",
    "abstract": "We report on the outcome of an audit of Twitter's Home Timeline ranking\nsystem. The goal of the audit was to determine if authors from some racial\ngroups experience systematically higher impression counts for their Tweets than\nothers. A central obstacle for any such audit is that Twitter does not\nordinarily collect or associate racial information with its users, thus\nprohibiting an analysis at the level of individual authors. Working around this\nobstacle, we take US counties as our unit of analysis. We associate each user\nin the United States on the Twitter platform to a county based on available\nlocation data. The US Census Bureau provides information about the racial\ndecomposition of the population in each county. The question we investigate\nthen is if the racial decomposition of a county is associated with the\nvisibility of Tweets originating from within the county. Focusing on two racial\ngroups, the Black or African American population and the White population as\ndefined by the US Census Bureau, we evaluate two statistical measures of bias.\nOur investigation represents the first large-scale algorithmic audit into\nracial bias on the Twitter platform. Additionally, it illustrates the\nchallenges of measuring racial bias in online platforms without having such\ninformation on the users.",
    "descriptor": "",
    "authors": [
      "Luca Belli",
      "Kyra Yee",
      "Uthaipon Tantipongpipat",
      "Aaron Gonzales",
      "Kristian Lum",
      "Moritz Hardt"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.08667"
  },
  {
    "id": "arXiv:2211.08669",
    "title": "Addressing the issue of stochastic environments and local  decision-making in multi-objective reinforcement learning",
    "abstract": "Multi-objective reinforcement learning (MORL) is a relatively new field which\nbuilds on conventional Reinforcement Learning (RL) to solve multi-objective\nproblems. One of common algorithm is to extend scalar value Q-learning by using\nvector Q values in combination with a utility function, which captures the\nuser's preference for action selection. This study follows on prior works, and\nfocuses on what factors influence the frequency with which value-based MORL\nQ-learning algorithms learn the optimal policy for an environment with\nstochastic state transitions in scenarios where the goal is to maximise the\nScalarised Expected Return (SER) - that is, to maximise the average outcome\nover multiple runs rather than the outcome within each individual episode. The\nanalysis of the interaction between stochastic environment and MORL Q-learning\nalgorithms run on a simple Multi-objective Markov decision process (MOMDP)\nSpace Traders problem with different variant versions. The empirical\nevaluations show that well designed reward signal can improve the performance\nof the original baseline algorithm, however it is still not enough to address\nmore general environment. A variant of MORL Q-Learning incorporating global\nstatistics is shown to outperform the baseline method in original Space Traders\nproblem, but remains below 100 percent effectiveness in finding the find\ndesired SER-optimal policy at the end of training. On the other hand, Option\nlearning is guarantied to converge to desired SER-optimal policy but it is not\nable to scale up to solve more complex problem in real-life. The main\ncontribution of this thesis is to identify the extent to which the issue of\nnoisy Q-value estimates impacts on the ability to learn optimal policies under\nthe combination of stochastic environments, non-linear utility and a constant\nlearning rate.",
    "descriptor": "\nComments: 55 pages, 21 figures\n",
    "authors": [
      "Kewen Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08669"
  },
  {
    "id": "arXiv:2211.08671",
    "title": "LEMMA: Bootstrapping High-Level Mathematical Reasoning with Learned  Symbolic Abstractions",
    "abstract": "Humans tame the complexity of mathematical reasoning by developing\nhierarchies of abstractions. With proper abstractions, solutions to hard\nproblems can be expressed concisely, thus making them more likely to be found.\nIn this paper, we propose Learning Mathematical Abstractions (LEMMA): an\nalgorithm that implements this idea for reinforcement learning agents in\nmathematical domains. LEMMA augments Expert Iteration with an abstraction step,\nwhere solutions found so far are revisited and rewritten in terms of new\nhigher-level actions, which then become available to solve new problems. We\nevaluate LEMMA on two mathematical reasoning tasks--equation solving and\nfraction simplification--in a step-by-step fashion. In these two domains, LEMMA\nimproves the ability of an existing agent, both solving more problems and\ngeneralizing more effectively to harder problems than those seen during\ntraining.",
    "descriptor": "\nComments: 10 pages, 2 figures; to appear in 2nd MATH-AI Workshop at NeurIPS'22\n",
    "authors": [
      "Zhening Li",
      "Gabriel Poesia",
      "Omar Costilla-Reyes",
      "Noah Goodman",
      "Armando Solar-Lezama"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08671"
  },
  {
    "id": "arXiv:2211.08672",
    "title": "Fair contrastive pre-training for geographic images",
    "abstract": "Contrastive representation learning is widely employed in visual recognition\nfor geographic image data (remote-sensing such as satellite imagery or proximal\nsensing such as street-view imagery), but because of landscape heterogeneity,\nmodels can show disparate performance across spatial units. In this work, we\nconsider fairness risks in land-cover semantic segmentation which uses\npre-trained representation in contrastive self-supervised learning. We assess\nclass distribution shifts and model prediction disparities across selected\nsensitive groups: urban and rural scenes for satellite image datasets and city\nGDP level for a street view image dataset. We propose a mutual information\ntraining objective for multi-level latent space. The objective improves feature\nidentification by removing spurious representations of dense local features\nwhich are disparately distributed across groups. The method achieves improved\nfairness results and outperforms state-of-the-art methods in terms of\nprecision-fairness trade-off. In addition, we validate that representations\nlearnt with the proposed method include lowest sensitive information using a\nlinear separation evaluation. This work highlights the need for specific\nfairness analyses in geographic images, and provides a solution that can be\ngeneralized to different self-supervised learning methods or image data. Our\ncode is available at: https://anonymous.4open.science/r/FairDCL-1283",
    "descriptor": "",
    "authors": [
      "Miao Zhang",
      "Rumi Chunara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08672"
  },
  {
    "id": "arXiv:2211.08675",
    "title": "XRBench: An Extended Reality (XR) Machine Learning Benchmark Suite for  the Metaverse",
    "abstract": "Real-time multi-model multi-task (MMMT) workloads, a new form of deep\nlearning inference workloads, are emerging for applications areas like extended\nreality (XR) to support metaverse use cases. These workloads combine user\ninteractivity with computationally complex machine learning (ML) activities.\nCompared to standard ML applications, these ML workloads present unique\ndifficulties and constraints. Real-time MMMT workloads impose heterogeneity and\nconcurrency requirements on future ML systems and devices, necessitating the\ndevelopment of new capabilities. This paper begins with a discussion of the\nvarious characteristics of these real-time MMMT ML workloads and presents an\nontology for evaluating the performance of future ML hardware for XR systems.\nNext, we present XRBench, a collection of MMMT ML tasks, models, and usage\nscenarios that execute these models in three representative ways: cascaded,\nconcurrent, and cascaded-concurrency for XR use cases. Finally, we emphasize\nthe need for new metrics that capture the requirements properly. We hope that\nour work will stimulate research and lead to the development of a new\ngeneration of ML systems for XR use cases.",
    "descriptor": "",
    "authors": [
      "Hyoukjun Kwon",
      "Krishnakumar Nair",
      "Jamin Seo",
      "Jason Yik",
      "Debabrata Mohapatra",
      "Dongyuan Zhan",
      "Jinook Song",
      "Peter Capak",
      "Peizhao Zhang",
      "Peter Vajda",
      "Colby Banbury",
      "Mark Mazumder",
      "Liangzhen Lai",
      "Ashish Sirasao",
      "Tushar Krishna",
      "Harshit Khaitan",
      "Vikas Chandra",
      "Vijay Janapa Reddi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2211.08675"
  },
  {
    "id": "arXiv:2211.08678",
    "title": "Nano-Resolution Visual Identifiers Enable Secure Monitoring in  Next-Generation Cyber-Physical Systems",
    "abstract": "Today's supply chains heavily rely on cyber-physical systems such as\nintelligent transportation, online shopping, and E-commerce. It is advantageous\nto track goods in real-time by web-based registration and authentication of\nproducts after any substantial change or relocation. Despite recent advantages\nin technology-based tracking systems, most supply chains still rely on plainly\nprinted tags such as barcodes and Quick Response (QR) codes for tracking\npurposes. Although affordable and efficient, these tags convey no security\nagainst counterfeit and cloning attacks, raising privacy concerns. It is a\ncritical matter since a few security breaches in merchandise databases in\nrecent years has caused crucial social and economic impacts such as identity\nloss, social panic, and loss of trust in the community. This paper considers an\nend-to-end system using dendrites as nano-resolution visual identifiers to\nsecure supply chains. Dendrites are formed by generating fractal metallic\npatterns on transparent substrates through an electrochemical process, which\ncan be used as secure identifiers due to their natural randomness, high\nentropy, and unclonable features. The proposed framework compromises the\nback-end program for identification and authentication, a web-based application\nfor mobile devices, and a cloud database. We review architectural design,\ndendrite operational phases (personalization, registration, inspection), a\nlightweight identification method based on 2D graph-matching, and a deep 3D\nimage authentication method based on Digital Holography (DH). A two-step search\nis proposed to make the system scalable by limiting the search space to samples\nwith high similarity scores in a lower-dimensional space. We conclude by\npresenting our solution to make dendrites secure against adversarial attacks.",
    "descriptor": "",
    "authors": [
      "Hao Wang",
      "Xiwen Chen",
      "Abolfazl Razi",
      "Michael Kozicki",
      "Rahul Amin",
      "Mark Manfredo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.08678"
  },
  {
    "id": "arXiv:2211.08680",
    "title": "An Efficient Light-weight LSB steganography with Deep learning  Steganalysis",
    "abstract": "Active research is going on to securely transmit a secret message or\nso-called steganography by using data-hiding techniques in digital images.\nAfter assessing the state-of-the-art research work, we found, most of the\nexisting solutions are not promising and are ineffective against machine\nlearning-based steganalysis. In this paper, a lightweight steganography scheme\nis presented through graphical key embedding and obfuscation of data through\nencryption. By keeping a mindset of industrial applicability, to show the\neffectiveness of the proposed scheme, we emphasized mainly deep learning-based\nsteganalysis. The proposed steganography algorithm containing two schemes\nwithstands not only statistical pattern recognizers but also machine learning\nsteganalysis through feature extraction using a well-known pre-trained deep\nlearning network Xception. We provided a detailed protocol of the algorithm for\ndifferent scenarios and implementation details. Furthermore, different\nperformance metrics are also evaluated with statistical and machine learning\nperformance analysis. The results were quite impressive with respect to the\nstate of the arts. We received 2.55% accuracy through statistical steganalysis\nand machine learning steganalysis gave maximum of 49.93~50% correctly\nclassified instances in good condition.",
    "descriptor": "\nComments: Accepted paper\n",
    "authors": [
      "Dipnarayan Das",
      "Asha Durafe",
      "Dr. Vinod Patidar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.08680"
  },
  {
    "id": "arXiv:2211.08681",
    "title": "Interclass Prototype Relation for Few-Shot Segmentation",
    "abstract": "Traditional semantic segmentation requires a large labeled image dataset and\ncan only be predicted within predefined classes. To solve this problem,\nfew-shot segmentation, which requires only a handful of annotations for the new\ntarget class, is important. However, with few-shot segmentation, the target\nclass data distribution in the feature space is sparse and has low coverage\nbecause of the slight variations in the sample data. Setting the classification\nboundary that properly separates the target class from other classes is an\nimpossible task. In particular, it is difficult to classify classes that are\nsimilar to the target class near the boundary. This study proposes the\nInterclass Prototype Relation Network (IPRNet), which improves the separation\nperformance by reducing the similarity between other classes. We conducted\nextensive experiments with Pascal-5i and COCO-20i and showed that IPRNet\nprovides the best segmentation performance compared with previous research.",
    "descriptor": "\nComments: Accepted to ECCV2022\n",
    "authors": [
      "Atsuro Okazawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08681"
  },
  {
    "id": "arXiv:2211.08682",
    "title": "Parameter-Efficient Tuning on Layer Normalization for Pre-trained  Language Models",
    "abstract": "Conventional fine-tuning encounters increasing difficulties given the size of\ncurrent Pre-trained Language Models, which makes parameter-efficient tuning\nbecome the focal point of frontier research. Previous methods in this field add\ntunable adapters into MHA or/and FFN of Transformer blocks to enable PLMs\nachieve transferability. However, as an important part of Transformer\narchitecture, the power of layer normalization for parameter-efficent tuning is\nignored. In this paper, we first propose LN-tuning, by tuning the gain and bias\nterm of Layer Normalization module with only 0.03\\% parameters, which is of\nhigh time-efficency and significantly superior to baselines which are less than\n0.1\\% tunable parameters. Further, we study the unified framework of combining\nLN-tuning with previous ones and we find that: (1) the unified framework of\ncombining prefix-tuning, the adapter-based method working on MHA, and LN-tuning\nachieves SOTA performance. (2) unified framework which tunes MHA and LayerNorm\nsimultaneously can get performance improvement but those which tune FFN and\nLayerNorm simultaneous will cause performance decrease. Ablation study\nvalidates LN-tuning is of no abundant parameters and gives a further\nunderstanding of it.",
    "descriptor": "",
    "authors": [
      "Wang Qi",
      "Yu-Ping Ruan",
      "Yuan Zuo",
      "Taihao Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08682"
  },
  {
    "id": "arXiv:2211.08684",
    "title": "Neural Unsupervised Reconstruction of Protolanguage Word Forms",
    "abstract": "We present a state-of-the-art neural approach to the unsupervised\nreconstruction of ancient word forms. Previous work in this domain used\nexpectation-maximization to predict simple phonological changes between ancient\nword forms and their cognates in modern languages. We extend this work with\nneural models that can capture more complicated phonological and morphological\nchanges. At the same time, we preserve the inductive biases from classical\nmethods by building monotonic alignment constraints into the model and\ndeliberately underfitting during the maximization step. We evaluate our\nperformance on the task of reconstructing Latin from a dataset of cognates\nacross five Romance languages, achieving a notable reduction in edit distance\nfrom the target word forms compared to previous methods.",
    "descriptor": "",
    "authors": [
      "Andre He",
      "Nicholas Tomlin",
      "Dan Klein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08684"
  },
  {
    "id": "arXiv:2211.08686",
    "title": "Improving Interpretability via Regularization of Neural Activation  Sensitivity",
    "abstract": "State-of-the-art deep neural networks (DNNs) are highly effective at tackling\nmany real-world tasks. However, their wide adoption in mission-critical\ncontexts is hampered by two major weaknesses - their susceptibility to\nadversarial attacks and their opaqueness. The former raises concerns about the\nsecurity and generalization of DNNs in real-world conditions, whereas the\nlatter impedes users' trust in their output. In this research, we (1) examine\nthe effect of adversarial robustness on interpretability and (2) present a\nnovel approach for improving the interpretability of DNNs that is based on\nregularization of neural activation sensitivity. We evaluate the\ninterpretability of models trained using our method to that of standard models\nand models trained using state-of-the-art adversarial robustness techniques.\nOur results show that adversarially robust models are superior to standard\nmodels and that models trained using our proposed method are even better than\nadversarially robust models in terms of interpretability.",
    "descriptor": "",
    "authors": [
      "Ofir Moshe",
      "Gil Fidel",
      "Ron Bitton",
      "Asaf Shabtai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08686"
  },
  {
    "id": "arXiv:2211.08690",
    "title": "RIS-THz Wireless Communication with Random Phase Noise and Misaligned  Transceiver",
    "abstract": "Existing research works on reconfigurable intelligent surfaces (RIS) based\nterahertz (THz) system ignores the effect of phase noise and employ the\nzero-boresight pointing errors model of the free-space optics channel in\nperformance analysis. In this paper, we analyze the performance of RIS-THz\ntransmission under the combined effect of channel fading, THz pointing error\n(TPE), and statistical phase noise due to imperfect phase compensation at each\nRIS element. First, we derive statistical results of the double $\\alpha$-$\\mu$\nfading combined with the TPE and phase noise at individual RIS elements using\nsingle-variate Fox's function. Next, we use the multi-variate Fox's H-function\nrepresentation to develop exact analytical expressions for the density and\ndistribution functions of the resultant signal-to-noise ratio (SNR) of the\nRIS-THz link considering the accumulating propagation effect from all RIS\nelements. Using the derived statistical results, we analyze the exact and\nasymptotic expressions for the considered system's outage probability and\naverage bit-error rate (BER). The analytical results show that the diversity\norder of the system is independent of phase noise, depends on the channel\nfading parameters $\\alpha$ and $\\mu$, and depends on the $\\beta$ parameter of\nthe TPE.",
    "descriptor": "",
    "authors": [
      "Omkar R. Durgada",
      "Vinay Kumar Chapala",
      "S. M. Zafaruddin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.08690"
  },
  {
    "id": "arXiv:2211.08691",
    "title": "Towards Long-Tailed 3D Detection",
    "abstract": "Contemporary autonomous vehicle (AV) benchmarks have advanced techniques for\ntraining 3D detectors, particularly on large-scale lidar data. Surprisingly,\nalthough semantic class labels naturally follow a long-tailed distribution,\ncontemporary benchmarks focus on only a few common classes (e.g., pedestrian\nand car) and neglect many rare classes in-the-tail (e.g., debris and stroller).\nHowever, AVs must still detect rare classes to ensure safe operation. Moreover,\nsemantic classes are often organized within a hierarchy, e.g., tail classes\nsuch as child and construction-worker are arguably subclasses of pedestrian.\nHowever, such hierarchical relationships are often ignored, which may lead to\nmisleading estimates of performance and missed opportunities for algorithmic\ninnovation. We address these challenges by formally studying the problem of\nLong-Tailed 3D Detection (LT3D), which evaluates on all classes, including\nthose in-the-tail. We evaluate and innovate upon popular 3D detection\ncodebases, such as CenterPoint and PointPillars, adapting them for LT3D. We\ndevelop hierarchical losses that promote feature sharing across common-vs-rare\nclasses, as well as improved detection metrics that award partial credit to\n\"reasonable\" mistakes respecting the hierarchy (e.g., mistaking a child for an\nadult). Finally, we point out that fine-grained tail class accuracy is\nparticularly improved via multimodal fusion of RGB images with LiDAR; simply\nput, small fine-grained classes are challenging to identify from sparse (lidar)\ngeometry alone, suggesting that multimodal cues are crucial to long-tailed 3D\ndetection. Our modifications improve accuracy by 5% AP on average for all\nclasses, and dramatically improve AP for rare classes (e.g., stroller AP\nimproves from 3.6 to 31.6)!",
    "descriptor": "\nComments: This work has been accepted to the Conference on Robot Learning (CoRL) 2022\n",
    "authors": [
      "Neehar Peri",
      "Achal Dave",
      "Deva Ramanan",
      "Shu Kong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.08691"
  },
  {
    "id": "arXiv:2211.08695",
    "title": "Distributed and Adversarial Resistant Workflow Execution on the Algorand  Blockchain",
    "abstract": "We provide a practical translation from the Dynamic Condition Response (DCR)\nprocess modelling language to the Transaction Execution Approval Language\n(TEAL) used by the Algorand blockchain. Compared to earlier implementations of\nbusiness process notations on blockchains, particularly Ethereum, the present\nimplementation is four orders of magnitude cheaper. This translation has the\nfollowing immediate ramifications: (1) It allows decentralised execution of\nDCR-specified business processes in the absence of expensive intermediaries\n(lawyers, brokers) or counterparty risk. (2) It provides a possibly helpful\nhigh-level language for implementing business processes on Algorand. (3) It\ndemonstrates that despite the strict limitations on Algorand smart contracts,\nthey are powerful enough to encode models of a modern process notation.",
    "descriptor": "",
    "authors": [
      "Yibin Xu",
      "Tijs Slaats",
      "Boris D\u00fcdder",
      "S\u00f8ren Debois",
      "Haiqin Wu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.08695"
  },
  {
    "id": "arXiv:2211.08697",
    "title": "PBSM: Backdoor attack against Keyword spotting based on pitch boosting  and sound masking",
    "abstract": "Keyword spotting (KWS) has been widely used in various speech control\nscenarios. The training of KWS is usually based on deep neural networks and\nrequires a large amount of data. Manufacturers often use third-party data to\ntrain KWS. However, deep neural networks are not sufficiently interpretable to\nmanufacturers, and attackers can manipulate third-party training data to plant\nbackdoors during the model training. An effective backdoor attack can force the\nmodel to make specified judgments under certain conditions, i.e., triggers. In\nthis paper, we design a backdoor attack scheme based on Pitch Boosting and\nSound Masking for KWS, called PBSM. Experimental results demonstrated that PBSM\nis feasible to achieve an average attack success rate close to 90% in three\nvictim models when poisoning less than 1% of the training data.",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Hanbo Cai",
      "Pengcheng Zhang",
      "Hai Dong",
      "Yan Xiao",
      "Shunhui Ji"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.08697"
  },
  {
    "id": "arXiv:2211.08700",
    "title": "Bi-directional Digital Twin and Edge Computing in the Metaverse",
    "abstract": "The Metaverse has emerged to extend our lifestyle beyond physical\nlimitations. As essential components in the Metaverse, digital twins (DTs) are\nthe digital replicas of physical items. End users access the Metaverse using a\nvariety of devices (e.g., head-mounted devices (HMDs)), mostly lightweight.\nMulti-access edge computing (MEC) and edge networks provide responsive services\nto the end users, leading to an immersive Metaverse experience. With the\nanticipation to represent physical objects, end users, and edge computing\nsystems as DTs in the Metaverse, the construction of these DTs and the\ninterplay between them have not been investigated. In this paper, we discuss\nthe bidirectional reliance between the DT and the MEC system and investigate\nthe creation of DTs of objects and users on the MEC servers and DT-assisted\nedge computing (DTEC). We also study the interplay between the DTs and DTECs to\nallocate the resources fairly and adequately and provide an immersive\nexperience in the Metaverse. Owing to the dynamic network states (e.g., channel\nstates) and mobility of the users, we discuss the interplay between local DTECs\n(on local MEC servers) and the global DTEC (on cloud server) to cope with the\nhandover among MEC servers and avoid intermittent Metaverse services.",
    "descriptor": "",
    "authors": [
      "Jiadong Yu",
      "Ahmad Alhilal",
      "Pan Hui",
      "Danny H.K. Tsang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.08700"
  },
  {
    "id": "arXiv:2211.08701",
    "title": "Interpretable Self-Aware Neural Networks for Robust Trajectory  Prediction",
    "abstract": "Although neural networks have seen tremendous success as predictive models in\na variety of domains, they can be overly confident in their predictions on\nout-of-distribution (OOD) data. To be viable for safety-critical applications,\nlike autonomous vehicles, neural networks must accurately estimate their\nepistemic or model uncertainty, achieving a level of system self-awareness.\nTechniques for epistemic uncertainty quantification often require OOD data\nduring training or multiple neural network forward passes during inference.\nThese approaches may not be suitable for real-time performance on\nhigh-dimensional inputs. Furthermore, existing methods lack interpretability of\nthe estimated uncertainty, which limits their usefulness both to engineers for\nfurther system development and to downstream modules in the autonomy stack. We\npropose the use of evidential deep learning to estimate the epistemic\nuncertainty over a low-dimensional, interpretable latent space in a trajectory\nprediction setting. We introduce an interpretable paradigm for trajectory\nprediction that distributes the uncertainty among the semantic concepts: past\nagent behavior, road structure, and social context. We validate our approach on\nreal-world autonomous driving data, demonstrating superior performance over\nstate-of-the-art baselines. Our code is available at:\nhttps://github.com/sisl/InterpretableSelfAwarePrediction.",
    "descriptor": "\nComments: Conference on Robot Learning (CoRL) 2022, 15 pages, 4 figures\n",
    "authors": [
      "Masha Itkina",
      "Mykel J. Kochenderfer"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08701"
  },
  {
    "id": "arXiv:2211.08702",
    "title": "PointInverter: Point Cloud Reconstruction and Editing via a Generative  Model with Shape Priors",
    "abstract": "In this paper, we propose a new method for mapping a 3D point cloud to the\nlatent space of a 3D generative adversarial network. Our generative model for\n3D point clouds is based on SP-GAN, a state-of-the-art sphere-guided 3D point\ncloud generator. We derive an efficient way to encode an input 3D point cloud\nto the latent space of the SP-GAN. Our point cloud encoder can resolve the\npoint ordering issue during inversion, and thus can determine the\ncorrespondences between points in the generated 3D point cloud and those in the\ncanonical sphere used by the generator. We show that our method outperforms\nprevious GAN inversion methods for 3D point clouds, achieving state-of-the-art\nresults both quantitatively and qualitatively. Our code is available at\nhttps://github.com/hkust-vgd/point_inverter.",
    "descriptor": "\nComments: WACV 2023 paper. 8 pages of main content, 2 pages of references, 7 pages of supplementary material\n",
    "authors": [
      "Jaeyeon Kim",
      "Binh-Son Hua",
      "Duc Thanh Nguyen",
      "Sai-Kit Yeung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.08702"
  },
  {
    "id": "arXiv:2211.08703",
    "title": "SATVSR: Scenario Adaptive Transformer for Cross Scenarios Video  Super-Resolution",
    "abstract": "Video Super-Resolution (VSR) aims to recover sequences of high-resolution\n(HR) frames from low-resolution (LR) frames. Previous methods mainly utilize\ntemporally adjacent frames to assist the reconstruction of target frames.\nHowever, in the real world, there is a lot of irrelevant information in\nadjacent frames of videos with fast scene switching, these VSR methods cannot\nadaptively distinguish and select useful information. In contrast, with a\ntransformer structure suitable for temporal tasks, we devise a novel adaptive\nscenario video super-resolution method. Specifically, we use optical flow to\nlabel the patches in each video frame, only calculate the attention of patches\nwith the same label. Then select the most relevant label among them to\nsupplement the spatial-temporal information of the target frame. This design\ncan directly make the supplementary information come from the same scene as\nmuch as possible. We further propose a cross-scale feature aggregation module\nto better handle the scale variation problem. Compared with other video\nsuper-resolution methods, our method not only achieves significant performance\ngains on single-scene videos but also has better robustness on cross-scene\ndatasets.",
    "descriptor": "",
    "authors": [
      "Yongjie Chen",
      "Tieru Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08703"
  },
  {
    "id": "arXiv:2211.08704",
    "title": "A Simple Transformer-Based Model for Ego4D Natural Language Queries  Challenge",
    "abstract": "This report describes Badgers@UW-Madison, our submission to the Ego4D Natural\nLanguage Queries (NLQ) Challenge. Our solution inherits the point-based event\nrepresentation from our prior work on temporal action localization, and\ndevelops a Transformer-based model for video grounding. Further, our solution\nintegrates several strong video features including SlowFast, Omnivore and\nEgoVLP. Without bells and whistles, our submission based on a single model\nachieves 12.64% Mean R@1 and is ranked 2nd on the public leaderboard.\nMeanwhile, our method garners 28.45% (18.03%) R@5 at tIoU=0.3 (0.5), surpassing\nthe top-ranked solution by up to 5.5 absolute percentage points.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Sicheng Mo",
      "Fangzhou Mu",
      "Yin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08704"
  },
  {
    "id": "arXiv:2211.08705",
    "title": "Resource Allocation of Federated Learning for the Metaverse with Mobile  Augmented Reality",
    "abstract": "The Metaverse has received much attention recently. Metaverse applications\nvia mobile augmented reality (MAR) require rapid and accurate object detection\nto mix digital data with the real world. Federated learning (FL) is an\nintriguing distributed machine learning approach due to its privacy-preserving\ncharacteristics. Due to privacy concerns and the limited computation resources\non mobile devices, we incorporate FL into MAR systems of the Metaverse to train\na model cooperatively. Besides, to balance the trade-off between energy,\nexecution latency and model accuracy, thereby accommodating different demands\nand application scenarios, we formulate an optimization problem to minimize a\nweighted combination of total energy consumption, completion time and model\naccuracy. Through decomposing the non-convex optimization problem into two\nsubproblems, we devise a resource allocation algorithm to determine the\nbandwidth allocation, transmission power, CPU frequency and video frame\nresolution for each participating device. We further present the convergence\nanalysis and computational complexity of the proposed algorithm. Numerical\nresults show that our proposed algorithm has better performance (in terms of\nenergy consumption, completion time and model accuracy) under different weight\nparameters compared to existing benchmarks.",
    "descriptor": "\nComments: Journal version of 2022 IEEE 42nd International Conference on Distributed Computing Systems (ICDCS) paper: arXiv:2209.14900; i.e., this https URL\n",
    "authors": [
      "Xinyu Zhou",
      "Chang Liu",
      "Jun Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.08705"
  },
  {
    "id": "arXiv:2211.08706",
    "title": "Efficiently Finding Adversarial Examples with DNN Preprocessing",
    "abstract": "Deep Neural Networks (DNNs) are everywhere, frequently performing a fairly\ncomplex task that used to be unimaginable for machines to carry out. In doing\nso, they do a lot of decision making which, depending on the application, may\nbe disastrous if gone wrong. This necessitates a formal argument that the\nunderlying neural networks satisfy certain desirable properties. Robustness is\none such key property for DNNs, particularly if they are being deployed in\nsafety or business critical applications. Informally speaking, a DNN is not\nrobust if very small changes to its input may affect the output in a\nconsiderable way (e.g. changes the classification for that input). The task of\nfinding an adversarial example is to demonstrate this lack of robustness,\nwhenever applicable. While this is doable with the help of constrained\noptimization techniques, scalability becomes a challenge due to large-sized\nnetworks. This paper proposes the use of information gathered by preprocessing\nthe DNN to heavily simplify the optimization problem. Our experiments\nsubstantiate that this is effective, and does significantly better than the\nstate-of-the-art.",
    "descriptor": "",
    "authors": [
      "Avriti Chauhan",
      "Mohammad Afzal",
      "Hrishikesh Karmarkar",
      "Yizhak Elboher",
      "Kumar Madhukar",
      "Guy Katz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08706"
  },
  {
    "id": "arXiv:2211.08708",
    "title": "Exploring Detection-based Method For Speaker Diarization @ Ego4D  Audio-only Diarization Challenge 2022",
    "abstract": "We provide the technical report for Ego4D audio-only diarization challenge in\nECCV 2022. Speaker diarization takes the audio streams as input and outputs the\nhomogeneous segments according to the speaker's identity. It aims to solve the\nproblem of \"Who spoke when.\" In this paper, we explore a Detection-based method\nto tackle the audio-only speaker diarization task. Our method first extracts\naudio features by audio backbone and then feeds the feature to a\ndetection-generate network to get the speaker proposals. Finally, after\npostprocessing, we can get the diarization results. The validation dataset\nvalidates this method, and our method achieves 53.85 DER on the test dataset.\nThese results rank 3rd on the leaderboard of Ego4D audio-only diarization\nchallenge 2022.",
    "descriptor": "\nComments: 2 pages\n",
    "authors": [
      "Jiahao Wang",
      "Guo Chen",
      "Yin-Dong Zheng",
      "Tong Lu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.08708"
  },
  {
    "id": "arXiv:2211.08711",
    "title": "Beyond Worst-Case Budget-Feasible Mechanism Design",
    "abstract": "Motivated by large-market applications such as crowdsourcing, we revisit the\nproblem of budget-feasible mechanism design under a \"small-bidder assumption\".\nAnari, Goel, and Nikzad (2018) gave a mechanism that has optimal competitive\nratio $1-1/e$ on worst-case instances. However, we observe that on many\nrealistic instances, their mechanism is significantly outperformed by a simpler\nopen clock auction by Ensthaler and Giebe (2014), although the open clock\nauction only achieves competitive ratio $1/2$ in the worst case. Is there a\nmechanism that gets the best of both worlds, i.e., a mechanism that is\nworst-case optimal and performs favorably on realistic instances?\nOur first main result is the design and the analysis of a natural mechanism\nthat gives an affirmative answer to our question above: (i) We prove that on\nevery instance, our mechanism performs at least as good as all uniform\nmechanisms, including Anari, Goel, and Nikzad's and Ensthaler and Giebe's\nmechanisms. (ii) Moreover, we empirically evaluate our mechanism on various\nrealistic instances and observe that it beats the worst-case $1-1/e$\ncompetitive ratio by a large margin and compares favorably to both mechanisms\nmentioned above.\nOur second main result is more interesting in theory: We show that in the\nsemi-adversarial model of budget-smoothed analysis, where the adversary designs\na single worst-case market for a distribution of budgets, our mechanism is\noptimal among all (including non-uniform) mechanisms; furthermore our mechanism\nguarantees a strictly better-than-$(1-1/e)$ expected competitive ratio for any\nnon-trivial budget distribution regardless of the market. We complement the\npositive result with a characterization of the worst-case markets for any given\nbudget distribution and prove a fairly robust hardness result that holds\nagainst any budget distribution and any mechanism.",
    "descriptor": "\nComments: ITCS 2023\n",
    "authors": [
      "Aviad Rubinstein",
      "Junyao Zhao"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.08711"
  },
  {
    "id": "arXiv:2211.08712",
    "title": "Improving Feature-based Visual Localization by Geometry-Aided Matching",
    "abstract": "Feature matching is an essential step in visual localization, where the\naccuracy of camera pose is mainly determined by the established 2D-3D\ncorrespondence. Due to the noise, solving the camera pose accurately requires a\nsufficient number of well-distributed 2D-3D correspondences. Existing 2D-3D\nfeature matching is typically achieved by finding the nearest neighbors in the\nfeature space, and then removing the outliers by some hand-crafted heuristics.\nHowever, this may lead to a large number of potentially true matches being\nmissed or the established correct matches being filtered out. In this work, we\nintroduce a novel 2D-3D matching method, Geometry-Aided Matching (GAM), which\nuses both appearance information and geometric context to improve 2D-3D feature\nmatching. GAM can greatly strengthen the recall of 2D-3D matches while\nmaintaining high precision. We insert GAM into a hierarchical visual\nlocalization pipeline and show that GAM can effectively improve the robustness\nand accuracy of localization. Extensive experiments show that GAM can find more\ncorrect matches than hand-crafted heuristics and learning baselines. Our\nproposed localization method achieves state-of-the-art results on multiple\nvisual localization datasets. Experiments on Cambridge Landmarks dataset show\nthat our method outperforms the existing state-of-the-art methods and is six\ntimes faster than the top-performed method.",
    "descriptor": "",
    "authors": [
      "Hailin Yu",
      "Youji Feng",
      "Weicai Ye",
      "Mingxuan Jiang",
      "Hujun Bao",
      "Guofeng Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08712"
  },
  {
    "id": "arXiv:2211.08714",
    "title": "Reward Gaming in Conditional Text Generation",
    "abstract": "To align conditional text generation model outputs with desired behaviors,\nthere has been an increasing focus on training the model using reinforcement\nlearning (RL) with reward functions learned from human annotations. Under this\nframework, we identify three common cases where high rewards are incorrectly\nassigned to undesirable patterns: noise-induced spurious correlation, naturally\noccurring spurious correlation, and covariate shift. We show that even though\nlearned metrics achieve high performance on the distribution of the data used\nto train the reward function, the undesirable patterns may be amplified during\nRL training of the text generation model. While there has been discussion about\nreward gaming in the RL or safety community, in this short discussion piece, we\nwould like to highlight reward gaming in the NLG community using concrete\nconditional text generation examples and discuss potential fixes and areas for\nfuture work.",
    "descriptor": "",
    "authors": [
      "Richard Yuanzhe Pang",
      "Vishakh Padmakumar",
      "Thibault Sellam",
      "Ankur P. Parikh",
      "He He"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08714"
  },
  {
    "id": "arXiv:2211.08715",
    "title": "Conditional variational autoencoder to improve neural audio synthesis  for polyphonic music sound",
    "abstract": "Deep generative models for audio synthesis have recently been significantly\nimproved. However, the task of modeling raw-waveforms remains a difficult\nproblem, especially for audio waveforms and music signals. Recently, the\nrealtime audio variational autoencoder (RAVE) method was developed for\nhigh-quality audio waveform synthesis. The RAVE method is based on the\nvariational autoencoder and utilizes the two-stage training strategy.\nUnfortunately, the RAVE model is limited in reproducing wide-pitch polyphonic\nmusic sound. Therefore, to enhance the reconstruction performance, we adopt the\npitch activation data as an auxiliary information to the RAVE model. To handle\nthe auxiliary information, we propose an enhanced RAVE model with a conditional\nvariational autoencoder structure and an additional fully-connected layer. To\nevaluate the proposed structure, we conducted a listening experiment based on\nmultiple stimulus tests with hidden references and an anchor (MUSHRA) with the\nMAESTRO. The obtained results indicate that the proposed model exhibits a more\nsignificant performance and stability improvement than the conventional RAVE\nmodel.",
    "descriptor": "\nComments: 5 pages, 6 figures\n",
    "authors": [
      "Seokjin Lee",
      "Minhan Kim",
      "Seunghyeon Shin",
      "Daeho Lee",
      "Inseon Jang",
      "Wootaek Lim"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.08715"
  },
  {
    "id": "arXiv:2211.08722",
    "title": "Learning with Noisy Labels over Imbalanced Subpopulations",
    "abstract": "Learning with Noisy Labels (LNL) has attracted significant attention from the\nresearch community. Many recent LNL methods rely on the assumption that clean\nsamples tend to have \"small loss\". However, this assumption always fails to\ngeneralize to some real-world cases with imbalanced subpopulations, i.e.,\ntraining subpopulations varying in sample size or recognition difficulty.\nTherefore, recent LNL methods face the risk of misclassifying those\n\"informative\" samples (e.g., hard samples or samples in the tail\nsubpopulations) into noisy samples, leading to poor generalization performance.\nTo address the above issue, we propose a novel LNL method to simultaneously\ndeal with noisy labels and imbalanced subpopulations. It first leverages sample\ncorrelation to estimate samples' clean probabilities for label correction and\nthen utilizes corrected labels for Distributionally Robust Optimization (DRO)\nto further improve the robustness. Specifically, in contrast to previous works\nusing classification loss as the selection criterion, we introduce a\nfeature-based metric that takes the sample correlation into account for\nestimating samples' clean probabilities. Then, we refurbish the noisy labels\nusing the estimated clean probabilities and the pseudo-labels from the model's\npredictions. With refurbished labels, we use DRO to train the model to be\nrobust to subpopulation imbalance. Extensive experiments on a wide range of\nbenchmarks demonstrate that our technique can consistently improve current\nstate-of-the-art robust learning paradigms against noisy labels, especially\nwhen encountering imbalanced subpopulations.",
    "descriptor": "",
    "authors": [
      "MingCai Chen",
      "Yu Zhao",
      "Bing He",
      "Zongbo Han",
      "Bingzhe Wu",
      "Jianhua Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08722"
  },
  {
    "id": "arXiv:2211.08723",
    "title": "Noisy Pairing and Partial Supervision for Opinion Summarization",
    "abstract": "Current opinion summarization systems simply generate summaries reflecting\nimportant opinions from customer reviews, but the generated summaries may not\nattract the reader's attention. Although it is helpful to automatically\ngenerate professional reviewer-like summaries from customer reviews, collecting\nmany training pairs of customer and professional reviews is generally tricky.\nWe propose a weakly supervised opinion summarization framework, Noisy Pairing\nand Partial Supervision (NAPA) that can build a stylized opinion summarization\nsystem with no customer-professional review pairs. Experimental results show\nconsistent improvements in automatic evaluation metrics, and qualitative\nanalysis shows that our weakly supervised opinion summarization system can\ngenerate summaries that look more like those written by professional reviewers.",
    "descriptor": "",
    "authors": [
      "Hayate Iso",
      "Xiaolan Wang",
      "Yoshi Suhara"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08723"
  },
  {
    "id": "arXiv:2211.08724",
    "title": "PAANet:Visual Perception based Four-stage Framework for Salient Object  Detection using High-order Contrast Operator",
    "abstract": "It is believed that human vision system (HVS) consists of pre-attentive\nprocess and attention process when performing salient object detection (SOD).\nBased on this fact, we propose a four-stage framework for SOD, in which the\nfirst two stages match the \\textbf{P}re-\\textbf{A}ttentive process consisting\nof general feature extraction (GFE) and feature preprocessing (FP), and the\nlast two stages are corresponding to \\textbf{A}ttention process containing\nsaliency feature extraction (SFE) and the feature aggregation (FA), namely\n\\textbf{PAANet}. According to the pre-attentive process, the GFE stage applies\nthe fully-trained backbone and needs no further finetuning for different\ndatasets. This modification can greatly increase the training speed. The FP\nstage plays the role of finetuning but works more efficiently because of its\nsimpler structure and fewer parameters. Moreover, in SFE stage we design for\nsaliency feature extraction a novel contrast operator, which works more\nsemantically in contrast with the traditional convolution operator when\nextracting the interactive information between the foreground and its\nsurroundings. Interestingly, this contrast operator can be cascaded to form a\ndeeper structure and extract higher-order saliency more effective for complex\nscene. Comparative experiments with the state-of-the-art methods on 5 datasets\ndemonstrate the effectiveness of our framework.",
    "descriptor": "",
    "authors": [
      "Yanbo Yuan",
      "Hua Zhong",
      "Haixiong Li",
      "Xiao cheng",
      "Linmei Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.08724"
  },
  {
    "id": "arXiv:2211.08726",
    "title": "Streaming Joint Speech Recognition and Disfluency Detection",
    "abstract": "Disfluency detection has mainly been solved in a pipeline approach, as\npost-processing of speech recognition. In this study, we propose\nTransformer-based encoder-decoder models that jointly solve speech recognition\nand disfluency detection, which work in a streaming manner. Compared to\npipeline approaches, the joint models can leverage acoustic information that\nmakes disfluency detection robust to recognition errors and provide non-verbal\nclues. Moreover, joint modeling results in low-latency and lightweight\ninference. We investigate two joint model variants for streaming disfluency\ndetection: a transcript-enriched model and a multi-task model. The\ntranscript-enriched model is trained on text with special tags indicating the\nstarting and ending points of the disfluent part. However, it has problems with\nlatency and standard language model adaptation, which arise from the additional\ndisfluency tags. We propose a multi-task model to solve such problems, which\nhas two output layers at the Transformer decoder; one for speech recognition\nand the other for disfluency detection. It is modeled to be conditioned on the\ncurrently recognized token with an additional token-dependency mechanism. We\nshow that the proposed joint models outperformed a BERT-based pipeline approach\nin both accuracy and latency, on both the Switchboard and the corpus of\nspontaneous Japanese.",
    "descriptor": "",
    "authors": [
      "Hayato Futami",
      "Emiru Tsunoo",
      "Kentaro Shibata",
      "Yosuke Kashiwagi",
      "Takao Okuda",
      "Siddhant Arora",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.08726"
  },
  {
    "id": "arXiv:2211.08728",
    "title": "Exploring State Change Capture of Heterogeneous Backbones @ Ego4D Hands  and Objects Challenge 2022",
    "abstract": "Capturing the state changes of interacting objects is a key technology for\nunderstanding human-object interactions. This technical report describes our\nmethod using heterogeneous backbones for the Ego4D Object State Change\nClassification and PNR Temporal Localization Challenge. In the challenge, we\nused the heterogeneous video understanding backbones, namely CSN with 3D\nconvolution as operator and VideoMAE with Transformer as operator. Our method\nachieves an accuracy of 0.796 on OSCC while achieving an absolute temporal\nlocalization error of 0.516 on PNR. These excellent results rank 1st on the\nleaderboard of Ego4D OSCC & PNR-TL Challenge 2022.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Yin-Dong Zheng",
      "Guo Chen",
      "Jiahao Wang",
      "Tong Lu",
      "Limin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08728"
  },
  {
    "id": "arXiv:2211.08732",
    "title": "Lesion Guided Explainable Few Weak-shot Medical Report Generation",
    "abstract": "Medical images are widely used in clinical practice for diagnosis.\nAutomatically generating interpretable medical reports can reduce radiologists'\nburden and facilitate timely care. However, most existing approaches to\nautomatic report generation require sufficient labeled data for training. In\naddition, the learned model can only generate reports for the training classes,\nlacking the ability to adapt to previously unseen novel diseases. To this end,\nwe propose a lesion guided explainable few weak-shot medical report generation\nframework that learns correlation between seen and novel classes through visual\nand semantic feature alignment, aiming to generate medical reports for diseases\nnot observed in training. It integrates a lesion-centric feature extractor and\na Transformer-based report generation module. Concretely, the lesion-centric\nfeature extractor detects the abnormal regions and learns correlations between\nseen and novel classes with multi-view (visual and lexical) embeddings. Then,\nfeatures of the detected regions and corresponding embeddings are concatenated\nas multi-view input to the report generation module for explainable report\ngeneration, including text descriptions and corresponding abnormal regions\ndetected in the images. We conduct experiments on FFA-IR, a dataset providing\nexplainable annotations, showing that our framework outperforms others on\nreport generation for novel diseases.",
    "descriptor": "",
    "authors": [
      "Jinghan Sun",
      "Dong Wei",
      "Liansheng Wang",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08732"
  },
  {
    "id": "arXiv:2211.08733",
    "title": "Comparing Subjective Perceptions of Robot-to-Human Handover Trajectories",
    "abstract": "Robots must move legibly around people for safety reasons, especially for\ntasks where physical contact is possible. One such task is handovers, which\nrequires implicit communication on where and when physical contact (object\ntransfer) occurs. In this work, we study whether the trajectory model used by a\nrobot during the reaching phase affects the subjective perceptions of receivers\nfor robot-to-human handovers. We conducted a user study where 32 participants\nwere handed over three objects with four trajectory models: three were versions\nof a minimum jerk trajectory, and one was an ellipse-fitting-based trajectory.\nThe start position of the handover was fixed for all trajectories, and the end\nposition was allowed to vary randomly around a fixed position by $\\pm$3 cm in\nall axis. The user study found no significant differences among the handover\ntrajectories in survey questions relating to safety, predictability,\nnaturalness, and other subjective metrics. While these results seemingly reject\nthe hypothesis that the trajectory affects human perceptions of a handover, it\nprompts future research to investigate the effect of other variables, such as\nrobot speed, object transfer position, object orientation at the transfer\npoint, and explicit communication signals such as gaze and speech.",
    "descriptor": "\nComments: Submitted to Australasian Conference on Robotics and Automation 2022. 9 pages, 4 figures\n",
    "authors": [
      "Alexander Calvert",
      "Wesley Chan",
      "Tin Tran",
      "Sara Sheikholeslami",
      "Rhys Newbury",
      "Akansel Cosgun",
      "Elizabeth Croft"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.08733"
  },
  {
    "id": "arXiv:2211.08735",
    "title": "Can Strategic Data Collection Improve the Performance of Poverty  Prediction Models?",
    "abstract": "Machine learning-based estimates of poverty and wealth are increasingly being\nused to guide the targeting of humanitarian aid and the allocation of social\nassistance. However, the ground truth labels used to train these models are\ntypically borrowed from existing surveys that were designed to produce national\nstatistics -- not to train machine learning models. Here, we test whether\nadaptive sampling strategies for ground truth data collection can improve the\nperformance of poverty prediction models. Through simulations, we compare the\nstatus quo sampling strategies (uniform at random and stratified random\nsampling) to alternatives that prioritize acquiring training data based on\nmodel uncertainty or model performance on sub-populations. Perhaps\nsurprisingly, we find that none of these active learning methods improve over\nuniform-at-random sampling. We discuss how these results can help shape future\nefforts to refine machine learning-based estimates of poverty.",
    "descriptor": "\nComments: Artificial Intelligence for Humanitarian Assistance and Disaster Response Workshop, 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Satej Soman",
      "Emily Aiken",
      "Esther Rolf",
      "Joshua Blumenstock"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08735"
  },
  {
    "id": "arXiv:2211.08736",
    "title": "AlignVE: Visual Entailment Recognition Based on Alignment Relations",
    "abstract": "Visual entailment (VE) is to recognize whether the semantics of a hypothesis\ntext can be inferred from the given premise image, which is one special task\namong recent emerged vision and language understanding tasks. Currently, most\nof the existing VE approaches are derived from the methods of visual question\nanswering. They recognize visual entailment by quantifying the similarity\nbetween the hypothesis and premise in the content semantic features from multi\nmodalities. Such approaches, however, ignore the VE's unique nature of relation\ninference between the premise and hypothesis. Therefore, in this paper, a new\narchitecture called AlignVE is proposed to solve the visual entailment problem\nwith a relation interaction method. It models the relation between the premise\nand hypothesis as an alignment matrix. Then it introduces a pooling operation\nto get feature vectors with a fixed size. Finally, it goes through the\nfully-connected layer and normalization layer to complete the classification.\nExperiments show that our alignment-based architecture reaches 72.45\\% accuracy\non SNLI-VE dataset, outperforming previous content-based models under the same\nsettings.",
    "descriptor": "\nComments: This paper is accepted for publication as a REGULAR paper in the IEEE Transactions on Multimedia\n",
    "authors": [
      "Biwei Cao",
      "Jiuxin Cao",
      "Jie Gui",
      "Jiayun Shen",
      "Bo Liu",
      "Lei He",
      "Yuan Yan Tang",
      "James Tin-Yau Kwok"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.08736"
  },
  {
    "id": "arXiv:2211.08738",
    "title": "Distributed Node Covering Optimization for Large Scale Networks and Its  Application on Social Advertising",
    "abstract": "Combinatorial optimizations are usually complex and inefficient, which limits\ntheir applications in large-scale networks with billions of links. We introduce\na distributed computational method for solving a node-covering problem at the\nscale of factual scenarios. We first construct a genetic algorithm and then\ndesign a two-step strategy to initialize the candidate solutions. All the\ncomputational operations are designed and developed in a distributed form on\n\\textit{Apache Spark} enabling fast calculation for practical graphs. We apply\nour method to social advertising of recalling back churn users in online mobile\ngames, which was previously only treated as a traditional item recommending or\nranking problem.",
    "descriptor": "\nComments: 4 pages, 3 figures, submited to www23\n",
    "authors": [
      "Qiang Liu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.08738"
  },
  {
    "id": "arXiv:2211.08739",
    "title": "A higher order approximation method for jump-diffusion SDEs with  discontinuous drift coefficient",
    "abstract": "We present the first higher-order approximation scheme for solutions of\njump-diffusion stochastic differential equations with discontinuous drift. For\nthis transformation-based jump-adapted quasi-Milstein scheme we prove\n$L^p$-convergence order 3/4. To obtain this result, we prove that under\nslightly stronger assumptions (but still weaker than anything known before) a\nrelated jump-adapted quasi-Milstein scheme has convergence order 3/4 - in a\nspecial case even order 1. Order 3/4 is conjectured to be optimal.",
    "descriptor": "",
    "authors": [
      "Pawe\u0142 Przyby\u0142owicz",
      "Verena Schwarz",
      "Michaela Sz\u00f6lgyenyi"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.08739"
  },
  {
    "id": "arXiv:2211.08740",
    "title": "A Basic Algorithm for Generating Individualized Numerical Scale (BAGINS)",
    "abstract": "Linguistic labels are effective means of expressing qualitative assessments\nbecause they account for the uncertain nature of human preferences. However, to\nperform computations with linguistic labels, they must first be converted to\nnumbers using a scale function. Within the context of the Analytic Hierarchy\nProcess (AHP), the most popular scale used to represent linguistic labels\nnumerically is the linear 1-9 scale, which was proposed by Saaty. However, this\nscale has been criticized by several researchers, and various alternatives are\nproposed in the literature. There is a growing interest in scale\nindividualization rather than relying on a generic fixed scale since the\nperceptions of the decision maker regarding these linguistic labels are highly\nsubjective. The methods proposed in the literature for scale individualization\nfocus on minimizing the transitivity errors, i.e., consistency. In this\nresearch, we proposed a novel, easy-to-learn, easy-to-implement, and\ncomputationally less demanding scale individualization approach based on\ncompatibility. We also developed an experimental setup and introduced two new\nmetrics that can be used by researchers that contribute to the theory of AHP.\nTo assess the value of scale individualization in general, and the performance\nof the proposed novel approach in particular, numerical and two empirical\nstudies are conducted. The results of the analyses demonstrate that the scale\nindividualization outperforms the conventional fixed scale approach and\nvalidates the benefit of the proposed novel heuristic.",
    "descriptor": "",
    "authors": [
      "Faran Ahmed",
      "Kemal Kilic"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.08740"
  },
  {
    "id": "arXiv:2211.08742",
    "title": "Auditing Algorithmic Fairness in Machine Learning for Health with  Severity-Based LOGAN",
    "abstract": "Auditing machine learning-based (ML) healthcare tools for bias is critical to\npreventing patient harm, especially in communities that disproportionately face\nhealth inequities. General frameworks are becoming increasingly available to\nmeasure ML fairness gaps between groups. However, ML for health (ML4H) auditing\nprinciples call for a contextual, patient-centered approach to model\nassessment. Therefore, ML auditing tools must be (1) better aligned with ML4H\nauditing principles and (2) able to illuminate and characterize communities\nvulnerable to the most harm. To address this gap, we propose supplementing ML4H\nauditing frameworks with SLOGAN (patient Severity-based LOcal Group biAs\ndetectioN), an automatic tool for capturing local biases in a clinical\nprediction task. SLOGAN adapts an existing tool, LOGAN (LOcal Group biAs\ndetectioN), by contextualizing group bias detection in patient illness severity\nand past medical history. We investigate and compare SLOGAN's bias detection\ncapabilities to LOGAN and other clustering techniques across patient subgroups\nin the MIMIC-III dataset. On average, SLOGAN identifies larger fairness\ndisparities in over 75% of patient groups than LOGAN while maintaining\nclustering quality. Furthermore, in a diabetes case study, health disparity\nliterature corroborates the characterizations of the most biased clusters\nidentified by SLOGAN. Our results contribute to the broader discussion of how\nmachine learning biases may perpetuate existing healthcare disparities.",
    "descriptor": "\nComments: v1\n",
    "authors": [
      "Anaelia Ovalle",
      "Sunipa Dev",
      "Jieyu Zhao",
      "Majid Sarrafzadeh",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08742"
  },
  {
    "id": "arXiv:2211.08743",
    "title": "Yield Evaluation of Citrus Fruits based on the YoloV5 compressed by  Knowledge Distillation",
    "abstract": "In the field of planting fruit trees, pre-harvest estimation of fruit yield\nis important for fruit storage and price evaluation. However, considering the\ncost, the yield of each tree cannot be assessed by directly picking the\nimmature fruit. Therefore, the problem is a very difficult task. In this paper,\na fruit counting and yield assessment method based on computer vision is\nproposed for citrus fruit trees as an example. Firstly, images of single fruit\ntrees from different angles are acquired and the number of fruits is detected\nusing a deep Convolutional Neural Network model YOLOv5, and the model is\ncompressed using a knowledge distillation method. Then, a linear regression\nmethod is used to model yield-related features and evaluate yield. Experiments\nshow that the proposed method can accurately count fruits and approximate the\nyield.",
    "descriptor": "",
    "authors": [
      "Yuqi Li",
      "Yuting He",
      "Yihang Zhou",
      "Zirui Gong",
      "Renjie Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08743"
  },
  {
    "id": "arXiv:2211.08745",
    "title": "Variational and thermodynamically consistent finite element  discretization for heat conducting viscous fluids",
    "abstract": "Respecting the laws of thermodynamics is crucial for ensuring that numerical\nsimulations of dynamical systems deliver physically relevant results. In this\npaper, we construct a structure-preserving and thermodynamically consistent\nfinite element method and time-stepping scheme for heat conducting viscous\nfluids. The method is deduced by discretizing a variational formulation for\nnonequilibrium thermodynamics that extends Hamilton's principle for fluids to\nsystems with irreversible processes. The resulting scheme preserves the balance\nof energy and mass to machine precision, as well as the second law of\nthermodynamics, both at the spatially and temporally discrete levels. The\nmethod is shown to apply both with insulated and prescribed heat flux boundary\nconditions, as well as with prescribed temperature boundary conditions. We\nillustrate the properties of the scheme with the Rayleigh-B\\'enard thermal\nconvection. While the focus is on heat conducting viscous fluids, the proposed\ndiscrete variational framework paves the way to a systematic construction of\nthermodynamically consistent discretizations of continuum systems.",
    "descriptor": "\nComments: 29 pages, 3 figures\n",
    "authors": [
      "Evan S. Gawlik",
      "Fran\u00e7ois Gay-Balmaz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.08745"
  },
  {
    "id": "arXiv:2211.08747",
    "title": "Deep Joint Source-Channel Coding for Semantic Communications",
    "abstract": "Semantic communications is considered as a promising technology for reducing\nthe bandwidth requirements of next-generation communication systems,\nparticularly targeting human-machine interactions. In contrast to the\nsource-agnostic approach of conventional wireless communication systems,\nsemantic communication seeks to ensure that only the relevant information for\nthe underlying task is communicated to the receiver. A prominent approach to\nsemantic communications is to model it as a joint source-channel coding (JSCC)\nproblem. Although JSCC has been a long-standing open problem in communication\nand coding theory, remarkable performance gains have been shown recently over\nexisting separate source and channel coding systems, particularly in\nlow-latency and low-power scenarios, typically encountered in edge intelligence\napplications. Recent progress is thanks to the adoption of deep learning\ntechniques for JSCC code design, which are shown to outperform the\nconcatenation of state-of-the-art compression and channel coding schemes, each\nof which is a result of decades-long research efforts. In this article, we\npresent an adaptive deep learning based JSCC (DeepJSCC) architecture for\nsemantic communications, introduce its design principles, highlight its\nbenefits, and outline future research challenges that lie ahead.",
    "descriptor": "\nComments: 7 pages, 6 figures\n",
    "authors": [
      "Jialong Xu",
      "Tze-Yang Tung",
      "Bo Ai",
      "Wei Chen",
      "Yuxuan Sun",
      "Deniz Gunduz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.08747"
  },
  {
    "id": "arXiv:2211.08752",
    "title": "Indoor Positioning via Gradient Boosting Enhanced with Feature  Augmentation using Deep Learning",
    "abstract": "With the emerge of the Internet of Things (IoT), localization within indoor\nenvironments has become inevitable and has attracted a great deal of attention\nin recent years. Several efforts have been made to cope with the challenges of\naccurate positioning systems in the presence of signal interference. In this\npaper, we propose a novel deep learning approach through Gradient Boosting\nEnhanced with Step-Wise Feature Augmentation using Artificial Neural Network\n(AugBoost-ANN) for indoor localization applications as it trains over labeled\ndata. For this purpose, we propose an IoT architecture using a star network\ntopology to collect the Received Signal Strength Indicator (RSSI) of Bluetooth\nLow Energy (BLE) modules by means of a Raspberry Pi as an Access Point (AP) in\nan indoor environment. The dataset for the experiments is gathered in the real\nworld in different periods to match the real environments. Next, we address the\nchallenges of the AugBoost-ANN training which augments features in each\niteration of making a decision tree using a deep neural network and the\ntransfer learning technique. Experimental results show more than 8\\%\nimprovement in terms of accuracy in comparison with the existing gradient\nboosting and deep learning methods recently proposed in the literature, and our\nproposed model acquires a mean location accuracy of 0.77 m.",
    "descriptor": "",
    "authors": [
      "Ashkan Goharfar",
      "Jaber Babaki",
      "Mehdi Rasti",
      "Pedro H. J. Nardelli"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08752"
  },
  {
    "id": "arXiv:2211.08754",
    "title": "Advanced Situational Graphs for Robot Navigation in Structured Indoor  Environments",
    "abstract": "Mobile robots extract information from its environment to understand their\ncurrent situation to enable intelligent decision making and autonomous task\nexecution. In our previous work, we introduced the concept of Situation Graphs\n(S-Graphs) which combines in a single optimizable graph, the robot keyframes\nand the representation of the environment with geometric, semantic and\ntopological abstractions. Although S-Graphs were built and optimized in\nreal-time and demonstrated state-of-the-art results, they are limited to\nspecific structured environments with specific hand-tuned dimensions of rooms\nand corridors.\nIn this work, we present an advanced version of the Situational Graphs\n(S-Graphs+), consisting of the five layered optimizable graph that includes (1)\nmetric layer along with the graph of free-space clusters (2) keyframe layer\nwhere the robot poses are registered (3) metric-semantic layer consisting of\nthe extracted planar walls (4) novel rooms layer constraining the extracted\nplanar walls (5) novel floors layer encompassing the rooms within a given floor\nlevel. S-Graphs+ demonstrates improved performance over S-Graphs efficiently\nextracting the room information while simultaneously improving the pose\nestimate of the robot, thus extending the robots situational awareness in the\nform of a five layered environmental model.",
    "descriptor": "\nComments: 4 pages, IROS 2022 Workshop Paper. arXiv admin note: text overlap with arXiv:2202.12197\n",
    "authors": [
      "Hriday Bavle",
      "Jose Luis Sanchez-Lopez",
      "Muhammad Shaheer",
      "Javier Civera",
      "Holger Voos"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08754"
  },
  {
    "id": "arXiv:2211.08760",
    "title": "SVD-PINNs: Transfer Learning of Physics-Informed Neural Networks via  Singular Value Decomposition",
    "abstract": "Physics-informed neural networks (PINNs) have attracted significant attention\nfor solving partial differential equations (PDEs) in recent years because they\nalleviate the curse of dimensionality that appears in traditional methods.\nHowever, the most disadvantage of PINNs is that one neural network corresponds\nto one PDE. In practice, we usually need to solve a class of PDEs, not just\none. With the explosive growth of deep learning, many useful techniques in\ngeneral deep learning tasks are also suitable for PINNs. Transfer learning\nmethods may reduce the cost for PINNs in solving a class of PDEs. In this\npaper, we proposed a transfer learning method of PINNs via keeping singular\nvectors and optimizing singular values (namely SVD-PINNs). Numerical\nexperiments on high dimensional PDEs (10-d linear parabolic equations and 10-d\nAllen-Cahn equations) show that SVD-PINNs work for solving a class of PDEs with\ndifferent but close right-hand-side functions.",
    "descriptor": "\nComments: Accepted to The 2022 IEEE Symposium Series on Computational Intelligence (IEEE SSCI 2022)\n",
    "authors": [
      "Yihang Gao",
      "Ka Chun Cheung",
      "Michael K. Ng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.08760"
  },
  {
    "id": "arXiv:2211.08761",
    "title": "Separable PINN: Mitigating the Curse of Dimensionality in  Physics-Informed Neural Networks",
    "abstract": "Physics-informed neural networks (PINNs) have emerged as new data-driven PDE\nsolvers for both forward and inverse problems. While promising, the expensive\ncomputational costs to obtain solutions often restrict their broader\napplicability. We demonstrate that the computations in automatic\ndifferentiation (AD) can be significantly reduced by leveraging forward-mode AD\nwhen training PINN. However, a naive application of forward-mode AD to\nconventional PINNs results in higher computation, losing its practical benefit.\nTherefore, we propose a network architecture, called separable PINN (SPINN),\nwhich can facilitate forward-mode AD for more efficient computation. SPINN\noperates on a per-axis basis instead of point-wise processing in conventional\nPINNs, decreasing the number of network forward passes. Besides, while the\ncomputation and memory costs of standard PINNs grow exponentially along with\nthe grid resolution, that of our model is remarkably less susceptible,\nmitigating the curse of dimensionality. We demonstrate the effectiveness of our\nmodel in various PDE systems by significantly reducing the training run-time\nwhile achieving comparable accuracy. Project page:\n\\url{https://jwcho5576.github.io/spinn/}",
    "descriptor": "\nComments: To appear in NeurIPS 2022 Workshop on The Symbiosis of Deep Learning and Differential Equations (DLDE) - II, 9 pages, 5 figures\n",
    "authors": [
      "Junwoo Cho",
      "Seungtae Nam",
      "Hyunmo Yang",
      "Seok-Bae Yun",
      "Youngjoon Hong",
      "Eunbyung Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08761"
  },
  {
    "id": "arXiv:2211.08769",
    "title": "RetroMAE v2: Duplex Masked Auto-Encoder For Pre-Training  Retrieval-Oriented Language Models",
    "abstract": "To better support retrieval applications such as web search and question\nanswering, growing effort is made to develop retrieval-oriented language\nmodels. Most of the existing works focus on improving the semantic\nrepresentation capability for the contextualized embedding of [CLS] token.\nHowever, recent study shows that the ordinary tokens besides [CLS] may provide\nextra information, which helps to produce a better representation effect. As\nsuch, it's necessary to extend the current methods where all contextualized\nembeddings can be jointly pre-trained for the retrieval tasks.\nWith this motivation, we propose a new pre-training method: duplex masked\nauto-encoder, a.k.a. DupMAE, which targets on improving the semantic\nrepresentation capacity for the contextualized embeddings of both [CLS] and\nordinary tokens. It introduces two decoding tasks: one is to reconstruct the\noriginal input sentence based on the [CLS] embedding, the other one is to\nminimize the bag-of-words loss (BoW) about the input sentence based on the\nentire ordinary tokens' embeddings. The two decoding losses are added up to\ntrain a unified encoding model. The embeddings from [CLS] and ordinary tokens,\nafter dimension reduction and aggregation, are concatenated as one unified\nsemantic representation for the input. DupMAE is simple but empirically\ncompetitive: with a small decoding cost, it substantially contributes to the\nmodel's representation capability and transferability, where remarkable\nimprovements are achieved on MS MARCO and BEIR benchmarks.",
    "descriptor": "",
    "authors": [
      "Shitao Xiao",
      "Zheng Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.08769"
  },
  {
    "id": "arXiv:2211.08770",
    "title": "On some orthogonalization schemes in Tensor Train format",
    "abstract": "In the framework of tensor spaces, we consider orthogonalization kernels to\ngenerate an orthogonal basis of a tensor subspace from a set of linearly\nindependent tensors. In particular, we investigate numerically the loss of\northogonality of six orthogonalization methods, namely Classical and Modified\nGram-Schmidt with (CGS2, MGS2) and without (CGS, MGS) re-orthogonalization, the\nGram approach, and the Householder transformation. To tackle the curse of\ndimensionality, we represent tensor with low rank approximation using the\nTensor Train (TT) formalism, and we introduce recompression steps in the\nstandard algorithm outline through the TT-rounding method at a prescribed\naccuracy. After describing the algorithm structure and properties, we\nillustrate numerically that the theoretical bounds for the loss of\northogonality in the classical matrix computation round-off analysis results\nare maintained, with the unit round-off replaced by the TT-rounding accuracy.\nThe computational analysis for each orthogonalization kernel in terms of the\nmemory requirement and the computational complexity measured as a function of\nthe number of TT-rounding, which happens to be the computational most expensive\noperation, completes the study.",
    "descriptor": "",
    "authors": [
      "Olivier Coulaud",
      "Luc Giraud",
      "Martina Iannacito"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.08770"
  },
  {
    "id": "arXiv:2211.08771",
    "title": "Symmetries in the dynamics of wide two-layer neural networks",
    "abstract": "We consider the idealized setting of gradient flow on the population risk for\ninfinitely wide two-layer ReLU neural networks (without bias), and study the\neffect of symmetries on the learned parameters and predictors. We first\ndescribe a general class of symmetries which, when satisfied by the target\nfunction $f^*$ and the input distribution, are preserved by the dynamics. We\nthen study more specific cases. When $f^*$ is odd, we show that the dynamics of\nthe predictor reduces to that of a (non-linearly parameterized) linear\npredictor, and its exponential convergence can be guaranteed. When $f^*$ has a\nlow-dimensional structure, we prove that the gradient flow PDE reduces to a\nlower-dimensional PDE. Furthermore, we present informal and numerical arguments\nthat suggest that the input neurons align with the lower-dimensional structure\nof the problem.",
    "descriptor": "",
    "authors": [
      "Karl Hajjar",
      "Lenaic Chizat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.08771"
  },
  {
    "id": "arXiv:2211.08772",
    "title": "TransCC: Transformer-based Multiple Illuminant Color Constancy Using  Multitask Learning",
    "abstract": "Multi-illuminant color constancy is a challenging problem with only a few\nexisting methods. For example, one prior work used a small set of predefined\nwhite balance settings and spatially blended among them, limiting the solution\nto predefined illuminations. Another method proposed a generative adversarial\nnetwork and an angular loss, yet the performance is suboptimal due to the lack\nof regularization for multi-illumination colors. This paper introduces a\ntransformer-based multi-task learning method to estimate single and multiple\nlight colors from a single input image. To help our deep learning model have\nbetter cues of the light colors, achromatic-pixel detection, and edge detection\nare used as auxiliary tasks in our multi-task learning setting. By exploiting\nextracted content features from the input image as tokens, illuminant color\ncorrelations between pixels are learned by leveraging contextual information in\nour transformer. Our transformer approach is further assisted via a contrastive\nloss defined between the input, output, and ground truth. We demonstrate that\nour proposed model achieves 40.7% improvement compared to a state-of-the-art\nmulti-illuminant color constancy method on a multi-illuminant dataset (LSMI).\nMoreover, our model maintains a robust performance on the single illuminant\ndataset (NUS-8) and provides 22.3% improvement on the state-of-the-art single\ncolor constancy method.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Shuwei Li",
      "Jikai Wang",
      "Michael S. Brown",
      "Robby T. Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08772"
  },
  {
    "id": "arXiv:2211.08774",
    "title": "Speaker Adaptation for End-To-End Speech Recognition Systems in Noisy  Environments",
    "abstract": "We analyze the impact of speaker adaptation in end-to-end architectures based\non transformers and wav2vec 2.0 under different noise conditions. We\ndemonstrate that the proven method of concatenating speaker vectors to the\nacoustic features and supplying them as an auxiliary model input remains a\nviable option to increase the robustness of end-to-end architectures. By\nincluding speaker embeddings obtained from x-vector and ECAPA-TDNN models, we\nachieve relative word error rate improvements of up to 9.6% on LibriSpeech and\nup to 14.5% on Switchboard. The effect on transformer-based architectures is\napproximately inversely proportional to the signal-to-noise ratio (SNR) and is\nstrongest in heavily noised environments ($SNR=0$). The most substantial\nbenefit of speaker adaption in systems based on wav2vec 2.0 can be achieved\nunder moderate noise conditions ($SNR\\geq18$). We also find that x-vectors tend\nto yield larger improvements than ECAPA-TDNN embeddings.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Dominik Wagner",
      "Ilja Baumann",
      "Sebastian P. Bayerl",
      "Korbinian Riedhammer",
      "Tobias Bocklet"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.08774"
  },
  {
    "id": "arXiv:2211.08776",
    "title": "An Efficient COarse-to-fiNE Alignment Framework @ Ego4D Natural Language  Queries Challenge 2022",
    "abstract": "This technical report describes the CONE approach for Ego4D Natural Language\nQueries (NLQ) Challenge in ECCV 2022. We leverage our model CONE, an efficient\nwindow-centric COarse-to-fiNE alignment framework. Specifically, CONE\ndynamically slices the long video into candidate windows via a sliding window\napproach. Centering at windows, CONE (1) learns the inter-window\n(coarse-grained) semantic variance through contrastive learning and speeds up\ninference by pre-filtering the candidate windows relevant to the NL query, and\n(2) conducts intra-window (fine-grained) candidate moments ranking utilizing\nthe powerful multi-modal alignment ability of the contrastive vision-text\npre-trained model EgoVLP. On the blind test set, CONE achieves 15.26 and 9.24\nfor R1@IoU=0.3 and R1@IoU=0.5, respectively.",
    "descriptor": "\nComments: Technical report for ECCV 2022 Ego4D workshop, 4 pages, 2 figures, 2 tables. arXiv admin note: substantial text overlap with arXiv:2209.10918\n",
    "authors": [
      "Zhijian Hou",
      "Wanjun Zhong",
      "Lei Ji",
      "Difei Gao",
      "Kun Yan",
      "Wing-Kwong Chan",
      "Chong-Wah Ngo",
      "Zheng Shou",
      "Nan Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.08776"
  },
  {
    "id": "arXiv:2211.08777",
    "title": "IRS-Assistance with Outdated CSI: Element subset selection for secrecy  performance enhancement",
    "abstract": "In this work, we investigate the secrecy performance in an intelligent\nreflecting surface (IRS)-assisted downlink system. In particular, we consider a\nbase station (BS)-side IRS and as such, the BS-IRS channel is assumed to be\nknown perfectly. Of more importance, we consider the case, in which only\noutdated channel state information (CSI) of the IRS-user channel is available.\nWe study the impact of outdated CSI on the secrecy performance numerically and\nanalytically. Furthermore, we propose an element subset selection (ESS) method\nin order to improve the secrecy performance. A key observation is that minimal\nsecrecy outage probability (SOP) can be achieved using a subset of the IRS, and\nthe optimal number of selected reflecting elements can be effectively found by\nclosed-form expressions.",
    "descriptor": "",
    "authors": [
      "Chu Li",
      "Aydin Sezgin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.08777"
  },
  {
    "id": "arXiv:2211.08778",
    "title": "A Combinational Multi-Kernel Decoder for Polar Codes",
    "abstract": "Polar codes have been selected as the channel coding scheme for control\nchannel in the fifth generation (5G) communication system thanks to their\ncapacity achieving characteristics. However, the traditional polar codes\nsupport only codes constructed by binary (2x2) kernel which limits the code\nlengths to powers of 2. Multi-kernel polar codes are proposed to achieve\nflexible block length. In this paper, the first combinational decoder for\nmulti-kernel polar codes based on successive cancellation algorithm is\nproposed. The proposed decoder can decode pure-binary and binary-ternary (3x3)\nmixed polar codes. The architecture is rate-flexible with the capability of\nonline rate assignment and supports any kernel sequences. The FPGA\nimplementation results reveal that for a code of length N = 48, the coded\nthroughput of 812.1 Mbps can be achieved.",
    "descriptor": "",
    "authors": [
      "Hossein Rezaei",
      "Nandana Rajatheva",
      "Matti Latva-aho"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Hardware Architecture (cs.AR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.08778"
  },
  {
    "id": "arXiv:2211.08787",
    "title": "Minimization and Learning of Deterministic $\u03c9$-Automata in the  Presence of Don't Care Words",
    "abstract": "We study minimization problems for deterministic $\\omega$-automata in the\npresence of don't care words. We prove that the number of priorities in\ndeterministic parity automata can be efficiently minimized under an arbitrary\nset of don't care words. We derive that from a more general result from which\none also obtains an efficient minimization algorithm for deterministic parity\nautomata with informative right-congruence (without don't care words).\nWe then analyze languages of don't care words with a trivial\nright-congruence. For such sets of don't care words it is known that weak\ndeterministic B\\\"uchi automata (WDBA) have a unique minimal automaton that can\nbe efficiently computed from a given WDBA (Eisinger, Klaedtke 2006). We give a\ncongruence-based characterization of the corresponding minimal WDBA, and show\nthat the don't care minimization results for WDBA do not extend to\ndeterministic $\\omega$-automata with informative right-congruence: for this\nclass there is no unique minimal automaton for a given don't care set with\ntrivial right congruence, and the minimization problem is NP-hard. Finally, we\nextend an active learning algorithm for WDBA (Maler, Pnueli 1995) to the\nsetting with an additional set of don't care words with trivial\nright-congruence.",
    "descriptor": "",
    "authors": [
      "Christof L\u00f6ding",
      "Max Philip Stachon"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2211.08787"
  },
  {
    "id": "arXiv:2211.08788",
    "title": "CSCD-IME: Correcting Spelling Errors Generated by Pinyin IME",
    "abstract": "Chinese Spelling Correction (CSC) is a task to detect and correct spelling\nmistakes in texts. In fact, most of Chinese input is based on pinyin input\nmethod, so the study of spelling errors in this process is more practical and\nvaluable. However, there is still no research dedicated to this essential\nscenario. In this paper, we first present a Chinese Spelling Correction Dataset\nfor errors generated by pinyin IME (CSCD-IME), including 40,000 annotated\nsentences from real posts of official media on Sina Weibo. Furthermore, we\npropose a novel method to automatically construct large-scale and high-quality\npseudo data by simulating the input through pinyin IME. A series of analyses\nand experiments on CSCD-IME show that spelling errors produced by pinyin IME\nhold a particular distribution at pinyin level and semantic level and are\nchallenging enough. Meanwhile, our proposed pseudo-data construction method can\nbetter fit this error distribution and improve the performance of CSC systems.\nFinally, we also provide a useful guide to using pseudo data, including the\ndata scale, the data source, and the training strategy",
    "descriptor": "",
    "authors": [
      "Yong Hu",
      "Fandong Meng",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08788"
  },
  {
    "id": "arXiv:2211.08792",
    "title": "Some Properties of the NE in $2 \\times 2$ Zero-Sum Games",
    "abstract": "In this report, some properties of the set of Nash equilibria (NEs) of $2\n\\times 2$ zero-sum games are reviewed. In particular, the cardinality of the\nset of NEs is given in terms of the entries of the payoff matrix. Moreover,\nclosed-form expressions for the NE strategies and the payoff at the NE (the\nvalue of the game) are provided in terms of the entries of the payoff matrix.\nThe results presented in this report are not necessarily new knowledge, as they\nfollow from the definition of the NE after some tedious calculations.\nNevertheless this synthetic presentation is original in the literature.",
    "descriptor": "",
    "authors": [
      "Ke Sun"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.08792"
  },
  {
    "id": "arXiv:2211.08794",
    "title": "Towards Robust Low-Resource Fine-Tuning with Multi-View Compressed  Representations",
    "abstract": "Due to the huge amount of parameters, fine-tuning of pretrained language\nmodels (PLMs) is prone to overfitting in the low resource scenarios. In this\nwork, we present a novel method that operates on the hidden representations of\na PLM to reduce overfitting. During fine-tuning, our method inserts random\nautoencoders between the hidden layers of a PLM, which transform activations\nfrom the previous layers into a multi-view compressed representation before\nfeeding it into the upper layers. The autoencoders are plugged out after\nfine-tuning, so our method does not add extra parameters or increase\ncomputation cost during inference. Our method demonstrates promising\nperformance improvement across a wide range of sequence- and token-level\nlow-resource NLP tasks.",
    "descriptor": "",
    "authors": [
      "Linlin Liu",
      "Xingxuan Li",
      "Megh Thakkar",
      "Xin Li",
      "Lidong Bing",
      "Shafiq Joty",
      "Luo Si"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08794"
  },
  {
    "id": "arXiv:2211.08796",
    "title": "Model Based Residual Policy Learning with Applications to Antenna  Control",
    "abstract": "Non-differentiable controllers and rule-based policies are widely used for\ncontrolling real systems such as robots and telecommunication networks. In this\npaper, we present a practical reinforcement learning method which improves upon\nsuch existing policies with a model-based approach for better sample\nefficiency. Our method significantly outperforms state-of-the-art model-based\nmethods, in terms of sample efficiency, on several widely used robotic\nbenchmark tasks. We also demonstrate the effectiveness of our approach on a\ncontrol problem in the telecommunications domain, where model-based methods\nhave not previously been explored. Experimental results indicate that a strong\ninitial performance can be achieved and combined with improved sample\nefficiency. We further motivate the design of our algorithm with a theoretical\nlower bound on the performance.",
    "descriptor": "",
    "authors": [
      "Viktor Eriksson M\u00f6llerstedt",
      "Alessio Russo",
      "Maxime Bouton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.08796"
  },
  {
    "id": "arXiv:2211.08799",
    "title": "Speeding Up Recommender Systems Using Association Rules",
    "abstract": "Recommender systems are considered one of the most rapidly growing branches\nof Artificial Intelligence. The demand for finding more efficient techniques to\ngenerate recommendations becomes urgent. However, many recommendations become\nuseless if there is a delay in generating and showing them to the user.\nTherefore, we focus on improving the speed of recommendation systems without\nimpacting the accuracy. In this paper, we suggest a novel recommender system\nbased on Factorization Machines and Association Rules (FMAR). We introduce an\napproach to generate association rules using two algorithms: (i) apriori and\n(ii) frequent pattern (FP) growth. These association rules will be utilized to\nreduce the number of items passed to the factorization machines recommendation\nmodel. We show that FMAR has significantly decreased the number of new items\nthat the recommender system has to predict and hence, decreased the required\ntime for generating the recommendations. On the other hand, while building the\nFMAR tool, we concentrate on making a balance between prediction time and\naccuracy of generated recommendations to ensure that the accuracy is not\nsignificantly impacted compared to the accuracy of using factorization machines\nwithout association rules.",
    "descriptor": "\nComments: 13 pages, 3 figures, 1 table, 14th Asian Conference on Intelligent Information and Database Systems (ACIIDS)\n",
    "authors": [
      "Eyad Kannout",
      "Hung Son Nguyen",
      "Marek Grzegorowski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08799"
  },
  {
    "id": "arXiv:2211.08800",
    "title": "Bounding the Response Time of DAG Tasks Using Long Paths",
    "abstract": "In 1969, Graham developed a well-known response time bound for a DAG task\nusing the total workload and the longest path of the DAG, which has been widely\napplied to solve many scheduling and analysis problems of DAG-based task\nsystems. This paper presents a new response time bound for a DAG task using the\ntotal workload and the lengths of multiple long paths of the DAG, instead of\nthe longest path in Graham's bound. Our new bound theoretically dominates and\nempirically outperforms Graham's bound. We further extend the proposed approach\nto multi-DAG task systems. Our schedulability test theoretically dominates\nfederated scheduling and outperforms the state-of-the-art by a considerable\nmargin.",
    "descriptor": "",
    "authors": [
      "Qingqiang He",
      "Nan Guan",
      "Mingsong Lv",
      "Xu Jiang",
      "Wanli Chang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.08800"
  },
  {
    "id": "arXiv:2211.08802",
    "title": "Giving Feedback on Interactive Student Programs with Meta-Exploration",
    "abstract": "Developing interactive software, such as websites or games, is a particularly\nengaging way to learn computer science. However, teaching and giving feedback\non such software is time-consuming -- standard approaches require instructors\nto manually grade student-implemented interactive programs. As a result, online\nplatforms that serve millions, like Code.org, are unable to provide any\nfeedback on assignments for implementing interactive programs, which critically\nhinders students' ability to learn. One approach toward automatic grading is to\nlearn an agent that interacts with a student's program and explores states\nindicative of errors via reinforcement learning. However, existing work on this\napproach only provides binary feedback of whether a program is correct or not,\nwhile students require finer-grained feedback on the specific errors in their\nprograms to understand their mistakes. In this work, we show that exploring to\ndiscover errors can be cast as a meta-exploration problem. This enables us to\nconstruct a principled objective for discovering errors and an algorithm for\noptimizing this objective, which provides fine-grained feedback. We evaluate\nour approach on a set of over 700K real anonymized student programs from a\nCode.org interactive assignment. Our approach provides feedback with 94.3%\naccuracy, improving over existing approaches by 17.7% and coming within 1.5% of\nhuman-level accuracy. Project web page: https://ezliu.github.io/dreamgrader.",
    "descriptor": "\nComments: Advances in Neural Information Processing Systems (NeurIPS 2022). Selected as Oral\n",
    "authors": [
      "Evan Zheran Liu",
      "Moritz Stephan",
      "Allen Nie",
      "Chris Piech",
      "Emma Brunskill",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.08802"
  },
  {
    "id": "arXiv:2211.08804",
    "title": "Analysis and Detectability of Offline Data Poisoning Attacks on Linear  Systems",
    "abstract": "A recent body of literature has investigated the effect of data poisoning\nattacks on data-driven control methods. Data poisoning attacks are well-known\nto the Machine Learning community, which, however, make use of assumptions,\nsuch as cross-sample independence, that in general do not hold for dynamical\nsystems. As a consequence, attacks, and detection methods, operate differently\nfrom the i.i.d. setting studied in classical supervised problems. In\nparticular, data poisoning attacks against data-driven control methods can be\nfundamentally seen as changing the behavior of the dynamical system described\nby the data. In this work, we study this phenomenon through the lens of\nstatistical testing, and verify the detectability of different attacks for a\nlinear dynamical system. On the basis of the arguments hereby presented, we\npropose a stealthy data poisoning attack that can escape classical detection\ntests, and conclude by showing the efficiency of the proposed attack.",
    "descriptor": "",
    "authors": [
      "Alessio Russo",
      "Alexandre Proutiere"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08804"
  },
  {
    "id": "arXiv:2211.08805",
    "title": "Interacting Hand-Object Pose Estimation via Dense Mutual Attention",
    "abstract": "3D hand-object pose estimation is the key to the success of many computer\nvision applications. The main focus of this task is to effectively model the\ninteraction between the hand and an object. To this end, existing works either\nrely on interaction constraints in a computationally-expensive iterative\noptimization, or consider only a sparse correlation between sampled hand and\nobject keypoints. In contrast, we propose a novel dense mutual attention\nmechanism that is able to model fine-grained dependencies between the hand and\nthe object. Specifically, we first construct the hand and object graphs\naccording to their mesh structures. For each hand node, we aggregate features\nfrom every object node by the learned attention and vice versa for each object\nnode. Thanks to such dense mutual attention, our method is able to produce\nphysically plausible poses with high quality and real-time inference speed.\nExtensive quantitative and qualitative experiments on large benchmark datasets\nshow that our method outperforms state-of-the-art methods. The code is\navailable at https://github.com/rongakowang/DenseMutualAttention.git.",
    "descriptor": "",
    "authors": [
      "Rong Wang",
      "Wei Mao",
      "Hongdong Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08805"
  },
  {
    "id": "arXiv:2211.08812",
    "title": "The Levenshtein's Sequence Reconstruction Problem and the Length of the  List",
    "abstract": "In the paper, the Levenshtein's sequence reconstruction problem is considered\nin the case where at most $t$ substitution errors occur in each of the $N$\nchannels and the decoder outputs a list of length $\\mathcal{L}$. Moreover, it\nis assumed that the transmitted words are chosen from an $e$-error-correcting\ncode $C \\ (\\subseteq \\{0,1\\}^n)$. Previously, when $t = e+\\ell$ and the length\n$n$ of the transmitted word is large enough, the numbers of required channels\nare determined for $\\mathcal{L} =1, 2 \\text{ and } \\ell+1$. Here we determine\nthe exact number of channels in the cases $\\mathcal{L} = 3, 4, \\ldots, \\ell$.\nFurthermore, with the aid of covering codes, we also consider the list sizes in\nthe cases where the length $n$ is rather small (improving previously known\nresults). After that we study how much we can decrease the number of required\nchannels when we use list-decoding codes. Finally, the majority algorithm is\ndiscussed for decoding in a probabilistic set-up; in particular, we show that\nwith high probability a decoder based on it is verifiably successful, i.e., the\noutput word of the decoder can be verified to be the transmitted one.",
    "descriptor": "",
    "authors": [
      "Ville Junnila",
      "Tero Laihonen",
      "Tuomo Lehtil\u00e4"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.08812"
  },
  {
    "id": "arXiv:2211.08813",
    "title": "Efficient and Fine-grained Redactable Blockchain Supporting  Accountability and Updating Policies",
    "abstract": "Redactable Blockchain aims to ensure immutability of the data for most of\nappications, and provide authorized mutability for some specific applications\nsuch as removing illegal content from blockchains. However, the existing\nredactable blockchain scheme has low redacting efficiency, and lacks an\naccountable and updatable fine-grained mechanism to control redacting rights.\nTo solve the above problems, we propose an efficient and fine-grained\nredactable blockchain scheme with accountability and updatable policies. In our\nscheme, the transaction owner can set the updatable policy associated with the\ntransaction, and only users who meet the policy can become the redactor of the\ntransaction. In order to prevent redactors from abusing redacting right, we\nintroduce the concept of a witness group. A redacted transaction is legal if\nand only if it contains the signatures of redactor and witness group. We first\ngive the concept of witness group, and then show the proposed scheme. Finally,\nwe demonstrate that scheme is feasible and efficient through a series of\nexperiments and analysis.",
    "descriptor": "",
    "authors": [
      "Bin Luo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.08813"
  },
  {
    "id": "arXiv:2211.08820",
    "title": "Computing-Aware Routing for LEO Satellite Networks: A Transmission and  Computation Integration Approach",
    "abstract": "The advancements of remote sensing (RS) pose increasingly high demands on\ncomputation and transmission resources. Conventional ground-offloading\ntechniques, which transmit large amounts of raw data to the ground, suffer from\npoor satellite-to-ground link quality. In addition, existing\nsatellite-offloading techniques, which offload computational tasks to low earth\norbit (LEO) satellites located within the visible range of RS satellites for\nprocessing, cannot leverage the full computing capability of the network\nbecause the computational resources of visible LEO satellites are limited. This\nsituation is even worse in hotspot areas.\nIn this paper, for efficient offloading via LEO satellite networks, we\npropose a novel computing-aware routing scheme. It fuses the transmission and\ncomputation processes and optimizes the overall delay of both. Specifically, we\nfirst model the LEO satellite network as a snapshot-free dynamic network, whose\nnodes and edges both have time-varying weights. By utilizing time-varying\nnetwork parameters to characterize the network dynamics, the proposed method\nestablishes a continuous-time model which scales well on large networks and\nimproves the accuracy. Next, we propose a computing-aware routing scheme\nfollowing the model. It processes tasks during the routing process instead of\noffloading raw data to ground stations, reducing the overall delay and avoiding\nnetwork congestion consequently. Finally, we formulate the computing-aware\nrouting problem in the dynamic network as a combination of multiple dynamic\nsingle source shortest path (DSSSP) problems and propose a genetic algorithm\n(GA) based method to approximate the results in a reasonable time. Simulation\nresults show that the computing-aware routing scheme decreases the overall\ndelay by up to 78.31% compared with offloading raw data to the ground to\nprocess.",
    "descriptor": "",
    "authors": [
      "Jiaqi Cao",
      "Shengli Zhang",
      "Qingxia Chen",
      "Houtian Wang",
      "Mingzhe Wang",
      "Naijin Liu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.08820"
  },
  {
    "id": "arXiv:2211.08824",
    "title": "SMILEtrack: SiMIlarity LEarning for Multiple Object Tracking",
    "abstract": "Multiple Object Tracking (MOT) is widely investigated in computer vision with\nmany applications. Tracking-By-Detection (TBD) is a popular multiple-object\ntracking paradigm. TBD consists of the first step of object detection and the\nsubsequent of data association, tracklet generation, and update. We propose a\nSimilarity Learning Module (SLM) motivated from the Siamese network to extract\nimportant object appearance features and a procedure to combine object motion\nand appearance features effectively. This design strengthens the modeling of\nobject motion and appearance features for data association. We design a\nSimilarity Matching Cascade (SMC) for the data association of our SMILEtrack\ntracker. SMILEtrack achieves 81.06 MOTA and 80.5 IDF1 on the MOTChallenge and\nthe MOT17 test set, respectively.",
    "descriptor": "\nComments: 9 pages, 6 figures\n",
    "authors": [
      "Yu-Hsiang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08824"
  },
  {
    "id": "arXiv:2211.08825",
    "title": "Cognitive Simplification Operations Improve Text Simplification",
    "abstract": "Text Simplification (TS) is the task of converting a text into a form that is\neasier to read while maintaining the meaning of the original text. A sub-task\nof TS is Cognitive Simplification (CS), converting text to a form that is\nreadily understood by people with cognitive disabilities without rendering it\nchildish or simplistic. This sub-task has yet to be explored with neural\nmethods in NLP, and resources for it are scarcely available. In this paper, we\npresent a method for incorporating knowledge from the cognitive accessibility\ndomain into a TS model, by introducing an inductive bias regarding what\nsimplification operations to use. We show that by adding this inductive bias to\na TS-trained model, it is able to adapt better to CS without ever seeing CS\ndata, and outperform a baseline model on a traditional TS benchmark. In\naddition, we provide a novel test dataset for CS, and analyze the differences\nbetween CS corpora and existing TS corpora, in terms of how simplification\noperations are applied.",
    "descriptor": "\nComments: 25 pages, 7 figures, 8 tables, uses emnlp2022.sty, to be published in CoNLL 2022\n",
    "authors": [
      "Eytan Chamovitz",
      "Omri Abend"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08825"
  },
  {
    "id": "arXiv:2211.08831",
    "title": "Neurodevelopmental Phenotype Prediction: A State-of-the-Art Deep  Learning Model",
    "abstract": "A major challenge in medical image analysis is the automated detection of\nbiomarkers from neuroimaging data. Traditional approaches, often based on image\nregistration, are limited in capturing the high variability of cortical\norganisation across individuals. Deep learning methods have been shown to be\nsuccessful in overcoming this difficulty, and some of them have even\noutperformed medical professionals on certain datasets. In this paper, we apply\na deep neural network to analyse the cortical surface data of neonates, derived\nfrom the publicly available Developing Human Connectome Project (dHCP). Our\ngoal is to identify neurodevelopmental biomarkers and to predict gestational\nage at birth based on these biomarkers. Using scans of preterm neonates\nacquired around the term-equivalent age, we were able to investigate the impact\nof preterm birth on cortical growth and maturation during late gestation.\nBesides reaching state-of-the-art prediction accuracy, the proposed model has\nmuch fewer parameters than the baselines, and its error stays low on both\nunregistered and registered cortical surfaces.",
    "descriptor": "\nComments: 11 pages, 3 figures, accepted for ML4H 2022\n",
    "authors": [
      "D\u00e1niel Unyi",
      "B\u00e1lint Gyires-T\u00f3th"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08831"
  },
  {
    "id": "arXiv:2211.08834",
    "title": "A Generalized Framework for Video Instance Segmentation",
    "abstract": "Recently, handling long videos of complex and occluded sequences has emerged\nas a new challenge in the video instance segmentation (VIS) community. However,\nexisting methods show limitations in addressing the challenge. We argue that\nthe biggest bottleneck in current approaches is the discrepancy between the\ntraining and the inference. To effectively bridge the gap, we propose a\n\\textbf{Gen}eralized framework for \\textbf{VIS}, namely \\textbf{GenVIS}, that\nachieves the state-of-the-art performance on challenging benchmarks without\ndesigning complicated architectures or extra post-processing. The key\ncontribution of GenVIS is the learning strategy. Specifically, we propose a\nquery-based training pipeline for sequential learning, using a novel target\nlabel assignment strategy. To further fill the remaining gaps, we introduce a\nmemory that effectively acquires information from previous states. Thanks to\nthe new perspective, which focuses on building relationships between separate\nframes or clips, GenVIS can be flexibly executed in both online and semi-online\nmanner. We evaluate our methods on popular VIS benchmarks, YouTube-VIS\n2019/2021/2022 and Occluded VIS (OVIS), achieving state-of-the-art results.\nNotably, we greatly outperform the state-of-the-art on the long VIS benchmark\n(OVIS), improving 5.6 AP with ResNet-50 backbone. Code will be available at\nhttps://github.com/miranheo/GenVIS.",
    "descriptor": "",
    "authors": [
      "Miran Heo",
      "Sukjun Hwang",
      "Jeongseok Hyun",
      "Hanjung Kim",
      "Seoung Wug Oh",
      "Joon-Young Lee",
      "Seon Joo Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08834"
  },
  {
    "id": "arXiv:2211.08837",
    "title": "RF-Annotate: Automatic RF-Supervised Image Annotation of Common Objects  in Context",
    "abstract": "Wireless tags are increasingly used to track and identify common items of\ninterest such as retail goods, food, medicine, clothing, books, documents,\nkeys, equipment, and more. At the same time, there is a need for labelled\nvisual data featuring such items for the purpose of training object detection\nand recognition models for robots operating in homes, warehouses, stores,\nlibraries, pharmacies, and so on. In this paper, we ask: can we leverage the\ntracking and identification capabilities of such tags as a basis for a\nlarge-scale automatic image annotation system for robotic perception tasks? We\npresent RF-Annotate, a pipeline for autonomous pixel-wise image annotation\nwhich enables robots to collect labelled visual data of objects of interest as\nthey encounter them within their environment. Our pipeline uses unmodified\ncommodity RFID readers and RGB-D cameras, and exploits arbitrary small-scale\nmotions afforded by mobile robotic platforms to spatially map RFIDs to\ncorresponding objects in the scene. Our only assumption is that the objects of\ninterest within the environment are pre-tagged with inexpensive battery-free\nRFIDs costing 3-15 cents each. We demonstrate the efficacy of our pipeline on\nseveral RGB-D sequences of tabletop scenes featuring common objects in a\nvariety of indoor environments.",
    "descriptor": "",
    "authors": [
      "Emerson Sie",
      "Deepak Vasisht"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08837"
  },
  {
    "id": "arXiv:2211.08840",
    "title": "Semi-Supervised and Self-Supervised Collaborative Learning for Prostate  3D MR Image Segmentation",
    "abstract": "Volumetric magnetic resonance (MR) image segmentation plays an important role\nin many clinical applications. Deep learning (DL) has recently achieved\nstate-of-the-art or even human-level performance on various image segmentation\ntasks. Nevertheless, manually annotating volumetric MR images for DL model\ntraining is labor-exhaustive and time-consuming. In this work, we aim to train\na semi-supervised and self-supervised collaborative learning framework for\nprostate 3D MR image segmentation while using extremely sparse annotations, for\nwhich the ground truth annotations are provided for just the central slice of\neach volumetric MR image. Specifically, semi-supervised learning and\nself-supervised learning methods are used to generate two independent sets of\npseudo labels. These pseudo labels are then fused by Boolean operation to\nextract a more confident pseudo label set. The images with either manual or\nnetwork self-generated labels are then employed to train a segmentation model\nfor target volume extraction. Experimental results on a publicly available\nprostate MR image dataset demonstrate that, while requiring significantly less\nannotation effort, our framework generates very encouraging segmentation\nresults. The proposed framework is very useful in clinical applications when\ntraining data with dense annotations are difficult to obtain.",
    "descriptor": "",
    "authors": [
      "Yousuf Babiker M. Osman",
      "Cheng Li",
      "Weijian Huang",
      "Nazik Elsayed",
      "Zhenzhen Xue",
      "Hairong Zheng",
      "Shanshan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08840"
  },
  {
    "id": "arXiv:2211.08842",
    "title": "Fast and Accurate FSA System Using ELBERT: An Efficient and Lightweight  BERT",
    "abstract": "As an application of Natural Language Processing (NLP) techniques, financial\nsentiment analysis (FSA) has become an invaluable tool for investors. Its speed\nand accuracy can significantly impact the returns of trading strategies.With\nthe development of deep learning and Transformer-based pre-trained models like\nBERT, the accuracy of FSA has been much improved, but these time-consuming big\nmodels will also slow down the computation. To boost the processing speed of\nthe FSA system and ensure high precision, we first propose an efficient and\nlightweight BERT (ELBERT) along with a novel confidence-window-based (CWB)\nearly exit mechanism. Based on ELBERT, an innovative method to accelerate text\nprocessing on the GPU platform is developed, solving the difficult problem of\nmaking the early exit mechanism work more effectively with a large input batch\nsize. Afterward, a fast and high-accuracy FSA system is built. Experimental\nresults show that the proposed CWB early exit mechanism achieves significantly\nhigher accuracy than existing early exit methods on BERT under the same\ncomputation cost. Besides, our FSA system can boost the processing speed to\nover 1000 texts per second with sufficient accuracy by using this acceleration\nmethod, which is nearly twice as fast as the FastBERT. Hence, this system can\nenable modern trading systems to quickly and accurately process financial text\ndata.",
    "descriptor": "",
    "authors": [
      "Siyuan Lu",
      "Chenchen Zhou",
      "Keli Xie",
      "Shiyi Liu",
      "Jun Lin",
      "Zhongfeng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08842"
  },
  {
    "id": "arXiv:2211.08843",
    "title": "Data Augmentation with Unsupervised Speaking Style Transfer for Speech  Emotion Recognition",
    "abstract": "Currently, the performance of Speech Emotion Recognition (SER) systems is\nmainly constrained by the absence of large-scale labelled corpora. Data\naugmentation is regarded as a promising approach, which borrows methods from\nAutomatic Speech Recognition (ASR), for instance, perturbation on speed and\npitch, or generating emotional speech utilizing generative adversarial\nnetworks. In this paper, we propose EmoAug, a novel style transfer model to\naugment emotion expressions, in which a semantic encoder and a paralinguistic\nencoder represent verbal and non-verbal information respectively. Additionally,\na decoder reconstructs speech signals by conditioning on the aforementioned two\ninformation flows in an unsupervised fashion. Once training is completed,\nEmoAug enriches expressions of emotional speech in different prosodic\nattributes, such as stress, rhythm and intensity, by feeding different styles\ninto the paralinguistic encoder. In addition, we can also generate similar\nnumbers of samples for each class to tackle the data imbalance issue.\nExperimental results on the IEMOCAP dataset demonstrate that EmoAug can\nsuccessfully transfer different speaking styles while retaining the speaker\nidentity and semantic content. Furthermore, we train a SER model with data\naugmented by EmoAug and show that it not only surpasses the state-of-the-art\nsupervised and self-supervised methods but also overcomes overfitting problems\ncaused by data imbalance. Some audio samples can be found on our demo website.",
    "descriptor": "",
    "authors": [
      "Leyuan Qu",
      "Wei Wang",
      "Taihao Li",
      "Cornelius Weber",
      "Stefan Wermter",
      "Fuji Ren"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.08843"
  },
  {
    "id": "arXiv:2211.08850",
    "title": "Consecutive Question Generation via Dynamic Multitask Learning",
    "abstract": "In this paper, we propose the task of consecutive question generation (CQG),\nwhich generates a set of logically related question-answer pairs to understand\na whole passage, with a comprehensive consideration of the aspects including\naccuracy, coverage, and informativeness. To achieve this, we first examine the\nfour key elements of CQG, i.e., question, answer, rationale, and context\nhistory, and propose a novel dynamic multitask framework with one main task\ngenerating a question-answer pair, and four auxiliary tasks generating other\nelements. It directly helps the model generate good questions through both\njoint training and self-reranking. At the same time, to fully explore the\nworth-asking information in a given passage, we make use of the reranking\nlosses to sample the rationales and search for the best question series\nglobally. Finally, we measure our strategy by QA data augmentation and manual\nevaluation, as well as a novel application of generated question-answer pairs\non DocNLI. We prove that our strategy can improve question generation\nsignificantly and benefit multiple related NLP tasks.",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Yunji Li",
      "Sujian Li",
      "Xing Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08850"
  },
  {
    "id": "arXiv:2211.08859",
    "title": "Attacking Object Detector Using A Universal Targeted Label-Switch Patch",
    "abstract": "Adversarial attacks against deep learning-based object detectors (ODs) have\nbeen studied extensively in the past few years. These attacks cause the model\nto make incorrect predictions by placing a patch containing an adversarial\npattern on the target object or anywhere within the frame. However, none of\nprior research proposed a misclassification attack on ODs, in which the patch\nis applied on the target object. In this study, we propose a novel, universal,\ntargeted, label-switch attack against the state-of-the-art object detector,\nYOLO. In our attack, we use (i) a tailored projection function to enable the\nplacement of the adversarial patch on multiple target objects in the image\n(e.g., cars), each of which may be located a different distance away from the\ncamera or have a different view angle relative to the camera, and (ii) a unique\nloss function capable of changing the label of the attacked objects. The\nproposed universal patch, which is trained in the digital domain, is\ntransferable to the physical domain. We performed an extensive evaluation using\ndifferent types of object detectors, different video streams captured by\ndifferent cameras, and various target classes, and evaluated different\nconfigurations of the adversarial patch in the physical domain.",
    "descriptor": "",
    "authors": [
      "Avishag Shapira",
      "Ron Bitton",
      "Dan Avraham",
      "Alon Zolfi",
      "Yuval Elovici",
      "Asaf Shabtai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08859"
  },
  {
    "id": "arXiv:2211.08861",
    "title": "Creative divergent synthesis with generative models",
    "abstract": "Machine learning approaches now achieve impressive generation capabilities in\nnumerous domains such as image, audio or video. However, most training \\&\nevaluation frameworks revolve around the idea of strictly modelling the\noriginal data distribution rather than trying to extrapolate from it. This\nprecludes the ability of such models to diverge from the original distribution\nand, hence, exhibit some creative traits. In this paper, we propose various\nperspectives on how this complicated goal could ever be achieved, and provide\npreliminary results on our novel training objective called \\textit{Bounded\nAdversarial Divergence} (BAD).",
    "descriptor": "",
    "authors": [
      "Axel Chemla--Romeu-Santos",
      "Philippe Esling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.08861"
  },
  {
    "id": "arXiv:2211.08863",
    "title": "ChartParser: Automatic Chart Parsing for Print-Impaired",
    "abstract": "Infographics are often an integral component of scientific documents for\nreporting qualitative or quantitative findings as they make it much simpler to\ncomprehend the underlying complex information. However, their interpretation\ncontinues to be a challenge for the blind, low-vision, and other print-impaired\n(BLV) individuals. In this paper, we propose ChartParser, a fully automated\npipeline that leverages deep learning, OCR, and image processing techniques to\nextract all figures from a research paper, classify them into various chart\ncategories (bar chart, line chart, etc.) and obtain relevant information from\nthem, specifically bar charts (including horizontal, vertical, stacked\nhorizontal and stacked vertical charts) which already have several exciting\nchallenges. Finally, we present the retrieved content in a tabular format that\nis screen-reader friendly and accessible to the BLV users. We present a\nthorough evaluation of our approach by applying our pipeline to sample\nreal-world annotated bar charts from research papers.",
    "descriptor": "\nComments: Submitted at Scientific Document Understanding Workshop, AAAI 2023\n",
    "authors": [
      "Anukriti Kumar",
      "Tanuja Ganu",
      "Saikat Guha"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.08863"
  },
  {
    "id": "arXiv:2211.08864",
    "title": "PrivacyProber: Assessment and Detection of Soft-Biometric  Privacy-Enhancing Techniques",
    "abstract": "Soft-biometric privacy-enhancing techniques represent machine learning\nmethods that aim to: (i) mitigate privacy concerns associated with face\nrecognition technology by suppressing selected soft-biometric attributes in\nfacial images (e.g., gender, age, ethnicity) and (ii) make unsolicited\nextraction of sensitive personal information infeasible. Because such\ntechniques are increasingly used in real-world applications, it is imperative\nto understand to what extent the privacy enhancement can be inverted and how\nmuch attribute information can be recovered from privacy-enhanced images. While\nthese aspects are critical, they have not been investigated in the literature.\nWe, therefore, study the robustness of several state-of-the-art soft-biometric\nprivacy-enhancing techniques to attribute recovery attempts. We propose\nPrivacyProber, a high-level framework for restoring soft-biometric information\nfrom privacy-enhanced facial images, and apply it for attribute recovery in\ncomprehensive experiments on three public face datasets, i.e., LFW, MUCT and\nAdience. Our experiments show that the proposed framework is able to restore a\nconsiderable amount of suppressed information, regardless of the\nprivacy-enhancing technique used, but also that there are significant\ndifferences between the considered privacy models. These results point to the\nneed for novel mechanisms that can improve the robustness of existing\nprivacy-enhancing techniques and secure them against potential adversaries\ntrying to restore suppressed information.",
    "descriptor": "",
    "authors": [
      "Peter Rot",
      "Peter Peer",
      "Vitomir \u0160truc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08864"
  },
  {
    "id": "arXiv:2211.08866",
    "title": "Unsupervised Domain Adaptation Based on the Predictive Uncertainty of  Models",
    "abstract": "Unsupervised domain adaptation (UDA) aims to improve the prediction\nperformance in the target domain under distribution shifts from the source\ndomain. The key principle of UDA is to minimize the divergence between the\nsource and the target domains. To follow this principle, many methods employ a\ndomain discriminator to match the feature distributions. Some recent methods\nevaluate the discrepancy between two predictions on target samples to detect\nthose that deviate from the source distribution. However, their performance is\nlimited because they either match the marginal distributions or measure the\ndivergence conservatively. In this paper, we present a novel UDA method that\nlearns domain-invariant features that minimize the domain divergence. We\npropose model uncertainty as a measure of the domain divergence. Our UDA method\nbased on model uncertainty (MUDA) adopts a Bayesian framework and provides an\nefficient way to evaluate model uncertainty by means of Monte Carlo dropout\nsampling. Empirical results on image recognition tasks show that our method is\nsuperior to existing state-of-the-art methods. We also extend MUDA to\nmulti-source domain adaptation problems.",
    "descriptor": "",
    "authors": [
      "JoonHo Lee",
      "Gyemin Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08866"
  },
  {
    "id": "arXiv:2211.08878",
    "title": "Video-Music Retrieval:A Dual-Path Cross-Modal Network",
    "abstract": "We propose a method to recommend background music for videos. Current work\nrarely considers the emotional information of music, which is essential for\nvideo music retrieval. To achieve this, we design two paths to process content\ninformation and emotional information between modal. Based on characteristics\nof video and music, we design various feature extraction schemes and common\nrepresentation spaces. More importantly, we propose a way to combine content\ninformation with emotional information. Additionally, we make improvements to\nthe classical metric loss to be more suited to this task. Experiments show that\nthis dual path video music retrieval network can effectively merge information.\nCompare with existing methods, the retrieval task evaluation index: increasing\nRecall@1 by 3.94 and Recall@25 by 16.36.",
    "descriptor": "\nComments: 5pages,3figures\n",
    "authors": [
      "Xin Gu",
      "Yinghua Shen",
      "Chaohui Lv"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.08878"
  },
  {
    "id": "arXiv:2211.08887",
    "title": "Stare at What You See: Masked Image Modeling without Reconstruction",
    "abstract": "Masked Autoencoders (MAE) have been prevailing paradigms for large-scale\nvision representation pre-training. By reconstructing masked image patches from\na small portion of visible image regions, MAE forces the model to infer\nsemantic correlation within an image. Recently, some approaches apply\nsemantic-rich teacher models to extract image features as the reconstruction\ntarget, leading to better performance. However, unlike the low-level features\nsuch as pixel values, we argue the features extracted by powerful teacher\nmodels already encode rich semantic correlation across regions in an intact\nimage.This raises one question: is reconstruction necessary in Masked Image\nModeling (MIM) with a teacher model? In this paper, we propose an efficient MIM\nparadigm named MaskAlign. MaskAlign simply learns the consistency of visible\npatch features extracted by the student model and intact image features\nextracted by the teacher model. To further advance the performance and tackle\nthe problem of input inconsistency between the student and teacher model, we\npropose a Dynamic Alignment (DA) module to apply learnable alignment. Our\nexperimental results demonstrate that masked modeling does not lose\neffectiveness even without reconstruction on masked regions. Combined with\nDynamic Alignment, MaskAlign can achieve state-of-the-art performance with much\nhigher efficiency. Code and models will be available at\nhttps://github.com/OpenPerceptionX/maskalign.",
    "descriptor": "",
    "authors": [
      "Hongwei Xue",
      "Peng Gao",
      "Hongyang Li",
      "Yu Qiao",
      "Hao Sun",
      "Houqiang Li",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08887"
  },
  {
    "id": "arXiv:2211.08888",
    "title": "ELDA: Using Edges to Have an Edge on Semantic Segmentation Based UDA",
    "abstract": "Many unsupervised domain adaptation (UDA) methods have been proposed to\nbridge the domain gap by utilizing domain invariant information. Most\napproaches have chosen depth as such information and achieved remarkable\nsuccess. Despite their effectiveness, using depth as domain invariant\ninformation in UDA tasks may lead to multiple issues, such as excessively high\nextraction costs and difficulties in achieving a reliable prediction quality.\nAs a result, we introduce Edge Learning based Domain Adaptation (ELDA), a\nframework which incorporates edge information into its training process to\nserve as a type of domain invariant information. In our experiments, we\nquantitatively and qualitatively demonstrate that the incorporation of edge\ninformation is indeed beneficial and effective and enables ELDA to outperform\nthe contemporary state-of-the-art methods on two commonly adopted benchmarks\nfor semantic segmentation based UDA tasks. In addition, we show that ELDA is\nable to better separate the feature distributions of different classes. We\nfurther provide an ablation analysis to justify our design decisions.",
    "descriptor": "\nComments: Accepted by BMVC2022. Ting-Hsuan Liao and Huang-Ru Liao contributed equally to this work\n",
    "authors": [
      "Ting-Hsuan Liao",
      "Huang-Ru Liao",
      "Shan-Ya Yang",
      "Jie-En Yao",
      "Li-Yuan Tsao",
      "Hsu-Shen Liu",
      "Bo-Wun Cheng",
      "Chen-Hao Chao",
      "Chia-Che Chang",
      "Yi-Chen Lo",
      "Chun-Yi Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08888"
  },
  {
    "id": "arXiv:2211.08890",
    "title": "Challenges related to system-of-systems for greening and climate  adaptation in smart cities",
    "abstract": "This paper presents the results of interviews conducted as part of the\nDYNASOS project. The objective was to collect challenges related to the design,\nimplementation and management of system-of-systems (SoS) in the context of\nclimate adaptation and greening of smart cities. 23 individuals from cities,\nacademia, and industry were interviewed between March and May 2022 and 57\ndistinct challenges were collected and analyzed. Our results show that while\ntechnical issues (such as interoperability or data acquisition) persist,\nnon-technical issues are the main obstacles. Difficulties in information\nsharing, effective communication, and synchronization between different actors\nare the most important challenges.",
    "descriptor": "\nComments: 15 pages, 2 figures, 10 tables. submitted at this https URL\n",
    "authors": [
      "Sarah Brandt",
      "Julien Siebert"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.08890"
  },
  {
    "id": "arXiv:2211.08891",
    "title": "Validating Streaming JSON Documents with Learned VPAs",
    "abstract": "We present a new streaming algorithm to validate JSON documents against a set\nof constraints given as a JSON schema. Among the possible values a JSON\ndocument can hold, objects are unordered collections of key-value pairs while\narrays are ordered collections of values. We prove that there always exists a\nvisibly pushdown automaton (VPA) that accepts the same set of JSON documents as\na JSON schema. Leveraging this result, our approach relies on learning a VPA\nfor the provided schema. As the learned VPA assumes a fixed order on the\nkey-value pairs of the objects, we abstract its transitions in a special kind\nof graph, and propose an efficient streaming algorithm using the VPA and its\ngraph to decide whether a JSON document is valid for the schema. We evaluate\nthe implementation of our algorithm on a number of random JSON documents, and\ncompare it to the classical validation algorithm.",
    "descriptor": "",
    "authors": [
      "V\u00e9ronique Bruy\u00e8re",
      "Guillermo A. Perez",
      "Ga\u00ebtan Staquet"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2211.08891"
  },
  {
    "id": "arXiv:2211.08892",
    "title": "Fast Graph Generative Model via Spectral Diffusion",
    "abstract": "Generating graph-structured data is a challenging problem, which requires\nlearning the underlying distribution of graphs. Various models such as graph\nVAE, graph GANs and graph diffusion models have been proposed to generate\nmeaningful and reliable graphs, among which the diffusion models have achieved\nstate-of-the-art performance. In this paper, we argue that running full-rank\ndiffusion SDEs on the whole space hinders diffusion models from learning graph\ntopology generation, and hence significantly deteriorates the quality of\ngenerated graph data. To address this limitation, we propose an efficient yet\neffective Graph Spectral Diffusion Model (GSDM), which is driven by low-rank\ndiffusion SDEs on the graph spectrum space. Our spectral diffusion model is\nfurther proven to enjoy a substantially stronger theoretical guarantee than\nstandard diffusion models. Extensive experiments across various datasets\ndemonstrate that, our proposed GSDM turns out to be the SOTA model, by\nexhibiting either significantly higher generation quality or much less\ncomputational consumption than the baselines.",
    "descriptor": "",
    "authors": [
      "Tianze Luo",
      "Zhanfeng Mo",
      "Sinno Jialin Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08892"
  },
  {
    "id": "arXiv:2211.08893",
    "title": "Reconfigurable Drone System for Transportation of Parcels With Variable  Mass and Size",
    "abstract": "Cargo drones are designed to carry payloads with predefined shape, size,\nand/or mass. This lack of flexibility requires a fleet of diverse drones\ntailored to specific cargo dimensions. Here we propose a new reconfigurable\ndrone based on a modular design that adapts to different cargo shapes, sizes,\nand mass. We also propose a method for the automatic generation of drone\nconfigurations and suitable parameters for the flight controller. The parcel\nbecomes the drone's body to which several individual propulsion modules are\nattached. We demonstrate the use of the reconfigurable hardware and the\naccompanying software by transporting parcels of different mass and sizes\nrequiring various numbers and propulsion modules' positioning. The experiments\nare conducted indoors (with a motion capture system) and outdoors (with an\nRTK-GNSS sensor). The proposed design represents a cheaper and more versatile\nalternative to the solutions involving several drones for parcel\ntransportation.",
    "descriptor": "",
    "authors": [
      "Fabrizio Schiano",
      "Przemyslaw Mariusz Kornatowski",
      "Leonardo Cencetti",
      "Dario Floreano"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.08893"
  },
  {
    "id": "arXiv:2211.08894",
    "title": "AdaTriplet-RA: Domain Matching via Adaptive Triplet and Reinforced  Attention for Unsupervised Domain Adaptation",
    "abstract": "Unsupervised domain adaption (UDA) is a transfer learning task where the data\nand annotations of the source domain are available but only have access to the\nunlabeled target data during training. Most previous methods try to minimise\nthe domain gap by performing distribution alignment between the source and\ntarget domains, which has a notable limitation, i.e., operating at the domain\nlevel, but neglecting the sample-level differences. To mitigate this weakness,\nwe propose to improve the unsupervised domain adaptation task with an\ninter-domain sample matching scheme. We apply the widely-used and robust\nTriplet loss to match the inter-domain samples. To reduce the catastrophic\neffect of the inaccurate pseudo-labels generated during training, we propose a\nnovel uncertainty measurement method to select reliable pseudo-labels\nautomatically and progressively refine them. We apply the advanced discrete\nrelaxation Gumbel Softmax technique to realise an adaptive Topk scheme to\nfulfil the functionality. In addition, to enable the global ranking\noptimisation within one batch for the domain matching, the whole model is\noptimised via a novel reinforced attention mechanism with supervision from the\npolicy gradient algorithm, using the Average Precision (AP) as the reward. Our\nmodel (termed \\textbf{\\textit{AdaTriplet-RA}}) achieves State-of-the-art\nresults on several public benchmark datasets, and its effectiveness is\nvalidated via comprehensive ablation studies. Our method improves the accuracy\nof the baseline by 9.7\\% (ResNet-101) and 6.2\\% (ResNet-50) on the VisDa\ndataset and 4.22\\% (ResNet-50) on the Domainnet dataset. {The source code is\npublicly available at \\textit{https://github.com/shuxy0120/AdaTriplet-RA}}.",
    "descriptor": "",
    "authors": [
      "Xinyao Shu",
      "Shiyang Yan",
      "Zhenyu Lu",
      "Xinshao Wang",
      "Yuan Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08894"
  },
  {
    "id": "arXiv:2211.08897",
    "title": "Error estimate of the Non-Intrusive Reduced Basis (NIRB) two-grid method  with parabolic equations",
    "abstract": "Reduced Basis Methods (RBMs) are frequently proposed to approximate\nparametric problem solutions. They can be used to calculate solutions for a\nlarge number of parameter values (e.g. for parameter fitting) as well as to\napproximate a solution for a new parameter value (e.g. real time approximation\nwith a very high accuracy). They intend to reduce the computational costs of\nHigh Fidelity (HF) codes. We will focus on the Non-Intrusive Reduced Basis\n(NIRB) two-grid method. Its main advantage is that it uses the HF code\nexclusively as a \"black-box,\" as opposed to other so-called intrusive methods\nthat require code modification. This is very convenient when the HF code is a\ncommercial one that has been purchased, as is frequently the case in the\nindustry. The effectiveness of this method relies on its decomposition into two\nstages, one offline (classical in most RBMs as presented above) and one online.\nThe offline part is time-consuming but it is only performed once. On the\ncontrary, the specificity of this NIRB approach is that, during the online\npart, it solves the parametric problem on a coarse mesh only and then improves\nits precision. As a result, it is significantly less expensive than a HF\nevaluation. This method has been originally developed for elliptic equations\nwith finite elements and has since been extended to finite volume. In this\npaper, we extend the NIRB two-grid method to parabolic equations. We recover\noptimal estimates in $L^{\\infty}(0,T;H^1(\\Omega))$ using as a model problem,\nthe heat equation. Then, we present numerical results on the heat equation and\non the Brusselator problem.",
    "descriptor": "",
    "authors": [
      "Elise Grosjean",
      "Yvon Maday"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.08897"
  },
  {
    "id": "arXiv:2211.08900",
    "title": "Convergence analysis of unsupervised Legendre-Galerkin neural networks  for linear second-order elliptic PDEs",
    "abstract": "In this paper, we perform the convergence analysis of unsupervised\nLegendre--Galerkin neural networks (ULGNet), a deep-learning-based numerical\nmethod for solving partial differential equations (PDEs). Unlike existing deep\nlearning-based numerical methods for PDEs, the ULGNet expresses the solution as\na spectral expansion with respect to the Legendre basis and predicts the\ncoefficients with deep neural networks by solving a variational residual\nminimization problem. Since the corresponding loss function is equivalent to\nthe residual induced by the linear algebraic system depending on the choice of\nbasis functions, we prove that the minimizer of the discrete loss function\nconverges to the weak solution of the PDEs. Numerical evidence will also be\nprovided to support the theoretical result. Key technical tools include the\nvariant of the universal approximation theorem for bounded neural networks, the\nanalysis of the stiffness and mass matrices, and the uniform law of large\nnumbers in terms of the Rademacher complexity.",
    "descriptor": "",
    "authors": [
      "Seungchan Ko",
      "Seok-Bae Yun",
      "Youngjoon Hong"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08900"
  },
  {
    "id": "arXiv:2211.08901",
    "title": "Brain PET Synthesis from MRI Using Joint Probability Distribution of  Diffusion Model at Ultrahigh Fields",
    "abstract": "MRI and PET are important modalities and can provide complementary\ninformation for the diagnosis of brain diseases because MRI can provide\nstructural information of brain and PET can obtain functional information of\nbrain. However, PET is usually missing. Especially, simultaneous PET and MRI\nimaging at ultrahigh field is not achievable in the current. Thus, synthetic\nPET using MRI at ultrahigh field is essential. In this paper, we synthetic PET\nusing MRI as a guide by joint probability distribution of diffusion model\n(JPDDM). Meanwhile, We utilized our model in Ultrahigh Fields.",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Xie Taofeng",
      "Cao Chentao",
      "Cui Zhuoxu",
      "Li Fanshi",
      "Wei Zidong",
      "Zhu Yanjie",
      "Li Ye",
      "Liang Dong",
      "Jin Qiyu",
      "Chen Guoqing",
      "Wang Haifeng"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.08901"
  },
  {
    "id": "arXiv:2211.08903",
    "title": "Cross-Mode Knowledge Adaptation for Bike Sharing Demand Prediction using  Domain-Adversarial Graph Neural Networks",
    "abstract": "For bike sharing systems, demand prediction is crucial to ensure the timely\nre-balancing of available bikes according to predicted demand. Existing methods\nfor bike sharing demand prediction are mostly based on its own historical\ndemand variation, essentially regarding it as a closed system and neglecting\nthe interaction between different transportation modes. This is particularly\nimportant for bike sharing because it is often used to complement travel\nthrough other modes (e.g., public transit). Despite some recent progress, no\nexisting method is capable of leveraging spatiotemporal information from\nmultiple modes and explicitly considers the distribution discrepancy between\nthem, which can easily lead to negative transfer. To address these challenges,\nthis study proposes a domain-adversarial multi-relational graph neural network\n(DA-MRGNN) for bike sharing demand prediction with multimodal historical data\nas input. A temporal adversarial adaptation network is introduced to extract\nshareable features from demand patterns of different modes. To capture\ncorrelations between spatial units across modes, we adapt a multi-relational\ngraph neural network (MRGNN) considering both cross-mode similarity and\ndifference. In addition, an explainable GNN technique is developed to\nunderstand how our proposed model makes predictions. Extensive experiments are\nconducted using real-world bike sharing, subway and ride-hailing data from New\nYork City. The results demonstrate the superior performance of our proposed\napproach compared to existing methods and the effectiveness of different model\ncomponents.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2203.10961\n",
    "authors": [
      "Yuebing Liang",
      "Guan Huang",
      "Zhan Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08903"
  },
  {
    "id": "arXiv:2211.08904",
    "title": "Self-supervised Egomotion and Depth Learning via Bi-directional  Coarse-to-Fine Scale Recovery",
    "abstract": "Self-supervised learning of egomotion and depth has recently attracted great\nattentions. These learning models can provide pose and depth maps to support\nnavigation and perception task for autonomous driving and robots, while they do\nnot require high-precision ground-truth labels to train the networks. However,\nmonocular vision based methods suffer from pose scale-ambiguity problem, so\nthat can not generate physical meaningful trajectory, and thus their\napplications are limited in real-world. We propose a novel self-learning deep\nneural network framework that can learn to estimate egomotion and depths with\nabsolute metric scale from monocular images. Coarse depth scale is recovered\nvia comparing point cloud data against a pretrained model that ensures the\nconsistency of photometric loss. The scale-ambiguity problem is solved by\nintroducing a novel two-stages coarse-to-fine scale recovery strategy that\njointly refines coarse poses and depths. Our model successfully produces pose\nand depth estimates in global scale-metric, even in low-light condition, i.e.\ndriving at night. The evaluation on the public datasets demonstrates that our\nmodel outperforms both representative traditional and learning based VOs and\nVIOs, e.g. VINS-mono, ORB-SLAM, SC-Learner, and UnVIO.",
    "descriptor": "",
    "authors": [
      "Hao Qu",
      "Lilian Zhang",
      "Xiaoping Hu",
      "Xiaofeng He",
      "Xianfei Pan",
      "Changhao Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.08904"
  },
  {
    "id": "arXiv:2211.08905",
    "title": "A necessary condition for non oscillatory and positivity preserving  time-integration schemes",
    "abstract": "Modified Patankar (MP) schemes are conservative, linear implicit and\nunconditionally positivity preserving time-integration schemes constructed for\nproduction-destruction systems. For such schemes, a classical stability\nanalysis does not yield any information about the performance. Recently, two\ndifferent techniques have been proposed to investigate the properties of MP\nschemes. In Izgin et al. [ESAIM: M2AN, 56 (2022)], inspired from dynamical\nsystems, the Lyapunov stability properties of such schemes have been\ninvestigated, while in Torlo et al. [Appl. Numer. Math., 182 (2022)] their\noscillatory behaviour has been studied. In this work, we investigate the\nconnection between the oscillatory behaviour and the Lyapunov stability and we\nprove that a condition on the Lyapunov stability function is necessary to avoid\noscillations. We verify our theoretical result on several numerical tests.",
    "descriptor": "",
    "authors": [
      "Thomas Izgin",
      "Philipp \u00d6ffner",
      "Davide Torlo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.08905"
  },
  {
    "id": "arXiv:2211.08910",
    "title": "On the Connection of Generative Models and Discriminative Models for  Anomaly Detection",
    "abstract": "Anomaly detection (AD) has attracted considerable attention in both academia\nand industry. Due to the lack of anomalous data in many practical cases, AD is\nusually solved by first modeling the normal data pattern and then determining\nif data fit this model. Generative models (GMs) seem a natural tool to achieve\nthis purpose, which learn the normal data distribution and estimate it using a\nprobability density function (PDF). However, some works have observed the ideal\nperformance of such GM-based AD methods. In this paper, we propose a new\nperspective on the ideal performance of GM-based AD methods. We state that in\nthese methods, the implicit assumption that connects GMs'results to AD's goal\nis usually implausible due to normal data's multi-peaked distribution\ncharacteristic, which is quite common in practical cases. We first\nqualitatively formulate this perspective, and then focus on the Gaussian\nmixture model (GMM) to intuitively illustrate the perspective, which is a\ntypical GM and has the natural property to approximate multi-peaked\ndistributions. Based on the proposed perspective, in order to bypass the\nimplicit assumption in the GMM-based AD method, we suggest integrating the\nDiscriminative idea to orient GMM to AD tasks (DiGMM). With DiGMM, we establish\na connection of generative and discriminative models, which are two key\nparadigms for AD and are usually treated separately before. This connection\nprovides a possible direction for future works to jointly consider the two\nparadigms and incorporate their complementary characteristics for AD.",
    "descriptor": "",
    "authors": [
      "Jingxuan Pang",
      "Chunguang Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.08910"
  },
  {
    "id": "arXiv:2211.08914",
    "title": "Dual Class-Aware Contrastive Federated Semi-Supervised Learning",
    "abstract": "Federated semi-supervised learning (FSSL), facilitates labeled clients and\nunlabeled clients jointly training a global model without sharing private data.\nExisting FSSL methods mostly focus on pseudo-labeling and consistency\nregularization to leverage the knowledge of unlabeled data, which have achieved\nsubstantial success on raw data utilization. However, their training procedures\nsuffer from the large deviation from local models of labeled clients and\nunlabeled clients and the confirmation bias induced by noisy pseudo labels,\nwhich seriously damage the performance of the global model. In this paper, we\npropose a novel FSSL method, named Dual Class-aware Contrastive Federated\nSemi-Supervised Learning (DCCFSSL), which considers the local class-aware\ndistribution of individual client's data and the global class-aware\ndistribution of all clients' data simultaneously in the feature space. By\nintroducing a dual class-aware contrastive module, DCCFSSL builds a common\ntraining goal for different clients to reduce the large deviation and\nintroduces contrastive information in the feature space to alleviate the\nconfirmation bias. Meanwhile, DCCFSSL presents an authentication-reweighted\naggregation method to enhance the robustness of the server's aggregation.\nExtensive experiments demonstrate that DCCFSSL not only outperforms\nstate-of-the-art methods on three benchmarked datasets, but also surpasses the\nFedAvg with relabeled unlabeled clients on CIFAR-10 and CIFAR-100 datasets. To\nour best knowledge, we are the first to present the FSSL method that utilizes\nonly 10\\% labeled clients of all clients to achieve better performance than the\nstandard federated supervised learning that uses all clients with labeled data.",
    "descriptor": "",
    "authors": [
      "Qi Guo",
      "Yong Qi",
      "Saiyu Qi",
      "Di Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08914"
  },
  {
    "id": "arXiv:2211.08916",
    "title": "Privacy Engineering in the Wild: Understanding the Practitioners'  Mindset, Organisational Culture, and Current Practices",
    "abstract": "Privacy engineering, as an emerging field of research and practice, comprises\nthe technical capabilities and management processes needed to implement,\ndeploy, and operate privacy features and controls in working systems. For that,\nsoftware practitioners and other stakeholders in software companies need to\nwork cooperatively toward building privacy-preserving businesses and\nengineering solutions. Significant research has been done to understand the\nsoftware practitioners' perceptions of information privacy, but more emphasis\nshould be given to the uptake of concrete privacy engineering components. This\nresearch delves into the software practitioners' perspectives and mindset,\norganisational aspects, and current practices on privacy and its engineering\nprocesses. A total of 30 practitioners from various countries and backgrounds\nwere interviewed, sharing their experiences and voicing their opinions on a\nbroad range of privacy topics. The thematic analysis methodology was adopted to\ncode the interview data qualitatively and construct a rich and nuanced thematic\nframework. As a result, we identified three critical interconnected themes that\ncompose our thematic framework for privacy engineering \"in the wild\": (1)\npersonal privacy mindset and stance, categorised into practitioners' privacy\nknowledge, attitudes and behaviours; (2) organisational privacy culture, such\nas decision-power and positive and negative examples of privacy climate; and,\n(3) privacy engineering practices, such as procedures and controls concretely\nused in the industry. Among the main findings, this study provides many\ninsights about the state-of-the-practice of privacy engineering, pointing to a\npositive influence of privacy laws (e.g., EU General Data Protection\nRegulation) on practitioners' behaviours and organisations' cultures. Aspects\nsuch as organisational privacy culture and climate were also confirmed to [...]",
    "descriptor": "\nComments: 24 pages, 8 figures\n",
    "authors": [
      "Leonardo Horn Iwaya",
      "Muhammad Ali Babar",
      "Awais Rashid"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.08916"
  },
  {
    "id": "arXiv:2211.08927",
    "title": "Benchmarking Graph Neural Networks for FMRI analysis",
    "abstract": "Graph Neural Networks (GNNs) have emerged as a powerful tool to learn from\ngraph-structured data. A paramount example of such data is the brain, which\noperates as a network, from the micro-scale of neurons, to the macro-scale of\nregions. This organization deemed GNNs a natural tool of choice to model brain\nactivity, and have consequently attracted a lot of attention in the\nneuroimaging community. Yet, the advantage of adopting these models over\nconventional methods has not yet been assessed in a systematic way to gauge if\nGNNs are capable of leveraging the underlying structure of the data to improve\nlearning. In this work, we study and evaluate the performance of five popular\nGNN architectures in diagnosing major depression disorder and autism spectrum\ndisorder in two multi-site clinical datasets, and sex classification on the\nUKBioBank, from functional brain scans under a general uniform framework. Our\nresults show that GNNs fail to outperform kernel-based and structure-agnostic\ndeep learning models, in which 1D CNNs outperform the other methods in all\nscenarios. We highlight that creating optimal graph structures for functional\nbrain data is a major bottleneck hindering the performance of GNNs, where\nexisting works use arbitrary measures to define the edges resulting in noisy\ngraphs. We therefore propose to integrate graph diffusion into existing\narchitectures and show that it can alleviate this problem and improve their\nperformance. Our results call for increased moderation and rigorous validation\nwhen evaluating graph methods and advocate for more data-centeric approaches in\ndeveloping GNNs for functional neuroimaging applications.",
    "descriptor": "\nComments: 14 pages, 3 figures\n",
    "authors": [
      "Ahmed ElGazzar",
      "Rajat Thomas",
      "Guido van Wingen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08927"
  },
  {
    "id": "arXiv:2211.08930",
    "title": "How Far Are Wireless Networks from Being Truly Deterministic?",
    "abstract": "With the rapid development of Internet-of-Things (IoT) technology and\nmachine-type communications, various emerging applications appear in industrial\nproductions and our daily lives. Among these, applications like industrial\nsensing and controlling, remote surgery, and automatic driving require an\nextremely low latency and a very small jitter. Delivering information\ndeterministically has become one of the the biggest challenges for modern\nwire-line and wireless communications. In this paper, we present a review of\ncurrently available wire-line deterministic networks and discuss the main\nchallenges to build wireless deterministic networks. We also discuss and\npropose several potential techniques enabling wireless networks to provide\ndeterministic communications. By elaborating the coding/modulation schemes of\nthe physical layer and managing the channel-access/packet-scheduling at the\nmedia access control (MAC) layer, it is believed that wireless deterministic\ncommunications can be realized in the near future.",
    "descriptor": "\nComments: 9 pages, 5 figures. Accepted for publish in IEEE Internet of Things Magazine\n",
    "authors": [
      "Yan Li",
      "Yunquan Dong",
      "Pingyi Fan",
      "Khaled Ben Letaief"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.08930"
  },
  {
    "id": "arXiv:2211.08932",
    "title": "Semantic Communications in Multi-user Wireless Networks",
    "abstract": "This article investigates the exploitation of semantic communications in\nmulti-user networks. We propose a novel heterogeneous semantic and bit\nmulti-user framework for providing flawless, customized, and intelligent\ninformation transmission. We discuss both orthogonal multiple access (OMA) and\nnon-orthogonal multiple access (NOMA) for the proposed heterogeneous framework,\nwith an emphasis on investigating the attractive interplay between semantic\ncommunications and NOMA, namely NOMA enabled semantic communications and\nsemantic communications enhanced NOMA. 1) For NOMA enabled semantic\ncommunications, we propose a semi-NOMA scheme for efficiently facilitating the\nheterogeneous semantic and bit multi-user communication, which unifies\nconventional NOMA and OMA schemes. The fundamental performance limit, namely\nsemantic-versus-bit rate region, is characterized, which shows the superiority\nof the proposed semi-NOMA. 2) For semantic communications enhanced NOMA, we\npropose an opportunistic semantic and bit communication approach to alleviate\nthe early-late rate disparity issue in NOMA. Numerical case studies demonstrate\nthat significant performance gain can be achieved for NOMA by employing\nsemantic communications than bit communications. Finally, several open research\ndirections are highlighted.",
    "descriptor": "\nComments: 7 pages, 6 figures\n",
    "authors": [
      "Xidong Mu",
      "Yuanwei Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.08932"
  },
  {
    "id": "arXiv:2211.08939",
    "title": "Augmented Physics-Informed Neural Networks (APINNs): A gating  network-based soft domain decomposition methodology",
    "abstract": "In this paper, we propose the augmented physics-informed neural network\n(APINN), which adopts soft and trainable domain decomposition and flexible\nparameter sharing to further improve the extended PINN (XPINN) as well as the\nvanilla PINN methods. In particular, a trainable gate network is employed to\nmimic the hard and discrete decomposition of XPINN, which can be flexibly\nfine-tuned for discovering a potentially better partition. It weight-averages\nseveral sub-nets as the output of APINN. APINN does not require complex\ninterface conditions, and its sub-nets can take advantage of all training\nsamples rather than just part of the training data in their subdomains. Lastly,\neach sub-net shares part of the common parameters to capture the similar\ncomponents in each decomposed function. Furthermore, following the PINN\ngeneralization theory in Hu et al. [2021], we show that APINN can improve\ngeneralization by proper gate network initialization and general domain &\nfunction decomposition. Extensive experiments on different types of PDEs\ndemonstrate how APINN improves the PINN and XPINN methods. Specifically, we\npresent examples where XPINN performs similarly to or worse than PINN, so that\nAPINN can significantly improve both. We also show cases where XPINN is already\nbetter than PINN, so APINN can still slightly improve XPINN. Furthermore, we\nvisualize the optimized gating networks and their optimization trajectories,\nand connect them with their performance, which helps discover the possibly\noptimal decomposition. Interestingly, if initialized by different\ndecomposition, the performances of corresponding APINNs can differ drastically.\nThis, in turn, shows the potential to design an optimal domain decomposition\nfor the differential equation problem under consideration.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Zheyuan Hu",
      "Ameya D. Jagtap",
      "George Em Karniadakis",
      "Kenji Kawaguchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.08939"
  },
  {
    "id": "arXiv:2211.08942",
    "title": "Differentially Private Optimizers Can Learn Adversarially Robust Models",
    "abstract": "Machine learning models have shone in a variety of domains and attracted\nincreasing attention from both the security and the privacy communities. One\nimportant yet worrying question is: will training models under the differential\nprivacy (DP) constraint unfavorably impact on the adversarial robustness? While\nprevious works have postulated that privacy comes at the cost of worse\nrobustness, we give the first theoretical analysis to show that DP models can\nindeed be robust and accurate, even sometimes more robust than their\nnaturally-trained non-private counterparts. We observe three key factors that\ninfluence the privacy-robustness-accuracy tradeoff: (1) hyperparameters for DP\noptimizers are critical; (2) pre-training on public data significantly\nmitigates the accuracy and robustness drop; (3) choice of DP optimizers makes a\ndifference. With these factors set properly, we achieve 90\\% natural accuracy,\n72\\% robust accuracy ($+9\\%$ than the non-private model) under $l_2(0.5)$\nattack, and 69\\% robust accuracy ($+16\\%$ than the non-private model) with\npre-trained SimCLRv2 model under $l_\\infty(4/255)$ attack on CIFAR10 with\n$\\epsilon=2$. In fact, we show both theoretically and empirically that DP\nmodels are Pareto optimal on the accuracy-robustness tradeoff. Empirically, the\nrobustness of DP models is consistently observed on MNIST, Fashion MNIST and\nCelebA datasets, with ResNet and Vision Transformer. We believe our encouraging\nresults are a significant step towards training models that are private as well\nas robust.",
    "descriptor": "",
    "authors": [
      "Yuan Zhang",
      "Zhiqi Bu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08942"
  },
  {
    "id": "arXiv:2211.08948",
    "title": "A comparison of Leja- and Krylov-based iterative schemes for Exponential  Integrators",
    "abstract": "Krylov-based algorithms have long been preferred to compute the matrix\nexponential and exponential-like functions appearing in exponential\nintegrators. Of late, direct polynomial interpolation of the action of these\nexponential-like functions have been shown to be competitive with the Krylov\nmethods. We analyse the performance of the state-of-the-art Krylov algorithm,\nKIOPS, and the method of polynomial interpolation at Leja points for a number\nof exponential integrators for various test problems and with varying amounts\nof stiffness. Additionally, we investigate the performance of an iterative\nscheme that combines both the KIOPS and Leja approach, named LeKry, that shows\nsubstantial improvements over both the Leja- and Krylov-based methods for\ncertain exponential integrators. Whilst we do manage to single out a favoured\niterative scheme for each of the exponential integrators that we consider in\nthis study, we do not find any conclusive evidence for preferring either KIOPS\nor Leja for different classes of exponential integrators. We are unable to\nidentify a superior exponential integrator, one that performs better than all\nothers, for most, if not all of the problems under consideration. We, however,\ndo find that the performance significantly depends on the interplay between the\niterative scheme and the specific exponential integrator under consideration.",
    "descriptor": "\nComments: in submission; attached supplemental material\n",
    "authors": [
      "Pranab J. Deka",
      "Mayya Tokman",
      "Lukas Einkemmer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.08948"
  },
  {
    "id": "arXiv:2211.08954",
    "title": "Weakly-supervised Fingerspelling Recognition in British Sign Language  Videos",
    "abstract": "The goal of this work is to detect and recognize sequences of letters signed\nusing fingerspelling in British Sign Language (BSL). Previous fingerspelling\nrecognition methods have not focused on BSL, which has a very different signing\nalphabet (e.g., two-handed instead of one-handed) to American Sign Language\n(ASL). They also use manual annotations for training. In contrast to previous\nmethods, our method only uses weak annotations from subtitles for training. We\nlocalize potential instances of fingerspelling using a simple feature\nsimilarity method, then automatically annotate these instances by querying\nsubtitle words and searching for corresponding mouthing cues from the signer.\nWe propose a Transformer architecture adapted to this task, with a\nmultiple-hypothesis CTC loss function to learn from alternative annotation\npossibilities. We employ a multi-stage training approach, where we make use of\nan initial version of our trained model to extend and enhance our training data\nbefore re-training again to achieve better performance. Through extensive\nevaluations, we verify our method for automatic annotation and our model\narchitecture. Moreover, we provide a human expert annotated test set of 5K\nvideo clips for evaluating BSL fingerspelling recognition methods to support\nsign language research.",
    "descriptor": "\nComments: Appears in: British Machine Vision Conference 2022 (BMVC 2022)\n",
    "authors": [
      "K R Prajwal",
      "Hannah Bull",
      "Liliane Momeni",
      "Samuel Albanie",
      "G\u00fcl Varol",
      "Andrew Zisserman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08954"
  },
  {
    "id": "arXiv:2211.08956",
    "title": "A Comprehensive Survey on Spectrum Sharing Techniques for 5G/B5G  Intelligent Wireless Networks: Opportunities, Challenges and Future Research  Directions",
    "abstract": "The increasing popularity of Internet of Everything and small-cell devices\nhas enormously accelerated traffic loads. Consequently, increased bandwidth and\nhigh data rate requirements stimulate the operation at the millimeter wave and\nthe Tera-Hertz spectrum bands in the fifth generation (5G) and beyond 5G (B5G)\nwireless networks. Furthermore, efficient spectrum allocation, maximizing the\nspectrum utilization, achieving efficient spectrum sharing (SS), and managing\nthe spectrum to enhance the system performance remain challenging. To this end,\nrecent studies have implemented artificial intelligence and machine learning\ntechniques, enabling intelligent and efficient spectrum leveraging. However,\ndespite many recent research advances focused on maximizing utilization of the\nspectrum bands, achieving efficient sharing, allocation, and management of the\nenormous available spectrum remains challenging. Therefore, the current article\nacquaints a comprehensive survey on intelligent SS methodologies for 5G and B5G\nwireless networks, considering the applications of artificial intelligence for\nefficient SS. Specifically, a thorough overview of SS methodologies is\nconferred, following which the various spectrum utilization opportunities\narising from the existing SS methodologies in intelligent wireless networks are\ndiscussed. Subsequently, to highlight critical limitations of the existing\nmethodologies, recent literature on existing SS methodologies is reviewed in\ndetail, classifying them based on the implemented technology, i.e., cognitive\nradio, machine learning, blockchain, and multiple other techniques. Moreover,\nthe related SS techniques are reviewed to highlight significant challenges in\nthe B5G intelligent wireless network. Finally, to provide an insight into the\nprospective research avenues, the article is concluded by presenting several\npotential research directions and proposed solutions.",
    "descriptor": "",
    "authors": [
      "Anita Patil",
      "Sridhar Iyer",
      "Onel L.A. Lopez",
      "Rahul J Pandya",
      "Anshuman Kalla",
      "Rakhee Kallimani"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.08956"
  },
  {
    "id": "arXiv:2211.08961",
    "title": "First-order system least-squares finite element method for singularly  perturbed Darcy equations",
    "abstract": "We define and analyse a least-squares finite element method for a first-order\nreformulation of a scaled Brinkman model of fluid flow through porous media. We\nintroduce a pseudostress variable that allows to eliminate the pressure\nvariable from the system. It can be recovered by a simple post-processing. It\nis shown that the least-squares functional is uniformly equivalent, i.e.,\nindependent of the singular perturbation parameter, to a parameter dependent\nnorm. This norm equivalence implies that the least-squares functional evaluated\nin the discrete solution provides an efficient and reliable a posteriori error\nestimator. Numerical experiments are presented.",
    "descriptor": "",
    "authors": [
      "Thomas F\u00fchrer",
      "Juha Videman"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.08961"
  },
  {
    "id": "arXiv:2211.08963",
    "title": "The Future of Hackathon Research and Practice",
    "abstract": "Hackathons are time-bounded collaborative events which have become a global\nphenomenon adopted by both researchers and practitioners in a plethora of\ncontexts. Hackathon events are generally used to accelerate the development of,\nfor example, scientific results and collaborations, communities, and innovative\nprototypes addressing urgent challenges. As hackathons have been adopted into\nmany different contexts, the events have also been adapted in numerous ways\ncorresponding to the unique needs and situations of organizers, participants\nand other stakeholders. While these interdisciplinary adaptions, in general\naffords many advantages - such as tailoring the format to specific needs - they\nalso entail certain challenges, specifically: 1) limited exchange of best\npractices, 2) limited exchange of research findings, and 3) larger overarching\nquestions that require interdisciplinary collaboration are not discovered and\nremain unaddressed. We call for interdisciplinary collaborations to address\nthese challenges. As a first initiative towards this, we performed an\ninterdisciplinary collaborative analysis in the context of a workshop at the\nLorentz Center, Leiden in December 2021. In this paper, we present the results\nof this analysis in terms of six important areas which we envision to\ncontribute to maturing hackathon research and practice: 1) hackathons for\ndifferent purposes, 2) socio-technical event design, 3) scaling up, 4) making\nhackathons equitable, 5) studying hackathons, and 6) hackathon goals and how to\nreach them. We present these areas in terms of the state of the art and\nresearch proposals and conclude the paper by suggesting next steps needed for\nadvancing hackathon research and practice.",
    "descriptor": "\nComments: 20 pages, 3 figures, 1 table\n",
    "authors": [
      "Jeanette Falk",
      "Alexander Nolte",
      "Daniela Huppenkothen",
      "Marion Weinzierl",
      "Kiev Gama",
      "Daniel Spikol",
      "Erik Tollerud",
      "Neil Chue Hong",
      "Ines Kn\u00e4pper",
      "Linda Bailey Hayden"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.08963"
  },
  {
    "id": "arXiv:2211.08969",
    "title": "Energy Smart Buildings: Parallel Uniform Cost-Search with Energy Storage  and Generation",
    "abstract": "The amalgamation of Internet of Things and the smart grid enables the energy\noptimal scheduling of appliances based on user needs and dynamic energy prices.\nAdditionally, progress in local storage technology calls for exploiting\nadditional sources of flexibility. In this paper, we propose a scheduling\napproach for building operation management, considering factors such as energy\nstorage, local energy generation, and dynamic energy prices. In addition, we\npropose a new optimization strategy to discover the optimal scheduling of\ndevices. Our approach utilizes parallel uniform cost-search to explore the\ncomplex search space and to find the optimal schedule within a user-acceptable\namount of time. The evaluation utilizes real-world data for the devices, and\nthe price signals, while the architecture is designed following a micro-service\napproach, enabling modularity and loose-coupling. The evaluation shows that\nincluding local energy storage as part of the optimization problem further\nreduces overall costs by up to 22.64\\% when compared to schedules without\nenergy storage. Parallel uniform cost-search decreases the time to find the\noptimal schedule by a factor of 4.7 with respect to the traditional uniform\ncost-search algorithm.",
    "descriptor": "\nComments: 14 pages, 7 figures, 6 tables\n",
    "authors": [
      "Brian Setz",
      "Kawsar Haghshenas",
      "Marco Aiello"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.08969"
  },
  {
    "id": "arXiv:2211.08972",
    "title": "New Frontiers in Graph Autoencoders: Joint Community Detection and Link  Prediction",
    "abstract": "Graph autoencoders (GAE) and variational graph autoencoders (VGAE) emerged as\npowerful methods for link prediction (LP). Their performances are less\nimpressive on community detection (CD), where they are often outperformed by\nsimpler alternatives such as the Louvain method. It is still unclear to what\nextent one can improve CD with GAE and VGAE, especially in the absence of node\nfeatures. It is moreover uncertain whether one could do so while simultaneously\npreserving good performances on LP in a multi-task setting. In this workshop\npaper, summarizing results from our journal publication (Salha-Galvan et al.\n2022), we show that jointly addressing these two tasks with high accuracy is\npossible. For this purpose, we introduce a community-preserving message passing\nscheme, doping our GAE and VGAE encoders by considering both the initial graph\nand Louvain-based prior communities when computing embedding spaces. Inspired\nby modularity-based clustering, we further propose novel training and\noptimization strategies specifically designed for joint LP and CD. We\ndemonstrate the empirical effectiveness of our approach, referred to as\nModularity-Aware GAE and VGAE, on various real-world graphs.",
    "descriptor": "\nComments: This NeurIPS 2022 GLFrontiers workshop paper summarizes results from the following journal article: arXiv:2202.00961. arXiv admin note: text overlap with arXiv:2205.14651\n",
    "authors": [
      "Guillaume Salha-Galvan",
      "Johannes F. Lutzeyer",
      "George Dasoulas",
      "Romain Hennequin",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.08972"
  },
  {
    "id": "arXiv:2211.08975",
    "title": "Region Embedding with Intra and Inter-View Contrastive Learning",
    "abstract": "Unsupervised region representation learning aims to extract dense and\neffective features from unlabeled urban data. While some efforts have been made\nfor solving this problem based on multiple views, existing methods are still\ninsufficient in extracting representations in a view and/or incorporating\nrepresentations from different views. Motivated by the success of contrastive\nlearning for representation learning, we propose to leverage it for multi-view\nregion representation learning and design a model called ReMVC (Region\nEmbedding with Multi-View Contrastive Learning) by following two guidelines: i)\ncomparing a region with others within each view for effective representation\nextraction and ii) comparing a region with itself across different views for\ncross-view information sharing. We design the intra-view contrastive learning\nmodule which helps to learn distinguished region embeddings and the inter-view\ncontrastive learning module which serves as a soft co-regularizer to constrain\nthe embedding parameters and transfer knowledge across multi-views. We exploit\nthe learned region embeddings in two downstream tasks named land usage\nclustering and region popularity prediction. Extensive experiments demonstrate\nthat our model achieves impressive improvements compared with seven\nstate-of-the-art baseline methods, and the margins are over 30% in the land\nusage clustering task.",
    "descriptor": "",
    "authors": [
      "Liang Zhang",
      "Cheng Long",
      "Gao Cong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08975"
  },
  {
    "id": "arXiv:2211.08976",
    "title": "Generating Stable and Collision-Free Policies through Lyapunov Function  Learning",
    "abstract": "The need for rapid and reliable robot deployment is on the rise. Imitation\nLearning (IL) has become popular for producing motion planning policies from a\nset of demonstrations. However, many methods in IL are not guaranteed to\nproduce stable policies. The generated policy may not converge to the robot\ntarget, reducing reliability, and may collide with its environment, reducing\nthe safety of the system. Stable Estimator of Dynamic Systems (SEDS) produces\nstable policies by constraining the Lyapunov stability criteria during\nlearning, but the Lyapunov candidate function had to be manually selected. In\nthis work, we propose a novel method for learning a Lyapunov function and a\npolicy using a single neural network model. The method can be equipped with an\nobstacle avoidance module for convex object pairs to guarantee no collisions.\nWe demonstrated our method is capable of finding policies in several simulation\nenvironments and transfer to a real-world scenario.",
    "descriptor": "\nComments: 7 pages, 11 figures, submitted to the International Conference on Robotics and Automation (2023)\n",
    "authors": [
      "Alexandre Coulombe",
      "Hsiu-Chin Lin"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.08976"
  },
  {
    "id": "arXiv:2211.08978",
    "title": "Rapid Connectionist Speaker Adaptation",
    "abstract": "We present SVCnet, a system for modelling speaker variability. Encoder Neural\nNetworks specialized for each speech sound produce low dimensionality models of\nacoustical variation, and these models are further combined into an overall\nmodel of voice variability. A training procedure is described which minimizes\nthe dependence of this model on which sounds have been uttered. Using the\ntrained model (SVCnet) and a brief, unconstrained sample of a new speaker's\nvoice, the system produces a Speaker Voice Code that can be used to adapt a\nrecognition system to the new speaker without retraining. A system which\ncombines SVCnet with an MS-TDNN recognizer is described",
    "descriptor": "\nComments: 6 Figures, Two Tables, ICASSP-92\n",
    "authors": [
      "Michael Witbrock",
      "Patrick Haffner"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.08978"
  },
  {
    "id": "arXiv:2211.08980",
    "title": "Asynchronous Gradient Play in Zero-Sum Multi-agent Games",
    "abstract": "Finding equilibria via gradient play in competitive multi-agent games has\nbeen attracting a growing amount of attention in recent years, with emphasis on\ndesigning efficient strategies where the agents operate in a decentralized and\nsymmetric manner with guaranteed convergence. While significant efforts have\nbeen made in understanding zero-sum two-player matrix games, the performance in\nzero-sum multi-agent games remains inadequately explored, especially in the\npresence of delayed feedbacks, leaving the scalability and resiliency of\ngradient play open to questions.\nIn this paper, we make progress by studying asynchronous gradient plays in\nzero-sum polymatrix games under delayed feedbacks. We first establish that the\nlast iterate of entropy-regularized optimistic multiplicative weight updates\n(OMWU) method converges linearly to the quantal response equilibrium (QRE), the\nsolution concept under bounded rationality, in the absence of delays. While the\nlinear convergence continues to hold even when the feedbacks are randomly\ndelayed under mild statistical assumptions, it converges at a noticeably slower\nrate due to a smaller tolerable range of learning rates. Moving beyond, we\ndemonstrate entropy-regularized OMWU -- by adopting two-timescale learning\nrates in a delay-aware manner -- enjoys faster last-iterate convergence under\nfixed delays, and continues to converge provably even when the delays are\narbitrarily bounded in an average-iterate manner. Our methods also lead to\nfinite-time guarantees to approximate the Nash equilibrium (NE) by moderating\nthe amount of regularization. To the best of our knowledge, this work is the\nfirst that aims to understand asynchronous gradient play in zero-sum polymatrix\ngames under a wide range of delay assumptions, highlighting the role of\nlearning rates separation.",
    "descriptor": "",
    "authors": [
      "Ruicheng Ao",
      "Shicong Cen",
      "Yuejie Chi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.08980"
  },
  {
    "id": "arXiv:2211.08982",
    "title": "Normative Modeling via Conditional Variational Autoencoder and  Adversarial Learning to Identify Brain Dysfunction in Alzheimer's Disease",
    "abstract": "Normative modeling is an emerging and promising approach to effectively study\ndisorder heterogeneity in individual participants. In this study, we propose a\nnovel normative modeling method by combining conditional variational\nautoencoder with adversarial learning (ACVAE) to identify brain dysfunction in\nAlzheimer's Disease (AD). Specifically, we first train a conditional VAE on the\nhealthy control (HC) group to create a normative model conditioned on\ncovariates like age, gender and intracranial volume. Then we incorporate an\nadversarial training process to construct a discriminative feature space that\ncan better generalize to unseen data. Finally, we compute deviations from the\nnormal criterion at the patient level to determine which brain regions were\nassociated with AD. Our experiments on OASIS-3 database show that the deviation\nmaps generated by our model exhibit higher sensitivity to AD compared to other\ndeep normative models, and are able to better identify differences between the\nAD and HC groups.",
    "descriptor": "\nComments: 5 pages, 3 figures, conference\n",
    "authors": [
      "Xuetong Wang",
      "Kanhao Zhao",
      "Rong Zhou",
      "Alex Leow",
      "Ricardo Osorio",
      "Yu Zhang",
      "Lifang He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.08982"
  },
  {
    "id": "arXiv:2211.08983",
    "title": "Is my automatic audio captioning system so bad? spider-max: a metric to  consider several caption candidates",
    "abstract": "Automatic Audio Captioning (AAC) is the task that aims to describe an audio\nsignal using natural language. AAC systems take as input an audio signal and\noutput a free-form text sentence, called a caption. Evaluating such systems is\nnot trivial, since there are many ways to express the same idea. For this\nreason, several complementary metrics, such as BLEU, CIDEr, SPICE and SPIDEr,\nare used to compare a single automatic caption to one or several captions of\nreference, produced by a human annotator. Nevertheless, an automatic system can\nproduce several caption candidates, either using some randomness in the\nsentence generation process, or by considering the various competing\nhypothesized captions during decoding with beam-search, for instance. If we\nconsider an end-user of an AAC system, presenting several captions instead of a\nsingle one seems relevant to provide some diversity, similarly to information\nretrieval systems. In this work, we explore the possibility to consider several\npredicted captions in the evaluation process instead of one. For this purpose,\nwe propose SPIDEr-max, a metric that takes the maximum SPIDEr value among the\nscores of several caption candidates. To advocate for our metric, we report\nexperiments on Clotho v2.1 and AudioCaps, with a transformed-based system. On\nAudioCaps for example, this system reached a SPIDEr-max value (with 5\ncandidates) close to the SPIDEr human score of reference.",
    "descriptor": "\nComments: Workshop on Detection and Classification of Acoustic Scenes and Events (DCASE 2022), Nov 2022, Nancy, France\n",
    "authors": [
      "Etienne Labb\u00e9",
      "Thomas Pellegrini",
      "Julien Pinquier"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.08983"
  },
  {
    "id": "arXiv:2211.08987",
    "title": "TSMind: Alibaba and Soochow University's Submission to the WMT22  Translation Suggestion Task",
    "abstract": "This paper describes the joint submission of Alibaba and Soochow University,\nTSMind, to the WMT 2022 Shared Task on Translation Suggestion (TS). We\nparticipate in the English-German and English-Chinese tasks. Basically, we\nutilize the model paradigm fine-tuning on the downstream tasks based on\nlarge-scale pre-trained models, which has recently achieved great success. We\nchoose FAIR's WMT19 English-German news translation system and MBART50 for\nEnglish-Chinese as our pre-trained models. Considering the task's condition of\nlimited use of training data, we follow the data augmentation strategies\nproposed by WeTS to boost our TS model performance. The difference is that we\nfurther involve the dual conditional cross-entropy model and GPT-2 language\nmodel to filter augmented data. The leader board finally shows that our\nsubmissions are ranked first in three of four language directions in the Naive\nTS task of the WMT22 Translation Suggestion task.",
    "descriptor": "",
    "authors": [
      "Xin Ge",
      "Ke Wang",
      "Jiayi Wang",
      "Nini Xiao",
      "Xiangyu Duan",
      "Yu Zhao",
      "Yuqi Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08987"
  },
  {
    "id": "arXiv:2211.08989",
    "title": "Avoid Overthinking in Self-Supervised Models for Speech Recognition",
    "abstract": "Self-supervised learning (SSL) models reshaped our approach to speech,\nlanguage and vision. However their huge size and the opaque relations between\ntheir layers and tasks result in slow inference and network overthinking, where\npredictions made from the last layer of large models is worse than those made\nfrom intermediate layers. Early exit (EE) strategies can solve both issues by\ndynamically reducing computations at inference time for certain samples.\nAlthough popular for classification tasks in vision and language, EE has seen\nless use for sequence-to-sequence speech recognition (ASR) tasks where outputs\nfrom early layers are often degenerate. This challenge is further compounded\nwhen speech SSL models are applied on out-of-distribution (OOD) data. This\npaper first shows that SSL models do overthinking in ASR. We then motivate\nfurther research in EE by computing an optimal bound for performance versus\nspeed trade-offs. To approach this bound we propose two new strategies for ASR:\n(1) we adapt the recently proposed patience strategy to ASR; and (2) we design\na new EE strategy specific to ASR that performs better than all strategies\npreviously introduced.",
    "descriptor": "",
    "authors": [
      "Dan Berrebbi",
      "Brian Yan",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.08989"
  },
  {
    "id": "arXiv:2211.08991",
    "title": "Estimating Discontinuous Time-Varying Risk Factors and Treatment  Benefits for COVID-19 with Interpretable ML",
    "abstract": "Treatment protocols, disease understanding, and viral characteristics changed\nover the course of the COVID-19 pandemic; as a result, the risks associated\nwith patient comorbidities and biomarkers also changed. We add to the\nconversation regarding inflammation, hemostasis and vascular function in\nCOVID-19 by performing a time-varying observational analysis of over 4000\npatients hospitalized for COVID-19 in a New York City hospital system from\nMarch 2020 to August 2021. To perform this analysis, we apply tree-based\ngeneralized additive models with temporal interactions which recover\ndiscontinuous risk changes caused by discrete protocols changes. We find that\nthe biomarkers of thrombosis increasingly predicted mortality from March 2020\nto August 2021, while the association between biomarkers of inflammation and\nthrombosis weakened. Beyond COVID-19, this presents a straightforward\nmethodology to estimate unknown and discontinuous time-varying effects.",
    "descriptor": "\nComments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 14 pages\n",
    "authors": [
      "Benjamin Lengerich",
      "Mark E. Nunnally",
      "Yin Aphinyanaphongs",
      "Rich Caruana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.08991"
  },
  {
    "id": "arXiv:2211.08992",
    "title": "DLKoopman: A deep learning software package for Koopman theory",
    "abstract": "We present DLKoopman -- a software package for Koopman theory that uses deep\nlearning to learn an encoding of a nonlinear dynamical system into a linear\nspace, while simultaneously learning the linear dynamics. While several\nprevious efforts have either restricted the ability to learn encodings, or been\nbespoke efforts designed for specific systems, DLKoopman is a generalized tool\nthat can be applied to data-driven learning and optimization of any dynamical\nsystem. It can either be trained on data from individual states (snapshots) of\na system and used to predict its unknown states, or trained on data from\ntrajectories of a system and used to predict unknown trajectories for new\ninitial states. DLKoopman is available on the Python Package Index (PyPI) as\n'dlkoopman', and includes extensive documentation and tutorials. Additional\ncontributions of the package include a novel metric called Average Normalized\nAbsolute Error for evaluating performance, and a ready-to-use hyperparameter\nsearch module for improving performance.",
    "descriptor": "\nComments: Submitted to 5th Annual Learning for Dynamics & Control Conference (L4DC)\n",
    "authors": [
      "Sourya Dey",
      "Eric Davis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.08992"
  },
  {
    "id": "arXiv:2211.08997",
    "title": "Dynamical Linear Bandits",
    "abstract": "In many real-world sequential decision-making problems, an action does not\nimmediately reflect on the feedback and spreads its effects over a long time\nframe. For instance, in online advertising, investing in a platform produces an\nincrease of awareness, but the actual reward, i.e., a conversion, might occur\nfar in the future. Furthermore, whether a conversion takes place depends on:\nhow fast the awareness grows, its vanishing effects, and the synergy or\ninterference with other advertising platforms. Previous work has investigated\nthe Multi-Armed Bandit framework with the possibility of delayed and aggregated\nfeedback, without a particular structure on how an action propagates in the\nfuture, disregarding possible dynamical effects. In this paper, we introduce a\nnovel setting, the Dynamical Linear Bandits (DLB), an extension of the linear\nbandits characterized by a hidden state. When an action is performed, the\nlearner observes a noisy reward whose mean is a linear function of the hidden\nstate and of the action. Then, the hidden state evolves according to a linear\ndynamics, affected by the performed action too. We start by introducing the\nsetting, discussing the notion of optimal policy, and deriving an expected\nregret lower bound. Then, we provide an any-time optimistic regret minimization\nalgorithm, Dynamical Linear Upper Confidence Bound (DynLin-UCB), that suffers\nan expected regret of order O(c d sqrt(T)), where c is a constant dependent on\nthe properties of the linear dynamical evolution, and d is the dimension of the\naction vector. Finally, we conduct a numerical validation on a synthetic\nenvironment and on real-world data to show the effectiveness of DynLin-UCB in\ncomparison with several baselines.",
    "descriptor": "",
    "authors": [
      "Marco Mussi",
      "Alberto Maria Metelli",
      "Marcello Restelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08997"
  },
  {
    "id": "arXiv:2211.08998",
    "title": "Data-pooling Reinforcement Learning for Personalized Healthcare  Intervention",
    "abstract": "Motivated by the emerging needs of personalized preventative intervention in\nmany healthcare applications, we consider a multi-stage, dynamic\ndecision-making problem in the online setting with unknown model parameters. To\ndeal with the pervasive issue of small sample size in personalized planning, we\ndevelop a novel data-pooling reinforcement learning (RL) algorithm based on a\ngeneral perturbed value iteration framework. Our algorithm adaptively pools\nhistorical data, with three main innovations: (i) the weight of pooling ties\ndirectly to the performance of decision (measured by regret) as opposed to\nestimation accuracy in conventional methods; (ii) no parametric assumptions are\nneeded between historical and current data; and (iii) requiring data-sharing\nonly via aggregate statistics, as opposed to patient-level data. Our\ndata-pooling algorithm framework applies to a variety of popular RL algorithms,\nand we establish a theoretical performance guarantee showing that our pooling\nversion achieves a regret bound strictly smaller than that of the no-pooling\ncounterpart. We substantiate the theoretical development with empirically\nbetter performance of our algorithm via a case study in the context of\npost-discharge intervention to prevent unplanned readmissions, generating\npractical insights for healthcare management. In particular, our algorithm\nalleviates privacy concerns about sharing health data, which (i) opens the door\nfor individual organizations to levering public datasets or published studies\nto better manage their own patients; and (ii) provides the basis for public\npolicy makers to encourage organizations to share aggregate data to improve\npopulation health outcomes for the broader community.",
    "descriptor": "",
    "authors": [
      "Xinyun Chen",
      "Pengyi Shi",
      "Shanwen Pu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.08998"
  },
  {
    "id": "arXiv:2211.09001",
    "title": "Multi-Timescale Modeling of Human Behavior",
    "abstract": "In recent years, the role of artificially intelligent (AI) agents has evolved\nfrom being basic tools to socially intelligent agents working alongside humans\ntowards common goals. In such scenarios, the ability to predict future behavior\nby observing past actions of their human teammates is highly desirable in an AI\nagent. Goal-oriented human behavior is complex, hierarchical, and unfolds\nacross multiple timescales. Despite this observation, relatively little\nattention has been paid towards using multi-timescale features to model such\nbehavior. In this paper, we propose an LSTM network architecture that processes\nbehavioral information at multiple timescales to predict future behavior. We\ndemonstrate that our approach for modeling behavior in multiple timescales\nsubstantially improves prediction of future behavior compared to methods that\ndo not model behavior at multiple timescales. We evaluate our architecture on\ndata collected in an urban search and rescue scenario simulated in a virtual\nMinecraft-based testbed, and compare its performance to that of a number of\nvalid baselines as well as other methods that do not process inputs at multiple\ntimescales.",
    "descriptor": "",
    "authors": [
      "Chinmai Basavaraj",
      "Adarsh Pyarelal",
      "Evan Carter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09001"
  },
  {
    "id": "arXiv:2211.09006",
    "title": "ToolFlowNet: Robotic Manipulation with Tools via Predicting Tool Flow  from Point Clouds",
    "abstract": "Point clouds are a widely available and canonical data modality which convey\nthe 3D geometry of a scene. Despite significant progress in classification and\nsegmentation from point clouds, policy learning from such a modality remains\nchallenging, and most prior works in imitation learning focus on learning\npolicies from images or state information. In this paper, we propose a novel\nframework for learning policies from point clouds for robotic manipulation with\ntools. We use a novel neural network, ToolFlowNet, which predicts dense\nper-point flow on the tool that the robot controls, and then uses the flow to\nderive the transformation that the robot should execute. We apply this\nframework to imitation learning of challenging deformable object manipulation\ntasks with continuous movement of tools, including scooping and pouring, and\ndemonstrate significantly improved performance over baselines which do not use\nflow. We perform 50 physical scooping experiments with ToolFlowNet and attain\n82% scooping success. See https://tinyurl.com/toolflownet for supplementary\nmaterial.",
    "descriptor": "\nComments: Conference on Robot Learning (CoRL), 2022. Supplementary material is available at this https URL\n",
    "authors": [
      "Daniel Seita",
      "Yufei Wang",
      "Sarthak J. Shetty",
      "Edward Yao Li",
      "Zackory Erickson",
      "David Held"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.09006"
  },
  {
    "id": "arXiv:2211.09011",
    "title": "Detecting train driveshaft damages using accelerometer signals and  Differential Convolutional Neural Networks",
    "abstract": "Railway axle maintenance is critical to avoid catastrophic failures.\nNowadays, condition monitoring techniques are becoming more prominent in the\nindustry to prevent enormous costs and damage to human lives. This paper\nproposes the development of a railway axle condition monitoring system based on\nadvanced 2D-Convolutional Neural Network (CNN) architectures applied to\ntime-frequency representations of vibration signals. For this purpose, several\npreprocessing steps and different types of Deep Learning (DL) and Machine\nLearning (ML) architectures are discussed to design an accurate classification\nsystem. The resultant system converts the railway axle vibration signals into\ntime-frequency domain representations, i.e., spectrograms, and, thus, trains a\ntwo-dimensional CNN to classify them depending on their cracks. The results\nshowed that the proposed approach outperforms several alternative methods\ntested. The CNN architecture has been tested in 3 different wheelset\nassemblies, achieving AUC scores of 0.93, 0.86, and 0.75 outperforming any\nother architecture and showing a high level of reliability when classifying 4\ndifferent levels of defects.",
    "descriptor": "",
    "authors": [
      "Ant\u00eda L\u00f3pez Galdo",
      "Alejandro Guerrero-L\u00f3pez",
      "Pablo M. Olmos",
      "Mar\u00eda Jes\u00fas G\u00f3mez Garc\u00eda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.09011"
  },
  {
    "id": "arXiv:2211.09013",
    "title": "Masked Reconstruction Contrastive Learning with Information Bottleneck  Principle",
    "abstract": "Contrastive learning (CL) has shown great power in self-supervised learning\ndue to its ability to capture insight correlations among large-scale data.\nCurrent CL models are biased to learn only the ability to discriminate positive\nand negative pairs due to the discriminative task setting. However, this bias\nwould lead to ignoring its sufficiency for other downstream tasks, which we\ncall the discriminative information overfitting problem. In this paper, we\npropose to tackle the above problems from the aspect of the Information\nBottleneck (IB) principle, further pushing forward the frontier of CL.\nSpecifically, we present a new perspective that CL is an instantiation of the\nIB principle, including information compression and expression. We\ntheoretically analyze the optimal information situation and demonstrate that\nminimum sufficient augmentation and information-generalized representation are\nthe optimal requirements for achieving maximum compression and generalizability\nto downstream tasks. Therefore, we propose the Masked Reconstruction\nContrastive Learning~(MRCL) model to improve CL models. For implementation in\npractice, MRCL utilizes the masking operation for stronger augmentation,\nfurther eliminating redundant and noisy information. In order to alleviate the\ndiscriminative information overfitting problem effectively, we employ the\nreconstruction task to regularize the discriminative task. We conduct\ncomprehensive experiments and show the superiority of the proposed model on\nmultiple tasks, including image classification, semantic segmentation and\nobjective detection.",
    "descriptor": "",
    "authors": [
      "Ziwen Liu",
      "Bonan Li",
      "Congying Han",
      "Tiande Guo",
      "Xuecheng Nie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.09013"
  },
  {
    "id": "arXiv:2211.09016",
    "title": "Multidimensional Generalized Riemann Problem Solver for Maxwell's  Equations",
    "abstract": "Approximate multidimensional Riemann solvers are essential building blocks in\ndesigning globally constraint-preserving finite volume time domain (FVTD) and\ndiscontinuous Galerkin time domain (DGTD) schemes for computational\nelectrodynamics (CED). In those schemes, we can achieve high-order temporal\naccuracy with the help of Runge-Kutta or ADER time-stepping. This paper\npresents the design of a multidimensional approximate Generalized Riemann\nProblem (GRP) solver for the first time. The multidimensional Riemann solver\naccepts as its inputs the four states surrounding an edge on a structured mesh,\nand its output consists of a resolved state and its associated fluxes. In\ncontrast, the multidimensional GRP solver accepts as its inputs the four states\nand their gradients in all directions; its output consists of the resolved\nstate and its corresponding fluxes and the gradients of the resolved state. The\ngradients can then be used to extend the solution in time. As a result, we\nachieve second-order temporal accuracy in a single step.\nIn this work, the formulation is optimized for linear hyperbolic systems with\nstiff, linear source terms because such a formulation will find maximal use in\nCED. Our formulation produces an overall constraint-preserving time-stepping\nstrategy based on the GRP that is provably L-stable in the presence of stiff\nsource terms. We present several stringent test problems, showing that the\nmultidimensional GRP solver for CED meets its design accuracy and performs\nstably with optimal time steps. The test problems include cases with high\nconductivity, showing that the beneficial L-stability is indeed realized in\npractical applications.",
    "descriptor": "\nComments: 36 Pages, 9 figures\n",
    "authors": [
      "Arijit Hazra",
      "Dinshaw S. Balsara",
      "Praveen Chandrashekar",
      "Sudip K. Garain"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.09016"
  },
  {
    "id": "arXiv:2211.09018",
    "title": "Real Estate Attribute Prediction from Multiple Visual Modalities with  Missing Data",
    "abstract": "The assessment and valuation of real estate requires large datasets with real\nestate information. Unfortunately, real estate databases are usually sparse in\npractice, i.e., not for each property every important attribute is available.\nIn this paper, we study the potential of predicting high-level real estate\nattributes from visual data, specifically from two visual modalities, namely\nindoor (interior) and outdoor (facade) photos. We design three models using\ndifferent multimodal fusion strategies and evaluate them for three different\nuse cases. Thereby, a particular challenge is to handle missing modalities. We\nevaluate different fusion strategies, present baselines for the different\nprediction tasks, and find that enriching the training data with additional\nincomplete samples can lead to an improvement in prediction accuracy.\nFurthermore, the fusion of information from indoor and outdoor photos results\nin a performance boost of up to 5% in Macro F1-score.",
    "descriptor": "\nComments: included in the Proceedings of the OAGM Workshop 2021\n",
    "authors": [
      "Eric Stumpe",
      "Miroslav Despotovic",
      "Zedong Zhang",
      "Matthias Zeppelzauer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09018"
  },
  {
    "id": "arXiv:2211.09019",
    "title": "Learning Reward Functions for Robotic Manipulation by Observing Humans",
    "abstract": "Observing a human demonstrator manipulate objects provides a rich, scalable\nand inexpensive source of data for learning robotic policies. However,\ntransferring skills from human videos to a robotic manipulator poses several\nchallenges, not least a difference in action and observation spaces. In this\nwork, we use unlabeled videos of humans solving a wide range of manipulation\ntasks to learn a task-agnostic reward function for robotic manipulation\npolicies. Thanks to the diversity of this training data, the learned reward\nfunction sufficiently generalizes to image observations from a previously\nunseen robot embodiment and environment to provide a meaningful prior for\ndirected exploration in reinforcement learning. The learned rewards are based\non distances to a goal in an embedding space learned using a time-contrastive\nobjective. By conditioning the function on a goal image, we are able to reuse\none model across a variety of tasks. Unlike prior work on leveraging human\nvideos to teach robots, our method, Human Offline Learned Distances (HOLD)\nrequires neither a priori data from the robot environment, nor a set of\ntask-specific human demonstrations, nor a predefined notion of correspondence\nacross morphologies, yet it is able to accelerate training of several\nmanipulation tasks on a simulated robot arm compared to using only a sparse\nreward obtained from task completion.",
    "descriptor": "",
    "authors": [
      "Minttu Alakuijala",
      "Gabriel Dulac-Arnold",
      "Julien Mairal",
      "Jean Ponce",
      "Cordelia Schmid"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09019"
  },
  {
    "id": "arXiv:2211.09020",
    "title": "Optimal SMC for Transactional Programs",
    "abstract": "The verification of transactional concurrent programs running over causally\nconsistent databases is a challenging problem. We present a framework for\nefficient stateless model checking (SMC) of concurrent programs with\ntransactions under two well known models of causal consistency, CCv and CC. Our\napproach is based on exploring the program order po and the reads from rf\nrelations, avoiding exploration of all possible coherence orders. Our SMC\nalgorithm is provably optimal in the sense that it explores each po and rf\nrelation exactly once. We have implemented our framework in a tool called\n\\ourtool{}. Experiments show that \\ourtool{} performs well in detecting\nanomalies in classical distributed databases benchmarks.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1906.12095 by other authors\n",
    "authors": [
      "Parosh Aziz Abdulla",
      "Mohamed Faouzi Atig",
      "Ashutosh Gupta",
      "Shankaranarayanan Krishna",
      "Omkar Tuppe"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.09020"
  },
  {
    "id": "arXiv:2211.09022",
    "title": "Region Proposal Network Pre-Training Helps Label-Efficient Object  Detection",
    "abstract": "Self-supervised pre-training, based on the pretext task of instance\ndiscrimination, has fueled the recent advance in label-efficient object\ndetection. However, existing studies focus on pre-training only a feature\nextractor network to learn transferable representations for downstream\ndetection tasks. This leads to the necessity of training multiple\ndetection-specific modules from scratch in the fine-tuning phase. We argue that\nthe region proposal network (RPN), a common detection-specific module, can\nadditionally be pre-trained towards reducing the localization error of\nmulti-stage detectors. In this work, we propose a simple pretext task that\nprovides an effective pre-training for the RPN, towards efficiently improving\ndownstream object detection performance. We evaluate the efficacy of our\napproach on benchmark object detection tasks and additional downstream tasks,\nincluding instance segmentation and few-shot detection. In comparison with\nmulti-stage detectors without RPN pre-training, our approach is able to\nconsistently improve downstream task performance, with largest gains found in\nlabel-scarce settings.",
    "descriptor": "\nComments: Presented at NeurIPS 2022 Workshop: Self-Supervised Learning - Theory and Practice\n",
    "authors": [
      "Linus Ericsson",
      "Nanqing Dong",
      "Yongxin Yang",
      "Ales Leonardis",
      "Steven McDonagh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09022"
  },
  {
    "id": "arXiv:2211.09025",
    "title": "Latency Reduction for Mobile Backhaul by Pipelining LTE and DOCSIS",
    "abstract": "The small cell market has been growing. To backhaul wireless traffic from\nsmall cells, the mobile network operators (MNOs) are looking into economically\nviable solutions, specifically the hybrid fiber coaxial networks (HFC), in\naddition to the traditional choice of fiber. When the latencies from both the\nwireless and the HFC networks are added together, it can result in noticeable\nend-to-end system latency, particularly under network congestion. If the two\nnetworks could somehow coordinate with each other, it would be possible to\ndecrease the total system latency and increase system performance. In this\npaper, we propose a method to improve upstream user-to-mobile core latency by\ncoordinating the LTE and HFC scheduling. The method reduces the impact on\nsystem latency from the HFC network's request-grant-data loop, which is the\nmain contributor of backhaul upstream latency. Through simulation, we show that\ncoordinated scheduling improves overall system latency.",
    "descriptor": "\nComments: IEEE Global Communications Conference (GLOBECOM), 2017. arXiv admin note: substantial text overlap with arXiv:2211.08292; text overlap with arXiv:2211.08298\n",
    "authors": [
      "Jennifer Andreoli-Fang",
      "John T Chapman"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.09025"
  },
  {
    "id": "arXiv:2211.09027",
    "title": "LLEDA -- Lifelong Self-Supervised Domain Adaptation",
    "abstract": "Lifelong domain adaptation remains a challenging task in machine learning due\nto the differences among the domains and the unavailability of historical data.\nThe ultimate goal is to learn the distributional shifts while retaining the\npreviously gained knowledge. Inspired by the Complementary Learning Systems\n(CLS) theory, we propose a novel framework called Lifelong Self-Supervised\nDomain Adaptation (LLEDA). LLEDA addresses catastrophic forgetting by replaying\nhidden representations rather than raw data pixels and domain-agnostic\nknowledge transfer using self-supervised learning. LLEDA does not access labels\nfrom the source or the target domain and only has access to a single domain at\nany given time. Extensive experiments demonstrate that the proposed method\noutperforms several other methods and results in a long-term adaptation, while\nbeing less prone to catastrophic forgetting when transferred to new domains.",
    "descriptor": "\nComments: 10 pages, 6 figures, 4 tables\n",
    "authors": [
      "Mamatha Thota",
      "Dewei Yi",
      "Georgios Leontidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09027"
  },
  {
    "id": "arXiv:2211.09029",
    "title": "If Multicast is the Answer -- What was the Question?",
    "abstract": "Multicast is (almost) as old as the Internet, having become a tool for\nincreasing network efficiency but also enabling destination discovery in a\nnumber of key use cases, although misaligned economic interests have limited\nits deployment to domain-local usages. But recent advances in multicast\ntechnologies as well as the identification of new use cases for which IP\nmulticast may be ill fitted yet network-level support may be desirable motivate\nto re-think old perceptions of multicast and its use in the Internet overall.\nFor this, we return to the original question to which multicast is seemingly\nthe right answer, based on which we outline emerging new answers to what\nmulticast intends to achieve. Key to this is to re-formulate the multicast\nquestion in an attempt to semantically and architecturally align different\nanswers, opening opportunities for more use cases to be served through\nmulticast solutions, thus also driving the need for more research in this\nspace. Our paper poses this new vision for multicast and investigates the\nalignment of existing and emerging multicast solutions with it, leading us to\nformulate a path for future research.",
    "descriptor": "\nComments: Under discussion\n",
    "authors": [
      "Dirk Trossen",
      "Jon Crowcroft"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.09029"
  },
  {
    "id": "arXiv:2211.09031",
    "title": "Numerical accuracy and stability of semilinear Klein--Gordon equation in  de Sitter spacetime",
    "abstract": "Numerical simulations of the semilinear Klein--Gordon equation in the de\nSitter spacetime are performed. We use two structure-preserving discrete forms\nof the Klein--Gordon equation. The disparity between the two forms is the\ndiscretization of the differential term. We show that one of the forms has\nhigher numerical stability and second-order numerical accuracy with respect to\nthe grid, and we explain the reason for the instability of the other form.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Takuya Tsuchiya",
      "Makoto Nakamura"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "General Relativity and Quantum Cosmology (gr-qc)"
    ],
    "url": "https://arxiv.org/abs/2211.09031"
  },
  {
    "id": "arXiv:2211.09032",
    "title": "CL2R: Compatible Lifelong Learning Representations",
    "abstract": "In this paper, we propose a method to partially mimic natural intelligence\nfor the problem of lifelong learning representations that are compatible. We\ntake the perspective of a learning agent that is interested in recognizing\nobject instances in an open dynamic universe in a way in which any update to\nits internal feature representation does not render the features in the gallery\nunusable for visual search. We refer to this learning problem as Compatible\nLifelong Learning Representations (CL2R) as it considers compatible\nrepresentation learning within the lifelong learning paradigm. We identify\nstationarity as the property that the feature representation is required to\nhold to achieve compatibility and propose a novel training procedure that\nencourages local and global stationarity on the learned representation. Due to\nstationarity, the statistical properties of the learned features do not change\nover time, making them interoperable with previously learned features.\nExtensive experiments on standard benchmark datasets show that our CL2R\ntraining procedure outperforms alternative baselines and state-of-the-art\nmethods. We also provide novel metrics to specifically evaluate compatible\nrepresentation learning under catastrophic forgetting in various sequential\nlearning tasks. Code at\nhttps://github.com/NiccoBiondi/CompatibleLifelongRepresentation.",
    "descriptor": "\nComments: Published on ACM TOMM 2022\n",
    "authors": [
      "Niccolo Biondi",
      "Federico Pernici",
      "Matteo Bruni",
      "Daniele Mugnai",
      "Alberto Del Bimbo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09032"
  },
  {
    "id": "arXiv:2211.09034",
    "title": "Research Software Science: Expanding the Impact of Research Software  Engineering",
    "abstract": "Software plays a central role in scientific discovery. Improving how we\ndevelop and use software for research can have both broad and deep impacts on a\nspectrum of challenges and opportunities society faces today. The emergence of\nResearch Software Engineer (RSE) as a role correlates with the growing\ncomplexity of scientific challenges and diversity of software team skills. In\nthis paper, we describe research software science (RSS), an idea related to\nRSE, and particularly suited to research software teams. RSS promotes the use\nof scientific methodologies to explore and establish broadly applicable\nknowledge. Using RSS, we can pursue sustainable, repeatable, and reproducible\nsoftware improvements that positively impact research software toward improved\nscientific discovery.",
    "descriptor": "\nComments: Submitted to IEEE Computing in Science and Engineering\n",
    "authors": [
      "Michael A. Heroux"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.09034"
  },
  {
    "id": "arXiv:2211.09035",
    "title": "A Creative Industry Image Generation Dataset Based on Captions",
    "abstract": "Most image generation methods are difficult to precisely control the\nproperties of the generated images, such as structure, scale, shape, etc.,\nwhich limits its large-scale application in creative industries such as\nconceptual design and graphic design, and so on. Using the prompt and the\nsketch is a practical solution for controllability. Existing datasets lack\neither prompt or sketch and are not designed for the creative industry. Here is\nthe main contribution of our work. a) This is the first dataset that covers the\n4 most important areas of creative industry domains and is labeled with prompt\nand sketch. b) We provide multiple reference images in the test set and\nfine-grained scores for each reference which are useful for measurement. c) We\napply two state-of-the-art models to our dataset and then find some\nshortcomings, such as the prompt is more highly valued than the sketch.",
    "descriptor": "",
    "authors": [
      "Xiang Yuejia",
      "Lv Chuanhao",
      "Liu Qingdazhu",
      "Yang Xiaocui",
      "Liu Bo",
      "Ju Meizhi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09035"
  },
  {
    "id": "arXiv:2211.09037",
    "title": "Complementary Textures. A Novel Approach to Object Alignment in Mixed  Reality",
    "abstract": "Alignment between real and virtual objects is a challenging task required for\nthe deployment of Mixed Reality (MR) into manufacturing, medical, and\nconstruction applications. To face this challenge, a series of methods have\nbeen proposed. While many approaches use dynamic augmentations such as\nanimations, arrows, or text to assist users, they require tracking the position\nof real objects. In contrast, when tracking of the real objects is not\navailable or desired, alternative approaches use virtual replicas of real\nobjects to allow for interactive, perceptual virtual-to-real, and/or\nreal-to-virtual alignment. In these cases, the accuracy achieved strongly\ndepends on the quality of the perceptual information provided to the user. This\npaper proposes a novel set of perceptual alignment concepts that go beyond the\nuse of traditional visualization of virtual replicas, introducing the concept\nof COMPLEMENTARY TEXTURES to improve interactive alignment in MR applications.\nTo showcase the advantages of using COMPLEMENTARY TEXTURES, we describe three\ndifferent implementations that provide highly salient visual cues when\nmisalignment is observed; or present semantic augmentations that, when combined\nwith a real object, provide contextual information that can be used during the\nalignment process. The authors aim to open new paths for the community to\nexplore rather than describing end-to-end solutions. The objective is to show\nthe multitude of opportunities such concepts could provide for further research\nand development.",
    "descriptor": "",
    "authors": [
      "Alejandro Martin-Gomez",
      "Alexander Winkler",
      "Rafael de la Tijera Obert",
      "Javad Fotouhi",
      "Daniel Roth",
      "Ulrich Eck",
      "Nassir Navab"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.09037"
  },
  {
    "id": "arXiv:2211.09039",
    "title": "UniRel: Unified Representation and Interaction for Joint Relational  Triple Extraction",
    "abstract": "Relational triple extraction is challenging for its difficulty in capturing\nrich correlations between entities and relations. Existing works suffer from 1)\nheterogeneous representations of entities and relations, and 2) heterogeneous\nmodeling of entity-entity interactions and entity-relation interactions.\nTherefore, the rich correlations are not fully exploited by existing works. In\nthis paper, we propose UniRel to address these challenges. Specifically, we\nunify the representations of entities and relations by jointly encoding them\nwithin a concatenated natural language sequence, and unify the modeling of\ninteractions with a proposed Interaction Map, which is built upon the\noff-the-shelf self-attention mechanism within any Transformer block. With\ncomprehensive experiments on two popular relational triple extraction datasets,\nwe demonstrate that UniRel is more effective and computationally efficient. The\nsource code is available at https://github.com/wtangdev/UniRel.",
    "descriptor": "\nComments: Accepted at EMNLP 2022. Camera-ready version\n",
    "authors": [
      "Wei Tang",
      "Benfeng Xu",
      "Yuyue Zhao",
      "Zhendong Mao",
      "Yifeng Liu",
      "Yong Liao",
      "Haiyong Xie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.09039"
  },
  {
    "id": "arXiv:2211.09041",
    "title": "Anomaly Detection via Multi-Scale Contrasted Memory",
    "abstract": "Deep anomaly detection (AD) aims to provide robust and efficient classifiers\nfor one-class and unbalanced settings. However current AD models still struggle\non edge-case normal samples and are often unable to keep high performance over\ndifferent scales of anomalies. Moreover, there currently does not exist a\nunified framework efficiently covering both one-class and unbalanced learnings.\nIn the light of these limitations, we introduce a new two-stage anomaly\ndetector which memorizes during training multi-scale normal prototypes to\ncompute an anomaly deviation score. First, we simultaneously learn\nrepresentations and memory modules on multiple scales using a novel\nmemory-augmented contrastive learning. Then, we train an anomaly distance\ndetector on the spatial deviation maps between prototypes and observations. Our\nmodel highly improves the state-of-the-art performance on a wide range of\nobject, style and local anomalies with up to 35\\% error relative improvement on\nCIFAR-10. It is also the first model to keep high performance across the\none-class and unbalanced settings.",
    "descriptor": "",
    "authors": [
      "Loic Jezequel",
      "Ngoc-Son Vu",
      "Jean Beaudet",
      "Aymeric Histace"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09041"
  },
  {
    "id": "arXiv:2211.09043",
    "title": "Community gifting groups on Facebook",
    "abstract": "We use de-identified data from Facebook Groups to study and provide a\ndescriptive analysis of local gift-giving communities, in particular buy\nnothing (BN) groups. These communities allow people to give items they no\nlonger need, reduce waste, and connect to local community. Millions of people\nhave joined BN groups on Facebook, with an increasing pace through the COVID-19\npandemic. BN groups are more popular in dense and urban US counties with higher\neducational attainment. Compared to other local groups, BN groups have lower\nFacebook friendship densities, suggesting they bring together people who are\nnot already connected. The interaction graphs in BN groups form larger strongly\nconnected components, indicative of norms of generalized reciprocity. The\ninteraction patterns in BN groups are similar to other local online gift-giving\ngroups, with names containing terms such as `free stuff\" and `pay it forward\".\nThis points to an interaction signature for local online gift-giving\ncommunities.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Ama\u00e7 Herda\u011fdelen",
      "Lada Adamic",
      "Bogdan State"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.09043"
  },
  {
    "id": "arXiv:2211.09053",
    "title": "A moving horizon state and parameter estimation scheme with guaranteed  robust convergence",
    "abstract": "We propose a moving horizon estimation scheme for joint state and parameter\nestimation for nonlinear uncertain discrete-time systems. We establish robust\nexponential convergence of the combined estimation error subject to process\ndisturbances and measurement noise. We employ a joint incremental\ninput/output-to-state stability ($\\delta$-IOSS) Lyapunov function to\ncharacterize nonlinear detectability for the states and (constant) parameters\nof the system. Sufficient conditions for the construction of a joint\n$\\delta$-IOSS Lyapunov function are provided for a special class of nonlinear\nsystems using a persistence of excitation condition. The theoretical results\nare illustrated by a numerical example.",
    "descriptor": "",
    "authors": [
      "Julian D. Schiller",
      "Matthias A. M\u00fcller"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.09053"
  },
  {
    "id": "arXiv:2211.09056",
    "title": "Linearizations of matrix polynomials viewed as Rosenbrock's system  matrices",
    "abstract": "A well known method to solve the Polynomial Eigenvalue Problem (PEP) is via\nlinearization. That is, transforming the PEP into a generalized linear\neigenvalue problem with the same spectral information and solving such linear\nproblem with some of the eigenvalue algorithms available in the literature.\nLinearizations of matrix polynomials are usually defined using unimodular\ntransformations. In this paper we establish a connection between the standard\ndefinition of linearization for matrix polynomials introduced by Gohberg,\nLancaster and Rodman and the notion of polynomial system matrix introduced by\nRosenbrock. This connection gives new techniques to show that a matrix pencil\nis a linearization of the corresponding matrix polynomial arising in a PEP.",
    "descriptor": "",
    "authors": [
      "Froil\u00e1n M. Dopico",
      "Silvia Marcaida",
      "Mar\u00eda C. Quintana",
      "Paul Van Dooren"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.09056"
  },
  {
    "id": "arXiv:2211.09061",
    "title": "Squeeze flow of micro-droplets: convolutional neural network with  trainable and tunable refinement",
    "abstract": "We propose a platform based on neural networks to solve the image-to-image\ntranslation problem in the context of squeeze flow of micro-droplets. In the\nfirst part of this paper, we present the governing partial differential\nequations to lay out the underlying physics of the problem. We also discuss our\ndeveloped Python package, sqflow, which can potentially serve as free,\nflexible, and scalable standardized benchmarks in the fields of machine\nlearning and computer vision. In the second part of this paper, we introduce a\nresidual convolutional neural network to solve the corresponding inverse\nproblem: to translate a high-resolution (HR) imprint image with a specific\nliquid film thickness to a low-resolution (LR) droplet pattern image capable of\nproducing the given imprint image for an appropriate spread time of droplets.\nWe propose a neural network architecture that learns to systematically tune the\nrefinement level of its residual convolutional blocks by using the function\napproximators that are trained to map a given input parameter (film thickness)\nto an appropriate refinement level indicator. We use multiple stacks of\nconvolutional layers the output of which is translated according to the\nrefinement level indicators provided by the directly-connected function\napproximators. Together with a non-linear activation function, such a\ntranslation mechanism enables the HR imprint image to be refined sequentially\nin multiple steps until the target LR droplet pattern image is revealed. The\nproposed platform can be potentially applied to data compression and data\nencryption. The developed package and datasets are publicly available on GitHub\nat https://github.com/sqflow/sqflow.",
    "descriptor": "\nComments: 27 pages, 18 figures\n",
    "authors": [
      "Aryan Mehboudi",
      "Shrawan Singhal",
      "S.V. Sreenivasan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09061"
  },
  {
    "id": "arXiv:2211.09064",
    "title": "Renewing Iterative Self-labeling Domain Adaptation with Application to  the Spine Motion Prediction",
    "abstract": "The area of transfer learning comprises supervised machine learning methods\nthat cope with the issue when the training and testing data have different\ninput feature spaces or distributions. In this work, we propose a novel\ntransfer learning algorithm called Renewing Iterative Self-labeling Domain\nAdaptation (Re-ISDA). In this work, we propose a novel transfer learning\nalgorithm called Renewing Iterative Self-labeling Domain Adaptation (Re-ISDA).",
    "descriptor": "",
    "authors": [
      "Gecheng Chen",
      "Yu Zhou",
      "Xudong Zhang",
      "Rui Tuo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.09064"
  },
  {
    "id": "arXiv:2211.09066",
    "title": "Teaching Algorithmic Reasoning via In-context Learning",
    "abstract": "Large language models (LLMs) have shown increasing in-context learning\ncapabilities through scaling up model and data size. Despite this progress,\nLLMs are still unable to solve algorithmic reasoning problems. While providing\na rationale with the final answer has led to further improvements in multi-step\nreasoning problems, Anil et al. 2022 showed that even simple algorithmic\nreasoning tasks such as parity are far from solved. In this work, we identify\nand study four key stages for successfully teaching algorithmic reasoning to\nLLMs: (1) formulating algorithms as skills, (2) teaching multiple skills\nsimultaneously (skill accumulation), (3) teaching how to combine skills (skill\ncomposition) and (4) teaching how to use skills as tools. We show that it is\npossible to teach algorithmic reasoning to LLMs via in-context learning, which\nwe refer to as algorithmic prompting. We evaluate our approach on a variety of\narithmetic and quantitative reasoning tasks, and demonstrate significant boosts\nin performance over existing prompting techniques. In particular, for long\nparity, addition, multiplication and subtraction, we achieve an error reduction\nof approximately 10x, 9x, 5x and 2x respectively compared to the best available\nbaselines.",
    "descriptor": "",
    "authors": [
      "Hattie Zhou",
      "Azade Nova",
      "Hugo Larochelle",
      "Aaron Courville",
      "Behnam Neyshabur",
      "Hanie Sedghi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.09066"
  },
  {
    "id": "arXiv:2211.09067",
    "title": "Egocentric Hand-object Interaction Detection",
    "abstract": "In this paper, we propose a method to jointly determine the status of\nhand-object interaction. This is crucial for egocentric human activity\nunderstanding and interaction. From a computer vision perspective, we believe\nthat determining whether a hand is interacting with an object depends on\nwhether there is an interactive hand pose and whether the hand is touching the\nobject. Thus, we extract the hand pose, hand-object masks to jointly determine\nthe interaction status. In order to solve the problem of hand pose estimation\ndue to in-hand object occlusion, we use a multi-cam system to capture hand pose\ndata from multiple perspectives. We evaluate and compare our method with the\nmost recent work from Shan et al. \\cite{Shan20} on selected images from\nEPIC-KITCHENS \\cite{damen2018scaling} dataset and achieve $89\\%$ accuracy on\nHOI (hand-object interaction) detection which is comparative to Shan's\n($92\\%$). However, for real-time performance, our method can run over\n$\\textbf{30}$ FPS which is much more efficient than Shan's\n($\\textbf{1}\\sim\\textbf{2}$ FPS). A demo can be found from\nhttps://www.youtube.com/watch?v=XVj3zBuynmQ",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2109.14734\n",
    "authors": [
      "Yao Lu",
      "Yanan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.09067"
  },
  {
    "id": "arXiv:2211.09070",
    "title": "Towards Computationally Verifiable Semantic Grounding for Language  Models",
    "abstract": "The paper presents an approach to semantic grounding of language models (LMs)\nthat conceptualizes the LM as a conditional model generating text given a\ndesired semantic message formalized as a set of entity-relationship triples. It\nembeds the LM in an auto-encoder by feeding its output to a semantic parser\nwhose output is in the same representation domain as the input message.\nCompared to a baseline that generates text using greedy search, we demonstrate\ntwo techniques that improve the fluency and semantic accuracy of the generated\ntext: The first technique samples multiple candidate text sequences from which\nthe semantic parser chooses. The second trains the language model while keeping\nthe semantic parser frozen to improve the semantic accuracy of the\nauto-encoder. We carry out experiments on the English WebNLG 3.0 data set,\nusing BLEU to measure the fluency of generated text and standard parsing\nmetrics to measure semantic accuracy. We show that our proposed approaches\nsignificantly improve on the greedy search baseline. Human evaluation\ncorroborates the results of the automatic evaluation experiments.",
    "descriptor": "",
    "authors": [
      "Chris Alberti",
      "Kuzman Ganchev",
      "Michael Collins",
      "Sebastian Gehrmann",
      "Ciprian Chelba"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.09070"
  },
  {
    "id": "arXiv:2211.09072",
    "title": "Mitigating Frequency Bias in Next-Basket Recommendation via  Deconfounders",
    "abstract": "Recent studies on Next-basket Recommendation (NBR) have achieved much\nprogress by leveraging Personalized Item Frequency (PIF) as one of the main\nfeatures, which measures the frequency of the user's interactions with the\nitem. However, taking the PIF as an explicit feature incurs bias towards\nfrequent items. Items that a user purchases frequently are assigned higher\nweights in the PIF-based recommender system and appear more frequently in the\npersonalized recommendation list. As a result, the system will lose the\nfairness and balance between items that the user frequently purchases and items\nthat the user never purchases. We refer to this systematic bias on personalized\nrecommendation lists as frequency bias, which narrows users' browsing scope and\nreduces the system utility. We adopt causal inference theory to address this\nissue. Considering the influence of historical purchases on users' future\ninterests, the user and item representations can be viewed as unobserved\nconfounders in the causal diagram. In this paper, we propose a deconfounder\nmodel named FENDER (Frequency-aware Deconfounder for Next-basket\nRecommendation) to mitigate the frequency bias. With the deconfounder theory\nand the causal diagram we propose, FENDER decomposes PIF with a neural tensor\nlayer to obtain substitute confounders for users and items. Then, FENDER\nperforms unbiased recommendations considering the effect of these substitute\nconfounders. Experimental results demonstrate that FENDER has derived diverse\nand fair results compared to ten baseline models on three datasets while\nachieving competitive performance. Further experiments illustrate how FENDER\nbalances users' historical purchases and potential interests.",
    "descriptor": "\nComments: IEEE Bigdata 2022\n",
    "authors": [
      "Xiaohan Li",
      "Zheng Liu",
      "Luyi Ma",
      "Kaushiki Nag",
      "Stephen Guo",
      "Philip Yu",
      "Kannan Achan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09072"
  },
  {
    "id": "arXiv:2211.09074",
    "title": "Where a Strong Backbone Meets Strong Features -- ActionFormer for Ego4D  Moment Queries Challenge",
    "abstract": "This report describes our submission to the Ego4D Moment Queries Challenge\n2022. Our submission builds on ActionFormer, the state-of-the-art backbone for\ntemporal action localization, and a trio of strong video features from\nSlowFast, Omnivore and EgoVLP. Our solution is ranked 2nd on the public\nleaderboard with 21.76% average mAP on the test set, which is nearly three\ntimes higher than the official baseline. Further, we obtain 42.54% Recall@1x at\ntIoU=0.5 on the test set, outperforming the top-ranked solution by a\nsignificant margin of 1.41 absolute percentage points. Our code is available at\nhttps://github.com/happyharrycn/actionformer_release.",
    "descriptor": "\nComments: 2nd place in ECCV 2022 Ego4D Moment Queries Challenge\n",
    "authors": [
      "Fangzhou Mu",
      "Sicheng Mo",
      "Gillian Wang",
      "Yin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09074"
  },
  {
    "id": "arXiv:2211.09075",
    "title": "Keeping it sparse: Computing Persistent Homology revised",
    "abstract": "In this work, we study several variants of matrix reduction via Gaussian\nelimination that try to keep the reduced matrix sparse. The motivation comes\nfrom the growing field of topological data analysis where matrix reduction is\nthe major subroutine to compute barcodes. We propose two novel variants of the\nstandard algorithm, called swap and retrospective reductions, which improve\nupon state-of-the-art techniques on several examples in practice. We also\npresent novel output-sensitive bounds for the retrospective variant which\nbetter explain the discrepancy between the cubic worst-case complexity bound\nand the almost linear practical behavior of matrix reduction. Finally, we\nprovide several constructions on which one of the variants performs strictly\nbetter than the others.",
    "descriptor": "\nComments: 21 pages, 8 tables\n",
    "authors": [
      "Ulrich Bauer",
      "Talha Bin Masood",
      "Barbara Giunti",
      "Guillaume Houry",
      "Michael Kerber",
      "Abhishek Rathod"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2211.09075"
  },
  {
    "id": "arXiv:2211.09078",
    "title": "Learning Dense and Continuous Optical Flow from an Event Camera",
    "abstract": "Event cameras such as DAVIS can simultaneously output high temporal\nresolution events and low frame-rate intensity images, which own great\npotential in capturing scene motion, such as optical flow estimation. Most of\nthe existing optical flow estimation methods are based on two consecutive image\nframes and can only estimate discrete flow at a fixed time interval. Previous\nwork has shown that continuous flow estimation can be achieved by changing the\nquantities or time intervals of events. However, they are difficult to estimate\nreliable dense flow , especially in the regions without any triggered events.\nIn this paper, we propose a novel deep learning-based dense and continuous\noptical flow estimation framework from a single image with event streams, which\nfacilitates the accurate perception of high-speed motion. Specifically, we\nfirst propose an event-image fusion and correlation module to effectively\nexploit the internal motion from two different modalities of data. Then we\npropose an iterative update network structure with bidirectional training for\noptical flow prediction. Therefore, our model can estimate reliable dense flow\nas two-frame-based methods, as well as estimate temporal continuous flow as\nevent-based methods. Extensive experimental results on both synthetic and real\ncaptured datasets demonstrate that our model outperforms existing event-based\nstate-of-the-art methods and our designed baselines for accurate dense and\ncontinuous optical flow estimation.",
    "descriptor": "\nComments: Project page (this https URL). This work has been accepted by IEEE TIP (this https URL). 15 pages, 10 figures\n",
    "authors": [
      "Zhexiong Wan",
      "Yuchao Dai",
      "Yuxin Mao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09078"
  },
  {
    "id": "arXiv:2211.09081",
    "title": "Secure SWIPT in STAR-RIS Aided Downlink MISO Rate-Splitting Multiple  Access Networks",
    "abstract": "Recently, simultaneously transmitting and reflecting reconfigurable\nintelligent surfaces (STAR-RISs) have emerged as a novel technology that\nfacilitates sustainable communication by providing 360 coverage and new\ndegrees-of-freedom (DoF) for manipulating signal propagation as well as\nsimultaneous wireless information and power transfer (SWIPT). Inspired by these\napplications, this paper presents a novel STAR-RIS-aided secure SWIPT system\nfor downlink multiple input single output (MISO) Rate-Splitting multiple access\n(RSMA) networks. The transmitter concurrently communicates with the information\nreceivers (IRs) and sends energy to untrusted energy receivers (UERs). UERs are\nalso able to wiretap the IR streams. The paper assumes that the channel state\ninformation (CSI) of the IRs is known at the transmitter. However, only\nimperfect CSI (ICSI) for the UERs is available at the transmitter. The paper\naims to maximize the achievable worst-case sum secrecy rate (WCSSR) of the IRs\nunder a total transmit power constraint, a sum energy constraint for the UERs,\nand constraints on the transmission and reflection coefficients by jointly\noptimizing the precoders and the transmission and reflection beamforming at the\nSTAR-RIS. The formulated problem is non-convex with intricately coupled\nvariables, and to tackle this challenge a suboptimal two-step iterative\nalgorithm based on the sequential parametric convex approximation (SPCA) method\nis proposed. Specifically, the precoders and the transmission and reflection\nbeamforming vectors are optimized alternatingly. Simulations are conducted to\nshow that the proposed RSMA-based algorithm in a STAR-RIS aided network can\nimprove the secrecy of the confidential information and the overall spectral\nefficiency.",
    "descriptor": "\nComments: 13 pages, journal paper\n",
    "authors": [
      "Hamid Reza Hashempour",
      "Hamed Bastami",
      "Majid Moradikia",
      "Seyed A.Zekavat",
      "Hamid Behroozi",
      "A. Lee Swindlehurst"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.09081"
  },
  {
    "id": "arXiv:2211.09084",
    "title": "Technical Report on Neural Language Models and Few-Shot Learning for  Systematic Requirements Processing in MDSE",
    "abstract": "Systems engineering, in particular in the automotive domain, needs to cope\nwith the massively increasing numbers of requirements that arise during the\ndevelopment process. To guarantee a high product quality and make sure that\nfunctional safety standards such as ISO26262 are fulfilled, the exploitation of\npotentials of model-driven systems engineering in the form of automatic\nanalyses, consistency checks, and tracing mechanisms is indispensable. However,\nthe language in which requirements are written, and the tools needed to operate\non them, are highly individual and require domain-specific tailoring. This\nhinders automated processing of requirements as well as the linking of\nrequirements to models. Introducing formal requirement notations in existing\nprojects leads to the challenge of translating masses of requirements and\nprocess changes on the one hand and to the necessity of the corresponding\ntraining for the requirements engineers.\nIn this paper, based on the analysis of an open-source set of automotive\nrequirements, we derive domain-specific language constructs helping us to avoid\nambiguities in requirements and increase the level of formality. The main\ncontribution is the adoption and evaluation of few-shot learning with large\npretrained language models for the automated translation of informal\nrequirements to structured languages such as a requirement DSL. We show that\nsupport sets of less than ten translation examples can suffice to few-shot\ntrain a language model to incorporate keywords and implement syntactic rules\ninto informal natural language requirements.",
    "descriptor": "",
    "authors": [
      "Vincent Bertram",
      "Miriam Bo\u00df",
      "Evgeny Kusmenko",
      "Imke Helene Nachmann",
      "Bernhard Rumpe",
      "Danilo Trotta",
      "Louis Wachtmeister"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.09084"
  },
  {
    "id": "arXiv:2211.09085",
    "title": "Galactica: A Large Language Model for Science",
    "abstract": "Information overload is a major obstacle to scientific progress. The\nexplosive growth in scientific literature and data has made it ever harder to\ndiscover useful insights in a large mass of information. Today scientific\nknowledge is accessed through search engines, but they are unable to organize\nscientific knowledge alone. In this paper we introduce Galactica: a large\nlanguage model that can store, combine and reason about scientific knowledge.\nWe train on a large scientific corpus of papers, reference material, knowledge\nbases and many other sources. We outperform existing models on a range of\nscientific tasks. On technical knowledge probes such as LaTeX equations,\nGalactica outperforms the latest GPT-3 by 68.2% versus 49.0%. Galactica also\nperforms well on reasoning, outperforming Chinchilla on mathematical MMLU by\n41.3% to 35.7%, and PaLM 540B on MATH with a score of 20.4% versus 8.8%. It\nalso sets a new state-of-the-art on downstream tasks such as PubMedQA and\nMedMCQA dev of 77.6% and 52.9%. And despite not being trained on a general\ncorpus, Galactica outperforms BLOOM and OPT-175B on BIG-bench. We believe these\nresults demonstrate the potential for language models as a new interface for\nscience. We open source the model for the benefit of the scientific community.",
    "descriptor": "",
    "authors": [
      "Ross Taylor",
      "Marcin Kardas",
      "Guillem Cucurull",
      "Thomas Scialom",
      "Anthony Hartshorn",
      "Elvis Saravia",
      "Andrew Poulton",
      "Viktor Kerkez",
      "Robert Stojnic"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.09085"
  },
  {
    "id": "arXiv:2211.09086",
    "title": "Molecular Fingerprints for Robust and Efficient ML-Driven Molecular  Generation",
    "abstract": "We propose a novel molecular fingerprint-based variational autoencoder\napplied for molecular generation on real-world drug molecules. We define more\nsuitable and pharma-relevant baseline metrics and tests, focusing on the\ngeneration of diverse, drug-like, novel small molecules and scaffolds. When we\napply these molecular generation metrics to our novel model, we observe a\nsubstantial improvement in chemical synthetic accessibility\n($\\Delta\\bar{{SAS}}$ = -0.83) and in computational efficiency up to 5.9x in\ncomparison to an existing state-of-the-art SMILES-based architecture.",
    "descriptor": "\nComments: 7 pages, 5 figures. To be presented in the Machine Learning and the Physical Sciences workshop, NeurIPS 2022, New Orleans, United States, December 3, 2022, this https URL\n",
    "authors": [
      "Ruslan N. Tazhigulov",
      "Joshua Schiller",
      "Jacob Oppenheim",
      "Max Winston"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09086"
  },
  {
    "id": "arXiv:2211.09088",
    "title": "Online convex optimization for constrained control of linear systems  using a reference governor",
    "abstract": "In this work, we propose a control scheme for linear systems subject to\npointwise in time state and input constraints that aims to minimize\ntime-varying and a priori unknown cost functions. The proposed controller is\nbased on online convex optimization and a reference governor. In particular, we\napply online gradient descent to track the time-varying and a priori unknown\noptimal steady state of the system. Moreover, we use a $\\lambda$-contractive\nset to enforce constraint satisfaction and a sufficient convergence rate of the\nclosed-loop system to the optimal steady state. We prove that the proposed\nscheme is recursively feasible, ensures that the state and input constraints\nare satisfied at all times, and achieves a dynamic regret that is linearly\nbounded by the variation of the cost functions. The algorithm's performance and\nconstraint satisfaction is illustrated by means of a simulation example.",
    "descriptor": "\nComments: 7 pages; This work has been submitted to IFAC for possible publication\n",
    "authors": [
      "Marko Nonhoff",
      "Johannes K\u00f6hler",
      "Matthias A. M\u00fcller"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.09088"
  },
  {
    "id": "arXiv:2211.09089",
    "title": "Psychophysiology-aided Perceptually Fluent Speech Analysis of Children  Who Stutter",
    "abstract": "This first-of-its-kind paper presents a novel approach named PASAD that\ndetects changes in perceptually fluent speech acoustics of young children.\nParticularly, analysis of perceptually fluent speech enables identifying the\nspeech-motor-control factors that are considered as the underlying cause of\nstuttering disfluencies. Recent studies indicate that the speech production of\nyoung children, especially those who stutter, may get adversely affected by\nsituational physiological arousal. A major contribution of this paper is\nleveraging the speaker's situational physiological responses in real-time to\nanalyze the speech signal effectively. The presented PASAD approach adapts a\nHyper-Network structure to extract temporal speech importance information\nleveraging physiological parameters. In addition, a novel non-local acoustic\nspectrogram feature extraction network identifies meaningful acoustic\nattributes. Finally, a sequential network utilizes the acoustic attributes and\nthe extracted temporal speech importance for effective classification. We\ncollected speech and physiological sensing data from 73 preschool-age children\nwho stutter (CWS) and who don't stutter (CWNS) in different conditions. PASAD's\nunique architecture enables visualizing speech attributes distinct to a CWS's\nfluent speech and mapping them to the speaker's respective speech-motor-control\nfactors (i.e., speech articulators). Extracted knowledge can enhance\nunderstanding of children's fluent speech, speech-motor-control (SMC), and\nstuttering development. Our comprehensive evaluation shows that PASAD\noutperforms state-of-the-art multi-modal baseline approaches in different\nconditions, is expressive and adaptive to the speaker's speech and physiology,\ngeneralizable, robust, and is real-time executable on mobile and scalable\ndevices.",
    "descriptor": "\nComments: 20 pages, 5 figures\n",
    "authors": [
      "Yi Xiao",
      "Harshit Sharma",
      "Victoria Tumanova",
      "Asif Salekin"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.09089"
  },
  {
    "id": "arXiv:2211.09093",
    "title": "Experimental Analysis of Machine Learning Techniques for Finding Search  Radius in Locality Sensitive Hashing",
    "abstract": "Finding similar data in high-dimensional spaces is one of the important tasks\nin multimedia applications. Approaches introduced to find exact searching\ntechniques often use tree-based index structures which are known to suffer from\nthe curse of the dimensionality problem that limits their performance.\nApproximate searching techniques prefer performance over accuracy and they\nreturn good enough results while achieving a better performance. Locality\nSensitive Hashing (LSH) is one of the most popular approximate nearest neighbor\nsearch techniques for high-dimensional spaces. One of the most time-consuming\nprocesses in LSH is to find the neighboring points in the projected spaces. An\nimproved LSH-based index structure, called radius-optimized Locality Sensitive\nHashing (roLSH) has been proposed to utilize Machine Learning and efficiently\nfind these neighboring points; thus, further improve the overall performance of\nLSH. In this paper, we extend roLSH by experimentally studying the effect of\ndifferent types of famous Machine Learning techniques on overall performance.\nWe compare ten regression techniques on four real-world datasets and show that\nNeural Network-based techniques are the best fit to be used in roLSH as their\naccuracy and performance trade-off are the best compared to the other\ntechniques.",
    "descriptor": "",
    "authors": [
      "Omid Jafari",
      "Parth Nagarkar"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09093"
  },
  {
    "id": "arXiv:2211.09098",
    "title": "ATEAM: Knowledge Integration from Federated Datasets for Vehicle Feature  Extraction using Annotation Team of Experts",
    "abstract": "The vehicle recognition area, including vehicle make-model recognition\n(VMMR), re-id, tracking, and parts-detection, has made significant progress in\nrecent years, driven by several large-scale datasets for each task. These\ndatasets are often non-overlapping, with different label schemas for each task:\nVMMR focuses on make and model, while re-id focuses on vehicle ID. It is\npromising to combine these datasets to take advantage of knowledge across\ndatasets as well as increased training data; however, dataset integration is\nchallenging due to the domain gap problem. This paper proposes ATEAM, an\nannotation team-of-experts to perform cross-dataset labeling and integration of\ndisjoint annotation schemas. ATEAM uses diverse experts, each trained on\ndatasets that contain an annotation schema, to transfer knowledge to datasets\nwithout that annotation. Using ATEAM, we integrated several common vehicle\nrecognition datasets into a Knowledge Integrated Dataset (KID). We evaluate\nATEAM and KID for vehicle recognition problems and show that our integrated\ndataset can help off-the-shelf models achieve excellent accuracy on VMMR and\nvehicle re-id with no changes to model architectures. We achieve mAP of 0.83 on\nVeRi, and accuracy of 0.97 on CompCars. We have released both the dataset and\nthe ATEAM framework for public use.",
    "descriptor": "\nComments: ATEAM for Vehicle Classification and Re-ID\n",
    "authors": [
      "Abhijit Suprem",
      "Purva Singh",
      "Suma Cherkadi",
      "Sanjyot Vaidya",
      "Joao Eduardo Ferreira",
      "Calton Pu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.09098"
  },
  {
    "id": "arXiv:2211.09100",
    "title": "Global Optimization with Parametric Function Approximation",
    "abstract": "We consider the problem of global optimization with noisy zeroth order\noracles - a well-motivated problem useful for various applications ranging from\nhyper-parameter tuning for deep learning to new material design. Existing work\nrelies on Gaussian processes or other non-parametric family, which suffers from\nthe curse of dimensionality. In this paper, we propose a new algorithm GO-UCB\nthat leverages a parametric family of functions (e.g., neural networks)\ninstead. Under a realizable assumption and a few other mild geometric\nconditions, we show that GO-UCB achieves a cumulative regret of\n$\\tilde{O}(\\sqrt{T})$ where $T$ is the time horizon. At the core of GO-UCB is a\ncarefully designed uncertainty set over parameters based on gradients that\nallows optimistic exploration. Numerical simulation illustrates that GO-UCB\nworks better than classical Bayesian optimization approaches in high\ndimensional cases, even if the model is misspecified.",
    "descriptor": "",
    "authors": [
      "Chong Liu",
      "Yu-Xiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09100"
  },
  {
    "id": "arXiv:2211.09101",
    "title": "Comparative Learning: A Sample Complexity Theory for Two Hypothesis  Classes",
    "abstract": "In many learning theory problems, a central role is played by a hypothesis\nclass: we might assume that the data is labeled according to a hypothesis in\nthe class (usually referred to as the realizable setting), or we might evaluate\nthe learned model by comparing it with the best hypothesis in the class (the\nagnostic setting).\nTaking a step beyond these classic setups that involve only a single\nhypothesis class, we introduce comparative learning as a combination of the\nrealizable and agnostic settings in PAC learning: given two binary hypothesis\nclasses $S$ and $B$, we assume that the data is labeled according to a\nhypothesis in the source class $S$ and require the learned model to achieve an\naccuracy comparable to the best hypothesis in the benchmark class $B$. Even\nwhen both $S$ and $B$ have infinite VC dimensions, comparative learning can\nstill have a small sample complexity. We show that the sample complexity of\ncomparative learning is characterized by the mutual VC dimension\n$\\mathsf{VC}(S,B)$ which we define to be the maximum size of a subset shattered\nby both $S$ and $B$. We also show a similar result in the online setting, where\nwe give a regret characterization in terms of the mutual Littlestone dimension\n$\\mathsf{Ldim}(S,B)$. These results also hold for partial hypotheses.\nWe additionally show that the insights necessary to characterize the sample\ncomplexity of comparative learning can be applied to characterize the sample\ncomplexity of realizable multiaccuracy and multicalibration using the mutual\nfat-shattering dimension, an analogue of the mutual VC dimension for\nreal-valued hypotheses. This not only solves an open problem proposed by Hu,\nPeale, Reingold (2022), but also leads to independently interesting results\nextending classic ones about regression, boosting, and covering number to our\ntwo-hypothesis-class setting.",
    "descriptor": "\nComments: In ITCS 2023\n",
    "authors": [
      "Lunjia Hu",
      "Charlotte Peale"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.09101"
  },
  {
    "id": "arXiv:2211.09102",
    "title": "Prompting PaLM for Translation: Assessing Strategies and Performance",
    "abstract": "Large language models (LLMs) that have been trained on multilingual but not\nparallel text exhibit a remarkable ability to translate between languages. We\nprobe this ability in an in-depth study of the pathways language model (PaLM),\nwhich has demonstrated the strongest machine translation (MT) performance among\nsimilarly-trained LLMs to date. We investigate various strategies for choosing\ntranslation examples for few-shot prompting, concluding that example quality is\nthe most important factor. Using optimized prompts, we revisit previous\nassessments of PaLM's MT capabilities with more recent test sets, modern MT\nmetrics, and human evaluation, and find that its performance, while impressive,\nstill lags that of state-of-the-art supervised systems. We conclude by\nproviding an analysis of PaLM's MT output which reveals some interesting\nproperties and prospects for future work.",
    "descriptor": "",
    "authors": [
      "David Vilar",
      "Markus Freitag",
      "Colin Cherry",
      "Jiaming Luo",
      "Viresh Ratnakar",
      "George Foster"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.09102"
  },
  {
    "id": "arXiv:2211.09106",
    "title": "The Exact Bipartite Matching Polytope Has Exponential Extension  Complexity",
    "abstract": "Given a graph with edges colored red or blue and an integer $k$, the exact\nperfect matching problem asks if there exists a perfect matching with exactly\n$k$ red edges. There exists a randomized polylogarithmic-time parallel\nalgorithm to solve this problem, dating back to the eighties, but no\ndeterministic polynomial-time algorithm is known, even for bipartite graphs. In\nthis paper we show that there is no sub-exponential sized linear program that\ncan describe the convex hull of exact matchings in bipartite graphs. In fact,\nwe prove something stronger, that there is no sub-exponential sized linear\nprogram to describe the convex hull of perfect matchings with an odd number of\nred edges.",
    "descriptor": "\nComments: SODA 2023\n",
    "authors": [
      "Xinrui Jia",
      "Ola Svensson",
      "Weiqiang Yuan"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.09106"
  },
  {
    "id": "arXiv:2211.09107",
    "title": "Interpretable Few-shot Learning with Online Attribute Selection",
    "abstract": "Few-shot learning (FSL) is a challenging learning problem in which only a few\nsamples are available for each class. Decision interpretation is more important\nin few-shot classification since there is a greater chance of error than in\ntraditional classification. However, most of the previous FSL methods are\nblack-box models. In this paper, we propose an inherently interpretable model\nfor FSL based on human-friendly attributes. Moreover, we propose an online\nattribute selection mechanism that can effectively filter out irrelevant\nattributes in each episode. The attribute selection mechanism improves the\naccuracy and helps with interpretability by reducing the number of participated\nattributes in each episode. We demonstrate that the proposed method achieves\nresults on par with black-box few-shot-learning models on four widely used\ndatasets. To further close the performance gap with the black-box models, we\npropose a mechanism that trades interpretability for accuracy. It automatically\ndetects the episodes where the provided human-friendly attributes are not\nadequate, and compensates by engaging learned unknown attributes.",
    "descriptor": "",
    "authors": [
      "Mohammad Reza Zarei",
      "Majid Komeili"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09107"
  },
  {
    "id": "arXiv:2211.09108",
    "title": "Robust Online Video Instance Segmentation with Track Queries",
    "abstract": "Recently, transformer-based methods have achieved impressive results on Video\nInstance Segmentation (VIS). However, most of these top-performing methods run\nin an offline manner by processing the entire video clip at once to predict\ninstance mask volumes. This makes them incapable of handling the long videos\nthat appear in challenging new video instance segmentation datasets like UVO\nand OVIS. We propose a fully online transformer-based video instance\nsegmentation model that performs comparably to top offline methods on the\nYouTube-VIS 2019 benchmark and considerably outperforms them on UVO and OVIS.\nThis method, called Robust Online Video Segmentation (ROVIS), augments the\nMask2Former image instance segmentation model with track queries, a lightweight\nmechanism for carrying track information from frame to frame, originally\nintroduced by the TrackFormer method for multi-object tracking. We show that,\nwhen combined with a strong enough image segmentation architecture, track\nqueries can exhibit impressive accuracy while not being constrained to short\nvideos.",
    "descriptor": "",
    "authors": [
      "Zitong Zhan",
      "Daniel McKee",
      "Svetlana Lazebnik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09108"
  },
  {
    "id": "arXiv:2211.09110",
    "title": "Holistic Evaluation of Language Models",
    "abstract": "Language models (LMs) are becoming the foundation for almost all major\nlanguage technologies, but their capabilities, limitations, and risks are not\nwell understood. We present Holistic Evaluation of Language Models (HELM) to\nimprove the transparency of language models. First, we taxonomize the vast\nspace of potential scenarios (i.e. use cases) and metrics (i.e. desiderata)\nthat are of interest for LMs. Then we select a broad subset based on coverage\nand feasibility, noting what's missing or underrepresented (e.g. question\nanswering for neglected English dialects, metrics for trustworthiness). Second,\nwe adopt a multi-metric approach: We measure 7 metrics (accuracy, calibration,\nrobustness, fairness, bias, toxicity, and efficiency) for each of 16 core\nscenarios when possible (87.5% of the time). This ensures metrics beyond\naccuracy don't fall to the wayside, and that trade-offs are clearly exposed. We\nalso perform 7 targeted evaluations, based on 26 targeted scenarios, to analyze\nspecific aspects (e.g. reasoning, disinformation). Third, we conduct a\nlarge-scale evaluation of 30 prominent language models (spanning open,\nlimited-access, and closed models) on all 42 scenarios, 21 of which were not\npreviously used in mainstream LM evaluation. Prior to HELM, models on average\nwere evaluated on just 17.9% of the core HELM scenarios, with some prominent\nmodels not sharing a single scenario in common. We improve this to 96.0%: now\nall 30 models have been densely benchmarked on the same core scenarios and\nmetrics under standardized conditions. Our evaluation surfaces 25 top-level\nfindings. For full transparency, we release all raw model prompts and\ncompletions publicly for further analysis, as well as a general modular\ntoolkit. We intend for HELM to be a living benchmark for the community,\ncontinuously updated with new scenarios, metrics, and models.",
    "descriptor": "\nComments: Authored by the Center for Research on Foundation Models (CRFM) at the Stanford Institute for Human-Centered Artificial Intelligence (HAI). Project page: this https URL\n",
    "authors": [
      "Percy Liang",
      "Rishi Bommasani",
      "Tony Lee",
      "Dimitris Tsipras",
      "Dilara Soylu",
      "Michihiro Yasunaga",
      "Yian Zhang",
      "Deepak Narayanan",
      "Yuhuai Wu",
      "Ananya Kumar",
      "Benjamin Newman",
      "Binhang Yuan",
      "Bobby Yan",
      "Ce Zhang",
      "Christian Cosgrove",
      "Christopher D. Manning",
      "Christopher R\u00e9",
      "Diana Acosta-Navas",
      "Drew A. Hudson",
      "Eric Zelikman",
      "Esin Durmus",
      "Faisal Ladhak",
      "Frieda Rong",
      "Hongyu Ren",
      "Huaxiu Yao",
      "Jue Wang",
      "Keshav Santhanam",
      "Laurel Orr",
      "Lucia Zheng",
      "Mert Yuksekgonul",
      "Mirac Suzgun",
      "Nathan Kim",
      "Neel Guha",
      "Niladri Chatterji",
      "Omar Khattab",
      "Peter Henderson",
      "Qian Huang",
      "Ryan Chi",
      "Sang Michael Xie",
      "Shibani Santurkar",
      "Surya Ganguli",
      "Tatsunori Hashimoto",
      "Thomas Icard",
      "Tianyi Zhang",
      "Vishrav Chaudhary",
      "William Wang",
      "Xuechen Li",
      "Yifan Mai",
      "Yuhui Zhang",
      "Yuta Koreeda"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09110"
  },
  {
    "id": "arXiv:2211.09113",
    "title": "On Measuring the Intrinsic Few-Shot Hardness of Datasets",
    "abstract": "While advances in pre-training have led to dramatic improvements in few-shot\nlearning of NLP tasks, there is limited understanding of what drives successful\nfew-shot adaptation in datasets. In particular, given a new dataset and a\npre-trained model, what properties of the dataset make it \\emph{few-shot\nlearnable} and are these properties independent of the specific adaptation\ntechniques used? We consider an extensive set of recent few-shot learning\nmethods, and show that their performance across a large number of datasets is\nhighly correlated, showing that few-shot hardness may be intrinsic to datasets,\nfor a given pre-trained model. To estimate intrinsic few-shot hardness, we then\npropose a simple and lightweight metric called \"Spread\" that captures the\nintuition that few-shot learning is made possible by exploiting feature-space\ninvariances between training and test samples. Our metric better accounts for\nfew-shot hardness compared to existing notions of hardness, and is ~8-100x\nfaster to compute.",
    "descriptor": "\nComments: EMNLP 2022 camera ready version\n",
    "authors": [
      "Xinran Zhao",
      "Shikhar Murty",
      "Christopher D. Manning"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.09113"
  },
  {
    "id": "arXiv:2211.09117",
    "title": "MAGE: MAsked Generative Encoder to Unify Representation Learning and  Image Synthesis",
    "abstract": "Generative modeling and representation learning are two key tasks in computer\nvision. However, these models are typically trained independently, which\nignores the potential for each task to help the other, and leads to training\nand model maintenance overheads. In this work, we propose MAsked Generative\nEncoder (MAGE), the first framework to unify SOTA image generation and\nself-supervised representation learning. Our key insight is that using variable\nmasking ratios in masked image modeling pre-training can allow generative\ntraining (very high masking ratio) and representation learning (lower masking\nratio) under the same training framework. Inspired by previous generative\nmodels, MAGE uses semantic tokens learned by a vector-quantized GAN at inputs\nand outputs, combining this with masking. We can further improve the\nrepresentation by adding a contrastive loss to the encoder output. We\nextensively evaluate the generation and representation learning capabilities of\nMAGE. On ImageNet-1K, a single MAGE ViT-L model obtains 9.10 FID in the task of\nclass-unconditional image generation and 78.9% top-1 accuracy for linear\nprobing, achieving state-of-the-art performance in both image generation and\nrepresentation learning. Code is available at https://github.com/LTH14/mage.",
    "descriptor": "",
    "authors": [
      "Tianhong Li",
      "Huiwen Chang",
      "Shlok Kumar Mishra",
      "Han Zhang",
      "Dina Katabi",
      "Dilip Krishnan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09117"
  },
  {
    "id": "arXiv:2211.09119",
    "title": "Token Turing Machines",
    "abstract": "We propose Token Turing Machines (TTM), a sequential, autoregressive\nTransformer model with memory for real-world sequential visual understanding.\nOur model is inspired by the seminal Neural Turing Machine, and has an external\nmemory consisting of a set of tokens which summarise the previous history\n(i.e., frames). This memory is efficiently addressed, read and written using a\nTransformer as the processing unit/controller at each step. The model's memory\nmodule ensures that a new observation will only be processed with the contents\nof the memory (and not the entire history), meaning that it can efficiently\nprocess long sequences with a bounded computational cost at each step. We show\nthat TTM outperforms other alternatives, such as other Transformer models\ndesigned for long sequences and recurrent neural networks, on two real-world\nsequential visual understanding tasks: online temporal activity detection from\nvideos and vision-based robot action policy learning.",
    "descriptor": "",
    "authors": [
      "Michael S. Ryoo",
      "Keerthana Gopalakrishnan",
      "Kumara Kahatapitiya",
      "Ted Xiao",
      "Kanishka Rao",
      "Austin Stone",
      "Yao Lu",
      "Julian Ibarz",
      "Anurag Arnab"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.09119"
  },
  {
    "id": "arXiv:2211.09120",
    "title": "AdaMAE: Adaptive Masking for Efficient Spatiotemporal Learning with  Masked Autoencoders",
    "abstract": "Masked Autoencoders (MAEs) learn generalizable representations for image,\ntext, audio, video, etc., by reconstructing masked input data from tokens of\nthe visible data. Current MAE approaches for videos rely on random patch, tube,\nor frame-based masking strategies to select these tokens. This paper proposes\nAdaMAE, an adaptive masking strategy for MAEs that is end-to-end trainable. Our\nadaptive masking strategy samples visible tokens based on the semantic context\nusing an auxiliary sampling network. This network estimates a categorical\ndistribution over spacetime-patch tokens. The tokens that increase the expected\nreconstruction error are rewarded and selected as visible tokens, motivated by\nthe policy gradient algorithm in reinforcement learning. We show that AdaMAE\nsamples more tokens from the high spatiotemporal information regions, thereby\nallowing us to mask 95% of tokens, resulting in lower memory requirements and\nfaster pre-training. We conduct ablation studies on the Something-Something v2\n(SSv2) dataset to demonstrate the efficacy of our adaptive sampling approach\nand report state-of-the-art results of 70.0% and 81.7% in top-1 accuracy on\nSSv2 and Kinetics-400 action classification datasets with a ViT-Base backbone\nand 800 pre-training epochs.",
    "descriptor": "\nComments: Code available at: this https URL\n",
    "authors": [
      "Wele Gedara Chaminda Bandara",
      "Naman Patel",
      "Ali Gholami",
      "Mehdi Nikkhah",
      "Motilal Agrawal",
      "Vishal M. Patel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.09120"
  },
  {
    "id": "arXiv:2211.08262",
    "title": "A mixed-categorical correlation kernel for Gaussian process",
    "abstract": "Recently, there has been a growing interest for mixed-categorical meta-models\nbased on Gaussian process (GP) surrogates. In this setting, several existing\napproaches use different strategies either by using continuous kernels (e.g.,\ncontinuous relaxation and Gower distance based GP) or by using a direct\nestimation of the correlation matrix. In this paper, we present a kernel-based\napproach that extends continuous exponential kernels to handle\nmixed-categorical variables. The proposed kernel leads to a new GP surrogate\nthat generalizes both the continuous relaxation and the Gower distance based GP\nmodels. We demonstrate, on both analytical and engineering problems, that our\nproposed GP model gives a higher likelihood and a smaller residual error than\nthe other kernel-based state-of-the-art models. Our method is available in the\nopen-source software SMT.",
    "descriptor": "",
    "authors": [
      "P. Saves",
      "Y. Diouane",
      "N. Bartoli",
      "T. Lefebvre",
      "J. Morlier"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.08262"
  },
  {
    "id": "arXiv:2211.08424",
    "title": "Cyclic Generative Adversarial Networks With Congruent Image-Report  Generation For Explainable Medical Image Analysis",
    "abstract": "We present a novel framework for explainable labeling and interpretation of\nmedical images. Medical images require specialized professionals for\ninterpretation, and are explained (typically) via elaborate textual reports.\nDifferent from prior methods that focus on medical report generation from\nimages or vice-versa, we novelly generate congruent image--report pairs\nemploying a cyclic-Generative Adversarial Network (cycleGAN); thereby, the\ngenerated report will adequately explain a medical image, while a\nreport-generated image that effectively characterizes the text visually should\n(sufficiently) resemble the original. The aim of the work is to generate\ntrustworthy and faithful explanations for the outputs of a model diagnosing\nchest x-ray images by pointing a human user to similar cases in support of a\ndiagnostic decision. Apart from enabling transparent medical image labeling and\ninterpretation, we achieve report and image-based labeling comparable to prior\nmethods, including state-of-the-art performance in some cases as evidenced by\nexperiments on the Indiana Chest X-ray dataset",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2206.13123, arXiv:2111.07646\n",
    "authors": [
      "Dwarikanath Mahapatra"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08424"
  },
  {
    "id": "arXiv:2211.08428",
    "title": "CaDM: Codec-aware Diffusion Modeling for Neural-enhanced Video Streaming",
    "abstract": "Recent years have witnessed the dramatic growth of Internet video traffic,\nwhere the video bitstreams are often compressed and delivered in low quality to\nfit the streamer's uplink bandwidth. To alleviate the quality degradation, it\ncomes the rise of Neural-enhanced Video Streaming (NVS), which shows great\nprospects to recover low-quality videos by mostly deploying neural\nsuper-resolution (SR) on the media server. Despite its benefit, we reveal that\ncurrent mainstream works with SR enhancement have not achieved the desired\nrate-distortion trade-off between bitrate saving and quality restoration, due\nto: (1) overemphasizing the enhancement on the decoder side while omitting the\nco-design of encoder, (2) inherent limited restoration capacity to generate\nhigh-fidelity perceptual details, and (3) optimizing the\ncompression-and-restoration pipeline from the resolution perspective solely,\nwithout considering color bit-depth. Aiming at overcoming these limitations, we\nare the first to conduct the encoder-decoder (i.e., codec) synergy by\nleveraging the visual-synthesis genius of diffusion models. Specifically, we\npresent the Codec-aware Diffusion Modeling (CaDM), a novel NVS paradigm to\nsignificantly reduce streaming delivery bitrate while holding pretty higher\nrestoration capacity over existing methods. First, CaDM improves the encoder's\ncompression efficiency by simultaneously reducing resolution and color\nbit-depth of video frames. Second, CaDM provides the decoder with perfect\nquality enhancement by making the denoising diffusion restoration aware of\nencoder's resolution-color conditions. Evaluation on public cloud services with\nOpenMMLab benchmarks shows that CaDM significantly saves streaming bitrate by a\nnearly 100 times reduction over vanilla H.264 and achieves much better recovery\nquality (e.g., FID of 0.61) over state-of-the-art neural-enhancing methods.",
    "descriptor": "",
    "authors": [
      "Qihua Zhou",
      "Ruibin Li",
      "Song Guo",
      "Yi Liu",
      "Jingcai Guo",
      "Zhenda Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.08428"
  },
  {
    "id": "arXiv:2211.08499",
    "title": "Probabilistic Querying of Continuous-Time Event Sequences",
    "abstract": "Continuous-time event sequences, i.e., sequences consisting of continuous\ntime stamps and associated event types (\"marks\"), are an important type of\nsequential data with many applications, e.g., in clinical medicine or user\nbehavior modeling. Since these data are typically modeled autoregressively\n(e.g., using neural Hawkes processes or their classical counterparts), it is\nnatural to ask questions about future scenarios such as \"what kind of event\nwill occur next\" or \"will an event of type $A$ occur before one of type $B$\".\nUnfortunately, some of these queries are notoriously hard to address since\ncurrent methods are limited to naive simulation, which can be highly\ninefficient. This paper introduces a new typology of query types and a\nframework for addressing them using importance sampling. Example queries\ninclude predicting the $n^\\text{th}$ event type in a sequence and the hitting\ntime distribution of one or more event types. We also leverage these findings\nfurther to be applicable for estimating general \"$A$ before $B$\" type of\nqueries. We prove theoretically that our estimation method is effectively\nalways better than naive simulation and show empirically based on three\nreal-world datasets that it is on average 1,000 times more efficient than\nexisting approaches.",
    "descriptor": "",
    "authors": [
      "Alex Boyd",
      "Yuxin Chang",
      "Stephan Mandt",
      "Padhraic Smyth"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08499"
  },
  {
    "id": "arXiv:2211.08511",
    "title": "A Heuristic Subexponential Algorithm to Find Paths in Markoff Graphs  Over Finite Fields",
    "abstract": "Charles, Goren, and Lauter [J. Cryptology 22(1), 2009] explained how one can\nconstruct hash functions using expander graphs in which it is hard to find\npaths between specified vertices. The set of solutions to the classical Markoff\nequation $X^2+Y^2+Z^2=XYZ$ in a finite field $\\mathbb{F}_q$ has a natural\nstructure as a tri-partite graph using three non-commuting polynomial\nautomorphisms to connect the points. These graphs conjecturally form an\nexpander family, and Fuchs, Lauter, Litman, and Tran [Mathematical Cryptology\n1(1), 2022] suggest using this family of Markoff graphs in the CGL\nconstruction. In this note we show that in both a theoretical and a practical\nsense, assuming two randomness hypotheses, the path problem in a Markoff graph\nover $\\mathbb{F}_q$ can be solved in subexponential time, and is more-or-less\nequivalent in difficulty to factoring $q-1$ and solving three discrete\nlogarithm problem in $\\mathbb{F}_q^*$.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Joseph H. Silverman"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.08511"
  },
  {
    "id": "arXiv:2211.08516",
    "title": "Phenotype Search Trajectory Networks for Linear Genetic Programming",
    "abstract": "Genotype-to-phenotype mappings translate genotypic variations such as\nmutations into phenotypic changes. Neutrality is the observation that some\nmutations do not lead to phenotypic changes. Studying the search trajectories\nin genotypic and phenotypic spaces, especially through neutral mutations, helps\nus to better understand the progression of evolution and its algorithmic\nbehaviour. In this study, we visualise the search trajectories of a genetic\nprogramming system as graph-based models, where nodes are genotypes/phenotypes\nand edges represent their mutational transitions. We also quantitatively\nmeasure the characteristics of phenotypes including their genotypic abundance\n(the requirement for neutrality) and Kolmogorov complexity. We connect these\nquantified metrics with search trajectory visualisations, and find that more\ncomplex phenotypes are under-represented by fewer genotypes and are harder for\nevolution to discover. Less complex phenotypes, on the other hand, are\nover-represented by genotypes, are easier to find, and frequently serve as\nstepping-stones for evolution.",
    "descriptor": "",
    "authors": [
      "Ting Hu",
      "Gabriela Ochoa",
      "Wolfgang Banzhaf"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08516"
  },
  {
    "id": "arXiv:2211.08522",
    "title": "The scaling of goals via homeostasis: an evolutionary simulation,  experiment and analysis",
    "abstract": "All cognitive agents are composite beings. Specifically, complex living\nagents consist of cells, which are themselves competent sub-agents navigating\nphysiological and metabolic spaces. Behavior science, evolutionary\ndevelopmental biology, and the field of machine intelligence all seek an answer\nto the scaling of biological cognition: what evolutionary dynamics enable\nindividual cells to integrate their activities to result in the emergence of a\nnovel, higher-level intelligence that has goals and competencies that belong to\nit and not to its parts? Here, we report the results of simulations based on\nthe TAME framework, which proposes that evolution pivoted the collective\nintelligence of cells during morphogenesis of the body into traditional\nbehavioral intelligence by scaling up the goal states at the center of\nhomeostatic processes. We tested the hypothesis that a minimal evolutionary\nframework is sufficient for small, low-level setpoints of metabolic homeostasis\nin cells to scale up into collectives (tissues) which solve a problem in\nmorphospace: the organization of a body-wide positional information axis (the\nclassic French Flag problem). We found that these emergent morphogenetic agents\nexhibit a number of predicted features, including the use of stress propagation\ndynamics to achieve its target morphology as well as the ability to recover\nfrom perturbation (robustness) and long-term stability (even though neither of\nthese was directly selected for). Moreover we observed unexpected behavior of\nsudden remodeling long after the system stabilizes. We tested this prediction\nin a biological system - regenerating planaria - and observed a very similar\nphenomenon. We propose that this system is a first step toward a quantitative\nunderstanding of how evolution scales minimal goal-directed behavior\n(homeostatic loops) into higher-level problem-solving agents in morphogenetic\nand other spaces.",
    "descriptor": "\nComments: 27 pages, 11 Figures, 2 Algorithms\n",
    "authors": [
      "Leo Pio-Lopez",
      "Johanna Bischof",
      "Jennifer V. LaPalme",
      "Michael Levin"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Multiagent Systems (cs.MA)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2211.08522"
  },
  {
    "id": "arXiv:2211.08553",
    "title": "Hybrid Transformers for Music Source Separation",
    "abstract": "A natural question arising in Music Source Separation (MSS) is whether long\nrange contextual information is useful, or whether local acoustic features are\nsufficient. In other fields, attention based Transformers have shown their\nability to integrate information over long sequences. In this work, we\nintroduce Hybrid Transformer Demucs (HT Demucs), an hybrid temporal/spectral\nbi-U-Net based on Hybrid Demucs, where the innermost layers are replaced by a\ncross-domain Transformer Encoder, using self-attention within one domain, and\ncross-attention across domains. While it performs poorly when trained only on\nMUSDB, we show that it outperforms Hybrid Demucs (trained on the same data) by\n0.45 dB of SDR when using 800 extra training songs. Using sparse attention\nkernels to extend its receptive field, and per source fine-tuning, we achieve\nstate-of-the-art results on MUSDB with extra training data, with 9.20 dB of\nSDR.",
    "descriptor": "",
    "authors": [
      "Simon Rouard",
      "Francisco Massa",
      "Alexandre D\u00e9fossez"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.08553"
  },
  {
    "id": "arXiv:2211.08566",
    "title": "The Association Between SOC and Land Prices Considering Spatial  Heterogeneity Based on Finite Mixture Modeling",
    "abstract": "An understanding of how Social Overhead Capital (SOC) is associated with the\nland value of the local community is important for effective urban planning.\nHowever, even within a district, there are multiple sections used for different\npurposes; the term for this is spatial heterogeneity. The spatial heterogeneity\nissue has to be considered when attempting to comprehend land prices. If there\nis spatial heterogeneity within a district, land prices can be managed by\nadopting the spatial clustering method. In this study, spatial attributes\nincluding SOC, socio-demographic features, and spatial information in a\nspecific district are analyzed with Finite Mixture Modeling (FMM) in order to\nfind (a) the optimal number of clusters and (b) the association among SOCs,\nsocio-demographic features, and land prices. FMM is a tool used to find\nclusters and the attributes' coefficients simultaneously. Using the FMM method,\nthe results show that four clusters exist in one district and the four clusters\nhave different associations among SOCs, demographic features, and land prices.\nPolicymakers and managerial administration need to look for information to make\npolicy about land prices. The current study finds the consideration of\ncloseness to SOC to be a significant factor on land prices and suggests the\npotential policy direction related to SOC.",
    "descriptor": "\nComments: 26 pages, 3 figures\n",
    "authors": [
      "Woo Seok Kang",
      "Eunchan Kim",
      "Wookjae Heo"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08566"
  },
  {
    "id": "arXiv:2211.08591",
    "title": "Exploring Supervised Machine Learning for Multi-Phase Identification and  Quantification from Powder X-Ray Diffraction Spectra",
    "abstract": "Powder X-ray diffraction analysis is a critical component of materials\ncharacterization methodologies. Discerning characteristic Bragg intensity peaks\nand assigning them to known crystalline phases is the first qualitative step of\nevaluating diffraction spectra. Subsequent to phase identification, Rietveld\nrefinement may be employed to extract the abundance of quantitative,\nmaterial-specific parameters hidden within powder data. These characterization\nprocedures are yet time-consuming and inhibit efficiency in materials science\nworkflows. The ever-increasing popularity and propulsion of data science\ntechniques has provided an obvious solution on the course towards materials\nanalysis automation. Deep learning has become a prime focus for predicting\ncrystallographic parameters and features from X-ray spectra. However, the\ninfeasibility of curating large, well-labelled experimental datasets means that\none must resort to a large number of theoretic simulations for powder data\naugmentation to effectively train deep models. Herein, we are interested in\nconventional supervised learning algorithms in lieu of deep learning for\nmulti-label crystalline phase identification and quantitative phase analysis\nfor a biomedical application. First, models were trained using very limited\nexperimental data. Further, we incorporated simulated XRD data to assess model\ngeneralizability as well as the efficacy of simulation-based training for\npredictive analysis in a real-world X-ray diffraction application.",
    "descriptor": "",
    "authors": [
      "Jaimie Greasley",
      "Patrick Hosein"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08591"
  },
  {
    "id": "arXiv:2211.08597",
    "title": "SketchySGD: Reliable Stochastic Optimization via Robust Curvature  Estimates",
    "abstract": "We introduce SketchySGD, a stochastic quasi-Newton method that uses sketching\nto approximate the curvature of the loss function. Quasi-Newton methods are\namong the most effective algorithms in traditional optimization, where they\nconverge much faster than first-order methods such as SGD. However, for\ncontemporary deep learning, quasi-Newton methods are considered inferior to\nfirst-order methods like SGD and Adam owing to higher per-iteration complexity\nand fragility due to inexact gradients. SketchySGD circumvents these issues by\na novel combination of subsampling, randomized low-rank approximation, and\ndynamic regularization. In the convex case, we show SketchySGD with a fixed\nstepsize converges to a small ball around the optimum at a faster rate than\nSGD. In the non-convex case, SketchySGD converges linearly under two additional\nassumptions, interpolation and the Polyak-Lojaciewicz condition, the latter of\nwhich holds with high probability for wide neural networks. Numerical\nexperiments on image and tabular data demonstrate the improved reliability and\nspeed of SketchySGD for deep learning, compared to standard optimizers such as\nSGD and Adam and existing quasi-Newton methods.",
    "descriptor": "\nComments: 24 pages, 8 figures, 7 tables\n",
    "authors": [
      "Zachary Frangella",
      "Pratik Rathore",
      "Shipu Zhao",
      "Madeleine Udell"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08597"
  },
  {
    "id": "arXiv:2211.08654",
    "title": "Prediction and Uncertainty Quantification of SAFARI-1 Axial Neutron Flux  Profiles with Neural Networks",
    "abstract": "Artificial Neural Networks (ANNs) have been successfully used in various\nnuclear engineering applications, such as predicting reactor physics parameters\nwithin reasonable time and with a high level of accuracy. Despite this success,\nthey cannot provide information about the model prediction uncertainties,\nmaking it difficult to assess ANN prediction credibility, especially in\nextrapolated domains. In this study, Deep Neural Networks (DNNs) are used to\npredict the assembly axial neutron flux profiles in the SAFARI-1 research\nreactor, with quantified uncertainties in the ANN predictions and extrapolation\nto cycles not used in the training process. The training dataset consists of\ncopper-wire activation measurements, the axial measurement locations and the\nmeasured control bank positions obtained from the reactor's historical cycles.\nUncertainty Quantification of the regular DNN models' predictions is performed\nusing Monte Carlo Dropout (MCD) and Bayesian Neural Networks solved by\nVariational Inference (BNN VI). The regular DNNs, DNNs solved with MCD and BNN\nVI results agree very well among each other as well as with the new measured\ndataset not used in the training process, thus indicating good prediction and\ngeneralization capability. The uncertainty bands produced by MCD and BNN VI\nagree very well, and in general, they can fully envelop the noisy measurement\ndata points. The developed ANNs are useful in supporting the experimental\nmeasurements campaign and neutronics code Verification and Validation (V&V).",
    "descriptor": "\nComments: 34 pages, 12 figures\n",
    "authors": [
      "Lesego E. Moloko",
      "Pavel M. Bokov",
      "Xu Wu",
      "Kostadin N. Ivanov"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.08654"
  },
  {
    "id": "arXiv:2211.08658",
    "title": "Consistent Direct Time-of-Flight Video Depth Super-Resolution",
    "abstract": "Direct time-of-flight (dToF) sensors are promising for next-generation\non-device 3D sensing. However, to achieve the sufficient signal-to-noise-ratio\n(SNR) in a compact module, the dToF data has limited spatial resolution (e.g.,\n~20x30 for iPhone dToF), and it requires a super-resolution step before being\npassed to downstream tasks. In this paper, we solve this super-resolution\nproblem by fusing the low-resolution dToF data with the corresponding\nhigh-resolution RGB guidance. Unlike the conventional RGB-guided depth\nenhancement approaches which perform the fusion in a per-frame manner, we\npropose the first multi-frame fusion scheme to mitigate the spatial ambiguity\nresulting from the low-resolution dToF imaging. In addition, dToF sensors\nprovide unique depth histogram information for each local patch, and we\nincorporate this dToF-specific feature in our network design to further\nalleviate spatial ambiguity. To evaluate our models on complex dynamic indoor\nenvironments and to provide a large-scale dToF sensor dataset, we introduce\nDyDToF, the first synthetic RGB-dToF video dataset that features dynamic\nobjects and a realistic dToF simulator following the physical imaging process.\nWe believe the methods and dataset are beneficial to a broad community as dToF\ndepth sensing is becoming mainstream on mobile devices.",
    "descriptor": "",
    "authors": [
      "Zhanghao Sun",
      "Wei Ye",
      "Jinhui Xiong",
      "Gyeongmin Choe",
      "Jialiang Wang",
      "Shuochen Su",
      "Rakesh Ranjan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08658"
  },
  {
    "id": "arXiv:2211.08685",
    "title": "Automated Analysis of Drawing Process for Detecting Prodromal and  Clinical Dementia",
    "abstract": "Early diagnosis of dementia, particularly in the prodromal stage (i.e., mild\ncognitive impairment, or MCI), has become a research and clinical priority but\nremains challenging. Automated analysis of the drawing process has been studied\nas a promising means for screening prodromal and clinical dementia, providing\nmultifaceted information encompassing features, such as drawing speed, pen\nposture, writing pressure, and pauses. We examined the feasibility of using\nthese features not only for detecting prodromal and clinical dementia but also\nfor predicting the severity of cognitive impairments assessed using Mini-Mental\nState Examination (MMSE) as well as the severity of neuropathological changes\nassessed by medial temporal lobe (MTL) atrophy. We collected drawing data with\na digitizing tablet and pen from 145 older adults of cognitively normal (CN),\nMCI, and dementia. The nested cross-validation results indicate that the\ncombination of drawing features could be used to classify CN, MCI, and dementia\nwith an AUC of 0.909 and 75.1% accuracy (CN vs. MCI: 82.4% accuracy; CN vs.\ndementia: 92.2% accuracy; MCI vs. dementia: 80.3% accuracy) and predict MMSE\nscores with an $R^2$ of 0.491 and severity of MTL atrophy with an $R^2$ of\n0.293. Our findings suggest that automated analysis of the drawing process can\nprovide information about cognitive impairments and neuropathological changes\ndue to dementia, which can help identify prodromal and clinical dementia as a\ndigital biomarker.",
    "descriptor": "",
    "authors": [
      "Yasunori Yamada",
      "Masatomo Kobayashi",
      "Kaoru Shinkawa",
      "Miyuki Nemoto",
      "Miho Ota",
      "Kiyotaka Nemoto",
      "Tetsuaki Arai"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08685"
  },
  {
    "id": "arXiv:2211.08717",
    "title": "SWIN-SFTNet : Spatial Feature Expansion and Aggregation using Swin  Transformer For Whole Breast micro-mass segmentation",
    "abstract": "Incorporating various mass shapes and sizes in training deep learning\narchitectures has made breast mass segmentation challenging. Moreover, manual\nsegmentation of masses of irregular shapes is time-consuming and error-prone.\nThough Deep Neural Network has shown outstanding performance in breast mass\nsegmentation, it fails in segmenting micro-masses. In this paper, we propose a\nnovel U-net-shaped transformer-based architecture, called Swin-SFTNet, that\noutperforms state-of-the-art architectures in breast mammography-based\nmicro-mass segmentation. Firstly to capture the global context, we designed a\nnovel Spatial Feature Expansion and Aggregation Block(SFEA) that transforms\nsequential linear patches into a structured spatial feature. Next, we combine\nit with the local linear features extracted by the swin transformer block to\nimprove overall accuracy. We also incorporate a novel embedding loss that\ncalculates similarities between linear feature embeddings of the encoder and\ndecoder blocks. With this approach, we achieve higher segmentation dice over\nthe state-of-the-art by 3.10% on CBIS-DDSM, 3.81% on InBreast, and 3.13% on\nCBIS pre-trained model on the InBreast test data set.",
    "descriptor": "\nComments: 5 pages, 3 figures, 2 tables\n",
    "authors": [
      "Sharif Amit Kamran",
      "Khondker Fariha Hossain",
      "Alireza Tavakkoli",
      "George Bebis",
      "Sal Baker"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08717"
  },
  {
    "id": "arXiv:2211.08718",
    "title": "Topology of cognitive maps",
    "abstract": "In present paper we test different approaches to reconstructing the topology\nof the physical space from neural activity data in A1 fields of mice brains, in\nparticular, having a Cognitome-focused approach in mind. Animals were placed in\ndifferent new environments and discovered them while their physical and neural\nactivity was recorded. We discuss possible approaches to identifying the place\ncells and make assumptions on how Cognitome theory might help with that. We\nalso test and discuss various methods of dimension reduction and topology\nreconstruction. In particular, two main strategies we focus on are the Nerve\ntheorem and point cloud-based methods. Conclusions on the results of\nreconstruction are supported with illustrations and mathematical background\nwhich is also briefly discussed.",
    "descriptor": "\nComments: 27 pages, 23 figures\n",
    "authors": [
      "Konstantin Sorokin",
      "Anton Ayzenberg",
      "Konstantin Anokhin",
      "Vladimir Sotskov",
      "Maxim Beketov",
      "Andrey Zaitsev",
      "Robert Drinking"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.08718"
  },
  {
    "id": "arXiv:2211.08737",
    "title": "Near-Term Quantum Computing Techniques: Variational Quantum Algorithms,  Error Mitigation, Circuit Compilation, Benchmarking and Classical Simulation",
    "abstract": "Quantum computing is a game-changing technology for global academia, research\ncenters and industries including computational science, mathematics, finance,\npharmaceutical, materials science, chemistry and cryptography. Although it has\nseen a major boost in the last decade, we are still a long way from reaching\nthe maturity of a full-fledged quantum computer. That said, we will be in the\nNoisy-Intermediate Scale Quantum (NISQ) era for a long time, working on dozens\nor even thousands of qubits quantum computing systems. An outstanding\nchallenge, then, is to come up with an application that can reliably carry out\na nontrivial task of interest on the near-term quantum devices with\nnon-negligible quantum noise. To address this challenge, several near-term\nquantum computing techniques, including variational quantum algorithms, error\nmitigation, quantum circuit compilation and benchmarking protocols, have been\nproposed to characterize and mitigate errors, and to implement algorithms with\na certain resistance to noise, so as to enhance the capabilities of near-term\nquantum devices and explore the boundaries of their ability to realize useful\napplications. Besides, the development of near-term quantum devices is\ninseparable from the efficient classical simulation, which plays a vital role\nin quantum algorithm design and verification, error-tolerant verification and\nother applications. This review will provide a thorough introduction of these\nnear-term quantum computing techniques, report on their progress, and finally\ndiscuss the future prospect of these techniques, which we hope will motivate\nresearchers to undertake additional studies in this field.",
    "descriptor": "\nComments: Please feel free to email He-Liang Huang with any comments, questions, suggestions or concerns\n",
    "authors": [
      "He-Liang Huang",
      "Xiao-Yue Xu",
      "Chu Guo",
      "Guojing Tian",
      "Shi-Jie Wei",
      "Xiaoming Sun",
      "Wan-Su Bao",
      "Gui-Lu Long"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08737"
  },
  {
    "id": "arXiv:2211.08748",
    "title": "Array Configuration-Agnostic Personalized Speech Enhancement using  Long-Short-Term Spatial Coherence",
    "abstract": "Personalized speech enhancement has been a field of active research for\nsuppression of speechlike interferers such as competing speakers or TV\ndialogues. Compared with single channel approaches, multichannel PSE systems\ncan be more effective in adverse acoustic conditions by leveraging the spatial\ninformation in microphone signals. However, the implementation of multichannel\nPSEs to accommodate a wide range of array topology in household applications\ncan be challenging. To develop an array configuration agnostic PSE system, we\ndefine a spatial feature termed the long short term spatial coherence as the\ninput feature to a convolutional recurrent network to monitor the voice\nactivity of the target speaker. As another refinement, an equivalent\nrectangular bandwidth scaled LSTSC feature can be used to reduce the\ncomputational cost. Experiments were conducted to compare the proposed PSE\nsystems, including the complete and the simplified versions with two baselines\nusing unseen room responses and array configurations in the presence of TV\nnoise and competing speakers. The results demonstrated that the proposed\nmultichannel PSE network trained with the LSTSC feature achieved superior\nenhancement performance without precise knowledge of the array configurations\nand room responses.",
    "descriptor": "",
    "authors": [
      "Yicheng Hsu",
      "Yonghan Lee",
      "Mingsian R. Bai"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.08748"
  },
  {
    "id": "arXiv:2211.08775",
    "title": "Unbalanced Optimal Transport, from Theory to Numerics",
    "abstract": "Optimal Transport (OT) has recently emerged as a central tool in data\nsciences to compare in a geometrically faithful way point clouds and more\ngenerally probability distributions. The wide adoption of OT into existing data\nanalysis and machine learning pipelines is however plagued by several\nshortcomings. This includes its lack of robustness to outliers, its high\ncomputational costs, the need for a large number of samples in high dimension\nand the difficulty to handle data in distinct spaces. In this review, we detail\nseveral recently proposed approaches to mitigate these issues. We insist in\nparticular on unbalanced OT, which compares arbitrary positive measures, not\nrestricted to probability distributions (i.e. their total mass can vary). This\ngeneralization of OT makes it robust to outliers and missing data. The second\nworkhorse of modern computational OT is entropic regularization, which leads to\nscalable algorithms while lowering the sample complexity in high dimension. The\nlast point presented in this review is the Gromov-Wasserstein (GW) distance,\nwhich extends OT to cope with distributions belonging to different metric\nspaces. The main motivation for this review is to explain how unbalanced OT,\nentropic regularization and GW can work hand-in-hand to turn OT into efficient\ngeometric loss functions for data sciences.",
    "descriptor": "",
    "authors": [
      "Thibault S\u00e9journ\u00e9",
      "Gabriel Peyr\u00e9",
      "Fran\u00e7ois-Xavier Vialard"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.08775"
  },
  {
    "id": "arXiv:2211.08783",
    "title": "Uncertainty-Aware Multi-Parametric Magnetic Resonance Image Information  Fusion for 3D Object Segmentation",
    "abstract": "Multi-parametric magnetic resonance (MR) imaging is an indispensable tool in\nthe clinic. Consequently, automatic volume-of-interest segmentation based on\nmulti-parametric MR imaging is crucial for computer-aided disease diagnosis,\ntreatment planning, and prognosis monitoring. Despite the extensive studies\nconducted in deep learning-based medical image analysis, further investigations\nare still required to effectively exploit the information provided by different\nimaging parameters. How to fuse the information is a key question in this\nfield. Here, we propose an uncertainty-aware multi-parametric MR image feature\nfusion method to fully exploit the information for enhanced 3D image\nsegmentation. Uncertainties in the independent predictions of individual\nmodalities are utilized to guide the fusion of multi-modal image features.\nExtensive experiments on two datasets, one for brain tissue segmentation and\nthe other for abdominal multi-organ segmentation, have been conducted, and our\nproposed method achieves better segmentation performance when compared to\nexisting models.",
    "descriptor": "",
    "authors": [
      "Cheng Li",
      "Yousuf Babiker M. Osman",
      "Weijian Huang",
      "Zhenzhen Xue",
      "Hua Han",
      "Hairong Zheng",
      "Shanshan Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08783"
  },
  {
    "id": "arXiv:2211.08790",
    "title": "Structural Segmentation and Labeling of Tabla Solo Performances",
    "abstract": "Tabla is a North Indian percussion instrument used as an accompaniment and an\nexclusive instrument for solo performances. Tabla solo is intricate and\nelaborate, exhibiting rhythmic evolution through a sequence of homogeneous\nsections marked by shared rhythmic characteristics. Each section has a specific\nstructure and name associated with it. Tabla learning and performance in the\nIndian subcontinent is based on stylistic schools called gharana-s. Several\ncompositions by various composers from different gharana-s are played in each\nsection. This paper addresses the task of segmenting the tabla solo concert\ninto musically meaningful sections. We then assign suitable section labels and\nrecognize gharana-s from the sections. We present a diverse collection of over\n38 hours of solo tabla recordings for the task. We motivate the problem and\npresent different challenges and facets of the tasks. Inspired by the distinct\nmusical properties of tabla solo, we compute several rhythmic and timbral\nfeatures for the segmentation task. This work explores the approach of\nautomatically locating the significant changes in the rhythmic structure by\nanalyzing local self-similarity in an unsupervised manner. We also explore\nsupervised random forest and a convolutional neural network trained on\nhand-crafted features. Both supervised and unsupervised approaches are also\ntested on a set of held-out recordings. Segmentation of an audio piece into its\nstructural components and labeling is crucial to many music information\nretrieval applications like repetitive structure finding, audio summarization,\nand fast music navigation. This work helps us obtain a comprehensive musical\ndescription of the tabla solo concert.",
    "descriptor": "\nComments: 35 pages, 11 figures\n",
    "authors": [
      "Gowriprasad R",
      "R Aravind",
      "Hema A Murthy"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08790"
  },
  {
    "id": "arXiv:2211.08801",
    "title": "Adapting to noise distribution shifts in flow-based gravitational-wave  inference",
    "abstract": "Deep learning techniques for gravitational-wave parameter estimation have\nemerged as a fast alternative to standard samplers $\\unicode{x2013}$ producing\nresults of comparable accuracy. These approaches (e.g., DINGO) enable amortized\ninference by training a normalizing flow to represent the Bayesian posterior\nconditional on observed data. By conditioning also on the noise power spectral\ndensity (PSD) they can even account for changing detector characteristics.\nHowever, training such networks requires knowing in advance the distribution of\nPSDs expected to be observed, and therefore can only take place once all data\nto be analyzed have been gathered. Here, we develop a probabilistic model to\nforecast future PSDs, greatly increasing the temporal scope of DINGO networks.\nUsing PSDs from the second LIGO-Virgo observing run (O2) $\\unicode{x2013}$ plus\njust a single PSD from the beginning of the third (O3) $\\unicode{x2013}$ we\nshow that we can train a DINGO network to perform accurate inference throughout\nO3 (on 37 real events). We therefore expect this approach to be a key component\nto enable the use of deep learning techniques for low-latency analyses of\ngravitational waves.",
    "descriptor": "",
    "authors": [
      "Jonas Wildberger",
      "Maximilian Dax",
      "Stephen R. Green",
      "Jonathan Gair",
      "Michael P\u00fcrrer",
      "Jakob H. Macke",
      "Alessandra Buonanno",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08801"
  },
  {
    "id": "arXiv:2211.08827",
    "title": "Adaptive observer for a nonlinear system with partially unknown state  matrix and delayed measurements",
    "abstract": "Problem of an adaptive state observer design for nonlinear system with\nunknown time-varying parameters and under condition of delayed measurements is\nconsidered. State observation problem was raised by many researchers (see for\nexample Sanx et al. (2019)). In this paper the results proposed in Bobtsov et\nal. (2021b), Bobtsov et al. (2021a), Bobtsov et al. (2022a), Bobtsov et al.\n(2022b) are developed. The problem is solved under assumption that the state\nmatrix can be represented as sum of known and unknown parts. The output vector\nis measured with a known constant delay. An adaptive observer which\nreconstructs unknown state and unknown time-varying parameter is proposed.",
    "descriptor": "\nComments: Submitted to IFAC World Congress 2023\n",
    "authors": [
      "Olga Kozachek",
      "Alexey Bobtsov",
      "Nikolay Nikolaev"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.08827"
  },
  {
    "id": "arXiv:2211.08848",
    "title": "Annotation of Soft Onsets in String Ensemble Recordings",
    "abstract": "Onset detection is the process of identifying the start points of musical\nnote events within an audio recording. While the detection of percussive onsets\nis often considered a solved problem, soft onsets-as found in string instrument\nrecordings-still pose a significant challenge for state-of-the-art algorithms.\nThe problem is further exacerbated by a paucity of data containing expert\nannotations and research related to best practices for curating soft onset\nannotations for string instruments. To this end, we investigate inter-annotator\nagreement between 24 participants, extend an algorithm for determining the most\nconsistent annotator, and compare the performance of human annotators and\nstate-of-the-art onset detection algorithms. Experimental results reveal a\npositive trend between musical experience and both inter-annotator agreement\nand performance in comparison with automated systems. Additionally, onsets\nproduced by changes in fingering as well as those from the cello were found to\nbe particularly challenging for both human annotators and automatic approaches.\nTo promote research in best practices for annotation of soft onsets, we have\nmade all experimental data associated with this study publicly available. In\naddition, we publish the ARME Virtuoso Strings dataset, consisting of over 144\nrecordings of professional performances of an excerpt from Haydn's string\nquartet Op. 74 No. 1 Finale, each with corresponding individual instrumental\nonset annotations.",
    "descriptor": "",
    "authors": [
      "Maciej Tomczak",
      "Min Susan Li",
      "Adrian Bradbury",
      "Mark Elliott",
      "Ryan Stables",
      "Maria Witek",
      "Tom Goodman",
      "Diar Abdlkarim",
      "Massimiliano Di Luca",
      "Alan Wing",
      "Jason Hockman"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Information Retrieval (cs.IR)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.08848"
  },
  {
    "id": "arXiv:2211.08849",
    "title": "L2 proficiency assessment using self-supervised speech representations",
    "abstract": "There has been a growing demand for automated spoken language assessment\nsystems in recent years. A standard pipeline for this process is to start with\na speech recognition system and derive features, either hand-crafted or based\non deep-learning, that exploit the transcription and audio. Though these\napproaches can yield high performance systems, they require speech recognition\nsystems that can be used for L2 speakers, and preferably tuned to the specific\nform of test being deployed. Recently a self-supervised speech representation\nbased scheme, requiring no speech recognition, was proposed. This work extends\nthe initial analysis conducted on this approach to a large scale proficiency\ntest, Linguaskill, that comprises multiple parts, each designed to assess\ndifferent attributes of a candidate's speaking proficiency. The performance of\nthe self-supervised, wav2vec 2.0, system is compared to a high performance\nhand-crafted assessment system and a BERT-based text system both of which use\nspeech transcriptions. Though the wav2vec 2.0 based system is found to be\nsensitive to the nature of the response, it can be configured to yield\ncomparable performance to systems requiring a speech transcription, and yields\ngains when appropriately combined with standard approaches.",
    "descriptor": "",
    "authors": [
      "Stefano Bann\u00f2",
      "Kate M. Knill",
      "Marco Matassoni",
      "Vyas Raina",
      "Mark J. F. Gales"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08849"
  },
  {
    "id": "arXiv:2211.08854",
    "title": "Graph Filters for Signal Processing and Machine Learning on Graphs",
    "abstract": "Filters are fundamental in extracting information from data. For time series\nand image data that reside on Euclidean domains, filters are the crux of many\nsignal processing and machine learning techniques, including convolutional\nneural networks. Increasingly, modern data also reside on networks and other\nirregular domains whose structure is better captured by a graph. To process and\nlearn from such data, graph filters account for the structure of the underlying\ndata domain. In this article, we provide a comprehensive overview of graph\nfilters, including the different filtering categories, design strategies for\neach type, and trade-offs between different types of graph filters. We discuss\nhow to extend graph filters into filter banks and graph neural networks to\nenhance the representational power; that is, to model a broader variety of\nsignal classes, data patterns, and relationships. We also showcase the\nfundamental role of graph filters in signal processing and machine learning\napplications. Our aim is that this article serves the dual purpose of providing\na unifying framework for both beginner and experienced researchers, as well as\na common understanding that promotes collaborations between signal processing,\nmachine learning, and application domains.",
    "descriptor": "",
    "authors": [
      "Elvin Isufi",
      "Fernando Gama",
      "David I. Shuman",
      "Santiago Segarra"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08854"
  },
  {
    "id": "arXiv:2211.08856",
    "title": "Challenges in creative generative models for music: a divergence  maximization perspective",
    "abstract": "The development of generative Machine Learning (ML) models in creative\npractices, enabled by the recent improvements in usability and availability of\npre-trained models, is raising more and more interest among artists,\npractitioners and performers. Yet, the introduction of such techniques in\nartistic domains also revealed multiple limitations that escape current\nevaluation methods used by scientists. Notably, most models are still unable to\ngenerate content that lay outside of the domain defined by the training\ndataset. In this paper, we propose an alternative prospective framework,\nstarting from a new general formulation of ML objectives, that we derive to\ndelineate possible implications and solutions that already exist in the ML\nliterature (notably for the audio and musical domain). We also discuss existing\nrelations between generative models and computational creativity and how our\nframework could help address the lack of creativity in existing models.",
    "descriptor": "\nComments: to be published in AI Music Creativity Conference proceedings (AIMC2022)\n",
    "authors": [
      "Axel Chemla--Romeu-Santos",
      "Philippe Esling"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.08856"
  },
  {
    "id": "arXiv:2211.08857",
    "title": "Delivering Speaking Style in Low-resource Voice Conversion with  Multi-factor Constraints",
    "abstract": "Conveying the linguistic content and maintaining the source speech's speaking\nstyle, such as intonation and emotion, is essential in voice conversion (VC).\nHowever, in a low-resource situation, where only limited utterances from the\ntarget speaker are accessible, existing VC methods are hard to meet this\nrequirement and capture the target speaker's timber. In this work, a novel VC\nmodel, referred to as MFC-StyleVC, is proposed for the low-resource VC task.\nSpecifically, speaker timbre constraint generated by clustering method is newly\nproposed to guide target speaker timbre learning in different stages.\nMeanwhile, to prevent over-fitting to the target speaker's limited data,\nperceptual regularization constraints explicitly maintain model performance on\nspecific aspects, including speaking style, linguistic content, and speech\nquality. Besides, a simulation mode is introduced to simulate the inference\nprocess to alleviate the mismatch between training and inference. Extensive\nexperiments performed on highly expressive speech demonstrate the superiority\nof the proposed method in low-resource VC.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Zhichao Wang",
      "Xinsheng Wang",
      "Lei Xie",
      "Yuanzhe Chen",
      "Qiao Tian",
      "Yuping Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.08857"
  },
  {
    "id": "arXiv:2211.08872",
    "title": "McNet: Fuse Multiple Cues for Multichannel Speech Enhancement",
    "abstract": "In multichannel speech enhancement, both spectral and spatial information are\nvital for discriminating between speech and noise. How to fully exploit these\ntwo types of information and their temporal dynamics remains an interesting\nresearch problem. As a solution to this problem, this paper proposes a\nmulti-cue fusion network named McNet, which cascades four modules to\nrespectively exploit the full-band spatial, narrow-band spatial, sub-band\nspectral, and full-band spectral information. Experiments show that each module\nin the proposed network has its unique contribution and, as a whole, notably\noutperforms other state-of-the-art methods.",
    "descriptor": "\nComments: submitted to icassp 2023\n",
    "authors": [
      "Yujie Yang",
      "Changsheng Quan",
      "Xiaofei Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.08872"
  },
  {
    "id": "arXiv:2211.08883",
    "title": "Identifying the Causes of Pyrocumulonimbus (PyroCb)",
    "abstract": "A first causal discovery analysis from observational data of pyroCb (storm\nclouds generated from extreme wildfires) is presented. Invariant Causal\nPrediction was used to develop tools to understand the causal drivers of pyroCb\nformation. This includes a conditional independence test for testing $Y \\indep\nE|X$ for binary variable $Y$ and multivariate, continuous variables $X$ and\n$E$, and a greedy-ICP search algorithm that relies on fewer conditional\nindependence tests to obtain a smaller more manageable set of causal\npredictors. With these tools, we identified a subset of seven causal predictors\nwhich are plausible when contrasted with domain knowledge: surface sensible\nheat flux, relative humidity at $850$\\,hPa, a component of wind at $250$\\,hPa,\n$13.3$\\,\\textmu m thermal emissions, convective available potential energy, and\naltitude.",
    "descriptor": "\nComments: 14 pages 9 figures. To be published in Tthe 2022 NeurIPS Workshop on Causal Machine Learning for Real-World Impact\n",
    "authors": [
      "Emiliano D\u00edaz Salas-Porras",
      "Kenza Tazi",
      "Ashwin Braude",
      "Daniel Okoh",
      "Kara D. Lamb",
      "Duncan Watson-Parris",
      "Paula Harder",
      "Nis Meinert"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08883"
  },
  {
    "id": "arXiv:2211.08943",
    "title": "Comparing Explanation Methods for Traditional Machine Learning Models  Part 1: An Overview of Current Methods and Quantifying Their Disagreement",
    "abstract": "With increasing interest in explaining machine learning (ML) models, the\nfirst part of this two-part study synthesizes recent research on methods for\nexplaining global and local aspects of ML models. This study distinguishes\nexplainability from interpretability, local from global explainability, and\nfeature importance versus feature relevance. We demonstrate and visualize\ndifferent explanation methods, how to interpret them, and provide a complete\nPython package (scikit-explain) to allow future researchers to explore these\nproducts. We also highlight the frequent disagreement between explanation\nmethods for feature rankings and feature effects and provide practical advice\nfor dealing with these disagreements. We used ML models developed for severe\nweather prediction and sub-freezing road surface temperature prediction to\ngeneralize the behavior of the different explanation methods. For feature\nrankings, there is substantially more agreement on the set of top features\n(e.g., on average, two methods agree on 6 of the top 10 features) than on\nspecific rankings (on average, two methods only agree on the ranks of 2-3\nfeatures in the set of top 10 features). On the other hand, two feature effect\ncurves from different methods are in high agreement as long as the phase space\nis well sampled. Finally, a lesser-known method, tree interpreter, was found\ncomparable to SHAP for feature effects, and with the widespread use of random\nforests in geosciences and computational ease of tree interpreter, we recommend\nit be explored in future research.",
    "descriptor": "\nComments: 22 pages; 10 figures\n",
    "authors": [
      "Montgomery Flora",
      "Corey Potvin",
      "Amy McGovern",
      "Shawn Handler"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.08943"
  },
  {
    "id": "arXiv:2211.08944",
    "title": "Reasons for the Superiority of Stochastic Estimators over Deterministic  Ones: Robustness, Consistency and Perceptual Quality",
    "abstract": "Stochastic restoration algorithms allow to explore the space of solutions\nthat correspond to the degraded input. In this paper we reveal additional\nfundamental advantages of stochastic methods over deterministic ones, which\nfurther motivate their use. First, we prove that any restoration algorithm that\nattains perfect perceptual quality and whose outputs are consistent with the\ninput must be a posterior sampler, and is thus required to be stochastic.\nSecond, we illustrate that while deterministic restoration algorithms may\nattain high perceptual quality, this can be achieved only by filling up the\nspace of all possible source images using an extremely sensitive mapping, which\nmakes them highly vulnerable to adversarial attacks. Indeed, we show that\nenforcing deterministic models to be robust to such attacks profoundly hinders\ntheir perceptual quality, while robustifying stochastic models hardly\ninfluences their perceptual quality, and improves their output variability.\nThese findings provide a motivation to foster progress in stochastic\nrestoration methods, paving the way to better recovery algorithms.",
    "descriptor": "",
    "authors": [
      "Guy Ohayon",
      "Theo Adrai",
      "Michael Elad",
      "Tomer Michaeli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08944"
  },
  {
    "id": "arXiv:2211.08953",
    "title": "Exponential methods for anisotropic diffusion",
    "abstract": "The anisotropic diffusion equation is of crucial importance in understanding\ncosmic ray (CR) diffusion across the Galaxy and its interplay with the Galactic\nmagnetic field. This diffusion term contributes to the highly stiff nature of\nthe CR transport equation. In order to conduct numerical simulations of\ntime-dependent cosmic ray transport, implicit integrators have been\ntraditionally favoured over the CFL-bound explicit integrators in order to be\nable to take large step sizes. We propose exponential methods that directly\ncompute the exponential of the matrix to solve the linear anisotropic diffusion\nequation. These methods allow us to take even larger step sizes; in certain\ncases, we are able to choose a step size as large as the simulation time, i.e.,\nonly one time step. This can substantially speed-up the simulations whilst\ngenerating highly accurate solutions (l2 error $\\leq 10^{-10}$). Additionally,\nwe test an approach based on extracting a constant coefficient from the\nanisotropic diffusion equation where the constant coefficient term is solved\nimplicitly or exponentially and the remainder is treated using some explicit\nmethod. We find that this approach, for linear problems, is unable to improve\non the exponential-based methods that directly evaluate the matrix exponential.",
    "descriptor": "\nComments: in submission\n",
    "authors": [
      "Pranab J. Deka",
      "Lukas Einkemmer",
      "Ralf Kissmann",
      "Stefan-Tiberiu Kis"
    ],
    "subjectives": [
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.08953"
  },
  {
    "id": "arXiv:2211.08958",
    "title": "Vector-Valued Least-Squares Regression under Output Regularity  Assumptions",
    "abstract": "We propose and analyse a reduced-rank method for solving least-squares\nregression problems with infinite dimensional output. We derive learning bounds\nfor our method, and study under which setting statistical performance is\nimproved in comparison to full-rank method. Our analysis extends the interest\nof reduced-rank regression beyond the standard low-rank setting to more general\noutput regularity assumptions. We illustrate our theoretical insights on\nsynthetic least-squares problems. Then, we propose a surrogate structured\nprediction method derived from this reduced-rank method. We assess its benefits\non three different problems: image reconstruction, multi-label classification,\nand metabolite identification.",
    "descriptor": "",
    "authors": [
      "Luc Brogat-Motte",
      "Alessandro Rudi",
      "C\u00e9line Brouard",
      "Juho Rousu",
      "Florence d'Alch\u00e9-Buc"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08958"
  },
  {
    "id": "arXiv:2211.08971",
    "title": "Energy Reconstruction in Analysis of Cherenkov Telescopes Images in  TAIGA Experiment Using Deep Learning Methods",
    "abstract": "Imaging Atmospheric Cherenkov Telescopes (IACT) of TAIGA astrophysical\ncomplex allow to observe high energy gamma radiation helping to study many\nastrophysical objects and processes. TAIGA-IACT enables us to select gamma\nquanta from the total cosmic radiation flux and recover their primary\nparameters, such as energy and direction of arrival. The traditional method of\nprocessing the resulting images is an image parameterization - so-called the\nHillas parameters method. At the present time Machine Learning methods, in\nparticular Deep Learning methods have become actively used for IACT image\nprocessing. This paper presents the analysis of simulated Monte Carlo images by\nseveral Deep Learning methods for a single telescope (mono-mode) and multiple\nIACT telescopes (stereo-mode). The estimation of the quality of energy\nreconstruction was carried out and their energy spectra were analyzed using\nseveral types of neural networks. Using the developed methods the obtained\nresults were also compared with the results obtained by traditional methods\nbased on the Hillas parameters.",
    "descriptor": "",
    "authors": [
      "E. O. Gres",
      "A. P. Kryukov"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08971"
  },
  {
    "id": "arXiv:2211.09008",
    "title": "Normalizing Flows for Hierarchical Bayesian Analysis: A Gravitational  Wave Population Study",
    "abstract": "We propose parameterizing the population distribution of the gravitational\nwave population modeling framework (Hierarchical Bayesian Analysis) with a\nnormalizing flow. We first demonstrate the merit of this method on illustrative\nexperiments and then analyze four parameters of the latest LIGO data release:\nprimary mass, secondary mass, redshift, and effective spin. Our results show\nthat despite the small and notoriously noisy dataset, the posterior predictive\ndistributions (assuming a prior over the parameters of the flow) of the\nobserved gravitational wave population recover structure that agrees with\nrobust previous phenomenological modeling results while being less susceptible\nto biases introduced by less-flexible distribution models. Therefore, the\nmethod forms a promising flexible, reliable replacement for population\ninference distributions, even when data is highly noisy.",
    "descriptor": "",
    "authors": [
      "David Ruhe",
      "Kaze Wong",
      "Miles Cranmer",
      "Patrick Forr\u00e9"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Machine Learning (cs.LG)",
      "General Relativity and Quantum Cosmology (gr-qc)"
    ],
    "url": "https://arxiv.org/abs/2211.09008"
  },
  {
    "id": "arXiv:2211.09024",
    "title": "Phenomenological Causality",
    "abstract": "Discussions on causal relations in real life often consider variables for\nwhich the definition of causality is unclear since the notion of interventions\non the respective variables is obscure. Asking 'what qualifies an action for\nbeing an intervention on the variable X' raises the question whether the action\nimpacted all other variables only through X or directly, which implicitly\nrefers to a causal model.\nTo avoid this known circularity, we instead suggest a notion of\n'phenomenological causality' whose basic concept is a set of elementary\nactions. Then the causal structure is defined such that elementary actions\nchange only the causal mechanism at one node (e.g. one of the causal\nconditionals in the Markov factorization). This way, the Principle of\nIndependent Mechanisms becomes the defining property of causal structure in\ndomains where causality is a more abstract phenomenon rather than being an\nobjective fact relying on hard-wired causal links between tangible objects. We\ndescribe this phenomenological approach to causality for toy and hypothetical\nreal-world examples and argue that it is consistent with the causal Markov\ncondition when the system under consideration interacts with other variables\nthat control the elementary actions.",
    "descriptor": "\nComments: 23 pages, 13 figures\n",
    "authors": [
      "Dominik Janzing",
      "Sergio Hernan Garrido Mejia"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.09024"
  },
  {
    "id": "arXiv:2211.09059",
    "title": "A generative grammar of cooking",
    "abstract": "Cooking is a uniquely human endeavor for transforming raw ingredients into\ndelicious dishes. Over centuries, cultures worldwide have evolved diverse\ncooking practices ingrained in their culinary traditions. Recipes, thus, are\ncultural capsules that capture culinary knowledge in elaborate cooking\nprotocols. While simple quantitative models have probed the patterns in recipe\ncomposition and the process of cuisine evolution, unlike other cultural quirks\nsuch as language, the principles of cooking remain hitherto unexplored. The\nfundamental rules that drive the act of cooking, shaping recipe composition and\ncuisine architecture, are unclear. Here we present a generative grammar of\ncooking that captures the underlying culinary logic. By studying an extensive\nrepository of structured recipes, we identify core concepts and rules that\ntogether forge a combinatorial system for culinary synthesis. Building on the\nbody of work done in the context of language, the demonstration of a logically\nconsistent generative framework offers profound insights into the act of\ncooking. Given the central role of food in nutrition and lifestyle disorders,\nculinary grammar provides leverage to improve public health through dietary\ninterventions beyond applications for creative pursuits such as novel recipe\ngeneration.",
    "descriptor": "\nComments: Main Text (8 pages, 4 figures); Supplementary Information (5 pages, 1 Figure, 5 Tables)\n",
    "authors": [
      "Ganesh Bagler"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.09059"
  },
  {
    "id": "arXiv:2211.09068",
    "title": "Ischemic Stroke Lesion Prediction using imbalanced Temporal Deep  Gaussian Process (iTDGP)",
    "abstract": "As one of the leading causes of mortality and disability worldwide, Acute\nIschemic Stroke (AIS) occurs when the blood supply to the brain is suddenly\ninterrupted because of a blocked artery. Within seconds of AIS onset, the brain\ncells surrounding the blocked artery die, which leads to the progression of the\nlesion. The automated and precise prediction of the existing lesion plays a\nvital role in the AIS treatment planning and prevention of further injuries.\nThe current standard AIS assessment method, which thresholds the 3D measurement\nmaps extracted from Computed Tomography Perfusion (CTP) images, is not accurate\nenough. Due to this fact, in this article, we propose the imbalanced Temporal\nDeep Gaussian Process (iTDGP), a probabilistic model that can improve AIS\nlesions prediction by using baseline CTP time series. Our proposed model can\neffectively extract temporal information from the CTP time series and map it to\nthe class labels of the brain's voxels. In addition, by using batch training\nand voxel-level analysis iTDGP can learn from a few patients and it is robust\nagainst imbalanced classes. Moreover, our model incorporates a post-processor\ncapable of improving prediction accuracy using spatial information. Our\ncomprehensive experiments, on the ISLES 2018 and the University of Alberta\nHospital (UAH) datasets, show that iTDGP performs better than state-of-the-art\nAIS lesion predictors, obtaining the (cross-validation) Dice score of 71.42%\nand 65.37% with a significant p<0.05, respectively.",
    "descriptor": "",
    "authors": [
      "Mohsen Soltanpour",
      "Muhammad Yousefnezhad",
      "Russ Greiner",
      "Pierre Boulanger",
      "Brian Buck"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09068"
  },
  {
    "id": "arXiv:2211.09076",
    "title": "Space-Time Digitally-Coded Metamaterial Antenna Enabled Directional  Modulation for Physical Layer Security",
    "abstract": "Developing low-cost and scalable security solutions is vital to the advent of\nfuture large-scale wireless networks. Traditional cryptographic methods fail to\nmeet the low-latency and scalability requirements of these networks due to\ntheir computational and key management complexity. On the other hand, physical\nlayer (PHY) security has been put forth as a cost-effective alternative to\ncryptographic mechanisms that can circumvent the need for explicit key exchange\nbetween communication devices, owing to the fact that PHY security relies on\nthe physics of the signal transmission for providing security. In this work, we\npropose a space-time-modulated digitally-coded metamaterial (MTM) leaky wave\nantenna (LWA) that can enable PHY security by achieving the functionalities of\ndirectional modulation (DM). From the theoretical perspective, we first show\nhow the proposed space-time MTM antenna architecture can achieve DM through\nboth the spatial and spectral manipulation of the orthogonal frequency division\nmultiplexing (OFDM) signal received by a user equipment (UE). Simulation\nresults are then provided as proof-of-principle, demonstrating the\napplicability of our approach for achieving DM in various communication\nsettings. To further validate our simulation results, we realize a prototype of\nthe proposed architecture controlled by a field-programmable gate array (FPGA),\nwhich achieves DM via an optimized coding sequence carried out by the\nbranch-and-bound algorithm corresponding to the states of the MTM LWA's unit\ncells. Experimental results confirm the theory behind the space-time-modulated\nMTM LWA in achieving DM, which is observed via both the spectral harmonic\npatterns and bit error rate (BER) measurements.",
    "descriptor": "",
    "authors": [
      "Alireza Nooraiepour",
      "Shaghayegh Vosoughitabar",
      "Chung-Tse Michael Wu",
      "Waheed U. Bajwa",
      "Narayan B. Mandayam"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.09076"
  },
  {
    "id": "arXiv:2211.09096",
    "title": "Testing geometric representation hypotheses from simulated place cell  recordings",
    "abstract": "Hippocampal place cells can encode spatial locations of an animal in physical\nor task-relevant spaces. We simulated place cell populations that encoded\neither Euclidean- or graph-based positions of a rat navigating to goal nodes in\na maze with a graph topology, and used manifold learning methods such as UMAP\nand Autoencoders (AE) to analyze these neural population activities. The\nstructure of the latent spaces learned by the AE reflects their true geometric\nstructure, while PCA fails to do so and UMAP is less robust to noise. Our\nresults support future applications of AE architectures to decipher the\ngeometry of spatial encoding in the brain.",
    "descriptor": "\nComments: NeurIPS 2022: NeurReps workshop, extended abstract track\n",
    "authors": [
      "Thibault Niederhauser",
      "Adam Lester",
      "Nina Miolane",
      "Khanh Dao Duc",
      "Manu S. Madhav"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.09096"
  },
  {
    "id": "arXiv:1811.02921",
    "title": "Flexible Representative Democracy: An Introduction with Binary Issues",
    "abstract": "Flexible Representative Democracy: An Introduction with Binary Issues",
    "descriptor": "",
    "authors": [
      "Ben Abramowitz",
      "Nicholas Mattei"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/1811.02921"
  },
  {
    "id": "arXiv:1910.09083",
    "title": "Spectral CUSUM for Online Network Structure Change Detection",
    "abstract": "Comments: In revision for IEEE Transactions on Information Theory",
    "descriptor": "\nComments: In revision for IEEE Transactions on Information Theory\n",
    "authors": [
      "Minghe Zhang",
      "Liyan Xie",
      "Yao Xie"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/1910.09083"
  },
  {
    "id": "arXiv:1911.00658",
    "title": "Global Adaptive Generative Adjustment",
    "abstract": "Global Adaptive Generative Adjustment",
    "descriptor": "",
    "authors": [
      "Bin Wang",
      "Xiaofei Wang",
      "Jianhua Guo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/1911.00658"
  },
  {
    "id": "arXiv:2001.05719",
    "title": "Semantic Security for Quantum Wiretap Channels",
    "abstract": "Comments: v2: published version; v1: 38 pages, 2 figures",
    "descriptor": "\nComments: v2: published version; v1: 38 pages, 2 figures\n",
    "authors": [
      "Holger Boche",
      "Minglai Cai",
      "Christian Deppe",
      "Roberto Ferrara",
      "Moritz Wiese"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2001.05719"
  },
  {
    "id": "arXiv:2001.06081",
    "title": "Fourier Transform Approach to Machine Learning III: Fourier  Classification",
    "abstract": "Fourier Transform Approach to Machine Learning III: Fourier  Classification",
    "descriptor": "",
    "authors": [
      "Soheil Mehrabkhani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2001.06081"
  },
  {
    "id": "arXiv:2002.07095",
    "title": "Product Subset Problem : Applications to number theory and cryptography",
    "abstract": "Comments: 18 pages, 2 figures, LaTeX; references added, minor improvements",
    "descriptor": "\nComments: 18 pages, 2 figures, LaTeX; references added, minor improvements\n",
    "authors": [
      "K.A.Draziotis",
      "V. Martidis",
      "S. Tiganourias"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2002.07095"
  },
  {
    "id": "arXiv:2002.11444",
    "title": "Further Geometric and Lyapunov Characterizations of Incrementally Stable  Systems on Finsler Manifolds",
    "abstract": "Further Geometric and Lyapunov Characterizations of Incrementally Stable  Systems on Finsler Manifolds",
    "descriptor": "",
    "authors": [
      "Dongjun Wu",
      "Guangren Duan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2002.11444"
  },
  {
    "id": "arXiv:2009.12293",
    "title": "robosuite: A Modular Simulation Framework and Benchmark for Robot  Learning",
    "abstract": "Comments: For more information, please visit this https URL",
    "descriptor": "\nComments: For more information, please visit this https URL\n",
    "authors": [
      "Yuke Zhu",
      "Josiah Wong",
      "Ajay Mandlekar",
      "Roberto Mart\u00edn-Mart\u00edn",
      "Abhishek Joshi",
      "Soroush Nasiriany",
      "Yifeng Zhu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.12293"
  },
  {
    "id": "arXiv:2010.10596",
    "title": "Counterfactual Explanations and Algorithmic Recourses for Machine  Learning: A Review",
    "abstract": "Comments: 23 pages (8 pages of references)",
    "descriptor": "\nComments: 23 pages (8 pages of references)\n",
    "authors": [
      "Sahil Verma",
      "Varich Boonsanong",
      "Minh Hoang",
      "Keegan E. Hines",
      "John P. Dickerson",
      "Chirag Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.10596"
  },
  {
    "id": "arXiv:2010.11523",
    "title": "Exploring search space trees using an adapted version of Monte Carlo  tree search for combinatorial optimization problems",
    "abstract": "Exploring search space trees using an adapted version of Monte Carlo  tree search for combinatorial optimization problems",
    "descriptor": "",
    "authors": [
      "Jorik Jooken",
      "Pieter Leyman",
      "Tony Wauters",
      "Patrick De Causmaecker"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2010.11523"
  },
  {
    "id": "arXiv:2012.09654",
    "title": "Detection and Prediction of Nutrient Deficiency Stress using  Longitudinal Aerial Imagery",
    "abstract": "Detection and Prediction of Nutrient Deficiency Stress using  Longitudinal Aerial Imagery",
    "descriptor": "",
    "authors": [
      "Saba Dadsetan",
      "Gisele Rose",
      "Naira Hovakimyan",
      "Jennifer Hobbs"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2012.09654"
  },
  {
    "id": "arXiv:2012.12546",
    "title": "Manifold Reconstruction and Denoising from Scattered Data in High  Dimension via a Generalization of $L_1$-Median",
    "abstract": "Manifold Reconstruction and Denoising from Scattered Data in High  Dimension via a Generalization of $L_1$-Median",
    "descriptor": "",
    "authors": [
      "Shira Faigenbaum-Golovin",
      "David Levin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2012.12546"
  },
  {
    "id": "arXiv:2102.09708",
    "title": "Back Translation Survey for Improving Text Augmentation",
    "abstract": "Comments: 18 Pages, 10 Figures, 4 Tables, 37 References",
    "descriptor": "\nComments: 18 Pages, 10 Figures, 4 Tables, 37 References\n",
    "authors": [
      "Matthew Ciolino",
      "David Noever",
      "Josh Kalin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2102.09708"
  },
  {
    "id": "arXiv:2103.10502",
    "title": "Ano-Graph: Learning Normal Scene Contextual Graphs to Detect Video  Anomalies",
    "abstract": "Comments: Inconsistencies in the results",
    "descriptor": "\nComments: Inconsistencies in the results\n",
    "authors": [
      "Masoud Pourreza",
      "Mohammadreza Salehi",
      "Mohammad Sabokrou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.10502"
  },
  {
    "id": "arXiv:2104.10249",
    "title": "Superpixels and Graph Convolutional Neural Networks for Efficient  Detection of Nutrient Deficiency Stress from Aerial Imagery",
    "abstract": "Superpixels and Graph Convolutional Neural Networks for Efficient  Detection of Nutrient Deficiency Stress from Aerial Imagery",
    "descriptor": "",
    "authors": [
      "Saba Dadsetan",
      "David Pichler",
      "David Wilson",
      "Naira Hovakimyan",
      "Jennifer Hobbs"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.10249"
  },
  {
    "id": "arXiv:2104.11270",
    "title": "Evolutionary game model of group choice dilemmas on hypergraphs",
    "abstract": "Comments: Main text (4 pages, 2 figures) and Supplemental Material (8 pages, 3 figures, 1 table)",
    "descriptor": "\nComments: Main text (4 pages, 2 figures) and Supplemental Material (8 pages, 3 figures, 1 table)\n",
    "authors": [
      "Andrea Civilini",
      "Nejat Anbarci",
      "Vito Latora"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2104.11270"
  },
  {
    "id": "arXiv:2105.02344",
    "title": "Policy Learning with Adaptively Collected Data",
    "abstract": "Comments: Improved the upper bound; added simulations",
    "descriptor": "\nComments: Improved the upper bound; added simulations\n",
    "authors": [
      "Ruohan Zhan",
      "Zhimei Ren",
      "Susan Athey",
      "Zhengyuan Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2105.02344"
  },
  {
    "id": "arXiv:2105.05516",
    "title": "Object-Based Augmentation Improves Quality of Remote Sensing Semantic  Segmentation",
    "abstract": "Object-Based Augmentation Improves Quality of Remote Sensing Semantic  Segmentation",
    "descriptor": "",
    "authors": [
      "Svetlana Illarionova",
      "Sergey Nesteruk",
      "Dmitrii Shadrin",
      "Vladimir Ignatiev",
      "Mariia Pukalchik",
      "Ivan Oseledets"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.05516"
  },
  {
    "id": "arXiv:2106.01489",
    "title": "Not All Knowledge Is Created Equal: Mutual Distillation of Confident  Knowledge",
    "abstract": "Comments: NeurIPS 2022 Workshop(Trustworthy and Socially Responsible Machine Learning) paper",
    "descriptor": "\nComments: NeurIPS 2022 Workshop(Trustworthy and Socially Responsible Machine Learning) paper\n",
    "authors": [
      "Ziyun Li",
      "Xinshao Wang",
      "Di Hu",
      "Neil M. Robertson",
      "David A. Clifton",
      "Christoph Meinel",
      "Haojin Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.01489"
  },
  {
    "id": "arXiv:2106.05250",
    "title": "The zero-rate threshold for adversarial bit-deletions is less than 1/2",
    "abstract": "Comments: 36 pages",
    "descriptor": "\nComments: 36 pages\n",
    "authors": [
      "Venkatesan Guruswami",
      "Xiaoyu He",
      "Ray Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2106.05250"
  },
  {
    "id": "arXiv:2107.02168",
    "title": "DPPIN: A Biological Repository of Dynamic Protein-Protein Interaction  Network Data",
    "abstract": "DPPIN: A Biological Repository of Dynamic Protein-Protein Interaction  Network Data",
    "descriptor": "",
    "authors": [
      "Dongqi Fu",
      "Jingrui He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.02168"
  },
  {
    "id": "arXiv:2107.04057",
    "title": "Machine Learning for Stuttering Identification: Review, Challenges and  Future Directions",
    "abstract": "Comments: Accepted in Journal of Neurocomputing 2022 this https URL",
    "descriptor": "\nComments: Accepted in Journal of Neurocomputing 2022 this https URL\n",
    "authors": [
      "Shakeel Ahmad Sheikh",
      "Md Sahidullah",
      "Fabrice Hirsch",
      "Slim Ouni"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.04057"
  },
  {
    "id": "arXiv:2107.05200",
    "title": "A Splitting Scheme for Flip-Free Distortion Energies",
    "abstract": "Comments: For supplemental material, see odedstein.com/projects/flip-free-parametrization",
    "descriptor": "\nComments: For supplemental material, see odedstein.com/projects/flip-free-parametrization\n",
    "authors": [
      "Oded Stein",
      "Jiajin Li",
      "Justin Solomon"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2107.05200"
  },
  {
    "id": "arXiv:2107.05853",
    "title": "Making Auctions Robust to Aftermarkets",
    "abstract": "Making Auctions Robust to Aftermarkets",
    "descriptor": "",
    "authors": [
      "Moshe Babaioff",
      "Nicole Immorlica",
      "Yingkai Li",
      "Brendan Lucier"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2107.05853"
  },
  {
    "id": "arXiv:2108.00731",
    "title": "Consistent Approximation of Interpolating Splines in Image Metamorphosis",
    "abstract": "Comments: 35 pages, 8 figures; This publication is an extended version of the previous conference proceeding presented at SSVM 2021",
    "descriptor": "\nComments: 35 pages, 8 figures; This publication is an extended version of the previous conference proceeding presented at SSVM 2021\n",
    "authors": [
      "Jorge Justiniano",
      "Marko Rajkovi\u0107",
      "Martin Rumpf"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.00731"
  },
  {
    "id": "arXiv:2108.01852",
    "title": "Semi-supervised Conditional GAN for Simultaneous Generation and  Detection of Phishing URLs: A Game theoretic Perspective",
    "abstract": "Comments: 5 Pages, 4 figures, 2 tables",
    "descriptor": "\nComments: 5 Pages, 4 figures, 2 tables\n",
    "authors": [
      "Sharif Amit Kamran",
      "Shamik Sengupta",
      "Alireza Tavakkoli"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2108.01852"
  },
  {
    "id": "arXiv:2109.02183",
    "title": "Towards high-accuracy deep learning inference of compressible turbulent  flows over aerofoils",
    "abstract": "Towards high-accuracy deep learning inference of compressible turbulent  flows over aerofoils",
    "descriptor": "",
    "authors": [
      "Li-Wei Chen",
      "Nils Thuerey"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.02183"
  },
  {
    "id": "arXiv:2109.03975",
    "title": "Membership Inference Attacks Against Temporally Correlated Data in Deep  Reinforcement Learning",
    "abstract": "Membership Inference Attacks Against Temporally Correlated Data in Deep  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Maziar Gomrokchi",
      "Susan Amin",
      "Hossein Aboutalebi",
      "Alexander Wong",
      "Doina Precup"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.03975"
  },
  {
    "id": "arXiv:2109.13855",
    "title": "Actionable Entities Recognition Benchmark for Interactive Fiction",
    "abstract": "Actionable Entities Recognition Benchmark for Interactive Fiction",
    "descriptor": "",
    "authors": [
      "Alexey Tikhonov",
      "Ivan P. Yamshchikov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2109.13855"
  },
  {
    "id": "arXiv:2110.02605",
    "title": "Computational lower bounds of the Maxwell eigenvalues",
    "abstract": "Computational lower bounds of the Maxwell eigenvalues",
    "descriptor": "",
    "authors": [
      "Dietmar Gallistl",
      "Vladislav Olkhovskiy"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.02605"
  },
  {
    "id": "arXiv:2110.06786",
    "title": "Optical Flow Reusing for High-Efficiency Space-Time Video Super  Resolution",
    "abstract": "Comments: new submit",
    "descriptor": "\nComments: new submit\n",
    "authors": [
      "Yuantong Zhang",
      "Huairui Wang",
      "Han Zhu",
      "Zhenzhong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.06786"
  },
  {
    "id": "arXiv:2110.07933",
    "title": "Relation Preserving Triplet Mining for Stabilising the Triplet Loss in  Re-identification Systems",
    "abstract": "Comments: WACV 2023",
    "descriptor": "\nComments: WACV 2023\n",
    "authors": [
      "Adhiraj Ghosh",
      "Kuruparan Shanmugalingam",
      "Wen-Yan Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.07933"
  },
  {
    "id": "arXiv:2110.11511",
    "title": "Energy-conserving explicit and implicit time integration methods for the  multi-dimensional Hermite-DG discretization of the Vlasov-Maxwell equations",
    "abstract": "Energy-conserving explicit and implicit time integration methods for the  multi-dimensional Hermite-DG discretization of the Vlasov-Maxwell equations",
    "descriptor": "",
    "authors": [
      "Cecilia Pagliantini",
      "Gianmarco Manzini",
      "Oleksandr Koshkarov",
      "Gian Luca Delzanno",
      "Vadim Roytershteyn"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2110.11511"
  },
  {
    "id": "arXiv:2111.04964",
    "title": "On Representation Knowledge Distillation for Graph Neural Networks",
    "abstract": "Comments: Accepted to IEEE Transactions on Neural Networks and Learning Representation (TNNLS)",
    "descriptor": "\nComments: Accepted to IEEE Transactions on Neural Networks and Learning Representation (TNNLS)\n",
    "authors": [
      "Chaitanya K. Joshi",
      "Fayao Liu",
      "Xu Xun",
      "Jie Lin",
      "Chuan-Sheng Foo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.04964"
  },
  {
    "id": "arXiv:2111.05062",
    "title": "Look back, look around: a systematic analysis of effective predictors  for new outlinks in focused Web crawling",
    "abstract": "Comments: 23 pages, 15 figures, 4 tables, uses arxiv.sty, added new title, heuristic features and their results added, figures 7, 14, and 15 updated, accepted version",
    "descriptor": "\nComments: 23 pages, 15 figures, 4 tables, uses arxiv.sty, added new title, heuristic features and their results added, figures 7, 14, and 15 updated, accepted version\n",
    "authors": [
      "Thi Kim Nhung Dang",
      "Doina Bucur",
      "Berk Atil",
      "Guillaume Pitel",
      "Frank Ruis",
      "Hamidreza Kadkhodaei",
      "Nelly Litvak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.05062"
  },
  {
    "id": "arXiv:2111.07829",
    "title": "Hybrid transforms of constructible functions",
    "abstract": "Comments: 44 pages. Some sections are clarified and proofs simplified following the reviews. We thank anonymous referees for their suggestions",
    "descriptor": "\nComments: 44 pages. Some sections are clarified and proofs simplified following the reviews. We thank anonymous referees for their suggestions\n",
    "authors": [
      "Vadim Lebovici"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2111.07829"
  },
  {
    "id": "arXiv:2111.08374",
    "title": "Literature-Augmented Clinical Outcome Prediction",
    "abstract": "Comments: Published at Findings of NAACL 2022. Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 16 pages. Code available at: this https URL",
    "descriptor": "\nComments: Published at Findings of NAACL 2022. Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 16 pages. Code available at: this https URL\n",
    "authors": [
      "Aakanksha Naik",
      "Sravanthi Parasa",
      "Sergey Feldman",
      "Lucy Lu Wang",
      "Tom Hope"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.08374"
  },
  {
    "id": "arXiv:2111.09159",
    "title": "Aggressive Q-Learning with Ensembles: Achieving Both High Sample  Efficiency and High Asymptotic Performance",
    "abstract": "Aggressive Q-Learning with Ensembles: Achieving Both High Sample  Efficiency and High Asymptotic Performance",
    "descriptor": "",
    "authors": [
      "Yanqiu Wu",
      "Xinyue Chen",
      "Che Wang",
      "Yiming Zhang",
      "Keith W. Ross"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.09159"
  },
  {
    "id": "arXiv:2112.00905",
    "title": "HelixMO: Sample-Efficient Molecular Optimization in Scene-Sensitive  Latent Space",
    "abstract": "HelixMO: Sample-Efficient Molecular Optimization in Scene-Sensitive  Latent Space",
    "descriptor": "",
    "authors": [
      "Zhiyuan Chen",
      "Xiaomin Fang",
      "Zixu Hua",
      "Yueyang Huang",
      "Fan Wang",
      "Hua Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2112.00905"
  },
  {
    "id": "arXiv:2112.05856",
    "title": "An Adaptive Bounded-Confidence Model of Opinion Dynamics on Networks",
    "abstract": "Comments: submitted to Journal of Complex Networks; revised version",
    "descriptor": "\nComments: submitted to Journal of Complex Networks; revised version\n",
    "authors": [
      "Unchitta Kan",
      "Michelle Feng",
      "Mason A. Porter"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2112.05856"
  },
  {
    "id": "arXiv:2112.06044",
    "title": "Achieving Low Complexity Neural Decoders via Iterative Pruning",
    "abstract": "Comments: Machine Learning For Systems Workshop at NeurIPS 2021",
    "descriptor": "\nComments: Machine Learning For Systems Workshop at NeurIPS 2021\n",
    "authors": [
      "Vikrant Malik",
      "Rohan Ghosh",
      "Mehul Motani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.06044"
  },
  {
    "id": "arXiv:2112.11723",
    "title": "Energy-Efficient Massive MIMO for Federated Learning: Transmission  Designs and Resource Allocations",
    "abstract": "Comments: accepted to appear",
    "descriptor": "\nComments: accepted to appear\n",
    "authors": [
      "Tung T. Vu",
      "Hien Q. Ngo",
      "Minh N. Dao",
      "Duy T. Ngo",
      "Erik G. Larsson",
      "Tho Le-Ngoc"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.11723"
  },
  {
    "id": "arXiv:2112.12284",
    "title": "A Survey on Perceptually Optimized Video Coding",
    "abstract": "Comments: 36 pages, 12 figures, 6 tables, accepted by ACM Computing Surveys",
    "descriptor": "\nComments: 36 pages, 12 figures, 6 tables, accepted by ACM Computing Surveys\n",
    "authors": [
      "Yun Zhang",
      "Linwei Zhu",
      "Gangyi Jiang",
      "Sam Kwong",
      "C.-C.Jay Kuo"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2112.12284"
  },
  {
    "id": "arXiv:2112.14126",
    "title": "Implicit relaxed all Mach number schemes for gases and compressible  materials",
    "abstract": "Implicit relaxed all Mach number schemes for gases and compressible  materials",
    "descriptor": "",
    "authors": [
      "Andrea Thomann",
      "Angelo Iollo",
      "Gabriella Puppo"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.14126"
  },
  {
    "id": "arXiv:2201.04583",
    "title": "VoxSRC 2021: The Third VoxCeleb Speaker Recognition Challenge",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2012.06867",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2012.06867\n",
    "authors": [
      "Andrew Brown",
      "Jaesung Huh",
      "Joon Son Chung",
      "Arsha Nagrani",
      "Daniel Garcia-Romero",
      "Andrew Zisserman"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2201.04583"
  },
  {
    "id": "arXiv:2201.04599",
    "title": "Towards a Catalog of Composite Refactorings",
    "abstract": "Towards a Catalog of Composite Refactorings",
    "descriptor": "",
    "authors": [
      "Aline Brito",
      "Andre Hora",
      "Marco Tulio Valente"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2201.04599"
  },
  {
    "id": "arXiv:2201.12052",
    "title": "Improved Overparametrization Bounds for Global Convergence of Stochastic  Gradient Descent for Shallow Neural Networks",
    "abstract": "Improved Overparametrization Bounds for Global Convergence of Stochastic  Gradient Descent for Shallow Neural Networks",
    "descriptor": "",
    "authors": [
      "Bart\u0142omiej Polaczyk",
      "Jacek Cyranka"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.12052"
  },
  {
    "id": "arXiv:2201.12191",
    "title": "Kernelized Concept Erasure",
    "abstract": "Comments: Accepted as a long paper in EMNLP22",
    "descriptor": "\nComments: Accepted as a long paper in EMNLP22\n",
    "authors": [
      "Shauli Ravfogel",
      "Francisco Vargas",
      "Yoav Goldberg",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.12191"
  },
  {
    "id": "arXiv:2202.00756",
    "title": "Ranging-Based Localizability Optimization for Mobile Robotic Networks",
    "abstract": "Comments: 19 pages, 16 figures, version 2",
    "descriptor": "\nComments: 19 pages, 16 figures, version 2\n",
    "authors": [
      "Justin Cano",
      "Jerome Le Ny"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.00756"
  },
  {
    "id": "arXiv:2202.01511",
    "title": "Challenging Common Assumptions in Convex Reinforcement Learning",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Mirco Mutti",
      "Riccardo De Santi",
      "Piersilvio De Bartolomeis",
      "Marcello Restelli"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01511"
  },
  {
    "id": "arXiv:2202.02414",
    "title": "OMLT: Optimization & Machine Learning Toolkit",
    "abstract": "Comments: 8 pages, 1 figure",
    "descriptor": "\nComments: 8 pages, 1 figure\n",
    "authors": [
      "Francesco Ceccon",
      "Jordan Jalving",
      "Joshua Haddad",
      "Alexander Thebelt",
      "Calvin Tsay",
      "Carl D. Laird",
      "Ruth Misener"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.02414"
  },
  {
    "id": "arXiv:2202.02568",
    "title": "Symmetric Volume Maps: Order-Invariant Volumetric Mesh Correspondence  with Free Boundary",
    "abstract": "Comments: Accepted to ACM Transactions on Graphics. Our code is available at this https URL",
    "descriptor": "\nComments: Accepted to ACM Transactions on Graphics. Our code is available at this https URL\n",
    "authors": [
      "S. Mazdak Abulnaga",
      "Oded Stein",
      "Polina Golland",
      "Justin Solomon"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02568"
  },
  {
    "id": "arXiv:2202.07178",
    "title": "Federated Learning with Sparsified Model Perturbation: Improving  Accuracy under Client-Level Differential Privacy",
    "abstract": "Federated Learning with Sparsified Model Perturbation: Improving  Accuracy under Client-Level Differential Privacy",
    "descriptor": "",
    "authors": [
      "Rui Hu",
      "Yanmin Gong",
      "Yuanxiong Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.07178"
  },
  {
    "id": "arXiv:2203.00054",
    "title": "LISA: Learning Interpretable Skill Abstractions from Language",
    "abstract": "LISA: Learning Interpretable Skill Abstractions from Language",
    "descriptor": "",
    "authors": [
      "Divyansh Garg",
      "Skanda Vaidyanath",
      "Kuno Kim",
      "Jiaming Song",
      "Stefano Ermon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.00054"
  },
  {
    "id": "arXiv:2203.06269",
    "title": "Parameter Inference of Time Series by Delay Embeddings and Learning  Differentiable Operators",
    "abstract": "Parameter Inference of Time Series by Delay Embeddings and Learning  Differentiable Operators",
    "descriptor": "",
    "authors": [
      "Alex Tong Lin",
      "Adrian S. Wong",
      "Robert Martin",
      "Stanley J. Osher",
      "Daniel Eckhardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Systems and Control (eess.SY)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.06269"
  },
  {
    "id": "arXiv:2203.09620",
    "title": "Message recovery attack to NTRU using a lattice independent from the  public key",
    "abstract": "Comments: We added some references and some minor improvements",
    "descriptor": "\nComments: We added some references and some minor improvements\n",
    "authors": [
      "Marios Adamoudis",
      "K. A. Draziotis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2203.09620"
  },
  {
    "id": "arXiv:2203.10989",
    "title": "Hierarchical autoregressive neural networks for statistical systems",
    "abstract": "Comments: 14 pages, 6 figures",
    "descriptor": "\nComments: 14 pages, 6 figures\n",
    "authors": [
      "Piotr Bia\u0142as",
      "Piotr Korcyl",
      "Tomasz Stebel"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Lattice (hep-lat)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.10989"
  },
  {
    "id": "arXiv:2203.11175",
    "title": "Quasilinear-time Computation of Generic Modal Witnesses for Behavioural  Inequivalence",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2105.00669",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2105.00669\n",
    "authors": [
      "Thorsten Wi\u00dfmann",
      "Stefan Milius",
      "Lutz Schr\u00f6der"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2203.11175"
  },
  {
    "id": "arXiv:2204.00331",
    "title": "Using segment-based features of jaw movements to recognize foraging  activities in grazing cattle",
    "abstract": "Comments: Preprint submitted to journal",
    "descriptor": "\nComments: Preprint submitted to journal\n",
    "authors": [
      "Jos\u00e9 O. Chelotti",
      "Sebasti\u00e1n R. Vanrell",
      "Luciano S. Martinez-Rau",
      "Julio R. Galli",
      "Santiago A. Utsumi",
      "Alejandra M. Planisich",
      "Suyai A. Almir\u00f3n",
      "Diego H. Milone",
      "Leonardo L. Giovanini",
      "H. Leonardo Rufiner"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.00331"
  },
  {
    "id": "arXiv:2204.01418",
    "title": "The Cardinal Complexity of Online Ordinal Problems",
    "abstract": "The Cardinal Complexity of Online Ordinal Problems",
    "descriptor": "",
    "authors": [
      "Nick Gravin",
      "Enze Sun",
      "Zhihao Gavin Tang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.01418"
  },
  {
    "id": "arXiv:2204.05574",
    "title": "A Dimension-adaptive Combination Technique for Uncertainty  Quantification",
    "abstract": "Comments: 26 pages, 6 figures",
    "descriptor": "\nComments: 26 pages, 6 figures\n",
    "authors": [
      "Uta Seidler",
      "Michael Griebel"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.05574"
  },
  {
    "id": "arXiv:2204.14198",
    "title": "Flamingo: a Visual Language Model for Few-Shot Learning",
    "abstract": "Comments: 54 pages. In Proceedings of Neural Information Processing Systems (NeurIPS) 2022",
    "descriptor": "\nComments: 54 pages. In Proceedings of Neural Information Processing Systems (NeurIPS) 2022\n",
    "authors": [
      "Jean-Baptiste Alayrac",
      "Jeff Donahue",
      "Pauline Luc",
      "Antoine Miech",
      "Iain Barr",
      "Yana Hasson",
      "Karel Lenc",
      "Arthur Mensch",
      "Katie Millican",
      "Malcolm Reynolds",
      "Roman Ring",
      "Eliza Rutherford",
      "Serkan Cabi",
      "Tengda Han",
      "Zhitao Gong",
      "Sina Samangooei",
      "Marianne Monteiro",
      "Jacob Menick",
      "Sebastian Borgeaud",
      "Andrew Brock",
      "Aida Nematzadeh",
      "Sahand Sharifzadeh",
      "Mikolaj Binkowski",
      "Ricardo Barreira",
      "Oriol Vinyals",
      "Andrew Zisserman",
      "Karen Simonyan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.14198"
  },
  {
    "id": "arXiv:2205.02546",
    "title": "Slotted Aloha with Capture for OWC-based IoT: Finite Block-Length  Performance Analysis",
    "abstract": "Comments: Submitted",
    "descriptor": "\nComments: Submitted\n",
    "authors": [
      "Tijana Devaja",
      "Milica Petkovic",
      "Francisco J. Escribano",
      "Cedomir Stefanovic",
      "Dejan Vukobratovic"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.02546"
  },
  {
    "id": "arXiv:2205.06518",
    "title": "Transmission operators for the non-overlapping Schwarz method for  solving Helmholtz problems in rectangular cavities",
    "abstract": "Comments: 37 pages, 23 figures. Changes with respect to the previous version: i) improved results thanks to the modified variant of the Gram-Schmidt process (discussion adapted accordingly), ii) theoretical comparison of the novel operators in the 1D case, iii) discussion of the spectra of the different iteration operators and iv) typos and inconsistencies in the text",
    "descriptor": "\nComments: 37 pages, 23 figures. Changes with respect to the previous version: i) improved results thanks to the modified variant of the Gram-Schmidt process (discussion adapted accordingly), ii) theoretical comparison of the novel operators in the 1D case, iii) discussion of the spectra of the different iteration operators and iv) typos and inconsistencies in the text\n",
    "authors": [
      "Nicolas Marsic",
      "Christophe Geuzaine",
      "Herbert De Gersem"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.06518"
  },
  {
    "id": "arXiv:2205.06891",
    "title": "Unsupervised Representation Learning for 3D MRI Super Resolution with  Degradation Adaptation",
    "abstract": "Comments: 10 pages, 6 figures",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Jianan Liu",
      "Hao Li",
      "Tao Huang",
      "Euijoon Ahn",
      "Kang Han",
      "Adeel Razi",
      "Wei Xiang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.06891"
  },
  {
    "id": "arXiv:2205.13847",
    "title": "Textural-Perceptual Joint Learning for No-Reference Super-Resolution  Image Quality Assessment",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Yuqing Liu",
      "Qi Jia",
      "Shanshe Wang",
      "Siwei Ma",
      "Wen Gao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.13847"
  },
  {
    "id": "arXiv:2206.01134",
    "title": "Language and Culture Internalisation for Human-Like Autotelic AI",
    "abstract": "Language and Culture Internalisation for Human-Like Autotelic AI",
    "descriptor": "",
    "authors": [
      "C\u00e9dric Colas",
      "Tristan Karch",
      "Cl\u00e9ment Moulin-Frier",
      "Pierre-Yves Oudeyer"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01134"
  },
  {
    "id": "arXiv:2206.01175",
    "title": "Robust Longitudinal Control for Vehicular Autonomous Platoons Using Deep  Reinforcement Learning",
    "abstract": "Robust Longitudinal Control for Vehicular Autonomous Platoons Using Deep  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Armando Alves Neto",
      "Leonardo Amaral Mozelli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01175"
  },
  {
    "id": "arXiv:2206.01204",
    "title": "Siamese Image Modeling for Self-Supervised Vision Representation  Learning",
    "abstract": "Siamese Image Modeling for Self-Supervised Vision Representation  Learning",
    "descriptor": "",
    "authors": [
      "Chenxin Tao",
      "Xizhou Zhu",
      "Weijie Su",
      "Gao Huang",
      "Bin Li",
      "Jie Zhou",
      "Yu Qiao",
      "Xiaogang Wang",
      "Jifeng Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.01204"
  },
  {
    "id": "arXiv:2206.03043",
    "title": "COVIDx CT-3: A Large-scale, Multinational, Open-Source Benchmark Dataset  for Computer-aided COVID-19 Screening from Chest CT Images",
    "abstract": "Comments: 6 pages, MED-NeurIPS 2022 workshop",
    "descriptor": "\nComments: 6 pages, MED-NeurIPS 2022 workshop\n",
    "authors": [
      "Hayden Gunraj",
      "Tia Tuinstra",
      "Alexander Wong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03043"
  },
  {
    "id": "arXiv:2206.03671",
    "title": "COVIDx CXR-3: A Large-Scale, Open-Source Benchmark Dataset of Chest  X-ray Images for Computer-Aided COVID-19 Diagnostics",
    "abstract": "Comments: 5 pages, MED-NeurIPS 2022 workshop",
    "descriptor": "\nComments: 5 pages, MED-NeurIPS 2022 workshop\n",
    "authors": [
      "Maya Pavlova",
      "Tia Tuinstra",
      "Hossein Aboutalebi",
      "Andy Zhao",
      "Hayden Gunraj",
      "Alexander Wong"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.03671"
  },
  {
    "id": "arXiv:2206.08604",
    "title": "An F-shape Click Model for Information Retrieval on Multi-block Mobile  Pages",
    "abstract": "Comments: WSDM 2023",
    "descriptor": "\nComments: WSDM 2023\n",
    "authors": [
      "Lingyue Fu",
      "Jianghao Lin",
      "Weiwen Liu",
      "Ruiming Tang",
      "Weinan Zhang",
      "Rui Zhang",
      "Yong Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.08604"
  },
  {
    "id": "arXiv:2206.09034",
    "title": "Towards Better Selective Classification",
    "abstract": "Towards Better Selective Classification",
    "descriptor": "",
    "authors": [
      "Leo Feng",
      "Mohamed Osama Ahmed",
      "Hossein Hajimirsadeghi",
      "Amir Abdi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09034"
  },
  {
    "id": "arXiv:2206.14349",
    "title": "Fleet-DAgger: Interactive Robot Fleet Learning with Scalable Human  Supervision",
    "abstract": "Comments: CoRL 2022 Oral",
    "descriptor": "\nComments: CoRL 2022 Oral\n",
    "authors": [
      "Ryan Hoque",
      "Lawrence Yunliang Chen",
      "Satvik Sharma",
      "Karthik Dharmarajan",
      "Brijen Thananjeyan",
      "Pieter Abbeel",
      "Ken Goldberg"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14349"
  },
  {
    "id": "arXiv:2206.14486",
    "title": "Beyond neural scaling laws: beating power law scaling via data pruning",
    "abstract": "Comments: Oral @ NeurIPS 2022 (camera ready version)",
    "descriptor": "\nComments: Oral @ NeurIPS 2022 (camera ready version)\n",
    "authors": [
      "Ben Sorscher",
      "Robert Geirhos",
      "Shashank Shekhar",
      "Surya Ganguli",
      "Ari S. Morcos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.14486"
  },
  {
    "id": "arXiv:2207.09233",
    "title": "Reconfigurable Plug-and-play Distributed Model Predictive Control for  Reference Tracking",
    "abstract": "Reconfigurable Plug-and-play Distributed Model Predictive Control for  Reference Tracking",
    "descriptor": "",
    "authors": [
      "Ahmed Aboudonia",
      "Andrea Martinelli",
      "Nicolas Hoischen",
      "John Lygeros"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.09233"
  },
  {
    "id": "arXiv:2207.10771",
    "title": "Reticula: A temporal network and hypergraph analysis software package",
    "abstract": "Reticula: A temporal network and hypergraph analysis software package",
    "descriptor": "",
    "authors": [
      "Arash Badie-Modiri",
      "Mikko Kivel\u00e4"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2207.10771"
  },
  {
    "id": "arXiv:2207.11697",
    "title": "Improving Mandarin Speech Recogntion with Block-augmented Transformer",
    "abstract": "Improving Mandarin Speech Recogntion with Block-augmented Transformer",
    "descriptor": "",
    "authors": [
      "Xiaoming Ren",
      "Huifeng Zhu",
      "Liuwei Wei",
      "Minghui Wu",
      "Jie Hao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.11697"
  },
  {
    "id": "arXiv:2207.12514",
    "title": "Testing of Index-Invariant Properties in the Huge Object Model",
    "abstract": "Comments: 66 pages, substantial changes from previous version, added new lower bound results (Theorem 1.4 and Theorem 1.7)",
    "descriptor": "\nComments: 66 pages, substantial changes from previous version, added new lower bound results (Theorem 1.4 and Theorem 1.7)\n",
    "authors": [
      "Sourav Chakraborty",
      "Eldar Fischer",
      "Arijit Ghosh",
      "Gopinath Mishra",
      "Sayantan Sen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2207.12514"
  },
  {
    "id": "arXiv:2207.13596",
    "title": "Fairness and Randomness in Machine Learning: Statistical Independence  and Relativization",
    "abstract": "Comments: This paper has been presented at the Philosophy of Science meets Machine Learning Conference in T\\\"ubingen in October 2022",
    "descriptor": "\nComments: This paper has been presented at the Philosophy of Science meets Machine Learning Conference in T\\\"ubingen in October 2022\n",
    "authors": [
      "Rabanus Derr",
      "Robert C. Williamson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2207.13596"
  },
  {
    "id": "arXiv:2208.01819",
    "title": "Adversarial Camouflage for Node Injection Attack on Graphs",
    "abstract": "Adversarial Camouflage for Node Injection Attack on Graphs",
    "descriptor": "",
    "authors": [
      "Shuchang Tao",
      "Qi Cao",
      "Huawei Shen",
      "Yunfan Wu",
      "Liang Hou",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.01819"
  },
  {
    "id": "arXiv:2208.03299",
    "title": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
    "abstract": "Atlas: Few-shot Learning with Retrieval Augmented Language Models",
    "descriptor": "",
    "authors": [
      "Gautier Izacard",
      "Patrick Lewis",
      "Maria Lomeli",
      "Lucas Hosseini",
      "Fabio Petroni",
      "Timo Schick",
      "Jane Dwivedi-Yu",
      "Armand Joulin",
      "Sebastian Riedel",
      "Edouard Grave"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.03299"
  },
  {
    "id": "arXiv:2208.11288",
    "title": "Higher-order adaptive methods for exit times of It\u00f4 diffusions",
    "abstract": "Comments: The computational cost results in Theorems 2.8 and 2.11 are improved through using a connection between the SDE and an absorbing-boundary Fokker--Planck equation. Correction of a few typos",
    "descriptor": "\nComments: The computational cost results in Theorems 2.8 and 2.11 are improved through using a connection between the SDE and an absorbing-boundary Fokker--Planck equation. Correction of a few typos\n",
    "authors": [
      "H\u00e5kon Hoel",
      "Sankarasubramanian Ragunathan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2208.11288"
  },
  {
    "id": "arXiv:2208.13049",
    "title": "TrojViT: Trojan Insertion in Vision Transformers",
    "abstract": "Comments: 10 pages, 4 figures, 10 tables",
    "descriptor": "\nComments: 10 pages, 4 figures, 10 tables\n",
    "authors": [
      "Mengxin Zheng",
      "Qian Lou",
      "Lei Jiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.13049"
  },
  {
    "id": "arXiv:2208.14153",
    "title": "Identifying Weight-Variant Latent Causal Models",
    "abstract": "Identifying Weight-Variant Latent Causal Models",
    "descriptor": "",
    "authors": [
      "Yuhang Liu",
      "Zhen Zhang",
      "Dong Gong",
      "Mingming Gong",
      "Biwei Huang",
      "Anton van den Hengel",
      "Kun Zhang",
      "Javen Qinfeng Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.14153"
  },
  {
    "id": "arXiv:2208.14870",
    "title": "A new lattice Boltzmann scheme for linear elastic solids: periodic  problems",
    "abstract": "A new lattice Boltzmann scheme for linear elastic solids: periodic  problems",
    "descriptor": "",
    "authors": [
      "Oliver Boolakee",
      "Martin Geier",
      "Laura De Lorenzis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2208.14870"
  },
  {
    "id": "arXiv:2209.01814",
    "title": "RLIP: Relational Language-Image Pre-training for Human-Object  Interaction Detection",
    "abstract": "Comments: Accepted to NeurIPS 2022 as a Spotlight paper",
    "descriptor": "\nComments: Accepted to NeurIPS 2022 as a Spotlight paper\n",
    "authors": [
      "Hangjie Yuan",
      "Jianwen Jiang",
      "Samuel Albanie",
      "Tao Feng",
      "Ziyuan Huang",
      "Dong Ni",
      "Mingqian Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.01814"
  },
  {
    "id": "arXiv:2209.01847",
    "title": "Conflict-Aware Pseudo Labeling via Optimal Transport for Entity  Alignment",
    "abstract": "Conflict-Aware Pseudo Labeling via Optimal Transport for Entity  Alignment",
    "descriptor": "",
    "authors": [
      "Qijie Ding",
      "Daokun Zhang",
      "Jie Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.01847"
  },
  {
    "id": "arXiv:2209.03102",
    "title": "MSMDFusion: A Gated Multi-Scale LiDAR-Camera Fusion Framework with  Multi-Depth Seeds for 3D Object Detection",
    "abstract": "MSMDFusion: A Gated Multi-Scale LiDAR-Camera Fusion Framework with  Multi-Depth Seeds for 3D Object Detection",
    "descriptor": "",
    "authors": [
      "Yang Jiao",
      "Zequn Jie",
      "Shaoxiang Chen",
      "Jingjing Chen",
      "Lin Ma",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.03102"
  },
  {
    "id": "arXiv:2209.03402",
    "title": "Counting Subgraphs in Somewhere Dense Graphs",
    "abstract": "Comments: 35 pages, 3 figures, 4 tables, abstract shortened due to ArXiv requirements",
    "descriptor": "\nComments: 35 pages, 3 figures, 4 tables, abstract shortened due to ArXiv requirements\n",
    "authors": [
      "Marco Bressan",
      "Leslie Ann Goldberg",
      "Kitty Meeks",
      "Marc Roth"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2209.03402"
  },
  {
    "id": "arXiv:2209.04049",
    "title": "Dr. Neurosymbolic, or: How I Learned to Stop Worrying and Accept  Statistics",
    "abstract": "Comments: 12 pages of main contents, 29 pages in total. It could also serve as an accompanying material for Latplan paper. (arXiv:2107.00110) v2: rewrote the general ELBO derivation without Prolog. v3: significantly extended the Bayesian reasoning section in the appendix, with several proofs for conjugate priors",
    "descriptor": "\nComments: 12 pages of main contents, 29 pages in total. It could also serve as an accompanying material for Latplan paper. (arXiv:2107.00110) v2: rewrote the general ELBO derivation without Prolog. v3: significantly extended the Bayesian reasoning section in the appendix, with several proofs for conjugate priors\n",
    "authors": [
      "Masataro Asai"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.04049"
  },
  {
    "id": "arXiv:2209.05653",
    "title": "Semantic2Graph: Graph-based Multi-modal Feature Fusion for Action  Segmentation in Videos",
    "abstract": "Comments: 11 pages, 3 figures, 8 tables. This paper was submitted to IEEE",
    "descriptor": "\nComments: 11 pages, 3 figures, 8 tables. This paper was submitted to IEEE\n",
    "authors": [
      "Junbin Zhang",
      "Pei-Hsuan Tsai",
      "Meng-Hsun Tsai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2209.05653"
  },
  {
    "id": "arXiv:2209.06865",
    "title": "Sketch of a novel approach to a neural model",
    "abstract": "Sketch of a novel approach to a neural model",
    "descriptor": "",
    "authors": [
      "Gabriele Scheler"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Molecular Networks (q-bio.MN)"
    ],
    "url": "https://arxiv.org/abs/2209.06865"
  },
  {
    "id": "arXiv:2209.08446",
    "title": "Dual Contrastive Network for Sequential Recommendation with User and  Item-Centric Perspectives",
    "abstract": "Comments: 23 pages",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Guanyu Lin",
      "Chen Gao",
      "Yinfeng Li",
      "Yu Zheng",
      "Zhiheng Li",
      "Depeng Jin",
      "Yong Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2209.08446"
  },
  {
    "id": "arXiv:2209.09475",
    "title": "Revisiting Image Pyramid Structure for High Resolution Salient Object  Detection",
    "abstract": "Comments: 27 pages, 15 figures, 7 tables. To appear in the 16th Asian Conference on Computer Vision (ACCV2022), December 4-8, 2022, Macau SAR, China. DOI will be added soon. Results on DIS5K are added in appendices which will not be in the published version",
    "descriptor": "\nComments: 27 pages, 15 figures, 7 tables. To appear in the 16th Asian Conference on Computer Vision (ACCV2022), December 4-8, 2022, Macau SAR, China. DOI will be added soon. Results on DIS5K are added in appendices which will not be in the published version\n",
    "authors": [
      "Taehun Kim",
      "Kunhee Kim",
      "Joonyeong Lee",
      "Dongmin Cha",
      "Jiho Lee",
      "Daijin Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.09475"
  },
  {
    "id": "arXiv:2209.10052",
    "title": "Adapting Pretrained Text-to-Text Models for Long Text Sequences",
    "abstract": "Adapting Pretrained Text-to-Text Models for Long Text Sequences",
    "descriptor": "",
    "authors": [
      "Wenhan Xiong",
      "Anchit Gupta",
      "Shubham Toshniwal",
      "Yashar Mehdad",
      "Wen-tau Yih"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.10052"
  },
  {
    "id": "arXiv:2209.11799",
    "title": "Emb-GAM: an Interpretable and Efficient Predictor using Pre-trained  Language Models",
    "abstract": "Emb-GAM: an Interpretable and Efficient Predictor using Pre-trained  Language Models",
    "descriptor": "",
    "authors": [
      "Chandan Singh",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2209.11799"
  },
  {
    "id": "arXiv:2209.12221",
    "title": "Hand Hygiene Assessment via Joint Step Segmentation and Key Action  Scorer",
    "abstract": "Hand Hygiene Assessment via Joint Step Segmentation and Key Action  Scorer",
    "descriptor": "",
    "authors": [
      "Chenglong Li",
      "Qiwen Zhu",
      "Tubiao Liu",
      "Jin Tang",
      "Yu Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.12221"
  },
  {
    "id": "arXiv:2209.12573",
    "title": "Digital Audio Forensics: Blind Human Voice Mimicry Detection",
    "abstract": "Comments: 11 pages, 4 figures (6 if you count subfigures), 2 tables",
    "descriptor": "\nComments: 11 pages, 4 figures (6 if you count subfigures), 2 tables\n",
    "authors": [
      "Sahar Al Ajmi",
      "Khizar Hayat",
      "Alaa M. Al Obaidi",
      "Naresh Kumar",
      "Munaf Najmuldeen",
      "Baptiste Magnier"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2209.12573"
  },
  {
    "id": "arXiv:2209.13284",
    "title": "Frame Interpolation for Dynamic Scenes with Implicit Flow Encoding",
    "abstract": "Comments: Accepted to WACV 2023. Project website: this https URL . Code: this https URL . YouTube: this https URL",
    "descriptor": "\nComments: Accepted to WACV 2023. Project website: this https URL . Code: this https URL . YouTube: this https URL\n",
    "authors": [
      "Pedro Figueir\u00eado",
      "Avinash Paliwal",
      "Nima Khademi Kalantari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.13284"
  },
  {
    "id": "arXiv:2209.13404",
    "title": "Polynomial time computable functions over the reals characterized using  discrete ordinary differential equations",
    "abstract": "Polynomial time computable functions over the reals characterized using  discrete ordinary differential equations",
    "descriptor": "",
    "authors": [
      "Manon Blanc",
      "Olivier Bournez"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2209.13404"
  },
  {
    "id": "arXiv:2209.15605",
    "title": "Bias Mimicking: A Simple Sampling Approach for Bias Mitigation",
    "abstract": "Bias Mimicking: A Simple Sampling Approach for Bias Mitigation",
    "descriptor": "",
    "authors": [
      "Maan Qraitem",
      "Kate Saenko",
      "Bryan A. Plummer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.15605"
  },
  {
    "id": "arXiv:2209.15616",
    "title": "Towards Multi-spatiotemporal-scale Generalized PDE Modeling",
    "abstract": "Towards Multi-spatiotemporal-scale Generalized PDE Modeling",
    "descriptor": "",
    "authors": [
      "Jayesh K. Gupta",
      "Johannes Brandstetter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.15616"
  },
  {
    "id": "arXiv:2210.00471",
    "title": "OCD: Learning to Overfit with Conditional Diffusion Models",
    "abstract": "OCD: Learning to Overfit with Conditional Diffusion Models",
    "descriptor": "",
    "authors": [
      "Shahar Lutati",
      "Lior Wolf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00471"
  },
  {
    "id": "arXiv:2210.00486",
    "title": "pMPL: A Robust Multi-Party Learning Framework with a Privileged Party",
    "abstract": "Comments: This paper is the full version of a paper to appear in CCS 2022",
    "descriptor": "\nComments: This paper is the full version of a paper to appear in CCS 2022\n",
    "authors": [
      "Lushan Song",
      "Jiaxuan Wang",
      "Zhexuan Wang",
      "Xinyu Tu",
      "Guopeng Lin",
      "Wenqiang Ruan",
      "Haoqi Wu",
      "Weili Han"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.00486"
  },
  {
    "id": "arXiv:2210.01628",
    "title": "Monte Carlo Tree Search based Variable Selection for High Dimensional  Bayesian Optimization",
    "abstract": "Comments: NeurIPS 2022 accept",
    "descriptor": "\nComments: NeurIPS 2022 accept\n",
    "authors": [
      "Lei Song",
      "Ke Xue",
      "Xiaobin Huang",
      "Chao Qian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.01628"
  },
  {
    "id": "arXiv:2210.02328",
    "title": "Geometric discretization of diffeomorphisms",
    "abstract": "Comments: 15 pages, 5 figures",
    "descriptor": "\nComments: 15 pages, 5 figures\n",
    "authors": [
      "Erik Jansson",
      "Klas Modin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2210.02328"
  },
  {
    "id": "arXiv:2210.03916",
    "title": "Low Error-Rate Approximate Multiplier Design for DNNs with  Hardware-Driven Co-Optimization",
    "abstract": "Comments: ISCAS 2022. 5pages, 1 figure",
    "descriptor": "\nComments: ISCAS 2022. 5pages, 1 figure\n",
    "authors": [
      "Yao Lu",
      "Jide Zhang",
      "Su Zheng",
      "Zhen Li",
      "Lingli Wang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03916"
  },
  {
    "id": "arXiv:2210.06080",
    "title": "Computing Power Network: A Survey",
    "abstract": "Computing Power Network: A Survey",
    "descriptor": "",
    "authors": [
      "Yukun Sun",
      "Bo Lei",
      "Junlin Liu",
      "Haonan Huang",
      "Xing Zhang",
      "Jing Peng",
      "Wenbo Wang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.06080"
  },
  {
    "id": "arXiv:2210.06592",
    "title": "Can Calibration Improve Sample Prioritization?",
    "abstract": "Can Calibration Improve Sample Prioritization?",
    "descriptor": "",
    "authors": [
      "Ganesh Tata",
      "Gautham Krishna Gudur",
      "Gopinath Chennupati",
      "Mohammad Emtiyaz Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.06592"
  },
  {
    "id": "arXiv:2210.06971",
    "title": "Reliable quantum kernel classification using fewer circuit evaluations",
    "abstract": "Comments: 18 pages, 6 figs, 4 tables (main + supplementary information)",
    "descriptor": "\nComments: 18 pages, 6 figs, 4 tables (main + supplementary information)\n",
    "authors": [
      "Abhay Shastry",
      "Abhijith J",
      "Apoorva Patel",
      "Chiranjib Bhattacharyya"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.06971"
  },
  {
    "id": "arXiv:2210.08220",
    "title": "Min max method, shape, topological derivatives, averaged Lagrangian,  homogenization, two scale convergence, Helmholtz equation",
    "abstract": "Min max method, shape, topological derivatives, averaged Lagrangian,  homogenization, two scale convergence, Helmholtz equation",
    "descriptor": "",
    "authors": [
      "Mame Gor Ngom",
      "Ibrahima Faye",
      "Diaraf Seck"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.08220"
  },
  {
    "id": "arXiv:2210.08773",
    "title": "Plug-and-Play VQA: Zero-shot VQA by Conjoining Large Pretrained Models  with Zero Training",
    "abstract": "Comments: EMNLP 2022 (Findings)",
    "descriptor": "\nComments: EMNLP 2022 (Findings)\n",
    "authors": [
      "Anthony Meng Huat Tiong",
      "Junnan Li",
      "Boyang Li",
      "Silvio Savarese",
      "Steven C.H. Hoi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08773"
  },
  {
    "id": "arXiv:2210.09524",
    "title": "SVLDL: Improved Speaker Age Estimation Using Selective Variance Label  Distribution Learning",
    "abstract": "Comments: Accepted by SLT 2022. The 2022 IEEE Spoken Language Technology Workshop (SLT 2022)",
    "descriptor": "\nComments: Accepted by SLT 2022. The 2022 IEEE Spoken Language Technology Workshop (SLT 2022)\n",
    "authors": [
      "Zuheng Kang",
      "Jianzong Wang",
      "Junqing Peng",
      "Jing Xiao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.09524"
  },
  {
    "id": "arXiv:2210.09958",
    "title": "Layer-wise Relevance Propagation for Echo State Networks applied to  Earth System Variability",
    "abstract": "Comments: Shortened title, corrected author affiliation, added citation reference: Accepted at 3rd International Conference on Machine Learning Techniques (MLTEC 2022), Zurich, Switzerland",
    "descriptor": "\nComments: Shortened title, corrected author affiliation, added citation reference: Accepted at 3rd International Conference on Machine Learning Techniques (MLTEC 2022), Zurich, Switzerland\n",
    "authors": [
      "Marco Landt-Hayen",
      "Peer Kr\u00f6ger",
      "Martin Claus",
      "Willi Rath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.09958"
  },
  {
    "id": "arXiv:2210.10031",
    "title": "Understanding COVID-19 Vaccine Campaign on Facebook using Minimal  Supervision",
    "abstract": "Comments: Accepted as a regular paper at 2022 IEEE International Conference on Big Data (IEEE BigData 2022). Also accepted at the NLP for Positive Impact (NLP4PI) workshop@EMNLP 2022",
    "descriptor": "\nComments: Accepted as a regular paper at 2022 IEEE International Conference on Big Data (IEEE BigData 2022). Also accepted at the NLP for Positive Impact (NLP4PI) workshop@EMNLP 2022\n",
    "authors": [
      "Tunazzina Islam",
      "Dan Goldwasser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.10031"
  },
  {
    "id": "arXiv:2210.11399",
    "title": "Transcending Scaling Laws with 0.1% Extra Compute",
    "abstract": "Comments: V2 has updated references/related work",
    "descriptor": "\nComments: V2 has updated references/related work\n",
    "authors": [
      "Yi Tay",
      "Jason Wei",
      "Hyung Won Chung",
      "Vinh Q. Tran",
      "David R. So",
      "Siamak Shakeri",
      "Xavier Garcia",
      "Huaixiu Steven Zheng",
      "Jinfeng Rao",
      "Aakanksha Chowdhery",
      "Denny Zhou",
      "Donald Metzler",
      "Slav Petrov",
      "Neil Houlsby",
      "Quoc V. Le",
      "Mostafa Dehghani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11399"
  },
  {
    "id": "arXiv:2210.11416",
    "title": "Scaling Instruction-Finetuned Language Models",
    "abstract": "Comments: Public checkpoints: this https URL",
    "descriptor": "\nComments: Public checkpoints: this https URL\n",
    "authors": [
      "Hyung Won Chung",
      "Le Hou",
      "Shayne Longpre",
      "Barret Zoph",
      "Yi Tay",
      "William Fedus",
      "Yunxuan Li",
      "Xuezhi Wang",
      "Mostafa Dehghani",
      "Siddhartha Brahma",
      "Albert Webson",
      "Shixiang Shane Gu",
      "Zhuyun Dai",
      "Mirac Suzgun",
      "Xinyun Chen",
      "Aakanksha Chowdhery",
      "Sharan Narang",
      "Gaurav Mishra",
      "Adams Yu",
      "Vincent Zhao",
      "Yanping Huang",
      "Andrew Dai",
      "Hongkun Yu",
      "Slav Petrov",
      "Ed H. Chi",
      "Jeff Dean",
      "Jacob Devlin",
      "Adam Roberts",
      "Denny Zhou",
      "Quoc V. Le",
      "Jason Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11416"
  },
  {
    "id": "arXiv:2210.11948",
    "title": "lo-fi: distributed fine-tuning without communication",
    "abstract": "lo-fi: distributed fine-tuning without communication",
    "descriptor": "",
    "authors": [
      "Mitchell Wortsman",
      "Suchin Gururangan",
      "Shen Li",
      "Ali Farhadi",
      "Ludwig Schmidt",
      "Michael Rabbat",
      "Ari S. Morcos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11948"
  },
  {
    "id": "arXiv:2210.12353",
    "title": "Leveraging Large Language Models for Multiple Choice Question Answering",
    "abstract": "Leveraging Large Language Models for Multiple Choice Question Answering",
    "descriptor": "",
    "authors": [
      "Joshua Robinson",
      "Christopher Michael Rytting",
      "David Wingate"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.12353"
  },
  {
    "id": "arXiv:2210.12391",
    "title": "MasakhaNER 2.0: Africa-centric Transfer Learning for Named Entity  Recognition",
    "abstract": "Comments: Accepted to EMNLP 2022 (updated Github link)",
    "descriptor": "\nComments: Accepted to EMNLP 2022 (updated Github link)\n",
    "authors": [
      "David Ifeoluwa Adelani",
      "Graham Neubig",
      "Sebastian Ruder",
      "Shruti Rijhwani",
      "Michael Beukman",
      "Chester Palen-Michel",
      "Constantine Lignos",
      "Jesujoba O. Alabi",
      "Shamsuddeen H. Muhammad",
      "Peter Nabende",
      "Cheikh M. Bamba Dione",
      "Andiswa Bukula",
      "Rooweither Mabuya",
      "Bonaventure F. P. Dossou",
      "Blessing Sibanda",
      "Happy Buzaaba",
      "Jonathan Mukiibi",
      "Godson Kalipe",
      "Derguene Mbaye",
      "Amelia Taylor",
      "Fatoumata Kabore",
      "Chris Chinenye Emezue",
      "Anuoluwapo Aremu",
      "Perez Ogayo",
      "Catherine Gitau",
      "Edwin Munkoh-Buabeng",
      "Victoire M. Koagne",
      "Allahsera Auguste Tapo",
      "Tebogo Macucwa",
      "Vukosi Marivate",
      "Elvis Mboning",
      "Tajuddeen Gwadabe",
      "Tosin Adewumi",
      "Orevaoghene Ahia",
      "Joyce Nakatumba-Nabende",
      "Neo L. Mokono",
      "Ignatius Ezeani",
      "Chiamaka Chukwuneke",
      "Mofetoluwa Adeyemi",
      "Gilles Q. Hacheme",
      "Idris Abdulmumin",
      "Odunayo Ogundepo",
      "Oreen Yousuf",
      "Tatiana Moteu Ngoli"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.12391"
  },
  {
    "id": "arXiv:2210.13801",
    "title": "Deep Boosting Robustness of DNN-based Image Watermarking via DBMark",
    "abstract": "Deep Boosting Robustness of DNN-based Image Watermarking via DBMark",
    "descriptor": "",
    "authors": [
      "Guanhui Ye",
      "Jiashi Gao",
      "Wei Xie",
      "Bo Yin",
      "Xuetao Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.13801"
  },
  {
    "id": "arXiv:2210.13952",
    "title": "KnowGL: Knowledge Generation and Linking from Text",
    "abstract": "Comments: AAAI-23 Demo Track",
    "descriptor": "\nComments: AAAI-23 Demo Track\n",
    "authors": [
      "Gaetano Rossiello",
      "Md. Mahbub Faisal Chowdhury",
      "Nandana Mihindukulasooriya",
      "Owen Cornec",
      "Alfio Massimiliano Gliozzo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.13952"
  },
  {
    "id": "arXiv:2210.14152",
    "title": "SleepMore: Inferring Sleep Duration at Scale via Multi-Device WiFi  Sensing",
    "abstract": "Comments: 32 pages, 24 figures, 14 tables",
    "descriptor": "\nComments: 32 pages, 24 figures, 14 tables\n",
    "authors": [
      "Camellia Zakaria",
      "Gizem Yilmaz",
      "Priyanka Mammen",
      "Michael Chee",
      "Prashant Shenoy",
      "Rajesh Balan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.14152"
  },
  {
    "id": "arXiv:2210.14449",
    "title": "Modeling of dendritic solidification and numerical analysis of the  phase-field approach to model complex morphologies in alloys",
    "abstract": "Comments: manuscript under review; 10 figures; 3 tables; updated figure caption and added clarifications to certain section",
    "descriptor": "\nComments: manuscript under review; 10 figures; 3 tables; updated figure caption and added clarifications to certain section\n",
    "authors": [
      "Kunal Bhagat",
      "Shiva Rudraraju"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.14449"
  },
  {
    "id": "arXiv:2210.15509",
    "title": "On Tsirelson pairs of C*-algebras",
    "abstract": "Comments: 13 pages; version 3; a slight redefinition of Tsirelson pair was needed to fix one of the propositions",
    "descriptor": "\nComments: 13 pages; version 3; a slight redefinition of Tsirelson pair was needed to fix one of the propositions\n",
    "authors": [
      "Isaac Goldbring",
      "Bradd Hart"
    ],
    "subjectives": [
      "Operator Algebras (math.OA)",
      "Computational Complexity (cs.CC)",
      "Logic (math.LO)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.15509"
  },
  {
    "id": "arXiv:2210.16156",
    "title": "Reliability of CKA as a Similarity Measure in Deep Learning",
    "abstract": "Reliability of CKA as a Similarity Measure in Deep Learning",
    "descriptor": "",
    "authors": [
      "MohammadReza Davari",
      "Stefan Horoi",
      "Amine Natik",
      "Guillaume Lajoie",
      "Guy Wolf",
      "Eugene Belilovsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.16156"
  },
  {
    "id": "arXiv:2210.16160",
    "title": "Some Remarks on Counting Propositional Logic",
    "abstract": "Comments: joint work with Ugo Dal Lago and Paolo Pistone",
    "descriptor": "\nComments: joint work with Ugo Dal Lago and Paolo Pistone\n",
    "authors": [
      "Melissa Antonelli"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.16160"
  },
  {
    "id": "arXiv:2210.17367",
    "title": "Analysis and Detection of Singing Techniques in Repertoires of J-POP  Solo Singers",
    "abstract": "Comments: Accepted at ISMIR 2022, appendix website: this https URL",
    "descriptor": "\nComments: Accepted at ISMIR 2022, appendix website: this https URL\n",
    "authors": [
      "Yuya Yamamoto",
      "Juhan Nam",
      "Hiroko Terasawa"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Digital Libraries (cs.DL)",
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.17367"
  },
  {
    "id": "arXiv:2211.00201",
    "title": "CCS Explorer: Relevance Prediction, Extractive Summarization, and Named  Entity Recognition from Clinical Cohort Studies",
    "abstract": "Comments: Accepted at IEEE BigData 2022",
    "descriptor": "\nComments: Accepted at IEEE BigData 2022\n",
    "authors": [
      "Irfan Al-Hussaini",
      "Davi Nakajima An",
      "Albert J. Lee",
      "Sarah Bi",
      "Cassie S. Mitchell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00201"
  },
  {
    "id": "arXiv:2211.00611",
    "title": "MedSegDiff: Medical Image Segmentation with Diffusion Probabilistic  Model",
    "abstract": "MedSegDiff: Medical Image Segmentation with Diffusion Probabilistic  Model",
    "descriptor": "",
    "authors": [
      "Junde Wu",
      "Huihui Fang",
      "Yu Zhang",
      "Yehui Yang",
      "Yanwu Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00611"
  },
  {
    "id": "arXiv:2211.01830",
    "title": "Ranking-based Group Identification via Factorized Attention on Social  Tripartite Graph",
    "abstract": "Comments: 9 pages. Accepted by WSDM'23. Github: this https URL",
    "descriptor": "\nComments: 9 pages. Accepted by WSDM'23. Github: this https URL\n",
    "authors": [
      "Mingdai Yang",
      "Zhiwei Liu",
      "Liangwei Yang",
      "Xiaolong Liu",
      "Chen Wang",
      "Hao Peng",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01830"
  },
  {
    "id": "arXiv:2211.02048",
    "title": "Efficient Spatially Sparse Inference for Conditional GANs and Diffusion  Models",
    "abstract": "Comments: NeurIPS 2022 Website: this https URL Code: this https URL",
    "descriptor": "\nComments: NeurIPS 2022 Website: this https URL Code: this https URL\n",
    "authors": [
      "Muyang Li",
      "Ji Lin",
      "Chenlin Meng",
      "Stefano Ermon",
      "Song Han",
      "Jun-Yan Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02048"
  },
  {
    "id": "arXiv:2211.03037",
    "title": "Knowledge Retrieval using Functional Object-Oriented Network",
    "abstract": "Knowledge Retrieval using Functional Object-Oriented Network",
    "descriptor": "",
    "authors": [
      "Naseem Shaik"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.03037"
  },
  {
    "id": "arXiv:2211.03418",
    "title": "QRF: Implicit Neural Representations with Quantum Radiance Fields",
    "abstract": "QRF: Implicit Neural Representations with Quantum Radiance Fields",
    "descriptor": "",
    "authors": [
      "YuanFu Yang",
      "Min Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.03418"
  },
  {
    "id": "arXiv:2211.03477",
    "title": "Information Properties of a Random Variable Decomposition through  Lattices",
    "abstract": "Comments: 11 pages, 6 figures. v2: improved some explanations in sections 2 and 4, typos, and added citation in section 3",
    "descriptor": "\nComments: 11 pages, 6 figures. v2: improved some explanations in sections 2 and 4, typos, and added citation in section 3\n",
    "authors": [
      "F\u00e1bio C. C. Meneghetti",
      "Henrique K. Miyamoto",
      "Sueli I. R. Costa"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.03477"
  },
  {
    "id": "arXiv:2211.04323",
    "title": "Sequential Transformer for End-to-End Person Search",
    "abstract": "Sequential Transformer for End-to-End Person Search",
    "descriptor": "",
    "authors": [
      "Long Chen",
      "Jinhua Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04323"
  },
  {
    "id": "arXiv:2211.04524",
    "title": "Knowledge Retrieval for Robotic Cooking",
    "abstract": "Comments: 3 pages, 1 figure, and 2 tables; modified references",
    "descriptor": "\nComments: 3 pages, 1 figure, and 2 tables; modified references\n",
    "authors": [
      "Kundana Mandapaka"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04524"
  },
  {
    "id": "arXiv:2211.04894",
    "title": "Disentangling Aesthetic and Technical Effects for Video Quality  Assessment of User Generated Content",
    "abstract": "Comments: 19 pages, 18 figures, 20 equation. The with-appendix version",
    "descriptor": "\nComments: 19 pages, 18 figures, 20 equation. The with-appendix version\n",
    "authors": [
      "Haoning Wu",
      "Liang Liao",
      "Chaofeng Chen",
      "Jingwen Hou",
      "Annan Wang",
      "Wenxiu Sun",
      "Qiong Yan",
      "Weisi Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.04894"
  },
  {
    "id": "arXiv:2211.05166",
    "title": "Grammatical Error Correction: A Survey of the State of the Art",
    "abstract": "Grammatical Error Correction: A Survey of the State of the Art",
    "descriptor": "",
    "authors": [
      "Christopher Bryant",
      "Zheng Yuan",
      "Muhammad Reza Qorib",
      "Hannan Cao",
      "Hwee Tou Ng",
      "Ted Briscoe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.05166"
  },
  {
    "id": "arXiv:2211.05448",
    "title": "On the Capacity of \"Beam-Pointing\" Channels with Block Memory and  Feedback: The Binary Case",
    "abstract": "Comments: 7 pages, 2 figures, this paper has been accepted by the 2022 Asilomar Conference on Signals, Systems, and Computers",
    "descriptor": "\nComments: 7 pages, 2 figures, this paper has been accepted by the 2022 Asilomar Conference on Signals, Systems, and Computers\n",
    "authors": [
      "Siyao Li",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.05448"
  },
  {
    "id": "arXiv:2211.05637",
    "title": "Description Graphs, Matrix-Power Stabilizations and Graph Isomorphism in  Polynomial Time",
    "abstract": "Comments: Some examples are supplied as illustrations to the contexts, and a brief suggestion to implementation of SaS process is also given in the appendix",
    "descriptor": "\nComments: Some examples are supplied as illustrations to the contexts, and a brief suggestion to implementation of SaS process is also given in the appendix\n",
    "authors": [
      "Rui Xue"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.05637"
  },
  {
    "id": "arXiv:2211.05719",
    "title": "MMDialog: A Large-scale Multi-turn Dialogue Dataset Towards Multi-modal  Open-domain Conversation",
    "abstract": "MMDialog: A Large-scale Multi-turn Dialogue Dataset Towards Multi-modal  Open-domain Conversation",
    "descriptor": "",
    "authors": [
      "Jiazhan Feng",
      "Qingfeng Sun",
      "Can Xu",
      "Pu Zhao",
      "Yaming Yang",
      "Chongyang Tao",
      "Dongyan Zhao",
      "Qingwei Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.05719"
  },
  {
    "id": "arXiv:2211.05913",
    "title": "Twitter Spam and False Accounts Prevalence, Detection and  Characterization: A Survey",
    "abstract": "Comments: Submitted to First Monday",
    "descriptor": "\nComments: Submitted to First Monday\n",
    "authors": [
      "Emilio Ferrara"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.05913"
  },
  {
    "id": "arXiv:2211.05968",
    "title": "Peeling Sequences",
    "abstract": "Comments: 5 pages, 2 figures",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Adrian Dumitrescu"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.05968"
  },
  {
    "id": "arXiv:2211.06689",
    "title": "TINC: Tree-structured Implicit Neural Compression",
    "abstract": "TINC: Tree-structured Implicit Neural Compression",
    "descriptor": "",
    "authors": [
      "Runzhao Yang",
      "Tingxiong Xiao",
      "Yuxiao Cheng",
      "Jinli Suo",
      "Qionghai Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.06689"
  },
  {
    "id": "arXiv:2211.06747",
    "title": "Formally Verified Samplers From Probabilistic Programs With Loops and  Conditioning",
    "abstract": "Formally Verified Samplers From Probabilistic Programs With Loops and  Conditioning",
    "descriptor": "",
    "authors": [
      "Alexander Bagnall",
      "Gordon Stewart",
      "Anindya Banerjee"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.06747"
  },
  {
    "id": "arXiv:2211.06828",
    "title": "Enhancing Few-shot Image Classification with Cosine Transformer",
    "abstract": "Enhancing Few-shot Image Classification with Cosine Transformer",
    "descriptor": "",
    "authors": [
      "Quang-Huy Nguyen",
      "Cuong Q. Nguyen",
      "Dung D. Le",
      "Hieu H. Pham",
      "Minh N. Do"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.06828"
  },
  {
    "id": "arXiv:2211.07004",
    "title": "Advancing Learned Video Compression with In-loop Frame Prediction",
    "abstract": "Advancing Learned Video Compression with In-loop Frame Prediction",
    "descriptor": "",
    "authors": [
      "Ren Yang",
      "Radu Timofte",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07004"
  },
  {
    "id": "arXiv:2211.07047",
    "title": "Language Model Classifier Aligns Better with Physician Word Sensitivity  than XGBoost on Readmission Prediction",
    "abstract": "Comments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 13 pages",
    "descriptor": "\nComments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 13 pages\n",
    "authors": [
      "Grace Yang",
      "Ming Cao",
      "Lavender Y. Jiang",
      "Xujin C. Liu",
      "Alexander T.M. Cheung",
      "Hannah Weiss",
      "David Kurland",
      "Kyunghyun Cho",
      "Eric K. Oermann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.07047"
  },
  {
    "id": "arXiv:2211.07303",
    "title": "Adaptive Federated Minimax Optimization with Lower complexities",
    "abstract": "Comments: 37 pages. arXiv admin note: substantial text overlap with arXiv:2211.01122; text overlap with arXiv:2211.01883",
    "descriptor": "\nComments: 37 pages. arXiv admin note: substantial text overlap with arXiv:2211.01122; text overlap with arXiv:2211.01883\n",
    "authors": [
      "Feihu Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.07303"
  },
  {
    "id": "arXiv:2211.07447",
    "title": "Deep Autoregressive Regression",
    "abstract": "Deep Autoregressive Regression",
    "descriptor": "",
    "authors": [
      "Adam Khakhar",
      "Jacob Buckman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07447"
  },
  {
    "id": "arXiv:2211.07479",
    "title": "Spreading processes with population heterogeneity over multi-layer  networks",
    "abstract": "Comments: Submitted to ICC 2023",
    "descriptor": "\nComments: Submitted to ICC 2023\n",
    "authors": [
      "Yurun Tian",
      "Osman Yagan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.07479"
  },
  {
    "id": "arXiv:2211.07499",
    "title": "AdaptKeyBERT: An Attention-Based approach towards Few-Shot & Zero-Shot  Domain Adaptation of KeyBERT",
    "abstract": "AdaptKeyBERT: An Attention-Based approach towards Few-Shot & Zero-Shot  Domain Adaptation of KeyBERT",
    "descriptor": "",
    "authors": [
      "Aman Priyanshu",
      "Supriti Vijay"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07499"
  },
  {
    "id": "arXiv:2211.07711",
    "title": "Multilevel Transformer For Multimodal Emotion Recognition",
    "abstract": "Comments: 5 pages, 2 figures, 3 tables. Submitted to ICASSP 2023",
    "descriptor": "\nComments: 5 pages, 2 figures, 3 tables. Submitted to ICASSP 2023\n",
    "authors": [
      "Junyi He",
      "Meimei Wu",
      "Meng Li",
      "Xiaobo Zhu",
      "Feng Ye"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07711"
  },
  {
    "id": "arXiv:2211.07805",
    "title": "Agent-State Construction with Auxiliary Inputs",
    "abstract": "Comments: 12 pages + 2 references + 12 appendix, 10 figures",
    "descriptor": "\nComments: 12 pages + 2 references + 12 appendix, 10 figures\n",
    "authors": [
      "Ruo Yu Tao",
      "Adam White",
      "Marlos C. Machado"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.07805"
  },
  {
    "id": "arXiv:2211.07820",
    "title": "Clinically Plausible Pathology-Anatomy Disentanglement in Patient Brain  MRI with Structured Variational Priors",
    "abstract": "Comments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 11 pages",
    "descriptor": "\nComments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 11 pages\n",
    "authors": [
      "Anjun Hu",
      "Jean-Pierre R. Falet",
      "Brennan S. Nichyporuk",
      "Changjian Shui",
      "Douglas L. Arnold",
      "Sotirios A. Tsaftaris",
      "Tal Arbel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07820"
  },
  {
    "id": "arXiv:2211.07906",
    "title": "Hierarchical Phrase-based Sequence-to-Sequence Learning",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Bailin Wang",
      "Ivan Titov",
      "Jacob Andreas",
      "Yoon Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.07906"
  },
  {
    "id": "arXiv:2211.07911",
    "title": "Operation-level Concurrent Transaction Execution for Blockchains",
    "abstract": "Operation-level Concurrent Transaction Execution for Blockchains",
    "descriptor": "",
    "authors": [
      "Haoran Lin",
      "Yajin Zhou",
      "Lei Wu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.07911"
  },
  {
    "id": "arXiv:2211.07937",
    "title": "An Improved Analysis of (Variance-Reduced) Policy Gradient and Natural  Policy Gradient Methods",
    "abstract": "Comments: NeurIPS 2020 (improve the proof of Lemma B.1 and Proposition G.1.)",
    "descriptor": "\nComments: NeurIPS 2020 (improve the proof of Lemma B.1 and Proposition G.1.)\n",
    "authors": [
      "Yanli Liu",
      "Kaiqing Zhang",
      "Tamer Ba\u015far",
      "Wotao Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07937"
  },
  {
    "id": "arXiv:2211.07967",
    "title": "Coordination for Connected and Automated Vehicles at Non-signalized  Intersections: A Value Decomposition-based Multiagent Deep Reinforcement  Learning Approach",
    "abstract": "Coordination for Connected and Automated Vehicles at Non-signalized  Intersections: A Value Decomposition-based Multiagent Deep Reinforcement  Learning Approach",
    "descriptor": "",
    "authors": [
      "Zihan Guo",
      "Yan Wu",
      "Lifang Wang",
      "Junzhi Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.07967"
  },
  {
    "id": "arXiv:2211.08071",
    "title": "Knowledge Distillation for Detection Transformer with Consistent  Distillation Points Sampling",
    "abstract": "Knowledge Distillation for Detection Transformer with Consistent  Distillation Points Sampling",
    "descriptor": "",
    "authors": [
      "Yu Wang",
      "Xin Li",
      "Shengzhao Wen",
      "Fukui Yang",
      "Wanping Zhang",
      "Gang Zhang",
      "Haocheng Feng",
      "Junyu Han",
      "Errui Ding"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08071"
  },
  {
    "id": "arXiv:2211.08184",
    "title": "Improved Coresets for Euclidean $k$-Means",
    "abstract": "Improved Coresets for Euclidean $k$-Means",
    "descriptor": "",
    "authors": [
      "Vincent Cohen-Addad",
      "Kasper Green Larsen",
      "David Saulpic",
      "Chris Schwiegelshohn",
      "Omar Ali Sheikh-Omar"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08184"
  },
  {
    "id": "arXiv:2211.08237",
    "title": "Multilingual Speech Emotion Recognition With Multi-Gating Mechanism and  Neural Architecture Search",
    "abstract": "Multilingual Speech Emotion Recognition With Multi-Gating Mechanism and  Neural Architecture Search",
    "descriptor": "",
    "authors": [
      "Zihan Wang",
      "Qi Meng",
      "HaiFeng Lan",
      "XinRui Zhang",
      "KeHao Guo",
      "Akshat Gupta"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.08237"
  },
  {
    "id": "arXiv:2211.08292",
    "title": "Mobile-Aware Scheduling for Low Latency Backhaul over DOCSIS",
    "abstract": "Comments: IEEE International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC), 2017",
    "descriptor": "\nComments: IEEE International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC), 2017\n",
    "authors": [
      "Jennifer Andreoli-Fang",
      "John T Chapman"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.08292"
  }
]
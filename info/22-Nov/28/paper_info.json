[
  {
    "id": "arXiv:2211.13234",
    "title": "RNTrajRec: Road Network Enhanced Trajectory Recovery with  Spatial-Temporal Transformer",
    "abstract": "GPS trajectories are the essential foundations for many trajectory-based\napplications, such as travel time estimation, traffic prediction and trajectory\nsimilarity measurement. Most applications require a large amount of high sample\nrate trajectories to achieve a good performance. However, many real-life\ntrajectories are collected with low sample rate due to energy concern or other\nconstraints.We study the task of trajectory recovery in this paper as a means\nfor increasing the sample rate of low sample trajectories. Currently, most\nexisting works on trajectory recovery follow a sequence-to-sequence diagram,\nwith an encoder to encode a trajectory and a decoder to recover real GPS points\nin the trajectory. However, these works ignore the topology of road network and\nonly use grid information or raw GPS points as input. Therefore, the encoder\nmodel is not able to capture rich spatial information of the GPS points along\nthe trajectory, making the prediction less accurate and lack spatial\nconsistency. In this paper, we propose a road network enhanced\ntransformer-based framework, namely RNTrajRec, for trajectory recovery.\nRNTrajRec first uses a graph model, namely GridGNN, to learn the embedding\nfeatures of each road segment. It next develops a Sub-Graph Generation module\nto represent each GPS point as a sub-graph structure of the road network around\nthe GPS point. It then introduces a spatial-temporal transformer model, namely\nGPSFormer, to learn rich spatial and temporal features. It finally forwards the\noutputs of encoder model into a multi-task decoder model to recover the missing\nGPS points. Extensive experiments based on three large-scale real-life\ntrajectory datasets confirm the effectiveness of our approach.",
    "descriptor": "",
    "authors": [
      "Yuqi Chen",
      "Hanyuan Zhang",
      "Weiwei Sun",
      "Baihua Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13234"
  },
  {
    "id": "arXiv:2211.13235",
    "title": "Unified Multimodal Model with Unlikelihood Training for Visual Dialog",
    "abstract": "The task of visual dialog requires a multimodal chatbot to answer sequential\nquestions from humans about image content. Prior work performs the standard\nlikelihood training for answer generation on the positive instances (involving\ncorrect answers). However, the likelihood objective often leads to frequent and\ndull outputs and fails to exploit the useful knowledge from negative instances\n(involving incorrect answers). In this paper, we propose a Unified Multimodal\nModel with UnLikelihood Training, named UniMM-UL, to tackle this problem.\nFirst, to improve visual dialog understanding and generation by multi-task\nlearning, our model extends ViLBERT from only supporting answer discrimination\nto holding both answer discrimination and answer generation seamlessly by\ndifferent attention masks. Specifically, in order to make the original\ndiscriminative model compatible with answer generation, we design novel\ngenerative attention masks to implement the autoregressive Masked Language\nModeling (autoregressive MLM) task. And to attenuate the adverse effects of the\nlikelihood objective, we exploit unlikelihood training on negative instances to\nmake the model less likely to generate incorrect answers. Then, to utilize\ndense annotations, we adopt different fine-tuning methods for both generating\nand discriminating answers, rather than just for discriminating answers as in\nthe prior work. Finally, on the VisDial dataset, our model achieves the best\ngenerative results (69.23 NDCG score). And our model also yields comparable\ndiscriminative results with the state-of-the-art in both single-model and\nensemble settings (75.92 and 76.17 NDCG scores).",
    "descriptor": "\nComments: Accepted by the 30th ACM International Conference on Multimedia (ACM MM 2022)\n",
    "authors": [
      "Zihao Wang",
      "Junli Wang",
      "Changjun Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13235"
  },
  {
    "id": "arXiv:2211.13236",
    "title": "MEGAN: Multi-Explanation Graph Attention Network",
    "abstract": "Explainable artificial intelligence (XAI) methods are expected to improve\ntrust during human-AI interactions, provide tools for model analysis and extend\nhuman understanding of complex problems. Explanation-supervised training allows\nto improve explanation quality by training self-explaining XAI models on ground\ntruth or human-generated explanations. However, existing explanation methods\nhave limited expressiveness and interoperability due to the fact that only\nsingle explanations in form of node and edge importance are generated. To that\nend we propose the novel multi-explanation graph attention network (MEGAN). Our\nfully differentiable, attention-based model features multiple explanation\nchannels, which can be chosen independently of the task specifications. We\nfirst validate our model on a synthetic graph regression dataset. We show that\nfor the special single explanation case, our model significantly outperforms\nexisting post-hoc and explanation-supervised baseline methods. Furthermore, we\ndemonstrate significant advantages when using two explanations, both in\nquantitative explanation measures as well as in human interpretability.\nFinally, we demonstrate our model's capabilities on multiple real-world\ndatasets. We find that our model produces sparse high-fidelity explanations\nconsistent with human intuition about those tasks and at the same time matches\nstate-of-the-art graph neural networks in predictive performance, indicating\nthat explanations and accuracy are not necessarily a trade-off.",
    "descriptor": "\nComments: 9 pages main text, 29 pages total, 19 figures\n",
    "authors": [
      "Jonas Teufel",
      "Luca Torresi",
      "Patrick Reiser",
      "Pascal Friederich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13236"
  },
  {
    "id": "arXiv:2211.13239",
    "title": "Relating Regularization and Generalization through the Intrinsic  Dimension of Activations",
    "abstract": "Given a pair of models with similar training set performance, it is natural\nto assume that the model that possesses simpler internal representations would\nexhibit better generalization. In this work, we provide empirical evidence for\nthis intuition through an analysis of the intrinsic dimension (ID) of model\nactivations, which can be thought of as the minimal number of factors of\nvariation in the model's representation of the data. First, we show that common\nregularization techniques uniformly decrease the last-layer ID (LLID) of\nvalidation set activations for image classification models and show how this\nstrongly affects generalization performance. We also investigate how excessive\nregularization decreases a model's ability to extract features from data in\nearlier layers, leading to a negative effect on validation accuracy even while\nLLID continues to decrease and training accuracy remains near-perfect. Finally,\nwe examine the LLID over the course of training of models that exhibit\ngrokking. We observe that well after training accuracy saturates, when models\n``grok'' and validation accuracy suddenly improves from random to perfect,\nthere is a co-occurent sudden drop in LLID, thus providing more insight into\nthe dynamics of sudden generalization.",
    "descriptor": "\nComments: NeurIPS 2022 OPT and HITY workshops\n",
    "authors": [
      "Bradley C.A. Brown",
      "Jordan Juravsky",
      "Anthony L. Caterini",
      "Gabriel Loaiza-Ganem"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13239"
  },
  {
    "id": "arXiv:2211.13250",
    "title": "Lempel-Ziv Networks",
    "abstract": "Sequence processing has long been a central area of machine learning\nresearch. Recurrent neural nets have been successful in processing sequences\nfor a number of tasks; however, they are known to be both ineffective and\ncomputationally expensive when applied to very long sequences.\nCompression-based methods have demonstrated more robustness when processing\nsuch sequences -- in particular, an approach pairing the Lempel-Ziv Jaccard\nDistance (LZJD) with the k-Nearest Neighbor algorithm has shown promise on long\nsequence problems (up to $T=200,000,000$ steps) involving malware\nclassification. Unfortunately, use of LZJD is limited to discrete domains. To\nextend the benefits of LZJD to a continuous domain, we investigate the\neffectiveness of a deep-learning analog of the algorithm, the Lempel-Ziv\nNetwork. While we achieve successful proof of concept, we are unable to improve\nmeaningfully on the performance of a standard LSTM across a variety of datasets\nand sequence processing tasks. In addition to presenting this negative result,\nour work highlights the problem of sub-par baseline tuning in newer research\nareas.",
    "descriptor": "\nComments: I Can't Believe It's Not Better Workshop at NeurIPS 2022\n",
    "authors": [
      "Rebecca Saul",
      "Mohammad Mahmudul Alam",
      "John Hurwitz",
      "Edward Raff",
      "Tim Oates",
      "James Holt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13250"
  },
  {
    "id": "arXiv:2211.13251",
    "title": "CGOF++: Controllable 3D Face Synthesis with Conditional Generative  Occupancy Fields",
    "abstract": "Capitalizing on the recent advances in image generation models, existing\ncontrollable face image synthesis methods are able to generate high-fidelity\nimages with some levels of controllability, e.g., controlling the shapes,\nexpressions, textures, and poses of the generated face images. However,\nprevious methods focus on controllable 2D image generative models, which are\nprone to producing inconsistent face images under large expression and pose\nchanges. In this paper, we propose a new NeRF-based conditional 3D face\nsynthesis framework, which enables 3D controllability over the generated face\nimages by imposing explicit 3D conditions from 3D face priors. At its core is a\nconditional Generative Occupancy Field (cGOF++) that effectively enforces the\nshape of the generated face to conform to a given 3D Morphable Model (3DMM)\nmesh, built on top of EG3D [1], a recent tri-plane-based generative model. To\nachieve accurate control over fine-grained 3D face shapes of the synthesized\nimages, we additionally incorporate a 3D landmark loss as well as a volume\nwarping loss into our synthesis framework. Experiments validate the\neffectiveness of the proposed method, which is able to generate high-fidelity\nface images and shows more precise 3D controllability than state-of-the-art\n2D-based controllable face synthesis methods.",
    "descriptor": "\nComments: This article is an extension of the NeurIPS'22 paper arXiv:2206.08361\n",
    "authors": [
      "Keqiang Sun",
      "Shangzhe Wu",
      "Ning Zhang",
      "Zhaoyang Huang",
      "Quan Wang",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13251"
  },
  {
    "id": "arXiv:2211.13252",
    "title": "Mask the Correct Tokens: An Embarrassingly Simple Approach for Error  Correction",
    "abstract": "Text error correction aims to correct the errors in text sequences such as\nthose typed by humans or generated by speech recognition models. Previous error\ncorrection methods usually take the source (incorrect) sentence as encoder\ninput and generate the target (correct) sentence through the decoder. Since the\nerror rate of the incorrect sentence is usually low (e.g., 10\\%), the\ncorrection model can only learn to correct on limited error tokens but\ntrivially copy on most tokens (correct tokens), which harms the effective\ntraining of error correction. In this paper, we argue that the correct tokens\nshould be better utilized to facilitate effective training and then propose a\nsimple yet effective masking strategy to achieve this goal. Specifically, we\nrandomly mask out a part of the correct tokens in the source sentence and let\nthe model learn to not only correct the original error tokens but also predict\nthe masked tokens based on their context information. Our method enjoys several\nadvantages: 1) it alleviates trivial copy; 2) it leverages effective training\nsignals from correct tokens; 3) it is a plug-and-play module and can be applied\nto different models and tasks. Experiments on spelling error correction and\nspeech recognition error correction on Mandarin datasets and grammar error\ncorrection on English datasets with both autoregressive and non-autoregressive\ngeneration models show that our method improves the correction accuracy\nconsistently.",
    "descriptor": "\nComments: main track of EMNLP 2022\n",
    "authors": [
      "Kai Shen",
      "Yichong Leng",
      "Xu Tan",
      "Siliang Tang",
      "Yuan Zhang",
      "Wenjie Liu",
      "Edward Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13252"
  },
  {
    "id": "arXiv:2211.13254",
    "title": "Space-efficient RLZ-to-LZ77 conversion",
    "abstract": "Consider a text $T [1..n]$ prefixed by a reference sequence $R = T\n[1..\\ell]$. We show how, given $R$ and the $z'$-phrase relative Lempel-Ziv\nparse of $T [\\ell + 1..n]$ with respect to $R$, we can build the LZ77 parse of\n$T$ in $n\\,\\mathrm{polylog} (n)$ time and $O (\\ell + z')$ total space.",
    "descriptor": "",
    "authors": [
      "Travis Gagie"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.13254"
  },
  {
    "id": "arXiv:2211.13257",
    "title": "Representation Learning for Continuous Action Spaces is Beneficial for  Efficient Policy Learning",
    "abstract": "Deep reinforcement learning (DRL) breaks through the bottlenecks of\ntraditional reinforcement learning (RL) with the help of the perception\ncapability of deep learning and has been widely applied in real-world\nproblems.While model-free RL, as a class of efficient DRL methods, performs the\nlearning of state representations simultaneously with policy learning in an\nend-to-end manner when facing large-scale continuous state and action spaces.\nHowever, training such a large policy model requires a large number of\ntrajectory samples and training time. On the other hand, the learned policy\noften fails to generalize to large-scale action spaces, especially for the\ncontinuous action spaces. To address this issue, in this paper we propose an\nefficient policy learning method in latent state and action spaces. More\nspecifically, we extend the idea of state representations to action\nrepresentations for better policy generalization capability. Meanwhile, we\ndivide the whole learning task into learning with the large-scale\nrepresentation models in an unsupervised manner and learning with the\nsmall-scale policy model in the RL manner.The small policy model facilitates\npolicy learning, while not sacrificing generalization and expressiveness via\nthe large representation model. Finally,the effectiveness of the proposed\nmethod is demonstrated by MountainCar,CarRacing and Cheetah experiments.",
    "descriptor": "",
    "authors": [
      "Tingting Zhao",
      "Ying Wang",
      "Wei Sun",
      "Yarui Chen",
      "Gang Niub",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13257"
  },
  {
    "id": "arXiv:2211.13258",
    "title": "Online Dynamic Reliability Evaluation of Wind Turbines based on  Drone-assisted Monitoring",
    "abstract": "The offshore wind energy is increasingly becoming an attractive source of\nenergy due to having lower environmental impact. Effective operation and\nmaintenance that ensures the maximum availability of the energy generation\nprocess using offshore facilities and minimal production cost are two key\nfactors to improve the competitiveness of this energy source over other\ntraditional sources of energy. Condition monitoring systems are widely used for\nhealth management of offshore wind farms to have improved operation and\nmaintenance. Reliability of the wind farms are increasingly being evaluated to\naid in the maintenance process and thereby to improve the availability of the\nfarms. However, much of the reliability analysis is performed offline based on\nstatistical data. In this article, we propose a drone-assisted monitoring based\nmethod for online reliability evaluation of wind turbines. A blade system of a\nwind turbine is used as an illustrative example to demonstrate the proposed\napproach.",
    "descriptor": "\nComments: A modified version of this work has been published in the 2022 International Conference on Computing, Electronics & Communications Engineering (iCCECE). This work is a draft author version\n",
    "authors": [
      "Sohag Kabir",
      "Koorosh Aslansefat",
      "Prosanta Gope",
      "Felician Campean",
      "Yiannis Papadopoulos"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.13258"
  },
  {
    "id": "arXiv:2211.13260",
    "title": "Actively Learning Costly Reward Functions for Reinforcement Learning",
    "abstract": "Transfer of recent advances in deep reinforcement learning to real-world\napplications is hindered by high data demands and thus low efficiency and\nscalability. Through independent improvements of components such as replay\nbuffers or more stable learning algorithms, and through massively distributed\nsystems, training time could be reduced from several days to several hours for\nstandard benchmark tasks. However, while rewards in simulated environments are\nwell-defined and easy to compute, reward evaluation becomes the bottleneck in\nmany real-world environments, e.g., in molecular optimization tasks, where\ncomputationally demanding simulations or even experiments are required to\nevaluate states and to quantify rewards. Therefore, training might become\nprohibitively expensive without an extensive amount of computational resources\nand time. We propose to alleviate this problem by replacing costly ground-truth\nrewards with rewards modeled by neural networks, counteracting non-stationarity\nof state and reward distributions during training with an active learning\ncomponent. We demonstrate that using our proposed ACRL method (Actively\nlearning Costly rewards for Reinforcement Learning), it is possible to train\nagents in complex real-world environments orders of magnitudes faster. By\nenabling the application of reinforcement learning methods to new domains, we\nshow that we can find interesting and non-trivial solutions to real-world\noptimization problems in chemistry, materials science and engineering.",
    "descriptor": "",
    "authors": [
      "Andr\u00e9 Eberhard",
      "Houssam Metni",
      "Georg Fahland",
      "Alexander Stroh",
      "Pascal Friederich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13260"
  },
  {
    "id": "arXiv:2211.13264",
    "title": "Distilling Knowledge from Self-Supervised Teacher by Embedding Graph  Alignment",
    "abstract": "Recent advances have indicated the strengths of self-supervised pre-training\nfor improving representation learning on downstream tasks. Existing works often\nutilize self-supervised pre-trained models by fine-tuning on downstream tasks.\nHowever, fine-tuning does not generalize to the case when one needs to build a\ncustomized model architecture different from the self-supervised model. In this\nwork, we formulate a new knowledge distillation framework to transfer the\nknowledge from self-supervised pre-trained models to any other student network\nby a novel approach named Embedding Graph Alignment. Specifically, inspired by\nthe spirit of instance discrimination in self-supervised learning, we model the\ninstance-instance relations by a graph formulation in the feature embedding\nspace and distill the self-supervised teacher knowledge to a student network by\naligning the teacher graph and the student graph. Our distillation scheme can\nbe flexibly applied to transfer the self-supervised knowledge to enhance\nrepresentation learning on various student networks. We demonstrate that our\nmodel outperforms multiple representative knowledge distillation methods on\nthree benchmark datasets, including CIFAR100, STL10, and TinyImageNet. Code is\nhere: https://github.com/yccm/EGA.",
    "descriptor": "\nComments: British Machine Vision Conference (BMVC 2022)\n",
    "authors": [
      "Yuchen Ma",
      "Yanbei Chen",
      "Zeynep Akata"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13264"
  },
  {
    "id": "arXiv:2211.13280",
    "title": "Device Directedness with Contextual Cues for Spoken Dialog Systems",
    "abstract": "In this work, we define barge-in verification as a supervised learning task\nwhere audio-only information is used to classify user spoken dialogue into true\nand false barge-ins. Following the success of pre-trained models, we use\nlow-level speech representations from a self-supervised representation learning\nmodel for our downstream classification task. Further, we propose a novel\ntechnique to infuse lexical information directly into speech representations to\nimprove the domain-specific language information implicitly learned during\npre-training. Experiments conducted on spoken dialog data show that our\nproposed model trained to validate barge-in entirely from speech\nrepresentations is faster by 38% relative and achieves 4.5% relative F1 score\nimprovement over a baseline LSTM model that uses both audio and Automatic\nSpeech Recognition (ASR) 1-best hypotheses. On top of this, our best proposed\nmodel with lexically infused representations along with contextual features\nprovides a further relative improvement of 5.7% in the F1 score but only 22%\nfaster than the baseline.",
    "descriptor": "",
    "authors": [
      "Dhanush Bekal",
      "Sundararajan Srinivasan",
      "Sravan Bodapati",
      "Srikanth Ronanki",
      "Katrin Kirchhoff"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.13280"
  },
  {
    "id": "arXiv:2211.13282",
    "title": "Voice-preserving Zero-shot Multiple Accent Conversion",
    "abstract": "Most people who have tried to learn a foreign language would have experienced\ndifficulties understanding or speaking with a native speaker's accent. For\nnative speakers, understanding or speaking a new accent is likewise a difficult\ntask. An accent conversion system that changes a speaker's accent but preserves\nthat speaker's voice identity, such as timbre and pitch, has the potential for\na range of applications, such as communication, language learning, and\nentertainment. Existing accent conversion models tend to change the speaker\nidentity and accent at the same time. Here, we use adversarial learning to\ndisentangle accent dependent features while retaining other acoustic\ncharacteristics. What sets our work apart from existing accent conversion\nmodels is the capability to convert an unseen speaker's utterance to multiple\naccents while preserving its original voice identity. Subjective evaluations\nshow that our model generates audio that sound closer to the target accent and\nlike the original speaker.",
    "descriptor": "\nComments: Submitted to IEEE ICASSP 2023\n",
    "authors": [
      "Mumin Jin",
      "Prashant Serai",
      "Jilong Wu",
      "Andros Tjandra",
      "Vimal Manohar",
      "Qing He"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.13282"
  },
  {
    "id": "arXiv:2211.13285",
    "title": "Proceedings of the 4th International Workshop on Reading Music Systems",
    "abstract": "The International Workshop on Reading Music Systems (WoRMS) is a workshop\nthat tries to connect researchers who develop systems for reading music, such\nas in the field of Optical Music Recognition, with other researchers and\npractitioners that could benefit from such systems, like librarians or\nmusicologists.\nThe relevant topics of interest for the workshop include, but are not limited\nto: Music reading systems; Optical music recognition; Datasets and performance\nevaluation; Image processing on music scores; Writer identification; Authoring,\nediting, storing and presentation systems for music scores; Multi-modal\nsystems; Novel input-methods for music to produce written music; Web-based\nMusic Information Retrieval services; Applications and projects; Use-cases\nrelated to written music.\nThese are the proceedings of the 4th International Workshop on Reading Music\nSystems, held online on Nov. 18th 2022.",
    "descriptor": "\nComments: Proceedings edited by Jorge Calvo-Zaragoza, Alexander Pacha and Elona Shatri\n",
    "authors": [
      "Jorge Calvo-Zaragoza",
      "Alexander Pacha",
      "Elona Shatri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.13285"
  },
  {
    "id": "arXiv:2211.13286",
    "title": "Corn Yield Prediction based on Remotely Sensed Variables Using  Variational Autoencoder and Multiple Instance Regression",
    "abstract": "In the U.S., corn is the most produced crop and has been an essential part of\nthe American diet. To meet the demand for supply chain management and regional\nfood security, accurate and timely large-scale corn yield prediction is\nattracting more attention in precision agriculture. Recently, remote sensing\ntechnology and machine learning methods have been widely explored for crop\nyield prediction. Currently, most county-level yield prediction models use\ncounty-level mean variables for prediction, ignoring much detailed information.\nMoreover, inconsistent spatial resolution between crop area and satellite\nsensors results in mixed pixels, which may decrease the prediction accuracy.\nOnly a few works have addressed the mixed pixels problem in large-scale crop\nyield prediction. To address the information loss and mixed pixels problem, we\ndeveloped a variational autoencoder (VAE) based multiple instance regression\n(MIR) model for large-scaled corn yield prediction. We use all unlabeled data\nto train a VAE and the well-trained VAE for anomaly detection. As a preprocess\nmethod, anomaly detection can help MIR find a better representation of every\nbag than traditional MIR methods, thus better performing in large-scale corn\nyield prediction. Our experiments showed that variational autoencoder based\nmultiple instance regression (VAEMIR) outperformed all baseline methods in\nlarge-scale corn yield prediction. Though a suitable meta parameter is\nrequired, VAEMIR shows excellent potential in feature learning and extraction\nfor large-scale corn yield prediction.",
    "descriptor": "",
    "authors": [
      "Zeyu Cao",
      "Yuchi Ma",
      "Zhou Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13286"
  },
  {
    "id": "arXiv:2211.13287",
    "title": "HouseDiffusion: Vector Floorplan Generation via a Diffusion Model with  Discrete and Continuous Denoising",
    "abstract": "The paper presents a novel approach for vector-floorplan generation via a\ndiffusion model, which denoises 2D coordinates of room/door corners with two\ninference objectives: 1) a single-step noise as the continuous quantity to\nprecisely invert the continuous forward process; and 2) the final 2D coordinate\nas the discrete quantity to establish geometric incident relationships such as\nparallelism, orthogonality, and corner-sharing. Our task is graph-conditioned\nfloorplan generation, a common workflow in floorplan design. We represent a\nfloorplan as 1D polygonal loops, each of which corresponds to a room or a door.\nOur diffusion model employs a Transformer architecture at the core, which\ncontrols the attention masks based on the input graph-constraint and directly\ngenerates vector-graphics floorplans via a discrete and continuous denoising\nprocess. We have evaluated our approach on RPLAN dataset. The proposed approach\nmakes significant improvements in all the metrics against the state-of-the-art\nwith significant margins, while being capable of generating non-Manhattan\nstructures and controlling the exact number of corners per room. A project\nwebsite with supplementary video and document is here\nhttps://aminshabani.github.io/housediffusion.",
    "descriptor": "",
    "authors": [
      "Mohammad Amin Shabani",
      "Sepidehsadat Hosseini",
      "Yasutaka Furukawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13287"
  },
  {
    "id": "arXiv:2211.13290",
    "title": "SEAT: Stable and Explainable Attention",
    "abstract": "Currently, attention mechanism becomes a standard fixture in most\nstate-of-the-art natural language processing (NLP) models, not only due to\noutstanding performance it could gain, but also due to plausible innate\nexplanation for the behaviors of neural architectures it provides, which is\nnotoriously difficult to analyze. However, recent studies show that attention\nis unstable against randomness and perturbations during training or testing,\nsuch as random seeds and slight perturbation of embedding vectors, which\nimpedes it from becoming a faithful explanation tool. Thus, a natural question\nis whether we can find some substitute of the current attention which is more\nstable and could keep the most important characteristics on explanation and\nprediction of attention. In this paper, to resolve the problem, we provide a\nfirst rigorous definition of such alternate namely SEAT (Stable and Explainable\nAttention). Specifically, a SEAT should has the following three properties: (1)\nIts prediction distribution is enforced to be close to the distribution based\non the vanilla attention; (2) Its top-k indices have large overlaps with those\nof the vanilla attention; (3) It is robust w.r.t perturbations, i.e., any\nslight perturbation on SEAT will not change the prediction distribution too\nmuch, which implicitly indicates that it is stable to randomness and\nperturbations. Finally, through intensive experiments on various datasets, we\ncompare our SEAT with other baseline methods using RNN, BiLSTM and BERT\narchitectures via six different evaluation metrics for model interpretation,\nstability and accuracy. Results show that SEAT is more stable against different\nperturbations and randomness while also keeps the explainability of attention,\nwhich indicates it is a more faithful explanation. Moreover, compared with\nvanilla attention, there is almost no utility (accuracy) degradation for SEAT.",
    "descriptor": "\nComments: To be appeared in AAAI 2023\n",
    "authors": [
      "Lijie Hu",
      "Yixin Liu",
      "Ninghao Liu",
      "Mengdi Huai",
      "Lichao Sun",
      "Di Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13290"
  },
  {
    "id": "arXiv:2211.13291",
    "title": "Learning and Testing Latent-Tree Ising Models Efficiently",
    "abstract": "We provide time- and sample-efficient algorithms for learning and testing\nlatent-tree Ising models, i.e. Ising models that may only be observed at their\nleaf nodes. On the learning side, we obtain efficient algorithms for learning a\ntree-structured Ising model whose leaf node distribution is close in Total\nVariation Distance, improving on the results of prior work. On the testing\nside, we provide an efficient algorithm with fewer samples for testing whether\ntwo latent-tree Ising models have leaf-node distributions that are close or far\nin Total Variation distance. We obtain our algorithms by showing novel\nlocalization results for the total variation distance between the leaf-node\ndistributions of tree-structured Ising models, in terms of their marginals on\npairs of leaves.",
    "descriptor": "",
    "authors": [
      "Davin Choo",
      "Yuval Dagan",
      "Constantinos Daskalakis",
      "Anthimos Vardis Kandiros"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2211.13291"
  },
  {
    "id": "arXiv:2211.13292",
    "title": "Discovering Influencers in Opinion Formation over Social Graphs",
    "abstract": "The adaptive social learning paradigm helps model how networked agents are\nable to form opinions on a state of nature and track its drifts in a changing\nenvironment. In this framework, the agents repeatedly update their beliefs\nbased on private observations and exchange the beliefs with their neighbors. In\nthis work, it is shown how the sequence of publicly exchanged beliefs over time\nallows users to discover rich information about the underlying network topology\nand about the flow of information over graph. In particular, it is shown that\nit is possible (i) to identify the influence of each individual agent to the\nobjective of truth learning, (ii) to discover how well informed each agent is,\n(iii) to quantify the pairwise influences between agents, and (iv) to learn the\nunderlying network topology. The algorithm derived herein is also able to work\nunder non-stationary environments where either the true state of nature or the\nnetwork topology are allowed to drift over time. We apply the proposed\nalgorithm to different subnetworks of Twitter users, and identify the most\ninfluential and central agents merely by using their public tweets (posts).",
    "descriptor": "",
    "authors": [
      "Valentina Shumovskaia",
      "Mert Kayaalp",
      "Mert Cemri",
      "Ali H. Sayed"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Multiagent Systems (cs.MA)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.13292"
  },
  {
    "id": "arXiv:2211.13295",
    "title": "Techniques, Tricks and Algorithms for Efficient GPU-Based Processing of  Higher Order Hyperbolic PDEs",
    "abstract": "GPU computing is expected to play an integral part in all modern Exascale\nsupercomputers. It is also expected that higher order Godunov schemes will make\nup about a significant fraction of the application mix on such supercomputers.\nIt is, therefore, very important to prepare the community of users of higher\norder schemes for hyperbolic PDEs for this emerging opportunity. We focus on\nthree broad and high-impact areas where higher order Godunov schemes are used.\nThe first area is computational fluid dynamics (CFD). The second is\ncomputational magnetohydrodynamics (MHD) which has an involution constraint\nthat has to be mimetically preserved. The third is computational\nelectrodynamics (CED) which has involution constraints and also extremely stiff\nsource terms. Together, these three diverse uses of higher order Godunov\nmethodology, cover many of the most important applications areas. In all three\ncases, we show that the optimal use of algorithms, techniques and tricks, along\nwith the use of OpenACC, yields superlative speedups on GPUs! As a bonus, we\nfind a most remarkable and desirable result: some higher order schemes, with\ntheir larger operations count per zone, show better speedup than lower order\nschemes on GPUs. In other words, the GPU is an optimal stratagem for overcoming\nthe higher computational complexities of higher order schemes! Several avenues\nfor future improvement have also been identified. A scalability study is\npresented for a real-world application using GPUs and comparable numbers of\nhigh-end multicore CPUs. It is found that GPUs offer a substantial performance\nbenefit over comparable number of CPUs, especially when all the methods\ndesigned in this paper are used.",
    "descriptor": "\nComments: 73 pages, 17 figures\n",
    "authors": [
      "Sethupathy Subramanian",
      "Dinshaw S. Balsara",
      "Deepak Bhoriya",
      "Harish Kumar"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.13295"
  },
  {
    "id": "arXiv:2211.13297",
    "title": "Multiple Imputation with Neural Network Gaussian Process for  High-dimensional Incomplete Data",
    "abstract": "Missing data are ubiquitous in real world applications and, if not adequately\nhandled, may lead to the loss of information and biased findings in downstream\nanalysis. Particularly, high-dimensional incomplete data with a moderate sample\nsize, such as analysis of multi-omics data, present daunting challenges.\nImputation is arguably the most popular method for handling missing data,\nthough existing imputation methods have a number of limitations. Single\nimputation methods such as matrix completion methods do not adequately account\nfor imputation uncertainty and hence would yield improper statistical\ninference. In contrast, multiple imputation (MI) methods allow for proper\ninference but existing methods do not perform well in high-dimensional\nsettings. Our work aims to address these significant methodological gaps,\nleveraging recent advances in neural network Gaussian process (NNGP) from a\nBayesian viewpoint. We propose two NNGP-based MI methods, namely MI-NNGP, that\ncan apply multiple imputations for missing values from a joint (posterior\npredictive) distribution. The MI-NNGP methods are shown to significantly\noutperform existing state-of-the-art methods on synthetic and real datasets, in\nterms of imputation error, statistical inference, robustness to missing rates,\nand computation costs, under three missing data mechanisms, MCAR, MAR, and\nMNAR.",
    "descriptor": "",
    "authors": [
      "Zongyu Dai",
      "Zhiqi Bu",
      "Qi Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.13297"
  },
  {
    "id": "arXiv:2211.13305",
    "title": "Dual Graphs of Polyhedral Decompositions for the Detection of  Adversarial Attacks",
    "abstract": "Previous work has shown that a neural network with the rectified linear unit\n(ReLU) activation function leads to a convex polyhedral decomposition of the\ninput space. These decompositions can be represented by a dual graph with\nvertices corresponding to polyhedra and edges corresponding to polyhedra\nsharing a facet, which is a subgraph of a Hamming graph. This paper illustrates\nhow one can utilize the dual graph to detect and analyze adversarial attacks in\nthe context of digital images. When an image passes through a network\ncontaining ReLU nodes, the firing or non-firing at a node can be encoded as a\nbit ($1$ for ReLU activation, $0$ for ReLU non-activation). The sequence of all\nbit activations identifies the image with a bit vector, which identifies it\nwith a polyhedron in the decomposition and, in turn, identifies it with a\nvertex in the dual graph. We identify ReLU bits that are discriminators between\nnon-adversarial and adversarial images and examine how well collections of\nthese discriminators can ensemble vote to build an adversarial image detector.\nSpecifically, we examine the similarities and differences of ReLU bit vectors\nfor adversarial images, and their non-adversarial counterparts, using a\npre-trained ResNet-50 architecture. While this paper focuses on adversarial\ndigital images, ResNet-50 architecture, and the ReLU activation function, our\nmethods extend to other network architectures, activation functions, and types\nof datasets.",
    "descriptor": "",
    "authors": [
      "Huma Jamil",
      "Yajing Liu",
      "Christina Cole",
      "Nathaniel Blanchard",
      "Emily J. King",
      "Michael Kirby",
      "Christopher Peterson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13305"
  },
  {
    "id": "arXiv:2211.13308",
    "title": "SciRepEval: A Multi-Format Benchmark for Scientific Document  Representations",
    "abstract": "Learned representations of scientific documents can serve as valuable input\nfeatures for downstream tasks, without the need for further fine-tuning.\nHowever, existing benchmarks for evaluating these representations fail to\ncapture the diversity of relevant tasks. In response, we introduce SciRepEval,\nthe first comprehensive benchmark for training and evaluating scientific\ndocument representations. It includes 25 challenging and realistic tasks, 11 of\nwhich are new, across four formats: classification, regression, ranking and\nsearch. We then use the benchmark to study and improve the generalization\nability of scientific document representation models. We show how\nstate-of-the-art models struggle to generalize across task formats, and that\nsimple multi-task training fails to improve them. However, a new approach that\nlearns multiple embeddings per document, each tailored to a different format,\ncan improve performance. We experiment with task-format-specific control codes\nand adapters in a multi-task setting and find that they outperform the existing\nsingle-embedding state-of-the-art by up to 1.5 points absolute.",
    "descriptor": "\nComments: 21 pages, 2 figures, 9 tables. For associated code, see this https URL\n",
    "authors": [
      "Amanpreet Singh",
      "Mike D'Arcy",
      "Arman Cohan",
      "Doug Downey",
      "Sergey Feldman"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13308"
  },
  {
    "id": "arXiv:2211.13309",
    "title": "How do Cross-View and Cross-Modal Alignment Affect Representations in  Contrastive Learning?",
    "abstract": "Various state-of-the-art self-supervised visual representation learning\napproaches take advantage of data from multiple sensors by aligning the feature\nrepresentations across views and/or modalities. In this work, we investigate\nhow aligning representations affects the visual features obtained from\ncross-view and cross-modal contrastive learning on images and point clouds. On\nfive real-world datasets and on five tasks, we train and evaluate 108 models\nbased on four pretraining variations. We find that cross-modal representation\nalignment discards complementary visual information, such as color and texture,\nand instead emphasizes redundant depth cues. The depth cues obtained from\npretraining improve downstream depth prediction performance. Also overall,\ncross-modal alignment leads to more robust encoders than pre-training by\ncross-view alignment, especially on depth prediction, instance segmentation,\nand object detection.",
    "descriptor": "",
    "authors": [
      "Thomas M. Hehn",
      "Julian F.P. Kooij",
      "Dariu M. Gavrila"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13309"
  },
  {
    "id": "arXiv:2211.13310",
    "title": "Development of a Mobile Vehicle Manipulator Simulator for the Validation  of Shared Control Concepts",
    "abstract": "This paper presents the development of a real-time simulator for the\nvalidation of controlling a large vehicle manipulator. The need for this\ndevelopment can be justified by the lack of such a simulator: There are neither\nopen source projects nor commercial products, which would be suitable for\ntesting cooperative control concepts. First, we present the nonlinear\nsimulation model of the vehicle and the manipulator. For the modeling\nMATLAB/Simulink is used, which also enables a code generation into standalone\nC++ ROS-Nodes (Robot Operating System Nodes). The emerging challenges of the\ncode generation are also discussed. Then, the obtained standalone C++ ROS-Nodes\nintegrated in the simulator framework which includes a graphical user\ninterface, a steering wheel and a joystick. This simulator can provide the\nreal-time calculation of the overall system's motion enabling the interaction\nof human and automation. Furthermore, a qualitative validation of the model is\ngiven. Finally, the functionalities of the simulator is demonstrated in tests\nwith a human operators.",
    "descriptor": "\nComments: in German language\n",
    "authors": [
      "Balint Varga",
      "Selina Meier",
      "Soeren Hohmann"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.13310"
  },
  {
    "id": "arXiv:2211.13312",
    "title": "A Moment-Matching Approach to Testable Learning and a New  Characterization of Rademacher Complexity",
    "abstract": "A remarkable recent paper by Rubinfeld and Vasilyan (2022) initiated the\nstudy of \\emph{testable learning}, where the goal is to replace hard-to-verify\ndistributional assumptions (such as Gaussianity) with efficiently testable ones\nand to require that the learner succeed whenever the unknown distribution\npasses the corresponding test. In this model, they gave an efficient algorithm\nfor learning halfspaces under testable assumptions that are provably satisfied\nby Gaussians.\nIn this paper we give a powerful new approach for developing algorithms for\ntestable learning using tools from moment matching and metric distances in\nprobability. We obtain efficient testable learners for any concept class that\nadmits low-degree \\emph{sandwiching polynomials}, capturing most important\nexamples for which we have ordinary agnostic learners. We recover the results\nof Rubinfeld and Vasilyan as a corollary of our techniques while achieving\nimproved, near-optimal sample complexity bounds for a broad range of concept\nclasses and distributions.\nSurprisingly, we show that the information-theoretic sample complexity of\ntestable learning is tightly characterized by the Rademacher complexity of the\nconcept class, one of the most well-studied measures in statistical learning\ntheory. In particular, uniform convergence is necessary and sufficient for\ntestable learning. This leads to a fundamental separation from (ordinary)\ndistribution-specific agnostic learning, where uniform convergence is\nsufficient but not necessary.",
    "descriptor": "\nComments: 34 pages\n",
    "authors": [
      "Aravind Gollakota",
      "Adam R. Klivans",
      "Pravesh K. Kothari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.13312"
  },
  {
    "id": "arXiv:2211.13313",
    "title": "Run-Based Semantics for RPQs",
    "abstract": "The formalism of RPQs (regular path queries) is an important building block\nof most query languages for graph databases. RPQs are generally evaluated under\nhomomorphism semantics; in particular only the endpoints of the matched walks\nare returned. Practical applications often need the full matched walks to\ncompute aggregate values. In those cases, homomorphism semantics are not\nsuitable since the number of matched walks can be infinite. Hence,\ngraph-database engines adapt the semantics of RPQs, often neglecting\ntheoretical red flags. For instance, the popular query language Cypher uses\ntrail semantics, which ensures the result to be finite at the cost of making\ncomputational problems intractable.\nWe propose a new kind of semantics for RPQs, including in particular\nsimple-run and binding-trail semantics, as a candidate to reconcile theoretical\nconsiderations with practical aspirations. Both ensure the output to be finite\nin a way that is compatible with homomorphism semantics: projection on\nendpoints coincides with homomorphism semantics. Hence, testing the emptiness\nof result is tractable, and known methods readily apply. Moreover, simple-run\nand binding-trail semantics support bag semantics, and enumeration of the bag\nof results is tractable",
    "descriptor": "\nComments: 35 pages\n",
    "authors": [
      "Claire David",
      "Victor Marsault",
      "Nadime Francis"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.13313"
  },
  {
    "id": "arXiv:2211.13314",
    "title": "CoMadOut -- A Robust Outlier Detection Algorithm based on CoMAD",
    "abstract": "Unsupervised learning methods are well established in the area of anomaly\ndetection and achieve state of the art performances on outlier data sets.\nOutliers play a significant role, since they bear the potential to distort the\npredictions of a machine learning algorithm on a given data set. Especially\namong PCA-based methods, outliers have an additional destructive potential\nregarding the result: they may not only distort the orientation and translation\nof the principal components, they also make it more complicated to detect\noutliers. To address this problem, we propose the robust outlier detection\nalgorithm CoMadOut, which satisfies two required properties: (1) being robust\ntowards outliers and (2) detecting them. Our outlier detection method using\ncoMAD-PCA defines dependent on its variant an inlier region with a robust noise\nmargin by measures of in-distribution (ID) and out-of-distribution (OOD). These\nmeasures allow distribution based outlier scoring for each principal component,\nand thus, for an appropriate alignment of the decision boundary between normal\nand abnormal instances. Experiments comparing CoMadOut with traditional, deep\nand other comparable robust outlier detection methods showed that the\nperformance of the introduced CoMadOut approach is competitive to well\nestablished methods related to average precision (AP), recall and area under\nthe receiver operating characteristic (AUROC) curve. In summary our approach\ncan be seen as a robust alternative for outlier detection tasks.",
    "descriptor": "",
    "authors": [
      "Andreas Lohrer",
      "Daniyal Kazempour",
      "Maximilian H\u00fcnem\u00f6rder",
      "Peer Kr\u00f6ger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13314"
  },
  {
    "id": "arXiv:2211.13315",
    "title": "Bayesian Brain: Computation with Perception to Recognize 3D Objects",
    "abstract": "We mimic the cognitive ability of Human perception, based on Bayesian\nhypothesis, to recognize view-based 3D objects. We consider approximate\nBayesian (Empirical Bayesian) for perceptual inference for recognition. We\nessentially handle computation with perception.",
    "descriptor": "",
    "authors": [
      "Kumar Sankar Ray"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13315"
  },
  {
    "id": "arXiv:2211.13316",
    "title": "Understanding Sample Generation Strategies for Learning Heuristic  Functions in Classical Planning",
    "abstract": "We study the problem of learning good heuristic functions for classical\nplanning tasks with neural networks based on samples that are states with their\ncost-to-goal estimates. It is well known that the learned model quality depends\non the training data quality. Our main goal is to understand better the\ninfluence of sample generation strategies on the performance of a greedy\nbest-first heuristic search guided by a learned heuristic function. In a set of\ncontrolled experiments, we find that two main factors determine the quality of\nthe learned heuristic: the regions of the state space included in the samples\nand the quality of the cost-to-goal estimates. Also, these two factors are\ninterdependent: having perfect estimates of cost-to-goal is insufficient if an\nunrepresentative part of the state space is included in the sample set.\nAdditionally, we study the effects of restricting samples to only include\nstates that could be evaluated when solving a given task and the effects of\nadding samples with high-value estimates. Based on our findings, we propose\npractical strategies to improve the quality of learned heuristics: three\nstrategies that aim to generate more representative states and two strategies\nthat improve the cost-to-goal estimates. Our resulting neural network heuristic\nhas higher coverage than a basic satisficing heuristic. Also, compared to a\nbaseline learned heuristic, our best neural network heuristic almost doubles\nthe mean coverage and can increase it for some domains by more than six times.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "R. V. Bettker",
      "P. P. Minini",
      "A. G. Pereira",
      "M. Ritt"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13316"
  },
  {
    "id": "arXiv:2211.13317",
    "title": "Rank-One Editing of Encoder-Decoder Models",
    "abstract": "Large sequence to sequence models for tasks such as Neural Machine\nTranslation (NMT) are usually trained over hundreds of millions of samples.\nHowever, training is just the origin of a model's life-cycle. Real-world\ndeployments of models require further behavioral adaptations as new\nrequirements emerge or shortcomings become known. Typically, in the space of\nmodel behaviors, behavior deletion requests are addressed through model\nretrainings whereas model finetuning is done to address behavior addition\nrequests, both procedures being instances of data-based model intervention. In\nthis work, we present a preliminary study investigating rank-one editing as a\ndirect intervention method for behavior deletion requests in encoder-decoder\ntransformer models. We propose four editing tasks for NMT and show that the\nproposed editing algorithm achieves high efficacy, while requiring only a\nsingle instance of positive example to fix an erroneous (negative) model\nbehavior.",
    "descriptor": "\nComments: The Second Workshop On Interactive Learning For Natural Language Processing (InterNLP 2022), NeurIPS 2022\n",
    "authors": [
      "Vikas Raunak",
      "Arul Menezes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13317"
  },
  {
    "id": "arXiv:2211.13319",
    "title": "Make-A-Story: Visual Memory Conditioned Consistent Story Generation",
    "abstract": "There has been a recent explosion of impressive generative models that can\nproduce high quality images (or videos) conditioned on text descriptions.\nHowever, all such approaches rely on conditional sentences that contain\nunambiguous descriptions of scenes and main actors in them. Therefore employing\nsuch models for more complex task of story visualization, where naturally\nreferences and co-references exist, and one requires to reason about when to\nmaintain consistency of actors and backgrounds across frames/scenes, and when\nnot to, based on story progression, remains a challenge. In this work, we\naddress the aforementioned challenges and propose a novel autoregressive\ndiffusion-based framework with a visual memory module that implicitly captures\nthe actor and background context across the generated frames.\nSentence-conditioned soft attention over the memories enables effective\nreference resolution and learns to maintain scene and actor consistency when\nneeded. To validate the effectiveness of our approach, we extend the MUGEN\ndataset and introduce additional characters, backgrounds and referencing in\nmulti-sentence storylines. Our experiments for story generation on the MUGEN\nand the FlintstonesSV dataset show that our method not only outperforms prior\nstate-of-the-art in generating frames with high visual quality, which are\nconsistent with the story, but also models appropriate correspondences between\nthe characters and the background.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Tanzila Rahman",
      "Hsin-Ying Lee",
      "Jian Ren",
      "Sergey Tulyakov",
      "Shweta Mahajan",
      "Leonid Sigal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13319"
  },
  {
    "id": "arXiv:2211.13322",
    "title": "Group SELFIES: A Robust Fragment-Based Molecular String Representation",
    "abstract": "We introduce Group SELFIES, a molecular string representation that leverages\ngroup tokens to represent functional groups or entire substructures while\nmaintaining chemical robustness guarantees. Molecular string representations,\nsuch as SMILES and SELFIES, serve as the basis for molecular generation and\noptimization in chemical language models, deep generative models, and\nevolutionary methods. While SMILES and SELFIES leverage atomic representations,\nGroup SELFIES builds on top of the chemical robustness guarantees of SELFIES by\nenabling group tokens, thereby creating additional flexibility to the\nrepresentation. Moreover, the group tokens in Group SELFIES can take advantage\nof inductive biases of molecular fragments that capture meaningful chemical\nmotifs. The advantages of capturing chemical motifs and flexibility are\ndemonstrated in our experiments, which show that Group SELFIES improves\ndistribution learning of common molecular datasets. Further experiments also\nshow that random sampling of Group SELFIES strings improves the quality of\ngenerated molecules compared to regular SELFIES strings. Our open-source\nimplementation of Group SELFIES is available online, which we hope will aid\nfuture research in molecular generation and optimization.",
    "descriptor": "\nComments: 11 pages + references and appendix\n",
    "authors": [
      "Austin Cheng",
      "Andy Cai",
      "Santiago Miret",
      "Gustavo Malkomes",
      "Mariano Phielipp",
      "Al\u00e1n Aspuru-Guzik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.13322"
  },
  {
    "id": "arXiv:2211.13324",
    "title": "A Garbled Circuit Accelerator for Arbitrary, Fast Privacy-Preserving  Computation",
    "abstract": "Privacy and security have rapidly emerged as priorities in system design. One\npowerful solution for providing both is privacy-preserving computation, where\nfunctions are computed directly on encrypted data and control can be provided\nover how data is used. Garbled circuits (GCs) are a PPC technology that provide\nboth confidential computing and control over how data is used. The challenge is\nthat they incur significant performance overheads compared to plaintext. This\npaper proposes a novel garbled circuit accelerator and compiler, named HAAC, to\nmitigate performance overheads and make privacy-preserving computation more\npractical. HAAC is a hardware-software co-design. GCs are exemplars of\nco-design as programs are completely known at compile time, i.e., all\ndependence, memory accesses, and control flow are fixed. The design philosophy\nof HAAC is to keep hardware simple and efficient, maximizing area devoted to\nour proposed custom execution units and other circuits essential for high\nperformance (e.g., on-chip storage). The compiler can leverage its program\nunderstanding to realize hardware's performance potential by generating\neffective instruction schedules, data layouts, and orchestrating off-chip\nevents. In taking this approach we can achieve ASIC performance/efficiency\nwithout sacrificing generality. Insights of our approach include how co-design\nenables expressing arbitrary GC programs as streams, which simplifies hardware\nand enables complete memory-compute decoupling, and the development of a\nscratchpad that captures data reuse by tracking program execution, eliminating\nthe need for costly hardware managed caches and tagging logic. We evaluate HAAC\nwith VIP-Bench and achieve a speedup of 608$\\times$ in 4.3mm$^2$ of area.",
    "descriptor": "",
    "authors": [
      "Jianqiao Mo",
      "Jayanth Gopinath",
      "Brandon Reagen"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.13324"
  },
  {
    "id": "arXiv:2211.13327",
    "title": "A Report on the Euphemisms Detection Shared Task",
    "abstract": "This paper presents The Shared Task on Euphemism Detection for the Third\nWorkshop on Figurative Language Processing (FigLang 2022) held in conjunction\nwith EMNLP 2022. Participants were invited to investigate the euphemism\ndetection task: given input text, identify whether it contains a euphemism. The\ninput data is a corpus of sentences containing potentially euphemistic terms\n(PETs) collected from the GloWbE corpus (Davies and Fuchs, 2015), and are\nhuman-annotated as containing either a euphemistic or literal usage of a PET.\nIn this paper, we present the results and analyze the common themes, methods\nand findings of the participating teams",
    "descriptor": "",
    "authors": [
      "Patrick Lee",
      "Anna Feldman",
      "Jing Peng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13327"
  },
  {
    "id": "arXiv:2211.13328",
    "title": "Search Behavior Prediction: A Hypergraph Perspective",
    "abstract": "Although the bipartite shopping graphs are straightforward to model search\nbehavior, they suffer from two challenges: 1) The majority of items are\nsporadically searched and hence have noisy/sparse query associations, leading\nto a \\textit{long-tail} distribution. 2) Infrequent queries are more likely to\nlink to popular items, leading to another hurdle known as\n\\textit{disassortative mixing}. To address these two challenges, we go beyond\nthe bipartite graph to take a hypergraph perspective, introducing a new\nparadigm that leverages \\underline{auxiliary} information from anonymized\ncustomer engagement sessions to assist the \\underline{main task} of query-item\nlink prediction. This auxiliary information is available at web scale in the\nform of search logs. We treat all items appearing in the same customer session\nas a single hyperedge. The hypothesis is that items in a customer session are\nunified by a common shopping interest. With these hyperedges, we augment the\noriginal bipartite graph into a new \\textit{hypergraph}. We develop a\n\\textit{\\textbf{D}ual-\\textbf{C}hannel \\textbf{A}ttention-Based\n\\textbf{H}ypergraph Neural Network} (\\textbf{DCAH}), which synergizes\ninformation from two potentially noisy sources (original query-item edges and\nitem-item hyperedges). In this way, items on the tail are better connected due\nto the extra hyperedges, thereby enhancing their link prediction performance.\nWe further integrate DCAH with self-supervised graph pre-training and/or\nDropEdge training, both of which effectively alleviate disassortative mixing.\nExtensive experiments on three proprietary E-Commerce datasets show that DCAH\nyields significant improvements of up to \\textbf{24.6\\% in mean reciprocal rank\n(MRR)} and \\textbf{48.3\\% in recall} compared to GNN-based baselines. Our\nsource code is available at\n\\url{https://github.com/amazon-science/dual-channel-hypergraph-neural-network}.",
    "descriptor": "",
    "authors": [
      "Yan Han",
      "Edward W Huang",
      "Wenqing Zheng",
      "Nikhil Rao",
      "Zhangyang Wang",
      "Karthik Subbian"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.13328"
  },
  {
    "id": "arXiv:2211.13331",
    "title": "Using Focal Loss to Fight Shallow Heuristics: An Empirical Analysis of  Modulated Cross-Entropy in Natural Language Inference",
    "abstract": "There is no such thing as a perfect dataset. In some datasets, deep neural\nnetworks discover underlying heuristics that allow them to take shortcuts in\nthe learning process, resulting in poor generalization capability. Instead of\nusing standard cross-entropy, we explore whether a modulated version of\ncross-entropy called focal loss can constrain the model so as not to use\nheuristics and improve generalization performance. Our experiments in natural\nlanguage inference show that focal loss has a regularizing impact on the\nlearning process, increasing accuracy on out-of-distribution data, but slightly\ndecreasing performance on in-distribution data. Despite the improved\nout-of-distribution performance, we demonstrate the shortcomings of focal loss\nand its inferiority in comparison to the performance of methods such as\nunbiased focal loss and self-debiasing ensembles.",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Frano Raji\u010d",
      "Ivan Stresec",
      "Axel Marmet",
      "Tim Po\u0161tuvan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13331"
  },
  {
    "id": "arXiv:2211.13332",
    "title": "Learning Compact Features via In-Training Representation Alignment",
    "abstract": "Deep neural networks (DNNs) for supervised learning can be viewed as a\npipeline of the feature extractor (i.e., last hidden layer) and a linear\nclassifier (i.e., output layer) that are trained jointly with stochastic\ngradient descent (SGD) on the loss function (e.g., cross-entropy). In each\nepoch, the true gradient of the loss function is estimated using a mini-batch\nsampled from the training set and model parameters are then updated with the\nmini-batch gradients. Although the latter provides an unbiased estimation of\nthe former, they are subject to substantial variances derived from the size and\nnumber of sampled mini-batches, leading to noisy and jumpy updates. To\nstabilize such undesirable variance in estimating the true gradients, we\npropose In-Training Representation Alignment (ITRA) that explicitly aligns\nfeature distributions of two different mini-batches with a matching loss in the\nSGD training process. We also provide a rigorous analysis of the desirable\neffects of the matching loss on feature representation learning: (1) extracting\ncompact feature representation; (2) reducing over-adaption on mini-batches via\nan adaptive weighting mechanism; and (3) accommodating to multi-modalities.\nFinally, we conduct large-scale experiments on both image and text\nclassifications to demonstrate its superior performance to the strong\nbaselines.",
    "descriptor": "\nComments: 11 pages, 4 figures, 6 tables. Accepted for publication by AAAI-23. arXiv admin note: text overlap with arXiv:2002.09917\n",
    "authors": [
      "Xin Li",
      "Xiangrui Li",
      "Deng Pan",
      "Yao Qiang",
      "Dongxiao Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13332"
  },
  {
    "id": "arXiv:2211.13333",
    "title": "Learning to Rasterize Differentiable",
    "abstract": "Differentiable rasterization changes the common formulation of primitive\nrasterization -- which has zero gradients almost everywhere, due to\ndiscontinuous edges and occlusion -- to an alternative one, which is not\nsubject to this limitation and has similar optima. These alternative versions\nin general are ''soft'' versions of the original one. Unfortunately, it is not\nclear, what exact way of softening will provide the best performance in terms\nof converging the most reliability to a desired goal. Previous work has\nanalyzed and compared several combinations of softening. In this work, we take\nit a step further and, instead of making a combinatorical choice of softening\noperations, parametrize the continuous space of all softening operations. We\nstudy meta-learning a parametric S-shape curve as well as an MLP over a set of\ninverse rendering tasks, so that it generalizes to new and unseen\ndifferentiable rendering tasks with optimal softness.",
    "descriptor": "",
    "authors": [
      "Chenghao Wu",
      "Zahra Montazeri",
      "Tobias Ritschel"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13333"
  },
  {
    "id": "arXiv:2211.13335",
    "title": "Ping-Pong Swaps",
    "abstract": "We propose Ping-Pong Swaps: A secure pure peer-to-peer crosschain swap\nmechanism of tokens or cryptocurrencies that does not require escrow nor an\nintermediate trusted third party. The only technical requirement is to be able\nto open unidirectional payment channels in both blockchain protocols. This\nallows anonymous cryptocurrency trading without the need of a centralized\nexchange, nor DEX's in DeFi platforms, nor multisignature escrow systems with\npenalties. Direct peer-to-peer crosschain swaps can be performed without a\nbridge platform. This enables the creation of a global peer-to-peer market of\npairs of tokens or cryptocurrencies. Ping-pong swaps with fiat currency is\npossible if banks incorporate simple payment channel functionalities. Some\ninmediate applications are simple and fast rebalancing of Lightning Network\nchannels, and wrapping tokens in smartchains.",
    "descriptor": "\nComments: 7 pages, 1 figure\n",
    "authors": [
      "Cyril Grunspan",
      "Ricardo Perez-Marco"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.13335"
  },
  {
    "id": "arXiv:2211.13336",
    "title": "Stackelberg Meta-Learning for Strategic Guidance in Multi-Robot  Trajectory Planning",
    "abstract": "Guided cooperation is a common task in many multi-agent teaming applications.\nThe planning of the cooperation is difficult when the leader robot has\nincomplete information about the follower, and there is a need to learn,\ncustomize, and adapt the cooperation plan online. To this end, we develop a\nlearning-based Stackelberg game-theoretic framework to address this challenge\nto achieve optimal trajectory planning for heterogeneous robots. We first\nformulate the guided trajectory planning problem as a dynamic Stackelberg game\nand design the cooperation plans using open-loop Stackelberg equilibria. We\nleverage meta-learning to deal with the unknown follower in the game and\npropose a Stackelberg meta-learning framework to create online adaptive\ntrajectory guidance plans, where the leader robot learns a meta-best-response\nmodel from a prescribed set of followers offline and then fast adapts to a\nspecific online trajectory guidance task using limited learning data. We use\nsimulations in three different scenarios to elaborate on the effectiveness of\nour framework. Comparison with other learning approaches and no guidance cases\nshow that our framework provides a more time- and data-efficient planning\nmethod in trajectory guidance tasks.",
    "descriptor": "",
    "authors": [
      "Yuhan Zhao",
      "Quanyan Zhu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.13336"
  },
  {
    "id": "arXiv:2211.13337",
    "title": "Multi-Environment Pretraining Enables Transfer to Action Limited  Datasets",
    "abstract": "Using massive datasets to train large-scale models has emerged as a dominant\napproach for broad generalization in natural language and vision applications.\nIn reinforcement learning, however, a key challenge is that available data of\nsequential decision making is often not annotated with actions - for example,\nvideos of game-play are much more available than sequences of frames paired\nwith their logged game controls. We propose to circumvent this challenge by\ncombining large but sparsely-annotated datasets from a \\emph{target}\nenvironment of interest with fully-annotated datasets from various other\n\\emph{source} environments. Our method, Action Limited PreTraining (ALPT),\nleverages the generalization capabilities of inverse dynamics modelling (IDM)\nto label missing action data in the target environment. We show that utilizing\neven one additional environment dataset of labelled data during IDM pretraining\ngives rise to substantial improvements in generating action labels for\nunannotated sequences. We evaluate our method on benchmark game-playing\nenvironments and show that we can significantly improve game performance and\ngeneralization capability compared to other approaches, using annotated\ndatasets equivalent to only $12$ minutes of gameplay. Highlighting the power of\nIDM, we show that these benefits remain even when target and source\nenvironments share no common actions.",
    "descriptor": "",
    "authors": [
      "David Venuto",
      "Sherry Yang",
      "Pieter Abbeel",
      "Doina Precup",
      "Igor Mordatch",
      "Ofir Nachum"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13337"
  },
  {
    "id": "arXiv:2211.13339",
    "title": "Robustness Analysis of Deep Learning Models for Population Synthesis",
    "abstract": "Deep generative models have become useful for synthetic data generation,\nparticularly population synthesis. The models implicitly learn the probability\ndistribution of a dataset and can draw samples from a distribution. Several\nmodels have been proposed, but their performance is only tested on a single\ncross-sectional sample. The implementation of population synthesis on single\ndatasets is seen as a drawback that needs further studies to explore the\nrobustness of the models on multiple datasets. While comparing with the real\ndata can increase trust and interpretability of the models, techniques to\nevaluate deep generative models' robustness for population synthesis remain\nunderexplored. In this study, we present bootstrap confidence interval for the\ndeep generative models, an approach that computes efficient confidence\nintervals for mean errors predictions to evaluate the robustness of the models\nto multiple datasets. Specifically, we adopt the tabular-based Composite Travel\nGenerative Adversarial Network (CTGAN) and Variational Autoencoder (VAE), to\nestimate the distribution of the population, by generating agents that have\ntabular data using several samples over time from the same study area. The\nmodels are implemented on multiple travel diaries of Montreal Origin-\nDestination Survey of 2008, 2013, and 2018 and compare the predictive\nperformance under varying sample sizes from multiple surveys. Results show that\nthe predictive errors of CTGAN have narrower confidence intervals indicating\nits robustness to multiple datasets of the varying sample sizes when compared\nto VAE. Again, the evaluation of model robustness against varying sample size\nshows a minimal decrease in model performance with decrease in sample size.\nThis study directly supports agent-based modelling by enabling finer synthetic\ngeneration of populations in a reliable environment.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2203.03489, arXiv:1909.07689 by other authors\n",
    "authors": [
      "Daniel Opoku Mensah",
      "Godwin Badu-Marfo",
      "Bilal Farooq"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13339"
  },
  {
    "id": "arXiv:2211.13343",
    "title": "Supervised Hypergraph Reconstruction",
    "abstract": "We study an issue commonly seen with graph data analysis: many real-world\ncomplex systems involving high-order interactions are best encoded by\nhypergraphs; however, their datasets often end up being published or studied\nonly in the form of their projections (with dyadic edges). To understand this\nissue, we first establish a theoretical framework to characterize this issue's\nimplications and worst-case scenarios. The analysis motivates our formulation\nof the new task, supervised hypergraph reconstruction: reconstructing a\nreal-world hypergraph from its projected graph, with the help of some existing\nknowledge of the application domain.\nTo reconstruct hypergraph data, we start by analyzing hyperedge distributions\nin the projection, based on which we create a framework containing two modules:\n(1) to handle the enormous search space of potential hyperedges, we design a\nsampling strategy with efficacy guarantees that significantly narrows the space\nto a smaller set of candidates; (2) to identify hyperedges from the candidates,\nwe further design a hyperedge classifier in two well-working variants that\ncapture structural features in the projection. Extensive experiments validate\nour claims, approach, and extensions. Remarkably, our approach outperforms all\nbaselines by an order of magnitude in accuracy on hard datasets. Our code and\ndata can be downloaded from bit.ly/SHyRe.",
    "descriptor": "",
    "authors": [
      "Yanbang Wang",
      "Jon Kleinberg"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13343"
  },
  {
    "id": "arXiv:2211.13345",
    "title": "Principled Data-Driven Decision Support for Cyber-Forensic  Investigations",
    "abstract": "In the wake of a cybersecurity incident, it is crucial to promptly discover\nhow the threat actors breached security in order to assess the impact of the\nincident and to develop and deploy countermeasures that can protect against\nfurther attacks. To this end, defenders can launch a cyber-forensic\ninvestigation, which discovers the techniques that the threat actors used in\nthe incident. A fundamental challenge in such an investigation is prioritizing\nthe investigation of particular techniques since the investigation of each\ntechnique requires time and effort, but forensic analysts cannot know which\nones were actually used before investigating them. To ensure prompt discovery,\nit is imperative to provide decision support that can help forensic analysts\nwith this prioritization. A recent study demonstrated that data-driven decision\nsupport, based on a dataset of prior incidents, can provide state-of-the-art\nprioritization. However, this data-driven approach, called DISCLOSE, is based\non a heuristic that utilizes only a subset of the available information and\ndoes not approximate optimal decisions. To improve upon this heuristic, we\nintroduce a principled approach for data-driven decision support for\ncyber-forensic investigations. We formulate the decision-support problem using\na Markov decision process, whose states represent the states of a forensic\ninvestigation. To solve the decision problem, we propose a Monte Carlo tree\nsearch based method, which relies on a k-NN regression over prior incidents to\nestimate state-transition probabilities. We evaluate our proposed approach on\nmultiple versions of the MITRE ATT&CK dataset, which is a knowledge base of\nadversarial techniques and tactics based on real-world cyber incidents, and\ndemonstrate that our approach outperforms DISCLOSE in terms of techniques\ndiscovered per effort spent.",
    "descriptor": "",
    "authors": [
      "Soodeh Atefi",
      "Sakshyam Panda",
      "Manos Panaousis",
      "Aron Laszka"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13345"
  },
  {
    "id": "arXiv:2211.13350",
    "title": "Choreographer: Learning and Adapting Skills in Imagination",
    "abstract": "Unsupervised skill learning aims to learn a rich repertoire of behaviors\nwithout external supervision, providing artificial agents with the ability to\ncontrol and influence the environment. However, without appropriate knowledge\nand exploration, skills may provide control only over a restricted area of the\nenvironment, limiting their applicability. Furthermore, it is unclear how to\nleverage the learned skill behaviors for adapting to downstream tasks in a\ndata-efficient manner. We present Choreographer, a model-based agent that\nexploits its world model to learn and adapt skills in imagination. Our method\ndecouples the exploration and skill learning processes, being able to discover\nskills in the latent state space of the model. During adaptation, the agent\nuses a meta-controller to evaluate and adapt the learned skills efficiently by\ndeploying them in parallel in imagination. Choreographer is able to learn\nskills both from offline data, and by collecting data simultaneously with an\nexploration policy. The skills can be used to effectively adapt to downstream\ntasks, as we show in the URL benchmark, where we outperform previous approaches\nfrom both pixels and states inputs. The learned skills also explore the\nenvironment thoroughly, finding sparse rewards more frequently, as shown in\ngoal-reaching tasks from the DMC Suite and Meta-World. Project website:\nhttps://skillchoreographer.github.io/",
    "descriptor": "",
    "authors": [
      "Pietro Mazzaglia",
      "Tim Verbelen",
      "Bart Dhoedt",
      "Alexandre Lacoste",
      "Sai Rajeswar"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13350"
  },
  {
    "id": "arXiv:2211.13353",
    "title": "Effects of Backtracking on PageRank",
    "abstract": "In this paper, we consider three variations on standard PageRank:\nNon-backtracking PageRank, $\\mu$-PageRank, and $\\infty$-PageRank, all of which\nalter the standard formula by adjusting the likelihood of backtracking in the\nalgorithm's random walk. We show that in the case of regular and bipartite\nbiregular graphs, standard PageRank and its variants are equivalent. We also\ncompare each centrality measure and investigate their clustering capabilities.",
    "descriptor": "",
    "authors": [
      "Cory Glover",
      "Tyler Jones",
      "Mark Kempton",
      "Alice Oveson"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.13353"
  },
  {
    "id": "arXiv:2211.13357",
    "title": "MPT: Mesh Pre-Training with Transformers for Human Pose and Mesh  Reconstruction",
    "abstract": "We present Mesh Pre-Training (MPT), a new pre-training framework that\nleverages 3D mesh data such as MoCap data for human pose and mesh\nreconstruction from a single image. Existing work in 3D pose and mesh\nreconstruction typically requires image-mesh pairs as the training data, but\nthe acquisition of 2D-to-3D annotations is difficult. In this paper, we explore\nhow to leverage 3D mesh data such as MoCap data, that does not have RGB images,\nfor pre-training. The key idea is that even though 3D mesh data cannot be used\nfor end-to-end training due to a lack of the corresponding RGB images, it can\nbe used to pre-train the mesh regression transformer subnetwork. We observe\nthat such pre-training not only improves the accuracy of mesh reconstruction\nfrom a single image, but also enables zero-shot capability. We conduct mesh\npre-training using 2 million meshes. Experimental results show that MPT\nadvances the state-of-the-art results on Human3.6M and 3DPW datasets. We also\nshow that MPT enables transformer models to have zero-shot capability of human\nmesh reconstruction from real images. In addition, we demonstrate the\ngeneralizability of MPT to 3D hand reconstruction, achieving state-of-the-art\nresults on FreiHAND dataset.",
    "descriptor": "",
    "authors": [
      "Kevin Lin",
      "Chung-Ching Lin",
      "Lin Liang",
      "Zicheng Liu",
      "Lijuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13357"
  },
  {
    "id": "arXiv:2211.13358",
    "title": "Turning the Tables: Biased, Imbalanced, Dynamic Tabular Datasets for ML  Evaluation",
    "abstract": "Evaluating new techniques on realistic datasets plays a crucial role in the\ndevelopment of ML research and its broader adoption by practitioners. In recent\nyears, there has been a significant increase of publicly available unstructured\ndata resources for computer vision and NLP tasks. However, tabular data --\nwhich is prevalent in many high-stakes domains -- has been lagging behind. To\nbridge this gap, we present Bank Account Fraud (BAF), the first publicly\navailable 1 privacy-preserving, large-scale, realistic suite of tabular\ndatasets. The suite was generated by applying state-of-the-art tabular data\ngeneration techniques on an anonymized,real-world bank account opening fraud\ndetection dataset. This setting carries a set of challenges that are\ncommonplace in real-world applications, including temporal dynamics and\nsignificant class imbalance. Additionally, to allow practitioners to stress\ntest both performance and fairness of ML methods, each dataset variant of BAF\ncontains specific types of data bias. With this resource, we aim to provide the\nresearch community with a more realistic, complete, and robust test bed to\nevaluate novel and existing methods.",
    "descriptor": "\nComments: Accepted at NeurIPS 2022. this https URL\n",
    "authors": [
      "S\u00e9rgio Jesus",
      "Jos\u00e9 Pombal",
      "Duarte Alves",
      "Andr\u00e9 Cruz",
      "Pedro Saleiro",
      "Rita P. Ribeiro",
      "Jo\u00e3o Gama",
      "Pedro Bizarro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13358"
  },
  {
    "id": "arXiv:2211.13366",
    "title": "Channel Optimized Visual Imagery based Robotic Arm Control under the  Online Environment",
    "abstract": "An electroencephalogram is an effective approach that provides a\nbidirectional pathway between the user and computer in a non-invasive way. In\nthis study, we adopted the visual imagery data for controlling the BCI-based\nrobotic arm. Visual imagery increases the power of the alpha frequency range of\nthe visual cortex over time as the user performs the task. We proposed a deep\nlearning architecture to decode the visual imagery data using only two channels\nand also we investigated the combination of two EEG channels that has\nsignificant classification performance. When using the proposed method, the\nhighest classification performance using two channels in the offline experiment\nwas 0.661. Also, the highest success rate in the online experiment using two\nchannels (AF3-Oz) was 0.78. Our results provide the possibility of controlling\nthe BCI-based robotic arm using visual imagery data.",
    "descriptor": "\nComments: 4 pages, 2 figures, 3 tables\n",
    "authors": [
      "Byoung-Hee Kwon",
      "Byeong-Hoo Lee",
      "Jeong-Hyun Cho"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.13366"
  },
  {
    "id": "arXiv:2211.13373",
    "title": "Tapping the Potential of Coherence and Syntactic Features in Neural  Models for Automatic Essay Scoring",
    "abstract": "In the prompt-specific holistic score prediction task for Automatic Essay\nScoring, the general approaches include pre-trained neural model, coherence\nmodel, and hybrid model that incorporate syntactic features with neural model.\nIn this paper, we propose a novel approach to extract and represent essay\ncoherence features with prompt-learning NSP that shows to match the\nstate-of-the-art AES coherence model, and achieves the best performance for\nlong essays. We apply syntactic feature dense embedding to augment BERT-based\nmodel and achieve the best performance for hybrid methodology for AES. In\naddition, we explore various ideas to combine coherence, syntactic information\nand semantic embeddings, which no previous study has done before. Our combined\nmodel also performs better than the SOTA available for combined model, even\nthough it does not outperform our syntactic enhanced neural model. We further\noffer analyses that can be useful for future study.",
    "descriptor": "\nComments: Accepted to \"2022 International Conference on Asian Language Processing (IALP)\"\n",
    "authors": [
      "Xinying Qiu",
      "Shuxuan Liao",
      "Jiajun Xie",
      "Jian-Yun Nie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.13373"
  },
  {
    "id": "arXiv:2211.13375",
    "title": "Lifting Weak Supervision To Structured Prediction",
    "abstract": "Weak supervision (WS) is a rich set of techniques that produce pseudolabels\nby aggregating easily obtained but potentially noisy label estimates from a\nvariety of sources. WS is theoretically well understood for binary\nclassification, where simple approaches enable consistent estimation of\npseudolabel noise rates. Using this result, it has been shown that downstream\nmodels trained on the pseudolabels have generalization guarantees nearly\nidentical to those trained on clean labels. While this is exciting, users often\nwish to use WS for structured prediction, where the output space consists of\nmore than a binary or multi-class label set: e.g. rankings, graphs, manifolds,\nand more. Do the favorable theoretical properties of WS for binary\nclassification lift to this setting? We answer this question in the affirmative\nfor a wide range of scenarios. For labels taking values in a finite metric\nspace, we introduce techniques new to weak supervision based on\npseudo-Euclidean embeddings and tensor decompositions, providing a\nnearly-consistent noise rate estimator. For labels in constant-curvature\nRiemannian manifolds, we introduce new invariants that also yield consistent\nnoise rate estimation. In both cases, when using the resulting pseudolabels in\nconcert with a flexible downstream model, we obtain generalization guarantees\nnearly identical to those for models trained on clean data. Several of our\nresults, which can be viewed as robustness guarantees in structured prediction\nwith noisy labels, may be of independent interest. Empirical evaluation\nvalidates our claims and shows the merits of the proposed method.",
    "descriptor": "",
    "authors": [
      "Harit Vishwakarma",
      "Nicholas Roberts",
      "Frederic Sala"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.13375"
  },
  {
    "id": "arXiv:2211.13376",
    "title": "InDEX: Indonesian Idiom and Expression Dataset for Cloze Test",
    "abstract": "We propose InDEX, an Indonesian Idiom and Expression dataset for cloze test.\nThe dataset contains 10438 unique sentences for 289 idioms and expressions for\nwhich we generate 15 different types of distractors, resulting in a large\ncloze-style corpus. Many baseline models of cloze test reading comprehension\napply BERT with random initialization to learn embedding representation. But\nidioms and fixed expressions are different such that the literal meaning of the\nphrases may or may not be consistent with their contextual meaning. Therefore,\nwe explore different ways to combine static and contextual representations for\na stronger baseline model. Experimentations show that combining definition and\nrandom initialization will better support cloze test model performance for\nidioms whether independently or mixed with fixed expressions. While for fixed\nexpressions with no special meaning, static embedding with random\ninitialization is sufficient for cloze test model.",
    "descriptor": "\nComments: Accepted to \"2022 International Conference on Asian Language Processing (IALP)\"\n",
    "authors": [
      "Xinying Qiu",
      "Guofeng Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.13376"
  },
  {
    "id": "arXiv:2211.13382",
    "title": "MaskPlace: Fast Chip Placement via Reinforced Visual Representation  Learning",
    "abstract": "Placement is an essential task in modern chip design, aiming at placing\nmillions of circuit modules on a 2D chip canvas. Unlike the human-centric\nsolution, which requires months of intense effort by hardware engineers to\nproduce a layout to minimize delay and energy consumption, deep reinforcement\nlearning has become an emerging autonomous tool. However, the learning-centric\nmethod is still in its early stage, impeded by a massive design space of size\nten to the order of a few thousand. This work presents MaskPlace to\nautomatically generate a valid chip layout design within a few hours, whose\nperformance can be superior or comparable to recent advanced approaches. It has\nseveral appealing benefits that prior arts do not have. Firstly, MaskPlace\nrecasts placement as a problem of learning pixel-level visual representation to\ncomprehensively describe millions of modules on a chip, enabling placement in a\nhigh-resolution canvas and a large action space. It outperforms recent methods\nthat represent a chip as a hypergraph. Secondly, it enables training the policy\nnetwork by an intuitive reward function with dense reward, rather than a\ncomplicated reward function with sparse reward from previous methods. Thirdly,\nextensive experiments on many public benchmarks show that MaskPlace outperforms\nexisting RL approaches in all key performance metrics, including wirelength,\ncongestion, and density. For example, it achieves 60%-90% wirelength reduction\nand guarantees zero overlaps. We believe MaskPlace can improve AI-assisted chip\nlayout design. The deliverables are released at\nhttps://laiyao1.github.io/maskplace.",
    "descriptor": "",
    "authors": [
      "Yao Lai",
      "Yao Mu",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13382"
  },
  {
    "id": "arXiv:2211.13389",
    "title": "FedCut: A Spectral Analysis Framework for Reliable Detection of  Byzantine Colluders",
    "abstract": "This paper proposes a general spectral analysis framework that thwarts a\nsecurity risk in federated Learning caused by groups of malicious Byzantine\nattackers or colluders, who conspire to upload vicious model updates to\nseverely debase global model performances. The proposed framework delineates\nthe strong consistency and temporal coherence between Byzantine colluders'\nmodel updates from a spectral analysis lens, and, formulates the detection of\nByzantine misbehaviours as a community detection problem in weighted graphs.\nThe modified normalized graph cut is then utilized to discern attackers from\nbenign participants. Moreover, the Spectral heuristics is adopted to make the\ndetection robust against various attacks. The proposed Byzantine colluder\nresilient method, i.e., FedCut, is guaranteed to converge with bounded errors.\nExtensive experimental results under a variety of settings justify the\nsuperiority of FedCut, which demonstrates extremely robust model performance\n(MP) under various attacks. It was shown that FedCut's averaged MP is 2.1% to\n16.5% better than that of the state of the art Byzantine-resilient methods. In\nterms of the worst-case model performance (MP), FedCut is 17.6% to 69.5% better\nthan these methods.",
    "descriptor": "",
    "authors": [
      "Hanlin Gu",
      "Lixin Fan",
      "Xingxing Tang",
      "Qiang Yang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13389"
  },
  {
    "id": "arXiv:2211.13391",
    "title": "Electrical Tunable Spintronic Neuron with Trainable Activation Function",
    "abstract": "Spintronic devices have been widely studied for the hardware realization of\nartificial neurons. The stochastic switching of magnetic tunnel junction driven\nby the spin torque is commonly used to produce the sigmoid activation function.\nHowever, the shape of the activation function in previous studies is fixed\nduring the training of neural network. This restricts the updating of weights\nand results in a limited performance. In this work, we exploit the physics\nbehind the spin torque induced magnetization switching to enable the dynamic\nchange of the activation function during the training process. Specifically,\nthe pulse width and magnetic anisotropy can be electrically controlled to\nchange the slope of activation function, which enables a faster or slower\nchange of output required by the backpropagation algorithm. This is also\nsimilar to the idea of batch normalization that is widely used in the machine\nlearning. Thus, this work demonstrates that the algorithms are no longer\nlimited to the software implementation. They can in fact be realized by the\nspintronic hardware using a single device. Finally, we show that the accuracy\nof hand-written digit recognition can be improved from 88% to 91.3% by using\nthese trainable spintronic neurons without introducing additional energy\nconsumption. Our proposals can stimulate the hardware realization of spintronic\nneural networks.",
    "descriptor": "\nComments: 26 pages, 9 figures\n",
    "authors": [
      "Yue Xin",
      "Kang Zhou",
      "Xuanyao Fong",
      "Yumeng Yang",
      "Shenghua Gao",
      "Zhifeng Zhu"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)"
    ],
    "url": "https://arxiv.org/abs/2211.13391"
  },
  {
    "id": "arXiv:2211.13392",
    "title": "One-Shot General Object Localization",
    "abstract": "This paper presents a general one-shot object localization algorithm called\nOneLoc. Current one-shot object localization or detection methods either rely\non a slow exhaustive feature matching process or lack the ability to generalize\nto novel objects. In contrast, our proposed OneLoc algorithm efficiently finds\nthe object center and bounding box size by a special voting scheme. To keep our\nmethod scale-invariant, only unit center offset directions and relative sizes\nare estimated. A novel dense equalized voting module is proposed to better\nlocate small texture-less objects. Experiments show that the proposed method\nachieves state-of-the-art overall performance on two datasets: OnePose dataset\nand LINEMOD dataset. In addition, our method can also achieve one-shot\nmulti-instance detection and non-rigid object localization. Code repository:\nhttps://github.com/qq456cvb/OneLoc.",
    "descriptor": "",
    "authors": [
      "Yang You",
      "Zhuochen Miao",
      "Kai Xiong",
      "Weiming Wang",
      "Cewu Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13392"
  },
  {
    "id": "arXiv:2211.13398",
    "title": "Go Beyond Point Pairs: A General and Accurate Sim2Real Object Pose  Voting Method with Efficient Online Synthetic Training",
    "abstract": "Object pose estimation is an important topic in 3D vision. Though most\ncurrent state-of-the-art method that trains on real-world pose annotations\nachieve good results, the cost of such real-world training data is too high. In\nthis paper, we propose a novel method for sim-to-real pose estimation, which is\neffective on both instance-level and category-level settings. The proposed\nmethod is based on the point-pair voting scheme from CPPF to vote for object\ncenters, orientations, and scales. Unlike naive point pairs, to enrich the\ncontext provided by each voting unit, we introduce N-point tuples to fuse\nfeatures from more than two points. Besides, a novel vote selection module is\nleveraged in order to discard those `bad' votes. Experiments show that our\nproposed method greatly advances the performance on both instance-level and\ncategory-level scenarios. Our method further narrows the gap between\nsim-to-real and real-training methods by generating synthetic training data\nonline efficiently, while all previous sim-to-real methods need to generate\ndata offline, because of their complex background synthesizing or\nphoto-realistic rendering. Code repository:\nhttps://github.com/qq456cvb/BeyondPPF.",
    "descriptor": "",
    "authors": [
      "Yang You",
      "Wenhao He",
      "Michael Xu Liu",
      "Weiming Wang",
      "Cewu Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13398"
  },
  {
    "id": "arXiv:2211.13400",
    "title": "The adaptive Levin method",
    "abstract": "The Levin method is a classical technique for evaluating oscillatory\nintegrals that operates by solving a certain ordinary differential equation in\norder to construct an antiderivative of the integrand. It was long believed\nthat the method suffers from ``low-frequency breakdown,'' meaning that the\naccuracy of the computed integral deteriorates when the integrand is only\nslowly oscillating. Recently presented experimental evidence suggests that,\nwhen a Chebyshev spectral method is used to discretize the differential\nequation and the resulting linear system is solved via a truncated singular\nvalue decomposition, no such phenomenon is observed. Here, we provide a proof\nthat this is, in fact, the case, and, remarkably, our proof applies even in the\npresence of saddle points. We also observe that the absence of low-frequency\nbreakdown makes the Levin method suitable for use as the basis of an adaptive\nintegration method. We describe extensive numerical experiments demonstrating\nthat the resulting adaptive Levin method can efficiently and accurately\nevaluate a large class of oscillatory integrals, including many with saddle\npoints.",
    "descriptor": "",
    "authors": [
      "Shukui Chen",
      "Kirill Serkh",
      "James Bremer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.13400"
  },
  {
    "id": "arXiv:2211.13402",
    "title": "MP-GELU Bayesian Neural Networks: Moment Propagation by GELU  Nonlinearity",
    "abstract": "Bayesian neural networks (BNNs) have been an important framework in the study\nof uncertainty quantification. Deterministic variational inference, one of the\ninference methods, utilizes moment propagation to compute the predictive\ndistributions and objective functions. Unfortunately, deriving the moments\nrequires computationally expensive Taylor expansion in nonlinear functions,\nsuch as a rectified linear unit (ReLU) or a sigmoid function. Therefore, a new\nnonlinear function that realizes faster moment propagation than conventional\nfunctions is required. In this paper, we propose a novel nonlinear function\nnamed moment propagating-Gaussian error linear unit (MP-GELU) that enables the\nfast derivation of first and second moments in BNNs. MP-GELU enables the\nanalytical computation of moments by applying nonlinearity to the input\nstatistics, thereby reducing the computationally expensive calculations\nrequired for nonlinear functions. In empirical experiments on regression tasks,\nwe observed that the proposed MP-GELU provides higher prediction accuracy and\nbetter quality of uncertainty with faster execution than those of ReLU-based\nBNNs.",
    "descriptor": "\nComments: 9 pages, 1 figures\n",
    "authors": [
      "Yuki Hirayama",
      "Sinya Takamaeda-Yamazaki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13402"
  },
  {
    "id": "arXiv:2211.13403",
    "title": "Differentially Private Image Classification from Features",
    "abstract": "Leveraging transfer learning has recently been shown to be an effective\nstrategy for training large models with Differential Privacy (DP). Moreover,\nsomewhat surprisingly, recent works have found that privately training just the\nlast layer of a pre-trained model provides the best utility with DP. While past\nstudies largely rely on algorithms like DP-SGD for training large models, in\nthe specific case of privately learning from features, we observe that\ncomputational burden is low enough to allow for more sophisticated optimization\nschemes, including second-order methods. To that end, we systematically explore\nthe effect of design parameters such as loss function and optimization\nalgorithm. We find that, while commonly used logistic regression performs\nbetter than linear regression in the non-private setting, the situation is\nreversed in the private setting. We find that linear regression is much more\neffective than logistic regression from both privacy and computational aspects,\nespecially at stricter epsilon values ($\\epsilon < 1$). On the optimization\nside, we also explore using Newton's method, and find that second-order\ninformation is quite helpful even with privacy, although the benefit\nsignificantly diminishes with stricter privacy guarantees. While both methods\nuse second-order information, least squares is effective at lower epsilons\nwhile Newton's method is effective at larger epsilon values. To combine the\nbenefits of both, we propose a novel algorithm called DP-FC, which leverages\nfeature covariance instead of the Hessian of the logistic regression loss and\nperforms well across all $\\epsilon$ values we tried. With this, we obtain new\nSOTA results on ImageNet-1k, CIFAR-100 and CIFAR-10 across all values of\n$\\epsilon$ typically considered. Most remarkably, on ImageNet-1K, we obtain\ntop-1 accuracy of 88\\% under (8, $8 * 10^{-7}$)-DP and 84.3\\% under (0.1, $8 *\n10^{-7}$)-DP.",
    "descriptor": "",
    "authors": [
      "Harsh Mehta",
      "Walid Krichene",
      "Abhradeep Thakurta",
      "Alexey Kurakin",
      "Ashok Cutkosky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13403"
  },
  {
    "id": "arXiv:2211.13408",
    "title": "Graph Contrastive Learning for Materials",
    "abstract": "Recent work has shown the potential of graph neural networks to efficiently\npredict material properties, enabling high-throughput screening of materials.\nTraining these models, however, often requires large quantities of labelled\ndata, obtained via costly methods such as ab initio calculations or\nexperimental evaluation. By leveraging a series of material-specific\ntransformations, we introduce CrystalCLR, a framework for constrastive learning\nof representations with crystal graph neural networks. With the addition of a\nnovel loss function, our framework is able to learn representations competitive\nwith engineered fingerprinting methods. We also demonstrate that via model\nfinetuning, contrastive pretraining can improve the performance of graph neural\nnetworks for prediction of material properties and significantly outperform\ntraditional ML models that use engineered fingerprints. Lastly, we observe that\nCrystalCLR produces material representations that form clusters by compound\nclass.",
    "descriptor": "\nComments: 7 pages, 3 figures, NeurIPS 2022 AI for Accelerated Materials Design Workshop\n",
    "authors": [
      "Teddy Koker",
      "Keegan Quigley",
      "Will Spaeth",
      "Nathan C. Frey",
      "Lin Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)"
    ],
    "url": "https://arxiv.org/abs/2211.13408"
  },
  {
    "id": "arXiv:2211.13409",
    "title": "Object Detection in Foggy Scenes by Embedding Depth and Reconstruction  into Domain Adaptation",
    "abstract": "Most existing domain adaptation (DA) methods align the features based on the\ndomain feature distributions and ignore aspects related to fog, background and\ntarget objects, rendering suboptimal performance. In our DA framework, we\nretain the depth and background information during the domain feature\nalignment. A consistency loss between the generated depth and fog transmission\nmap is introduced to strengthen the retention of the depth information in the\naligned features. To address false object features potentially generated during\nthe DA process, we propose an encoder-decoder framework to reconstruct the\nfog-free background image. This reconstruction loss also reinforces the\nencoder, i.e., our DA backbone, to minimize false object features.Moreover, we\ninvolve our target data in training both our DA module and our detection module\nin a semi-supervised manner, so that our detection module is also exposed to\nthe unlabeled target data, the type of data used in the testing stage. Using\nthese ideas, our method significantly outperforms the state-of-the-art method\n(47.6 mAP against the 44.3 mAP on the Foggy Cityscapes dataset), and obtains\nthe best performance on multiple real-image public datasets. Code is available\nat: https://github.com/VIML-CVDL/Object-Detection-in-Foggy-Scenes",
    "descriptor": "\nComments: Accepted by ACCV\n",
    "authors": [
      "Xin Yang",
      "Michael Bi Mi",
      "Yuan Yuan",
      "Xin Wang",
      "Robby T. Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13409"
  },
  {
    "id": "arXiv:2211.13411",
    "title": "Remote State Estimation with Privacy Against Eavesdroppers",
    "abstract": "We study the problem of remote state estimation in the presence of a passive\neavesdropper, under the challenging network environment of no packet receipt\nacknowledgments. A remote legitimate user estimates the state of a linear plant\nfrom the state information received from a sensor via an insecure and\nunreliable network. The transmission from the sensor may be intercepted by the\neavesdropper. To maintain state confidentiality, we propose an encoding scheme,\nwhich is activated on detection of an eavesdropper. Our scheme randomly\ntransmits noise based on a pseudo-random indicator, pre-arranged at the\nlegitimate user and sensor. The transmission of noise harms the eavesdropper's\nperformance. Under our encoding scheme, we impair the eavesdropper's expected\nestimation performance, whilst minimising expected performance degradation at\nthe legitimate user. We explore the trade-off between state secrecy and\nlegitimate user performance degradation.",
    "descriptor": "\nComments: 6 Pages, 3 figures\n",
    "authors": [
      "Matthew Crimson",
      "Justin M. Kennedy",
      "Daniel E. Quevedo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.13411"
  },
  {
    "id": "arXiv:2211.13416",
    "title": "Data Provenance Inference in Machine Learning",
    "abstract": "Unintended memorization of various information granularity has garnered\nacademic attention in recent years, e.g. membership inference and property\ninference. How to inversely use this privacy leakage to facilitate real-world\napplications is a growing direction; the current efforts include dataset\nownership inference and user auditing. Standing on the data lifecycle and ML\nmodel production, we propose an inference process named Data Provenance\nInference, which is to infer the generation, collection or processing property\nof the ML training data, to assist ML developers in locating the training data\ngaps without maintaining strenuous metadata. We formularly define the data\nprovenance and the data provenance inference task in ML training. Then we\npropose a novel inference strategy combining embedded-space multiple instance\nclassification and shadow learning. Comprehensive evaluations cover language,\nvisual and structured data in black-box and white-box settings, with diverse\nkinds of data provenance (i.e. business, county, movie, user). Our best\ninference accuracy achieves 98.96% in the white-box text model when \"author\" is\nthe data provenance. The experimental results indicate that, in general, the\ninference performance positively correlated with the amount of reference data\nfor inference, the depth and also the amount of the parameter of the accessed\nlayer. Furthermore, we give a post-hoc statistical analysis of the data\nprovenance definition to explain when our proposed method works well.",
    "descriptor": "",
    "authors": [
      "Mingxue Xu",
      "Xiang-Yang Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.13416"
  },
  {
    "id": "arXiv:2211.13419",
    "title": "Network Security Modelling with Distributional Data",
    "abstract": "We investigate the detection of botnet command and control (C2) hosts in\nmassive IP traffic using machine learning methods. To this end, we use NetFlow\ndata -- the industry standard for monitoring of IP traffic -- and ML models\nusing two sets of features: conventional NetFlow variables and distributional\nfeatures based on NetFlow variables. In addition to using static summaries of\nNetFlow features, we use quantiles of their IP-level distributions as input\nfeatures in predictive models to predict whether an IP belongs to known botnet\nfamilies. These models are used to develop intrusion detection systems to\npredict traffic traces identified with malicious attacks. The results are\nvalidated by matching predictions to existing denylists of published malicious\nIP addresses and deep packet inspection. The usage of our proposed novel\ndistributional features, combined with techniques that enable modelling complex\ninput feature spaces result in highly accurate predictions by our trained\nmodels.",
    "descriptor": "\nComments: Accepted and presented in CAMLIS 2022, this https URL arXiv admin note: text overlap with arXiv:2108.08924\n",
    "authors": [
      "Subhabrata Majumdar",
      "Ganesh Subramaniam"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.13419"
  },
  {
    "id": "arXiv:2211.13420",
    "title": "Projection pursuit adaptation on polynomial chaos expansions",
    "abstract": "The present work addresses the issue of accurate stochastic approximations in\nhigh-dimensional parametric space using tools from uncertainty quantification\n(UQ). The basis adaptation method and its accelerated algorithm in polynomial\nchaos expansions (PCE) were recently proposed to construct low-dimensional\napproximations adapted to specific quantities of interest (QoI). The present\npaper addresses one difficulty with these adaptations, namely their reliance on\nquadrature point sampling, which limits the reusability of potentially\nexpensive samples. Projection pursuit (PP) is a statistical tool to find the\n``interesting'' projections in high-dimensional data and thus bypass the\ncurse-of-dimensionality. In the present work, we combine the fundamental ideas\nof basis adaptation and projection pursuit regression (PPR) to propose a novel\nmethod to simultaneously learn the optimal low-dimensional spaces and PCE\nrepresentation from given data. While this projection pursuit adaptation (PPA)\ncan be entirely data-driven, the constructed approximation exhibits mean-square\nconvergence to the solution of an underlying governing equation and is thus\nsubject to the same physics constraints. The proposed approach is demonstrated\non a borehole problem and a structural dynamics problem, demonstrating the\nversatility of the method and its ability to discover low-dimensional manifolds\nwith high accuracy with limited data. In addition, the method can learn\nsurrogate models for different quantities of interest while reusing the same\ndata set.",
    "descriptor": "",
    "authors": [
      "Xiaoshu Zeng",
      "Roger Ghanem"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2211.13420"
  },
  {
    "id": "arXiv:2211.13424",
    "title": "Deepfake Detection via Joint Unsupervised Reconstruction and Supervised  Classification",
    "abstract": "Deep learning has enabled realistic face manipulation (i.e., deepfake), which\nposes significant concerns over the integrity of the media in circulation. Most\nexisting deep learning techniques for deepfake detection can achieve promising\nperformance in the intra-dataset evaluation setting (i.e., training and testing\non the same dataset), but are unable to perform satisfactorily in the\ninter-dataset evaluation setting (i.e., training on one dataset and testing on\nanother). Most of the previous methods use the backbone network to extract\nglobal features for making predictions and only employ binary supervision\n(i.e., indicating whether the training instances are fake or authentic) to\ntrain the network. Classification merely based on the learning of global\nfeatures leads often leads to weak generalizability to unseen manipulation\nmethods. In addition, the reconstruction task can improve the learned\nrepresentations. In this paper, we introduce a novel approach for deepfake\ndetection, which considers the reconstruction and classification tasks\nsimultaneously to address these problems. This method shares the information\nlearned by one task with the other, which focuses on a different aspect other\nexisting works rarely consider and hence boosts the overall performance. In\nparticular, we design a two-branch Convolutional AutoEncoder (CAE), in which\nthe Convolutional Encoder used to compress the feature map into the latent\nrepresentation is shared by both branches. Then the latent representation of\nthe input data is fed to a simple classifier and the unsupervised\nreconstruction component simultaneously. Our network is trained end-to-end.\nExperiments demonstrate that our method achieves state-of-the-art performance\non three commonly-used datasets, particularly in the cross-dataset evaluation\nsetting.",
    "descriptor": "",
    "authors": [
      "Bosheng Yan",
      "Xuequan Lu",
      "Chang-Tsun Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13424"
  },
  {
    "id": "arXiv:2211.13425",
    "title": "Automated Driving Systems Data Acquisition and Processing Platform",
    "abstract": "This paper presents an automated driving system (ADS) data acquisition and\nprocessing platform for vehicle trajectory extraction, reconstruction, and\nevaluation based on connected automated vehicle (CAV) cooperative perception.\nThis platform presents a holistic pipeline from the raw advanced sensory data\ncollection to data processing, which can process the sensor data from multiple\nCAVs and extract the objects' Identity (ID) number, position, speed, and\norientation information in the map and Frenet coordinates. First, the ADS data\nacquisition and analytics platform are presented. Specifically, the\nexperimental CAVs platform and sensor configuration are shown, and the\nprocessing software, including a deep-learning-based object detection algorithm\nusing LiDAR information, a late fusion scheme to leverage cooperative\nperception to fuse the detected objects from multiple CAVs, and a multi-object\ntracking method is introduced. To further enhance the object detection and\ntracking results, high definition maps consisting of point cloud and vector\nmaps are generated and forwarded to a world model to filter out the objects off\nthe road and extract the objects' coordinates in Frenet coordinates and the\nlane information. In addition, a post-processing method is proposed to refine\ntrajectories from the object tracking algorithms. Aiming to tackle the ID\nswitch issue of the object tracking algorithm, a fuzzy-logic-based approach is\nproposed to detect the discontinuous trajectories of the same object. Finally,\nresults, including object detection and tracking and a late fusion scheme, are\npresented, and the post-processing algorithm's improvements in noise level and\noutlier removal are discussed, confirming the functionality and effectiveness\nof the proposed holistic data collection and processing platform.",
    "descriptor": "",
    "authors": [
      "Xin Xia",
      "Zonglin Meng",
      "Xu Han",
      "Hanzhao Li",
      "Takahiro Tsukiji",
      "Runsheng Xu",
      "Zhaoliang Zhang",
      "Jiaqi Ma"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.13425"
  },
  {
    "id": "arXiv:2211.13428",
    "title": "Real-Time Marker Localization Learning for GelStereo Tactile Sensing",
    "abstract": "Visuotactile sensing technology is becoming more popular in tactile sensing,\nbut the effectiveness of the existing marker detection localization methods\nremains to be further explored. Instead of contour-based blob detection, this\npaper presents a learning-based marker localization network for GelStereo\nvisuotactile sensing called Marknet. Specifically, the Marknet presents a grid\nregression architecture to incorporate the distribution of the GelStereo\nmarkers. Furthermore, a marker rationality evaluator (MRE) is modelled to\nscreen suitable prediction results. The experimental results show that the\nMarknet combined with MRE achieves 93.90% precision for irregular markers in\ncontact areas, which outperforms the traditional contour-based blob detection\nmethod by a large margin of 42.32%. Meanwhile, the proposed learning-based\nmarker localization method can achieve better real-time performance beyond the\nblob detection interface provided by the OpenCV library through GPU\nacceleration, which we believe will lead to considerable perceptual sensitivity\ngains in various robotic manipulation tasks.",
    "descriptor": "",
    "authors": [
      "Shujuan Liu",
      "Shaowei Cui",
      "Chaofan Zhang",
      "Yinghao Cai",
      "Shuo Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.13428"
  },
  {
    "id": "arXiv:2211.13429",
    "title": "UV-Based 3D Hand-Object Reconstruction with Grasp Optimization",
    "abstract": "We propose a novel framework for 3D hand shape reconstruction and hand-object\ngrasp optimization from a single RGB image. The representation of hand-object\ncontact regions is critical for accurate reconstructions. Instead of\napproximating the contact regions with sparse points, as in previous works, we\npropose a dense representation in the form of a UV coordinate map. Furthermore,\nwe introduce inference-time optimization to fine-tune the grasp and improve\ninteractions between the hand and the object. Our pipeline increases hand shape\nreconstruction accuracy and produces a vibrant hand texture. Experiments on\ndatasets such as Ho3D, FreiHAND, and DexYCB reveal that our proposed method\noutperforms the state-of-the-art.",
    "descriptor": "\nComments: BMVC 2022 Spotlight\n",
    "authors": [
      "Ziwei Yu",
      "Linlin Yang",
      "You Xie",
      "Ping Chen",
      "Angela Yao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13429"
  },
  {
    "id": "arXiv:2211.13430",
    "title": "Multi-Job Intelligent Scheduling with Cross-Device Federated Learning",
    "abstract": "Recent years have witnessed a large amount of decentralized data in various\n(edge) devices of end-users, while the decentralized data aggregation remains\ncomplicated for machine learning jobs because of regulations and laws. As a\npractical approach to handling decentralized data, Federated Learning (FL)\nenables collaborative global machine learning model training without sharing\nsensitive raw data. The servers schedule devices to jobs within the training\nprocess of FL. In contrast, device scheduling with multiple jobs in FL remains\na critical and open problem. In this paper, we propose a novel multi-job FL\nframework, which enables the training process of multiple jobs in parallel. The\nmulti-job FL framework is composed of a system model and a scheduling method.\nThe system model enables a parallel training process of multiple jobs, with a\ncost model based on the data fairness and the training time of diverse devices\nduring the parallel training process. We propose a novel intelligent scheduling\napproach based on multiple scheduling methods, including an original\nreinforcement learning-based scheduling method and an original Bayesian\noptimization-based scheduling method, which corresponds to a small cost while\nscheduling devices to multiple jobs. We conduct extensive experimentation with\ndiverse jobs and datasets. The experimental results reveal that our proposed\napproaches significantly outperform baseline approaches in terms of training\ntime (up to 12.73 times faster) and accuracy (up to 46.4% higher).",
    "descriptor": "\nComments: To appear in TPDS; 22 pages, 17 figures, 8 tables. arXiv admin note: substantial text overlap with arXiv:2112.05928\n",
    "authors": [
      "Ji Liu",
      "Juncheng Jia",
      "Beichen Ma",
      "Chendi Zhou",
      "Jingbo Zhou",
      "Yang Zhou",
      "Huaiyu Dai",
      "Dejing Dou"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13430"
  },
  {
    "id": "arXiv:2211.13432",
    "title": "LaCAM: Search-Based Algorithm for Quick Multi-Agent Pathfinding",
    "abstract": "We propose a novel complete algorithm for multi-agent pathfinding (MAPF)\ncalled lazy constraints addition search for MAPF (LaCAM). MAPF is a problem of\nfinding collision-free paths for multiple agents on graphs and is the\nfoundation of multi-robot coordination. LaCAM uses a two-level search to find\nsolutions quickly, even with hundreds of agents or more. At the low-level, it\nsearches constraints about agents' locations. At the high-level, it searches a\nsequence of all agents' locations, following the constraints specified by the\nlow-level. Our exhaustive experiments reveal that LaCAM is comparable to or\noutperforms state-of-the-art sub-optimal MAPF algorithms in a variety of\nscenarios, regarding success rate, planning time, and solution quality of\nsum-of-costs.",
    "descriptor": "\nComments: to be presented at AAAI-23\n",
    "authors": [
      "Keisuke Okumura"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.13432"
  },
  {
    "id": "arXiv:2211.13434",
    "title": "A fast and simple $O (z \\log n)$-space index for finding approximately  longest common substrings",
    "abstract": "We describe how, given a text $T [1..n]$ and a positive constant $\\epsilon$,\nwe can build a simple $O (z \\log n)$-space index, where $z$ is the number of\nphrases in the LZ77 parse of $T$, such that later, given a pattern $P [1..m]$,\nin $O (m \\log \\log z + \\mathrm{polylog} (m + z))$ time and with high\nprobability we can find a substring of $P$ that occurs in $T$ and whose length\nis at least a $(1 - \\epsilon)$-fraction of the length of a longest common\nsubstring of $P$ and $T$.",
    "descriptor": "",
    "authors": [
      "Nick Fagan",
      "Jorge Hermo Gonz\u00e1lez",
      "Travis Gagie"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.13434"
  },
  {
    "id": "arXiv:2211.13435",
    "title": "A Benchmark of Long-tailed Instance Segmentation with Noisy Labels  (Short Version)",
    "abstract": "In this paper, we consider the instance segmentation task on a long-tailed\ndataset, which contains label noise, i.e., some of the annotations are\nincorrect. There are two main reasons making this case realistic. First,\ndatasets collected from real world usually obey a long-tailed distribution.\nSecond, for instance segmentation datasets, as there are many instances in one\nimage and some of them are tiny, it is easier to introduce noise into the\nannotations. Specifically, we propose a new dataset, which is a large\nvocabulary long-tailed dataset containing label noise for instance\nsegmentation. Furthermore, we evaluate previous proposed instance segmentation\nalgorithms on this dataset. The results indicate that the noise in the training\ndataset will hamper the model in learning rare categories and decrease the\noverall performance, and inspire us to explore more effective approaches to\naddress this practical challenge. The code and dataset are available in\nhttps://github.com/GuanlinLee/Noisy-LVIS.",
    "descriptor": "",
    "authors": [
      "Guanlin Li",
      "Guowen Xu",
      "Tianwei Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13435"
  },
  {
    "id": "arXiv:2211.13436",
    "title": "Solving Bilevel Knapsack Problem using Graph Neural Networks",
    "abstract": "The Bilevel Optimization Problem is a hierarchical optimization problem with\ntwo agents, a leader and a follower. The leader make their own decisions first,\nand the followers make the best choices accordingly. The leader knows the\ninformation of the followers, and the goal of the problem is to find the\noptimal solution by considering the reactions of the followers from the\nleader's point of view. For the Bilevel Optimization Problem, there are no\ngeneral and efficient algorithms or commercial solvers to get an optimal\nsolution, and it is very difficult to get a good solution even for a simple\nproblem. In this paper, we propose a deep learning approach using Graph Neural\nNetworks to solve the bilevel knapsack problem. We train the model to predict\nthe leader's solution and use it to transform the hierarchical optimization\nproblem into a single-level optimization problem to get the solution. Our model\nfound the feasible solution that was about 500 times faster than the exact\nalgorithm with $1.7\\%$ optimal gap. Also, our model performed well on problems\nof different size from the size it was trained on.",
    "descriptor": "\nComments: 27 pages, 2 figures\n",
    "authors": [
      "Sunhyeon Kwon",
      "Sungsoo Park"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.13436"
  },
  {
    "id": "arXiv:2211.13437",
    "title": "Seeing What You Miss: Vision-Language Pre-training with Semantic  Completion Learning",
    "abstract": "Cross-modal alignment is essential for vision-language pre-training (VLP)\nmodels to learn the correct corresponding information across different\nmodalities. For this purpose, inspired by the success of masked language\nmodeling (MLM) tasks in the NLP pre-training area, numerous masked modeling\ntasks have been proposed for VLP to further promote cross-modal interactions.\nThe core idea of previous masked modeling tasks is to focus on reconstructing\nthe masked tokens based on visible context for learning local-to-local\nalignment. However, most of them pay little attention to the global semantic\nfeatures generated for the masked data, resulting in the limited cross-modal\nalignment ability of global representations. Therefore, in this paper, we\npropose a novel Semantic Completion Learning (SCL) task, complementary to\nexisting masked modeling tasks, to facilitate global-to-local alignment.\nSpecifically, the SCL task complements the missing semantics of masked data by\ncapturing the corresponding information from the other modality, promoting\nlearning more representative global features which have a great impact on the\nperformance of downstream tasks. Moreover, we present a flexible vision\nencoder, which enables our model to perform image-text and video-text\nmultimodal tasks simultaneously. Experimental results show that our proposed\nmethod obtains state-of-the-art performance on various vision-language\nbenchmarks, such as visual question answering, image-text retrieval, and\nvideo-text retrieval.",
    "descriptor": "",
    "authors": [
      "Yatai Ji",
      "Rongcheng Tu",
      "Jie Jiang",
      "Weijie Kong",
      "Chengfei Cai",
      "Wenzhe Zhao",
      "Hongfa Wang",
      "Yujiu Yang",
      "Wei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.13437"
  },
  {
    "id": "arXiv:2211.13443",
    "title": "TESSP: Text-Enhanced Self-Supervised Speech Pre-training",
    "abstract": "Self-supervised speech pre-training empowers the model with the contextual\nstructure inherent in the speech signal while self-supervised text pre-training\nempowers the model with linguistic information. Both of them are beneficial for\ndownstream speech tasks such as ASR. However, the distinct pre-training\nobjectives make it challenging to jointly optimize the speech and text\nrepresentation in the same model. To solve this problem, we propose\nText-Enhanced Self-Supervised Speech Pre-training (TESSP), aiming to\nincorporate the linguistic information into speech pre-training. Our model\nconsists of three parts, i.e., a speech encoder, a text encoder and a shared\nencoder. The model takes unsupervised speech and text data as the input and\nleverages the common HuBERT and MLM losses respectively. We also propose\nphoneme up-sampling and representation swapping to enable joint modeling of the\nspeech and text information. Specifically, to fix the length mismatching\nproblem between speech and text data, we phonemize the text sequence and\nup-sample the phonemes with the alignment information extracted from a small\nset of supervised data. Moreover, to close the gap between the learned speech\nand text representations, we swap the text representation with the speech\nrepresentation extracted by the respective private encoders according to the\nalignment information. Experiments on the Librispeech dataset shows the\nproposed TESSP model achieves more than 10% improvement compared with WavLM on\nthe test-clean and test-other sets. We also evaluate our model on the SUPERB\nbenchmark, showing our model has better performance on Phoneme Recognition,\nAcoustic Speech Recognition and Speech Translation compared with WavLM.",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Zhuoyuan Yao",
      "Shuo Ren",
      "Sanyuan Chen",
      "Ziyang Ma",
      "Pengcheng Guo",
      "Lei Xie"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.13443"
  },
  {
    "id": "arXiv:2211.13445",
    "title": "Delving into Out-of-Distribution Detection with Vision-Language  Representations",
    "abstract": "Recognizing out-of-distribution (OOD) samples is critical for machine\nlearning systems deployed in the open world. The vast majority of OOD detection\nmethods are driven by a single modality (e.g., either vision or language),\nleaving the rich information in multi-modal representations untapped. Inspired\nby the recent success of vision-language pre-training, this paper enriches the\nlandscape of OOD detection from a single-modal to a multi-modal regime.\nParticularly, we propose Maximum Concept Matching (MCM), a simple yet effective\nzero-shot OOD detection method based on aligning visual features with textual\nconcepts. We contribute in-depth analysis and theoretical insights to\nunderstand the effectiveness of MCM. Extensive experiments demonstrate that MCM\nachieves superior performance on a wide variety of real-world tasks. MCM with\nvision-language features outperforms a common baseline with pure visual\nfeatures on a hard OOD task with semantically similar classes by 13.1% (AUROC).\nCode is available at https://github.com/deeplearning-wisc/MCM.",
    "descriptor": "\nComments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Yifei Ming",
      "Ziyang Cai",
      "Jiuxiang Gu",
      "Yiyou Sun",
      "Wei Li",
      "Yixuan Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13445"
  },
  {
    "id": "arXiv:2211.13447",
    "title": "On the Complexity of Counterfactual Reasoning",
    "abstract": "We study the computational complexity of counterfactual reasoning in relation\nto the complexity of associational and interventional reasoning on structural\ncausal models (SCMs). We show that counterfactual reasoning is no harder than\nassociational or interventional reasoning on fully specified SCMs in the\ncontext of two computational frameworks. The first framework is based on the\nnotion of treewidth and includes the classical variable elimination and\njointree algorithms. The second framework is based on the more recent and\nrefined notion of causal treewidth which is directed towards models with\nfunctional dependencies such as SCMs. Our results are constructive and based on\nbounding the (causal) treewidth of twin networks -- used in standard\ncounterfactual reasoning that contemplates two worlds, real and imaginary -- to\nthe (causal) treewidth of the underlying SCM structure. In particular, we show\nthat the latter (causal) treewidth is no more than twice the former plus one.\nHence, if associational or interventional reasoning is tractable on a fully\nspecified SCM then counterfactual reasoning is tractable too. We extend our\nresults to general counterfactual reasoning that requires contemplating more\nthan two worlds and discuss applications of our results to counterfactual\nreasoning with a partially specified SCM that is coupled with data. We finally\npresent empirical results that measure the gap between the complexities of\ncounterfactual reasoning and associational/interventional reasoning on random\nSCMs.",
    "descriptor": "\nComments: An earlier version of this paper appeared in NeurIPS 2022 workshop, \"A causal view on dynamical systems.\"\n",
    "authors": [
      "Yunqiu Han",
      "Yizuo Chen",
      "Adnan Darwiche"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.13447"
  },
  {
    "id": "arXiv:2211.13448",
    "title": "Robust fractional-order fast terminal sliding mode control of aerial  manipulator derived from a mutable inertia parameters model",
    "abstract": "The coupling disturbance between the manipulator and the unmanned aerial\nvehicle (UAV) deteriorates the control performance of system. To get high\nperformance of the aerial manipulator, a robust fractional order fast terminal\nsliding mode control (FOFTSMC) strategy based on mutable inertia parameters is\nproposed in this paper. First, the dynamics of aerial manipulator with\nconsideration of the coupling disturbance is derived by utilizing mutable\ninertia parameters. Then, based on the dynamic model, a robust FOFTSMC\nalgorithm is designed to make the system fly steadily under coupling\ndisturbance. Furthermore, stability analysis is conducted to prove the\nconvergence of tracking errors. Finally, comparative simulation results are\ngiven to show the validity and superiority of the proposed scheme.",
    "descriptor": "\nComments: This paper has been accepted by ICBDAI2022\n",
    "authors": [
      "Wenlei Zheng",
      "Zhan Li",
      "Bingkai Xiu",
      "Bingliang Zhao",
      "Zhigang Guo"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.13448"
  },
  {
    "id": "arXiv:2211.13449",
    "title": "Fast Sampling of Diffusion Models via Operator Learning",
    "abstract": "Diffusion models have found widespread adoption in various areas. However,\nsampling from them is slow because it involves emulating a reverse process with\nhundreds-to-thousands of network evaluations. Inspired by the success of neural\noperators in accelerating differential equations solving, we approach this\nproblem by solving the underlying neural differential equation from an operator\nlearning perspective. We examine probability flow ODE trajectories in diffusion\nmodels and observe a compact energy spectrum that can be learned efficiently in\nFourier space. With this insight, we propose diffusion Fourier neural operator\n(DFNO) with temporal convolution in Fourier space to parameterize the operator\nthat maps initial condition to the solution trajectory, which is a continuous\nfunction in time. DFNO can be applied to any diffusion model and generate\nhigh-quality samples in one model forward call. Our method achieves the\nstate-of-the-art FID of 4.72 on CIFAR-10 using only one model evaluation.",
    "descriptor": "",
    "authors": [
      "Hongkai Zheng",
      "Weili Nie",
      "Arash Vahdat",
      "Kamyar Azizzadenesheli",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13449"
  },
  {
    "id": "arXiv:2211.13454",
    "title": "Differentially Private Heatmaps",
    "abstract": "We consider the task of producing heatmaps from users' aggregated data while\nprotecting their privacy. We give a differentially private (DP) algorithm for\nthis task and demonstrate its advantages over previous algorithms on real-world\ndatasets.\nOur core algorithmic primitive is a DP procedure that takes in a set of\ndistributions and produces an output that is close in Earth Mover's Distance to\nthe average of the inputs. We prove theoretical bounds on the error of our\nalgorithm under a certain sparsity assumption and that these are near-optimal.",
    "descriptor": "\nComments: To appear in AAAI 2023\n",
    "authors": [
      "Badih Ghazi",
      "Junfeng He",
      "Kai Kohlhoff",
      "Ravi Kumar",
      "Pasin Manurangsi",
      "Vidhya Navalpakkam",
      "Nachiappan Valliappan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.13454"
  },
  {
    "id": "arXiv:2211.13455",
    "title": "Automated Quantification of Traffic Particulate Emissions via an Image  Analysis Pipeline",
    "abstract": "Traffic emissions are known to contribute significantly to air pollution\naround the world, especially in heavily urbanized cities such as Singapore. It\nhas been previously shown that the particulate pollution along major roadways\nexhibit strong correlation with increased traffic during peak hours, and that\nreductions in traffic emissions can lead to better health outcomes. However, in\nmany instances, obtaining proper counts of vehicular traffic remains manual and\nextremely laborious. This then restricts one's ability to carry out\nlongitudinal monitoring for extended periods, for example, when trying to\nunderstand the efficacy of intervention measures such as new traffic\nregulations (e.g. car-pooling) or for computational modelling. Hence, in this\nstudy, we propose and implement an integrated machine learning pipeline that\nutilizes traffic images to obtain vehicular counts that can be easily\nintegrated with other measurements to facilitate various studies. We verify the\nutility and accuracy of this pipeline on an open-source dataset of traffic\nimages obtained for a location in Singapore and compare the obtained vehicular\ncounts with collocated particulate measurement data obtained over a 2-week\nperiod in 2022. The roadside particulate emission is observed to correlate well\nwith obtained vehicular counts with a correlation coefficient of 0.93,\nindicating that this method can indeed serve as a quick and effective correlate\nof particulate emissions.",
    "descriptor": "",
    "authors": [
      "Kong Yuan Ho",
      "Chin Seng Lim",
      "Matthena A. Kattar",
      "Bharathi Boppana",
      "Liya Yu",
      "Chin Chun Ooi"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2211.13455"
  },
  {
    "id": "arXiv:2211.13461",
    "title": "Highest-performance Stream Processing",
    "abstract": "We present the stream processing library that achieves the highest\nperformance of existing OCaml streaming libraries, attaining the speed and\nmemory efficiency of hand-written state machines. It supports finite and\ninfinite streams with the familiar declarative interface, of any combination of\nmap, filter, take(while), drop(while), zip, flatmap combinators and tupling.\nExperienced users may use the lower-level interface of stateful streams and\nimplement accumulating maps, compression and windowing. The library is based on\nassured code generation (at present, of OCaml and C) and guarantees in all\ncases complete fusion.",
    "descriptor": "\nComments: Peer-reviewed, accepted for presentation and presented at the ACM SIGPLAN OCAML 2022 workshop\n",
    "authors": [
      "Oleg Kiselyov",
      "Tomoaki Kobayashi",
      "Aggelos Biboudis",
      "Nick Palladinos"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.13461"
  },
  {
    "id": "arXiv:2211.13462",
    "title": "Estimation of Similarity between DNA Sequences and Its Graphical  Representation",
    "abstract": "Bioinformatics, which is now a well known field of study, originated in the\ncontext of biological sequence analysis. Recently graphical representation\ntakes place for the research on DNA sequence. Research in biological sequence\nis mainly based on the function and its structure. Bioinformatics finds wide\nrange of applications specifically in the domain of molecular biology which\nfocuses on the analysis of molecules viz. DNA, RNA, Protein etc. In this\nreview, we mainly deal with the similarity analysis between sequences and\ngraphical representation of DNA sequence.",
    "descriptor": "\nComments: 8 pages, 13 Figures, 4 Tables\n",
    "authors": [
      "Probir Mondal"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.13462"
  },
  {
    "id": "arXiv:2211.13464",
    "title": "Design of Turing Systems with Physics-Informed Neural Networks",
    "abstract": "Reaction-diffusion (Turing) systems are fundamental to the formation of\nspatial patterns in nature and engineering. These systems are governed by a set\nof non-linear partial differential equations containing parameters that\ndetermine the rate of constituent diffusion and reaction. Critically, these\nparameters, such as diffusion coefficient, heavily influence the mode and type\nof the final pattern, and quantitative characterization and knowledge of these\nparameters can aid in bio-mimetic design or understanding of real-world\nsystems. However, the use of numerical methods to infer these parameters can be\ndifficult and computationally expensive. Typically, adjoint solvers may be\nused, but they are frequently unstable for very non-linear systems.\nAlternatively, massive amounts of iterative forward simulations are used to\nfind the best match, but this is extremely effortful. Recently,\nphysics-informed neural networks have been proposed as a means for data-driven\ndiscovery of partial differential equations, and have seen success in various\napplications. Thus, we investigate the use of physics-informed neural networks\nas a tool to infer key parameters in reaction-diffusion systems in the\nsteady-state for scientific discovery or design. Our proof-of-concept results\nshow that the method is able to infer parameters for different pattern modes\nand types with errors of less than 10\\%. In addition, the stochastic nature of\nthis method can be exploited to provide multiple parameter alternatives to the\ndesired pattern, highlighting the versatility of this method for bio-mimetic\ndesign. This work thus demonstrates the utility of physics-informed neural\nnetworks for inverse parameter inference of reaction-diffusion systems to\nenhance scientific discovery and design.",
    "descriptor": "",
    "authors": [
      "Jordon Kho",
      "Winston Koh",
      "Jian Cheng Wong",
      "Pao-Hsiung Chiu",
      "Chin Chun Ooi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biological Physics (physics.bio-ph)",
      "Chemical Physics (physics.chem-ph)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2211.13464"
  },
  {
    "id": "arXiv:2211.13465",
    "title": "On the Importance of Image Encoding in Automated Chest X-Ray Report  Generation",
    "abstract": "Chest X-ray is one of the most popular medical imaging modalities due to its\naccessibility and effectiveness. However, there is a chronic shortage of\nwell-trained radiologists who can interpret these images and diagnose the\npatient's condition. Therefore, automated radiology report generation can be a\nvery helpful tool in clinical practice. A typical report generation workflow\nconsists of two main steps: (i) encoding the image into a latent space and (ii)\ngenerating the text of the report based on the latent image embedding. Many\nexisting report generation techniques use a standard convolutional neural\nnetwork (CNN) architecture for image encoding followed by a Transformer-based\ndecoder for medical text generation. In most cases, CNN and the decoder are\ntrained jointly in an end-to-end fashion. In this work, we primarily focus on\nunderstanding the relative importance of encoder and decoder components.\nTowards this end, we analyze four different image encoding approaches: direct,\nfine-grained, CLIP-based, and Cluster-CLIP-based encodings in conjunction with\nthree different decoders on the large-scale MIMIC-CXR dataset. Among these\nencoders, the cluster CLIP visual encoder is a novel approach that aims to\ngenerate more discriminative and explainable representations. CLIP-based\nencoders produce comparable results to traditional CNN-based encoders in terms\nof NLP metrics, while fine-grained encoding outperforms all other encoders both\nin terms of NLP and clinical accuracy metrics, thereby validating the\nimportance of image encoder to effectively extract semantic information. GitHub\nrepository: https://github.com/mudabek/encoding-cxr-report-gen",
    "descriptor": "",
    "authors": [
      "Otabek Nazarov",
      "Mohammad Yaqub",
      "Karthik Nandakumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13465"
  },
  {
    "id": "arXiv:2211.13466",
    "title": "Hierarchical Consistent Contrastive Learning for Skeleton-Based Action  Recognition with Growing Augmentations",
    "abstract": "Contrastive learning has been proven beneficial for self-supervised\nskeleton-based action recognition. Most contrastive learning methods utilize\ncarefully designed augmentations to generate different movement patterns of\nskeletons for the same semantics. However, it is still a pending issue to apply\nstrong augmentations, which distort the images/skeletons' structures and cause\nsemantic loss, due to their resulting unstable training. In this paper, we\ninvestigate the potential of adopting strong augmentations and propose a\ngeneral hierarchical consistent contrastive learning framework (HiCLR) for\nskeleton-based action recognition. Specifically, we first design a gradual\ngrowing augmentation policy to generate multiple ordered positive pairs, which\nguide to achieve the consistency of the learned representation from different\nviews. Then, an asymmetric loss is proposed to enforce the hierarchical\nconsistency via a directional clustering operation in the feature space,\npulling the representations from strongly augmented views closer to those from\nweakly augmented views for better generalizability. Meanwhile, we propose and\nevaluate three kinds of strong augmentations for 3D skeletons to demonstrate\nthe effectiveness of our method. Extensive experiments show that HiCLR\noutperforms the state-of-the-art methods notably on three large-scale datasets,\ni.e., NTU60, NTU120, and PKUMMD.",
    "descriptor": "\nComments: Accepted by AAAI 2023. Project page: this https URL\n",
    "authors": [
      "Jiahang Zhang",
      "Lilang Lin",
      "Jiaying Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13466"
  },
  {
    "id": "arXiv:2211.13469",
    "title": "NQE: N-ary Query Embedding for Complex Query Answering over  Hyper-relational Knowledge Graphs",
    "abstract": "Complex query answering (CQA) is an essential task for multi-hop and logical\nreasoning on knowledge graphs (KGs). Currently, most approaches are limited to\nqueries among binary relational facts and pay less attention to n-ary facts\n(n>=2) containing more than two entities, which are more prevalent in the real\nworld. Moreover, previous CQA methods can only make predictions for a few given\ntypes of queries and cannot be flexibly extended to more complex logical\nqueries, which significantly limits their applications. To overcome these\nchallenges, in this work, we propose a novel N-ary Query Embedding (NQE) model\nfor CQA over hyper-relational knowledge graphs (HKGs), which include massive\nn-ary facts. The NQE utilizes a dual-heterogeneous Transformer encoder and\nfuzzy logic theory to satisfy all n-ary FOL queries, including existential\nquantifiers, conjunction, disjunction, and negation. We also propose a parallel\nprocessing algorithm that can train or predict arbitrary n-ary FOL queries in a\nsingle batch, regardless of the kind of each query, with good flexibility and\nextensibility. In addition, we generate a new CQA dataset WD50K-NFOL, including\ndiverse n-ary FOL queries over WD50K. Experimental results on WD50K-NFOL and\nother standard CQA datasets show that NQE is the state-of-the-art CQA method\nover HKGs with good generalization capability. Our code and dataset are\npublicly available.",
    "descriptor": "\nComments: Accepted by the 37th AAAI Conference on Artificial Intelligence (AAAI-2023)\n",
    "authors": [
      "Haoran Luo",
      "Haihong E",
      "Yuhao Yang",
      "Gengxian Zhou",
      "Yikai Guo",
      "Tianyu Yao",
      "Zichen Tang",
      "Xueyuan Lin",
      "Kaiyang Wan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13469"
  },
  {
    "id": "arXiv:2211.13470",
    "title": "Efficient Zero-shot Visual Search via Target and Context-aware  Transformer",
    "abstract": "Visual search is a ubiquitous challenge in natural vision, including daily\ntasks such as finding a friend in a crowd or searching for a car in a parking\nlot. Human rely heavily on relevant target features to perform goal-directed\nvisual search. Meanwhile, context is of critical importance for locating a\ntarget object in complex scenes as it helps narrow down the search area and\nmakes the search process more efficient. However, few works have combined both\ntarget and context information in visual search computational models. Here we\npropose a zero-shot deep learning architecture, TCT (Target and Context-aware\nTransformer), that modulates self attention in the Vision Transformer with\ntarget and contextual relevant information to enable human-like zero-shot\nvisual search performance. Target modulation is computed as patch-wise local\nrelevance between the target and search images, whereas contextual modulation\nis applied in a global fashion. We conduct visual search experiments on TCT and\nother competitive visual search models on three natural scene datasets with\nvarying levels of difficulty. TCT demonstrates human-like performance in terms\nof search efficiency and beats the SOTA models in challenging visual search\ntasks. Importantly, TCT generalizes well across datasets with novel objects\nwithout retraining or fine-tuning. Furthermore, we also introduce a new dataset\nto benchmark models for invariant visual search under incongruent contexts. TCT\nmanages to search flexibly via target and context modulation, even under\nincongruent contexts.",
    "descriptor": "",
    "authors": [
      "Zhiwei Ding",
      "Xuezhe Ren",
      "Erwan David",
      "Melissa Vo",
      "Gabriel Kreiman",
      "Mengmi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13470"
  },
  {
    "id": "arXiv:2211.13471",
    "title": "Minority-Oriented Vicinity Expansion with Attentive Aggregation for  Video Long-Tailed Recognition",
    "abstract": "A dramatic increase in real-world video volume with extremely diverse and\nemerging topics naturally forms a long-tailed video distribution in terms of\ntheir categories, and it spotlights the need for Video Long-Tailed Recognition\n(VLTR). In this work, we summarize the challenges in VLTR and explore how to\novercome them. The challenges are: (1) it is impractical to re-train the whole\nmodel for high-quality features, (2) acquiring frame-wise labels requires\nextensive cost, and (3) long-tailed data triggers biased training. Yet, most\nexisting works for VLTR unavoidably utilize image-level features extracted from\npretrained models which are task-irrelevant, and learn by video-level labels.\nTherefore, to deal with such (1) task-irrelevant features and (2) video-level\nlabels, we introduce two complementary learnable feature aggregators. Learnable\nlayers in each aggregator are to produce task-relevant representations, and\neach aggregator is to assemble the snippet-wise knowledge into a video\nrepresentative. Then, we propose Minority-Oriented Vicinity Expansion (MOVE)\nthat explicitly leverages the class frequency into approximating the vicinity\ndistributions to alleviate (3) biased training. By combining these solutions,\nour approach achieves state-of-the-art results on large-scale VideoLT and\nsynthetically induced Imbalanced-MiniKinetics200. With VideoLT features from\nResNet-50, it attains 18% and 58% relative improvements on head and tail\nclasses over the previous state-of-the-art method, respectively.",
    "descriptor": "\nComments: Accepted to AAAI 2023. Code is available at this https URL\n",
    "authors": [
      "WonJun Moon",
      "Hyun Seok Seong",
      "Jae-Pil Heo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13471"
  },
  {
    "id": "arXiv:2211.13473",
    "title": "Communication Complexity of Inner Product in Symmetric Normed Spaces",
    "abstract": "We introduce and study the communication complexity of computing the inner\nproduct of two vectors, where the input is restricted w.r.t. a norm $N$ on the\nspace $\\mathbb{R}^n$. Here, Alice and Bob hold two vectors $v,u$ such that\n$\\|v\\|_N\\le 1$ and $\\|u\\|_{N^*}\\le 1$, where $N^*$ is the dual norm. They want\nto compute their inner product $\\langle v,u \\rangle$ up to an $\\varepsilon$\nadditive term. The problem is denoted by $\\mathrm{IP}_N$.\nWe systematically study $\\mathrm{IP}_N$, showing the following results:\n- For any symmetric norm $N$, given $\\|v\\|_N\\le 1$ and $\\|u\\|_{N^*}\\le 1$\nthere is a randomized protocol for $\\mathrm{IP}_N$ using\n$\\tilde{\\mathcal{O}}(\\varepsilon^{-6} \\log n)$ bits -- we will denote this by\n$\\mathcal{R}_{\\varepsilon,1/3}(\\mathrm{IP}_{N}) \\leq\n\\tilde{\\mathcal{O}}(\\varepsilon^{-6} \\log n)$.\n- One way communication complexity\n$\\overrightarrow{\\mathcal{R}}(\\mathrm{IP}_{\\ell_p})\\leq\\mathcal{O}(\\varepsilon^{-\\max(2,p)}\\cdot\n\\log\\frac n\\varepsilon)$, and a nearly matching lower bound\n$\\overrightarrow{\\mathcal{R}}(\\mathrm{IP}_{\\ell_p}) \\geq\n\\Omega(\\varepsilon^{-\\max(2,p)})$ for $\\varepsilon^{-\\max(2,p)} \\ll n$.\n- One way communication complexity $\\overrightarrow{\\mathcal{R}}(N)$ for a\nsymmetric norm $N$ is governed by embeddings $\\ell_\\infty^k$ into $N$.\nSpecifically, while a small distortion embedding easily implies a lower bound\n$\\Omega(k)$, we show that, conversely, non-existence of such an embedding\nimplies protocol with communication $k^{\\mathcal{O}(\\log \\log k)} \\log^2 n$.\n- For arbitrary origin symmetric convex polytope $P$, we show\n$\\mathcal{R}(\\mathrm{IP}_{N}) \\le\\mathcal{O}(\\varepsilon^{-2} \\log\n\\mathrm{xc}(P))$, where $N$ is the unique norm for which $P$ is a unit ball,\nand $\\mathrm{xc}(P)$ is the extension complexity of $P$.",
    "descriptor": "\nComments: Accepted to ITCS 2023\n",
    "authors": [
      "Alexandr Andoni",
      "Jaros\u0142aw B\u0142asiok",
      "Arnold Filtser"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.13473"
  },
  {
    "id": "arXiv:2211.13474",
    "title": "Explainable and Safe Reinforcement Learning for Autonomous Air Mobility",
    "abstract": "Increasing traffic demands, higher levels of automation, and communication\nenhancements provide novel design opportunities for future air traffic\ncontrollers (ATCs). This article presents a novel deep reinforcement learning\n(DRL) controller to aid conflict resolution for autonomous free flight.\nAlthough DRL has achieved important advancements in this field, the existing\nworks pay little attention to the explainability and safety issues related to\nDRL controllers, particularly the safety under adversarial attacks. To address\nthose two issues, we design a fully explainable DRL framework wherein we: 1)\ndecompose the coupled Q value learning model into a safety-awareness and\nefficiency (reach the target) one; and 2) use information from surrounding\nintruders as inputs, eliminating the needs of central controllers. In our\nsimulated experiments, we show that by decoupling the safety-awareness and\nefficiency, we can exceed performance on free flight control tasks while\ndramatically improving explainability on practical. In addition, the safety Q\nlearning module provides rich information about the safety situation of\nenvironments. To study the safety under adversarial attacks, we additionally\npropose an adversarial attack strategy that can impose both safety-oriented and\nefficiency-oriented attacks. The adversarial aims to minimize safety/efficiency\nby only attacking the agent at a few time steps. In the experiments, our attack\nstrategy increases as many collisions as the uniform attack (i.e., attacking at\nevery time step) by only attacking the agent four times less often, which\nprovide insights into the capabilities and restrictions of the DRL in future\nATC designs. The source code is publicly available at\nhttps://github.com/WLeiiiii/Gym-ATC-Attack-Project.",
    "descriptor": "",
    "authors": [
      "Lei Wang",
      "Hongyu Yang",
      "Yi Lin",
      "Suwan Yin",
      "Yuankai Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.13474"
  },
  {
    "id": "arXiv:2211.13481",
    "title": "The Second-place Solution for CVPR 2022 SoccerNet Tracking Challenge",
    "abstract": "This is our second-place solution for CVPR 2022 SoccerNet Tracking Challenge.\nOur method mainly includes two steps: online short-term tracking using our\nCascaded Buffer-IoU (C-BIoU) Tracker, and, offline long-term tracking using\nappearance feature and hierarchical clustering. At each step, online tracking\nyielded HOTA scores near 90, and offline tracking further improved HOTA scores\nto around 93.2.",
    "descriptor": "",
    "authors": [
      "Fan Yang",
      "Shigeyuki Odashima",
      "Shoichi Masui",
      "Shan Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13481"
  },
  {
    "id": "arXiv:2211.13483",
    "title": "Towards computer vision technologies: Semi-automated reading of  automated utility meters",
    "abstract": "In this report we analysed a possibility of using computer vision techniques\nfor automated reading of utility meters. In our study, we focused on two\ncomputer vision techniques: an open-source solution Tensorflow Object Detection\n(Tensorflow) and a commercial solution Anyline. This report extends our\nprevious publication: We start with presentation of a structured analysis of\nrelated approaches. After that we provide a detailed comparison of two computer\nvision technologies, Tensorflow Object Detection (Tensorflow) and Anyline,\napplied to semi-automated reading of utility meters. In this paper, we discuss\nlimitations and benefits of each solution applied to utility meters reading,\nespecially focusing on aspects such as accuracy and inference time. Our goal\nwas to determine the solution that is the most suitable for this particular\napplication area, where there are several specific challenges.",
    "descriptor": "",
    "authors": [
      "Maria Spichkova",
      "Johan van Zyl"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13483"
  },
  {
    "id": "arXiv:2211.13484",
    "title": "Robust-MSA: Understanding the Impact of Modality Noise on Multimodal  Sentiment Analysis",
    "abstract": "Improving model robustness against potential modality noise, as an essential\nstep for adapting multimodal models to real-world applications, has received\nincreasing attention among researchers. For Multimodal Sentiment Analysis\n(MSA), there is also a debate on whether multimodal models are more effective\nagainst noisy features than unimodal ones. Stressing on intuitive illustration\nand in-depth analysis of these concerns, we present Robust-MSA, an interactive\nplatform that visualizes the impact of modality noise as well as simple defence\nmethods to help researchers know better about how their models perform with\nimperfect real-world data.",
    "descriptor": "\nComments: Accept by AAAI 2023. Code is available at this https URL\n",
    "authors": [
      "Huisheng Mao",
      "Baozheng Zhang",
      "Hua Xu",
      "Ziqi Yuan",
      "Yihe Liu"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.13484"
  },
  {
    "id": "arXiv:2211.13490",
    "title": "Pose-disentangled Contrastive Learning for Self-supervised Facial  Representation",
    "abstract": "Self-supervised facial representation has recently attracted increasing\nattention due to its ability to perform face understanding without relying on\nlarge-scale annotated datasets heavily. However, analytically, current\ncontrastive-based self-supervised learning still performs unsatisfactorily for\nlearning facial representation. More specifically, existing contrastive\nlearning (CL) tends to learn pose-invariant features that cannot depict the\npose details of faces, compromising the learning performance. To conquer the\nabove limitation of CL, we propose a novel Pose-disentangled Contrastive\nLearning (PCL) method for general self-supervised facial representation. Our\nPCL first devises a pose-disentangled decoder (PDD) with a delicately designed\northogonalizing regulation, which disentangles the pose-related features from\nthe face-aware features; therefore, pose-related and other pose-unrelated\nfacial information could be performed in individual subnetworks and do not\naffect each other's training. Furthermore, we introduce a pose-related\ncontrastive learning scheme that learns pose-related information based on data\naugmentation of the same image, which would deliver more effective face-aware\nrepresentation for various downstream tasks. We conducted a comprehensive\nlinear evaluation on three challenging downstream facial understanding tasks,\ni.e., facial expression recognition, face recognition, and AU detection.\nExperimental results demonstrate that our method outperforms cutting-edge\ncontrastive and other self-supervised learning methods with a great margin.",
    "descriptor": "",
    "authors": [
      "Yuanyuan Liu",
      "Wenbin Wang",
      "Yibing Zhan",
      "Zhe Chen",
      "Shaoze Feng",
      "Kejun Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13490"
  },
  {
    "id": "arXiv:2211.13491",
    "title": "Spatial Mixture-of-Experts",
    "abstract": "Many data have an underlying dependence on spatial location; it may be\nweather on the Earth, a simulation on a mesh, or a registered image. Yet this\nfeature is rarely taken advantage of, and violates common assumptions made by\nmany neural network layers, such as translation equivariance. Further, many\nworks that do incorporate locality fail to capture fine-grained structure. To\naddress this, we introduce the Spatial Mixture-of-Experts (SMoE) layer, a\nsparsely-gated layer that learns spatial structure in the input domain and\nroutes experts at a fine-grained level to utilize it. We also develop new\ntechniques to train SMoEs, including a self-supervised routing loss and damping\nexpert errors. Finally, we show strong results for SMoEs on numerous tasks, and\nset new state-of-the-art results for medium-range weather prediction and\npost-processing ensemble weather forecasts.",
    "descriptor": "\nComments: 20 pages, 3 figures; NeurIPS 2022\n",
    "authors": [
      "Nikoli Dryden",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13491"
  },
  {
    "id": "arXiv:2211.13494",
    "title": "Immersive Neural Graphics Primitives",
    "abstract": "Neural radiance field (NeRF), in particular its extension by instant neural\ngraphics primitives, is a novel rendering method for view synthesis that uses\nreal-world images to build photo-realistic immersive virtual scenes. Despite\nits potential, research on the combination of NeRF and virtual reality (VR)\nremains sparse. Currently, there is no integration into typical VR systems\navailable, and the performance and suitability of NeRF implementations for VR\nhave not been evaluated, for instance, for different scene complexities or\nscreen resolutions. In this paper, we present and evaluate a NeRF-based\nframework that is capable of rendering scenes in immersive VR allowing users to\nfreely move their heads to explore complex real-world scenes. We evaluate our\nframework by benchmarking three different NeRF scenes concerning their\nrendering performance at different scene complexities and resolutions.\nUtilizing super-resolution, our approach can yield a frame rate of 30 frames\nper second with a resolution of 1280x720 pixels per eye. We discuss potential\napplications of our framework and provide an open source implementation online.",
    "descriptor": "\nComments: Submitted to IEEE VR, currently under review\n",
    "authors": [
      "Ke Li",
      "Tim Rolff",
      "Susanne Schmidt",
      "Reinhard Bacher",
      "Simone Frintrop",
      "Wim Leemans",
      "Frank Steinicke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13494"
  },
  {
    "id": "arXiv:2211.13495",
    "title": "Few-shot Object Detection with Refined Contrastive Learning",
    "abstract": "Due to the scarcity of sampling data in reality, few-shot object detection\n(FSOD) has drawn more and more attention because of its ability to quickly\ntrain new detection concepts with less data. However, there are still failure\nidentifications due to the difficulty in distinguishing confusable classes. We\nalso notice that the high standard deviation of average precisions reveals the\ninconsistent detection performance. To this end, we propose a novel FSOD method\nwith Refined Contrastive Learning (FSRC). A pre-determination component is\nintroduced to find out the Resemblance Group (GR) from novel classes which\ncontains confusable classes. Afterwards, refined contrastive learning (RCL) is\npointedly performed on this group of classes in order to increase the\ninter-class distances among them. In the meantime, the detection results\ndistribute more uniformly which further improve the performance. Experimental\nresults based on PASCAL VOC and COCO datasets demonstrate our proposed method\noutperforms the current state-of-the-art research. FSRC can not only decouple\nthe relevance of confusable classes to get a better performance, but also makes\npredictions more consistent by reducing the standard deviation of the AP of\nclasses to be detected.",
    "descriptor": "",
    "authors": [
      "Zeyu Shangguan",
      "Lian Huai",
      "Tong Liu",
      "Xingqun Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13495"
  },
  {
    "id": "arXiv:2211.13498",
    "title": "GitHub Considered Harmful? Analyzing Open-Source Projects for the  Automatic Generation of Cryptographic API Call Sequences",
    "abstract": "GitHub is a popular data repository for code examples. It is being\ncontinuously used to train several AI-based tools to automatically generate\ncode. However, the effectiveness of such tools in correctly demonstrating the\nusage of cryptographic APIs has not been thoroughly assessed. In this paper, we\ninvestigate the extent and severity of misuses, specifically caused by\nincorrect cryptographic API call sequences in GitHub. We also analyze the\nsuitability of GitHub data to train a learning-based model to generate correct\ncryptographic API call sequences. For this, we manually extracted and analyzed\nthe call sequences from GitHub. Using this data, we augmented an existing\nlearning-based model called DeepAPI to create two security-specific models that\ngenerate cryptographic API call sequences for a given natural language (NL)\ndescription. Our results indicate that it is imperative to not neglect the\nmisuses in API call sequences while using data sources like GitHub, to train\nmodels that generate code.",
    "descriptor": "\nComments: Accepted at QRS 2022\n",
    "authors": [
      "Catherine Tony",
      "Nicol\u00e1s E. D\u00edaz Ferreyra",
      "Riccardo Scandariato"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.13498"
  },
  {
    "id": "arXiv:2211.13500",
    "title": "Multi-Task Learning of Object State Changes from Uncurated Videos",
    "abstract": "We aim to learn to temporally localize object state changes and the\ncorresponding state-modifying actions by observing people interacting with\nobjects in long uncurated web videos. We introduce three principal\ncontributions. First, we explore alternative multi-task network architectures\nand identify a model that enables efficient joint learning of multiple object\nstates and actions such as pouring water and pouring coffee. Second, we design\na multi-task self-supervised learning procedure that exploits different types\nof constraints between objects and state-modifying actions enabling end-to-end\ntraining of a model for temporal localization of object states and actions in\nvideos from only noisy video-level supervision. Third, we report results on the\nlarge-scale ChangeIt and COIN datasets containing tens of thousands of long\n(un)curated web videos depicting various interactions such as hole drilling,\ncream whisking, or paper plane folding. We show that our multi-task model\nachieves a relative improvement of 40% over the prior single-task methods and\nsignificantly outperforms both image-based and video-based zero-shot models for\nthis problem. We also test our method on long egocentric videos of the\nEPIC-KITCHENS and the Ego4D datasets in a zero-shot setup demonstrating the\nrobustness of our learned model.",
    "descriptor": "",
    "authors": [
      "Tom\u00e1\u0161 Sou\u010dek",
      "Jean-Baptiste Alayrac",
      "Antoine Miech",
      "Ivan Laptev",
      "Josef Sivic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13500"
  },
  {
    "id": "arXiv:2211.13503",
    "title": "Optimization of Humanoid Robot Designs for Human-Robot Ergonomic Payload  Lifting",
    "abstract": "When a human and a humanoid robot collaborate physically, ergonomics is a key\nfactor to consider. Assuming a given humanoid robot, several control\narchitectures exist nowadays to address ergonomic physical human-robot\ncollaboration. This paper takes one step further by considering robot hardware\nparameters as optimization variables in the problem of collaborative payload\nlifting. The variables that parametrize robot's kinematics and dynamics ensure\ntheir physical consistency, and the human model is considered in the\noptimization problem. By leveraging the proposed modelling framework, the\nergonomy of the interaction is maximized, here given by the agents' energy\nexpenditure. Robot kinematic, dynamics, hardware constraints and human\ngeometries are considered when solving the associated optimization problem. The\nproposed methodology is used to identify optimum hardware parameters for the\ndesign of the ergoCub robot, a humanoid possessing a degree of embodied\nintelligence for ergonomic interaction with humans. For the optimization\nproblem, the starting point is the iCub humanoid robot. The obtained robot\ndesign reaches loads at heights in the range of 0.8-1.5 m with respect to the\niCub robot whose range is limited to 0.8-1.2 m. The robot energy expenditure is\ndecreased by about 33%, meanwhile, the human ergonomy is preserved, leading\noverall to an improved interaction.",
    "descriptor": "\nComments: Accepted to 2022 IEEE-RAS International Conference on Humanoid Robotics (Humanoids)\n",
    "authors": [
      "Carlotta Sartore",
      "Lorenzo Rapetti",
      "Daniele Pucci"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.13503"
  },
  {
    "id": "arXiv:2211.13507",
    "title": "Identifiability of nonlinear ODE Models with Time-Varying Parameters:  the General Analytical Solution and Applications in Viral Dynamics",
    "abstract": "Identifiability is a structural property of any ODE model characterized by a\nset of unknown parameters. It describes the possibility of determining the\nvalues of these parameters from fusing the observations of the system inputs\nand outputs. This paper finds the general analytical solution of this\nfundamental problem and, based on this, provides a general and automated\nanalytical method to determine the identifiability of the unknown parameters.\nIn particular, the method can handle any model, regardless of its complexity\nand type of non-linearity, and provides the identifiability of the parameters\neven when they are time-varying. In addition, it is automatic as it simply\nneeds to follow the steps of a systematic procedure that only requires to\nperform the calculation of derivatives and matrix ranks. Time-varying\nparameters are treated as unknown inputs and their identification is based on\nthe very recent analytical solution of the unknown input observability problem,\nrecently published on Information Fusion journal. The method is used to\ndetermine the identifiability of the unknown time-varying parameters that\ncharacterize two non-linear models in the field of viral dynamics (HIV and\nCovid-19). New fundamental properties that characterize these viral models are\ndetermined and discussed in detail through a comparison with the\nstate-of-the-art results. In particular, regarding the very popular HIV ODE\nmodel here investigated, the method automatically finds a new important result\nthat is in contrast with the results in the current literature.",
    "descriptor": "",
    "authors": [
      "Agostino Martinelli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.13507"
  },
  {
    "id": "arXiv:2211.13508",
    "title": "1st Workshop on Maritime Computer Vision (MaCVi) 2023: Challenge Results",
    "abstract": "The 1$^{\\text{st}}$ Workshop on Maritime Computer Vision (MaCVi) 2023 focused\non maritime computer vision for Unmanned Aerial Vehicles (UAV) and Unmanned\nSurface Vehicle (USV), and organized several subchallenges in this domain: (i)\nUAV-based Maritime Object Detection, (ii) UAV-based Maritime Object Tracking,\n(iii) USV-based Maritime Obstacle Segmentation and (iv) USV-based Maritime\nObstacle Detection. The subchallenges were based on the SeaDronesSee and MODS\nbenchmarks. %This report summarizes the main findings of the individual\nsubchallenges, which are (1) UAV-based Maritime Object Detection, (2) UAV-based\nMaritime Object Tracking, (3) USV-based Maritime Obstacle Segmentation and (4)\nUSV-based Maritime Obstacle Detection. This report summarizes the main findings\nof the individual subchallenges and introduces %Furthermore, we introduce a new\nbenchmark, called SeaDronesSee Object Detection v2, which extends the previous\nbenchmark by including more classes and footage. We provide statistical and\nqualitative analyses, and assess trends in the best-performing methodologies of\nover 130 submissions. The methods are summarized in the appendix. %The tech\nreport for most of the top performing methods is attached. The datasets,\nevaluation code and the %competition's final standing leaderboard are publicly\navailable at https://seadronessee.cs.uni-tuebingen.de/macvi.",
    "descriptor": "\nComments: MaCVi 2023 was part of WACV 2023. This report (38 pages) discusses the competition as part of MaCVi\n",
    "authors": [
      "Benjamin Kiefer",
      "Matej Kristan",
      "Janez Per\u0161",
      "Lojze \u017dust",
      "Fabio Poiesi",
      "Fabio Augusto de Alcantara Andrade",
      "Alexandre Bernardino",
      "Matthew Dawkins",
      "Jenni Raitoharju",
      "Yitong Quan",
      "Adem Atmaca",
      "Timon H\u00f6fer",
      "Qiming Zhang",
      "Yufei Xu",
      "Jing Zhang",
      "Dacheng Tao",
      "Lars Sommer",
      "Raphael Spraul",
      "Hangyue Zhao",
      "Hongpu Zhang",
      "Yanyun Zhao",
      "Jan Lukas Augustin",
      "Eui-ik Jeon",
      "Impyeong Lee",
      "Luca Zedda",
      "Andrea Loddo",
      "Cecilia Di Ruberto",
      "Sagar Verma",
      "Siddharth Gupta",
      "Shishir Muralidhara",
      "Niharika Hegde",
      "Daitao Xing",
      "Nikolaos Evangeliou",
      "Anthony Tzes",
      "Vojt\u011bch Bartl",
      "Jakub \u0160pa\u0148hel",
      "Adam Herout",
      "Neelanjan Bhowmik",
      "Toby P. Breckon",
      "Shivanand Kundargi",
      "Tejas Anvekar",
      "Chaitra Desai",
      "Ramesh Ashok Tabib",
      "Uma Mudengudi",
      "Arpita Vats",
      "Yang Song",
      "Delong Liu",
      "Yonglin Li",
      "Shuman Li",
      "Chenhao Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.13508"
  },
  {
    "id": "arXiv:2211.13509",
    "title": "The Second-place Solution for ECCV 2022 Multiple People Tracking in  Group Dance Challenge",
    "abstract": "This is our 2nd-place solution for the ECCV 2022 Multiple People Tracking in\nGroup Dance Challenge. Our method mainly includes two steps: online short-term\ntracking using our Cascaded Buffer-IoU (C-BIoU) Tracker, and, offline long-term\ntracking using appearance feature and hierarchical clustering. Our C-BIoU\ntracker adds buffers to expand the matching space of detections and tracks,\nwhich mitigates the effect of irregular motions in two aspects: one is to\ndirectly match identical but non-overlapping detections and tracks in adjacent\nframes, and the other is to compensate for the motion estimation bias in the\nmatching space. In addition, to reduce the risk of overexpansion of the\nmatching space, cascaded matching is employed: first matching alive tracks and\ndetections with a small buffer, and then matching unmatched tracks and\ndetections with a large buffer. After using our C-BIoU for online tracking, we\napplied the offline refinement introduced by ReMOTS.",
    "descriptor": "",
    "authors": [
      "Fan Yang",
      "Shigeyuki Odashima",
      "Shoichi Masui",
      "Shan Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13509"
  },
  {
    "id": "arXiv:2211.13514",
    "title": "Link Count Data-driven Static Traffic Assignment Models Through Network  Modularity Partitioning",
    "abstract": "Accurate static traffic assignment models are important tools for the\nassessment of strategic transportation policies. In this article we present a\nnovel approach to partition road networks through network modularity to produce\ndata-driven static traffic assignment models from loop detector data on large\nroad systems. The use of partitioning allows the estimation of the key model\ninput of Origin-Destination demand matrices from flow counts alone. Previous\nnetwork tomography-based demand estimation techniques have been limited by the\nnetwork size. The amount of partitioning changes the Origin-Destination\nestimation optimisation problems to different levels of computational\ndifficulty. Different approaches to utilising the partitioning were tested, one\nwhich degenerated the road network to the scale of the partitions and others\nwhich left the network intact. Applied to a subnetwork of England's Strategic\nRoad Network and other test networks, our results for the degenerate case\nshowed flow and travel time errors are reasonable with a small amount of\ndegeneration. The results for the non-degenerate cases showed that similar\nerrors in model prediction with lower computation requirements can be obtained\nwhen using large partitions compared with the non-partitioned case. This work\ncould be used to improve the effectiveness of national road systems planning\nand infrastructure models.",
    "descriptor": "\nComments: 29 pages, 11 figures\n",
    "authors": [
      "Alexander Roocroft",
      "Giuliano Punzo",
      "Muhamad Azfar Ramli"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.13514"
  },
  {
    "id": "arXiv:2211.13515",
    "title": "TSGP: Two-Stage Generative Prompting for Unsupervised Commonsense  Question Answering",
    "abstract": "Unsupervised commonsense question answering requires mining effective\ncommonsense knowledge without the rely on the labeled task data. Previous\nmethods typically retrieved from traditional knowledge bases or used\npre-trained language models (PrLMs) to generate fixed types of knowledge, which\nhave poor generalization ability. In this paper, we aim to address the above\nlimitation by leveraging the implicit knowledge stored in PrLMs and propose a\ntwo-stage prompt-based unsupervised commonsense question answering framework\n(TSGP). Specifically, we first use knowledge generation prompts to generate the\nknowledge required for questions with unlimited types and possible candidate\nanswers independent of specified choices. Then, we further utilize answer\ngeneration prompts to generate possible candidate answers independent of\nspecified choices. Experimental results and analysis on three different\ncommonsense reasoning tasks, CommonsenseQA, OpenBookQA, and SocialIQA,\ndemonstrate that TSGP significantly improves the reasoning ability of language\nmodels in unsupervised settings. Our code is available at:\nhttps://github.com/Yueqing-Sun/TSGP.",
    "descriptor": "\nComments: Findings of EMNLP2022\n",
    "authors": [
      "Yueqing Sun",
      "Yu Zhang",
      "Le Qi",
      "Qi Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13515"
  },
  {
    "id": "arXiv:2211.13518",
    "title": "Chinese Character Recognition with Radical-Structured Stroke Trees",
    "abstract": "The flourishing blossom of deep learning has witnessed the rapid development\nof Chinese character recognition. However, it remains a great challenge that\nthe characters for testing may have different distributions from those of the\ntraining dataset. Existing methods based on a single-level representation\n(character-level, radical-level, or stroke-level) may be either too sensitive\nto distribution changes (e.g., induced by blurring, occlusion, and zero-shot\nproblems) or too tolerant to one-to-many ambiguities. In this paper, we\nrepresent each Chinese character as a stroke tree, which is organized according\nto its radical structures, to fully exploit the merits of both radical and\nstroke levels in a decent way. We propose a two-stage decomposition framework,\nwhere a Feature-to-Radical Decoder perceives radical structures and radical\nregions, and a Radical-to-Stroke Decoder further predicts the stroke sequences\naccording to the features of radical regions. The generated radical structures\nand stroke sequences are encoded as a Radical-Structured Stroke Tree (RSST),\nwhich is fed to a Tree-to-Character Translator based on the proposed Weighted\nEdit Distance to match the closest candidate character in the RSST lexicon. Our\nextensive experimental results demonstrate that the proposed method outperforms\nthe state-of-the-art single-level methods by increasing margins as the\ndistribution difference becomes more severe in the blurring, occlusion, and\nzero-shot scenarios, which indeed validates the robustness of the proposed\nmethod.",
    "descriptor": "",
    "authors": [
      "Haiyang Yu",
      "Jingye Chen",
      "Bin Li",
      "Xiangyang Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13518"
  },
  {
    "id": "arXiv:2211.13521",
    "title": "A Velocity-based Moving Mesh Virtual Element Method",
    "abstract": "We present a velocity-based moving mesh virtual element method for the\nnumerical solution of PDEs involving moving boundaries. The virtual element\nmethod is used for computing both the mesh velocity and a conservative\nArbitrary Lagrangian-Eulerian solution transfer on general polygonal meshes.\nThe approach extends the linear finite element method to polygonal mesh\nstructures, achieving the same degree of accuracy. In the context of moving\nmeshes, a major advantage of the virtual element approach is the ease with\nwhich nodes can be inserted on mesh edges. Demonstrations of node insertion\ntechniques are presented to show that moving polygonal meshes can be simply\nadapted for situations where a boundary encounters a solid object or another\nmoving boundary, without reduction in degree of accuracy.",
    "descriptor": "",
    "authors": [
      "H. Wells",
      "M. E. Hubbard",
      "A. Cangiani"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.13521"
  },
  {
    "id": "arXiv:2211.13523",
    "title": "Roboflow 100: A Rich, Multi-Domain Object Detection Benchmark",
    "abstract": "The evaluation of object detection models is usually performed by optimizing\na single metric, e.g. mAP, on a fixed set of datasets, e.g. Microsoft COCO and\nPascal VOC. Due to image retrieval and annotation costs, these datasets consist\nlargely of images found on the web and do not represent many real-life domains\nthat are being modelled in practice, e.g. satellite, microscopic and gaming,\nmaking it difficult to assert the degree of generalization learned by the\nmodel. We introduce the Roboflow-100 (RF100) consisting of 100 datasets, 7\nimagery domains, 224,714 images, and 805 class labels with over 11,170\nlabelling hours. We derived RF100 from over 90,000 public datasets, 60 million\npublic images that are actively being assembled and labelled by computer vision\npractitioners in the open on the web application Roboflow Universe. By\nreleasing RF100, we aim to provide a semantically diverse, multi-domain\nbenchmark of datasets to help researchers test their model's generalizability\nwith real-life data. RF100 download and benchmark replication are available on\nGitHub.",
    "descriptor": "",
    "authors": [
      "Floriana Ciaglia",
      "Francesco Saverio Zuppichini",
      "Paul Guerrie",
      "Mark McQuade",
      "Jacob Solawetz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13523"
  },
  {
    "id": "arXiv:2211.13524",
    "title": "GAN Prior based Null-Space Learning for Consistent Super-Resolution",
    "abstract": "Consistency and realness have always been the two critical issues of image\nsuper-resolution. While the realness has been dramatically improved with the\nuse of GAN prior, the state-of-the-art methods still suffer inconsistencies in\nlocal structures and colors (e.g., tooth and eyes). In this paper, we show that\nthese inconsistencies can be analytically eliminated by learning only the\nnull-space component while fixing the range-space part. Further, we design a\npooling-based decomposition (PD), a universal range-null space decomposition\nfor super-resolution tasks, which is concise, fast, and parameter-free. PD can\nbe easily applied to state-of-the-art GAN Prior based SR methods to eliminate\ntheir inconsistencies, neither compromising the realness nor bringing extra\nparameters or computational costs. Besides, our ablation studies reveal that PD\ncan replace pixel-wise losses for training and achieve better generalization\nperformance when facing unseen downsamplings or even real-world degradation.\nExperiments show that the use of PD refreshes state-of-the-art SR performance\nand speeds up the convergence of training up to 2~10 times.",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Yinhuai Wang",
      "Yujie Hu",
      "Jiwen Yu",
      "Jian Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.13524"
  },
  {
    "id": "arXiv:2211.13525",
    "title": "Multi-Objective Search-Based Software Microbenchmark Prioritization",
    "abstract": "Ensuring that software performance does not degrade after a code change is\nparamount. A potential solution, particularly for libraries and frameworks, is\nregularly executing software microbenchmarks, a performance testing technique\nsimilar to (functional) unit tests. This often becomes infeasible due to the\nextensive runtimes of microbenchmark suites, however. To address that\nchallenge, research has investigated regression testing techniques, such as\ntest case prioritization (TCP), which reorder the execution within a\nmicrobenchmark suite to detect larger performance changes sooner. Such\ntechniques are either designed for unit tests and perform sub-par on\nmicrobenchmarks or require complex performance models, reducing their potential\napplication drastically. In this paper, we propose a search-based technique\nbased on multi-objective evolutionary algorithms (MOEAs) to improve the current\nstate of microbenchmark prioritization. The technique utilizes three\nobjectives, i.e., coverage to maximize, coverage overlap to minimize, and\nhistorical performance change detection to maximize. We find that our technique\nimproves over the best coverage-based, greedy baselines in terms of average\npercentage of fault-detection on performance (APFD-P) and Top-3 effectiveness\nby 26 percentage points (pp) and 43 pp (for Additional) and 17 pp and 32 pp\n(for Total) to 0.77 and 0.24, respectively. Employing the Indicator-Based\nEvolutionary Algorithm (IBEA) as MOEA leads to the best effectiveness among six\nMOEAs. Finally, the technique's runtime overhead is acceptable at 19% of the\noverall benchmark suite runtime, if we consider the enormous runtimes often\nspanning multiple hours. The added overhead compared to the greedy baselines is\nminiscule at 1%.These results mark a step forward for universally applicable\nperformance regression testing techniques.",
    "descriptor": "\nComments: 17 pages, 5 figures\n",
    "authors": [
      "Christoph Laaber",
      "Tao Yue",
      "Shaukat Ali"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.13525"
  },
  {
    "id": "arXiv:2211.13526",
    "title": "Specognitor: Identifying Spectre Vulnerabilities via Prediction-Aware  Symbolic Execution",
    "abstract": "Spectre attacks exploit speculative execution to leak sensitive information.\nIn the last few years, a number of static side-channel detectors have been\nproposed to detect cache leakage in the presence of speculative execution.\nHowever, these techniques either ignore branch prediction mechanism, detect\nstatic pre-defined patterns which is not suitable for detecting new patterns,\nor lead to false negatives.\nIn this paper, we illustrate the weakness of prediction-agnostic\nstate-of-the-art approaches. We propose Specognitor, a novel prediction-aware\nsymbolic execution engine to soundly explore program paths and detect subtle\nspectre variant 1 and variant 2 vulnerabilities. We propose a dynamic pattern\ndetection mechanism to account for both existing and future vulnerabilities.\nOur experimental results show the effectiveness and efficiency of Specognitor\nin analyzing real-world cryptographic programs w.r.t. different processor\nfamilies.",
    "descriptor": "",
    "authors": [
      "Ali Sahraee"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)",
      "Symbolic Computation (cs.SC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.13526"
  },
  {
    "id": "arXiv:2211.13527",
    "title": "Beyond Mahalanobis-Based Scores for Textual OOD Detection",
    "abstract": "Deep learning methods have boosted the adoption of NLP systems in real-life\napplications. However, they turn out to be vulnerable to distribution shifts\nover time which may cause severe dysfunctions in production systems, urging\npractitioners to develop tools to detect out-of-distribution (OOD) samples\nthrough the lens of the neural network. In this paper, we introduce TRUSTED, a\nnew OOD detector for classifiers based on Transformer architectures that meets\noperational requirements: it is unsupervised and fast to compute. The\nefficiency of TRUSTED relies on the fruitful idea that all hidden layers carry\nrelevant information to detect OOD examples. Based on this, for a given input,\nTRUSTED consists in (i) aggregating this information and (ii) computing a\nsimilarity score by exploiting the training distribution, leveraging the\npowerful concept of data depth. Our extensive numerical experiments involve 51k\nmodel configurations, including various checkpoints, seeds, and datasets, and\ndemonstrate that TRUSTED achieves state-of-the-art performances. In particular,\nit improves previous AUROC over 3 points.",
    "descriptor": "",
    "authors": [
      "Pierre Colombo",
      "Eduardo D. C. Gomes",
      "Guillaume Staerman",
      "Nathan Noiry",
      "Pablo Piantanida"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.13527"
  },
  {
    "id": "arXiv:2211.13529",
    "title": "3D Dual-Fusion: Dual-Domain Dual-Query Camera-LiDAR Fusion for 3D Object  Detection",
    "abstract": "Fusing data from cameras and LiDAR sensors is an essential technique to\nachieve robust 3D object detection. One key challenge in camera-LiDAR fusion\ninvolves mitigating the large domain gap between the two sensors in terms of\ncoordinates and data distribution when fusing their features. In this paper, we\npropose a novel camera-LiDAR fusion architecture called, 3D Dual-Fusion, which\nis designed to mitigate the gap between the feature representations of camera\nand LiDAR data. The proposed method fuses the features of the camera-view and\n3D voxel-view domain and models their interactions through deformable\nattention. We redesign the transformer fusion encoder to aggregate the\ninformation from the two domains. Two major changes include 1) dual query-based\ndeformable attention to fuse the dual-domain features interactively and 2) 3D\nlocal self-attention to encode the voxel-domain queries prior to dual-query\ndecoding. The results of an experimental evaluation show that the proposed\ncamera-LiDAR fusion architecture achieved competitive performance on the KITTI\nand nuScenes datasets, with state-of-the-art performances in some 3D object\ndetection benchmarks categories.",
    "descriptor": "\nComments: 12 pages, 3 figures\n",
    "authors": [
      "Yecheol Kim",
      "Konyul Park",
      "Minwook Kim",
      "Dongsuk Kum",
      "Jun Won Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13529"
  },
  {
    "id": "arXiv:2211.13535",
    "title": "Tracking Dataset IP Use in Deep Neural Networks",
    "abstract": "Training highly performant deep neural networks (DNNs) typically requires the\ncollection of a massive dataset and the use of powerful computing resources.\nTherefore, unauthorized redistribution of private pre-trained DNNs may cause\nsevere economic loss for model owners. For protecting the ownership of DNN\nmodels, DNN watermarking schemes have been proposed by embedding secret\ninformation in a DNN model and verifying its presence for model ownership.\nHowever, existing DNN watermarking schemes compromise the model utility and are\nvulnerable to watermark removal attacks because a model is modified with a\nwatermark. Alternatively, a new approach dubbed DEEPJUDGE was introduced to\nmeasure the similarity between a suspect model and a victim model without\nmodifying the victim model. However, DEEPJUDGE would only be designed to detect\nthe case where a suspect model's architecture is the same as a victim model's.\nIn this work, we propose a novel DNN fingerprinting technique dubbed DEEPTASTER\nto prevent a new attack scenario in which a victim's data is stolen to build a\nsuspect model. DEEPTASTER can effectively detect such data theft attacks even\nwhen a suspect model's architecture differs from a victim model's. To achieve\nthis goal, DEEPTASTER generates a few adversarial images with perturbations,\ntransforms them into the Fourier frequency domain, and uses the transformed\nimages to identify the dataset used in a suspect model. The intuition is that\nthose adversarial images can be used to capture the characteristics of DNNs\nbuilt on a specific dataset. We evaluated the detection accuracy of DEEPTASTER\non three datasets with three model architectures under various attack\nscenarios, including transfer learning, pruning, fine-tuning, and data\naugmentation. Overall, DEEPTASTER achieves a balanced accuracy of 94.95%, which\nis significantly better than 61.11% achieved by DEEPJUDGE in the same settings.",
    "descriptor": "",
    "authors": [
      "Seonhye Park",
      "Alsharif Abuadbba",
      "Shuo Wang",
      "Kristen Moore",
      "Yansong Gao",
      "Hyoungshick Kim",
      "Surya Nepal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13535"
  },
  {
    "id": "arXiv:2211.13536",
    "title": "Proprioceptive Sensing of Soft Tentacles with Model Based Reconstruction  for Controller Optimization",
    "abstract": "The success of soft robots in displaying emergent behaviors is tightly linked\nto the compliant interaction with the environment. However, to exploit such\nphenomena, proprioceptive sensing methods which do not hinder their softness\nare needed. In this work we propose a new sensing approach for soft underwater\nslender structures based on embedded pressure sensors and use a learning-based\npipeline to link the sensor readings to the shape of the soft structure. Using\ntwo different modeling techniques, we compare the pose reconstruction accuracy\nand identify the optimal approach. Using the proprioceptive sensing\ncapabilities we show how this information can be used to assess the swimming\nperformance over a number of metrics, namely swimming thrust, tip deflection,\nand the traveling wave index. We conclude by demonstrating the robustness of\nthe embedded sensor on a free swimming soft robotic squid swimming at a maximum\nvelocity of 9.5 cm/s, with the absolute tip deflection being predicted within\nan error less than 9% without the aid of external sensors.",
    "descriptor": "",
    "authors": [
      "Andrea Vicari",
      "Nana Obayashi",
      "Francesco Stella",
      "Gaetan Raynaud",
      "Karen Mulleners",
      "Cosimo Della Santina",
      "Josie Hughes"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.13536"
  },
  {
    "id": "arXiv:2211.13539",
    "title": "Optical MIMO communication with unequal power allocation to channels",
    "abstract": "Multiple input multiple output (MIMO) approach in fiber optical communication\nhas emerged as an effective proposition to address the ever increasing demand\nfor information exchange. In the ergodic case, the multiple channels,\nassociated with multiple modes or cores or both in the optical fiber, is\nmodeled by the Jacobi ensemble of random matrices. A key quantity for assessing\nthe performance of MIMO systems is the mutual information (MI). We focus here\non the case of an arbitrary transmission covariance matrix and derive exact\ndeterminant based results for the moment generating function (MGF) of mutual\ninformation (MI), and thereby address the scenario of unequal power per excited\nmode. The MGF is used to obtain Gaussian- and Weibull-distribution based\napproximations for the probability density function (PDF), cumulative\ndistribution function (CDF) or, equivalently, the outage probability, and also\nthe survival function (SF) or reliability function. Moreover, a numerical\nFourier inversion approach is implemented to obtain the PDF, CDF, and SF\ndirectly from the MGF. The MGF is further used to investigate the ergodic\ncapacity, which is the first moment (mean) of the mutual information. The\nanalytical results are found to be in excellent agreement with Monte Carlo\nsimulations. Our study goes beyond the earlier investigations where covariance\nmatrix proportional to identity matrix has been considered which corresponds to\nequal power allocation per excited mode.",
    "descriptor": "\nComments: 16 pages; 12 figures; 3 tables; Published version (some typos fixed)\n",
    "authors": [
      "Aritra Laha",
      "Santosh Kumar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.13539"
  },
  {
    "id": "arXiv:2211.13542",
    "title": "A Privacy-Preserving Outsourced Data Model in Cloud Environment",
    "abstract": "Nowadays, more and more machine learning applications, such as medical\ndiagnosis, online fraud detection, email spam filtering, etc., services are\nprovided by cloud computing. The cloud service provider collects the data from\nthe various owners to train or classify the machine learning system in the\ncloud environment. However, multiple data owners may not entirely rely on the\ncloud platform that a third party engages. Therefore, data security and privacy\nproblems are among the critical hindrances to using machine learning tools,\nparticularly with multiple data owners. In addition, unauthorized entities can\ndetect the statistical input data and infer the machine learning model\nparameters. Therefore, a privacy-preserving model is proposed, which protects\nthe privacy of the data without compromising machine learning efficiency. In\norder to protect the data of data owners, the epsilon-differential privacy is\nused, and fog nodes are used to address the problem of the lower bandwidth and\nlatency in this proposed scheme. The noise is produced by the\nepsilon-differential mechanism, which is then added to the data. Moreover, the\nnoise is injected at the data owner site to protect the owners data. Fog nodes\ncollect the noise-added data from the data owners, then shift it to the cloud\nplatform for storage, computation, and performing the classification tasks\npurposes.",
    "descriptor": "",
    "authors": [
      "Rishabh Gupta",
      "Ashutosh Kumar Singh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13542"
  },
  {
    "id": "arXiv:2211.13543",
    "title": "Impure Simplicial Complexes: Complete Axiomatization",
    "abstract": "Combinatorial topology is used in distributed computing to model concurrency\nand asynchrony. The basic structure in combinatorial topology is the simplicial\ncomplex, a collection of subsets called simplices of a set of vertices, closed\nunder containment. Pure simplicial complexes describe message passing in\nasynchronous systems where all processes (agents) are alive, whereas impure\nsimplicial complexes describe message passing in synchronous systems where\nprocesses may be dead (have crashed). Properties of impure simplicial complexes\ncan be described in a three-valued multi-agent epistemic logic where the third\nvalue represents formulas that are undefined, e.g., the knowledge and local\npropositions of dead agents. In this work we present the axiomatization called\n$\\mathsf{S5}^{\\bowtie}$ and show that it is sound and complete for the class of\nimpure complexes. The completeness proof involves the novel construction of the\ncanonical simplicial model and requires a careful manipulation of undefined\nformulas.",
    "descriptor": "",
    "authors": [
      "Rojo Fanamperana Randrianomentsoa",
      "Hans van Ditmarsch",
      "Roman Kuznets"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.13543"
  },
  {
    "id": "arXiv:2211.13546",
    "title": "Number Theoretic Transform and Its Applications in Lattice-based  Cryptosystems: A Survey",
    "abstract": "Number theoretic transform (NTT) is the most efficient method for multiplying\ntwo polynomials of high degree with integer coefficients, due to its series of\nadvantages in terms of algorithm and implementation, and is consequently\nwidely-used and particularly fundamental in the practical implementations of\nlattice-based cryptographic schemes. Especially, recent works have shown that\nNTT can be utilized in those schemes without NTT-friendly rings, and can\noutperform other multiplication algorithms. In this paper, we first review the\nbasic concepts of polynomial multiplication, convolution and NTT. Subsequently,\nwe systematically introduce basic radix-2 fast NTT algorithms in an algebraic\nway via Chinese Remainder Theorem. And then, we elaborate recent advances about\nthe methods to weaken restrictions on parameter conditions of NTT. Furthermore,\nwe systematically introduce how to choose appropriate strategy of NTT\nalgorithms for the various given rings. Later, we introduce the applications of\nNTT in the lattice-based cryptographic schemes of NIST post-quantum\ncryptography standardization competition. Finally, we try to present some\npossible future research directions.",
    "descriptor": "",
    "authors": [
      "Zhichuang Liang",
      "Yunlei Zhao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.13546"
  },
  {
    "id": "arXiv:2211.13551",
    "title": "SfM-TTR: Using Structure from Motion for Test-Time Refinement of  Single-View Depth Networks",
    "abstract": "Estimating a dense depth map from a single view is geometrically ill-posed,\nand state-of-the-art methods rely on learning depth's relation with visual\nappearance using deep neural networks. On the other hand, Structure from Motion\n(SfM) leverages multi-view constraints to produce very accurate but sparse\nmaps, as accurate matching across images is limited by locally discriminative\ntexture. In this work, we combine the strengths of both approaches by proposing\na novel test-time refinement (TTR) method, denoted as SfM-TTR, that boosts the\nperformance of single-view depth networks at test time using SfM multi-view\ncues. Specifically, and differently from the state of the art, we use sparse\nSfM point clouds as test-time self-supervisory signal, fine-tuning the network\nencoder to learn a better representation of the test scene. Our results show\nhow the addition of SfM-TTR to several state-of-the-art self-supervised and\nsupervised networks improves significantly their performance, outperforming\nprevious TTR baselines mainly based on photometric multi-view consistency.",
    "descriptor": "",
    "authors": [
      "Sergio Izquierdo",
      "Javier Civera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13551"
  },
  {
    "id": "arXiv:2211.13554",
    "title": "Quality-Based Conditional Processing in Multi-Biometrics: Application to  Sensor Interoperability",
    "abstract": "As biometric technology is increasingly deployed, it will be common to\nreplace parts of operational systems with newer designs. The cost and\ninconvenience of reacquiring enrolled users when a new vendor solution is\nincorporated makes this approach difficult and many applications will require\nto deal with information from different sources regularly. These\ninteroperability problems can dramatically affect the performance of biometric\nsystems and thus, they need to be overcome. Here, we describe and evaluate the\nATVS-UAM fusion approach submitted to the quality-based evaluation of the 2007\nBioSecure Multimodal Evaluation Campaign, whose aim was to compare fusion\nalgorithms when biometric signals were generated using several biometric\ndevices in mismatched conditions. Quality measures from the raw biometric data\nare available to allow system adjustment to changing quality conditions due to\ndevice changes. This system adjustment is referred to as quality-based\nconditional processing. The proposed fusion approach is based on linear\nlogistic regression, in which fused scores tend to be log-likelihood-ratios.\nThis allows the easy and efficient combination of matching scores from\ndifferent devices assuming low dependence among modalities. In our system,\nquality information is used to switch between different system modules\ndepending on the data source (the sensor in our case) and to reject channels\nwith low quality data during the fusion. We compare our fusion approach to a\nset of rule-based fusion schemes over normalized scores. Results show that the\nproposed approach outperforms all the rule-based fusion schemes. We also show\nthat with the quality-based channel rejection scheme, an overall improvement of\n25% in the equal error rate is obtained.",
    "descriptor": "\nComments: Published at IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans\n",
    "authors": [
      "Fernando Alonso-Fernandez",
      "Julian Fierrez",
      "Daniel Ramos",
      "Joaquin Gonzalez-Rodriguez"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13554"
  },
  {
    "id": "arXiv:2211.13555",
    "title": "Error estimates for the scalar auxiliary variable (SAV) scheme to the  Cahn-Hilliard equation",
    "abstract": "The optimal error estimate that depending only on the polynomial degree of $\n\\varepsilon^{-1}$ is established for the temporal semi-discrete scheme of the\nCahn-Hilliard equation, which is based on the scalar auxiliary variable (SAV)\nformulation. The key to our analysis is to convert the structure of the SAV\ntime-stepping scheme back to a form compatible with the original format of the\nCahn-Hilliard equation, which makes it feasible to use spectral estimates to\nhandle the nonlinear term. Based on the transformation of the SAV numerical\nscheme, the optimal error estimate for the temporal semi-discrete scheme which\ndepends only on the low polynomial order of $\\varepsilon^{-1}$ instead of the\nexponential order, is derived by using mathematical induction, spectral\narguments, and the superconvergence properties of some nonlinear terms.\nNumerical examples are provided to illustrate the discrete energy decay\nproperty and validate our theoretical convergence analysis.",
    "descriptor": "\nComments: 25 pages, 8 figures\n",
    "authors": [
      "Shu Ma",
      "Weifeng Qiu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.13555"
  },
  {
    "id": "arXiv:2211.13557",
    "title": "Fingerprint Image-Quality Estimation and its Application to  Multialgorithm Verification",
    "abstract": "Signal-quality awareness has been found to increase recognition rates and to\nsupport decisions in multisensor environments significantly. Nevertheless,\nautomatic quality assessment is still an open issue. Here, we study the\norientation tensor of fingerprint images to quantify signal impairments, such\nas noise, lack of structure, blur, with the help of symmetry descriptors. A\nstrongly reduced reference is especially favorable in biometrics, but less\ninformation is not sufficient for the approach. This is also supported by\nnumerous experiments involving a simpler quality estimator, a trained method\n(NFIQ), as well as the human perception of fingerprint quality on several\npublic databases. Furthermore, quality measurements are extensively reused to\nadapt fusion parameters in a monomodal multialgorithm fingerprint recognition\nenvironment. In this study, several trained and nontrained score-level fusion\nschemes are investigated. A Bayes-based strategy for incorporating experts past\nperformances and current quality conditions, a novel cascaded scheme for\ncomputational efficiency, besides simple fusion rules, is presented. The\nquantitative results favor quality awareness under all aspects, boosting\nrecognition rates and fusing differently skilled experts efficiently as well as\neffectively (by training).",
    "descriptor": "\nComments: Published at IEEE Transactions on Information Forensics and Security\n",
    "authors": [
      "Hartwig Fronthaler",
      "Klaus Kollreider",
      "Josef Bigun",
      "Julian Fierrez",
      "Fernando Alonso-Fernandez",
      "Javier Ortega-Garcia",
      "Joaquin Gonzalez-Rodriguez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13557"
  },
  {
    "id": "arXiv:2211.13560",
    "title": "How \"open\" are the conversations with open-domain chatbots? A proposal  for Speech Event based evaluation",
    "abstract": "Open-domain chatbots are supposed to converse freely with humans without\nbeing restricted to a topic, task or domain. However, the boundaries and/or\ncontents of open-domain conversations are not clear. To clarify the boundaries\nof \"openness\", we conduct two studies: First, we classify the types of \"speech\nevents\" encountered in a chatbot evaluation data set (i.e., Meena by Google)\nand find that these conversations mainly cover the \"small talk\" category and\nexclude the other speech event categories encountered in real life human-human\ncommunication. Second, we conduct a small-scale pilot study to generate online\nconversations covering a wider range of speech event categories between two\nhumans vs. a human and a state-of-the-art chatbot (i.e., Blender by Facebook).\nA human evaluation of these generated conversations indicates a preference for\nhuman-human conversations, since the human-chatbot conversations lack coherence\nin most speech event categories. Based on these results, we suggest (a) using\nthe term \"small talk\" instead of \"open-domain\" for the current chatbots which\nare not that \"open\" in terms of conversational abilities yet, and (b) revising\nthe evaluation methods to test the chatbot conversations against other speech\nevents.",
    "descriptor": "",
    "authors": [
      "A. Seza Do\u011fru\u00f6z",
      "Gabriel Skantze"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.13560"
  },
  {
    "id": "arXiv:2211.13564",
    "title": "More comprehensive facial inversion for more effective expression  recognition",
    "abstract": "Facial expression recognition (FER) plays a significant role in the\nubiquitous application of computer vision. We revisit this problem with a new\nperspective on whether it can acquire useful representations that improve FER\nperformance in the image generation process, and propose a novel generative\nmethod based on the image inversion mechanism for the FER task, termed\nInversion FER (IFER). Particularly, we devise a novel Adversarial Style\nInversion Transformer (ASIT) towards IFER to comprehensively extract features\nof generated facial images. In addition, ASIT is equipped with an image\ninversion discriminator that measures the cosine similarity of semantic\nfeatures between source and generated images, constrained by a distribution\nalignment loss. Finally, we introduce a feature modulation module to fuse the\nstructural code and latent codes from ASIT for the subsequent FER work. We\nextensively evaluate ASIT on facial datasets such as FFHQ and CelebA-HQ,\nshowing that our approach achieves state-of-the-art facial inversion\nperformance. IFER also achieves competitive results in facial expression\nrecognition datasets such as RAF-DB, SFEW and AffectNet. The code and models\nare available at https://github.com/Talented-Q/IFER-master.",
    "descriptor": "",
    "authors": [
      "Jiawei Mao",
      "Guangyi Zhao",
      "Yuanqi Chang",
      "Xuesong Yin",
      "Xiaogang Peng",
      "Rui Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13564"
  },
  {
    "id": "arXiv:2211.13567",
    "title": "Strategyproofness and Proportionality in Party-Approval Multiwinner  Elections",
    "abstract": "In party-approval multiwinner elections the goal is to allocate the seats of\na fixed-size committee to parties based on the approval ballots of the voters\nover the parties. In particular, each voter can approve multiple parties and\neach party can be assigned multiple seats. Two central requirements in this\nsetting are proportional representation and strategyproofness. Intuitively,\nproportional representation requires that every sufficiently large group of\nvoters with similar preferences is represented in the committee.\nStrategyproofness demands that no voter can benefit by misreporting her true\npreferences. We show that these two axioms are incompatible for anonymous\nparty-approval multiwinner voting rules, thus proving a far-reaching\nimpossibility theorem. The proof of this result is obtained by formulating the\nproblem in propositional logic and then letting a SAT solver show that the\nformula is unsatisfiable. Additionally, we demonstrate how to circumvent this\nimpossibility by considering a weakening of strategy\\-proofness which requires\nthat only voters who do not approve any elected party cannot manipulate. While\nmost common voting rules fail even this weak notion of strategyproofness, we\ncharacterize Chamberlin--Courant approval voting within the class of Thiele\nrules based on this strategyproofness notion.",
    "descriptor": "\nComments: Appears in the 37th AAAI Conference on Artificial Intelligence (AAAI), 2023\n",
    "authors": [
      "Th\u00e9o Delemazure",
      "Tom Demeulemeester",
      "Manuel Eberl",
      "Jonas Israel",
      "Patrick Lederer"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2211.13567"
  },
  {
    "id": "arXiv:2211.13572",
    "title": "Real-Time Physics-Based Object Pose Tracking during Non-Prehensile  Manipulation",
    "abstract": "We propose a method to track the 6D pose of an object over time, while the\nobject is under non-prehensile manipulation by a robot. At any given time\nduring the manipulation of the object, we assume access to the robot joint\ncontrols and an image from a camera looking at the scene. We use the robot\njoint controls to perform a physics-based prediction of how the object might be\nmoving. We then combine this prediction with the observation coming from the\ncamera, to estimate the object pose as accurately as possible. We use a\nparticle filtering approach to combine the control information with the visual\ninformation. We compare the proposed method with two baselines: (i) using only\nan image-based pose estimation system at each time-step, and (ii) a particle\nfilter which does not perform the computationally expensive physics\npredictions, but assumes the object moves with constant velocity. Our results\nshow that making physics-based predictions is worth the computational cost,\nresulting in more accurate tracking, and estimating object pose even when the\nobject is not clearly visible to the camera.",
    "descriptor": "",
    "authors": [
      "Zisong Xu",
      "Rafael Papallas",
      "Mehmet Dogar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13572"
  },
  {
    "id": "arXiv:2211.13573",
    "title": "MIMO Systems with Reconfigurable Antennas: Joint Channel Estimation and  Mode Selection",
    "abstract": "Reconfigurable antennas (RAs) are a promising technology to enhance the\ncapacity and coverage of wireless communication systems. However, RA systems\nhave two major challenges: (i) High computational complexity of mode selection,\nand (ii) High overhead of channel estimation for all modes. In this paper, we\ndevelop a low-complexity iterative mode selection algorithm for data\ntransmission in an RA-MIMO system. Furthermore, we study channel estimation of\nan RA multi-user MIMO system. However, given the coherence time, it is\nchallenging to estimate channels of all modes. We propose a mode selection\nscheme to select a subset of modes, train channels for the selected subset, and\npredict channels for the remaining modes. In addition, we propose a prediction\nscheme based on pattern correlation between modes. Representative simulation\nresults demonstrate the system's channel estimation error and achievable\nsum-rate for various selected modes and different signal-to-noise ratios\n(SNRs).",
    "descriptor": "",
    "authors": [
      "Fariba Armandoust",
      "Ehsan Tohidi",
      "Martin Kasparick",
      "Li Wang",
      "Ahmet Hasim Gokceoglu",
      "Slawomir Stanczak"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.13573"
  },
  {
    "id": "arXiv:2211.13577",
    "title": "Towards Interpretable Anomaly Detection via Invariant Rule Mining",
    "abstract": "In the research area of anomaly detection, novel and promising methods are\nfrequently developed. However, most existing studies, especially those\nleveraging deep neural networks, exclusively focus on the detection task only\nand ignore the interpretability of the underlying models as well as their\ndetection results. However, anomaly interpretation, which aims to provide\nexplanation of why specific data instances are identified as anomalies, is an\nequally (if not more) important task in many real-world applications. In this\nwork, we pursue highly interpretable anomaly detection via invariant rule\nmining. Specifically, we leverage decision tree learning and association rule\nmining to automatically generate invariant rules that are consistently\nsatisfied by the underlying data generation process. The generated invariant\nrules can provide explicit explanation of anomaly detection results and thus\nare extremely useful for subsequent decision-making. Furthermore, our empirical\nevaluation shows that the proposed method can also achieve comparable\nperformance in terms of AUC and partial AUC with popular anomaly detection\nmodels in various benchmark datasets.",
    "descriptor": "",
    "authors": [
      "Cheng Feng",
      "Pingge Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13577"
  },
  {
    "id": "arXiv:2211.13578",
    "title": "Multiagent MST Cover: Pleasing All Optimally via A Simple Voting Rule",
    "abstract": "Given a connected graph on whose edges we can build roads to connect the\nnodes, a number of agents hold possibly different perspectives on which edges\nshould be selected by assigning different edge weights. Our task is to build a\nminimum number of roads so that every agent has a spanning tree in the built\nsubgraph whose weight is the same as a minimum spanning tree in the original\ngraph. We first show that this problem is NP-hard and does not admit better\nthan $((1-o(1))\\ln k)$-approximation polynomial-time algorithms unless P=NP,\nwhere $k$ is the number of agents. We then give a simple voting algorithm with\nan optimal approximation ratio. Moreover, our algorithm only needs to access\nthe agents' rankings on the edges. Finally, we extend our results to submodular\nobjective functions and Matroid rank constraints.",
    "descriptor": "\nComments: To appear in AAAI 2023\n",
    "authors": [
      "Bo Li",
      "Xiaowei Wu",
      "Chenyang Xu",
      "Ruilong Zhang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.13578"
  },
  {
    "id": "arXiv:2211.13579",
    "title": "Knowledge-Aware Federated Active Learning with Non-IID Data",
    "abstract": "Federated learning enables multiple decentralized clients to learn\ncollaboratively without sharing the local training data. However, the expensive\nannotation cost to acquire data labels on local clients remains an obstacle in\nutilizing local data. In this paper, we propose a federated active learning\nparadigm to efficiently learn a global model with limited annotation budget\nwhile protecting data privacy in a decentralized learning way. The main\nchallenge faced by federated active learning is the mismatch between the active\nsampling goal of the global model on the server and that of the asynchronous\nlocal clients. This becomes even more significant when data is distributed\nnon-IID across local clients. To address the aforementioned challenge, we\npropose Knowledge-Aware Federated Active Learning (KAFAL), which consists of\nKnowledge-Specialized Active Sampling (KSAS) and Knowledge-Compensatory\nFederated Update (KCFU). KSAS is a novel active sampling method tailored for\nthe federated active learning problem. It deals with the mismatch challenge by\nsampling actively based on the discrepancies between local and global models.\nKSAS intensifies specialized knowledge in local clients, ensuring the sampled\ndata to be informative for both the local clients and the global model. KCFU,\nin the meantime, deals with the client heterogeneity caused by limited data and\nnon-IID data distributions. It compensates for each client's ability in weak\nclasses by the assistance of the global model. Extensive experiments and\nanalyses are conducted to show the superiority of KSAS over the\nstate-of-the-art active learning methods and the efficiency of KCFU under the\nfederated active learning framework.",
    "descriptor": "\nComments: 14 pages, 12 figures\n",
    "authors": [
      "Yu-Tong Cao",
      "Jingya Wang",
      "Ye Shi",
      "Baosheng Yu",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13579"
  },
  {
    "id": "arXiv:2211.13581",
    "title": "On a novel numerical quadrature based on cycle index of symmetric group  for the Hadamard finite-part integrals",
    "abstract": "To evaluate the Hadamard finite-part integrals accurately, a novel\ninterpolatory-type quadrature is proposed in this article. In our approach,\nnumerical divided difference is utilized to represent the high order\nderivatives of the integrated function, which make it possible to reduced the\nnumerical quadrature into a concise formula based on the cycle index for\nsymmetric group. In addition, convergence analysis is presented and the error\nestimation is given. Numerical results are presented on cases with different\nweight functions, which substantiate the performance of the proposed method.",
    "descriptor": "",
    "authors": [
      "Jiajie Yao",
      "Congcong Xie"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.13581"
  },
  {
    "id": "arXiv:2211.13582",
    "title": "A structure-preserving parametric finite element method for  area-conserved generalized mean curvature flow",
    "abstract": "We propose and analyze a structure-preserving parametric finite element\nmethod (SP-PFEM) to simulate the motion of closed curves governed by\narea-conserved generalized mean curvature flow in two dimensions (2D). We first\npresent a variational formulation and rigorously prove that it preserves two\nfundamental geometric structures of the flows, i.e., (a) the conservation of\nthe area enclosed by the closed curve; (b) the decrease of the perimeter of the\ncurve. Then the variational formulation is approximated by using piecewise\nlinear parametric finite elements in space to develop the semi-discrete scheme.\nWith the help of the discrete Cauchy's inequality and discrete power mean\ninequality, the area conservation and perimeter decrease properties of the\nsemi-discrete scheme are shown. On this basis, by combining the backward Euler\nmethod in time and a proper approximation of the unit normal vector, a\nstructure-preserving fully discrete scheme is constructed successfully, which\ncan preserve the two essential geometric structures simultaneously at the\ndiscrete level. Finally, numerical experiments test the convergence rate, area\nconservation, perimeter decrease and mesh quality, and depict the evolution of\ncurves. Numerical results indicate that the proposed SP-PFEM provides a\nreliable and powerful tool for the simulation of area-conserved generalized\nmean curvature flow in 2D.",
    "descriptor": "\nComments: 24 pages, 8 figures\n",
    "authors": [
      "Lifang Pei",
      "Yifei Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.13582"
  },
  {
    "id": "arXiv:2211.13583",
    "title": "The intersection of machine learning with forecasting and optimisation:  theory and applications",
    "abstract": "Forecasting and optimisation are two major fields of operations research that\nare widely used in practice. These methods have contributed to each other\ngrowth in several ways. However, the nature of the relationship between these\ntwo fields and integrating them have not been explored or understood enough. We\nadvocate the integration of these two fields and explore several problems that\nrequire both forecasting and optimisation to deal with the uncertainties. We\nfurther investigate some of the methodologies that lie at the intersection of\nmachine learning with prediction and optimisation to address real-world\nproblems. Finally, we provide several research directions for those interested\nto work in this domain.",
    "descriptor": "",
    "authors": [
      "Mahdi Abolghasemi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.13583"
  },
  {
    "id": "arXiv:2211.13585",
    "title": "Learning to Take a Break: Sustainable Optimization of Long-Term User  Engagement",
    "abstract": "Optimizing user engagement is a key goal for modern recommendation systems,\nbut blindly pushing users towards increased consumption risks burn-out, churn,\nor even addictive habits. To promote digital well-being, most platforms now\noffer a service that periodically prompts users to take a break. These,\nhowever, must be set up manually, and so may be suboptimal for both users and\nthe system. In this paper, we propose a framework for optimizing long-term\nengagement by learning individualized breaking policies. Using Lotka-Volterra\ndynamics, we model users as acting based on two balancing latent states: drive,\nand interest -- which must be conserved. We then give an efficient learning\nalgorithm, provide theoretical guarantees, and empirically evaluate its\nperformance on semi-synthetic data.",
    "descriptor": "\nComments: Comments are welcome\n",
    "authors": [
      "Eden Saig",
      "Nir Rosenfeld"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.13585"
  },
  {
    "id": "arXiv:2211.13586",
    "title": "How to predict and optimise with asymmetric error metrics",
    "abstract": "In this paper, we examine the concept of the predict and optimise problem\nwith specific reference to the third Technical Challenge of the IEEE\nComputational Intelligence Society. In this competition, entrants were asked to\nforecast building energy use and solar generation at six buildings and six\nsolar installations, and then use their forecast to optimize energy cost while\nscheduling classes and batteries over a month. We examine the possible effect\nof underforecasting and overforecasting and asymmetric errors on the\noptimisation cost. We explore the different nature of loss functions for the\nprediction and optimisation phase and propose to adjust the final forecasts for\na better optimisation cost. We report that while there is a positive\ncorrelation between these two, more appropriate loss functions can be used to\noptimise the costs associated with final decisions.",
    "descriptor": "",
    "authors": [
      "Mahdi Abolghasemi",
      "Richard Bean"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13586"
  },
  {
    "id": "arXiv:2211.13587",
    "title": "Responsible Active Learning via Human-in-the-loop Peer Study",
    "abstract": "Active learning has been proposed to reduce data annotation efforts by only\nmanually labelling representative data samples for training. Meanwhile, recent\nactive learning applications have benefited a lot from cloud computing services\nwith not only sufficient computational resources but also crowdsourcing\nframeworks that include many humans in the active learning loop. However,\nprevious active learning methods that always require passing large-scale\nunlabelled data to cloud may potentially raise significant data privacy issues.\nTo mitigate such a risk, we propose a responsible active learning method,\nnamely Peer Study Learning (PSL), to simultaneously preserve data privacy and\nimprove model stability. Specifically, we first introduce a human-in-the-loop\nteacher-student architecture to isolate unlabelled data from the task learner\n(teacher) on the cloud-side by maintaining an active learner (student) on the\nclient-side. During training, the task learner instructs the light-weight\nactive learner which then provides feedback on the active sampling criterion.\nTo further enhance the active learner via large-scale unlabelled data, we\nintroduce multiple peer students into the active learner which is trained by a\nnovel learning paradigm, including the In-Class Peer Study on labelled data and\nthe Out-of-Class Peer Study on unlabelled data. Lastly, we devise a\ndiscrepancy-based active sampling criterion, Peer Study Feedback, that exploits\nthe variability of peer students to select the most informative data to improve\nmodel stability. Extensive experiments demonstrate the superiority of the\nproposed PSL over a wide range of active learning methods in both standard and\nsensitive protection settings.",
    "descriptor": "\nComments: 15 pages, 8 figures\n",
    "authors": [
      "Yu-Tong Cao",
      "Jingya Wang",
      "Baosheng Yu",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13587"
  },
  {
    "id": "arXiv:2211.13591",
    "title": "Bidirectional optogenetic control of inhibitory neurons in freely-moving  mice",
    "abstract": "Objective: Optogenetic manipulations of excitable cells enable activating or\nsilencing specific types of neurons. By expressing two types of exogenous\nproteins, a single neuron can be depolarized using light of one wavelength and\nhyperpolarized with another. However, routing two distinct wavelengths into the\nsame brain locality typically requires bulky optics that cannot be implanted on\nthe head of a freely-moving animal.\nMethods: We developed a lens-free approach for constructing dual-color\nhead-mounted, fiber-based optical units: any two wavelengths can be combined.\nResults: Here, each unit was comprised of one 450 nm and one 638 nm laser\ndiode, yielding light power of 0.4 mW and 8 mW at the end of a 50 micrometer\nmultimode fiber. To create a multi-color/multi-site optoelectronic device, a\nfour-shank silicon probe mounted on a microdrive was equipped with two\ndual-color and two single-color units, for a total weight under 3 g. Devices\nwere implanted in mice expressing the blue-light sensitive cation channel ChR2\nand the red-light sensitive chloride pump Jaws in parvalbumin-immunoreactive\n(PV) inhibitory neurons. The combination of dual-color units with recording\nelectrodes was free from electromagnetic interference, and device heating was\nunder 7{\\deg}C even after prolonged operation.\nConclusion: Using these devices, the same cortical PV cell could be activated\nand silenced. This was achieved for multiple cells both in neocortex and\nhippocampus of freely-moving mice.\nSignificance: This technology can be used for controlling spatially\nintermingled neurons that have distinct genetic profiles, and for controlling\nspike timing of cortical neurons during cognitive tasks.",
    "descriptor": "\nComments: 11 pages, 9 figures\n",
    "authors": [
      "Ori Noked",
      "Amir Levi",
      "Shirly Someck",
      "Ortal Amber-Vitos",
      "Eran Stark"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.13591"
  },
  {
    "id": "arXiv:2211.13594",
    "title": "Self-supervised vision-language pretraining for Medical visual question  answering",
    "abstract": "Medical image visual question answering (VQA) is a task to answer clinical\nquestions, given a radiographic image, which is a challenging problem that\nrequires a model to integrate both vision and language information. To solve\nmedical VQA problems with a limited number of training data, pretrain-finetune\nparadigm is widely used to improve the model generalization. In this paper, we\npropose a self-supervised method that applies Masked image modeling, Masked\nlanguage modeling, Image text matching and Image text alignment via contrastive\nlearning (M2I2) for pretraining on medical image caption dataset, and finetunes\nto downstream medical VQA tasks. The proposed method achieves state-of-the-art\nperformance on all the three public medical VQA datasets. Our codes and models\nare available at https://github.com/pengfeiliHEU/M2I2.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Pengfei Li",
      "Gang Liu",
      "Lin Tan",
      "Jinying Liao",
      "Shenjun Zhong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13594"
  },
  {
    "id": "arXiv:2211.13606",
    "title": "Collaborative Training of Medical Artificial Intelligence Models with  non-uniform Labels",
    "abstract": "Artificial intelligence (AI) methods are revolutionizing medical image\nanalysis. However, robust AI models require large multi-site datasets for\ntraining. While multiple stakeholders have provided publicly available\ndatasets, the ways in which these data are labeled differ widely. For example,\none dataset of chest radiographs might contain labels denoting the presence of\nmetastases in the lung, while another dataset of chest radiograph might focus\non the presence of pneumonia. With conventional approaches, these data cannot\nbe used together to train a single AI model. We propose a new framework that we\ncall flexible federated learning (FFL) for collaborative training on such data.\nUsing publicly available data of 695,000 chest radiographs from five\ninstitutions - each with differing labels - we demonstrate that large and\nheterogeneously labeled datasets can be used to train one big AI model with\nthis framework. We find that models trained with FFL are superior to models\nthat are trained on matching annotations only. This may pave the way for\ntraining of truly large-scale AI models that make efficient use of all existing\ndata.",
    "descriptor": "\nComments: 2 figures, 3 tables, 5 supplementary tables\n",
    "authors": [
      "Soroosh Tayebi Arasteh",
      "Peter Isfort",
      "Marwin Saehn",
      "Gustav Mueller-Franzes",
      "Firas Khader",
      "Jakob Nikolas Kather",
      "Christiane Kuhl",
      "Sven Nebelung",
      "Daniel Truhn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.13606"
  },
  {
    "id": "arXiv:2211.13609",
    "title": "PAC-Bayes Compression Bounds So Tight That They Can Explain  Generalization",
    "abstract": "While there has been progress in developing non-vacuous generalization bounds\nfor deep neural networks, these bounds tend to be uninformative about why deep\nlearning works. In this paper, we develop a compression approach based on\nquantizing neural network parameters in a linear subspace, profoundly improving\non previous results to provide state-of-the-art generalization bounds on a\nvariety of tasks, including transfer learning. We use these tight bounds to\nbetter understand the role of model size, equivariance, and the implicit biases\nof optimization, for generalization in deep learning. Notably, we find large\nmodels can be compressed to a much greater extent than previously known,\nencapsulating Occam's razor. We also argue for data-independent bounds in\nexplaining generalization.",
    "descriptor": "\nComments: NeurIPS 2022. Code is available at this https URL\n",
    "authors": [
      "Sanae Lotfi",
      "Marc Finzi",
      "Sanyam Kapoor",
      "Andres Potapczynski",
      "Micah Goldblum",
      "Andrew Gordon Wilson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.13609"
  },
  {
    "id": "arXiv:2211.13613",
    "title": "Ham2Pose: Animating Sign Language Notation into Pose Sequences",
    "abstract": "Translating spoken languages into Sign languages is necessary for open\ncommunication between the hearing and hearing-impaired communities. To achieve\nthis goal, we propose the first method for animating a text written in\nHamNoSys, a lexical Sign language notation, into signed pose sequences. As\nHamNoSys is universal, our proposed method offers a generic solution invariant\nto the target Sign language. Our method gradually generates pose predictions\nusing transformer encoders that create meaningful representations of the text\nand poses while considering their spatial and temporal information. We use weak\nsupervision for the training process and show that our method succeeds in\nlearning from partial and inaccurate data. Additionally, we offer a new\ndistance measurement for pose sequences, normalized Dynamic Time Warping\n(nDTW), based on DTW over normalized keypoints trajectories, and validate its\ncorrectness using AUTSL, a large-scale Sign language dataset. We show that it\nmeasures the distance between pose sequences more accurately than existing\nmeasurements and use it to assess the quality of our generated pose sequences.\nCode for the data pre-processing, the model, and the distance measurement is\npublicly released for future research.",
    "descriptor": "",
    "authors": [
      "Rotem Shalev-Arkushin",
      "Amit Moryossef",
      "Ohad Fried"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.13613"
  },
  {
    "id": "arXiv:2211.13617",
    "title": "ML Interpretability: Simple Isn't Easy",
    "abstract": "The interpretability of ML models is important, but it is not clear what it\namounts to. So far, most philosophers have discussed the lack of\ninterpretability of black-box models such as neural networks, and methods such\nas explainable AI that aim to make these models more transparent. The goal of\nthis paper is to clarify the nature of interpretability by focussing on the\nother end of the 'interpretability spectrum'. The reasons why some models,\nlinear models and decision trees, are highly interpretable will be examined,\nand also how more general models, MARS and GAM, retain some degree of\ninterpretability. I find that while there is heterogeneity in how we gain\ninterpretability, what interpretability is in particular cases can be\nexplicated in a clear manner.",
    "descriptor": "\nComments: 22 pages, 4 figures\n",
    "authors": [
      "Tim R\u00e4z"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.13617"
  },
  {
    "id": "arXiv:2211.13622",
    "title": "The Westermo test results data set",
    "abstract": "There is a growing body of knowledge in the computer science, software\nengineering, software testing and software test automation disciplines.\nHowever, there is a challenge for researchers to evaluate their research\nfindings, innovations and tools due to lack of realistic data. This paper\npresents the Westermo test results data set, more than one million verdicts\nfrom testing of embedded systems, from more than five hundred consecutive days\nof nightly testing. The data also contains information on code changes in both\nthe software under test and the test framework used for testing. This data set\ncan support the research community in particular with respect to the regression\ntest selection problem, flaky tests, test results visualization, etc.",
    "descriptor": "",
    "authors": [
      "Per Erik Strandberg"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.13622"
  },
  {
    "id": "arXiv:2211.13626",
    "title": "Bidding Graph Games with Partially-Observable Budgets",
    "abstract": "Two-player zero-sum \"graph games\" are a central model, which proceeds as\nfollows. A token is placed on a vertex of a graph, and the two players move it\nto produce an infinite \"play\", which determines the winner or payoff of the\ngame. Traditionally, the players alternate turns in moving the token. In\n\"bidding games\", however, the players have budgets and in each turn, an auction\n(bidding) determines which player moves the token. So far, bidding games have\nonly been studied as full-information games. In this work we initiate the study\nof partial-information bidding games: we study bidding games in which a\nplayer's initial budget is drawn from a known probability distribution. We show\nthat while for some bidding mechanisms and objectives, it is straightforward to\nadapt the results from the full-information setting to the partial-information\nsetting, for others, the analysis is significantly more challenging, requires\nnew techniques, and gives rise to interesting results. Specifically, we study\ngames with \"mean-payoff\" objectives in combination with \"poorman\" bidding. We\nconstruct optimal strategies for a partially-informed player who plays against\na fully-informed adversary. We show that, somewhat surprisingly, the \"value\"\nunder pure strategies does not necessarily exist in such games.",
    "descriptor": "\nComments: The full version of a paper published at AAAI 23\n",
    "authors": [
      "Guy Avni",
      "Ismael Jecker",
      "Djordje Zikelic"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2211.13626"
  },
  {
    "id": "arXiv:2211.13627",
    "title": "Energy-efficient tunable-stiffness soft robots using second moment of  area actuation",
    "abstract": "The optimal stiffness for soft swimming robots depends on swimming speed,\nwhich means no single stiffness can maximise efficiency in all swimming\nconditions. Tunable stiffness would produce an increased range of\nhigh-efficiency swimming speeds for robots with flexible propulsors and enable\nsoft control surfaces for steering underwater vehicles. We propose and\ndemonstrate a method for tunable soft robotic stiffness using inflatable rubber\ntubes to stiffen a silicone foil through pressure and second moment of area\nchange. We achieved double the effective stiffness of the system for an input\npressure change from 0 to 0.8 bar and 2 J energy input. We achieved a resonant\namplitude gain of 5 to 7 times the input amplitude and tripled the high-gain\nfrequency range comparedto a foil with fixed stiffness. These results show that\nchanging second moment of area is an energy effective approach tot\nunable-stiffness robots.",
    "descriptor": "\nComments: 6 pages, 8 figures, Presented at IEEE/RSJ International Conference on Intelligent Robots and Systems 2022 in Kyoto, Japan\n",
    "authors": [
      "Leo Micklem",
      "Gabriel D. Weymouth",
      "Blair Thornton"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.13627"
  },
  {
    "id": "arXiv:2211.13632",
    "title": "Reducing a Set of Regular Expressions and Analyzing Differences of  Domain-specific Statistic Reporting",
    "abstract": "Due to the large amount of daily scientific publications, it is impossible to\nmanually review each one. Therefore, an automatic extraction of key information\nis desirable. In this paper, we examine STEREO, a tool for extracting\nstatistics from scientific papers using regular expressions. By adapting an\nexisting regular expression inclusion algorithm for our use case, we decrease\nthe number of regular expressions used in STEREO by about $33.8\\%$. We reveal\ncommon patterns from the condensed rule set that can be used for the creation\nof new rules. We also apply STEREO, which was previously trained in the\nlife-sciences and medical domain, to a new scientific domain, namely\nHuman-Computer-Interaction (HCI), and re-evaluate it. According to our\nresearch, statistics in the HCI domain are similar to those in the medical\ndomain, although a higher percentage of APA-conform statistics were found in\nthe HCI domain. Additionally, we compare extraction on PDF and LaTeX source\nfiles, finding LaTeX to be more reliable for extraction.",
    "descriptor": "",
    "authors": [
      "Tobias Kalmbach",
      "Marcel Hoffmann",
      "Nicolas Lell",
      "Ansgar Scherp"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2211.13632"
  },
  {
    "id": "arXiv:2211.13638",
    "title": "Prototypical Fine-tuning: Towards Robust Performance Under Varying Data  Sizes",
    "abstract": "In this paper, we move towards combining large parametric models with\nnon-parametric prototypical networks. We propose prototypical fine-tuning, a\nnovel prototypical framework for fine-tuning pretrained language models (LM),\nwhich automatically learns a bias to improve predictive performance for varying\ndata sizes, especially low-resource settings. Our prototypical fine-tuning\napproach can automatically adjust the model capacity according to the number of\ndata points and the model's inherent attributes. Moreover, we propose four\nprinciples for effective prototype fine-tuning towards the optimal solution.\nExperimental results across various datasets show that our work achieves\nsignificant performance improvements under various low-resource settings, as\nwell as comparable and usually better performances in high-resource scenarios.",
    "descriptor": "\nComments: Published as a conference paper at AAAI 2023\n",
    "authors": [
      "Yiqiao Jin",
      "Xiting Wang",
      "Yaru Hao",
      "Yizhou Sun",
      "Xing Xie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13638"
  },
  {
    "id": "arXiv:2211.13644",
    "title": "Seeds Don't Lie: An Adaptive Watermarking Framework for Computer Vision  Models",
    "abstract": "In recent years, various watermarking methods were suggested to detect\ncomputer vision models obtained illegitimately from their owners, however they\nfail to demonstrate satisfactory robustness against model extraction attacks.\nIn this paper, we present an adaptive framework to watermark a protected model,\nleveraging the unique behavior present in the model due to a unique random seed\ninitialized during the model training. This watermark is used to detect\nextracted models, which have the same unique behavior, indicating an\nunauthorized usage of the protected model's intellectual property (IP). First,\nwe show how an initial seed for random number generation as part of model\ntraining produces distinct characteristics in the model's decision boundaries,\nwhich are inherited by extracted models and present in their decision\nboundaries, but aren't present in non-extracted models trained on the same\ndata-set with a different seed. Based on our findings, we suggest the Robust\nAdaptive Watermarking (RAW) Framework, which utilizes the unique behavior\npresent in the protected and extracted models to generate a watermark key-set\nand verification model. We show that the framework is robust to (1) unseen\nmodel extraction attacks, and (2) extracted models which undergo a blurring\nmethod (e.g., weight pruning). We evaluate the framework's robustness against a\nnaive attacker (unaware that the model is watermarked), and an informed\nattacker (who employs blurring strategies to remove watermarked behavior from\nan extracted model), and achieve outstanding (i.e., >0.9) AUC values. Finally,\nwe show that the framework is robust to model extraction attacks with different\nstructure and/or architecture than the protected model.",
    "descriptor": "\nComments: 9 pages, 6 figures, 3 tables\n",
    "authors": [
      "Jacob Shams",
      "Ben Nassi",
      "Ikuya Morikawa",
      "Toshiya Shimizu",
      "Asaf Shabtai",
      "Yuval Elovici"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13644"
  },
  {
    "id": "arXiv:2211.13649",
    "title": "End-to-end Wind Turbine Wake Modelling with Deep Graph Representation  Learning",
    "abstract": "Wind turbine wake modelling is of crucial importance to accurate resource\nassessment, to layout optimisation, and to the operational control of wind\nfarms. This work proposes a surrogate model for the representation of wind\nturbine wakes based on a state-of-the-art graph representation learning method\ntermed a graph neural network. The proposed end-to-end deep learning model\noperates directly on unstructured meshes and has been validated against\nhigh-fidelity data, demonstrating its ability to rapidly make accurate 3D flow\nfield predictions for various inlet conditions and turbine yaw angles. The\nspecific graph neural network model employed here is shown to generalise well\nto unseen data and is less sensitive to over-smoothing compared to common graph\nneural networks. A case study based upon a real world wind farm further\ndemonstrates the capability of the proposed approach to predict farm scale\npower generation. Moreover, the proposed graph neural network framework is\nflexible and highly generic and as formulated here can be applied to any steady\nstate computational fluid dynamics simulations on unstructured meshes.",
    "descriptor": "\nComments: 20 pages, 12 figures\n",
    "authors": [
      "Siyi Li",
      "Mingrui Zhang",
      "Matthew Piggott"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.13649"
  },
  {
    "id": "arXiv:2211.13652",
    "title": "The GA-cal software for the automatic calibration of soil constitutive  laws: a tutorial and a user manual",
    "abstract": "The calibration of an advanced constitutive law for soil is a challenging\ntask. This work describes GA-cal, a Fortran software for automatically\ncalibrating constitutive laws using Genetic Algorithms (GA) optimization. The\nproposed approach sets the calibration problem as a regression, and the GA\noptimization is used to adjust the model parameters so that a numerical model\nmatches experimental data. This document provides a user guide and a simple\ntutorial. We showcase GA-cal on the calibration of the Sand Hypoplastic law\nproposed by von Wolffersdorff, with the oedometer and triaxial drained test\ndata. The implemented subroutines can be easily extended to solve other\nregression or optimization problems, including different tests and constitutive\nmodels. The source code and the presented tutorial are freely available at\n\\url{https://github.com/FraJoMen/GA-cal}.",
    "descriptor": "",
    "authors": [
      "Francisco J. Mendez",
      "Miguel A. Mendez",
      "Antonio Pasculli"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.13652"
  },
  {
    "id": "arXiv:2211.13654",
    "title": "Cross Aggregation Transformer for Image Restoration",
    "abstract": "Recently, Transformer architecture has been introduced into image restoration\nto replace convolution neural network (CNN) with surprising results.\nConsidering the high computational complexity of Transformer with global\nattention, some methods use the local square window to limit the scope of\nself-attention. However, these methods lack direct interaction among different\nwindows, which limits the establishment of long-range dependencies. To address\nthe above issue, we propose a new image restoration model, Cross Aggregation\nTransformer (CAT). The core of our CAT is the Rectangle-Window Self-Attention\n(Rwin-SA), which utilizes horizontal and vertical rectangle window attention in\ndifferent heads parallelly to expand the attention area and aggregate the\nfeatures cross different windows. We also introduce the Axial-Shift operation\nfor different window interactions. Furthermore, we propose the Locality\nComplementary Module to complement the self-attention mechanism, which\nincorporates the inductive bias of CNN (e.g., translation invariance and\nlocality) into Transformer, enabling global-local coupling. Extensive\nexperiments demonstrate that our CAT outperforms recent state-of-the-art\nmethods on several image restoration applications. The code and models are\navailable at https://github.com/zhengchen1999/CAT.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022. Code is available at this https URL\n",
    "authors": [
      "Chen Zheng",
      "Yulun Zhang",
      "Jinjin Gu",
      "Yongbing Zhang",
      "Linghe Kong",
      "Xin Yuan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13654"
  },
  {
    "id": "arXiv:2211.13655",
    "title": "Learning with Partial Labels from Semi-supervised Perspective",
    "abstract": "Partial Label (PL) learning refers to the task of learning from the partially\nlabeled data, where each training instance is ambiguously equipped with a set\nof candidate labels but only one is valid. Advances in the recent deep PL\nlearning literature have shown that the deep learning paradigms, e.g.,\nself-training, contrastive learning, or class activate values, can achieve\npromising performance. Inspired by the impressive success of deep\nSemi-Supervised (SS) learning, we transform the PL learning problem into the SS\nlearning problem, and propose a novel PL learning method, namely Partial Label\nlearning with Semi-supervised Perspective (PLSP). Specifically, we first form\nthe pseudo-labeled dataset by selecting a small number of reliable\npseudo-labeled instances with high-confidence prediction scores and treating\nthe remaining instances as pseudo-unlabeled ones. Then we design a SS learning\nobjective, consisting of a supervised loss for pseudo-labeled instances and a\nsemantic consistency regularization for pseudo-unlabeled instances. We further\nintroduce a complementary regularization for those non-candidate labels to\nconstrain the model predictions on them to be as small as possible. Empirical\nresults demonstrate that PLSP significantly outperforms the existing PL\nbaseline methods, especially on high ambiguity levels. Code available:\nhttps://github.com/changchunli/PLSP.",
    "descriptor": "",
    "authors": [
      "Ximing Li",
      "Yuanzhi Jiang",
      "Changchun Li",
      "Yiyuan Wang",
      "Jihong Ouyang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13655"
  },
  {
    "id": "arXiv:2211.13656",
    "title": "Federated Learning Hyper-Parameter Tuning from a System Perspective",
    "abstract": "Federated learning (FL) is a distributed model training paradigm that\npreserves clients' data privacy. It has gained tremendous attention from both\nacademia and industry. FL hyper-parameters (e.g., the number of selected\nclients and the number of training passes) significantly affect the training\noverhead in terms of computation time, transmission time, computation load, and\ntransmission load. However, the current practice of manually selecting FL\nhyper-parameters imposes a heavy burden on FL practitioners because\napplications have different training preferences. In this paper, we propose\nFedTune, an automatic FL hyper-parameter tuning algorithm tailored to\napplications' diverse system requirements in FL training. FedTune iteratively\nadjusts FL hyper-parameters during FL training and can be easily integrated\ninto existing FL systems. Through extensive evaluations of FedTune for diverse\napplications and FL aggregation algorithms, we show that FedTune is lightweight\nand effective, achieving 8.48%-26.75% system overhead reduction compared to\nusing fixed FL hyper-parameters. This paper assists FL practitioners in\ndesigning high-performance FL training solutions. The source code of FedTune is\navailable at https://github.com/DataSysTech/FedTune.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2110.03061\n",
    "authors": [
      "Huanle Zhang",
      "Lei Fu",
      "Mi Zhang",
      "Pengfei Hu",
      "Xiuzhen Cheng",
      "Prasant Mohapatra",
      "Xin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.13656"
  },
  {
    "id": "arXiv:2211.13662",
    "title": "Cross-domain Transfer of defect features in technical domains based on  partial target data",
    "abstract": "A common challenge in real world classification scenarios with sequentially\nappending target domain data is insufficient training datasets during the\ntraining phase. Therefore, conventional deep learning and transfer learning\nclassifiers are not applicable especially when individual classes are not\nrepresented or are severely underrepresented at the outset. In many technical\ndomains, however, it is only the defect or worn reject classes that are\ninsufficiently represented, while the non-defect class is often available from\nthe beginning. The proposed classification approach addresses such conditions\nand is based on a CNN encoder. Following a contrastive learning approach, it is\ntrained with a modified triplet loss function using two datasets: Besides the\nnon-defective target domain class 1st dataset, a state-of-the-art labeled\nsource domain dataset that contains highly related classes e.g., a related\nmanufacturing error or wear defect but originates from a highly different\ndomain e.g., different product, material, or appearance = 2nd dataset is\nutilized. The approach learns the classification features from the source\ndomain dataset while at the same time learning the differences between the\nsource and the target domain in a single training step, aiming to transfer the\nrelevant features to the target domain. The classifier becomes sensitive to the\nclassification features and by architecture robust against the highly\ndomain-specific context. The approach is benchmarked in a technical and a\nnon-technical domain and shows convincing classification results. In\nparticular, it is shown that the domain generalization capabilities and\nclassification results are improved by the proposed architecture, allowing for\nlarger domain shifts between source and target domains.",
    "descriptor": "",
    "authors": [
      "Tobias Schlagenhauf",
      "Tim Scheurenbrand"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13662"
  },
  {
    "id": "arXiv:2211.13670",
    "title": "SmartIntentNN: Towards Smart Contract Intent Detection",
    "abstract": "Researchers currently have been focusing on smart contract vulnerability\ndetection, but we find that developers' intent to write smart contracts is a\nmore noteworthy security concern because smart contracts with malicious intent\nhave caused significant financial loss to users. A more unfortunate fact is\nthat we can only rely on manual audits to check for unfriendly smart contracts.\nIn this paper, we propose \\textsc{SmartIntentNN}, Smart Contract Intent Neural\nNetwork, a deep learning-based tool that aims to automate the process of\ndevelopers' intent detection in smart contracts, saving human resources and\noverhead.\nThe demo video is available on \\url{https://youtu.be/ho1SMtYm-wI}.",
    "descriptor": "\nComments: 4 pages, 3 figures, conference tool track. arXiv admin note: substantial text overlap with arXiv:2211.10724\n",
    "authors": [
      "Youwei Huang",
      "Tao Zhang",
      "Sen Fang",
      "Youshuai Tan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.13670"
  },
  {
    "id": "arXiv:2211.13676",
    "title": "Perception-Oriented Single Image Super-Resolution using Optimal  Objective Estimation",
    "abstract": "Single-image super-resolution (SISR) networks trained with perceptual and\nadversarial losses provide high-contrast outputs compared to those of networks\ntrained with distortion-oriented losses, such as L1 or L2. However, it has been\nshown that using a single perceptual loss is insufficient for accurately\nrestoring locally varying diverse shapes in images, often generating\nundesirable artifacts or unnatural details. For this reason, combinations of\nvarious losses, such as perceptual, adversarial, and distortion losses, have\nbeen attempted, yet it remains challenging to find optimal combinations. Hence,\nin this paper, we propose a new SISR framework that applies optimal objectives\nfor each region to generate plausible results in overall areas of\nhigh-resolution outputs. Specifically, the framework comprises two models: a\npredictive model that infers an optimal objective map for a given\nlow-resolution (LR) input and a generative model that applies a target\nobjective map to produce the corresponding SR output. The generative model is\ntrained over our proposed objective trajectory representing a set of essential\nobjectives, which enables the single network to learn various SR results\ncorresponding to combined losses on the trajectory. The predictive model is\ntrained using pairs of LR images and corresponding optimal objective maps\nsearched from the objective trajectory. Experimental results on five benchmarks\nshow that the proposed method outperforms state-of-the-art perception-driven SR\nmethods in LPIPS, DISTS, PSNR, and SSIM metrics. The visual results also\ndemonstrate the superiority of our method in perception-oriented\nreconstruction.",
    "descriptor": "\nComments: Code and trained models will be available at this https URL\n",
    "authors": [
      "Seung Ho Park",
      "Young Su Moon",
      "Nam Ik Cho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.13676"
  },
  {
    "id": "arXiv:2211.13680",
    "title": "Whole-Body Control of a Mobile Manipulator for Passive Collaborative  Transportation",
    "abstract": "Human-robot collaborative tasks foresee interactions between humans and\nrobots with various degrees of complexity. Specifically, for tasks which\ninvolve physical contact among the agents, challenges arise in the modelling\nand control of such interaction. In this paper we propose a control\narchitecture capable of ensuring a flexible and robustly stable physical\nhuman-robot interaction, focusing on a collaborative transportation task. The\narchitecture is deployed onto a mobile manipulator, modelled as a whole-body\nstructure, which aids the operator during the transportation of an unwieldy\nload. Thanks to passivity techniques, the controller adapts its interaction\nparameters online while preserving robust stability for the overall system,\nthus experimentally validating the architecture.",
    "descriptor": "",
    "authors": [
      "Federico Benzi",
      "Cristian Mancus",
      "Cristian Secchi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.13680"
  },
  {
    "id": "arXiv:2211.13681",
    "title": "Meta-Learning for Automated Selection of Anomaly Detectors for  Semi-Supervised Datasets",
    "abstract": "In anomaly detection, a prominent task is to induce a model to identify\nanomalies learned solely based on normal data. Generally, one is interested in\nfinding an anomaly detector that correctly identifies anomalies, i.e., data\npoints that do not belong to the normal class, without raising too many false\nalarms. Which anomaly detector is best suited depends on the dataset at hand\nand thus needs to be tailored. The quality of an anomaly detector may be\nassessed via confusion-based metrics such as the Matthews correlation\ncoefficient (MCC). However, since during training only normal data is available\nin a semi-supervised setting, such metrics are not accessible. To facilitate\nautomated machine learning for anomaly detectors, we propose to employ\nmeta-learning to predict MCC scores based on metrics that can be computed with\nnormal data only. First promising results can be obtained considering the\nhypervolume and the false positive rate as meta-features.",
    "descriptor": "",
    "authors": [
      "David Schubert",
      "Pritha Gupta",
      "Marcel Wever"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13681"
  },
  {
    "id": "arXiv:2211.13682",
    "title": "A Null-space based Approach for a Safe and Effective Human-Robot  Collaboration",
    "abstract": "During physical human robot collaboration, it is important to be able to\nimplement a time-varying interactive behaviour while ensuring robust stability.\nAdmittance control and passivity theory can be exploited for achieving these\nobjectives. Nevertheless, when the admittance dynamics is time-varying, it can\nhappen that, for ensuring a passive and stable behaviour, some spurious\ndissipative effects have to be introduced in the admittance dynamics. These\neffects are perceived by the user and degrade the collaborative performance. In\nthis paper we exploit the task redundancy of the manipulator in order to\nharvest energy in the null space and to avoid spurious dynamics on the\nadmittance. The proposed architecture is validated by simulations and by\nexperiments onto a collaborative robot.",
    "descriptor": "",
    "authors": [
      "Federico Benzi",
      "Cristian Secchi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.13682"
  },
  {
    "id": "arXiv:2211.13683",
    "title": "Fingerprint of a Traffic Scene: an Approach for a Generic and  Independent Scene Assessment",
    "abstract": "A major challenge in the safety assessment of automated vehicles is to ensure\nthat risk for all traffic participants is as low as possible. A concept that is\nbecoming increasingly popular for testing in automated driving is\nscenario-based testing. It is founded on the assumption that most time on the\nroad can be seen as uncritical and in mainly critical situations contribute to\nthe safety case. Metrics describing the criticality are necessary to\nautomatically identify the critical situations and scenarios from measurement\ndata. However, established metrics lack universality or a concept for metric\ncombination. In this work, we present a multidimensional evaluation model that,\nbased on conventional metrics, can evaluate scenes independently of the scene\ntype. Furthermore, we present two new, further enhanced evaluation approaches,\nwhich can additionally serve as universal metrics. The metrics we introduce are\nthen evaluated and discussed using real data from a motion dataset.",
    "descriptor": "",
    "authors": [
      "Maximilian Zipfl",
      "Barbara Sch\u00fctt",
      "J. Marius Z\u00f6llner",
      "Eric Sax"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.13683"
  },
  {
    "id": "arXiv:2211.13688",
    "title": "Equality on all #CSP Instances Yields Constraint Function Isomorphism  via Interpolation and Intertwiners",
    "abstract": "A fundamental result in the study of graph homomorphisms is Lov\\'asz's\ntheorem that two graphs are isomorphic if and only if they admit the same\nnumber of homomorphisms from every graph. A line of work extending Lov\\'asz's\nresult to more general types of graphs was recently capped by Cai and Govorov,\nwho showed that it holds for graphs with vertex and edge weights from an\narbitrary field of characteristic 0. In this work, we generalize from graph\nhomomorphism -- a special case of #CSP with a single binary function -- to\ngeneral #CSP by showing that two sets $\\mathcal{F}$ and $\\mathcal{G}$ of\narbitrary constraint functions are isomorphic if and only if the partition\nfunction of any #CSP instance is unchanged when we replace the functions in\n$\\mathcal{F}$ with those in $\\mathcal{G}$. We give two very different proofs of\nthis result. First, we demonstrate the power of the simple Vandermonde\ninterpolation technique of Cai and Govorov by extending it to general #CSP.\nSecond, we give a proof using the intertwiners of the automorphism group of a\nconstraint function set, a concept from the representation theory of compact\ngroups. This proof is a generalization of a classical version of the recent\nproof of the Lov\\'asz-type result by Man\\v{c}inska and Roberson relating\nquantum isomorphism and homomorphisms from planar graphs.",
    "descriptor": "\nComments: 21 pages, 2 figures\n",
    "authors": [
      "Ben Young"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.13688"
  },
  {
    "id": "arXiv:2211.13692",
    "title": "To be or not to be stable, that is the question: understanding neural  networks for inverse problems",
    "abstract": "The solution of linear inverse problems arising, for example, in signal and\nimage processing is a challenging problem, since the ill-conditioning amplifies\nthe noise on the data. Recently introduced deep-learning based algorithms\noverwhelm the more traditional model-based approaches but they typically suffer\nfrom instability with respect to data perturbation. In this paper, we\ntheoretically analyse the trade-off between neural networks stability and\naccuracy in the solution of linear inverse problems. Moreover, we propose\ndifferent supervised and unsupervised solutions, to increase network stability\nby maintaining good accuracy, by inheriting, in the network training,\nregularization from a model-based iterative scheme. Extensive numerical\nexperiments on image deblurring confirm the theoretical results and the\neffectiveness of the proposed networks in solving inverse problems with\nstability with respect to noise.",
    "descriptor": "\nComments: 26 pages, 9 figures, divided in 4 blocks of figures in the LaTeX code. Paper will be sent for publication on a journal soon. This is a preliminary version, updated versions will be uploaded on ArXiv\n",
    "authors": [
      "Davide Evangelista",
      "James Nagy",
      "Elena Morotti",
      "Elena Loli Piccolomini"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13692"
  },
  {
    "id": "arXiv:2211.13694",
    "title": "Hand Guided High Resolution Feature Enhancement for Fine-Grained Atomic  Action Segmentation within Complex Human Assemblies",
    "abstract": "Due to the rapid temporal and fine-grained nature of complex human assembly\natomic actions, traditional action segmentation approaches requiring the\nspatial (and often temporal) down sampling of video frames often loose vital\nfine-grained spatial and temporal information required for accurate\nclassification within the manufacturing domain. In order to fully utilise\nhigher resolution video data (often collected within the manufacturing domain)\nand facilitate real time accurate action segmentation - required for human\nrobot collaboration - we present a novel hand location guided high resolution\nfeature enhanced model. We also propose a simple yet effective method of\ndeploying offline trained action recognition models for real time action\nsegmentation on temporally short fine-grained actions, through the use of\nsurround sampling while training and temporally aware label cleaning at\ninference. We evaluate our model on a novel action segmentation dataset\ncontaining 24 (+background) atomic actions from video data of a real world\nrobotics assembly production line. Showing both high resolution hand features\nas well as traditional frame wide features improve fine-grained atomic action\nclassification, and that though temporally aware label clearing our model is\ncapable of surpassing similar encoder/decoder methods, while allowing for real\ntime classification.",
    "descriptor": "",
    "authors": [
      "Matthew Kent Myers",
      "Nick Wright",
      "Stephen McGough",
      "Nicholas Martin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13694"
  },
  {
    "id": "arXiv:2211.13696",
    "title": "FPT: a Fixed-Point Accelerator for Torus Fully Homomorphic Encryption",
    "abstract": "Fully Homomorphic Encryption is a technique that allows computation on\nencrypted data. It has the potential to drastically change privacy\nconsiderations in the cloud, but high computational and memory overheads are\npreventing its broad adoption. TFHE is a promising Torus-based FHE scheme that\nheavily relies on bootstrapping, the noise-removal tool that must be invoked\nafter every encrypted gate computation.\nWe present FPT, a Fixed-Point FPGA accelerator for TFHE bootstrapping. FPT is\nthe first hardware accelerator to heavily exploit the inherent noise present in\nFHE calculations. Instead of double or single-precision floating-point\narithmetic, it implements TFHE bootstrapping entirely with approximate\nfixed-point arithmetic. Using an in-depth analysis of noise propagation in\nbootstrapping FFT computations, FPT is able to use noise-trimmed fixed-point\nrepresentations that are up to 50% smaller than prior implementations using\nfloating-point or integer FFTs.\nFPT's microarchitecture is built as a streaming processor inspired by\ntraditional streaming DSPs: it instantiates high-throughput computational\nstages that are directly cascaded, with simplified control logic and routing\nnetworks. FPT's streaming approach allows 100% utilization of arithmetic units\nand requires only small bootstrapping key caches, enabling an entirely\ncompute-bound bootstrapping throughput of 1 BS / 35$\\mu$s. This is in stark\ncontrast to the established classical CPU approach to FHE bootstrapping\nacceleration, which tends to be heavily memory and bandwidth-constrained.\nFPT is fully implemented and evaluated as a bootstrapping FPGA kernel for an\nAlveo U280 datacenter accelerator card. FPT achieves almost three orders of\nmagnitude higher bootstrapping throughput than existing CPU-based\nimplementations, and 2.5$\\times$ higher throughput compared to recent ASIC\nemulation experiments.",
    "descriptor": "",
    "authors": [
      "Michiel Van Beirendonck",
      "Jan-Pieter D'Anvers",
      "Ingrid Verbauwhede"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.13696"
  },
  {
    "id": "arXiv:2211.13698",
    "title": "Certified data-driven physics-informed greedy auto-encoder simulator",
    "abstract": "A parametric adaptive greedy Latent Space Dynamics Identification (gLaSDI)\nframework is developed for accurate, efficient, and certified data-driven\nphysics-informed greedy auto-encoder simulators of high-dimensional nonlinear\ndynamical systems. In the proposed framework, an auto-encoder and dynamics\nidentification models are trained interactively to discover intrinsic and\nsimple latent-space dynamics. To effectively explore the parameter space for\noptimal model performance, an adaptive greedy sampling algorithm integrated\nwith a physics-informed error indicator is introduced to search for optimal\ntraining samples on the fly, outperforming the conventional predefined uniform\nsampling. Further, an efficient k-nearest neighbor convex interpolation scheme\nis employed to exploit local latent-space dynamics for improved predictability.\nNumerical results demonstrate that the proposed method achieves 121 to 2,658x\nspeed-up with 1 to 5% relative errors for radial advection and 2D Burgers\ndynamical problems.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2204.12005\n",
    "authors": [
      "Xiaolong He",
      "Youngsoo Choi",
      "William D. Fries",
      "Jonathan L. Belof",
      "Jiun-Shyan Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.13698"
  },
  {
    "id": "arXiv:2211.13702",
    "title": "CasFusionNet: A Cascaded Network for Point Cloud Semantic Scene  Completion by Dense Feature Fusion",
    "abstract": "Semantic scene completion (SSC) aims to complete a partial 3D scene and\npredict its semantics simultaneously. Most existing works adopt the voxel\nrepresentations, thus suffering from the growth of memory and computation cost\nas the voxel resolution increases. Though a few works attempt to solve SSC from\nthe perspective of 3D point clouds, they have not fully exploited the\ncorrelation and complementarity between the two tasks of scene completion and\nsemantic segmentation. In our work, we present CasFusionNet, a novel cascaded\nnetwork for point cloud semantic scene completion by dense feature fusion.\nSpecifically, we design (i) a global completion module (GCM) to produce an\nupsampled and completed but coarse point set, (ii) a semantic segmentation\nmodule (SSM) to predict the per-point semantic labels of the completed points\ngenerated by GCM, and (iii) a local refinement module (LRM) to further refine\nthe coarse completed points and the associated labels from a local perspective.\nWe organize the above three modules via dense feature fusion in each level, and\ncascade a total of four levels, where we also employ feature fusion between\neach level for sufficient information usage. Both quantitative and qualitative\nresults on our compiled two point-based datasets validate the effectiveness and\nsuperiority of our CasFusionNet compared to state-of-the-art methods in terms\nof both scene completion and semantic segmentation. The codes and datasets are\navailable at: https://github.com/JinfengX/CasFusionNet.",
    "descriptor": "",
    "authors": [
      "Jinfeng Xu",
      "Xianzhi Li",
      "Yuan Tang",
      "Qiao Yu",
      "Yixue Hao",
      "Long Hu",
      "Min Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13702"
  },
  {
    "id": "arXiv:2211.13703",
    "title": "Multitask Learning for Low Resource Spoken Language Understanding",
    "abstract": "We explore the benefits that multitask learning offer to speech processing as\nwe train models on dual objectives with automatic speech recognition and intent\nclassification or sentiment classification. Our models, although being of\nmodest size, show improvements over models trained end-to-end on intent\nclassification. We compare different settings to find the optimal disposition\nof each task module compared to one another. Finally, we study the performance\nof the models in low-resource scenario by training the models with as few as\none example per class. We show that multitask learning in these scenarios\ncompete with a baseline model trained on text features and performs\nconsiderably better than a pipeline model. On sentiment classification, we\nmatch the performance of an end-to-end model with ten times as many parameters.\nWe consider 4 tasks and 4 datasets in Dutch and English.",
    "descriptor": "",
    "authors": [
      "Quentin Meeus",
      "Marie-Francine Moens",
      "Hugo Van hamme"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.13703"
  },
  {
    "id": "arXiv:2211.13705",
    "title": "Control and Morphology Optimization of Passive Asymmetric Structures for  Robotic Swimming",
    "abstract": "Aquatic creatures exhibit remarkable adaptations of their body to efficiently\ninteract with the surrounding fluid. The tight coupling between their\nmorphology, motion, and the environment are highly complex but serves as a\nvaluable example when creating biomimetic structures in soft robotic swimmers.\nWe focus on the use of asymmetry in structures to aid thrust generation and\nmaneuverability. Designs of structures with asymmetric profiles are explored so\nthat we can use morphology to `shape' the thrust generation. We propose\ncombining simple simulation with automatic data-driven methods to explore their\ninteractions with the fluid. The asymmetric structure with its co-optimized\nmorphology and controller is able to produce 2.5 times the useful thrust\ncompared to a baseline symmetric structure. Furthermore these asymmetric\nfeather-like arms are validated on a robotic system capable of forward swimming\nmotion while the same robot fitted with a plain feather is not able to move\nforward.",
    "descriptor": "",
    "authors": [
      "Nana Obayashi",
      "Andrea Vicari",
      "Kai Junge",
      "Kamran Shakir",
      "Josie Hughes"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.13705"
  },
  {
    "id": "arXiv:2211.13706",
    "title": "Fast M\u00f6bius and Zeta Transforms",
    "abstract": "M\\\"obius inversion of functions on partially ordered sets (posets)\n$\\mathcal{P}$ is a classical tool in combinatorics. For finite posets it\nconsists of two, mutually inverse, linear transformations called zeta and\nM\\\"obius transform, respectively. In this paper we provide novel fast\nalgorithms for both that require $O(nk)$ time and space, where $n =\n|\\mathcal{P}|$ and $k$ is the width (length of longest antichain) of\n$\\mathcal{P}$, compared to $O(n^2)$ for a direct computation. Our approach\nassumes that $\\mathcal{P}$ is given as directed acyclic graph (DAG)\n$(\\mathcal{E}, \\mathcal{P})$. The algorithms are then constructed using a chain\ndecomposition for a one time cost of $O(|\\mathcal{E}| +\n|\\mathcal{E}_\\text{red}| k)$, where $\\mathcal{E}_\\text{red}$ is the number of\nedges in the DAG's transitive reduction. We show benchmarks with\nimplementations of all algorithms including parallelized versions. The results\nshow that our algorithms enable M\\\"obius inversion on posets with millions of\nnodes in seconds if the defining DAGs are sufficiently sparse.",
    "descriptor": "\nComments: 16 pages, 7 figures, submitted for review\n",
    "authors": [
      "Tommaso Pegolotti",
      "Bastian Seifert",
      "Markus P\u00fcschel"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.13706"
  },
  {
    "id": "arXiv:2211.13708",
    "title": "Reduction Algorithms for Persistence Diagrams of Networks: CoralTDA and  PrunIT",
    "abstract": "Topological data analysis (TDA) delivers invaluable and complementary\ninformation on the intrinsic properties of data inaccessible to conventional\nmethods. However, high computational costs remain the primary roadblock\nhindering the successful application of TDA in real-world studies, particularly\nwith machine learning on large complex networks.\nIndeed, most modern networks such as citation, blockchain, and online social\nnetworks often have hundreds of thousands of vertices, making the application\nof existing TDA methods infeasible. We develop two new, remarkably simple but\neffective algorithms to compute the exact persistence diagrams of large graphs\nto address this major TDA limitation. First, we prove that $(k+1)$-core of a\ngraph $\\mathcal{G}$ suffices to compute its $k^{th}$ persistence diagram,\n$PD_k(\\mathcal{G})$. Second, we introduce a pruning algorithm for graphs to\ncompute their persistence diagrams by removing the dominated vertices. Our\nexperiments on large networks show that our novel approach can achieve\ncomputational gains up to 95%.\nThe developed framework provides the first bridge between the graph theory\nand TDA, with applications in machine learning of large complex networks. Our\nimplementation is available at\nhttps://github.com/cakcora/PersistentHomologyWithCoralPrunit",
    "descriptor": "\nComments: Spotlight paper at NeurIPS 2022\n",
    "authors": [
      "Cuneyt Gurcan Akcora",
      "Murat Kantarcioglu",
      "Yulia R. Gel",
      "Baris Coskunuzer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2211.13708"
  },
  {
    "id": "arXiv:2211.13709",
    "title": "Undesirable biases in NLP: Averting a crisis of measurement",
    "abstract": "As Natural Language Processing (NLP) technology rapidly develops and spreads\ninto daily life, it becomes crucial to anticipate how its use could harm\npeople. However, our ways of assessing the biases of NLP models have not kept\nup. While especially the detection of English gender bias in such models has\nenjoyed increasing research attention, many of the measures face serious\nproblems, as it is often unclear what they actually measure and how much they\nare subject to measurement error. In this paper, we provide an\ninterdisciplinary approach to discussing the issue of NLP model bias by\nadopting the lens of psychometrics -- a field specialized in the measurement of\nconcepts like bias that are not directly observable. We pair an introduction of\nrelevant psychometric concepts with a discussion of how they could be used to\nevaluate and improve bias measures. We also argue that adopting psychometric\nvocabulary and methodology can make NLP bias research more efficient and\ntransparent.",
    "descriptor": "",
    "authors": [
      "Oskar van der Wal",
      "Dominik Bachmann",
      "Alina Leidinger",
      "Leendert van Maanen",
      "Willem Zuidema",
      "Katrin Schulz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13709"
  },
  {
    "id": "arXiv:2211.13718",
    "title": "Emotion-guided Cross-domain Fake News Detection using Adversarial Domain  Adaptation",
    "abstract": "Recent works on fake news detection have shown the efficacy of using emotions\nas a feature or emotions-based features for improved performance. However, the\nimpact of these emotion-guided features for fake news detection in cross-domain\nsettings, where we face the problem of domain shift, is still largely\nunexplored. In this work, we evaluate the impact of emotion-guided features for\ncross-domain fake news detection, and further propose an emotion-guided,\ndomain-adaptive approach using adversarial learning. We prove the efficacy of\nemotion-guided models in cross-domain settings for various combinations of\nsource and target datasets from FakeNewsAMT, Celeb, Politifact and Gossipcop\ndatasets.",
    "descriptor": "\nComments: Accepted as a Short Paper in the 19th International Conference on Natural Language Processing (ICON) 2022\n",
    "authors": [
      "Arjun Choudhry",
      "Inder Khatri",
      "Arkajyoti Chakraborty",
      "Dinesh Kumar Vishwakarma",
      "Mukesh Prasad"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.13718"
  },
  {
    "id": "arXiv:2211.13720",
    "title": "Cooperative Collision Avoidance in Mobile Robots using Dynamic Vortex  Potential Fields",
    "abstract": "In this paper, the collision avoidance problem for non-holonomic robots\nmoving at constant linear speeds in the 2-D plane is considered. The maneuvers\nto avoid collisions are designed using dynamic vortex potential fields (PFs)\nand their negative gradients; this formulation leads to a reciprocal behaviour\nbetween the robots, denoted as being cooperative. The repulsive field is\nselected as a function of the velocity and position of a robot relative to\nanother and introducing vorticity in its definition guarantees the absence of\nlocal minima. Such a repulsive field is activated by a robot only when it is on\na collision path with other mobile robots or stationary obstacles. By analysing\nthe kinematics-based engagement dynamics in polar coordinates, it is shown that\na cooperative robot is able to avoid collisions with non-cooperating robots,\nsuch as stationary and constant velocity robots, as well as those actively\nseeking to collide with it. Conditions on the PF parameters are identified that\nensure collision avoidance for all cases. Experimental results acquired using a\nmobile robot platform support the theoretical contributions.",
    "descriptor": "",
    "authors": [
      "Wayne Paul Martis",
      "Sachit Rao"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.13720"
  },
  {
    "id": "arXiv:2211.13723",
    "title": "Improving Multi-task Learning via Seeking Task-based Flat Regions",
    "abstract": "Multi-Task Learning (MTL) is a widely-used and powerful learning paradigm for\ntraining deep neural networks that allows learning more than one objective by a\nsingle backbone. Compared to training tasks separately, MTL significantly\nreduces computational costs, improves data efficiency, and potentially enhances\nmodel performance by leveraging knowledge across tasks. Hence, it has been\nadopted in a variety of applications, ranging from computer vision to natural\nlanguage processing and speech recognition. Among them, there is an emerging\nline of work in MTL that focuses on manipulating the task gradient to derive an\nultimate gradient descent direction to benefit all tasks. Despite achieving\nimpressive results on many benchmarks, directly applying these approaches\nwithout using appropriate regularization techniques might lead to suboptimal\nsolutions on real-world problems. In particular, standard training that\nminimizes the empirical loss on the training data can easily suffer from\noverfitting to low-resource tasks or be spoiled by noisy-labeled ones, which\ncan cause negative transfer between tasks and overall performance drop. To\nalleviate such problems, we propose to leverage a recently introduced training\nmethod, named Sharpness-aware Minimization, which can enhance model\ngeneralization ability on single-task learning. Accordingly, we present a novel\nMTL training methodology, encouraging the model to find task-based flat minima\nfor coherently improving its generalization capability on all tasks. Finally,\nwe conduct comprehensive experiments on a variety of applications to\ndemonstrate the merit of our proposed approach to existing gradient-based MTL\nmethods, as suggested by our developed theory.",
    "descriptor": "\nComments: 29 pages, 11 figures, 6 tables\n",
    "authors": [
      "Hoang Phan",
      "Lam Tran",
      "Ngoc N. Tran",
      "Nhat Ho",
      "Dinh Phung",
      "Trung Le"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13723"
  },
  {
    "id": "arXiv:2211.13724",
    "title": "Estimating Regression Predictive Distributions with Sample Networks",
    "abstract": "Estimating the uncertainty in deep neural network predictions is crucial for\nmany real-world applications. A common approach to model uncertainty is to\nchoose a parametric distribution and fit the data to it using maximum\nlikelihood estimation. The chosen parametric form can be a poor fit to the\ndata-generating distribution, resulting in unreliable uncertainty estimates. In\nthis work, we propose SampleNet, a flexible and scalable architecture for\nmodeling uncertainty that avoids specifying a parametric form on the output\ndistribution. SampleNets do so by defining an empirical distribution using\nsamples that are learned with the Energy Score and regularized with the\nSinkhorn Divergence. SampleNets are shown to be able to well-fit a wide range\nof distributions and to outperform baselines on large-scale real-world\nregression tasks.",
    "descriptor": "\nComments: Accepted for publication in AAAI 2023. Example code at: this https URL\n",
    "authors": [
      "Ali Harakeh",
      "Jordan Hu",
      "Naiqing Guan",
      "Steven L. Waslander",
      "Liam Paull"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13724"
  },
  {
    "id": "arXiv:2211.13725",
    "title": "Asynchronous Computation of Tube-based Model Predictive Control",
    "abstract": "Tube-based model predictive control (MPC) methods bound deviations from a\nnominal trajectory due to uncertainties in order to ensure constraint\nsatisfaction. While techniques that compute the tubes online reduce\nconservativeness and increase performance, they suffer from high and\npotentially prohibitive computational complexity. This paper presents an\nasynchronous computation mechanism for system level tube-MPC (SLTMPC), a\nrecently proposed tube-based MPC method which optimizes over both the nominal\ntrajectory and the tubes. Computations are split into a primary and a secondary\nprocess, computing the nominal trajectory and the tubes, respectively. This\nenables running the primary process at a high frequency and moving the\ncomputationally complex tube computations to the secondary process. We show\nthat the secondary process can continuously update the tubes, while retaining\nrecursive feasibility and robust stability of the primary process.",
    "descriptor": "\nComments: Submitted to IFAC WC 2023\n",
    "authors": [
      "Jerome Sieber",
      "Andrea Zanelli",
      "Samir Bennani",
      "Melanie N. Zeilinger"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.13725"
  },
  {
    "id": "arXiv:2211.13726",
    "title": "Lightweight Event-based Optical Flow Estimation via Iterative Deblurring",
    "abstract": "Inspired by frame-based methods, state-of-the-art event-based optical flow\nnetworks rely on the explicit computation of correlation volumes, which are\nexpensive to compute and store on systems with limited processing budget and\nmemory. To this end, we introduce IDNet (Iterative Deblurring Network), a\nlightweight yet well-performing event-based optical flow network without using\ncorrelation volumes. IDNet leverages the unique spatiotemporally continuous\nnature of event streams to propose an alternative way of implicitly capturing\ncorrelation through iterative refinement and motion deblurring. Our network\ndoes not compute correlation volumes but rather utilizes a recurrent network to\nmaximize the spatiotemporal correlation of events iteratively. We further\npropose two iterative update schemes: \"ID\" which iterates over the same batch\nof events, and \"TID\" which iterates over time with streaming events in an\nonline fashion. Benchmark results show the former \"ID\" scheme can reach close\nto state-of-the-art performance with 33% of savings in compute and 90% in\nmemory footprint, while the latter \"TID\" scheme is even more efficient\npromising 83% of compute savings and 15 times less latency at the cost of 18%\nof performance drop.",
    "descriptor": "",
    "authors": [
      "Yilun Wu",
      "Federico Paredes-Vall\u00e9s",
      "Guido C. H. E. de Croon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13726"
  },
  {
    "id": "arXiv:2211.13727",
    "title": "Question-type Identification for Academic Questions in Online Learning  Platform",
    "abstract": "Online learning platforms provide learning materials and answers to students'\nacademic questions by experts, peers, or systems. This paper explores\nquestion-type identification as a step in content understanding for an online\nlearning platform. The aim of the question-type identifier is to categorize\nquestion types based on their structure and complexity, using the question\ntext, subject, and structural features. We have defined twelve question-type\nclasses, including Multiple-Choice Question (MCQ), essay, and others. We have\ncompiled an internal dataset of students' questions and used a combination of\nweak-supervision techniques and manual annotation. We then trained a BERT-based\nensemble model on this dataset and evaluated this model on a separate\nhuman-labeled test set. Our experiments yielded an F1-score of 0.94 for MCQ\nbinary classification and promising results for 12-class multilabel\nclassification. We deployed the model in our online learning platform as a\ncrucial enabler for content understanding to enhance the student learning\nexperience.",
    "descriptor": "\nComments: 18 pages, 6 figures, 4th International Conference on Semantic & Natural Language Processing (SNLP 2023)\n",
    "authors": [
      "Azam Rabiee",
      "Alok Goel",
      "Johnson D'Souza",
      "Saurabh Khanwalkar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13727"
  },
  {
    "id": "arXiv:2211.13729",
    "title": "Probabilistic Time Series Forecasting for Adaptive Monitoring in Edge  Computing Environments",
    "abstract": "With increasingly more computation being shifted to the edge of the network,\nmonitoring of critical infrastructures, such as intermediate processing nodes\nin autonomous driving, is further complicated due to the typically\nresource-constrained environments. In order to reduce the resource overhead on\nthe network link imposed by monitoring, various methods have been discussed\nthat either follow a filtering approach for data-emitting devices or conduct\ndynamic sampling based on employed prediction models. Still, existing methods\nare mainly requiring adaptive monitoring on edge devices, which demands device\nreconfigurations, utilizes additional resources, and limits the sophistication\nof employed models.\nIn this paper, we propose a sampling-based and cloud-located approach that\ninternally utilizes probabilistic forecasts and hence provides means of\nquantifying model uncertainties, which can be used for contextualized\nadaptations of sampling frequencies and consequently relieves constrained\nnetwork resources. We evaluate our prototype implementation for the monitoring\npipeline on a publicly available streaming dataset and demonstrate its positive\nimpact on resource efficiency in a method comparison.",
    "descriptor": "\nComments: 6 pages, 5 figures, 2 tables\n",
    "authors": [
      "Dominik Scheinert",
      "Babak Sistani Zadeh Aghdam",
      "Soeren Becker",
      "Odej Kao",
      "Lauritz Thamsen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13729"
  },
  {
    "id": "arXiv:2211.13731",
    "title": "Computational multiscale methods for nondivergence-form elliptic partial  differential equations",
    "abstract": "This paper proposes novel computational multiscale methods for linear\nsecond-order elliptic partial differential equations in nondivergence-form with\nheterogeneous coefficients satisfying a Cordes condition. The construction\nfollows the methodology of localized orthogonal decomposition (LOD) and\nprovides operator-adapted coarse spaces by solving localized cell problems on a\nfine scale in the spirit of numerical homogenization. The degrees of freedom of\nthe coarse spaces are related to nonconforming and mixed finite element methods\nfor homogeneous problems. The rigorous error analysis of one exemplary approach\nshows that the favorable properties of the LOD methodology known from\ndivergence-form PDEs, i.e., its applicability and accuracy beyond scale\nseparation and periodicity, remain valid for problems in nondivergence-form.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Philip Freese",
      "Dietmar Gallistl",
      "Daniel Peterseim",
      "Timo Sprekeler"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.13731"
  },
  {
    "id": "arXiv:2211.13732",
    "title": "Deep Demosaicing for Polarimetric Filter Array Cameras",
    "abstract": "Polarisation Filter Array (PFA) cameras allow the analysis of light\npolarisation state in a simple and cost-effective manner. Such filter arrays\nwork as the Bayer pattern for colour cameras, sharing similar advantages and\ndrawbacks. Among the others, the raw image must be demosaiced considering the\nlocal variations of the PFA and the characteristics of the imaged scene.\nNon-linear effects, like the cross-talk among neighbouring pixels, are\ndifficult to explicitly model and suggest the potential advantage of a\ndata-driven learning approach. However, the PFA cannot be removed from the\nsensor, making it difficult to acquire the ground-truth polarization state for\ntraining. In this work we propose a novel CNN-based model which directly\ndemosaics the raw camera image to a per-pixel Stokes vector. Our contribution\nis twofold. First, we propose a network architecture composed by a sequence of\nMosaiced Convolutions operating coherently with the local arrangement of the\ndifferent filters. Second, we introduce a new method, employing a consumer LCD\nscreen, to effectively acquire real-world data for training. The process is\ndesigned to be invariant by monitor gamma and external lighting conditions. We\nextensively compared our method against algorithmic and learning-based\ndemosaicing techniques, obtaining a consistently lower error especially in\nterms of polarisation angle.",
    "descriptor": "",
    "authors": [
      "Mara Pistellato",
      "Filippo Bergamasco",
      "Tehreem Fatima",
      "Andrea Torsello"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.13732"
  },
  {
    "id": "arXiv:2211.13734",
    "title": "On Pitfalls of Measuring Occlusion Robustness through Data Distortion",
    "abstract": "Over the past years, the crucial role of data has largely been shadowed by\nthe field's focus on architectures and training procedures. We often cause\nchanges to the data without being aware of their wider implications. In this\npaper we show that distorting images without accounting for the artefacts\nintroduced leads to biased results when establishing occlusion robustness. To\nensure models behave as expected in real-world scenarios, we need to rule out\nthe impact added artefacts have on evaluation. We propose a new approach,\niOcclusion, as a fairer alternative for applications where the possible\noccluders are unknown.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2111.11514\n",
    "authors": [
      "Antonia Marcu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13734"
  },
  {
    "id": "arXiv:2211.13735",
    "title": "Explainable Model-Agnostic Similarity and Confidence in Face  Verification",
    "abstract": "Recently, face recognition systems have demonstrated remarkable performances\nand thus gained a vital role in our daily life. They already surpass human face\nverification accountability in many scenarios. However, they lack explanations\nfor their predictions. Compared to human operators, typical face recognition\nnetwork system generate only binary decisions without further explanation and\ninsights into those decisions. This work focuses on explanations for face\nrecognition systems, vital for developers and operators. First, we introduce a\nconfidence score for those systems based on facial feature distances between\ntwo input images and the distribution of distances across a dataset. Secondly,\nwe establish a novel visualization approach to obtain more meaningful\npredictions from a face recognition system, which maps the distance deviation\nbased on a systematic occlusion of images. The result is blended with the\noriginal images and highlights similar and dissimilar facial regions. Lastly,\nwe calculate confidence scores and explanation maps for several\nstate-of-the-art face verification datasets and release the results on a web\nplatform. We optimize the platform for a user-friendly interaction and hope to\nfurther improve the understanding of machine learning decisions. The source\ncode is available on GitHub, and the web platform is publicly available at\nthis http URL",
    "descriptor": "",
    "authors": [
      "Martin Knoche",
      "Torben Teepe",
      "Stefan H\u00f6rmann",
      "Gerhard Rigoll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13735"
  },
  {
    "id": "arXiv:2211.13737",
    "title": "CycleGANWM: A CycleGAN watermarking method for ownership verification",
    "abstract": "Due to the proliferation and widespread use of deep neural networks (DNN),\ntheir Intellectual Property Rights (IPR) protection has become increasingly\nimportant. This paper presents a novel model watermarking method for an\nunsupervised image-to-image translation (I2IT) networks, named CycleGAN, which\nleverage the image translation visual quality and watermark embedding. In this\nmethod, a watermark decoder is trained initially. Then the decoder is frozen\nand used to extract the watermark bits when training the CycleGAN watermarking\nmodel. The CycleGAN watermarking (CycleGANWM) is trained with specific loss\nfunctions and optimized to get a good performance on both I2IT task and\nwatermark embedding. For watermark verification, this work uses statistical\nsignificance test to identify the ownership of the model from the extract\nwatermark bits. We evaluate the robustness of the model against image\npost-processing and improve it by fine-tuning the model with adding data\naugmentation on the output images before extracting the watermark bits. We also\ncarry out surrogate model attack under black-box access of the model. The\nexperimental results prove that the proposed method is effective and robust to\nsome image post-processing, and it is able to resist surrogate model attack.",
    "descriptor": "",
    "authors": [
      "Dongdong Lin",
      "Benedetta Tondi",
      "Bin Li",
      "Mauro Barni"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.13737"
  },
  {
    "id": "arXiv:2211.13739",
    "title": "Numerical Approximation of Gaussian random fields on Closed Surfaces",
    "abstract": "We consider the numerical approximation of Gaussian random fields on closed\nsurfaces defined as the solution to a fractional stochastic partial\ndifferential equation (SPDE) with additive white noise. The SPDE involves two\nparameters controlling the smoothness and the correlation length of the\nGaussian random field. The proposed numerical method relies on the Balakrishnan\nintegral representation of the solution and does not require the approximation\nof eigenpairs. Rather, it consists of a sinc quadrature coupled with a standard\nsurface finite element method. We provide a complete error analysis of the\nmethod and illustrate its performances by several numerical experiments.",
    "descriptor": "\nComments: 33 pages, 2 figures, 5 tables\n",
    "authors": [
      "Andrea Bonito",
      "Diane Guignard",
      "Wenyu Lei"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.13739"
  },
  {
    "id": "arXiv:2211.13741",
    "title": "Parallel Repetition for the GHZ Game: Exponential Decay",
    "abstract": "We show that the value of the $n$-fold repeated GHZ game is at most\n$2^{-\\Omega(n)}$, improving upon the polynomial bound established by Holmgren\nand Raz. Our result is established via a reduction to approximate subgroup type\nquestions from additive combinatorics.",
    "descriptor": "",
    "authors": [
      "Mark Braverman",
      "Subhash Khot",
      "Dor Minzer"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.13741"
  },
  {
    "id": "arXiv:2211.13742",
    "title": "Assessing Quality-Diversity Neuro-Evolution Algorithms Performance in  Hard Exploration Problems",
    "abstract": "A fascinating aspect of nature lies in its ability to produce a collection of\norganisms that are all high-performing in their niche. Quality-Diversity (QD)\nmethods are evolutionary algorithms inspired by this observation, that obtained\ngreat results in many applications, from wing design to robot adaptation.\nRecently, several works demonstrated that these methods could be applied to\nperform neuro-evolution to solve control problems in large search spaces. In\nsuch problems, diversity can be a target in itself. Diversity can also be a way\nto enhance exploration in tasks exhibiting deceptive reward signals. While the\nfirst aspect has been studied in depth in the QD community, the latter remains\nscarcer in the literature. Exploration is at the heart of several domains\ntrying to solve control problems such as Reinforcement Learning and QD methods\nare promising candidates to overcome the challenges associated. Therefore, we\nbelieve that standardized benchmarks exhibiting control problems in high\ndimension with exploration difficulties are of interest to the QD community. In\nthis paper, we highlight three candidate benchmarks and explain why they appear\nrelevant for systematic evaluation of QD algorithms. We also provide\nopen-source implementations in Jax allowing practitioners to run fast and\nnumerous experiments on few compute resources.",
    "descriptor": "\nComments: GECCO 2022 Workshop on Quality Diversity Algorithm Benchmarks\n",
    "authors": [
      "Felix Chalumeau",
      "Thomas Pierrot",
      "Valentin Mac\u00e9",
      "Arthur Flajolet",
      "Karim Beguir",
      "Antoine Cully",
      "Nicolas Perrin-Gilbert"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13742"
  },
  {
    "id": "arXiv:2211.13743",
    "title": "SkillS: Adaptive Skill Sequencing for Efficient Temporally-Extended  Exploration",
    "abstract": "The ability to effectively reuse prior knowledge is a key requirement when\nbuilding general and flexible Reinforcement Learning (RL) agents. Skill reuse\nis one of the most common approaches, but current methods have considerable\nlimitations.For example, fine-tuning an existing policy frequently fails, as\nthe policy can degrade rapidly early in training. In a similar vein,\ndistillation of expert behavior can lead to poor results when given sub-optimal\nexperts. We compare several common approaches for skill transfer on multiple\ndomains including changes in task and system dynamics. We identify how existing\nmethods can fail and introduce an alternative approach to mitigate these\nproblems. Our approach learns to sequence existing temporally-extended skills\nfor exploration but learns the final policy directly from the raw experience.\nThis conceptual split enables rapid adaptation and thus efficient data\ncollection but without constraining the final solution.It significantly\noutperforms many classical methods across a suite of evaluation tasks and we\nuse a broad set of ablations to highlight the importance of differentc\nomponents of our method.",
    "descriptor": "",
    "authors": [
      "Giulia Vezzani",
      "Dhruva Tirumala",
      "Markus Wulfmeier",
      "Dushyant Rao",
      "Abbas Abdolmaleki",
      "Ben Moran",
      "Tuomas Haarnoja",
      "Jan Humplik",
      "Roland Hafner",
      "Michael Neunert",
      "Claudio Fantacci",
      "Tim Hertweck",
      "Thomas Lampe",
      "Fereshteh Sadeghi",
      "Nicolas Heess",
      "Martin Riedmiller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.13743"
  },
  {
    "id": "arXiv:2211.13744",
    "title": "Phase function methods for second order inhomogeneous linear ordinary  differential equations",
    "abstract": "It is well known that second order homogeneous linear ordinary differential\nequations with slowly varying coefficients admit slowly varying phase\nfunctions. This observation underlies the Liouville-Green method and many other\ntechniques for the asymptotic approximation of the solutions of such equations.\nIt is also the basis of a recently developed numerical algorithm that, in many\ncases of interest, runs in time independent of the magnitude of the equation's\ncoefficients and achieves accuracy on par with that predicted by its condition\nnumber. Here we point out that a large class of second order inhomogeneous\nlinear ordinary differential equations can be efficiently and accurately solved\nby combining phase function methods for second order homogeneous linear\nordinary differential equations with a variant of the adaptive Levin method for\nevaluating oscillatory integrals.",
    "descriptor": "",
    "authors": [
      "Kirill Serkh",
      "James Bremer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.13744"
  },
  {
    "id": "arXiv:2211.13745",
    "title": "Attention-based Feature Compression for CNN Inference Offloading in Edge  Computing",
    "abstract": "This paper studies the computational offloading of CNN inference in\ndevice-edge co-inference systems. Inspired by the emerging paradigm semantic\ncommunication, we propose a novel autoencoder-based CNN architecture (AECNN),\nfor effective feature extraction at end-device. We design a feature compression\nmodule based on the channel attention method in CNN, to compress the\nintermediate data by selecting the most important features. To further reduce\ncommunication overhead, we can use entropy encoding to remove the statistical\nredundancy in the compressed data. At the receiver, we design a lightweight\ndecoder to reconstruct the intermediate data through learning from the received\ncompressed data to improve accuracy. To fasten the convergence, we use a\nstep-by-step approach to train the neural networks obtained based on ResNet-50\narchitecture. Experimental results show that AECNN can compress the\nintermediate data by more than 256x with only about 4% accuracy loss, which\noutperforms the state-of-the-art work, BottleNet++. Compared to offloading\ninference task directly to edge server, AECNN can complete inference task\nearlier, in particular, under poor wireless channel condition, which highlights\nthe effectiveness of AECNN in guaranteeing higher accuracy within time\nconstraint.",
    "descriptor": "\nComments: Submitted to IEEE ICC 2023\n",
    "authors": [
      "Nan Li",
      "Alexandros Iosifidis",
      "Qi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13745"
  },
  {
    "id": "arXiv:2211.13746",
    "title": "Melting Pot 2.0",
    "abstract": "Multi-agent artificial intelligence research promises a path to develop\nintelligent technologies that are more human-like and more human-compatible\nthan those produced by \"solipsistic\" approaches, which do not consider\ninteractions between agents. Melting Pot is a research tool developed to\nfacilitate work on multi-agent artificial intelligence, and provides an\nevaluation protocol that measures generalization to novel social partners in a\nset of canonical test scenarios. Each scenario pairs a physical environment (a\n\"substrate\") with a reference set of co-players (a \"background population\"), to\ncreate a social situation with substantial interdependence between the\nindividuals involved. For instance, some scenarios were inspired by\ninstitutional-economics-based accounts of natural resource management and\npublic-good-provision dilemmas. Others were inspired by considerations from\nevolutionary biology, game theory, and artificial life. Melting Pot aims to\ncover a maximally diverse set of interdependencies and incentives. It includes\nthe commonly-studied extreme cases of perfectly-competitive (zero-sum)\nmotivations and perfectly-cooperative (shared-reward) motivations, but does not\nstop with them. As in real-life, a clear majority of scenarios in Melting Pot\nhave mixed incentives. They are neither purely competitive nor purely\ncooperative and thus demand successful agents be able to navigate the resulting\nambiguity. Here we describe Melting Pot 2.0, which revises and expands on\nMelting Pot. We also introduce support for scenarios with asymmetric roles, and\nexplain how to integrate them into the evaluation protocol. This report also\ncontains: (1) details of all substrates and scenarios; (2) a complete\ndescription of all baseline algorithms and results. Our intention is for it to\nserve as a reference for researchers using Melting Pot 2.0.",
    "descriptor": "\nComments: 47 pages, 4 figures. arXiv admin note: text overlap with arXiv:2107.06857\n",
    "authors": [
      "John P. Agapiou",
      "Alexander Sasha Vezhnevets",
      "Edgar A. Du\u00e9\u00f1ez-Guzm\u00e1n",
      "Jayd Matyas",
      "Yiran Mao",
      "Peter Sunehag",
      "Raphael K\u00f6ster",
      "Udari Madhushani",
      "Kavya Kopparapu",
      "Ramona Comanescu",
      "DJ Strouse",
      "Michael B. Johanson",
      "Sukhdeep Singh",
      "Julia Haas",
      "Igor Mordatch",
      "Dean Mobbs",
      "Joel Z. Leibo"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.13746"
  },
  {
    "id": "arXiv:2211.13748",
    "title": "How We Express Ourselves Freely: Censorship, Self-censorship, and  Anti-censorship on a Chinese Social Media",
    "abstract": "Censorship, anti-censorship, and self-censorship in an authoritarian regime\nhave been extensively studies, yet the relationship between these intertwined\nfactors is not well understood. In this paper, we report results of a\nlarge-scale survey study (N = 526) with Sina Weibo users toward bridging this\nresearch gap. Through descriptive statistics, correlation analysis, and\nregression analysis, we uncover how users are being censored, how and why they\nconduct self-censorship on different topics and in different scenarios (i.e.,\npost, repost, and comment), and their various anti-censorship strategies. We\nfurther identify the metrics of censorship and self-censorship, find the\ninfluence factors, and construct a mediation model to measure their\nrelationship. Based on these findings, we discuss implications for democratic\nsocial media design and future censorship research.",
    "descriptor": "\nComments: iConference 2023 has accepted\n",
    "authors": [
      "Xiang Chen",
      "Jiamu Xie",
      "Zixin Wang",
      "Bohui Shen",
      "Zhixuan Zhou"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.13748"
  },
  {
    "id": "arXiv:2211.13752",
    "title": "Sketch-Guided Text-to-Image Diffusion Models",
    "abstract": "Text-to-Image models have introduced a remarkable leap in the evolution of\nmachine learning, demonstrating high-quality synthesis of images from a given\ntext-prompt. However, these powerful pretrained models still lack control\nhandles that can guide spatial properties of the synthesized images. In this\nwork, we introduce a universal approach to guide a pretrained text-to-image\ndiffusion model, with a spatial map from another domain (e.g., sketch) during\ninference time. Unlike previous works, our method does not require to train a\ndedicated model or a specialized encoder for the task. Our key idea is to train\na Latent Guidance Predictor (LGP) - a small, per-pixel, Multi-Layer Perceptron\n(MLP) that maps latent features of noisy images to spatial maps, where the deep\nfeatures are extracted from the core Denoising Diffusion Probabilistic Model\n(DDPM) network. The LGP is trained only on a few thousand images and\nconstitutes a differential guiding map predictor, over which the loss is\ncomputed and propagated back to push the intermediate images to agree with the\nspatial map. The per-pixel training offers flexibility and locality which\nallows the technique to perform well on out-of-domain sketches, including\nfree-hand style drawings. We take a particular focus on the sketch-to-image\ntranslation task, revealing a robust and expressive way to generate images that\nfollow the guidance of a sketch of arbitrary style or domain. Project page:\nsketch-guided-diffusion.github.io",
    "descriptor": "",
    "authors": [
      "Andrey Voynov",
      "Kfir Aberman",
      "Daniel Cohen-Or"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13752"
  },
  {
    "id": "arXiv:2211.13755",
    "title": "TemporalStereo: Efficient Spatial-Temporal Stereo Matching Network",
    "abstract": "We present TemporalStereo, a coarse-to-fine based online stereo matching\nnetwork which is highly efficient, and able to effectively exploit the past\ngeometry and context information to boost the matching accuracy. Our network\nleverages sparse cost volume and proves to be effective when a single stereo\npair is given, however, its peculiar ability to use spatio-temporal information\nacross frames allows TemporalStereo to alleviate problems such as occlusions\nand reflective regions while enjoying high efficiency also in the case of\nstereo sequences. Notably our model trained, once with stereo videos, can run\nin both single-pair and temporal ways seamlessly. Experiments show that our\nnetwork relying on camera motion is even robust to dynamic objects when running\non videos. We validate TemporalStereo through extensive experiments on\nsynthetic (SceneFlow, TartanAir) and real (KITTI 2012, KITTI 2015) datasets.\nDetailed results show that our model achieves state-of-the-art performance on\nany of these datasets. Code is available at\n\\url{https://github.com/youmi-zym/TemporalStereo.git}.",
    "descriptor": "",
    "authors": [
      "Youmin Zhang",
      "Matteo Poggi",
      "Stefano Mattoccia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13755"
  },
  {
    "id": "arXiv:2211.13756",
    "title": "Contrastive pretraining for semantic segmentation is robust to noisy  positive pairs",
    "abstract": "Domain-specific variants of contrastive learning can construct positive pairs\nfrom two distinct images, as opposed to augmenting the same image twice. Unlike\nin traditional contrastive methods, this can result in positive pairs not\nmatching perfectly. Similar to false negative pairs, this could impede model\nperformance. Surprisingly, we find that downstream semantic segmentation is\neither robust to the noisy pairs or even benefits from them. The experiments\nare conducted on the remote sensing dataset xBD, and a synthetic segmentation\ndataset, on which we have full control over the noise parameters. As a result,\npractitioners should be able to use such domain-specific contrastive methods\nwithout having to filter their positive pairs beforehand.",
    "descriptor": "\nComments: 8 pages, 8 figures\n",
    "authors": [
      "Sebastian Gerard",
      "Josephine Sullivan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13756"
  },
  {
    "id": "arXiv:2211.13757",
    "title": "DiffusionSDF: Conditional Generative Modeling of Signed Distance  Functions",
    "abstract": "Probabilistic diffusion models have achieved state-of-the-art results for\nimage synthesis, inpainting, and text-to-image tasks. However, they are still\nin the early stages of generating complex 3D shapes. This work proposes\nDiffusionSDF, a generative model for shape completion, single-view\nreconstruction, and reconstruction of real-scanned point clouds. We use neural\nsigned distance functions (SDFs) as our 3D representation to parameterize the\ngeometry of various signals (e.g., point clouds, 2D images) through neural\nnetworks. Neural SDFs are implicit functions and diffusing them amounts to\nlearning the reversal of their neural network weights, which we solve using a\ncustom modulation module. Extensive experiments show that our method is capable\nof both realistic unconditional generation and conditional generation from\npartial inputs. This work expands the domain of diffusion models from learning\n2D, explicit representations, to 3D, implicit representations.",
    "descriptor": "",
    "authors": [
      "Gene Chou",
      "Yuval Bahat",
      "Felix Heide"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13757"
  },
  {
    "id": "arXiv:2211.13762",
    "title": "ScanNeRF: a Scalable Benchmark for Neural Radiance Fields",
    "abstract": "In this paper, we propose the first-ever real benchmark thought for\nevaluating Neural Radiance Fields (NeRFs) and, in general, Neural Rendering\n(NR) frameworks. We design and implement an effective pipeline for scanning\nreal objects in quantity and effortlessly. Our scan station is built with less\nthan 500$ hardware budget and can collect roughly 4000 images of a scanned\nobject in just 5 minutes. Such a platform is used to build ScanNeRF, a dataset\ncharacterized by several train/val/test splits aimed at benchmarking the\nperformance of modern NeRF methods under different conditions. Accordingly, we\nevaluate three cutting-edge NeRF variants on it to highlight their strengths\nand weaknesses. The dataset is available on our project page, together with an\nonline benchmark to foster the development of better and better NeRFs.",
    "descriptor": "\nComments: WACV 2023. The first three authors contributed equally. Project page: this https URL\n",
    "authors": [
      "Luca De Luigi",
      "Damiano Bolognini",
      "Federico Domeniconi",
      "Daniele De Gregorio",
      "Matteo Poggi",
      "Luigi Di Stefano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13762"
  },
  {
    "id": "arXiv:2211.13769",
    "title": "On designing light-weight object trackers through network pruning: Use  CNNs or transformers?",
    "abstract": "Object trackers deployed on low-power devices need to be light-weight,\nhowever, most of the current state-of-the-art (SOTA) methods rely on using\ncompute-heavy backbones built using CNNs or transformers. Large sizes of such\nmodels do not allow their deployment in low-power conditions and designing\ncompressed variants of large tracking models is of great importance. This paper\ndemonstrates how highly compressed light-weight object trackers can be designed\nusing neural architectural pruning of large CNN and transformer based trackers.\nFurther, a comparative study on architectural choices best suited to design\nlight-weight trackers is provided. A comparison between SOTA trackers using\nCNNs, transformers as well as the combination of the two is presented to study\ntheir stability at various compression ratios. Finally results for extreme\npruning scenarios going as low as 1% in some cases are shown to study the\nlimits of network pruning in object tracking. This work provides deeper\ninsights into designing highly efficient trackers from existing SOTA methods.",
    "descriptor": "\nComments: Submitted at IEEE ICASSP 2023\n",
    "authors": [
      "Saksham Aggarwal",
      "Taneesh Gupta",
      "Pawan Kumar Sahu",
      "Arnav Chavan",
      "Rishabh Tiwari",
      "Dilip K. Prasad",
      "Deepak K. Gupta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13769"
  },
  {
    "id": "arXiv:2211.13771",
    "title": "Towards Practical Control of Singular Values of Convolutional Layers",
    "abstract": "In general, convolutional neural networks (CNNs) are easy to train, but their\nessential properties, such as generalization error and adversarial robustness,\nare hard to control. Recent research demonstrated that singular values of\nconvolutional layers significantly affect such elusive properties and offered\nseveral methods for controlling them. Nevertheless, these methods present an\nintractable computational challenge or resort to coarse approximations. In this\npaper, we offer a principled approach to alleviating constraints of the prior\nart at the expense of an insignificant reduction in layer expressivity. Our\nmethod is based on the tensor-train decomposition; it retains control over the\nactual singular values of convolutional mappings while providing structurally\nsparse and hardware-friendly representation. We demonstrate the improved\nproperties of modern CNNs with our method and analyze its impact on the model\nperformance, calibration, and adversarial robustness. The source code is\navailable at: https://github.com/WhiteTeaDragon/practical_svd_conv",
    "descriptor": "\nComments: Published as a conference paper at NeurIPS 2022\n",
    "authors": [
      "Alexandra Senderovich",
      "Ekaterina Bulatova",
      "Anton Obukhov",
      "Maxim Rakhuba"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13771"
  },
  {
    "id": "arXiv:2211.13773",
    "title": "Impact of NOMA on Age of Information: A Grant-Free Transmission  Perspective",
    "abstract": "The aim of this paper is to characterize the impact of non-orthogonal\nmultiple access (NOMA) on the age of information (AoI) of grant-free\ntransmission. In particular, a low-complexity form of NOMA, termed\nNOMA-assisted random access, is applied to grant-free transmission in order to\nillustrate the two benefits of NOMA for AoI reduction, namely increasing\nchannel access and reducing user collisions. Closed-form analytical expressions\nfor the AoI achieved by NOMA assisted grant-free transmission are obtained, and\nasymptotic studies are carried out to demonstrate that the use of the simplest\nform of NOMA is already sufficient to reduce the AoI of orthogonal multiple\naccess (OMA) by more than 40%. In addition, the developed analytical\nexpressions are also shown to be useful for optimizing the users' transmission\nattempt probabilities, which are key parameters for grant-free transmission.",
    "descriptor": "",
    "authors": [
      "Z. Ding",
      "R. Schober",
      "H. V. Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.13773"
  },
  {
    "id": "arXiv:2211.13775",
    "title": "SAGA: Spectral Adversarial Geometric Attack on 3D Meshes",
    "abstract": "A triangular mesh is one of the most popular 3D data representations. As\nsuch, the deployment of deep neural networks for mesh processing is widely\nspread and is increasingly attracting more attention. However, neural networks\nare prone to adversarial attacks, where carefully crafted inputs impair the\nmodel's functionality. The need to explore these vulnerabilities is a\nfundamental factor in the future development of 3D-based applications.\nRecently, mesh attacks were studied on the semantic level, where classifiers\nare misled to produce wrong predictions. Nevertheless, mesh surfaces possess\ncomplex geometric attributes beyond their semantic meaning, and their analysis\noften includes the need to encode and reconstruct the geometry of the shape.\nWe propose a novel framework for a geometric adversarial attack on a 3D mesh\nautoencoder. In this setting, an adversarial input mesh deceives the\nautoencoder by forcing it to reconstruct a different geometric shape at its\noutput. The malicious input is produced by perturbing a clean shape in the\nspectral domain. Our method leverages the spectral decomposition of the mesh\nalong with additional mesh-related properties to obtain visually credible\nresults that consider the delicacy of surface distortions. Our code is publicly\navailable at https://github.com/StolikTomer/SAGA.",
    "descriptor": "",
    "authors": [
      "Tomer Stolik",
      "Itai Lang",
      "Shai Avidan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13775"
  },
  {
    "id": "arXiv:2211.13776",
    "title": "German Phoneme Recognition with Text-to-Phoneme Data Augmentation",
    "abstract": "In this study, we experimented to examine the effect of adding the most\nfrequent n phoneme bigrams to the basic vocabulary on the German phoneme\nrecognition model using the text-to-phoneme data augmentation strategy. As a\nresult, compared to the baseline model, the vowel30 model and the const20 model\nshowed an increased BLEU score of more than 1 point, and the total30 model\nshowed a significant decrease in the BLEU score of more than 20 points, showing\nthat the phoneme bigrams could have a positive or negative effect on the model\nperformance. In addition, we identified the types of errors that the models\nrepeatedly showed through error analysis.",
    "descriptor": "",
    "authors": [
      "Dojun Park",
      "Seohyun Park"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.13776"
  },
  {
    "id": "arXiv:2211.13778",
    "title": "Design and Prototyping Distributed CNN Inference Acceleration in Edge  Computing",
    "abstract": "For time-critical IoT applications using deep learning, inference\nacceleration through distributed computing is a promising approach to meet a\nstringent deadline. In this paper, we implement a working prototype of a new\ndistributed inference acceleration method HALP using three raspberry Pi 4. HALP\naccelerates inference by designing a seamless collaboration among edge devices\n(EDs) in Edge Computing. We maximize the parallelization between communication\nand computation among the collaborative EDs by optimizing the task partitioning\nratio based on the segment-based partitioning. Experimental results show that\nthe distributed inference HALP achieves 1.7x inference acceleration for VGG-16.\nThen, we combine distributed inference with conventional neural network model\ncompression by setting up different shrinking hyperparameters for MobileNet-V1.\nIn this way, we can further accelerate inference but at the cost of inference\naccuracy loss. To strike a balance between latency and accuracy, we propose\ndynamic model selection to select a model which provides the highest accuracy\nwithin the latency constraint. It is shown that the model selection with\ndistributed inference HALP can significantly improve service reliability\ncompared to the conventional stand-alone computation.",
    "descriptor": "\nComments: Accepted by European Wireless 2022\n",
    "authors": [
      "hongtian Dong",
      "Nan Li",
      "Alexandros Iosifidis",
      "Qi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.13778"
  },
  {
    "id": "arXiv:2211.13779",
    "title": "Learning to Play Trajectory Games Against Opponents with Unknown  Objectives",
    "abstract": "Many autonomous agents, such as intelligent vehicles, are inherently required\nto interact with one another. Game theory provides a natural mathematical tool\nfor robot motion planning in such interactive settings. However, tractable\nalgorithms for such problems usually rely on a strong assumption, namely that\nthe objectives of all players in the scene are known. To make such tools\napplicable for ego-centric planning with only local information, we propose an\nadaptive model-predictive game solver, which jointly infers other players'\nobjectives online and computes a corresponding generalized Nash equilibrium\n(GNE) strategy. The adaptivity of our approach is enabled by a differentiable\ntrajectory game solver whose gradient signal is used for maximum likelihood\nestimation (MLE) of opponents' objectives. This differentiability of our\npipeline facilitates direct integration with other differentiable elements,\nsuch as neural networks (NNs). Furthermore, in contrast to existing solvers for\ncost inference in games, our method handles not only partial state observations\nbut also general inequality constraints. In two simulated traffic scenarios, we\nfind superior performance of our approach over both existing game-theoretic\nmethods and non-game-theoretic model-predictive control (MPC) approaches. We\nalso demonstrate the real-time planning capabilities and robustness of our\napproach in a hardware experiment.",
    "descriptor": "",
    "authors": [
      "Xinjie Liu",
      "Lasse Peters",
      "Javier Alonso-Mora"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.13779"
  },
  {
    "id": "arXiv:2211.13780",
    "title": "CryptoLight: An Electro-Optical Accelerator for Fully Homomorphic  Encryption",
    "abstract": "Fully homomorphic encryption (FHE) protects data privacy in cloud computing\nby enabling computations to directly occur on ciphertexts. Although the speed\nof computationally expensive FHE operations can be significantly boosted by\nprior ASIC-based FHE accelerators, the performance of key-switching, the\ndominate primitive in various FHE operations, is seriously limited by their\nsmall bit-width datapaths and frequent matrix transpositions. In this paper, we\npresent an electro-optical (EO) FHE accelerator, CryptoLight, to accelerate FHE\noperations. Its 512-bit datapath supporting 510-bit residues greatly reduces\nthe key-switching cost. We also create an in-scratchpad-memory transpose unit\nto fast transpose matrices. Compared to prior FHE accelerators, on average,\nCryptoLight reduces the latency of various FHE applications by >94.4% and the\nenergy consumption by >95%.",
    "descriptor": "\nComments: 6 pages, 8 figures\n",
    "authors": [
      "Mengxin Zheng",
      "Qian Lou",
      "Fan Chen",
      "Lei Jiang",
      "Yongxin Zhu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.13780"
  },
  {
    "id": "arXiv:2211.13785",
    "title": "JigsawPlan: Room Layout Jigsaw Puzzle Extreme Structure from Motion  using Diffusion Models",
    "abstract": "This paper presents a novel approach to the Extreme Structure from Motion\n(E-SfM) problem, which takes a set of room layouts as polygonal curves in the\ntop-down view, and aligns the room layout pieces by estimating their 2D\ntranslations and rotations, akin to solving the jigsaw puzzle of room layouts.\nThe biggest discovery and surprise of the paper is that the simple use of a\nDiffusion Model solves this challenging registration problem as a conditional\ngeneration process. The paper presents a new dataset of room layouts and\nfloorplans for 98,780 houses. The qualitative and quantitative evaluations\ndemonstrate that the proposed approach outperforms the competing methods by\nsignificant margins.",
    "descriptor": "",
    "authors": [
      "Sepidehsadat Hosseini",
      "Mohammad Amin Shabani",
      "Saghar Irandoust",
      "Yasutaka Furukawa"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13785"
  },
  {
    "id": "arXiv:2211.13786",
    "title": "PyTAIL: Interactive and Incremental Learning of NLP Models with Human in  the Loop for Online Data",
    "abstract": "Online data streams make training machine learning models hard because of\ndistribution shift and new patterns emerging over time. For natural language\nprocessing (NLP) tasks that utilize a collection of features based on lexicons\nand rules, it is important to adapt these features to the changing data. To\naddress this challenge we introduce PyTAIL, a python library, which allows a\nhuman in the loop approach to actively train NLP models. PyTAIL enhances\ngeneric active learning, which only suggests new instances to label by also\nsuggesting new features like rules and lexicons to label. Furthermore, PyTAIL\nis flexible enough for users to accept, reject, or update rules and lexicons as\nthe model is being trained. Finally, we simulate the performance of PyTAIL on\nexisting social media benchmark datasets for text classification. We compare\nvarious active learning strategies on these benchmarks. The model closes the\ngap with as few as 10% of the training data. Finally, we also highlight the\nimportance of tracking evaluation metric on remaining data (which is not yet\nmerged with active learning) alongside the test dataset. This highlights the\neffectiveness of the model in accurately annotating the remaining dataset,\nwhich is especially suitable for batch processing of large unlabelled corpora.\nPyTAIL will be available at https://github.com/socialmediaie/pytail.",
    "descriptor": "\nComments: 9pages, 3 figures, 2 tables\n",
    "authors": [
      "Shubhanshu Mishra",
      "Jana Diesner"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13786"
  },
  {
    "id": "arXiv:2211.13787",
    "title": "Semantic Communication Enabling Robust Edge Intelligence for  Time-Critical IoT Applications",
    "abstract": "This paper aims to design robust Edge Intelligence using semantic\ncommunication for time-critical IoT applications. We systematically analyze the\neffect of image DCT coefficients on inference accuracy and propose the\nchannel-agnostic effectiveness encoding for offloading by transmitting the most\nmeaningful task data first. This scheme can well utilize all available\ncommunication resource and strike a balance between transmission latency and\ninference accuracy. Then, we design an effectiveness decoding by implementing a\nnovel image augmentation process for convolutional neural network (CNN)\ntraining, through which an original CNN model is transformed into a Robust CNN\nmodel. We use the proposed training method to generate Robust MobileNet-v2 and\nRobust ResNet-50. The proposed Edge Intelligence framework consists of the\nproposed effectiveness encoding and effectiveness decoding. The experimental\nresults show that the effectiveness decoding using the Robust CNN models\nperform consistently better under various image distortions caused by channel\nerrors or limited communication resource. The proposed Edge Intelligence\nframework using semantic communication significantly outperforms the\nconventional approach under latency and data rate constraints, in particular,\nunder ultra stringent deadlines and low data rate.",
    "descriptor": "",
    "authors": [
      "Andrea Cavagn",
      "Nan Li",
      "Alexandros Iosifidis",
      "Qi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.13787"
  },
  {
    "id": "arXiv:2211.13790",
    "title": "Approximating the chromatic polynomial is as hard as computing it  exactly",
    "abstract": "We show that for any non-real algebraic number $q$ such that $|q-1|>1$ or\n$\\Re(q)>\\frac{3}{2}$ it is \\textsc{\\#P}-hard to compute a multiplicative (resp.\nadditive) approximation to the absolute value (resp. argument) of the chromatic\npolynomial evaluated at $q$ on planar graphs. This implies\n\\textsc{\\#P}-hardness for all non-real algebraic $q$ on the family of all\ngraphs. We moreover prove several hardness results for $q$ such that $|q-1|\\leq\n1$.\nOur hardness results are obtained by showing that a polynomial time algorithm\nfor approximately computing the chromatic polynomial of a planar graph at\nnon-real algebraic $q$ (satisfying some properties) leads to a polynomial time\nalgorithm for \\emph{exactly} computing it, which is known to be hard by a\nresult of Vertigan. Many of our results extend in fact to the more general\npartition function of the random cluster model, a well known reparametrization\nof the Tutte polynomial.",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Ferenc Bencs",
      "Jeroen Huijben",
      "Guus Regts"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.13790"
  },
  {
    "id": "arXiv:2211.13794",
    "title": "Question Answering and Question Generation for Finnish",
    "abstract": "Recent advances in the field of language modeling have improved the\nstate-of-the-art in question answering (QA) and question generation (QG).\nHowever, the development of modern neural models, their benchmarks, and\ndatasets for training them has mainly focused on English. Finnish, like many\nother languages, faces a shortage of large QA/QG model training resources,\nwhich has prevented experimenting with state-of-the-art QA/QG fine-tuning\nmethods. We present the first neural QA and QG models that work with Finnish.\nTo train the models, we automatically translate the SQuAD dataset and then use\nnormalization methods to reduce the amount of problematic data created during\nthe translation. Using the synthetic data, together with the Finnish partition\nof the TyDi-QA dataset, we fine-tune several transformer-based models to both\nQA and QG and evaluate their performance. To the best of our knowledge, the\nresulting dataset is the first large-scale QA/QG resource for Finnish. This\npaper also sets the initial benchmarks for Finnish-language QA and QG.",
    "descriptor": "",
    "authors": [
      "Ilmari Kylli\u00e4inen",
      "Roman Yangarber"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.13794"
  },
  {
    "id": "arXiv:2211.13800",
    "title": "Estimation of a Causal Directed Acyclic Graph Process using  Non-Gaussianity",
    "abstract": "Numerous approaches have been proposed to discover causal dependencies in\nmachine learning and data mining; among them, the state-of-the-art VAR-LiNGAM\n(short for Vector Auto-Regressive Linear Non-Gaussian Acyclic Model) is a\ndesirable approach to reveal both the instantaneous and time-lagged\nrelationships. However, all the obtained VAR matrices need to be analyzed to\ninfer the final causal graph, leading to a rise in the number of parameters. To\naddress this issue, we propose the CGP-LiNGAM (short for Causal Graph\nProcess-LiNGAM), which has significantly fewer model parameters and deals with\nonly one causal graph for interpreting the causal relations by exploiting Graph\nSignal Processing (GSP).",
    "descriptor": "",
    "authors": [
      "Aref Einizade",
      "Sepideh Hajipour Sardouie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.13800"
  },
  {
    "id": "arXiv:2211.13801",
    "title": "Theoretical Study of Optimizing Rugged Landscapes with the cGA",
    "abstract": "Estimation of distribution algorithms (EDAs) provide a distribution - based\napproach for optimization which adapts its probability distribution during the\nrun of the algorithm. We contribute to the theoretical understanding of EDAs\nand point out that their distribution approach makes them more suitable to deal\nwith rugged fitness landscapes than classical local search algorithms.\nConcretely, we make the OneMax function rugged by adding noise to each fitness\nvalue. The cGA can nevertheless find solutions with n(1 - \\epsilon) many 1s,\neven for high variance of noise. In contrast to this, RLS and the (1+1) EA,\nwith high probability, only find solutions with n(1/2+o(1)) many 1s, even for\nnoise with small variance.",
    "descriptor": "\nComments: 17 pages, 1 figure, PPSN 2022\n",
    "authors": [
      "Tobias Friedrich",
      "Timo K\u00f6tzing",
      "Frank Neumann",
      "Aishwarya Radhakrishnan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.13801"
  },
  {
    "id": "arXiv:2211.13802",
    "title": "Sequential Gradient Coding For Straggler Mitigation",
    "abstract": "In distributed computing, slower nodes (stragglers) usually become a\nbottleneck. Gradient Coding (GC), introduced by Tandon et al., is an efficient\ntechnique that uses principles of error-correcting codes to distribute gradient\ncomputation in the presence of stragglers. In this paper, we consider the\ndistributed computation of a sequence of gradients $\\{g(1),g(2),\\ldots,g(J)\\}$,\nwhere processing of each gradient $g(t)$ starts in round-$t$ and finishes by\nround-$(t+T)$. Here $T\\geq 0$ denotes a delay parameter. For the GC scheme,\ncoding is only across computing nodes and this results in a solution where\n$T=0$. On the other hand, having $T>0$ allows for designing schemes which\nexploit the temporal dimension as well. In this work, we propose two schemes\nthat demonstrate improved performance compared to GC. Our first scheme combines\nGC with selective repetition of previously unfinished tasks and achieves\nimproved straggler mitigation. In our second scheme, which constitutes our main\ncontribution, we apply GC to a subset of the tasks and repetition for the\nremainder of the tasks. We then multiplex these two classes of tasks across\nworkers and rounds in an adaptive manner, based on past straggler patterns.\nUsing theoretical analysis, we demonstrate that our second scheme achieves\nsignificant reduction in the computational load. In our experiments, we study a\npractical setting of concurrently training multiple neural networks over an AWS\nLambda cluster involving 256 worker nodes, where our framework naturally\napplies. We demonstrate that the latter scheme can yield a 16\\% improvement in\nruntime over the baseline GC scheme, in the presence of naturally occurring,\nnon-simulated stragglers.",
    "descriptor": "",
    "authors": [
      "M. Nikhil Krishnan",
      "MohammadReza Ebrahimi",
      "Ashish Khisti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.13802"
  },
  {
    "id": "arXiv:2211.13804",
    "title": "On the Linguistic and Computational Requirements for Creating  Face-to-Face Multimodal Human-Machine Interaction",
    "abstract": "In this study, conversations between humans and avatars are linguistically,\norganizationally, and structurally analyzed, focusing on what is necessary for\ncreating face-to-face multimodal interfaces for machines. We videorecorded\nthirty-four human-avatar interactions, performed complete linguistic\nmicroanalysis on video excerpts, and marked all the occurrences of multimodal\nactions and events. Statistical inferences were applied to data, allowing us to\ncomprehend not only how often multimodal actions occur but also how multimodal\nevents are distributed between the speaker (emitter) and the listener\n(recipient). We also observed the distribution of multimodal occurrences for\neach modality. The data show evidence that double-loop feedback is established\nduring a face-to-face conversation. This led us to propose that knowledge from\nConversation Analysis (CA), cognitive science, and Theory of Mind (ToM), among\nothers, should be incorporated into the ones used for describing human-machine\nmultimodal interactions. Face-to-face interfaces require an additional control\nlayer to the multimodal fusion layer. This layer has to organize the flow of\nconversation, integrate the social context into the interaction, as well as\nmake plans concerning 'what' and 'how' to progress on the interaction. This\nhigher level is best understood if we incorporate insights from CA and ToM into\nthe interface system.",
    "descriptor": "",
    "authors": [
      "Jo\u00e3o Ranhel",
      "Cacilda Vilela de Lima"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.13804"
  },
  {
    "id": "arXiv:2211.13807",
    "title": "ReFace: Improving Clothes-Changing Re-Identification With Face Features",
    "abstract": "Person re-identification (ReID) has been an active research field for many\nyears. Despite that, models addressing this problem tend to perform poorly when\nthe task is to re-identify the same people over a prolonged time, due to\nappearance changes such as different clothes and hairstyles. In this work, we\nintroduce a new method that takes full advantage of the ability of existing\nReID models to extract appearance-related features and combines it with a face\nfeature extraction model to achieve new state-of-the-art results, both on\nimage-based and video-based benchmarks. Moreover, we show how our method could\nbe used for an application in which multiple people of interest, under\nclothes-changing settings, should be re-identified given an unseen video and a\nlimited amount of labeled data. We claim that current ReID benchmarks do not\nrepresent such real-world scenarios, and publish a new dataset, 42Street, based\non a theater play as an example of such an application. We show that our\nproposed method outperforms existing models also on this dataset while using\nonly pre-trained modules and without any further training.",
    "descriptor": "",
    "authors": [
      "Daniel Arkushin",
      "Bar Cohen",
      "Shmuel Peleg",
      "Ohad Fried"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13807"
  },
  {
    "id": "arXiv:2211.13808",
    "title": "Detecting Anomalies using Generative Adversarial Networks on Images",
    "abstract": "Automatic detection of anomalies such as weapons or threat objects in baggage\nsecurity, or detecting impaired items in industrial production is an important\ncomputer vision task demanding high efficiency and accuracy. Most of the\navailable data in the anomaly detection task is imbalanced as the number of\npositive/anomalous instances is sparse. Inadequate availability of the data\nmakes training of a deep neural network architecture for anomaly detection\nchallenging. This paper proposes a novel Generative Adversarial Network (GAN)\nbased model for anomaly detection. It uses normal (non-anomalous) images to\nlearn about the normality based on which it detects if an input image contains\nan anomalous/threat object. The proposed model uses a generator with an\nencoder-decoder network having dense convolutional skip connections for\nenhanced reconstruction and to capture the data distribution. A self-attention\naugmented discriminator is used having the ability to check the consistency of\ndetailed features even in distant portions. We use spectral normalisation to\nfacilitate stable and improved training of the GAN. Experiments are performed\non three datasets, viz. CIFAR-10, MVTec AD (for industrial applications) and\nSIXray (for X-ray baggage security). On the MVTec AD and SIXray datasets, our\nmodel achieves an improvement of upto 21% and 4.6%, respectively",
    "descriptor": "",
    "authors": [
      "Rushikesh Zawar",
      "Krupa Bhayani",
      "Neelanjan Bhowmik",
      "Kamlesh Tiwari",
      "Dhiraj Sangwan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.13808"
  },
  {
    "id": "arXiv:2211.13810",
    "title": "Enhanced Inversion of Schema Evolution with Provenance",
    "abstract": "Long-term data-driven studies have become indispensable in many areas of\nscience. Often, the data formats, structures and semantics of data change over\ntime, the data sets evolve. Therefore, studies over several decades in\nparticular have to consider changing database schemas. The evolution of these\ndatabases lead at some point to a large number of schemas, which have to be\nstored and managed, costly and time-consuming. However, in the sense of\nreproducibility of research data each database version must be reconstructable\nwith little effort. So a previously published result can be validated and\nreproduced at any time.\nNevertheless, in many cases, such an evolution can not be fully\nreconstructed. This article classifies the 15 most frequently used schema\nmodification operators and defines the associated inverses for each operation.\nFor avoiding an information loss, it furthermore defines which additional\nprovenance information have to be stored. We define four classes dealing with\ndangling tuples, duplicates and provenance-invariant operators. Each class will\nbe presented by one representative.\nBy using and extending the theory of schema mappings and their inverses for\nqueries, data analysis, why-provenance, and schema evolution, we are able to\ncombine data analysis applications with provenance under evolving database\nstructures, in order to enable the reproducibility of scientific results over\nlonger periods of time. While most of the inverses of schema mappings used for\nanalysis or evolution are not exact, but only quasi-inverses, adding provenance\ninformation enables us to reconstruct a sub-database of research data that is\nsufficient to guarantee reproducibility.",
    "descriptor": "",
    "authors": [
      "Tanja Auge",
      "Andreas Heuer"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.13810"
  },
  {
    "id": "arXiv:2211.13812",
    "title": "Multi-Template Temporal Siamese Network for Long-Term Object Tracking",
    "abstract": "Siamese Networks are one of most popular visual object tracking methods for\ntheir high speed and high accuracy tracking ability as long as the target is\nwell identified. However, most Siamese Network based trackers use the first\nframe as the ground truth of an object and fail when target appearance changes\nsignificantly in next frames. They also have dif iculty distinguishing the\ntarget from similar other objects in the frame. We propose two ideas to solve\nboth problems. The first idea is using a bag of dynamic templates, containing\ndiverse, similar, and recent target features and continuously updating it with\ndiverse target appearances. The other idea is to let a network learn the path\nhistory and project a potential future target location in a next frame. This\ntracker achieves state-of-the-art performance on the long-term tracking dataset\nUAV20L by improving the success rate by a large margin of 15% (65.4 vs 56.6)\ncompared to the state-of-the-art method, HiFT. The of icial python code of this\npaper is publicly available.",
    "descriptor": "",
    "authors": [
      "Ali Sekhavati",
      "Won-Sook Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13812"
  },
  {
    "id": "arXiv:2211.13813",
    "title": "Multi-label Few-shot ICD Coding as Autoregressive Generation with Prompt",
    "abstract": "Automatic International Classification of Diseases (ICD) coding aims to\nassign multiple ICD codes to a medical note with an average of 3,000+ tokens.\nThis task is challenging due to the high-dimensional space of multi-label\nassignment (155,000+ ICD code candidates) and the long-tail challenge - Many\nICD codes are infrequently assigned yet infrequent ICD codes are important\nclinically. This study addresses the long-tail challenge by transforming this\nmulti-label classification task into an autoregressive generation task.\nSpecifically, we first introduce a novel pretraining objective to generate free\ntext diagnoses and procedure using the SOAP structure, the medical logic\nphysicians use for note documentation. Second, instead of directly predicting\nthe high dimensional space of ICD codes, our model generates the lower\ndimension of text descriptions, which then infer ICD codes. Third, we designed\na novel prompt template for multi-label classification. We evaluate our\nGeneration with Prompt model with the benchmark of all code assignment\n(MIMIC-III-full) and few shot ICD code assignment evaluation benchmark\n(MIMIC-III-few). Experiments on MIMIC-III-few show that our model performs with\na marco F1 30.2, which substantially outperforms the previous MIMIC-III-full\nSOTA model (marco F1 4.3) and the model specifically designed for few/zero shot\nsetting (marco F1 18.7). Finally, we design a novel ensemble learner, a cross\nattention reranker with prompts, to integrate previous SOTA and our best\nfew-shot coding predictions. Experiments on MIMIC-III-full show that our\nensemble learner substantially improves both macro and micro F1, from 10.4 to\n14.6 and from 58.2 to 59.1, respectively.",
    "descriptor": "\nComments: To be appear in AAAI2023\n",
    "authors": [
      "Zhichao Yang",
      "Sunjae Kwon",
      "Zonghai Yao",
      "Hong Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13813"
  },
  {
    "id": "arXiv:2211.13815",
    "title": "Using Selective Masking as a Bridge between Pre-training and Fine-tuning",
    "abstract": "Pre-training a language model and then fine-tuning it for downstream tasks\nhas demonstrated state-of-the-art results for various NLP tasks. Pre-training\nis usually independent of the downstream task, and previous works have shown\nthat this pre-training alone might not be sufficient to capture the\ntask-specific nuances. We propose a way to tailor a pre-trained BERT model for\nthe downstream task via task-specific masking before the standard supervised\nfine-tuning. For this, a word list is first collected specific to the task. For\nexample, if the task is sentiment classification, we collect a small sample of\nwords representing both positive and negative sentiments. Next, a word's\nimportance for the task, called the word's task score, is measured using the\nword list. Each word is then assigned a probability of masking based on its\ntask score. We experiment with different masking functions that assign the\nprobability of masking based on the word's task score. The BERT model is\nfurther trained on MLM objective, where masking is done using the above\nstrategy. Following this standard supervised fine-tuning is done for different\ndownstream tasks. Results on these tasks show that the selective masking\nstrategy outperforms random masking, indicating its effectiveness.",
    "descriptor": "\nComments: ENLSP Workshop, NeurIPS 2022\n",
    "authors": [
      "Tanish Lad",
      "Himanshu Maheshwari",
      "Shreyas Kottukkal",
      "Radhika Mamidi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.13815"
  },
  {
    "id": "arXiv:2211.13817",
    "title": "Psychometric Instruments in Software Engineering Research on  Personality: Status Quo After Fifty Years",
    "abstract": "Context: Although software development is a human activity, Software\nEngineering (SE) research has focused mostly on processes and tools, making\nhuman factors underrepresented. This kind of research may be improved using\nknowledge from human-focused disciplines. An example of missed opportunities is\nhow SE employs psychometric instruments. Objective: Provide an overview of\npsychometric instruments in SE research regarding personality and provide\nrecommendations on when adopting them. Method: We conducted a systematic\nmapping to build a catalog of instruments used within SE for assessing\npersonality and reviewed their use from a multidisciplinary perspective of SE\nand social science. Results: We contribute with an update of a secondary study\ncovering fifty years of research (1970 to 2020). We observed remaining\ndiscrepancies between one of the most adopted instruments (MBTI) and existing\nrecommendations in the literature. We also emphasize that several instruments\nrefer to the Five-Factor Model, and specific advice on how to apply this model\nwithin the SE domain is still missing. Conclusion: The findings show that the\nadoption of psychometric instruments regarding personality in SE needs to be\nimproved, ideally with the support of social sciences researchers. We believe\nthat the review presented in this study can help to understand limitations and\nevolve in this direction.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2108.11988\n",
    "authors": [
      "Danilo Almeida Felipe",
      "Marcos Kalinowski",
      "Daniel Graziotin",
      "Jean Carlos Natividade"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.13817"
  },
  {
    "id": "arXiv:2211.13818",
    "title": "Digital Twin-Driven Computing Resource Management for Vehicular Networks",
    "abstract": "This paper presents a novel approach for computing resource management of\nedge servers in vehicular networks based on digital twins and artificial\nintelligence (AI). Specifically, we construct two-tier digital twins tailored\nfor vehicular networks to capture networking-related features of vehicles and\nedge servers. By exploiting such features, we propose a two-stage computing\nresource allocation scheme. First, the central controller periodically\ngenerates reference policies for real-time computing resource allocation\naccording to the network dynamics and service demands captured by digital twins\nof edge servers. Second, computing resources of the edge servers are allocated\nin real time to individual vehicles via low-complexity matching-based\nallocation that complies with the reference policies. By leveraging digital\ntwins, the proposed scheme can adapt to dynamic service demands and vehicle\nmobility in a scalable manner. Simulation results demonstrate that the proposed\ndigital twin-driven scheme enables the vehicular network to support more\ncomputing tasks than benchmark schemes.",
    "descriptor": "\nComments: 6 pages, 4 figures, accepted by 2022 IEEE GLOBECOM\n",
    "authors": [
      "Mushu Li",
      "Jie Gao",
      "Conghao Zhou",
      "Xuemin",
      "Shen",
      "Weihua Zhuang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.13818"
  },
  {
    "id": "arXiv:2211.13819",
    "title": "Detecting Entities in the Astrophysics Literature: A Comparison of  Word-based and Span-based Entity Recognition Methods",
    "abstract": "Information Extraction from scientific literature can be challenging due to\nthe highly specialised nature of such text. We describe our entity recognition\nmethods developed as part of the DEAL (Detecting Entities in the Astrophysics\nLiterature) shared task. The aim of the task is to build a system that can\nidentify Named Entities in a dataset composed by scholarly articles from\nastrophysics literature. We planned our participation such that it enables us\nto conduct an empirical comparison between word-based tagging and span-based\nclassification methods. When evaluated on two hidden test sets provided by the\norganizer, our best-performing submission achieved $F_1$ scores of 0.8307\n(validation phase) and 0.7990 (testing phase).",
    "descriptor": "\nComments: AACL-IJCNLP Workshop on Information Extraction from Scientific Publications (WIESP 2022)\n",
    "authors": [
      "Xiang Dai",
      "Sarvnaz Karimi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.13819"
  },
  {
    "id": "arXiv:2211.13823",
    "title": "Neural Weight Search for Scalable Task Incremental Learning",
    "abstract": "Task incremental learning aims to enable a system to maintain its performance\non previously learned tasks while learning new tasks, solving the problem of\ncatastrophic forgetting. One promising approach is to build an individual\nnetwork or sub-network for future tasks. However, this leads to an ever-growing\nmemory due to saving extra weights for new tasks and how to address this issue\nhas remained an open problem in task incremental learning. In this paper, we\nintroduce a novel Neural Weight Search technique that designs a fixed search\nspace where the optimal combinations of frozen weights can be searched to build\nnew models for novel tasks in an end-to-end manner, resulting in scalable and\ncontrollable memory growth. Extensive experiments on two benchmarks, i.e.,\nSplit-CIFAR-100 and CUB-to-Sketches, show our method achieves state-of-the-art\nperformance with respect to both average inference accuracy and total memory\ncost.",
    "descriptor": "",
    "authors": [
      "Jian Jiang",
      "Oya Celiktutan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13823"
  },
  {
    "id": "arXiv:2211.13827",
    "title": "Lessons Learned to Improve the UX Practices in Agile Projects Involving  Data Science and Process Automation",
    "abstract": "Context: User-Centered Design and Agile methodologies focus on human issues.\nNevertheless, agile methodologies focus on contact with contracting customers\nand generating value for them. Usually, the communication between end users and\nthe agile team is mediated by customers. However, they do not know the problems\nend users face in their routines. Hence, UX issues are typically identified\nonly after the implementation, during user testing and validation. Objective:\nAiming to improve the understanding and definition of the problem in agile\nprojects, this research investigates the practices and difficulties experienced\nby agile teams during the development of data science and process automation\nprojects. Also, we analyze the benefits and the teams' perceptions regarding\nuser participation in these projects. Method: We collected data from four agile\nteams in an academia-industry collaboration focusing on delivering data science\nand process automation solutions. Therefore, we applied a carefully designed\nquestionnaire answered by developers, scrum masters, and UX designers. In\ntotal, 18 subjects answered the questionnaire. Results: From the results, we\nidentify practices used by the teams to define and understand the problem and\nto represent the solution. The practices most often used are prototypes and\nmeetings with stakeholders. Another practice that helped the team to understand\nthe problem was using Lean Inceptions. Also, our results present some specific\nissues regarding data science projects. Conclusion: We observed that end-user\nparticipation can be critical to understanding and defining the problem. They\nhelp to define elements of the domain and barriers in the implementation. We\nidentified a need for approaches that facilitate user-team communication in\ndata science projects and the need for more detailed requirements\nrepresentations to support data science solutions.",
    "descriptor": "",
    "authors": [
      "Bruna Ferreira",
      "Silvio Marques",
      "Marcos Kalinowski",
      "Helio Lopes",
      "Simone D. J. Barbosa"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.13827"
  },
  {
    "id": "arXiv:2211.13828",
    "title": "Joint segmentation and discontinuity-preserving deformable registration:  Application to cardiac cine-MR images",
    "abstract": "Medical image registration is a challenging task involving the estimation of\nspatial transformations to establish anatomical correspondence between pairs or\ngroups of images. Recently, deep learning-based image registration methods have\nbeen widely explored, and demonstrated to enable fast and accurate image\nregistration in a variety of applications. However, most deep learning-based\nregistration methods assume that the deformation fields are smooth and\ncontinuous everywhere in the image domain, which is not always true, especially\nwhen registering images whose fields of view contain discontinuities at\ntissue/organ boundaries. In such scenarios, enforcing smooth, globally\ncontinuous deformation fields leads to incorrect/implausible registration\nresults. We propose a novel discontinuity-preserving image registration method\nto tackle this challenge, which ensures globally discontinuous and locally\nsmooth deformation fields, leading to more accurate and realistic registration\nresults. The proposed method leverages the complementary nature of image\nsegmentation and registration and enables joint segmentation and pair-wise\nregistration of images. A co-attention block is proposed in the segmentation\ncomponent of the network to learn the structural correlations in the input\nimages, while a discontinuity-preserving registration strategy is employed in\nthe registration component of the network to ensure plausibility in the\nestimated deformation fields at tissue/organ interfaces. We evaluate our method\non the task of intra-subject spatio-temporal image registration using\nlarge-scale cinematic cardiac magnetic resonance image sequences, and\ndemonstrate that our method achieves significant improvements over the\nstate-of-the-art for medical image registration, and produces high-quality\nsegmentation masks for the regions of interest.",
    "descriptor": "",
    "authors": [
      "Xiang Chen",
      "Yan Xia",
      "Nishant Ravikumar",
      "Alejandro F Frangi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13828"
  },
  {
    "id": "arXiv:2211.13829",
    "title": "Learning-enhanced Nonlinear Model Predictive Control using  Knowledge-based Neural Ordinary Differential Equations and Deep Ensembles",
    "abstract": "Nonlinear model predictive control (MPC) is a flexible and increasingly\npopular framework used to synthesize feedback control strategies that can\nsatisfy both state and control input constraints. In this framework, an\noptimization problem, subjected to a set of dynamics constraints characterized\nby a nonlinear dynamics model, is solved at each time step. Despite its\nversatility, the performance of nonlinear MPC often depends on the accuracy of\nthe dynamics model. In this work, we leverage deep learning tools, namely\nknowledge-based neural ordinary differential equations (KNODE) and deep\nensembles, to improve the prediction accuracy of this model. In particular, we\nlearn an ensemble of KNODE models, which we refer to as the KNODE ensemble, to\nobtain an accurate prediction of the true system dynamics. This learned model\nis then integrated into a novel learning-enhanced nonlinear MPC framework. We\nprovide sufficient conditions that guarantees asymptotic stability of the\nclosed-loop system and show that these conditions can be implemented in\npractice. We show that the KNODE ensemble provides more accurate predictions\nand illustrate the efficacy and closed-loop performance of the proposed\nnonlinear MPC framework using two case studies.",
    "descriptor": "\nComments: 16 pages, 2 figures, includes Appendix\n",
    "authors": [
      "Kong Yao Chee",
      "M. Ani Hsieh",
      "Nikolai Matni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.13829"
  },
  {
    "id": "arXiv:2211.13837",
    "title": "End-to-End Stochastic Optimization with Energy-Based Model",
    "abstract": "Decision-focused learning (DFL) was recently proposed for stochastic\noptimization problems that involve unknown parameters. By integrating\npredictive modeling with an implicitly differentiable optimization layer, DFL\nhas shown superior performance to the standard two-stage predict-then-optimize\npipeline. However, most existing DFL methods are only applicable to convex\nproblems or a subset of nonconvex problems that can be easily relaxed to convex\nones. Further, they can be inefficient in training due to the requirement of\nsolving and differentiating through the optimization problem in every training\niteration. We propose SO-EBM, a general and efficient DFL method for stochastic\noptimization using energy-based models. Instead of relying on KKT conditions to\ninduce an implicit optimization layer, SO-EBM explicitly parameterizes the\noriginal optimization problem using a differentiable optimization layer based\non energy functions. To better approximate the optimization landscape, we\npropose a coupled training objective that uses a maximum likelihood loss to\ncapture the optimum location and a distribution-based regularizer to capture\nthe overall energy landscape. Finally, we propose an efficient training\nprocedure for SO-EBM with a self-normalized importance sampler based on a\nGaussian mixture proposal. We evaluate SO-EBM in three applications: power\nscheduling, COVID-19 resource allocation, and non-convex adversarial security\ngame, demonstrating the effectiveness and efficiency of SO-EBM.",
    "descriptor": "\nComments: NeurIPS 2022 Oral\n",
    "authors": [
      "Lingkai Kong",
      "Jiaming Cui",
      "Yuchen Zhuang",
      "Rui Feng",
      "B. Aditya Prakash",
      "Chao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.13837"
  },
  {
    "id": "arXiv:2211.13838",
    "title": "Signed Binary Weight Networks: Improving Efficiency of Binary Weight  Networks by Exploiting Sparsity",
    "abstract": "Efficient inference of Deep Neural Networks (DNNs) is essential to making AI\nubiquitous. Two important algorithmic techniques have shown promise for\nenabling efficient inference - sparsity and binarization. These techniques\ntranslate into weight sparsity and weight repetition at the hardware-software\nlevel allowing the deployment of DNNs with critically low power and latency\nrequirements. We propose a new method called signed-binary networks to improve\nfurther efficiency (by exploiting both weight sparsity and weight repetition)\nwhile maintaining similar accuracy. Our method achieves comparable accuracy on\nImageNet and CIFAR10 datasets with binary and can lead to $>69\\%$ sparsity. We\nobserve real speedup when deploying these models on general-purpose devices. We\nshow that this high percentage of unstructured sparsity can lead to a further\n~2x reduction in energy consumption on ASICs with respect to binary.",
    "descriptor": "",
    "authors": [
      "Sachit Kuhar",
      "Alexey Tumanov",
      "Judy Hoffman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2211.13838"
  },
  {
    "id": "arXiv:2211.13843",
    "title": "Automated design of pneumatic soft grippers through design-dependent  multi-material topology optimization",
    "abstract": "In recent years, soft robotic grasping has rapidly spread through the\nacademic robotics community and pushed into industrial applications. At the\nsame time, multimaterial 3D printing has become widely available, enabling\nmonolithic manufacture of devices containing rigid and elastic section. We\npropose a novel design technique which leverages both of these technologies and\nis able to automatically design bespoke soft robotic grippers for fruit-picking\nand similar applications. We demonstrate the novel topology optimisation\nformulation which generates multi-material soft gippers and is able to solve\nboth the internal and external pressure boundaries, and investigate methods to\nproduce air-tight designs. Compared to existing methods, it vastly expands the\nsearchable design space whilst increasing simulation accuracy.",
    "descriptor": "",
    "authors": [
      "Josh Pinskier",
      "Prabhat Kumar",
      "David Howard",
      "Matthijs Langelaar"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.13843"
  },
  {
    "id": "arXiv:2211.13844",
    "title": "Ladder Siamese Network: a Method and Insights for Multi-level  Self-Supervised Learning",
    "abstract": "Siamese-network-based self-supervised learning (SSL) suffers from slow\nconvergence and instability in training. To alleviate this, we propose a\nframework to exploit intermediate self-supervisions in each stage of deep nets,\ncalled the Ladder Siamese Network. Our self-supervised losses encourage the\nintermediate layers to be consistent with different data augmentations to\nsingle samples, which facilitates training progress and enhances the\ndiscriminative ability of the intermediate layers themselves. While some\nexisting work has already utilized multi-level self supervisions in SSL, ours\nis different in that 1) we reveal its usefulness with non-contrastive Siamese\nframeworks in both theoretical and empirical viewpoints, and 2) ours improves\nimage-level classification, instance-level detection, and pixel-level\nsegmentation simultaneously. Experiments show that the proposed framework can\nimprove BYOL baselines by 1.0% points in ImageNet linear classification, 1.2%\npoints in COCO detection, and 3.1% points in PASCAL VOC segmentation. In\ncomparison with the state-of-the-art methods, our Ladder-based model achieves\ncompetitive and balanced performances in all tested benchmarks without causing\nlarge degradation in one.",
    "descriptor": "",
    "authors": [
      "Ryota Yoshihashi",
      "Shuhei Nishimura",
      "Dai Yonebayashi",
      "Yuya Otsuka",
      "Tomohiro Tanaka",
      "Takashi Miyazaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13844"
  },
  {
    "id": "arXiv:2211.13846",
    "title": "Asynchronous Event-Triggered Control for Non-Linear Systems",
    "abstract": "With the increasing ubiquity of networked control systems, various strategies\nfor sampling constituent subsystems' outputs have emerged. In contrast with\nperiodic sampling, event-triggered control provides a way to efficiently sample\na subsystem and conserve network resource usage, by triggering an update only\nwhen a state-dependent error threshold is satisfied. Herein we describe a\nscheme for asynchronous event-triggered control (ETC) of a nonlinear plant\nusing sampler subsystems with hybrid dynamics. By exploiting inherent\ndifferences in the plant and controllers time scales, the proposed scheme\npermits independent sampling of plant and controller states. We extend existing\nETC literature by adopting a more general representation of the sampler\nsubsystem dynamics, thus accommodating different sampling schemes for both\nsynchronous and asynchronous ETC applications. We present a numerical example\nin order to illustrate important operational considerations for the proposed\nscheme.",
    "descriptor": "",
    "authors": [
      "Daniel A. Williams",
      "Airlie Chapman",
      "Chris Manzie"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.13846"
  },
  {
    "id": "arXiv:2211.13847",
    "title": "Zero-Sum Stochastic Stackelberg Games",
    "abstract": "Zero-sum stochastic games have found important applications in a variety of\nfields, from machine learning to economics. Work on this model has primarily\nfocused on the computation of Nash equilibrium due to its effectiveness in\nsolving adversarial board and video games. Unfortunately, a Nash equilibrium is\nnot guaranteed to exist in zero-sum stochastic games when the payoffs at each\nstate are not convex-concave in the players' actions. A Stackelberg\nequilibrium, however, is guaranteed to exist. Consequently, in this paper, we\nstudy zero-sum stochastic Stackelberg games. Going beyond known existence\nresults for (non-stationary) Stackelberg equilibria, we prove the existence of\nrecursive (i.e., Markov perfect) Stackelberg equilibria (recSE) in these games,\nprovide necessary and sufficient conditions for a policy profile to be a recSE,\nand show that recSE can be computed in (weakly) polynomial time via value\niteration. Finally, we show that zero-sum stochastic Stackelberg games can\nmodel the problem of pricing and allocating goods across agents and time. More\nspecifically, we propose a zero-sum stochastic Stackelberg game whose recSE\ncorrespond to the recursive competitive equilibria of a large class of\nstochastic Fisher markets. We close with a series of experiments that showcase\nhow our methodology can be used to solve the consumption-savings problem in\nstochastic Fisher markets.",
    "descriptor": "\nComments: 29 pages 2 figures, Appeared in NeurIPS'22\n",
    "authors": [
      "Denizalp Goktas",
      "Jiayi Zhao",
      "Amy Greenwald"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2211.13847"
  },
  {
    "id": "arXiv:2211.13852",
    "title": "Adaptive Attention Link-based Regularization for Vision Transformers",
    "abstract": "Although transformer networks are recently employed in various vision tasks\nwith outperforming performance, extensive training data and a lengthy training\ntime are required to train a model to disregard an inductive bias. Using\ntrainable links between the channel-wise spatial attention of a pre-trained\nConvolutional Neural Network (CNN) and the attention head of Vision\nTransformers (ViT), we present a regularization technique to improve the\ntraining efficiency of ViT. The trainable links are referred to as the\nattention augmentation module, which is trained simultaneously with ViT,\nboosting the training of ViT and allowing it to avoid the overfitting issue\ncaused by a lack of data. From the trained attention augmentation module, we\ncan extract the relevant relationship between each CNN activation map and each\nViT attention head, and based on this, we also propose an advanced attention\naugmentation module. Consequently, even with a small amount of data, the\nsuggested method considerably improves the performance of ViT while achieving\nfaster convergence during training.",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Heegon Jin",
      "Jongwon Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13852"
  },
  {
    "id": "arXiv:2211.13853",
    "title": "Extreme Acceleration of Graph Neural Network-based Prediction Models for  Quantum Chemistry",
    "abstract": "Molecular property calculations are the bedrock of chemical physics.\nHigh-fidelity \\textit{ab initio} modeling techniques for computing the\nmolecular properties can be prohibitively expensive, and motivate the\ndevelopment of machine-learning models that make the same predictions more\nefficiently. Training graph neural networks over large molecular databases\nintroduces unique computational challenges such as the need to process millions\nof small graphs with variable size and support communication patterns that are\ndistinct from learning over large graphs such as social networks. This paper\ndemonstrates a novel hardware-software co-design approach to scale up the\ntraining of graph neural networks for molecular property prediction. We\nintroduce an algorithm to coalesce the batches of molecular graphs into fixed\nsize packs to eliminate redundant computation and memory associated with\nalternative padding techniques and improve throughput via minimizing\ncommunication. We demonstrate the effectiveness of our co-design approach by\nproviding an implementation of a well-established molecular property prediction\nmodel on the Graphcore Intelligence Processing Units (IPU). We evaluate the\ntraining performance on multiple molecular graph databases with varying degrees\nof graph counts, sizes and sparsity. We demonstrate that such a co-design\napproach can reduce the training time of such molecular property prediction\nmodels from days to less than two hours, opening new possibilities for\nAI-driven scientific discovery.",
    "descriptor": "",
    "authors": [
      "Hatem Helal",
      "Jesun Firoz",
      "Jenna Bilbrey",
      "Mario Michael Krell",
      "Tom Murray",
      "Ang Li",
      "Sotiris Xantheas",
      "Sutanay Choudhury"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.13853"
  },
  {
    "id": "arXiv:2211.13854",
    "title": "ComCLIP: Training-Free Compositional Image and Text Matching",
    "abstract": "Contrastive Language-Image Pretraining (CLIP) has demonstrated great\nzero-shot performance for image-text matching because of its holistic use of\nnatural language supervision that covers large-scale, open-world visual\nconcepts. However, it is still challenging to adapt CLIP to compositional image\nand text matching -- a more challenging image and matching mask requiring the\nmodel understanding of compositional word concepts and visual components.\nTowards better compositional generalization in zero-shot image and text\nmatching, in this paper, we study the problem from a causal perspective: the\nerroneous semantics of individual entities are essentially confounders that\ncause the matching failure. Therefore, we propose a novel training-free\ncompositional CLIP model (ComCLIP). ComCLIP disentangles input images into\nsubjects, objects, and action sub-images and composes CLIP's vision encoder and\ntext encoder to perform evolving matching over compositional text embedding and\nsub-image embeddings. In this way, ComCLIP can mitigate spurious correlations\nintroduced by the pretrained CLIP models and dynamically assess the\ncontribution of each entity when performing image and text matching.\nExperiments on compositional image-text matching on SVO and ComVG and general\nimage-text retrieval on Flickr8K demonstrate the effectiveness of our\nplug-and-play method, which boosts the zero-shot inference ability of CLIP even\nwithout further training or fine-tuning of CLIP.",
    "descriptor": "",
    "authors": [
      "Kenan Jiang",
      "Xuehai He",
      "Ruize Xu",
      "Xin Eric Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.13854"
  },
  {
    "id": "arXiv:2211.13856",
    "title": "WSSL: Weighted Self-supervised Learning Framework For Image-inpainting",
    "abstract": "Image inpainting is the process of regenerating lost parts of the image.\nSupervised algorithm-based methods have shown excellent results but have two\nsignificant drawbacks. They do not perform well when tested with unseen data.\nThey fail to capture the global context of the image, resulting in a visually\nunappealing result. We propose a novel self-supervised learning framework for\nimage-inpainting: Weighted Self-Supervised Learning (WSSL) to tackle these\nproblems. We designed WSSL to learn features from multiple weighted pretext\ntasks. These features are then utilized for the downstream task,\nimage-inpainting. To improve the performance of our framework and produce more\nvisually appealing images, we also present a novel loss function for image\ninpainting. The loss function takes advantage of both reconstruction loss and\nperceptual loss functions to regenerate the image. Our experimentation shows\nWSSL outperforms previous methods, and our loss function helps produce better\nresults.",
    "descriptor": "\nComments: 9 Pages, document submitted for publication at CGVCVIP 2022\n",
    "authors": [
      "Shubham Gupta",
      "Rahul Kunigal Ravishankar",
      "Madhoolika Gangaraju",
      "Poojasree Dwarkanath",
      "Natarajan Subramanyam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13856"
  },
  {
    "id": "arXiv:2211.13857",
    "title": "Generative Modeling in Structural-Hankel Domain for Color Image  Inpainting",
    "abstract": "In recent years, some researchers focused on using a single image to obtain a\nlarge number of samples through multi-scale features. This study intends to a\nbrand-new idea that requires only ten or even fewer samples to construct the\nlow-rank structural-Hankel matrices-assisted score-based generative model\n(SHGM) for color image inpainting task. During the prior learning process, a\ncertain amount of internal-middle patches are firstly extracted from several\nimages and then the structural-Hankel matrices are constructed from these\npatches. To better apply the score-based generative model to learn the internal\nstatistical distribution within patches, the large-scale Hankel matrices are\nfinally folded into the higher dimensional tensors for prior learning. During\nthe iterative inpainting process, SHGM views the inpainting problem as a\nconditional generation procedure in low-rank environment. As a result, the\nintermediate restored image is acquired by alternatively performing the\nstochastic differential equation solver, alternating direction method of\nmultipliers, and data consistency steps. Experimental results demonstrated the\nremarkable performance and diversity of SHGM.",
    "descriptor": "\nComments: 11 pages, 10 figures\n",
    "authors": [
      "Zihao Li",
      "Chunhua Wu",
      "Shenglin Wu",
      "Wenbo Wan",
      "Yuhao Wang",
      "Qiegen Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13857"
  },
  {
    "id": "arXiv:2211.13858",
    "title": "Far3Det: Towards Far-Field 3D Detection",
    "abstract": "We focus on the task of far-field 3D detection (Far3Det) of objects beyond a\ncertain distance from an observer, e.g., $>$50m. Far3Det is particularly\nimportant for autonomous vehicles (AVs) operating at highway speeds, which\nrequire detections of far-field obstacles to ensure sufficient braking\ndistances. However, contemporary AV benchmarks such as nuScenes underemphasize\nthis problem because they evaluate performance only up to a certain distance\n(50m). One reason is that obtaining far-field 3D annotations is difficult,\nparticularly for lidar sensors that produce very few point returns for far-away\nobjects. Indeed, we find that almost 50% of far-field objects (beyond 50m)\ncontain zero lidar points. Secondly, current metrics for 3D detection employ a\n\"one-size-fits-all\" philosophy, using the same tolerance thresholds for near\nand far objects, inconsistent with tolerances for both human vision and stereo\ndisparities. Both factors lead to an incomplete analysis of the Far3Det task.\nFor example, while conventional wisdom tells us that high-resolution RGB\nsensors should be vital for 3D detection of far-away objects, lidar-based\nmethods still rank higher compared to RGB counterparts on the current benchmark\nleaderboards. As a first step towards a Far3Det benchmark, we develop a method\nto find well-annotated scenes from the nuScenes dataset and derive a\nwell-annotated far-field validation set. We also propose a Far3Det evaluation\nprotocol and explore various 3D detection methods for Far3Det. Our result\nconvincingly justifies the long-held conventional wisdom that high-resolution\nRGB improves 3D detection in the far-field. We further propose a simple yet\neffective method that fuses detections from RGB and lidar detectors based on\nnon-maximum suppression, which remarkably outperforms state-of-the-art 3D\ndetectors in the far-field.",
    "descriptor": "\nComments: WACV 2023 12 Pages, 8 Figures, 10 Tables\n",
    "authors": [
      "Shubham Gupta",
      "Jeet Kanjani",
      "Mengtian Li",
      "Francesco Ferroni",
      "James Hays",
      "Deva Ramanan",
      "Shu Kong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.13858"
  },
  {
    "id": "arXiv:2211.13859",
    "title": "DATE: Dual Assignment for End-to-End Fully Convolutional Object  Detection",
    "abstract": "Fully convolutional detectors discard the one-to-many assignment and adopt a\none-to-one assigning strategy to achieve end-to-end detection but suffer from\nthe slow convergence issue. In this paper, we revisit these two assignment\nmethods and find that bringing one-to-many assignment back to end-to-end fully\nconvolutional detectors helps with model convergence. Based on this\nobservation, we propose {\\em \\textbf{D}ual \\textbf{A}ssignment} for end-to-end\nfully convolutional de\\textbf{TE}ction (DATE). Our method constructs two\nbranches with one-to-many and one-to-one assignment during training and speeds\nup the convergence of the one-to-one assignment branch by providing more\nsupervision signals. DATE only uses the branch with the one-to-one matching\nstrategy for model inference, which doesn't bring inference overhead.\nExperimental results show that Dual Assignment gives nontrivial improvements\nand speeds up model convergence upon OneNet and DeFCN. Code:\nhttps://github.com/YiqunChen1999/date.",
    "descriptor": "",
    "authors": [
      "Yiqun Chen",
      "Qiang Chen",
      "Qinghao Hu",
      "Jian Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13859"
  },
  {
    "id": "arXiv:2211.13860",
    "title": "Fast and Efficient Malware Detection with Joint Static and Dynamic  Features Through Transfer Learning",
    "abstract": "In malware detection, dynamic analysis extracts the runtime behavior of\nmalware samples in a controlled environment and static analysis extracts\nfeatures using reverse engineering tools. While the former faces the challenges\nof anti-virtualization and evasive behavior of malware samples, the latter\nfaces the challenges of code obfuscation. To tackle these drawbacks, prior\nworks proposed to develop detection models by aggregating dynamic and static\nfeatures, thus leveraging the advantages of both approaches. However, simply\nconcatenating dynamic and static features raises an issue of imbalanced\ncontribution due to the heterogeneous dimensions of feature vectors to the\nperformance of malware detection models. Yet, dynamic analysis is a\ntime-consuming task and requires a secure environment, leading to detection\ndelays and high costs for maintaining the analysis infrastructure. In this\npaper, we first introduce a method of constructing aggregated features via\nconcatenating latent features learned through deep learning with\nequally-contributed dimensions. We then develop a knowledge distillation\ntechnique to transfer knowledge learned from aggregated features by a teacher\nmodel to a student model trained only on static features and use the trained\nstudent model for the detection of new malware samples. We carry out extensive\nexperiments with a dataset of 86709 samples including both benign and malware\nsamples. The experimental results show that the teacher model trained on\naggregated features constructed by our method outperforms the state-of-the-art\nmodels with an improvement of up to 2.38% in detection accuracy. The distilled\nstudent model not only achieves high performance (97.81% in terms of accuracy)\nas that of the teacher model but also significantly reduces the detection time\n(from 70046.6 ms to 194.9 ms) without requiring dynamic analysis.",
    "descriptor": "\nComments: Accepted for presentation and publication at the 21st International Conference on Applied Cryptography and Network Security (ACNS 2023)\n",
    "authors": [
      "Mao V. Ngo",
      "Tram Truong-Huu",
      "Dima Rabadi",
      "Jia Yi Loo",
      "Sin G. Teo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.13860"
  },
  {
    "id": "arXiv:2211.13862",
    "title": "Generalized convolution quadrature for the fractional integral and  fractional diffusion equations",
    "abstract": "We consider the application of the generalized Convolution Quadrature (gCQ)\nof the first order to approximate fractional integrals and associated\nfractional diffusion equations. The gCQ is a generalization of Lubich's\nConvolution Quadrature (CQ) which allows for variable steps. In this paper we\nanalyze the application of the gCQ to fractional integrals, with a focus in the\nlow regularity case. It is well known that in this situation the original CQ\npresents an order reduction close to the singularity. Moreover, the available\ntheory for the gCQ does not cover this situation. Here we deduce error bounds\nfor a general time mesh. We show first order of convergence under much weaker\nregularity requirements than previous results in the literature. We also prove\nthat uniform first order convergence is achievable for a graded time mesh,\nwhich is appropriately refined close to the singularity, according to the order\nof the fractional integral and the regularity of the data. Then we study how to\nobtain full order of convergence for the application to fractional diffusion\nequations. For the implementation of this method, we use fast and oblivious\nquadrature and present several numerical experiments to illustrate our\ntheoretical results.",
    "descriptor": "\nComments: 22 pages, 18 figures\n",
    "authors": [
      "Jing Guo",
      "Maria Lopez-Fernandez"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.13862"
  },
  {
    "id": "arXiv:2211.13865",
    "title": "Competency-Aware Neural Machine Translation: Can Machine Translation  Know its Own Translation Quality?",
    "abstract": "Neural machine translation (NMT) is often criticized for failures that happen\nwithout awareness. The lack of competency awareness makes NMT untrustworthy.\nThis is in sharp contrast to human translators who give feedback or conduct\nfurther investigations whenever they are in doubt about predictions. To fill\nthis gap, we propose a novel competency-aware NMT by extending conventional NMT\nwith a self-estimator, offering abilities to translate a source sentence and\nestimate its competency. The self-estimator encodes the information of the\ndecoding procedure and then examines whether it can reconstruct the original\nsemantics of the source sentence. Experimental results on four translation\ntasks demonstrate that the proposed method not only carries out translation\ntasks intact but also delivers outstanding performance on quality estimation.\nWithout depending on any reference or annotated data typically required by\nstate-of-the-art metric and quality estimation methods, our model yields an\neven higher correlation with human quality judgments than a variety of\naforementioned methods, such as BLEURT, COMET, and BERTScore. Quantitative and\nqualitative analyses show better robustness of competency awareness in our\nmodel.",
    "descriptor": "\nComments: accepted to EMNLP 2022\n",
    "authors": [
      "Pei Zhang",
      "Baosong Yang",
      "Haoran Wei",
      "Dayiheng Liu",
      "Kai Fan",
      "Luo Si",
      "Jun Xie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13865"
  },
  {
    "id": "arXiv:2211.13868",
    "title": "Can Knowledge of End-to-End Text-to-Speech Models Improve Neural  MIDI-to-Audio Synthesis Systems?",
    "abstract": "With the similarity between music and speech synthesis from symbolic input\nand the rapid development of text-to-speech (TTS) techniques, it is worthwhile\nto explore ways to improve the MIDI-to-audio performance by borrowing from TTS\ntechniques. In this study, we analyze the shortcomings of a TTS-based\nMIDI-to-audio system and improve it in terms of feature computation, model\nselection, and training strategy, aiming to synthesize highly natural-sounding\naudio. Moreover, we conducted an extensive model evaluation through listening\ntests, pitch measurement, and spectrogram analysis. This work demonstrates not\nonly synthesis of highly natural music but offers a thorough analytical\napproach and useful outcomes for the community. Our code and pre-trained models\nare open sourced at https://github.com/nii-yamagishilab/midi-to-audio.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Xuan Shi",
      "Erica Cooper",
      "Xin Wang",
      "Junichi Yamagishi",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.13868"
  },
  {
    "id": "arXiv:2211.13873",
    "title": "Global and Local Hierarchy-aware Contrastive Framework for Implicit  Discourse Relation Recognition",
    "abstract": "Due to the absence of explicit connectives, implicit discourse relation\nrecognition (IDRR) remains a challenging task in discourse analysis. The\ncritical step for IDRR is to learn high-quality discourse relation\nrepresentations between two arguments. Recent methods tend to integrate the\nwhole hierarchical information of senses into discourse relation\nrepresentations for multi-level sense recognition. Nevertheless, they\ninsufficiently incorporate the static hierarchical structure containing all\nsenses (defined as global hierarchy), and ignore the hierarchical sense label\nsequence corresponding to each instance (defined as local hierarchy). For the\npurpose of sufficiently exploiting global and local hierarchies of senses to\nlearn better discourse relation representations, we propose a novel GLobal and\nLOcal Hierarchy-aware Contrastive Framework (GLOF), to model two kinds of\nhierarchies with the aid of contrastive learning. Experimental results on the\nPDTB dataset demonstrate that our method remarkably outperforms the current\nstate-of-the-art model at all hierarchical levels.",
    "descriptor": "\nComments: 13 pages, 10 figures\n",
    "authors": [
      "Yuxin Jiang",
      "Linhan Zhang",
      "Wei Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.13873"
  },
  {
    "id": "arXiv:2211.13874",
    "title": "FFHQ-UV: Normalized Facial UV-Texture Dataset for 3D Face Reconstruction",
    "abstract": "We present a large-scale facial UV-texture dataset that contains over 50,000\nhigh-quality texture UV-maps with even illuminations, neutral expressions, and\ncleaned facial regions, which are desired characteristics for rendering\nrealistic 3D face models under different lighting conditions. The dataset is\nderived from a large-scale face image dataset namely FFHQ, with the help of our\nfully automatic and robust UV-texture production pipeline. Our pipeline\nutilizes the recent advances in StyleGAN-based facial image editing approaches\nto generate multi-view normalized face images from single-image inputs. An\nelaborated UV-texture extraction, correction, and completion procedure is then\napplied to produce high-quality UV-maps from the normalized face images.\nCompared with existing UV-texture datasets, our dataset has more diverse and\nhigher-quality texture maps. We further train a GAN-based texture decoder as\nthe nonlinear texture basis for parametric fitting based 3D face\nreconstruction. Experiments show that our method improves the reconstruction\naccuracy over state-of-the-art approaches, and more importantly, produces\nhigh-quality texture maps that are ready for realistic renderings. The dataset,\ncode, and pre-trained texture decoder are publicly available at\nhttps://github.com/csbhr/FFHQ-UV.",
    "descriptor": "\nComments: The dataset, code, and pre-trained texture decoder are publicly available at this https URL\n",
    "authors": [
      "Haoran Bai",
      "Di Kang",
      "Haoxian Zhang",
      "Jinshan Pan",
      "Linchao Bao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13874"
  },
  {
    "id": "arXiv:2211.13878",
    "title": "Galvatron: Efficient Transformer Training over Multiple GPUs Using  Automatic Parallelism",
    "abstract": "Transformer models have achieved state-of-the-art performance on various\ndomains of applications and gradually becomes the foundations of the advanced\nlarge deep learning (DL) models. However, how to train these models over\nmultiple GPUs efficiently is still challenging due to a large number of\nparallelism choices. Existing DL systems either rely on manual efforts to make\ndistributed training plans or apply parallelism combinations within a very\nlimited search space. In this approach, we propose Galvatron, a new system\nframework that incorporates multiple popular parallelism dimensions and\nautomatically finds the most efficient hybrid parallelism strategy. To better\nexplore such a rarely huge search space, we 1) involve a decision tree to make\ndecomposition and pruning based on some reasonable intuitions, and then 2)\ndesign a dynamic programming search algorithm to generate the optimal plan.\nEvaluations on four representative Transformer workloads show that Galvatron\ncould perform automatically distributed training with different GPU memory\nbudgets. Among all evluated scenarios, Galvatron always achieves superior\nsystem throughput compared to previous work with limited parallelism.",
    "descriptor": "",
    "authors": [
      "Xupeng Miao",
      "Yujie Wang",
      "Youhe Jiang",
      "Chunan Shi",
      "Xiaonan Nie",
      "Hailin Zhang",
      "Bin Cui"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.13878"
  },
  {
    "id": "arXiv:2211.13879",
    "title": "Sensitivity Analyses of Resilience-oriented Risk-averse Active  Distribution Systems Planning",
    "abstract": "This paper presents sensitivity analyses of resilience-based active\ndistribution system planning solutions with respect to different parameters.\nThe distribution system planning problem is formulated as a two-stage\nrisk-averse stochastic optimization model with conditional value-at-risk (CVaR)\nas the risk measure. The probabilistic scenarios are obtained using regional\nwind profiles, and Monte Carlo simulations are conducted to obtain failure\nscenarios based on component fragility models. The planning measure includes\nadvanced distribution grid operations with intentional islanding measures. The\nthree main parameters used in this work for sensitivity analysis are the number\nof scenarios, risk preference, and planning budget allocation. Such analysis\ncan provide additional information to system operators on dispatching the\nplanning budget and available resources properly to enhance the grid's\nresilience.",
    "descriptor": "\nComments: 5 pages, 12 figures, submitted to 2023 IEEE Power and Energy Society General Meeting for review\n",
    "authors": [
      "Abodh Poudyal",
      "Anamika Dubey"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.13879"
  },
  {
    "id": "arXiv:2211.13882",
    "title": "Towards Better Bounds for Finding Quasi-Identifiers",
    "abstract": "We revisit the problem of finding small $\\epsilon$-separation keys introduced\nby Motwani and Xu (VLDB 07). In this problem, the input is $m$-dimensional\ntuples $x_1,x_2,\\ldots,x_n $. The goal is to find a small subset of coordinates\nthat separates at least $(1-\\epsilon){n \\choose 2}$ pairs of tuples. They\nprovided a fast algorithm that runs on $\\Theta(m/\\epsilon)$ tuples sampled\nuniformly at random. We show that the sample size can be improved to\n$\\Theta(m/\\sqrt{\\epsilon})$. Our algorithm also enjoys a faster running time.\nTo obtain this result, we provide upper and lower bounds on the sample size to\nsolve the following decision problem. Given a subset of coordinates $A$, reject\nif $A$ separates fewer than $(1-\\epsilon){n \\choose 2}$ pairs, and accept if\n$A$ separates all pairs. The algorithm must be correct with probability at\nleast $1-\\delta$ for all $A$. We show that for algorithms based on sampling:\n- $\\Theta(m/\\sqrt{\\epsilon})$ samples are sufficient and necessary so that\n$\\delta \\leq e^{-m}$ and\n- $\\Omega(\\sqrt{\\frac{\\log m}{\\epsilon}})$ samples are necessary so that\n$\\delta$ is a constant.\nOur analysis is based on a constrained version of the balls-into-bins\nproblem. We believe our analysis may be of independent interest. We also study\na related problem that asks for the following sketching algorithm: with given\nparameters $\\alpha,k$ and $\\epsilon$, the algorithm takes a subset of\ncoordinates $A$ of size at most $k$ and returns an estimate of the number of\nunseparated pairs in $A$ up to a $(1\\pm\\epsilon)$ factor if it is at least\n$\\alpha {n \\choose 2}$. We show that even for constant $\\alpha$ and success\nprobability, such a sketching algorithm must use $\\Omega(mk \\log\n\\epsilon^{-1})$ bits of space; on the other hand, uniform sampling yields a\nsketch of size $\\Theta(\\frac{mk \\log m}{\\alpha \\epsilon^2})$ for this purpose.",
    "descriptor": "\nComments: Abstract shortened to meet requirements\n",
    "authors": [
      "Ryan Hildebrant",
      "Quoc-Tung Le",
      "Duy-Hoang Ta",
      "Hoa T. Vu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.13882"
  },
  {
    "id": "arXiv:2211.13883",
    "title": "Learning with Silver Standard Data for Zero-shot Relation Extraction",
    "abstract": "The superior performance of supervised relation extraction (RE) methods\nheavily relies on a large amount of gold standard data. Recent zero-shot\nrelation extraction methods converted the RE task to other NLP tasks and used\noff-the-shelf models of these NLP tasks to directly perform inference on the\ntest data without using a large amount of RE annotation data. A potentially\nvaluable by-product of these methods is the large-scale silver standard data.\nHowever, there is no further investigation on the use of potentially valuable\nsilver standard data. In this paper, we propose to first detect a small amount\nof clean data from silver standard data and then use the selected clean data to\nfinetune the pretrained model. We then use the finetuned model to infer\nrelation types. We also propose a class-aware clean data detection module to\nconsider class information when selecting clean data. The experimental results\nshow that our method can outperform the baseline by 12% and 11% on TACRED and\nWiki80 dataset in the zero-shot RE task. By using extra silver standard data of\ndifferent distributions, the performance can be further improved.",
    "descriptor": "\nComments: 21 pages, 6 figures\n",
    "authors": [
      "Tianyin Wang",
      "Jianwei Wang",
      "Ziqian Zeng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.13883"
  },
  {
    "id": "arXiv:2211.13887",
    "title": "TPA-Net: Generate A Dataset for Text to Physics-based Animation",
    "abstract": "Recent breakthroughs in Vision-Language (V&L) joint research have achieved\nremarkable results in various text-driven tasks. High-quality Text-to-video\n(T2V), a task that has been long considered mission-impossible, was proven\nfeasible with reasonably good results in latest works. However, the resulting\nvideos often have undesired artifacts largely because the system is purely\ndata-driven and agnostic to the physical laws. To tackle this issue and further\npush T2V towards high-level physical realism, we present an autonomous data\ngeneration technique and a dataset, which intend to narrow the gap with a large\nnumber of multi-modal, 3D Text-to-Video/Simulation (T2V/S) data. In the\ndataset, we provide high-resolution 3D physical simulations for both solids and\nfluids, along with textual descriptions of the physical phenomena. We take\nadvantage of state-of-the-art physical simulation methods (i) Incremental\nPotential Contact (IPC) and (ii) Material Point Method (MPM) to simulate\ndiverse scenarios, including elastic deformations, material fractures,\ncollisions, turbulence, etc. Additionally, high-quality, multi-view rendering\nvideos are supplied for the benefit of T2V, Neural Radiance Fields (NeRF), and\nother communities. This work is the first step towards fully automated\nText-to-Video/Simulation (T2V/S). Live examples and subsequent work are at\nhttps://sites.google.com/view/tpa-net.",
    "descriptor": "",
    "authors": [
      "Yuxing Qiu",
      "Feng Gao",
      "Minchen Li",
      "Govind Thattai",
      "Yin Yang",
      "Chenfanfu Jiang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.13887"
  },
  {
    "id": "arXiv:2211.13890",
    "title": "Option Pricing under Multifactor Black-Scholes Model Using Orthogonal  Spline Wavelets",
    "abstract": "The paper focuses on pricing European-style options on several underlying\nassets under the Black-Scholes model represented by a nonstationary partial\ndifferential equation. The proposed method combines the Galerkin method with\n$L^2$-orthogonal sparse grid spline wavelets and the Crank-Nicolson scheme with\nRannacher time-stepping. To this end, we construct an orthogonal cubic spline\nwavelet basis on the interval satisfying homogeneous Dirichlet boundary\nconditions and design a wavelet basis on the unit cube using the sparse tensor\nproduct. The method brings the following advantages. First, the number of basis\nfunctions is significantly smaller than for the full grid, which makes it\npossible to overcome the so-called curse of dimensionality. Second, some\nmatrices involved in the computation are identity matrices, which significantly\nsimplifies and streamlines the algorithm, especially in higher dimensions.\nFurther, we prove that discretization matrices have uniformly bounded condition\nnumbers, even without preconditioning, and that the condition numbers do not\ndepend on the dimension of the problem. Due to the use of cubic spline\nwavelets, the method is higher-order convergent. Numerical experiments are\npresented for options on the geometric average.",
    "descriptor": "\nComments: 43 pages, 10 figures\n",
    "authors": [
      "Dana \u010cern\u00e1",
      "Kate\u0159ina Fi\u0148kov\u00e1"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.13890"
  },
  {
    "id": "arXiv:2211.13892",
    "title": "Complementary Explanations for Effective In-Context Learning",
    "abstract": "Large language models (LLMs) have exhibited remarkable capabilities in\nlearning from explanations in prompts. Yet, there has been limited\nunderstanding of what makes explanations effective for in-context learning.\nThis work aims to better understand the mechanisms by which explanations are\nused for in-context learning. We first study the impact of two different\nfactors on prompting performance when using explanations: the computation trace\n(the way the solution is decomposed) and the natural language of the prompt. By\nperturbing explanations on three controlled tasks, we show that both factors\ncontribute to the effectiveness of explanations, indicating that LLMs do\nfaithfully follow the explanations to some extent. We further study how to form\nmaximally effective sets of explanations for solving a given test query. We\nfind that LLMs can benefit from the complementarity of the explanation set as\nthey are able to fuse different reasoning specified by individual exemplars in\nprompts. Additionally, having relevant exemplars also contributes to more\neffective prompts. Therefore, we propose a maximal-marginal-relevance-based\nexemplar selection approach for constructing exemplar sets that are both\nrelevant as well as complementary, which successfully improves the in-context\nlearning performance across three real-world tasks on multiple LLMs.",
    "descriptor": "",
    "authors": [
      "Xi Ye",
      "Srinivasan Iyer",
      "Asli Celikyilmaz",
      "Ves Stoyanov",
      "Greg Durrett",
      "Ramakanth Pasunuru"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.13892"
  },
  {
    "id": "arXiv:2211.13893",
    "title": "Scalable multiscale-spectral GFEM for composite aero-structures",
    "abstract": "Ill-conditioned and multiscale partial differential equations (PDEs) arise in\nmany fields. It is a very challenging problem to compute a resolved, fine-scale\nsolution or to find a robust low-dimensional approximation. In this paper, the\nfirst large-scale application of multiscale-spectral generalized finite element\nmethods (MS-GFEM) to composite aero-structures is presented. A problem-specific\ncoarse space generated from local eigenproblems yields a spectral element-type\nmethod with excellent approximation properties at low basis size, even for\nchallenging multiscale problems. The implementation of the framework in the\nDUNE software package, as well as a detailed description of all components of\nthe method are presented and exemplified on a composite laminated beam under\ncompressive loading. The excellent parallel scalability of the method, as well\nas its superior performance compared to the related, previously introduced\nGenEO method are demonstrated on two realistic application cases. Further, by\nallowing low-cost approximate solves for closely related models or geometries\nthis efficient, novel technology provides the basis for future applications in\noptimisation or uncertainty quantification on challenging problems in composite\naero-structures.",
    "descriptor": "",
    "authors": [
      "Jean B\u00e9n\u00e9zech",
      "Linus Seelinger",
      "Peter Bastian",
      "Richard Butler",
      "Timothy Dodwell",
      "Chupeng Ma",
      "Robert Scheichl"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.13893"
  },
  {
    "id": "arXiv:2211.13895",
    "title": "Identifying Incorrect Annotations in Multi-Label Classification Data",
    "abstract": "In multi-label classification, each example in a dataset may be annotated as\nbelonging to one or more classes (or none of the classes). Example applications\ninclude image (or document) tagging where each possible tag either applies to a\nparticular image (or document) or not. With many possible classes to consider,\ndata annotators are likely to make errors when labeling such data in practice.\nHere we consider algorithms for finding mislabeled examples in multi-label\nclassification datasets. We propose an extension of the Confident Learning\nframework to this setting, as well as a label quality score that ranks examples\nwith label errors much higher than those which are correctly labeled. Both\napproaches can utilize any trained classifier. After demonstrating that our\nmethodology empirically outperforms other algorithms for label error detection,\nwe apply our approach to discover many label errors in the CelebA image tagging\ndataset.",
    "descriptor": "",
    "authors": [
      "Aditya Thyagarajan",
      "El\u00edas Snorrason",
      "Curtis Northcutt",
      "Jonas Mueller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13895"
  },
  {
    "id": "arXiv:2211.13896",
    "title": "MUSIED: A Benchmark for Event Detection from Multi-Source Heterogeneous  Informal Texts",
    "abstract": "Event detection (ED) identifies and classifies event triggers from\nunstructured texts, serving as a fundamental task for information extraction.\nDespite the remarkable progress achieved in the past several years, most\nresearch efforts focus on detecting events from formal texts (e.g., news\narticles, Wikipedia documents, financial announcements). Moreover, the texts in\neach dataset are either from a single source or multiple yet relatively\nhomogeneous sources. With massive amounts of user-generated text accumulating\non the Web and inside enterprises, identifying meaningful events in these\ninformal texts, usually from multiple heterogeneous sources, has become a\nproblem of significant practical value. As a pioneering exploration that\nexpands event detection to the scenarios involving informal and heterogeneous\ntexts, we propose a new large-scale Chinese event detection dataset based on\nuser reviews, text conversations, and phone conversations in a leading\ne-commerce platform for food service. We carefully investigate the proposed\ndataset's textual informality and multi-source heterogeneity characteristics by\ninspecting data samples quantitatively and qualitatively. Extensive experiments\nwith state-of-the-art event detection methods verify the unique challenges\nposed by these characteristics, indicating that multi-source informal event\ndetection remains an open problem and requires further efforts. Our benchmark\nand code are released at \\url{https://github.com/myeclipse/MUSIED}.",
    "descriptor": "\nComments: Accepted at EMNLP 2022\n",
    "authors": [
      "Xiangyu Xi",
      "Jianwei Lv",
      "Shuaipeng Liu",
      "Wei Ye",
      "Fan Yang",
      "Guanglu Wan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.13896"
  },
  {
    "id": "arXiv:2211.13897",
    "title": "AFR-Net: Attention-Driven Fingerprint Recognition Network",
    "abstract": "The use of vision transformers (ViT) in computer vision is increasing due to\nlimited inductive biases (e.g., locality, weight sharing, etc.) and increased\nscalability compared to other deep learning methods (e.g., convolutional neural\nnetworks (CNN)). This has led to some initial studies on the use of ViT for\nbiometric recognition, including fingerprint recognition. In this work, we\nimprove on these initial studies for transformers in fingerprint recognition by\ni.) evaluating additional attention-based architectures in addition to vanilla\nViT, ii.) scaling to larger and more diverse training and evaluation datasets,\nand iii.) combining the complimentary representations of attention-based and\nCNN-based embeddings for improved state-of-the-art (SOTA) fingerprint\nrecognition for both authentication (1:1 comparisons) and identification (1:N\ncomparisions). Our combined architecture, AFR-Net (Attention-Driven Fingerprint\nRecognition Network), outperforms several baseline transformer and CNN-based\nmodels, including a SOTA commercial fingerprint system, Verifinger v12.3,\nacross many intra-sensor, cross-sensor (including contact to contactless), and\nlatent to rolled fingerprint matching datasets. Additionally, we propose a\nrealignment strategy using local embeddings extracted from intermediate feature\nmaps within the networks to refine the global embeddings in low certainty\nsituations, which boosts the overall recognition accuracy significantly for all\nthe evaluations across each of the models. This realignment strategy requires\nno additional training and can be applied as a wrapper to any existing deep\nlearning network (including attention-based, CNN-based, or both) to boost its\nperformance.",
    "descriptor": "",
    "authors": [
      "Steven A. Grosz",
      "Anil K. Jain"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13897"
  },
  {
    "id": "arXiv:2211.13898",
    "title": "Synthesis Cost-Optimal Targeted Mutant Protein Libraries",
    "abstract": "Protein variant libraries produced by site-directed mutagenesis are a useful\ntool utilized by protein engineers to explore variants with potentially\nimproved properties, such as activity and stability. These libraries are\ncommonly built by selecting residue positions and alternative beneficial\nmutations for each position. All possible combinations are then constructed and\nscreened, by incorporating degenerate codons at mutation sites. These\ndegenerate codons often encode additional unwanted amino acids or even STOP\ncodons. Our study aims to take advantage of annealing based recombination of\noligonucleotides during synthesis and utilize multiple degenerate codons per\nmutation site to produce targeted protein libraries devoid of unwanted\nvariants. Toward this goal we created an algorithm to calculate the minimum\nnumber of degenerate codons necessary to specify any given amino acid set, and\na dynamic programming method that uses this algorithm to optimally partition a\nDNA target sequence with degeneracies into overlapping oligonucleotides, such\nthat the total cost of synthesis of the target mutant protein library is\nminimized. Computational experiments show that, for a modest increase in DNA\nsynthesis costs, beneficial variant yields in produced mutant libraries are\nincreased by orders of magnitude, an effect particularly pronounced in large\ncombinatorial libraries.",
    "descriptor": "",
    "authors": [
      "Dimitris Papamichail",
      "Madeline Febinger",
      "Shm Almeda",
      "Georgios Papamichail"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.13898"
  },
  {
    "id": "arXiv:2211.13899",
    "title": "Comparison Study Between Token Classification and Sequence  Classification In Text Classification",
    "abstract": "Unsupervised Machine Learning techniques have been applied to Natural\nLanguage Processing tasks and surpasses the benchmarks such as GLUE with great\nsuccess. Building language models approach achieves good results in one\nlanguage and it can be applied to multiple NLP task such as classification,\nsummarization, generation and etc as an out of box model. Among all the of the\nclassical approaches used in NLP, the masked language modeling is the most\nused. In general, the only requirement to build a language model is presence of\nthe large corpus of textual data. Text classification engines uses a variety of\nmodels from classical and state of art transformer models to classify texts for\nin order to save costs. Sequence Classifiers are mostly used in the domain of\ntext classification. However Token classifiers also are viable candidate models\nas well. Sequence Classifiers and Token Classifier both tend to improve the\nclassification predictions due to the capturing the context information\ndifferently. This work aims to compare the performance of Sequence Classifier\nand Token Classifiers and evaluate each model on the same set of data. In this\nwork, we are using a pre-trained model as the base model and Token Classifier\nand Sequence Classier heads results of these two scoring paradigms with be\ncompared..",
    "descriptor": "\nComments: 11 Pages, 3, figures\n",
    "authors": [
      "Amir Jafari"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.13899"
  },
  {
    "id": "arXiv:2211.13900",
    "title": "A Deep Learning Anomaly Detection Method in Textual Data",
    "abstract": "In this article, we propose using deep learning and transformer architectures\ncombined with classical machine learning algorithms to detect and identify text\nanomalies in texts. Deep learning model provides a very crucial context\ninformation about the textual data which all textual context are converted to a\nnumerical representation. We used multiple machine learning methods such as\nSentence Transformers, Auto Encoders, Logistic Regression and Distance\ncalculation methods to predict anomalies. The method are tested on the texts\ndata and we used syntactic data from different source injected into the\noriginal text as anomalies or use them as target. Different methods and\nalgorithm are explained in the field of outlier detection and the results of\nthe best technique is presented. These results suggest that our algorithm could\npotentially reduce false positive rates compared with other anomaly detection\nmethods that we are testing.",
    "descriptor": "\nComments: 8 Pages, 4 Figures\n",
    "authors": [
      "Amir Jafari"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.13900"
  },
  {
    "id": "arXiv:2211.13901",
    "title": "Learning Detailed Radiance Manifolds for High-Fidelity and 3D-Consistent  Portrait Synthesis from Monocular Image",
    "abstract": "A key challenge for novel view synthesis of monocular portrait images is 3D\nconsistency under continuous pose variations. Most existing methods rely on 2D\ngenerative models which often leads to obvious 3D inconsistency artifacts. We\npresent a 3D-consistent novel view synthesis approach for monocular portrait\nimages based on a recent proposed 3D-aware GAN, namely Generative Radiance\nManifolds (GRAM), which has shown strong 3D consistency at multiview image\ngeneration of virtual subjects via the radiance manifolds representation.\nHowever, simply learning an encoder to map a real image into the latent space\nof GRAM can only reconstruct coarse radiance manifolds without faithful fine\ndetails, while improving the reconstruction fidelity via instance-specific\noptimization is time-consuming. We introduce a novel detail manifolds\nreconstructor to learn 3D-consistent fine details on the radiance manifolds\nfrom monocular images, and combine them with the coarse radiance manifolds for\nhigh-fidelity reconstruction. The 3D priors derived from the coarse radiance\nmanifolds are used to regulate the learned details to ensure reasonable\nsynthesized results at novel views. Trained on in-the-wild 2D images, our\nmethod achieves high-fidelity and 3D-consistent portrait synthesis largely\noutperforming the prior art.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Yu Deng",
      "Baoyuan Wang",
      "Heung-Yeung Shum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13901"
  },
  {
    "id": "arXiv:2211.13902",
    "title": "TAOTF: A Two-stage Approximately Orthogonal Training Framework in Deep  Neural Networks",
    "abstract": "The orthogonality constraints, including the hard and soft ones, have been\nused to normalize the weight matrices of Deep Neural Network (DNN) models,\nespecially the Convolutional Neural Network (CNN) and Vision Transformer (ViT),\nto reduce model parameter redundancy and improve training stability. However,\nthe robustness to noisy data of these models with constraints is not always\nsatisfactory. In this work, we propose a novel two-stage approximately\northogonal training framework (TAOTF) to find a trade-off between the\northogonal solution space and the main task solution space to solve this\nproblem in noisy data scenarios. In the first stage, we propose a novel\nalgorithm called polar decomposition-based orthogonal initialization (PDOI) to\nfind a good initialization for the orthogonal optimization. In the second\nstage, unlike other existing methods, we apply soft orthogonal constraints for\nall layers of DNN model. We evaluate the proposed model-agnostic framework both\non the natural image and medical image datasets, which show that our method\nachieves stable and superior performances to existing methods.",
    "descriptor": "",
    "authors": [
      "Taoyong Cui",
      "Jianze Li",
      "Yuhan Dong",
      "Li Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13902"
  },
  {
    "id": "arXiv:2211.13904",
    "title": "Policy-Adaptive Estimator Selection for Off-Policy Evaluation",
    "abstract": "Off-policy evaluation (OPE) aims to accurately evaluate the performance of\ncounterfactual policies using only offline logged data. Although many\nestimators have been developed, there is no single estimator that dominates the\nothers, because the estimators' accuracy can vary greatly depending on a given\nOPE task such as the evaluation policy, number of actions, and noise level.\nThus, the data-driven estimator selection problem is becoming increasingly\nimportant and can have a significant impact on the accuracy of OPE. However,\nidentifying the most accurate estimator using only the logged data is quite\nchallenging because the ground-truth estimation accuracy of estimators is\ngenerally unavailable. This paper studies this challenging problem of estimator\nselection for OPE for the first time. In particular, we enable an estimator\nselection that is adaptive to a given OPE task, by appropriately subsampling\navailable logged data and constructing pseudo policies useful for the\nunderlying estimator selection task. Comprehensive experiments on both\nsynthetic and real-world company data demonstrate that the proposed procedure\nsubstantially improves the estimator selection compared to a non-adaptive\nheuristic.",
    "descriptor": "\nComments: accepted at AAAI'23\n",
    "authors": [
      "Takuma Udagawa",
      "Haruka Kiyohara",
      "Yusuke Narita",
      "Yuta Saito",
      "Kei Tateno"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13904"
  },
  {
    "id": "arXiv:2211.13905",
    "title": "Uncertainty-Informed Renewable Energy Scheduling: A Scalable Bilevel  Framework",
    "abstract": "Accommodating the uncertainty of variable renewable energy sources (VRES) in\nelectricity markets requires sophisticated and scalable tools to achieve market\nefficiency. To account for the uncertain imbalance costs in the real-time\nmarket while remaining compatible with the existing sequential market-clearing\nstructure, our work adopts an uncertainty-informed adjustment toward the VRES\ncontract quantity scheduled in the day-ahead market. This mechanism requires\nsolving a bilevel problem, which is computationally challenging for practical\nlarge-scale systems. To improve the scalability, we propose a technique based\non strong duality and McCormick envelopes, which relaxes the original problem\nto linear programming. We conduct numerical studies on both IEEE 118-bus and\n1814-bus NYISO systems. Results show that the proposed relaxation can achieve\ngood performance in accuracy (0.7%-gap in the system cost wrt. the least-cost\nstochastic clearing benchmark) and scalability (solving the NYISO system in\nminutes). Furthermore, the benefit of the uncertainty-informed VRES-quantity\nadjustment is more significant under higher levels of VRES (e.g., 70%), under\nwhich the system cost can be reduced substantially compared to a myopic\nday-ahead offer strategy of VRES.",
    "descriptor": "\nComments: Submitted to IEEE PES general meeting 2023\n",
    "authors": [
      "Dongwei Zhao",
      "Vladimir Dvorkin",
      "Stefanos Delikaraoglou",
      "Alberto J. Lamadrid L.",
      "Audun Botterud"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.13905"
  },
  {
    "id": "arXiv:2211.13907",
    "title": "Blockchain based solution design for Energy Exchange Platform",
    "abstract": "It is observed that users have higher requirements for fairness,\ntransparency, and privacy of transactions of energy exchanges that occur across\nplatforms like Indian Energy Exchange (IEX) and Power Exchange India Limited\n(PXIL). As a decentralized distributed accounting system, blockchain is\ncharacterized by traceability, security, credibility, and non-tampering of\ntransactions, which can meet the needs of integrated energy and multi-energy\ntransactions. Based on the research on the application of blockchain technology\nin the field of integrated energy services, this solution proposes an\nintegrated energy trading process based on smart contracts and explores the\napplication of blockchain technology in integrated energy services.",
    "descriptor": "",
    "authors": [
      "Atharv Bhadange",
      "Rohan Doshi",
      "Tanmay Karmarkar",
      "Snehal Shintre"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.13907"
  },
  {
    "id": "arXiv:2211.13908",
    "title": "Fault-Tolerant Offline Multi-Agent Path Planning",
    "abstract": "We study a novel graph path planning problem for multiple agents that may\ncrash at runtime, and block part of the workspace. In our setting, agents can\ndetect neighboring crashed agents, and change followed paths at runtime. The\nobjective is then to prepare a set of paths and switching rules for each agent,\nensuring that all correct agents reach their destinations without collisions or\ndeadlocks, despite unforeseen crashes of other agents. Such planning is\nattractive to build reliable multi-robot systems. We present problem\nformalization, theoretical analysis such as computational complexities, and how\nto solve this offline planning problem.",
    "descriptor": "\nComments: to be presented at AAAI-23\n",
    "authors": [
      "Keisuke Okumura",
      "S\u00e9bastien Tixeuil"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.13908"
  },
  {
    "id": "arXiv:2211.13909",
    "title": "The Magic of Slow-to-Fast and Constant: Evaluating Time Perception of  Progress Bars by Bayesian Model",
    "abstract": "Objective: We aimed to use adaptive psychophysics methods, which is a\nBayesian Model, to measure users' time perception of various progress bar\nquantitatively. Background: Progress bar informs users about the status of\nongoing processes. Progress bars frequently display nonuniform speed patterns,\nsuch as acceleration and deceleration. However, which progress bar is perceived\nfaster remain unclear. Methods: We measured the point of subject equality (PSE)\nof the constant progress bar toward four different 5-second progress bars with\na non-constant speed. To measure PSE, in each trial, a constant progress bar\nand a non-constant progress bar were presented to participants. Participants\nneeded to judge which one is shorter. Based on their choice, the model\ngenerated the time duration of constant progress bar in next trial. After 40\ntrials for each non-constant progress bar, the PSE was calculated by the model.\nEye tracking was recorded during the experiment.Results: Our results show that\nthe constant progress bar and speed-up progress bar are perceived to be faster.\nThe anchoring effect fits the results of our study, indicating that the final\npart of the progress bar is more important for time perception. Moreover, the\neye-tracking results indicate that the progress bar is perceived to be slower\nis related to the overload of cognitive resources.Conclusion: The constant\nprogress bar and speed-up progress bar are perceived as the quickest.\nApplication: The results suggest that UX design can use constant or speed-up\nprogress bar, in order to improve user experience in waiting.",
    "descriptor": "",
    "authors": [
      "Qihan Wang",
      "Xinyue Kang",
      "Pei-Luen Patrick Rau"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.13909"
  },
  {
    "id": "arXiv:2211.13912",
    "title": "Soft BPR Loss for Dynamic Hard Negative Sampling in Recommender Systems",
    "abstract": "In recommender systems, leveraging Graph Neural Networks (GNNs) to formulate\nthe bipartite relation between users and items is a promising way. However,\npowerful negative sampling methods that is adapted to GNN-based recommenders\nstill requires a lot of efforts. One critical gap is that it is rather tough to\ndistinguish real negatives from massive unobserved items during hard negative\nsampling. Towards this problem, this paper develops a novel hard negative\nsampling method for GNN-based recommendation systems by simply reformulating\nthe loss function. We conduct various experiments on three datasets,\ndemonstrating that the method proposed outperforms a set of state-of-the-art\nbenchmarks.",
    "descriptor": "\nComments: 9 pages, 16 figures\n",
    "authors": [
      "Kexin Shi",
      "Yun Zhang",
      "Bingyi Jing",
      "Wenjia Wang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.13912"
  },
  {
    "id": "arXiv:2211.13916",
    "title": "Towards Good Practices for Missing Modality Robust Action Recognition",
    "abstract": "Standard multi-modal models assume the use of the same modalities in training\nand inference stages. However, in practice, the environment in which\nmulti-modal models operate may not satisfy such assumption. As such, their\nperformances degrade drastically if any modality is missing in the inference\nstage. We ask: how can we train a model that is robust to missing modalities?\nThis paper seeks a set of good practices for multi-modal action recognition,\nwith a particular interest in circumstances where some modalities are not\navailable at an inference time. First, we study how to effectively regularize\nthe model during training (e.g., data augmentation). Second, we investigate on\nfusion methods for robustness to missing modalities: we find that\ntransformer-based fusion shows better robustness for missing modality than\nsummation or concatenation. Third, we propose a simple modular network,\nActionMAE, which learns missing modality predictive coding by randomly dropping\nmodality features and tries to reconstruct them with the remaining modality\nfeatures. Coupling these good practices, we build a model that is not only\neffective in multi-modal action recognition but also robust to modality\nmissing. Our model achieves the state-of-the-arts on multiple benchmarks and\nmaintains competitive performances even in missing modality scenarios. Codes\nare available at https://github.com/sangminwoo/ActionMAE.",
    "descriptor": "\nComments: AAAI 2023\n",
    "authors": [
      "Sangmin Woo",
      "Sumin Lee",
      "Yeonju Park",
      "Muhammad Adi Nugroho",
      "Changick Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13916"
  },
  {
    "id": "arXiv:2211.13919",
    "title": "Mutual Guidance and Residual Integration for Image Enhancement",
    "abstract": "Previous studies show the necessity of global and local adjustment for image\nenhancement. However, existing convolutional neural networks (CNNs) and\ntransformer-based models face great challenges in balancing the computational\nefficiency and effectiveness of global-local information usage. Especially,\nexisting methods typically adopt the global-to-local fusion mode, ignoring the\nimportance of bidirectional interactions. To address those issues, we propose a\nnovel mutual guidance network (MGN) to perform effective bidirectional\nglobal-local information exchange while keeping a compact architecture. In our\ndesign, we adopt a two-branch framework where one branch focuses more on\nmodeling global relations while the other is committed to processing local\ninformation. Then, we develop an efficient attention-based mutual guidance\napproach throughout our framework for bidirectional global-local interactions.\nAs a result, both the global and local branches can enjoy the merits of mutual\ninformation aggregation. Besides, to further refine the results produced by our\nMGN, we propose a novel residual integration scheme following the\ndivide-and-conquer philosophy. The extensive experiments demonstrate the\neffectiveness of our proposed method, which achieves state-of-the-art\nperformance on several public image enhancement benchmarks.",
    "descriptor": "\nComments: 17 pages, 15 figures\n",
    "authors": [
      "Kun Zhou",
      "KenKun Liu",
      "Wenbo Li",
      "Xiaoguang Han",
      "Jiangbo Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13919"
  },
  {
    "id": "arXiv:2211.13922",
    "title": "Combining Constructive and Perturbative Deep Learning Algorithms for the  Capacitated Vehicle Routing Problem",
    "abstract": "The Capacitated Vehicle Routing Problem is a well-known NP-hard problem that\nposes the challenge of finding the optimal route of a vehicle delivering\nproducts to multiple locations. Recently, new efforts have emerged to create\nconstructive and perturbative heuristics to tackle this problem using Deep\nLearning. In this paper, we join these efforts to develop the Combined Deep\nConstructor and Perturbator, which combines two powerful constructive and\nperturbative Deep Learning-based heuristics, using attention mechanisms at\ntheir core. Furthermore, we improve the Attention Model-Dynamic for the\nCapacitated Vehicle Routing Problem by proposing a memory-efficient algorithm\nthat reduces its memory complexity by a factor of the number of nodes. Our\nmethod shows promising results. It demonstrates a cost improvement in common\ndatasets when compared against other multiple Deep Learning methods. It also\nobtains close results to the state-of-the art heuristics from the Operations\nResearch field. Additionally, the proposed memory efficient algorithm for the\nAttention Model-Dynamic model enables its use in problem instances with more\nthan 100 nodes.",
    "descriptor": "",
    "authors": [
      "Roberto Garc\u00eda-Torres",
      "Alitzel Adriana Macias-Infante",
      "Santiago Enrique Conant-Pablos",
      "Jos\u00e9 Carlos Ortiz-Bayliss",
      "Hugo Terashima-Mar\u00edn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.13922"
  },
  {
    "id": "arXiv:2211.13925",
    "title": "On DNA Codes Over the Non-Chain Ring  $\\mathbb{Z}_4+u\\mathbb{Z}_4+u^2\\mathbb{Z}_4$ with $u^3=1$",
    "abstract": "In this paper, we present a novel design strategy of DNA codes with length\n$3n$ over the non-chain ring $R=\\mathbb{Z}_4+u\\mathbb{Z}_4+u^2\\mathbb{Z}_4$\nwith $64$ elements and $u^3=1$, where $n$ denotes the length of a code over\n$R$. We first study and analyze a distance conserving map defined over the ring\n$R$ into the length-$3$ DNA sequences. Then, we derive some conditions on the\ngenerator matrix of a linear code over $R$, which leads to a DNA code with\nreversible, reversible-complement, homopolymer $2$-run-length, and\n$\\frac{w}{3n}$-GC-content constraints for integer $w$ ($0\\leq w\\leq 3n$).\nFinally, we propose a new construction of DNA codes using Reed-Muller type\ngenerator matrices. This allows us to obtain DNA codes with reversible,\nreversible-complement, homopolymer $2$-run-length, and $\\frac{2}{3}$-GC-content\nconstraints.",
    "descriptor": "\nComments: This paper has been presented in IEEE Information Theory Workshop (ITW) 2022, Mumbai, INDIA\n",
    "authors": [
      "Shibsankar Das",
      "Krishna Gopal Benerjee",
      "Adrish Banerjee"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.13925"
  },
  {
    "id": "arXiv:2211.13928",
    "title": "UperFormer: A Multi-scale Transformer-based Decoder for Semantic  Segmentation",
    "abstract": "While a large number of recent works on semantic segmentation focus on\ndesigning and incorporating a transformer-based encoder, much less attention\nand vigor have been devoted to transformer-based decoders. For such a task\nwhose hallmark quest is pixel-accurate prediction, we argue that the decoder\nstage is just as crucial as that of the encoder in achieving superior\nsegmentation performance, by disentangling and refining the high-level cues and\nworking out object boundaries with pixel-level precision. In this paper, we\npropose a novel transformer-based decoder called UperFormer, which is\nplug-and-play for hierarchical encoders and attains high quality segmentation\nresults regardless of encoder architecture. UperFormer is equipped with\ncarefully designed multi-head skip attention units and novel upsampling\noperations. Multi-head skip attention is able to fuse multi-scale features from\nbackbones with those in decoders. The upsampling operation, which incorporates\nfeature from encoder, can be more friendly for object localization. It brings a\n0.4% to 3.2% increase compared with traditional upsampling methods. By\ncombining UperFormer with Swin Transformer (Swin-T), a fully transformer-based\nsymmetric network is formed for semantic segmentation tasks. Extensive\nexperiments show that our proposed approach is highly effective and\ncomputationally efficient. On Cityscapes dataset, we achieve state-of-the-art\nperformance. On the more challenging ADE20K dataset, our best model yields a\nsingle-scale mIoU of 50.18, and a multi-scale mIoU of 51.8, which is on-par\nwith the current state-of-art model, while we drastically cut the number of\nFLOPs by 53.5%. Our source code and models are publicly available at:\nhttps://github.com/shiwt03/UperFormer",
    "descriptor": "",
    "authors": [
      "Jing Xu",
      "Wentao Shi",
      "Pan Gao",
      "Zhengwei Wang",
      "Qizhu Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13928"
  },
  {
    "id": "arXiv:2211.13929",
    "title": "XKD: Cross-modal Knowledge Distillation with Domain Alignment for Video  Representation Learning",
    "abstract": "We present XKD, a novel self-supervised framework to learn meaningful\nrepresentations from unlabelled video clips. XKD is trained with two pseudo\ntasks. First, masked data reconstruction is performed to learn\nmodality-specific representations. Next, self-supervised cross-modal knowledge\ndistillation is performed between the two modalities through teacher-student\nsetups to learn complementary information. To identify the most effective\ninformation to transfer and also to tackle the domain gap between audio and\nvisual modalities which could hinder knowledge transfer, we introduce a domain\nalignment strategy for effective cross-modal distillation. Lastly, to develop a\ngeneral-purpose solution capable of handling both audio and visual streams, a\nmodality-agnostic variant of our proposed framework is introduced, which uses\nthe same backbone for both audio and visual modalities. Our proposed\ncross-modal knowledge distillation improves linear evaluation top-1 accuracy of\nvideo action classification by 8.4% on UCF101, 8.1% on HMDB51, 13.8% on\nKinetics-Sound, and 14.2% on Kinetics400. Additionally, our modality-agnostic\nvariant shows promising results in developing a general-purpose network capable\nof handling different data streams. The code is released on the project\nwebsite.",
    "descriptor": "",
    "authors": [
      "Pritam Sarkar",
      "Ali Etemad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13929"
  },
  {
    "id": "arXiv:2211.13930",
    "title": "TRAC: A Textual Benchmark for Reasoning about Actions and Change",
    "abstract": "Reasoning about actions and change (RAC) is essential to understand and\ninteract with the ever-changing environment. Previous AI research has shown the\nimportance of fundamental and indispensable knowledge of actions, i.e.,\npreconditions and effects. However, traditional methods rely on logical\nformalization which hinders practical applications. With recent\ntransformer-based language models (LMs), reasoning over text is desirable and\nseemingly feasible, leading to the question of whether LMs can effectively and\nefficiently learn to solve RAC problems. We propose four essential RAC tasks as\na comprehensive textual benchmark and generate problems in a way that minimizes\nthe influence of other linguistic requirements (e.g., grounding) to focus on\nRAC. The resulting benchmark, TRAC, encompassing problems of various\ncomplexities, facilitates a more granular evaluation of LMs, precisely\ntargeting the structural generalization ability much needed for RAC.\nExperiments with three high-performing transformers indicates that additional\nefforts are needed to tackle challenges raised by TRAC.",
    "descriptor": "",
    "authors": [
      "Weinan He",
      "Canming Huang",
      "Zhanhao Xiao",
      "Yongmei Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13930"
  },
  {
    "id": "arXiv:2211.13933",
    "title": "Enhanced Tracking and Beamforming Codebook Design for Wideband Terahertz  Massive MIMO System",
    "abstract": "True-time-delay (TTD) lines are recently applied inside Terahertz (THz)\nhybrid-precoding transceiver to acquire high beamforming gain against beam\nsquint effect. However, beam tracking turns into a challenging puzzle where\nenormous potential beam directions bring about unacceptable overhead\nconsumption. Frequency-scanning-based beam tracking is initially explored but\nstill imperfect in previous studies. In this paper, based on TTD-aided hybrid\nprecoding structure, we give an enhanced frequency-scanning-based tracking\nscheme. Multiple beams are generated and utilized simultaneously via several\nsubcarriers for tracking at one timeslot. The squint beams' angular coverage at\nall subcarriers can be flexibly controlled by two different subcarrier-angular\nmapping policies, named forward-pairing and backward-pairing. Then multiple\nphysical directions can be simultaneously searched in one timeslot for lower\noverhead consumption. Besides, closed-form searching radius bound, parameter\nconfiguration and interferences are theoretically analyzed. Furthermore, we\nprovide the coupled codebook design for TTDs and phase shifters (PSs), with\njoint consideration of both beamforming and tracking. Analytical and numerical\nresults demonstrate the superiority of the new frequency-scanning-based\ntracking scheme and beamforming codebook.",
    "descriptor": "\nComments: This work has been submitted to the IEEE journal for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Xu Shi",
      "Jintao Wang",
      "Jian Song"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.13933"
  },
  {
    "id": "arXiv:2211.13935",
    "title": "LU decomposition and Toeplitz decomposition of a neural network",
    "abstract": "It is well-known that any matrix $A$ has an LU decomposition. Less well-known\nis the fact that it has a 'Toeplitz decomposition' $A = T_1 T_2 \\cdots T_r$\nwhere $T_i$'s are Toeplitz matrices. We will prove that any continuous function\n$f : \\mathbb{R}^n \\to \\mathbb{R}^m$ has an approximation to arbitrary accuracy\nby a neural network that takes the form $L_1 \\sigma_1 U_1 \\sigma_2 L_2 \\sigma_3\nU_2 \\cdots L_r \\sigma_{2r-1} U_r$, i.e., where the weight matrices alternate\nbetween lower and upper triangular matrices, $\\sigma_i(x) := \\sigma(x - b_i)$\nfor some bias vector $b_i$, and the activation $\\sigma$ may be chosen to be\nessentially any uniformly continuous nonpolynomial function. The same result\nalso holds with Toeplitz matrices, i.e., $f \\approx T_1 \\sigma_1 T_2 \\sigma_2\n\\cdots \\sigma_{r-1} T_r$ to arbitrary accuracy, and likewise for Hankel\nmatrices. A consequence of our Toeplitz result is a fixed-width universal\napproximation theorem for convolutional neural networks, which so far have only\narbitrary width versions. Since our results apply in particular to the case\nwhen $f$ is a general neural network, we may regard them as LU and Toeplitz\ndecompositions of a neural network. The practical implication of our results is\nthat one may vastly reduce the number of weight parameters in a neural network\nwithout sacrificing its power of universal approximation. We will present\nseveral experiments on real data sets to show that imposing such structures on\nthe weight matrices sharply reduces the number of training parameters with\nalmost no noticeable effect on test accuracy.",
    "descriptor": "\nComments: 14 pages, 3 figures\n",
    "authors": [
      "Yucong Liu",
      "Simiao Jiao",
      "Lek-Heng Lim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.13935"
  },
  {
    "id": "arXiv:2211.13937",
    "title": "Operator Splitting Value Iteration",
    "abstract": "We introduce new planning and reinforcement learning algorithms for\ndiscounted MDPs that utilize an approximate model of the environment to\naccelerate the convergence of the value function. Inspired by the splitting\napproach in numerical linear algebra, we introduce Operator Splitting Value\nIteration (OS-VI) for both Policy Evaluation and Control problems. OS-VI\nachieves a much faster convergence rate when the model is accurate enough. We\nalso introduce a sample-based version of the algorithm called OS-Dyna. Unlike\nthe traditional Dyna architecture, OS-Dyna still converges to the correct value\nfunction in presence of model approximation error.",
    "descriptor": "\nComments: Accepted to NeurIPS2022\n",
    "authors": [
      "Amin Rakhsha",
      "Andrew Wang",
      "Mohammad Ghavamzadeh",
      "Amir-massoud Farahmand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.13937"
  },
  {
    "id": "arXiv:2211.13939",
    "title": "Efficient Incremental Text-to-Speech on GPUs",
    "abstract": "Incremental text-to-speech, also known as streaming TTS, has been\nincreasingly applied to online speech applications that require ultra-low\nresponse latency to provide an optimal user experience. However, most of the\nexisting speech synthesis pipelines deployed on GPU are still non-incremental,\nwhich uncovers limitations in high-concurrency scenarios, especially when the\npipeline is built with end-to-end neural network models. To address this issue,\nwe present a highly efficient approach to perform real-time incremental TTS on\nGPUs with Instant Request Pooling and Module-wise Dynamic Batching.\nExperimental results demonstrate that the proposed method is capable of\nproducing high-quality speech with a first-chunk latency lower than 80ms under\n100 QPS on a single NVIDIA A10 GPU and significantly outperforms the\nnon-incremental twin in both concurrency and latency. Our work reveals the\neffectiveness of high-performance incremental TTS on GPUs.",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Muyang Du",
      "Chuan Liu",
      "Jiaxing Qi",
      "Junjie Lai"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.13939"
  },
  {
    "id": "arXiv:2211.13940",
    "title": "Spatial-Temporal Attention Network for Open-Set Fine-Grained Image  Recognition",
    "abstract": "Triggered by the success of transformers in various visual tasks, the spatial\nself-attention mechanism has recently attracted more and more attention in the\ncomputer vision community. However, we empirically found that a typical vision\ntransformer with the spatial self-attention mechanism could not learn accurate\nattention maps for distinguishing different categories of fine-grained images.\nTo address this problem, motivated by the temporal attention mechanism in\nbrains, we propose a spatial-temporal attention network for learning\nfine-grained feature representations, called STAN, where the features learnt by\nimplementing a sequence of spatial self-attention operations corresponding to\nmultiple moments are aggregated progressively. The proposed STAN consists of\nfour modules: a self-attention backbone module for learning a sequence of\nfeatures with self-attention operations, a spatial feature self-organizing\nmodule for facilitating the model training, a spatial-temporal feature learning\nmodule for aggregating the re-organized features via a Long Short-Term Memory\nnetwork, and a context-aware module that is implemented as the forget block of\nthe spatial-temporal feature learning module for preserving/forgetting the\nlong-term memory by utilizing contextual information. Then, we propose a\nSTAN-based method for open-set fine-grained recognition by integrating the\nproposed STAN network with a linear classifier, called STAN-OSFGR. Extensive\nexperimental results on 3 fine-grained datasets and 2 coarse-grained datasets\ndemonstrate that the proposed STAN-OSFGR outperforms 9 state-of-the-art\nopen-set recognition methods significantly in most cases.",
    "descriptor": "",
    "authors": [
      "Jiayin Sun",
      "Hong Wang",
      "Qiulei Dong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13940"
  },
  {
    "id": "arXiv:2211.13941",
    "title": "Combinatorial Civic Crowdfunding with Budgeted Agents: Welfare  Optimality at Equilibrium and Optimal Deviation",
    "abstract": "Civic Crowdfunding (CC) uses the ``power of the crowd'' to garner\ncontributions towards public projects. As these projects are non-excludable,\nagents may prefer to ``free-ride,'' resulting in the project not being funded.\nFor single project CC, researchers propose to provide refunds to incentivize\nagents to contribute, thereby guaranteeing the project's funding. These funding\nguarantees are applicable only when agents have an unlimited budget. This work\nfocuses on a combinatorial setting, where multiple projects are available for\nCC and agents have a limited budget. We study certain specific conditions where\nfunding can be guaranteed. Further, funding the optimal social welfare subset\nof projects is desirable when every available project cannot be funded due to\nbudget restrictions. We prove the impossibility of achieving optimal welfare at\nequilibrium for any monotone refund scheme. We then study different heuristics\nthat the agents can use to contribute to the projects in practice. Through\nsimulations, we demonstrate the heuristics' performance as the average-case\ntrade-off between welfare obtained and agent utility.",
    "descriptor": "\nComments: To appear in the Proceedings of the Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI '23). A preliminary version of this paper titled \"Welfare Optimal Combinatorial Civic Crowdfunding with Budgeted Agents\" also appeared at GAIW@AAMAS '22\n",
    "authors": [
      "Sankarshan Damle",
      "Manisha Padala",
      "Sujit Gujar"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13941"
  },
  {
    "id": "arXiv:2211.13944",
    "title": "DMIS: Dynamic Mesh-based Importance Sampling for Training  Physics-Informed Neural Networks",
    "abstract": "Modeling dynamics in the form of partial differential equations (PDEs) is an\neffectual way to understand real-world physics processes. For complex physics\nsystems, analytical solutions are not available and numerical solutions are\nwidely-used. However, traditional numerical algorithms are computationally\nexpensive and challenging in handling multiphysics systems. Recently, using\nneural networks to solve PDEs has made significant progress, called\nphysics-informed neural networks (PINNs). PINNs encode physical laws into\nneural networks and learn the continuous solutions of PDEs. For the training of\nPINNs, existing methods suffer from the problems of inefficiency and unstable\nconvergence, since the PDE residuals require calculating automatic\ndifferentiation. In this paper, we propose Dynamic Mesh-based Importance\nSampling (DMIS) to tackle these problems. DMIS is a novel sampling scheme based\non importance sampling, which constructs a dynamic triangular mesh to estimate\nsample weights efficiently. DMIS has broad applicability and can be easily\nintegrated into existing methods. The evaluation of DMIS on three widely-used\nbenchmarks shows that DMIS improves the convergence speed and accuracy in the\nmeantime. Especially in solving the highly nonlinear Schr\\\"odinger Equation,\ncompared with state-of-the-art methods, DMIS shows up to 46% smaller root mean\nsquare error and five times faster convergence speed. Code are available at\nhttps://github.com/MatrixBrain/DMIS.",
    "descriptor": "\nComments: Accepted to AAAl-23\n",
    "authors": [
      "Zijiang Yang",
      "Zhongwei Qiu",
      "Dongmei Fu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.13944"
  },
  {
    "id": "arXiv:2211.13951",
    "title": "On picking sequences for chores",
    "abstract": "We consider the problem of allocating $m$ indivisible chores to $n$ agents\nwith additive disvaluation (cost) functions. It is easy to show that there are\npicking sequences that give every agent (that uses the greedy picking strategy)\na bundle of chores of disvalue at most twice her share value (maximin share,\nMMS, for agents of equal entitlement, and anyprice share, APS, for agents of\narbitrary entitlement). Aziz, Li and Wu (2022) designed picking sequences that\nimprove this ratio to $\\frac{5}{3}$ for the case of equal entitlement. We\ndesign picking sequences that improve the ratio to~1.733 for the case of\narbitrary entitlement, and to $\\frac{8}{5}$ for the case of equal entitlement.\n(In fact, computer assisted analysis suggests that the ratio is smaller than\n$1.543$ in the equal entitlement case.) We also prove a lower bound of\n$\\frac{3}{2}$ on the obtainable ratio when $n$ is sufficiently large.\nAdditional contributions of our work include improved guarantees in the equal\nentitlement case when $n$ is small; introduction of the chore share as a\nconvenient proxy to other share notions for chores; introduction of ex-ante\nnotions of envy for risk averse agents; enhancements to our picking sequences\nthat eliminate such envy; showing that a known allocation algorithm (not based\non picking sequences) for the equal entitlement case gives each agent a bundle\nof disvalue at most $\\frac{4n-1}{3n}$ times her APS (previously, this ratio was\nshown for this algorithm with respect to the easier benchmark of the MMS).",
    "descriptor": "",
    "authors": [
      "Uriel Feige",
      "Xin Huang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.13951"
  },
  {
    "id": "arXiv:2211.13952",
    "title": "On the Re-Solving Heuristic for (Binary) Contextual Bandits with  Knapsacks",
    "abstract": "In the problem of (binary) contextual bandits with knapsacks (CBwK), the\nagent receives an i.i.d. context in each of the $T$ rounds and chooses an\naction, resulting in a random reward and a random consumption of resources that\nare related to an i.i.d. external factor. The agent's goal is to maximize the\naccumulated reward under the initial resource constraints. In this work, we\ncombine the re-solving heuristic, which proved successful in revenue\nmanagement, with distribution estimation techniques to solve this problem. We\nconsider two different information feedback models, with full and partial\ninformation, which vary in the difficulty of getting a sample of the external\nfactor. Under both information feedback settings, we achieve two-way results:\n(1) For general problems, we show that our algorithm gets an $\\widetilde\nO(T^{\\alpha_u} + T^{\\alpha_v} + T^{1/2})$ regret against the fluid benchmark.\nHere, $\\alpha_u$ and $\\alpha_v$ reflect the complexity of the context and\nexternal factor distributions, respectively. This result is comparable to\nexisting results. (2) When the fluid problem is linear programming with a\nunique and non-degenerate optimal solution, our algorithm leads to an\n$\\widetilde O(1)$ regret. To the best of our knowledge, this is the first\n$\\widetilde O(1)$ regret result in the CBwK problem regardless of information\nfeedback models. We further use numerical experiments to verify our results.",
    "descriptor": "\nComments: 43 pages, 2 figures, 1 table\n",
    "authors": [
      "Rui Ai",
      "Zhaohua Chen",
      "Xiaotie Deng",
      "Yuqi Pan",
      "Chang Wang",
      "Mingwei Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13952"
  },
  {
    "id": "arXiv:2211.13955",
    "title": "MPCViT: Searching for MPC-friendly Vision Transformer with Heterogeneous  Attention",
    "abstract": "Secure multi-party computation (MPC) enables computation directly on\nencrypted data on non-colluding untrusted servers and protects both data and\nmodel privacy in deep learning inference. However, existing neural network (NN)\narchitectures, including Vision Transformers (ViTs), are not designed or\noptimized for MPC protocols and incur significant latency overhead due to the\nSoftmax function in the multi-head attention (MHA). In this paper, we propose\nan MPC-friendly ViT, dubbed MPCViT, to enable accurate yet efficient ViT\ninference in MPC. We systematically compare different attention variants in MPC\nand propose a heterogeneous attention search space, which combines the\nhigh-accuracy and MPC-efficient attentions with diverse structure\ngranularities. We further propose a simple yet effective differentiable neural\narchitecture search (NAS) algorithm for fast ViT optimization. MPCViT\nsignificantly outperforms prior-art ViT variants in MPC. With the proposed NAS\nalgorithm, our extensive experiments demonstrate that MPCViT achieves 7.9x and\n2.8x latency reduction with better accuracy compared to Linformer and MPCFormer\non the Tiny-ImageNet dataset, respectively. Further, with proper knowledge\ndistillation (KD), MPCViT even achieves 1.9% better accuracy compared to the\nbaseline ViT with 9.9x latency reduction on the Tiny-ImageNet dataset.",
    "descriptor": "\nComments: 6 pages, 6 figures\n",
    "authors": [
      "Wenxuan Zeng",
      "Meng Li",
      "Wenjie Xiong",
      "Wenjie Lu",
      "Jin Tan",
      "Runsheng Wang",
      "Ru Huang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13955"
  },
  {
    "id": "arXiv:2211.13956",
    "title": "Learning General Audio Representations with Large-Scale Training of  Patchout Audio Transformers",
    "abstract": "The success of supervised deep learning methods is largely due to their\nability to learn relevant features from raw data. Deep Neural Networks (DNNs)\ntrained on large-scale datasets are capable of capturing a diverse set of\nfeatures, and learning a representation that can generalize onto unseen tasks\nand datasets that are from the same domain. Hence, these models can be used as\npowerful feature extractors, in combination with shallower models as\nclassifiers, for smaller tasks and datasets where the amount of training data\nis insufficient for learning an end-to-end model from scratch. During the past\nyears, Convolutional Neural Networks (CNNs) have largely been the method of\nchoice for audio processing. However, recently attention-based transformer\nmodels have demonstrated great potential in supervised settings, outperforming\nCNNs. In this work, we investigate the use of audio transformers trained on\nlarge-scale datasets to learn general-purpose representations. We study how the\ndifferent setups in these audio transformers affect the quality of their\nembeddings. We experiment with the models' time resolution, extracted embedding\nlevel, and receptive fields in order to see how they affect performance on a\nvariety of tasks and datasets, following the HEAR 2021 NeurIPS challenge\nevaluation setup. Our results show that representations extracted by audio\ntransformers outperform CNN representations. Furthermore, we will show that\ntransformers trained on Audioset can be extremely effective representation\nextractors for a wide range of downstream tasks.",
    "descriptor": "\nComments: will apear in HEAR: Holistic Evaluation of Audio Representations Proceedings of Machine Learning Research PMLR 166. Source code: this https URL\n",
    "authors": [
      "Khaled Koutini",
      "Shahed Masoudian",
      "Florian Schmid",
      "Hamid Eghbal-zadeh",
      "Jan Schl\u00fcter",
      "Gerhard Widmer"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.13956"
  },
  {
    "id": "arXiv:2211.13958",
    "title": "Microarchitectural Leakage Templates and Their Application to  Cache-Based Side Channels",
    "abstract": "The complexity of modern processor architectures has given rise to\nsophisticated interactions among their components. Such interactions may result\nin potential attack vectors in terms of side channels, possibly available to\nuser-land exploits to leak secret data. Exploitation and countering of such\nside channels require a detailed understanding of the target component.\nHowever, such detailed information is commonly unpublished for many CPUs.\nIn this paper, we introduce the concept of Leakage Templates to abstractly\ndescribe specific side channels and identify their occurrences in binary\napplications. We design and implement Plumber, a framework to derive the\ngeneric Leakage Templates from individual code sequences that are known to\ncause leakage (e.g., found by prior work). Plumber uses a combination of\ninstruction fuzzing, instructions' operand mutation and statistical analysis to\nexplore undocumented behavior of microarchitectural optimizations and derive\nsufficient conditions on vulnerable code inputs that, if hold can trigger a\ndistinguishing behavior. Using Plumber we identified novel leakage primitives\nbased on Leakage Templates (for ARM Cortex-A53 and -A72 cores), in particular\nrelated to previction (a new premature cache eviction), and prefetching\nbehavior. We show the utility of Leakage Templates by re-identifying a\nprefetcher-based vulnerability in OpenSSL 1.1.0g first reported by Shin et al.\n[40].",
    "descriptor": "",
    "authors": [
      "Ahmad Ibrahim",
      "Hamed Nemati",
      "Till Schl\u00fcter",
      "Nils Ole Tippenhauer",
      "Christian Rossow"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.13958"
  },
  {
    "id": "arXiv:2211.13960",
    "title": "The European AI Liability Directives -- Critique of a Half-Hearted  Approach and Lessons for the Future",
    "abstract": "The optimal liability framework for AI systems remains an unsolved problem\nacross the globe. In a much-anticipated move, the European Commission advanced\ntwo proposals outlining the European approach to AI liability in September\n2022: a novel AI Liability Directive and a revision of the Product Liability\nDirective. They constitute the final, and much-anticipated, cornerstone of AI\nregulation in the EU. Crucially, the liability proposals and the EU AI Act are\ninherently intertwined: the latter does not contain any individual rights of\naffected persons, and the former lack specific, substantive rules on AI\ndevelopment and deployment. Taken together, these acts may well trigger a\nBrussels effect in AI regulation, with significant consequences for the US and\nother countries.\nThis paper makes three novel contributions. First, it examines in detail the\nCommission proposals and shows that, while making steps in the right direction,\nthey ultimately represent a half-hearted approach: if enacted as foreseen, AI\nliability in the EU will primarily rest on disclosure of evidence mechanisms\nand a set of narrowly defined presumptions concerning fault, defectiveness and\ncausality. Hence, second, the article suggests amendments, which are collected\nin an Annex at the end of the paper. Third, based on an analysis of the key\nrisks AI poses, the final part of the paper maps out a road for the future of\nAI liability and regulation, in the EU and beyond. This includes: a\ncomprehensive framework for AI liability; provisions to support innovation; an\nextension to non-discrimination/algorithmic fairness, as well as explainable\nAI; and sustainability. I propose to jump-start sustainable AI regulation via\nsustainability impact assessments in the AI Act and sustainable design defects\nin the liability regime. In this way, the law may help spur not only fair AI\nand XAI, but potentially also sustainable AI (SAI).",
    "descriptor": "\nComments: under peer-review; contains 3 Tables\n",
    "authors": [
      "Philipp Hacker"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13960"
  },
  {
    "id": "arXiv:2211.13962",
    "title": "Video on Demand Streaming Using RL-based Edge Caching in 5G Networks",
    "abstract": "Edge caching can significantly improve the 5G networks' performance both in\nterms of delay and backhaul traffic. We use a reinforcement learning-based\n(RL-based) caching technique that can adapt to time-location-dependent\npopularity patterns for on-demand video contents. In a private 5G, we implement\nthe proposed caching scheme as two virtual network functions (VNFs), edge and\nremote servers, and measure the cache hit ratio as a KPI. Combined with the HLS\nprotocol, the proposed video-on-demand (VoD) streaming is a reliable and\nscalable service that can adapt to content popularity.",
    "descriptor": "\nComments: 3 pages, 1 figure One page version of this paper has been accepted to 2022 IEEE Conference on Standards for Communications and Networking (CSCN) - Demo submissions\n",
    "authors": [
      "Rasoul Nikbakht",
      "Sarang Kahvazadeh",
      "Josep Mangues-Bafalluy"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.13962"
  },
  {
    "id": "arXiv:2211.13964",
    "title": "Generating 2D and 3D Master Faces for Dictionary Attacks with a  Network-Assisted Latent Space Evolution",
    "abstract": "A master face is a face image that passes face-based identity authentication\nfor a high percentage of the population. These faces can be used to\nimpersonate, with a high probability of success, any user, without having\naccess to any user information. We optimize these faces for 2D and 3D face\nverification models, by using an evolutionary algorithm in the latent embedding\nspace of the StyleGAN face generator. For 2D face verification, multiple\nevolutionary strategies are compared, and we propose a novel approach that\nemploys a neural network to direct the search toward promising samples, without\nadding fitness evaluations. The results we present demonstrate that it is\npossible to obtain a considerable coverage of the identities in the LFW or RFW\ndatasets with less than 10 master faces, for six leading deep face recognition\nsystems. In 3D, we generate faces using the 2D StyleGAN2 generator and predict\na 3D structure using a deep 3D face reconstruction network. When employing two\ndifferent 3D face recognition systems, we are able to obtain a coverage of\n40%-50%. Additionally, we present the generation of paired 2D RGB and 3D master\nfaces, which simultaneously match 2D and 3D models with high impersonation\nrates.",
    "descriptor": "\nComments: accepted for publication in IEEE Transactions on Biometrics, Behavior, and Identity Science (TBIOM). arXiv admin note: substantial text overlap with arXiv:2108.01077\n",
    "authors": [
      "Tomer Friedlander",
      "Ron Shmelkin",
      "Lior Wolf"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.13964"
  },
  {
    "id": "arXiv:2211.13968",
    "title": "MIAD: A Maintenance Inspection Dataset for Unsupervised Anomaly  Detection",
    "abstract": "Visual anomaly detection plays a crucial role in not only manufacturing\ninspection to find defects of products during manufacturing processes, but also\nmaintenance inspection to keep equipment in optimum working condition\nparticularly outdoors. Due to the scarcity of the defective samples,\nunsupervised anomaly detection has attracted great attention in recent years.\nHowever, existing datasets for unsupervised anomaly detection are biased\ntowards manufacturing inspection, not considering maintenance inspection which\nis usually conducted under outdoor uncontrolled environment such as varying\ncamera viewpoints, messy background and degradation of object surface after\nlong-term working. We focus on outdoor maintenance inspection and contribute a\ncomprehensive Maintenance Inspection Anomaly Detection (MIAD) dataset which\ncontains more than 100K high-resolution color images in various outdoor\nindustrial scenarios. This dataset is generated by a 3D graphics software and\ncovers both surface and logical anomalies with pixel-precise ground truth.\nExtensive evaluations of representative algorithms for unsupervised anomaly\ndetection are conducted, and we expect MIAD and corresponding experimental\nresults can inspire research community in outdoor unsupervised anomaly\ndetection tasks. Worthwhile and related future work can be spawned from our new\ndataset.",
    "descriptor": "",
    "authors": [
      "Tianpeng Bao",
      "Jiadong Chen",
      "Wei Li",
      "Xiang Wang",
      "Jingjing Fei",
      "Liwei Wu",
      "Rui Zhao",
      "Ye Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13968"
  },
  {
    "id": "arXiv:2211.13969",
    "title": "Unsupervised Continual Semantic Adaptation through Neural Rendering",
    "abstract": "An increasing amount of applications rely on data-driven models that are\ndeployed for perception tasks across a sequence of scenes. Due to the mismatch\nbetween training and deployment data, adapting the model on the new scenes is\noften crucial to obtain good performance. In this work, we study continual\nmulti-scene adaptation for the task of semantic segmentation, assuming that no\nground-truth labels are available during deployment and that performance on the\nprevious scenes should be maintained. We propose training a Semantic-NeRF\nnetwork for each scene by fusing the predictions of a segmentation model and\nthen using the view-consistent rendered semantic labels as pseudo-labels to\nadapt the model. Through joint training with the segmentation model, the\nSemantic-NeRF model effectively enables 2D-3D knowledge transfer. Furthermore,\ndue to its compact size, it can be stored in a long-term memory and\nsubsequently used to render data from arbitrary viewpoints to reduce\nforgetting. We evaluate our approach on ScanNet, where we outperform both a\nvoxel-based baseline and a state-of-the-art unsupervised domain adaptation\nmethod.",
    "descriptor": "\nComments: Zhizheng Liu and Francesco Milano share first authorship. Hermann Blum and Cesar Cadena share senior authorship. 18 pages, 7 figures, 10 tables\n",
    "authors": [
      "Zhizheng Liu",
      "Francesco Milano",
      "Jonas Frey",
      "Marco Hutter",
      "Roland Siegwart",
      "Hermann Blum",
      "Cesar Cadena"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.13969"
  },
  {
    "id": "arXiv:2211.13972",
    "title": "Picking on the Same Person: Does Algorithmic Monoculture lead to Outcome  Homogenization?",
    "abstract": "As the scope of machine learning broadens, we observe a recurring theme of\nalgorithmic monoculture: the same systems, or systems that share components\n(e.g. training data), are deployed by multiple decision-makers. While sharing\noffers clear advantages (e.g. amortizing costs), does it bear risks? We\nintroduce and formalize one such risk, outcome homogenization: the extent to\nwhich particular individuals or groups experience negative outcomes from all\ndecision-makers. If the same individuals or groups exclusively experience\nundesirable outcomes, this may institutionalize systemic exclusion and\nreinscribe social hierarchy. To relate algorithmic monoculture and outcome\nhomogenization, we propose the component-sharing hypothesis: if decision-makers\nshare components like training data or specific models, then they will produce\nmore homogeneous outcomes. We test this hypothesis on algorithmic fairness\nbenchmarks, demonstrating that sharing training data reliably exacerbates\nhomogenization, with individual-level effects generally exceeding group-level\neffects. Further, given the dominant paradigm in AI of foundation models, i.e.\nmodels that can be adapted for myriad downstream tasks, we test whether model\nsharing homogenizes outcomes across tasks. We observe mixed results: we find\nthat for both vision and language settings, the specific methods for adapting a\nfoundation model significantly influence the degree of outcome homogenization.\nWe conclude with philosophical analyses of and societal challenges for outcome\nhomogenization, with an eye towards implications for deployed machine learning\nsystems.",
    "descriptor": "\nComments: Published at NeurIPS 2022, presented at EAAMO 2022\n",
    "authors": [
      "Rishi Bommasani",
      "Kathleen A. Creel",
      "Ananya Kumar",
      "Dan Jurafsky",
      "Percy Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.13972"
  },
  {
    "id": "arXiv:2211.13974",
    "title": "ILSGAN: Independent Layer Synthesis for Unsupervised  Foreground-Background Segmentation",
    "abstract": "Unsupervised foreground-background segmentation aims at extracting salient\nobjects from cluttered backgrounds, where Generative Adversarial Network (GAN)\napproaches, especially layered GANs, show great promise. However, without human\nannotations, they are typically prone to produce foreground and background\nlayers with non-negligible semantic and visual confusion, dubbed ``information\nleakage\", resulting in notable degeneration of the generated segmentation mask.\nTo alleviate this issue, we propose a simple-yet-effective explicit layer\nindependence modeling approach, termed Independent Layer Synthesis GAN\n(ILSGAN), pursuing independent foreground-background layer generation by\nencouraging their discrepancy. Specifically, it targets minimizing the mutual\ninformation between visible and invisible regions of the foreground and\nbackground to spur interlayer independence. Through in-depth theoretical and\nexperimental analyses, we justify that explicit layer independence modeling is\ncritical to suppressing information leakage and contributes to impressive\nsegmentation performance gains. Also, our ILSGAN achieves strong\nstate-of-the-art generation quality and segmentation performance on complex\nreal-world data. The code is available in the supplementary material.",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Qiran Zou",
      "Yu Yang",
      "Wing Yin Cheung",
      "Chang Liu",
      "Xiangyang Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13974"
  },
  {
    "id": "arXiv:2211.13975",
    "title": "Federated Graph-based Sampling with Arbitrary Client Availability",
    "abstract": "While federated learning has shown strong results in optimizing a machine\nlearning model without direct access to the original data, its performance may\nbe hindered by intermittent client availability which slows down the\nconvergence and biases the final learned model. There are significant\nchallenges to achieve both stable and bias-free training under arbitrary client\navailability. To address these challenges, we propose a framework named\nFederated Graph-based Sampling (FedGS), to stabilize the global model update\nand mitigate the long-term bias given arbitrary client availability\nsimultaneously. First, we model the data correlations of clients with a\nData-Distribution-Dependency Graph (3DG) that helps keep the sampled clients\ndata apart from each other, which is theoretically shown to improve the\napproximation to the optimal model update. Second, constrained by the\nfar-distance in data distribution of the sampled clients, we further minimize\nthe variance of the numbers of times that the clients are sampled, to mitigate\nlong-term bias. To validate the effectiveness of FedGS, we conduct experiments\non three datasets under a comprehensive set of seven client availability modes.\nOur experimental results confirm FedGS's advantage in both enabling a fair\nclient-sampling scheme and improving the model performance under arbitrary\nclient availability. Our code is available at\n\\url{https://github.com/WwZzz/FedGS}.",
    "descriptor": "",
    "authors": [
      "Zheng Wang",
      "Xiaoliang Fan",
      "Jianzhong Qi",
      "Haibing Jin",
      "Peizhen Yang",
      "Siqi Shen",
      "Cheng Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13975"
  },
  {
    "id": "arXiv:2211.13976",
    "title": "Expanding Small-Scale Datasets with Guided Imagination",
    "abstract": "The power of Deep Neural Networks (DNNs) depends heavily on the training data\nquantity, quality and diversity. However, in many real scenarios, it is costly\nand time-consuming to collect and annotate large-scale data. This has severely\nhindered the application of DNNs. To address this challenge, we explore a new\ntask of dataset expansion, which seeks to automatically create new labeled\nsamples to expand a small dataset. To this end, we present a Guided Imagination\nFramework (GIF) that leverages the recently developed big generative models\n(e.g., DALL-E2) and reconstruction models (e.g., MAE) to \"imagine\" and create\ninformative new data from seed data to expand small datasets. Specifically, GIF\nconducts imagination by optimizing the latent features of seed data in a\nsemantically meaningful space, which are fed into the generative models to\ngenerate photo-realistic images with new contents. For guiding the imagination\ntowards creating samples useful for model training, we exploit the zero-shot\nrecognition ability of CLIP and introduce three criteria to encourage\ninformative sample generation, i.e., prediction consistency, entropy\nmaximization and diversity promotion. With these essential criteria as\nguidance, GIF works well for expanding datasets in different domains, leading\nto 29.9% accuracy gain on average over six natural image datasets, and 12.3%\naccuracy gain on average over three medical image datasets.",
    "descriptor": "",
    "authors": [
      "Yifan Zhang",
      "Daquan Zhou",
      "Bryan Hooi",
      "Kai Wang",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13976"
  },
  {
    "id": "arXiv:2211.13977",
    "title": "CLIP-ReID: Exploiting Vision-Language Model for Image Re-Identification  without Concrete Text Labels",
    "abstract": "Pre-trained vision-language models like CLIP have recently shown superior\nperformances on various downstream tasks, including image classification and\nsegmentation. However, in fine-grained image re-identification (ReID), the\nlabels are indexes, lacking concrete text descriptions. Therefore, it remains\nto be determined how such models could be applied to these tasks. This paper\nfirst finds out that simply fine-tuning the visual model initialized by the\nimage encoder in CLIP, has already obtained competitive performances in various\nReID tasks. Then we propose a two-stage strategy to facilitate a better visual\nrepresentation. The key idea is to fully exploit the cross-modal description\nability in CLIP through a set of learnable text tokens for each ID and give\nthem to the text encoder to form ambiguous descriptions. In the first training\nstage, image and text encoders from CLIP keep fixed, and only the text tokens\nare optimized from scratch by the contrastive loss computed within a batch. In\nthe second stage, the ID-specific text tokens and their encoder become static,\nproviding constraints for fine-tuning the image encoder. With the help of the\ndesigned loss in the downstream task, the image encoder is able to represent\ndata as vectors in the feature embedding accurately. The effectiveness of the\nproposed strategy is validated on several datasets for the person or vehicle\nReID tasks. Code is available at https://github.com/Syliz517/CLIP-ReID.",
    "descriptor": "",
    "authors": [
      "Siyuan Li",
      "Li Sun",
      "Qingli Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13977"
  },
  {
    "id": "arXiv:2211.13979",
    "title": "BatmanNet: Bi-branch Masked Graph Transformer Autoencoder for Molecular  Representation",
    "abstract": "Although substantial efforts have been made using graph neural networks\n(GNNs) for AI-driven drug discovery (AIDD), effective molecular representation\nlearning remains an open challenge, especially in the case of insufficient\nlabeled molecules. Recent studies suggest that big GNN models pre-trained by\nself-supervised learning on unlabeled datasets enable better transfer\nperformance in downstream molecular property prediction tasks. However, they\noften require large-scale datasets and considerable computational resources,\nwhich is time-consuming, computationally expensive, and environmentally\nunfriendly. To alleviate these limitations, we propose a novel pre-training\nmodel for molecular representation learning, Bi-branch Masked Graph Transformer\nAutoencoder (BatmanNet). BatmanNet features two tailored and complementary\ngraph autoencoders to reconstruct the missing nodes and edges from a masked\nmolecular graph. To our surprise, BatmanNet discovered that the highly masked\nproportion (60%) of the atoms and bonds achieved the best performance. We\nfurther propose an asymmetric graph-based encoder-decoder architecture for\neither nodes and edges, where a transformer-based encoder only takes the\nvisible subset of nodes or edges, and a lightweight decoder reconstructs the\noriginal molecule from the latent representation and mask tokens. With this\nsimple yet effective asymmetrical design, our BatmanNet can learn efficiently\neven from a much smaller-scale unlabeled molecular dataset to capture the\nunderlying structural and semantic information, overcoming a major limitation\nof current deep neural networks for molecular representation learning. For\ninstance, using only 250K unlabelled molecules as pre-training data, our\nBatmanNet with 2.575M parameters achieves a 0.5% improvement on the average AUC\ncompared with the current state-of-the-art method with 100M parameters\npre-trained on 11M molecules.",
    "descriptor": "\nComments: 11 pages, 3 figures\n",
    "authors": [
      "Zhen Wang",
      "Zheng Feng",
      "Yanjun Li",
      "Bowen Li",
      "Yongrui Wang",
      "Chulin Sha",
      "Min He",
      "Xiaolin Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2211.13979"
  },
  {
    "id": "arXiv:2211.13980",
    "title": "Sparse Hamming Graph: A Customizable Network-on-Chip Topology",
    "abstract": "Chips with hundreds to thousands of cores require scalable networks-on-chip\n(NoCs). Customization of the NoC topology is necessary to reach the diverse\ndesign goals of different chips. We introduce sparse Hamming graph, a novel NoC\ntopology with an adjustable costperformance trade-off that is based on four NoC\ntopology design principles we identified. To efficiently customize this\ntopology, we develop a toolchain that leverages approximate floorplanning and\nlink routing to deliver fast and accurate cost and performance predictions. We\ndemonstrate how to use our methodology to achieve desired cost-performance\ntrade-offs while outperforming established topologies in cost, performance, or\nboth.",
    "descriptor": "",
    "authors": [
      "Patrick Iff",
      "Maciej Besta",
      "Matheus Cavalcante",
      "Tim Fischer",
      "Luca Benini",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.13980"
  },
  {
    "id": "arXiv:2211.13984",
    "title": "Aggregated Text Transformer for Scene Text Detection",
    "abstract": "This paper explores the multi-scale aggregation strategy for scene text\ndetection in natural images. We present the Aggregated Text TRansformer(ATTR),\nwhich is designed to represent texts in scene images with a multi-scale\nself-attention mechanism. Starting from the image pyramid with multiple\nresolutions, the features are first extracted at different scales with shared\nweight and then fed into an encoder-decoder architecture of Transformer. The\nmulti-scale image representations are robust and contain rich information on\ntext contents of various sizes. The text Transformer aggregates these features\nto learn the interaction across different scales and improve text\nrepresentation. The proposed method detects scene texts by representing each\ntext instance as an individual binary mask, which is tolerant of curve texts\nand regions with dense instances. Extensive experiments on public scene text\ndetection datasets demonstrate the effectiveness of the proposed framework.",
    "descriptor": "",
    "authors": [
      "Zhao Zhou",
      "Xiangcheng Du",
      "Yingbin Zheng",
      "Cheng Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13984"
  },
  {
    "id": "arXiv:2211.13989",
    "title": "HexaMesh: Scaling to Hundreds of Chiplets with an Optimized Chiplet  Arrangement",
    "abstract": "2.5D integration is an important technique to tackle the growing cost of\nmanufacturing chips in advanced technology nodes. This poses the challenge of\nproviding high-performance inter-chiplet interconnects (ICIs). As the number of\nchiplets grows to tens or hundreds, it becomes infeasible to hand-optimize\ntheir arrangement in a way that maximizes the ICI performance. In this paper,\nwe propose HexaMesh, an arrangement of chiplets that outperforms a grid\narrangement both in theory (network diameter reduced by 42%; bisection\nbandwidth improved by 130%) and in practice (latency reduced by 19%; throughput\nimproved by 34%). MexaMesh enables large-scale chiplet designs with\nhigh-performance ICIs.",
    "descriptor": "",
    "authors": [
      "Patrick Iff",
      "Maciej Besta",
      "Matheus Cavalcante",
      "Tim Fischer",
      "Luca Benini",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.13989"
  },
  {
    "id": "arXiv:2211.13990",
    "title": "Quantum Software Engineering: A New Genre of Computing",
    "abstract": "Quantum computing (QC) is no longer only a scientific interest but is rapidly\nbecoming an industrially available technology that can potentially tackle the\nlimitations of classical computing. Over the last few years, major technology\ngiants have invested in developing hardware and programming frameworks to\ndevelop quantum-specific applications. QC hardware technologies are gaining\nmomentum, however, operationalizing the QC technologies trigger the need for\nsoftware-intensive methodologies, techniques, processes, tools, roles, and\nresponsibilities for developing industrial-centric quantum software\napplications. This paper presents the vision of the quantum software\nengineering (QSE) life cycle consisting of quantum requirements engineering,\nquantum software design, quantum software implementation, quantum software\ntesting, and quantum software maintenance. This paper particularly calls for\njoint contributions of software engineering research and industrial community\nto present real-world solutions to support the entire quantum software\ndevelopment activities. The proposed vision facilitates the researchers and\npractitioners to propose new processes, reference architectures, novel tools,\nand practices to leverage quantum computers and develop emerging and next\ngenerations of quantum software.",
    "descriptor": "",
    "authors": [
      "Muhammad Azeem Akbar",
      "Arif Ali Khan",
      "Sajjad Mahmood",
      "Saima Rafi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.13990"
  },
  {
    "id": "arXiv:2211.13991",
    "title": "TrustGAN: Training safe and trustworthy deep learning models through  generative adversarial networks",
    "abstract": "Deep learning models have been developed for a variety of tasks and are\ndeployed every day to work in real conditions. Some of these tasks are critical\nand models need to be trusted and safe, e.g. military communications or cancer\ndiagnosis. These models are given real data, simulated data or combination of\nboth and are trained to be highly predictive on them. However, gathering enough\nreal data or simulating them to be representative of all the real conditions\nis: costly, sometimes impossible due to confidentiality and most of the time\nimpossible. Indeed, real conditions are constantly changing and sometimes are\nintractable. A solution is to deploy machine learning models that are able to\ngive predictions when they are confident enough otherwise raise a flag or\nabstain. One issue is that standard models easily fail at detecting\nout-of-distribution samples where their predictions are unreliable.\nWe present here TrustGAN, a generative adversarial network pipeline targeting\ntrustness. It is a deep learning pipeline which improves a target model\nestimation of the confidence without impacting its predictive power. The\npipeline can accept any given deep learning model which outputs a prediction\nand a confidence on this prediction. Moreover, the pipeline does not need to\nmodify this target model. It can thus be easily deployed in a MLOps (Machine\nLearning Operations) setting.\nThe pipeline is applied here to a target classification model trained on\nMNIST data to recognise numbers based on images. We compare such a model when\ntrained in the standard way and with TrustGAN. We show that on\nout-of-distribution samples, here FashionMNIST and CIFAR10, the estimated\nconfidence is largely reduced. We observe similar conclusions for a\nclassification model trained on 1D radio signals from AugMod, tested on\nRML2016.04C. We also publicly release the code.",
    "descriptor": "\nComments: 8 pages, 6 figures, 1 table, presented at CAID 2022: Conference on Artificial Intelligence for Defence\n",
    "authors": [
      "H\u00e9lion du Mas des Bourboux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13991"
  },
  {
    "id": "arXiv:2211.13993",
    "title": "Combating noisy labels in object detection datasets",
    "abstract": "The quality of training datasets for deep neural networks is a key factor\ncontributing to the accuracy of resulting models. This is even more important\nin difficult tasks such as object detection. Dealing with errors in these\ndatasets was in the past limited to accepting that some fraction of examples is\nincorrect or predicting their confidence and assigning appropriate weights\nduring training. In this work, we propose a different approach. For the first\ntime, we extended the confident learning algorithm to the object detection\ntask. By focusing on finding incorrect labels in the original training\ndatasets, we can eliminate erroneous examples in their root. Suspicious\nbounding boxes can be re-annotated in order to improve the quality of the\ndataset itself, thus leading to better models without complicating their\nalready complex architectures. We can effectively point out 99\\% of\nartificially disturbed bounding boxes with FPR below 0.3. We see this method as\na promising path to correcting well-known object detection datasets.",
    "descriptor": "\nComments: 10 pages, 8 figures, submitted to CVPR 2023 Conference\n",
    "authors": [
      "Krystian Chachu\u0142a",
      "Adam Popowicz",
      "Jakub \u0141yskawa",
      "Bart\u0142omiej Olber",
      "Piotr Fr\u0105tczak",
      "Krystian Radlak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13993"
  },
  {
    "id": "arXiv:2211.13994",
    "title": "Dynamic Neural Portraits",
    "abstract": "We present Dynamic Neural Portraits, a novel approach to the problem of\nfull-head reenactment. Our method generates photo-realistic video portraits by\nexplicitly controlling head pose, facial expressions and eye gaze. Our proposed\narchitecture is different from existing methods that rely on GAN-based\nimage-to-image translation networks for transforming renderings of 3D faces\ninto photo-realistic images. Instead, we build our system upon a 2D\ncoordinate-based MLP with controllable dynamics. Our intuition to adopt a\n2D-based representation, as opposed to recent 3D NeRF-like systems, stems from\nthe fact that video portraits are captured by monocular stationary cameras,\ntherefore, only a single viewpoint of the scene is available. Primarily, we\ncondition our generative model on expression blendshapes, nonetheless, we show\nthat our system can be successfully driven by audio features as well. Our\nexperiments demonstrate that the proposed method is 270 times faster than\nrecent NeRF-based reenactment methods, with our networks achieving speeds of 24\nfps for resolutions up to 1024 x 1024, while outperforming prior works in terms\nof visual quality.",
    "descriptor": "\nComments: In IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023\n",
    "authors": [
      "Michail Christos Doukas",
      "Stylianos Ploumpis",
      "Stefanos Zafeiriou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13994"
  },
  {
    "id": "arXiv:2211.13995",
    "title": "Mobile Edge Vertical Applications Using ETSI MEC APIs and Sandbox",
    "abstract": "MEC Sandbox is an excellent tool that simulates wireless networks and deploys\nETSI Multi-access Edge Computing (MEC) APIs on top of the simulated wireless\nnetwork. In this demo, we consume these APIs using a decision engine (DE) to\nscale a video-on-demand (VoD) application located on the network edge, assuming\nthat the average number of users is a good proxy of the demand. Specifically,\nthe developed DE uses the ETSI MEC Location API and retrieves the number of\nusers in a given zone. The DE then takes actions at the microservice scaling\nlevel and executes them through a custom-made Kubernetes-based OpenAPI.",
    "descriptor": "\nComments: A one-page version of this paper is accepted in the 2022 IEEE Conference on Standards for Communications and Networking(CSCN)-Demo submissions\n",
    "authors": [
      "Rasoul Nikbakht",
      "Michail Dalgitsis",
      "Sergio Barrachina-Mu\u00f1oz",
      "Sarang Kahvazadeh"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.13995"
  },
  {
    "id": "arXiv:2211.13996",
    "title": "A Vision of DevOps Requirements Change Management Standardization",
    "abstract": "DevOps (development and operations) aims to shorten the software development\nprocess and provide continuous delivery with high software quality. To get the\npotential gains of DevOps, the software development industry considering global\nsoftware development (GSD) environment to hire skilled human resources and\nround-the-clock working hours. However, due to the lack of frequent\ncommunication and coordination in GSD, the planning and managing of the\nrequirements change process becomes a challenging task. As in DevOps,\nrequirements are not only shaped by development feedback but also by the\noperations team. This means requirements affect development, development\naffects operations and operations affect requirements. However, DevOps in GSD\nstill faces many challenges in terms of requirement management. The purpose of\nthis research project is to develop a DevOps requirement change management and\nimplementation maturity model (DevOps-RCMIMM) that could assist the GSD\norganizations in modifying and improving their requirement management process\nin the DevOps process. The development of DevOps-RCMIMM will be based on the\nexisting DevOps and RCM literature, industrial empirical study, and\nunderstanding of factors that could impact the implementation of the DevOps\nrequirement change management process in the domain of GSD. This vision study\npresents the initial results of a systematic literature review that will\ncontribute to the development of maturity levels of the proposed DevOps-RCMIMM.",
    "descriptor": "",
    "authors": [
      "Muhammad Azeem Akbar",
      "Arif Ali Khan",
      "Sajjad Mahmood",
      "Saima Rafi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.13996"
  },
  {
    "id": "arXiv:2211.13999",
    "title": "CoMFormer: Continual Learning in Semantic and Panoptic Segmentation",
    "abstract": "Continual learning for segmentation has recently seen increasing interest.\nHowever, all previous works focus on narrow semantic segmentation and disregard\npanoptic segmentation, an important task with real-world impacts. %a In this\npaper, we present the first continual learning model capable of operating on\nboth semantic and panoptic segmentation. Inspired by recent transformer\napproaches that consider segmentation as a mask-classification problem, we\ndesign CoMFormer. Our method carefully exploits the properties of transformer\narchitectures to learn new classes over time. Specifically, we propose a novel\nadaptive distillation loss along with a mask-based pseudo-labeling technique to\neffectively prevent forgetting. To evaluate our approach, we introduce a novel\ncontinual panoptic segmentation benchmark on the challenging ADE20K dataset.\nOur CoMFormer outperforms all the existing baselines by forgetting less old\nclasses but also learning more effectively new classes. In addition, we also\nreport an extensive evaluation in the large-scale continual semantic\nsegmentation scenario showing that CoMFormer also significantly outperforms\nstate-of-the-art methods.",
    "descriptor": "\nComments: Under submission\n",
    "authors": [
      "Fabio Cermelli",
      "Matthieu Cord",
      "Arthur Douillard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13999"
  },
  {
    "id": "arXiv:2211.14003",
    "title": "Assistive Teaching of Motor Control Tasks to Humans",
    "abstract": "Recent works on shared autonomy and assistive-AI technologies, such as\nassistive robot teleoperation, seek to model and help human users with limited\nability in a fixed task. However, these approaches often fail to account for\nhumans' ability to adapt and eventually learn how to execute a control task\nthemselves. Furthermore, in applications where it may be desirable for a human\nto intervene, these methods may inhibit their ability to learn how to succeed\nwith full self-control. In this paper, we focus on the problem of assistive\nteaching of motor control tasks such as parking a car or landing an aircraft.\nDespite their ubiquitous role in humans' daily activities and occupations,\nmotor tasks are rarely taught in a uniform way due to their high complexity and\nvariance. We propose an AI-assisted teaching algorithm that leverages skill\ndiscovery methods from reinforcement learning (RL) to (i) break down any motor\ncontrol task into teachable skills, (ii) construct novel drill sequences, and\n(iii) individualize curricula to students with different capabilities. Through\nan extensive mix of synthetic and user studies on two motor control tasks --\nparking a car with a joystick and writing characters from the Balinese alphabet\n-- we show that assisted teaching with skills improves student performance by\naround 40% compared to practicing full trajectories without skills, and\npracticing with individualized drills can result in up to 25% further\nimprovement. Our source code is available at\nhttps://github.com/Stanford-ILIAD/teaching",
    "descriptor": "\nComments: 22 pages, 14 figures, NeurIPS 2022\n",
    "authors": [
      "Megha Srivastava",
      "Erdem Biyik",
      "Suvir Mirchandani",
      "Noah Goodman",
      "Dorsa Sadigh"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.14003"
  },
  {
    "id": "arXiv:2211.14005",
    "title": "Efficient Feature Extraction for High-resolution Video Frame  Interpolation",
    "abstract": "Most deep learning methods for video frame interpolation consist of three\nmain components: feature extraction, motion estimation, and image synthesis.\nExisting approaches are mainly distinguishable in terms of how these modules\nare designed. However, when interpolating high-resolution images, e.g. at 4K,\nthe design choices for achieving high accuracy within reasonable memory\nrequirements are limited. The feature extraction layers help to compress the\ninput and extract relevant information for the latter stages, such as motion\nestimation. However, these layers are often costly in parameters, computation\ntime, and memory. We show how ideas from dimensionality reduction combined with\na lightweight optimization can be used to compress the input representation\nwhile keeping the extracted information suitable for frame interpolation.\nFurther, we require neither a pretrained flow network nor a synthesis network,\nadditionally reducing the number of trainable parameters and required memory.\nWhen evaluating on three 4K benchmarks, we achieve state-of-the-art image\nquality among the methods without pretrained flow while having the lowest\nnetwork complexity and memory requirements overall.",
    "descriptor": "\nComments: Accepted to BMVC 2022. Code: this https URL\n",
    "authors": [
      "Moritz Nottebaum",
      "Stefan Roth",
      "Simone Schaub-Meyer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14005"
  },
  {
    "id": "arXiv:2211.14009",
    "title": "A Flux-Differencing Formula for Split-Form Summation By Parts  Discretizations of Non-Conservative Systems: Applications to Subcell Limiting  for magneto-hydrodynamics",
    "abstract": "In this paper, we show that diagonal-norm summation by parts (SBP)\ndiscretizations of general non-conservative systems of hyperbolic balance laws\ncan be rewritten as a finite-volume-type formula, also known as\nflux-differencing formula, if the non-conservative terms can be written as the\nproduct of a local and a symmetric contribution. Furthermore, we show that the\nexistence of a flux-differencing formula enables the use of recent subcell\nlimiting strategies to improve the robustness of the high-order\ndiscretizations.\nTo demonstrate the utility of the novel flux-differencing formula, we\nconstruct hybrid schemes that combine high-order SBP methods (the discontinuous\nGalerkin spectral element method and a high-order SBP finite difference method)\nwith a compatible low-order finite volume (FV) scheme at the subcell level. We\napply the hybrid schemes to solve challenging magnetohydrodynamics (MHD)\nproblems featuring strong shocks.",
    "descriptor": "",
    "authors": [
      "Andr\u00e9s M Rueda-Ram\u00edrez",
      "Gregor J Gassner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.14009"
  },
  {
    "id": "arXiv:2211.14013",
    "title": "Collection and Evaluation of a Long-Term 4D Agri-Robotic Dataset",
    "abstract": "Long-term autonomy is one of the most demanded capabilities looked into a\nrobot. The possibility to perform the same task over and over on a long\ntemporal horizon, offering a high standard of reproducibility and robustness,\nis appealing. Long-term autonomy can play a crucial role in the adoption of\nrobotics systems for precision agriculture, for example in assisting humans in\nmonitoring and harvesting crops in a large orchard. With this scope in mind, we\nreport an ongoing effort in the long-term deployment of an autonomous mobile\nrobot in a vineyard for data collection across multiple months. The main aim is\nto collect data from the same area at different points in time so to be able to\nanalyse the impact of the environmental changes in the mapping and localisation\ntasks. In this work, we present a map-based localisation study taking 4 data\nsessions. We identify expected failures when the pre-built map visually differs\nfrom the environment's current appearance and we anticipate LTS-Net, a solution\npointed at extracting stable temporal features for improving long-term 4D\nlocalisation results.",
    "descriptor": "\nComments: Presented at the \"Perception and Navigation for Autonomous Robotics in Unstructured and Dynamic Environments\" (PNARUDE) Workshop at IROS 22\n",
    "authors": [
      "Riccardo Polvara",
      "Sergi Molina Mellado",
      "Ibrahim Hroob",
      "Grzegorz Cielniak",
      "Marc Hanheide"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14013"
  },
  {
    "id": "arXiv:2211.14016",
    "title": "Strategic Facility Location with Clients that Minimize Total Waiting  Time",
    "abstract": "We study a non-cooperative two-sided facility location game in which\nfacilities and clients behave strategically. This is in contrast to many other\nfacility location games in which clients simply visit their closest facility.\nFacility agents select a location on a graph to open a facility to attract as\nmuch purchasing power as possible, while client agents choose which facilities\nto patronize by strategically distributing their purchasing power in order to\nminimize their total waiting time. Here, the waiting time of a facility depends\non its received total purchasing power. We show that our client stage is an\natomic splittable congestion game, which implies existence, uniqueness and\nefficient computation of a client equilibrium. Therefore, facility agents can\nefficiently predict client behavior and make strategic decisions accordingly.\nDespite that, we prove that subgame perfect equilibria do not exist in all\ninstances of this game and that their existence is NP-hard to decide. On the\npositive side, we provide a simple and efficient algorithm to compute\n3-approximate subgame perfect equilibria.",
    "descriptor": "\nComments: To appear at the 37th AAAI Conference on Artificial Intelligence (AAAI-23), full version\n",
    "authors": [
      "Simon Krogmann",
      "Pascal Lenzner",
      "Alexander Skopalik"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14016"
  },
  {
    "id": "arXiv:2211.14017",
    "title": "Learnable Blur Kernel for Single-Image Defocus Deblurring in the Wild",
    "abstract": "Recent research showed that the dual-pixel sensor has made great progress in\ndefocus map estimation and image defocus deblurring. However, extracting\nreal-time dual-pixel views is troublesome and complex in algorithm deployment.\nMoreover, the deblurred image generated by the defocus deblurring network lacks\nhigh-frequency details, which is unsatisfactory in human perception. To\novercome this issue, we propose a novel defocus deblurring method that uses the\nguidance of the defocus map to implement image deblurring. The proposed method\nconsists of a learnable blur kernel to estimate the defocus map, which is an\nunsupervised method, and a single-image defocus deblurring generative\nadversarial network (DefocusGAN) for the first time. The proposed network can\nlearn the deblurring of different regions and recover realistic details. We\npropose a defocus adversarial loss to guide this training process. Competitive\nexperimental results confirm that with a learnable blur kernel, the generated\ndefocus map can achieve results comparable to supervised methods. In the\nsingle-image defocus deblurring task, the proposed method achieves\nstate-of-the-art results, especially significant improvements in perceptual\nquality, where PSNR reaches 25.56 dB and LPIPS reaches 0.111.",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Jucai Zhai",
      "Pengcheng Zeng",
      "Chihao Ma",
      "Yong Zhao",
      "Jie Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.14017"
  },
  {
    "id": "arXiv:2211.14020",
    "title": "SCOOP: Self-Supervised Correspondence and Optimization-Based Scene Flow",
    "abstract": "Scene flow estimation is a long-standing problem in computer vision, where\nthe goal is to find the 3D motion of a scene from its consecutive observations.\nRecently, there have been efforts to compute the scene flow from 3D point\nclouds. A common approach is to train a regression model that consumes source\nand target point clouds and outputs the per-point translation vectors. An\nalternative is to learn point matches between the point clouds concurrently\nwith regressing a refinement of the initial correspondence flow. In both cases,\nthe learning task is very challenging since the flow regression is done in the\nfree 3D space, and a typical solution is to resort to a large annotated\nsynthetic dataset. We introduce SCOOP, a new method for scene flow estimation\nthat can be learned on a small amount of data without employing ground-truth\nflow supervision. In contrast to previous work, we train a pure correspondence\nmodel focused on learning point feature representation and initialize the flow\nas the difference between a source point and its softly corresponding target\npoint. Then, in the run-time phase, we directly optimize a flow refinement\ncomponent with a self-supervised objective, which leads to a coherent and\naccurate flow field between the point clouds. Experiments on widespread\ndatasets demonstrate the performance gains achieved by our method compared to\nexisting leading techniques while using a fraction of the training data. Our\ncode is publicly available at https://github.com/itailang/SCOOP.",
    "descriptor": "",
    "authors": [
      "Itai Lang",
      "Dror Aiger",
      "Forrester Cole",
      "Shai Avidan",
      "Michael Rubinstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14020"
  },
  {
    "id": "arXiv:2211.14026",
    "title": "Cross-network transferable neural models for WLAN interference  estimation",
    "abstract": "Airtime interference is a key performance indicator for WLANs, measuring, for\na given time period, the percentage of time during which a node is forced to\nwait for other transmissions before to transmitting or receiving. Being able to\naccurately estimate interference resulting from a given state change (e.g.,\nchannel, bandwidth, power) would allow a better control of WLAN resources,\nassessing the impact of a given configuration before actually implementing it.\nIn this paper, we adopt a principled approach to interference estimation in\nWLANs. We first use real data to characterize the factors that impact it, and\nderive a set of relevant synthetic workloads for a controlled comparison of\nvarious deep learning architectures in terms of accuracy, generalization and\nrobustness to outlier data. We find, unsurprisingly, that Graph Convolutional\nNetworks (GCNs) yield the best performance overall, leveraging the graph\nstructure inherent to campus WLANs. We notice that, unlike e.g. LSTMs, they\nstruggle to learn the behavior of specific nodes, unless given the node indexes\nin addition. We finally verify GCN model generalization capabilities, by\napplying trained models on operational deployments unseen at training time.",
    "descriptor": "",
    "authors": [
      "Danilo Marinho Fernandes",
      "Jonatan Krolikowski",
      "Zied Ben Houidi",
      "Fuxing Chen",
      "Dario Rossi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14026"
  },
  {
    "id": "arXiv:2211.14028",
    "title": "Automata Cascades: Expressivity and Sample Complexity",
    "abstract": "Every automaton can be decomposed into a cascade of basic automata. This is\nthe Prime Decomposition Theorem by Krohn and Rhodes. We show that cascades\nallow for describing the sample complexity of automata in terms of their\ncomponents. In particular, we show that the sample complexity is linear in the\nnumber of components and the maximum complexity of a single component. This\nopens to the possibility for learning automata representing large dynamic\nsystems consisting of many parts interacting with each other. It is in sharp\ncontrast with the established understanding of the sample complexity of\nautomata, described in terms of the overall number of states and input letters,\nwhich in turn implies that it is only possible to learn automata where the\nnumber of states and letters is linear in the amount of data available. Instead\nour results show that one can in principle learn automata with infinite input\nalphabets and a number of states that is exponential in the amount of data\navailable.",
    "descriptor": "\nComments: AAAI 2023\n",
    "authors": [
      "Alessandro Ronca",
      "Nadezda A. Knorozova",
      "Giuseppe De Giacomo"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14028"
  },
  {
    "id": "arXiv:2211.14029",
    "title": "When Congestion Games Meet Mobile Crowdsourcing: Selective Information  Disclosure",
    "abstract": "In congestion games, users make myopic routing decisions to jam each other,\nand the social planner with the full information designs mechanisms on\ninformation or payment side to regulate. However, it is difficult to obtain\ntime-varying traffic conditions, and emerging crowdsourcing platforms (e.g.,\nWaze and Google Maps) provide a convenient way for mobile users travelling on\nthe paths to learn and share the traffic conditions over time. When congestion\ngames meet mobile crowdsourcing, it is critical to incentive selfish users to\nchange their myopic routing policy and reach the best exploitation-exploration\ntrade-off. By considering a simple but fundamental parallel routing network\nwith one deterministic path and multiple stochastic paths for atomic users, we\nprove that the myopic routing policy's price of anarchy (PoA) is larger than\n$\\frac{1}{1-\\rho}$, which can be arbitrarily large as discount factor\n$\\rho\\rightarrow1$. To remedy such huge efficiency loss, we propose a selective\ninformation disclosure (SID) mechanism: we only reveal the latest traffic\ninformation to users when they intend to over-explore the stochastic paths,\nwhile hiding such information when they want to under-explore. We prove that\nour mechanism reduces PoA to be less than $\\frac{1}{1-\\frac{\\rho}{2}}$. Besides\nthe worst-case performance, we further examine our mechanism's average-case\nperformance by using extensive simulations.",
    "descriptor": "\nComments: Online technical report for our forthcoming AAAI 2023 paper. 12 pages, 3 figures\n",
    "authors": [
      "Hongbo Li",
      "Lingjie Duan"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.14029"
  },
  {
    "id": "arXiv:2211.14033",
    "title": "Minimal regret state estimation of time-varying systems",
    "abstract": "Kalman and H-infinity filters, the most popular paradigms for linear state\nestimation, are designed for very specific specific noise and disturbance\npatterns, which may not appear in practice. State observers based on the\nminimization of regret measures are a promising alternative, as they aim to\nadapt to recognizable patterns in the estimation error. In this paper, we show\nthat the regret minimization problem for finite horizon estimation can be cast\ninto a simple convex optimization problem. For this purpose, we first rewrite\nlinear time-varying system dynamics using a novel system level synthesis\nparametrization for state estimation, capable of handling both disturbance and\nmeasurement noise. We then provide a tractable formulation for the minimization\nof regret based on semi-definite programming. Both contributions make the\nminimal regret observer design easily implementable in practice. Finally,\nnumerical experiments show that the computed observer can significantly\noutperform both H-2 and H-infinity filters.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Jean-S\u00e9bastien Brouillon",
      "Giancarlo Ferrari-Trecate",
      "Florian D\u00f6rfler"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.14033"
  },
  {
    "id": "arXiv:2211.14036",
    "title": "Privileged Prior Information Distillation for Image Matting",
    "abstract": "Performance of trimap-free image matting methods is limited when trying to\ndecouple the deterministic and undetermined regions, especially in the scenes\nwhere foregrounds are semantically ambiguous, chromaless, or high\ntransmittance. In this paper, we propose a novel framework named Privileged\nPrior Information Distillation for Image Matting (PPID-IM) that can effectively\ntransfer privileged prior environment-aware information to improve the\nperformance of students in solving hard foregrounds. The prior information of\ntrimap regulates only the teacher model during the training stage, while not\nbeing fed into the student network during actual inference. In order to achieve\neffective privileged cross-modality (i.e. trimap and RGB) information\ndistillation, we introduce a Cross-Level Semantic Distillation (CLSD) module\nthat reinforces the trimap-free students with more knowledgeable semantic\nrepresentations and environment-aware information. We also propose an\nAttention-Guided Local Distillation module that efficiently transfers\nprivileged local attributes from the trimap-based teacher to trimap-free\nstudents for the guidance of local-region optimization. Extensive experiments\ndemonstrate the effectiveness and superiority of our PPID framework on the task\nof image matting. In addition, our trimap-free IndexNet-PPID surpasses the\nother competing state-of-the-art methods by a large margin, especially in\nscenarios with chromaless, weak texture, or irregular objects.",
    "descriptor": "\nComments: 15 pages, 7 figures\n",
    "authors": [
      "Cheng Lyu",
      "Jiake Xie",
      "Bo Xu",
      "Cheng Lu",
      "Han Huang",
      "Xin Huang",
      "Ming Wu",
      "Chuang Zhang",
      "Yong Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.14036"
  },
  {
    "id": "arXiv:2211.14037",
    "title": "MorphPool: Efficient Non-linear Pooling & Unpooling in CNNs",
    "abstract": "Pooling is essentially an operation from the field of Mathematical\nMorphology, with max pooling as a limited special case. The more general\nsetting of MorphPooling greatly extends the tool set for building neural\nnetworks. In addition to pooling operations, encoder-decoder networks used for\npixel-level predictions also require unpooling. It is common to combine\nunpooling with convolution or deconvolution for up-sampling. However, using its\nmorphological properties, unpooling can be generalised and improved. Extensive\nexperimentation on two tasks and three large-scale datasets shows that\nmorphological pooling and unpooling lead to improved predictive performance at\nmuch reduced parameter counts.",
    "descriptor": "\nComments: Accepted paper at the British Machine Vision Conference (BMVC) 2022\n",
    "authors": [
      "Rick Groenendijk",
      "Leo Dorst",
      "Theo Gevers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14037"
  },
  {
    "id": "arXiv:2211.14042",
    "title": "Molecular Joint Representation Learning via Multi-modal Information",
    "abstract": "In recent years, artificial intelligence has played an important role on\naccelerating the whole process of drug discovery. Various of molecular\nrepresentation schemes of different modals (e.g. textual sequence or graph) are\ndeveloped. By digitally encoding them, different chemical information can be\nlearned through corresponding network structures. Molecular graphs and\nSimplified Molecular Input Line Entry System (SMILES) are popular means for\nmolecular representation learning in current. Previous works have done attempts\nby combining both of them to solve the problem of specific information loss in\nsingle-modal representation on various tasks. To further fusing such\nmulti-modal imformation, the correspondence between learned chemical feature\nfrom different representation should be considered. To realize this, we propose\na novel framework of molecular joint representation learning via Multi-Modal\ninformation of SMILES and molecular Graphs, called MMSG. We improve the\nself-attention mechanism by introducing bond level graph representation as\nattention bias in Transformer to reinforce feature correspondence between\nmulti-modal information. We further propose a Bidirectional Message\nCommunication Graph Neural Network (BMC GNN) to strengthen the information flow\naggregated from graphs for further combination. Numerous experiments on public\nproperty prediction datasets have demonstrated the effectiveness of our model.",
    "descriptor": "",
    "authors": [
      "Tianyu Wu",
      "Yang Tang",
      "Qiyu Sun",
      "Luolin Xiong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2211.14042"
  },
  {
    "id": "arXiv:2211.14045",
    "title": "A Configurable Protocol for Quantum Entanglement Distribution to End  Nodes",
    "abstract": "The primary task of a quantum repeater network is to deliver entanglement\namong end nodes. Most of existing entanglement distribution protocols do not\nconsider purification, which is thus delegated to an upper layer. This is a\nmajor drawback since, once an end-to-end entangled connection (or a portion\nthereof) is established it cannot be purified if its fidelity (F) does not fall\nwithin an interval bounded by Fmin (greater than 0.5) and Fmax (less than 1).\nIn this paper, we propose the Ranked Entanglement Distribution Protocol\n(REDiP), a connection-oriented protocol that overcomes the above drawback. This\nresult was achieved by including in our protocol two mechanisms for carrying\nout jointly purification and entanglement swapping. We use simulations to\ninvestigate the impact of these mechanisms on the performance of a repeater\nnetwork, in terms of throughput and fidelity. Moreover, we show how REDiP can\neasily be configured to implement custom entanglement swapping and purification\nstrategies, including (but not restricted to) those adopted in two recent\nworks.",
    "descriptor": "\nComments: 6 pages, 6 figures, submitted to IEEE ICC 2023\n",
    "authors": [
      "Leonardo Bacciottini",
      "Luciano Lenzini",
      "Enzo Mingozzi",
      "Giuseppe Anastasi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.14045"
  },
  {
    "id": "arXiv:2211.14047",
    "title": "On the Universal Approximation Property of Deep Fully Convolutional  Neural Networks",
    "abstract": "We study the approximation of shift-invariant or equivariant functions by\ndeep fully convolutional networks from the dynamical systems perspective. We\nprove that deep residual fully convolutional networks and their\ncontinuous-layer counterpart can achieve universal approximation of these\nsymmetric functions at constant channel width. Moreover, we show that the same\ncan be achieved by non-residual variants with at least 2 channels in each layer\nand convolutional kernel size of at least 2. In addition, we show that these\nrequirements are necessary, in the sense that networks with fewer channels or\nsmaller kernels fail to be universal approximators.",
    "descriptor": "",
    "authors": [
      "Ting Lin",
      "Zuowei Shen",
      "Qianxiao Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14047"
  },
  {
    "id": "arXiv:2211.14052",
    "title": "Towards Hard-pose Virtual Try-on via 3D-aware Global Correspondence  Learning",
    "abstract": "In this paper, we target image-based person-to-person virtual try-on in the\npresence of diverse poses and large viewpoint variations. Existing methods are\nrestricted in this setting as they estimate garment warping flows mainly based\non 2D poses and appearance, which omits the geometric prior of the 3D human\nbody shape. Moreover, current garment warping methods are confined to localized\nregions, which makes them ineffective in capturing long-range dependencies and\nresults in inferior flows with artifacts. To tackle these issues, we present\n3D-aware global correspondences, which are reliable flows that jointly encode\nglobal semantic correlations, local deformations, and geometric priors of 3D\nhuman bodies. Particularly, given an image pair depicting the source and target\nperson, (a) we first obtain their pose-aware and high-level representations via\ntwo encoders, and introduce a coarse-to-fine decoder with multiple refinement\nmodules to predict the pixel-wise global correspondence. (b) 3D parametric\nhuman models inferred from images are incorporated as priors to regularize the\ncorrespondence refinement process so that our flows can be 3D-aware and better\nhandle variations of pose and viewpoint. (c) Finally, an adversarial generator\ntakes the garment warped by the 3D-aware flow, and the image of the target\nperson as inputs, to synthesize the photo-realistic try-on result. Extensive\nexperiments on public benchmarks and our HardPose test set demonstrate the\nsuperiority of our method against the SOTA try-on approaches.",
    "descriptor": "\nComments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Zaiyu Huang",
      "Hanhui Li",
      "Zhenyu Xie",
      "Michael Kampffmeyer",
      "Qingling Cai",
      "Xiaodan Liang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14052"
  },
  {
    "id": "arXiv:2211.14053",
    "title": "Re^2TAL: Rewiring Pretrained Video Backbones for Reversible Temporal  Action Localization",
    "abstract": "Temporal action localization (TAL) requires long-form reasoning to predict\nactions of various lengths and complex content. Given limited GPU memory,\ntraining TAL end-to-end on such long-form videos (i.e., from videos to\npredictions) is a significant challenge. Most methods can only train on\npre-extracted features without optimizing them for the localization problem,\nconsequently limiting localization performance. In this work, to extend the\npotential in TAL networks, we propose a novel end-to-end method Re2TAL, which\nrewires pretrained video backbones for reversible TAL. Re2TAL builds a backbone\nwith reversible modules, where the input can be recovered from the output such\nthat the bulky intermediate activations can be cleared from memory during\ntraining. Instead of designing one single type of reversible module, we propose\na network rewiring mechanism, to transform any module with a residual\nconnection to a reversible module without changing any parameters. This\nprovides two benefits: (1) a large variety of reversible networks are easily\nobtained from existing and even future model designs, and (2) the reversible\nmodels require much less training effort as they reuse the pre-trained\nparameters of their original non-reversible versions. Re2TAL reaches 37.01%\naverage mAP, a new state-of-the-art record on ActivityNet-v1.3, and mAP 64.9%\nat tIoU=0.5 on THUMOS-14 without using optimal flow.",
    "descriptor": "",
    "authors": [
      "Chen Zhao",
      "Shuming Liu",
      "Karttikeya Mangalam",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.14053"
  },
  {
    "id": "arXiv:2211.14054",
    "title": "CAD2Render: A Modular Toolkit for GPU-accelerated Photorealistic  Synthetic Data Generation for the Manufacturing Industry",
    "abstract": "The use of computer vision for product and assembly quality control is\nbecoming ubiquitous in the manufacturing industry. Lately, it is apparent that\nmachine learning based solutions are outperforming classical computer vision\nalgorithms in terms of performance and robustness. However, a main drawback is\nthat they require sufficiently large and labeled training datasets, which are\noften not available or too tedious and too time consuming to acquire. This is\nespecially true for low-volume and high-variance manufacturing. Fortunately, in\nthis industry, CAD models of the manufactured or assembled products are\navailable. This paper introduces CAD2Render, a GPU-accelerated synthetic data\ngenerator based on the Unity High Definition Render Pipeline (HDRP). CAD2Render\nis designed to add variations in a modular fashion, making it possible for high\ncustomizable data generation, tailored to the needs of the industrial use case\nat hand. Although CAD2Render is specifically designed for manufacturing use\ncases, it can be used for other domains as well. We validate CAD2Render by\ndemonstrating state of the art performance in two industrial relevant setups.\nWe demonstrate that the data generated by our approach can be used to train\nobject detection and pose estimation models with a high enough accuracy to\ndirect a robot. The code for CAD2Render is available at\nhttps://github.com/EDM-Research/CAD2Render.",
    "descriptor": "\nComments: Accepted at the Workshop on Photorealistic Image and Environment Synthesis for Computer Vision (PIES-CV) at WACV23\n",
    "authors": [
      "Steven Moonen",
      "Bram Vanherle",
      "Joris de Hoog",
      "Taoufik Bourgana",
      "Abdellatif Bey-Temsamani",
      "Nick Michiels"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14054"
  },
  {
    "id": "arXiv:2211.14058",
    "title": "Cross-Domain Ensemble Distillation for Domain Generalization",
    "abstract": "Domain generalization is the task of learning models that generalize to\nunseen target domains. We propose a simple yet effective method for domain\ngeneralization, named cross-domain ensemble distillation (XDED), that learns\ndomain-invariant features while encouraging the model to converge to flat\nminima, which recently turned out to be a sufficient condition for domain\ngeneralization. To this end, our method generates an ensemble of the output\nlogits from training data with the same label but from different domains and\nthen penalizes each output for the mismatch with the ensemble. Also, we present\na de-stylization technique that standardizes features to encourage the model to\nproduce style-consistent predictions even in an arbitrary target domain. Our\nmethod greatly improves generalization capability in public benchmarks for\ncross-domain image classification, cross-dataset person re-ID, and\ncross-dataset semantic segmentation. Moreover, we show that models learned by\nour method are robust against adversarial attacks and image corruptions.",
    "descriptor": "\nComments: Accepted to ECCV 2022. Code is available at this http URL\n",
    "authors": [
      "Kyungmoon Lee",
      "Sungyeon Kim",
      "Suha Kwak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14058"
  },
  {
    "id": "arXiv:2211.14061",
    "title": "A Survey of Learning Curves with Bad Behavior: or How More Data Need Not  Lead to Better Performance",
    "abstract": "Plotting a learner's generalization performance against the training set size\nresults in a so-called learning curve. This tool, providing insight in the\nbehavior of the learner, is also practically valuable for model selection,\npredicting the effect of more training data, and reducing the computational\ncomplexity of training. We set out to make the (ideal) learning curve concept\nprecise and briefly discuss the aforementioned usages of such curves. The\nlarger part of this survey's focus, however, is on learning curves that show\nthat more data does not necessarily leads to better generalization performance.\nA result that seems surprising to many researchers in the field of artificial\nintelligence. We point out the significance of these findings and conclude our\nsurvey with an overview and discussion of open problems in this area that\nwarrant further theoretical and empirical investigation.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2103.10948\n",
    "authors": [
      "Marco Loog",
      "Tom Viering"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.14061"
  },
  {
    "id": "arXiv:2211.14062",
    "title": "M$^2$M: A general method to perform various data analysis tasks from a  differentially private sketch",
    "abstract": "Differential privacy is the standard privacy definition for performing\nanalyses over sensitive data. Yet, its privacy budget bounds the number of\ntasks an analyst can perform with reasonable accuracy, which makes it\nchallenging to deploy in practice. This can be alleviated by private sketching,\nwhere the dataset is compressed into a single noisy sketch vector which can be\nshared with the analysts and used to perform arbitrarily many analyses.\nHowever, the algorithms to perform specific tasks from sketches must be\ndeveloped on a case-by-case basis, which is a major impediment to their use. In\nthis paper, we introduce the generic moment-to-moment (M$^2$M) method to\nperform a wide range of data exploration tasks from a single private sketch.\nAmong other things, this method can be used to estimate empirical moments of\nattributes, the covariance matrix, counting queries (including histograms), and\nregression models. Our method treats the sketching mechanism as a black-box\noperation, and can thus be applied to a wide variety of sketches from the\nliterature, widening their ranges of applications without further engineering\nor privacy loss, and removing some of the technical barriers to the wider\nadoption of sketches for data exploration under differential privacy. We\nvalidate our method with data exploration tasks on artificial and real-world\ndata, and show that it can be used to reliably estimate statistics and train\nclassification models from private sketches.",
    "descriptor": "\nComments: Published at the 18th International Workshop on Security and Trust Management (STM 2022)\n",
    "authors": [
      "Florimond Houssiau",
      "Vincent Schellekens",
      "Antoine Chatalic",
      "Shreyas Kumar Annamraju",
      "Yves-Alexandre de Montjoye"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14062"
  },
  {
    "id": "arXiv:2211.14065",
    "title": "Beyond Smoothing: Unsupervised Graph Representation Learning with Edge  Heterophily Discriminating",
    "abstract": "Unsupervised graph representation learning (UGRL) has drawn increasing\nresearch attention and achieved promising results in several graph analytic\ntasks. Relying on the homophily assumption, existing UGRL methods tend to\nsmooth the learned node representations along all edges, ignoring the existence\nof heterophilic edges that connect nodes with distinct attributes. As a result,\ncurrent methods are hard to generalize to heterophilic graphs where dissimilar\nnodes are widely connected, and also vulnerable to adversarial attacks. To\naddress this issue, we propose a novel unsupervised Graph Representation\nlearning method with Edge hEterophily discriminaTing (GREET) which learns\nrepresentations by discriminating and leveraging homophilic edges and\nheterophilic edges. To distinguish two types of edges, we build an edge\ndiscriminator that infers edge homophily/heterophily from feature and structure\ninformation. We train the edge discriminator in an unsupervised way through\nminimizing the crafted pivot-anchored ranking loss, with randomly sampled node\npairs acting as pivots. Node representations are learned through contrasting\nthe dual-channel encodings obtained from the discriminated homophilic and\nheterophilic edges. With an effective interplaying scheme, edge discriminating\nand representation learning can mutually boost each other during the training\nphase. We conducted extensive experiments on 14 benchmark datasets and multiple\nlearning scenarios to demonstrate the superiority of GREET.",
    "descriptor": "\nComments: 14 pages, 7 tables, 6 figures, accepted by AAAI 2023\n",
    "authors": [
      "Yixin Liu",
      "Yizhen Zheng",
      "Daokun Zhang",
      "Vincent CS Lee",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.14065"
  },
  {
    "id": "arXiv:2211.14068",
    "title": "Fine-Grained Face Swapping via Regional GAN Inversion",
    "abstract": "We present a novel paradigm for high-fidelity face swapping that faithfully\npreserves the desired subtle geometry and texture details. We rethink face\nswapping from the perspective of fine-grained face editing, \\textit{i.e.,\n``editing for swapping'' (E4S)}, and propose a framework that is based on the\nexplicit disentanglement of the shape and texture of facial components.\nFollowing the E4S principle, our framework enables both global and local\nswapping of facial features, as well as controlling the amount of partial\nswapping specified by the user. Furthermore, the E4S paradigm is inherently\ncapable of handling facial occlusions by means of facial masks. At the core of\nour system lies a novel Regional GAN Inversion (RGI) method, which allows the\nexplicit disentanglement of shape and texture. It also allows face swapping to\nbe performed in the latent space of StyleGAN. Specifically, we design a\nmulti-scale mask-guided encoder to project the texture of each facial component\ninto regional style codes. We also design a mask-guided injection module to\nmanipulate the feature maps with the style codes. Based on the disentanglement,\nface swapping is reformulated as a simplified problem of style and mask\nswapping. Extensive experiments and comparisons with current state-of-the-art\nmethods demonstrate the superiority of our approach in preserving texture and\nshape details, as well as working with high resolution images at\n1024$\\times$1024.",
    "descriptor": "\nComments: Project page, see this http URL\n",
    "authors": [
      "Zhian Liu",
      "Maomao Li",
      "Yong Zhang",
      "Cairong Wang",
      "Qi Zhang",
      "Jue Wang",
      "Yongwei Nie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14068"
  },
  {
    "id": "arXiv:2211.14073",
    "title": "EDGAR: Embedded Detection of Gunshots by AI in Real-time",
    "abstract": "Electronic shot counters allow armourers to perform preventive and predictive\nmaintenance based on quantitative measurements, improving reliability, reducing\nthe frequency of accidents, and reducing maintenance costs. To answer a market\npressure for both low lead time to market and increased customisation, we aim\nto solve the shot detection and shot counting problem in a generic way through\nmachine learning.\nIn this study, we describe a method allowing one to construct a dataset with\nminimal labelling effort by only requiring the total number of shots fired in a\ntime series. To our knowledge, this is the first study to propose a technique,\nbased on learning from label proportions, that is able to exploit these weak\nlabels to derive an instance-level classifier able to solve the counting\nproblem and the more general discrimination problem. We also show that this\ntechnique can be deployed in heavily constrained microcontrollers while still\nproviding hard real-time (<100ms) inference. We evaluate our technique against\na state-of-the-art unsupervised algorithm and show a sizeable improvement,\nsuggesting that the information from the weak labels is successfully leveraged.\nFinally, we evaluate our technique against human-generated state-of-the-art\nalgorithms and show that it provides comparable performance and significantly\noutperforms them in some offline and real-world benchmarks.",
    "descriptor": "\nComments: 19 pages, 4 figures, submitted to the 7th Workshop on Advanced Analytics and Learning on Temporal Data\n",
    "authors": [
      "Nathan Morsa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.14073"
  },
  {
    "id": "arXiv:2211.14074",
    "title": "Copy-Pasting Coherent Depth Regions Improves Contrastive Learning for  Urban-Scene Segmentation",
    "abstract": "In this work, we leverage estimated depth to boost self-supervised\ncontrastive learning for segmentation of urban scenes, where unlabeled videos\nare readily available for training self-supervised depth estimation. We argue\nthat the semantics of a coherent group of pixels in 3D space is self-contained\nand invariant to the contexts in which they appear. We group coherent,\nsemantically related pixels into coherent depth regions given their estimated\ndepth and use copy-paste to synthetically vary their contexts. In this way,\ncross-context correspondences are built in contrastive learning and a\ncontext-invariant representation is learned. For unsupervised semantic\nsegmentation of urban scenes, our method surpasses the previous\nstate-of-the-art baseline by +7.14% in mIoU on Cityscapes and +6.65% on KITTI.\nFor fine-tuning on Cityscapes and KITTI segmentation, our method is competitive\nwith existing models, yet, we do not need to pre-train on ImageNet or COCO, and\nwe are also more computationally efficient. Our code is available on\nhttps://github.com/LeungTsang/CPCDR",
    "descriptor": "\nComments: BMVC 2022 Best Student Paper Award(Honourable Mention)\n",
    "authors": [
      "Liang Zeng",
      "Attila Lengyel",
      "Nergis T\u00f6men",
      "Jan van Gemert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14074"
  },
  {
    "id": "arXiv:2211.14076",
    "title": "Factor-balanced $S$-adic languages",
    "abstract": "A set of words, also called a language, is letter-balanced if the number of\noccurrences of each letter only depends on the length of the word, up to a\nconstant. Similarly, a language is factor-balanced if the difference of the\nnumber of occurrences of any given factor in words of the same length is\nbounded. The most prominent example of a letter-balanced but not\nfactor-balanced language is given by the Thue-Morse sequence. We establish\nconnections between the two notions, in particular for languages given by\nsubstitutions and, more generally, by sequences of substitutions. We show that\nthe two notions essentially coincide when the sequence of substitutions is\nproper. For the example of Thue-Morse-Sturmian languages, we give a full\ncharacterisation of factor-balancedness.",
    "descriptor": "",
    "authors": [
      "L\u00e9o Poirier",
      "Wolfgang Steiner"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.14076"
  },
  {
    "id": "arXiv:2211.14077",
    "title": "Detecting broken Absorber Tubes in CSP plants using intelligent sampling  and dual loss",
    "abstract": "Concentrated solar power (CSP) is one of the growing technologies that is\nleading the process of changing from fossil fuels to renewable energies. The\nsophistication and size of the systems require an increase in maintenance tasks\nto ensure reliability, availability, maintainability and safety. Currently,\nautomatic fault detection in CSP plants using Parabolic Trough Collector\nsystems evidences two main drawbacks: 1) the devices in use needs to be\nmanually placed near the receiver tube, 2) the Machine Learning-based solutions\nare not tested in real plants. We address both gaps by combining the data\nextracted with the use of an Unmaned Aerial Vehicle, and the data provided by\nsensors placed within 7 real plants. The resulting dataset is the first one of\nthis type and can help to standardize research activities for the problem of\nfault detection in this type of plants. Our work proposes supervised\nmachine-learning algorithms for detecting broken envelopes of the absorber\ntubes in CSP plants. The proposed solution takes the class imbalance problem\ninto account, boosting the accuracy of the algorithms for the minority class\nwithout harming the overall performance of the models. For a Deep Residual\nNetwork, we solve an imbalance and a balance problem at the same time, which\nincreases by 5% the Recall of the minority class with no harm to the F1-score.\nAdditionally, the Random Under Sampling technique boost the performance of\ntraditional Machine Learning models, being the Histogram Gradient Boost\nClassifier the algorithm with the highest increase (3%) in the F1-Score. To the\nbest of our knowledge, this paper is the first providing an automated solution\nto this problem using data from operating plants.",
    "descriptor": "",
    "authors": [
      "Miguel Angel P\u00e9rez-Cuti\u00f1o",
      "Juan Sebasti\u00e1n Valverde",
      "Jos\u00e9 Miguel D\u00edaz-B\u00e1\u00f1ez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14077"
  },
  {
    "id": "arXiv:2211.14078",
    "title": "Vertical-oriented 5G platform-as-a-service: user-generated content case  study",
    "abstract": "5G realizes an impactful convergence, where Network Functions Virtualization\n(NFV) and cloud-native models become fundamental for profiting from the\nunprecedented capacity offered at the 5G Radio Access Network (RAN). For\nproviding scalability and automation management over resources in 5G\ninfrastructure, cloud-native and Platform as a service (PaaS) are proposed as\nsolutions for paving the way for vertical applications in 5G. This paper\nleverages cloud-native models, PaaS, and virtual testbed instances to provide\nkey platform provisioning and service life-cycle management features to a\nselected User Generated Content (UGC) scenario in multimedia applications.\nSpecifically, this article and results show how service-level telemetry from a\nUGC cloud-native application is used to automatically scale system resources\nacross the NFV infrastructure.",
    "descriptor": "\nComments: Previous version of the paper is accepted in IEEE Future Networks World Forum (FNWF), Montreal, 2022\n",
    "authors": [
      "Sarang Kahvazadeh",
      "Hamzeh Khalili",
      "Rasoul Nikbakht Silab",
      "Bahador Bakhshi",
      "Josep Mangues-Bafalluy"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.14078"
  },
  {
    "id": "arXiv:2211.14079",
    "title": "Training Data Improvement for Image Forgery Detection using Comprint",
    "abstract": "Manipulated images are a threat to consumers worldwide, when they are used to\nspread disinformation. Therefore, Comprint enables forgery detection by\nutilizing JPEG-compression fingerprints. This paper evaluates the impact of the\ntraining set on Comprint's performance. Most interestingly, we found that\nincluding images compressed with low quality factors during training does not\nhave a significant effect on the accuracy, whereas incorporating recompression\nboosts the robustness. As such, consumers can use Comprint on their smartphones\nto verify the authenticity of images.",
    "descriptor": "\nComments: Will be presented at the International Conference on Consumer Electronics (ICCE) 2023 in Las Vegas, NV, USA\n",
    "authors": [
      "Hannes Mareen",
      "Dante Vanden Bussche",
      "Glenn Van Wallendael",
      "Luisa Verdoliva",
      "Peter Lambert"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14079"
  },
  {
    "id": "arXiv:2211.14082",
    "title": "Simple Algorithms for Stochastic Score Classification with Small  Approximation Ratios",
    "abstract": "We revisit the Stochastic Score Classification (SSC) problem introduced by\nGkenosis et al. (ESA 2018): We are given $n$ tests. Each test $j$ can be\nconducted at cost $c_j$, and it succeeds independently with probability $p_j$.\nFurther, a partition of the (integer) interval $\\{0,\\dots,n\\}$ into $B$ smaller\nintervals is known. The goal is to conduct tests so as to determine that\ninterval from the partition in which the number of successful tests lies while\nminimizing the expected cost. Ghuge et al. (IPCO 2022) recently showed that a\npolynomial-time constant-factor approximation algorithm exists.\nWe show that interweaving the two strategies that order tests increasingly by\ntheir $c_j/p_j$ and $c_j/(1-p_j)$ ratios, respectively, -- as already proposed\nby Gkensosis et al. for a special case -- yields a small approximation ratio.\nWe also show that the approximation ratio can be slightly decreased from $6$ to\n$3+2\\sqrt{2}\\approx 5.828$ by adding in a third strategy that simply orders\ntests increasingly by their costs. The similar analyses for both algorithms are\nnontrivial but arguably clean. Finally, we complement the implied upper bound\nof $3+2\\sqrt{2}$ on the adaptivity gap with a lower bound of $3/2$. Since the\nlower-bound instance is a so-called unit-cost $k$-of-$n$ instance, we settle\nthe adaptivity gap in this case.",
    "descriptor": "",
    "authors": [
      "Benedikt M. Plank",
      "Kevin Schewior"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.14082"
  },
  {
    "id": "arXiv:2211.14085",
    "title": "Positive unlabeled learning with tensor networks",
    "abstract": "Positive unlabeled learning is a binary classification problem with positive\nand unlabeled data. It is common in domains where negative labels are costly or\nimpossible to obtain, e.g., medicine and personalized advertising. We apply the\nlocally purified state tensor network to the positive unlabeled learning\nproblem and test our model on the MNIST image and 15 categorical/mixed\ndatasets. On the MNIST dataset, we achieve state-of-the-art results even with\nvery few labeled positive samples. Similarly, we significantly improve the\nstate-of-the-art on categorical datasets. Further, we show that the agreement\nfraction between outputs of different models on unlabeled samples is a good\nindicator of the model's performance. Finally, our method can generate new\npositive and negative instances, which we demonstrate on simple synthetic\ndatasets.",
    "descriptor": "\nComments: 12 pages, 5 figures, 4 tables\n",
    "authors": [
      "Bojan \u017dunkovi\u010d"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14085"
  },
  {
    "id": "arXiv:2211.14086",
    "title": "ShadowNeuS: Neural SDF Reconstruction by Shadow Ray Supervision",
    "abstract": "By supervising camera rays between a scene and multi-view image planes, NeRF\nreconstructs a neural scene representation for the task of novel view\nsynthesis. On the other hand, shadow rays between the light source and the\nscene have yet to be considered. Therefore, we propose a novel shadow ray\nsupervision scheme that optimizes both the samples along the ray and the ray\nlocation. By supervising shadow rays, we successfully reconstruct a neural SDF\nof the scene from single-view pure shadow or RGB images under multiple lighting\nconditions. Given single-view binary shadows, we train a neural network to\nreconstruct a complete scene not limited by the camera's line of sight. By\nfurther modeling the correlation between the image colors and the shadow rays,\nour technique can also be effectively extended to RGB inputs. We compare our\nmethod with previous works on challenging tasks of shape reconstruction from\nsingle-view binary shadow or RGB images and observe significant improvements.\nThe code and data will be released.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Jingwang Ling",
      "Zhibo Wang",
      "Feng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14086"
  },
  {
    "id": "arXiv:2211.14088",
    "title": "Boundary Adversarial Examples Against Adversarial Overfitting",
    "abstract": "Standard adversarial training approaches suffer from robust overfitting where\nthe robust accuracy decreases when models are adversarially trained for too\nlong. The origin of this problem is still unclear and conflicting explanations\nhave been reported, i.e., memorization effects induced by large loss data or\nbecause of small loss data and growing differences in loss distribution of\ntraining samples as the adversarial training progresses. Consequently, several\nmitigation approaches including early stopping, temporal ensembling and weight\nperturbations on small loss data have been proposed to mitigate the effect of\nrobust overfitting. However, a side effect of these strategies is a larger\nreduction in clean accuracy compared to standard adversarial training. In this\npaper, we investigate if these mitigation approaches are complimentary to each\nother in improving adversarial training performance. We further propose the use\nof helper adversarial examples that can be obtained with minimal cost in the\nadversarial example generation, and show how they increase the clean accuracy\nin the existing approaches without compromising the robust accuracy.",
    "descriptor": "",
    "authors": [
      "Muhammad Zaid Hameed",
      "Beat Buesser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14088"
  },
  {
    "id": "arXiv:2211.14090",
    "title": "Spatial-Spectral Transformer for Hyperspectral Image Denoising",
    "abstract": "Hyperspectral image (HSI) denoising is a crucial preprocessing procedure for\nthe subsequent HSI applications. Unfortunately, though witnessing the\ndevelopment of deep learning in HSI denoising area, existing convolution-based\nmethods face the trade-off between computational efficiency and capability to\nmodel non-local characteristics of HSI. In this paper, we propose a\nSpatial-Spectral Transformer (SST) to alleviate this problem. To fully explore\nintrinsic similarity characteristics in both spatial dimension and spectral\ndimension, we conduct non-local spatial self-attention and global spectral\nself-attention with Transformer architecture. The window-based spatial\nself-attention focuses on the spatial similarity beyond the neighboring region.\nWhile, spectral self-attention exploits the long-range dependencies between\nhighly correlative bands. Experimental results show that our proposed method\noutperforms the state-of-the-art HSI denoising methods in quantitative quality\nand visual results.",
    "descriptor": "",
    "authors": [
      "Miaoyu Li",
      "Ying Fu",
      "Yulun Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.14090"
  },
  {
    "id": "arXiv:2211.14091",
    "title": "Language-Assisted 3D Feature Learning for Semantic Scene Understanding",
    "abstract": "Learning descriptive 3D features is crucial for understanding 3D scenes with\ndiverse objects and complex structures. However, it is usually unknown whether\nimportant geometric attributes and scene context obtain enough emphasis in an\nend-to-end trained 3D scene understanding network. To guide 3D feature learning\ntoward important geometric attributes and scene context, we explore the help of\ntextual scene descriptions. Given some free-form descriptions paired with 3D\nscenes, we extract the knowledge regarding the object relationships and object\nattributes. We then inject the knowledge to 3D feature learning through three\nclassification-based auxiliary tasks. This language-assisted training can be\ncombined with modern object detection and instance segmentation methods to\npromote 3D semantic scene understanding, especially in a label-deficient\nregime. Moreover, the 3D feature learned with language assistance is better\naligned with the language features, which can benefit various 3D-language\nmultimodal tasks. Experiments on several benchmarks of 3D-only and 3D-language\ntasks demonstrate the effectiveness of our language-assisted 3D feature\nlearning. Code is available at\nhttps://github.com/Asterisci/Language-Assisted-3D.",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Junbo Zhang",
      "Guofan Fan",
      "Guanghan Wang",
      "Zhengyuan Su",
      "Kaisheng Ma",
      "Li Yi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14091"
  },
  {
    "id": "arXiv:2211.14095",
    "title": "A Hierarchical Variable Autonomy Mixed-Initiative Framework for  Human-Robot Teaming in Mobile Robotics",
    "abstract": "This paper presents a Mixed-Initiative (MI) framework for addressing the\nproblem of control authority transfer between a remote human operator and an AI\nagent when cooperatively controlling a mobile robot. Our Hierarchical\nExpert-guided Mixed-Initiative Control Switcher (HierEMICS) leverages\ninformation on the human operator's state and intent. The control switching\npolicies are based on a criticality hierarchy. An experimental evaluation was\nconducted in a high-fidelity simulated disaster response and remote inspection\nscenario, comparing HierEMICS with a state-of-the-art Expert-guided\nMixed-Initiative Control Switcher (EMICS) in the context of mobile robot\nnavigation. Results suggest that HierEMICS reduces conflicts for control\nbetween the human and the AI agent, which is a fundamental challenge in both\nthe MI control paradigm and also in the related shared control paradigm.\nAdditionally, we provide statistically significant evidence of improved,\nnavigational safety (i.e., fewer collisions), LOA switching efficiency, and\nconflict for control reduction.",
    "descriptor": "\nComments: 6 pages, 4 figures, ICHMS 2022, First two Authors contributed equally\n",
    "authors": [
      "Dimitris Panagopoulos",
      "Giannis Petousakis",
      "Aniketh Ramesh",
      "Tianshu Ruan",
      "Grigoris Nikolaou",
      "Rustam Stolkin",
      "Manolis Chiou"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.14095"
  },
  {
    "id": "arXiv:2211.14098",
    "title": "An Ensemble-Based Deep Framework for Estimating Thermo-Chemical State  Variables from Flamelet Generated Manifolds",
    "abstract": "Complete computation of turbulent combustion flow involves two separate\nsteps: mapping reaction kinetics to low-dimensional manifolds and looking-up\nthis approximate manifold during CFD run-time to estimate the thermo-chemical\nstate variables. In our previous work, we showed that using a deep architecture\nto learn the two steps jointly, instead of separately, is 73% more accurate at\nestimating the source energy, a key state variable, compared to benchmarks and\ncan be integrated within a DNS turbulent combustion framework. In their natural\nform, such deep architectures do not allow for uncertainty quantification of\nthe quantities of interest: the source energy and key species source terms. In\nthis paper, we expand on such architectures, specifically ChemTab, by\nintroducing deep ensembles to approximate the posterior distribution of the\nquantities of interest. We investigate two strategies of creating these\nensemble models: one that keeps the flamelet origin information (Flamelets\nstrategy) and one that ignores the origin and considers all the data\nindependently (Points strategy). To train these models we used flamelet data\ngenerated by the GRI--Mech 3.0 methane mechanism, which consists of 53 chemical\nspecies and 325 reactions. Our results demonstrate that the Flamelets strategy\nis superior in terms of the absolute prediction error for the quantities of\ninterest, but is reliant on the types of flamelets used to train the ensemble.\nThe Points strategy is best at capturing the variability of the quantities of\ninterest, independent of the flamelet types. We conclude that, overall, ChemTab\nDeep Ensembles allows for a more accurate representation of the source energy\nand key species source terms, compared to the model without these\nmodifications.",
    "descriptor": "",
    "authors": [
      "Amol Salunkhe",
      "Georgios Georgalis",
      "Abani Patra",
      "Varun Chandola"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.14098"
  },
  {
    "id": "arXiv:2211.14099",
    "title": "Fuzzy clustering for the within-season estimation of cotton phenology",
    "abstract": "Crop phenology is crucial information for crop yield estimation and\nagricultural management. Traditionally, phenology has been observed from the\nground; however Earth observation, weather and soil data have been used to\ncapture the physiological growth of crops. In this work, we propose a new\napproach for the within-season phenology estimation for cotton at the field\nlevel. For this, we exploit a variety of Earth observation vegetation indices\n(derived from Sentinel-2) and numerical simulations of atmospheric and soil\nparameters. Our method is unsupervised to address the ever-present problem of\nsparse and scarce ground truth data that makes most supervised alternatives\nimpractical in real-world scenarios. We applied fuzzy c-means clustering to\nidentify the principal phenological stages of cotton and then used the cluster\nmembership weights to further predict the transitional phases between adjacent\nstages. In order to evaluate our models, we collected 1,285 crop growth ground\nobservations in Orchomenos, Greece. We introduced a new collection protocol,\nassigning up to two phenology labels that represent the primary and secondary\ngrowth stage in the field and thus indicate when stages are transitioning. Our\nmodel was tested against a baseline model that allowed to isolate the random\nagreement and evaluate its true competence. The results showed that our model\nconsiderably outperforms the baseline one, which is promising considering the\nunsupervised nature of the approach. The limitations and the relevant future\nwork are thoroughly discussed. The ground observations are formatted in an\nready-to-use dataset and will be available at\nhttps://github.com/Agri-Hub/cotton-phenology-dataset upon publication.",
    "descriptor": "\nComments: also contained in arXiv:2211.12584\n",
    "authors": [
      "Vasileios Sitokonstantinou",
      "Alkiviadis Koukos",
      "Ilias Tsoumas",
      "Nikolaos S. Bartsotas",
      "Charalampos Kontoes",
      "Vassilia Karathanassi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14099"
  },
  {
    "id": "arXiv:2211.14105",
    "title": "Unifying conditional and unconditional semantic image synthesis with  OCO-GAN",
    "abstract": "Generative image models have been extensively studied in recent years. In the\nunconditional setting, they model the marginal distribution from unlabelled\nimages. To allow for more control, image synthesis can be conditioned on\nsemantic segmentation maps that instruct the generator the position of objects\nin the image. While these two tasks are intimately related, they are generally\nstudied in isolation. We propose OCO-GAN, for Optionally COnditioned GAN, which\naddresses both tasks in a unified manner, with a shared image synthesis network\nthat can be conditioned either on semantic maps or directly on latents. Trained\nadversarially in an end-to-end approach with a shared discriminator, we are\nable to leverage the synergy between both tasks. We experiment with Cityscapes,\nCOCO-Stuff, ADE20K datasets in a limited data, semi-supervised and full data\nregime and obtain excellent performance, improving over existing hybrid models\nthat can generate both with and without conditioning in all settings. Moreover,\nour results are competitive or better than state-of-the art specialised\nunconditional and conditional models.",
    "descriptor": "",
    "authors": [
      "Marl\u00e8ne Careil",
      "St\u00e9phane Lathuili\u00e8re",
      "Camille Couprie",
      "Jakob Verbeek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14105"
  },
  {
    "id": "arXiv:2211.14108",
    "title": "3DDesigner: Towards Photorealistic 3D Object Generation and Editing with  Text-guided Diffusion Models",
    "abstract": "Text-guided diffusion models have shown superior performance in image/video\ngeneration and editing. While few explorations have been performed in 3D\nscenarios. In this paper, we discuss three fundamental and interesting problems\non this topic. First, we equip text-guided diffusion models to achieve\n\\textbf{3D-consistent generation}. Specifically, we integrate a NeRF-like\nneural field to generate low-resolution coarse results for a given camera view.\nSuch results can provide 3D priors as condition information for the following\ndiffusion process. During denoising diffusion, we further enhance the 3D\nconsistency by modeling cross-view correspondences with a novel two-stream\n(corresponding to two different views) asynchronous diffusion process. Second,\nwe study \\textbf{3D local editing} and propose a two-step solution that can\ngenerate 360$^{\\circ}$ manipulated results by editing an object from a single\nview. Step 1, we propose to perform 2D local editing by blending the predicted\nnoises. Step 2, we conduct a noise-to-text inversion process that maps 2D\nblended noises into the view-independent text embedding space. Once the\ncorresponding text embedding is obtained, 360$^{\\circ}$ images can be\ngenerated. Last but not least, we extend our model to perform \\textbf{one-shot\nnovel view synthesis} by fine-tuning on a single image, firstly showing the\npotential of leveraging text guidance for novel view synthesis. Extensive\nexperiments and various applications show the prowess of our 3DDesigner.\nProject page is available at \\url{https://3ddesigner-diffusion.github.io/}.",
    "descriptor": "\nComments: 15 pages, 12 figures, conference\n",
    "authors": [
      "Gang Li",
      "Heliang Zheng",
      "Chaoyue Wang",
      "Chang Li",
      "Changwen Zheng",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14108"
  },
  {
    "id": "arXiv:2211.14114",
    "title": "Interval-censored Transformer Hawkes: Detecting Information Operations  using the Reaction of Social Systems",
    "abstract": "Social media is being increasingly weaponized by state-backed actors to\nelicit reactions, push narratives and sway public opinion. These are known as\nInformation Operations (IO). The covert nature of IO makes their detection\ndifficult. This is further amplified by missing data due to the user and\ncontent removal and privacy requirements. This work advances the hypothesis\nthat the very reactions that Information Operations seek to elicit within the\ntarget social systems can be used to detect them. We propose an\nInterval-censored Transformer Hawkes (IC-TH) architecture and a novel data\nencoding scheme to account for both observed and missing data. We derive a\nnovel log-likelihood function that we deploy together with a contrastive\nlearning procedure. We showcase the performance of IC-TH on three real-world\nTwitter datasets and two learning tasks: future popularity prediction and item\ncategory prediction. The latter is particularly significant. Using the\nretweeting timing and patterns solely, we can predict the category of YouTube\nvideos, guess whether news publishers are reputable or controversial and, most\nimportantly, identify state-backed IO agent accounts. Additional qualitative\ninvestigations uncover that the automatically discovered clusters of\nRussian-backed agents appear to coordinate their behavior, activating\nsimultaneously to push specific narratives.",
    "descriptor": "",
    "authors": [
      "Quyu Kong",
      "Pio Calderon",
      "Rohit Ram",
      "Olga Boichak",
      "Marian-Andrei Rizoiu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.14114"
  },
  {
    "id": "arXiv:2211.14118",
    "title": "MS-PS: A Multi-Scale Network for Photometric Stereo With a New  Comprehensive Training Dataset",
    "abstract": "The photometric stereo (PS) problem consists in reconstructing the 3D-surface\nof an object, thanks to a set of photographs taken under different lighting\ndirections. In this paper, we propose a multi-scale architecture for PS which,\ncombined with a new dataset, yields state-of-the-art results. Our proposed\narchitecture is flexible: it permits to consider a variable number of images as\nwell as variable image size without loss of performance. In addition, we define\na set of constraints to allow the generation of a relevant synthetic dataset to\ntrain convolutional neural networks for the PS problem. Our proposed dataset is\nmuch larger than pre-existing ones, and contains many objects with challenging\nmaterials having anisotropic reflectance (e.g. metals, glass). We show on\npublicly available benchmarks that the combination of both these contributions\ndrastically improves the accuracy of the estimated normal field, in comparison\nwith previous state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Cl\u00e9ment Hardy",
      "Yvain Qu\u00e9au",
      "David Tschumperl\u00e9"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14118"
  },
  {
    "id": "arXiv:2211.14119",
    "title": "A reduced-order model for dynamic simulation of district heating  networks",
    "abstract": "This study concerns the development of a data-based compact model for the\nprediction of the fluid temperature evolution in district heating (DH) pipeline\nnetworks. This so-called \"reduced-order model\" (ROM) is obtained from reduction\nof the conservation law for energy for each pipe segment to a semi-analytical\ninput-output relation between the pipe outlet temperature and the pipe inlet\nand ground temperatures that can be identified from training data. The ROM\nbasically is valid for generic pipe configurations involving 3D unsteady heat\ntransfer and 3D steady flow as long as heat-transfer mechanisms are linearly\ndependent on the temperature field. Moreover, the training data can be\ngenerated by physics-based computational \"full-order\" models (FOMs) yet also by\n(calibration) experiments or field measurements. Performance tests using\ncomputational training data for a single 1D pipe configuration demonstrate that\nthe ROM (i) can be successfully identified and (ii) can accurately describe the\nresponse of the outlet temperature to arbitrary input profiles for inlet and\nground temperatures. Application of the ROM to two case studies, i.e. fast\nsimulation of a small DH network and design of a controller for user-defined\ntemperature regulation of a DH system, demonstrate its predictive ability and\nefficiency also for realistic systems. Dedicated cost analyses further reveal\nthat the ROM may significantly reduce the computational costs compared to FOMs\nby (up to) orders of magnitude for higher-dimensional pipe configurations.\nThese findings advance the proposed ROM as a robust and efficient simulation\ntool for practical DH systems with a far greater predictive ability than\nexisting compact models.",
    "descriptor": "\nComments: 30 pages, 19 figures\n",
    "authors": [
      "Mengting Jiang",
      "Michel Speetjens",
      "Camilo Rindt",
      "David Smeulders"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.14119"
  },
  {
    "id": "arXiv:2211.14125",
    "title": "PoET: Pose Estimation Transformer for Single-View, Multi-Object 6D Pose  Estimation",
    "abstract": "Accurate 6D object pose estimation is an important task for a variety of\nrobotic applications such as grasping or localization. It is a challenging task\ndue to object symmetries, clutter and occlusion, but it becomes more\nchallenging when additional information, such as depth and 3D models, is not\nprovided. We present a transformer-based approach that takes an RGB image as\ninput and predicts a 6D pose for each object in the image. Besides the image,\nour network does not require any additional information such as depth maps or\n3D object models. First, the image is passed through an object detector to\ngenerate feature maps and to detect objects. Then, the feature maps are fed\ninto a transformer with the detected bounding boxes as additional information.\nAfterwards, the output object queries are processed by a separate translation\nand rotation head. We achieve state-of-the-art results for RGB-only approaches\non the challenging YCB-V dataset. We illustrate the suitability of the\nresulting model as pose sensor for a 6-DoF state estimation task. Code is\navailable at https://github.com/aau-cns/poet.",
    "descriptor": "\nComments: Supplementary material available: this https URL , Code available: this https URL\n",
    "authors": [
      "Thomas Jantos",
      "Mohamed Amin Hamdad",
      "Wolfgang Granig",
      "Stephan Weiss",
      "Jan Steinbrener"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14125"
  },
  {
    "id": "arXiv:2211.14126",
    "title": "A Strong Baseline for Generalized Few-Shot Semantic Segmentation",
    "abstract": "This paper introduces a generalized few-shot segmentation framework with a\nstraightforward training process and an easy-to-optimize inference phase. In\nparticular, we propose a simple yet effective model based on the well-known\nInfoMax principle, where the Mutual Information (MI) between the learned\nfeature representations and their corresponding predictions is maximized. In\naddition, the terms derived from our MI-based formulation are coupled with a\nknowledge distillation term to retain the knowledge on base classes. With a\nsimple training process, our inference model can be applied on top of any\nsegmentation network trained on base classes. The proposed inference yields\nsubstantial improvements on the popular few-shot segmentation benchmarks\nPASCAL-$5^i$ and COCO-$20^i$. Particularly, for novel classes, the improvement\ngains range from 5% to 20% (PASCAL-$5^i$) and from 2.5% to 10.5% (COCO-$20^i$)\nin the 1-shot and 5-shot scenarios, respectively. Furthermore, we propose a\nmore challenging setting, where performance gaps are further exacerbated. Our\ncode is publicly available at https://github.com/sinahmr/DIaM.",
    "descriptor": "\nComments: 13 pages, 4 figures\n",
    "authors": [
      "Sina Hajimiri",
      "Malik Boudiaf",
      "Ismail Ben Ayed",
      "Jose Dolz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14126"
  },
  {
    "id": "arXiv:2211.14130",
    "title": "Puffin: pitch-synchronous neural waveform generation for fullband speech  on modest devices",
    "abstract": "We present a neural vocoder designed with low-powered Alternative and\nAugmentative Communication devices in mind. By combining elements of successful\nmodern vocoders with established ideas from an older generation of technology,\nour system is able to produce high quality synthetic speech at 48kHz on devices\nwhere neural vocoders are otherwise prohibitively complex. The system is\ntrained adversarially using differentiable pitch synchronous overlap add, and\nreduces complexity by relying on pitch synchronous Inverse Short-Time Fourier\nTransform (ISTFT) to generate speech samples. Our system achieves comparable\nquality with a strong (HiFi-GAN) baseline while using only a fraction of the\ncompute. We present results of a perceptual evaluation as well as an analysis\nof system complexity.",
    "descriptor": "\nComments: ICASSP 2023 submission\n",
    "authors": [
      "Oliver Watts",
      "Lovisa Wihlborg",
      "Cassia Valentini-Botinhao"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.14130"
  },
  {
    "id": "arXiv:2211.14133",
    "title": "PipeFisher: Efficient Training of Large Language Models Using Pipelining  and Fisher Information Matrices",
    "abstract": "Pipeline parallelism enables efficient training of Large Language Models\n(LLMs) on large-scale distributed accelerator clusters. Yet, pipeline bubbles\nduring startup and tear-down reduce the utilization of accelerators. Although\nefficient pipeline schemes with micro-batching and bidirectional pipelines have\nbeen proposed to maximize utilization, a significant number of bubbles cannot\nbe filled using synchronous forward and backward passes. To address this\nproblem, we suggest that extra work be assigned to the bubbles to gain\nauxiliary benefits in LLM training. As an example in this direction, we propose\nPipeFisher, which assigns the work of K-FAC, a second-order optimization method\nbased on the Fisher information matrix, to the bubbles to accelerate\nconvergence. In Phase 1 pretraining of BERT-Base and -Large models, PipeFisher\nreduces the (simulated) training time to 50-75% compared to training with a\nfirst-order optimizer by greatly improving the accelerator utilization and\nbenefiting from the improved convergence by K-FAC.",
    "descriptor": "",
    "authors": [
      "Kazuki Osawa",
      "Shigang Li",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14133"
  },
  {
    "id": "arXiv:2211.14134",
    "title": "Evaluation of the impact of the indiscernibility relation on the  fuzzy-rough nearest neighbours algorithm",
    "abstract": "Fuzzy rough sets are well-suited for working with vague, imprecise or\nuncertain information and have been succesfully applied in real-world\nclassification problems. One of the prominent representatives of this theory is\nfuzzy-rough nearest neighbours (FRNN), a classification algorithm based on the\nclassical k-nearest neighbours algorithm. The crux of FRNN is the\nindiscernibility relation, which measures how similar two elements in the data\nset of interest are. In this paper, we investigate the impact of this\nindiscernibility relation on the performance of FRNN classification. In\naddition to relations based on distance functions and kernels, we also explore\nthe effect of distance metric learning on FRNN for the first time. Furthermore,\nwe also introduce an asymmetric, class-specific relation based on the\nMahalanobis distance which uses the correlation within each class, and which\nshows a significant improvement over the regular Mahalanobis distance, but is\nstill beaten by the Manhattan distance. Overall, the Neighbourhood Components\nAnalysis algorithm is found to be the best performer, trading speed for\naccuracy.",
    "descriptor": "",
    "authors": [
      "Henri Bollaert",
      "Chris Cornelis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14134"
  },
  {
    "id": "arXiv:2211.14138",
    "title": "The TSN Building Blocks in Linux",
    "abstract": "Various application areas e.g. industrial automation, professional\naudio-video, automotive in-vehicle, aerospace on-board, and mobile fronthaul\nnetworks require deterministic communication: loss-less forwarding with bounded\nmaximum latency. There is a lot of ongoing standardization activity in\ndifferent organizations to provide vendor-agnostic building blocks for\nTime-Sensitive Networking (TSN), what is aimed as the universal solution for\ndeterministic forwarding in OSI Layer-2 networks. Furthermore, the\nimplementation of those standards is also happening in Linux. Some of them\nrequire software changes only, but others have hardware support requirements.\nIn this paper, we give an overview of the implementation of the main TSN\nstandards in the mainline Linux kernel. Furthermore, we provide measurement\nresults on key functionality in support of TSN, e.g., scheduled transmission\nand Linux bridging characteristics.",
    "descriptor": "\nComments: Draft of the paper submitted to Netdev 0x16 conference. Link to the submission: this https URL\n",
    "authors": [
      "Ferenc Fejes",
      "P\u00e9ter Antal",
      "M\u00e1rton Kerekes"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.14138"
  },
  {
    "id": "arXiv:2211.14143",
    "title": "Efficient a Posteriori Error Control of a Consistent Atomistic/Continuum  Coupling Method for Two Dimensional Crystalline Defects",
    "abstract": "Adaptive atomistic/continuum (a/c) coupling method is an important method for\nthe simulation of material and atomistic systems with defects to achieve the\nbalance of accuracy and efficiency. Residual based a posteriori error estimator\nis often employed in the adaptive algorithm to provide an estimate of the error\nof the strain committed by applying the continuum approximation for the\natomistic system and the finite element discretization in the continuum region.\nIn this work, we propose a theory based approximation for the residual based a\nposteriori error estimator which greatly improves the efficiency of the\nadaptivity. In particular, the numerically expensive modeling residual is only\ncomputed exactly in a small region around the coupling interface but replaced\nby a theoretically justified approximation by the coarsening residual outside\nthat region. We present a range of adaptive computations based on our modified\na posteriori error estimator and its variants for different types of\ncrystalline defects some of which are not considered in previous related\nliterature of the adaptive a/c methods. The numerical results show that,\ncompared with the original residual based error estimator, the adaptive\nalgorithm using the modified error estimator with properly chosen parameters\nleads to the same optimal convergence rate of the error but reduces the\ncomputational cost by one order with respect to the number of degrees of\nfreedom.",
    "descriptor": "",
    "authors": [
      "Yangshuai Wang",
      "Hao Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.14143"
  },
  {
    "id": "arXiv:2211.14144",
    "title": "Graph Convolutional Network-based Feature Selection for High-dimensional  and Low-sample Size Data",
    "abstract": "Feature selection is a powerful dimension reduction technique which selects a\nsubset of relevant features for model construction. Numerous feature selection\nmethods have been proposed, but most of them fail under the high-dimensional\nand low-sample size (HDLSS) setting due to the challenge of overfitting. In\nthis paper, we present a deep learning-based method - GRAph Convolutional\nnEtwork feature Selector (GRACES) - to select important features for HDLSS\ndata. We demonstrate empirical evidence that GRACES outperforms other feature\nselection methods on both synthetic and real-world datasets.",
    "descriptor": "\nComments: 24 pages, 4 figures, 4 tables\n",
    "authors": [
      "Can Chen",
      "Scott T. Weiss",
      "Yang-Yu Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14144"
  },
  {
    "id": "arXiv:2211.14149",
    "title": "Estimating a Personalized Basal Insulin Dose from Short-Term Closed-Loop  Data in Type 2 Diabetes",
    "abstract": "In type 2 diabetes (T2D) treatment, finding a safe and effective basal\ninsulin dose is a challenge. The dose-response is highly individual and to\nensure safety, people with T2D titrate by slowly increasing the daily insulin\ndose to meet treatment targets. This titration can take months. To ease and\naccelerate the process, we use short-term artificial pancreas (AP) treatment\ntailored for initial titration and apply it as a diagnostic tool. Specifically,\nwe present a method to automatically estimate a personalized daily dose of\nbasal insulin from closed-loop data collected with an AP. Based on AP-data from\na stochastic simulation model, we employ the continuous-discrete extended\nKalman filter and a maximum likelihood approach to estimate parameters in a\nsimple dose-response model for 100 virtual people. With the identified model,\nwe compute a daily dose of basal insulin to meet treatment targets for each\nindividual. We test the personalized dose and evaluate the treatment outcomes\nagainst clinical reference values. In the tested simulation setup, the proposed\nmethod is feasible. However, more extensive tests will reveal whether it can be\ndeemed safe for clinical implementation.",
    "descriptor": "\nComments: 6 pages, 4 figures, 1 table. Accepted for publication in Proceedings of the 2022 61st IEEE Conference on Decision and Control (CDC)\n",
    "authors": [
      "Sarah Ellinor Engell",
      "Tinna Bj\u00f6rk Arad\u00f3ttir",
      "Tobias K. S. Ritschel",
      "Henrik Bengtsson",
      "John Bagterp J\u00f8rgensen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.14149"
  },
  {
    "id": "arXiv:2211.14154",
    "title": "Interaction Visual Transformer for Egocentric Action Anticipation",
    "abstract": "Human-object interaction is one of the most important visual cues that has\nnot been explored for egocentric action anticipation. We propose a novel\nTransformer variant to model interactions by computing the change in the\nappearance of objects and human hands due to the execution of the actions and\nuse those changes to refine the video representation. Specifically, we model\ninteractions between hands and objects using Spatial Cross-Attention (SCA) and\nfurther infuse contextual information using Trajectory Cross-Attention to\nobtain environment-refined interaction tokens. Using these tokens, we construct\nan interaction-centric video representation for action anticipation. We term\nour model InAViT which achieves state-of-the-art action anticipation\nperformance on large-scale egocentric datasets EPICKTICHENS100 (EK100) and\nEGTEA Gaze+. InAViT outperforms other visual transformer-based methods\nincluding object-centric video representation. On the EK100 evaluation server,\nInAViT is the top-performing method on the public leaderboard (at the time of\nsubmission) where it outperforms the second-best model by 3.3% on mean-top5\nrecall.",
    "descriptor": "",
    "authors": [
      "Debaditya Roy",
      "Ramanathan Rajendiran",
      "Basura Fernando"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14154"
  },
  {
    "id": "arXiv:2211.14155",
    "title": "Caching Historical Embeddings in Conversational Search",
    "abstract": "Rapid response, namely low latency, is fundamental in search applications; it\nis particularly so in interactive search sessions, such as those encountered in\nconversational settings. An observation with a potential to reduce latency\nasserts that conversational queries exhibit a temporal locality in the lists of\ndocuments retrieved. Motivated by this observation, we propose and evaluate a\nclient-side document embedding cache, improving the responsiveness of\nconversational search systems. By leveraging state-of-the-art dense retrieval\nmodels to abstract document and query semantics, we cache the embeddings of\ndocuments retrieved for a topic introduced in the conversation, as they are\nlikely relevant to successive queries. Our document embedding cache implements\nan efficient metric index, answering nearest-neighbor similarity queries by\nestimating the approximate result sets returned. We demonstrate the efficiency\nachieved using our cache via reproducible experiments based on TREC CAsT\ndatasets, achieving a hit rate of up to 75% without degrading answer quality.\nOur achieved high cache hit rates significantly improve the responsiveness of\nconversational systems while likewise reducing the number of queries managed on\nthe search back-end.",
    "descriptor": "",
    "authors": [
      "Ophir Frieder",
      "Ida Mele",
      "Cristina Ioana Muntean",
      "Franco Maria Nardini",
      "Raffaele Perego",
      "Nicola Tonellotto"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.14155"
  },
  {
    "id": "arXiv:2211.14157",
    "title": "Learning 3D Scene Priors with 2D Supervision",
    "abstract": "Holistic 3D scene understanding entails estimation of both layout\nconfiguration and object geometry in a 3D environment. Recent works have shown\nadvances in 3D scene estimation from various input modalities (e.g., images, 3D\nscans), by leveraging 3D supervision (e.g., 3D bounding boxes or CAD models),\nfor which collection at scale is expensive and often intractable. To address\nthis shortcoming, we propose a new method to learn 3D scene priors of layout\nand shape without requiring any 3D ground truth. Instead, we rely on 2D\nsupervision from multi-view RGB images. Our method represents a 3D scene as a\nlatent vector, from which we can progressively decode to a sequence of objects\ncharacterized by their class categories, 3D bounding boxes, and meshes. With\nour trained autoregressive decoder representing the scene prior, our method\nfacilitates many downstream applications, including scene synthesis,\ninterpolation, and single-view reconstruction. Experiments on 3D-FRONT and\nScanNet show that our method outperforms state of the art in single-view\nreconstruction, and achieves state-of-the-art results in scene synthesis\nagainst baselines which require for 3D supervision.",
    "descriptor": "\nComments: Video: this https URL Project: this https URL\n",
    "authors": [
      "Yinyu Nie",
      "Angela Dai",
      "Xiaoguang Han",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14157"
  },
  {
    "id": "arXiv:2211.14158",
    "title": "Isolation Scheme for Virtual Network Embedding Based on Reinforcement  Learning for Smart City Vertical Industries",
    "abstract": "Modern ICT infrastructure is built on virtualization technologies, which\nconnect a diverse set of dedicated networks to support a variety of smart city\nvertical industries (SCVI), such as energy, healthcare, manufacturing,\nentertainment, and intelligent transportation. The wide range of SCVI use cases\nrequire services to operate continuously and reliably. The violation of\nisolation by a specific SCVI, that is, a SCVI network must operate\nindependently of other SCVI networks, complicates service assurance for\ninfrastructure providers (InPs) significantly. As a result, a solution must be\nconsidered from the standpoint of isolation, which raises two issues: first,\nthese SCVI networks have diverse resource requirements, and second, they\nnecessitate additional functionality requirements such as isolation. Based on\nthe above two problems faced by SCVI use cases, we propose a virtual network\nembedding (VNE) algorithm with resource and isolation constraints based on deep\nreinforcement learning (DRL). The proposed DRL_VNE algorithm can automatically\nadapt to changing dynamics and outperforms existing three state-of-the-art\nsolutions by 12.9%, 19.0% and 4% in terms of the acceptance rate, the long-term\naverage revenue, and long-term average revenue to cost ratio.",
    "descriptor": "\nComments: 6 pages, 4 figures, 3 tables, 2 algorithms\n",
    "authors": [
      "Ali Gohar"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14158"
  },
  {
    "id": "arXiv:2211.14160",
    "title": "Exposure and Emergence in Usage-Based Grammar: Computational Experiments  in 35 Languages",
    "abstract": "This paper uses computational experiments to explore the role of exposure in\nthe emergence of construction grammars. While usage-based grammars are\nhypothesized to depend on a learner's exposure to actual language use, the\nmechanisms of such exposure have only been studied in a few constructions in\nisolation. This paper experiments with (i) the growth rate of the\nconstructicon, (ii) the convergence rate of grammars exposed to independent\nregisters, and (iii) the rate at which constructions are forgotten when they\nhave not been recently observed. These experiments show that the lexicon grows\nmore quickly than the grammar and that the growth rate of the grammar is not\ndependent on the growth rate of the lexicon. At the same time,\nregister-specific grammars converge onto more similar constructions as the\namount of exposure increases. This means that the influence of specific\nregisters becomes less important as exposure increases. Finally, the rate at\nwhich constructions are forgotten when they have not been recently observed\nmirrors the growth rate of the constructicon. This paper thus presents a\ncomputational model of usage-based grammar that includes both the emergence and\nthe unentrenchment of constructions.",
    "descriptor": "",
    "authors": [
      "Jonathan Dunn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.14160"
  },
  {
    "id": "arXiv:2211.14163",
    "title": "Contactless Haptic Display Through Magnetic Field Control",
    "abstract": "Haptic rendering enables people to touch, perceive, and manipulate virtual\nobjects in a virtual environment. Using six cascaded identical hollow disk\nelectromagnets and a small permanent magnet attached to an operator's finger,\nthis paper proposes and develops an untethered haptic interface through\nmagnetic field control. The concentric hole inside the six cascaded\nelectromagnets provides the workspace, where the 3D position of the permanent\nmagnet is tracked with a Microsoft Kinect sensor. The driving currents of six\ncascaded electromagnets are calculated in real-time for generating the desired\nmagnetic force. Offline data from an FEA (finite element analysis) based\nsimulation, determines the relationship between the magnetic force, the driving\ncurrents, and the position of the permanent magnet. A set of experiments\nincluding the virtual object recognition experiment, the virtual surface\nidentification experiment, and the user perception evaluation experiment were\nconducted to demonstrate the proposed system, where Microsoft HoloLens\nholographic glasses are used for visual rendering. The proposed magnetic haptic\ndisplay leads to an untethered and non-contact interface for natural haptic\nrendering applications, which overcomes the constraints of mechanical linkages\nin tool-based traditional haptic devices.",
    "descriptor": "",
    "authors": [
      "Xiong Lu",
      "Yuxing Yan",
      "Beibei Qi",
      "Huang Qian",
      "Junbin Sun",
      "Aaron Quigley"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.14163"
  },
  {
    "id": "arXiv:2211.14173",
    "title": "NeuralUDF: Learning Unsigned Distance Fields for Multi-view  Reconstruction of Surfaces with Arbitrary Topologies",
    "abstract": "We present a novel method, called NeuralUDF, for reconstructing surfaces with\narbitrary topologies from 2D images via volume rendering. Recent advances in\nneural rendering based reconstruction have achieved compelling results.\nHowever, these methods are limited to objects with closed surfaces since they\nadopt Signed Distance Function (SDF) as surface representation which requires\nthe target shape to be divided into inside and outside. In this paper, we\npropose to represent surfaces as the Unsigned Distance Function (UDF) and\ndevelop a new volume rendering scheme to learn the neural UDF representation.\nSpecifically, a new density function that correlates the property of UDF with\nthe volume rendering scheme is introduced for robust optimization of the UDF\nfields. Experiments on the DTU and DeepFashion3D datasets show that our method\nnot only enables high-quality reconstruction of non-closed shapes with complex\ntypologies, but also achieves comparable performance to the SDF based methods\non the reconstruction of closed surfaces.",
    "descriptor": "\nComments: Visit our project page at this https URL\n",
    "authors": [
      "Xiaoxiao Long",
      "Cheng Lin",
      "Lingjie Liu",
      "Yuan Liu",
      "Peng Wang",
      "Christian Theobalt",
      "Taku Komura",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14173"
  },
  {
    "id": "arXiv:2211.14175",
    "title": "MCFFA-Net: Multi-Contextual Feature Fusion and Attention Guided Network  for Apple Foliar Disease Classification",
    "abstract": "Numerous diseases cause severe economic loss in the apple production-based\nindustry. Early disease identification in apple leaves can help to stop the\nspread of infections and provide better productivity. Therefore, it is crucial\nto study the identification and classification of different apple foliar\ndiseases. Various traditional machine learning and deep learning methods have\naddressed and investigated this issue. However, it is still challenging to\nclassify these diseases because of their complex background, variation in the\ndiseased spot in the images, and the presence of several symptoms of multiple\ndiseases on the same leaf. This paper proposes a novel transfer learning-based\nstacked ensemble architecture named MCFFA-Net, which is composed of three\npre-trained architectures named MobileNetV2, DenseNet201, and InceptionResNetV2\nas backbone networks. We also propose a novel multi-scale dilated residual\nconvolution module to capture multi-scale contextual information with several\ndilated receptive fields from the extracted features. Channel-based attention\nmechanism is provided through squeeze and excitation networks to make the\nMCFFA-Net focused on the relevant information in the multi-receptive fields.\nThe proposed MCFFA-Net achieves a classification accuracy of 90.86%.",
    "descriptor": "\nComments: 7 pages, 6 figures, ICCIT 2022 submission, Conference\n",
    "authors": [
      "Md. Rayhan Ahmed",
      "Adnan Ferdous Ashrafi",
      "Raihan Uddin Ahmed",
      "Tanveer Ahmed"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14175"
  },
  {
    "id": "arXiv:2211.14177",
    "title": "Overcoming Catastrophic Forgetting by XAI",
    "abstract": "Explaining the behaviors of deep neural networks, usually considered as black\nboxes, is critical especially when they are now being adopted over diverse\naspects of human life. Taking the advantages of interpretable machine learning\n(interpretable ML), this work proposes a novel tool called Catastrophic\nForgetting Dissector (or CFD) to explain catastrophic forgetting in continual\nlearning settings. We also introduce a new method called Critical Freezing\nbased on the observations of our tool. Experiments on ResNet articulate how\ncatastrophic forgetting happens, particularly showing which components of this\nfamous network are forgetting. Our new continual learning algorithm defeats\nvarious recent techniques by a significant margin, proving the capability of\nthe investigation. Critical freezing not only attacks catastrophic forgetting\nbut also exposes explainability.",
    "descriptor": "\nComments: Master of Science Thesis at KAIST; 24 pages; Keywords: continual learning, catastrophic forgetting, XAI, attribution map, interpretability\n",
    "authors": [
      "Giang Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14177"
  },
  {
    "id": "arXiv:2211.14196",
    "title": "Post-Quantum Signatures in DNSSEC via Request-Based Fragmentation",
    "abstract": "The Domain Name System Security Extensions (DNSSEC) provide authentication of\nDNS responses using digital signatures. DNS operates primarily over UDP, which\nleads to several constraints: notably, packets should be at most 1232 bytes\nlong to avoid problems during transmission. Larger DNS responses either need to\nbe fragmented into several UDP responses or the request would need to be\nrepeated over TCP, neither of which is sufficiently reliable in today's DNS\necosystem. While RSA or elliptic curve digital signatures are sufficiently\nsmall to avoid this problem, even for DNSSEC packets containing both a public\nkey and a signature, this problem is unavoidable when considering the larger\nsizes of post-quantum schemes.\nWe propose ARRF, a method of fragmenting DNS resource records at the\napplication layer (rather than the transport layer) that is request-based,\nmeaning the initial response contains a truncated fragment and then the\nrequester sends follow-up requests for the remaining fragments. Using\nrequest-based fragmentation avoids problems identified for several previously\nproposed (and rejected) application-level DNS fragmentation techniques. We\nimplement our approach and evaluate its performance in a simulated network when\nused for the three post-quantum digital signature schemes selected by NIST for\nstandardization (Falcon, Dilithium, and SPHINCS+) at the 128-bit security\nlevel. Our experiments show that our request-based fragmentation approach\nprovides substantially lower resolution times compared to standard DNS over UDP\nwith TCP fallback, for all the tested post-quantum algorithms, and with less\ndata transmitted in the case of both Falcon and Dilithium. Furthermore, our\nrequest-based fragmentation design can be implemented relatively easily: our\nimplementation is in fact a small daemon that can sit in front of a DNS name\nserver or resolver to fragment/reassemble transparently.",
    "descriptor": "",
    "authors": [
      "Jason Goertzen",
      "Douglas Stebila"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.14196"
  },
  {
    "id": "arXiv:2211.14206",
    "title": "McEliece cryptosystem based on Plotkin construction with QC-MDPC and  QC-LDPC codes",
    "abstract": "In this paper, we propose a new variant of the McEliece cryptosystem using\ntwo families of quasi-cyclic codes: low density parity check codes (QC-LDPC)\nand moderate density parity check codes (QC-MDPC) (QC-MDPC). Due to the low\nweight codewords in the dual of LDPC codes, this family of codes is vulnerable\nto dual code attacks, making it unsuitable for use with the McEliece\ncryptosystem. However, this is not the case in our proposal, and it is possible\nby using the (U |U + V ) construction to concatenate LDPC codes with MDPC\ncodes. We will demonstrate that our proposed cryptosystem can withstand dual\ncode and generic decoding attacks, and that the public key can be reduced by\nleveraging the quasi-cyclic property and the Plotkin construction.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Belkacem Imine",
      "Naima Hadj-Said",
      "Herv\u00e9 Tal\u00e9 Kalachi",
      "Adda Ali-Pacha"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.14206"
  },
  {
    "id": "arXiv:2211.14207",
    "title": "Invariance-Aware Randomized Smoothing Certificates",
    "abstract": "Building models that comply with the invariances inherent to different\ndomains, such as invariance under translation or rotation, is a key aspect of\napplying machine learning to real world problems like molecular property\nprediction, medical imaging, protein folding or LiDAR classification. For the\nfirst time, we study how the invariances of a model can be leveraged to\nprovably guarantee the robustness of its predictions. We propose a gray-box\napproach, enhancing the powerful black-box randomized smoothing technique with\nwhite-box knowledge about invariances. First, we develop gray-box certificates\nbased on group orbits, which can be applied to arbitrary models with invariance\nunder permutation and Euclidean isometries. Then, we derive provably tight\ngray-box certificates. We experimentally demonstrate that the provably tight\ncertificates can offer much stronger guarantees, but that in practical\nscenarios the orbit-based method is a good approximation.",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Jan Schuchardt",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14207"
  },
  {
    "id": "arXiv:2211.14208",
    "title": "GREAD: Graph Neural Reaction-Diffusion Equations",
    "abstract": "Graph neural networks (GNNs) are one of the most popular research topics for\ndeep learning. GNN methods typically have been designed on top of the graph\nsignal processing theory. In particular, diffusion equations have been widely\nused for designing the core processing layer of GNNs and therefore, they are\ninevitably vulnerable to the oversmoothing problem. Recently, a couple of\npapers paid attention to reaction equations in conjunctions with diffusion\nequations. However, they all consider limited forms of reaction equations. To\nthis end, we present a reaction-diffusion equation-based GNN method that\nconsiders all popular types of reaction equations in addition to one special\nreaction equation designed by us. To our knowledge, our paper is one of the\nmost comprehensive studies on reaction-diffusion equation-based GNNs. In our\nexperiments with 9 datasets and 17 baselines, our method, called GREAD,\noutperforms them in almost all cases. Further synthetic data experiments show\nthat GREAD mitigates the oversmoothing and performs well for various homophily\nrates.",
    "descriptor": "",
    "authors": [
      "Jeongwhan Choi",
      "Seoyoung Hong",
      "Noseong Park",
      "Sung-Bae Cho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14208"
  },
  {
    "id": "arXiv:2211.14212",
    "title": "On Krylov Methods for Large Scale CBCT Reconstruction",
    "abstract": "Krylov subspace methods are a powerful family of iterative solvers for linear\nsystems of equations, which are commonly used for inverse problems due to their\nintrinsic regularization properties. Moreover, these methods are naturally\nsuited to solve large-scale problems, as they only require matrix-vector\nproducts with the system matrix (and its adjoint) to compute approximate\nsolutions, and they display a very fast convergence. Even if this class of\nmethods has been widely researched and studied in the numerical linear algebra\ncommunity, its use in applied medical physics and applied engineering is still\nvery limited. e.g. in realistic large-scale Computed Tomography (CT) problems,\nand more specifically in Cone Beam CT (CBCT). This work attempts to breach this\ngap by providing a general framework for the most relevant Krylov subspace\nmethods applied to 3D CT problems, including the most well-known Krylov solvers\nfor non-square systems (CGLS, LSQR, LSMR), possibly in combination with\nTikhonov regularization, and methods that incorporate total variation (TV)\nregularization. This is provided within an open source framework: the\nTomographic Iterative GPU-based Reconstruction (TIGRE) toolbox, with the idea\nof promoting accessibility and reproducibility of the results for the\nalgorithms presented. Finally, numerical results in synthetic and real-world 3D\nCT applications (medical CBCT and {\\mu}-CT datasets) are provided to showcase\nand compare the different Krylov subspace methods presented in the paper, as\nwell as their suitability for different kinds of problems.",
    "descriptor": "\nComments: submitted\n",
    "authors": [
      "Malena Sabate Landman",
      "Ander Biguri",
      "Sepideh Hatamikia",
      "Richard Boardman",
      "John Aston",
      "Carola-Bibiane Schonlieb"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.14212"
  },
  {
    "id": "arXiv:2211.14213",
    "title": "Secure Distributed Gram Matrix Multiplication",
    "abstract": "The Gram matrix of a matrix $A$ is defined as $AA^T$ (or $A^TA$). Computing\nthe Gram matrix is an important operation in many applications, such as linear\nregression with the least squares method, where the explicit solution formula\nincludes the Gram matrix of the data matrix. Secure distributed matrix\nmultiplication (SDMM) can be used to compute the product of two matrices using\nthe help of worker servers. If a Gram matrix were computed using SDMM, the data\nmatrix would need to be encoded twice, which causes an unnecessary overhead in\nthe communication cost. We propose a new scheme for this purpose called secure\ndistributed Gram matrix multiplication (SDGMM). It can leverage the advantages\nof computing a Gram matrix instead of a regular matrix product.",
    "descriptor": "\nComments: 12 pages, 1 figure\n",
    "authors": [
      "Okko Makkonen",
      "Camilla Hollanti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.14213"
  },
  {
    "id": "arXiv:2211.14214",
    "title": "Complexity Framework for Forbidden Subgraphs: When Hardness Is Not  Preserved under Edge Subdivision",
    "abstract": "A graph $G$ is $H$-subgraph-free if $G$ does not contain $H$ as a (not\nnecessarily induced) subgraph. We make inroads into the classification of three\nproblems for $H$-subgraph-free graphs that have the properties that they are\nsolvable in polynomial time on classes of bounded treewidth and NP-complete on\nsubcubic graphs, yet NP-hardness is not preserved under edge subdivision. The\nthree problems are $k$-Induced Disjoint Paths, $C_5$-Colouring and Hamilton\nCycle. Although we do not complete the classifications, we show that the\nboundary between polynomial time and NP-complete differs for $C_5$-Colouring\nfrom the other two problems.",
    "descriptor": "",
    "authors": [
      "Barnaby Martin",
      "Sukanya Pandey",
      "Daniel Paulusma",
      "Siani Smith",
      "Erik Jan van Leeuwen"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.14214"
  },
  {
    "id": "arXiv:2211.14221",
    "title": "High-Dimensional Causal Discovery: Learning from Inverse Covariance via  Independence-based Decomposition",
    "abstract": "Inferring causal relationships from observational data is a fundamental yet\nhighly complex problem when the number of variables is large. Recent advances\nhave made much progress in learning causal structure models (SEMs) but still\nface challenges in scalability. This paper aims to efficiently discover causal\nDAGs from high-dimensional data. We investigate a way of recovering causal DAGs\nfrom inverse covariance estimators of the observational data. The proposed\nalgorithm, called ICID (inverse covariance estimation and {\\it\nindependence-based} decomposition), searches for a decomposition of the inverse\ncovariance matrix that preserves its nonzero patterns. This algorithm benefits\nfrom properties of positive definite matrices supported on {\\it chordal} graphs\nand the preservation of nonzero patterns in their Cholesky decomposition; we\nfind exact mirroring between the support-preserving property and the\nindependence-preserving property of our decomposition method, which explains\nits effectiveness in identifying causal structures from the data distribution.\nWe show that the proposed algorithm recovers causal DAGs with a complexity of\n$O(d^2)$ in the context of sparse SEMs. The advantageously low complexity is\nreflected by good scalability of our algorithm in thorough experiments and\ncomparisons with state-of-the-art algorithms.",
    "descriptor": "",
    "authors": [
      "Shuyu Dong",
      "Kento Uemura",
      "Akito Fujii",
      "Shuang Chang",
      "Yusuke Koyanagi",
      "Koji Maruhashi",
      "Mich\u00e8le Sebag"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.14221"
  },
  {
    "id": "arXiv:2211.14222",
    "title": "The Effect of Epigenetic Blocking on Dynamic Multi-Objective  Optimisation Problems",
    "abstract": "Hundreds of Evolutionary Computation approaches have been reported. From an\nevolutionary perspective they focus on two fundamental mechanisms: cultural\ninheritance in Swarm Intelligence and genetic inheritance in Evolutionary\nAlgorithms. Contemporary evolutionary biology looks beyond genetic inheritance,\nproposing a so-called ``Extended Evolutionary Synthesis''. Many concepts from\nthe Extended Evolutionary Synthesis have been left out of Evolutionary\nComputation as interest has moved toward specific implementations of the same\ngeneral mechanisms. One such concept is epigenetic inheritance, which is\nincreasingly considered central to evolutionary thinking. Epigenetic mechanisms\nallow quick non- or partially-genetic adaptations to environmental changes.\nDynamic multi-objective optimisation problems represent similar circumstances\nto the natural world where fitness can be determined by multiple objectives\n(traits), and the environment is constantly changing.\nThis paper asks if the advantages that epigenetic inheritance provide in the\nnatural world are replicated in dynamic multi-objective optimisation problems.\nSpecifically, an epigenetic blocking mechanism is applied to a state-of-the-art\nmulti-objective genetic algorithm, MOEA/D-DE, and its performance is compared\non three sets of dynamic test functions, FDA, JY, and UDF. The mechanism shows\nimproved performance on 12 of the 16 test problems, providing initial evidence\nthat more algorithms should explore the wealth of epigenetic mechanisms seen in\nthe natural world.",
    "descriptor": "\nComments: Published in GECCO '22: Proceedings of the Genetic and Evolutionary Computation Conference Companion\n",
    "authors": [
      "Sizhe Yuen",
      "Thomas H.G. Ezard",
      "Adam J. Sobey"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14222"
  },
  {
    "id": "arXiv:2211.14227",
    "title": "Bypass Exponential Time Preprocessing: Fast Neural Network Training via  Weight-Data Correlation Preprocessing",
    "abstract": "Over the last decade, deep neural networks have transformed our society, and\nthey are already widely applied in various machine learning applications.\nState-of-art deep neural networks are becoming larger in size every year to\ndeliver increasing model accuracy, and as a result, model training consumes\nsubstantial computing resources and will only consume more in the future. Using\ncurrent training methods, in each iteration, to process a data point $x \\in\n\\mathbb{R}^d$ in a layer, we need to spend $\\Theta(md)$ time to evaluate all\nthe $m$ neurons in the layer. This means processing the entire layer takes\n$\\Theta(nmd)$ time for $n$ data points. Recent work [Song, Yang and Zhang,\nNeurIPS 2021] reduces this time per iteration to $o(nmd)$, but requires\nexponential time to preprocess either the data or the neural network weights,\nmaking it unlikely to have practical usage.\nIn this work, we present a new preprocessing method that simply stores the\nweight-data correlation in a tree data structure in order to quickly,\ndynamically detect which neurons fire at each iteration. Our method requires\nonly $O(nmd)$ time in preprocessing and still achieves $o(nmd)$ time per\niteration. We complement our new algorithm with a lower bound, proving that\nassuming a popular conjecture from complexity theory, one could not\nsubstantially speed up our algorithm for dynamic detection of firing neurons.",
    "descriptor": "",
    "authors": [
      "Josh Alman",
      "Jiehao Liang",
      "Zhao Song",
      "Ruizhe Zhang",
      "Danyang Zhuo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.14227"
  },
  {
    "id": "arXiv:2211.14228",
    "title": "GPT-3-driven pedagogical agents for training children's curious  question-asking skills",
    "abstract": "Students' ability to ask curious questions is a crucial skill that improves\ntheir learning processes. To train this skill, previous research has used a\nconversational agent that propose specific cues to prompt children's curiosity\nduring learning. Despite showing pedagogical efficiency, this method is still\nlimited since it relies on generating the said prompts by hand for each\neducational resource, which can be a very long and costly process. In this\ncontext, we leverage the advances in the natural language processing field and\nexplore using a large language model (GPT-3) to automate the generation of this\nagent's curiosity-prompting cues to help children ask more and deeper\nquestions. We then used this study to investigate a different\ncuriosity-prompting behavior for the agent. The study was conducted with 75\nstudents aged between 9 and 10. They either interacted with a hand-crafted\nconversational agent that proposes \"closed\" manually-extracted cues leading to\npredefined questions, a GPT-3-driven one that proposes the same type of cues,\nor a GPT-3-driven one that proposes \"open\" cues that can lead to several\npossible questions. Results showed a similar question-asking performance\nbetween children who had the two \"closed\" agents, but a significantly better\none for participants with the \"open\" agent. Our first results suggest the\nvalidity of using GPT-3 to facilitate the implementation of\ncuriosity-stimulating learning technologies. In a second step, we also show\nthat GPT-3 can be efficient in proposing the relevant open cues that leave\nchildren with more autonomy to express their curiosity.",
    "descriptor": "",
    "authors": [
      "Rania Abdelghani",
      "Yen-Hsiang Wang",
      "Xingdi Yuan",
      "Tong Wang",
      "H\u00e9l\u00e8ne Sauz\u00e9on",
      "Pierre-Yves Oudeyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.14228"
  },
  {
    "id": "arXiv:2211.14233",
    "title": "strategFTO: Untimed control for timed opacity",
    "abstract": "We introduce a prototype tool strategFTO addressing the verification of a\nsecurity property in critical software. We consider a recent definition of\ntimed opacity where an attacker aims to deduce some secret while having access\nonly to the total execution time. The system, here modeled by timed automata,\nis deemed opaque if for any execution time, there are either no corresponding\nruns, or both public and private corresponding runs. We focus on the untimed\ncontrol problem: exhibiting a controller, i.e., a set of allowed actions, such\nthat the system restricted to those actions is fully timed-opaque. We first\nshow that this problem is not more complex than the full timed opacity problem,\nand then we propose an algorithm, implemented and evaluated in practice.",
    "descriptor": "\nComments: This work is partially supported by the ANR-NRF French-Singaporean research program ProMiS (ANR-19-CE25-0015 / 2019 ANR NRF 0092) and the ANR research program BisoUS. Experiments presented in this paper were carried out using the Grid'5000 testbed, supported by a scientific interest group hosted by Inria and including CNRS, RENATER and several universities as well as other organizations\n",
    "authors": [
      "\u00c9tienne Andr\u00e9",
      "Shapagat Bolat",
      "Engel Lefaucheux",
      "Dylan Marinho"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.14233"
  },
  {
    "id": "arXiv:2211.14234",
    "title": "Bovine Tuberculosis in Britain: identifying signatures of polarisation  and controversy on Twitter",
    "abstract": "Approaches to disease control are influenced by and reflected in public\nopinion, and the two are intrinsically entwined. Bovine tuberculosis (bTB) in\nBritish cattle and badgers is one example where there is a high degree of\npolarisation in opinion. Bovine viral diarrhoea (BVD), on the other hand, does\nnot have the same controversy.\nIn this paper we examine how language subjectivity on Twitter differs when\ncomparing the discourses surrounding bTB and BVD, using a combination of\nnetwork analysis and language and sentiment analysis. That data used for this\nstudy was collected from the Twitter public API over a two-year period. We\ninvestigated the network structure, language content, and user profiles of\ntweets featuring both diseases.\nWhile analysing network structure showed little difference between the two\ndisease topics, elements of the structure allowed us to better investigate the\nlanguage structure and profile of users. We found distinct differences between\nthe language and sentiment used in tweets about each disease, and in the\nprofile of the users who were doing the tweeting. We hope that this will guide\nfurther investigation and potential avenues for surveillance or the control of\nmisinformation.",
    "descriptor": "",
    "authors": [
      "Christopher J. Banks",
      "Jessica Enright",
      "Sibylle Mohr",
      "Rowland R. Kao"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.14234"
  },
  {
    "id": "arXiv:2211.14238",
    "title": "Wild-Time: A Benchmark of in-the-Wild Distribution Shift over Time",
    "abstract": "Distribution shift occurs when the test distribution differs from the\ntraining distribution, and it can considerably degrade performance of machine\nlearning models deployed in the real world. Temporal shifts -- distribution\nshifts arising from the passage of time -- often occur gradually and have the\nadditional structure of timestamp metadata. By leveraging timestamp metadata,\nmodels can potentially learn from trends in past distribution shifts and\nextrapolate into the future. While recent works have studied distribution\nshifts, temporal shifts remain underexplored. To address this gap, we curate\nWild-Time, a benchmark of 5 datasets that reflect temporal distribution shifts\narising in a variety of real-world applications, including patient prognosis\nand news classification. On these datasets, we systematically benchmark 13\nprior approaches, including methods in domain generalization, continual\nlearning, self-supervised learning, and ensemble learning. We use two\nevaluation strategies: evaluation with a fixed time split (Eval-Fix) and\nevaluation with a data stream (Eval-Stream). Eval-Fix, our primary evaluation\nstrategy, aims to provide a simple evaluation protocol, while Eval-Stream is\nmore realistic for certain real-world applications. Under both evaluation\nstrategies, we observe an average performance drop of 20% from in-distribution\nto out-of-distribution data. Existing methods are unable to close this gap.\nCode is available at https://wild-time.github.io/.",
    "descriptor": "\nComments: Accepted by NeurIPS 2022 Track on Datasets and Benchmarks\n",
    "authors": [
      "Huaxiu Yao",
      "Caroline Choi",
      "Bochuan Cao",
      "Yoonho Lee",
      "Pang Wei Koh",
      "Chelsea Finn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14238"
  },
  {
    "id": "arXiv:2211.14241",
    "title": "Look Around and Refer: 2D Synthetic Semantics Knowledge Distillation for  3D Visual Grounding",
    "abstract": "The 3D visual grounding task has been explored with visual and language\nstreams comprehending referential language to identify target objects in 3D\nscenes. However, most existing methods devote the visual stream to capturing\nthe 3D visual clues using off-the-shelf point clouds encoders. The main\nquestion we address in this paper is \"can we consolidate the 3D visual stream\nby 2D clues synthesized from point clouds and efficiently utilize them in\ntraining and testing?\". The main idea is to assist the 3D encoder by\nincorporating rich 2D object representations without requiring extra 2D inputs.\nTo this end, we leverage 2D clues, synthetically generated from 3D point\nclouds, and empirically show their aptitude to boost the quality of the learned\nvisual representations. We validate our approach through comprehensive\nexperiments on Nr3D, Sr3D, and ScanRefer datasets and show consistent\nperformance gains compared to existing methods. Our proposed module, dubbed as\nLook Around and Refer (LAR), significantly outperforms the state-of-the-art 3D\nvisual grounding techniques on three benchmarks, i.e., Nr3D, Sr3D, and\nScanRefer. The code is available at https://eslambakr.github.io/LAR.github.io/.",
    "descriptor": "",
    "authors": [
      "Eslam Mohamed Bakr",
      "Yasmeen Alsaedy",
      "Mohamed Elhoseiny"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14241"
  },
  {
    "id": "arXiv:2211.14247",
    "title": "Group Buying Recommendation Model Based on Multi-task Learning",
    "abstract": "In recent years, group buying has become one popular kind of online shopping\nactivity, thanks to its larger sales and lower unit price. Unfortunately,\nresearch seldom focuses on recommendations specifically for group buying by\nnow. Although some recommendation models have been proposed for group\nrecommendation, they can not be directly used to achieve real-world group\nbuying recommendation, due to the essential difference between group\nrecommendation and group buying recommendation. In this paper, we first\nformalize the task of group buying recommendations into two sub-tasks. Then,\nbased on our insights into the correlations and interactions between the two\nsub-tasks, we propose a novel recommendation model for group buying, MGBR,\nbuilt mainly with a multi-task learning module. To improve recommendation\nperformance further, we devise some collaborative expert networks and adjusted\ngates in the multi-task learning module, to promote the information interaction\nbetween the two sub-tasks. Furthermore, we propose two auxiliary losses\ncorresponding to the two sub-tasks, to refine the representation learning in\nour model. Our extensive experiments not only demonstrate that the augmented\nrepresentations in our model result in better performance than previous\nrecommendation models, but also justify the impacts of the specially designed\ncomponents in our model.",
    "descriptor": "",
    "authors": [
      "Shuoyao Zhai",
      "Baichuan Liu",
      "Deqing Yang",
      "Yanghua Xiao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.14247"
  },
  {
    "id": "arXiv:2211.14249",
    "title": "Neural Poisson: Indicator Functions for Neural Fields",
    "abstract": "Implicit neural field generating signed distance field representations (SDFs)\nof 3D shapes have shown remarkable progress in 3D shape reconstruction and\ngeneration. We introduce a new paradigm for neural field representations of 3D\nscenes; rather than characterizing surfaces as SDFs, we propose a\nPoisson-inspired characterization for surfaces as indicator functions optimized\nby neural fields. Crucially, for reconstruction of real scan data, the\nindicator function representation enables simple and effective constraints\nbased on common range sensing inputs, which indicate empty space based on line\nof sight. Such empty space information is intrinsic to the scanning process,\nand incorporating this knowledge enables more accurate surface reconstruction.\nWe show that our approach demonstrates state-of-the-art reconstruction\nperformance on both synthetic and real scanned 3D scene data, with 9.5%\nimprovement in Chamfer distance over state of the art.",
    "descriptor": "\nComments: Video: this https URL\n",
    "authors": [
      "Angela Dai",
      "Matthias Nie\u00dfner"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14249"
  },
  {
    "id": "arXiv:2211.14250",
    "title": "A Note on Model-Free Reinforcement Learning with the Decision-Estimation  Coefficient",
    "abstract": "We consider the problem of interactive decision making, encompassing\nstructured bandits and reinforcement learning with general function\napproximation. Recently, Foster et al. (2021) introduced the\nDecision-Estimation Coefficient, a measure of statistical complexity that lower\nbounds the optimal regret for interactive decision making, as well as a\nmeta-algorithm, Estimation-to-Decisions, which achieves upper bounds in terms\nof the same quantity. Estimation-to-Decisions is a reduction, which lifts\nalgorithms for (supervised) online estimation into algorithms for decision\nmaking. In this note, we show that by combining Estimation-to-Decisions with a\nspecialized form of optimistic estimation introduced by Zhang (2022), it is\npossible to obtain guarantees that improve upon those of Foster et al. (2021)\nby accommodating more lenient notions of estimation error. We use this approach\nto derive regret bounds for model-free reinforcement learning with value\nfunction approximation.",
    "descriptor": "",
    "authors": [
      "Dylan J. Foster",
      "Noah Golowich",
      "Jian Qian",
      "Alexander Rakhlin",
      "Ayush Sekhari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.14250"
  },
  {
    "id": "arXiv:2211.14255",
    "title": "Degenerate Swin to Win: Plain Window-based Transformer without  Sophisticated Operations",
    "abstract": "The formidable accomplishment of Transformers in natural language processing\nhas motivated the researchers in the computer vision community to build Vision\nTransformers. Compared with the Convolution Neural Networks (CNN), a Vision\nTransformer has a larger receptive field which is capable of characterizing the\nlong-range dependencies. Nevertheless, the large receptive field of Vision\nTransformer is accompanied by the huge computational cost. To boost efficiency,\nthe window-based Vision Transformers emerge. They crop an image into several\nlocal windows, and the self-attention is conducted within each window. To bring\nback the global receptive field, window-based Vision Transformers have devoted\na lot of efforts to achieving cross-window communications by developing several\nsophisticated operations. In this work, we check the necessity of the key\ndesign element of Swin Transformer, the shifted window partitioning. We\ndiscover that a simple depthwise convolution is sufficient for achieving\neffective cross-window communications. Specifically, with the existence of the\ndepthwise convolution, the shifted window configuration in Swin Transformer\ncannot lead to an additional performance improvement. Thus, we degenerate the\nSwin Transformer to a plain Window-based (Win) Transformer by discarding\nsophisticated shifted window partitioning. The proposed Win Transformer is\nconceptually simpler and easier for implementation than Swin Transformer.\nMeanwhile, our Win Transformer achieves consistently superior performance than\nSwin Transformer on multiple computer vision tasks, including image\nrecognition, semantic segmentation, and object detection.",
    "descriptor": "",
    "authors": [
      "Tan Yu",
      "Ping Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14255"
  },
  {
    "id": "arXiv:2211.14259",
    "title": "Better Trees for Santa Claus",
    "abstract": "We revisit the problem max-min degree arborescence, which was introduced by\nBateni et al. [STOC'09] as a central special case of the general Santa Claus\nproblem, which constitutes a notorious open question in approximation\nalgorithms. In the former problem we are given a directed graph with sources\nand sinks and our goal is to find vertex disjoint arborescences rooted in the\nsources such that at each non-sink vertex of an arborescence the out-degree is\nat least $k$, where $k$ is to be maximized.\nThis problem is of particular interest, since it appears to capture much of\nthe difficulty of the Santa Claus problem: (1) like in the Santa Claus problem\nthe configuration LP has a large integrality gap in this case and (2) previous\nprogress by Bateni et al. was quickly generalized to the Santa Claus problem\n(Chakrabarty et al. [FOCS'09]). These results remain the state-of-the-art both\nfor the Santa Claus problem and for max-min degree arborescence and they yield\na polylogarithmic approximation in quasi-polynomial time. We present an\nexponential improvement to this, a $\\mathrm{poly}(\\log\\log n)$-approximation in\nquasi-polynomial time for the max-min degree arborescence problem. To the best\nof our knowledge, this is the first example of breaking the logarithmic barrier\nfor a special case of the Santa Claus problem, where the configuration LP\ncannot be utilized.",
    "descriptor": "\nComments: Abstract abridged to meet arXiv requirements\n",
    "authors": [
      "\u00c9tienne Bamas",
      "Lars Rohwedder"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.14259"
  },
  {
    "id": "arXiv:2211.14260",
    "title": "An agent-based simulation model of pedestrian evacuation based on  Bayesian Nash Equilibrium",
    "abstract": "This research incorporates Bayesian game theory into pedestrian evacuation in\nan agent-based model. Three pedestrian behaviours were compared: Random Follow,\nShortest Route and Bayesian Nash Equilibrium (BNE), as well as combinations of\nthese. The results showed that BNE pedestrians were able to evacuate more\nquickly as they predict congestion levels in their next step and adjust their\ndirections to avoid congestion, closely matching the behaviours of evacuating\npedestrians in reality. A series of simulation experiments were conducted to\nevaluate whether and how BNE affects pedestrian evacuation procedures. The\nresults showed that: 1) BNE has a large impact on reducing evacuation time; 2)\nBNE pedestrians displayed more intelligent and efficient evacuating behaviours;\n3) As the proportion of BNE users rises, average evacuation time decreases, and\naverage comfort level increases. A detailed description of the model and\nrelevant experimental results is provided in this paper. Several limitations as\nwell as further works are also identified.",
    "descriptor": "",
    "authors": [
      "Yiyu Wang",
      "Jiaqi Ge",
      "Alexis Comber"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.14260"
  },
  {
    "id": "arXiv:2211.14261",
    "title": "Temporal Waypoint Navigation of Multi-UAV Payload System using Barrier  Functions",
    "abstract": "Aerial package transportation often requires complex spatial and temporal\nspecifications to be satisfied in order to ensure safe and timely delivery from\none point to another. It is usually efficient to transport versatile payloads\nusing multiple UAVs that can work collaboratively to achieve the desired task.\nThe complex temporal specifications can be handled coherently by applying\nSignal Temporal Logic (STL) to dynamical systems. This paper addresses the\nproblem of waypoint navigation of a multi-UAV payload system under temporal\nspecifications using higher-order time-varying control barrier functions\n(HOCBFs). The complex nonlinear system of relative degree two is transformed\ninto a simple linear system using input-output feedback linearization. An\noptimization-based control law is then derived to achieve the temporal waypoint\nnavigation of the payload. The controller's efficacy and real-time\nimplementability are demonstrated by simulating a package delivery scenario\ninside a high-fidelity Gazebo simulation environment.",
    "descriptor": "\nComments: Submitted to ECC 2023\n",
    "authors": [
      "Nishanth Rao",
      "Suresh Sundaram",
      "Pushpak Jagtap"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.14261"
  },
  {
    "id": "arXiv:2211.14265",
    "title": "Multiscale methods for solving wave equations on spatial networks",
    "abstract": "We present and analyze a multiscale method for wave propagation problems,\nposed on spatial networks. By introducing a coarse scale, using a finite\nelement space interpolated onto the network, we construct a discrete multiscale\nspace using the localized orthogonal decomposition (LOD) methodology. The\nspatial discretization is then combined with an energy conserving temporal\nscheme to form the proposed method. Under the assumption of well-prepared\ninitial data, we derive an a priori error bound of optimal order with respect\nto the space and time discretization. In the analysis, we combine the theory\nderived for stationary elliptic problems on spatial networks with classical\nfinite element results for hyperbolic problems. Finally, we present numerical\nexperiments that confirm our theoretical findings.",
    "descriptor": "",
    "authors": [
      "Morgan G\u00f6rtz",
      "Per Ljung",
      "Axel M\u00e5lqvist"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.14265"
  },
  {
    "id": "arXiv:2211.14275",
    "title": "Solving math word problems with process- and outcome-based feedback",
    "abstract": "Recent work has shown that asking language models to generate reasoning steps\nimproves performance on many reasoning tasks. When moving beyond prompting,\nthis raises the question of how we should supervise such models: outcome-based\napproaches which supervise the final result, or process-based approaches which\nsupervise the reasoning process itself? Differences between these approaches\nmight naturally be expected not just in final-answer errors but also in\nreasoning errors, which can be difficult to detect and are problematic in many\nreal-world domains such as education. We run the first comprehensive comparison\nbetween process- and outcome-based approaches trained on a natural language\ntask, GSM8K. We find that pure outcome-based supervision produces similar\nfinal-answer error rates with less label supervision. However, for correct\nreasoning steps we find it necessary to use process-based supervision or\nsupervision from learned reward models that emulate process-based feedback. In\ntotal, we improve the previous best results from 16.8% $\\to$ 12.7% final-answer\nerror and 14.0% $\\to$ 3.4% reasoning error among final-answer-correct\nsolutions.",
    "descriptor": "",
    "authors": [
      "Jonathan Uesato",
      "Nate Kushman",
      "Ramana Kumar",
      "Francis Song",
      "Noah Siegel",
      "Lisa Wang",
      "Antonia Creswell",
      "Geoffrey Irving",
      "Irina Higgins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.14275"
  },
  {
    "id": "arXiv:2211.14279",
    "title": "Multiverse: Multilingual Evidence for Fake News Detection",
    "abstract": "Misleading information spreads on the Internet at an incredible speed, which\ncan lead to irreparable consequences in some cases. It is becoming essential to\ndevelop fake news detection technologies. While substantial work has been done\nin this direction, one of the limitations of the current approaches is that\nthese models are focused only on one language and do not use multilingual\ninformation. In this work, we propose Multiverse -- a new feature based on\nmultilingual evidence that can be used for fake news detection and improve\nexisting approaches. The hypothesis of the usage of cross-lingual evidence as a\nfeature for fake news detection is confirmed, firstly, by manual experiment\nbased on a set of known true and fake news. After that, we compared our fake\nnews classification system based on the proposed feature with several baselines\non two multi-domain datasets of general-topic news and one fake COVID-19 news\ndataset showing that in additional combination with linguistic features it\nyields significant improvements.",
    "descriptor": "\nComments: 24 pages, 10 figures, extended version of ACL SRW 2021 paper\n",
    "authors": [
      "Daryna Dementieva",
      "Mikhail Kuimov",
      "Alexander Panchenko"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.14279"
  },
  {
    "id": "arXiv:2211.14284",
    "title": "Multigrid solvers for the de Rham complex with optimal complexity in  polynomial degree",
    "abstract": "The Riesz maps of the $L^2$ de Rham complex frequently arise as subproblems\nin the construction of fast preconditioners for more complicated problems. In\nthis work we present multigrid solvers for high-order finite element\ndiscretizations of these Riesz maps with the same time and space complexity as\nsum-factorized operator application, i.e.~with optimal complexity in polynomial\ndegree in the context of Krylov methods. The key idea of our approach is to\nbuild new finite elements for each space in the de Rham complex with\northogonality properties in both the $L^2$- and $H(\\mathrm{d})$-inner products\n($\\mathrm{d} \\in \\{\\mathrm{grad}, \\mathrm{curl}, \\mathrm{div}\\})$ on the\nreference hexahedron. The resulting sparsity enables the fast solution of the\npatch problems arising in the Pavarino, Arnold--Falk--Winther and Hiptmair\nspace decompositions, in the separable case. In the non-separable case, the\nmethod can be applied to an auxiliary operator that is sparse by construction.\nWith exact Cholesky factorizations of the sparse patch problems, the\napplication complexity is optimal but the setup costs and storage are not. We\novercome this with the finer Hiptmair space decomposition and the use of\nincomplete Cholesky factorizations imposing the sparsity pattern arising from\nstatic condensation, which applies whether static condensation is used for the\nsolver or not. This yields multigrid relaxations with time and space complexity\nthat are both optimal in the polynomial degree.",
    "descriptor": "",
    "authors": [
      "Pablo D. Brubeck",
      "Patrick E. Farrell"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.14284"
  },
  {
    "id": "arXiv:2211.14286",
    "title": "CHIMLE: Conditional Hierarchical IMLE for Multimodal Conditional Image  Synthesis",
    "abstract": "A persistent challenge in conditional image synthesis has been to generate\ndiverse output images from the same input image despite only one output image\nbeing observed per input image. GAN-based methods are prone to mode collapse,\nwhich leads to low diversity. To get around this, we leverage Implicit Maximum\nLikelihood Estimation (IMLE) which can overcome mode collapse fundamentally.\nIMLE uses the same generator as GANs but trains it with a different,\nnon-adversarial objective which ensures each observed image has a generated\nsample nearby. Unfortunately, to generate high-fidelity images, prior\nIMLE-based methods require a large number of samples, which is expensive. In\nthis paper, we propose a new method to get around this limitation, which we dub\nConditional Hierarchical IMLE (CHIMLE), which can generate high-fidelity images\nwithout requiring many samples. We show CHIMLE significantly outperforms the\nprior best IMLE, GAN and diffusion-based methods in terms of image fidelity and\nmode coverage across four tasks, namely night-to-day, 16x single image\nsuper-resolution, image colourization and image decompression. Quantitatively,\nour method improves Fr\\'echet Inception Distance (FID) by 36.9% on average\ncompared to the prior best IMLE-based method, and by 27.5% on average compared\nto the best non-IMLE-based general-purpose methods.",
    "descriptor": "",
    "authors": [
      "Shichong Peng",
      "Alireza Moazeni",
      "Ke Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14286"
  },
  {
    "id": "arXiv:2211.14293",
    "title": "Pixels Together Strong: Segmenting Unknown Regions Rejected by All",
    "abstract": "Semantic segmentation methods typically perform per-pixel classification by\nassuming a fixed set of semantic categories. While they perform well on the\nknown set, the network fails to learn the concept of objectness, which is\nnecessary for identifying unknown objects. In this paper, we explore the\npotential of query-based mask classification for unknown object segmentation.\nWe discover that object queries specialize in predicting a certain class and\nbehave like one vs. all classifiers, allowing us to detect unknowns by finding\nregions that are ignored by all the queries. Based on a detailed analysis of\nthe model's behavior, we propose a novel anomaly scoring function. We\ndemonstrate that mask classification helps to preserve the objectness and the\nproposed scoring function eliminates irrelevant sources of uncertainty. Our\nmethod achieves consistent improvements in multiple benchmarks, even under high\ndomain shift, without retraining or using outlier data. With modest supervision\nfor outliers, we show that further improvements can be achieved without\naffecting the closed-set performance.",
    "descriptor": "\nComments: 18 pages, 14 figures\n",
    "authors": [
      "Nazir Nayal",
      "M\u0131sra Yavuz",
      "Jo\u00e3o F. Henriques",
      "Fatma G\u00fcney"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14293"
  },
  {
    "id": "arXiv:2211.14296",
    "title": "A System for Morphology-Task Generalization via Unified Representation  and Behavior Distillation",
    "abstract": "The rise of generalist large-scale models in natural language and vision has\nmade us expect that a massive data-driven approach could achieve broader\ngeneralization in other domains such as continuous control. In this work, we\nexplore a method for learning a single policy that manipulates various forms of\nagents to solve various tasks by distilling a large amount of proficient\nbehavioral data. In order to align input-output (IO) interface among multiple\ntasks and diverse agent morphologies while preserving essential 3D geometric\nrelations, we introduce morphology-task graph, which treats observations,\nactions and goals/task in a unified graph representation. We also develop\nMxT-Bench for fast large-scale behavior generation, which supports procedural\ngeneration of diverse morphology-task combinations with a minimal blueprint and\nhardware-accelerated simulator. Through efficient representation and\narchitecture selection on MxT-Bench, we find out that a morphology-task graph\nrepresentation coupled with Transformer architecture improves the multi-task\nperformances compared to other baselines including recent discrete\ntokenization, and provides better prior knowledge for zero-shot transfer or\nsample efficiency in downstream multi-task imitation learning. Our work\nsuggests large diverse offline datasets, unified IO representation, and policy\nrepresentation and architecture selection through supervised learning form a\npromising approach for studying and advancing morphology-task generalization.",
    "descriptor": "\nComments: Website: this https URL\n",
    "authors": [
      "Hiroki Furuta",
      "Yusuke Iwasawa",
      "Yutaka Matsuo",
      "Shixiang Shane Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.14296"
  },
  {
    "id": "arXiv:2211.14298",
    "title": "PIP: Positional-encoding Image Prior",
    "abstract": "In Deep Image Prior (DIP), a Convolutional Neural Network (CNN) is fitted to\nmap a latent space to a degraded (e.g. noisy) image but in the process learns\nto reconstruct the clean image. This phenomenon is attributed to CNN's internal\nimage-prior. We revisit the DIP framework, examining it from the perspective of\na neural implicit representation. Motivated by this perspective, we replace the\nrandom or learned latent with Fourier-Features (Positional Encoding). We show\nthat thanks to the Fourier features properties, we can replace the convolution\nlayers with simple pixel-level MLPs. We name this scheme ``Positional Encoding\nImage Prior\" (PIP) and exhibit that it performs very similarly to DIP on\nvarious image-reconstruction tasks with much less parameters required.\nAdditionally, we demonstrate that PIP can be easily extended to videos, where\n3D-DIP struggles and suffers from instability. Code and additional examples for\nall tasks, including videos, are available on the project page\nhttps://nimrodshabtay.github.io/PIP/",
    "descriptor": "",
    "authors": [
      "Nimrod Shabtay",
      "Eli Schwartz",
      "Raja Giryes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14298"
  },
  {
    "id": "arXiv:2211.14301",
    "title": "On the Effect of Anticipation on Reading Times",
    "abstract": "Over the past two decades, numerous studies have demonstrated how less\npredictable (i.e. higher surprisal) words take more time to read. In general,\nthese previous studies implicitly assumed the reading process to be purely\nresponsive: readers observe a new word and allocate time to read it as\nrequired. These results, however, are also compatible with a reading time that\nis anticipatory: readers could, e.g., allocate time to a future word based on\ntheir expectation about it. In this work, we examine the anticipatory nature of\nreading by looking at how people's predictions about upcoming material\ninfluence reading times. Specifically, we test anticipation by looking at the\neffects of surprisal and contextual entropy on four reading-time datasets: two\nself-paced and two eye-tracking. In three of four datasets tested, we find that\nthe entropy predicts reading times as well as (or better than) the surprisal.\nWe then hypothesise four cognitive mechanisms through which the contextual\nentropy could impact RTs -- three of which we design experiments to analyse.\nOverall, our results support a view of reading that is both anticipatory and\nresponsive.",
    "descriptor": "\nComments: Code is available in this https URL\n",
    "authors": [
      "Tiago Pimentel",
      "Clara Meister",
      "Ethan G. Wilcox",
      "Roger Levy",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.14301"
  },
  {
    "id": "arXiv:2211.14302",
    "title": "Neural DAEs: Constrained neural networks",
    "abstract": "In this article we investigate the effect of explicitly adding auxiliary\ntrajectory information to neural networks for dynamical systems. We draw\ninspiration from the field of differential-algebraic equations and differential\nequations on manifolds and implement similar methods in residual neural\nnetworks. We discuss constraints through stabilization as well as projection\nmethods, and show when to use which method based on experiments involving\nsimulations of multi-body pendulums and molecular dynamics scenarios. Several\nof our methods are easy to implement in existing code and have limited impact\non training performance while giving significant boosts in terms of inference.",
    "descriptor": "\nComments: submitted to IOP machine learning\n",
    "authors": [
      "Tue Boesen",
      "Eldad Haber",
      "Uri M. Ascher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.14302"
  },
  {
    "id": "arXiv:2211.14304",
    "title": "BeLFusion: Latent Diffusion for Behavior-Driven Human Motion Prediction",
    "abstract": "Stochastic human motion prediction (HMP) has generally been tackled with\ngenerative adversarial networks and variational autoencoders. Most prior works\naim at predicting highly diverse movements in terms of the skeleton joints'\ndispersion. This has led to methods predicting fast and motion-divergent\nmovements, which are often unrealistic and incoherent with past motion. Such\nmethods also neglect contexts that need to anticipate diverse low-range\nbehaviors, or actions, with subtle joint displacements. To address these\nissues, we present BeLFusion, a model that, for the first time, leverages\nlatent diffusion models in HMP to sample from a latent space where behavior is\ndisentangled from pose and motion. As a result, diversity is encouraged from a\nbehavioral perspective. Thanks to our behavior coupler's ability to transfer\nsampled behavior to ongoing motion, BeLFusion's predictions display a variety\nof behaviors that are significantly more realistic than the state of the art.\nTo support it, we introduce two metrics, the Area of the Cumulative Motion\nDistribution, and the Average Pairwise Distance Error, which are correlated to\nour definition of realism according to a qualitative study with 126\nparticipants. Finally, we prove BeLFusion's generalization power in a new\ncross-dataset scenario for stochastic HMP.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "German Barquero",
      "Sergio Escalera",
      "Cristina Palmero"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14304"
  },
  {
    "id": "arXiv:2211.14305",
    "title": "SpaText: Spatio-Textual Representation for Controllable Image Generation",
    "abstract": "Recent text-to-image diffusion models are able to generate convincing results\nof unprecedented quality. However, it is nearly impossible to control the\nshapes of different regions/objects or their layout in a fine-grained fashion.\nPrevious attempts to provide such controls were hindered by their reliance on a\nfixed set of labels. To this end, we present SpaText - a new method for\ntext-to-image generation using open-vocabulary scene control. In addition to a\nglobal text prompt that describes the entire scene, the user provides a\nsegmentation map where each region of interest is annotated by a free-form\nnatural language description. Due to lack of large-scale datasets that have a\ndetailed textual description for each region in the image, we choose to\nleverage the current large-scale text-to-image datasets and base our approach\non a novel CLIP-based spatio-textual representation, and show its effectiveness\non two state-of-the-art diffusion models: pixel-based and latent-based. In\naddition, we show how to extend the classifier-free guidance method in\ndiffusion models to the multi-conditional case and present an alternative\naccelerated inference algorithm. Finally, we offer several automatic evaluation\nmetrics and use them, in addition to FID scores and a user study, to evaluate\nour method and show that it achieves state-of-the-art results on image\ngeneration with free-form textual scene control.",
    "descriptor": "\nComments: Project page available at: this https URL\n",
    "authors": [
      "Omri Avrahami",
      "Thomas Hayes",
      "Oran Gafni",
      "Sonal Gupta",
      "Yaniv Taigman",
      "Devi Parikh",
      "Dani Lischinski",
      "Ohad Fried",
      "Xi Yin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14305"
  },
  {
    "id": "arXiv:2211.14306",
    "title": "RUST: Latent Neural Scene Representations from Unposed Imagery",
    "abstract": "Inferring the structure of 3D scenes from 2D observations is a fundamental\nchallenge in computer vision. Recently popularized approaches based on neural\nscene representations have achieved tremendous impact and have been applied\nacross a variety of applications. One of the major remaining challenges in this\nspace is training a single model which can provide latent representations which\neffectively generalize beyond a single scene. Scene Representation Transformer\n(SRT) has shown promise in this direction, but scaling it to a larger set of\ndiverse scenes is challenging and necessitates accurately posed ground truth\ndata. To address this problem, we propose RUST (Really Unposed Scene\nrepresentation Transformer), a pose-free approach to novel view synthesis\ntrained on RGB images alone. Our main insight is that one can train a Pose\nEncoder that peeks at the target image and learns a latent pose embedding which\nis used by the decoder for view synthesis. We perform an empirical\ninvestigation into the learned latent pose structure and show that it allows\nmeaningful test-time camera transformations and accurate explicit pose\nreadouts. Perhaps surprisingly, RUST achieves similar quality as methods which\nhave access to perfect camera pose, thereby unlocking the potential for\nlarge-scale training of amortized neural scene representations.",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Mehdi S. M. Sajjadi",
      "Aravindh Mahendran",
      "Thomas Kipf",
      "Etienne Pot",
      "Daniel Duckworth",
      "Mario Lucic",
      "Klaus Greff"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.14306"
  },
  {
    "id": "arXiv:2211.14307",
    "title": "MAEDAY: MAE for few and zero shot AnomalY-Detection",
    "abstract": "The goal of Anomaly-Detection (AD) is to identify outliers, or outlying\nregions, from some unknown distribution given only a set of positive (good)\nexamples. Few-Shot AD (FSAD) aims to solve the same task with a minimal amount\nof normal examples. Recent embedding-based methods, that compare the embedding\nvectors of queries to a set of reference embeddings, have demonstrated\nimpressive results for FSAD, where as little as one good example is provided. A\ndifferent approach, image-reconstruction-based, has been historically used for\nAD. The idea is to train a model to recover normal images from corrupted\nobservations, assuming that the model will fail to recover regions when\nencountered with an out-of-distribution image. However,\nimage-reconstruction-based methods were not yet used in the low-shot regime as\nthey need to be trained on a diverse set of normal images in order to properly\nperform. We suggest using Masked Auto-Encoder (MAE), a self-supervised\ntransformer model trained for recovering missing image regions based on their\nsurroundings for FSAD. We show that MAE performs well by pre-training on an\narbitrary set of natural images (ImageNet) and only fine-tuning on a small set\nof normal images. We name this method MAEDAY. We further find that MAEDAY\nprovides an orthogonal signal to the embedding-based methods and the ensemble\nof the two approaches achieves very strong SOTA results. We also present a\nnovel task of Zero-Shot AD (ZSAD) where no normal samples are available at\ntraining time. We show that MAEDAY performs surprisingly well at this task.\nFinally, we provide a new dataset for detecting foreign objects on the ground\nand demonstrate superior results for this task as well. Code is available at\nhttps://github.com/EliSchwartz/MAEDAY .",
    "descriptor": "",
    "authors": [
      "Eli Schwartz",
      "Assaf Arbelle",
      "Leonid Karlinsky",
      "Sivan Harary",
      "Florian Scheidegger",
      "Sivan Doveh",
      "Raja Giryes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14307"
  },
  {
    "id": "arXiv:2211.14308",
    "title": "WALDO: Future Video Synthesis using Object Layer Decomposition and  Parametric Flow Prediction",
    "abstract": "This paper presents WALDO (WArping Layer-Decomposed Objects), a novel\napproach to the prediction of future video frames from past ones. Individual\nimages are decomposed into multiple layers combining object masks and a small\nset of control points. The layer structure is shared across all frames in each\nvideo to build dense inter-frame connections. Complex scene motions are modeled\nby combining parametric geometric transformations associated with individual\nlayers, and video synthesis is broken down into discovering the layers\nassociated with past frames, predicting the corresponding transformations for\nupcoming ones and warping the associated object regions accordingly, and\nfilling in the remaining image parts. Extensive experiments on the Cityscapes\n(resp. KITTI) dataset show that WALDO significantly outperforms prior works\nwith, e.g., 3, 27, and 51% (resp. 5, 20 and 11%) relative improvement in SSIM,\nLPIPS and FVD metrics. Code, pretrained models, and video samples synthesized\nby our approach can be found in the project webpage\nhttps://16lemoing.github.io/waldo.",
    "descriptor": "",
    "authors": [
      "Guillaume Le Moing",
      "Jean Ponce",
      "Cordelia Schmid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14308"
  },
  {
    "id": "arXiv:2211.14309",
    "title": "Forecasting Actions and Characteristic 3D Poses",
    "abstract": "We propose to model longer-term future human behavior by jointly predicting\naction labels and 3D characteristic poses (3D poses representative of the\nassociated actions). While previous work has considered action and 3D pose\nforecasting separately, we observe that the nature of the two tasks is coupled,\nand thus we predict them together. Starting from an input 2D video observation,\nwe jointly predict a future sequence of actions along with 3D poses\ncharacterizing these actions. Since coupled action labels and 3D pose\nannotations are difficult and expensive to acquire for videos of complex action\nsequences, we train our approach with action labels and 2D pose supervision\nfrom two existing action video datasets, in tandem with an adversarial loss\nthat encourages likely 3D predicted poses. Our experiments demonstrate the\ncomplementary nature of joint action and characteristic 3D pose prediction: our\njoint approach outperforms each task treated individually, enables robust\nlonger-term sequence prediction, and outperforms alternative approaches to\nforecast actions and characteristic 3D poses.",
    "descriptor": "\nComments: Video: this https URL; Project Page: this https URL\n",
    "authors": [
      "Christian Diller",
      "Thomas Funkhouser",
      "Angela Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14309"
  },
  {
    "id": "arXiv:2211.14310",
    "title": "Efficient 3D Reconstruction, Streaming and Visualization of Static and  Dynamic Scene Parts for Multi-client Live-telepresence in Large-scale  Environments",
    "abstract": "Despite the impressive progress of telepresence systems for room-scale scenes\nwith static and dynamic scene entities, expanding their capabilities to\nscenarios with larger dynamic environments beyond a fixed size of a few\nsquaremeters remains challenging.\nIn this paper, we aim at sharing 3D live-telepresence experiences in\nlarge-scale environments beyond room scale with both static and dynamic scene\nentities at practical bandwidth requirements only based on light-weight scene\ncapture with a single moving consumer-grade RGB-D camera. To this end, we\npresent a system which is built upon a novel hybrid volumetric scene\nrepresentation in terms of the combination of a voxel-based scene\nrepresentation for the static contents, that not only stores the reconstructed\nsurface geometry but also contains information about the object semantics as\nwell as their accumulated dynamic movement over time, and a point-cloud-based\nrepresentation for dynamic scene parts, where the respective separation from\nstatic parts is achieved based on semantic and instance information extracted\nfor the input frames. With an independent yet simultaneous streaming of both\nstatic and dynamic content, where we seamlessly integrate potentially moving\nbut currently static scene entities in the static model until they are becoming\ndynamic again, as well as the fusion of static and dynamic data at the remote\nclient, our system is able to achieve VR-based live-telepresence at interactive\nrates. Our evaluation demonstrates the potential of our novel approach in terms\nof visual quality, performance, and ablation studies regarding involved design\nchoices.",
    "descriptor": "",
    "authors": [
      "Leif Van Holland",
      "Patrick Stotko",
      "Stefan Krumpen",
      "Reinhard Klein",
      "Michael Weinmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.14310"
  },
  {
    "id": "arXiv:1810.05319",
    "title": "A Fully Time-domain Neural Model for Subband-based Speech Synthesizer",
    "abstract": "This paper introduces a deep neural network model for subband-based speech\nsynthesizer. The model benefits from the short bandwidth of the subband signals\nto reduce the complexity of the time-domain speech generator. We employed the\nmulti-level wavelet analysis/synthesis to decompose/reconstruct the signal into\nsubbands in time domain. Inspired from the WaveNet, a convolutional neural\nnetwork (CNN) model predicts subband speech signals fully in time domain. Due\nto the short bandwidth of the subbands, a simple network architecture is enough\nto train the simple patterns of the subbands accurately. In the ground truth\nexperiments with teacher-forcing, the subband synthesizer outperforms the\nfullband model significantly in terms of both subjective and objective\nmeasures. In addition, by conditioning the model on the phoneme sequence using\na pronunciation dictionary, we have achieved the fully time-domain neural model\nfor subband-based text-to-speech (TTS) synthesizer, which is nearly end-to-end.\nThe generated speech of the subband TTS shows comparable quality as the\nfullband one with a slighter network architecture for each subband.",
    "descriptor": "\nComments: 5 pages, 3 figure\n",
    "authors": [
      "Azam Rabiee",
      "Geonmin Kim",
      "Tae-Ho Kim",
      "Soo-Young Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/1810.05319"
  },
  {
    "id": "arXiv:1906.05507",
    "title": "Adjusting Pleasure-Arousal-Dominance for Continuous Emotional  Text-to-speech Synthesizer",
    "abstract": "Emotion is not limited to discrete categories of happy, sad, angry, fear,\ndisgust, surprise, and so on. Instead, each emotion category is projected into\na set of nearly independent dimensions, named pleasure (or valence), arousal,\nand dominance, known as PAD. The value of each dimension varies from -1 to 1,\nsuch that the neutral emotion is in the center with all-zero values. Training\nan emotional continuous text-to-speech (TTS) synthesizer on the independent\ndimensions provides the possibility of emotional speech synthesis with\nunlimited emotion categories. Our end-to-end neural speech synthesizer is based\non the well-known Tacotron. Empirically, we have found the optimum network\narchitecture for injecting the 3D PADs. Moreover, the PAD values are adjusted\nfor the speech synthesis purpose.",
    "descriptor": "\nComments: Interspeech2019, Show and Tell demonstration this https URL&feature=youtu.be\n",
    "authors": [
      "Azam Rabiee",
      "Tae-Ho Kim",
      "Soo-Young Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/1906.05507"
  },
  {
    "id": "arXiv:2202.02301",
    "title": "Log-Sobolev inequality for near critical Ising models",
    "abstract": "For general ferromagnetic Ising models whose coupling matrix has bounded\nspectral radius, we show that the log-Sobolev constant satisfies a simple bound\nexpressed only in terms of the susceptibility of the model. This bound implies\nvery generally that the log-Sobolev constant is uniform in the system size up\nto the critical point (including on lattices), without using any mixing\nconditions. Moreover, if the susceptibility satisfies the mean-field bound as\nthe critical point is approached, our bound implies that the log-Sobolev\nconstant depends polynomially on the distance to the critical point and on the\nvolume. In particular, this applies to the Ising model on subsets of\n$\\mathbb{Z}^d$ when $d>4$.\nThe proof uses a general criterion for the log-Sobolev inequality in terms of\nthe Polchinski (renormalisation group) equation, a recently proved remarkable\ncorrelation inequality for Ising models with general external fields, the\nPerron--Frobenius theorem, and the log-Sobolev inequality for product Bernoulli\nmeasures.",
    "descriptor": "\nComments: Minor revisions, accepted\n",
    "authors": [
      "Roland Bauerschmidt",
      "Benoit Dagallier"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Data Structures and Algorithms (cs.DS)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.02301"
  },
  {
    "id": "arXiv:2204.03553",
    "title": "Embeddings between partial combinatory algebras",
    "abstract": "Partial combinatory algebras are algebraic structures that serve as\ngeneralized models of computation. In this paper, we study embeddings of pcas.\nIn particular, we systematize the embeddings between relativizations of\nKleene's models, of van Oosten's sequential computation model, and of Scott's\ngraph model, showing that an embedding between two relativized models exists if\nand only if there exists a particular reduction between the oracles. We obtain\na similar result for the lambda calculus, showing in particular that it cannot\nbe embedded in Kleene's first model.",
    "descriptor": "\nComments: 31 pages\n",
    "authors": [
      "Anton Golov",
      "Sebastiaan A. Terwijn"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2204.03553"
  },
  {
    "id": "arXiv:2211.12519",
    "title": "Optimizing the depth of variational quantum algorithms is strongly  QCMA-hard to approximate",
    "abstract": "Variational Quantum Algorithms (VQAs), such as the Quantum Approximate\nOptimization Algorithm (QAOA) of [Farhi, Goldstone, Gutmann, 2014], have seen\nintense study towards near-term applications on quantum hardware. A crucial\nparameter for VQAs is the depth of the variational ansatz used - the smaller\nthe depth, the more amenable the ansatz is to near-term quantum hardware in\nthat it gives the circuit a chance to be fully executed before the system\ndecoheres. This potential for depth reduction has made VQAs a staple of Noisy\nIntermediate-Scale Quantum (NISQ)-era research.\nIn this work, we show that approximating the optimal depth for a given VQA\nansatz is intractable. Formally, we show that for any constant $\\epsilon>0$, it\nis QCMA-hard to approximate the optimal depth of a VQA ansatz within\nmultiplicative factor $N^{1-\\epsilon}$, for $N$ denoting the encoding size of\nthe VQA instance. (Here, Quantum Classical Merlin-Arthur (QCMA) is a quantum\ngeneralization of NP.) We then show that this hardness persists even in the\n\"simpler\" setting of QAOAs. To our knowledge, this yields the first natural\nQCMA-hard-to-approximate problems. To achieve these results, we bypass the need\nfor a PCP theorem for QCMA by appealing to the disperser-based NP-hardness of\napproximation construction of [Umans, FOCS 1999].",
    "descriptor": "\nComments: 31 pages, 2 figures\n",
    "authors": [
      "Lennart Bittel",
      "Sevag Gharibian",
      "Martin Kliesch"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.12519"
  },
  {
    "id": "arXiv:2211.13229",
    "title": "DeltaNet:Conditional Medical Report Generation for COVID-19 Diagnosis",
    "abstract": "Fast screening and diagnosis are critical in COVID-19 patient treatment. In\naddition to the gold standard RT-PCR, radiological imaging like X-ray and CT\nalso works as an important means in patient screening and follow-up. However,\ndue to the excessive number of patients, writing reports becomes a heavy burden\nfor radiologists. To reduce the workload of radiologists, we propose DeltaNet\nto generate medical reports automatically. Different from typical image\ncaptioning approaches that generate reports with an encoder and a decoder,\nDeltaNet applies a conditional generation process. In particular, given a\nmedical image, DeltaNet employs three steps to generate a report: 1) first\nretrieving related medical reports, i.e., the historical reports from the same\nor similar patients; 2) then comparing retrieved images and current image to\nfind the differences; 3) finally generating a new report to accommodate\nidentified differences based on the conditional report. We evaluate DeltaNet on\na COVID-19 dataset, where DeltaNet outperforms state-of-the-art approaches.\nBesides COVID-19, the proposed DeltaNet can be applied to other diseases as\nwell. We validate its generalization capabilities on the public IU-Xray and\nMIMIC-CXR datasets for chest-related diseases. Code is available at\n\\url{https://github.com/LX-doctorAI1/DeltaNet}.",
    "descriptor": "",
    "authors": [
      "Xian Wu",
      "Shuxin Yang",
      "Zhaopeng Qiu",
      "Shen Ge",
      "Yangtian Yan",
      "Xingwang Wu",
      "Yefeng Zheng",
      "S. Kevin Zhou",
      "Li Xiao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13229"
  },
  {
    "id": "arXiv:2211.13230",
    "title": "Generalization of Artificial Intelligence Models in Medical Imaging: A  Case-Based Review",
    "abstract": "The discussions around Artificial Intelligence (AI) and medical imaging are\ncentered around the success of deep learning algorithms. As new algorithms\nenter the market, it is important for practicing radiologists to understand the\npitfalls of various AI algorithms. This entails having a basic understanding of\nhow algorithms are developed, the kind of data they are trained on, and the\nsettings in which they will be deployed. As with all new technologies, use of\nAI should be preceded by a fundamental understanding of the risks and benefits\nto those it is intended to help. This case-based review is intended to point\nout specific factors practicing radiologists who intend to use AI should\nconsider.",
    "descriptor": "",
    "authors": [
      "Rishi Gadepally",
      "Andrew Gomella",
      "Eric Gingold",
      "Paras Lakhani"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13230"
  },
  {
    "id": "arXiv:2211.13231",
    "title": "Predicting Biomedical Interactions with Probabilistic Model Selection  for Graph Neural Networks",
    "abstract": "A biological system is a complex network of heterogeneous molecular entities\nand their interactions contributing to various biological characteristics of\nthe system. However, current biological networks are noisy, sparse, and\nincomplete, limiting our ability to create a holistic view of the biological\nsystem and understand the biological phenomena. Experimental identification of\nsuch interactions is both time-consuming and expensive. With the recent\nadvancements in high-throughput data generation and significant improvement in\ncomputational power, various computational methods have been developed to\npredict novel interactions in the noisy network. Recently, deep learning\nmethods such as graph neural networks have shown their effectiveness in\nmodeling graph-structured data and achieved good performance in biomedical\ninteraction prediction. However, graph neural networks-based methods require\nhuman expertise and experimentation to design the appropriate complexity of the\nmodel and significantly impact the performance of the model. Furthermore, deep\ngraph neural networks face overfitting problems and tend to be poorly\ncalibrated with high confidence on incorrect predictions. To address these\nchallenges, we propose Bayesian model selection for graph convolutional\nnetworks to jointly infer the most plausible number of graph convolution layers\n(depth) warranted by data and perform dropout regularization simultaneously.\nExperiments on four interaction datasets show that our proposed method achieves\naccurate and calibrated predictions. Our proposed method enables the graph\nconvolutional networks to dynamically adapt their depths to accommodate an\nincreasing number of interactions.",
    "descriptor": "",
    "authors": [
      "Kishan K C",
      "Rui Li",
      "Paribesh Regmi",
      "Anne R. Haake"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13231"
  },
  {
    "id": "arXiv:2211.13238",
    "title": "ProstAttention-Net: A deep attention model for prostate cancer  segmentation by aggressiveness in MRI scans",
    "abstract": "Multiparametric magnetic resonance imaging (mp-MRI) has shown excellent\nresults in the detection of prostate cancer (PCa). However, characterizing\nprostate lesions aggressiveness in mp-MRI sequences is impossible in clinical\npractice, and biopsy remains the reference to determine the Gleason score (GS).\nIn this work, we propose a novel end-to-end multi-class network that jointly\nsegments the prostate gland and cancer lesions with GS group grading. After\nencoding the information on a latent space, the network is separated in two\nbranches: 1) the first branch performs prostate segmentation 2) the second\nbranch uses this zonal prior as an attention gate for the detection and grading\nof prostate lesions. The model was trained and validated with a 5-fold\ncross-validation on an heterogeneous series of 219 MRI exams acquired on three\ndifferent scanners prior prostatectomy. In the free-response receiver operating\ncharacteristics (FROC) analysis for clinically significant lesions (defined as\nGS > 6) detection, our model achieves 69.0% $\\pm$14.5% sensitivity at 2.9 false\npositive per patient on the whole prostate and 70.8% $\\pm$14.4% sensitivity at\n1.5 false positive when considering the peripheral zone (PZ) only. Regarding\nthe automatic GS group",
    "descriptor": "",
    "authors": [
      "Audrey Duran",
      "Gaspard Dussert",
      "Olivier Rouvi\u00e8re",
      "Tristan Jaouen",
      "Pierre-Marc Jodoin",
      "Carole Lartizien"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.13238"
  },
  {
    "id": "arXiv:2211.13289",
    "title": "Shapley Curves: A Smoothing Perspective",
    "abstract": "Originating from cooperative game theory, Shapley values have become one of\nthe most widely used measures for variable importance in applied Machine\nLearning. However, the statistical understanding of Shapley values is still\nlimited. In this paper, we take a nonparametric (or smoothing) perspective by\nintroducing Shapley curves as a local measure of variable importance. We\npropose two estimation strategies and derive the consistency and asymptotic\nnormality both under independence and dependence among the features. This\nallows us to construct confidence intervals and conduct inference on the\nestimated Shapley curves. The asymptotic results are validated in extensive\nexperiments. In an empirical application, we analyze which attributes drive the\nprices of vehicles.",
    "descriptor": "",
    "authors": [
      "Ratmir Miftachov",
      "Georg Keilbar",
      "Wolfgang Karl H\u00e4rdle"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.13289"
  },
  {
    "id": "arXiv:2211.13294",
    "title": "Improved Elekes-Szab\u00f3 type estimates using proximity",
    "abstract": "We prove a new Elekes-Szab\\'o type estimate on the size of the intersection\nof a Cartesian product $A\\times B\\times C$ with an algebraic surface $\\{f=0\\}$\nover the reals. In particular, if $A,B,C$ are sets of $N$ real numbers and $f$\nis a trivariate polynomial, then either $f$ has a special form that encodes\nadditive group structure (for example $f(x,y,x) = x + y - z$), or $A \\times\nB\\times C \\cap\\{f=0\\}$ has cardinality $O(N^{12/7})$. This is an improvement\nover the previously bound $O(N^{11/6})$. We also prove an asymmetric version of\nour main result, which yields an Elekes-Ronyai type expanding polynomial\nestimate with exponent $3/2$. This has applications to questions in\ncombinatorial geometry related to the Erd\\H{o}s distinct distances problem.\nLike previous approaches to the problem, we rephrase the question as a $L^2$\nestimate, which can be analyzed by counting additive quadruples. The latter\nproblem can be recast as an incidence problem involving points and curves in\nthe plane. The new idea in our proof is that we use the order structure of the\nreals to restrict attention to a smaller collection of proximate additive\nquadruples.",
    "descriptor": "\nComments: 7 pages, 0 figures\n",
    "authors": [
      "Jozsef Solymosi",
      "Joshua Zahl"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2211.13294"
  },
  {
    "id": "arXiv:2211.13306",
    "title": "Nepal Himalaya Offers Considerable Potential for Pumped Storage  Hydropower",
    "abstract": "There is a pressing need for a transition from fossil-fuel to renewable\nenergy to meet the increasing energy demands and reduce greenhouse gas\nemissions. The Nepal Himalaya possesses substantial renewable energy potential\nthat can be harnessed through hydropower projects due to its peculiar\ntopographic characteristics and abundant water resources. However, the current\nexploitation rate is low owing to the predominance of run-of-river hydropower\nsystems to support the nation's power system. The utility-scale storage\nfacility is crucial in the load scenario of an integrated Nepalese power system\nto manage diurnal variation, peak demand, and penetration of intermittent\nenergy sources. In this study, we first identify the potential of pumped\nstorage hydropower across the country under multiple configurations by pairing\nlakes, hydropower projects, rivers, and available flat terrains. We then\nidentify technically feasible pairs from those of potential locations.\nInfrastructural, environmental, operational, and other technical constraints\ngovern the choice of feasible locations. We find the flat land-to-river\nconfiguration most promising over other configurations for Nepal. Our results\nprovide insight into the potential of pumped storage hydropower and are of\npractical importance in planning sustainable power systems in the Himalayas.",
    "descriptor": "",
    "authors": [
      "Rupesh Baniya",
      "Rocky Talchabhadel",
      "Jeeban Panthi",
      "Ganesh R Ghimire",
      "Sanjib Sharma",
      "Prithvi Dhwoj Khadka",
      "Sanghoon Shin",
      "Yadu Pokhrel",
      "Utsav Bhattarai",
      "Rajaram Prajapati",
      "Bhesh Raj Thapa",
      "Ramesh Kumar Maskey"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.13306"
  },
  {
    "id": "arXiv:2211.13351",
    "title": "Laser Pulse Duration Optimization With Numerical Methods",
    "abstract": "In this study we explore the optimization of laser pulse duration to obtain\nthe shortest possible pulse. We do this by employing a feedback loop between a\npulse shaper and pulse duration measurements. We apply to this problem several\niterative algorithms including gradient descent, Bayesian Optimization and\ngenetic algorithms, using a simulation of the actual laser represented via a\nsemi-physical model of the laser based on the process of linear and non-linear\nphase accumulation.",
    "descriptor": "\nComments: 4 pages 3 figures - submitted to 2022 PCAPAC Conference\n",
    "authors": [
      "Francesco Capuano",
      "Davorin Peceli",
      "Gabriele Tiboni",
      "Alexandr \u0160pa\u010dek",
      "Bed\u0159ic Rus"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.13351"
  },
  {
    "id": "arXiv:2211.13352",
    "title": "Improving dermatology classifiers across populations using images  generated by large diffusion models",
    "abstract": "Dermatological classification algorithms developed without sufficiently\ndiverse training data may generalize poorly across populations. While\nintentional data collection and annotation offer the best means for improving\nrepresentation, new computational approaches for generating training data may\nalso aid in mitigating the effects of sampling bias. In this paper, we show\nthat DALL$\\cdot$E 2, a large-scale text-to-image diffusion model, can produce\nphotorealistic images of skin disease across skin types. Using the Fitzpatrick\n17k dataset as a benchmark, we demonstrate that augmenting training data with\nDALL$\\cdot$E 2-generated synthetic images improves classification of skin\ndisease overall and especially for underrepresented groups.",
    "descriptor": "\nComments: NeurIPS 2022 Workshop on Synthetic Data for Empowering ML Research\n",
    "authors": [
      "Luke W. Sagers",
      "James A. Diao",
      "Matthew Groh",
      "Pranav Rajpurkar",
      "Adewole S. Adamson",
      "Arjun K. Manrai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13352"
  },
  {
    "id": "arXiv:2211.13374",
    "title": "A Multivariate Non-Gaussian Bayesian Filter Using Power Moments",
    "abstract": "In this paper, which is a very preliminary version, we extend our results on\nthe univariate non-Gaussian Bayesian filter using power moments to the\nmultivariate systems, which can be either linear or nonlinear. Doing this\nintroduces several challenging problems, for example a positive parametrization\nof the density surrogate, which is not only a problem of filter design, but\nalso one of the multiple dimensional Hamburger moment problem. We propose a\nparametrization of the density surrogate with the proofs to its existence,\nPositivstellensatze and uniqueness. Based on it, we analyze the error of\nmoments of the density estimates through the filtering process with the\nproposed density surrogate. An error upper bound in the sense of total\nvariation distance is also given. A discussion on continuous and discrete\ntreatments to the non-Gaussian Bayesian filtering problem is proposed to\nexplain why our proposed filter shall also be a mainstream of the non-Gaussian\nBayesian filtering research and motivate the research on continuous\nparametrization of the system state. Last but not the least, simulation results\non estimating different types of multivariate density functions are given to\nvalidate our proposed filter. To the best of our knowledge, the proposed filter\nis the first one implementing the multivariate Bayesian filter with the system\nstate parameterized as a continuous function, which only requires the true\nstates being Lebesgue integrable.",
    "descriptor": "\nComments: 16 pages, 2 figures. arXiv admin note: text overlap with arXiv:2207.08519\n",
    "authors": [
      "Guangyu Wu",
      "Anders Lindquist"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.13374"
  },
  {
    "id": "arXiv:2211.13377",
    "title": "A new Speech Feature Fusion method with cross gate parallel CNN for  Speaker Recognition",
    "abstract": "In this paper, a new speech feature fusion method is proposed for speaker\nrecognition on the basis of the cross gate parallel convolutional neural\nnetwork (CG-PCNN). The Mel filter bank features (MFBFs) of different frequency\nresolutions can be extracted from each speech frame of a speaker's speech by\nseveral Mel filter banks, where the numbers of the triangular filters in the\nMel filter banks are different. Due to the frequency resolutions of these MFBFs\nare different, there are some complementaries for these MFBFs. The CG-PCNN is\nutilized to extract the deep features from these MFBFs, which applies a cross\ngate mechanism to capture the complementaries for improving the performance of\nthe speaker recognition system. Then, the fusion feature can be obtained by\nconcatenating these deep features for speaker recognition. The experimental\nresults show that the speaker recognition system with the proposed speech\nfeature fusion method is effective, and marginally outperforms the existing\nstate-of-the-art systems.",
    "descriptor": "",
    "authors": [
      "Jiacheng Zhang",
      "Wenyi Yan",
      "Ye Zhang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.13377"
  },
  {
    "id": "arXiv:2211.13440",
    "title": "Iterative Data Refinement for Self-Supervised MR Image Reconstruction",
    "abstract": "Magnetic Resonance Imaging (MRI) has become an important technique in the\nclinic for the visualization, detection, and diagnosis of various diseases.\nHowever, one bottleneck limitation of MRI is the relatively slow data\nacquisition process. Fast MRI based on k-space undersampling and high-quality\nimage reconstruction has been widely utilized, and many deep learning-based\nmethods have been developed in recent years. Although promising results have\nbeen achieved, most existing methods require fully-sampled reference data for\ntraining the deep learning models. Unfortunately, fully-sampled MRI data are\ndifficult if not impossible to obtain in real-world applications. To address\nthis issue, we propose a data refinement framework for self-supervised MR image\nreconstruction. Specifically, we first analyze the reason of the performance\ngap between self-supervised and supervised methods and identify that the bias\nin the training datasets between the two is one major factor. Then, we design\nan effective self-supervised training data refinement method to reduce this\ndata bias. With the data refinement, an enhanced self-supervised MR image\nreconstruction framework is developed to prompt accurate MR imaging. We\nevaluate our method on an in-vivo MRI dataset. Experimental results show that\nwithout utilizing any fully sampled MRI data, our self-supervised framework\npossesses strong capabilities in capturing image details and structures at high\nacceleration factors.",
    "descriptor": "\nComments: 5 pages, 2 figures, 1 table\n",
    "authors": [
      "Xue Liu",
      "Juan Zou",
      "Xiawu Zheng",
      "Cheng Li",
      "Hairong Zheng",
      "Shanshan Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13440"
  },
  {
    "id": "arXiv:2211.13452",
    "title": "Deep unfolding as iterative regularization for imaging inverse problems",
    "abstract": "Recently, deep unfolding methods that guide the design of deep neural\nnetworks (DNNs) through iterative algorithms have received increasing attention\nin the field of inverse problems. Unlike general end-to-end DNNs, unfolding\nmethods have better interpretability and performance. However, to our\nknowledge, their accuracy and stability in solving inverse problems cannot be\nfully guaranteed. To bridge this gap, we modified the training procedure and\nproved that the unfolding method is an iterative regularization method. More\nprecisely, we jointly learn a convex penalty function adversarially by an\ninput-convex neural network (ICNN) to characterize the distance to a real data\nmanifold and train a DNN unfolded from the proximal gradient descent algorithm\nwith this learned penalty. Suppose the real data manifold intersects the\ninverse problem solutions with only the unique real solution. We prove that the\nunfolded DNN will converge to it stably. Furthermore, we demonstrate with an\nexample of MRI reconstruction that the proposed method outperforms conventional\nunfolding methods and traditional regularization methods in terms of\nreconstruction quality, stability and convergence speed.",
    "descriptor": "",
    "authors": [
      "Zhuo-Xu Cui",
      "Qingyong Zhu",
      "Jing Cheng",
      "Dong Liang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.13452"
  },
  {
    "id": "arXiv:2211.13485",
    "title": "A doubly-infinite family of 0-APN monomials",
    "abstract": "We consider an infinite family of exponents $e(l,k)$ with two parameters, $l$\nand $k$, and derive sufficient conditions for $e(l,k)$ to be 0-APN over\n$\\mathbb{F}_{2^n}$. These conditions allow us to generate, for each choice of\n$l$ and $k$, an infinite list of dimensions $n$ where $x^{e(l,k)}$ is 0-APN\nmuch more efficiently than in general. We observe that the Gold and Inverse\nexponents, as well as the inverses of the Gold exponents can be expressed in\nthe form $e(l,k)$ for suitable $l$ and $k$. We characterize all cases in which\n$e(l,k)$ can be cyclotomic equivalent to a representative from the Gold,\nKasami, Welch, Niho, and Inverse families of exponents. We characterize when\n$e(l,k)$ can lie in the same cyclotomic coset as the Dobbertin exponent\n(without considering inverses) and provide computational data showing that the\nDobbertin inverse is never equivalent to $e(l,k)$. We computationally test the\nAPN-ness of $e(l,k)$ for small values of $l$ and $k$ over $\\mathbb{F}_{2^n}$\nfor $n \\le 100$, and sketch the limits to which such tests can be performed\nusing currently available technology. We conclude that there are no APN\nmonomials among the tested functions, outside of known classes.",
    "descriptor": "",
    "authors": [
      "Nikolay Kaleyski",
      "Kjetil Nesheim",
      "Patenlimon St\u0103nic\u0103"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.13485"
  },
  {
    "id": "arXiv:2211.13487",
    "title": "Sensing Aided Reconfigurable Intelligent Surfaces for 3GPP 5G  Transparent Operation",
    "abstract": "Can reconfigurable intelligent surfaces (RISs) operate in a standalone mode\nthat is completely transparent to the 3GPP 5G initial access process? Realizing\nthat may greatly simplify the deployment and operation of these surfaces and\nreduce the infrastructure control overhead. This paper investigates the\nfeasibility of building standalone/transparent RIS systems and shows that one\nkey challenge lies in determining the user equipment (UE)-side RIS beam\nreflection direction. To address this challenge, we propose to equip the RISs\nwith multi-modal sensing capabilities (e.g., using wireless and visual sensors)\nthat enable them to develop some perception of the surrounding environment and\nthe mobile users. Based on that, we develop a machine learning framework that\nleverages the wireless and visual sensors at the RIS to select the optimal\nbeams between the base station (BS) and users and enable 5G\nstandalone/transparent RIS operation. Using a high-fidelity synthetic dataset\nwith co-existing wireless and visual data, we extensively evaluate the\nperformance of the proposed framework. Experimental results demonstrate that\nthe proposed approach can accurately predict the BS and UE-side candidate\nbeams, and that the standalone RIS beam selection solution is capable of\nrealizing near-optimal achievable rates with significantly reduced beam\ntraining overhead.",
    "descriptor": "\nComments: The RIS dataset and script files will be available soon. arXiv admin note: text overlap with arXiv:2211.07563\n",
    "authors": [
      "Shuaifeng Jiang",
      "Ahmed Hindy",
      "Ahmed Alkhateeb"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.13487"
  },
  {
    "id": "arXiv:2211.13517",
    "title": "Cutting the cost of pulsar astronomy: Saving time and energy when  searching for binary pulsars using NVIDIA GPUs",
    "abstract": "Using the Fourier Domain Acceleration Search (FDAS) method to search for\nbinary pulsars is a computationally costly process. Next generation radio\ntelescopes will have to perform FDAS in real time, as data volumes are too\nlarge to store. FDAS is a matched filtering approach for searching time-domain\nradio astronomy datasets for the signatures of binary pulsars with\napproximately linear acceleration. In this paper we will explore how we have\nreduced the energy cost of an SKA-like implementation of FDAS in\nAstroAccelerate, utilising a combination of mixed-precision computing and\ndynamic frequency scaling on NVIDIA GPUs. Combining the two approaches, we have\nmanaged to save 58% of the overall energy cost of FDAS with a (<3%) sacrifice\nin numerical sensitivity.",
    "descriptor": "",
    "authors": [
      "Jack White",
      "Karel Adamek",
      "Wes Armour"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.13517"
  },
  {
    "id": "arXiv:2211.13532",
    "title": "Many bounded versions of undecidable problems are NP-hard",
    "abstract": "Several physically inspired problems have been proven undecidable; examples\nare the spectral gap problem and the membership problem for quantum\ncorrelations. Most of these results rely on reductions from a handful of\nundecidable problems, such as the halting problem, the tiling problem, the Post\ncorrespondence problem or the matrix mortality problem. All these problems have\na common property: they have an NP-hard bounded version. This work establishes\na relation between undecidable unbounded problems and their bounded NP-hard\nversions. Specifically, we show that NP-hardness of a bounded version follows\neasily from the reduction of the unbounded problems. This leads to new and\nsimpler proofs of the NP-hardness of bounded version of the Post correspondence\nproblem, the matrix mortality problem, the positivity of matrix product\noperators, the reachability problem, the tiling problem, and the ground state\nenergy problem. This work sheds light on the intractability of problems in\ntheoretical physics and on the computational consequences of bounding a\nparameter.",
    "descriptor": "\nComments: 10 pages and 6 pages of appendices, 8 figures\n",
    "authors": [
      "Andreas Klingler",
      "Mirte van der Eyden",
      "Sebastian Stengele",
      "Tobias Reinhart",
      "Gemma De las Cuevas"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.13532"
  },
  {
    "id": "arXiv:2211.13533",
    "title": "Prosody-controllable spontaneous TTS with neural HMMs",
    "abstract": "Spontaneous speech has many affective and pragmatic functions that are\ninteresting and challenging to model in TTS (text-to-speech). However, the\npresence of reduced articulation, fillers, repetitions, and other disfluencies\nmean that text and acoustics are less well aligned than in read speech. This is\nproblematic for attention-based TTS. We propose a TTS architecture that is\nparticularly suited for rapidly learning to speak from irregular and small\ndatasets while also reproducing the diversity of expressive phenomena present\nin spontaneous speech. Specifically, we modify an existing neural HMM-based TTS\nsystem, which is capable of stable, monotonic alignments for spontaneous\nspeech, and add utterance-level prosody control, so that the system can\nrepresent the wide range of natural variability in a spontaneous speech corpus.\nWe objectively evaluate control accuracy and perform a subjective listening\ntest to compare to a system without prosody control. To exemplify the power of\ncombining mid-level prosody control and ecologically valid data for reproducing\nintricate spontaneous speech phenomena, we evaluate the system's capability of\nsynthesizing two types of creaky phonation. Audio samples are available at\nhttps://hfkml.github.io/pc_nhmm_tts/",
    "descriptor": "\nComments: 5 pages, 3 figures, Submitted to ICASSP 2023\n",
    "authors": [
      "Harm Lameris",
      "Shivam Mehta",
      "Gustav Eje Henter",
      "Joakim Gustafson",
      "\u00c9va Sz\u00e9kely"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.13533"
  },
  {
    "id": "arXiv:2211.13549",
    "title": "Online Regularized Learning Algorithm for Functional Data",
    "abstract": "In recent years, functional linear models have attracted growing attention in\nstatistics and machine learning, with the aim of recovering the slope function\nor its functional predictor. This paper considers online regularized learning\nalgorithm for functional linear models in reproducing kernel Hilbert spaces.\nConvergence analysis of excess prediction error and estimation error are\nprovided with polynomially decaying step-size and constant step-size,\nrespectively. Fast convergence rates can be derived via a capacity dependent\nanalysis. By introducing an explicit regularization term, we uplift the\nsaturation boundary of unregularized online learning algorithms when the\nstep-size decays polynomially, and establish fast convergence rates of\nestimation error without capacity assumption. However, it remains an open\nproblem to obtain capacity independent convergence rates for the estimation\nerror of the unregularized online learning algorithm with decaying step-size.\nIt also shows that convergence rates of both prediction error and estimation\nerror with constant step-size are competitive with those in the literature.",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Yuan Mao",
      "Zheng-Chu Guo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13549"
  },
  {
    "id": "arXiv:2211.13568",
    "title": "New High Dimensional Expanders from Covers",
    "abstract": "We present a new construction of high dimensional expanders based on covering\nspaces of simplicial complexes. High dimensional expanders (HDXs) are\nhypergraph analogues of expander graphs. They have many uses in theoretical\ncomputer science, but unfortunately only few constructions are known which have\narbitrarily small local spectral expansion.\nWe give a randomized algorithm that takes as input a high dimensional\nexpander $X$ (satisfying some mild assumptions). It outputs a sub-complex $Y\n\\subseteq X$ that is a high dimensional expander and has infinitely many\nsimplicial covers. These covers form new families of bounded-degree high\ndimensional expanders. The sub-complex $Y$ inherits $X$'s underlying graph and\nits links are sparsifications of the links of $X$. When the size of the links\nof $X$ is $O(\\log |X|)$, this algorithm can be made deterministic. Our\nalgorithm is based on the groups and generating sets discovered by Lubotzky,\nSamuels and Vishne (2005), that were used to construct the first discovered\nhigh dimensional expanders. We show these groups give rise to many more\n``randomized'' high dimensional expanders.\nIn addition, our techniques also give a random sparsification algorithm for\nhigh dimensional expanders, that maintains its local spectral properties. This\nmay be of independent interest.",
    "descriptor": "",
    "authors": [
      "Yotam Dikstein"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.13568"
  },
  {
    "id": "arXiv:2211.13589",
    "title": "Outan: An On-Head System for Driving micro-LED Arrays Implanted in  Freely Moving Mice",
    "abstract": "In the intact brain, neural activity can be recorded using sensing electrodes\nand manipulated using light stimulation. Silicon probes with integrated\nelectrodes and micro-LEDs enable the detection and control of neural activity\nusing a single implanted device. Miniaturized solutions for recordings from\nsmall freely moving animals are commercially available, but stimulation is\ndriven by large, stationary current sources. We designed and fabricated a\ncurrent source chip and integrated it into a headstage PCB that weighs 1.37 g.\nThe proposed system provides 10-bit resolution current control for 32 channels,\ndriving micro-LEDs with up to 4.6 V and sourcing up to 0.9 mA at a refresh rate\nof 5 kHz per channel. When calibrated against a micro-LED probe, the system\nallows linear control of light output power, up to 10 micro-W per micro-LED. To\ndemonstrate the capabilities of the system, synthetic sequences of neural\nspiking activity were produced by driving multiple micro-LEDs implanted in the\nhippocampal CA1 area of a freely moving mouse. The high spatial, temporal, and\namplitude resolution of the system provides a rich variety of stimulation\npatterns. Combined with commercially available sampling headstages, the system\nprovides an easy to use back-end, fully utilizing the bi-directional potential\nof integrated opto-electronic arrays.",
    "descriptor": "\nComments: 11 pages, 9 figures\n",
    "authors": [
      "Alexander Tarnavsky Eitan",
      "Shirly Someck",
      "Mario Zajac",
      "Eran Socher",
      "Eran Stark"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.13589"
  },
  {
    "id": "arXiv:2211.13611",
    "title": "Software Architecture and System Design of Rubin Observatory",
    "abstract": "Starting from a description of the Rubin Observatory Data Management System\nArchitecture, and drawing on our experience with and involvement in a range of\nother projects including Gaia, SDSS, UKIRT, and JCMT, we derive a series of\ngeneric design patterns and lessons learned.",
    "descriptor": "\nComments: 10 pages ADASS XXXII submission\n",
    "authors": [
      "William O'Mullane",
      "Frossie Economou",
      "Kian-Tat Lim",
      "Fritz Mueller",
      "Tim Jenness",
      "Gregory P. Dubois-Felsmann",
      "Leanne P. Guy",
      "Ian S. Sullivan",
      "Yusra AlSayyad",
      "John D. Swinbank",
      "K. Simon Krughoff"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.13611"
  },
  {
    "id": "arXiv:2211.13621",
    "title": "ACROBAT -- a multi-stain breast cancer histological whole-slide-image  data set from routine diagnostics for computational pathology",
    "abstract": "The analysis of FFPE tissue sections stained with haematoxylin and eosin\n(H&E) or immunohistochemistry (IHC) is an essential part of the pathologic\nassessment of surgically resected breast cancer specimens. IHC staining has\nbeen broadly adopted into diagnostic guidelines and routine workflows to\nmanually assess status and scoring of several established biomarkers, including\nER, PGR, HER2 and KI67. However, this is a task that can also be facilitated by\ncomputational pathology image analysis methods. The research in computational\npathology has recently made numerous substantial advances, often based on\npublicly available whole slide image (WSI) data sets. However, the field is\nstill considerably limited by the sparsity of public data sets. In particular,\nthere are no large, high quality publicly available data sets with WSIs of\nmatching IHC and H&E-stained tissue sections. Here, we publish the currently\nlargest publicly available data set of WSIs of tissue sections from surgical\nresection specimens from female primary breast cancer patients with matched\nWSIs of corresponding H&E and IHC-stained tissue, consisting of 4,212 WSIs from\n1,153 patients. The primary purpose of the data set was to facilitate the\nACROBAT WSI registration challenge, aiming at accurately aligning H&E and IHC\nimages. For research in the area of image registration, automatic quantitative\nfeedback on registration algorithm performance remains available through the\nACROBAT challenge website, based on more than 37,000 manually annotated\nlandmark pairs from 13 annotators. Beyond registration, this data set has the\npotential to enable many different avenues of computational pathology research,\nincluding stain-guided learning, virtual staining, unsupervised pre-training,\nartefact detection and stain-independent models.",
    "descriptor": "",
    "authors": [
      "Philippe Weitz",
      "Masi Valkonen",
      "Leslie Solorzano",
      "Circe Carr",
      "Kimmo Kartasalo",
      "Constance Boissin",
      "Sonja Koivukoski",
      "Aino Kuusela",
      "Dusan Rasic",
      "Yanbo Feng",
      "Sandra Kristiane Sinius Pouplier",
      "Abhinav Sharma",
      "Kajsa Ledesma Eriksson",
      "Leena Latonen",
      "Anne-Vibeke Laenkholm",
      "Johan Hartman",
      "Pekka Ruusuvuori",
      "Mattias Rantalainen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.13621"
  },
  {
    "id": "arXiv:2211.13624",
    "title": "Adaptive mixture approximation for target tracking in clutter",
    "abstract": "Target tracking represents a state estimation problem recurrent in many\npractical scenarios like air traffic control, autonomous vehicles, marine radar\nsurveillance and so on. In a Bayesian perspective, when phenomena like clutter\nare present, the vast majority of the existing tracking algorithms have to deal\nwith association hypotheses which can grow in the number over time; in that\ncase, the posterior state distribution can become computationally intractable\nand approximations have to be introduced. In this work, the impact of the\nnumber of hypotheses and corresponding reductions is investigated both in terms\nof employed computational resources and tracking performances. For this\npurpose, a recently developed adaptive mixture model reduction algorithm is\nconsidered in order to assess its performances when applied to the problem of\nsingle object tracking in the presence of clutter and to provide additional\ninsights on the addressed problem.",
    "descriptor": "",
    "authors": [
      "Alessandro D'Ortenzio",
      "Costanzo Manes",
      "Umut Orguner"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Systems and Control (eess.SY)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.13624"
  },
  {
    "id": "arXiv:2211.13666",
    "title": "Sampling strategies for the Herman-Kluk propagator of the wavefunction",
    "abstract": "When the semiclassical Herman-Kluk propagator is used for evaluating\nquantum-mechanical observables or time-correlation functions, the initial\nconditions for the guiding trajectories are typically sampled from the Husimi\ndensity. Here, we employ this propagator to evolve the wavefunction itself. We\ninvestigate two grid-free strategies for the initial sampling of the\nHerman-Kluk propagator applied to the wavefunction and validate the resulting\ntime-dependent wavefunctions evolved in harmonic and anharmonic potentials. In\nparticular, we consider Monte Carlo quadratures based either on the initial\nHusimi density or on its square root as possible and most natural sampling\ndensities. We prove analytical convergence error estimates and validate them\nwith numerical experiments on the harmonic oscillator and on a series of Morse\npotentials with increasing anharmonicity. In all cases, sampling from the\nsquare root of Husimi density leads to faster convergence of the wavefunction.",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Fabian Kr\u00f6ninger",
      "Caroline Lasser",
      "Ji\u0159\u00ed Van\u00ed\u010dek"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Numerical Analysis (math.NA)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.13666"
  },
  {
    "id": "arXiv:2211.13668",
    "title": "Zeroth-Order Alternating Gradient Descent Ascent Algorithms for a Class  of Nonconvex-Nonconcave Minimax Problems",
    "abstract": "In this paper, we consider a class of nonconvex-nonconcave minimax problems,\ni.e., NC-PL minimax problems, whose objective functions satisfy the\nPolyak-$\\L$ojasiewicz (PL) condition with respect to the inner variable. We\npropose a zeroth-order alternating gradient descent ascent (ZO-AGDA) algorithm\nand a zeroth-order variance reduced alternating gradient descent ascent\n(ZO-VRAGDA) algorithm for solving NC-PL minimax problem under the deterministic\nand the stochastic setting, respectively. The number of iterations to obtain an\n$\\epsilon$-stationary point of ZO-AGDA and ZO-VRAGDA algorithm for solving\nNC-PL minimax problem is upper bounded by $\\mathcal{O}(\\varepsilon^{-2})$ and\n$\\mathcal{O}(\\varepsilon^{-3})$, respectively. To the best of our knowledge,\nthey are the first two zeroth-order algorithms with the iteration complexity\ngurantee for solving NC-PL minimax problems.",
    "descriptor": "",
    "authors": [
      "Zi Xu",
      "Zi-Qi Wang",
      "Jun-Lin Wang",
      "Yu-Hong Dai"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.13668"
  },
  {
    "id": "arXiv:2211.13672",
    "title": "A Self-Attention Ansatz for Ab-initio Quantum Chemistry",
    "abstract": "We present a novel neural network architecture using self-attention, the\nWavefunction Transformer (Psiformer), which can be used as an approximation (or\nAnsatz) for solving the many-electron Schr\\\"odinger equation, the fundamental\nequation for quantum chemistry and material science. This equation can be\nsolved from first principles, requiring no external training data. In recent\nyears, deep neural networks like the FermiNet and PauliNet have been used to\nsignificantly improve the accuracy of these first-principle calculations, but\nthey lack an attention-like mechanism for gating interactions between\nelectrons. Here we show that the Psiformer can be used as a drop-in replacement\nfor these other neural networks, often dramatically improving the accuracy of\nthe calculations. On larger molecules especially, the ground state energy can\nbe improved by dozens of kcal/mol, a qualitative leap over previous methods.\nThis demonstrates that self-attention networks can learn complex quantum\nmechanical correlations between electrons, and are a promising route to\nreaching unprecedented accuracy in chemical calculations on larger systems.",
    "descriptor": "",
    "authors": [
      "Ingrid von Glehn",
      "James S. Spencer",
      "David Pfau"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.13672"
  },
  {
    "id": "arXiv:2211.13715",
    "title": "Trust Your $\\nabla$: Gradient-based Intervention Targeting for Causal  Discovery",
    "abstract": "Inferring causal structure from data is a challenging task of fundamental\nimportance in science. Observational data are often insufficient to identify a\nsystem's causal structure uniquely. While conducting interventions (i.e.,\nexperiments) can improve the identifiability, such samples are usually\nchallenging and expensive to obtain. Hence, experimental design approaches for\ncausal discovery aim to minimize the number of interventions by estimating the\nmost informative intervention target. In this work, we propose a novel\nGradient-based Intervention Targeting method, abbreviated GIT, that 'trusts'\nthe gradient estimator of a gradient-based causal discovery framework to\nprovide signals for the intervention acquisition function. We provide extensive\nexperiments in simulated and real-world datasets and demonstrate that GIT\nperforms on par with competitive baselines, surpassing them in the low-data\nregime.",
    "descriptor": "",
    "authors": [
      "Mateusz Olko",
      "Micha\u0142 Zaj\u0105c",
      "Aleksandra Nowak",
      "Nino Scherrer",
      "Yashas Annadani",
      "Stefan Bauer",
      "\u0141ukasz Kuci\u0144ski",
      "Piotr Mi\u0142o\u015b"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.13715"
  },
  {
    "id": "arXiv:2211.13719",
    "title": "MRHS multigrid solver for Wilson-clover fermions",
    "abstract": "We describe our implementation of a multigrid solver for Wilson-clover\nfermions, which increases parallelism by solving for multiple right-hand sides\n(MRHS) simultaneously. The solver is based on Grid and thus runs on all\ncomputing architectures supported by the Grid framework. We present detailed\nbenchmarks of the relevant kernels, such as hopping and clover term on the\nvarious multigrid levels, intergrid operators, and reductions. The benchmarks\nwere performed on the JUWELS Booster system at J\\\"ulich Supercomputing Centre,\nwhich is based on Nvidia A100 GPUs. For example, solving a $24^3\\times128$\nlattice on 16 GPUs, the overall speedup obtained solely from MRHS is about 10x.",
    "descriptor": "\nComments: 8 pages, 14 figures, proceedings of Lattice 2022\n",
    "authors": [
      "Daniel Richtmann",
      "Nils Meyer",
      "Tilo Wettig"
    ],
    "subjectives": [
      "High Energy Physics - Lattice (hep-lat)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.13719"
  },
  {
    "id": "arXiv:2211.13740",
    "title": "Cutting Medusa's Path -- Tackling Kill-Chains with Quantum Computing",
    "abstract": "This paper embarks upon exploration of quantum vulnerability analysis. By\nintroducing vulnerability graphs, related to attack graphs, this paper provides\nbackground theory and a subsequent method for solving significant cybersecurity\nproblems with quantum computing. The example given is to prioritize patches by\nexpressing the connectivity of various vulnerabilities on a network with a QUBO\nand then solving this with quantum annealing. Such a solution is then proved to\nremove all kill-chains (paths to security compromise) on a network. The results\ndemonstrate that the quantum computer's solve time is almost constant compared\nto the exponential increase in classical solve time for vulnerability graphs of\nexpected real world density. As such, this paper presents a novel example of\nadvantageous quantum vulnerability analysis.",
    "descriptor": "\nComments: 9 pages, 1 figure, 2 tables\n",
    "authors": [
      "Mark Carney"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.13740"
  },
  {
    "id": "arXiv:2211.13767",
    "title": "Quantum Adversarial Learning in Emulation of Monte-Carlo Methods for  Max-cut Approximation: QAOA is not optimal",
    "abstract": "One of the leading candidates for near-term quantum advantage is the class of\nVariational Quantum Algorithms, but these algorithms suffer from classical\ndifficulty in optimizing the variational parameters as the number of parameters\nincreases. Therefore, it is important to understand the expressibility and\npower of various ans\\\"atze to produce target states and distributions. To this\nend, we apply notions of emulation to Variational Quantum Annealing and the\nQuantum Approximate Optimization Algorithm (QAOA) to show that QAOA is\noutperformed by variational annealing schedules with equivalent numbers of\nparameters. Our Variational Quantum Annealing schedule is based on a novel\npolynomial parameterization that can be optimized in a similar gradient-free\nway as QAOA, using the same physical ingredients. In order to compare the\nperformance of ans\\\"atze types, we have developed statistical notions of\nMonte-Carlo methods. Monte-Carlo methods are computer programs that generate\nrandom variables that approximate a target number that is computationally hard\nto calculate exactly. While the most well-known Monte-Carlo method is\nMonte-Carlo integration (e.g. Diffusion Monte-Carlo or path-integral quantum\nMonte-Carlo), QAOA is itself a Monte-Carlo method that finds good solutions to\nNP-complete problems such as Max-cut. We apply these statistical Monte-Carlo\nnotions to further elucidate the theoretical framework around these quantum\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Cem M. Unsal",
      "Lucas T. Brady"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.13767"
  },
  {
    "id": "arXiv:2211.13772",
    "title": "Generative Joint Source-Channel Coding for Semantic Image Transmission",
    "abstract": "Recent works have shown that joint source-channel coding (JSCC) schemes using\ndeep neural networks (DNNs), called DeepJSCC, provide promising results in\nwireless image transmission. However, these methods mostly focus on the\ndistortion of the reconstructed signals with respect to the input image, rather\nthan their perception by humans. However, focusing on traditional distortion\nmetrics alone does not necessarily result in high perceptual quality,\nespecially in extreme physical conditions, such as very low bandwidth\ncompression ratio (BCR) and low signal-to-noise ratio (SNR) regimes. In this\nwork, we propose two novel JSCC schemes that leverage the perceptual quality of\ndeep generative models (DGMs) for wireless image transmission, namely\nInverseJSCC and GenerativeJSCC. While the former is an inverse problem approach\nto DeepJSCC, the latter is an end-to-end optimized JSCC scheme. In both, we\noptimize a weighted sum of mean squared error (MSE) and learned perceptual\nimage patch similarity (LPIPS) losses, which capture more semantic similarities\nthan other distortion metrics. InverseJSCC performs denoising on the distorted\nreconstructions of a DeepJSCC model by solving an inverse optimization problem\nusing style-based generative adversarial network (StyleGAN). Our simulation\nresults show that InverseJSCC significantly improves the state-of-the-art\n(SotA) DeepJSCC in terms of perceptual quality in edge cases. In\nGenerativeJSCC, we carry out end-to-end training of an encoder and a\nStyleGAN-based decoder, and show that GenerativeJSCC significantly outperforms\nDeepJSCC both in terms of distortion and perceptual quality.",
    "descriptor": "\nComments: 12 pages, 9 figures\n",
    "authors": [
      "Ecenaz Erdemir",
      "Tze-Yang Tung",
      "Pier Luigi Dragotti",
      "Deniz Gunduz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.13772"
  },
  {
    "id": "arXiv:2211.13784",
    "title": "Late lumping of observer-based state feedback for boundary control  systems",
    "abstract": "Infinite-dimensional linear systems with unbounded input and output operators\nare considered. For the purpose of finite-dimensional observer-based state\nfeedback, an observer approximation scheme will be developed which can be\ndirectly combined with existing late-lumping controllers and observer output\ninjection gains. It relies on a decomposition of the feedback gain, resp.\nobserver output injection gain, into a bounded and an unbounded part. Based on\na perturbation result, the spectrum-determined growth condition is established,\nfor the closed loop.",
    "descriptor": "\nComments: 7 pages, 1 figure, 1 table, submitted to IFAC WC 2023\n",
    "authors": [
      "Marcus Riesmeier",
      "Frank Woittennek"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.13784"
  },
  {
    "id": "arXiv:2211.13793",
    "title": "Tensor Decomposition of Large-scale Clinical EEGs Reveals Interpretable  Patterns of Brain Physiology",
    "abstract": "Identifying abnormal patterns in electroencephalography (EEG) remains the\ncornerstone of diagnosing several neurological diseases. The current clinical\nEEG review process relies heavily on expert visual review, which is unscalable\nand error-prone. In an effort to augment the expert review process, there is a\nsignificant interest in mining population-level EEG patterns using unsupervised\napproaches. Current approaches rely either on two-dimensional decompositions\n(e.g., principal and independent component analyses) or deep representation\nlearning (e.g., auto-encoders, self-supervision). However, most approaches do\nnot leverage the natural multi-dimensional structure of EEGs and lack\ninterpretability. In this study, we propose a tensor decomposition approach\nusing the canonical polyadic decomposition to discover a parsimonious set of\npopulation-level EEG patterns, retaining the natural multi-dimensional\nstructure of EEGs (time x space x frequency). We then validate their clinical\nvalue using a cohort of patients including varying stages of cognitive\nimpairment. Our results show that the discovered patterns reflect\nphysiologically meaningful features and accurately classify the stages of\ncognitive impairment (healthy vs mild cognitive impairment vs Alzheimer's\ndementia) with substantially fewer features compared to classical and deep\nlearning-based baselines. We conclude that the decomposition of\npopulation-level EEG tensors recovers expert-interpretable EEG patterns that\ncan aid in the study of smaller specialized clinical cohorts.",
    "descriptor": "\nComments: 4 pages, 3 Figures, 2 Tables; Under submission at IEEE NER\n",
    "authors": [
      "Teja Gupta",
      "Neeraj Wagh",
      "Samarth Rawal",
      "Brent Berry",
      "Gregory Worrell",
      "Yogatheesan Varatharajah"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.13793"
  },
  {
    "id": "arXiv:2211.13797",
    "title": "Data-Driven Distributionally Robust Electric Vehicle Balancing for  Autonomous Mobility-on-Demand Systems under Demand and Supply Uncertainties",
    "abstract": "Electric vehicles (EVs) are being rapidly adopted due to their economic and\nsocietal benefits. Autonomous mobility-on-demand (AMoD) systems also embrace\nthis trend. However, the long charging time and high recharging frequency of\nEVs pose challenges to efficiently managing EV AMoD systems. The complicated\ndynamic charging and mobility process of EV AMoD systems makes the demand and\nsupply uncertainties significant when designing vehicle balancing algorithms.\nIn this work, we design a data-driven distributionally robust optimization\n(DRO) approach to balance EVs for both the mobility service and the charging\nprocess. The optimization goal is to minimize the worst-case expected cost\nunder both passenger mobility demand uncertainties and EV supply uncertainties.\nWe then propose a novel distributional uncertainty sets construction algorithm\nthat guarantees the produced parameters are contained in desired confidence\nregions with a given probability. To solve the proposed DRO AMoD EV balancing\nproblem, we derive an equivalent computationally tractable convex optimization\nproblem. Based on real-world EV data of a taxi system, we show that with our\nsolution the average total balancing cost is reduced by 14.49%, and the average\nmobility fairness and charging fairness are improved by 15.78% and 34.51%,\nrespectively, compared to solutions that do not consider uncertainties.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Sihong He",
      "Zhili Zhang",
      "Shuo Han",
      "Lynn Pepin",
      "Guang Wang",
      "Desheng Zhang",
      "John Stankovic",
      "Fei Miao"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.13797"
  },
  {
    "id": "arXiv:2211.13866",
    "title": "Minimal Width for Universal Property of Deep RNN",
    "abstract": "A recurrent neural network (RNN) is a widely used deep-learning network for\ndealing with sequential data. Imitating a dynamical system, an infinite-width\nRNN can approximate any open dynamical system in a compact domain. In general,\ndeep networks with bounded widths are more effective than wide networks in\npractice; however, the universal approximation theorem for deep narrow\nstructures has yet to be extensively studied. In this study, we prove the\nuniversality of deep narrow RNNs and show that the upper bound of the minimum\nwidth for universality can be independent of the length of the data.\nSpecifically, we show that a deep RNN with ReLU activation can approximate any\ncontinuous function or $L^p$ function with the widths $d_x+d_y+2$ and\n$\\max\\{d_x+1,d_y\\}$, respectively, where the target function maps a finite\nsequence of vectors in $\\mathbb{R}^{d_x}$ to a finite sequence of vectors in\n$\\mathbb{R}^{d_y}$. We also compute the additional width required if the\nactivation function is $\\tanh$ or more. In addition, we prove the universality\nof other recurrent networks, such as bidirectional RNNs. Bridging a multi-layer\nperceptron and an RNN, our theory and proof technique can be an initial step\ntoward further research on deep RNNs.",
    "descriptor": "",
    "authors": [
      "Chang hoon Song",
      "Geonho Hwang",
      "Jun ho Lee",
      "Myungjoo Kang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13866"
  },
  {
    "id": "arXiv:2211.13914",
    "title": "Unbalanced penalization: A new approach to encode inequality constraints  of combinatorial problems for quantum optimization algorithms",
    "abstract": "Solving combinatorial optimization problems of the kind that can be codified\nby quadratic unconstrained binary optimization (QUBO) is a promising\napplication of quantum computation. Some problems of this class suitable for\npractical applications such as the traveling salesman problem (TSP), the bin\npacking problem (BPP), or the knapsack problem (KP) have inequality constraints\nthat require a particular cost function encoding. The common approach is the\nuse of slack variables to represent the inequality constraints in the cost\nfunction. However, the use of slack variables increases considerably the number\nof qubits and operations required to solve these problems using quantum\ndevices. In this work, we present an alternative method that does not require\nextra slack variables and consists of using an unbalanced penalization function\nto represent the inequality constraints in the QUBO. This function is\ncharacterized by having a larger penalization when the inequality constraint is\nnot achieved than when it is. We tested our approach for the TSP, the BPP, and\nthe KP. For all of them, we are able to encode the optimal solution in the\nvicinity of the cost Hamiltonian ground state. This new approach can be used to\nsolve combinatorial problems with inequality constraints with a reduced number\nof resources compared to the slack variables approach using quantum annealing\nor variational quantum algorithms.",
    "descriptor": "\nComments: 11 pages, 12 figures\n",
    "authors": [
      "Alejandro Montanez-Barrera",
      "Alberto Maldonado-Romo",
      "Dennis Willsch",
      "Kristel Michielsen"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.13914"
  },
  {
    "id": "arXiv:2211.13915",
    "title": "Confidence Interval Construction for Multivariate time series using Long  Short Term Memory Network",
    "abstract": "In this paper we propose a novel procedure to construct a confidence interval\nfor multivariate time series predictions using long short term memory network.\nThe construction uses a few novel block bootstrap techniques. We also propose\nan innovative block length selection procedure for each of these schemes. Two\nnovel benchmarks help us to compare the construction of this confidence\nintervals by different bootstrap techniques. We illustrate the whole\nconstruction through S\\&P $500$ and Dow Jones Index datasets.",
    "descriptor": "",
    "authors": [
      "Aryan Bhambu",
      "Arabin Kumar Dey"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.13915"
  },
  {
    "id": "arXiv:2211.13926",
    "title": "Generative Modeling in Sinogram Domain for Sparse-view CT Reconstruction",
    "abstract": "The radiation dose in computed tomography (CT) examinations is harmful for\npatients but can be significantly reduced by intuitively decreasing the number\nof projection views. Reducing projection views usually leads to severe aliasing\nartifacts in reconstructed images. Previous deep learning (DL) techniques with\nsparse-view data require sparse-view/full-view CT image pairs to train the\nnetwork with supervised manners. When the number of projection view changes,\nthe DL network should be retrained with updated sparse-view/full-view CT image\npairs. To relieve this limitation, we present a fully unsupervised score-based\ngenerative model in sinogram domain for sparse-view CT reconstruction.\nSpecifically, we first train a score-based generative model on full-view\nsinogram data and use multi-channel strategy to form highdimensional tensor as\nthe network input to capture their prior distribution. Then, at the inference\nstage, the stochastic differential equation (SDE) solver and data-consistency\nstep were performed iteratively to achieve fullview projection. Filtered\nback-projection (FBP) algorithm was used to achieve the final image\nreconstruction. Qualitative and quantitative studies were implemented to\nevaluate the presented method with several CT data. Experimental results\ndemonstrated that our method achieved comparable or better performance than the\nsupervised learning counterparts.",
    "descriptor": "\nComments: 11 pages, 12 figures\n",
    "authors": [
      "Bing Guan",
      "Cailian Yang",
      "Liu Zhang",
      "Shanzhou Niu",
      "Minghui Zhang",
      "Yuhao Wang",
      "Weiwen Wu",
      "Qiegen Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13926"
  },
  {
    "id": "arXiv:2211.13931",
    "title": "Transitivity on subclasses of chordal graphs",
    "abstract": "Let $G=(V, E)$ be a graph, where $V$ and $E$ are the vertex and edge sets,\nrespectively. For two disjoint subsets $A$ and $B$ of $V$, we say $A$\n\\textit{dominates} $B$ if every vertex of $B$ is adjacent to at least one\nvertex of $A$ in $G$. A vertex partition $\\pi = \\{V_1, V_2, \\ldots, V_k\\}$ of\n$G$ is called a \\emph{transitive $k$-partition} if $V_i$ dominates $V_j$ for\nall $i,j$, where $1\\leq i<j\\leq k$. The maximum integer $k$ for which the above\npartition exists is called \\emph{transitivity} of $G$ and it is denoted by\n$Tr(G)$. The \\textsc{Maximum Transitivity Problem} is to find a transitive\npartition of a given graph with the maximum number of partitions. It was known\nthat the decision version of \\textsc{Maximum Transitivity Problem} is\nNP-complete for chordal graphs [Iterated colorings of graphs, \\emph{Discrete\nMathematics}, 278, 2004]. In this paper, we first prove that this problem can\nbe solved in linear time for \\emph{split graphs} and for the \\emph{complement\nof bipartite chain graphs}, two subclasses of chordal graphs. We also discuss\nNordhaus-Gaddum type relations for transitivity and provide counterexamples for\nan open problem posed by J. T. Hedetniemi and S. T. Hedetniemi [The\ntransitivity of a graph, \\emph{J. Combin. Math. Combin. Comput}, 104, 2018].\nFinally, we characterize transitively critical graphs having fixed\ntransitivity.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2204.13148\n",
    "authors": [
      "Subhabrata Paul",
      "Kamal Santra"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.13931"
  },
  {
    "id": "arXiv:2211.13942",
    "title": "Affine Transformation Edited and Refined Deep Neural Network for  Quantitative Susceptibility Mapping",
    "abstract": "Deep neural networks have demonstrated great potential in solving dipole\ninversion for Quantitative Susceptibility Mapping (QSM). However, the\nperformances of most existing deep learning methods drastically degrade with\nmismatched sequence parameters such as acquisition orientation and spatial\nresolution. We propose an end-to-end AFfine Transformation Edited and Refined\n(AFTER) deep neural network for QSM, which is robust against arbitrary\nacquisition orientation and spatial resolution up to 0.6 mm isotropic at the\nfinest. The AFTER-QSM neural network starts with a forward affine\ntransformation layer, followed by an Unet for dipole inversion, then an inverse\naffine transformation layer, followed by a Residual Dense Network (RDN) for QSM\nrefinement. Simulation and in-vivo experiments demonstrated that the proposed\nAFTER-QSM network architecture had excellent generalizability. It can\nsuccessfully reconstruct susceptibility maps from highly oblique and\nanisotropic scans, leading to the best image quality assessments in simulation\ntests and suppressed streaking artifacts and noise levels for in-vivo\nexperiments compared with other methods. Furthermore, ablation studies showed\nthat the RDN refinement network significantly reduced image blurring and\nsusceptibility underestimation due to affine transformations. In addition, the\nAFTER-QSM network substantially shortened the reconstruction time from minutes\nusing conventional methods to only a few seconds.",
    "descriptor": "",
    "authors": [
      "Zhuang Xiong",
      "Yang Gao",
      "Feng Liu",
      "Hongfu Sun"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13942"
  },
  {
    "id": "arXiv:2211.13954",
    "title": "Particle-based Variational Inference with Preconditioned Functional  Gradient Flow",
    "abstract": "Particle-based variational inference (VI) minimizes the KL divergence between\nmodel samples and the target posterior with gradient flow estimates. With the\npopularity of Stein variational gradient descent (SVGD), the focus of\nparticle-based VI algorithms has been on the properties of functions in\nReproducing Kernel Hilbert Space (RKHS) to approximate the gradient flow.\nHowever, the requirement of RKHS restricts the function class and algorithmic\nflexibility. This paper remedies the problem by proposing a general framework\nto obtain tractable functional gradient flow estimates. The functional gradient\nflow in our framework can be defined by a general functional regularization\nterm that includes the RKHS norm as a special case. We use our framework to\npropose a new particle-based VI algorithm: preconditioned functional gradient\nflow (PFG). Compared with SVGD, the proposed method has several advantages:\nlarger function class; greater scalability in large particle-size scenarios;\nbetter adaptation to ill-conditioned distributions; provable continuous-time\nconvergence in KL divergence. Non-linear function classes such as neural\nnetworks can be incorporated to estimate the gradient flow. Both theory and\nexperiments have shown the effectiveness of our framework.",
    "descriptor": "\nComments: 34 pages, 8 figures\n",
    "authors": [
      "Hanze Dong",
      "Xi Wang",
      "Yong Lin",
      "Tong Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13954"
  },
  {
    "id": "arXiv:2211.14010",
    "title": "Circuit Analysis using Monotone+Skew Splitting",
    "abstract": "It is shown that the behavior of an $m$-port circuit of maximal monotone\nelements can be expressed as a zero of the sum of a maximal monotone operator\ncontaining the circuit elements, and a structured skew-symmetric linear\noperator representing the interconnection structure, together with a linear\noutput transformation. The Condat-V\\~u algorithm solves inclusion problems of\nthis form, and may be used to solve for the periodic steady-state behavior,\ngiven a periodic excitation at each port, using an iteration in the space of\nperiodic trajectories.",
    "descriptor": "\nComments: Submitted to the 2023 European Control Conference\n",
    "authors": [
      "Thomas Chaffey",
      "Sebastian Banert",
      "Pontus Giselsson",
      "Richard Pates"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.14010"
  },
  {
    "id": "arXiv:2211.14024",
    "title": "Toward Unlimited Self-Learning Monte Carlo with Annealing Process Using  VAE's Implicit Isometricity",
    "abstract": "Self-learning Monte Carlo (SLMC) methods are recently proposed to accelerate\nMarkov chain Monte Carlo (MCMC) methods by using a machine learning model.With\ngenerative models having latent variables, SLMC methods realize efficient Monte\nCarlo updates with less autocorrelation. However, SLMC methods are difficult to\ndirectly apply to multimodal distributions for which training data are\ndifficult to obtain. In this paper, we propose a novel SLMC method called the\n``annealing VAE-SLMC\" to drastically expand the range of applications. Our\nVAE-SLMC utilizes a variational autoencoder (VAE) as a generative model to make\nefficient parallel proposals independent of any previous state by applying the\ntheoretically derived implicit isometricity of the VAE. We combine an adaptive\nannealing process to the VAE-SLMC, making our method applicable to the cases\nwhere obtaining unbiased training data is difficult in practical sense due to\nslow mixing. We also propose a parallel annealing process and an exchange\nprocess between chains to make the annealing operation more precise and\nefficient. Experiments validate that our method can proficiently obtain\nunbiased samples from multiple multimodal toy distributions and practical\nmultimodal posterior distributions, which is difficult to achieve with the\nexisting SLMC methods.",
    "descriptor": "\nComments: 24 pages,12 figures\n",
    "authors": [
      "Yuma Ichikawa",
      "Akira Nakagawa",
      "Hiromoto Masayuki",
      "Yuhei Umeda"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.14024"
  },
  {
    "id": "arXiv:2211.14040",
    "title": "Real-Time Under-Display Cameras Image Restoration and HDR on Mobile  Devices",
    "abstract": "The new trend of full-screen devices implies positioning the camera behind\nthe screen to bring a larger display-to-body ratio, enhance eye contact, and\nprovide a notch-free viewing experience on smartphones, TV or tablets. On the\nother hand, the images captured by under-display cameras (UDCs) are degraded by\nthe screen in front of them. Deep learning methods for image restoration can\nsignificantly reduce the degradation of captured images, providing satisfying\nresults for the human eyes. However, most proposed solutions are unreliable or\nefficient enough to be used in real-time on mobile devices.\nIn this paper, we aim to solve this image restoration problem using efficient\ndeep learning methods capable of processing FHD images in real-time on\ncommercial smartphones while providing high-quality results. We propose a\nlightweight model for blind UDC Image Restoration and HDR, and we also provide\na benchmark comparing the performance and runtime of different methods on\nsmartphones. Our models are competitive on UDC benchmarks while using x4 less\noperations than others. To the best of our knowledge, we are the first work to\napproach and analyze this real-world single image restoration problem from the\nefficiency and production point of view.",
    "descriptor": "\nComments: ECCV 2022 AIM Workshop\n",
    "authors": [
      "Marcos V. Conde",
      "Florin Vasluianu",
      "Sabari Nathan",
      "Radu Timofte"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14040"
  },
  {
    "id": "arXiv:2211.14043",
    "title": "Decisive role of fluctuations in the resource dependency networks",
    "abstract": "Individual components of many real-world complex networks produce and\nexchange resources among themselves. However, because the resource production\nin such networks is almost always stochastic, fluctuations in the production\nare unavoidable. In this paper, we study the effect of fluctuations on the\nresource dependencies in complex networks. To this end, we consider a\nmodification of a threshold model of resource dependencies in networks that was\nrecently proposed, where each vertex can either be in a fit or a degraded\nstate. We study how the \"network fitness\" is affected as the fluctuation size\nis varied. We show that, the relative value of the average production with\nrespect to the threshold, decides whether the fluctuations are beneficial or\ndetrimental to the network fitness. We further show that the networks with a\nhomogeneous degree distribution, such as the Erdos-Renyi network, perform\nbetter in terms of fitness and also produce lower wastage than the Scale-Free\nnetwork. Our work shows that, in the study of resource dependencies in\nnetworks, the role of the fluctuations is as decisive as the average\nproduction.",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Saumitra Kulkarni",
      "Snehal M. Shekatkar"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2211.14043"
  },
  {
    "id": "arXiv:2211.14049",
    "title": "Task-Oriented Communication for Edge Video Analytics",
    "abstract": "With the development of artificial intelligence (AI) techniques and the\nincreasing popularity of camera-equipped devices, many edge video analytics\napplications are emerging, calling for the deployment of computation-intensive\nAI models at the network edge. Edge inference is a promising solution to move\nthe computation-intensive workloads from low-end devices to a powerful edge\nserver for video analytics, but the device-server communications will remain a\nbottleneck due to the limited bandwidth. This paper proposes a task-oriented\ncommunication framework for edge video analytics, where multiple devices\ncollect the visual sensory data and transmit the informative features to an\nedge server for processing. To enable low-latency inference, this framework\nremoves video redundancy in spatial and temporal domains and transmits minimal\ninformation that is essential for the downstream task, rather than\nreconstructing the videos at the edge server. Specifically, it extracts compact\ntask-relevant features based on the deterministic information bottleneck (IB)\nprinciple, which characterizes a tradeoff between the informativeness of the\nfeatures and the communication cost. As the features of consecutive frames are\ntemporally correlated, we propose a temporal entropy model (TEM) to reduce the\nbitrate by taking the previous features as side information in feature\nencoding. To further improve the inference performance, we build a\nspatial-temporal fusion module at the server to integrate features of the\ncurrent and previous frames for joint inference. Extensive experiments on video\nanalytics tasks evidence that the proposed framework effectively encodes\ntask-relevant information of video data and achieves a better rate-performance\ntradeoff than existing methods.",
    "descriptor": "",
    "authors": [
      "Jiawei Shao",
      "Xinjie Zhang",
      "Jun Zhang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14049"
  },
  {
    "id": "arXiv:2211.14051",
    "title": "Open-Source Skull Reconstruction with MONAI",
    "abstract": "We present a deep learning-based approach for skull reconstruction for MONAI,\nwhich has been pre-trained on the MUG500+ skull dataset. The implementation\nfollows the MONAI contribution guidelines, hence, it can be easily tried out\nand used, and extended by MONAI users. The primary goal of this paper lies in\nthe investigation of open-sourcing codes and pre-trained deep learning models\nunder the MONAI framework. Nowadays, open-sourcing software, especially\n(pre-trained) deep learning models, has become increasingly important. Over the\nyears, medical image analysis experienced a tremendous transformation. Over a\ndecade ago, algorithms had to be implemented and optimized with low-level\nprogramming languages, like C or C++, to run in a reasonable time on a desktop\nPC, which was not as powerful as today's computers. Nowadays, users have\nhigh-level scripting languages like Python, and frameworks like PyTorch and\nTensorFlow, along with a sea of public code repositories at hand. As a result,\nimplementations that had thousands of lines of C or C++ code in the past, can\nnow be scripted with a few lines and in addition executed in a fraction of the\ntime. To put this even on a higher level, the Medical Open Network for\nArtificial Intelligence (MONAI) framework tailors medical imaging research to\nan even more convenient process, which can boost and push the whole field. The\nMONAI framework is a freely available, community-supported, open-source and\nPyTorch-based framework, that also enables to provide research contributions\nwith pre-trained models to others. Codes and pre-trained weights for skull\nreconstruction are publicly available at:\nhttps://github.com/Project-MONAI/research-contributions/tree/master/SkullRec",
    "descriptor": "",
    "authors": [
      "Jianning Li",
      "Andr\u00e9 Ferreira",
      "Behrus Puladi",
      "Victor Alves",
      "Michael Kamp",
      "Moon-Sung Kim",
      "Felix Nensa",
      "Jens Kleesiek",
      "Seyed-Ahmad Ahmadi",
      "Jan Egger"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14051"
  },
  {
    "id": "arXiv:2211.14075",
    "title": "On a Moving Average with Internal Degrees of Freedom",
    "abstract": "A new type of moving average is developed. Whereas a regular moving average\n(e.g. of price) has a built-in internal time scale (time-window, exponential\nweight, etc.), the moving average developed in this paper has the weight as the\nproduct of a polynomial by window factor. The polynomial is the square of a\nwavefunction obtained from an eigenproblem corresponding to other observable\n(e.g. execution flow I=dV/dt , the number of shares traded per unit time). This\nallows to obtain an immediate \"switch\" without lagging typical for regular\nmoving average.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2210.04223\n",
    "authors": [
      "Linda Boudjemila",
      "Alexander Bobyl",
      "Vadim Davydov",
      "Vladislav Malyshkin"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Numerical Analysis (math.NA)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2211.14075"
  },
  {
    "id": "arXiv:2211.14080",
    "title": "MTRESS 3.0 -- Modell Template for Residential Energy Supply Systems",
    "abstract": "MTRESS is a tool that facilitates the creation of models of residential\nenergy supply systems by providing a template with meaningful presets. This\nmodel can then be used to linearly optimise the operation of the energy system.\nVersion~3.0 enables multiple locations belonging to one energy system to be\ndefined. Furthermore, it adds hydrogen as an energy carrier with the\npossibility to convert power to gas using electrolysis and to store gas at\ndifferent pressure levels. Additionally, we reworked the Python API, giving\nmore flexibility to the user.",
    "descriptor": "\nComments: 14 pages, 2 figures\n",
    "authors": [
      "Patrik Sch\u00f6nfeldt",
      "Sunke Schl\u00fcters",
      "Keno Oltmanns"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.14080"
  },
  {
    "id": "arXiv:2211.14096",
    "title": "Deep grading for MRI-based differential diagnosis of Alzheimer's disease  and Frontotemporal dementia",
    "abstract": "Alzheimer's disease and Frontotemporal dementia are common forms of\nneurodegenerative dementia. Behavioral alterations and cognitive impairments\nare found in the clinical courses of both diseases and their differential\ndiagnosis is sometimes difficult for physicians. Therefore, an accurate tool\ndedicated to this diagnostic challenge can be valuable in clinical practice.\nHowever, current structural imaging methods mainly focus on the detection of\neach disease but rarely on their differential diagnosis. In this paper, we\npropose a deep learning based approach for both problems of disease detection\nand differential diagnosis. We suggest utilizing two types of biomarkers for\nthis application: structure grading and structure atrophy. First, we propose to\ntrain a large ensemble of 3D U-Nets to locally determine the anatomical\npatterns of healthy people, patients with Alzheimer's disease and patients with\nFrontotemporal dementia using structural MRI as input. The output of the\nensemble is a 2-channel disease's coordinate map able to be transformed into a\n3D grading map which is easy to interpret for clinicians. This 2-channel map is\ncoupled with a multi-layer perceptron classifier for different classification\ntasks. Second, we propose to combine our deep learning framework with a\ntraditional machine learning strategy based on volume to improve the model\ndiscriminative capacity and robustness. After both cross-validation and\nexternal validation, our experiments based on 3319 MRI demonstrated competitive\nresults of our method compared to the state-of-the-art methods for both disease\ndetection and differential diagnosis.",
    "descriptor": "",
    "authors": [
      "Huy-Dung Nguyen",
      "Micha\u00ebl Cl\u00e9ment",
      "Vincent Planche",
      "Boris Mansencal",
      "Pierrick Coup\u00e9"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14096"
  },
  {
    "id": "arXiv:2211.14115",
    "title": "Inverse Solvability and Security with Applications to Federated Learning",
    "abstract": "We introduce the concepts of inverse solvability and security for a generic\nlinear forward model and demonstrate how they can be applied to models used in\nfederated learning. We provide examples of such models which differ in the\nresulting inverse solvability and security as defined in this paper. We also\nshow how the large number of users participating in a given iteration of\nfederated learning can be leveraged to increase both solvability and security.\nFinally, we discuss possible extensions of the presented concepts including the\nnonlinear case.",
    "descriptor": "",
    "authors": [
      "Tomasz Piotrowski",
      "Matthias Frey",
      "Renato L.G. Cavalcante",
      "Rafail Ismailov"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14115"
  },
  {
    "id": "arXiv:2211.14122",
    "title": "Automating Cobb Angle Measurement for Adolescent Idiopathic Scoliosis  using Instance Segmentation",
    "abstract": "Scoliosis is a three-dimensional deformity of the spine, most often diagnosed\nin childhood. It affects 2-3% of the population, which is approximately seven\nmillion people in North America. Currently, the reference standard for\nassessing scoliosis is based on the manual assignment of Cobb angles at the\nsite of the curvature center. This manual process is time consuming and\nunreliable as it is affected by inter- and intra-observer variance. To overcome\nthese inaccuracies, machine learning (ML) methods can be used to automate the\nCobb angle measurement process. This paper proposes to address the Cobb angle\nmeasurement task using YOLACT, an instance segmentation model. The proposed\nmethod first segments the vertebrae in an X-Ray image using YOLACT, then it\ntracks the important landmarks using the minimum bounding box approach. Lastly,\nthe extracted landmarks are used to calculate the corresponding Cobb angles.\nThe model achieved a Symmetric Mean Absolute Percentage Error (SMAPE) score of\n10.76%, demonstrating the reliability of this process in both vertebra\nlocalization and Cobb angle measurement.",
    "descriptor": "",
    "authors": [
      "Chaojun Chen",
      "Khashayar Namdar",
      "Yujie Wu",
      "Shahob Hosseinpour",
      "Manohar Shroff",
      "Andrea S. Doria",
      "Farzad Khalvati"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14122"
  },
  {
    "id": "arXiv:2211.14162",
    "title": "A Gaussian Process Regression based Dynamical Models Learning Algorithm  for Target Tracking",
    "abstract": "Maneuvering target tracking is a challenging problem for sensor systems\nbecause of the unpredictability of the targets' motions. This paper proposes a\nnovel data-driven method for learning the dynamical motion model of a target.\nNon-parametric Gaussian process regression (GPR) is used to learn a target's\nnaturally shift invariant motion (NSIM) behavior, which is translationally\ninvariant and does not need to be constantly updated as the target moves. The\nlearned Gaussian processes (GPs) can be applied to track targets within\ndifferent surveillance regions from the surveillance region of the training\ndata by being incorporated into the particle filter (PF) implementation. The\nperformance of our proposed approach is evaluated over different maneuvering\nscenarios by being compared with commonly used interacting multiple model\n(IMM)-PF methods and provides around $90\\%$ performance improvement for a\nmulti-target tracking (MTT) highly maneuvering scenario.",
    "descriptor": "\nComments: 11 pages, 10 figures\n",
    "authors": [
      "Mengwei Sun",
      "Mike E. Davies",
      "Ian K. Proudler",
      "James R. Hopgood"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.14162"
  },
  {
    "id": "arXiv:2211.14218",
    "title": "Shotgun assembly of random graphs",
    "abstract": "Graph shotgun assembly refers to the problem of reconstructing a graph from\nthe collection of $r$-balls around each vertex. We study this problem for an\nErd\\H{o}s-R\\'enyi random graph $G\\in \\mathcal G(n,p)$, and for a wide range of\nvalues of $r$. We determine the exact thresholds for $r$-reconstructibility for\n$r\\geq 3$, which improves and generalises the result of Mossel and Ross for\n$r=3$. In addition, we give better upper and lower bounds on the threshold of\n2-reconstructibility, improving the results of Gaudio and Mossel by polynomial\nfactors. We also give an improved lower bound for the result of Huang and\nTikhomirov for $r=1$.",
    "descriptor": "\nComments: 37 pages, 3 figures\n",
    "authors": [
      "Tom Johnston",
      "Gal Kronenberg",
      "Alexander Roberts",
      "Alex Scott"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.14218"
  },
  {
    "id": "arXiv:2211.14219",
    "title": "The Economics of Recommender Systems: Evidence from a Field Experiment  on MovieLens",
    "abstract": "We conduct a field experiment on a movie-recommendation platform to identify\nif and how recommendations affect consumption. We use within-consumer\nrandomization at the good level and elicit beliefs about unconsumed goods to\ndisentangle exposure from informational effects. We find recommendations\nincrease consumption beyond its role in exposing goods to consumers. We provide\nsupport for an informational mechanism: recommendations affect consumers'\nbeliefs, which in turn explain consumption. Recommendations reduce uncertainty\nabout goods consumers are most uncertain about and induce information\nacquisition. Our results highlight the importance of recommender systems'\ninformational role when considering policies targeting these systems in online\nmarketplaces.",
    "descriptor": "",
    "authors": [
      "Guy Aridor",
      "Duarte Goncalves",
      "Daniel Kluver",
      "Ruoyan Kong",
      "Joseph Konstan"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.14219"
  },
  {
    "id": "arXiv:2211.14220",
    "title": "Data-driven identification and analysis of the glass transition in  polymer melts",
    "abstract": "We propose a data-driven approach based on information about structural\nfluctuations of polymer chains, which clearly identifies the glass transition\ntemperature $T_g$ of polymer melts of weakly semiflexible chains. We use\nprincipal component analysis (PCA) with clustering to distinguish between\nliquid and glassy states and predict $T_g$ in the asymptotic limit. Our method\nindicates that for temperatures approaching $T_g$ from above it is sufficient\nto consider short molecular dynamics simulation trajectories, which just reach\ninto the Rouse-like monomer displacement regime. The first eigenvalue of PCA\nand participation ratio show sharp changes around $T_g$. Our approach requires\nminimum user inputs and is robust and transferable.",
    "descriptor": "",
    "authors": [
      "Atreyee Banerjee",
      "Hsiao-Ping Hsu",
      "Kurt Kremer",
      "Oleksandra Kukharenko"
    ],
    "subjectives": [
      "Soft Condensed Matter (cond-mat.soft)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14220"
  },
  {
    "id": "arXiv:2211.14235",
    "title": "DoubleU-NetPlus: A Novel Attention and Context Guided Dual U-Net with  Multi-Scale Residual Feature Fusion Network for Semantic Segmentation of  Medical Images",
    "abstract": "Accurate segmentation of the region of interest in medical images can provide\nan essential pathway for devising effective treatment plans for\nlife-threatening diseases. It is still challenging for U-Net, and its\nstate-of-the-art variants, such as CE-Net and DoubleU-Net, to effectively model\nthe higher-level output feature maps of the convolutional units of the network\nmostly due to the presence of various scales of the region of interest,\nintricacy of context environments, ambiguous boundaries, and multiformity of\ntextures in medical images. In this paper, we exploit multi-contextual features\nand several attention strategies to increase networks' ability to model\ndiscriminative feature representation for more accurate medical image\nsegmentation, and we present a novel dual U-Net-based architecture named\nDoubleU-NetPlus. The DoubleU-NetPlus incorporates several architectural\nmodifications. In particular, we integrate EfficientNetB7 as the feature\nencoder module, a newly designed multi-kernel residual convolution module, and\nan adaptive feature re-calibrating attention-based atrous spatial pyramid\npooling module to progressively and precisely accumulate discriminative\nmulti-scale high-level contextual feature maps and emphasize the salient\nregions. In addition, we introduce a novel triple attention gate module and a\nhybrid triple attention module to encourage selective modeling of relevant\nmedical image features. Moreover, to mitigate the gradient vanishing issue and\nincorporate high-resolution features with deeper spatial details, the standard\nconvolution operation is replaced with the attention-guided residual\nconvolution operations, ...",
    "descriptor": "\nComments: 25 pages, 9 figures, 4 tables, Submitted to Springer\n",
    "authors": [
      "Md. Rayhan Ahmed",
      "Adnan Ferdous Ashrafi",
      "Raihan Uddin Ahmed",
      "Swakkhar Shatabda",
      "A.K.M. Muzahidul Islam",
      "Salekul Islam"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14235"
  },
  {
    "id": "arXiv:2211.14236",
    "title": "Strategyproof Decision-Making in Panel Data Settings and Beyond",
    "abstract": "We propose a framework for decision-making in the presence of strategic\nagents with panel data, a standard setting in econometrics and statistics where\none gets noisy, repeated measurements of multiple units. We consider a setup\nwhere there is a pre-intervention period, when the principal observes the\noutcomes of each unit, after which the principal uses these observations to\nassign treatment to each unit. Our model can be thought of as a generalization\nof the synthetic controls and synthetic interventions frameworks, where units\n(or agents) may strategically manipulate pre-intervention outcomes to receive a\nmore desirable intervention. We identify necessary and sufficient conditions\nunder which a strategyproof mechanism that assigns interventions in the\npost-intervention period exists. Under a latent factor model assumption, we\nshow that whenever a strategyproof mechanism exists, there is one with a simple\nclosed form. In the setting where there is a single treatment and control\n(i.e., no other interventions), we establish that there is always a\nstrategyproof mechanism, and provide an algorithm for learning such a\nmechanism. For the setting of multiple interventions, we provide an algorithm\nfor learning a strategyproof mechanism, if there exists a sufficiently large\ngap in rewards between the different interventions. Along the way, we prove\nimpossibility results for multi-class strategic classification, which may be of\nindependent interest.",
    "descriptor": "",
    "authors": [
      "Keegan Harris",
      "Anish Agarwal",
      "Chara Podimata",
      "Zhiwei Steven Wu"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14236"
  },
  {
    "id": "arXiv:2211.14282",
    "title": "Domain generalization in fetal brain MRI segmentation \\\\with  multi-reconstruction augmentation",
    "abstract": "Quantitative analysis of in utero human brain development is crucial for\nabnormal characterization. Magnetic resonance image (MRI) segmentation is\ntherefore an asset for quantitative analysis. However, the development of\nautomated segmentation methods is hampered by the scarce availability of fetal\nbrain MRI annotated datasets and the limited variability within these cohorts.\nIn this context, we propose to leverage the power of fetal brain MRI\nsuper-resolution (SR) reconstruction methods to generate multiple\nreconstructions of a single subject with different parameters, thus as an\nefficient tuning-free data augmentation strategy. Overall, the latter\nsignificantly improves the generalization of segmentation methods over SR\npipelines.",
    "descriptor": "\nComments: 5 pages. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Priscille de Dumast",
      "Meritxell Bach Cuadra"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14282"
  },
  {
    "id": "arXiv:2211.14292",
    "title": "Analysis of Error Feedback in Federated Non-Convex Optimization with  Biased Compression",
    "abstract": "In federated learning (FL) systems, e.g., wireless networks, the\ncommunication cost between the clients and the central server can often be a\nbottleneck. To reduce the communication cost, the paradigm of communication\ncompression has become a popular strategy in the literature. In this paper, we\nfocus on biased gradient compression techniques in non-convex FL problems. In\nthe classical setting of distributed learning, the method of error feedback\n(EF) is a common technique to remedy the downsides of biased gradient\ncompression. In this work, we study a compressed FL scheme equipped with error\nfeedback, named Fed-EF. We further propose two variants: Fed-EF-SGD and\nFed-EF-AMS, depending on the choice of the global model optimizer. We provide a\ngeneric theoretical analysis, which shows that directly applying biased\ncompression in FL leads to a non-vanishing bias in the convergence rate. The\nproposed Fed-EF is able to match the convergence rate of the full-precision FL\ncounterparts under data heterogeneity with a linear speedup.\nMoreover, we develop a new analysis of the EF under partial client\nparticipation, which is an important scenario in FL. We prove that under\npartial participation, the convergence rate of Fed-EF exhibits an extra\nslow-down factor due to a so-called ``stale error compensation'' effect. A\nnumerical study is conducted to justify the intuitive impact of stale error\naccumulation on the norm convergence of Fed-EF under partial participation.\nFinally, we also demonstrate that incorporating the two-way compression in\nFed-EF does not change the convergence results. In summary, our work conducts a\nthorough analysis of the error feedback in federated non-convex optimization.\nOur analysis with partial client participation also provides insights on a\ntheoretical limitation of the error feedback mechanism, and possible directions\nfor improvements.",
    "descriptor": "",
    "authors": [
      "Xiaoyun Li",
      "Ping Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14292"
  },
  {
    "id": "arXiv:2211.14297",
    "title": "Doubly robust nearest neighbors in factor models",
    "abstract": "In this technical note, we introduce an improved variant of nearest neighbors\nfor counterfactual inference in panel data settings where multiple units are\nassigned multiple treatments over multiple time points, each sampled with\nconstant probabilities. We call this estimator a doubly robust nearest neighbor\nestimator and provide a high probability non-asymptotic error bound for the\nmean parameter corresponding to each unit at each time. Our guarantee shows\nthat the doubly robust estimator provides a (near-)quadratic improvement in the\nerror compared to nearest neighbor estimators analyzed in prior work for these\nsettings.",
    "descriptor": "",
    "authors": [
      "Raaz Dwivedi",
      "Katherine Tian",
      "Sabina Tomkins",
      "Predrag Klasnja",
      "Susan Murphy",
      "Devavrat Shah"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14297"
  },
  {
    "id": "arXiv:1612.03191",
    "title": "Multiparty testing preorders",
    "abstract": "Multiparty testing preorders",
    "descriptor": "",
    "authors": [
      "Rocco de Nicola",
      "Hern\u00e1n Melgratti"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1612.03191"
  },
  {
    "id": "arXiv:1709.09480",
    "title": "A Benchmark Environment Motivated by Industrial Control Problems",
    "abstract": "A Benchmark Environment Motivated by Industrial Control Problems",
    "descriptor": "",
    "authors": [
      "Daniel Hein",
      "Stefan Depeweg",
      "Michel Tokic",
      "Steffen Udluft",
      "Alexander Hentschel",
      "Thomas A. Runkler",
      "Volkmar Sterzing"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/1709.09480"
  },
  {
    "id": "arXiv:1901.04056",
    "title": "The Liver Tumor Segmentation Benchmark (LiTS)",
    "abstract": "Comments: Patrick Bilic, Patrick Christ, Hongwei Bran Li, and Eugene Vorontsov made equal contributions to this work. Published in Medical Image Analysis",
    "descriptor": "\nComments: Patrick Bilic, Patrick Christ, Hongwei Bran Li, and Eugene Vorontsov made equal contributions to this work. Published in Medical Image Analysis\n",
    "authors": [
      "Patrick Bilic",
      "Patrick Christ",
      "Hongwei Bran Li",
      "Eugene Vorontsov",
      "Avi Ben-Cohen",
      "Georgios Kaissis",
      "Adi Szeskin",
      "Colin Jacobs",
      "Gabriel Efrain Humpire Mamani",
      "Gabriel Chartrand",
      "Fabian Loh\u00f6fer",
      "Julian Walter Holch",
      "Wieland Sommer",
      "Felix Hofmann",
      "Alexandre Hostettler",
      "Naama Lev-Cohain",
      "Michal Drozdzal",
      "Michal Marianne Amitai",
      "Refael Vivantik",
      "Jacob Sosna",
      "Ivan Ezhov",
      "Anjany Sekuboyina",
      "Fernando Navarro",
      "Florian Kofler",
      "Johannes C. Paetzold",
      "Suprosanna Shit",
      "Xiaobin Hu",
      "Jana Lipkov\u00e1",
      "Markus Rempfler",
      "Marie Piraud",
      "Jan Kirschke",
      "Benedikt Wiestler",
      "Zhiheng Zhang",
      "Christian H\u00fclsemeyer",
      "Marcel Beetz",
      "Florian Ettlinger",
      "Michela Antonelli",
      "Woong Bae",
      "M\u00edriam Bellver",
      "Lei Bi",
      "Hao Chen",
      "Grzegorz Chlebus",
      "Erik B. Dam",
      "Qi Dou",
      "Chi-Wing Fu",
      "Bogdan Georgescu",
      "Xavier Gir\u00f3-i-Nieto"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1901.04056"
  },
  {
    "id": "arXiv:2001.03212",
    "title": "A Supervisory Frequency Support Control Scheme for Distributed PV",
    "abstract": "Comments: 9 pages, 13 figures",
    "descriptor": "\nComments: 9 pages, 13 figures\n",
    "authors": [
      "Qinmiao Li",
      "Mesut Baran"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2001.03212"
  },
  {
    "id": "arXiv:2005.08454",
    "title": "Reliability and Robustness analysis of Machine Learning based Phishing  URL Detectors",
    "abstract": "Comments: Accepted in Transactions of Dependable and Secure Computing (SI-Reliability and Robustness in AI-Based Cybersecurity Solutions)",
    "descriptor": "\nComments: Accepted in Transactions of Dependable and Secure Computing (SI-Reliability and Robustness in AI-Based Cybersecurity Solutions)\n",
    "authors": [
      "Bushra Sabir",
      "M. Ali Babar",
      "Raj Gaire",
      "Alsharif Abuadbba"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2005.08454"
  },
  {
    "id": "arXiv:2006.07862",
    "title": "Exploiting Higher Order Smoothness in Derivative-free Optimization and  Continuous Bandits",
    "abstract": "Exploiting Higher Order Smoothness in Derivative-free Optimization and  Continuous Bandits",
    "descriptor": "",
    "authors": [
      "Arya Akhavan",
      "Massimiliano Pontil",
      "Alexandre B. Tsybakov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.07862"
  },
  {
    "id": "arXiv:2006.16129",
    "title": "Algebraic coherent confluence and higher globular Kleene algebras",
    "abstract": "Algebraic coherent confluence and higher globular Kleene algebras",
    "descriptor": "",
    "authors": [
      "Cameron Calk",
      "Eric Goubault",
      "Philippe Malbos",
      "Georg Struth"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2006.16129"
  },
  {
    "id": "arXiv:2008.11898",
    "title": "Pose-Guided High-Resolution Appearance Transfer via Progressive Training",
    "abstract": "Comments: 10 pages, 10 figures, 2 tables",
    "descriptor": "\nComments: 10 pages, 10 figures, 2 tables\n",
    "authors": [
      "Ji Liu",
      "Heshan Liu",
      "Mang-Tik Chiu",
      "Yu-Wing Tai",
      "Chi-Keung Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2008.11898"
  },
  {
    "id": "arXiv:2009.08681",
    "title": "Information- and Coding-Theoretic Analysis of the RLWE Channel",
    "abstract": "Comments: 15 pages, 8 figures, 9 tables",
    "descriptor": "\nComments: 15 pages, 8 figures, 9 tables\n",
    "authors": [
      "Georg Maringer",
      "Sven Puchinger",
      "Antonia Wachter-Zeh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2009.08681"
  },
  {
    "id": "arXiv:2010.10069",
    "title": "Span(Graph): a Canonical Feedback Algebra of Open Transition Systems",
    "abstract": "Comments: 49 pages, 33 figures. Expanded discussion and conclusions. Discussion on Structured Feedback Categories. Other minor revisions for the journal version",
    "descriptor": "\nComments: 49 pages, 33 figures. Expanded discussion and conclusions. Discussion on Structured Feedback Categories. Other minor revisions for the journal version\n",
    "authors": [
      "Elena Di Lavore",
      "Alessandro Gianola",
      "Mario Rom\u00e1n",
      "Nicoletta Sabadini",
      "Pawe\u0142 Soboci\u0144ski"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2010.10069"
  },
  {
    "id": "arXiv:2011.09756",
    "title": "Active Inference and Behavior Trees for Reactive Action Planning and  Execution in Robotics",
    "abstract": "Comments: Accepted at Transactions on Robotics (IEEE T-RO)",
    "descriptor": "\nComments: Accepted at Transactions on Robotics (IEEE T-RO)\n",
    "authors": [
      "Corrado Pezzato",
      "Carlos Hernandez Corbato",
      "Stefan Bonhof",
      "Martijn Wisse"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2011.09756"
  },
  {
    "id": "arXiv:2012.01511",
    "title": "Temporal Representation Learning on Monocular Videos for 3D Human Pose  Estimation",
    "abstract": "Comments: Accepted in \"IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)\"",
    "descriptor": "\nComments: Accepted in \"IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)\"\n",
    "authors": [
      "Sina Honari",
      "Victor Constantin",
      "Helge Rhodin",
      "Mathieu Salzmann",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.01511"
  },
  {
    "id": "arXiv:2101.05791",
    "title": "U-Noise: Learnable Noise Masks for Interpretable Image Segmentation",
    "abstract": "Comments: ICIP 2021. Revision: corrected affiliation and reference",
    "descriptor": "\nComments: ICIP 2021. Revision: corrected affiliation and reference\n",
    "authors": [
      "Teddy Koker",
      "Fatemehsadat Mireshghallah",
      "Tom Titcombe",
      "Georgios Kaissis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.05791"
  },
  {
    "id": "arXiv:2102.05013",
    "title": "Spherical Message Passing for 3D Graph Networks",
    "abstract": "Comments: The paper has been accepted by ICLR 2022. You can also cite the conference version",
    "descriptor": "\nComments: The paper has been accepted by ICLR 2022. You can also cite the conference version\n",
    "authors": [
      "Yi Liu",
      "Limei Wang",
      "Meng Liu",
      "Xuan Zhang",
      "Bora Oztekin",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.05013"
  },
  {
    "id": "arXiv:2102.11854",
    "title": "Conditional Dichotomy of Boolean Ordered Promise CSPs",
    "abstract": "Comments: 20 pages, 1 figure",
    "descriptor": "\nComments: 20 pages, 1 figure\n",
    "authors": [
      "Joshua Brakensiek",
      "Venkatesan Guruswami",
      "Sai Sandeep"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2102.11854"
  },
  {
    "id": "arXiv:2103.10306",
    "title": "Data-driven inference on optimal input-output properties of polynomial  systems with focus on nonlinearity measures",
    "abstract": "Data-driven inference on optimal input-output properties of polynomial  systems with focus on nonlinearity measures",
    "descriptor": "",
    "authors": [
      "Tim Martin",
      "Frank Allg\u00f6wer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.10306"
  },
  {
    "id": "arXiv:2103.15450",
    "title": "Joint Sampling and Transmission Policies for Minimizing Cost under AoI  Constraints",
    "abstract": "Comments: 30 pages, submitted on a journal",
    "descriptor": "\nComments: 30 pages, submitted on a journal\n",
    "authors": [
      "Emmanouil Fountoulakis",
      "Marian Codreanu",
      "Anthony Ephremides",
      "Nikolaos Pappas"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2103.15450"
  },
  {
    "id": "arXiv:2104.03864",
    "title": "Modeling Object Dissimilarity for Deep Saliency Prediction",
    "abstract": "Comments: Transactions on Machine Learning Research (TMLR 2022) this https URL",
    "descriptor": "\nComments: Transactions on Machine Learning Research (TMLR 2022) this https URL\n",
    "authors": [
      "Bahar Aydemir",
      "Deblina Bhattacharjee",
      "Tong Zhang",
      "Seungryong Kim",
      "Mathieu Salzmann",
      "Sabine S\u00fcsstrunk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.03864"
  },
  {
    "id": "arXiv:2104.10152",
    "title": "Computing homotopy classes for diagrams",
    "abstract": "Comments: 47 pages",
    "descriptor": "\nComments: 47 pages\n",
    "authors": [
      "Marek Filakovsk\u00fd",
      "Luk\u00e1\u0161 Vok\u0159\u00ednek"
    ],
    "subjectives": [
      "Algebraic Topology (math.AT)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2104.10152"
  },
  {
    "id": "arXiv:2106.06152",
    "title": "On the Robustness of Average Losses for Partial-Label Learning",
    "abstract": "On the Robustness of Average Losses for Partial-Label Learning",
    "descriptor": "",
    "authors": [
      "Jiaqi Lv",
      "Biao Liu",
      "Lei Feng",
      "Ning Xu",
      "Miao Xu",
      "Bo An",
      "Gang Niu",
      "Xin Geng",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.06152"
  },
  {
    "id": "arXiv:2106.10637",
    "title": "More than Encoder: Introducing Transformer Decoder to Upsample",
    "abstract": "Comments: Accepted by BIBM2022",
    "descriptor": "\nComments: Accepted by BIBM2022\n",
    "authors": [
      "Yijiang Li",
      "Wentian Cai",
      "Ying Gao",
      "Chengming Li",
      "Xiping Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2106.10637"
  },
  {
    "id": "arXiv:2107.03769",
    "title": "Susceptibility to Image Resolution in Face Recognition and Trainings  Strategies",
    "abstract": "Comments: 19 pages, 15 figures, 2 tables",
    "descriptor": "\nComments: 19 pages, 15 figures, 2 tables\n",
    "authors": [
      "Martin Knoche",
      "Stefan H\u00f6rmann",
      "Gerhard Rigoll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.03769"
  },
  {
    "id": "arXiv:2107.10648",
    "title": "DEAP-FAKED: Knowledge Graph based Approach for Fake News Detection",
    "abstract": "Comments: Accepted at IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM) 2022",
    "descriptor": "\nComments: Accepted at IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM) 2022\n",
    "authors": [
      "Mohit Mayank",
      "Shakshi Sharma",
      "Rajesh Sharma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.10648"
  },
  {
    "id": "arXiv:2108.00738",
    "title": "Thermodynamics of Internal Correlations",
    "abstract": "Comments: 13 pages, 3 figures",
    "descriptor": "\nComments: 13 pages, 3 figures\n",
    "authors": [
      "Akihito Sudo"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2108.00738"
  },
  {
    "id": "arXiv:2108.06197",
    "title": "A comparison of latent semantic analysis and correspondence analysis of  document-term matrices",
    "abstract": "A comparison of latent semantic analysis and correspondence analysis of  document-term matrices",
    "descriptor": "",
    "authors": [
      "Qianqian Qi",
      "David J. Hessen",
      "Tejaswini Deoskar",
      "Peter G. M. van der Heijden"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.06197"
  },
  {
    "id": "arXiv:2108.06717",
    "title": "Time delay estimation of traffic congestion propagation due to accidents  based on statistical causality",
    "abstract": "Comments: this http URL",
    "descriptor": "\nComments: this http URL\n",
    "authors": [
      "YongKyung Oh",
      "JiIn Kwak",
      "Sungil Kim"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.06717"
  },
  {
    "id": "arXiv:2108.09988",
    "title": "Farsighted Probabilistic Sampling: A General Strategy for Boosting Local  Search MaxSAT Solvers",
    "abstract": "Comments: Accepted by AAAI 2023",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Jiongzhi Zheng",
      "Kun He",
      "Jianrong Zhou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.09988"
  },
  {
    "id": "arXiv:2108.10290",
    "title": "Cross-Quality LFW: A Database for Analyzing Cross-Resolution Image Face  Recognition in Unconstrained Environments",
    "abstract": "Comments: 9 pages, 4 figures, 2 tables",
    "descriptor": "\nComments: 9 pages, 4 figures, 2 tables\n",
    "authors": [
      "Martin Knoche",
      "Stefan H\u00f6rmann",
      "Gerhard Rigoll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.10290"
  },
  {
    "id": "arXiv:2108.10735",
    "title": "Misleading the Covid-19 vaccination discourse on Twitter: An exploratory  study of infodemic around the pandemic",
    "abstract": "Comments: Accepted at IEEE Transactions on Computational Social Systems 2022",
    "descriptor": "\nComments: Accepted at IEEE Transactions on Computational Social Systems 2022\n",
    "authors": [
      "Shakshi Sharma",
      "Rajesh Sharma",
      "Anwitaman Datta"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2108.10735"
  },
  {
    "id": "arXiv:2109.03569",
    "title": "LiDARTouch: Monocular metric depth estimation with a few-beam LiDAR",
    "abstract": "LiDARTouch: Monocular metric depth estimation with a few-beam LiDAR",
    "descriptor": "",
    "authors": [
      "Florent Bartoccioni",
      "\u00c9loi Zablocki",
      "Patrick P\u00e9rez",
      "Matthieu Cord",
      "Karteek Alahari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.03569"
  },
  {
    "id": "arXiv:2109.04337",
    "title": "PATRIOT: Anti-Repackaging for IoT Firmware Integrity",
    "abstract": "Comments: Revised version of the paper with updated experimental campaign and conclusion",
    "descriptor": "\nComments: Revised version of the paper with updated experimental campaign and conclusion\n",
    "authors": [
      "Luca Verderame",
      "Antonio Ruggia",
      "Alessio Merlo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2109.04337"
  },
  {
    "id": "arXiv:2109.10529",
    "title": "Numerical Continued Fraction Interpolation",
    "abstract": "Comments: corrected a typo",
    "descriptor": "\nComments: corrected a typo\n",
    "authors": [
      "Oliver Salazar Celis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.10529"
  },
  {
    "id": "arXiv:2109.10902",
    "title": "Segmentation with mixed supervision: Confidence maximization helps  knowledge distillation",
    "abstract": "Comments: To be published at Medical Image Analysis (Volume 83, January 2023). Code: this https URL Note: this article is a journal extension of our paper in IPMI 2021 arXiv:2012.08051",
    "descriptor": "\nComments: To be published at Medical Image Analysis (Volume 83, January 2023). Code: this https URL Note: this article is a journal extension of our paper in IPMI 2021 arXiv:2012.08051\n",
    "authors": [
      "Bingyuan Liu",
      "Christian Desrosiers",
      "Ismail Ben Ayed",
      "Jose Dolz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.10902"
  },
  {
    "id": "arXiv:2109.13138",
    "title": "On Kosloff Tal-Ezer Least-Squares Quadrature Formulas",
    "abstract": "Comments: The revised manuscript contains 24 pages and 9 figures. The content is based on the bachelor thesis of G. Cappellazzo",
    "descriptor": "\nComments: The revised manuscript contains 24 pages and 9 figures. The content is based on the bachelor thesis of G. Cappellazzo\n",
    "authors": [
      "Giacomo Cappellazzo",
      "Wolfgang Erb",
      "Francesco Marchetti",
      "Davide Poggiali"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.13138"
  },
  {
    "id": "arXiv:2110.00857",
    "title": "FairFed: Enabling Group Fairness in Federated Learning",
    "abstract": "Comments: Accepted to appeat at AAAI 2023",
    "descriptor": "\nComments: Accepted to appeat at AAAI 2023\n",
    "authors": [
      "Yahya H. Ezzeldin",
      "Shen Yan",
      "Chaoyang He",
      "Emilio Ferrara",
      "Salman Avestimehr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.00857"
  },
  {
    "id": "arXiv:2110.07867",
    "title": "Exploring Universal Intrinsic Task Subspace via Prompt Tuning",
    "abstract": "Comments: Previously accepted by Findings of ACL 2022 and Findings of EMNLP 2022",
    "descriptor": "\nComments: Previously accepted by Findings of ACL 2022 and Findings of EMNLP 2022\n",
    "authors": [
      "Yujia Qin",
      "Xiaozhi Wang",
      "Yusheng Su",
      "Yankai Lin",
      "Ning Ding",
      "Jing Yi",
      "Weize Chen",
      "Zhiyuan Liu",
      "Juanzi Li",
      "Lei Hou",
      "Peng Li",
      "Maosong Sun",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.07867"
  },
  {
    "id": "arXiv:2110.08843",
    "title": "Graph Wedgelets: Adaptive Data Compression on Graphs based on Binary  Wedge Partitioning Trees and Geometric Wavelets",
    "abstract": "Comments: 12 pages, 10 figures",
    "descriptor": "\nComments: 12 pages, 10 figures\n",
    "authors": [
      "Wolfgang Erb"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.08843"
  },
  {
    "id": "arXiv:2110.09344",
    "title": "ifMixup: Interpolating Graph Pair to Regularize Graph Classification",
    "abstract": "Comments: To appear in AAAI2023",
    "descriptor": "\nComments: To appear in AAAI2023\n",
    "authors": [
      "Hongyu Guo",
      "Yongyi Mao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.09344"
  },
  {
    "id": "arXiv:2110.09585",
    "title": "A-Optimal Active Learning",
    "abstract": "Comments: 14 pages, submitted to Physica Scripta",
    "descriptor": "\nComments: 14 pages, submitted to Physica Scripta\n",
    "authors": [
      "Tue Boesen",
      "Eldad Haber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.09585"
  },
  {
    "id": "arXiv:2111.00088",
    "title": "Stitching Dynamic Movement Primitives and Image-based Visual Servo  Control",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Ghananeel Rotithor",
      "Iman Salehi",
      "Edward Tunstel",
      "Ashwin P. Dani"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.00088"
  },
  {
    "id": "arXiv:2111.00482",
    "title": "On Small Types in Univalent Foundations",
    "abstract": "Comments: Extended version of arXiv:2102.08812. v3: Revised following referee reports",
    "descriptor": "\nComments: Extended version of arXiv:2102.08812. v3: Revised following referee reports\n",
    "authors": [
      "Tom de Jong",
      "Mart\u00edn H\u00f6tzel Escard\u00f3"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2111.00482"
  },
  {
    "id": "arXiv:2111.00794",
    "title": "Geodesic Models with Convexity Shape Prior",
    "abstract": "Comments: This paper has been accepted by TPAMI",
    "descriptor": "\nComments: This paper has been accepted by TPAMI\n",
    "authors": [
      "Da Chen",
      "Jean-Marie Mirebeau",
      "Minglei Shu",
      "Xuecheng Tai",
      "Laurent D. Cohen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.00794"
  },
  {
    "id": "arXiv:2111.00991",
    "title": "Differential elimination for dynamical models via projections with  applications to structural identifiability",
    "abstract": "Differential elimination for dynamical models via projections with  applications to structural identifiability",
    "descriptor": "",
    "authors": [
      "Ruiwen Dong",
      "Christian Goodbrake",
      "Heather A Harrington",
      "Gleb Pogudin"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Computational Geometry (cs.CG)",
      "Symbolic Computation (cs.SC)",
      "Systems and Control (eess.SY)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2111.00991"
  },
  {
    "id": "arXiv:2111.05329",
    "title": "Self-Supervised Audio-Visual Representation Learning with Relaxed  Cross-Modal Synchronicity",
    "abstract": "Comments: Accepted in AAAI 2023",
    "descriptor": "\nComments: Accepted in AAAI 2023\n",
    "authors": [
      "Pritam Sarkar",
      "Ali Etemad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.05329"
  },
  {
    "id": "arXiv:2111.06495",
    "title": "FairAutoML: Embracing Unfairness Mitigation in AutoML",
    "abstract": "Comments: 18 pages (including 6 pages of appendixes)",
    "descriptor": "\nComments: 18 pages (including 6 pages of appendixes)\n",
    "authors": [
      "Qingyun Wu",
      "Chi Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.06495"
  },
  {
    "id": "arXiv:2111.06978",
    "title": "RLOps: Development Life-cycle of Reinforcement Learning Aided Open RAN",
    "abstract": "Comments: 17 pages, 6 figrues",
    "descriptor": "\nComments: 17 pages, 6 figrues\n",
    "authors": [
      "Peizheng Li",
      "Jonathan Thomas",
      "Xiaoyang Wang",
      "Ahmed Khalil",
      "Abdelrahim Ahmad",
      "Rui Inacio",
      "Shipra Kapoor",
      "Arjun Parekh",
      "Angela Doufexi",
      "Arman Shojaeifard",
      "Robert Piechocki"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.06978"
  },
  {
    "id": "arXiv:2111.10862",
    "title": "Strictification of weakly stable type-theoretic structures using generic  contexts",
    "abstract": "Strictification of weakly stable type-theoretic structures using generic  contexts",
    "descriptor": "",
    "authors": [
      "Rafa\u00ebl Bocquet"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2111.10862"
  },
  {
    "id": "arXiv:2111.11932",
    "title": "Modelling Direct Messaging Networks with Multiple Recipients for Cyber  Deception",
    "abstract": "Modelling Direct Messaging Networks with Multiple Recipients for Cyber  Deception",
    "descriptor": "",
    "authors": [
      "Kristen Moore",
      "Cody J. Christopher",
      "David Liebowitz",
      "Surya Nepal",
      "Renee Selvey"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.11932"
  },
  {
    "id": "arXiv:2111.12545",
    "title": "Data2Model: Predicting Models from Training Data",
    "abstract": "Data2Model: Predicting Models from Training Data",
    "descriptor": "",
    "authors": [
      "Yingyan Zeng",
      "Jiachen T. Wang",
      "Si Chen",
      "Hoang Anh Just",
      "Ran Jin",
      "Ruoxi Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.12545"
  },
  {
    "id": "arXiv:2111.13304",
    "title": "Data Fusion Challenges Privacy: What Can Privacy Regulation Do?",
    "abstract": "Comments: 18 pages",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "G\u00e1bor Erd\u00e9lyi",
      "Olivia J. Erd\u00e9lyi",
      "Andreas W. Kempa-Liehr"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.13304"
  },
  {
    "id": "arXiv:2112.04768",
    "title": "Quantum Link Prediction in Complex Networks",
    "abstract": "Comments: Keywords: Complex Networks, Quantum Algorithms, Link Prediction, Social Networks, Protein-Protein Interaction Networks",
    "descriptor": "\nComments: Keywords: Complex Networks, Quantum Algorithms, Link Prediction, Social Networks, Protein-Protein Interaction Networks\n",
    "authors": [
      "Jo\u00e3o P. Moutinho",
      "Andr\u00e9 Melo",
      "Bruno Coutinho",
      "Istv\u00e1n A. Kov\u00e1cs",
      "Yasser Omar"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Social and Information Networks (cs.SI)",
      "Biological Physics (physics.bio-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.04768"
  },
  {
    "id": "arXiv:2112.08544",
    "title": "NewsClaims: A New Benchmark for Claim Detection from News with Attribute  Knowledge",
    "abstract": "Comments: Accepted at EMNLP 2022",
    "descriptor": "\nComments: Accepted at EMNLP 2022\n",
    "authors": [
      "Revanth Gangi Reddy",
      "Sai Chetan",
      "Zhenhailong Wang",
      "Yi R. Fung",
      "Kathryn Conger",
      "Ahmed Elsayed",
      "Martha Palmer",
      "Preslav Nakov",
      "Eduard Hovy",
      "Kevin Small",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.08544"
  },
  {
    "id": "arXiv:2112.15093",
    "title": "Benchmarking Chinese Text Recognition: Datasets, Baselines, and an  Empirical Study",
    "abstract": "Comments: Code is available at this https URL",
    "descriptor": "\nComments: Code is available at this https URL\n",
    "authors": [
      "Haiyang Yu",
      "Jingye Chen",
      "Bin Li",
      "Jianqi Ma",
      "Mengnan Guan",
      "Xixi Xu",
      "Xiaocong Wang",
      "Shaobo Qu",
      "Xiangyang Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15093"
  },
  {
    "id": "arXiv:2112.15454",
    "title": "Advanced Drone Swarm Security by Using Blockchain Governance Game",
    "abstract": "Comments: Song-Kyoo Kim, Advanced Drone Swarm Security by Using Blockchain Governance Game, Mathematics 10:18 (2022), 3338",
    "descriptor": "\nComments: Song-Kyoo Kim, Advanced Drone Swarm Security by Using Blockchain Governance Game, Mathematics 10:18 (2022), 3338\n",
    "authors": [
      "Song-Kyoo Kim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2112.15454"
  },
  {
    "id": "arXiv:2201.03866",
    "title": "Deep Learning-Aided 6G Wireless Networks: A Comprehensive Survey of  Revolutionary PHY Architectures",
    "abstract": "Comments: Published in IEEE OJ-COMS",
    "descriptor": "\nComments: Published in IEEE OJ-COMS\n",
    "authors": [
      "Burak Ozpoyraz",
      "A. Tugberk Dogukan",
      "Yarkin Gevez",
      "Ufuk Altun",
      "Ertugrul Basar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2201.03866"
  },
  {
    "id": "arXiv:2201.04786",
    "title": "A Non-Classical Parameterization for Density Estimation Using Sample  Moments",
    "abstract": "Comments: 17 pages, 1 figure",
    "descriptor": "\nComments: 17 pages, 1 figure\n",
    "authors": [
      "Guangyu Wu",
      "Anders Lindquist"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2201.04786"
  },
  {
    "id": "arXiv:2201.05842",
    "title": "UDC: Unified DNAS for Compressible TinyML Models",
    "abstract": "UDC: Unified DNAS for Compressible TinyML Models",
    "descriptor": "",
    "authors": [
      "Igor Fedorov",
      "Ramon Matas",
      "Hokchhay Tann",
      "Chuteng Zhou",
      "Matthew Mattina",
      "Paul Whatmough"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.05842"
  },
  {
    "id": "arXiv:2201.05995",
    "title": "The Secure Storage Capacity of a DNA Wiretap Channel Model",
    "abstract": "Comments: 35 pages, 6 figures, submitted to the IEEE Transactions on Information Theory. This version includes a DNA wiretap channel with a shared key and a section on block-erasure wiretap channels",
    "descriptor": "\nComments: 35 pages, 6 figures, submitted to the IEEE Transactions on Information Theory. This version includes a DNA wiretap channel with a shared key and a section on block-erasure wiretap channels\n",
    "authors": [
      "Praneeth Kumar Vippathalla",
      "Navin Kashyap"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.05995"
  },
  {
    "id": "arXiv:2201.09805",
    "title": "Non-Linear Dynamic Inversion with Actuator Dynamics: an Incremental  Control Perspective",
    "abstract": "Comments: 16 pages, 7 figures",
    "descriptor": "\nComments: 16 pages, 7 figures\n",
    "authors": [
      "Rasmus Steffensen",
      "Agnes Steinert",
      "Ewoud Jan Jacob Smeur"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.09805"
  },
  {
    "id": "arXiv:2201.11775",
    "title": "The Effect of Diversity in Meta-Learning",
    "abstract": "Comments: Accepted at AAAI 23",
    "descriptor": "\nComments: Accepted at AAAI 23\n",
    "authors": [
      "Ramnath Kumar",
      "Tristan Deleu",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11775"
  },
  {
    "id": "arXiv:2201.13250",
    "title": "Differentiating and Integrating ZX Diagrams with Applications to Quantum  Machine Learning",
    "abstract": "Comments: 37 pages, 3 authors now, more results",
    "descriptor": "\nComments: 37 pages, 3 authors now, more results\n",
    "authors": [
      "Quanlong Wang",
      "Richie Yeung",
      "Mark Koch"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.13250"
  },
  {
    "id": "arXiv:2202.00471",
    "title": "Causal effect of racial bias in data and machine learning algorithms on  user persuasiveness & discriminatory decision making: An Empirical Study",
    "abstract": "Comments: Fresh experiments need to be added to the design of experiments",
    "descriptor": "\nComments: Fresh experiments need to be added to the design of experiments\n",
    "authors": [
      "Kinshuk Sengupta",
      "Praveen Ranjan Srivastava"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.00471"
  },
  {
    "id": "arXiv:2202.00667",
    "title": "DKM: Dense Kernelized Feature Matching for Geometry Estimation",
    "abstract": "DKM: Dense Kernelized Feature Matching for Geometry Estimation",
    "descriptor": "",
    "authors": [
      "Johan Edstedt",
      "Ioannis Athanasiadis",
      "M\u00e5rten Wadenb\u00e4ck",
      "Michael Felsberg"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00667"
  },
  {
    "id": "arXiv:2202.01606",
    "title": "Graph Coloring with Physics-Inspired Graph Neural Networks",
    "abstract": "Comments: Manuscript: 8 pages, 5 figures, 2 tables. Supplemental Material: 1 page, 2 tables",
    "descriptor": "\nComments: Manuscript: 8 pages, 5 figures, 2 tables. Supplemental Material: 1 page, 2 tables\n",
    "authors": [
      "Martin J. A. Schuetz",
      "J. Kyle Brubaker",
      "Zhihuai Zhu",
      "Helmut G. Katzgraber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.01606"
  },
  {
    "id": "arXiv:2202.02242",
    "title": "Dikaios: Privacy Auditing of Algorithmic Fairness via Attribute  Inference Attacks",
    "abstract": "Comments: The paper's results and conclusions underwent significant changes. The updated paper can be found at arXiv:2211.10209",
    "descriptor": "\nComments: The paper's results and conclusions underwent significant changes. The updated paper can be found at arXiv:2211.10209\n",
    "authors": [
      "Jan Aalmoes",
      "Vasisht Duddu",
      "Antoine Boutet"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02242"
  },
  {
    "id": "arXiv:2202.05621",
    "title": "Nonlinear MCMC for Bayesian Machine Learning",
    "abstract": "Comments: This version is accepted to NeurIPS 2022 and replaces the previous working draft. 10 + 27 pages, many figures",
    "descriptor": "\nComments: This version is accepted to NeurIPS 2022 and replaces the previous working draft. 10 + 27 pages, many figures\n",
    "authors": [
      "James Vuckovic"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2202.05621"
  },
  {
    "id": "arXiv:2202.09497",
    "title": "Gradient Estimation with Discrete Stein Operators",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Jiaxin Shi",
      "Yuhao Zhou",
      "Jessica Hwang",
      "Michalis K. Titsias",
      "Lester Mackey"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09497"
  },
  {
    "id": "arXiv:2202.12299",
    "title": "Capturing Failures of Large Language Models via Human Cognitive Biases",
    "abstract": "Comments: Published at NeurIPS 2022",
    "descriptor": "\nComments: Published at NeurIPS 2022\n",
    "authors": [
      "Erik Jones",
      "Jacob Steinhardt"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.12299"
  },
  {
    "id": "arXiv:2203.04713",
    "title": "Defending Black-box Skeleton-based Human Activity Classifiers",
    "abstract": "Comments: Accepted in AAAI 2023",
    "descriptor": "\nComments: Accepted in AAAI 2023\n",
    "authors": [
      "He Wang",
      "Yunfeng Diao",
      "Zichang Tan",
      "Guodong Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.04713"
  },
  {
    "id": "arXiv:2203.06897",
    "title": "Drift Reduced Navigation with Deep Explainable Features",
    "abstract": "Comments: Accepted in IROS 2022",
    "descriptor": "\nComments: Accepted in IROS 2022\n",
    "authors": [
      "Mohd Omama",
      "Sundar Sripada Venugopalaswamy Sriraman",
      "Sandeep Chinchali",
      "Arun Kumar Singh",
      "K. Madhava Krishna"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.06897"
  },
  {
    "id": "arXiv:2203.06966",
    "title": "Playing (Almost-)Optimally in Concurrent B\u00fcchi and co-B\u00fcchi Games",
    "abstract": "Playing (Almost-)Optimally in Concurrent B\u00fcchi and co-B\u00fcchi Games",
    "descriptor": "",
    "authors": [
      "Benjamin Bordais",
      "Patricia Bouyer",
      "St\u00e9phane Le Roux"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2203.06966"
  },
  {
    "id": "arXiv:2203.08451",
    "title": "Analysis of fully discrete mixed finite element scheme for Stochastic  Navier-Stokes equations with multiplicative noise",
    "abstract": "Analysis of fully discrete mixed finite element scheme for Stochastic  Navier-Stokes equations with multiplicative noise",
    "descriptor": "",
    "authors": [
      "Hailong Qiu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.08451"
  },
  {
    "id": "arXiv:2203.09995",
    "title": "Elastica Models for Color Image Regularization",
    "abstract": "Elastica Models for Color Image Regularization",
    "descriptor": "",
    "authors": [
      "Hao Liu",
      "Xue-Cheng Tai",
      "Ron Kimmel",
      "Roland Glowinski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2203.09995"
  },
  {
    "id": "arXiv:2203.10836",
    "title": "A Model and Survey of Distributed Data-Intensive Systems",
    "abstract": "Comments: Preprint, submitted to ACM Computing Surveys on March 2022, revised on November 2022",
    "descriptor": "\nComments: Preprint, submitted to ACM Computing Surveys on March 2022, revised on November 2022\n",
    "authors": [
      "Alessandro Margara",
      "Gianpaolo Cugola",
      "Nicol\u00f2 Felicioni",
      "Stefano Cilloni"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2203.10836"
  },
  {
    "id": "arXiv:2203.10974",
    "title": "Towards Self-Supervised Gaze Estimation",
    "abstract": "Comments: BMVC 2022. For code and pre-trained models, visit this https URL",
    "descriptor": "\nComments: BMVC 2022. For code and pre-trained models, visit this https URL\n",
    "authors": [
      "Arya Farkhondeh",
      "Cristina Palmero",
      "Simone Scardapane",
      "Sergio Escalera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.10974"
  },
  {
    "id": "arXiv:2203.11892",
    "title": "Multiple Estimation Models for Discrete-time Adaptive Iterative Learning  Control",
    "abstract": "Comments: 22 pages, 5 figures, 4 tables",
    "descriptor": "\nComments: 22 pages, 5 figures, 4 tables\n",
    "authors": [
      "Ram Padmanabhan",
      "Rajini Makam",
      "Koshy George"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.11892"
  },
  {
    "id": "arXiv:2203.13552",
    "title": "On the Role of Quantization of Soft Information in GRAND",
    "abstract": "On the Role of Quantization of Soft Information in GRAND",
    "descriptor": "",
    "authors": [
      "Peihong Yuan",
      "Ken R. Duffy",
      "Evan P. Gabhart",
      "Muriel M\u00e9dard"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2203.13552"
  },
  {
    "id": "arXiv:2204.00313",
    "title": "Deep neural networks for solving large linear systems arising from  high-dimensional problems",
    "abstract": "Deep neural networks for solving large linear systems arising from  high-dimensional problems",
    "descriptor": "",
    "authors": [
      "Yiqi Gu",
      "Michael K. Ng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.00313"
  },
  {
    "id": "arXiv:2204.01329",
    "title": "Channel Acquisition for HF Skywave Massive MIMO-OFDM Communications",
    "abstract": "Comments: 15 pages, 6 figures, accepted for publication in IEEE Transactions on Wireless Communications",
    "descriptor": "\nComments: 15 pages, 6 figures, accepted for publication in IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Ding Shi",
      "Linfeng Song",
      "Wenqi Zhou",
      "Xiqi Gao",
      "Cheng-Xiang Wang",
      "Geoffrey Ye Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2204.01329"
  },
  {
    "id": "arXiv:2204.03316",
    "title": "Structured Gradient Descent for Fast Robust Low-Rank Hankel Matrix  Completion",
    "abstract": "Structured Gradient Descent for Fast Robust Low-Rank Hankel Matrix  Completion",
    "descriptor": "",
    "authors": [
      "HanQin Cai",
      "Jian-Feng Cai",
      "Juntao You"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.03316"
  },
  {
    "id": "arXiv:2204.03541",
    "title": "End-to-End Zero-Shot HOI Detection via Vision and Language Knowledge  Distillation",
    "abstract": "End-to-End Zero-Shot HOI Detection via Vision and Language Knowledge  Distillation",
    "descriptor": "",
    "authors": [
      "Mingrui Wu",
      "Jiaxin Gu",
      "Yunhang Shen",
      "Mingbao Lin",
      "Chao Chen",
      "Xiaoshuai Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.03541"
  },
  {
    "id": "arXiv:2204.05923",
    "title": "An Algebraically Converging Stochastic Gradient Descent Algorithm for  Global Optimization",
    "abstract": "Comments: 28 pages, 9 figures",
    "descriptor": "\nComments: 28 pages, 9 figures\n",
    "authors": [
      "Bj\u00f6rn Engquist",
      "Kui Ren",
      "Yunan Yang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.05923"
  },
  {
    "id": "arXiv:2204.07719",
    "title": "Stress-Testing Point Cloud Registration on Automotive LiDAR",
    "abstract": "Comments: Accepted to the NeurIPS 2022 workshop on Machine Learning for Autonomous Driving. Project Page: this https URL",
    "descriptor": "\nComments: Accepted to the NeurIPS 2022 workshop on Machine Learning for Autonomous Driving. Project Page: this https URL\n",
    "authors": [
      "Amnon Drory",
      "Shai Avidan",
      "Raja Giryes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07719"
  },
  {
    "id": "arXiv:2204.12586",
    "title": "Enhanced compound-protein binding affinity prediction by representing  protein multimodal information via a coevolutionary strategy",
    "abstract": "Comments: 53 pages, 14 figures, 3 tables",
    "descriptor": "\nComments: 53 pages, 14 figures, 3 tables\n",
    "authors": [
      "Binjie Guo",
      "Hanyu Zheng",
      "Haohan Jiang",
      "Xiaodan Li",
      "Naiyu Guan",
      "Yanming Zuo",
      "Yicheng Zhang",
      "Hengfu Yang",
      "Xuhua Wang"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.12586"
  },
  {
    "id": "arXiv:2204.13591",
    "title": "Continual Learning for Peer-to-Peer Federated Learning: A Study on  Automated Brain Metastasis Identification",
    "abstract": "Continual Learning for Peer-to-Peer Federated Learning: A Study on  Automated Brain Metastasis Identification",
    "descriptor": "",
    "authors": [
      "Yixing Huang",
      "Christoph Bert",
      "Stefan Fischer",
      "Manuel Schmidt",
      "Arnd D\u00f6rfler",
      "Andreas Maier",
      "Rainer Fietkau",
      "Florian Putz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2204.13591"
  },
  {
    "id": "arXiv:2205.00615",
    "title": "Distributed Symmetric Key Exchange: A scalable, quantum-proof key  distribution system",
    "abstract": "Comments: Our protocol has been renamed Distributed Symmetric Key Exchange (DSKE). 11 pages, 6 figures",
    "descriptor": "\nComments: Our protocol has been renamed Distributed Symmetric Key Exchange (DSKE). 11 pages, 6 figures\n",
    "authors": [
      "Hoi-Kwong Lo",
      "Mattia Montagna",
      "Manfred von Willich"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.00615"
  },
  {
    "id": "arXiv:2205.02464",
    "title": "Experimental Study of Concise Representations of Concepts and  Dependencies",
    "abstract": "Experimental Study of Concise Representations of Concepts and  Dependencies",
    "descriptor": "",
    "authors": [
      "Aleksey Buzmakov",
      "Egor Dudyrev",
      "Sergei O. Kuznetsov",
      "Tatiana Makhalova",
      "Amedeo Napoli"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2205.02464"
  },
  {
    "id": "arXiv:2205.03883",
    "title": "WKGM: Weight-K-space Generative Model for Parallel Imaging  Reconstruction",
    "abstract": "Comments: 11pages, 12 figures",
    "descriptor": "\nComments: 11pages, 12 figures\n",
    "authors": [
      "Zongjiang Tu",
      "Die Liu",
      "Xiaoqing Wang",
      "Chen Jiang",
      "Pengwen Zhu",
      "Minghui Zhang",
      "Shanshan Wang",
      "Dong Liang",
      "Qiegen Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.03883"
  },
  {
    "id": "arXiv:2205.06643",
    "title": "The Design Space of E(3)-Equivariant Atom-Centered Interatomic  Potentials",
    "abstract": "The Design Space of E(3)-Equivariant Atom-Centered Interatomic  Potentials",
    "descriptor": "",
    "authors": [
      "Ilyes Batatia",
      "Simon Batzner",
      "D\u00e1vid P\u00e9ter Kov\u00e1cs",
      "Albert Musaelian",
      "Gregor N. C. Simm",
      "Ralf Drautz",
      "Christoph Ortner",
      "Boris Kozinsky",
      "G\u00e1bor Cs\u00e1nyi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2205.06643"
  },
  {
    "id": "arXiv:2205.06887",
    "title": "AVCAffe: A Large Scale Audio-Visual Dataset of Cognitive Load and Affect  for Remote Work",
    "abstract": "Comments: Accepted in AAAI 2023",
    "descriptor": "\nComments: Accepted in AAAI 2023\n",
    "authors": [
      "Pritam Sarkar",
      "Aaron Posen",
      "Ali Etemad"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.06887"
  },
  {
    "id": "arXiv:2205.09797",
    "title": "Improving Multi-Task Generalization via Regularizing Spurious  Correlation",
    "abstract": "Comments: Published on NeurIPS 2022",
    "descriptor": "\nComments: Published on NeurIPS 2022\n",
    "authors": [
      "Ziniu Hu",
      "Zhe Zhao",
      "Xinyang Yi",
      "Tiansheng Yao",
      "Lichan Hong",
      "Yizhou Sun",
      "Ed H. Chi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.09797"
  },
  {
    "id": "arXiv:2205.10003",
    "title": "InDistill: Information flow-preserving knowledge distillation for model  compression",
    "abstract": "InDistill: Information flow-preserving knowledge distillation for model  compression",
    "descriptor": "",
    "authors": [
      "Ioannis Sarridis",
      "Christos Koutlis",
      "Giorgos Kordopatis-Zilos",
      "Ioannis Kompatsiaris",
      "Symeon Papadopoulos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.10003"
  },
  {
    "id": "arXiv:2205.10023",
    "title": "Transition-based Semantic Role Labeling with Pointer Networks",
    "abstract": "Comments: Final peer-reviewed manuscript accepted for publication in Knowledge-Based Systems",
    "descriptor": "\nComments: Final peer-reviewed manuscript accepted for publication in Knowledge-Based Systems\n",
    "authors": [
      "Daniel Fern\u00e1ndez-Gonz\u00e1lez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.10023"
  },
  {
    "id": "arXiv:2205.10366",
    "title": "Fast Change Identification in Multi-Play Bandits and its Applications in  Wireless Networks",
    "abstract": "Comments: Corrected the assumptions and removed the case-study due to an error",
    "descriptor": "\nComments: Corrected the assumptions and removed the case-study due to an error\n",
    "authors": [
      "Gourab Ghatak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2205.10366"
  },
  {
    "id": "arXiv:2205.11029",
    "title": "META-GUI: Towards Multi-modal Conversational Agents on Mobile GUI",
    "abstract": "Comments: 14 pages, 10 figures",
    "descriptor": "\nComments: 14 pages, 10 figures\n",
    "authors": [
      "Liangtai Sun",
      "Xingyu Chen",
      "Lu Chen",
      "Tianle Dai",
      "Zichen Zhu",
      "Kai Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11029"
  },
  {
    "id": "arXiv:2205.11108",
    "title": "Paddy Doctor: A Visual Image Dataset for Automated Paddy Disease  Classification and Benchmarking",
    "abstract": "Paddy Doctor: A Visual Image Dataset for Automated Paddy Disease  Classification and Benchmarking",
    "descriptor": "",
    "authors": [
      "Petchiammal A",
      "Briskline Kiruba S",
      "D. Murugan",
      "Pandarasamy A"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.11108"
  },
  {
    "id": "arXiv:2206.00205",
    "title": "CAFA: Class-Aware Feature Alignment for Test-Time Adaptation",
    "abstract": "CAFA: Class-Aware Feature Alignment for Test-Time Adaptation",
    "descriptor": "",
    "authors": [
      "Sanghun Jung",
      "Jungsoo Lee",
      "Nanhee Kim",
      "Amirreza Shaban",
      "Byron Boots",
      "Jaegul Choo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.00205"
  },
  {
    "id": "arXiv:2206.00241",
    "title": "Asymptotic Properties for Bayesian Neural Network in Besov Space",
    "abstract": "Asymptotic Properties for Bayesian Neural Network in Besov Space",
    "descriptor": "",
    "authors": [
      "Kyeongwon Lee",
      "Jaeyong Lee"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.00241"
  },
  {
    "id": "arXiv:2206.00407",
    "title": "Generalized Delayed Feedback Model with Post-Click Information in  Recommender Systems",
    "abstract": "Comments: NeurIPS'22",
    "descriptor": "\nComments: NeurIPS'22\n",
    "authors": [
      "Jia-Qi Yang",
      "De-Chuan Zhan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.00407"
  },
  {
    "id": "arXiv:2206.01563",
    "title": "Optimal Weak to Strong Learning",
    "abstract": "Optimal Weak to Strong Learning",
    "descriptor": "",
    "authors": [
      "Kasper Green Larsen",
      "Martin Ritzert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.01563"
  },
  {
    "id": "arXiv:2206.02095",
    "title": "ARC -- Actor Residual Critic for Adversarial Imitation Learning",
    "abstract": "ARC -- Actor Residual Critic for Adversarial Imitation Learning",
    "descriptor": "",
    "authors": [
      "Ankur Deka",
      "Changliu Liu",
      "Katia Sycara"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.02095"
  },
  {
    "id": "arXiv:2206.02180",
    "title": "Semi-Supervised Learning for Mars Imagery Classification and  Segmentation",
    "abstract": "Comments: Accepted by ACM Trans. on Multimedia Computing Communications and Applications (TOMM)",
    "descriptor": "\nComments: Accepted by ACM Trans. on Multimedia Computing Communications and Applications (TOMM)\n",
    "authors": [
      "Wenjing Wang",
      "Lilang Lin",
      "Zejia Fan",
      "Jiaying Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.02180"
  },
  {
    "id": "arXiv:2206.02993",
    "title": "False Consensus, Information Theory, and Prediction Markets",
    "abstract": "Comments: To appear in ITCS 2023",
    "descriptor": "\nComments: To appear in ITCS 2023\n",
    "authors": [
      "Yuqing Kong",
      "Grant Schoenebeck"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2206.02993"
  },
  {
    "id": "arXiv:2206.03599",
    "title": "Multi-qubit doilies: enumeration for all ranks and classification for  ranks four and five",
    "abstract": "Comments: Minor revisions and corrections. Published in Journal of Computational Science, Volume 64, 2022, 101853, ISSN 1877-7503, this https URL",
    "descriptor": "\nComments: Minor revisions and corrections. Published in Journal of Computational Science, Volume 64, 2022, 101853, ISSN 1877-7503, this https URL\n",
    "authors": [
      "Axel Muller",
      "Metod Saniga",
      "Alain Giorgetti",
      "Henri De Boutray",
      "Fr\u00e9d\u00e9ric Holweck"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2206.03599"
  },
  {
    "id": "arXiv:2206.04006",
    "title": "Few-Shot Audio-Visual Learning of Environment Acoustics",
    "abstract": "Comments: Accepted to NeurIPS 2022",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Sagnik Majumder",
      "Changan Chen",
      "Ziad Al-Halah",
      "Kristen Grauman"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.04006"
  },
  {
    "id": "arXiv:2206.04510",
    "title": "SsciBERT: A Pre-trained Language Model for Social Science Texts",
    "abstract": "Comments: 24 pages,2 figures",
    "descriptor": "\nComments: 24 pages,2 figures\n",
    "authors": [
      "Si Shen",
      "Jiangfeng Liu",
      "Litao Lin",
      "Ying Huang",
      "Lin Zhang",
      "Chang Liu",
      "Yutong Feng",
      "Dongbo Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.04510"
  },
  {
    "id": "arXiv:2206.04640",
    "title": "Regret Bounds for Information-Directed Reinforcement Learning",
    "abstract": "Comments: Accepted at NeurIPS 2022",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Botao Hao",
      "Tor Lattimore"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.04640"
  },
  {
    "id": "arXiv:2206.05260",
    "title": "Balanced Product of Calibrated Experts for Long-Tailed Recognition",
    "abstract": "Comments: 19 pages, under review",
    "descriptor": "\nComments: 19 pages, under review\n",
    "authors": [
      "Emanuel Sanchez Aimar",
      "Arvi Jonnarth",
      "Michael Felsberg",
      "Marco Kuhlmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.05260"
  },
  {
    "id": "arXiv:2206.06112",
    "title": "Vision-State Fusion: Improving Deep Neural Networks for Autonomous  Robotics",
    "abstract": "Comments: 8 pages, 8 figures",
    "descriptor": "\nComments: 8 pages, 8 figures\n",
    "authors": [
      "Elia Cereda",
      "Stefano Bonato",
      "Mirko Nava",
      "Alessandro Giusti",
      "Daniele Palossi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.06112"
  },
  {
    "id": "arXiv:2206.06266",
    "title": "Enhancement of Rural Connectivity by Recycling TV Towers with Massive  MIMO Techniques",
    "abstract": "Comments: 7 pages, submitted to IEEE Communications Magazine (June 2022), 1st revision (October 2022), 2nd revision (November 2022)",
    "descriptor": "\nComments: 7 pages, submitted to IEEE Communications Magazine (June 2022), 1st revision (October 2022), 2nd revision (November 2022)\n",
    "authors": [
      "Ammar El Falou",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.06266"
  },
  {
    "id": "arXiv:2206.06743",
    "title": "Weakly-Supervised Crack Detection",
    "abstract": "Comments: Submitted to IEEE Transactions on Intelligent Transportation Systems",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Intelligent Transportation Systems\n",
    "authors": [
      "Yuki Inoue",
      "Hiroto Nagayoshi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06743"
  },
  {
    "id": "arXiv:2206.07293",
    "title": "FRCRN: Boosting Feature Representation using Frequency Recurrence for  Monaural Speech Enhancement",
    "abstract": "Comments: The paper has been accepted by ICASSP 2022. 5 pages, 2 figures, 5 tables",
    "descriptor": "\nComments: The paper has been accepted by ICASSP 2022. 5 pages, 2 figures, 5 tables\n",
    "authors": [
      "Shengkui Zhao",
      "Bin Ma",
      "Karn N. Watcharasupat",
      "Woon-Seng Gan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.07293"
  },
  {
    "id": "arXiv:2206.08169",
    "title": "Deterministic and Random Perturbations of the Kepler Problem",
    "abstract": "Comments: Honors thesis submitted to Department of Mathematics of the College of Staten Island City University of New York in partial fulfillment of the requirements for the degree of Bachelor of Science in Mathematics with Honors. Signatures not included due to privacy concerns. Updated to correct certain figures",
    "descriptor": "\nComments: Honors thesis submitted to Department of Mathematics of the College of Staten Island City University of New York in partial fulfillment of the requirements for the degree of Bachelor of Science in Mathematics with Honors. Signatures not included due to privacy concerns. Updated to correct certain figures\n",
    "authors": [
      "Jesse Dimino"
    ],
    "subjectives": [
      "Classical Physics (physics.class-ph)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.08169"
  },
  {
    "id": "arXiv:2206.08657",
    "title": "BridgeTower: Building Bridges Between Encoders in Vision-Language  Representation Learning",
    "abstract": "Comments: Accepted by AAAI 2023",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Xiao Xu",
      "Chenfei Wu",
      "Shachar Rosenman",
      "Vasudev Lal",
      "Wanxiang Che",
      "Nan Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.08657"
  },
  {
    "id": "arXiv:2206.09059",
    "title": "CLiMB: A Continual Learning Benchmark for Vision-and-Language Tasks",
    "abstract": "Comments: Accepted to NeurIPS 2022 Datasets and Benchmarks track",
    "descriptor": "\nComments: Accepted to NeurIPS 2022 Datasets and Benchmarks track\n",
    "authors": [
      "Tejas Srinivasan",
      "Ting-Yun Chang",
      "Leticia Leonor Pinto Alva",
      "Georgios Chochlakis",
      "Mohammad Rostami",
      "Jesse Thomason"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.09059"
  },
  {
    "id": "arXiv:2206.09428",
    "title": "Reputation, Risk, and Trust on User Adoption of Internet Search Engines:  The Case of DuckDuckGo",
    "abstract": "Reputation, Risk, and Trust on User Adoption of Internet Search Engines:  The Case of DuckDuckGo",
    "descriptor": "",
    "authors": [
      "Antonios Saravanos",
      "Stavros Zervoudakis",
      "Dongnanzi Zheng",
      "Amarpreet Nanda",
      "Georgios Shaheen",
      "Charles Hornat",
      "Jeremiah Konde Chaettle",
      "Alassane Yoda",
      "Hyeree Park",
      "Will Ang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.09428"
  },
  {
    "id": "arXiv:2206.11134",
    "title": "Open Vocabulary Object Detection with Proposal Mining and Prediction  Equalization",
    "abstract": "Open Vocabulary Object Detection with Proposal Mining and Prediction  Equalization",
    "descriptor": "",
    "authors": [
      "Peixian Chen",
      "Kekai Sheng",
      "Mengdan Zhang",
      "Mingbao Lin",
      "Yunhang Shen",
      "Shaohui Lin",
      "Bo Ren",
      "Ke Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.11134"
  },
  {
    "id": "arXiv:2206.11397",
    "title": "Online Bipartite Matching with Advice: Tight Robustness-Consistency  Tradeoffs for the Two-Stage Model",
    "abstract": "Online Bipartite Matching with Advice: Tight Robustness-Consistency  Tradeoffs for the Two-Stage Model",
    "descriptor": "",
    "authors": [
      "Billy Jin",
      "Will Ma"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2206.11397"
  },
  {
    "id": "arXiv:2206.12150",
    "title": "Decoding Short LDPC Codes via BP-RNN Diversity and Reliability-Based  Post-Processing",
    "abstract": "Decoding Short LDPC Codes via BP-RNN Diversity and Reliability-Based  Post-Processing",
    "descriptor": "",
    "authors": [
      "Joachim Rosseel",
      "Val\u00e9rian Mannoni",
      "Inbar Fijalkow",
      "Valentin Savin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.12150"
  },
  {
    "id": "arXiv:2206.12961",
    "title": "An Efficient Global Optimality Certificate for Landmark-Based SLAM",
    "abstract": "Comments: 10 pages, 7 figures",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Connor Holmes",
      "Timothy D. Barfoot"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.12961"
  },
  {
    "id": "arXiv:2206.13263",
    "title": "Learning with Weak Annotations for Robust Maritime Obstacle Detection",
    "abstract": "Comments: Published in MDPI Sensors, 23 pages, 8 figures",
    "descriptor": "\nComments: Published in MDPI Sensors, 23 pages, 8 figures\n",
    "authors": [
      "Lojze \u017dust",
      "Matej Kristan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.13263"
  },
  {
    "id": "arXiv:2206.13998",
    "title": "Learning Symmetric Rules with SATNet",
    "abstract": "Comments: 27 pages, 10 figures, the first two authors contributed equally to this work, accepted at NeurIPS'22",
    "descriptor": "\nComments: 27 pages, 10 figures, the first two authors contributed equally to this work, accepted at NeurIPS'22\n",
    "authors": [
      "Sangho Lim",
      "Eun-Gyeol Oh",
      "Hongseok Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)",
      "Group Theory (math.GR)"
    ],
    "url": "https://arxiv.org/abs/2206.13998"
  },
  {
    "id": "arXiv:2206.15153",
    "title": "Some $3$-designs and shortened codes from binary cyclic codes with three  zeros",
    "abstract": "Comments: 20 pages. arXiv admin note: text overlap with arXiv:2110.03881, arXiv:2007.05923",
    "descriptor": "\nComments: 20 pages. arXiv admin note: text overlap with arXiv:2110.03881, arXiv:2007.05923\n",
    "authors": [
      "Can Xiang",
      "Chunming Tang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.15153"
  },
  {
    "id": "arXiv:2206.15397",
    "title": "Randomized K-FACs: Speeding up K-FAC with Randomized Numerical Linear  Algebra",
    "abstract": "Comments: Version 2: corrected all typos",
    "descriptor": "\nComments: Version 2: corrected all typos\n",
    "authors": [
      "Constantin Octavian Puiu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.15397"
  },
  {
    "id": "arXiv:2207.00938",
    "title": "Interpretable by Design: Learning Predictors by Composing Interpretable  Queries",
    "abstract": "Comments: 29 pages, 14 figures. Accepted as a Regular Paper in Transactions on Pattern Analysis and Machine Intelligence",
    "descriptor": "\nComments: 29 pages, 14 figures. Accepted as a Regular Paper in Transactions on Pattern Analysis and Machine Intelligence\n",
    "authors": [
      "Aditya Chattopadhyay",
      "Stewart Slocum",
      "Benjamin D. Haeffele",
      "Rene Vidal",
      "Donald Geman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.00938"
  },
  {
    "id": "arXiv:2207.01206",
    "title": "WebShop: Towards Scalable Real-World Web Interaction with Grounded  Language Agents",
    "abstract": "Comments: Project page with code, data, demos: this https URL v3 is NeurIPS camera ready version",
    "descriptor": "\nComments: Project page with code, data, demos: this https URL v3 is NeurIPS camera ready version\n",
    "authors": [
      "Shunyu Yao",
      "Howard Chen",
      "John Yang",
      "Karthik Narasimhan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.01206"
  },
  {
    "id": "arXiv:2207.01297",
    "title": "Revisiting Classifier: Transferring Vision-Language Models for Video  Recognition",
    "abstract": "Comments: Accepted by AAAI-2023",
    "descriptor": "\nComments: Accepted by AAAI-2023\n",
    "authors": [
      "Wenhao Wu",
      "Zhun Sun",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.01297"
  },
  {
    "id": "arXiv:2207.03268",
    "title": "Fast Discrepancy Minimization with Hereditary Guarantees",
    "abstract": "Fast Discrepancy Minimization with Hereditary Guarantees",
    "descriptor": "",
    "authors": [
      "Kasper Green Larsen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2207.03268"
  },
  {
    "id": "arXiv:2207.04208",
    "title": "SCouT: Synthetic Counterfactuals via Spatiotemporal Transformers for  Actionable Healthcare",
    "abstract": "SCouT: Synthetic Counterfactuals via Spatiotemporal Transformers for  Actionable Healthcare",
    "descriptor": "",
    "authors": [
      "Bhishma Dedhia",
      "Roshini Balasubramanian",
      "Niraj K. Jha"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04208"
  },
  {
    "id": "arXiv:2207.04498",
    "title": "Multi-UAV Collaborative Sensing and Communication: Joint Task Allocation  and Power Optimization",
    "abstract": "Comments: 32 pages, submitted to IEEE for possible publication",
    "descriptor": "\nComments: 32 pages, submitted to IEEE for possible publication\n",
    "authors": [
      "Kaitao Meng",
      "Xiaofan He",
      "Qingqing Wu",
      "Deshi Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.04498"
  },
  {
    "id": "arXiv:2207.05018",
    "title": "Learning Temporally Extended Skills in Continuous Domains as Symbolic  Actions for Planning",
    "abstract": "Comments: Accepted for publication at the 6th Conference on Robot Learning (CoRL) 2022, Auckland, New Zealand. Project website (including video) is available at this https URL",
    "descriptor": "\nComments: Accepted for publication at the 6th Conference on Robot Learning (CoRL) 2022, Auckland, New Zealand. Project website (including video) is available at this https URL\n",
    "authors": [
      "Jan Achterhold",
      "Markus Krimmel",
      "Joerg Stueckler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.05018"
  },
  {
    "id": "arXiv:2207.08562",
    "title": "DHGE: Dual-view Hyper-Relational Knowledge Graph Embedding for Link  Prediction and Entity Typing",
    "abstract": "Comments: Accepted by the 37th AAAI Conference on Artificial Intelligence (AAAI-2023)",
    "descriptor": "\nComments: Accepted by the 37th AAAI Conference on Artificial Intelligence (AAAI-2023)\n",
    "authors": [
      "Haoran Luo",
      "Haihong E",
      "Ling Tan",
      "Gengxian Zhou",
      "Tianyu Yao",
      "Kaiyang Wan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.08562"
  },
  {
    "id": "arXiv:2207.09088",
    "title": "XG-BoT: An Explainable Deep Graph Neural Network for Botnet Detection  and Forensics",
    "abstract": "Comments: 7 pages, 5 figures",
    "descriptor": "\nComments: 7 pages, 5 figures\n",
    "authors": [
      "Wai Weng Lo",
      "Gayan K. Kulatilleke",
      "Mohanad Sarhan",
      "Siamak Layeghy",
      "Marius Portmann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2207.09088"
  },
  {
    "id": "arXiv:2207.10656",
    "title": "Adaptive sparse interpolation for accelerating nonlinear stochastic  reduced-order modeling with time-dependent bases",
    "abstract": "Comments: 31 pages, 14 figures",
    "descriptor": "\nComments: 31 pages, 14 figures\n",
    "authors": [
      "Mohammad Hossein Naderi",
      "Hessam Babaee"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2207.10656"
  },
  {
    "id": "arXiv:2207.10716",
    "title": "JAWS: Auditing Predictive Uncertainty Under Covariate Shift",
    "abstract": "Comments: Thirty-sixth Conference on Neural Information Processing Systems",
    "descriptor": "\nComments: Thirty-sixth Conference on Neural Information Processing Systems\n",
    "authors": [
      "Drew Prinster",
      "Anqi Liu",
      "Suchi Saria"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.10716"
  },
  {
    "id": "arXiv:2207.11088",
    "title": "Layer-refined Graph Convolutional Networks for Recommendation",
    "abstract": "Comments: Accepted as a research track paper in ICDE 2023",
    "descriptor": "\nComments: Accepted as a research track paper in ICDE 2023\n",
    "authors": [
      "Xin Zhou",
      "Donghui Lin",
      "Yong Liu",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2207.11088"
  },
  {
    "id": "arXiv:2207.11224",
    "title": "Humans plan for the near future to walk economically on uneven terrain",
    "abstract": "Comments: 17 pages, 8 figures",
    "descriptor": "\nComments: 17 pages, 8 figures\n",
    "authors": [
      "Osman Darici",
      "Arthur D. Kuo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)",
      "Optimization and Control (math.OC)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2207.11224"
  },
  {
    "id": "arXiv:2207.12391",
    "title": "SegPGD: An Effective and Efficient Adversarial Attack for Evaluating and  Boosting Segmentation Robustness",
    "abstract": "SegPGD: An Effective and Efficient Adversarial Attack for Evaluating and  Boosting Segmentation Robustness",
    "descriptor": "",
    "authors": [
      "Jindong Gu",
      "Hengshuang Zhao",
      "Volker Tresp",
      "Philip Torr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2207.12391"
  },
  {
    "id": "arXiv:2207.13339",
    "title": "ALBench: A Framework for Evaluating Active Learning in Object Detection",
    "abstract": "ALBench: A Framework for Evaluating Active Learning in Object Detection",
    "descriptor": "",
    "authors": [
      "Zhanpeng Feng",
      "Shiliang Zhang",
      "Rinyoichi Takezoe",
      "Wenze Hu",
      "Manmohan Chandraker",
      "Li-Jia Li",
      "Vijay K. Narayanan",
      "Xiaoyu Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.13339"
  },
  {
    "id": "arXiv:2208.00001",
    "title": "FastGeodis: Fast Generalised Geodesic Distance Transform",
    "abstract": "Comments: Accepted at Journal of Open Source Software (JOSS)",
    "descriptor": "\nComments: Accepted at Journal of Open Source Software (JOSS)\n",
    "authors": [
      "Muhammad Asad",
      "Reuben Dorent",
      "Tom Vercauteren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2208.00001"
  },
  {
    "id": "arXiv:2208.01521",
    "title": "DSR -- A dual subspace re-projection network for surface anomaly  detection",
    "abstract": "Comments: Presented at ECCV2022",
    "descriptor": "\nComments: Presented at ECCV2022\n",
    "authors": [
      "Vitjan Zavrtanik",
      "Matej Kristan",
      "Danijel Sko\u010daj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.01521"
  },
  {
    "id": "arXiv:2208.02862",
    "title": "Improved Bounds for Rectangular Monotone Min-Plus Product",
    "abstract": "Improved Bounds for Rectangular Monotone Min-Plus Product",
    "descriptor": "",
    "authors": [
      "Anita D\u00fcrr"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2208.02862"
  },
  {
    "id": "arXiv:2208.03196",
    "title": "COPER: Continuous Patient State Perceiver",
    "abstract": "Comments: 2 figures; presented in IEEE International Conference on Biomedical and Health Informatics (IEEE BHI-2022)",
    "descriptor": "\nComments: 2 figures; presented in IEEE International Conference on Biomedical and Health Informatics (IEEE BHI-2022)\n",
    "authors": [
      "Vinod Kumar Chauhan",
      "Anshul Thakur",
      "Odhran O'Donoghue",
      "David A. Clifton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.03196"
  },
  {
    "id": "arXiv:2208.03610",
    "title": "Blackbox Attacks via Surrogate Ensemble Search",
    "abstract": "Comments: Our code is available at this https URL",
    "descriptor": "\nComments: Our code is available at this https URL\n",
    "authors": [
      "Zikui Cai",
      "Chengyu Song",
      "Srikanth Krishnamurthy",
      "Amit Roy-Chowdhury",
      "M. Salman Asif"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.03610"
  },
  {
    "id": "arXiv:2208.04018",
    "title": "Hybrid-ARQ Based Relaying Strategies for Enhancing Reliability in  Delay-Bounded Networks",
    "abstract": "Comments: 30 pages. arXiv admin note: text overlap with arXiv:2203.08381",
    "descriptor": "\nComments: 30 pages. arXiv admin note: text overlap with arXiv:2203.08381\n",
    "authors": [
      "Jaya Goel",
      "J. Harshan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2208.04018"
  },
  {
    "id": "arXiv:2208.06263",
    "title": "Probabilistic Rank and Reward: A Scalable Model for Slate Recommendation",
    "abstract": "Probabilistic Rank and Reward: A Scalable Model for Slate Recommendation",
    "descriptor": "",
    "authors": [
      "Imad Aouali",
      "Achraf Ait Sidi Hammou",
      "Sergey Ivanov",
      "Otmane Sakhi",
      "David Rohde",
      "Flavian Vasile"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.06263"
  },
  {
    "id": "arXiv:2208.06681",
    "title": "Modeling biological face recognition with deep convolutional neural  networks",
    "abstract": "Comments: 24 pages, 2 figures, 1 table",
    "descriptor": "\nComments: 24 pages, 2 figures, 1 table\n",
    "authors": [
      "Leonard E. van Dyck",
      "Walter R. Gruber"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.06681"
  },
  {
    "id": "arXiv:2208.08618",
    "title": "Perfect Out-forests and Steiner Cycle Packing in Digraphs",
    "abstract": "Perfect Out-forests and Steiner Cycle Packing in Digraphs",
    "descriptor": "",
    "authors": [
      "Yuefang Sun"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2208.08618"
  },
  {
    "id": "arXiv:2208.08677",
    "title": "Enhancing Targeted Attack Transferability via Diversified Weight Pruning",
    "abstract": "Comments: 8 pages + Appendix",
    "descriptor": "\nComments: 8 pages + Appendix\n",
    "authors": [
      "Hung-Jui Wang",
      "Yu-Yu Wu",
      "Shang-Tse Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08677"
  },
  {
    "id": "arXiv:2208.08965",
    "title": "GSRFormer: Grounded Situation Recognition Transformer with Alternate  Semantic Attention Refinement",
    "abstract": "Comments: ACM Multimedia 2022 (Oral), Code: this https URL",
    "descriptor": "\nComments: ACM Multimedia 2022 (Oral), Code: this https URL\n",
    "authors": [
      "Zhi-Qi Cheng",
      "Qi Dai",
      "Siyao Li",
      "Teruko Mitamura",
      "Alexander Hauptmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2208.08965"
  },
  {
    "id": "arXiv:2208.12856",
    "title": "Local Context-Aware Active Domain Adaptation",
    "abstract": "Local Context-Aware Active Domain Adaptation",
    "descriptor": "",
    "authors": [
      "Tao Sun",
      "Cheng Lu",
      "Haibin Ling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.12856"
  },
  {
    "id": "arXiv:2208.12975",
    "title": "Deep Kernel Learning of Dynamical Models from High-Dimensional Noisy  Data",
    "abstract": "Deep Kernel Learning of Dynamical Models from High-Dimensional Noisy  Data",
    "descriptor": "",
    "authors": [
      "Nicol\u00f2 Botteghi",
      "Mengwu Guo",
      "Christoph Brune"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.12975"
  },
  {
    "id": "arXiv:2208.13179",
    "title": "Learning Heterogeneous Interaction Strengths by Trajectory Prediction  with Graph Neural Network",
    "abstract": "Comments: 14 pages, 8 figures",
    "descriptor": "\nComments: 14 pages, 8 figures\n",
    "authors": [
      "Seungwoong Ha",
      "Hawoong Jeong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.13179"
  },
  {
    "id": "arXiv:2208.14246",
    "title": "Self-support topology optimization considering distortion for metal  additive manufacturing",
    "abstract": "Comments: 38 pages, 29 figures",
    "descriptor": "\nComments: 38 pages, 29 figures\n",
    "authors": [
      "Takao Miki"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2208.14246"
  },
  {
    "id": "arXiv:2209.02681",
    "title": "How important are activation functions in regression and classification?  A survey, performance comparison, and future directions",
    "abstract": "Comments: 48 pages, 15 figures",
    "descriptor": "\nComments: 48 pages, 15 figures\n",
    "authors": [
      "Ameya D. Jagtap",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.02681"
  },
  {
    "id": "arXiv:2209.03500",
    "title": "Tube-Based Zonotopic Data-Driven Predictive Control",
    "abstract": "Tube-Based Zonotopic Data-Driven Predictive Control",
    "descriptor": "",
    "authors": [
      "Alessio Russo",
      "Alexandre Proutiere"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.03500"
  },
  {
    "id": "arXiv:2209.04101",
    "title": "On the computational hardness needed for quantum cryptography",
    "abstract": "Comments: 30 pages, 1 figure",
    "descriptor": "\nComments: 30 pages, 1 figure\n",
    "authors": [
      "Zvika Brakerski",
      "Ran Canetti",
      "Luowen Qian"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2209.04101"
  },
  {
    "id": "arXiv:2209.04636",
    "title": "Revisiting Active Sets for Gaussian Process Decoders",
    "abstract": "Comments: Accepted at Advances in Neural Information Processing Systems (NeurIPS) 2022",
    "descriptor": "\nComments: Accepted at Advances in Neural Information Processing Systems (NeurIPS) 2022\n",
    "authors": [
      "Pablo Moreno-Mu\u00f1oz",
      "Cilie W Feldager",
      "S\u00f8ren Hauberg"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.04636"
  },
  {
    "id": "arXiv:2209.05486",
    "title": "Active Learning and Novel Model Calibration Measurements for Automated  Visual Inspection in Manufacturing",
    "abstract": "Active Learning and Novel Model Calibration Measurements for Automated  Visual Inspection in Manufacturing",
    "descriptor": "",
    "authors": [
      "Jo\u017ee M. Ro\u017eanec",
      "Luka Bizjak",
      "Elena Trajkova",
      "Patrik Zajec",
      "Jelle Keizer",
      "Bla\u017e Fortuna",
      "Dunja Mladeni\u0107"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.05486"
  },
  {
    "id": "arXiv:2209.05534",
    "title": "PreSTU: Pre-Training for Scene-Text Understanding",
    "abstract": "PreSTU: Pre-Training for Scene-Text Understanding",
    "descriptor": "",
    "authors": [
      "Jihyung Kil",
      "Soravit Changpinyo",
      "Xi Chen",
      "Hexiang Hu",
      "Sebastian Goodman",
      "Wei-Lun Chao",
      "Radu Soricut"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.05534"
  },
  {
    "id": "arXiv:2209.06535",
    "title": "CRAFT: Camera-Radar 3D Object Detection with Spatio-Contextual Fusion  Transformer",
    "abstract": "Comments: Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI'23)",
    "descriptor": "\nComments: Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI'23)\n",
    "authors": [
      "Youngseok Kim",
      "Sanmin Kim",
      "Jun Won Choi",
      "Dongsuk Kum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.06535"
  },
  {
    "id": "arXiv:2209.09108",
    "title": "Online Poisoning Attacks Against Data-Driven Predictive Control",
    "abstract": "Online Poisoning Attacks Against Data-Driven Predictive Control",
    "descriptor": "",
    "authors": [
      "Yue Yu",
      "Ruihan Zhao",
      "Sandeep Chinchali",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.09108"
  },
  {
    "id": "arXiv:2209.09139",
    "title": "Machine Learning based Extraction of Boundary Conditions from Doppler  Echo Images for Patient Specific Coarctation of the Aorta: Computational  Fluid Dynamics Study",
    "abstract": "Comments: Article to be submitted to Springer Nature Cardiovascular Engineering and Technology Journal",
    "descriptor": "\nComments: Article to be submitted to Springer Nature Cardiovascular Engineering and Technology Journal\n",
    "authors": [
      "Vincent Milimo Masilokwa Punabantu",
      "Malebogo Ngoepe",
      "Amit Kumar Mishra",
      "Thomas Aldersley",
      "John Lawrenson",
      "Liesl Zuhlke"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.09139"
  },
  {
    "id": "arXiv:2209.09383",
    "title": "Distributed representations of graphs for drug pair scoring",
    "abstract": "Comments: Updated manuscript, 9 main pages, 8 pages reference and appendix",
    "descriptor": "\nComments: Updated manuscript, 9 main pages, 8 pages reference and appendix\n",
    "authors": [
      "Paul Scherer",
      "Pietro Li\u00f2",
      "Mateja Jamnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2209.09383"
  },
  {
    "id": "arXiv:2209.09732",
    "title": "Neural Graph Databases",
    "abstract": "Neural Graph Databases",
    "descriptor": "",
    "authors": [
      "Maciej Besta",
      "Patrick Iff",
      "Florian Scheidl",
      "Kazuki Osawa",
      "Nikoli Dryden",
      "Michal Podstawski",
      "Tiancheng Chen",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2209.09732"
  },
  {
    "id": "arXiv:2209.10445",
    "title": "Interactive Abstract Interpretation: Reanalyzing Whole Programs for  Cheap",
    "abstract": "Comments: 16 pages, 9 figures",
    "descriptor": "\nComments: 16 pages, 9 figures\n",
    "authors": [
      "Julian Erhard",
      "Simmo Saan",
      "Sarah Tilscher",
      "Michael Schwarz",
      "Karoliine Holter",
      "Vesal Vojdani",
      "Helmut Seidl"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2209.10445"
  },
  {
    "id": "arXiv:2209.10702",
    "title": "SPICE, A Dataset of Drug-like Molecules and Peptides for Training  Machine Learning Potentials",
    "abstract": "Comments: 19 pages, 6 figures",
    "descriptor": "\nComments: 19 pages, 6 figures\n",
    "authors": [
      "Peter Eastman",
      "Pavan Kumar Behara",
      "David L. Dotson",
      "Raimondas Galvelis",
      "John E. Herr",
      "Josh T. Horton",
      "Yuezhi Mao",
      "John D. Chodera",
      "Benjamin P. Pritchard",
      "Yuanqing Wang",
      "Gianni De Fabritiis",
      "Thomas E. Markland"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2209.10702"
  },
  {
    "id": "arXiv:2209.11888",
    "title": "JPEG Artifact Correction using Denoising Diffusion Restoration Models",
    "abstract": "Comments: Presented at NeurIPS 2022 Workshop on Score-Based Methods. Code: this https URL",
    "descriptor": "\nComments: Presented at NeurIPS 2022 Workshop on Score-Based Methods. Code: this https URL\n",
    "authors": [
      "Bahjat Kawar",
      "Jiaming Song",
      "Stefano Ermon",
      "Michael Elad"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.11888"
  },
  {
    "id": "arXiv:2209.12362",
    "title": "Multi-dataset Training of Transformers for Robust Action Recognition",
    "abstract": "Comments: NeurIPS 2022 Spotlight paper. Supplementary material at this https URL Code and models are available at this https URL",
    "descriptor": "\nComments: NeurIPS 2022 Spotlight paper. Supplementary material at this https URL Code and models are available at this https URL\n",
    "authors": [
      "Junwei Liang",
      "Enwei Zhang",
      "Jun Zhang",
      "Chunhua Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.12362"
  },
  {
    "id": "arXiv:2209.12894",
    "title": "Biologically-Plausible Determinant Maximization Neural Networks for  Blind Separation of Correlated Sources",
    "abstract": "Comments: NeurIPS 2022, 37 pages",
    "descriptor": "\nComments: NeurIPS 2022, 37 pages\n",
    "authors": [
      "Bariscan Bozkurt",
      "Cengiz Pehlevan",
      "Alper T. Erdogan"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.12894"
  },
  {
    "id": "arXiv:2209.13129",
    "title": "Deep Generative Multimedia Children's Literature",
    "abstract": "Comments: Under review at AAAI 2023 Workshop on Creative AI Across Modalities",
    "descriptor": "\nComments: Under review at AAAI 2023 Workshop on Creative AI Across Modalities\n",
    "authors": [
      "Matthew L. Olson"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.13129"
  },
  {
    "id": "arXiv:2209.13410",
    "title": "Graph Neural Network Expressivity and Meta-Learning for Molecular  Property Regression",
    "abstract": "Graph Neural Network Expressivity and Meta-Learning for Molecular  Property Regression",
    "descriptor": "",
    "authors": [
      "Haitz S\u00e1ez de Oc\u00e1riz Borde",
      "Federico Barbero"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2209.13410"
  },
  {
    "id": "arXiv:2209.14007",
    "title": "OA-Bug: An Olfactory-Auditory Augmented Bug Algorithm for Swarm Robots  in a Denied Environment",
    "abstract": "Comments: 7 pages, 5 figures",
    "descriptor": "\nComments: 7 pages, 5 figures\n",
    "authors": [
      "Siqi Tan",
      "Xiaoya Zhang",
      "Jingyao Li",
      "Ruitao Jing",
      "Mufan Zhao",
      "Yang Liu",
      "Quan Quan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2209.14007"
  },
  {
    "id": "arXiv:2209.15611",
    "title": "Protein structure generation via folding diffusion",
    "abstract": "Protein structure generation via folding diffusion",
    "descriptor": "",
    "authors": [
      "Kevin E. Wu",
      "Kevin K. Yang",
      "Rianne van den Berg",
      "James Y. Zou",
      "Alex X. Lu",
      "Ava P. Amini"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.15611"
  },
  {
    "id": "arXiv:2210.00750",
    "title": "Offline Reinforcement Learning with Differentiable Function  Approximation is Provably Efficient",
    "abstract": "Offline Reinforcement Learning with Differentiable Function  Approximation is Provably Efficient",
    "descriptor": "",
    "authors": [
      "Ming Yin",
      "Mengdi Wang",
      "Yu-Xiang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00750"
  },
  {
    "id": "arXiv:2210.00935",
    "title": "Analysis of (sub-)Riemannian PDE-G-CNNs",
    "abstract": "Comments: 28 pages, 19 figures",
    "descriptor": "\nComments: 28 pages, 19 figures\n",
    "authors": [
      "Gijs Bellaard",
      "Daan L. J. Bon",
      "Gautam Pai",
      "Bart M. N. Smets",
      "Remco Duits"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2210.00935"
  },
  {
    "id": "arXiv:2210.01241",
    "title": "Is Reinforcement Learning (Not) for Natural Language Processing?:  Benchmarks, Baselines, and Building Blocks for Natural Language Policy  Optimization",
    "abstract": "Comments: Preprint. Under review. Code found at this https URL and Project website at this https URL",
    "descriptor": "\nComments: Preprint. Under review. Code found at this https URL and Project website at this https URL\n",
    "authors": [
      "Rajkumar Ramamurthy",
      "Prithviraj Ammanabrolu",
      "Kiant\u00e9 Brantley",
      "Jack Hessel",
      "Rafet Sifa",
      "Christian Bauckhage",
      "Hannaneh Hajishirzi",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01241"
  },
  {
    "id": "arXiv:2210.02438",
    "title": "DALL-E-Bot: Introducing Web-Scale Diffusion Models to Robotics",
    "abstract": "Comments: Webpage and videos: ( this https URL ) V1: initial submission. V2: new baselines",
    "descriptor": "\nComments: Webpage and videos: ( this https URL ) V1: initial submission. V2: new baselines\n",
    "authors": [
      "Ivan Kapelyukh",
      "Vitalis Vosylius",
      "Edward Johns"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02438"
  },
  {
    "id": "arXiv:2210.03137",
    "title": "Deep Inventory Management",
    "abstract": "Deep Inventory Management",
    "descriptor": "",
    "authors": [
      "Dhruv Madeka",
      "Kari Torkkola",
      "Carson Eisenach",
      "Anna Luo",
      "Dean P. Foster",
      "Sham M. Kakade"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.03137"
  },
  {
    "id": "arXiv:2210.03205",
    "title": "Synthetic Dataset Generation for Privacy-Preserving Machine Learning",
    "abstract": "Comments: the results are not correct",
    "descriptor": "\nComments: the results are not correct\n",
    "authors": [
      "Efstathia Soufleri",
      "Gobinda Saha",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03205"
  },
  {
    "id": "arXiv:2210.03919",
    "title": "CLIP-PAE: Projection-Augmentation Embedding to Extract Relevant Features  for a Disentangled, Interpretable, and Controllable Text-Guided Image  Manipulation",
    "abstract": "CLIP-PAE: Projection-Augmentation Embedding to Extract Relevant Features  for a Disentangled, Interpretable, and Controllable Text-Guided Image  Manipulation",
    "descriptor": "",
    "authors": [
      "Chenliang Zhou",
      "Fangcheng Zhong",
      "Cengiz Oztireli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03919"
  },
  {
    "id": "arXiv:2210.05294",
    "title": "Identifying Difficult exercises in an eTextbook Using Item Response  Theory and Logged Data Analysis",
    "abstract": "Comments: 6 pages,5 figures",
    "descriptor": "\nComments: 6 pages,5 figures\n",
    "authors": [
      "Ahmed Abd Elrahman",
      "Ahmed I. Taloba",
      "Mohammed F. Farghally",
      "Taysir Hassan A Soliman"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.05294"
  },
  {
    "id": "arXiv:2210.06278",
    "title": "On the Nonlinear Shaping Gain with Probabilistic Shaping and Carrier  Phase Recovery",
    "abstract": "Comments: Submitted for publication to the Journal of Lightwave Technologies on November 25th, 2022",
    "descriptor": "\nComments: Submitted for publication to the Journal of Lightwave Technologies on November 25th, 2022\n",
    "authors": [
      "Stella Civelli",
      "Emanuele Parente",
      "Enrico Forestieri",
      "Marco Secondini"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.06278"
  },
  {
    "id": "arXiv:2210.07426",
    "title": "Skill-Based Reinforcement Learning with Intrinsic Reward Matching",
    "abstract": "Comments: 17 pages",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Ademi Adeniji",
      "Amber Xie",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.07426"
  },
  {
    "id": "arXiv:2210.07783",
    "title": "Prompt Conditioned VAE: Enhancing Generative Replay for Lifelong  Learning in Task-Oriented Dialogue",
    "abstract": "Comments: EMNLP2022 Long Paper (Main Track)",
    "descriptor": "\nComments: EMNLP2022 Long Paper (Main Track)\n",
    "authors": [
      "Yingxiu Zhao",
      "Yinhe Zheng",
      "Zhiliang Tian",
      "Chang Gao",
      "Bowen Yu",
      "Haiyang Yu",
      "Yongbin Li",
      "Jian Sun",
      "Nevin L. Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07783"
  },
  {
    "id": "arXiv:2210.08217",
    "title": "PI-QT-Opt: Predictive Information Improves Multi-Task Robotic  Reinforcement Learning at Scale",
    "abstract": "Comments: CoRL 2022. 21 pages, 9 figures. The supplementary video is available at this https URL",
    "descriptor": "\nComments: CoRL 2022. 21 pages, 9 figures. The supplementary video is available at this https URL\n",
    "authors": [
      "Kuang-Huei Lee",
      "Ted Xiao",
      "Adrian Li",
      "Paul Wohlhart",
      "Ian Fischer",
      "Yao Lu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08217"
  },
  {
    "id": "arXiv:2210.08219",
    "title": "Unveiling the Sampling Density in Non-Uniform Geometric Graphs",
    "abstract": "Comments: updated affiliations; improved references; more experiments; streamlined the paper; added justification for the geometric graph with hubs model",
    "descriptor": "\nComments: updated affiliations; improved references; more experiments; streamlined the paper; added justification for the geometric graph with hubs model\n",
    "authors": [
      "Raffaele Paolino",
      "Aleksandar Bojchevski",
      "Stephan G\u00fcnnemann",
      "Gitta Kutyniok",
      "Ron Levie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08219"
  },
  {
    "id": "arXiv:2210.08836",
    "title": "MSDS: A Large-Scale Chinese Signature and Token Digit String Dataset for  Handwriting Verification",
    "abstract": "MSDS: A Large-Scale Chinese Signature and Token Digit String Dataset for  Handwriting Verification",
    "descriptor": "",
    "authors": [
      "Peirong Zhang",
      "Jiajia Jiang",
      "Yuliang Liu",
      "Lianwen Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08836"
  },
  {
    "id": "arXiv:2210.10886",
    "title": "Backdoor Attack and Defense in Federated Generative Adversarial  Network-based Medical Image Synthesis",
    "abstract": "Comments: 25 pages, 7 figures. arXiv admin note: text overlap with arXiv:2207.00762",
    "descriptor": "\nComments: 25 pages, 7 figures. arXiv admin note: text overlap with arXiv:2207.00762\n",
    "authors": [
      "Ruinan Jin",
      "Xiaoxiao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10886"
  },
  {
    "id": "arXiv:2210.11456",
    "title": "MixMask: Revisiting Masked Siamese Self-supervised Learning in  Asymmetric Distance",
    "abstract": "Comments: Technical report. Code is available at this https URL",
    "descriptor": "\nComments: Technical report. Code is available at this https URL\n",
    "authors": [
      "Kirill Vishniakov",
      "Eric Xing",
      "Zhiqiang Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11456"
  },
  {
    "id": "arXiv:2210.11915",
    "title": "Efficient identification of informative features in simulation-based  inference",
    "abstract": "Efficient identification of informative features in simulation-based  inference",
    "descriptor": "",
    "authors": [
      "Jonas Beck",
      "Michael Deistler",
      "Yves Bernaerts",
      "Jakob Macke",
      "Philipp Berens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.11915"
  },
  {
    "id": "arXiv:2210.12499",
    "title": "Training Dynamics for Curriculum Learning: A Study on Monolingual and  Cross-lingual NLU",
    "abstract": "Comments: 17 pages, 4 figures, 6 tables. To appear in EMNLP 2022",
    "descriptor": "\nComments: 17 pages, 4 figures, 6 tables. To appear in EMNLP 2022\n",
    "authors": [
      "Fenia Christopoulou",
      "Gerasimos Lampouras",
      "Ignacio Iacobacci"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.12499"
  },
  {
    "id": "arXiv:2210.12681",
    "title": "Rethinking Rotation in Self-Supervised Contrastive Learning: Adaptive  Positive or Negative Data Augmentation",
    "abstract": "Comments: Accepted at the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023",
    "descriptor": "\nComments: Accepted at the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023\n",
    "authors": [
      "Atsuyuki Miyai",
      "Qing Yu",
      "Daiki Ikami",
      "Go Irie",
      "Kiyoharu Aizawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.12681"
  },
  {
    "id": "arXiv:2210.13325",
    "title": "ICSSIM-A Framework for Building Industrial Control Systems Security  Simulation Testbeds",
    "abstract": "Comments: 43 pages, 13 figures",
    "descriptor": "\nComments: 43 pages, 13 figures\n",
    "authors": [
      "Alireza Dehlaghi-Ghadim",
      "Ali Balador",
      "Mahshid Helali Moghadam",
      "Hans Hansson",
      "Mauro Conti"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.13325"
  },
  {
    "id": "arXiv:2210.13700",
    "title": "Does Joint Training Really Help Cascaded Speech Translation?",
    "abstract": "Comments: Accepted to EMNLP 2022",
    "descriptor": "\nComments: Accepted to EMNLP 2022\n",
    "authors": [
      "Viet Anh Khoa Tran",
      "David Thulke",
      "Yingbo Gao",
      "Christian Herold",
      "Hermann Ney"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.13700"
  },
  {
    "id": "arXiv:2210.15212",
    "title": "COCO-DR: Combating Distribution Shifts in Zero-Shot Dense Retrieval with  Contrastive and Distributionally Robust Learning",
    "abstract": "Comments: EMNLP 2022 (Main Conference). The code and Model can be found at this https URL",
    "descriptor": "\nComments: EMNLP 2022 (Main Conference). The code and Model can be found at this https URL\n",
    "authors": [
      "Yue Yu",
      "Chenyan Xiong",
      "Si Sun",
      "Chao Zhang",
      "Arnold Overwijk"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15212"
  },
  {
    "id": "arXiv:2210.15511",
    "title": "ProContEXT: Progressive Context Transformer for Tracking",
    "abstract": "Comments: The source code is at this https URL",
    "descriptor": "\nComments: The source code is at this https URL\n",
    "authors": [
      "Jin-Peng Lan",
      "Zhi-Qi Cheng",
      "Jun-Yan He",
      "Chenyang Li",
      "Bin Luo",
      "Xu Bao",
      "Wangmeng Xiang",
      "Yifeng Geng",
      "Xuansong Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.15511"
  },
  {
    "id": "arXiv:2210.15793",
    "title": "Conditioning and Sampling in Variational Diffusion Models for Speech  Super-Resolution",
    "abstract": "Comments: Submitted to ICASSP 2023",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Chin-Yun Yu",
      "Sung-Lin Yeh",
      "Gy\u00f6rgy Fazekas",
      "Hao Tang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.15793"
  },
  {
    "id": "arXiv:2210.15936",
    "title": "A comprehensive study on self-supervised distillation for speaker  representation learning",
    "abstract": "Comments: Accepted by SLT2022",
    "descriptor": "\nComments: Accepted by SLT2022\n",
    "authors": [
      "Zhengyang Chen",
      "Yao Qian",
      "Bing Han",
      "Yanmin Qian",
      "Michael Zeng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15936"
  },
  {
    "id": "arXiv:2210.17073",
    "title": "Communication-Efficient Local SGD with Age-Based Worker Selection",
    "abstract": "Communication-Efficient Local SGD with Age-Based Worker Selection",
    "descriptor": "",
    "authors": [
      "Feng Zhu",
      "Jingjing Zhang",
      "Xin Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.17073"
  },
  {
    "id": "arXiv:2211.00071",
    "title": "CarbonTag: A browser-based method for approximating energy consumption  of online ads",
    "abstract": "CarbonTag: A browser-based method for approximating energy consumption  of online ads",
    "descriptor": "",
    "authors": [
      "Jos\u00e9 Gonz\u00e1lez Caba\u00f1as",
      "Patricia Callejo",
      "Rub\u00e9n Cuevas",
      "Steffen Svatberg",
      "Tommy Torjesen",
      "\u00c1ngel Cuevas",
      "Antonio Pastor",
      "Mikko Kotila"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00071"
  },
  {
    "id": "arXiv:2211.03095",
    "title": "Cyclability, Connectivity and Circumference",
    "abstract": "Cyclability, Connectivity and Circumference",
    "descriptor": "",
    "authors": [
      "Niranjan Balachandran",
      "Anish Hebbar"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.03095"
  },
  {
    "id": "arXiv:2211.03263",
    "title": "AfroLM: A Self-Active Learning-based Multilingual Pretrained Language  Model for 23 African Languages",
    "abstract": "Comments: Third Workshop on Simple and Efficient Natural Language Processing, EMNLP 2022",
    "descriptor": "\nComments: Third Workshop on Simple and Efficient Natural Language Processing, EMNLP 2022\n",
    "authors": [
      "Bonaventure F. P. Dossou",
      "Atnafu Lambebo Tonja",
      "Oreen Yousuf",
      "Salomey Osei",
      "Abigail Oppong",
      "Iyanuoluwa Shode",
      "Oluwabusayo Olufunke Awoyomi",
      "Chris Chinenye Emezue"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.03263"
  },
  {
    "id": "arXiv:2211.03364",
    "title": "Medical Diffusion -- Denoising Diffusion Probabilistic Models for 3D  Medical Image Generation",
    "abstract": "Medical Diffusion -- Denoising Diffusion Probabilistic Models for 3D  Medical Image Generation",
    "descriptor": "",
    "authors": [
      "Firas Khader",
      "Gustav Mueller-Franzes",
      "Soroosh Tayebi Arasteh",
      "Tianyu Han",
      "Christoph Haarburger",
      "Maximilian Schulze-Hagen",
      "Philipp Schad",
      "Sandy Engelhardt",
      "Bettina Baessler",
      "Sebastian Foersch",
      "Johannes Stegmaier",
      "Christiane Kuhl",
      "Sven Nebelung",
      "Jakob Nikolas Kather",
      "Daniel Truhn"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.03364"
  },
  {
    "id": "arXiv:2211.04254",
    "title": "FedGrad: Optimisation in Decentralised Machine Learning",
    "abstract": "Comments: 4 pages, 6 figures, submitting @ FL-AAAI Workshop",
    "descriptor": "\nComments: 4 pages, 6 figures, submitting @ FL-AAAI Workshop\n",
    "authors": [
      "Mann Patel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04254"
  },
  {
    "id": "arXiv:2211.06545",
    "title": "Self-Supervised Graph Structure Refinement for Graph Neural Networks",
    "abstract": "Comments: WSDM 2023",
    "descriptor": "\nComments: WSDM 2023\n",
    "authors": [
      "Jianan Zhao",
      "Qianlong Wen",
      "Mingxuan Ju",
      "Chuxu Zhang",
      "Yanfang Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.06545"
  },
  {
    "id": "arXiv:2211.06666",
    "title": "Optimizing Bandwidth Sharing for Real-time Traffic in Wireless Networks",
    "abstract": "Optimizing Bandwidth Sharing for Real-time Traffic in Wireless Networks",
    "descriptor": "",
    "authors": [
      "Sushi Anna George",
      "Vinay Joseph"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.06666"
  },
  {
    "id": "arXiv:2211.06953",
    "title": "Collaborative Application Security Testing for DevSecOps: An Empirical  Analysis of Challenges, Best Practices and Tool Support",
    "abstract": "Comments: Submitted to the Empirical Software Engineering journal_v2",
    "descriptor": "\nComments: Submitted to the Empirical Software Engineering journal_v2\n",
    "authors": [
      "Roshan Namal Rajapakse",
      "Mansooreh Zahedi",
      "Muhammad Ali Babar"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.06953"
  },
  {
    "id": "arXiv:2211.07394",
    "title": "Composed Image Retrieval with Text Feedback via Multi-grained  Uncertainty Regularization",
    "abstract": "Composed Image Retrieval with Text Feedback via Multi-grained  Uncertainty Regularization",
    "descriptor": "",
    "authors": [
      "Yiyang Chen",
      "Zhedong Zheng",
      "Wei Ji",
      "Leigang Qu",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07394"
  },
  {
    "id": "arXiv:2211.07400",
    "title": "Efficient Integration of Multi-Order Dynamics and Internal Dynamics in  Stock Movement Prediction",
    "abstract": "Comments: Technical report for accepted paper at WSDM 2023",
    "descriptor": "\nComments: Technical report for accepted paper at WSDM 2023\n",
    "authors": [
      "Thanh Trung Huynh",
      "Minh Hieu Nguyen",
      "Thanh Tam Nguyen",
      "Phi Le Nguyen",
      "Matthias Weidlich",
      "Quoc Viet Hung Nguyen",
      "Karl Aberer"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07400"
  },
  {
    "id": "arXiv:2211.07521",
    "title": "PKCAM: Previous Knowledge Channel Attention Module",
    "abstract": "PKCAM: Previous Knowledge Channel Attention Module",
    "descriptor": "",
    "authors": [
      "Eslam Mohamed Bakr",
      "Ahmad El Sallab",
      "Mohsen A. Rashwan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07521"
  },
  {
    "id": "arXiv:2211.07915",
    "title": "Backdoor Attacks on Time Series: A Generative Approach",
    "abstract": "Backdoor Attacks on Time Series: A Generative Approach",
    "descriptor": "",
    "authors": [
      "Yujing Jiang",
      "Xingjun Ma",
      "Sarah Monazam Erfani",
      "James Bailey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.07915"
  },
  {
    "id": "arXiv:2211.08005",
    "title": "Cross-Reality Re-Rendering: Manipulating between Digital and Physical  Realities",
    "abstract": "Comments: updated. arXiv admin note: text overlap with arXiv:2204.03731",
    "descriptor": "\nComments: updated. arXiv admin note: text overlap with arXiv:2204.03731\n",
    "authors": [
      "Siddhartha Datta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.08005"
  },
  {
    "id": "arXiv:2211.08788",
    "title": "CSCD-IME: Correcting Spelling Errors Generated by Pinyin IME",
    "abstract": "CSCD-IME: Correcting Spelling Errors Generated by Pinyin IME",
    "descriptor": "",
    "authors": [
      "Yong Hu",
      "Fandong Meng",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08788"
  },
  {
    "id": "arXiv:2211.09602",
    "title": "Validation Diagnostics for SBI algorithms based on Normalizing Flows",
    "abstract": "Comments: 7 pages, 2 figures, 1 appendix, published at \"Machine Learning and the Physical Sciences\" workshop (NeurIPS 2022): this https URL",
    "descriptor": "\nComments: 7 pages, 2 figures, 1 appendix, published at \"Machine Learning and the Physical Sciences\" workshop (NeurIPS 2022): this https URL\n",
    "authors": [
      "Julia Linhart",
      "Alexandre Gramfort",
      "Pedro L. C. Rodrigues"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.09602"
  },
  {
    "id": "arXiv:2211.10012",
    "title": "A Tale of Two Cities: Data and Configuration Variances in Robust Deep  Learning",
    "abstract": "A Tale of Two Cities: Data and Configuration Variances in Robust Deep  Learning",
    "descriptor": "",
    "authors": [
      "Guanqin Zhang",
      "Jiankun Sun",
      "Feng Xu",
      "H.M.N. Dilum Bandara",
      "Shiping Chen",
      "Yulei Sui",
      "Tim Menzies"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.10012"
  },
  {
    "id": "arXiv:2211.10618",
    "title": "Fully implicit frictional dynamics with soft constraints",
    "abstract": "Fully implicit frictional dynamics with soft constraints",
    "descriptor": "",
    "authors": [
      "Egor Larionov",
      "Andreas Longva",
      "Uri M. Ascher",
      "Jan Bender",
      "Dinesh K. Pai"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.10618"
  },
  {
    "id": "arXiv:2211.10684",
    "title": "Personalized Federated Learning with Hidden Information on Personalized  Prior",
    "abstract": "Comments: 19 pages, 6 figures, 3 tables",
    "descriptor": "\nComments: 19 pages, 6 figures, 3 tables\n",
    "authors": [
      "Mingjia Shi",
      "Yuhao Zhou",
      "Qing Ye",
      "Jiancheng Lv"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.10684"
  },
  {
    "id": "arXiv:2211.10738",
    "title": "Relational Symmetry based Knowledge Graph Contrastive Learning",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Ke Liang",
      "Yue Liu",
      "Sihang Zhou",
      "Xinwang Liu",
      "Wenxuan Tu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10738"
  },
  {
    "id": "arXiv:2211.10782",
    "title": "Let Graph be the Go Board: Gradient-free Node Injection Attack for Graph  Neural Networks via Reinforcement Learning",
    "abstract": "Comments: AAAI 2023. v2: update acknowledgement section. arXiv admin note: substantial text overlap with arXiv:2202.09389",
    "descriptor": "\nComments: AAAI 2023. v2: update acknowledgement section. arXiv admin note: substantial text overlap with arXiv:2202.09389\n",
    "authors": [
      "Mingxuan Ju",
      "Yujie Fan",
      "Chuxu Zhang",
      "Yanfang Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.10782"
  },
  {
    "id": "arXiv:2211.10968",
    "title": "Statistical Optimality of Divide and Conquer Kernel-based Functional  Linear Regression",
    "abstract": "Statistical Optimality of Divide and Conquer Kernel-based Functional  Linear Regression",
    "descriptor": "",
    "authors": [
      "Jiading Liu",
      "Lei Shi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10968"
  },
  {
    "id": "arXiv:2211.11109",
    "title": "Deep Learning on a Healthy Data Diet: Finding Important Examples for  Fairness",
    "abstract": "Comments: In Proceedings of AAAI 2023",
    "descriptor": "\nComments: In Proceedings of AAAI 2023\n",
    "authors": [
      "Abdelrahman Zayed",
      "Prasanna Parthasarathi",
      "Goncalo Mordido",
      "Hamid Palangi",
      "Samira Shabanian",
      "Sarath Chandar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11109"
  },
  {
    "id": "arXiv:2211.11260",
    "title": "Discovering Evolution Strategies via Meta-Black-Box Optimization",
    "abstract": "Comments: 22 pages, 21 figures",
    "descriptor": "\nComments: 22 pages, 21 figures\n",
    "authors": [
      "Robert Tjarko Lange",
      "Tom Schaul",
      "Yutian Chen",
      "Tom Zahavy",
      "Valentin Dallibard",
      "Chris Lu",
      "Satinder Singh",
      "Sebastian Flennerhag"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11260"
  },
  {
    "id": "arXiv:2211.11349",
    "title": "Data-Driven Offline Decision-Making via Invariant Representation  Learning",
    "abstract": "Comments: This is an extended version of the NeurIPS 2022 conference paper titled: \"Data-Driven Offline Model-Based Optimization via Invariant Representation Learning\"",
    "descriptor": "\nComments: This is an extended version of the NeurIPS 2022 conference paper titled: \"Data-Driven Offline Model-Based Optimization via Invariant Representation Learning\"\n",
    "authors": [
      "Han Qi",
      "Yi Su",
      "Aviral Kumar",
      "Sergey Levine"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11349"
  },
  {
    "id": "arXiv:2211.11432",
    "title": "MATE: Masked Autoencoders are Online 3D Test-Time Learners",
    "abstract": "Comments: Minor fix in citations",
    "descriptor": "\nComments: Minor fix in citations\n",
    "authors": [
      "M. Jehanzeb Mirza",
      "Inkyu Shin",
      "Wei Lin",
      "Andreas Schriebl",
      "Kunyang Sun",
      "Jaesung Choe",
      "Horst Possegger",
      "Mateusz Kozinski",
      "In So Kweon",
      "Kun-Jin Yoon",
      "Horst Bischof"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11432"
  },
  {
    "id": "arXiv:2211.11500",
    "title": "Compositional Scene Modeling with Global Object-Centric Representations",
    "abstract": "Compositional Scene Modeling with Global Object-Centric Representations",
    "descriptor": "",
    "authors": [
      "Tonglin Chen",
      "Bin Li",
      "Zhimeng Shen",
      "Xiangyang Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11500"
  },
  {
    "id": "arXiv:2211.11828",
    "title": "Data analysis and visualization techniques for project tracking:  Experiences with the ITLingo-Cloud Platform",
    "abstract": "Comments: 19 pages, 5 figures",
    "descriptor": "\nComments: 19 pages, 5 figures\n",
    "authors": [
      "Andre Nobre Barrocas",
      "Alberto Rodrigues da Silva",
      "Joao Paulo Saraiva"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Human-Computer Interaction (cs.HC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.11828"
  },
  {
    "id": "arXiv:2211.11865",
    "title": "Bayesian Learning for Neural Networks: an algorithmic survey",
    "abstract": "Bayesian Learning for Neural Networks: an algorithmic survey",
    "descriptor": "",
    "authors": [
      "Martin Magris",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11865"
  },
  {
    "id": "arXiv:2211.11892",
    "title": "Equality of Effort via Algorithmic Recourse",
    "abstract": "Equality of Effort via Algorithmic Recourse",
    "descriptor": "",
    "authors": [
      "Francesca E. D. Raimondi",
      "Andrew R. Lawrence",
      "Hana Chockler"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.11892"
  },
  {
    "id": "arXiv:2211.11904",
    "title": "EM's Convergence in Gaussian Latent Tree Models",
    "abstract": "EM's Convergence in Gaussian Latent Tree Models",
    "descriptor": "",
    "authors": [
      "Yuval Dagan",
      "Constantinos Daskalakis",
      "Anthimos Vardis Kandiros"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.11904"
  },
  {
    "id": "arXiv:2211.11923",
    "title": "Towards Optimal Coreset Construction for $(k,z)$-Clustering: Breaking  the Quadratic Dependency on $k$",
    "abstract": "Towards Optimal Coreset Construction for $(k,z)$-Clustering: Breaking  the Quadratic Dependency on $k$",
    "descriptor": "",
    "authors": [
      "Lingxiao Huang",
      "Jian Li",
      "Xuan Wu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2211.11923"
  },
  {
    "id": "arXiv:2211.11982",
    "title": "BotSIM: An End-to-End Bot Simulation Framework for Commercial  Task-Oriented Dialog Systems",
    "abstract": "Comments: Paper accepted by the EMNLP 2022 System Demo Track",
    "descriptor": "\nComments: Paper accepted by the EMNLP 2022 System Demo Track\n",
    "authors": [
      "Guangsen Wang",
      "Samson Tan",
      "Shafiq Joty",
      "Gang Wu",
      "Jimmy Au",
      "Steven Hoi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11982"
  },
  {
    "id": "arXiv:2211.12111",
    "title": "Evaluation of MPC-based Imitation Learning for Human-like Autonomous  Driving",
    "abstract": "Comments: This work has been submitted to IFAC for possible publication. arXiv admin note: text overlap with arXiv:2206.12348",
    "descriptor": "\nComments: This work has been submitted to IFAC for possible publication. arXiv admin note: text overlap with arXiv:2206.12348\n",
    "authors": [
      "Flavia Sofia Acerbo",
      "Jan Swevers",
      "Tinne Tuytelaars",
      "Tong Duy Son"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.12111"
  },
  {
    "id": "arXiv:2211.12118",
    "title": "HaRiM$^+$: Evaluating Summary Quality with Hallucination Risk",
    "abstract": "Comments: 9 pages (+ 21 pages of Appendix), AACL 2022",
    "descriptor": "\nComments: 9 pages (+ 21 pages of Appendix), AACL 2022\n",
    "authors": [
      "Seonil Son",
      "Junsoo Park",
      "Jeong-in Hwang",
      "Junghwa Lee",
      "Hyungjong Noh",
      "Yeonsoo Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.12118"
  },
  {
    "id": "arXiv:2211.12139",
    "title": "City-Wide Perceptions of Neighbourhood Quality using Street View Images",
    "abstract": "City-Wide Perceptions of Neighbourhood Quality using Street View Images",
    "descriptor": "",
    "authors": [
      "Emily Muller",
      "Emily Gemmell",
      "Ishmam Choudhury",
      "Ricky Nathvani",
      "Antje Barbara Metzler",
      "James Bennett",
      "Emily Denton",
      "Seth Flaxman",
      "Majid Ezzati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.12139"
  },
  {
    "id": "arXiv:2211.12322",
    "title": "TranViT: An Integrated Vision Transformer Framework for Discrete Transit  Travel Time Range Prediction",
    "abstract": "Comments: Revised typographical errors, added more details to results and discussions",
    "descriptor": "\nComments: Revised typographical errors, added more details to results and discussions\n",
    "authors": [
      "Awad Abdelhalim",
      "Jinhua Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12322"
  },
  {
    "id": "arXiv:2211.12417",
    "title": "ProCC: Progressive Cross-primitive Consistency for Open-World  Compositional Zero-Shot Learning",
    "abstract": "ProCC: Progressive Cross-primitive Consistency for Open-World  Compositional Zero-Shot Learning",
    "descriptor": "",
    "authors": [
      "Fushuo Huo",
      "Wenchao Xu",
      "Song Guo",
      "Jingcai Guo",
      "Haozhao Wang",
      "Ziming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12417"
  },
  {
    "id": "arXiv:2211.12588",
    "title": "Program of Thoughts Prompting: Disentangling Computation from Reasoning  for Numerical Reasoning Tasks",
    "abstract": "Program of Thoughts Prompting: Disentangling Computation from Reasoning  for Numerical Reasoning Tasks",
    "descriptor": "",
    "authors": [
      "Wenhu Chen",
      "Xueguang Ma",
      "Xinyi Wang",
      "William W. Cohen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12588"
  },
  {
    "id": "arXiv:2211.12706",
    "title": "Quality Assurance in MLOps Setting: An Industrial Perspective",
    "abstract": "Comments: Accepted in ISE2022 of the 29th Asia-Pacific Software Engineering Conference (APSEC 2022)",
    "descriptor": "\nComments: Accepted in ISE2022 of the 29th Asia-Pacific Software Engineering Conference (APSEC 2022)\n",
    "authors": [
      "Ayan Chatterjee",
      "Bestoun S. Ahmed",
      "Erik Hallin",
      "Anton Engman"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12706"
  },
  {
    "id": "arXiv:2211.12748",
    "title": "Dynamic Appearance: A Video Representation for Action Recognition with  Joint Training",
    "abstract": "Dynamic Appearance: A Video Representation for Action Recognition with  Joint Training",
    "descriptor": "",
    "authors": [
      "Guoxi Huang",
      "Adrian G. Bors"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12748"
  },
  {
    "id": "arXiv:2211.12759",
    "title": "NAS-LID: Efficient Neural Architecture Search with Local Intrinsic  Dimension",
    "abstract": "Comments: Accepted by AAAI2023, AutoML, NAS",
    "descriptor": "\nComments: Accepted by AAAI2023, AutoML, NAS\n",
    "authors": [
      "Xin He",
      "Jiangchao Yao",
      "Yuxin Wang",
      "Zhenheng Tang",
      "Ka Chu Cheung",
      "Simon See",
      "Bo Han",
      "Xiaowen Chu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12759"
  },
  {
    "id": "arXiv:2211.12814",
    "title": "Vertical Federated Learning",
    "abstract": "Vertical Federated Learning",
    "descriptor": "",
    "authors": [
      "Yang Liu",
      "Yan Kang",
      "Tianyuan Zou",
      "Yanhong Pu",
      "Yuanqin He",
      "Xiaozhou Ye",
      "Ye Ouyang",
      "Ya-Qin Zhang",
      "Qiang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.12814"
  },
  {
    "id": "arXiv:2211.12833",
    "title": "Worst-Case to Expander-Case Reductions",
    "abstract": "Comments: ITCS 2023",
    "descriptor": "\nComments: ITCS 2023\n",
    "authors": [
      "Amir Abboud",
      "Nathan Wallheimer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.12833"
  },
  {
    "id": "arXiv:2211.12845",
    "title": "Superresolution Reconstruction of Single Image for Latent features",
    "abstract": "Superresolution Reconstruction of Single Image for Latent features",
    "descriptor": "",
    "authors": [
      "Xin Wang",
      "Jing-Ke Yan",
      "Jing-Ye Cai",
      "Jian-Hua Deng",
      "Qin Qin",
      "Qin Wang",
      "Heng Xiao",
      "Yao Cheng",
      "Peng-Fei Ye"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12845"
  },
  {
    "id": "arXiv:2211.12875",
    "title": "A Survey of Deep Graph Clustering: Taxonomy, Challenge, and Application",
    "abstract": "Comments: 13 pages, 13 figures",
    "descriptor": "\nComments: 13 pages, 13 figures\n",
    "authors": [
      "Yue Liu",
      "Jun Xia",
      "Sihang Zhou",
      "Siwei Wang",
      "Xifeng Guo",
      "Xihong Yang",
      "Ke Liang",
      "Wenxuan Tu",
      "Stan Z. Li",
      "Xinwang Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12875"
  },
  {
    "id": "arXiv:2211.12879",
    "title": "Data Augmentation Vision Transformer for Fine-grained Image  Classification",
    "abstract": "Comments: IEEE Signal Processing Letters",
    "descriptor": "\nComments: IEEE Signal Processing Letters\n",
    "authors": [
      "Chao Hu",
      "Liqiang Zhu",
      "Weibin Qiu",
      "Weijie Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12879"
  },
  {
    "id": "arXiv:2211.12934",
    "title": "Applying the Web of Things Abstraction to Bluetooth Low Energy  Communication",
    "abstract": "Comments: Accepted at Connected World Semantic Interoperability Workshop 2022, 8 pages",
    "descriptor": "\nComments: Accepted at Connected World Semantic Interoperability Workshop 2022, 8 pages\n",
    "authors": [
      "Michael Freund",
      "Rene Dorsch",
      "Andreas Harth"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.12934"
  },
  {
    "id": "arXiv:2211.12956",
    "title": "Reinforcement learning for traffic signal control in hybrid action space",
    "abstract": "Comments: There are serious problems with the innovation of the paper",
    "descriptor": "\nComments: There are serious problems with the innovation of the paper\n",
    "authors": [
      "Haoqing Luo",
      "sheng jin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12956"
  },
  {
    "id": "arXiv:2211.12979",
    "title": "FLAIR #1: semantic segmentation and domain adaptation dataset",
    "abstract": "FLAIR #1: semantic segmentation and domain adaptation dataset",
    "descriptor": "",
    "authors": [
      "Anatol Garioud",
      "St\u00e9phane Peillet",
      "Eva Bookjans",
      "S\u00e9bastien Giordano",
      "Boris Wattrelos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.12979"
  },
  {
    "id": "arXiv:2211.13006",
    "title": "Quantized Compressed Sensing with Score-Based Generative Models",
    "abstract": "Comments: 29 pages, code available at this https URL",
    "descriptor": "\nComments: 29 pages, code available at this https URL\n",
    "authors": [
      "Xiangming Meng",
      "Yoshiyuki Kabashima"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13006"
  },
  {
    "id": "arXiv:2211.13090",
    "title": "TransVCL: Attention-enhanced Video Copy Localization Network with  Flexible Supervision",
    "abstract": "Comments: Accepted by the Thirty-Seventh AAAI Conference on Artificial Intelligence(AAAI2023)",
    "descriptor": "\nComments: Accepted by the Thirty-Seventh AAAI Conference on Artificial Intelligence(AAAI2023)\n",
    "authors": [
      "Sifeng He",
      "Yue He",
      "Minlong Lu",
      "Chen Jiang",
      "Xudong Yang",
      "Feng Qian",
      "Xiaobo Zhang",
      "Lei Yang",
      "Jiandong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13090"
  },
  {
    "id": "arXiv:2211.13110",
    "title": "Compiler Provenance Recovery for Multi-CPU Architectures Using a  Centrifuge Mechanism",
    "abstract": "Comments: 8 pages, 4 figures, 5 tables",
    "descriptor": "\nComments: 8 pages, 4 figures, 5 tables\n",
    "authors": [
      "Yuhei Otsubo",
      "Akira Otsuka",
      "Mamoru Mimura"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.13110"
  },
  {
    "id": "arXiv:2211.13157",
    "title": "Physics-Informed Multi-Stage Deep Learning Framework Development for  Digital Twin-Centred State-Based Reactor Power Prediction",
    "abstract": "Physics-Informed Multi-Stage Deep Learning Framework Development for  Digital Twin-Centred State-Based Reactor Power Prediction",
    "descriptor": "",
    "authors": [
      "James Daniell",
      "Kazuma Kobayashi",
      "Susmita Naskar",
      "Dinesh Kumar",
      "Souvik Chakraborty",
      "Ayodeji Alajo",
      "Ethan Taber",
      "Joseph Graham",
      "Syed Alam"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.13157"
  },
  {
    "id": "arXiv:2211.13172",
    "title": "Kernel PCA for multivariate extremes",
    "abstract": "Kernel PCA for multivariate extremes",
    "descriptor": "",
    "authors": [
      "Marco Avella-Medina",
      "Richard A. Davis",
      "Gennady Samorodnitsky"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.13172"
  }
]
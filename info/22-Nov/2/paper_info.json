[
  {
    "id": "arXiv:2211.00002",
    "title": "A Self-Supervised Approach to Reconstruction in Sparse X-Ray Computed  Tomography",
    "abstract": "Computed tomography has propelled scientific advances in fields from biology\nto materials science. This technology allows for the elucidation of\n3-dimensional internal structure by the attenuation of x-rays through an object\nat different rotations relative to the beam. By imaging 2-dimensional\nprojections, a 3-dimensional object can be reconstructed through a\ncomputational algorithm. Imaging at a greater number of rotation angles allows\nfor improved reconstruction. However, taking more measurements increases the\nx-ray dose and may cause sample damage. Deep neural networks have been used to\ntransform sparse 2-D projection measurements to a 3-D reconstruction by\ntraining on a dataset of known similar objects. However, obtaining high-quality\nobject reconstructions for the training dataset requires high x-ray dose\nmeasurements that can destroy or alter the specimen before imaging is complete.\nThis becomes a chicken-and-egg problem: high-quality reconstructions cannot be\ngenerated without deep learning, and the deep neural network cannot be learned\nwithout the reconstructions. This work develops and validates a self-supervised\nprobabilistic deep learning technique, the physics-informed variational\nautoencoder, to solve this problem. A dataset consisting solely of sparse\nprojection measurements from each object is used to jointly reconstruct all\nobjects of the set. This approach has the potential to allow visualization of\nfragile samples with x-ray computed tomography. We release our code for\nreproducing our results at: https://github.com/vganapati/CT_PVAE .",
    "descriptor": "\nComments: NeurIPS 2022 Machine Learning and the Physical Sciences Workshop. arXiv admin note: text overlap with arXiv:2210.16709\n",
    "authors": [
      "Rey Mendoza",
      "Minh Nguyen",
      "Judith Weng Zhu",
      "Vincent Dumont",
      "Talita Perciano",
      "Juliane Mueller",
      "Vidya Ganapati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2211.00002"
  },
  {
    "id": "arXiv:2211.00005",
    "title": "Uncertainty-DTW for Time Series and Sequences",
    "abstract": "Dynamic Time Warping (DTW) is used for matching pairs of sequences and\ncelebrated in applications such as forecasting the evolution of time series,\nclustering time series or even matching sequence pairs in few-shot action\nrecognition. The transportation plan of DTW contains a set of paths; each path\nmatches frames between two sequences under a varying degree of time warping, to\naccount for varying temporal intra-class dynamics of actions. However, as DTW\nis the smallest distance among all paths, it may be affected by the feature\nuncertainty which varies across time steps/frames. Thus, in this paper, we\npropose to model the so-called aleatoric uncertainty of a differentiable (soft)\nversion of DTW. To this end, we model the heteroscedastic aleatoric uncertainty\nof each path by the product of likelihoods from Normal distributions, each\ncapturing variance of pair of frames. (The path distance is the sum of base\ndistances between features of pairs of frames of the path.) The Maximum\nLikelihood Estimation (MLE) applied to a path yields two terms: (i) a sum of\nEuclidean distances weighted by the variance inverse, and (ii) a sum of\nlog-variance regularization terms. Thus, our uncertainty-DTW is the smallest\nweighted path distance among all paths, and the regularization term (penalty\nfor the high uncertainty) is the aggregate of log-variances along the path. The\ndistance and the regularization term can be used in various objectives. We\nshowcase forecasting the evolution of time series, estimating the Fr\\'echet\nmean of time series, and supervised/unsupervised few-shot action recognition of\nthe articulated human 3D body joints.",
    "descriptor": "\nComments: Accepted as an oral paper at the 17th European Conference on Computer Vision (ECCV 2022). arXiv admin note: text overlap with arXiv:2210.16820\n",
    "authors": [
      "Lei Wang",
      "Piotr Koniusz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00005"
  },
  {
    "id": "arXiv:2211.00006",
    "title": "High-Level Event Mining: A Framework",
    "abstract": "Process mining methods often analyze processes in terms of the individual\nend-to-end process runs. Process behavior, however, may materialize as a\ngeneral state of many involved process components, which can not be captured by\nlooking at the individual process instances. A more holistic state of the\nprocess can be determined by looking at the events that occur close in time and\nshare common process capacities. In this work, we conceptualize such behavior\nusing high-level events and propose a new framework for detecting and logging\nsuch high-level events. The output of our method is a new high-level event log,\nwhich collects all generated high-level events together with the newly assigned\nevent attributes: activity, case, and timestamp. Existing process mining\ntechniques can then be applied on the produced high-level event log to obtain\nfurther insights. Experiments on both simulated and real-life event data show\nthat our method is able to automatically discover how system-level patterns\nsuch as high traffic and workload emerge, propagate and dissolve throughout the\nprocess.",
    "descriptor": "",
    "authors": [
      "Bianka Bakullari",
      "Wil M.P. van der Aalst"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.00006"
  },
  {
    "id": "arXiv:2211.00007",
    "title": "Maximizing Quality and Minimizing Cost for VCPS in ISAC-Based Vehicular  Networks: A Deep Reinforcement Learning Approach",
    "abstract": "With the continued development of beyond 5G and 6G networks, integrated\nsensing and communication (ISAC) is emerging as a critical technology to\nrealize various intelligent transportation systems (ITSs), such as vehicular\ncyber-physical systems (VCPSs). In ISAC-based vehicular networks, logical view\nconstructions based on heterogeneous information sensing and uploading are\ncritical to the realization of VCPS. However, a higher-quality view (i.e., more\nreal-time and accurate) may require more frequent or redundant sensing and\nuploading. This paper makes the first attempt to maximize the quality and\nminimize the cost of the VCPS modeling in ISAC-based vehicular networks. We\nderive an information sensing model based on multi-class M/G/1 priority queue\nand a data uploading model based on reliability-guaranteed V2I communications.\nOn this basis, we design two metrics, namely, age of view (AoV) and cost of\nview (CoV). Then, we formulate an optimization problem to maximize the AoV and\nminimize the CoV. Further, we propose a distributed distributional deep\ndeterministic policy gradient (D4PG) solution implemented in the roadside units\n(RSUs), which determine the actions on sensing information, frequency,\nuploading priority, transmission power, and V2I bandwidth jointly. Finally, we\nbuild a simulation model and give a comprehensive performance evaluation, and\nthe simulation results conclusively demonstrate the superiority of the proposed\nsolution.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2209.12265, arXiv:2210.17386\n",
    "authors": [
      "Xincao Xu",
      "Kai Liu",
      "Penglin Dai",
      "Hao Zhang",
      "Ke Xiao"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.00007"
  },
  {
    "id": "arXiv:2211.00046",
    "title": "Very Low Resource Sentence Alignment: Luhya and Swahili",
    "abstract": "Language-agnostic sentence embeddings generated by pre-trained models such as\nLASER and LaBSE are attractive options for mining large datasets to produce\nparallel corpora for low-resource machine translation. We test LASER and LaBSE\nin extracting bitext for two related low-resource African languages: Luhya and\nSwahili. For this work, we created a new parallel set of nearly 8000\nLuhya-English sentences which allows a new zero-shot test of LASER and LaBSE.\nWe find that LaBSE significantly outperforms LASER on both languages. Both\nLASER and LaBSE however perform poorly at zero-shot alignment on Luhya,\nachieving just 1.5% and 22.0% successful alignments respectively (P@1 score).\nWe fine-tune the embeddings on a small set of parallel Luhya sentences and show\nsignificant gains, improving the LaBSE alignment accuracy to 53.3%. Further,\nrestricting the dataset to sentence embedding pairs with cosine similarity\nabove 0.7 yielded alignments with over 85% accuracy.",
    "descriptor": "\nComments: Accepted to LoResMT 2022\n",
    "authors": [
      "Everlyn Asiko Chimoto",
      "Bruce A. Bassett"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.00046"
  },
  {
    "id": "arXiv:2211.00053",
    "title": "Generating Sequences by Learning to Self-Correct",
    "abstract": "Sequence generation applications require satisfying semantic constraints,\nsuch as ensuring that programs are correct, using certain keywords, or avoiding\nundesirable content. Language models, whether fine-tuned or prompted with\nfew-shot demonstrations, frequently violate these constraints, and lack a\nmechanism to iteratively revise their outputs. Moreover, some powerful language\nmodels are of extreme scale or inaccessible, making it inefficient, if not\ninfeasible, to update their parameters for task-specific adaptation. We present\nSelf-Correction, an approach that decouples an imperfect base generator (an\noff-the-shelf language model or supervised sequence-to-sequence model) from a\nseparate corrector that learns to iteratively correct imperfect generations. To\ntrain the corrector, we propose an online training procedure that can use\neither scalar or natural language feedback on intermediate imperfect\ngenerations. We show that Self-Correction improves upon the base generator in\nthree diverse generation tasks - mathematical program synthesis,\nlexically-constrained generation, and toxicity control - even when the\ncorrector is much smaller than the base generator.",
    "descriptor": "",
    "authors": [
      "Sean Welleck",
      "Ximing Lu",
      "Peter West",
      "Faeze Brahman",
      "Tianxiao Shen",
      "Daniel Khashabi",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.00053"
  },
  {
    "id": "arXiv:2211.00056",
    "title": "How fair were COVID-19 restriction decisions? A data-driven  investigation of England using the dominance-based rough sets approach",
    "abstract": "During the COVID-19 pandemic, several countries have taken the approach of\ntiered restrictions which has remained a point of debate due to a lack of\ntransparency. Using the dominance-based rough set approach, we identify\npatterns in the COVID-19 data pertaining to the UK government's tiered\nrestrictions allocation system. These insights from the analysis are translated\ninto \"if-then\" type rules, which can easily be interpreted by policy makers.\nThe differences in the rules extracted from different geographical areas\nsuggest inconsistencies in the allocations of tiers in these areas. We found\nthat the differences delineated an overall north south divide in England,\nhowever, this divide was driven mostly by London. Based on our analysis, we\ndemonstrate the usefulness of the dominance-based rough sets approach for\ninvestigating the fairness and explainabilty of decision making regarding\nCOVID-19 restrictions. The proposed approach and analysis could provide a more\ntransparent approach to localised public health restrictions, which can help\nensure greater conformity to the public safety rules.",
    "descriptor": "",
    "authors": [
      "Edward Abel",
      "Sajid Siraj"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00056"
  },
  {
    "id": "arXiv:2211.00057",
    "title": "New and emerging forms of data and technologies: literature and  bibliometric review",
    "abstract": "With the increased digitalisation of our society, new and emerging forms of\ndata present new values and opportunities for improved data driven multimedia\nservices, or even new solutions for managing future global pandemics (i.e.,\nDisease X). The results are somewhat unexpected. Despite the special\nrelationship between the US and the UK, there is not much evidence of\ncollaboration in research on this topic. Similarly, despite the negative media\npublicity on the current relationship between the US and China (and the US\nsanctions on China), the research on this topic seems to be growing strong.\nHowever, it would be interesting to repeat this exercise after a few years and\ncompare the results. It is possible that the effect of the current US sanctions\non China has not taken its full effect yet.",
    "descriptor": "\nComments: Multimed Tools Appl (2022)\n",
    "authors": [
      "Petar Radanliev",
      "David De Roure"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.00057"
  },
  {
    "id": "arXiv:2211.00058",
    "title": "Semantic Web in Healthcare: A Systematic Literature Review of  Application, Research Gap, and Future Research Avenues",
    "abstract": "Today, healthcare has become one of the largest and most fast-paced\nindustries due to the rapid development of digital healthcare technologies. The\nfundamental thing to enhance healthcare services is communicating and linking\nmassive volumes of available healthcare data. However, the key challenge in\nreaching this ambitious goal is letting the information exchange across\nheterogeneous sources and methods as well as establishing efficient tools and\ntechniques. Semantic Web (SW) technology can help to tackle these problems.\nThey can enhance knowledge exchange, information management, data\ninteroperability, and decision support in healthcare systems. They can also be\nutilized to create various e-healthcare systems that aid medical practitioners\nin making decisions and provide patients with crucial medical information and\nautomated hospital services. This systematic literature review (SLR) on SW in\nhealthcare systems aims to assess and critique previous findings while adhering\nto appropriate research procedures. We looked at 65 papers and came up with\nfive themes: e-service, disease, information management, frontier technology,\nand regulatory conditions. In each thematic research area, we presented the\ncontributions of previous literature. We emphasized the topic by responding to\nfive specific research questions. We have finished the SLR study by identifying\nresearch gaps and establishing future research goals that will help to minimize\nthe difficulty of adopting SW in healthcare systems and provide new approaches\nfor SW-based medical systems progress.",
    "descriptor": "\nComments: 27 Pages\n",
    "authors": [
      "A. K. M. Bahalul Haque",
      "B. M. Arifuzzaman",
      "Sayed Abu Noman Siddik",
      "Abul Kalam",
      "Tabassum Sadia Shahjahan",
      "T. S. Saleena",
      "Morshed Alam",
      "Md. Rabiul Islam",
      "Foyez Ahmmed",
      "5and Md. Jamal Hossain"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.00058"
  },
  {
    "id": "arXiv:2211.00061",
    "title": "Discrete-Event Simulation in Healthcare Settings: a Review",
    "abstract": "We review and define the current state of the art as relating to discrete\nevent simulation in healthcare-related systems. A review of published\nliterature over the past five years (2017 - 2021) was conducted, building upon\npreviously published work. PubMed and EBSCOhost were searched for journal\narticles on discrete event simulation in healthcare resulting in identification\nof 933 unique articles. Of these about half were excluded at the title/abstract\nlevel and 154 at the full text level, leaving 311 papers to analyze. These were\ncategorized, then analyzed by category and collectively to identify publication\nvolume over time, disease focus, activity levels by coun-try, software systems\nused, and sizes of healthcare unit under study. A total of 1196 articles were\ninitially identified. This list was narrowed down to 311 for systematic review.\nFollowing the schema from prior systematic reviews, the articles fell into four\nbroad categories: health care sys-tems operations (HCSO), disease progression\nmodeling (DPM), screening modeling (SM), and health behavior modeling (HBM). We\nfound that discrete event simulation in healthcare has con-tinued to increase\nyear-over-year, as well as expand into diverse areas of the healthcare system.\nIn addition, this study adds extra bibliometric dimensions to gain more insight\ninto the details and nuances of how and where simulation is being used in\nhealthcare.",
    "descriptor": "\nComments: Preprint of the article\n",
    "authors": [
      "John J. Forbus",
      "Daniel Berleant"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.00061"
  },
  {
    "id": "arXiv:2211.00062",
    "title": "Technology and COVID-19: How Reliant is Society on Technology?",
    "abstract": "Social media and messaging platforms have become a support system for those\nin fear of COVID-19 while, at the same time, becoming the root cause of\nspreading hate, inaccurate representations, and false realities. As technology\nhas morphed into a commodity for daily tasks and actions, this article may be\nuseful for people of all ages and backgrounds who are interested in\nunderstanding the impact of technology on society.",
    "descriptor": "",
    "authors": [
      "Afsana Rahman",
      "Dr. Ruhul Amin"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.00062"
  },
  {
    "id": "arXiv:2211.00063",
    "title": "Rogue Protocol: A Framework For NFT Royalties Tokenisation",
    "abstract": "The crypto ecosystem has evolved into a formidable channel for raising\nventure capital. Each new wave of capital inflows has been epitomized by a new\ntype of investment vehicle, may it be ICOs, DAOs, or NFTs. Regrettably, none of\nthese paradigms tried to address the issue of investor protection, a pillar of\nefficient capital markets. Moreover, very few projects tried to generate\neconomic revenue, focusing instead on marketing alone to attract new investors.\nWithout revenues, price discovery was impossible, while investors were left\nwithout any protection against rug pulls. This has forced regulators to take a\nhard-line approach to the ecosystem, and rule that certain tokens are\nsecurities when they are not intended to be. Regulators have left the door open\nto cryptocurrencies with truly decentralised activity like Ethereum, most\nnotably the SEC in its interpretation of the Howey test for digital assets. We\nbelieve that a great number of decentralised projects could benefit from this\nregulatory exception. A system where project revenue is automatically directed\nto a treasury pool, and the price of tokens is computed following a\npredetermined bonding curve, would allow to efficiently raise capital, while\ninvestors would have automatic guarantees of fair participation in the success\nof the project. Such a framework would incentivise founders to design\ndecentralised projects that create value instead of hype, while making the\napplication of securities laws less stringent or even needed. NFT royalties in\nparticular are an example of decentralised economic activity that generates\ncash flows, used to back the value of associated tokens. We propose a\ncryptographic system that ties the price of tokens to the success of a\ndecentralised activity, guarantees the fair distribution of tokens, and rewards\nfounders and participants in the system in line with the amount of risk they\nare taking.",
    "descriptor": "",
    "authors": [
      "\u0160ar\u016bnas Barauskas",
      "Roberto Ripamonti",
      "Emanuele Ragnoli"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.00063"
  },
  {
    "id": "arXiv:2211.00065",
    "title": "Artificial Intelligence and Arms Control",
    "abstract": "Potential advancements in artificial intelligence (AI) could have profound\nimplications for how countries research and develop weapons systems, and how\nmilitaries deploy those systems on the battlefield. The idea of AI-enabled\nmilitary systems has motivated some activists to call for restrictions or bans\non some weapon systems, while others have argued that AI may be too diffuse to\ncontrol. This paper argues that while a ban on all military applications of AI\nis likely infeasible, there may be specific cases where arms control is\npossible. Throughout history, the international community has attempted to ban\nor regulate weapons or military systems for a variety of reasons. This paper\nanalyzes both successes and failures and offers several criteria that seem to\ninfluence why arms control works in some cases and not others. We argue that\nsuccess or failure depends on the desirability (i.e., a weapon's military value\nversus its perceived horribleness) and feasibility (i.e., sociopolitical\nfactors that influence its success) of arms control. Based on these criteria,\nand the historical record of past attempts at arms control, we analyze the\npotential for AI arms control in the future and offer recommendations for what\npolicymakers can do today.",
    "descriptor": "\nComments: 81 pages, 1 figure, 2 tables\n",
    "authors": [
      "Paul Scharre",
      "Megan Lamberth"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00065"
  },
  {
    "id": "arXiv:2211.00067",
    "title": "COVID-19 Infection Exposure to Customers Shopping during Black Friday",
    "abstract": "The outbreak of COVID-19 within the last two years has resulted in much\nfurther investigation into the safety of large events that involve a gathering\nof people. This study aims to investigate how COVID-19 can spread through a\nlarge crowd of people shopping in a store with no safety precautions taken. The\nevent being investigated is Black Friday, where hundreds or thousands of\ncustomers flood stores to hopefully receive the best deals on popular items. A\nmock store was created, separated into several different shopping sections, and\nrepresented using a 2-D grid where each square on the grid represented a 5 feet\nby 5 feet area of the mock store. Customers were simulated to enter the store,\nshop for certain items, check out, and then leave the store. A percentage of\ncustomers were chosen to be infective when they entered the store, which means\nthat they could spread infection quantum to other customers. Four hours of time\nwas simulated with around 6,000 customers being included. The maximum distance\nexposure could be spread (2 feet-10 feet), the minimum time of exposure needed\nto become infected (2 - 15 minutes), and the total percentage of customers who\nstarted as infective (1% - 5%) were all changed and their effects on the number\nof newly infected customers were measured. It was found that increasing the\nmaximum exposure distance by 2 feet resulted in between a 20% to 250% increase\nin newly infected customers, depending on the distances being used. It was also\nfound that increasing the percentage of customers who started as infective from\n1% to 2% and then to 5% resulted in a 200% to 300% increase in newly infected\ncustomers.",
    "descriptor": "\nComments: 22 pages, 11 tables, and 8 figures\n",
    "authors": [
      "Braxton Rolle",
      "Ravi Kiran"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.00067"
  },
  {
    "id": "arXiv:2211.00069",
    "title": "AI Explainability and Governance in Smart Energy Systems: A Review",
    "abstract": "Traditional electrical power grids have long suffered from operational\nunreliability, instability, inflexibility, and inefficiency. Smart grids (or\nsmart energy systems) continue to transform the energy sector with emerging\ntechnologies, renewable energy sources, and other trends. Artificial\nintelligence (AI) is being applied to smart energy systems to process massive\nand complex data in this sector and make smart and timely decisions. However,\nthe lack of explainability and governability of AI is a major concern for\nstakeholders hindering a fast uptake of AI in the energy sector. This paper\nprovides a review of AI explainability and governance in smart energy systems.\nWe collect 3,568 relevant papers from the Scopus database, automatically\ndiscover 15 parameters or themes for AI governance in energy and elaborate the\nresearch landscape by reviewing over 100 papers and providing temporal\nprogressions of the research. The methodology for discovering parameters or\nthemes is based on \"deep journalism\", our data-driven deep learning-based big\ndata analytics approach to automatically discover and analyse cross-sectional\nmulti-perspective information to enable better decision-making and develop\nbetter instruments for governance. The findings show that research on AI\nexplainability in energy systems is segmented and narrowly focussed on a few AI\ntraits and energy system problems. This paper deepens our knowledge of AI\ngovernance in energy and is expected to help governments, industry, academics,\nenergy prosumers, and other stakeholders to understand the landscape of AI in\nthe energy sector, leading to better design, operations, utilisation, and risk\nmanagement of energy systems.",
    "descriptor": "\nComments: 20 pages, 1 table, 1 figure, submitted to a journal, under review (the paper is short due to journal limits on words, figures, tables, etc.)\n",
    "authors": [
      "Roba Alsaigh",
      "Rashid Mehmood",
      "Iyad Katib"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00069"
  },
  {
    "id": "arXiv:2211.00071",
    "title": "CarbonTag: A browser-based method for approximating energy consumption  of online ads",
    "abstract": "Energy is today the most critical environmental challenge. The amount of\ncarbon emissions contributing to climate change is significantly influenced by\nboth the production and consumption of energy. Measuring and reducing the\nenergy consumption of services is a crucial step toward reducing adverse\nenvironmental effects caused by carbon emissions. Millions of websites rely on\nonline advertisements to generate revenue, with most websites earning most or\nall of their revenues from ads. As a result, hundreds of billions of online ads\nare delivered daily to internet users to be rendered in their browsers. Both\nthe delivery and rendering of each ad consume energy. This study investigates\nhow much energy online ads use and offers a way for predicting it as part of\nrendering the ad. To the best of the authors' knowledge, this is the first\nstudy to calculate the energy usage of single advertisements. Our research\nfurther introduces different levels of consumption by which online ads can be\nclassified based on energy efficiency. This classification will allow\nadvertisers to add energy efficiency metrics and optimize campaigns towards\nconsuming less possible.",
    "descriptor": "",
    "authors": [
      "Jos\u00e9 Gonz\u00e1lez Caba\u00f1as",
      "Patricia Callejo",
      "Rub\u00e9n Cuevas",
      "Steffen Svatberg",
      "Tommy Torjesen",
      "\u00c1ngel Cuevas",
      "Antonio Pastor",
      "Mikko Kotila"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00071"
  },
  {
    "id": "arXiv:2211.00072",
    "title": "Secure Web-Based Student Information Management System",
    "abstract": "The reliability and success of any organization such as academic institution\nrely on its ability to provide secure, accurate and timely data about its\noperations. Erstwhile managing student information in academic institution was\ndone through paper-based information system, where academic records are\ndocumented in several files that are kept in shelves. Several problems are\nassociated with paper-based information system. Managing information through\nthe manual approach require physical exertion to retrieve, alter, and re-file\nthe paper records. These are nonvalue added services results in data\ninconsistency and redundancy, currently institutions have migrated to web-based\nstudent information management system without considering the security\narchitecture of the web portal. This project seeks to ameliorates and secure\nhow information is being managed in Nigeria Police Academy through the\ndevelopment of a secured web-based student information management system, which\nhas a friendly user interface that provides an easy and secure way to manage\nacademic information such as students information, staff information, course\nregistration, course materials and results. This project was developed using\nLaravel 5.5 PHP Framework to provide a robust secure web-based student\ninformation system that is not vulnerable to 2018 OWASP TOP 10 web\nvulnerabilities.",
    "descriptor": "",
    "authors": [
      "Oluwatosin Samuel Falebita"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.00072"
  },
  {
    "id": "arXiv:2211.00073",
    "title": "Digital divide among the States of Mexico: a comparison 2010-2020",
    "abstract": "Digital divide is one of the challenges that open government must face in\nmid- and low-income countries. In these contexts, inhabitants are left out of\nthe benefits of information and communication technology (ICT), such as online\ngovernment services. The present scenario that has emerged from the COVID-19\npandemic offers opportunities and challenges in ICT access and use to current\nand potential users all over the world. Therefore, it is important to know the\nadvancement in digital inclusion in the recent years, particularly regarding\nthe consumption and use of ICT goods and services. Thus, this article analyzes\nthe Mexican case by comparing the availability of ICT in households of the\nstates between the years 2010 and 2020. Open data from the Mexican Censuses of\nthese two years are used to produce these analyses. The results suggest that\ninequalities prevail between South and Southeast states compared to Center and\nNorth states, and that cell telephone availability has increased, fostering\nInternet access.",
    "descriptor": "\nComments: 15 pages, 7 figures\n",
    "authors": [
      "Sergio R. Coria",
      "Luz M. Garcia-Garcia"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.00073"
  },
  {
    "id": "arXiv:2211.00074",
    "title": "IoT-based Efficient Streetlight Controlling, Monitoring and Real-time  Error Detection System in Major Bangladeshi Cities",
    "abstract": "A huge wastage of electricity can be seen in Bangladesh due to improper\nstreet light management which leads to an enormous financial loss every year.\nMany noteworthy works have been done by researchers from different parts of the\nworld in tackling this issue by using the Internet of Things yet very few in\nBangladeshi perspective. In this work, we propose an efficient Internet of\nThings-based integrated streetlight framework that offers cloud-powered\nmonitoring, controlling through light dimming as per external lighting\nconditions and traffic detection, as well as a fault-detecting system to ensure\nlow power and electricity consumption. We analyzed data from Dhaka North and\nSouth City Corporation, Narayanganj City Corporation, and Chattogram City\nCorporation where our proposed model demonstrates a reduction in energy cost of\nup to approximately 60 percent more than that of the existing system.",
    "descriptor": "",
    "authors": [
      "A.T.M Mustafa Masud Chowdhury",
      "Jeenat Sultana",
      "Md Sakib Ullah Sourav"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.00074"
  },
  {
    "id": "arXiv:2211.00075",
    "title": "Automated Gender Bias Evaluation in YouTube",
    "abstract": "Students are increasingly using online materials to learn new subjects or to\nsupplement their learning process in educational institutions. Issues regarding\ngender bias have been raised in the context of formal education and some\nmeasures have been proposed to mitigate them. In our previous work, we\ninvestigate the perceived gender bias in YouTube using manually annotations for\ndetecting the narrators' perceived gender in educational videos. In this work,\nour goal is to evaluate the perceived gender bias in online education by\nexploiting an automated annotations. The automated pipeline has already\nproposed in a recent paper, thus in this paper we only share our empirical\nresults with important findings. Our results show that educational videos are\nbiased towards the male and STEM-related videos are more biased than their\nNON-STEM counterparts.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2210.10517\n",
    "authors": [
      "Gizem Gezici"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00075"
  },
  {
    "id": "arXiv:2211.00077",
    "title": "Optimizing Closed-Loop Performance with Data from Similar Systems: A  Bayesian Meta-Learning Approach",
    "abstract": "Bayesian optimization (BO) has demonstrated potential for optimizing control\nperformance in data-limited settings, especially for systems with unknown\ndynamics or unmodeled performance objectives. The BO algorithm efficiently\ntrades-off exploration and exploitation by leveraging uncertainty estimates\nusing surrogate models. These surrogates are usually learned using data\ncollected from the target dynamical system to be optimized. Intuitively, the\nconvergence rate of BO is better for surrogate models that can accurately\npredict the target system performance. In classical BO, initial surrogate\nmodels are constructed using very limited data points, and therefore rarely\nyield accurate predictions of system performance. In this paper, we propose the\nuse of meta-learning to generate an initial surrogate model based on data\ncollected from performance optimization tasks performed on a variety of systems\nthat are different to the target system. To this end, we employ deep kernel\nnetworks (DKNs) which are simple to train and which comprise encoded Gaussian\nprocess models that integrate seamlessly with classical BO. The effectiveness\nof our proposed DKN-BO approach for speeding up control system performance\noptimization is demonstrated using a well-studied nonlinear system with unknown\ndynamics and an unmodeled performance function.",
    "descriptor": "\nComments: To appear in the Proceedings of the 61st IEEE Conference on Decision and Control\n",
    "authors": [
      "Ankush Chakrabarty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.00077"
  },
  {
    "id": "arXiv:2211.00080",
    "title": "Denoising neural networks for magnetic resonance spectroscopy",
    "abstract": "In many scientific applications, measured time series are corrupted by noise\nor distortions. Traditional denoising techniques often fail to recover the\nsignal of interest, particularly when the signal-to-noise ratio is low or when\ncertain assumptions on the signal and noise are violated. In this work, we\ndemonstrate that deep learning-based denoising methods can outperform\ntraditional techniques while exhibiting greater robustness to variation in\nnoise and signal characteristics. Our motivating example is magnetic resonance\nspectroscopy, in which a primary goal is to detect the presence of\nshort-duration, low-amplitude radio frequency signals that are often obscured\nby strong interference that can be difficult to separate from the signal using\ntraditional methods. We explore various deep learning architecture choices to\ncapture the inherently complex-valued nature of magnetic resonance signals. On\nboth synthetic and experimental data, we show that our deep learning-based\napproaches can exceed performance of traditional techniques, providing a\npowerful new class of methods for analysis of scientific time series data.",
    "descriptor": "\nComments: 5 pages with appendix\n",
    "authors": [
      "Natalie Klein",
      "Amber J. Day",
      "Harris Mason",
      "Michael W. Malone",
      "Sinead A. Williamson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.00080"
  },
  {
    "id": "arXiv:2211.00082",
    "title": "Spatial-Temporal Synchronous Graph Transformer network (STSGT) for  COVID-19 forecasting",
    "abstract": "COVID-19 has become a matter of serious concern over the last few years. It\nhas adversely affected numerous people around the globe and has led to the loss\nof billions of dollars of business capital. In this paper, we propose a novel\nSpatial-Temporal Synchronous Graph Transformer network (STSGT) to capture the\ncomplex spatial and temporal dependency of the COVID-19 time series data and\nforecast the future status of an evolving pandemic. The layers of STSGT combine\nthe graph convolution network (GCN) with the self-attention mechanism of\ntransformers on a synchronous spatial-temporal graph to capture the dynamically\nchanging pattern of the COVID time series. The spatial-temporal synchronous\ngraph simultaneously captures the spatial and temporal dependencies between the\nvertices of the graph at a given and subsequent time-steps, which helps capture\nthe heterogeneity in the time series and improve the forecasting accuracy. Our\nextensive experiments on two publicly available real-world COVID-19 time series\ndatasets demonstrate that STSGT significantly outperforms state-of-the-art\nalgorithms that were designed for spatial-temporal forecasting tasks.\nSpecifically, on average over a 12-day horizon, we observe a potential\nimprovement of 12.19% and 3.42% in Mean Absolute Error(MAE) over the next best\nalgorithm while forecasting the daily infected and death cases respectively for\nthe 50 states of US and Washington, D.C. Additionally, STSGT also outperformed\nothers when forecasting the daily infected cases at the state level, e.g., for\nall the counties in the State of Michigan. The code and models are publicly\navailable at https://github.com/soumbane/STSGT.",
    "descriptor": "\nComments: 11 pages, 8 figures, 5 tables, accepted for CHASE 2022 conference and Smart Health journal\n",
    "authors": [
      "Soumyanil Banerjee",
      "Ming Dong",
      "Weisong Shi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00082"
  },
  {
    "id": "arXiv:2211.00083",
    "title": "WHEN FLUE MEETS FLANG: Benchmarks and Large Pre-trained Language Model  for Financial Domain",
    "abstract": "Pre-trained language models have shown impressive performance on a variety of\ntasks and domains. Previous research on financial language models usually\nemploys a generic training scheme to train standard model architectures,\nwithout completely leveraging the richness of the financial data. We propose a\nnovel domain specific Financial LANGuage model (FLANG) which uses financial\nkeywords and phrases for better masking, together with span boundary objective\nand in-filing objective. Additionally, the evaluation benchmarks in the field\nhave been limited. To this end, we contribute the Financial Language\nUnderstanding Evaluation (FLUE), an open-source comprehensive suite of\nbenchmarks for the financial domain. These include new benchmarks across 5 NLP\ntasks in financial domain as well as common benchmarks used in the previous\nresearch. Experiments on these benchmarks suggest that our model outperforms\nthose in prior literature on a variety of NLP tasks. Our models, code and\nbenchmark data are publicly available on Github and Huggingface.",
    "descriptor": "",
    "authors": [
      "Raj Sanjay Shah",
      "Kunal Chawla",
      "Dheeraj Eidnani",
      "Agam Shah",
      "Wendi Du",
      "Sudheer Chava",
      "Natraj Raman",
      "Charese Smiley",
      "Jiaao Chen",
      "Diyi Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00083"
  },
  {
    "id": "arXiv:2211.00084",
    "title": "An explicit exponential time integrator based on Faber polynomials and  its application to seismic wave modelling",
    "abstract": "Exponential time integrators have been applied successfully in several\nphysics-related differential equations. However, their application in\nhyperbolic systems with absorbing boundaries, like the ones arising in seismic\nimaging, still lacks theoretical and experimental investigations. The present\nwork conducts an in-depth study of exponential integration using Faber\npolynomials, consisting of a generalization of a popular exponential method\nthat uses Chebyshev polynomials. This allows solving non-symmetric operators\nthat emerge from classic seismic wave propagation problems with absorbing\nboundaries. Theoretical as well as numerical results are presented for Faber\napproximations. One of the theoretical contributions is the proposal of a sharp\nbound for the approximation error of the exponential of a normal matrix. We\nalso show the practical importance of determining an optimal ellipse\nencompassing the full spectrum of the discrete operator, in order to ensure and\nenhance convergence of the Faber exponential series. Furthermore, based on\nestimates of the spectrum of the discrete operator of the wave equations with a\nwidely used absorbing boundary method, we numerically investigate stability,\ndispersion, convergence and computational efficiency of the Faber exponential\nscheme. Overall, we conclude that the method is suitable for seismic wave\nproblems and can provide accurate results with large time step sizes, with\ncomputational efficiency increasing with the increase of the approximation\ndegree.",
    "descriptor": "\nComments: 30 pages, 55 figure, original research. Keywords: Exponential integrator, Faber polynomial, Wave equation, Absorbing boundaries, Eigenvalue distribution\n",
    "authors": [
      "Fernando V. Ravelo",
      "Pedro S. Peixoto",
      "Martin Schreiber"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.00084"
  },
  {
    "id": "arXiv:2211.00086",
    "title": "Disentangled (Un)Controllable Features",
    "abstract": "In the context of MDPs with high-dimensional states, reinforcement learning\ncan achieve better results when using a compressed, low-dimensional\nrepresentation of the original input space. A variety of learning objectives\nhave therefore been used to learn useful representations. However, these\nrepresentations usually lack interpretability of the different features. We\npropose a representation learning algorithm that is able to disentangle latent\nfeatures into a controllable and an uncontrollable part. The resulting\nrepresentations are easily interpretable and can be used for learning and\nplanning efficiently by leveraging the specific properties of the two parts. To\nhighlight the benefits of the approach, the disentangling properties of the\nalgorithm are illustrated in three different environments.",
    "descriptor": "\nComments: 14 pages (9 main paper pages), 9 figures\n",
    "authors": [
      "Jacob E. Kooi",
      "Mark Hoogendoorn",
      "Vincent Fran\u00e7ois-Lavet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00086"
  },
  {
    "id": "arXiv:2211.00091",
    "title": "Road Damages Detection and Classification with YOLOv7",
    "abstract": "Maintaining the roadway infrastructure is one of the essential factors in\nenabling a safe, economic, and sustainable transportation system. Manual\nroadway damage data collection is laborious and unsafe for humans to perform.\nThis area is poised to benefit from the rapid advance and diffusion of\nartificial intelligence technologies. Specifically, deep learning advancements\nenable the detection of road damages automatically from the collected road\nimages. This work proposes to collect and label road damage data using Google\nStreet View and use YOLOv7 (You Only Look Once version 7) together with\ncoordinate attention and related accuracy fine-tuning techniques such as label\nsmoothing and ensemble method to train deep learning models for automatic road\ndamage detection and classification. The proposed approaches are applied to the\nCrowdsensing-based Road Damage Detection Challenge (CRDDC2022), IEEE BigData\n2022. The results show that the data collection from Google Street View is\nefficient, and the proposed deep learning approach results in F1 scores of\n81.7% on the road damage data collected from the United States using Google\nStreet View and 74.1% on all test images of this dataset.",
    "descriptor": "\nComments: 8 pages, 5 tables, 9 figures, 17 references\n",
    "authors": [
      "Vung Pham",
      "Du Nguyen",
      "Christopher Donan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00091"
  },
  {
    "id": "arXiv:2211.00094",
    "title": "RIS-enhanced Resilience in Cell-Free MIMO",
    "abstract": "More and more applications that require high reliability and fault tolerance\nare realized with wireless network architectures and thus ultimately rely on\nthe wireless channels, which can be subject to impairments and blockages.\nHence, these architectures require a backup plan in the physical layer in order\nto guarantee functionality, especially when safety-relevant aspects are\ninvolved. To this end, this work proposes to utilize the reconfigurable\nintelligent surface (RIS) as a resilience mechanism to counteract outages. The\nadvantages of RISs for such a purpose derive from their inherent addition of\nalternative channel links in combination with their reconfigurability. The\nmajor benefits are investigated in a cell-free multiple-input and\nmultiple-output (MIMO) setting, in which the direct channel paths are subject\nto blockages. An optimization problem is formulated that includes rate\nallocation with beamforming and phase shift configuration and is solved with a\nresilience-aware alternating optimization approach. Numerical results show that\ndeploying even a randomly-configured RIS to a network reduces the performance\ndegradation caused by blockages. This becomes even more pronounced in the\noptimized case, in which the RIS is able to potentially counteract the\nperformance degradation entirely. Interestingly, adding more reflecting\nelements to the system brings an overall benefit for the resilience, even for\ntime-sensitive systems, due to the contribution of the RIS reflections, even\nwhen unoptimized.",
    "descriptor": "\nComments: 6 pages, 6 figures, submitted to International ITG 26th Workshop on Smart Antennas and 13th Conference on Systems, Communications, and Coding (WSA&SCC2023)\n",
    "authors": [
      "Kevin Weinberger",
      "Robert-Jeron Reifert",
      "Aydin Sezgin",
      "Ertugrul Basar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.00094"
  },
  {
    "id": "arXiv:2211.00098",
    "title": "Synthetic ID Card Image Generation for Improving Presentation Attack  Detection",
    "abstract": "Currently, it is ever more common to access online services for activities\nwhich formerly required physical attendance. From banking operations to visa\napplications, a significant number of processes have been digitised, especially\nsince the advent of the COVID-19 pandemic, requiring remote biometric\nauthentication of the user. On the downside, some subjects intend to interfere\nwith the normal operation of remote systems for personal profit by using fake\nidentity documents, such as passports and ID cards. Deep learning solutions to\ndetect such frauds have been presented in the literature. However, due to\nprivacy concerns and the sensitive nature of personal identity documents,\ndeveloping a dataset with the necessary number of examples for training deep\nneural networks is challenging. This work explores three methods for\nsynthetically generating ID card images to increase the amount of data while\ntraining fraud-detection networks. These methods include computer vision\nalgorithms and Generative Adversarial Networks. Our results indicate that\ndatabases can be supplemented with synthetic images without any loss in\nperformance for the print/scan Presentation Attack Instrument Species (PAIS)\nand a loss in performance of 1% for the screen capture PAIS.",
    "descriptor": "",
    "authors": [
      "Daniel Benalcazar",
      "Juan E. Tapia",
      "Sebastian Gonzalez",
      "Christoph Busch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.00098"
  },
  {
    "id": "arXiv:2211.00099",
    "title": "UmeTrack: Unified multi-view end-to-end hand tracking for VR",
    "abstract": "Real-time tracking of 3D hand pose in world space is a challenging problem\nand plays an important role in VR interaction. Existing work in this space are\nlimited to either producing root-relative (versus world space) 3D pose or rely\non multiple stages such as generating heatmaps and kinematic optimization to\nobtain 3D pose. Moreover, the typical VR scenario, which involves multi-view\ntracking from wide \\ac{fov} cameras is seldom addressed by these methods. In\nthis paper, we present a unified end-to-end differentiable framework for\nmulti-view, multi-frame hand tracking that directly predicts 3D hand pose in\nworld space. We demonstrate the benefits of end-to-end differentiabilty by\nextending our framework with downstream tasks such as jitter reduction and\npinch prediction. To demonstrate the efficacy of our model, we further present\na new large-scale egocentric hand pose dataset that consists of both real and\nsynthetic data. Experiments show that our system trained on this dataset\nhandles various challenging interactive motions, and has been successfully\napplied to real-time VR applications.",
    "descriptor": "\nComments: SIGGRAPH Asia 2022 Conference Papers, 8 pages\n",
    "authors": [
      "Shangchen Han",
      "Po-chen Wu",
      "Yubo Zhang",
      "Beibei Liu",
      "Linguang Zhang",
      "Zheng Wang",
      "Weiguang Si",
      "Peizhao Zhang",
      "Yujun Cai",
      "Tomas Hodan",
      "Randi Cabezas",
      "Luan Tran",
      "Muzaffer Akbay",
      "Tsz-Ho Yu",
      "Cem Keskin",
      "Robert Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00099"
  },
  {
    "id": "arXiv:2211.00101",
    "title": "A General Decomposition Method for a Convex Problem Related to Total  Variation Minimization",
    "abstract": "We consider sequential and parallel decomposition methods for a dual problem\nof a general total variation minimization problem with applications in several\nimage processing tasks, like image inpainting, estimation of optical flow and\nreconstruction of missing wavelet coefficients. The convergence of these\nmethods to a solution of the global problem is analysed in a Hilbert space\nsetting and a convergence rate is provided. Thereby, these convergence result\nhold not only for exact local minimization but also if the subproblems are just\nsolved approximately. As a concrete example of an approximate local solution\nprocess a surrogate technique is presented and analysed. Further, the obtained\nconvergence rate is compared with related results in the literature and shown\nto be in agreement with or even improve upon them. Numerical experiments are\npresented to support the theoretical findings and to show the performance of\nthe proposed decomposition algorithms in image inpainting, optical flow\nestimation and wavelet inpainting tasks.",
    "descriptor": "",
    "authors": [
      "Stephan Hilb",
      "Andreas Langer"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.00101"
  },
  {
    "id": "arXiv:2211.00103",
    "title": "Towards Human Cognition Level-based Experiment Design for Counterfactual  Explanations (XAI)",
    "abstract": "Explainable Artificial Intelligence (XAI) has recently gained a swell of\ninterest, as many Artificial Intelligence (AI) practitioners and developers are\ncompelled to rationalize how such AI-based systems work. Decades back, most XAI\nsystems were developed as knowledge-based or expert systems. These systems\nassumed reasoning for the technical description of an explanation, with little\nregard for the user's cognitive capabilities. The emphasis of XAI research\nappears to have turned to a more pragmatic explanation approach for better\nunderstanding. An extensive area where cognitive science research may\nsubstantially influence XAI advancements is evaluating user knowledge and\nfeedback, which are essential for XAI system evaluation. To this end, we\npropose a framework to experiment with generating and evaluating the\nexplanations on the grounds of different cognitive levels of understanding. In\nthis regard, we adopt Bloom's taxonomy, a widely accepted model for assessing\nthe user's cognitive capability. We utilize the counterfactual explanations as\nan explanation-providing medium encompassed with user feedback to validate the\nlevels of understanding about the explanation at each cognitive level and\nimprovise the explanation generation methods accordingly.",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Muhammad Suffian",
      "Muhammad Yaseen Khan",
      "Alessandro Bogliolo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.00103"
  },
  {
    "id": "arXiv:2211.00106",
    "title": "Data-Efficient Cross-Lingual Transfer with Language-Specific Subnetworks",
    "abstract": "Large multilingual language models typically share their parameters across\nall languages, which enables cross-lingual task transfer, but learning can also\nbe hindered when training updates from different languages are in conflict. In\nthis paper, we propose novel methods for using language-specific subnetworks,\nwhich control cross-lingual parameter sharing, to reduce conflicts and increase\npositive transfer during fine-tuning. We introduce dynamic subnetworks, which\nare jointly updated with the model, and we combine our methods with\nmeta-learning, an established, but complementary, technique for improving\ncross-lingual transfer. Finally, we provide extensive analyses of how each of\nour methods affects the models.",
    "descriptor": "",
    "authors": [
      "Rochelle Choenni",
      "Dan Garrette",
      "Ekaterina Shutova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.00106"
  },
  {
    "id": "arXiv:2211.00107",
    "title": "Where to start? Analyzing the potential value of intermediate models",
    "abstract": "Previous studies observed that finetuned models may be better base models\nthan the vanilla pretrained model. Such a model, finetuned on some source\ndataset, may provide a better starting point for a new finetuning process on a\ndesired target dataset. Here, we perform a systematic analysis of this\n\\emph{intertraining} scheme, over a wide range of English classification tasks.\nSurprisingly, our analysis suggests that the potential intertraining gain can\nbe analyzed \\emph{independently} for the target dataset under consideration,\nand for a base model being considered as a starting point. This is in contrast\nto current perception that the alignment between the target dataset and the\nsource dataset used to generate the base model is a major factor in determining\nintertraining success. We analyze different aspects that contribute to each.\nFurthermore, we leverage our analysis to propose a practical and efficient\napproach to determine if and how to select a base model in real-world settings.\nLast, we release an updating ranking of best models in the HuggingFace hub per\narchitecture\\anonm{remove this link: https://ibm.github.io/model-recycling/.",
    "descriptor": "",
    "authors": [
      "Leshem Choshen",
      "Elad Venezian",
      "Shachar Don-Yehia",
      "Noam Slonim",
      "Yoav Katz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00107"
  },
  {
    "id": "arXiv:2211.00110",
    "title": "A new benchmark for group distribution shifts in hand grasp regression  for object manipulation. Can meta-learning raise the bar?",
    "abstract": "Understanding hand-object pose with computer vision opens the door to new\napplications in mixed reality, assisted living or human-robot interaction. Most\nmethods are trained and evaluated on balanced datasets. This is of limited use\nin real-world applications; how do these methods perform in the wild on unknown\nobjects? We propose a novel benchmark for object group distribution shifts in\nhand and object pose regression. We then test the hypothesis that meta-learning\na baseline pose regression neural network can adapt to these shifts and\ngeneralize better to unknown objects. Our results show measurable improvements\nover the baseline, depending on the amount of prior knowledge. For the task of\njoint hand-object pose regression, we observe optimization interference for the\nmeta-learner. To address this issue and improve the method further, we provide\na comprehensive analysis which should serve as a basis for future work on this\nbenchmark.",
    "descriptor": "\nComments: Workshop on Distribution Shifts, 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Th\u00e9o Morales",
      "Gerard Lacey"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00110"
  },
  {
    "id": "arXiv:2211.00111",
    "title": "Unsafe's Betrayal: Abusing Unsafe Rust in Binary Reverse Engineering  toward Finding Memory-safety Bugs via Machine Learning",
    "abstract": "Memory-safety bugs introduce critical software-security issues. Rust provides\nmemory-safe mechanisms to avoid memory-safety bugs in programming, while still\nallowing unsafe escape hatches via unsafe code. However, the unsafe code that\nenhances the usability of Rust provides clear spots for finding memory-safety\nbugs in Rust source code. In this paper, we claim that these unsafe spots can\nstill be identifiable in Rust binary code via machine learning and be leveraged\nfor finding memory-safety bugs. To support our claim, we propose the tool\ntextttrustspot, that enables reverse engineering to learn an unsafe classifier\nthat proposes a list of functions in Rust binaries for downstream analysis. We\nempirically show that the function proposals by textttrustspot can recall\n$92.92\\%$ of memory-safety bugs, while it covers only $16.79\\%$ of the entire\nbinary code. As an application, we demonstrate that the function proposals are\nused in targeted fuzzing on Rust packages, which contribute to reducing the\nfuzzing time compared to non-targeted fuzzing.",
    "descriptor": "",
    "authors": [
      "Sangdon Park",
      "Xiang Cheng",
      "Taesoo Kim"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.00111"
  },
  {
    "id": "arXiv:2211.00112",
    "title": "Indexability is Not Enough for Whittle: Improved, Near-Optimal  Algorithms for Restless Bandits",
    "abstract": "We study the problem of planning restless multi-armed bandits (RMABs) with\nmultiple actions. This is a popular model for multi-agent systems with\napplications like multi-channel communication, monitoring and machine\nmaintenance tasks, and healthcare. Whittle index policies, which are based on\nLagrangian relaxations, are widely used in these settings due to their\nsimplicity and near-optimality under certain conditions. In this work, we first\nshow that Whittle index policies can fail in simple and practically relevant\nRMAB settings, \\textit{even when} the RMABs are indexable. We discuss why the\noptimality guarantees fail and why asymptotic optimality may not translate well\nto practically relevant planning horizons.\nWe then propose an alternate planning algorithm based on the mean-field\nmethod, which can provably and efficiently obtain near-optimal policies with a\nlarge number of arms, without the stringent structural assumptions required by\nthe Whittle index policies. This borrows ideas from existing research with some\nimprovements: our approach is hyper-parameter free, and we provide an improved\nnon-asymptotic analysis which has: (a) no requirement for exogenous\nhyper-parameters and tighter polynomial dependence on known problem parameters;\n(b) high probability bounds which show that the reward of the policy is\nreliable; and (c) matching sub-optimality lower bounds for this algorithm with\nrespect to the number of arms, thus demonstrating the tightness of our bounds.\nOur extensive experimental analysis shows that the mean-field approach matches\nor outperforms other baselines.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Abheek Ghosh",
      "Dheeraj Nagaraj",
      "Manish Jain",
      "Milind Tambe"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00112"
  },
  {
    "id": "arXiv:2211.00113",
    "title": "SAGE: Saliency-Guided Mixup with Optimal Rearrangements",
    "abstract": "Data augmentation is a key element for training accurate models by reducing\noverfitting and improving generalization. For image classification, the most\npopular data augmentation techniques range from simple photometric and\ngeometrical transformations, to more complex methods that use visual saliency\nto craft new training examples. As augmentation methods get more complex, their\nability to increase the test accuracy improves, yet, such methods become\ncumbersome, inefficient and lead to poor out-of-domain generalization, as we\nshow in this paper. This motivates a new augmentation technique that allows for\nhigh accuracy gains while being simple, efficient (i.e., minimal computation\noverhead) and generalizable. To this end, we introduce Saliency-Guided Mixup\nwith Optimal Rearrangements (SAGE), which creates new training examples by\nrearranging and mixing image pairs using visual saliency as guidance. By\nexplicitly leveraging saliency, SAGE promotes discriminative foreground objects\nand produces informative new images useful for training. We demonstrate on\nCIFAR-10 and CIFAR-100 that SAGE achieves better or comparable performance to\nthe state of the art while being more efficient. Additionally, evaluations in\nthe out-of-distribution setting, and few-shot learning on mini-ImageNet, show\nthat SAGE achieves improved generalization performance without trading off\nrobustness.",
    "descriptor": "\nComments: Accepted at British Machine Vision Conference (BMVC) 2022. Code: this https URL\n",
    "authors": [
      "Avery Ma",
      "Nikita Dvornik",
      "Ran Zhang",
      "Leila Pishdad",
      "Konstantinos G. Derpanis",
      "Afsaneh Fazly"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00113"
  },
  {
    "id": "arXiv:2211.00115",
    "title": "Textless Direct Speech-to-Speech Translation with Discrete Speech  Representation",
    "abstract": "Research on speech-to-speech translation (S2ST) has progressed rapidly in\nrecent years. Many end-to-end systems have been proposed and show advantages\nover conventional cascade systems, which are often composed of recognition,\ntranslation and synthesis sub-systems. However, most of the end-to-end systems\nstill rely on intermediate textual supervision during training, which makes it\ninfeasible to work for languages without written forms. In this work, we\npropose a novel model, Textless Translatotron, which is based on Translatotron\n2, for training an end-to-end direct S2ST model without any textual\nsupervision. Instead of jointly training with an auxiliary task predicting\ntarget phonemes as in Translatotron 2, the proposed model uses an auxiliary\ntask predicting discrete speech representations which are obtained from learned\nor random speech quantizers. When a speech encoder pre-trained with\nunsupervised speech data is used for both models, the proposed model obtains\ntranslation quality nearly on-par with Translatotron 2 on the multilingual\nCVSS-C corpus as well as the bilingual Fisher Spanish-English corpus. On the\nlatter, it outperforms the prior state-of-the-art textless model by +18.5 BLEU.",
    "descriptor": "",
    "authors": [
      "Xinjian Li",
      "Ye Jia",
      "Chung-Cheng Chiu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.00115"
  },
  {
    "id": "arXiv:2211.00119",
    "title": "Active Learning of Non-semantic Speech Tasks with Pretrained Models",
    "abstract": "Pretraining neural networks with massive unlabeled datasets have become\npopular as it equips the deep models with a better prior to solve downstream\ntasks. However, this approach generally assumes that for downstream tasks, we\nhave access to annotated data of sufficient size. In this work, we propose\nALOE, a novel system for improving the data- and label-efficiency of\nnon-semantic speech tasks with active learning (AL). ALOE uses pre-trained\nmodels in conjunction with active learning to label data incrementally and\nlearns classifiers for downstream tasks, thereby mitigating the need to acquire\nlabeled data beforehand. We demonstrate the effectiveness of ALOE on a wide\nrange of tasks, uncertainty-based acquisition functions, and model\narchitectures. Training a linear classifier on top of a frozen encoder with\nALOE is shown to achieve performance similar to several baselines that utilize\nthe entire labeled data.",
    "descriptor": "",
    "authors": [
      "Harlin Lee",
      "Aaqib Saeed",
      "Andrea L. Bertozzi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00119"
  },
  {
    "id": "arXiv:2211.00120",
    "title": "A GPU-friendly, Parallel, and (Almost-)In-Place Algorithm for Building  Left-Balanced kd-Trees",
    "abstract": "We present an algorithm that allows for building left-balanced and complete\nk-d trees over k-dimensional points in a trivially parallel and GPU friendly\nway. Our algorithm requires exactly one int per data point as temporary\nstorage, and uses O(logN ) iterations, each of which performs one parallel\nsort, and one trivially parallel CUDA per-node update kernel.",
    "descriptor": "",
    "authors": [
      "Ingo Wald"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.00120"
  },
  {
    "id": "arXiv:2211.00129",
    "title": "Is Facial Recognition Biased at Near-Infrared Spectrum As Well?",
    "abstract": "Published academic research and media articles suggest face recognition is\nbiased across demographics. Specifically, unequal performance is obtained for\nwomen, dark-skinned people, and older adults. However, these published studies\nhave examined the bias of facial recognition in the visible spectrum (VIS).\nFactors such as facial makeup, facial hair, skin color, and illumination\nvariation have been attributed to the bias of this technology at the VIS. The\nnear-infrared (NIR) spectrum offers an advantage over the VIS in terms of\nrobustness to factors such as illumination changes, facial makeup, and skin\ncolor. Therefore, it is worthwhile to investigate the bias of facial\nrecognition at the near-infrared spectrum (NIR). This first study investigates\nthe bias of the face recognition systems at the NIR spectrum. To this aim, two\npopular NIR facial image datasets namely, CASIA-Face-Africa and Notre-Dame-NIVL\nconsisting of African and Caucasian subjects, respectively, are used to\ninvestigate the bias of facial recognition technology across gender and race.\nInterestingly, experimental results suggest equitable face recognition\nperformance across gender and race at the NIR spectrum.",
    "descriptor": "\nComments: 7 pages, 2022 Virtual IEEE International Symposium on Technologies for Homeland Security\n",
    "authors": [
      "Anoop Krishnan",
      "Brian Neas",
      "Ajita Rattani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00129"
  },
  {
    "id": "arXiv:2211.00134",
    "title": "HAVOK Model Predictive Control for Time-Delay Systems with Applications  to District Heating",
    "abstract": "A computationally efficient Model-Predictive Control (MPC) approach is\nproposed for systems with unknown delay using only input/output data. We use\nthe Koopman operator framework and the related Hankel Alternative View of\nKoopman (HAVOK) algorithm to identify a model in a basis of projected\ntime-delay coordinates and demonstrate a novel MPC structure that reduces and\nbounds the computational complexity. The proposed HAVOK-MPC approach is\nvalidated experimentally on a laboratory-scale District Heating System (DHS),\ndemonstrating excellent prediction and tracking performance while only\nrequiring knowledge of a conservative upper bound on the system delay.\nThis work has been submitted to IFAC for possible publication.",
    "descriptor": "",
    "authors": [
      "Christian M. Jensen",
      "Mathias C. Frederiksen",
      "Carsten S. Kalles\u00f8e",
      "Jeppe N. Jensen",
      "Laurits H. Andersen",
      "Roozbeh Izadi-Zamanabadi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.00134"
  },
  {
    "id": "arXiv:2211.00142",
    "title": "TaTa: A Multilingual Table-to-Text Dataset for African Languages",
    "abstract": "Existing data-to-text generation datasets are mostly limited to English. To\naddress this lack of data, we create Table-to-Text in African languages (TaTa),\nthe first large multilingual table-to-text dataset with a focus on African\nlanguages. We created TaTa by transcribing figures and accompanying text in\nbilingual reports by the Demographic and Health Surveys Program, followed by\nprofessional translation to make the dataset fully parallel. TaTa includes\n8,700 examples in nine languages including four African languages (Hausa, Igbo,\nSwahili, and Yor\\`ub\\'a) and a zero-shot test language (Russian). We\nadditionally release screenshots of the original figures for future research on\nmultilingual multi-modal approaches. Through an in-depth human evaluation, we\nshow that TaTa is challenging for current models and that less than half the\noutputs from an mT5-XXL-based model are understandable and attributable to the\nsource data. We further demonstrate that existing metrics perform poorly for\nTaTa and introduce learned metrics that achieve a high correlation with human\njudgments. We release all data and annotations at\nhttps://github.com/google-research/url-nlp.",
    "descriptor": "\nComments: 24 pages, 6 figures\n",
    "authors": [
      "Sebastian Gehrmann",
      "Sebastian Ruder",
      "Vitaly Nikolaev",
      "Jan A. Botha",
      "Michael Chavinda",
      "Ankur Parikh",
      "Clara Rivera"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00142"
  },
  {
    "id": "arXiv:2211.00147",
    "title": "A Machine Learning Tutorial for Operational Meteorology, Part II: Neural  Networks and Deep Learning",
    "abstract": "Over the past decade the use of machine learning in meteorology has grown\nrapidly. Specifically neural networks and deep learning have been being used at\nan unprecedented rate. In order to fill the dearth of resources covering neural\nnetworks with a meteorological lens, this paper discusses machine learning\nmethods in a plain language format that is targeted for the operational\nmeteorolgical community. This is the second paper in a pair that aim to serve\nas a machine learning resource for meteorologists. While the first paper\nfocused on traditional machine learning methods (e.g., random forest), here a\nbroad spectrum of neural networks and deep learning methods are discussed.\nSpecifically this paper covers perceptrons, artificial neural networks,\nconvolutional neural networks and U-networks. Like the part 1 paper, this\nmanuscript discusses the terms associated with neural networks and their\ntraining. Then the manuscript provides some intuition behind every method and\nconcludes by showing each method used in a meteorological example of diagnosing\nthunderstorms from satellite images (e.g., lightning flashes). This paper is\naccompanied by an open-source code repository to allow readers to explore\nneural networks using either the dataset provided (which is used in the paper)\nor as a template for alternate datasets.",
    "descriptor": "",
    "authors": [
      "Randy J. Chase",
      "David R. Harrison",
      "Gary Lackmann",
      "Amy McGovern"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.00147"
  },
  {
    "id": "arXiv:2211.00149",
    "title": "Improving Motion Forecasting for Autonomous Driving with the Cycle  Consistency Loss",
    "abstract": "Robust motion forecasting of the dynamic scene is a critical component of an\nautonomous vehicle. It is a challenging problem due to the heterogeneity in the\nscene and the inherent uncertainties in the problem. To improve the accuracy of\nmotion forecasting, in this work, we identify a new consistency constraint in\nthis task, that is an agent's future trajectory should be coherent with its\nhistory observations and visa versa. To leverage this property, we propose a\nnovel cycle consistency training scheme and define a novel cycle loss to\nencourage this consistency. In particular, we reverse the predicted future\ntrajectory backward in time and feed it back into the prediction model to\npredict the history and compute the loss as an additional cycle loss term.\nThrough our experiments on the Argoverse dataset, we demonstrate that cycle\nloss can improve the performance of competitive motion forecasting models.",
    "descriptor": "\nComments: Accepted at NeurIPS 2022 Machine Learning for Autonomous Driving Workshop\n",
    "authors": [
      "Titas Chakraborty",
      "Akshay Bhagat",
      "Henggang Cui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00149"
  },
  {
    "id": "arXiv:2211.00150",
    "title": "A 5G Enabled Adaptive Computing Workflow for Greener Power Grid",
    "abstract": "5G wireless technology can deliver higher data speeds, ultra low latency,\nmore reliability, massive network capacity, increased availability, and a more\nuniform user experience to users. It brings additional power to help address\nthe challenges brought by renewable integration and decarbonization. In this\npaper, a 5G enabled adaptive computing workflow has been presented that\nconsists of various computing resources, such as 5G equipment, edge computing,\ncluster, Graphics processing unit (GPU) and cloud computing, with two examples\nshowing technical feasibility for edge-grid-cloud interaction for power system\nreal-time monitoring, security assessment, and forecasting. Benefiting from the\nhigh speed data transport and massive connection capability of 5G, the workflow\nshows its potential to seamlessly integrate various applications at distributed\nand/or centralized locations to build more complex and powerful functions, with\nbetter flexibility.",
    "descriptor": "\nComments: 5 pages, 6 figures\n",
    "authors": [
      "Yousu Chen",
      "Liwei Wang",
      "Xiaoyuan Fan",
      "Dexin Wang",
      "James Ogle"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.00150"
  },
  {
    "id": "arXiv:2211.00151",
    "title": "A Close Look into the Calibration of Pre-trained Language Models",
    "abstract": "Pre-trained language models (PLMs) achieve remarkable performance on many\ndownstream tasks, but may fail in giving reliable estimates of their predictive\nuncertainty. Given the lack of a comprehensive understanding of PLMs\ncalibration, we take a close look into this new research problem, aiming to\nanswer two questions: (1) Do PLMs learn to become calibrated in the training\nprocess? (2) How effective are existing calibration methods? For the first\nquestion, we conduct fine-grained control experiments to study the dynamic\nchange in PLMs' calibration performance in training. We consider six factors as\ncontrol variables, including dataset difficulty, available training samples,\ntraining steps, the number of tunable parameters, model scale, and pretraining.\nIn experiments, we observe a consistent change in calibration performance\nacross six factors. We find that PLMs don't learn to become calibrated in\ntraining, evidenced by the continual increase in confidence, no matter the\npredictions are correct or not. We highlight that our finding presents some\ncontradiction with two established conclusions: (a) Larger PLMs are more\ncalibrated; (b) Pretraining improves model calibration. Next, we study the\neffectiveness of existing calibration methods in mitigating the overconfidence\nissue, in both in-distribution and various out-of-distribution settings.\nBesides unlearnable calibration methods, we adapt two recently proposed\nlearnable methods that directly collect data to train models to have reasonable\nconfidence estimations. Also, we propose extended learnable methods based on\nexisting ones to further improve or maintain PLMs calibration without\nsacrificing the original task performance. Experimental results show that\nlearnable methods significantly reduce PLMs' confidence in wrong predictions,\nand our methods exhibit superior performance compared with previous methods.",
    "descriptor": "\nComments: Code is available at: this https URL\n",
    "authors": [
      "Yangyi Chen",
      "Lifan Yuan",
      "Ganqu Cui",
      "Zhiyuan Liu",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00151"
  },
  {
    "id": "arXiv:2211.00153",
    "title": "Do LSTMs See Gender? Probing the Ability of LSTMs to Learn Abstract  Syntactic Rules",
    "abstract": "LSTMs trained on next-word prediction can accurately perform linguistic tasks\nthat require tracking long-distance syntactic dependencies. Notably, model\naccuracy approaches human performance on number agreement tasks (Gulordava et\nal., 2018). However, we do not have a mechanistic understanding of how LSTMs\nperform such linguistic tasks. Do LSTMs learn abstract grammatical rules, or do\nthey rely on simple heuristics? Here, we test gender agreement in French which\nrequires tracking both hierarchical syntactic structures and the inherent\ngender of lexical units. Our model is able to reliably predict long-distance\ngender agreement in two subject-predicate contexts: noun-adjective and\nnoun-passive-verb agreement. The model showed more inaccuracies on plural noun\nphrases with gender attractors compared to singular cases, suggesting a\nreliance on clues from gendered articles for agreement. Overall, our study\nhighlights key ways in which LSTMs deviate from human behaviour and questions\nwhether LSTMs genuinely learn abstract syntactic rules and categories. We\npropose using gender agreement as a useful probe to investigate the underlying\nmechanisms, internal representations, and linguistic capabilities of LSTM\nlanguage models.",
    "descriptor": "\nComments: Accepted at EMNLP 2022 Workshop BlackBoxNLP: Analysing and Interpreting Neural Networks for NLP\n",
    "authors": [
      "Priyanka Sukumaran",
      "Conor Houghton",
      "Nina Kazanina"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00153"
  },
  {
    "id": "arXiv:2211.00157",
    "title": "Large scale traffic forecasting with gradient boosting, Traffic4cast  2022 challenge",
    "abstract": "Accurate traffic forecasting is of the utmost importance for optimal travel\nplanning and for efficient city mobility. IARAI (The Institute of Advanced\nResearch in Artificial Intelligence) organizes Traffic4cast, a yearly traffic\nprediction competition based on real-life data\n[https://www.iarai.ac.at/traffic4cast/], aiming to leverage artificial\nintelligence advances for producing accurate traffic estimates. We present our\nsolution to the IARAI Traffic4cast 2022 competition, in which the goal is to\ndevelop algorithms for predicting road graph edge congestion classes and\nsupersegment-level travel times. In contrast to the previous years, this year's\ncompetition focuses on modelling graph edge level behaviour, rather than more\ncoarse aggregated grid-based traffic movies. Due to this, we leverage a method\nfamiliar from tabular data modelling -- gradient-boosted decision tree\nensembles. We reduce the dimensionality of the input data representing traffic\ncounters with the help of the classic PCA method and feed it as input to a\nLightGBM model. This simple, fast, and scalable technique allowed us to win\nsecond place in the core competition. The source code and references to trained\nmodel files and submissions are available at https://github.com/skandium/t4c22 .",
    "descriptor": "",
    "authors": [
      "Martin Lumiste",
      "Andrei Ilie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00157"
  },
  {
    "id": "arXiv:2211.00164",
    "title": "Agent-Controller Representations: Principled Offline RL with Rich  Exogenous Information",
    "abstract": "Learning to control an agent from data collected offline in a rich\npixel-based visual observation space is vital for real-world applications of\nreinforcement learning (RL). A major challenge in this setting is the presence\nof input information that is hard to model and irrelevant to controlling the\nagent. This problem has been approached by the theoretical RL community through\nthe lens of exogenous information, i.e, any control-irrelevant information\ncontained in observations. For example, a robot navigating in busy streets\nneeds to ignore irrelevant information, such as other people walking in the\nbackground, textures of objects, or birds in the sky. In this paper, we focus\non the setting with visually detailed exogenous information, and introduce new\noffline RL benchmarks offering the ability to study this problem. We find that\ncontemporary representation learning techniques can fail on datasets where the\nnoise is a complex and time dependent process, which is prevalent in practical\napplications. To address these, we propose to use multi-step inverse models,\nwhich have seen a great deal of interest in the RL theory community, to learn\nAgent-Controller Representations for Offline-RL (ACRO). Despite being simple\nand requiring no reward, we show theoretically and empirically that the\nrepresentation created by this objective greatly outperforms baselines.",
    "descriptor": "",
    "authors": [
      "Riashat Islam",
      "Manan Tomar",
      "Alex Lamb",
      "Yonathan Efroni",
      "Hongyu Zang",
      "Aniket Didolkar",
      "Dipendra Misra",
      "Xin Li",
      "Harm van Seijen",
      "Remi Tachet des Combes",
      "John Langford"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.00164"
  },
  {
    "id": "arXiv:2211.00166",
    "title": "Decorrelating ReSTIR Samplers via MCMC Mutations",
    "abstract": "Monte Carlo rendering algorithms often utilize correlations between pixels to\nimprove efficiency and enhance image quality. For real-time applications in\nparticular, repeated reservoir resampling offers a powerful framework to reuse\nsamples both spatially in an image and temporally across multiple frames. While\nsuch techniques achieve equal-error up to 100 times faster for real-time direct\nlighting and global illumination, they are still far from optimal. For\ninstance, unchecked spatiotemporal resampling often introduces noticeable\ncorrelation artifacts, while reservoirs holding more than one sample suffer\nfrom impoverishment in the form of duplicate samples. We demonstrate how\ninterleaving Markov Chain Monte Carlo (MCMC) mutations with reservoir\nresampling helps alleviate these issues, especially in scenes with glossy\nmaterials and difficult-to-sample lighting. Moreover, our approach does not\nintroduce any bias, and in practice we find considerable improvement in image\nquality with just a single mutation per reservoir sample in each frame.",
    "descriptor": "",
    "authors": [
      "Rohan Sawhney",
      "Daqi Lin",
      "Markus Kettunen",
      "Benedikt Bitterli",
      "Ravi Ramamoorthi",
      "Chris Wyman",
      "Matt Pharr"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.00166"
  },
  {
    "id": "arXiv:2211.00168",
    "title": "Improving Fairness in Image Classification via Sketching",
    "abstract": "Fairness is a fundamental requirement for trustworthy and human-centered\nArtificial Intelligence (AI) system. However, deep neural networks (DNNs) tend\nto make unfair predictions when the training data are collected from different\nsub-populations with different attributes (i.e. color, sex, age), leading to\nbiased DNN predictions. We notice that such a troubling phenomenon is often\ncaused by data itself, which means that bias information is encoded to the DNN\nalong with the useful information (i.e. class information, semantic\ninformation). Therefore, we propose to use sketching to handle this phenomenon.\nWithout losing the utility of data, we explore the image-to-sketching methods\nthat can maintain useful semantic information for the target classification\nwhile filtering out the useless bias information. In addition, we design a fair\nloss to further improve the model fairness. We evaluate our method through\nextensive experiments on both general scene dataset and medical scene dataset.\nOur results show that the desired image-to-sketching method improves model\nfairness and achieves satisfactory results among state-of-the-art.",
    "descriptor": "\nComments: 8 pages, 2 figures. To appear in 2022 Trustworthy and Socially Responsible Machine Learning (TSRML 2022) co-located with NeurIPS 2022\n",
    "authors": [
      "Ruichen Yao",
      "Ziteng Cui",
      "Xiaoxiao Li",
      "Lin Gu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00168"
  },
  {
    "id": "arXiv:2211.00170",
    "title": "What is my math transformer doing? -- Three results on interpretability  and generalization",
    "abstract": "This paper investigates the failure cases and out-of-distribution behavior of\ntransformers trained on matrix inversion and eigenvalue decomposition. I show\nthat incorrect model predictions still retain deep mathematical properties of\nthe solution (e.g. correct eigenvalues, unit norm of eigenvectors), and that\nalmost all model failures can be attributed to, and predicted from, properties\nof the problem or solution. This demonstrates that, when in doubt, math\ntransformers do not hallucinate absurd solutions (as was sometimes proposed)\nbut remain ``roughly right''. I also show that the careful choice of a training\ndataset can accelerate training, while allowing the model to generalize out of\nits training distribution, invalidating the idea that transformers ``merely\ninterpolate'' from memorized examples.",
    "descriptor": "",
    "authors": [
      "Fran\u00e7ois Charton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00170"
  },
  {
    "id": "arXiv:2211.00171",
    "title": "Using Emotion Embeddings to Transfer Knowledge Between Emotions,  Languages, and Annotation Formats",
    "abstract": "The need for emotional inference from text continues to diversify as more and\nmore disciplines integrate emotions into their theories and applications. These\nneeds include inferring different emotion types, handling multiple languages,\nand different annotation formats. A shared model between different\nconfigurations would enable the sharing of knowledge and a decrease in training\ncosts, and would simplify the process of deploying emotion recognition models\nin novel environments. In this work, we study how we can build a single model\nthat can transition between these different configurations by leveraging\nmultilingual models and Demux, a transformer-based model whose input includes\nthe emotions of interest, enabling us to dynamically change the emotions\npredicted by the model. Demux also produces emotion embeddings, and performing\noperations on them allows us to transition to clusters of emotions by pooling\nthe embeddings of each cluster. We show that Demux can simultaneously transfer\nknowledge in a zero-shot manner to a new language, to a novel annotation format\nand to unseen emotions. Code is available at\nhttps://github.com/gchochla/Demux-MEmo .",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Georgios Chochlakis",
      "Gireesh Mahajan",
      "Sabyasachee Baruah",
      "Keith Burghardt",
      "Kristina Lerman",
      "Shrikanth Narayanan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00171"
  },
  {
    "id": "arXiv:2211.00174",
    "title": "Joint Audio/Text Training for Transformer Rescorer of Streaming Speech  Recognition",
    "abstract": "Recently, there has been an increasing interest in two-pass streaming\nend-to-end speech recognition (ASR) that incorporates a 2nd-pass rescoring\nmodel on top of the conventional 1st-pass streaming ASR model to improve\nrecognition accuracy while keeping latency low. One of the latest 2nd-pass\nrescoring model, Transformer Rescorer, takes the n-best initial outputs and\naudio embeddings from the 1st-pass model, and then choose the best output by\nre-scoring the n-best initial outputs. However, training this Transformer\nRescorer requires expensive paired audio-text training data because the model\nuses audio embeddings as input. In this work, we present our Joint Audio/Text\ntraining method for Transformer Rescorer, to leverage unpaired text-only data\nwhich is relatively cheaper than paired audio-text data. We evaluate\nTransformer Rescorer with our Joint Audio/Text training on Librispeech dataset\nas well as our large-scale in-house dataset and show that our training method\ncan improve word error rate (WER) significantly compared to standard\nTransformer Rescorer without requiring any extra model parameters or latency.",
    "descriptor": "",
    "authors": [
      "Suyoun Kim",
      "Ke Li",
      "Lucas Kabela",
      "Rongqing Huang",
      "Jiedan Zhu",
      "Ozlem Kalinli",
      "Duc Le"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.00174"
  },
  {
    "id": "arXiv:2211.00176",
    "title": "Xtreme Margin: A Tunable Loss Function for Binary Classification  Problems",
    "abstract": "Loss functions drive the optimization of machine learning algorithms. The\nchoice of a loss function can have a significant impact on the training of a\nmodel, and how the model learns the data. Binary classification is one of the\nmajor pillars of machine learning problems, used in medical imaging to failure\ndetection applications. The most commonly used surrogate loss functions for\nbinary classification include the binary cross-entropy and the hinge loss\nfunctions, which form the focus of our study.\nIn this paper, we provide an overview of a novel loss function, the Xtreme\nMargin loss function. Unlike the binary cross-entropy and the hinge loss\nfunctions, this loss function provides researchers and practitioners\nflexibility with their training process, from maximizing precision and AUC\nscore to maximizing conditional accuracy for a particular class, through\ntunable hyperparameters $\\lambda_1$ and $\\lambda_2$, i.e., changing their\nvalues will alter the training of a model.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Rayan Wali"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00176"
  },
  {
    "id": "arXiv:2211.00177",
    "title": "Learning to Navigate Wikipedia by Taking Random Walks",
    "abstract": "A fundamental ability of an intelligent web-based agent is seeking out and\nacquiring new information. Internet search engines reliably find the correct\nvicinity but the top results may be a few links away from the desired target. A\ncomplementary approach is navigation via hyperlinks, employing a policy that\ncomprehends local content and selects a link that moves it closer to the\ntarget. In this paper, we show that behavioral cloning of randomly sampled\ntrajectories is sufficient to learn an effective link selection policy. We\ndemonstrate the approach on a graph version of Wikipedia with 38M nodes and\n387M edges. The model is able to efficiently navigate between nodes 5 and 20\nsteps apart 96% and 92% of the time, respectively. We then use the resulting\nembeddings and policy in downstream fact verification and question answering\ntasks where, in combination with basic TF-IDF search and ranking methods, they\nare competitive results to the state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Manzil Zaheer",
      "Kenneth Marino",
      "Will Grathwohl",
      "John Schultz",
      "Wendy Shang",
      "Sheila Babayan",
      "Arun Ahuja",
      "Ishita Dasgupta",
      "Christine Kaeser-Chen",
      "Rob Fergus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.00177"
  },
  {
    "id": "arXiv:2211.00181",
    "title": "The Numerical Stability of Hyperbolic Representation Learning",
    "abstract": "Given the exponential growth of the volume of the ball w.r.t. its radius, the\nhyperbolic space is capable of embedding trees with arbitrarily small\ndistortion and hence has received wide attention for representing hierarchical\ndatasets. However, this exponential growth property comes at a price of\nnumerical instability such that training hyperbolic learning models will\nsometimes lead to catastrophic NaN problems, encountering unrepresentable\nvalues in floating point arithmetic. In this work, we carefully analyze the\nlimitation of two popular models for the hyperbolic space, namely, the\nPoincar\\'e ball and the Lorentz model. We first show that, under the 64 bit\narithmetic system, the Poincar\\'e ball has a relatively larger capacity than\nthe Lorentz model for correctly representing points. Then, we theoretically\nvalidate the superiority of the Lorentz model over the Poincar\\'e ball from the\nperspective of optimization. Given the numerical limitations of both models, we\nidentify one Euclidean parametrization of the hyperbolic space which can\nalleviate these limitations. We further extend this Euclidean parametrization\nto hyperbolic hyperplanes and exhibits its ability in improving the performance\nof hyperbolic SVM.",
    "descriptor": "",
    "authors": [
      "Gal Mishne",
      "Zhengchao Wan",
      "Yusu Wang",
      "Sheng Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.00181"
  },
  {
    "id": "arXiv:2211.00184",
    "title": "FL Games: A Federated Learning Framework for Distribution Shifts",
    "abstract": "Federated learning aims to train predictive models for data that is\ndistributed across clients, under the orchestration of a server. However,\nparticipating clients typically each hold data from a different distribution,\nwhich can yield to catastrophic generalization on data from a different client,\nwhich represents a new domain. In this work, we argue that in order to\ngeneralize better across non-i.i.d. clients, it is imperative to only learn\ncorrelations that are stable and invariant across domains. We propose FL GAMES,\na game-theoretic framework for federated learning that learns causal features\nthat are invariant across clients. While training to achieve the Nash\nequilibrium, the traditional best response strategy suffers from high-frequency\noscillations. We demonstrate that FL GAMES effectively resolves this challenge\nand exhibits smooth performance curves. Further, FL GAMES scales well in the\nnumber of clients, requires significantly fewer communication rounds, and is\nagnostic to device heterogeneity. Through empirical evaluation, we demonstrate\nthat FL GAMES achieves high out-of-distribution performance on various\nbenchmarks.",
    "descriptor": "\nComments: Accepted as ORAL at NeurIPS Workshop on Federated Learning: Recent Advances and New Challenges. arXiv admin note: text overlap with arXiv:2205.11101\n",
    "authors": [
      "Sharut Gupta",
      "Kartik Ahuja",
      "Mohammad Havaei",
      "Niladri Chatterjee",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00184"
  },
  {
    "id": "arXiv:2211.00185",
    "title": "Hybrid CNN -Interpreter: Interpret local and global contexts for  CNN-based Models",
    "abstract": "Convolutional neural network (CNN) models have seen advanced improvements in\nperformance in various domains, but lack of interpretability is a major barrier\nto assurance and regulation during operation for acceptance and deployment of\nAI-assisted applications. There have been many works on input interpretability\nfocusing on analyzing the input-output relations, but the internal logic of\nmodels has not been clarified in the current mainstream interpretability\nmethods. In this study, we propose a novel hybrid CNN-interpreter through: (1)\nAn original forward propagation mechanism to examine the layer-specific\nprediction results for local interpretability. (2) A new global\ninterpretability that indicates the feature correlation and filter importance\neffects. By combining the local and global interpretabilities, hybrid\nCNN-interpreter enables us to have a solid understanding and monitoring of\nmodel context during the whole learning process with detailed and consistent\nrepresentations. Finally, the proposed interpretabilities have been\ndemonstrated to adapt to various CNN-based model structures.",
    "descriptor": "",
    "authors": [
      "Wenli Yang",
      "Guan Huang",
      "Renjie Li",
      "Jiahao Yu",
      "Yanyu Chen",
      "Quan Bai",
      "Beyong Kang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00185"
  },
  {
    "id": "arXiv:2211.00188",
    "title": "Adaptive Compression for Communication-Efficient Distributed Training",
    "abstract": "We propose Adaptive Compressed Gradient Descent (AdaCGD) - a novel\noptimization algorithm for communication-efficient training of supervised\nmachine learning models with adaptive compression level. Our approach is\ninspired by the recently proposed three point compressor (3PC) framework of\nRichtarik et al. (2022), which includes error feedback (EF21), lazily\naggregated gradient (LAG), and their combination as special cases, and offers\nthe current state-of-the-art rates for these methods under weak assumptions.\nWhile the above mechanisms offer a fixed compression level, or adapt between\ntwo extremes only, our proposal is to perform a much finer adaptation. In\nparticular, we allow the user to choose any number of arbitrarily chosen\ncontractive compression mechanisms, such as Top-K sparsification with a\nuser-defined selection of sparsification levels K, or quantization with a\nuser-defined selection of quantization levels, or their combination. AdaCGD\nchooses the appropriate compressor and compression level adaptively during the\noptimization process. Besides i) proposing a theoretically-grounded\nmulti-adaptive communication compression mechanism, we further ii) extend the\n3PC framework to bidirectional compression, i.e., we allow the server to\ncompress as well, and iii) provide sharp convergence bounds in the strongly\nconvex, convex and nonconvex settings. The convex regime results are new even\nfor several key special cases of our general mechanism, including 3PC and EF21.\nIn all regimes, our rates are superior compared to all existing adaptive\ncompression methods.",
    "descriptor": "",
    "authors": [
      "Maksim Makarenko",
      "Elnur Gasanov",
      "Rustem Islamov",
      "Abdurakhmon Sadiev",
      "Peter Richtarik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.00188"
  },
  {
    "id": "arXiv:2211.00191",
    "title": "Edge Grasp Network: A Graph-Based SE(3)-invariant Approach to Grasp  Detection",
    "abstract": "Given point cloud input, the problem of 6-DoF grasp pose detection is to\nidentify a set of hand poses in SE(3) from which an object can be successfully\ngrasped. This important problem has many practical applications. Here we\npropose a novel method and neural network model that enables better grasp\nsuccess rates relative to what is available in the literature. The method takes\nstandard point cloud data as input and works well with single-view point clouds\nobserved from arbitrary viewing directions.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Haojie Huang",
      "Dian Wang",
      "Xupeng Zhu",
      "Robin Walters",
      "Robert Platt"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00191"
  },
  {
    "id": "arXiv:2211.00192",
    "title": "AI Assistants: A Framework for Semi-Automated Data Wrangling",
    "abstract": "Data wrangling tasks such as obtaining and linking data from various sources,\ntransforming data formats, and correcting erroneous records, can constitute up\nto 80% of typical data engineering work. Despite the rise of machine learning\nand artificial intelligence, data wrangling remains a tedious and manual task.\nWe introduce AI assistants, a class of semi-automatic interactive tools to\nstreamline data wrangling. An AI assistant guides the analyst through a\nspecific data wrangling task by recommending a suitable data transformation\nthat respects the constraints obtained through interaction with the analyst.\nWe formally define the structure of AI assistants and describe how existing\ntools that treat data cleaning as an optimization problem fit the definition.\nWe implement AI assistants for four common data wrangling tasks and make AI\nassistants easily accessible to data analysts in an open-source notebook\nenvironment for data science, by leveraging the common structure they follow.\nWe evaluate our AI assistants both quantitatively and qualitatively through\nthree example scenarios. We show that the unified and interactive design makes\nit easy to perform tasks that would be difficult to do manually or with a fully\nautomatic tool.",
    "descriptor": "\nComments: Accepted for publication in IEEE Transactions on Knowledge and Data Engineering\n",
    "authors": [
      "Tomas Petricek",
      "Gerrit J. J. van den Burg",
      "Alfredo Naz\u00e1bal",
      "Taha Ceritli",
      "Ernesto Jim\u00e9nez-Ruiz",
      "Christopher K. I. Williams"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.00192"
  },
  {
    "id": "arXiv:2211.00194",
    "title": "SEIL: Simulation-augmented Equivariant Imitation Learning",
    "abstract": "In robotic manipulation, acquiring samples is extremely expensive because it\noften requires interacting with the real world. Traditional image-level data\naugmentation has shown the potential to improve sample efficiency in various\nmachine learning tasks. However, image-level data augmentation is insufficient\nfor an imitation learning agent to learn good manipulation policies in a\nreasonable amount of demonstrations. We propose Simulation-augmented\nEquivariant Imitation Learning (SEIL), a method that combines a novel data\naugmentation strategy of supplementing expert trajectories with simulated\ntransitions and an equivariant model that exploits the $\\mathrm{O}(2)$ symmetry\nin robotic manipulation. Experimental evaluations demonstrate that our method\ncan learn non-trivial manipulation tasks within ten demonstrations and\noutperforms the baselines with a significant margin.",
    "descriptor": "",
    "authors": [
      "Mingxi Jia",
      "Dian Wang",
      "Guanang Su",
      "David Klee",
      "Xupeng Zhu",
      "Robin Walters",
      "Robert Platt"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.00194"
  },
  {
    "id": "arXiv:2211.00198",
    "title": "Frequency Cam: Imaging Periodic Signals in Real-Time",
    "abstract": "Due to their high temporal resolution and large dynamic range event cameras\nare uniquely suited for the analysis of time-periodic signals in an image. In\nthis work we present an efficient and fully asynchronous event camera algorithm\nfor detecting the fundamental frequency at which image pixels flicker. The\nalgorithm employs a second-order digital infinite impulse response (IIR) filter\nto perform an approximate per-pixel brightness reconstruction and is more\nrobust to high-frequency noise than the baseline method we compare to. We\nfurther demonstrate that using the falling edge of the signal leads to more\naccurate period estimates than the rising edge, and that for certain signals\ninterpolating the zero-level crossings can further increase accuracy. Our\nexperiments find that the outstanding capabilities of the camera in detecting\nfrequencies up to 64kHz for a single pixel do not carry over to full sensor\nimaging as readout bandwidth limitations become a serious obstacle. This\nsuggests that a hardware implementation closer to the sensor will allow for\ngreatly improved frequency imaging. We discuss the important design parameters\nfor fullsensor frequency imaging and present Frequency Cam, an open-source\nimplementation as a ROS node that can run on a single core of a laptop CPU at\nmore than 50 million events per second. It produces results that are\nqualitatively very similar to those obtained from the closed source vibration\nanalysis module in Prophesee's Metavision Toolkit. The code for Frequency Cam\nand a demonstration video can be found at\nhttps://github.com/berndpfrommer/frequency_cam",
    "descriptor": "\nComments: 13 pages, 16 figures, one table\n",
    "authors": [
      "Bernd Pfrommer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.00198"
  },
  {
    "id": "arXiv:2211.00201",
    "title": "CCS Explorer: Relevance Prediction, Extractive Summarization, and Named  Entity Recognition from Clinical Cohort Studies",
    "abstract": "Clinical Cohort Studies (CCS) are a great source of documented clinical\nresearch. Ideally, a clinical expert will interpret these articles for\nexploratory analysis ranging from drug discovery for evaluating the efficacy of\nexisting drugs in tackling emerging diseases to the first test of newly\ndeveloped drugs. However, more than 100 CCS articles are published on PubMed\nevery day. As a result, it can take days for a doctor to find articles and\nextract relevant information. Can we find a way to quickly sift through the\nlong list of these articles faster and document the crucial takeaways from each\nof these articles? In this work, we propose CCS Explorer, an end-to-end system\nfor relevance prediction of sentences, extractive summarization, and patient,\noutcome, and intervention entity detection from CCS. CCS Explorer is packaged\nin a web-based graphical user interface where the user can provide any disease\nname. CCS Explorer then extracts and aggregates all relevant information from\narticles on PubMed based on the results of an automatically generated query\nproduced on the back-end. CCS Explorer fine-tunes pre-trained language models\nbased on transformers with additional layers for each of these tasks. We\nevaluate the models using two publicly available datasets. CCS Explorer obtains\na recall of 80.2%, AUC-ROC of 0.843, and an accuracy of 88.3% on sentence\nrelevance prediction using BioBERT and achieves an average Micro F1-Score of\n77.8% on Patient, Intervention, Outcome detection (PIO) using PubMedBERT. Thus,\nCCS Explorer can reliably extract relevant information to summarize articles,\nsaving time by ~ 660$\\times$.",
    "descriptor": "\nComments: Accepted at IEEE BigData 2022\n",
    "authors": [
      "Irfan Al-Hussaini",
      "Davi Nakajima An",
      "Albert J. Lee",
      "Sarah Bi",
      "Cassie S. Mitchell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00201"
  },
  {
    "id": "arXiv:2211.00206",
    "title": "A Primary Frequency Control Strategy for Variable-Speed Pumped-Storage  Plant in Power Generation Based on Adaptive Model Predictive Control",
    "abstract": "Variable-speed pumped-storage (VSPS) has great potential in helping solve the\nfrequency control problem caused by low inertia, owing to its remarkable\nflexibility beyond conventional fixed-speed one, to make better use of which, a\nprimary frequency control strategy based on adaptive model predictive control\n(AMPC) is proposed in this paper for VSPS plant in power generation.",
    "descriptor": "\nComments: 8 pages, 9 figures\n",
    "authors": [
      "Zhenghua Xu",
      "Changhong Deng",
      "Qiuling Yang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.00206"
  },
  {
    "id": "arXiv:2211.00207",
    "title": "GMF: General Multimodal Fusion Framework for Correspondence Outlier  Rejection",
    "abstract": "Rejecting correspondence outliers enables to boost the correspondence\nquality, which is a critical step in achieving high point cloud registration\naccuracy. The current state-of-the-art correspondence outlier rejection methods\nonly utilize the structure features of the correspondences. However, texture\ninformation is critical to reject the correspondence outliers in our human\nvision system. In this paper, we propose General Multimodal Fusion (GMF) to\nlearn to reject the correspondence outliers by leveraging both the structure\nand texture information. Specifically, two cross-attention-based fusion layers\nare proposed to fuse the texture information from paired images and structure\ninformation from point correspondences. Moreover, we propose a convolutional\nposition encoding layer to enhance the difference between Tokens and enable the\nencoding feature pay attention to neighbor information. Our position encoding\nlayer will make the cross-attention operation integrate both local and global\ninformation. Experiments on multiple datasets(3DMatch, 3DLoMatch, KITTI) and\nrecent state-of-the-art models (3DRegNet, DGR, PointDSC) prove that our GMF\nachieves wide generalization ability and consistently improves the point cloud\nregistration accuracy. Furthermore, several ablation studies demonstrate the\nrobustness of the proposed GMF on different loss functions, lighting conditions\nand noises.The code is available at https://github.com/XiaoshuiHuang/GMF.",
    "descriptor": "\nComments: Accepted by IEEE RAL\n",
    "authors": [
      "Xiaoshui Huang",
      "Wentao Qu",
      "Yifan Zuo",
      "Yuming Fang",
      "Xiaowei Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00207"
  },
  {
    "id": "arXiv:2211.00208",
    "title": "Invited Paper: Fault-tolerant and Expressive Cross-Chain Swaps",
    "abstract": "Cross-chain swaps enable exchange of different assets that reside on\ndifferent blockchains. Several protocols have been proposed for atomic\ncross-chain swaps. However, those protocols are not fault-tolerant, in the\nsense that if any party deviates, no asset transfer can happen. In this paper,\nwe propose two alternative protocols for structuring composable and robust\ncross-chain swaps. Participants can propose multiple swaps simultaneously and\nthen complete a subset of those swaps according to their needs. Their needs are\nexpressed as predicates which capture acceptable payoff of each participant.\nOur proposed protocols are thus more expressive due to the introduction of\npredicates. The proposed protocols are fault-tolerant since, even if some\nparticipants deviate, those predicates can still be satisfied, and conforming\nparties can complete an acceptable set of swaps.",
    "descriptor": "\nComments: to appear in ICDCN'23\n",
    "authors": [
      "Yingjie Xue",
      "Di Jin",
      "Maurice Herlihy"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.00208"
  },
  {
    "id": "arXiv:2211.00213",
    "title": "Rarest-First with Probabilistic-Mode-Suppression",
    "abstract": "Recent studies suggested that the BitTorrent's rarest-first protocol, owing\nto its work-conserving nature, can become unstable in the presence of\nnon-persistent users. Consequently, for any provably stable protocol, many\npeers, at some point, would have to be endogenously forced to hold off their\nfile-download activity. In this work, we propose a tunable piece-selection\npolicy that minimizes this (undesirable) requisite by combining the\n(work-conserving but not stabilizing) rarest-first protocol with only an\nappropriate share of the (non-work conserving and stabilizing) mode-suppression\nprotocol. We refer to this policy as ``Rarest-First with Probabilistic\nMode-Suppression'' or simply RFwPMS. We study RFwPMS using a stochastic\nabstraction of the BitTorrent network that is general enough to capture a\nmultiple swarm setting of non-persistent users -- each swarm having its own\naltruistic preferences that may or may not overlap with those of other swarms.\nUsing Lyapunov drift analysis, we show that for all kinds of inter-swarm\nbehaviors and all arrival-rate configurations, RFwPMS is stable. Then, using\nthe Kingman's moment bound technique, we further show that the expected\nsteady-state sojourn time of RFwPMS is independent of the arrival-rate in the\nsingle-swarm case (under a mild additional assumption). Finally, our\nsimulation-based performance evaluation confirms our theoretical findings and\nshows that the steady-state expected sojourn time is linear in the file-size\n(compared to our loose estimate of a polynomial with degree 6). Overall, an\nimproved performance is observed in comparison to previously proposed\nstabilizing schemes like mode-suppression (MS).",
    "descriptor": "",
    "authors": [
      "Nouman Khan",
      "Mehrdad Moharrami",
      "Vijay Subramanian"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.00213"
  },
  {
    "id": "arXiv:2211.00214",
    "title": "Transfer Learning with Physics-Informed Neural Networks for Efficient  Simulation of Branched Flows",
    "abstract": "Physics-Informed Neural Networks (PINNs) offer a promising approach to\nsolving differential equations and, more generally, to applying deep learning\nto problems in the physical sciences. We adopt a recently developed transfer\nlearning approach for PINNs and introduce a multi-head model to efficiently\nobtain accurate solutions to nonlinear systems of ordinary differential\nequations with random potentials. In particular, we apply the method to\nsimulate stochastic branched flows, a universal phenomenon in random wave\ndynamics. Finally, we compare the results achieved by feed forward and\nGAN-based PINNs on two physically relevant transfer learning tasks and show\nthat our methods provide significant computational speedups in comparison to\nstandard PINNs trained from scratch.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Rapha\u00ebl Pellegrin",
      "Blake Bullwinkel",
      "Marios Mattheakis",
      "Pavlos Protopapas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.00214"
  },
  {
    "id": "arXiv:2211.00216",
    "title": "Distributed Graph Neural Network Training: A Survey",
    "abstract": "Graph neural networks (GNNs) are a type of deep learning models that learning\nover graphs, and have been successfully applied in many domains. Despite the\neffectiveness of GNNs, it is still challenging for GNNs to efficiently scale to\nlarge graphs. As a remedy, distributed computing becomes a promising solution\nof training large-scale GNNs, since it is able to provide abundant computing\nresources. However, the dependency of graph structure increases the difficulty\nof achieving high-efficiency distributed GNN training, which suffers from the\nmassive communication and workload imbalance. In recent years, many efforts\nhave been made on distributed GNN training, and an array of training algorithms\nand systems have been proposed. Yet, there is a lack of systematic review on\nthe optimization techniques from graph processing to distributed execution. In\nthis survey, we analyze three major challenges in distributed GNN training that\nare massive feature communication, the loss of model accuracy and workload\nimbalance. Then we introduce a new taxonomy for the optimization techniques in\ndistributed GNN training that address the above challenges. The new taxonomy\nclassifies existing techniques into four categories that are GNN data\npartition, GNN batch generation, GNN execution model, and GNN communication\nprotocol.We carefully discuss the techniques in each category. In the end, we\nsummarize existing distributed GNN systems for multi-GPUs, GPU-clusters and\nCPU-clusters, respectively, and give a discussion about the future direction on\nscalable GNNs.",
    "descriptor": "",
    "authors": [
      "Yingxia Shao",
      "Hongzheng Li",
      "Xizhi Gu",
      "Hongbo Yin",
      "Yawen Li",
      "Xupeng Miao",
      "Wentao Zhang",
      "Bin Cui",
      "Lei Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.00216"
  },
  {
    "id": "arXiv:2211.00217",
    "title": "Tensor Regularized Total Least Squares Methods with Applications to  Image and Video Deblurring",
    "abstract": "Total Least Squares (TLS) is an effective method for solving linear equations\nwith the situations, when noise is not just in observation matrices but also\nmapping matrices. Moreover, Tikhonov regularization is widely used in plenty of\nill-posed problems. In this paper, we extend the Regularized Total Least\nSquares (RTLS) method in matrix form proposed by Golub, Hansen and O'Leary in\n1999 to tensor form, proposing the tensor Regularized Total Least Squares\n(TRTLS) method for solving ill-conditioned tensor systems of equations.\nProperties and algorithms about the solution of TRTLS problem, which might be\nsimilar with those about RTLS, are also proposed and proved. Based on this\nmethod, some applications in image and video deblurring are explored in this\npaper. Numerical experiments show the effectiveness of TRTLS method, compared\nwith the existing methods.",
    "descriptor": "",
    "authors": [
      "F. Han",
      "Y. Wei"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.00217"
  },
  {
    "id": "arXiv:2211.00218",
    "title": "Pixel-Wise Contrastive Distillation",
    "abstract": "We present the first pixel-level self-supervised distillation framework\nspecified for dense prediction tasks. Our approach, called Pixel-Wise\nContrastive Distillation (PCD), distills knowledge by attracting the\ncorresponding pixels from student's and teacher's output feature maps. This\npixel-to-pixel distillation demands for maintaining the spatial information of\nteacher's output. We propose a SpatialAdaptor that adapts the well-trained\nprojection/prediction head of the teacher used to encode vectorized features to\nprocessing 2D feature maps. SpatialAdaptor enables more informative pixel-level\ndistillation, yielding a better student for dense prediction tasks. Besides, in\nlight of the inadequate effective receptive fields of small models, we utilize\na plug-in multi-head self-attention module to explicitly relate the pixels of\nstudent's feature maps. Overall, our PCD outperforms previous self-supervised\ndistillation methods on various dense prediction tasks. A backbone of ResNet-18\ndistilled by PCD achieves $37.4$ AP$^\\text{bbox}$ and $34.0$ AP$^{mask}$ with\nMask R-CNN detector on COCO dataset, emerging as the first pre-training method\nsurpassing the supervised pre-trained counterpart.",
    "descriptor": "\nComments: tech report\n",
    "authors": [
      "Junqiang Huang",
      "Zichao Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00218"
  },
  {
    "id": "arXiv:2211.00221",
    "title": "Review on Monitoring, Operation and Maintenance of Smart Offshore Wind  Farms",
    "abstract": "In recent years, with the development of wind energy, the number and scale of\nwind farms are developing rapidly. Since offshore wind farm has the advantages\nof stable wind speed, clean, renewable, non-polluting and no occupation of\ncultivated land, which has gradually become a new trend of wind power industry\nall over the world. The operation and maintenance mode of offshore wind power\nis developing in the direction of digitization and intelligence. It is of great\nsignificance to carry out the research on the monitoring, operation and\nmaintenance of offshore wind farm, which will be of benefits to reduce the\noperation and maintenance cost, improve the power generation efficiency,\nimprove the stability of offshore wind farm system and build smart offshore\nwind farm. This paper will mainly analyze and summarize the monitoring,\noperation and maintenance of offshore wind farm, especially from the following\npoints: monitoring of \"offshore wind power engineering & biological &\nenvironment\", the monitoring of power equipment and the operation & maintenance\nof smart offshore wind farms. Finally, the future research challenges about\nmonitoring, operation and maintenance of smart offshore wind farm are proposed,\nand the future research directions in this field are prospected.",
    "descriptor": "\nComments: accepted by Sensors\n",
    "authors": [
      "Lei Kou",
      "Yang Li",
      "Fangfang Zhang",
      "Xiaodong Gong",
      "Yinghong Hu",
      "Quande Yuan",
      "Wende Ke"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.00221"
  },
  {
    "id": "arXiv:2211.00222",
    "title": "SDMuse: Stochastic Differential Music Editing and Generation via Hybrid  Representation",
    "abstract": "While deep generative models have empowered music generation, it remains a\nchallenging and under-explored problem to edit an existing musical piece at\nfine granularity. In this paper, we propose SDMuse, a unified Stochastic\nDifferential Music editing and generation framework, which can not only compose\na whole musical piece from scratch, but also modify existing musical pieces in\nmany ways, such as combination, continuation, inpainting, and style\ntransferring. The proposed SDMuse follows a two-stage pipeline to achieve music\ngeneration and editing on top of a hybrid representation including pianoroll\nand MIDI-event. In particular, SDMuse first generates/edits pianoroll by\niteratively denoising through a stochastic differential equation (SDE) based on\na diffusion model generative prior, and then refines the generated pianoroll\nand predicts MIDI-event tokens auto-regressively. We evaluate the generated\nmusic of our method on ailabs1k7 pop music dataset in terms of quality and\ncontrollability on various music editing and generation tasks. Experimental\nresults demonstrate the effectiveness of our proposed stochastic differential\nmusic editing and generation process, as well as the hybrid representations.",
    "descriptor": "",
    "authors": [
      "Chen Zhang",
      "Yi Ren",
      "Kejun Zhang",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00222"
  },
  {
    "id": "arXiv:2211.00224",
    "title": "SOLAR: A Highly Optimized Data Loading Framework for Distributed  Training of CNN-based Scientific Surrogates",
    "abstract": "CNN-based surrogates have become prevalent in scientific applications to\nreplace conventional time-consuming physical approaches. Although these\nsurrogates can yield satisfactory results with significantly lower computation\ncosts over small training datasets, our benchmarking results show that\ndata-loading overhead becomes the major performance bottleneck when training\nsurrogates with large datasets. In practice, surrogates are usually trained\nwith high-resolution scientific data, which can easily reach the terabyte\nscale. Several state-of-the-art data loaders are proposed to improve the\nloading throughput in general CNN training; however, they are sub-optimal when\napplied to the surrogate training. In this work, we propose SOLAR, a surrogate\ndata loader, that can ultimately increase loading throughput during the\ntraining. It leverages our three key observations during the benchmarking and\ncontains three novel designs. Specifically, SOLAR first generates a\npre-determined shuffled index list and accordingly optimizes the global access\norder and the buffer eviction scheme to maximize the data reuse and the buffer\nhit rate. It then proposes a tradeoff between lightweight computational\nimbalance and heavyweight loading workload imbalance to speed up the overall\ntraining. It finally optimizes its data access pattern with HDF5 to achieve a\nbetter parallel I/O throughput. Our evaluation with three scientific surrogates\nand 32 GPUs illustrates that SOLAR can achieve up to 24.4X speedup over PyTorch\nData Loader and 3.52X speedup over state-of-the-art data loaders.",
    "descriptor": "\nComments: 14 pages, 15 figures, 5 tables\n",
    "authors": [
      "Baixi Sun",
      "Xiaodong Yu",
      "Chengming Zhang",
      "Jiannan Tian",
      "Sian Jin",
      "Kamil Iskra",
      "Tao Zhou",
      "Tekin Bicer",
      "Pete Beckman",
      "Dingwen Tao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00224"
  },
  {
    "id": "arXiv:2211.00225",
    "title": "Additive Schwarz algorithms for neural network approximate solutions",
    "abstract": "Additive Schwarz algorithms are proposed as an iterative procedure for neural\nnetwork approximate solutions of partial differential equations. Based on the\nconvergence analysis of the additive Schwarz algorithms in a general Hilbert\nspace setting, the convergence of the neural network approximate solutions is\nanalyzed for the one-level and two-level iterative schemes. Numerical results\nof the proposed methods are presented for test examples.",
    "descriptor": "",
    "authors": [
      "Hee Jun Yang",
      "Hyea Hyun Kim"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.00225"
  },
  {
    "id": "arXiv:2211.00227",
    "title": "Transfer Learning with Kernel Methods",
    "abstract": "Transfer learning refers to the process of adapting a model trained on a\nsource task to a target task. While kernel methods are conceptually and\ncomputationally simple machine learning models that are competitive on a\nvariety of tasks, it has been unclear how to perform transfer learning for\nkernel methods. In this work, we propose a transfer learning framework for\nkernel methods by projecting and translating the source model to the target\ntask. We demonstrate the effectiveness of our framework in applications to\nimage classification and virtual drug screening. In particular, we show that\ntransferring modern kernels trained on large-scale image datasets can result in\nsubstantial performance increase as compared to using the same kernel trained\ndirectly on the target task. In addition, we show that transfer-learned kernels\nallow a more accurate prediction of the effect of drugs on cancer cell lines.\nFor both applications, we identify simple scaling laws that characterize the\nperformance of transfer-learned kernels as a function of the number of target\nexamples. We explain this phenomenon in a simplified linear setting, where we\nare able to derive the exact scaling laws. By providing a simple and effective\ntransfer learning framework for kernel methods, our work enables kernel methods\ntrained on large datasets to be easily adapted to a variety of downstream\ntarget tasks.",
    "descriptor": "",
    "authors": [
      "Adityanarayanan Radhakrishnan",
      "Max Ruiz Luyten",
      "Neha Prasad",
      "Caroline Uhler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00227"
  },
  {
    "id": "arXiv:2211.00228",
    "title": "Fault diagnosis for three-phase PWM rectifier based on deep feedforward  network with transient synthetic features",
    "abstract": "Three-phase PWM rectifiers are adopted extensively in industry because of\ntheir excellent properties and potential advantages. However, while the IGBT\nhas an open-circuit fault, the system does not crash suddenly, the performance\nwill be reduced for instance voltages fluctuation and current harmonics. A\nfault diagnosis method based on deep feedforward network with transient\nsynthetic features is proposed to reduce the dependence on the fault\nmathematical models in this paper, which mainly uses the transient phase\ncurrent to train the deep feedforward network classifier. Firstly, the features\nof fault phase current are analyzed in this paper. Secondly, the historical\nfault data after feature synthesis is employed to train the deep feedforward\nnetwork classifier, and the average fault diagnosis accuracy can reach 97.85%\nfor transient synthetic fault data, the classifier trained by the transient\nsynthetic features obtained more than 1% gain in performance compared with\noriginal transient features. Finally, the online fault diagnosis experiments\nshow that the method can accurately locate the fault IGBTs, and the final\ndiagnosis result is determined by multiple groups results, which has the\nability to increase the accuracy and reliability of the diagnosis results. (c)\n2020 ISA. Published by Elsevier Ltd. All rights reserved.",
    "descriptor": "\nComments: ISA TRANSACTIONS\n",
    "authors": [
      "Kou Lei",
      "Liu Chuang",
      "Cai Guo-Wei",
      "Zhang Zhe",
      "Zhou Jia-Ning",
      "Wang Xue-Mei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.00228"
  },
  {
    "id": "arXiv:2211.00229",
    "title": "Full-Duplex Communication for ISAC: Joint Beamforming and Power  Optimization",
    "abstract": "Beamforming design has been widely investigated for integrated sensing and\ncommunication (ISAC) systems with full-duplex (FD) sensing and half-duplex (HD)\ncommunication. To achieve higher spectral efficiency, in this paper, we extend\nexisting ISAC beamforming design by considering the FD capability for both\nradar and communication. Specifically, we consider an ISAC system, where the BS\nperforms target detection and communicates with multiple downlink users and\nuplink users reusing the same time and frequency resources. We jointly optimize\nthe downlink dual-functional transmit signal and the uplink receive beamformers\nat the BS and the transmit power at the uplink users. The problems are\nformulated under two criteria: power consumption minimization and sum rate\nmaximization. The downlink and uplink transmissions are tightly coupled due to\nboth the desired target echo and the undesired interference received at the BS,\nmaking the problems challenging. To handle these issues in both cases, we first\ndetermine the optimal receive beamformers, which are derived in closed forms\nwith respect to the BS transmit beamforming and the user transmit power, for\nradar target detection and uplink communications, respectively. Subsequently,\nwe invoke these results to obtain equivalent optimization problems and propose\nefficient iterative algorithms to solve them by using the techniques of rank\nrelaxation and successive convex approximation (SCA), where the adopted\nrelaxation is proven to be tight. In addition, we consider a special case under\nthe power minimization criterion and propose an alternative low complexity\ndesign. Numerical results demonstrate that the optimized FD communication-based\nISAC brings tremendous improvements in terms of both power efficiency and\nspectral efficiency compared to the conventional ISAC with HD communication.",
    "descriptor": "\nComments: Submitted to IEEE for possible publication\n",
    "authors": [
      "Zhenyao He",
      "Wei Xu",
      "Hong Shen",
      "Derrick Wing Kwan Ng",
      "Yonina C. Eldar",
      "Xiaohu You"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.00229"
  },
  {
    "id": "arXiv:2211.00230",
    "title": "Multi-Network Joint Source-Channel Coding Over Varying Noise Channels",
    "abstract": "Inspired by the recent success of deep learning methods for joint source and\nchannel coding (JSCC), we propose an optimized system to improve the\nperformance in the transmission of deep-JSCC in an environment of time-varying\nnoise. The scheme incorporates three aspects: First, a multi-network parallel\nstructure is proposed to sufficiently exploit the label information. Second, a\nclosed-form linear encoder \\& decoder pair is adopted at the input and output\nend of the channel to handle the noise variation under the power constraint.\nThe linear encoder and decoder update themselves in terms of the estimation on\nthe channel noise from the pilot signals. Third, the estimation of the noise\nstatistics is fulfilled by a transfer learning algorithm, which outperforms the\nusual estimation methods when the noise statistics are time-dependent. These\nthree ingredients are integrated efficiently together in the scheme to form a\ncomplete image transmission system. Numerical results show that our optimized\nscheme performs better than the existing schemes in the literature.",
    "descriptor": "",
    "authors": [
      "Weida Wang",
      "Xinchun Yu",
      "Xinyi Tong",
      "Runpeng Yu",
      "Shao-Lun Huang",
      "Xiao-Ping Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.00230"
  },
  {
    "id": "arXiv:2211.00233",
    "title": "Detection of (Hidden) Emotions from Videos using Muscles Movements and  Face Manifold Embedding",
    "abstract": "We provide a new non-invasive, easy-to-scale for large amounts of subjects\nand a remotely accessible method for (hidden) emotion detection from videos of\nhuman faces. Our approach combines face manifold detection for accurate\nlocation of the face in the video with local face manifold embedding to create\na common domain for the measurements of muscle micro-movements that is\ninvariant to the movement of the subject in the video. In the next step, we\nemploy the Digital Image Speckle Correlation (DISC) and the optical flow\nalgorithm to compute the pattern of micro-movements in the face. The\ncorresponding vector field is mapped back to the original space and\nsuperimposed on the original frames of the videos. Hence, the resulting videos\ninclude additional information about the direction of the movement of the\nmuscles in the face. We take the publicly available CK++ dataset of visible\nemotions and add to it videos of the same format but with hidden emotions. We\nprocess all the videos using our micro-movement detection and use the results\nto train a state-of-the-art network for emotions classification from videos --\nFrame Attention Network (FAN). Although the original FAN model achieves very\nhigh out-of-sample performance on the original CK++ videos, it does not perform\nso well on hidden emotions videos. The performance improves significantly when\nthe model is trained and tested on videos with the vector fields of muscle\nmovements. Intuitively, the corresponding arrows serve as edges in the image\nthat are easily captured by the convolutions filters in the FAN network.",
    "descriptor": "",
    "authors": [
      "Juni Kim",
      "Zhikang Dong",
      "Eric Guan",
      "Judah Rosenthal",
      "Shi Fu",
      "Miriam Rafailovich",
      "Pawel Polak"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00233"
  },
  {
    "id": "arXiv:2211.00234",
    "title": "Clustering-Based Approaches for Symbolic Knowledge Extraction",
    "abstract": "Opaque models belonging to the machine learning world are ever more exploited\nin the most different application areas. These models, acting as black boxes\n(BB) from the human perspective, cannot be entirely trusted if the application\nis critical unless there exists a method to extract symbolic and human-readable\nknowledge out of them. In this paper we analyse a recurrent design adopted by\nsymbolic knowledge extractors for BB regressors - that is, the creation of\nrules associated with hypercubic input space regions. We argue that this kind\nof partitioning may lead to suboptimal solutions when the data set at hand is\nhigh-dimensional or does not satisfy symmetric constraints. We then propose a\n(deep) clustering-based approach to be performed before symbolic knowledge\nextraction to achieve better performance with data sets of any kind.",
    "descriptor": "\nComments: Third Workshop on Explainable Logic-Based Knowledge Representation (XLoKR2022)\n",
    "authors": [
      "Federico Sabbatini",
      "Roberta Calegari"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00234"
  },
  {
    "id": "arXiv:2211.00235",
    "title": "Efficient AlphaFold2 Training using Parallel Evoformer and Branch  Parallelism",
    "abstract": "The accuracy of AlphaFold2, a frontier end-to-end structure prediction\nsystem, is already close to that of the experimental determination techniques.\nDue to the complex model architecture and large memory consumption, it requires\nlots of computational resources and time to train AlphaFold2 from scratch.\nEfficient AlphaFold2 training could accelerate the development of life science.\nIn this paper, we propose a Parallel Evoformer and Branch Parallelism to speed\nup the training of AlphaFold2. We conduct sufficient experiments on UniFold\nimplemented in PyTorch and HelixFold implemented in PaddlePaddle, and Branch\nParallelism can improve the training performance by 38.67% and 36.93%,\nrespectively. We also demonstrate that the accuracy of Parallel Evoformer could\nbe on par with AlphaFold2 on the CASP14 and CAMEO datasets. The source code is\navailable on https://github.com/PaddlePaddle/PaddleFleetX",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2207.05477\n",
    "authors": [
      "Guoxia Wang",
      "Zhihua Wu",
      "Xiaomin Fang",
      "Yingfei Xiang",
      "Yiqun Liu",
      "Dianhai Yu",
      "Yanjun Ma"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.00235"
  },
  {
    "id": "arXiv:2211.00238",
    "title": "Evaluation Metrics for Symbolic Knowledge Extracted from Machine  Learning Black Boxes: A Discussion Paper",
    "abstract": "As opaque decision systems are being increasingly adopted in almost any\napplication field, issues about their lack of transparency and human\nreadability are a concrete concern for end-users. Amongst existing proposals to\nassociate human-interpretable knowledge with accurate predictions provided by\nopaque models, there are rule extraction techniques, capable of extracting\nsymbolic knowledge out of an opaque model. However, how to assess the level of\nreadability of the extracted knowledge quantitatively is still an open issue.\nFinding such a metric would be the key, for instance, to enable automatic\ncomparison between a set of different knowledge representations, paving the way\nfor the development of parameter autotuning algorithms for knowledge\nextractors. In this paper we discuss the need for such a metric as well as the\ncriticalities of readability assessment and evaluation, taking into account the\nmost common knowledge representations while highlighting the most puzzling\nissues.",
    "descriptor": "\nComments: 2nd International Workshop on Explainable AI in Finance (XAI-FIN 2022)\n",
    "authors": [
      "Federico Sabbatini",
      "Roberta Calegari"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00238"
  },
  {
    "id": "arXiv:2211.00239",
    "title": "ARDIR: Improving Robustness using Knowledge Distillation of Internal  Representation",
    "abstract": "Adversarial training is the most promising method for learning robust models\nagainst adversarial examples. A recent study has shown that knowledge\ndistillation between the same architectures is effective in improving the\nperformance of adversarial training. Exploiting knowledge distillation is a new\napproach to improve adversarial training and has attracted much attention.\nHowever, its performance is still insufficient. Therefore, we propose\nAdversarial Robust Distillation with Internal Representation~(ARDIR) to utilize\nknowledge distillation even more effectively. In addition to the output of the\nteacher model, ARDIR uses the internal representation of the teacher model as a\nlabel for adversarial training. This enables the student model to be trained\nwith richer, more informative labels. As a result, ARDIR can learn more robust\nstudent models. We show that ARDIR outperforms previous methods in our\nexperiments.",
    "descriptor": "\nComments: 15 pages, 3 figures\n",
    "authors": [
      "Tomokatsu Takahashi",
      "Masanori Yamada",
      "Yuuki Yamanaka",
      "Tomoya Yamashita"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00239"
  },
  {
    "id": "arXiv:2211.00241",
    "title": "Adversarial Policies Beat Professional-Level Go AIs",
    "abstract": "We attack the state-of-the-art Go-playing AI system, KataGo, by training an\nadversarial policy that plays against a frozen KataGo victim. Our attack\nachieves a >99% win-rate against KataGo without search, and a >50% win-rate\nwhen KataGo uses enough search to be near-superhuman. To the best of our\nknowledge, this is the first successful end-to-end attack against a Go AI\nplaying at the level of a top human professional. Notably, the adversary does\nnot win by learning to play Go better than KataGo -- in fact, the adversary is\neasily beaten by human amateurs. Instead, the adversary wins by tricking KataGo\ninto ending the game prematurely at a point that is favorable to the adversary.\nOur results demonstrate that even professional-level AI systems may harbor\nsurprising failure modes. See https://goattack.alignmentfund.org/ for example\ngames.",
    "descriptor": "\nComments: 21 pages, 11 figures\n",
    "authors": [
      "Tony Tong Wang",
      "Adam Gleave",
      "Nora Belrose",
      "Tom Tseng",
      "Joseph Miller",
      "Michael D Dennis",
      "Yawen Duan",
      "Viktor Pogrebniak",
      "Sergey Levine",
      "Stuart Russell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.00241"
  },
  {
    "id": "arXiv:2211.00243",
    "title": "Why Is It Hate Speech? Masked Rationale Prediction for Explainable Hate  Speech Detection",
    "abstract": "In a hate speech detection model, we should consider two critical aspects in\naddition to detection performance-bias and explainability. Hate speech cannot\nbe identified based solely on the presence of specific words: the model should\nbe able to reason like humans and be explainable. To improve the performance\nconcerning the two aspects, we propose Masked Rationale Prediction (MRP) as an\nintermediate task. MRP is a task to predict the masked human\nrationales-snippets of a sentence that are grounds for human judgment-by\nreferring to surrounding tokens combined with their unmasked rationales. As the\nmodel learns its reasoning ability based on rationales by MRP, it performs hate\nspeech detection robustly in terms of bias and explainability. The proposed\nmethod generally achieves state-of-the-art performance in various metrics,\ndemonstrating its effectiveness for hate speech detection.",
    "descriptor": "\nComments: 10 pages, 4 figures, 3 tables. Accepted at COLING 2022\n",
    "authors": [
      "Jiyun Kim",
      "Byounghan Lee",
      "Kyung-Ah Sohn"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.00243"
  },
  {
    "id": "arXiv:2211.00246",
    "title": "Batch Active Learning from the Perspective of Sparse Approximation",
    "abstract": "Active learning enables efficient model training by leveraging interactions\nbetween machine learning agents and human annotators. We study and propose a\nnovel framework that formulates batch active learning from the sparse\napproximation's perspective. Our active learning method aims to find an\ninformative subset from the unlabeled data pool such that the corresponding\ntraining loss function approximates its full data pool counterpart. We realize\nthe framework as sparsity-constrained discontinuous optimization problems,\nwhich explicitly balance uncertainty and representation for large-scale\napplications and could be solved by greedy or proximal iterative hard\nthresholding algorithms. The proposed method can adapt to various settings,\nincluding both Bayesian and non-Bayesian neural networks. Numerical experiments\nshow that our work achieves competitive performance across different settings\nwith lower computational complexity.",
    "descriptor": "",
    "authors": [
      "Maohao Shen",
      "Bowen Jiang",
      "Jacky Yibo Zhang",
      "Oluwasanmi Koyejo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.00246"
  },
  {
    "id": "arXiv:2211.00247",
    "title": "Discrete Factorial Representations as an Abstraction for Goal  Conditioned Reinforcement Learning",
    "abstract": "Goal-conditioned reinforcement learning (RL) is a promising direction for\ntraining agents that are capable of solving multiple tasks and reach a diverse\nset of objectives. How to \\textit{specify} and \\textit{ground} these goals in\nsuch a way that we can both reliably reach goals during training as well as\ngeneralize to new goals during evaluation remains an open area of research.\nDefining goals in the space of noisy and high-dimensional sensory inputs poses\na challenge for training goal-conditioned agents, or even for generalization to\nnovel goals. We propose to address this by learning factorial representations\nof goals and processing the resulting representation via a discretization\nbottleneck, for coarser goal specification, through an approach we call DGRL.\nWe show that applying a discretizing bottleneck can improve performance in\ngoal-conditioned RL setups, by experimentally evaluating this method on tasks\nranging from maze environments to complex robotic navigation and manipulation.\nAdditionally, we prove a theorem lower-bounding the expected return on\nout-of-distribution goals, while still allowing for specifying goals with\nexpressive combinatorial structure.",
    "descriptor": "\nComments: Neurips 2022\n",
    "authors": [
      "Riashat Islam",
      "Hongyu Zang",
      "Anirudh Goyal",
      "Alex Lamb",
      "Kenji Kawaguchi",
      "Xin Li",
      "Romain Laroche",
      "Yoshua Bengio",
      "Remi Tachet Des Combes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00247"
  },
  {
    "id": "arXiv:2211.00250",
    "title": "FADO: Feedback-Aware Double COntrolling Network for Emotional Support  Conversation",
    "abstract": "Emotional Support Conversation (ESConv) aims to reduce help-seekers'emotional\ndistress with the supportive strategy and response. It is essential for the\nsupporter to select an appropriate strategy with the feedback of the\nhelp-seeker (e.g., emotion change during dialog turns, etc) in ESConv. However,\nprevious methods mainly focus on the dialog history to select the strategy and\nignore the help-seeker's feedback, leading to the wrong and user-irrelevant\nstrategy prediction. In addition, these approaches only model the\ncontext-to-strategy flow and pay less attention to the strategy-to-context flow\nthat can focus on the strategy-related context for generating the\nstrategy-constrain response. In this paper, we propose a Feedback-Aware Double\nCOntrolling Network (FADO) to make a strategy schedule and generate the\nsupportive response. The core module in FADO consists of a dual-level feedback\nstrategy selector and a double control reader. Specifically, the dual-level\nfeedback strategy selector leverages the turn-level and conversation-level\nfeedback to encourage or penalize strategies. The double control reader\nconstructs the novel strategy-to-context flow for generating the\nstrategy-constrain response. Furthermore, a strategy dictionary is designed to\nenrich the semantic information of the strategy and improve the quality of\nstrategy-constrain response. Experimental results on ESConv show that the\nproposed FADO has achieved the state-of-the-art performance in terms of both\nstrategy selection and response generation. Our code is available at\nhttps://github/after/reviewing.",
    "descriptor": "",
    "authors": [
      "Wei Peng",
      "Ziyuan Qin",
      "Yue Hu",
      "Yuqiang Xie",
      "Yunpeng Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.00250"
  },
  {
    "id": "arXiv:2211.00251",
    "title": "End-to-End Optimization and Learning for Multiagent Ensembles",
    "abstract": "Multiagent ensemble learning is an important class of algorithms aimed at\ncreating accurate and robust machine learning models by combining predictions\nfrom individual agents. A key challenge for the design of these models is to\ncreate effective rules to combine individual predictions for any particular\ninput sample.\nThis paper addresses this challenge and proposes a unique integration of\nconstrained optimization and learning to derive specialized consensus rules to\ncompose accurate predictions from a pretrained ensemble. The resulting\nstrategy, called end-to-end Multiagent ensemble Learning (e2e-MEL), learns to\nselect appropriate predictors to combine for a particular input sample. The\npaper shows how to derive the ensemble learning task into a differentiable\nselection program which is trained end-to-end within the ensemble learning\nmodel. Results over standard benchmarks demonstrate the ability of e2e-MEL to\nsubstantially outperform conventional consensus rules in a variety of settings.",
    "descriptor": "\nComments: Preprint. Under review\n",
    "authors": [
      "James Kotary",
      "Vincenzo Di Vito",
      "Ferdinando Fioretto"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.00251"
  },
  {
    "id": "arXiv:2211.00255",
    "title": "CARE: Causality Reasoning for Empathetic Responses by Conditional Graph  Generation",
    "abstract": "Recent approaches to empathetic response generation incorporate emotion\ncausalities to enhance comprehension of both the user's feelings and\nexperiences. However, these approaches suffer from two critical issues. First,\nthey only consider causalities between the user's emotion and the user's\nexperiences, and ignore those between the user's experiences. Second, they\nneglect interdependence among causalities and reason them independently. To\nsolve the above problems, we expect to reason all plausible causalities\ninterdependently and simultaneously, given the user's emotion, dialogue\nhistory, and future dialogue content. Then, we infuse these causalities into\nresponse generation for empathetic responses. Specifically, we design a new\nmodel, i.e., the Conditional Variational Graph Auto-Encoder (CVGAE), for the\ncausality reasoning, and adopt a multi-source attention mechanism in the\ndecoder for the causality infusion. We name the whole framework as CARE,\nabbreviated for CAusality Reasoning for Empathetic conversation. Experimental\nresults indicate that our method achieves state-of-the-art performance.",
    "descriptor": "\nComments: EMNLP 2022 findings\n",
    "authors": [
      "Jiashuo Wang",
      "Yi Cheng",
      "Wenjie Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.00255"
  },
  {
    "id": "arXiv:2211.00256",
    "title": "Feature-Informed Data Assimilation -- Definitions and Illustrative  Examples",
    "abstract": "We introduce a mathematical formulation of feature-informed data assimilation\n(FIDA). In FIDA, the information about feature events, such as shock waves,\nlevel curves, wavefronts and peak value, in dynamical systems are used for the\nestimation of state variables and unknown parameters. The observation operator\nin FIDA is a set-valued functional, which is fundamentally different from the\nobservation operators in conventional data assimilation. Demonstrated in three\nexample, FIDA problems introduced in this note exist in a wide spectrum of\napplications in science and engineering.",
    "descriptor": "",
    "authors": [
      "Wei Kang",
      "Daniel M. Tartakovsky",
      "Apoorv Srivastava"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.00256"
  },
  {
    "id": "arXiv:2211.00262",
    "title": "Training Vision-Language Models with Less Bimodal Supervision",
    "abstract": "Standard practice in pretraining multimodal models, such as vision-language\nmodels, is to rely on pairs of aligned inputs from both modalities, for\nexample, aligned image-text pairs. However, such pairs can be difficult to\nobtain in low-resource settings and for some modality pairs (e.g., structured\ntables and images). In this work, we investigate the extent to which we can\nreduce the reliance on such parallel data, which we term \\emph{bimodal\nsupervision}, and use models that are pretrained on each modality\nindependently. We experiment with a high-performing vision-language model, and\nanalyze the effect of bimodal supervision on three vision-language tasks. We\nfind that on simpler tasks, such as VQAv2 and GQA, one can eliminate bimodal\nsupervision completely, suffering only a minor loss in performance. Conversely,\nfor NLVR2, which requires more complex reasoning, training without bimodal\nsupervision leads to random performance. Nevertheless, using only 5\\% of the\nbimodal data (142K images along with their captions), or leveraging weak\nsupervision in the form of a list of machine-generated labels for each image,\nleads to only a moderate degradation compared to using 3M image-text pairs:\n74\\%$\\rightarrow$$\\sim$70\\%. Our code is available at\nhttps://github.com/eladsegal/less-bimodal-sup.",
    "descriptor": "\nComments: AKBC 2022\n",
    "authors": [
      "Elad Segal",
      "Ben Bogin",
      "Jonathan Berant"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00262"
  },
  {
    "id": "arXiv:2211.00266",
    "title": "Two Low-complexity Efficient Beamformers for IRS-aided Directional  Modulation Networks",
    "abstract": "As an excellent tool for aiding communication, intelligent reflecting surface\n(IRS) can extend the coverage area, remove blind area, and achieve a dramatic\nrate improvement. In this paper, we improve the secret rate (SR) performance at\ndirectional modulation (DM) networks using IRS. To fully explore the benefits\nof IRS, two efficient methods are proposed to enhance SR performance. The first\napproach computes the confidential message (CM) beamforming vector by\nmaximizing the SR, and the signal-to-leakage-noise ratio (SLNR) method is used\nto optimize the IRS phase shift matrix, which is called Max-SR-SLNR. Here, Eve\nis maximally interfered by transmiting artificial noise (AN) along the direct\npath and null-space projection (NSP) on the remaining two channels. To reduce\nthe computational complexity, the CM, AN beamforming and IRS phase shift design\nare independently designed in the following methods. The CM beamforming vector\nis constructed based on maximum ratio transmission (MRT) criteria along the\nchannel from Alice-to-IRS, and phase shift matrix of IRS is directly given by\nphase alignment (PA) method. This method is called MRT-NSP-PA. Simulation\nresults show that the SR performance of the Max-SR-SLNR method outperforms the\nMRT-NSP-PA method in the cases of small-scale and medium-scale IRSs, and the\nlatter approaches the former as IRS tends to lager-scale.",
    "descriptor": "",
    "authors": [
      "Yeqing Lin",
      "Rongen Dong",
      "Xun Chen",
      "Yue Wu",
      "Feng Shu",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.00266"
  },
  {
    "id": "arXiv:2211.00269",
    "title": "Adversarial Training with Complementary Labels: On the Benefit of  Gradually Informative Attacks",
    "abstract": "Adversarial training (AT) with imperfect supervision is significant but\nreceives limited attention. To push AT towards more practical scenarios, we\nexplore a brand new yet challenging setting, i.e., AT with complementary labels\n(CLs), which specify a class that a data sample does not belong to. However,\nthe direct combination of AT with existing methods for CLs results in\nconsistent failure, but not on a simple baseline of two-stage training. In this\npaper, we further explore the phenomenon and identify the underlying challenges\nof AT with CLs as intractable adversarial optimization and low-quality\nadversarial examples. To address the above problems, we propose a new learning\nstrategy using gradually informative attacks, which consists of two critical\ncomponents: 1) Warm-up Attack (Warm-up) gently raises the adversarial\nperturbation budgets to ease the adversarial optimization with CLs; 2)\nPseudo-Label Attack (PLA) incorporates the progressively informative model\npredictions into a corrected complementary loss. Extensive experiments are\nconducted to demonstrate the effectiveness of our method on a range of\nbenchmarked datasets. The code is publicly available at:\nhttps://github.com/RoyalSkye/ATCL.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Jianan Zhou",
      "Jianing Zhu",
      "Jingfeng Zhang",
      "Tongliang Liu",
      "Gang Niu",
      "Bo Han",
      "Masashi Sugiyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.00269"
  },
  {
    "id": "arXiv:2211.00273",
    "title": "ActGraph: Prioritization of Test Cases Based on Deep Neural Network  Activation Graph",
    "abstract": "Widespread applications of deep neural networks (DNNs) benefit from DNN\ntesting to guarantee their quality. In the DNN testing, numerous test cases are\nfed into the model to explore potential vulnerabilities, but they require\nexpensive manual cost to check the label. Therefore, test case prioritization\nis proposed to solve the problem of labeling cost, e.g., activation-based and\nmutation-based prioritization methods. However, most of them suffer from\nlimited scenarios (i.e. high confidence adversarial or false positive cases)\nand high time complexity. To address these challenges, we propose the concept\nof the activation graph from the perspective of the spatial relationship of\nneurons. We observe that the activation graph of cases that triggers the\nmodels' misbehavior significantly differs from that of normal cases. Motivated\nby it, we design a test case prioritization method based on the activation\ngraph, ActGraph, by extracting the high-order node features of the activation\ngraph for prioritization. ActGraph explains the difference between the test\ncases to solve the problem of scenario limitation. Without mutation operations,\nActGraph is easy to implement, leading to lower time complexity. Extensive\nexperiments on three datasets and four models demonstrate that ActGraph has the\nfollowing key characteristics. (i) Effectiveness and generalizability: ActGraph\nshows competitive performance in all of the natural, adversarial and mixed\nscenarios, especially in RAUC-100 improvement (~1.40). (ii) Efficiency:\nActGraph does not use complex mutation operations and runs in less time (~1/50)\nthan the state-of-the-art method.",
    "descriptor": "",
    "authors": [
      "Jinyin Chen",
      "Jie Ge",
      "Haibin Zheng"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.00273"
  },
  {
    "id": "arXiv:2211.00277",
    "title": "HFN: Heterogeneous Feature Network for Multivariate Time Series Anomaly  Detection",
    "abstract": "Network or physical attacks on industrial equipment or computer systems may\ncause massive losses. Therefore, a quick and accurate anomaly detection (AD)\nbased on monitoring data, especially the multivariate time-series (MTS) data,\nis of great significance. As the key step of anomaly detection for MTS data,\nlearning the relations among different variables has been explored by many\napproaches. However, most of the existing approaches do not consider the\nheterogeneity between variables, that is, different types of variables\n(continuous numerical variables, discrete categorical variables or hybrid\nvariables) may have different and distinctive edge distributions. In this\npaper, we propose a novel semi-supervised anomaly detection framework based on\na heterogeneous feature network (HFN) for MTS, learning heterogeneous structure\ninformation from a mass of unlabeled time-series data to improve the accuracy\nof anomaly detection, and using attention coefficient to provide an explanation\nfor the detected anomalies. Specifically, we first combine the embedding\nsimilarity subgraph generated by sensor embedding and feature value similarity\nsubgraph generated by sensor values to construct a time-series heterogeneous\ngraph, which fully utilizes the rich heterogeneous mutual information among\nvariables. Then, a prediction model containing nodes and channel attentions is\njointly optimized to obtain better time-series representations. This approach\nfuses the state-of-the-art technologies of heterogeneous graph structure\nlearning (HGSL) and representation learning. The experiments on four sensor\ndatasets from real-world applications demonstrate that our approach detects the\nanomalies more accurately than those baseline approaches, thus providing a\nbasis for the rapid positioning of anomalies.",
    "descriptor": "",
    "authors": [
      "Jun Zhan",
      "Chengkun Wu",
      "Canqun Yang",
      "Qiucheng Miao",
      "Xiandong Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.00277"
  },
  {
    "id": "arXiv:2211.00286",
    "title": "Strategies for Optimizing End-to-End Artificial Intelligence Pipelines  on Intel Xeon Processors",
    "abstract": "End-to-end (E2E) artificial intelligence (AI) pipelines are composed of\nseveral stages including data preprocessing, data ingestion, defining and\ntraining the model, hyperparameter optimization, deployment, inference,\npostprocessing, followed by downstream analyses. To obtain efficient E2E\nworkflow, it is required to optimize almost all the stages of pipeline. Intel\nXeon processors come with large memory capacities, bundled with AI acceleration\n(e.g., Intel Deep Learning Boost), well suited to run multiple instances of\ntraining and inference pipelines in parallel and has low total cost of\nownership (TCO). To showcase the performance on Xeon processors, we applied\ncomprehensive optimization strategies coupled with software and hardware\nacceleration on variety of E2E pipelines in the areas of Computer Vision, NLP,\nRecommendation systems, etc. We were able to achieve a performance improvement,\nranging from 1.8x to 81.7x across different E2E pipelines. In this paper, we\nwill be highlighting the optimization strategies adopted by us to achieve this\nperformance on Intel Xeon processors with a set of eight different E2E\npipelines.",
    "descriptor": "\nComments: 10 pages, 11 figures, 3 tables\n",
    "authors": [
      "Meena Arunachalam",
      "Vrushabh Sanghavi",
      "Yi A Yao",
      "Yi A Zhou",
      "Lifeng A Wang",
      "Zongru Wen",
      "Niroop Ammbashankar",
      "Ning W Wang",
      "Fahim Mohammad"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.00286"
  },
  {
    "id": "arXiv:2211.00288",
    "title": "Self-supervised Character-to-Character Distillation",
    "abstract": "Handling complicated text images (e.g., irregular structures, low resolution,\nheavy occlusion, and even illumination), existing supervised text recognition\nmethods are data-hungry. Although these methods employ large-scale synthetic\ntext images to reduce the dependence on annotated real images, the domain gap\nlimits the recognition performance. Therefore, exploring the robust text\nfeature representation on unlabeled real images by self-supervised learning is\na good solution. However, existing self-supervised text recognition methods\nonly execute sequence-to-sequence representation learning by roughly splitting\nthe visual features along the horizontal axis, which will damage the character\nstructures. Besides, these sequential-level self-learning methods limit the\navailability of geometric-based data augmentation, as large-scale geometry\naugmentation leads to sequence-to-sequence inconsistency. To address the\nabove-mentioned issues, we proposed a novel self-supervised\ncharacter-to-character distillation method, CCD. Specifically, we delineate the\ncharacter structures of unlabeled real images by designing a self-supervised\ncharacter segmentation module, and further apply the segmentation results to\nbuild character-level representation learning.\nCCD differs from prior works in that we propose a character-level pretext\ntask to learn more fine-grained feature representations. Besides, compared with\nthe inflexible augmentations of sequence-to-sequence models, our work satisfies\ncharacter-to-character representation consistency, across various\ntransformations (e.g., geometry and colour), to generate robust text features\nin the representative space. Experiments demonstrate that CCD achieves\nstate-of-the-art performance on publicly available text recognition benchmarks.",
    "descriptor": "",
    "authors": [
      "Tongkun Guan",
      "Wei Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00288"
  },
  {
    "id": "arXiv:2211.00289",
    "title": "Composable Coresets for Constrained Determinant Maximization and Beyond",
    "abstract": "We study the task of determinant maximization under partition constraint, in\nthe context of large data sets. Given a point set $V\\subset \\mathbb{R}^d$ that\nis partitioned into $s$ groups $V_1,..., V_s$, and integers $k_1,...,k_s$ where\n$k=\\sum_i k_i$, the goal is to pick $k_i$ points from group $i$ such that the\noverall determinant of the picked $k$ points is maximized. Determinant\nMaximization and its constrained variants have gained a lot of interest for\nmodeling diversityand have found applications in the context of fairness and\ndata summarization.\nWe study the design of composable coresets for the constrained determinant\nmaximization problem. Composable coresets are small subsets of the data that\n(approximately) preserve optimal solutions to optimization tasks and enable\nefficient solutions in several other large data models including the\ndistributed and the streaming settings. In this work, we consider two regimes.\nFor the case of $k>d$, we show a peeling algorithm that gives us a composable\ncoreset of size $kd$ with an approximation factor of $d^{O(d)}$. We complement\nour results by showing that this approximation factor is tight. For the case of\n$k\\leq d$, we show that a simple modification of the previous algorithms\nresults in an optimal coreset verified by our lower bounds. Our results apply\nto all strongly Rayleigh distribution and several other experimental design\nproblems. In addition, we show coreset construction algorithms under the more\ngeneral laminar matroid constraints.",
    "descriptor": "",
    "authors": [
      "Sepideh Mahabadi",
      "Thuy-Duong Vuong"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.00289"
  },
  {
    "id": "arXiv:2211.00294",
    "title": "FRSUM: Towards Faithful Abstractive Summarization via Enhancing Factual  Robustness",
    "abstract": "Despite being able to generate fluent and grammatical text, current Seq2Seq\nsummarization models still suffering from the unfaithful generation problem. In\nthis paper, we study the faithfulness of existing systems from a new\nperspective of factual robustness which is the ability to correctly generate\nfactual information over adversarial unfaithful information. We first measure a\nmodel's factual robustness by its success rate to defend against adversarial\nattacks when generating factual information. The factual robustness analysis on\na wide range of current systems shows its good consistency with human judgments\non faithfulness. Inspired by these findings, we propose to improve the\nfaithfulness of a model by enhancing its factual robustness. Specifically, we\npropose a novel training strategy, namely FRSUM, which teaches the model to\ndefend against both explicit adversarial samples and implicit factual\nadversarial perturbations. Extensive automatic and human evaluation results\nshow that FRSUM consistently improves the faithfulness of various Seq2Seq\nmodels, such as T5, BART.",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Wenhao Wu",
      "Wei Li",
      "Jiachen Liu",
      "Xinyan Xiao",
      "Ziqiang Cao",
      "Sujian Li",
      "Hua Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.00294"
  },
  {
    "id": "arXiv:2211.00295",
    "title": "CONDAQA: A Contrastive Reading Comprehension Dataset for Reasoning about  Negation",
    "abstract": "The full power of human language-based communication cannot be realized\nwithout negation. All human languages have some form of negation. Despite this,\nnegation remains a challenging phenomenon for current natural language\nunderstanding systems. To facilitate the future development of models that can\nprocess negation effectively, we present CONDAQA, the first English reading\ncomprehension dataset which requires reasoning about the implications of\nnegated statements in paragraphs. We collect paragraphs with diverse negation\ncues, then have crowdworkers ask questions about the implications of the\nnegated statement in the passage. We also have workers make three kinds of\nedits to the passage -- paraphrasing the negated statement, changing the scope\nof the negation, and reversing the negation -- resulting in clusters of\nquestion-answer pairs that are difficult for models to answer with spurious\nshortcuts. CONDAQA features 14,182 question-answer pairs with over 200 unique\nnegation cues and is challenging for current state-of-the-art models. The best\nperforming model on CONDAQA (UnifiedQA-v2-3b) achieves only 42% on our\nconsistency metric, well below human performance which is 81%. We release our\ndataset, along with fully-finetuned, few-shot, and zero-shot evaluations, to\nfacilitate the development of future NLP methods that work on negated language.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Abhilasha Ravichander",
      "Matt Gardner",
      "Ana Marasovi\u0107"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00295"
  },
  {
    "id": "arXiv:2211.00297",
    "title": "A structure-preserving parametric finite element method for geometric  flows with anisotropic surface energy",
    "abstract": "We propose and analyze structure-preserving parametric finite element methods\n(SP-PFEM) for evolution of a closed curve under different geometric flows with\narbitrary anisotropic surface energy $\\gamma(\\boldsymbol{n})$ for\n$\\boldsymbol{n}\\in \\mathbb{S}^1$ representing the outward unit normal vector.\nBy introducing a novel surface energy matrix $\\boldsymbol{G}_k(\\boldsymbol{n})$\ndepending on $\\gamma(\\boldsymbol{n})$ and the Cahn-Hoffman\n$\\boldsymbol{\\xi}$-vector as well as a nonnegative stabilizing function\n$k(\\boldsymbol{n}):\\ \\mathbb{S}^1\\to \\mathbb{R}$, which is a sum of a symmetric\npositive definite matrix and an anti-symmetric matrix, we obtain a new\ngeometric partial differential equation and its corresponding variational\nformulation for the evolution of a closed curve under anisotropic surface\ndiffusion. Based on the new weak formulation, we propose a parametric finite\nelement method for the anisotropic surface diffusion and show that it is area\nconservation and energy dissipation under a very mild condition on\n$\\gamma(\\boldsymbol{n})$. The SP-PFEM is then extended to simulate evolution of\na close curve under other anisotropic geometric flows including anisotropic\ncurvature flow and area-conserved anisotropic curvature flow. Extensive\nnumerical results are reported to demonstrate the efficiency and unconditional\nenergy stability as well as good mesh quality property of the proposed SP-PFEM\nfor simulating anisotropic geometric flows.",
    "descriptor": "",
    "authors": [
      "Weizhu Bao",
      "Yifei Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.00297"
  },
  {
    "id": "arXiv:2211.00298",
    "title": "Constructing MRD codes by switching",
    "abstract": "MRD codes are maximum codes in the rank-distance metric space on $m$-by-$n$\nmatrices over the finite field of order $q$. They are diameter perfect and have\nthe cardinality $q^{m(n-d+1)}$ if $m\\ge n$. We define switching in MRD codes as\nreplacing special MRD subcodes by other subcodes with the same parameters. We\nconsider constructions of MRD codes admitting such switching, including\npunctured twisted Gabidulin codes and direct-product codes. Using switching, we\nconstruct a huge class of MRD codes whose cardinality grows doubly\nexponentially in $m$ if the other parameters ($n$, $q$, the code distance) are\nfixed. Moreover, we construct MRD codes with different affine ranks and\naperiodic MRD codes.\nKeywords: MRD codes, rank distance, bilinear forms graph, switching, diameter\nperfect codes",
    "descriptor": "",
    "authors": [
      "Minjia Shi",
      "Denis S. Krotov",
      "Ferruh \u00d6zbudak"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.00298"
  },
  {
    "id": "arXiv:2211.00301",
    "title": "Recognizing Nested Entities from Flat Supervision: A New NER Subtask,  Feasibility and Challenges",
    "abstract": "Many recent named entity recognition (NER) studies criticize flat NER for its\nnon-overlapping assumption, and switch to investigating nested NER. However,\nexisting nested NER models heavily rely on training data annotated with nested\nentities, while labeling such data is costly. This study proposes a new\nsubtask, nested-from-flat NER, which corresponds to a realistic application\nscenario: given data annotated with flat entities only, one may still desire\nthe trained model capable of recognizing nested entities. To address this task,\nwe train span-based models and deliberately ignore the spans nested inside\nlabeled entities, since these spans are possibly unlabeled entities. With\nnested entities removed from the training data, our model achieves 54.8%, 54.2%\nand 41.1% F1 scores on the subset of spans within entities on ACE 2004, ACE\n2005 and GENIA, respectively. This suggests the effectiveness of our approach\nand the feasibility of the task. In addition, the model's performance on flat\nentities is entirely unaffected. We further manually annotate the nested\nentities in the test set of CoNLL 2003, creating a nested-from-flat NER\nbenchmark. Analysis results show that the main challenges stem from the data\nand annotation inconsistencies between the flat and nested entities.",
    "descriptor": "",
    "authors": [
      "Enwei Zhu",
      "Yiyang Liu",
      "Ming Jin",
      "Jinpeng Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00301"
  },
  {
    "id": "arXiv:2211.00306",
    "title": "Empowering Data Centers for Next Generation Trusted Computing",
    "abstract": "Modern data centers have grown beyond CPU nodes to provide domain-specific\naccelerators such as GPUs and FPGAs to their customers. From a security\nstandpoint, cloud customers want to protect their data. They are willing to pay\nadditional costs for trusted execution environments such as enclaves provided\nby Intel SGX and AMD SEV. Unfortunately, the customers have to make a critical\nchoice -- either use domain-specific accelerators for speed or use CPU-based\nconfidential computing solutions. To bridge this gap, we aim to enable\ndata-center scale confidential computing that expands across CPUs and\naccelerators. We argue that having wide-scale TEE-support for accelerators\npresents a technically easier solution, but is far away from being a reality.\nInstead, our hybrid design provides enclaved execution guarantees for\ncomputation distributed over multiple CPU nodes and devices with/without TEE\nsupport. Our solution scales gracefully in two dimensions -- it can handle a\nlarge number of heterogeneous nodes and it can accommodate TEE-enabled devices\nas and when they are available in the future. We observe marginal overheads of\n$0.42$--$8\\%$ on real-world AI data center workloads that are independent of\nthe number of nodes in the data center. We add custom TEE support to two\naccelerators (AI and storage) and integrate it into our solution, thus\ndemonstrating that it can cater to future TEE devices.",
    "descriptor": "\nComments: 23 pages, 12 figures\n",
    "authors": [
      "Aritra Dhar",
      "Supraja Sridhara",
      "Shweta Shinde",
      "Srdjan Capkun",
      "Renzo Andri"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.00306"
  },
  {
    "id": "arXiv:2211.00310",
    "title": "SADT: Combining Sharpness-Aware Minimization with Self-Distillation for  Improved Model Generalization",
    "abstract": "Methods for improving deep neural network training times and model\ngeneralizability consist of various data augmentation, regularization, and\noptimization approaches, which tend to be sensitive to hyperparameter settings\nand make reproducibility more challenging. This work jointly considers two\nrecent training strategies that address model generalizability: sharpness-aware\nminimization, and self-distillation, and proposes the novel training strategy\nof Sharpness-Aware Distilled Teachers (SADT). The experimental section of this\nwork shows that SADT consistently outperforms previously published training\nstrategies in model convergence time, test-time performance, and model\ngeneralizability over various neural architectures, datasets, and\nhyperparameter settings.",
    "descriptor": "\nComments: Accepted to the \"Has it Trained Yet?\" Workshop at the Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Masud An-Nur Islam Fahim",
      "Jani Boutellier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00310"
  },
  {
    "id": "arXiv:2211.00311",
    "title": "Entity Matching by Pool-based Active Learning",
    "abstract": "The goal of entity matching is to find the corresponding records representing\nthe same real-world entity from different data sources. At present, in the\nmainstream methods, rule-based entity matching methods need tremendous domain\nknowledge. The machine-learning based or deep-learning based entity matching\nmethods need a large number of labeled samples to build the model, which is\ndifficult to achieve in some applications. In addition, learning-based methods\nare easy to over-fitting, so the quality requirements of training samples are\nvery high. In this paper, we present an active learning method ALMatcher for\nthe entity matching tasks. This method needs to manually label only a small\nnumber of valuable samples, and use these samples to build a model with high\nquality. This paper proposes a hybrid uncertainty as query strategy to find\nthose valuable samples for labeling, which can minimize the number of labeled\ntraining samples meanwhile meet the task requirements. The proposed method has\nbeen validated on seven data sets in different fields. The experiment shows\nthat ALMatcher uses only a small number of labeled samples and achieves better\nresults compared to existing approaches.",
    "descriptor": "",
    "authors": [
      "Youfang Han",
      "Chunping Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.00311"
  },
  {
    "id": "arXiv:2211.00312",
    "title": "HDNet: Hierarchical Dynamic Network for Gait Recognition using  Millimeter-Wave Radar",
    "abstract": "Gait recognition is widely used in diversified practical applications.\nCurrently, the most prevalent approach is to recognize human gait from RGB\nimages, owing to the progress of computer vision technologies. Nevertheless,\nthe perception capability of RGB cameras deteriorates in rough circumstances,\nand visual surveillance may cause privacy invasion. Due to the robustness and\nnon-invasive feature of millimeter wave (mmWave) radar, radar-based gait\nrecognition has attracted increasing attention in recent years. In this\nresearch, we propose a Hierarchical Dynamic Network (HDNet) for gait\nrecognition using mmWave radar. In order to explore more dynamic information,\nwe propose point flow as a novel point clouds descriptor. We also devise a\ndynamic frame sampling module to promote the efficiency of computation without\ndeteriorating performance noticeably. To prove the superiority of our methods,\nwe perform extensive experiments on two public mmWave radar-based gait\nrecognition datasets, and the results demonstrate that our model is superior to\nexisting state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Yanyan Huang",
      "Yong Wang",
      "Kun Shi",
      "Chaojie Gu",
      "Yu Fu",
      "Cheng Zhuo",
      "Zhiguo Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00312"
  },
  {
    "id": "arXiv:2211.00313",
    "title": "RGMIM: Region-Guided Masked Image Modeling for COVID-19 Detection",
    "abstract": "Self-supervised learning has developed rapidly and also advances\ncomputer-aided diagnosis in the medical field. Masked image modeling (MIM) is\none of the self-supervised learning methods that masks a portion of input\npixels and tries to predict the masked pixels. Traditional MIM methods often\nuse a random masking strategy. However, medical images often have a small\nregion of interest for disease detection compared to ordinary images. For\nexample, the regions outside the lung do not contain the information for\ndecision, which may cause the random masking strategy not to learn enough\ninformation for COVID-19 detection. Hence, we propose a novel region-guided\nmasked image modeling method (RGMIM) for COVID-19 detection in this paper. In\nour method, we design a new masking strategy that uses lung mask information to\nlocate valid regions to learn more helpful information for COVID-19 detection.\nExperimental results show that RGMIM can outperform other state-of-the-art\nself-supervised learning methods on an open COVID-19 radiography dataset.",
    "descriptor": "",
    "authors": [
      "Guang Li",
      "Ren Togo",
      "Takahiro Ogawa",
      "Miki Haseyama"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.00313"
  },
  {
    "id": "arXiv:2211.00316",
    "title": "Hessian-inversion-free ray-born inversion for high-resolution  quantitative ultrasound tomography",
    "abstract": "This study proposes a Hessian-inversion-free ray-born inversion approach for\nbiomedical ultrasound tomography. The proposed approach is a more efficient\nversion of the ray-born inversion approach proposed in [1]. Using these\napproaches, the propagation of acoustic waves are modelled using a ray\napproximation to heterogeneous Green's function. The inverse problem is solved\nin the frequency domain by iteratively linearisation and minimisation of the\nobjective function from low to high frequencies. In [1], the linear subproblem\nassociated with each frequency interval is solved by an implicit and iterative\ninversion of the Hessian matrix (inner iterations). Instead, this study applies\na preconditioning approach to each linear subproblem so that the Hessian matrix\nbecomes diagonalised, and can thus be inverted in a single step. Using the\nproposed preconditioning approach, the computational cost of solving each\nlinear subproblem of the proposed ray-Born inversion approach becomes almost\nthe same as solving one linear subproblem associated with a radon-type\ntime-of-flight-based approach using bent rays. More importantly, the smoothness\nassumptions made for diagonalising the Hessian matrix make the image\nreconstruction more stable than the inversion approach in [1] to noise.",
    "descriptor": "",
    "authors": [
      "Ashkan Javaherian"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.00316"
  },
  {
    "id": "arXiv:2211.00321",
    "title": "Improving Variational Autoencoders with Density Gap-based Regularization",
    "abstract": "Variational autoencoders (VAEs) are one of the powerful unsupervised learning\nframeworks in NLP for latent representation learning and latent-directed\ngeneration. The classic optimization goal of VAEs is to maximize the Evidence\nLower Bound (ELBo), which consists of a conditional likelihood for generation\nand a negative Kullback-Leibler (KL) divergence for regularization. In\npractice, optimizing ELBo often leads the posterior distribution of all samples\nconverge to the same degenerated local optimum, namely posterior collapse or KL\nvanishing. There are effective ways proposed to prevent posterior collapse in\nVAEs, but we observe that they in essence make trade-offs between posterior\ncollapse and hole problem, i.e., mismatch between the aggregated posterior\ndistribution and the prior distribution. To this end, we introduce new training\nobjectives to tackle both two problems through a novel regularization based on\nthe probabilistic density gap between the aggregated posterior distribution and\nthe prior distribution. Through experiments on language modeling, latent space\nvisualization and interpolation, we show that our proposed method can solve\nboth problems effectively and thus outperforms the existing methods in\nlatent-directed generation. To the best of our knowledge, we are the first to\njointly solve the hole problem and the posterior collapse.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Jianfei Zhang",
      "Jun Bai",
      "Chenghua Lin",
      "Yanmeng Wang",
      "Wenge Rong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00321"
  },
  {
    "id": "arXiv:2211.00322",
    "title": "DensePure: Understanding Diffusion Models towards Adversarial Robustness",
    "abstract": "Diffusion models have been recently employed to improve certified robustness\nthrough the process of denoising. However, the theoretical understanding of why\ndiffusion models are able to improve the certified robustness is still lacking,\npreventing from further improvement. In this study, we close this gap by\nanalyzing the fundamental properties of diffusion models and establishing the\nconditions under which they can enhance certified robustness. This deeper\nunderstanding allows us to propose a new method DensePure, designed to improve\nthe certified robustness of a pretrained model (i.e. classifier). Given an\n(adversarial) input, DensePure consists of multiple runs of denoising via the\nreverse process of the diffusion model (with different random seeds) to get\nmultiple reversed samples, which are then passed through the classifier,\nfollowed by majority voting of inferred labels to make the final prediction.\nThis design of using multiple runs of denoising is informed by our theoretical\nanalysis of the conditional distribution of the reversed sample. Specifically,\nwhen the data density of a clean sample is high, its conditional density under\nthe reverse process in a diffusion model is also high; thus sampling from the\nlatter conditional distribution can purify the adversarial example and return\nthe corresponding clean sample with a high probability. By using the highest\ndensity point in the conditional distribution as the reversed sample, we\nidentify the robust region of a given instance under the diffusion model's\nreverse process. We show that this robust region is a union of multiple convex\nsets, and is potentially much larger than the robust regions identified in\nprevious works. In practice, DensePure can approximate the label of the high\ndensity region in the conditional distribution so that it can enhance certified\nrobustness.",
    "descriptor": "",
    "authors": [
      "Chaowei Xiao",
      "Zhongzhu Chen",
      "Kun Jin",
      "Jiongxiao Wang",
      "Weili Nie",
      "Mingyan Liu",
      "Anima Anandkumar",
      "Bo Li",
      "Dawn Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.00322"
  },
  {
    "id": "arXiv:2211.00323",
    "title": "Reconfigurable Intelligent Surface: Power Consumption Modeling and  Practical Measurement Validation",
    "abstract": "Due to the ability to reshape the wireless communication environment in a\ncost- and energy-efficient manner, the reconfigurable intelligent surface (RIS)\nhas garnered substantial attention. However, the explicit power consumption\nmodel of RIS and measurement validation, have received far too little\nattention. Therefore, in this work, we propose the RIS power consumption model\nand implement the practical measurement validation with various RISs.\nMeasurement results illustrate the generality and accuracy of the proposed\nmodel. Firstly, we verify that RIS has static power consumption, and present\nthe experiment results. Secondly, we confirm that the dynamic power consumption\nof the varactor-diode based RIS is almost negligible. Finally but\nsignificantly, we model the quantitative relationship between the dynamic power\nconsumption of the PIN-diode based RIS and the polarization mode, controllable\nbit resolution, working status of RIS, which is validated by practical\nexperimental results.",
    "descriptor": "",
    "authors": [
      "Jinghe Wang",
      "Wankai Tang",
      "Jing Cheng Liang",
      "Lei Zhang",
      "Jun Yan Dai",
      "Xiao Li",
      "Shi Jin",
      "Qiang Cheng",
      "Tie Jun Cui"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.00323"
  },
  {
    "id": "arXiv:2211.00328",
    "title": "The standard forms of the Kaczmarz-Tanabe type methods and their  convergence theory",
    "abstract": "In this paper, we consider the standard form of two kinds of Kaczmarz-Tanabe\ntype methods, one derived from the Kaczmarz method and the other derived from\nthe symmetric Kaczmarz method. As a famous image reconstruction method in\ncomputed tomography, the Kaczmarz method has both advantage and disadvantage.\nThe advantage are simple and easy to implement, while the disadvantages are\nslow convergence speed, and the symmetric Kaczmarz method is the same. For the\nstandard form of this method, once the iterative matrix is generated, it can be\nused continuously in the subsequent iterations. Moreover, the iterative matrix\ncan be stored in the image reconstructive devices, which makes the Kaczmarz\nmethod and the symmetric Kaczmarz method can be used like the simultaneous\niterative reconstructive techniques (SIRT). Meanwhile, theoretical analysis\nshows that the convergence rate of symmetric Kaczmarz method is better than the\nKaczmarz method but is slightly worse than that of two iterations Kaczmarz\nmethod, which is verified numerically. Numerical experiments also show that the\nconvergence rates of the Kaczmarz method and the symmetric Kaczmarz method are\nbetter than the SIRT methods and slightly worse than CGMN method in some cases.\nHowever, the Kaczmarz Tanabe type methods have better problem adaptability.",
    "descriptor": "\nComments: 21pages\n",
    "authors": [
      "Chuan-gang Kang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.00328"
  },
  {
    "id": "arXiv:2211.00330",
    "title": "Real-Time Character Inverse Kinematics using the Gauss-Seidel Iterative  Approximation Method",
    "abstract": "We present a realistic, robust, and computationally fast method of solving\nhighly non-linear inverse kinematic problems with angular limits using the\nGauss-Seidel iterative method. Our method is ideally suited towards character\nbased interactive applications such as games. To achieve interactive simulation\nspeeds, numerous acceleration techniques are employed, including spatial\ncoherent starting approximations and projected angular clamping. The method has\nbeen tested on a continuous range of poses for animated articulated characters\nand successfully performed in all cases and produced good visual outcomes.",
    "descriptor": "",
    "authors": [
      "Ben Kenwright"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.00330"
  },
  {
    "id": "arXiv:2211.00331",
    "title": "Comparative analysis of PV configurations for agrivoltaic systems in  Europe",
    "abstract": "Agrivoltaics (APV) is the dual use of land by combining agricultural crop\nproduction and photovoltaic (PV) systems. In this work, we have analyzed three\ndifferent APV configurations: static with optimal tilt, vertically-mounted\nbifacial, and single-axis horizontal tracking. A model is developed to\ncalculate the shadowing losses on the PV panels along with the reduced solar\nirradiation reaching the area under them for different PV capacity densities.\nFirst, we investigate the trade-offs using a location in Denmark as a case\nstudy and second, we extrapolate the analysis to the rest of Europe. We find\nthat the vertical and single-axis tracking produce more uniform irradiance on\nthe ground, and a capacity density of around 30 W/m2 is suitable for APV\nsystems. Based on our model and a 100 m-resolution land cover database, we\ncalculate the potential for APV in every NUTS-2 region within the European\nUnion (EU). The potential for APV is enormous as the electricity generated by\nAPV systems could produce 28 times the current electricity demand in Europe.\nOverall, the potential capacity for APV in Europe is 51 TW, which would result\nin an electricity yield of 71500 TWh/year.",
    "descriptor": "",
    "authors": [
      "Kamran Ali Khan Niazi",
      "Marta Victoria"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.00331"
  },
  {
    "id": "arXiv:2211.00332",
    "title": "Computational Power of A Single Oblivious Mobile Agent in  Two-Edge-Connected Graphs",
    "abstract": "We investigate the computational power of a single mobile agent in an\n$n$-node graph with storage (i.e., node memory). It has been shown that the\nsystem with one-bit agent memory and $O(1)$-bit storage is as powerful as the\none with $O(n)$-bit agent memory and $O(1)$-bit storage, and thus we focus on\nthe difference between one-bit memory agents and oblivious (i.e. zero-bit\nmemory) agents. While it has been also shown that their computational powers\nare not equivalent, all the known results exhibiting such a difference rely on\nthe fact that oblivious agents cannot transfer any information from one side to\nthe other side across the bridge edge. Then our main question is stated as\nfollows: Are the computational powers of one-bit memory agents and oblivious\nagents equivalent in 2-edge-connected graphs or not? The main contribution of\nthis paper is to answer this question positively under the relaxed assumption\nthat each node has $O(\\log\\Delta)$-bit storage ($\\Delta$ is the maximum degree\nof the graph). We present an algorithm of simulating any algorithm for a single\none-bit memory agent by one oblivious agent with $O(n^2)$-time overhead per\nround. Our result implies that the topological structure of graphs\ndifferentiating the computational powers of oblivious and non-oblivious agents\nis completely characterized by the existence of bridge edges.",
    "descriptor": "\nComments: 13 pages, 2 figures\n",
    "authors": [
      "Taichi Inoue",
      "Naoki Kitamura",
      "Taisuke Izumi",
      "Toshimitsu Masuzawa"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.00332"
  },
  {
    "id": "arXiv:2211.00342",
    "title": "Investigating Content-Aware Neural Text-To-Speech MOS Prediction Using  Prosodic and Linguistic Features",
    "abstract": "Current state-of-the-art methods for automatic synthetic speech evaluation\nare based on MOS prediction neural models. Such MOS prediction models include\nMOSNet and LDNet that use spectral features as input, and SSL-MOS that relies\non a pretrained self-supervised learning model that directly uses the speech\nsignal as input. In modern high-quality neural TTS systems, prosodic\nappropriateness with regard to the spoken content is a decisive factor for\nspeech naturalness. For this reason, we propose to include prosodic and\nlinguistic features as additional inputs in MOS prediction systems, and\nevaluate their impact on the prediction outcome. We consider phoneme level F0\nand duration features as prosodic inputs, as well as Tacotron encoder outputs,\nPOS tags and BERT embeddings as higher-level linguistic inputs. All MOS\nprediction systems are trained on SOMOS, a neural TTS-only dataset with\ncrowdsourced naturalness MOS evaluations. Results show that the proposed\nadditional features are beneficial in the MOS prediction task, by improving the\npredicted MOS scores' correlation with the ground truths, both at\nutterance-level and system-level predictions.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Alexandra Vioni",
      "Georgia Maniati",
      "Nikolaos Ellinas",
      "June Sig Sung",
      "Inchul Hwang",
      "Aimilios Chalamandaris",
      "Pirros Tsiakoulis"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00342"
  },
  {
    "id": "arXiv:2211.00347",
    "title": "Carbon Footprints on Inter-Domain Paths: Uncovering CO2 Tracks on Global  Networks",
    "abstract": "In the years after signing the Paris agreement, corporations have been\nexperiencing increasing pressure to monitor and reduce their carbon footprint.\nNevertheless, the information and communication technology sector lacks an\neffective tool for monitoring and optimizing the carbon footprint of data\ntransmissions over the public Internet.\nIn this work, we propose a carbon-footprint transparency system based on a\npath-aware Internet architecture that enables endpoints to monitor the carbon\nfootprint of their inter-domain communications, and optimize it through\ncarbon-aware path selection. Furthermore, we show by means of simulations that\nin a realistic inter-domain topology, 85% of traffic sources could reduce the\ncarbon footprint of their outbound inter-domain traffic by at least 50% through\ncarbon-aware path selection.",
    "descriptor": "",
    "authors": [
      "Seyedali Tabaeiaghdaei",
      "Simon Scherrer",
      "Adrian Perrig"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.00347"
  },
  {
    "id": "arXiv:2211.00348",
    "title": "Informed Priors for Knowledge Integration in Trajectory Prediction",
    "abstract": "Informed machine learning methods allow the integration of prior knowledge\ninto learning systems. This can increase accuracy and robustness or reduce data\nneeds. However, existing methods often assume hard constraining knowledge, that\ndoes not require to trade-off prior knowledge with observations, but can be\nused to directly reduce the problem space. Other approaches use specific,\narchitectural changes as representation of prior knowledge, limiting\napplicability. We propose an informed machine learning method, based on\ncontinual learning. This allows the integration of arbitrary, prior knowledge,\npotentially from multiple sources, and does not require specific architectures.\nFurthermore, our approach enables probabilistic and multi-modal predictions,\nthat can improve predictive accuracy and robustness. We exemplify our approach\nby applying it to a state-of-the-art trajectory predictor for autonomous\ndriving. This domain is especially dependent on informed learning approaches,\nas it is subject to an overwhelming large variety of possible environments and\nvery rare events, while requiring robust and accurate predictions. We evaluate\nour model on a commonly used benchmark dataset, only using data already\navailable in a conventional setup. We show that our method outperforms both\nnon-informed and informed learning methods, that are often used in the\nliterature. Furthermore, we are able to compete with a conventional baseline,\neven using half as many observation examples.",
    "descriptor": "",
    "authors": [
      "Christian Schlauch",
      "Nadja Klein",
      "Christian Wirth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.00348"
  },
  {
    "id": "arXiv:2211.00349",
    "title": "Siamese Transition Masked Autoencoders as Uniform Unsupervised Visual  Anomaly Detector",
    "abstract": "Unsupervised visual anomaly detection conveys practical significance in many\nscenarios and is a challenging task due to the unbounded definition of\nanomalies. Moreover, most previous methods are application-specific, and\nestablishing a unified model for anomalies across application scenarios remains\nunsolved. This paper proposes a novel hybrid framework termed Siamese\nTransition Masked Autoencoders(ST-MAE) to handle various visual anomaly\ndetection tasks uniformly via deep feature transition. Concretely, the proposed\nmethod first extracts hierarchical semantics features from a pre-trained deep\nconvolutional neural network and then develops a feature decoupling strategy to\nsplit the deep features into two disjoint feature patch subsets. Leveraging the\ndecoupled features, the ST-MAE is developed with the Siamese encoders that\noperate on each subset of feature patches and perform the latent\nrepresentations transition of two subsets, along with a lightweight decoder\nthat reconstructs the original feature from the transitioned latent\nrepresentation. Finally, the anomalous attributes can be detected using the\nsemantic deep feature residual. Our deep feature transition scheme yields a\nnontrivial and semantic self-supervisory task to extract prototypical normal\npatterns, which allows for learning uniform models that generalize well for\ndifferent visual anomaly detection tasks. The extensive experiments conducted\ndemonstrate that the proposed ST-MAE method can advance state-of-the-art\nperformance on multiple benchmarks across application scenarios with a superior\ninference efficiency, which exhibits great potential to be the uniform model\nfor unsupervised visual anomaly detection.",
    "descriptor": "",
    "authors": [
      "Haiming Yao",
      "Xue Wang",
      "Wenyong Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00349"
  },
  {
    "id": "arXiv:2211.00352",
    "title": "Understanding Acoustic Patterns of Human Teachers Demonstrating  Manipulation Tasks to Robots",
    "abstract": "Humans use audio signals in the form of spoken language or verbal reactions\neffectively when teaching new skills or tasks to other humans. While\ndemonstrations allow humans to teach robots in a natural way, learning from\ntrajectories alone does not leverage other available modalities including audio\nfrom human teachers. To effectively utilize audio cues accompanying human\ndemonstrations, first it is important to understand what kind of information is\npresent and conveyed by such cues. This work characterizes audio from human\nteachers demonstrating multi-step manipulation tasks to a situated Sawyer robot\nusing three feature types: (1) duration of speech used, (2) expressiveness in\nspeech or prosody, and (3) semantic content of speech. We analyze these\nfeatures along four dimensions and find that teachers convey similar semantic\nconcepts via spoken words for different conditions of (1) demonstration types,\n(2) audio usage instructions, (3) subtasks, and (4) errors during\ndemonstrations. However, differentiating properties of speech in terms of\nduration and expressiveness are present along the four dimensions, highlighting\nthat human audio carries rich information, potentially beneficial for\ntechnological advancement of robot learning from demonstration methods.",
    "descriptor": "\nComments: IROS 2022\n",
    "authors": [
      "Akanksha Saran",
      "Kush Desai",
      "Mai Lee Chang",
      "Rudolf Lioutikov",
      "Andrea Thomaz",
      "Scott Niekum"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.00352"
  },
  {
    "id": "arXiv:2211.00360",
    "title": "sRSP: GPUlarda Asimetrik Senkronizasyon Icin Yeni Olceklenebilir Bir  Cozum",
    "abstract": "Asymmetric sharing is a dynamic sharing model, where a shared data is heavily\naccessed by a (local) sharer, and rarely accessed by other (remote) sharers. On\nGPUs, without special support, asymmetric sharing requires heavily loaded\nsynchronization on every access. With the introduction of Remote Scope\nPromotion (RSP), access to the local sharer is allowed with lightweight\nsynchronization, while heavyweight synchronization is only used for remote\naccesses where it is rarely needed. RSP ensures data consistency by promoting\nlocal synchronizations on remote accesses. Unfortunately, the first\nimplementation of RSP is not a scalable solution. We offer a more efficient and\nscalable RSP implementation. This new design, which we call sRSP, is based on\nthe monitoring of the local sharer and the selective execution of heavyweight\nsynchronization operations. We evaluated the sRSP with the time-detailed\nGem5-APU simulator and the results show that the sRSP improves performance by\nan average of 29 percent on a 64 Compute Unit GPU.",
    "descriptor": "\nComments: in Turkish language\n",
    "authors": [
      "Ayse Yilmazer-Metin"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.00360"
  },
  {
    "id": "arXiv:2211.00361",
    "title": "Academic Search Engines: Constraints, Bugs, and Recommendation",
    "abstract": "Background: Academic search engines (i.e., digital libraries and indexers)\nplay an increasingly important role in systematic reviews however these engines\ndo not seem to effectively support such reviews, e.g., researchers confront\nusability issues with the engines when conducting their searches. Aims: To\ninvestigate whether the usability issues are bugs (i.e., faults in the search\nengines) or constraints, and to provide recommendations to search-engine\nproviders and researchers on how to tackle these issues. Method: Using\nsnowball-sampling from tertiary studies, we identify a set of 621 secondary\nstudies in software engineering. By physically re-attempting the searches for\nall of these 621 studies, we effectively conduct regression testing for 42\nsearch engines. Results: We identify 13 bugs for eight engines, and also\nidentify other constraints. We provide recommendations for tackling these\nissues. Conclusions: There is still a considerable gap between the search-needs\nof researchers and the usability of academic search engines. It is not clear\nwhether search-engine developers are aware of this gap. Also, the evaluation,\nby academics, of academic search engines has not kept pace with the\ndevelopment, by search-engine providers, of those search engines. Thus, the gap\nbetween evaluation and development makes it harder to properly understand the\ngap between the search-needs of researchers and search-features of the search\nengines.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Zheng Li",
      "Austen Rainer"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2211.00361"
  },
  {
    "id": "arXiv:2211.00366",
    "title": "Universal Perturbation Attack on Differentiable No-Reference Image- and  Video-Quality Metrics",
    "abstract": "Universal adversarial perturbation attacks are widely used to analyze image\nclassifiers that employ convolutional neural networks. Nowadays, some attacks\ncan deceive image- and video-quality metrics. So sustainability analysis of\nthese metrics is important. Indeed, if an attack can confuse the metric, an\nattacker can easily increase quality scores. When developers of image- and\nvideo-algorithms can boost their scores through detached processing, algorithm\ncomparisons are no longer fair. Inspired by the idea of universal adversarial\nperturbation for classifiers, we suggest a new method to attack differentiable\nno-reference quality metrics through universal perturbation. We applied this\nmethod to seven no-reference image- and video-quality metrics (PaQ-2-PiQ,\nLinearity, VSFA, MDTVSFA, KonCept512, Nima and SPAQ). For each one, we trained\na universal perturbation that increases the respective scores. We also propose\na method for assessing metric stability and identify the metrics that are the\nmost vulnerable and the most resistant to our attack. The existence of\nsuccessful universal perturbations appears to diminish the metric's ability to\nprovide reliable scores. We therefore recommend our proposed method as an\nadditional verification of metric reliability to complement traditional\nsubjective tests and benchmarks.",
    "descriptor": "\nComments: BMVC 2022\n",
    "authors": [
      "Ekaterina Shumitskaya",
      "Anastasia Antsiferova",
      "Dmitriy Vatolin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.00366"
  },
  {
    "id": "arXiv:2211.00367",
    "title": "Towards Maximizing Nonlinear Delay Sensitive Rewards in Queuing Systems",
    "abstract": "We consider maximizing the long-term average reward in a single server queue,\nwhere the reward obtained for a job is a non-increasing function of its sojourn\ntime. The motivation behind this work comes from multiple applications,\nincluding quantum information processing and multimedia streaming. We introduce\na new service discipline, shortest predicted sojourn time (SPST), which, in\nsimulations, performs better than well-known disciplines. We also present some\nlimited analytical guarantees for this highly intricate problem.",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Sushmitha Shree S",
      "Avijit Mandal",
      "Avhishek Chatterjee",
      "Krishna Jagannathan"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2211.00367"
  },
  {
    "id": "arXiv:2211.00369",
    "title": "Anytime Generation of Counterfactual Explanations for Text  Classification",
    "abstract": "In many machine learning applications, it is important for the user to\nunderstand the reasoning behind the recommendation or prediction of the\nclassifiers. The learned models, however, are often too complicated to be\nunderstood by a human. Research from the social sciences indicates that humans\nprefer counterfactual explanations over alternatives. In this paper, we present\na general framework for generating counterfactual explanations in the textual\ndomain. Our framework is model-agnostic, representation-agnostic,\ndomain-agnostic, and anytime. We model the task as a search problem in a space\nwhere the initial state is the classified text, and the goal state is a text in\nthe complementary class. The operators transform a text by replacing parts of\nit. Our framework includes domain-independent operators, but can also exploit\ndomain-specific knowledge through specialized operators. The search algorithm\nattempts to find a text from the complementary class with minimal word-level\nLevenshtein distance from the original classified object.",
    "descriptor": "",
    "authors": [
      "Daniel Gilo",
      "Shaul Markovitch"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.00369"
  },
  {
    "id": "arXiv:2211.00372",
    "title": "Meta-Learning for Unsupervised Outlier Detection with Optimal Transport",
    "abstract": "Automated machine learning has been widely researched and adopted in the\nfield of supervised classification and regression, but progress in unsupervised\nsettings has been limited. We propose a novel approach to automate outlier\ndetection based on meta-learning from previous datasets with outliers. Our\npremise is that the selection of the optimal outlier detection technique\ndepends on the inherent properties of the data distribution. We leverage\noptimal transport in particular, to find the dataset with the most similar\nunderlying distribution, and then apply the outlier detection techniques that\nproved to work best for that data distribution. We evaluate the robustness of\nour approach and find that it outperforms the state of the art methods in\nunsupervised outlier detection. This approach can also be easily generalized to\nautomate other unsupervised settings.",
    "descriptor": "",
    "authors": [
      "Prabhant Singh",
      "Joaquin Vanschoren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00372"
  },
  {
    "id": "arXiv:2211.00373",
    "title": "On Kubernetes-aided Federated Database Systems",
    "abstract": "Cloud computing has made federated database systems (FDBS) significantly more\npractical to implement than in the past. As part of a recent Web-based\nGeographic Information System (WebGIS) project, we are employing cloud-native\ntechnologies (from the container ecosystem) to develop a federated database\n(DB) infrastructure, to help manage and utilise the distributed and various\ngeospatial data. Unfortunately, there seem to be inherent challenges and\ncomplexity of applying the container and Kubernetes technologies to building\nand running DB systems. Considering that most of the geospatial and theme data\nare pre-obtained and fixed in our WebGIS project, we decided to focus on the\nread-only user queries and still resort to Kubernetes to implement an FDBS\ninstance to use. Unlike the de facto practices (e.g., using the StatefulSets\nmechanism, extending Kuberentes APIs, or employing KubeFed), our solution for\nKubernetes-aided FDBS simplifies the tech stack by investigating the fractal\nobject of federated data management, inclusively containerising DB instances,\nand using the lightweight Deployment mechanism to handle stateless DB\ncontainers. Overall, this research not only reveals an easy-to-implement\napproach to constructing read-only components in a fully-fledged FDBS, but also\nproposes and demonstrates a novel methodology for FDBS investigations.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Zheng Li",
      "Nicol\u00e1s Sald\u00edas-Vallejos",
      "Mar\u00eda Andrea Rodr\u00edguez",
      "Austen Rainer"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.00373"
  },
  {
    "id": "arXiv:2211.00374",
    "title": "What drives a goalkeepers' decisions?",
    "abstract": "In soccer games, the goalkeeper's performance is an important factor to the\nsuccess of the whole team. Despite the goalkeeper's importance, little\nattention has been paid to their performance in events and tracking data. Here,\nwe developed a model to predict which movements would be most effective for\nshot-stopping and compare it to the real-life behavior of goalkeepers. This\nmodel evaluates the performance of goalkeepers based on their position and dive\nradius. We found that contrary to the movements that were considered most\neffective by our model, real-life goalkeepers' movements were more diverse. We\nfurther used our model to develop a tool to analyse goalkeepers' behavior in\nreal-life soccer games. In addition, a simulator function allows team analysts\nor couches to identify situations that allow further improvement of the\nreaction of the goalkeeper.",
    "descriptor": "\nComments: Statsbomb conference 2021, London, UK\n",
    "authors": [
      "Samer Fatayri",
      "Kirill Serykh",
      "Egor Gumin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00374"
  },
  {
    "id": "arXiv:2211.00375",
    "title": "Generating Gender-Ambiguous Text-to-Speech Voices",
    "abstract": "The gender of a voice assistant or any voice user interface is a central\nelement of its perceived identity. While a female voice is a common choice,\nthere is an increasing interest in alternative approaches where the gender is\nambiguous rather than clearly identifying as female or male. This work\naddresses the task of generating gender-ambiguous text-to-speech (TTS) voices\nthat do not correspond to any existing person. This is accomplished by sampling\nfrom a latent speaker embeddings' space that was formed while training a\nmultilingual, multi-speaker TTS system on data from multiple male and female\nspeakers. Various options are investigated regarding the sampling process. In\nour experiments, the effects of different sampling choices on the gender\nambiguity and the naturalness of the resulting voices are evaluated. The\nproposed method is shown able to efficiently generate novel speakers that are\nsuperior to a baseline averaged speaker embedding. To our knowledge, this is\nthe first systematic approach that can reliably generate a range of\ngender-ambiguous voices to meet diverse user requirements.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Konstantinos Markopoulos",
      "Georgia Maniati",
      "Georgios Vamvoukakis",
      "Nikolaos Ellinas",
      "Karolos Nikitaras",
      "Konstantinos Klapsas",
      "Georgios Vardaxoglou",
      "Panos Kakoulidis",
      "June Sig Sung",
      "Inchul Hwang",
      "Aimilios Chalamandaris",
      "Pirros Tsiakoulis",
      "Spyros Raptis"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00375"
  },
  {
    "id": "arXiv:2211.00376",
    "title": "Automated Imbalanced Learning",
    "abstract": "Automated Machine Learning has grown very successful in automating the\ntime-consuming, iterative tasks of machine learning model development. However,\ncurrent methods struggle when the data is imbalanced. Since many real-world\ndatasets are naturally imbalanced, and improper handling of this issue can lead\nto quite useless models, this issue should be handled carefully. This paper\nfirst introduces a new benchmark to study how different AutoML methods are\naffected by label imbalance. Second, we propose strategies to better deal with\nimbalance and integrate them into an existing AutoML framework. Finally, we\npresent a systematic study which evaluates the impact of these strategies and\nfind that their inclusion in AutoML systems significantly increases their\nrobustness against label imbalance.",
    "descriptor": "",
    "authors": [
      "Prabhant Singh",
      "Joaquin Vanschoren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00376"
  },
  {
    "id": "arXiv:2211.00378",
    "title": "A Near-Linear Kernel for Two-Parsimony Distance",
    "abstract": "The maximum parsimony distance $d_{\\textrm{MP}}(T_1,T_2)$ and the\nbounded-state maximum parsimony distance $d_{\\textrm{MP}}^t(T_1,T_2)$ measure\nthe difference between two phylogenetic trees $T_1,T_2$ in terms of the maximum\ndifference between their parsimony scores for any character (with $t$ a bound\non the number of states in the character, in the case of\n$d_{\\textrm{MP}}^t(T_1,T_2)$). While computing $d_{\\textrm{MP}}(T_1, T_2)$ was\npreviously shown to be fixed-parameter tractable with a linear kernel, no such\nresult was known for $d_{\\textrm{MP}}^t(T_1,T_2)$. In this paper, we prove that\ncomputing $d_{\\textrm{MP}}^t(T_1, T_2)$ is fixed-parameter tractable for\nall~$t$. Specifically, we prove that this problem has a kernel of size $O(k \\lg\nk)$, where $k = d_{\\textrm{MP}}^t(T_1, T_2)$. As the primary analysis tool, we\nintroduce the concept of leg-disjoint incompatible quartets, which may be of\nindependent interest.",
    "descriptor": "",
    "authors": [
      "Elise Deen",
      "Leo van Iersel",
      "Remie Janssen",
      "Mark Jones",
      "Yuki Murakami",
      "Norbert Zeh"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.00378"
  },
  {
    "id": "arXiv:2211.00381",
    "title": "LinkFormer: Automatic Contextualised Link Recovery of Software Artifacts  in both Project-based and Transfer Learning Settings",
    "abstract": "Software artifacts often interact with each other throughout the software\ndevelopment cycle. Associating related artifacts is a common practice for\neffective documentation and maintenance of software projects. Conventionally,\nto register the link between an issue report and its associated commit,\ndevelopers manually include the issue identifier in the message of the relevant\ncommit. Research has shown that developers tend to forget to connect said\nartifacts manually, resulting in a loss of links. Hence, several link recovery\ntechniques were proposed to discover and revive such links automatically.\nHowever, the literature mainly focuses on improving the prediction accuracy on\na randomly-split test set, while neglecting other important aspects of this\nproblem, including the effect of time and generalizability of the predictive\nmodels. In this paper, we propose LinkFormer to address this problem from three\naspects; 1) Accuracy: To better utilize contextual information for prediction,\nwe employ the Transformer architecture and fine-tune multiple pre-trained\nmodels on textual and metadata of issues and commits. 2) Data leakage: To\nempirically assess the impact of time through the splitting policy, we train\nand test our proposed model along with several existing approaches on both\nrandomly- and temporally split data. 3) Generalizability: To provide a generic\nmodel that can perform well across different projects, we further fine-tune\nLinkFormer in two transfer learning settings. We empirically show that\nresearchers should preserve the temporal flow of data when training\nlearning-based models to resemble the real-world setting. In addition,\nLinkFormer significantly outperforms the state-of-the-art by large margins.\nLinkFormer is also capable of extending the knowledge it learned to unseen\nprojects with little to no historical data.",
    "descriptor": "",
    "authors": [
      "Maliheh Izadi",
      "Pooya Rostami Mazrae",
      "Tom Mens",
      "Arie van Deursen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00381"
  },
  {
    "id": "arXiv:2211.00382",
    "title": "Seg&Struct: The Interplay Between Part Segmentation and Structure  Inference for 3D Shape Parsing",
    "abstract": "We propose Seg&Struct, a supervised learning framework leveraging the\ninterplay between part segmentation and structure inference and demonstrating\ntheir synergy in an integrated framework. Both part segmentation and structure\ninference have been extensively studied in the recent deep learning literature,\nwhile the supervisions used for each task have not been fully exploited to\nassist the other task. Namely, structure inference has been typically conducted\nwith an autoencoder that does not leverage the point-to-part associations.\nAlso, segmentation has been mostly performed without structural priors that\ntell the plausibility of the output segments. We present how these two tasks\ncan be best combined while fully utilizing supervision to improve performance.\nOur framework first decomposes a raw input shape into part segments using an\noff-the-shelf algorithm, whose outputs are then mapped to nodes in a part\nhierarchy, establishing point-to-part associations. Following this, ours\npredicts the structural information, e.g., part bounding boxes and part\nrelationships. Lastly, the segmentation is rectified by examining the confusion\nof part boundaries using the structure-based part features. Our experimental\nresults based on the StructureNet and PartNet demonstrate that the interplay\nbetween the two tasks results in remarkable improvements in both tasks: 27.91%\nin structure inference and 0.5% in segmentation.",
    "descriptor": "\nComments: WACV 2023 (Algorithm Track)\n",
    "authors": [
      "Jeonghyun Kim",
      "Kaichun Mo",
      "Minhyuk Sung",
      "Woontack Woo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00382"
  },
  {
    "id": "arXiv:2211.00384",
    "title": "The future is different: Large pre-trained language models fail in  prediction tasks",
    "abstract": "Large pre-trained language models (LPLM) have shown spectacular success when\nfine-tuned on downstream supervised tasks. Yet, it is known that their\nperformance can drastically drop when there is a distribution shift between the\ndata used during training and that used at inference time. In this paper we\nfocus on data distributions that naturally change over time and introduce four\nnew REDDIT datasets, namely the WALLSTREETBETS, ASKSCIENCE, THE DONALD, and\nPOLITICS sub-reddits. First, we empirically demonstrate that LPLM can display\naverage performance drops of about 88% (in the best case!) when predicting the\npopularity of future posts from sub-reddits whose topic distribution changes\nwith time. We then introduce a simple methodology that leverages neural\nvariational dynamic topic models and attention mechanisms to infer temporal\nlanguage model representations for regression tasks. Our models display\nperformance drops of only about 40% in the worst cases (2% in the best ones)\nwhen predicting the popularity of future posts, while using only about 7% of\nthe total number of parameters of LPLM and providing interpretable\nrepresentations that offer insight into real-world events, like the GameStop\nshort squeeze of 2021",
    "descriptor": "",
    "authors": [
      "Kostadin Cvejoski",
      "Rams\u00e9s J. S\u00e1nchez",
      "C\u00e9sar Ojeda"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.00384"
  },
  {
    "id": "arXiv:2211.00385",
    "title": "Behavioral Intention Prediction in Driving Scenes: A Survey",
    "abstract": "In the driving scene, the road participants usually show frequent interaction\nand intention understanding with the surrounding. Ego-agent (each road\nparticipant itself) conducts the prediction of what behavior will be done by\nother road users all the time and expects a shared and consistent\nunderstanding. For instance, we need to predict the next movement of other road\nusers and expect a consistent joint action to avoid unexpected accident.\nBehavioral Intention Prediction (BIP) is to simulate such a human consideration\nprocess and fulfill the beginning time prediction of specific behaviors. It\nprovides an earlier signal promptly than the specific behaviors for whether the\nsurrounding road participants will present specific behavior (crossing,\novertaking, and turning, etc.) in near future or not. More and more works in\nBIP are based on deep learning models to take advantage of big data, and focus\non developing effective inference approaches (e.g., explainable inference,\ncross-modality fusion, and simulation augmentation). Therefore, in this work,\nwe focus on BIP-conditioned prediction tasks, including trajectory prediction,\nbehavior prediction, and accident prediction and explore the differences among\nvarious works in this field. Based on this investigation and the findings, we\ndiscuss the open problems in behavioral intention prediction and propose future\nresearch directions.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Intelligent Transportation Systems\n",
    "authors": [
      "Jianwu Fang",
      "Fan Wang",
      "Peining Shen",
      "Zhedong Zheng",
      "Jianru Xue",
      "Tat-seng Chua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00385"
  },
  {
    "id": "arXiv:2211.00387",
    "title": "Reasoning on Property Graphs with Graph Generating Dependencies",
    "abstract": "Graph Generating Dependencies (GGDs) informally express constraints between\ntwo (possibly different) graph patterns which enforce relationships on both\ngraph's data (via property value constraints) and its structure (via\ntopological constraints). Graph Generating Dependencies (GGDs) can express\ntuple- and equality-generating dependencies on property graphs, both of which\nfind broad application in graph data management. In this paper, we discuss the\nreasoning behind GGDs. We propose algorithms to solve the satisfiability,\nimplication, and validation problems for GGDs and analyze their complexity. To\ndemonstrate the practical use of GGDs, we propose an algorithm which finds\ninconsistencies in data through validation of GGDs. Our experiments show that\neven though the validation of GGDs has high computational complexity, GGDs can\nbe used to find data inconsistencies in a feasible execution time on both\nsynthetic and real-world data.",
    "descriptor": "",
    "authors": [
      "Larissa C. Shimomura",
      "Nikolay Yakovets",
      "George Fletcher"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.00387"
  },
  {
    "id": "arXiv:2211.00391",
    "title": "Optimization of Oblivious Decision Tree Ensembles Evaluation for CPU",
    "abstract": "CatBoost is a popular machine learning library. CatBoost models are based on\noblivious decision trees, making training and evaluation rapid. CatBoost has\nmany applications, and some require low latency and high throughput evaluation.\nThis paper investigates the possibilities for improving CatBoost's performance\nin single-core CPU computations. We explore the new features provided by the\nAVX instruction sets to optimize evaluation. We increase performance by 20-40%\nusing AVX2 instructions without quality impact. We also introduce a new\ntrade-off between speed and quality. Using float16 for leaf values and AVX-512\ninstructions, we achieve 50-70% speed-up.",
    "descriptor": "\nComments: in Russian language\n",
    "authors": [
      "Alexey Mironov",
      "Ilnur Khuziev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00391"
  },
  {
    "id": "arXiv:2211.00392",
    "title": "Expansion of Visual Hints for Improved Generalization in Stereo Matching",
    "abstract": "We introduce visual hints expansion for guiding stereo matching to improve\ngeneralization. Our work is motivated by the robustness of Visual Inertial\nOdometry (VIO) in computer vision and robotics, where a sparse and unevenly\ndistributed set of feature points characterizes a scene. To improve stereo\nmatching, we propose to elevate 2D hints to 3D points. These sparse and\nunevenly distributed 3D visual hints are expanded using a 3D random geometric\ngraph, which enhances the learning and inference process. We evaluate our\nproposal on multiple widely adopted benchmarks and show improved performance\nwithout access to additional sensors other than the image sequence. To\nhighlight practical applicability and symbiosis with visual odometry, we\ndemonstrate how our methods run on embedded hardware.",
    "descriptor": "\nComments: 2023 IEEE Winter Conference on Applications of Computer Vision (WACV)\n",
    "authors": [
      "Andrea Pilzer",
      "Yuxin Hou",
      "Niki Loppi",
      "Arno Solin",
      "Juho Kannala"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00392"
  },
  {
    "id": "arXiv:2211.00394",
    "title": "Comprehensive Study on Railway Communications Systems to Support  Hyperloop",
    "abstract": "Hyperloop is a sonic-speed train transporting passengers and freights in a\nvacuum tube without friction or air resistance. Two essential communications in\nsuch vehicles are central control connection and real-time dispatching, also an\noptional data connection for passengers is welcome. The high mobility of\nHyperloop imposes a severe impact on the performance of wireless communication\nlinks. Therefore, designing a new wireless communication system is necessary to\ncope with the challenges. Motivated by the importance of doppler spreading,\nthis paper focuses on the characterizations of the wireless channel in\nHyperloop and then analyzes the performance degradation of the radio link.\nAfterward, a comprehensive overview of the present railway communication\ntechnologies as potential solutions for the Hyperloop project and a detailed\ndiscussion of their cons and pros are provided. It is shown that current\ncommunication technologies are not satisfactory for this scenario. Finally,\nthis paper concludes the key points that need to be considered in future\nrailway communications systems in order to overcome the Hyperloop communication\nchallenges. So, we open up a new issue that Hyperloop communications require\ndesigning a novel method or improving the existing technologies or a\ncombination of different techniques (some of these techniques are mentioned).",
    "descriptor": "",
    "authors": [
      "Hamid Amiriara"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.00394"
  },
  {
    "id": "arXiv:2211.00396",
    "title": "Wavelet Neural Networks versus Wavelet-based Neural Networks",
    "abstract": "This is the first paper in a sequence of studies in which we introduce a new\ntype of neural networks (NNs) -- wavelet-based neural networks (WBNNs) -- and\nstudy their properties and potential for applications. We begin this study with\na comparison to the currently existing type of wavelet neural networks (WNNs)\nand show that WBNNs vastly outperform WNNs. One reason for the vast superiority\nof WBNNs is their advanced hierarchical tree structure based on biorthonormal\nmultiresolution analysis (MRA). Another reason for this is the implementation\nof our new idea to incorporate the wavelet tree depth into the neural width of\nthe NN. The separation of the roles of wavelet depth and neural depth provides\na conceptually and algorithmically simple but highly efficient methodology for\nsharp increase in functionality of swarm and deep WBNNs and rapid acceleration\nof the machine learning process.",
    "descriptor": "",
    "authors": [
      "Lubomir T. Dechevsky",
      "Kristoffer M. Tangrand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.00396"
  },
  {
    "id": "arXiv:2211.00409",
    "title": "Oracle-guided Contrastive Clustering",
    "abstract": "Deep clustering aims to learn a clustering representation through deep\narchitectures. Most of the existing methods usually conduct clustering with the\nunique goal of maximizing clustering performance, that ignores the personalized\ndemand of clustering tasks.% and results in unguided clustering solutions.\nHowever, in real scenarios, oracles may tend to cluster unlabeled data by\nexploiting distinct criteria, such as distinct semantics (background, color,\nobject, etc.), and then put forward personalized clustering tasks. To achieve\ntask-aware clustering results, in this study, Oracle-guided Contrastive\nClustering(OCC) is then proposed to cluster by interactively making pairwise\n``same-cluster\" queries to oracles with distinctive demands. Specifically,\ninspired by active learning, some informative instance pairs are queried, and\nevaluated by oracles whether the pairs are in the same cluster according to\ntheir desired orientation. And then these queried same-cluster pairs extend the\nset of positive instance pairs for contrastive learning, guiding OCC to extract\norientation-aware feature representation. Accordingly, the query results,\nguided by oracles with distinctive demands, may drive the OCC's clustering\nresults in a desired orientation. Theoretically, the clustering risk in an\nactive learning manner is given with a tighter upper bound, that guarantees\nactive queries to oracles do mitigate the clustering risk. Experimentally,\nextensive results verify that OCC can cluster accurately along the specific\norientation and it substantially outperforms the SOTA clustering methods as\nwell. To the best of our knowledge, it is the first deep framework to perform\npersonalized clustering.",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Mengdie Wang",
      "Liyuan Shang",
      "Suyun Zhao",
      "Yiming Wang",
      "Hong Chen",
      "Cuiping Li",
      "Xizhao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00409"
  },
  {
    "id": "arXiv:2211.00414",
    "title": "Using coevolution and substitution of the fittest for health and  well-being recommender systems",
    "abstract": "This research explores substitution of the fittest (SF), a technique designed\nto counteract the problem of disengagement in two-population competitive\ncoevolutionary genetic algorithms. SF is domain-independent and requires no\ncalibration. We first perform a controlled comparative evaluation of SF's\nability to maintain engagement and discover optimal solutions in a minimal toy\ndomain. Experimental results demonstrate that SF is able to maintain engagement\nbetter than other techniques in the literature. We then address the more\ncomplex real-world problem of evolving recommendations for health and\nwell-being. We introduce a coevolutionary extension of EvoRecSys, a previously\npublished evolutionary recommender system. We demonstrate that SF is able to\nmaintain engagement better than other techniques in the literature, and the\nresultant recommendations using SF are higher quality and more diverse than\nthose produced by EvoRecSys.",
    "descriptor": "\nComments: 16 pages, 11 figures. arXiv admin note: substantial text overlap with arXiv:2108.03156\n",
    "authors": [
      "Hugo Alcaraz-Herrera",
      "John Cartlidge"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00414"
  },
  {
    "id": "arXiv:2211.00416",
    "title": "Higher-order mutual information reveals synergistic sub-networks for  multi-neuron importance",
    "abstract": "Quantifying which neurons are important with respect to the classification\ndecision of a trained neural network is essential for understanding their inner\nworkings. Previous work primarily attributed importance to individual neurons.\nIn this work, we study which groups of neurons contain synergistic or redundant\ninformation using a multivariate mutual information method called the\nO-information. We observe the first layer is dominated by redundancy suggesting\ngeneral shared features (i.e. detecting edges) while the last layer is\ndominated by synergy indicating local class-specific features (i.e. concepts).\nFinally, we show the O-information can be used for multi-neuron importance.\nThis can be demonstrated by re-training a synergistic sub-network, which\nresults in a minimal change in performance. These results suggest our method\ncan be used for pruning and unsupervised representation learning.",
    "descriptor": "\nComments: Paper presented at InfoCog @ NeurIPS 2022\n",
    "authors": [
      "Kenzo Clauw",
      "Sebastiano Stramaglia",
      "Daniele Marinazzo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2211.00416"
  },
  {
    "id": "arXiv:2211.00419",
    "title": "Learning in colloids: Synapse-like ZnO + DMSO colloid",
    "abstract": "Colloids submitted to electrical stimuli exhibit a reconfiguration that could\nbe used to store information and, potentially, compute. We investigated\nlearnign, memorization, and time and stimulation's voltage dependence of\nconductive network formation in a colloidal suspension of ZnO nanoparticles in\nDMSO. Relations between critical resistance and stimulation time were\nreconstructed. The critical voltage, i.e. the stimulation voltage necessary for\ndropping the resistance, was shown to decrease in response to an increase in\nstimulation time.",
    "descriptor": "",
    "authors": [
      "Noushin Raeisi Kheirabadi",
      "Alessandro Chioleriob",
      "Neil Phillipsa",
      "Andrew Adamatzky"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)"
    ],
    "url": "https://arxiv.org/abs/2211.00419"
  },
  {
    "id": "arXiv:2211.00421",
    "title": "Order-sensitive Neural Constituency Parsing",
    "abstract": "We propose a novel algorithm that improves on the previous neural span-based\nCKY decoder for constituency parsing. In contrast to the traditional span-based\ndecoding, where spans are combined only based on the sum of their scores, we\nintroduce an order-sensitive strategy, where the span combination scores are\nmore carefully derived from an order-sensitive basis. Our decoder can be\nregarded as a generalization over existing span-based decoder in determining a\nfiner-grain scoring scheme for the combination of lower-level spans into\nhigher-level spans, where we emphasize on the order of the lower-level spans\nand use order-sensitive span scores as well as order-sensitive combination\ngrammar rule scores to enhance prediction accuracy. We implement the proposed\ndecoding strategy harnessing GPU parallelism and achieve a decoding speed on\npar with state-of-the-art span-based parsers. Using the previous\nstate-of-the-art model without additional data as our baseline, we outperform\nit and improve the F1 score on the Penn Treebank Dataset by 0.26% and on the\nChinese Treebank Dataset by 0.35%.",
    "descriptor": "\nComments: Paper presented at The 34th IEEE International Conference on Tools with Artificial Intelligence (ICTAI)\n",
    "authors": [
      "Zhicheng Wang",
      "Tianyu Shi",
      "Liyin Xiao",
      "Cong Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00421"
  },
  {
    "id": "arXiv:2211.00426",
    "title": "Two classes of subfield codes of linear codes",
    "abstract": "Recently, subfiled codes of linear code over GF$ (q) $ with good parameters\nwere studied, and many optimal subfield codes were obtained. In this paper, Our\nmainly motivation is to generlize the results of the subfield codes of\nhyperoval in Ding and Heng (Finite Fields Their Appl. 56, 308-331 (2019)), and\ngenerlize the results of two families of subfield codes in Xiang and Yin\n(Cryptogr. Commun. 13(1), 117-127 (2021)) to $ p $-ary where $ p $ is odd. We\nget the parameters and weight distribution of these subfield codes. At the same\ntime, the parameters of their dual codes are also studied. When $ m=1 $, The\ndual codes of these subfield codes are almost MDS code, when $ m>1 $ and $ p $\nodd, these dual codes are dimension-optimal with respect to the sphere-backing\nbound.",
    "descriptor": "",
    "authors": [
      "Xiaoqiong Ran",
      "Rong Luo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.00426"
  },
  {
    "id": "arXiv:2211.00430",
    "title": "VarMAE: Pre-training of Variational Masked Autoencoder for  Domain-adaptive Language Understanding",
    "abstract": "Pre-trained language models have achieved promising performance on general\nbenchmarks, but underperform when migrated to a specific domain. Recent works\nperform pre-training from scratch or continual pre-training on domain corpora.\nHowever, in many specific domains, the limited corpus can hardly support\nobtaining precise representations. To address this issue, we propose a novel\nTransformer-based language model named VarMAE for domain-adaptive language\nunderstanding. Under the masked autoencoding objective, we design a context\nuncertainty learning module to encode the token's context into a smooth latent\ndistribution. The module can produce diverse and well-formed contextual\nrepresentations. Experiments on science- and finance-domain NLU tasks\ndemonstrate that VarMAE can be efficiently adapted to new domains with limited\nresources.",
    "descriptor": "\nComments: 11 pages, accepted by Findings of EMNLP 2022\n",
    "authors": [
      "Dou Hu",
      "Xiaolong Hou",
      "Xiyang Du",
      "Mengyuan Zhou",
      "Lianxin Jiang",
      "Yang Mo",
      "Xiaofeng Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00430"
  },
  {
    "id": "arXiv:2211.00441",
    "title": "Zero Day Threat Detection Using Metric Learning Autoencoders",
    "abstract": "The proliferation of zero-day threats (ZDTs) to companies' networks has been\nimmensely costly and requires novel methods to scan traffic for malicious\nbehavior at massive scale. The diverse nature of normal behavior along with the\nhuge landscape of attack types makes deep learning methods an attractive option\nfor their ability to capture highly-nonlinear behavior patterns. In this paper,\nthe authors demonstrate an improvement upon a previously introduced\nmethodology, which used a dual-autoencoder approach to identify ZDTs in network\nflow telemetry. In addition to the previously-introduced asset-level graph\nfeatures, which help abstractly represent the role of a host in its network,\nthis new model uses metric learning to train the second autoencoder on labeled\nattack data. This not only produces stronger performance, but it has the added\nadvantage of improving the interpretability of the model by allowing for\nmulticlass classification in the latent space. This can potentially save human\nthreat hunters time when they investigate predicted ZDTs by showing them which\nknown attack classes were nearby in the latent space. The models presented here\nare also trained and evaluated with two more datasets, and continue to show\npromising results even when generalizing to new network topologies.",
    "descriptor": "\nComments: 8 pages, accepted to ICMLA 2022\n",
    "authors": [
      "Dhruv Nandakumar",
      "Robert Schiller",
      "Christopher Redino",
      "Kevin Choi",
      "Abdul Rahman",
      "Edward Bowen",
      "Marc Vucovich",
      "Joe Nehila",
      "Matthew Weeks",
      "Aaron Shaha"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00441"
  },
  {
    "id": "arXiv:2211.00445",
    "title": "A device-interaction model for users with special needs",
    "abstract": "Interaction is a fundamental part of using any computer system but it is\nstill an issue for people with special needs. In order to improve this\nsituation, this paper describes a new device-interaction model based on\nadaptation rules for user models. The aim is the adaptation at the interaction\nlevel, taking into account the interaction device features in order to improve\nthe usability through the user experience in the education sector. In the\nevaluation process, several students from a special education center have\nparticipated. These students have either a physical or sensory disability or\nautism. The results are promising enough to consider that this model will be\nable to help students with disabilities to interact with a computer system\nwhich will inevitably provide tremendous benefits to their academic and\npersonal development.",
    "descriptor": "\nComments: Journal paper published in Multimedia Tools and Applications\n",
    "authors": [
      "Juan Jesus Ojeda-Castelo",
      "Jose A. Piedra-Fernandez",
      "Luis Iribarne"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.00445"
  },
  {
    "id": "arXiv:2211.00446",
    "title": "A new filter for dimensionality reduction and classification of  hyperspectral images using GLCM features and mutual information",
    "abstract": "Dimensionality reduction is an important preprocessing step of the\nhyperspectral images classification (HSI), it is inevitable task. Some methods\nuse feature selection or extraction algorithms based on spectral and spatial\ninformation. In this paper, we introduce a new methodology for dimensionality\nreduction and classification of HSI taking into account both spectral and\nspatial information based on mutual information. We characterise the spatial\ninformation by the texture features extracted from the grey level cooccurrence\nmatrix (GLCM); we use Homogeneity, Contrast, Correlation and Energy. For\nclassification, we use support vector machine (SVM). The experiments are\nperformed on three well-known hyperspectral benchmark datasets. The proposed\nalgorithm is compared with the state of the art methods. The obtained results\nof this fusion show that our method outperforms the other approaches by\nincreasing the classification accuracy in a good timing. This method may be\nimproved for more performance\nKeywords: hyperspectral images; classification; spectral and spatial\nfeatures; grey level cooccurrence matrix; GLCM; mutual information; support\nvector machine; SVM.",
    "descriptor": "",
    "authors": [
      "Hasna Nhaila",
      "Elkebir Sarhrouni",
      "Ahmed Hammouch"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00446"
  },
  {
    "id": "arXiv:2211.00448",
    "title": "Signing Outside the Studio: Benchmarking Background Robustness for  Continuous Sign Language Recognition",
    "abstract": "The goal of this work is background-robust continuous sign language\nrecognition. Most existing Continuous Sign Language Recognition (CSLR)\nbenchmarks have fixed backgrounds and are filmed in studios with a static\nmonochromatic background. However, signing is not limited only to studios in\nthe real world. In order to analyze the robustness of CSLR models under\nbackground shifts, we first evaluate existing state-of-the-art CSLR models on\ndiverse backgrounds. To synthesize the sign videos with a variety of\nbackgrounds, we propose a pipeline to automatically generate a benchmark\ndataset utilizing existing CSLR benchmarks. Our newly constructed benchmark\ndataset consists of diverse scenes to simulate a real-world environment. We\nobserve even the most recent CSLR method cannot recognize glosses well on our\nnew dataset with changed backgrounds. In this regard, we also propose a simple\nyet effective training scheme including (1) background randomization and (2)\nfeature disentanglement for CSLR models. The experimental results on our\ndataset demonstrate that our method generalizes well to other unseen background\ndata with minimal additional training images.",
    "descriptor": "\nComments: Our dataset is available at this https URL\n",
    "authors": [
      "Youngjoon Jang",
      "Youngtaek Oh",
      "Jae Won Cho",
      "Dong-Jin Kim",
      "Joon Son Chung",
      "In So Kweon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00448"
  },
  {
    "id": "arXiv:2211.00453",
    "title": "The Perils of Learning From Unlabeled Data: Backdoor Attacks on  Semi-supervised Learning",
    "abstract": "Semi-supervised machine learning (SSL) is gaining popularity as it reduces\nthe cost of training ML models. It does so by using very small amounts of\n(expensive, well-inspected) labeled data and large amounts of (cheap,\nnon-inspected) unlabeled data. SSL has shown comparable or even superior\nperformances compared to conventional fully-supervised ML techniques.\nIn this paper, we show that the key feature of SSL that it can learn from\n(non-inspected) unlabeled data exposes SSL to strong poisoning attacks. In\nfact, we argue that, due to its reliance on non-inspected unlabeled data,\npoisoning is a much more severe problem in SSL than in conventional\nfully-supervised ML.\nSpecifically, we design a backdoor poisoning attack on SSL that can be\nconducted by a weak adversary with no knowledge of target SSL pipeline. This is\nunlike prior poisoning attacks in fully-supervised settings that assume strong\nadversaries with practically-unrealistic capabilities. We show that by\npoisoning only 0.2% of the unlabeled training data, our attack can cause\nmisclassification of more than 80% of test inputs (when they contain the\nadversary's backdoor trigger). Our attacks remain effective across twenty\ncombinations of benchmark datasets and SSL algorithms, and even circumvent the\nstate-of-the-art defenses against backdoor attacks. Our work raises significant\nconcerns about the practical utility of existing SSL algorithms.",
    "descriptor": "",
    "authors": [
      "Virat Shejwalkar",
      "Lingjuan Lyu",
      "Amir Houmansadr"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.00453"
  },
  {
    "id": "arXiv:2211.00457",
    "title": "Evaluation of a blockchain-enabled resource management mechanism for  NGNs",
    "abstract": "A new era in ICT has begun with the evolution of Next Generation Networks\n(NGNs) and the development of human-centric applications. Ultra-low latency,\nhigh throughput, and high availability are a few of the main characteristics of\nmodern networks. Network Providers (NPs) are responsible for the development\nand maintenance of network infrastructures ready to support the most demanding\napplications that should be available not only in urban areas but in every\ncorner of the earth. The NPs must collaborate to offer high-quality services\nand keep their overall cost low. The collaboration among competitive entities\ncan in principle be regulated by a trusted 3rd party or by a distributed\napproach/technology which can guarantee integrity, security, and trust. This\npaper examines the use of blockchain technology for resource management and\nnegotiation among NPs and presents the results of experiments conducted in a\ndedicated real testbed. The implementation of the resource management mechanism\nis described in a Smart Contract (SC) and the testbeds use the Raft and the\nIBFT consensus mechanisms respectively. The goal of this paper is two-fold: to\nassess its performance in terms of transaction throughput and latency so that\nwe can assess the granularity at which this solution can operate (e.g. support\nresource re-allocation among NPs on micro-service level or not) and define\nimplementation-specific parameters like the consensus mechanism that is the\nmost suitable for this use case based on performance metrics.",
    "descriptor": "",
    "authors": [
      "Michael Xevgenis",
      "Dimitrios Kogias",
      "Ioannis Christidis",
      "Charalampos Patrikakis",
      "Helen C. Leligou"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00457"
  },
  {
    "id": "arXiv:2211.00458",
    "title": "CPG-RL: Learning Central Pattern Generators for Quadruped Locomotion",
    "abstract": "In this letter, we present a method for integrating central pattern\ngenerators (CPGs), i.e. systems of coupled oscillators, into the deep\nreinforcement learning (DRL) framework to produce robust and omnidirectional\nquadruped locomotion. The agent learns to directly modulate the intrinsic\noscillator setpoints (amplitude and frequency) and coordinate rhythmic behavior\namong different oscillators. This approach also allows the use of DRL to\nexplore questions related to neuroscience, namely the role of descending\npathways, interoscillator couplings, and sensory feedback in gait generation.\nWe train our policies in simulation and perform a sim-to-real transfer to the\nUnitree A1 quadruped, where we observe robust behavior to disturbances unseen\nduring training, most notably to a dynamically added 13.75 kg load representing\n115% of the nominal quadruped mass. We test several different observation\nspaces based on proprioceptive sensing and show that our framework is\ndeployable with no domain randomization and very little feedback, where along\nwith the oscillator states, it is possible to provide only contact booleans in\nthe observation space. Video results can be found at\nhttps://youtu.be/xqXHLzLsEV4.",
    "descriptor": "\nComments: Accepted for IEEE Robotics and Automation Letters, September 2022\n",
    "authors": [
      "Guillaume Bellegarda",
      "Auke Ijspeert"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.00458"
  },
  {
    "id": "arXiv:2211.00463",
    "title": "Amplifying Membership Exposure via Data Poisoning",
    "abstract": "As in-the-wild data are increasingly involved in the training stage, machine\nlearning applications become more susceptible to data poisoning attacks. Such\nattacks typically lead to test-time accuracy degradation or controlled\nmisprediction. In this paper, we investigate the third type of exploitation of\ndata poisoning - increasing the risks of privacy leakage of benign training\nsamples. To this end, we demonstrate a set of data poisoning attacks to amplify\nthe membership exposure of the targeted class. We first propose a generic\ndirty-label attack for supervised classification algorithms. We then propose an\noptimization-based clean-label attack in the transfer learning scenario,\nwhereby the poisoning samples are correctly labeled and look \"natural\" to evade\nhuman moderation. We extensively evaluate our attacks on computer vision\nbenchmarks. Our results show that the proposed attacks can substantially\nincrease the membership inference precision with minimum overall test-time\nmodel performance degradation. To mitigate the potential negative impacts of\nour attacks, we also investigate feasible countermeasures.",
    "descriptor": "\nComments: To Appear in the 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Yufei Chen",
      "Chao Shen",
      "Yun Shen",
      "Cong Wang",
      "Yang Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.00463"
  },
  {
    "id": "arXiv:2211.00466",
    "title": "Recognition of Defective Mineral Wool Using Pruned ResNet Models",
    "abstract": "Mineral wool production is a non-linear process that makes it hard to control\nthe final quality. Therefore, having a non-destructive method to analyze the\nproduct quality and recognize defective products is critical. For this purpose,\nwe developed a visual quality control system for mineral wool. X-ray images of\nwool specimens were collected to create a training set of defective and\nnon-defective samples. Afterward, we developed several recognition models based\non the ResNet architecture to find the most efficient model. In order to have a\nlight-weight and fast inference model for real-life applicability, two\nstructural pruning methods are applied to the classifiers. Considering the low\nquantity of the dataset, cross-validation and augmentation methods are used\nduring the training. As a result, we obtained a model with more than 98%\naccuracy, which in comparison to the current procedure used at the company, it\ncan recognize 20% more defective products.",
    "descriptor": "\nComments: 6 pages, 5 figures, 3 tables Submitted on IEEE Transactions on Industrial Informatics\n",
    "authors": [
      "Mehdi Rafiei",
      "Dat Thanh Tran",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.00466"
  },
  {
    "id": "arXiv:2211.00471",
    "title": "Exploring Effects of Computational Parameter Changes to Image  Recognition Systems",
    "abstract": "Image recognition tasks typically use deep learning and require enormous\nprocessing power, thus relying on hardware accelerators like GPUs and FPGAs for\nfast, timely processing. Failure in real-time image recognition tasks can occur\ndue to incorrect mapping on hardware accelerators, which may lead to timing\nuncertainty and incorrect behavior. Owing to the increased use of image\nrecognition tasks in safety-critical applications like autonomous driving and\nmedical imaging, it is imperative to assess their robustness to changes in the\ncomputational environment as parameters like deep learning frameworks, compiler\noptimizations for code generation, and hardware devices are not regulated with\nvarying impact on model performance and correctness. In this paper we conduct\nrobustness analysis of four popular image recognition models (MobileNetV2,\nResNet101V2, DenseNet121 and InceptionV3) with the ImageNet dataset, assessing\nthe impact of the following parameters in the model's computational\nenvironment: (1) deep learning frameworks; (2) compiler optimizations; and (3)\nhardware devices. We report sensitivity of model performance in terms of output\nlabel and inference time for changes in each of these environment parameters.\nWe find that output label predictions for all four models are sensitive to\nchoice of deep learning framework (by up to 57%) and insensitive to other\nparameters. On the other hand, model inference time was affected by all\nenvironment parameters with changes in hardware device having the most effect.\nThe extent of effect was not uniform across models.",
    "descriptor": "\nComments: 9 pages, 8 figures, 1 table\n",
    "authors": [
      "Nikolaos Louloudakis",
      "Perry Gibson",
      "Jos\u00e9 Cano",
      "Ajitha Rajan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.00471"
  },
  {
    "id": "arXiv:2211.00472",
    "title": "Backtracking Counterfactuals",
    "abstract": "Counterfactual reasoning -- envisioning hypothetical scenarios, or possible\nworlds, where some circumstances are different from what (f)actually occurred\n(counter-to-fact) -- is ubiquitous in human cognition. Conventionally,\ncounterfactually-altered circumstances have been treated as \"small miracles\"\nthat locally violate the laws of nature while sharing the same initial\nconditions. In Pearl's structural causal model (SCM) framework this is made\nmathematically rigorous via interventions that modify the causal laws while the\nvalues of exogenous variables are shared. In recent years, however, this purely\ninterventionist account of counterfactuals has increasingly come under scrutiny\nfrom both philosophers and psychologists. Instead, they suggest a backtracking\naccount of counterfactuals, according to which the causal laws remain unchanged\nin the counterfactual world; differences to the factual world are instead\n\"backtracked\" to altered initial conditions (exogenous variables). In the\npresent work, we explore and formalise this alternative mode of counterfactual\nreasoning within the SCM framework. Despite ample evidence that humans\nbacktrack, the present work constitutes, to the best of our knowledge, the\nfirst general account and algorithmisation of backtracking counterfactuals. We\ndiscuss our backtracking semantics in the context of related literature and\ndraw connections to recent developments in explainable artificial intelligence\n(XAI).",
    "descriptor": "",
    "authors": [
      "Julius von K\u00fcgelgen",
      "Abdirisak Mohamed",
      "Sander Beckers"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.00472"
  },
  {
    "id": "arXiv:2211.00478",
    "title": "Understanding the Unforeseen via the Intentional Stance",
    "abstract": "We present an architecture and system for understanding novel behaviors of an\nobserved agent. The two main features of our approach are the adoption of\nDennett's intentional stance and analogical reasoning as one of the main\ncomputational mechanisms for understanding unforeseen experiences. Our approach\nuses analogy with past experiences to construct hypothetical rationales that\nexplain the behavior of an observed agent. Moreover, we view analogies as\npartial; thus multiple past experiences can be blended to analogically explain\nan unforeseen event, leading to greater inferential flexibility. We argue that\nthis approach results in more meaningful explanations of observed behavior than\napproaches based on surface-level comparisons. A key advantage of behavior\nexplanation over classification is the ability to i) take appropriate responses\nbased on reasoning and ii) make non-trivial predictions that allow for the\nverification of the hypothesized explanation. We provide a simple use case to\ndemonstrate novel experience understanding through analogy in a gas station\nenvironment.",
    "descriptor": "",
    "authors": [
      "Stephanie Stacy",
      "Alfredo Gabaldon",
      "John Karigiannis",
      "James Kubrich",
      "Peter Tu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00478"
  },
  {
    "id": "arXiv:2211.00479",
    "title": "Revisiting the Practical Effectiveness of Constituency Parse Extraction  from Pre-trained Language Models",
    "abstract": "Constituency Parse Extraction from Pre-trained Language Models (CPE-PLM) is a\nrecent paradigm that attempts to induce constituency parse trees relying only\non the internal knowledge of pre-trained language models. While attractive in\nthe perspective that similar to in-context learning, it does not require\ntask-specific fine-tuning, the practical effectiveness of such an approach\nstill remains unclear, except that it can function as a probe for investigating\nlanguage models' inner workings. In this work, we mathematically reformulate\nCPE-PLM and propose two advanced ensemble methods tailored for it,\ndemonstrating that the new parsing paradigm can be competitive with common\nunsupervised parsers by introducing a set of heterogeneous PLMs combined using\nour techniques. Furthermore, we explore some scenarios where the trees\ngenerated by CPE-PLM are practically useful. Specifically, we show that CPE-PLM\nis more effective than typical supervised parsers in few-shot settings.",
    "descriptor": "\nComments: COLING 2022\n",
    "authors": [
      "Taeuk Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.00479"
  },
  {
    "id": "arXiv:2211.00480",
    "title": "Pricing for Reconfigurable Intelligent Surface Aided Wireless Networks:  Models and Principles",
    "abstract": "Owing to the recent advancements of meta-materials and meta-surfaces, the\nconcept of reconfigurable intelligent surface (RIS) has been embraced to meet\nthe spectral- and energy-efficient, and yet cost-effective solutions for the\nsixth-generation (6G) wireless networks. From an operational standpoint, RISs\ncan be easily deployed on the facades of buildings and indoor walls. Albeit\npromising, in the actual network operation, the deployment of RISs may face\nchallenges because of the willingness and benefits of RIS holders from the\naspect of installing RISs on their properties. Accordingly, RIS-aided wireless\nnetworks are faced with a formidable mission: how to balance the wireless\nservice providers (WSPs) and RIS holders in terms of their respective\ninterests. To alleviate this deadlock, we focus on the application of pricing\nmodels in RIS-aided wireless networks in pursuit of a win-win solution for both\nsides. Specifically, we commence with a comprehensive introduction of RIS\npricing with its potential applications in RIS networks, meanwhile the\nfundamentals of pricing models are summarized in order to benefit both RIS\nholders and WSPs. In addition, a Stackelberg game-based model is exemplified to\nillustrate the operation of utility-maximization pricing. Finally, we highlight\nopen issues and future research directions of applying pricing models to the\nRIS-aided wireless networks.",
    "descriptor": "",
    "authors": [
      "Yulan Gao",
      "Yue Xiao",
      "Xianfu Lei",
      "Qiaonan Zhu",
      "Dusit Niyato",
      "Kai-Kit Wong",
      "Pingzhi Fan",
      "Rose Qingyang Hu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.00480"
  },
  {
    "id": "arXiv:2211.00481",
    "title": "Multi-Resource Allocation for On-Device Distributed Federated Learning  Systems",
    "abstract": "This work poses a distributed multi-resource allocation scheme for minimizing\nthe weighted sum of latency and energy consumption in the on-device distributed\nfederated learning (FL) system. Each mobile device in the system engages the\nmodel training process within the specified area and allocates its computation\nand communication resources for deriving and uploading parameters,\nrespectively, to minimize the objective of system subject to the\ncomputation/communication budget and a target latency requirement. In\nparticular, mobile devices are connect via wireless TCP/IP architectures.\nExploiting the optimization problem structure, the problem can be decomposed to\ntwo convex sub-problems. Drawing on the Lagrangian dual and harmony search\ntechniques, we characterize the global optimal solution by the closed-form\nsolutions to all sub-problems, which give qualitative insights to\nmulti-resource tradeoff. Numerical simulations are used to validate the\nanalysis and assess the performance of the proposed algorithm.",
    "descriptor": "",
    "authors": [
      "Yulan Gao",
      "Ziqiang Ye",
      "Han Yu",
      "Zehui Xiong",
      "Yue Xiao",
      "Dusit Niyato"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00481"
  },
  {
    "id": "arXiv:2211.00483",
    "title": "From Information to Affirmation: An Investigation on the Echo Chamber  Effect from YouTube Comments under Technology Product Reviews",
    "abstract": "Social media may create echo chambers that reaffirm users' beliefs and\nopinions through repeated exposure of similar notions. Whilst the formation and\neffect of echo chambers have been intensively examined in thread-based\nplatforms such as Twitter, Facebook and Reddit, we shift our focus on product\nreview discussions on YouTube. This paper examines YouTube comments (n=2500)\nthrough a combined approach of quantitative content analysis (QCA) and\nsentiment analysis (SA) under selected selected YouTube videos (n=10). We\nconclude this paper by highlighting the formation of echo chamber effect in\nrelation to comment argumentation and sentiments.",
    "descriptor": "\nComments: 13 pages, 3 figures and 3 tables\n",
    "authors": [
      "Hongrui Jin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.00483"
  },
  {
    "id": "arXiv:2211.00486",
    "title": "Causal DAG extraction from a library of books or videos/movies",
    "abstract": "Determining a causal DAG (directed acyclic graph) for a problem under\nconsideration, is a major roadblock when doing Judea Pearl's Causal Inference\n(CI) in Statistics. The same problem arises when doing CI in Artificial\nIntelligence (AI) and Machine Learning (ML). As with many problems in Science,\nwe think Nature has found an effective solution to this problem. We argue that\nhuman and animal brains contain an explicit engine for doing CI, and that such\nan engine uses as input an atlas (i.e., collection) of causal DAGs. We propose\na simple algorithm for constructing such an atlas from a library of books or\nvideos/movies. We illustrate our method by applying it to a database of\nrandomly generated Tic-Tac-Toe games. The software used to generate this\nTic-Tac-Toe example is open source and available at GitHub.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Robert R. Tucci"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00486"
  },
  {
    "id": "arXiv:2211.00495",
    "title": "Efficient Graph Neural Network Inference at Large Scale",
    "abstract": "Graph neural networks (GNNs) have demonstrated excellent performance in a\nwide range of applications. However, the enormous size of large-scale graphs\nhinders their applications under real-time inference scenarios. Although\nexisting scalable GNNs leverage linear propagation to preprocess the features\nand accelerate the training and inference procedure, these methods still suffer\nfrom scalability issues when making inferences on unseen nodes, as the feature\npreprocessing requires the graph is known and fixed. To speed up the inference\nin the inductive setting, we propose a novel adaptive propagation order\napproach that generates the personalized propagation order for each node based\non its topological information. This could successfully avoid the redundant\ncomputation of feature propagation. Moreover, the trade-off between accuracy\nand inference latency can be flexibly controlled by simple hyper-parameters to\nmatch different latency constraints of application scenarios. To compensate for\nthe potential inference accuracy loss, we further propose Inception\nDistillation to exploit the multi scale reception information and improve the\ninference performance. Extensive experiments are conducted on four public\ndatasets with different scales and characteristics, and the experimental\nresults show that our proposed inference acceleration framework outperforms the\nSOTA graph inference acceleration baselines in terms of both accuracy and\nefficiency. In particular, the advantage of our proposed method is more\nsignificant on larger-scale datasets, and our framework achieves $75\\times$\ninference speedup on the largest Ogbn-products dataset.",
    "descriptor": "",
    "authors": [
      "Xinyi Gao",
      "Wentao Zhang",
      "Yingxia Shao",
      "Quoc Viet Hung Nguyen",
      "Bin Cui",
      "Hongzhi Yin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00495"
  },
  {
    "id": "arXiv:2211.00497",
    "title": "Modelling black-box audio effects with time-varying feature modulation",
    "abstract": "Deep learning approaches for black-box modelling of audio effects have shown\npromise, however, the majority of existing work focuses on nonlinear effects\nwith behaviour on relatively short time-scales, such as guitar amplifiers and\ndistortion. While recurrent and convolutional architectures can theoretically\nbe extended to capture behaviour at longer time scales, we show that simply\nscaling the width, depth, or dilation factor of existing architectures does not\nresult in satisfactory performance when modelling audio effects such as fuzz\nand dynamic range compression. To address this, we propose the integration of\ntime-varying feature-wise linear modulation into existing temporal\nconvolutional backbones, an approach that enables learnable adaptation of the\nintermediate activations. We demonstrate that our approach more accurately\ncaptures long-range dependencies for a range of fuzz and compressor\nimplementations across both time and frequency domain metrics. We provide sound\nexamples, source code, and pretrained models to faciliate reproducibility.",
    "descriptor": "",
    "authors": [
      "Marco Comunit\u00e0",
      "Christian J. Steinmetz",
      "Huy Phan",
      "Joshua D. Reiss"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00497"
  },
  {
    "id": "arXiv:2211.00498",
    "title": "Should I disclose my dataset? Caveats between reproducibility and  individual data rights",
    "abstract": "Natural language processing techniques have helped domain experts solve legal\nproblems. Digital availability of court documents increases possibilities for\nresearchers, who can access them as a source for building datasets -- whose\ndisclosure is aligned with good reproducibility practices in computational\nresearch. Large and digitized court systems, such as the Brazilian one, are\nprone to be explored in that sense. However, personal data protection laws\nimpose restrictions on data exposure and state principles about which\nresearchers should be mindful. Special caution must be taken in cases with\nhuman rights violations, such as gender discrimination, over which we elaborate\nas an example of interest. We present legal and ethical considerations on the\nissue, as well as guidelines for researchers dealing with this kind of data and\ndeciding whether to disclose it.",
    "descriptor": "\nComments: 10 pages, 2 figures. To be published in the 4th Workshop on Natural Legal Language Processing (NLLP 2022), co-located with the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP 2022)\n",
    "authors": [
      "Raysa M. Benatti",
      "Camila M. L. Villarroel",
      "Sandra Avila",
      "Esther L. Colombini",
      "Fabiana C. Severi"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.00498"
  },
  {
    "id": "arXiv:2211.00499",
    "title": "A combination technique for optimal control problems constrained by  random PDEs",
    "abstract": "We present a combination technique based on mixed differences of both spatial\napproximations and quadrature formulae for the stochastic variables to solve\nefficiently a class of Optimal Control Problems (OCPs) constrained by random\npartial differential equations. The method requires to solve the OCP for\nseveral low-fidelity spatial grids and quadrature formulae for the objective\nfunctional. All the computed solutions are then linearly combined to get a\nfinal approximation which, under suitable regularity assumptions, preserves the\nsame accuracy of fine tensor product approximations, while drastically reducing\nthe computational cost. The combination technique involves only tensor product\nquadrature formulae, thus the discretized OCPs preserve the convexity of the\ncontinuous OCP. Hence, the combination technique avoids the inconveniences of\nMultilevel Monte Carlo and/or sparse grids approaches, but remains suitable for\nhigh dimensional problems. The manuscript presents an a-priori procedure to\nchoose the most important mixed differences and an asymptotic complexity\nanalysis, which states that the asymptotic complexity is exclusively determined\nby the spatial solver. Numerical experiments validate the results.",
    "descriptor": "\nComments: 25 pages, 4 figures\n",
    "authors": [
      "Fabio Nobile",
      "Tommaso Vanzan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.00499"
  },
  {
    "id": "arXiv:2211.00502",
    "title": "Phase-based Ranging in Narrowband Systems with Missing/Interfered Tones",
    "abstract": "The growth in the number of low-cost narrow band radios such as Bluetooth low\nenergy (BLE) enabled applications such as asset tracking, human behavior\nmonitoring, and keyless entry. The accurate range estimation is a must in such\napplications. Phase-based ranging has recently gained momentum due to its high\naccuracy in multipath environment compared to traditional schemes such as\nranging based on received signal strength. The phase-based ranging requires\ntone exchange on multiple frequencies on a uniformly sampled frequency grid.\nSuch tone exchange may not be possible due to some missing tones, e.g.,\nreserved advertisement channels. Furthermore, the IQ values at a given tone may\nbe distorted by interference. In this paper, we proposed two phase-based\nranging schemes which deal with the missing/interfered tones. We compare the\nperformance and complexity of the proposed schemes using simulations,\ncomplexity analysis, and two measurement setups. In particular, we show that\nfor small number of missing/interfered tones, the proposed system based on\nemploying a trained neural network (NN) performs very close to a reference\nranging system where there is no missing/interference tones. Interestingly,\nthis high performance is at the cost of negligible additional computational\ncomplexity and up to 60.5 Kbytes of additional required memory compared to the\nreference system, making it an attractive solution for ranging using\nhardware-limited radios such as BLE.",
    "descriptor": "",
    "authors": [
      "Alireza Sheikh",
      "Jac Romme",
      "Jochem Govers",
      "Amirashkan Farsaei",
      "Christian Bachmann"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.00502"
  },
  {
    "id": "arXiv:2211.00509",
    "title": "Self-Supervised Intensity-Event Stereo Matching",
    "abstract": "Event cameras are novel bio-inspired vision sensors that output pixel-level\nintensity changes in microsecond accuracy with a high dynamic range and low\npower consumption. Despite these advantages, event cameras cannot be directly\napplied to computational imaging tasks due to the inability to obtain\nhigh-quality intensity and events simultaneously. This paper aims to connect a\nstandalone event camera and a modern intensity camera so that the applications\ncan take advantage of both two sensors. We establish this connection through a\nmulti-modal stereo matching task. We first convert events to a reconstructed\nimage and extend the existing stereo networks to this multi-modality condition.\nWe propose a self-supervised method to train the multi-modal stereo network\nwithout using ground truth disparity data. The structure loss calculated on\nimage gradients is used to enable self-supervised learning on such multi-modal\ndata. Exploiting the internal stereo constraint between views with different\nmodalities, we introduce general stereo loss functions, including disparity\ncross-consistency loss and internal disparity loss, leading to improved\nperformance and robustness compared to existing approaches. The experiments\ndemonstrate the effectiveness of the proposed method, especially the proposed\ngeneral stereo loss functions, on both synthetic and real datasets. At last, we\nshed light on employing the aligned events and intensity images in downstream\ntasks, e.g., video interpolation application.",
    "descriptor": "\nComments: This paper has been accepted by the Journal of Imaging Science & Technology\n",
    "authors": [
      "Jinjin Gu",
      "Jinan Zhou",
      "Ringo Sai Wo Chu",
      "Yan Chen",
      "Jiawei Zhang",
      "Xuanye Cheng",
      "Song Zhang",
      "Jimmy S. Ren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00509"
  },
  {
    "id": "arXiv:2211.00513",
    "title": "E2E Refined Dataset",
    "abstract": "Although the well-known MR-to-text E2E dataset has been used by many\nresearchers, its MR-text pairs include many deletion/insertion/substitution\nerrors. Since such errors affect the quality of MR-to-text systems, they must\nbe fixed as much as possible. Therefore, we developed a refined dataset and\nsome python programs that convert the original E2E dataset into a refined\ndataset.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Keisuke Toyama",
      "Katsuhito Sudoh",
      "Satoshi Nakamura"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.00513"
  },
  {
    "id": "arXiv:2211.00514",
    "title": "MDC Enhanced IoT Networks: Network Modeling and Performance Analysis",
    "abstract": "As a promising architecture, Mobile Data Collector (MDC) enhanced Internet of\nThings (IoT) exhibits broad prospects in efficient data collection and data\naggregation especially for sparse deployment scenarios. Combining the tools\nfrom queueing theory and stochastic geometry, we propose an analytical\nframework to study the network performance of an MDC enhanced IoT network, in\nterms of coverage probability, end-to-end delay and energy consumption. We\nderive the closed-form expressions for average contact and inter-contact time\nbetween a sensor and its associated MDC. By modeling the data collection system\nbetween a sensor and its associated MDCs as an M/G/1 queue system with\nvacations and general limited (G-limited) service, we first derive the queueing\ndelay at the tagged sensor, and further obtain the end-to-end delay. The\nproposed analytical framework enables us to quantify the effect on network\nperformance of key system parameters, such as MDC velocity, packet arrival\nrate, densities of sensors and MDCs, and contact radius. This study reveals\nthat the MDC velocity has little impact on the coverage probability, and\nprovides guidelines to minimize the end-to-end delay by optimizing the density\nand contact radius of sensors, and the velocity and density of MDCs.",
    "descriptor": "\nComments: 32 pages, 12 figures, submitted to IEEE Transactions on Green Communications and Networking\n",
    "authors": [
      "Hongguang Sun",
      "Yajun Ma",
      "Tony Q. S. Quek",
      "Xijun Wang",
      "Kun Guo",
      "Hongming Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.00514"
  },
  {
    "id": "arXiv:2211.00515",
    "title": "Infinite-Dimensional Adaptive Boundary Observer for Inner-Domain  Temperature Estimation of 3D Electrosurgical Processes using Surface  Thermography Sensing",
    "abstract": "We present a novel 3D adaptive observer framework for use in the\ndetermination of subsurface organic tissue temperatures in electrosurgery. The\nobserver structure leverages pointwise 2D surface temperature readings obtained\nfrom a real-time infrared thermographer for both parameter estimation and\ntemperature field observation. We introduce a novel approach to decoupled\nparameter adaptation and estimation, wherein the parameter estimation can run\nin real-time, while the observer loop runs on a slower time scale. To achieve\nthis, we introduce a novel parameter estimation method known as attention-based\nnoise-robust averaging, in which surface thermography time series are used to\ndirectly estimate the tissue's diffusivity. Our observer contains a real-time\nparameter adaptation component based on this diffusivity adaptation law, as\nwell as a Luenberger-type corrector based on the sensed surface temperature. In\nthis work, we also present a novel model structure adapted to the setting of\nrobotic surgery, wherein we model the electrosurgical heat distribution as a\ncompactly supported magnitude- and velocity-controlled heat source involving a\nnew nonlinear input mapping. We demonstrate satisfactory performance of the\nadaptive observer in simulation, using real-life experimental ex vivo porcine\ntissue data.",
    "descriptor": "\nComments: Paper accepted to the 2022 IEEE Conference on Decision and Control (CDC 2022)\n",
    "authors": [
      "Hamza El-Kebir",
      "Junren Ran",
      "Martin Ostoja-Starzewski",
      "Richard Berlin",
      "Joseph Bentsman",
      "Leonardo P. Chamorro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.00515"
  },
  {
    "id": "arXiv:2211.00519",
    "title": "Learning Neural Implicit Representations with Surface Signal  Parameterizations",
    "abstract": "Neural implicit surface representations have recently emerged as popular\nalternative to explicit 3D object encodings, such as polygonal meshes,\ntabulated points, or voxels. While significant work has improved the geometric\nfidelity of these representations, much less attention is given to their final\nappearance. Traditional explicit object representations commonly couple the 3D\nshape data with auxiliary surface-mapped image data, such as diffuse color\ntextures and fine-scale geometric details in normal maps that typically require\na mapping of the 3D surface onto a plane, i.e., a surface parameterization;\nimplicit representations, on the other hand, cannot be easily textured due to\nlack of configurable surface parameterization. Inspired by this digital content\nauthoring methodology, we design a neural network architecture that implicitly\nencodes the underlying surface parameterization suitable for appearance data.\nAs such, our model remains compatible with existing mesh-based digital content\nwith appearance data. Motivated by recent work that overfits compact networks\nto individual 3D objects, we present a new weight-encoded neural implicit\nrepresentation that extends the capability of neural implicit surfaces to\nenable various common and important applications of texture mapping. Our method\noutperforms reasonable baselines and state-of-the-art alternatives.",
    "descriptor": "",
    "authors": [
      "Yanran Guan",
      "Andrei Chubarau",
      "Ruby Rao",
      "Derek Nowrouzezahrai"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00519"
  },
  {
    "id": "arXiv:2211.00522",
    "title": "TrimTail: Low-Latency Streaming ASR with Simple but Effective  Spectrogram-Level Length Penalty",
    "abstract": "In this paper, we present TrimTail, a simple but effective emission\nregularization method to improve the latency of streaming ASR models. The core\nidea of TrimTail is to apply length penalty (i.e., by trimming trailing frames,\nsee Fig. 1-(b)) directly on the spectrogram of input utterances, which does not\nrequire any alignment. We demonstrate that TrimTail is computationally cheap\nand can be applied online and optimized with any training loss or any model\narchitecture on any dataset without any extra effort by applying it on various\nend-to-end streaming ASR networks either trained with CTC loss [1] or\nTransducer loss [2]. We achieve 100 $\\sim$ 200ms latency reduction with equal\nor even better accuracy on both Aishell-1 and Librispeech. Moreover, by using\nTrimTail, we can achieve a 400ms algorithmic improvement of User Sensitive\nDelay (USD) with an accuracy loss of less than 0.2.",
    "descriptor": "\nComments: submitted to ICASSP 2023\n",
    "authors": [
      "Xingchen Song",
      "Di Wu",
      "Zhiyong Wu",
      "Binbin Zhang",
      "Yuekai Zhang",
      "Zhendong Peng",
      "Wenpeng Li",
      "Fuping Pan",
      "Changbao Zhu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00522"
  },
  {
    "id": "arXiv:2211.00523",
    "title": "Learning utterance-level representations through token-level acoustic  latents prediction for Expressive Speech Synthesis",
    "abstract": "This paper proposes an Expressive Speech Synthesis model that utilizes\ntoken-level latent prosodic variables in order to capture and control\nutterance-level attributes, such as character acting voice and speaking style.\nCurrent works aim to explicitly factorize such fine-grained and utterance-level\nspeech attributes into different representations extracted by modules that\noperate in the corresponding level. We show that the fine-grained latent space\nalso captures coarse-grained information, which is more evident as the\ndimension of latent space increases in order to capture diverse prosodic\nrepresentations. Therefore, a trade-off arises between the diversity of the\ntoken-level and utterance-level representations and their disentanglement. We\nalleviate this issue by first capturing rich speech attributes into a\ntoken-level latent space and then, separately train a prior network that given\nthe input text, learns utterance-level representations in order to predict the\nphoneme-level, posterior latents extracted during the previous step. Both\nqualitative and quantitative evaluations are used to demonstrate the\neffectiveness of the proposed approach. Audio samples are available in our demo\npage.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Karolos Nikitaras",
      "Konstantinos Klapsas",
      "Nikolaos Ellinas",
      "Georgia Maniati",
      "June Sig Sung",
      "Inchul Hwang",
      "Spyros Raptis",
      "Aimilios Chalamandaris",
      "Pirros Tsiakoulis"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00523"
  },
  {
    "id": "arXiv:2211.00525",
    "title": "The Enemy of My Enemy is My Friend: Exploring Inverse Adversaries for  Improving Adversarial Training",
    "abstract": "Although current deep learning techniques have yielded superior performance\non various computer vision tasks, yet they are still vulnerable to adversarial\nexamples. Adversarial training and its variants have been shown to be the most\neffective approaches to defend against adversarial examples. These methods\nusually regularize the difference between output probabilities for an\nadversarial and its corresponding natural example. However, it may have a\nnegative impact if the model misclassifies a natural example. To circumvent\nthis issue, we propose a novel adversarial training scheme that encourages the\nmodel to produce similar outputs for an adversarial example and its ``inverse\nadversarial'' counterpart. These samples are generated to maximize the\nlikelihood in the neighborhood of natural examples. Extensive experiments on\nvarious vision datasets and architectures demonstrate that our training method\nachieves state-of-the-art robustness as well as natural accuracy. Furthermore,\nusing a universal version of inverse adversarial examples, we improve the\nperformance of single-step adversarial training techniques at a low\ncomputational cost.",
    "descriptor": "",
    "authors": [
      "Junhao Dong",
      "Seyed-Mohsen Moosavi-Dezfooli",
      "Jianhuang Lai",
      "Xiaohua Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00525"
  },
  {
    "id": "arXiv:2211.00526",
    "title": "Leveraging Graph-based Cross-modal Information Fusion for Neural Sign  Language Translation",
    "abstract": "Sign Language (SL), as the mother tongue of the deaf community, is a special\nvisual language that most hearing people cannot understand. In recent years,\nneural Sign Language Translation (SLT), as a possible way for bridging\ncommunication gap between the deaf and the hearing people, has attracted\nwidespread academic attention. We found that the current mainstream end-to-end\nneural SLT models, which tries to learning language knowledge in a weakly\nsupervised manner, could not mine enough semantic information under the\ncondition of low data resources. Therefore, we propose to introduce additional\nword-level semantic knowledge of sign language linguistics to assist in\nimproving current end-to-end neural SLT models. Concretely, we propose a novel\nneural SLT model with multi-modal feature fusion based on the dynamic graph, in\nwhich the cross-modal information, i.e. text and video, is first assembled as a\ndynamic graph according to their correlation, and then the graph is processed\nby a multi-modal graph encoder to generate the multi-modal embeddings for\nfurther usage in the subsequent neural translation models. To the best of our\nknowledge, we are the first to introduce graph neural networks, for fusing\nmulti-modal information, into neural sign language translation models.\nMoreover, we conducted experiments on a publicly available popular SLT dataset\nRWTH-PHOENIX-Weather-2014T. and the quantitative experiments show that our\nmethod can improve the model.",
    "descriptor": "",
    "authors": [
      "Jiangbin Zheng",
      "Siyuan Li",
      "Cheng Tan",
      "Chong Wu",
      "Yidong Chen",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00526"
  },
  {
    "id": "arXiv:2211.00533",
    "title": "Optimal Complexity in Non-Convex Decentralized Learning over  Time-Varying Networks",
    "abstract": "Decentralized optimization with time-varying networks is an emerging paradigm\nin machine learning. It saves remarkable communication overhead in large-scale\ndeep training and is more robust in wireless scenarios especially when nodes\nare moving. Federated learning can also be regarded as decentralized\noptimization with time-varying communication patterns alternating between\nglobal averaging and local updates.\nWhile numerous studies exist to clarify its theoretical limits and develop\nefficient algorithms, it remains unclear what the optimal complexity is for\nnon-convex decentralized stochastic optimization over time-varying networks.\nThe main difficulties lie in how to gauge the effectiveness when transmitting\nmessages between two nodes via time-varying communications, and how to\nestablish the lower bound when the network size is fixed (which is a\nprerequisite in stochastic optimization). This paper resolves these challenges\nand establish the first lower bound complexity. We also develop a new\ndecentralized algorithm to nearly attain the lower bound, showing the tightness\nof the lower bound and the optimality of our algorithm.",
    "descriptor": "\nComments: Accepted by 14th Annual Workshop on Optimization for Machine Learning. arXiv admin note: text overlap with arXiv:2210.07863\n",
    "authors": [
      "Xinmeng Huang",
      "Kun Yuan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.00533"
  },
  {
    "id": "arXiv:2211.00534",
    "title": "Deep Learning for Global Wildfire Forecasting",
    "abstract": "Climate change is expected to aggravate wildfire activity through the\nexacerbation of fire weather. Improving our capabilities to anticipate\nwildfires on a global scale is of uttermost importance for mitigating their\nnegative effects. In this work, we create a global fire dataset and demonstrate\na prototype for predicting the presence of global burned areas on a\nsub-seasonal scale with the use of segmentation deep learning models.\nParticularly, we present an open-access global analysis-ready datacube, which\ncontains a variety of variables related to the seasonal and sub-seasonal fire\ndrivers (climate, vegetation, oceanic indices, human-related variables), as\nwell as the historical burned areas and wildfire emissions for 2001-2021. We\ntrain a deep learning model, which treats global wildfire forecasting as an\nimage segmentation task and skillfully predicts the presence of burned areas 8,\n16, 32 and 64 days ahead of time. Our work motivates the use of deep learning\nfor global burned area forecasting and paves the way towards improved\nanticipation of global wildfire patterns.",
    "descriptor": "\nComments: Accept in NeurIPS 2022 workshop on Tackling Climate Change with Machine Learning\n",
    "authors": [
      "Ioannis Prapas",
      "Akanksha Ahuja",
      "Spyros Kondylatos",
      "Ilektra Karasante",
      "Eleanna Panagiotou",
      "Lazaro Alonso",
      "Charalampos Davalas",
      "Dimitrios Michail",
      "Nuno Carvalhais",
      "Ioannis Papoutsis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00534"
  },
  {
    "id": "arXiv:2211.00537",
    "title": "On the Semi-supervised Expectation Maximization",
    "abstract": "The Expectation Maximization (EM) algorithm is widely used as an iterative\nmodification to maximum likelihood estimation when the data is incomplete. We\nfocus on a semi-supervised case to learn the model from labeled and unlabeled\nsamples. Existing work in the semi-supervised case has focused mainly on\nperformance rather than convergence guarantee, however we focus on the\ncontribution of the labeled samples to the convergence rate. The analysis\nclearly demonstrates how the labeled samples improve the convergence rate for\nthe exponential family mixture model. In this case, we assume that the\npopulation EM (EM with unlimited data) is initialized within the neighborhood\nof global convergence for the population EM that consists solely of samples\nthat have not been labeled. The analysis for the labeled samples provides a\ncomprehensive description of the convergence rate for the Gaussian mixture\nmodel. In addition, we extend the findings for labeled samples and offer an\nalternative proof for the population EM's convergence rate with unlabeled\nsamples for the symmetric mixture of two Gaussians.",
    "descriptor": "\nComments: 7 pages, 0 figures\n",
    "authors": [
      "Erixhen Sula",
      "Lizhong Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.00537"
  },
  {
    "id": "arXiv:2211.00539",
    "title": "Dungeons and Data: A Large-Scale NetHack Dataset",
    "abstract": "Recent breakthroughs in the development of agents to solve challenging\nsequential decision making problems such as Go, StarCraft, or DOTA, have relied\non both simulated environments and large-scale datasets. However, progress on\nthis research has been hindered by the scarcity of open-sourced datasets and\nthe prohibitive computational cost to work with them. Here we present the\nNetHack Learning Dataset (NLD), a large and highly-scalable dataset of\ntrajectories from the popular game of NetHack, which is both extremely\nchallenging for current methods and very fast to run. NLD consists of three\nparts: 10 billion state transitions from 1.5 million human trajectories\ncollected on the NAO public NetHack server from 2009 to 2020; 3 billion\nstate-action-score transitions from 100,000 trajectories collected from the\nsymbolic bot winner of the NetHack Challenge 2021; and, accompanying code for\nusers to record, load and stream any collection of such trajectories in a\nhighly compressed form. We evaluate a wide range of existing algorithms\nincluding online and offline RL, as well as learning from demonstrations,\nshowing that significant research advances are needed to fully leverage\nlarge-scale datasets for challenging sequential decision making tasks.",
    "descriptor": "\nComments: 9 pages, to be published in the Proceedings of the 36th Conference on Neural Information Processing Systems (NeurIPS 2022) Track on Datasets and Benchmarks\n",
    "authors": [
      "Eric Hambro",
      "Roberta Raileanu",
      "Danielle Rothermel",
      "Vegard Mella",
      "Tim Rockt\u00e4schel",
      "Heinrich K\u00fcttler",
      "Naila Murray"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00539"
  },
  {
    "id": "arXiv:2211.00541",
    "title": "Logic-Based Explainability in Machine Learning",
    "abstract": "The last decade witnessed an ever-increasing stream of successes in Machine\nLearning (ML). These successes offer clear evidence that ML is bound to become\npervasive in a wide range of practical uses, including many that directly\naffect humans. Unfortunately, the operation of the most successful ML models is\nincomprehensible for human decision makers. As a result, the use of ML models,\nespecially in high-risk and safety-critical settings is not without concern. In\nrecent years, there have been efforts on devising approaches for explaining ML\nmodels. Most of these efforts have focused on so-called model-agnostic\napproaches. However, all model-agnostic and related approaches offer no\nguarantees of rigor, hence being referred to as non-formal. For example, such\nnon-formal explanations can be consistent with different predictions, which\nrenders them useless in practice. This paper overviews the ongoing research\nefforts on computing rigorous model-based explanations of ML models; these\nbeing referred to as formal explanations. These efforts encompass a variety of\ntopics, that include the actual definitions of explanations, the\ncharacterization of the complexity of computing explanations, the currently\nbest logical encodings for reasoning about different ML models, and also how to\nmake explanations interpretable for human decision makers, among others.",
    "descriptor": "",
    "authors": [
      "Joao Marques-Silva"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00541"
  },
  {
    "id": "arXiv:2211.00543",
    "title": "Geo-Information Harvesting from Social Media Data",
    "abstract": "As unconventional sources of geo-information, massive imagery and text\nmessages from open platforms and social media form a temporally quasi-seamless,\nspatially multi-perspective stream, but with unknown and diverse quality. Due\nto its complementarity to remote sensing data, geo-information from these\nsources offers promising perspectives, but harvesting is not trivial due to its\ndata characteristics. In this article, we address key aspects in the field,\nincluding data availability, analysis-ready data preparation and data\nmanagement, geo-information extraction from social media text messages and\nimages, and the fusion of social media and remote sensing data. We then\nshowcase some exemplary geographic applications. In addition, we present the\nfirst extensive discussion of ethical considerations of social media data in\nthe context of geo-information harvesting and geographic applications. With\nthis effort, we wish to stimulate curiosity and lay the groundwork for\nresearchers who intend to explore social media data for geo-applications. We\nencourage the community to join forces by sharing their code and data.",
    "descriptor": "\nComments: Accepted for publication IEEE Geoscience and Remote Sensing Magazine\n",
    "authors": [
      "Xiao Xiang Zhu",
      "Yuanyuan Wang",
      "Mrinalini Kochupillai",
      "Martin Werner",
      "Matthias H\u00e4berle",
      "Eike Jens Hoffmann",
      "Hannes Taubenb\u00f6ck",
      "Devis Tuia",
      "Alex Levering",
      "Nathan Jacobs",
      "Anna Kruspe",
      "Karam Abdulahhad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00543"
  },
  {
    "id": "arXiv:2211.00549",
    "title": "No-audio speaking status detection in crowded settings via visual  pose-based filtering and wearable acceleration",
    "abstract": "Recognizing who is speaking in a crowded scene is a key challenge towards the\nunderstanding of the social interactions going on within. Detecting speaking\nstatus from body movement alone opens the door for the analysis of social\nscenes in which personal audio is not obtainable. Video and wearable sensors\nmake it possible recognize speaking in an unobtrusive, privacy-preserving way.\nWhen considering the video modality, in action recognition problems, a bounding\nbox is traditionally used to localize and segment out the target subject, to\nthen recognize the action taking place within it. However, cross-contamination,\nocclusion, and the articulated nature of the human body, make this approach\nchallenging in a crowded scene. Here, we leverage articulated body poses for\nsubject localization and in the subsequent speech detection stage. We show that\nthe selection of local features around pose keypoints has a positive effect on\ngeneralization performance while also significantly reducing the number of\nlocal features considered, making for a more efficient method. Using two\nin-the-wild datasets with different viewpoints of subjects, we investigate the\nrole of cross-contamination in this effect. We additionally make use of\nacceleration measured through wearable sensors for the same task, and present a\nmultimodal approach combining both methods.",
    "descriptor": "",
    "authors": [
      "Jose Vargas-Quiros",
      "Laura Cabrera-Quiros",
      "Hayley Hung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00549"
  },
  {
    "id": "arXiv:2211.00550",
    "title": "GLINKX: A Scalable Unified Framework For Homophilous and Heterophilous  Graphs",
    "abstract": "In graph learning, there have been two predominant inductive biases regarding\ngraph-inspired architectures: On the one hand, higher-order interactions and\nmessage passing work well on homophilous graphs and are leveraged by GCNs and\nGATs. Such architectures, however, cannot easily scale to large real-world\ngraphs. On the other hand, shallow (or node-level) models using ego features\nand adjacency embeddings work well in heterophilous graphs. In this work, we\npropose a novel scalable shallow method -- GLINKX -- that can work both on\nhomophilous and heterophilous graphs. GLINKX leverages (i) novel monophilous\nlabel propagations, (ii) ego/node features, (iii) knowledge graph embeddings as\npositional embeddings, (iv) node-level training, and (v) low-dimensional\nmessage passing. Formally, we prove novel error bounds and justify the\ncomponents of GLINKX. Experimentally, we show its effectiveness on several\nhomophilous and heterophilous datasets.",
    "descriptor": "",
    "authors": [
      "Marios Papachristou",
      "Rishab Goel",
      "Frank Portman",
      "Matthew Miller",
      "Rong Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.00550"
  },
  {
    "id": "arXiv:2211.00555",
    "title": "Datasets of Fire and Crime Incidents in Pampanga, Philippines",
    "abstract": "The fire and crime incident datasets were requested and collected from two\nPhilippine regional agencies (i.e., the Bureau of Fire Protection and the\nPhilippine National Police). The datasets were used to initially analyze and\nmap both fire and crime incidents within the province of Pampanga for a\nspecific time frame. Several data preparation, normalization, and data cleaning\nsteps were implemented to properly map and identify patterns within the\ndatasets. The initial results also indicate the leading causes of fire and\ncrimes are rubbish and acts against property. Fires mostly occur during the dry\nseason in the province. Crime is particularly high during December, and most of\nthe fire and crime incidents occur during the time when people are most active.\nThe dataset was able to present the temporal characteristics of the fire and\ncrime incidents that occurred in the province of Pampanga. Merge the existing\ndataset with the other datasets from other related agencies to get a bigger\npicture and produce more objective results that could be used for\ndecision-making.",
    "descriptor": "\nComments: 10 pages, 10 citations, 5 figures, 1 table, journal article, peer-reviewed\n",
    "authors": [
      "John Paul P. Miranda",
      "Julieta M. Umali",
      "Aileen P. de Leon"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.00555"
  },
  {
    "id": "arXiv:2211.00557",
    "title": "True Concurrency Can Be Easy",
    "abstract": "Net bisimilarity is a behavioral equivalence for finite Petri nets, which is\nequivalent to structure-preserving bisimilarity and causal-net bisimilarity,\nbut with a much simpler definition, which is a smooth generalization of the\ndefinition of standard bisimilarity on Labeled Transition Systems. We show that\nit can be characterized logically by means of a suitable modal logic, called\nNML (acronym of net modal logic): two markings are net bisimilar if and only if\nthey satisfy the same NML formulae.",
    "descriptor": "",
    "authors": [
      "Roberto Gorrieri"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.00557"
  },
  {
    "id": "arXiv:2211.00558",
    "title": "Contextual Mixture of Experts: Integrating Knowledge into Predictive  Modeling",
    "abstract": "This work proposes a new data-driven model devised to integrate process\nknowledge into its structure to increase the human-machine synergy in the\nprocess industry. The proposed Contextual Mixture of Experts (cMoE) explicitly\nuses process knowledge along the model learning stage to mold the historical\ndata to represent operators' context related to the process through possibility\ndistributions. This model was evaluated in two real case studies for quality\nprediction, including a sulfur recovery unit and a polymerization process. The\ncontextual mixture of experts was employed to represent different contexts in\nboth experiments. The results indicate that integrating process knowledge has\nincreased predictive performance while improving interpretability by providing\ninsights into the variables affecting the process's different regimes.",
    "descriptor": "",
    "authors": [
      "Francisco Souza",
      "Tim Offermans",
      "Ruud Barendse",
      "Geert Postma",
      "Jeroen Jansen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00558"
  },
  {
    "id": "arXiv:2211.00562",
    "title": "Leveraging commonsense for object localisation in partial scenes",
    "abstract": "We propose an end-to-end solution to address the problem of object\nlocalisation in partial scenes, where we aim to estimate the position of an\nobject in an unknown area given only a partial 3D scan of the scene. We propose\na novel scene representation to facilitate the geometric reasoning, Directed\nSpatial Commonsense Graph (D-SCG), a spatial scene graph that is enriched with\nadditional concept nodes from a commonsense knowledge base. Specifically, the\nnodes of D-SCG represent the scene objects and the edges are their relative\npositions. Each object node is then connected via different commonsense\nrelationships to a set of concept nodes. With the proposed graph-based scene\nrepresentation, we estimate the unknown position of the target object using a\nGraph Neural Network that implements a novel attentional message passing\nmechanism. The network first predicts the relative positions between the target\nobject and each visible object by learning a rich representation of the objects\nvia aggregating both the object nodes and the concept nodes in D-SCG. These\nrelative positions then are merged to obtain the final position. We evaluate\nour method using Partial ScanNet, improving the state-of-the-art by 5.9% in\nterms of the localisation accuracy at a 8x faster training speed.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2203.05380\n",
    "authors": [
      "Francesco Giuliari",
      "Geri Skenderi",
      "Marco Cristani",
      "Alessio Del Bue",
      "Yiming Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00562"
  },
  {
    "id": "arXiv:2211.00565",
    "title": "Revisiting Heterophily in Graph Convolution Networks by Learning  Representations Across Topological and Feature Spaces",
    "abstract": "Graph convolution networks (GCNs) have been enormously successful in learning\nrepresentations over several graph-based machine learning tasks. Specific to\nlearning rich node representations, most of the methods have solely relied on\nthe homophily assumption and have shown limited performance on the\nheterophilous graphs. While several methods have been developed with new\narchitectures to address heterophily, we argue that by learning graph\nrepresentations across two spaces i.e., topology and feature space GCNs can\naddress heterophily. In this work, we experimentally demonstrate the\nperformance of the proposed GCN framework over semi-supervised node\nclassification task on both homophilous and heterophilous graph benchmarks by\nlearning and combining representations across the topological and the feature\nspaces.",
    "descriptor": "\nComments: Submitted to ICASSP 2023 (Under Review) Project Page: this https URL\n",
    "authors": [
      "Ashish Tiwari",
      "Sresth Tosniwal",
      "Shanmuganathan Raman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00565"
  },
  {
    "id": "arXiv:2211.00567",
    "title": "Analysis Without Data: Teaching Students to Tackle the VAST Challenge",
    "abstract": "The VAST Challenges have been shown to be an effective tool in visual\nanalytics education, encouraging student learning while enforcing good\nvisualization design and development practices. However, research has observed\nthat students often struggle at identifying a good \"starting point\" when\ntackling the VAST Challenge. Consequently, students who could not identify a\ngood starting point failed at finding the correct solution to the challenge. In\nthis paper, we propose a preliminary guideline for helping students approach\nthe VAST Challenge and identify initial analysis directions. We recruited two\nstudents to analyze the VAST 2017 Challenge using a hypothesis-driven approach,\nwhere they were required to pre-register their hypotheses prior to inspecting\nand analyzing the full dataset. From their experience, we developed a\nprescriptive guideline for other students to tackle VAST Challenges. In a\npreliminary study, we found that the students were able to use the guideline to\ngenerate well-formed hypotheses that could lead them towards solving the\nchallenge. Additionally, the students reported that with the guideline, they\nfelt like they had concrete steps that they could follow, thereby alleviating\nthe burden of identifying a good starting point in their analysis process.",
    "descriptor": "\nComments: IEEE Workshop on Visualization Guidelines in Research, Design, and Education (VisGuides)\n",
    "authors": [
      "Edward W He",
      "Daniel Tolessa",
      "Ashley Suh",
      "Remco Chang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.00567"
  },
  {
    "id": "arXiv:2211.00568",
    "title": "Consistent Training via Energy-Based GFlowNets for Modeling Discrete  Joint Distributions",
    "abstract": "Generative Flow Networks (GFlowNets) have demonstrated significant\nperformance improvements for generating diverse discrete objects $x$ given a\nreward function $R(x)$, indicating the utility of the object and trained\nindependently from the GFlowNet by supervised learning to predict a desirable\nproperty $y$ given $x$. We hypothesize that this can lead to\n\\textit{incompatibility} between the inductive optimization biases in training\n$R$ and in training the GFlowNet, potentially leading to worse samples and slow\nadaptation to changes in the distribution. In this work, we build upon recent\nwork on jointly learning energy-based models with GFlowNets and extend it to\nlearn the joint over multiple variables, which we call Joint Energy-Based\nGFlowNets (JEBGFNs), such as peptide sequences and their antimicrobial\nactivity. Joint learning of the energy-based model, used as a reward for the\nGFlowNet, can resolve the issues of incompatibility since both the reward\nfunction $R$ and the GFlowNet sampler are trained jointly. We find that this\njoint training or joint energy-based formulation leads to significant\nimprovements in generating anti-microbial peptides. As the training sequences\narose out of evolutionary or artificial selection for high antibiotic activity,\nthere is presumably some structure in the distribution of sequences that\nreveals information about the antibiotic activity. This results in an advantage\nto modeling their joint generatively vs. pure discriminative modeling. We also\nevaluate JEBGFN in an active learning setting for discovering anti-microbial\npeptides.",
    "descriptor": "\nComments: 9 Pages, 10 Figures\n",
    "authors": [
      "Chanakya Ekbote",
      "Moksh Jain",
      "Payel Das",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00568"
  },
  {
    "id": "arXiv:2211.00572",
    "title": "Position-Aware Subgraph Neural Networks with Data-Efficient Learning",
    "abstract": "Data-efficient learning on graphs (GEL) is essential in real-world\napplications. Existing GEL methods focus on learning useful representations for\nnodes, edges, or entire graphs with ``small'' labeled data. But the problem of\ndata-efficient learning for subgraph prediction has not been explored. The\nchallenges of this problem lie in the following aspects: 1) It is crucial for\nsubgraphs to learn positional features to acquire structural information in the\nbase graph in which they exist. Although the existing subgraph neural network\nmethod is capable of learning disentangled position encodings, the overall\ncomputational complexity is very high. 2) Prevailing graph augmentation methods\nfor GEL, including rule-based, sample-based, adaptive, and automated methods,\nare not suitable for augmenting subgraphs because a subgraph contains fewer\nnodes but richer information such as position, neighbor, and structure.\nSubgraph augmentation is more susceptible to undesirable perturbations. 3) Only\na small number of nodes in the base graph are contained in subgraphs, which\nleads to a potential ``bias'' problem that the subgraph representation learning\nis dominated by these ``hot'' nodes. By contrast, the remaining nodes fail to\nbe fully learned, which reduces the generalization ability of subgraph\nrepresentation learning. In this paper, we aim to address the challenges above\nand propose a Position-Aware Data-Efficient Learning framework for subgraph\nneural networks called PADEL. Specifically, we propose a novel node position\nencoding method that is anchor-free, and design a new generative subgraph\naugmentation method based on a diffused variational subgraph autoencoder, and\nwe propose exploratory and exploitable views for subgraph contrastive learning.\nExtensive experiment results on three real-world datasets show the superiority\nof our proposed method over state-of-the-art baselines.",
    "descriptor": "\nComments: 9 pages, 7 figures, accepted by WSDM 23\n",
    "authors": [
      "Chang Liu",
      "Yuwen Yang",
      "Zhe Xie",
      "Hongtao Lu",
      "Yue Ding"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00572"
  },
  {
    "id": "arXiv:2211.00573",
    "title": "On the Analysis and Optimization of Fast Conditional Handover with Hand  Blockage for Mobility",
    "abstract": "Although frequency range 2 (FR2) systems are an essential part of 5G-Advanced\nand future 3GPP releases, the mobility performance of multi-panel user\nequipment (MPUE) with hand blockage is still an area open for research and\nstandardization. In this article, a comprehensive study on the mobility\nperformance of MPUE with hand blockage is performed for conditional handover\n(CHO) and its potential enhancement denoted by fast conditional handover\n(FCHO). In contrast to CHO, MPUEs can reuse in FCHO earlier target cell\npreparations after each handover to autonomously execute subsequent handovers.\nThis saves both the signaling overhead associated with the reconfiguration and\nre-preparation of target cells after each handover and reduces mobility\nfailures. Results have shown that FCHO offers considerable mobility performance\ngain as compared to CHO for different hand blockage cases that are dependent on\nthe hand position around the MPUE. This gain comes at the expense of reserving\nthe handover resources of an MPUE for a longer time given that the target cell\nconfigurations are not necessarily released after each handover. In this\narticle, the longer resource reservation problem in FCHO is analysed and three\ndifferent resource reservation optimization techniques are introduced. Results\nhave shown that these optimization techniques not only reduce the resource\nreservation time but also significantly reduce the signaling overhead at the\npossible expense of a tolerable degradation in mobility performance.",
    "descriptor": "\nComments: Submitted to IEEE Access for possible publication\n",
    "authors": [
      "Subhyal Bin Iqbal",
      "Salman Nadaf",
      "Ahmad Awada",
      "Umur Karabulut",
      "Philipp Schulz",
      "Gerhard P. Fettweis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.00573"
  },
  {
    "id": "arXiv:2211.00575",
    "title": "Text-Only Training for Image Captioning using Noise-Injected CLIP",
    "abstract": "We consider the task of image-captioning using only the CLIP model and\nadditional text data at training time, and no additional captioned images. Our\napproach relies on the fact that CLIP is trained to make visual and textual\nembeddings similar. Therefore, we only need to learn how to translate CLIP\ntextual embeddings back into text, and we can learn how to do this by learning\na decoder for the frozen CLIP text encoder using only text. We argue that this\nintuition is \"almost correct\" because of a gap between the embedding spaces,\nand propose to rectify this via noise injection during training. We demonstrate\nthe effectiveness of our approach by showing SOTA zero-shot image captioning\nacross four benchmarks, including style transfer. Code, data, and models are\navailable on GitHub.",
    "descriptor": "\nComments: Will be presented at EMNLP 2022. GitHub: this https URL\n",
    "authors": [
      "David Nukrai",
      "Ron Mokady",
      "Amir Globerson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00575"
  },
  {
    "id": "arXiv:2211.00576",
    "title": "Event Tables for Efficient Experience Replay",
    "abstract": "Experience replay (ER) is a crucial component of many deep reinforcement\nlearning (RL) systems. However, uniform sampling from an ER buffer can lead to\nslow convergence and unstable asymptotic behaviors. This paper introduces\nStratified Sampling from Event Tables (SSET), which partitions an ER buffer\ninto Event Tables, each capturing important subsequences of optimal behavior.\nWe prove a theoretical advantage over the traditional monolithic buffer\napproach and combine SSET with an existing prioritized sampling strategy to\nfurther improve learning speed and stability. Empirical results in challenging\nMiniGrid domains, benchmark RL environments, and a high-fidelity car racing\nsimulator demonstrate the advantages and versatility of SSET over existing ER\nbuffer sampling approaches.",
    "descriptor": "",
    "authors": [
      "Varun Kompella",
      "Thomas Walsh",
      "Samuel Barrett",
      "Peter Wurman",
      "Peter Stone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00576"
  },
  {
    "id": "arXiv:2211.00582",
    "title": "ClassActionPrediction: A Challenging Benchmark for Legal Judgment  Prediction of Class Action Cases in the US",
    "abstract": "The research field of Legal Natural Language Processing (NLP) has been very\nactive recently, with Legal Judgment Prediction (LJP) becoming one of the most\nextensively studied tasks. To date, most publicly released LJP datasets\noriginate from countries with civil law. In this work, we release, for the\nfirst time, a challenging LJP dataset focused on class action cases in the US.\nIt is the first dataset in the common law system that focuses on the harder and\nmore realistic task involving the complaints as input instead of the often used\nfacts summary written by the court. Additionally, we study the difficulty of\nthe task by collecting expert human predictions, showing that even human\nexperts can only reach 53% accuracy on this dataset. Our Longformer model\nclearly outperforms the human baseline (63%), despite only considering the\nfirst 2,048 tokens. Furthermore, we perform a detailed error analysis and find\nthat the Longformer model is significantly better calibrated than the human\nexperts. Finally, we publicly release the dataset and the code used for the\nexperiments.",
    "descriptor": "",
    "authors": [
      "Gil Semo",
      "Dor Bernsohn",
      "Ben Hagag",
      "Gila Hayat",
      "Joel Niklaus"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.00582"
  },
  {
    "id": "arXiv:2211.00586",
    "title": "T5lephone: Bridging Speech and Text Self-supervised Models for Spoken  Language Understanding via Phoneme level T5",
    "abstract": "In Spoken language understanding (SLU), a natural solution is concatenating\npre-trained speech models (e.g. HuBERT) and pretrained language models (PLM,\ne.g. T5). Most previous works use pretrained language models with subword-based\ntokenization. However, the granularity of input units affects the alignment of\nspeech model outputs and language model inputs, and PLM with character-based\ntokenization is underexplored. In this work, we conduct extensive studies on\nhow PLMs with different tokenization strategies affect spoken language\nunderstanding task including spoken question answering (SQA) and speech\ntranslation (ST). We further extend the idea to create T5lephone(pronounced as\ntelephone), a variant of T5 that is pretrained using phonemicized text. We\ninitialize T5lephone with existing PLMs to pretrain it using relatively\nlightweight computational resources. We reached state-of-the-art on NMSQA, and\nthe T5lephone model exceeds T5 with other types of units on end-to-end SQA and\nST.",
    "descriptor": "",
    "authors": [
      "Chan-Jan Hsu",
      "Ho-Lam Chung",
      "Hung-yi Lee",
      "Yu Tsao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00586"
  },
  {
    "id": "arXiv:2211.00590",
    "title": "Reliability-Aware Deployment of DNNs on In-Memory Analog Computing  Architectures",
    "abstract": "Conventional in-memory computing (IMC) architectures consist of analog\nmemristive crossbars to accelerate matrix-vector multiplication (MVM), and\ndigital functional units to realize nonlinear vector (NLV) operations in deep\nneural networks (DNNs). These designs, however, require energy-hungry signal\nconversion units which can dissipate more than 95% of the total power of the\nsystem. In-Memory Analog Computing (IMAC) circuits, on the other hand, remove\nthe need for signal converters by realizing both MVM and NLV operations in the\nanalog domain leading to significant energy savings. However, they are more\nsusceptible to reliability challenges such as interconnect parasitic and noise.\nHere, we introduce a practical approach to deploy large matrices in DNNs onto\nmultiple smaller IMAC subarrays to alleviate the impacts of noise and\nparasitics while keeping the computation in the analog domain.",
    "descriptor": "",
    "authors": [
      "Md Hasibul Amin",
      "Mohammed Elbtity",
      "Ramtin Zand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2211.00590"
  },
  {
    "id": "arXiv:2211.00593",
    "title": "Interpretability in the Wild: a Circuit for Indirect Object  Identification in GPT-2 small",
    "abstract": "Research in mechanistic interpretability seeks to explain behaviors of\nmachine learning models in terms of their internal components. However, most\nprevious work either focuses on simple behaviors in small models, or describes\ncomplicated behaviors in larger models with broad strokes. In this work, we\nbridge this gap by presenting an explanation for how GPT-2 small performs a\nnatural language task called indirect object identification (IOI). Our\nexplanation encompasses 26 attention heads grouped into 7 main classes, which\nwe discovered using a combination of interpretability approaches relying on\ncausal interventions. To our knowledge, this investigation is the largest\nend-to-end attempt at reverse-engineering a natural behavior \"in the wild\" in a\nlanguage model. We evaluate the reliability of our explanation using three\nquantitative criteria--faithfulness, completeness and minimality. Though these\ncriteria support our explanation, they also point to remaining gaps in our\nunderstanding. Our work provides evidence that a mechanistic understanding of\nlarge ML models is feasible, opening opportunities to scale our understanding\nto both larger models and more complex tasks.",
    "descriptor": "",
    "authors": [
      "Kevin Wang",
      "Alexandre Variengien",
      "Arthur Conmy",
      "Buck Shlegeris",
      "Jacob Steinhardt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.00593"
  },
  {
    "id": "arXiv:2211.00596",
    "title": "Algebra of N-event synchronization",
    "abstract": "We have previously defined synchronization (Gomez, E. and K. Schubert 2011)\nas a relation between the times at which a pair of events can happen, and\nintroduced an algebra that covers all possible relations for such pairs. In\nthis work we introduce the synchronization matrix, to make it easier to\ncalculate the properties and results of $N$ event synchronizations, such as are\ncommonly encountered in parallel execution of multiple processes. The\nsynchronization matrix leads to the definition of N-event synchronization\nalgebras as specific extensions to the original algebra. We derive general\nproperties of such synchronization, and we are able to analyze effects of\nsynchronization on the phase space of parallel execution introduced in (Gomez E\nKai R, Schubert KE 2017)",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Ernesto Gomez",
      "Keith E. Schubert",
      "Khalil Dajani"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.00596"
  },
  {
    "id": "arXiv:2211.00597",
    "title": "Mixed Reality Interface for Digital Twin of Plant Factory",
    "abstract": "An easier and intuitive interface architecture is necessary for digital twin\nof plant factory. I suggest an immersive and interactive mixed reality\ninterface for digital twin models of smart farming, for remote work rather than\nsimulation of components. The environment is constructed with UI display and a\nstreaming background scene, which is a real time scene taken from camera device\nlocated in the plant factory, processed with deformable neural radiance fields.\nUser can monitor and control the remote plant factory facilities with HMD or 2D\ndisplay based mixed reality environment. This paper also introduces detailed\nconcept and describes the system architecture to implement suggested mixed\nreality interface.",
    "descriptor": "\nComments: 5 pages, 7 figures\n",
    "authors": [
      "Byunghyun Ban"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.00597"
  },
  {
    "id": "arXiv:2211.00599",
    "title": "UNFIS: A Novel Neuro-Fuzzy Inference System with Unstructured Fuzzy  Rules for Classification",
    "abstract": "An important constraint of Fuzzy Inference Systems (FIS) is their structured\nrules defined based on evaluating all input variables. Indeed, the length of\nall fuzzy rules and the number of input variables are equal. However, in many\ndecision-making problems evaluating some conditions on a limited set of input\nvariables is sufficient to decide properly (unstructured rules). Therefore,\nthis constraint limits the performance, generalization, and interpretability of\nthe FIS. To address this issue, this paper presents a neuro-fuzzy inference\nsystem for classification applications that can select different sets of input\nvariables for constructing each fuzzy rule. To realize this capability, a new\nfuzzy selector neuron with an adaptive parameter is proposed that can select\ninput variables in the antecedent part of each fuzzy rule. Moreover, in this\npaper, the consequent part of the Takagi-Sugeno-Kang FIS is also changed\nproperly to consider only the selected set of input variables. To learn the\nparameters of the proposed architecture, a trust-region-based learning method\n(General quasi-Levenberg-Marquardt (GqLM)) is proposed to minimize\ncross-entropy in multiclass problems. The performance of the proposed method is\ncompared with some related previous approaches in some real-world\nclassification problems. Based on these comparisons the proposed method has\nbetter or very close performance with a parsimonious structure consisting of\nunstructured fuzzy.",
    "descriptor": "",
    "authors": [
      "Armin Salimi-Badr"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00599"
  },
  {
    "id": "arXiv:2211.00600",
    "title": "Interactive Imitation Learning in Robotics: A Survey",
    "abstract": "Interactive Imitation Learning (IIL) is a branch of Imitation Learning (IL)\nwhere human feedback is provided intermittently during robot execution allowing\nan online improvement of the robot's behavior. In recent years, IIL has\nincreasingly started to carve out its own space as a promising data-driven\nalternative for solving complex robotic tasks. The advantages of IIL are its\ndata-efficient, as the human feedback guides the robot directly towards an\nimproved behavior, and its robustness, as the distribution mismatch between the\nteacher and learner trajectories is minimized by providing feedback directly\nover the learner's trajectories. Nevertheless, despite the opportunities that\nIIL presents, its terminology, structure, and applicability are not clear nor\nunified in the literature, slowing down its development and, therefore, the\nresearch of innovative formulations and discoveries. In this article, we\nattempt to facilitate research in IIL and lower entry barriers for new\npractitioners by providing a survey of the field that unifies and structures\nit. In addition, we aim to raise awareness of its potential, what has been\naccomplished and what are still open research questions. We organize the most\nrelevant works in IIL in terms of human-robot interaction (i.e., types of\nfeedback), interfaces (i.e., means of providing feedback), learning (i.e.,\nmodels learned from feedback and function approximators), user experience\n(i.e., human perception about the learning process), applications, and\nbenchmarks. Furthermore, we analyze similarities and differences between IIL\nand RL, providing a discussion on how the concepts offline, online, off-policy\nand on-policy learning should be transferred to IIL from the RL literature. We\nparticularly focus on robotic applications in the real world and discuss their\nimplications, limitations, and promising future areas of research.",
    "descriptor": "",
    "authors": [
      "Carlos Celemin",
      "Rodrigo P\u00e9rez-Dattari",
      "Eugenio Chisari",
      "Giovanni Franzese",
      "Leandro de Souza Rosa",
      "Ravi Prakash",
      "Zlatan Ajanovi\u0107",
      "Marta Ferraz",
      "Abhinav Valada",
      "Jens Kober"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.00600"
  },
  {
    "id": "arXiv:2211.00607",
    "title": "Magnitude or Phase? A Two Stage Algorithm for Dereverberation",
    "abstract": "In this work we present a new single-microphone speech dereverberation\nalgorithm. First, a performance analysis is presented to interpret that\nalgorithms focused on improving solely magnitude or phase are not good enough.\nFurthermore, we demonstrate that few objective measurements have high\ncorrelation with the clean magnitude while others with the clean phase.\nConsequently ,we propose a new architecture which consists of two sub-models,\neach of which is responsible for a different task. The first model estimates\nthe clean magnitude given the noisy input. The enhanced magnitude together with\nthe noisy-input phase are then used as inputs to the second model to estimate\nthe real and imaginary portions of the dereverberated signal. A training scheme\nincluding pre-training and fine-tuning is presented in the paper. We evaluate\nour proposed approach using data from the REVERB challenge and compare our\nresults to other methods. We demonstrate consistent improvements in all\nmeasures, which can be attributed to the improved estimates of both the\nmagnitude and the phase.",
    "descriptor": "",
    "authors": [
      "Ayal Schwartz",
      "Sharon Gannot",
      "Shlomo E. Chazan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00607"
  },
  {
    "id": "arXiv:2211.00608",
    "title": "ReachLipBnB: A branch-and-bound method for reachability analysis of  neural autonomous systems using Lipschitz bounds",
    "abstract": "We propose a novel Branch-and-Bound method for reachability analysis of\nneural networks in both open-loop and closed-loop settings. Our idea is to\nfirst compute accurate bounds on the Lipschitz constant of the neural network\nin certain directions of interest offline using a convex program. We then use\nthese bounds to obtain an instantaneous but conservative polyhedral\napproximation of the reachable set using Lipschitz continuity arguments. To\nreduce conservatism, we incorporate our bounding algorithm within a branching\nstrategy to decrease the over-approximation error within an arbitrary accuracy.\nWe then extend our method to reachability analysis of control systems with\nneural network controllers. Finally, to capture the shape of the reachable sets\nas accurately as possible, we use sample trajectories to inform the directions\nof the reachable set over-approximations using Principal Component Analysis\n(PCA). We evaluate the performance of the proposed method in several open-loop\nand closed-loop settings.",
    "descriptor": "",
    "authors": [
      "Taha Entesari",
      "Sina Sharifi",
      "Mahyar Fazlyab"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.00608"
  },
  {
    "id": "arXiv:2211.00609",
    "title": "A Simple, Yet Effective Approach to Finding Biases in Code Generation",
    "abstract": "Recently, scores of high-performing code generation systems have surfaced. As\nhas become a popular choice in many domains, code generation is often\napproached using large language models as a core, trained under the masked or\ncausal language modeling schema. This work shows that current code generation\nsystems exhibit biases inherited from large language model backbones, which\nmight leak into generated code under specific circumstances.\nTo investigate the effect, we propose a framework that automatically removes\nhints and exposes various biases that these code generation models use. We\napply our framework to three coding challenges and test it across\ntop-performing coding generation models. Our experiments reveal biases towards\nspecific prompt structure and exploitation of keywords during code generation.\nFinally, we demonstrate how to use our framework as a data transformation\ntechnique, which we find a promising direction toward more robust code\ngeneration.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Spyridon Mouselinos",
      "Mateusz Malinowski",
      "Henryk Michalewski"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.00609"
  },
  {
    "id": "arXiv:2211.00610",
    "title": "Fast Staircase Detection and Estimation using 3D Point Clouds with  Multi-detection Merging for Heterogeneous Robots",
    "abstract": "Robotic systems need advanced mobility capabilities to operate in complex,\nthree-dimensional environments designed for human use, e.g., multi-level\nbuildings. Incorporating some level of autonomy enables robots to operate\nrobustly, reliably, and efficiently in such complex environments, e.g.,\nautomatically ``returning home'' if communication between an operator and robot\nis lost during deployment. This work presents a novel method that enables\nmobile robots to robustly operate in multi-level environments by making it\npossible to autonomously locate and climb a range of different staircases. We\npresent results wherein a wheeled robot works together with a quadrupedal\nsystem to quickly detect different staircases and reliably climb them. The\nperformance of this novel staircase detection algorithm that is able to run on\nthe heterogeneous platforms is compared to the current state-of-the-art\ndetection algorithm. We show that our approach significantly increases the\naccuracy and speed at which detections occur.",
    "descriptor": "\nComments: 7 pages, 8 Figures, 2 Tables\n",
    "authors": [
      "Prasanna Sriganesh",
      "Namya Bagree",
      "Bhaskar Vundurthy",
      "Matthew Travers"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.00610"
  },
  {
    "id": "arXiv:2211.00611",
    "title": "MedSegDiff: Medical Image Segmentation with Diffusion Probabilistic  Model",
    "abstract": "Diffusion probabilistic model (DPM) recently becomes one of the hottest topic\nin computer vision. Its image generation application such as Imagen, Latent\nDiffusion Models and Stable Diffusion have shown impressive generation\ncapabilities, which aroused extensive discussion in the community. Many recent\nstudies also found it useful in many other vision tasks, like image deblurring,\nsuper-resolution and anomaly detection. Inspired by the success of DPM, we\npropose the first DPM based model toward general medical image segmentation\ntasks, which we named MedSegDiff. In order to enhance the step-wise regional\nattention in DPM for the medical image segmentation, we propose dynamic\nconditional encoding, which establishes the state-adaptive conditions for each\nsampling step. We further propose Feature Frequency Parser (FF-Parser), to\neliminate the negative effect of high-frequency noise component in this\nprocess. We verify MedSegDiff on three medical segmentation tasks with\ndifferent image modalities, which are optic cup segmentation over fundus\nimages, brain tumor segmentation over MRI images and thyroid nodule\nsegmentation over ultrasound images. The experimental results show that\nMedSegDiff outperforms state-of-the-art (SOTA) methods with considerable\nperformance gap, indicating the generalization and effectiveness of the\nproposed model.",
    "descriptor": "",
    "authors": [
      "Junde Wu",
      "Huihui Fang",
      "Yu Zhang",
      "Yehui Yang",
      "Yanwu Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00611"
  },
  {
    "id": "arXiv:2211.00614",
    "title": "Natural Language Deduction with Incomplete Information",
    "abstract": "A growing body of work studies how to answer a question or verify a claim by\ngenerating a natural language \"proof\": a chain of deductive inferences yielding\nthe answer based on a set of premises. However, these methods can only make\nsound deductions when they follow from evidence that is given. We propose a new\nsystem that can handle the underspecified setting where not all premises are\nstated at the outset; that is, additional assumptions need to be materialized\nto prove a claim. By using a natural language generation model to abductively\ninfer a premise given another premise and a conclusion, we can impute missing\npieces of evidence needed for the conclusion to be true. Our system searches\nover two fringes in a bidirectional fashion, interleaving deductive\n(forward-chaining) and abductive (backward-chaining) generation steps. We\nsample multiple possible outputs for each step to achieve coverage of the\nsearch space, at the same time ensuring correctness by filtering low-quality\ngenerations with a round-trip validation procedure. Results on a modified\nversion of the EntailmentBank dataset and a new dataset called Everyday Norms:\nWhy Not? show that abductive generation with validation can recover premises\nacross in- and out-of-domain settings.",
    "descriptor": "\nComments: Conference of EMNLP 2022\n",
    "authors": [
      "Zayne Sprague",
      "Kaj Bostrom",
      "Swarat Chaudhuri",
      "Greg Durrett"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.00614"
  },
  {
    "id": "arXiv:2211.00618",
    "title": "Optimal Covariance Steering for Discrete-Time Linear Stochastic Systems",
    "abstract": "In this paper we study the optimal control for steering the state covariance\nof a discrete-time linear stochastic system over a finite time horizon. First,\nwe establish the existence and uniqueness of the optimal control law for a\nquadratic cost function. Then, we develop efficient computational methods for\nsolving for the optimal control law, which is identified as the solution to a\nsemi-definite program. During the analysis, we also obtain some useful results\non a matrix Riccati difference equation, which may be of independent interest.",
    "descriptor": "",
    "authors": [
      "Fengjiao Liu",
      "George Rapakoulias",
      "Panagiotis Tsiotras"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.00618"
  },
  {
    "id": "arXiv:2211.00619",
    "title": "Asymmetric Hashing for Fast Ranking via Neural Network Measures",
    "abstract": "Fast item ranking is an important task in recommender systems. In previous\nworks, graph-based Approximate Nearest Neighbor (ANN) approaches have\ndemonstrated good performance on item ranking tasks with generic\nsearching/matching measures (including complex measures such as neural network\nmeasures). However, since these ANN approaches must go through the neural\nmeasures several times during ranking, the computation is not practical if the\nneural measure is a large network. On the other hand, fast item ranking using\nexisting hashing-based approaches, such as Locality Sensitive Hashing (LSH),\nonly works with a limited set of measures. Previous learning-to-hash approaches\nare also not suitable to solve the fast item ranking problem since they can\ntake a significant amount of time and computation to train the hash functions.\nHashing approaches, however, are attractive because they provide a principle\nand efficient way to retrieve candidate items. In this paper, we propose a\nsimple and effective learning-to-hash approach for the fast item ranking\nproblem that can be used for any type of measure, including neural network\nmeasures. Specifically, we solve this problem with an asymmetric hashing\nframework based on discrete inner product fitting. We learn a pair of related\nhash functions that map heterogeneous objects (e.g., users and items) into a\ncommon discrete space where the inner product of their binary codes reveals\ntheir true similarity defined via the original searching measure. The fast\nranking problem is reduced to an ANN search via this asymmetric hashing scheme.\nThen, we propose a sampling strategy to efficiently select relevant and\ncontrastive samples to train the hashing model. We empirically validate the\nproposed method against the existing state-of-the-art fast item ranking methods\nin several combinations of non-linear searching functions and prominent\ndatasets.",
    "descriptor": "",
    "authors": [
      "Khoa Doan",
      "Shulong Tan",
      "Weijie Zhao",
      "Ping Li"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.00619"
  },
  {
    "id": "arXiv:2211.00621",
    "title": "Expression Acceleration: Seamless Parallelization of Typed High-Level  Languages",
    "abstract": "Efficient parallelization of algorithms on general-purpose GPUs is today\nessential in many areas. However, it is a non-trivial task for software\nengineers to utilize GPUs to improve the performance of high-level programs in\ngeneral. Although many domain-specific approaches are available for GPU\nacceleration, it is difficult to accelerate existing high-level programs\nwithout rewriting parts of the programs using low-level GPU code. In this\npaper, we propose a different approach, where expressions are marked for\nacceleration, and the compiler automatically infers which code needs to be\naccelerated. We call this approach expression acceleration. We design a\ncompiler pipeline for the approach and show how to handle several challenges,\nincluding expression extraction, well-formedness, and compiling using multiple\nbackends. The approach is designed and implemented within a statically-typed\nfunctional intermediate language and evaluated using three distinct non-trivial\ncase studies.",
    "descriptor": "",
    "authors": [
      "Lars Hummelgren",
      "John Wikman",
      "Oscar Eriksson",
      "Philipp Haller",
      "David Broman"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.00621"
  },
  {
    "id": "arXiv:2211.00631",
    "title": "Composite Feature Selection using Deep Ensembles",
    "abstract": "In many real world problems, features do not act alone but in combination\nwith each other. For example, in genomics, diseases might not be caused by any\nsingle mutation but require the presence of multiple mutations. Prior work on\nfeature selection either seeks to identify individual features or can only\ndetermine relevant groups from a predefined set. We investigate the problem of\ndiscovering groups of predictive features without predefined grouping. To do\nso, we define predictive groups in terms of linear and non-linear interactions\nbetween features. We introduce a novel deep learning architecture that uses an\nensemble of feature selection models to find predictive groups, without\nrequiring candidate groups to be provided. The selected groups are sparse and\nexhibit minimum overlap. Furthermore, we propose a new metric to measure\nsimilarity between discovered groups and the ground truth. We demonstrate the\nutility of our model on multiple synthetic tasks and semi-synthetic chemistry\ndatasets, where the ground truth structure is known, as well as an image\ndataset and a real-world cancer dataset.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Fergus Imrie",
      "Alexander Norcliffe",
      "Pietro Lio",
      "Mihaela van der Schaar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00631"
  },
  {
    "id": "arXiv:2211.00635",
    "title": "Preserving In-Context Learning ability in Large Language Model  Fine-tuning",
    "abstract": "Pretrained large language models (LLMs) are strong in-context learners that\nare able to perform few-shot learning without changing model parameters.\nHowever, as we show, fine-tuning an LLM on any specific task generally destroys\nits in-context ability. We discover an important cause of this loss, format\nspecialization, where the model overfits to the format of the fine-tuned task\nand is unable to output anything beyond this format. We further show that\nformat specialization happens at the beginning of fine-tuning. To solve this\nproblem, we propose Prompt Tuning with MOdel Tuning (ProMoT), a simple yet\neffective two-stage fine-tuning framework that preserves in-context abilities\nof the pretrained model. ProMoT first trains a soft prompt for the fine-tuning\ntarget task, and then fine-tunes the model itself with this soft prompt\nattached. ProMoT offloads task-specific formats into the soft prompt that can\nbe removed when doing other in-context tasks. We fine-tune mT5 XXL with ProMoT\non natural language inference (NLI) and English-French translation and evaluate\nthe in-context abilities of the resulting models on 8 different NLP tasks.\nProMoT achieves similar performance on the fine-tuned tasks compared with\nvanilla fine-tuning, but with much less reduction of in-context learning\nperformances across the board. More importantly, ProMoT shows remarkable\ngeneralization ability on tasks that have different formats, e.g. fine-tuning\non a NLI binary classification task improves the model's in-context ability to\ndo summarization (+0.53 Rouge-2 score compared to the pretrained model), making\nProMoT a promising method to build general purpose capabilities such as\ngrounding and reasoning into LLMs with small but high quality datasets. When\nextended to sequential or multi-task training, ProMoT can achieve even better\nout-of-domain generalization performance.",
    "descriptor": "",
    "authors": [
      "Yihan Wang",
      "Si Si",
      "Daliang Li",
      "Michal Lukasik",
      "Felix Yu",
      "Cho-Jui Hsieh",
      "Inderjit S Dhillon",
      "Sanjiv Kumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00635"
  },
  {
    "id": "arXiv:2211.00639",
    "title": "A General Language for Modeling Social Media Account Behavior",
    "abstract": "Malicious actors exploit social media to inflate stock prices, sway\nelections, spread misinformation, and sow discord. To these ends, they employ\ntactics that include the use of inauthentic accounts and campaigns. Methods to\ndetect these abuses currently rely on features specifically designed to target\nsuspicious behaviors. However, the effectiveness of these methods decays as\nmalicious behaviors evolve. To address this challenge, we propose a general\nlanguage for modeling social media account behavior. Words in this language,\ncalled BLOC, consist of symbols drawn from distinct alphabets representing user\nactions and content. The language is highly flexible and can be applied to\nmodel a broad spectrum of legitimate and suspicious online behaviors without\nextensive fine-tuning. Using BLOC to represent the behaviors of Twitter\naccounts, we achieve performance comparable to or better than state-of-the-art\nmethods in the detection of social bots and coordinated inauthentic behavior.",
    "descriptor": "",
    "authors": [
      "Alexander C. Nwala",
      "Alessandro Flammini",
      "Filippo Menczer"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.00639"
  },
  {
    "id": "arXiv:2201.11147",
    "title": "OntoProtein: Protein Pretraining With Gene Ontology Embedding",
    "abstract": "Self-supervised protein language models have proved their effectiveness in\nlearning the proteins representations. With the increasing computational power,\ncurrent protein language models pre-trained with millions of diverse sequences\ncan advance the parameter scale from million-level to billion-level and achieve\nremarkable improvement. However, those prevailing approaches rarely consider\nincorporating knowledge graphs (KGs), which can provide rich structured\nknowledge facts for better protein representations. We argue that informative\nbiology knowledge in KGs can enhance protein representation with external\nknowledge. In this work, we propose OntoProtein, the first general framework\nthat makes use of structure in GO (Gene Ontology) into protein pre-training\nmodels. We construct a novel large-scale knowledge graph that consists of GO\nand its related proteins, and gene annotation texts or protein sequences\ndescribe all nodes in the graph. We propose novel contrastive learning with\nknowledge-aware negative sampling to jointly optimize the knowledge graph and\nprotein embedding during pre-training. Experimental results show that\nOntoProtein can surpass state-of-the-art methods with pre-trained protein\nlanguage models in TAPE benchmark and yield better performance compared with\nbaselines in protein-protein interaction and protein function prediction. Code\nand datasets are available in https://github.com/zjunlp/OntoProtein.",
    "descriptor": "\nComments: Accepted by ICLR 2022\n",
    "authors": [
      "Ningyu Zhang",
      "Zhen Bi",
      "Xiaozhuan Liang",
      "Siyuan Cheng",
      "Haosen Hong",
      "Shumin Deng",
      "Jiazhang Lian",
      "Qiang Zhang",
      "Huajun Chen"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11147"
  },
  {
    "id": "arXiv:2207.10080",
    "title": "Multi-modal Protein Knowledge Graph Construction and Applications",
    "abstract": "Existing data-centric methods for protein science generally cannot\nsufficiently capture and leverage biology knowledge, which may be crucial for\nmany protein tasks. To facilitate research in this field, we create\nProteinKG65, a knowledge graph for protein science. Using gene ontology and\nUniprot knowledge base as a basis, we transform and integrate various kinds of\nknowledge with aligned descriptions and protein sequences, respectively, to GO\nterms and protein entities. ProteinKG65 is mainly dedicated to providing a\nspecialized protein knowledge graph, bringing the knowledge of Gene Ontology to\nprotein function and structure prediction. The current version contains about\n614,099 entities, 5,620,437 triples (including 5,510,437 protein-go triplets\nand 110,000 GO-GO triplets). We also illustrate the potential applications of\nProteinKG65 with a prototype. Our dataset can be downloaded at\nhttps://w3id.org/proteinkg65.",
    "descriptor": "\nComments: Work in progress. Dataset available in this https URL\n",
    "authors": [
      "Siyuan Cheng",
      "Xiaozhuan Liang",
      "Zhen Bi",
      "Huajun Chen",
      "Ningyu Zhang"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.10080"
  },
  {
    "id": "arXiv:2210.16988",
    "title": "Data Bricks Space Mission: Teaching Kids about Data with Physicalization",
    "abstract": "The Data Bricks Space Mission is a prototype activity based on data\nphysicalization for teaching kids about data. The design of the activity is\nbased on a literature review and interviews with elementary school teachers,\nand targets kids aged 10-12. Using Lego bricks and a fictional space adventure\nstory, teachers can use the Data Bricks Space Mission activity to empower kids\nto produce data, communicate their findings, and gain a better understanding of\nthe relationship between data and the world around them.",
    "descriptor": "",
    "authors": [
      "Lorenzo Ambrosini",
      "Miriah Meyer"
    ],
    "subjectives": [
      "Physics Education (physics.ed-ph)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.16988"
  },
  {
    "id": "arXiv:2211.00003",
    "title": "MEDS-Net: Self-Distilled Multi-Encoders Network with Bi-Direction  Maximum Intensity projections for Lung Nodule Detection",
    "abstract": "In this study, we propose a lung nodule detection scheme which fully\nincorporates the clinic workflow of radiologists. Particularly, we exploit\nBi-Directional Maximum intensity projection (MIP) images of various thicknesses\n(i.e., 3, 5 and 10mm) along with a 3D patch of CT scan, consisting of 10\nadjacent slices to feed into self-distillation-based Multi-Encoders Network\n(MEDS-Net). The proposed architecture first condenses 3D patch input to three\nchannels by using a dense block which consists of dense units which effectively\nexamine the nodule presence from 2D axial slices. This condensed information,\nalong with the forward and backward MIP images, is fed to three different\nencoders to learn the most meaningful representation, which is forwarded into\nthe decoded block at various levels. At the decoder block, we employ a\nself-distillation mechanism by connecting the distillation block, which\ncontains five lung nodule detectors. It helps to expedite the convergence and\nimproves the learning ability of the proposed architecture. Finally, the\nproposed scheme reduces the false positives by complementing the main detector\nwith auxiliary detectors. The proposed scheme has been rigorously evaluated on\n888 scans of LUNA16 dataset and obtained a CPM score of 93.6\\%. The results\ndemonstrate that incorporating of bi-direction MIP images enables MEDS-Net to\neffectively distinguish nodules from surroundings which help to achieve the\nsensitivity of 91.5% and 92.8% with false positives rate of 0.25 and 0.5 per\nscan, respectively.",
    "descriptor": "",
    "authors": [
      "Muhammad Usman",
      "Azka Rehman",
      "Abdullah Shahid",
      "Siddique Latif",
      "Shi Sub Byon",
      "Byoung Dai Lee",
      "Sung Hyun Kim",
      "Byung il Lee",
      "Yeong Gil Shin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00003"
  },
  {
    "id": "arXiv:2211.00004",
    "title": "Classical ensemble of Quantum-classical ML algorithms for Phishing  detection in Ethereum transaction networks",
    "abstract": "Ethereum is one of the most valuable blockchain networks in terms of the\ntotal monetary value locked in it, and arguably been the most active network\nwhere new blockchain innovations in research and applications are demonstrated.\nBut, this also leads to Ethereum network being susceptible to a wide variety of\nthreats and attacks in an attempt to gain unreasonable advantage or to\nundermine the value of the users. Even with the state-of-art classical ML\nalgorithms, detecting such attacks is still hard. This motivated us to build a\nhybrid system of quantum-classical algorithms that improves phishing detection\nin financial transaction networks. This paper presents a classical ensemble\npipeline of classical and quantum algorithms and a detailed study benchmarking\nexisting Quantum Machine Learning algorithms such as Quantum Support Vector\nMachine and Variational Quantum Classifier. With the current generation of\nquantum hardware available, smaller datasets are more suited to the QML models\nand most research restricts to hundreds of samples. However, we experimented on\ndifferent data sizes and report results with a test data of 12K transaction\nnodes, which is to the best of the authors knowledge the largest QML experiment\nrun so far on any real quantum hardware. The classical ensembles of\nquantum-classical models improved the macro F-score and phishing F-score. One\nkey observation is QSVM constantly gives lower false positives, thereby higher\nprecision compared with any other classical or quantum network, which is always\npreferred for any anomaly detection problem. This is true for QSVMs when used\nindividually or via bagging of same models or in combination with other\nclassical/quantum models making it the most advantageous quantum algorithm so\nfar. The proposed ensemble framework is generic and can be applied for any\nclassification task",
    "descriptor": "",
    "authors": [
      "Anupama Ray",
      "Sai Sakunthala Guddanti",
      "Vishnu Ajith",
      "Dhinakaran Vinayagamurthy"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00004"
  },
  {
    "id": "arXiv:2211.00024",
    "title": "A robust estimator of mutual information for deep learning  interpretability",
    "abstract": "We develop the use of mutual information (MI), a well-established metric in\ninformation theory, to interpret the inner workings of deep learning models. To\naccurately estimate MI from a finite number of samples, we present GMM-MI\n(pronounced $``$Jimmie$\"$), an algorithm based on Gaussian mixture models that\ncan be applied to both discrete and continuous settings. GMM-MI is\ncomputationally efficient, robust to the choice of hyperparameters and provides\nthe uncertainty on the MI estimate due to the finite sample size. We\nextensively validate GMM-MI on toy data for which the ground truth MI is known,\ncomparing its performance against established mutual information estimators. We\nthen demonstrate the use of our MI estimator in the context of representation\nlearning, working with synthetic data and physical datasets describing highly\nnon-linear processes. We train deep learning models to encode high-dimensional\ndata within a meaningful compressed (latent) representation, and use GMM-MI to\nquantify both the level of disentanglement between the latent variables, and\ntheir association with relevant physical quantities, thus unlocking the\ninterpretability of the latent representation. We make GMM-MI publicly\navailable.",
    "descriptor": "\nComments: 13 pages, 7 figures, comments welcome. GMM-MI available at this https URL\n",
    "authors": [
      "Davide Piras",
      "Hiranya V. Peiris",
      "Andrew Pontzen",
      "Luisa Lucie-Smith",
      "Ningyuan Guo",
      "Brian Nord"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00024"
  },
  {
    "id": "arXiv:2211.00027",
    "title": "Global high-order numerical schemes for the time evolution of the  general relativistic radiation magneto-hydrodynamics equations",
    "abstract": "Modeling correctly the transport of neutrinos is crucial in some\nastrophysical scenarios such as core-collapse supernovae and binary neutron\nstar mergers. In this paper, we focus on the truncated-moment formalism,\nconsidering only the first two moments (M1 scheme) within the grey\napproximation, which reduces Boltzmann seven-dimensional equation to a system\nof $3+1$ equations closely resembling the hydrodynamic ones. Solving the M1\nscheme is still mathematically challenging, since it is necessary to model the\nradiation-matter interaction in regimes where the evolution equations become\nstiff and behave as an advection-diffusion problem. Here, we present different\nglobal, high-order time integration schemes based on Implicit-Explicit\nRunge-Kutta (IMEX) methods designed to overcome the time-step restriction\ncaused by such behavior while allowing us to use the explicit RK commonly\nemployed for the MHD and Einstein equations. Finally, we analyze their\nperformance in several numerical tests.",
    "descriptor": "\nComments: 22 pages, 11 figures\n",
    "authors": [
      "Manuel R. Izquierdo",
      "Lorenzo Pareschi",
      "Borja Mi\u00f1ano",
      "Joan Mass\u00f3",
      "Carlos Palenzuela"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.00027"
  },
  {
    "id": "arXiv:2211.00054",
    "title": "The interaction of transmission intensity, mortality, and the economy: a  retrospective analysis of the COVID-19 pandemic",
    "abstract": "The COVID-19 pandemic has caused over 6.4 million registered deaths to date,\nand has had a profound impact on economic activity. Here, we study the\ninteraction of transmission, mortality, and the economy during the SARS-CoV-2\npandemic from January 2020 to December 2022 across 25 European countries. We\nadopt a Bayesian vector autoregressive model with both fixed and random\neffects. We find that increases in disease transmission intensity decreases\nGross domestic product (GDP) and increases daily excess deaths, with a longer\nlasting impact on excess deaths in comparison to GDP, which recovers more\nrapidly. Broadly, our results reinforce the intuitive phenomenon that\nsignificant economic activity arises from diverse person-to-person\ninteractions. We report on the effectiveness of non-pharmaceutical\ninterventions (NPIs) on transmission intensity, excess deaths and changes in\nGDP, and resulting implications for policy makers. Our results highlight a\ncomplex cost-benefit trade off from individual NPIs. For example, banning\ninternational travel increases GDP however reduces excess deaths. We consider\ncountry random effects and their associations with excess changes in GDP and\nexcess deaths. For example, more developed countries in Europe typically had\nmore cautious approaches to the COVID-19 pandemic, prioritising healthcare and\nexcess deaths over economic performance. Long term economic impairments are not\nfully captured by our model, as well as long term disease effects (Long Covid).\nOur results highlight that the impact of disease on a country is complex and\nmultifaceted, and simple heuristic conclusions to extract the best outcome from\nthe economy and disease burden are challenging.",
    "descriptor": "",
    "authors": [
      "Christian Morgenstern",
      "Daniel J. Laydon",
      "Charles Whittaker",
      "Swapnil Mishra",
      "David Haw",
      "Samir Bhatt",
      "Neil M. Ferguson"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2211.00054"
  },
  {
    "id": "arXiv:2211.00089",
    "title": "An analysis of degenerating speech due to progressive dysarthria on ASR  performance",
    "abstract": "Although personalized automatic speech recognition (ASR) models have recently\nbeen designed to recognize even severely impaired speech, model performance may\ndegrade over time for persons with degenerating speech. The aims of this study\nwere to (1) analyze the change of performance of ASR over time in individuals\nwith degrading speech, and (2) explore mitigation strategies to optimize\nrecognition throughout disease progression. Speech was recorded by four\nindividuals with degrading speech due to amyotrophic lateral sclerosis (ALS).\nWord error rates (WER) across recording sessions were computed for three ASR\nmodels: Unadapted Speaker Independent (U-SI), Adapted Speaker Independent\n(A-SI), and Adapted Speaker Dependent (A-SD or personalized). The performance\nof all three models degraded significantly over time as speech became more\nimpaired, but the performance of the A-SD model improved markedly when it was\nupdated with recordings from the severe stages of speech progression. Recording\nadditional utterances early in the disease before speech degraded significantly\ndid not improve the performance of A-SD models. Overall, our findings emphasize\nthe importance of continuous recording (and model retraining) when providing\npersonalized models for individuals with progressive speech impairments.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Katrin Tomanek",
      "Katie Seaver",
      "Pan-Pan Jiang",
      "Richard Cave",
      "Lauren Harrel",
      "Jordan R. Green"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.00089"
  },
  {
    "id": "arXiv:2211.00100",
    "title": "Federated Averaging Langevin Dynamics: Toward a unified theory and new  algorithms",
    "abstract": "This paper focuses on Bayesian inference in a federated learning context\n(FL). While several distributed MCMC algorithms have been proposed, few\nconsider the specific limitations of FL such as communication bottlenecks and\nstatistical heterogeneity. Recently, Federated Averaging Langevin Dynamics\n(FALD) was introduced, which extends the Federated Averaging algorithm to\nBayesian inference. We obtain a novel tight non-asymptotic upper bound on the\nWasserstein distance to the global posterior for FALD. This bound highlights\nthe effects of statistical heterogeneity, which causes a drift in the local\nupdates that negatively impacts convergence. We propose a new algorithm\nVR-FALD* that uses control variates to correct the client drift. We establish\nnon-asymptotic bounds showing that VR-FALD* is not affected by statistical\nheterogeneity. Finally, we illustrate our results on several FL benchmarks for\nBayesian inference.",
    "descriptor": "\nComments: 58 pages\n",
    "authors": [
      "Vincent Plassier",
      "Alain Durmus",
      "Eric Moulines"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00100"
  },
  {
    "id": "arXiv:2211.00109",
    "title": "ImagineNET: Target Speaker Extraction with Intermittent Visual Cue  through Embedding Inpainting",
    "abstract": "The speaker extraction technique seeks to single out the voice of a target\nspeaker from the interfering voices in a speech mixture. Typically an auxiliary\nreference of the target speaker is used to form voluntary attention. Either a\npre-recorded utterance or a synchronized lip movement in a video clip can serve\nas the auxiliary reference. The use of visual cue is not only feasible, but\nalso effective due to its noise robustness, and becoming popular. However, it\nis difficult to guarantee that such parallel visual cue is always available in\nreal-world applications where visual occlusion or intermittent communication\ncan occur. In this paper, we study the audio-visual speaker extraction\nalgorithms with intermittent visual cue. We propose a joint speaker extraction\nand visual embedding inpainting framework to explore the mutual benefits. To\nencourage the interaction between the two tasks, they are performed alternately\nwith an interlacing structure and optimized jointly. We also propose two types\nof visual inpainting losses and study our proposed method with two types of\npopularly used visual embeddings. The experimental results show that we\noutperform the baseline in terms of signal quality, perceptual quality, and\nintelligibility.",
    "descriptor": "",
    "authors": [
      "Zexu Pan",
      "Wupeng Wang",
      "Marvin Borsdorf",
      "Haizhou Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.00109"
  },
  {
    "id": "arXiv:2211.00128",
    "title": "SIMPLE-RC: Group Network Inference with Non-Sharp Nulls and Weak Signals",
    "abstract": "Large-scale network inference with uncertainty quantification has important\napplications in natural, social, and medical sciences. The recent work of Fan,\nFan, Han and Lv (2022) introduced a general framework of statistical inference\non membership profiles in large networks (SIMPLE) for testing the sharp null\nhypothesis that a pair of given nodes share the same membership profiles. In\nreal applications, there are often groups of nodes under investigation that may\nshare similar membership profiles at the presence of relatively weaker signals\nthan the setting considered in SIMPLE. To address these practical challenges,\nin this paper we propose a SIMPLE method with random coupling (SIMPLE-RC) for\ntesting the non-sharp null hypothesis that a group of given nodes share similar\n(not necessarily identical) membership profiles under weaker signals. Utilizing\nthe idea of random coupling, we construct our test as the maximum of the SIMPLE\ntests for subsampled node pairs from the group. Such technique reduces\nsignificantly the correlation among individual SIMPLE tests while largely\nmaintaining the power, enabling delicate analysis on the asymptotic\ndistributions of the SIMPLE-RC test. Our method and theory cover both the cases\nwith and without node degree heterogeneity. These new theoretical developments\nare empowered by a second-order expansion of spiked eigenvectors under the\n$\\ell_\\infty$-norm, built upon our work for random matrices with weak spikes.\nOur theoretical results and the practical advantages of the newly suggested\nmethod are demonstrated through several simulation and real data examples.",
    "descriptor": "\nComments: 71 pages, 4 figures\n",
    "authors": [
      "Jianqing Fan",
      "Yingying Fan",
      "Jinchi Lv",
      "Fan Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.00128"
  },
  {
    "id": "arXiv:2211.00169",
    "title": "SIS Epidemic Spreading under Multi-layer Population Dispersal in Patchy  Environments",
    "abstract": "We study SIS epidemic spreading models under population dispersal on\nmulti-layer networks. We consider a patchy environment in which each patch\ncomprises individuals belonging to different classes. Individuals disperse to\nother patches on a multi-layer network in which each layer corresponds to a\nclass. The dispersal on each layer is modeled by a Continuous Time Markov Chain\n(CTMC). At each time, individuals disperse according to their CTMC and\nsubsequently interact with the local individuals in the patch according to an\nSIS model. We establish the existence of various equilibria under different\nparameter regimes and establish their (almost) global asymptotic stability\nusing Lyapunov techniques. We also derive simple conditions that highlight the\ninfluence of the multi-layer network on the stability of these equilibria. For\nthis model, we study optimal intervention strategies using a convex\noptimization framework. Finally, we numerically illustrate the influence of the\nmulti-layer network structure and the effectiveness of the optimal intervention\nstrategies.",
    "descriptor": "\nComments: Extended version of a journal paper under review. arXiv admin note: substantial text overlap with arXiv:2003.06341, arXiv:1909.02647\n",
    "authors": [
      "Vishal Abhishek",
      "Vaibhav Srivastava"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2211.00169"
  },
  {
    "id": "arXiv:2211.00172",
    "title": "Infusing known operators in convolutional neural networks for lateral  strain imaging in ultrasound elastography",
    "abstract": "Convolutional Neural Networks (CNN) have been employed for displacement\nestimation in ultrasound elastography (USE). High-quality axial strains\n(derivative of the axial displacement in the axial direction) can be estimated\nby the proposed networks. In contrast to axial strain, lateral strain, which is\nhighly required in Poisson's ratio imaging and elasticity reconstruction, has a\npoor quality. The main causes include low sampling frequency, limited motion,\nand lack of phase information in the lateral direction. Recently, physically\ninspired constraint in unsupervised regularized elastography (PICTURE) has been\nproposed. This method took into account the range of the feasible lateral\nstrain defined by the rules of physics of motion and employed a regularization\nstrategy to improve the lateral strains. Despite the substantial improvement,\nthe regularization was only applied during the training; hence it did not\nguarantee during the test that the lateral strain is within the feasible range.\nFurthermore, only the feasible range was employed, other constraints such as\nincompressibility were not investigated. In this paper, we address these two\nissues and propose kPICTURE in which two iterative algorithms were infused into\nthe network architecture in the form of known operators to ensure the lateral\nstrain is within the feasible range and impose incompressibility during the\ntest phase.",
    "descriptor": "\nComments: Submitted to IEEE International Symposium on Biomedical Imaging (ISBI) 2023\n",
    "authors": [
      "Ali K. Z. Tehrani",
      "Hassan Rivaz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00172"
  },
  {
    "id": "arXiv:2211.00175",
    "title": "Homodyned K-distribution: parameter estimation and uncertainty  quantification using Bayesian neural networks",
    "abstract": "Quantitative ultrasound (QUS) allows estimating the intrinsic tissue\nproperties. Speckle statistics are the QUS parameters that describe the first\norder statistics of ultrasound (US) envelope data. The parameters of Homodyned\nK-distribution (HK-distribution) are the speckle statistics that can model the\nenvelope data in diverse scattering conditions. However, they require a large\namount of data to be estimated reliably. Consequently, finding out the\nintrinsic uncertainty of the estimated parameters can help us to have a better\nunderstanding of the estimated parameters. In this paper, we propose a Bayesian\nNeural Network (BNN) to estimate the parameters of HK-distribution and quantify\nthe uncertainty of the estimator.",
    "descriptor": "\nComments: Submitted to IEEE International Symposium on Biomedical Imaging (ISBI) 2023\n",
    "authors": [
      "Ali K. Z. Tehrani",
      "Ivan M. Rosado-Mendez",
      "Hassan Rivaz"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.00175"
  },
  {
    "id": "arXiv:2211.00226",
    "title": "Waveform Boundary Detection for Partially Spoofed Audio",
    "abstract": "The present paper proposes a waveform boundary detection system for audio\nspoofing attacks containing partially manipulated segments. Partially\nspoofed/fake audio, where part of the utterance is replaced, either with\nsynthetic or natural audio clips, has recently been reported as one scenario of\naudio deepfakes. As deepfakes can be a threat to social security, the detection\nof such spoofing audio is essential. Accordingly, we propose to address the\nproblem with a deep learning-based frame-level detection system that can detect\npartially spoofed audio and locate the manipulated pieces. Our proposed method\nis trained and evaluated on data provided by the ADD2022 Challenge. We evaluate\nour detection model concerning various acoustic features and network\nconfigurations. As a result, our detection system achieves an equal error rate\n(EER) of 6.58% on the ADD2022 challenge test set, which is the best performance\nin partially spoofed audio detection systems that can locate manipulated clips.",
    "descriptor": "",
    "authors": [
      "Zexin Cai",
      "Weiqing Wang",
      "Ming Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.00226"
  },
  {
    "id": "arXiv:2211.00240",
    "title": "Angular upsampling in diffusion MRI using contextual HemiHex  sub-sampling in q-space",
    "abstract": "Artificial Intelligence (Deep Learning(DL)/ Machine Learning(ML)) techniques\nare widely being used to address and overcome all kinds of ill-posed problems\nin medical imaging which was or in fact is seemingly impossible. Reducing\ngradient directions but harnessing high angular resolution(HAR) diffusion data\nin MR that retains clinical features is an important and challenging problem in\nthe field. While the DL/ML approaches are promising, it is important to\nincorporate relevant context for the data to ensure that maximum prior\ninformation is provided for the AI model to infer the posterior. In this paper,\nwe introduce HemiHex (HH) subsampling to suggestively address training data\nsampling on q-space geometry, followed by a nearest neighbor regression\ntraining on the HH-samples to finally upsample the dMRI data. Earlier studies\nhas tried to use regression for up-sampling dMRI data but yields performance\nissues as it fails to provide structured geometrical measures for inference.\nOur proposed approach is a geometrically optimized regression technique which\ninfers the unknown q-space thus addressing the limitations in the earlier\nstudies.",
    "descriptor": "\nComments: 4 pages, 6 figures, Submitted methodology to MICCAI Challenge 2022 (QuaD22) at this https URL\n",
    "authors": [
      "Abrar Faiyaz",
      "Md Nasir Uddin",
      "Giovanni Schifitto"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00240"
  },
  {
    "id": "arXiv:2211.00249",
    "title": "Robust Direct Learning for Causal Data Fusion",
    "abstract": "In the era of big data, the explosive growth of multi-source heterogeneous\ndata offers many exciting challenges and opportunities for improving the\ninference of conditional average treatment effects. In this paper, we\ninvestigate homogeneous and heterogeneous causal data fusion problems under a\ngeneral setting that allows for the presence of source-specific covariates. We\nprovide a direct learning framework for integrating multi-source data that\nseparates the treatment effect from other nuisance functions, and achieves\ndouble robustness against certain misspecification. To improve estimation\nprecision and stability, we propose a causal information-aware weighting\nfunction motivated by theoretical insights from the semiparametric efficiency\ntheory; it assigns larger weights to samples containing more causal information\nwith high interpretability. We introduce a two-step algorithm, the weighted\nmulti-source direct learner, based on constructing a pseudo-outcome and\nregressing it on covariates under a weighted least square criterion; it offers\nus a powerful tool for causal data fusion, enjoying the advantages of easy\nimplementation, double robustness and model flexibility. In simulation studies,\nwe demonstrate the effectiveness of our proposed methods in both homogeneous\nand heterogeneous causal data fusion scenarios.",
    "descriptor": "\nComments: 16 pages, 2 figures. Accepted for presentation at the 14th Asian Conference on Machine Learning (ACML 2022), and for publication in Proceedings of Machine Learning Research, Volume 189\n",
    "authors": [
      "Xinyu Li",
      "Yilin Li",
      "Qing Cui",
      "Longfei Li",
      "Jun Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.00249"
  },
  {
    "id": "arXiv:2211.00261",
    "title": "Learning Task-Aware Effective Brain Connectivity for fMRI Analysis with  Graph Neural Networks",
    "abstract": "Functional magnetic resonance imaging (fMRI) has become one of the most\ncommon imaging modalities for brain function analysis. Recently, graph neural\nnetworks (GNN) have been adopted for fMRI analysis with superior performance.\nUnfortunately, traditional functional brain networks are mainly constructed\nbased on similarities among region of interests (ROI), which are noisy and\nagnostic to the downstream prediction tasks and can lead to inferior results\nfor GNN-based models. To better adapt GNNs for fMRI analysis, we propose TBDS,\nan end-to-end framework based on \\underline{T}ask-aware \\underline{B}rain\nconnectivity \\underline{D}AG (short for Directed Acyclic Graph)\n\\underline{S}tructure generation for fMRI analysis. The key component of TBDS\nis the brain network generator which adopts a DAG learning approach to\ntransform the raw time-series into task-aware brain connectivities. Besides, we\ndesign an additional contrastive regularization to inject task-specific\nknowledge during the brain network generation process. Comprehensive\nexperiments on two fMRI datasets, namely Adolescent Brain Cognitive Development\n(ABCD) and Philadelphia Neuroimaging Cohort (PNC) datasets demonstrate the\nefficacy of TBDS. In addition, the generated brain networks also highlight the\nprediction-related brain regions and thus provide unique interpretations of the\nprediction results. Our implementation will be published to\nhttps://github.com/yueyu1030/TBDS upon acceptance.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Yue Yu",
      "Xuan Kan",
      "Hejie Cui",
      "Ran Xu",
      "Yujia Zheng",
      "Xiangchen Song",
      "Yanqiao Zhu",
      "Kun Zhang",
      "Razieh Nabi",
      "Ying Guo",
      "Chao Zhang",
      "Carl Yang"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.00261"
  },
  {
    "id": "arXiv:2211.00296",
    "title": "Bayesian Parameter Inference for Partially Observed SDEs driven by  Fractional Brownian Motion",
    "abstract": "In this paper we consider Bayesian parameter inference for partially observed\nfractional Brownian motion (fBM) models. The approach we follow is to\ntime-discretize the hidden process and then to design Markov chain Monte Carlo\n(MCMC) algorithms to sample from the posterior density on the parameters given\ndata. We rely on a novel representation of the time discretization, which seeks\nto sample from an approximation of the posterior and then corrects via\nimportance sampling; the approximation reduces the time (in terms of total\nobservation time T) by O(T). This method is extended by using a multilevel MCMC\nmethod which can reduce the computational cost to achieve a given mean square\nerror (MSE) versus using a single time discretization. Our methods are\nillustrated on simulated and real data.",
    "descriptor": "",
    "authors": [
      "Mohamed Maama",
      "Ajay Jasra",
      "Hernando Ombao"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Numerical Analysis (math.NA)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.00296"
  },
  {
    "id": "arXiv:2211.00303",
    "title": "Exploring Structure-Wise Uncertainty for 3D Medical Image Segmentation",
    "abstract": "When applying a Deep Learning model to medical images, it is crucial to\nestimate the model uncertainty. Voxel-wise uncertainty is a useful visual\nmarker for human experts and could be used to improve the model's voxel-wise\noutput, such as segmentation. Moreover, uncertainty provides a solid foundation\nfor out-of-distribution (OOD) detection, improving the model performance on the\nimage-wise level. However, one of the frequent tasks in medical imaging is the\nsegmentation of distinct, local structures such as tumors or lesions. Here, the\nstructure-wise uncertainty allows more precise operations than image-wise and\nmore semantic-aware than voxel-wise. The way to produce uncertainty for\nindividual structures remains poorly explored. We propose a framework to\nmeasure the structure-wise uncertainty and evaluate the impact of OOD data on\nthe model performance. Thus, we identify the best UE method to improve the\nsegmentation quality. The proposed framework is tested on three datasets with\nthe tumor segmentation task: LIDC-IDRI, LiTS, and a private one with multiple\nbrain metastases cases.",
    "descriptor": "",
    "authors": [
      "Anton Vasiliuk",
      "Daria Frolova",
      "Mikhail Belyaev",
      "Boris Shirokikh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00303"
  },
  {
    "id": "arXiv:2211.00307",
    "title": "Combined space-time reduced-order model with 3D deep convolution for  extrapolating fluid dynamics",
    "abstract": "There is a critical need for efficient and reliable active flow control\nstrategies to reduce drag and noise in aerospace and marine engineering\napplications. While traditional full-order models based on the Navier-Stokes\nequations are not feasible, advanced model reduction techniques can be\ninefficient for active control tasks, especially with strong non-linearity and\nconvection-dominated phenomena. Using convolutional recurrent autoencoder\nnetwork architectures, deep learning-based reduced-order models have been\nrecently shown to be effective while performing several orders of magnitude\nfaster than full-order simulations. However, these models encounter significant\nchallenges outside the training data, limiting their effectiveness for active\ncontrol and optimization tasks. In this study, we aim to improve the\nextrapolation capability by modifying network architecture and integrating\ncoupled space-time physics as an implicit bias. Reduced-order models via deep\nlearning generally employ decoupling in spatial and temporal dimensions, which\ncan introduce modeling and approximation errors. To alleviate these errors, we\npropose a novel technique for learning coupled spatial-temporal correlation\nusing a 3D convolution network. We assess the proposed technique against a\nstandard encoder-propagator-decoder model and demonstrate a superior\nextrapolation performance. To demonstrate the effectiveness of 3D convolution\nnetwork, we consider a benchmark problem of the flow past a circular cylinder\nat laminar flow conditions and use the spatio-temporal snapshots from the\nfull-order simulations. Our proposed 3D convolution architecture accurately\ncaptures the velocity and pressure fields for varying Reynolds numbers.\nCompared to the standard encoder-propagator-decoder network, the\nspatio-temporal-based 3D convolution network improves the prediction range of\nReynolds numbers outside of the training data.",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Indu Kant Deo",
      "Rui Gao",
      "Rajeev Jaiman"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00307"
  },
  {
    "id": "arXiv:2211.00317",
    "title": "Quantum-inspired optimization for routing and wavelength assignment",
    "abstract": "Problems related to routing and wavelength assignment (RWA) in optical\ncommunications networks involve allocating transmission wavelengths and finding\ntransmission paths between nodes that minimize a certain objective function,\nfor example, the total number of wavelengths. Playing a central role in modern\ntelecommunications, this problem belongs to NP-complete class for a general\ncase, so that obtaining optimal solutions for industry relevant cases is\nexponentially hard. In this work, we propose and develop a quantum-inspired\nalgorithm for solving the RWA problem in a particular yet industry relevant\ncase, in which we specifically focus on the wavelength assignment task for\nknown routes. We propose an advanced embedding procedure for this problem into\nthe quadratic unconstrained binary optimization (QUBO) form having a\nlogarithmic improvement in the number of iterations with price-to-pay being a\nslight increase in the number of variables (\"spins\"). Then we compare a\nquantum-inspired technique for solving the corresponding QUBO form against\nclassical heuristic and industrial combinatorial solvers. The obtained\nnumerical results indicate on an advantage of the quantum-inspired approach in\na substantial number of test cases against the industrial combinatorial solver\nthat works in the standard setting. Our results pave the way to the use of\nquantum-inspired algorithms for practical problems in telecommunications and\nopen a perspective for the further analysis of the employ of quantum computing\ndevices.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Aleksey S. Boev",
      "Sergey R. Usmanov",
      "Alexander M. Semenov",
      "Maria M. Ushakova",
      "Gleb V. Salahov",
      "Alena S. Mastiukova",
      "Evgeniy O. Kiktenko",
      "Aleksey K. Fedorov"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.00317"
  },
  {
    "id": "arXiv:2211.00325",
    "title": "Speech-text based multi-modal training with bidirectional attention for  improved speech recognition",
    "abstract": "To let the state-of-the-art end-to-end ASR model enjoy data efficiency, as\nwell as much more unpaired text data by multi-modal training, one needs to\naddress two problems: 1) the synchronicity of feature sampling rates between\nspeech and language (aka text data); 2) the homogeneity of the learned\nrepresentations from two encoders. In this paper we propose to employ a novel\nbidirectional attention mechanism (BiAM) to jointly learn both ASR encoder\n(bottom layers) and text encoder with a multi-modal learning method. The BiAM\nis to facilitate feature sampling rate exchange, realizing the quality of the\ntransformed features for the one kind to be measured in another space, with\ndiversified objective functions. As a result, the speech representations are\nenriched with more linguistic information, while the representations generated\nby the text encoder are more similar to corresponding speech ones, and\ntherefore the shared ASR models are more amenable for unpaired text data\npretraining. To validate the efficacy of the proposed method, we perform two\ncategories of experiments with or without extra unpaired text data.\nExperimental results on Librispeech corpus show it can achieve up to 6.15% word\nerror rate reduction (WERR) with only paired data learning, while 9.23% WERR\nwhen more unpaired text data is employed.",
    "descriptor": "\nComments: 5 pages, 3 figures, 3 tables\n",
    "authors": [
      "Yuhang Yang",
      "Haihua Xu",
      "Hao Huang",
      "Eng Siong Chng",
      "Sheng Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.00325"
  },
  {
    "id": "arXiv:2211.00326",
    "title": "Rating Triggers for Collateral-Inclusive XVA via Machine Learning and  SDEs on Lie Groups",
    "abstract": "In this paper, we model the rating process of an entity by using a\ngeometrical approach. We model rating transitions as an SDE on a Lie group.\nSpecifically, we focus on calibrating the model to both historical data (rating\ntransition matrices) and market data (CDS quotes) and compare the most popular\nchoices of changes of measure to switch from the historical probability to the\nrisk-neutral one. For this, we show how the classical Girsanov theorem can be\napplied in the Lie group setting. Moreover, we overcome some of the\nimperfections of rating matrices published by rating agencies, which are\ncomputed with the cohort method, by using a novel Deep Learning approach. This\nleads to an improvement of the entire scheme and makes the model more robust\nfor applications. We apply our model to compute bilateral credit and debit\nvaluation adjustments of a netting set under a CSA with thresholds depending on\nratings of the two parties.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2207.03883\n",
    "authors": [
      "Kevin Kamm",
      "Michelle Muniz"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/2211.00326"
  },
  {
    "id": "arXiv:2211.00335",
    "title": "Recurrent Neural Networks and Universal Approximation of Bayesian  Filters",
    "abstract": "We consider the Bayesian optimal filtering problem: i.e. estimating some\nconditional statistics of a latent time-series signal from an observation\nsequence. Classical approaches often rely on the use of assumed or estimated\ntransition and observation models. Instead, we formulate a generic recurrent\nneural network framework and seek to learn directly a recursive mapping from\nobservational inputs to the desired estimator statistics. The main focus of\nthis article is the approximation capabilities of this framework. We provide\napproximation error bounds for filtering in general non-compact domains. We\nalso consider strong time-uniform approximation error bounds that guarantee\ngood long-time performance. We discuss and illustrate a number of practical\nconcerns and implications of these results.",
    "descriptor": "",
    "authors": [
      "Adrian N. Bishop",
      "Edwin V. Bonilla"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.00335"
  },
  {
    "id": "arXiv:2211.00355",
    "title": "Urban Mobility",
    "abstract": "In this chapter, we discuss urban mobility from a complexity science\nperspective. First, we give an overview of the datasets that enable this\napproach, such as mobile phone records, location-based social network traces,\nor GPS trajectories from sensors installed on vehicles. We then review the\nempirical and theoretical understanding of the properties of human movements,\nincluding the distribution of travel distances and times, the entropy of\ntrajectories, and the interplay between exploration and exploitation of\nlocations. Next, we explain generative and predictive models of individual\nmobility, and their limitations due to intrinsic limits of predictability.\nFinally, we discuss urban transport from a systemic perspective, including\nsystem-wide challenges like ridesharing, multimodality, and sustainable\ntransport.",
    "descriptor": "\nComments: Compendium of Urban Complexity. 21 pages\n",
    "authors": [
      "Laura Alessandretti",
      "Michael Szell"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.00355"
  },
  {
    "id": "arXiv:2211.00357",
    "title": "Generalized Quadratic-Embeddings for Nonlinear Dynamics using Deep  Learning",
    "abstract": "The engineering design process (e.g., control and forecasting) relies on\nmathematical modeling, describing the underlying dynamic behavior. For complex\ndynamics behavior, modeling procedures, as well as models, can be intricated,\nwhich can make the design process cumbersome. Therefore, it is desirable to\nhave a common model structure, which is also simple enough, for all nonlinear\ndynamics to enhance design processes. The simplest dynamical model -- one can\nthink of -- is linear, but linear models are often not expressive enough to\napprehend complex dynamics. In this work, we propose a modeling approach for\nnonlinear dynamics and discuss a common framework to model nonlinear dynamic\nprocesses, which is built upon a \\emph{lifting-principle}. The preeminent idea\nof the principle is that smooth nonlinear systems can be written as quadratic\nsystems in an appropriate lifted coordinate system without any approximation\nerror. Hand-designing these coordinates is not straightforward. In this work,\nwe utilize deep learning capabilities and discuss suitable neural network\narchitectures to find such a coordinate system using data. We present\ninnovative neural architectures and the corresponding objective criterion to\nachieve our goal. We illustrate the approach using data coming from\napplications in engineering and biology.",
    "descriptor": "",
    "authors": [
      "Pawan Goyal",
      "Peter Benner"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00357"
  },
  {
    "id": "arXiv:2211.00377",
    "title": "combined digital drone camera and optical channel parameters for air  surveillance",
    "abstract": "Digital drone cameras with free-space optical (FSO) communication networks\nhave been proposed to be promising for air surveillance. In the FSO channel,\natmospheric turbulence (AT) degrades the signal. In this study, we combined the\nparameters of the digital drone camera and the optical channel to mitigate the\nAT effect. The digital drone camera parameters are indicated by the field of\nview and camera object distance to support this proposal. Meanwhile, the\noptical channel parameters, rather than the altitude, are denoted by the most\ncritical parameter, which is the refractive index structure parameter used to\ncharacterize the effects of AT. Consequently, two lemmas are proposed and\ncombined to present the optimum relationship between the digital drone camera\nand optical channel parameters. Therefore, the quality of the entire air\nsurveillance system with a digital drone camera FSO is significantly improved.\nFurthermore, the analysis and optimization for practical cases were applied to\nsupport our findings. Finally, our results demonstrated that an impressive\nperformance improvement of an air surveillance system of 17 dB is possible\ncompared without optimization by combining digital drone camera and FSO\nparameters at a target outage transceiver probability of $10^-6$.",
    "descriptor": "",
    "authors": [
      "Wamidh Jalil Mazher",
      "hadeel Tariq Ibrahim"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.00377"
  },
  {
    "id": "arXiv:2211.00397",
    "title": "Galaxy classification: a deep learning approach for classifying Sloan  Digital Sky Survey images",
    "abstract": "In recent decades, large-scale sky surveys such as Sloan Digital Sky Survey\n(SDSS) have resulted in generation of tremendous amount of data. The\nclassification of this enormous amount of data by astronomers is time\nconsuming. To simplify this process, in 2007 a volunteer-based citizen science\nproject called Galaxy Zoo was introduced, which has reduced the time for\nclassification by a good extent. However, in this modern era of deep learning,\nautomating this classification task is highly beneficial as it reduces the time\nfor classification. For the last few years, many algorithms have been proposed\nwhich happen to do a phenomenal job in classifying galaxies into multiple\nclasses. But all these algorithms tend to classify galaxies into less than six\nclasses. However, after considering the minute information which we know about\ngalaxies, it is necessary to classify galaxies into more than eight classes. In\nthis study, a neural network model is proposed so as to classify SDSS data into\n10 classes from an extended Hubble Tuning Fork. Great care is given to disc\nedge and disc face galaxies, distinguishing between a variety of substructures\nand minute features which are associated with each class. The proposed model\nconsists of convolution layers to extract features making this method fully\nautomatic. The achieved test accuracy is 84.73 per cent which happens to be\npromising after considering such minute details in classes. Along with\nconvolution layers, the proposed model has three more layers responsible for\nclassification, which makes the algorithm consume less time.",
    "descriptor": "\nComments: Published in MNRAS\n",
    "authors": [
      "Sarvesh Gharat",
      "Yogesh Dandawate"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00397"
  },
  {
    "id": "arXiv:2211.00435",
    "title": "Spreading dynamics in networks under context-dependent behavior",
    "abstract": "The constituent units of certain systems are able to define a `context' that,\naltering the behavior of other units, indirectly modifies the (direct)\ninteractions occurring among the latter.Motivated by mechanisms of `indirect\nmodification' -- as they are called in ecology -- identified in real systems,\nwe present a minimal model of context-dependent spreading where, during an\ninteraction, an agent either actively behaves to alter (impede/favor) the\ndiffusion or not depending on the behavior it observes among the co-present\npeers. Considering populations where agents are divided into two behavioral\ntypes, encoding different intrinsic inclinations to take on active behavior, we\nprovide a mean-field theory able to parametrize mixing patterns of any\ntype-(dis)assortativity within groups of arbitrary size. As an application, we\nconsider an epidemic spreading model under context-dependent adoption of\nprophylactic behavior like face-masks wearing. Assuming individuals gathering\nin pairs and triads, we characterize the rich phenomenology found for the basic\nreproduction number and the endemic state in relation to the distributions of\nsize and type-composition of the groups. We demonstrate that changes in such\nfeatures of the contact organization either facilitate or hinder epidemic\nspreading depending mainly on sociological factors (hardness to induce active\nbehavior and types' proportions) and, secondarily, on technical ones\n(prophylactic efficacy). More generally, our work provides a way to model a\nhigher-order context for processes under heterogeneous mixing, and reaffirms\nhow higher-order interactions can lead to significant deviations from what is\nexpected based on pairwise information alone, opening new questions for a\nseries of complex systems.",
    "descriptor": "\nComments: 24 pages, 12 figures\n",
    "authors": [
      "Giulio Burgio",
      "Sergio G\u00f3mez",
      "Alex Arenas"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.00435"
  },
  {
    "id": "arXiv:2211.00437",
    "title": "Disentangled representation learning for multilingual speaker  recognition",
    "abstract": "The goal of this paper is to train speaker embeddings that are robust to\nbilingual speaking scenario. The majority of the world's population speak at\nleast two languages; however, most speaker recognition systems fail to\nrecognise the same speaker when speaking in different languages.\nPopular speaker recognition evaluation sets do not consider the bilingual\nscenario, making it difficult to analyse the effect of bilingual speakers on\nspeaker recognition performance. This paper proposes a new large-scale\nevaluation set derived from VoxCeleb that considers bilingual scenarios. We\nalso introduce a representation learning strategy, which disentangles language\ninformation from speaker representation to account for the bilingual scenario.\nThis language-disentangled representation learning strategy can be adapted to\nexisting models with small changes to the training pipeline.\nExperimental results demonstrate that the baseline models suffer significant\nperformance degradation when evaluated on the proposed bilingual test set. On\nthe contrary, the model trained with the proposed disentanglement strategy\nshows significant improvement under the bilingual evaluation scenario while\nsimultaneously retaining competitive performance on existing monolingual test\nsets.",
    "descriptor": "",
    "authors": [
      "Kihyun Nam",
      "Youkyum Kim",
      "Hee Soo Heo",
      "Jee-weon Jung",
      "Joon Son Chung"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.00437"
  },
  {
    "id": "arXiv:2211.00439",
    "title": "Metric Learning for User-defined Keyword Spotting",
    "abstract": "The goal of this work is to detect new spoken terms defined by users. While\nmost previous works address Keyword Spotting (KWS) as a closed-set\nclassification problem, this limits their transferability to unseen terms. The\nability to define custom keywords has advantages in terms of user experience.\nIn this paper, we propose a metric learning-based training strategy for\nuser-defined keyword spotting. In particular, we make the following\ncontributions: (1) we construct a large-scale keyword dataset with an existing\nspeech corpus and propose a filtering method to remove data that degrade model\ntraining; (2) we propose a metric learning-based two-stage training strategy,\nand demonstrate that the proposed method improves the performance on the\nuser-defined keyword spotting task by enriching their representations; (3) to\nfacilitate the fair comparison in the user-defined KWS field, we propose\nunified evaluation protocol and metrics.\nOur proposed system does not require an incremental training on the\nuser-defined keywords, and outperforms previous works by a significant margin\non the Google Speech Commands dataset using the proposed as well as the\nexisting metrics.",
    "descriptor": "",
    "authors": [
      "Jaemin Jung",
      "Youkyum Kim",
      "Jihwan Park",
      "Youshin Lim",
      "Byeong-Yeol Kim",
      "Youngjoon Jang",
      "Joon Son Chung"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.00439"
  },
  {
    "id": "arXiv:2211.00454",
    "title": "PELICAN: Permutation Equivariant and Lorentz Invariant or Covariant  Aggregator Network for Particle Physics",
    "abstract": "Many current approaches to machine learning in particle physics use generic\narchitectures that require large numbers of parameters and disregard underlying\nphysics principles, limiting their applicability as scientific modeling tools.\nIn this work, we present a machine learning architecture that uses a set of\ninputs maximally reduced with respect to the full 6-dimensional Lorentz\nsymmetry, and is fully permutation-equivariant throughout. We study the\napplication of this network architecture to the standard task of top quark\ntagging and show that the resulting network outperforms all existing\ncompetitors despite much lower model complexity. In addition, we present a\nLorentz-covariant variant of the same network applied to a 4-momentum\nregression task.",
    "descriptor": "",
    "authors": [
      "Alexander Bogatskiy",
      "Timothy Hoffman",
      "David W. Miller",
      "Jan T. Offermann"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ],
    "url": "https://arxiv.org/abs/2211.00454"
  },
  {
    "id": "arXiv:2211.00460",
    "title": "Augmentation Invariant Manifold Learning",
    "abstract": "Data augmentation is a widely used technique and an essential ingredient in\nthe recent advance in self-supervised representation learning. By preserving\nthe similarity between augmented data, the resulting data representation can\nimprove various downstream analyses and achieve state-of-art performance in\nmany applications. To demystify the role of data augmentation, we develop a\nstatistical framework on a low-dimension product manifold to theoretically\nunderstand why the unlabeled augmented data can lead to useful data\nrepresentation. Under this framework, we propose a new representation learning\nmethod called augmentation invariant manifold learning and develop the\ncorresponding loss function, which can work with a deep neural network to learn\ndata representations. Compared with existing methods, the new data\nrepresentation simultaneously exploits the manifold's geometric structure and\ninvariant property of augmented data. Our theoretical investigation precisely\ncharacterizes how the data representation learned from augmented data can\nimprove the $k$-nearest neighbor classifier in the downstream analysis, showing\nthat a more complex data augmentation leads to more improvement in downstream\nanalysis. Finally, numerical experiments on simulated and real datasets are\npresented to support the theoretical results in this paper.",
    "descriptor": "",
    "authors": [
      "Shulei Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.00460"
  },
  {
    "id": "arXiv:2211.00464",
    "title": "On the zeroes of hypergraph independence polynomials",
    "abstract": "We study the locations of complex zeroes of independence polynomials of\nbounded degree hypergraphs. For graphs, this is a long-studied subject with\napplications to statistical physics, algorithms, and combinatorics. Results on\nzero-free regions for bounded-degree graphs include Shearer's result on the\noptimal zero-free disk, along with several recent results on other zero-free\nregions. Much less is known for hypergraphs. We make some steps towards an\nunderstanding of zero-free regions for bounded-degree hypergaphs by proving\nthat all hypergraphs of maximum degree $\\Delta$ have a zero-free disk almost as\nlarge as the optimal disk for graphs of maximum degree $\\Delta$ established by\nShearer (of radius $\\sim 1/(e \\Delta)$). Up to logarithmic factors in $\\Delta$\nthis is optimal, even for hypergraphs with all edge-sizes strictly greater than\n$2$. We conjecture that for $k\\ge 3$, $k$-uniform linear hypergraphs have a\nmuch larger zero-free disk of radius $\\Omega(\\Delta^{- \\frac{1}{k-1}} )$. We\nestablish this in the case of linear hypertrees.",
    "descriptor": "",
    "authors": [
      "David Galvin",
      "Gwen McKinley",
      "Will Perkins",
      "Michail Sarantis",
      "Prasad Tetali"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Data Structures and Algorithms (cs.DS)",
      "Mathematical Physics (math-ph)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.00464"
  },
  {
    "id": "arXiv:2211.00482",
    "title": "Adapting self-supervised models to multi-talker speech recognition using  speaker embeddings",
    "abstract": "Self-supervised learning (SSL) methods which learn representations of data\nwithout explicit supervision have gained popularity in speech-processing tasks,\nparticularly for single-talker applications. However, these models often have\ndegraded performance for multi-talker scenarios -- possibly due to the domain\nmismatch -- which severely limits their use for such applications. In this\npaper, we investigate the adaptation of upstream SSL models to the multi-talker\nautomatic speech recognition (ASR) task under two conditions. First, when\nsegmented utterances are given, we show that adding a target speaker extraction\n(TSE) module based on enrollment embeddings is complementary to mixture-aware\npre-training. Second, for unsegmented mixtures, we propose a novel joint\nspeaker modeling (JSM) approach, which aggregates information from all speakers\nin the mixture through their embeddings. With controlled experiments on\nLibri2Mix, we show that using speaker embeddings provides relative WER\nimprovements of 9.1% and 42.1% over strong baselines for the segmented and\nunsegmented cases, respectively. We also demonstrate the effectiveness of our\nmodels for real conversational mixtures through experiments on the AMI dataset.",
    "descriptor": "\nComments: submitted to ICASSP 2023\n",
    "authors": [
      "Zili Huang",
      "Desh Raj",
      "Paola Garc\u00eda",
      "Sanjeev Khudanpur"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.00482"
  },
  {
    "id": "arXiv:2211.00484",
    "title": "Fast and parallel decoding for transducer",
    "abstract": "The transducer architecture is becoming increasingly popular in the field of\nspeech recognition, because it is naturally streaming as well as high in\naccuracy. One of the drawbacks of transducer is that it is difficult to decode\nin a fast and parallel way due to an unconstrained number of symbols that can\nbe emitted per time step. In this work, we introduce a constrained version of\ntransducer loss to learn strictly monotonic alignments between the sequences;\nwe also improve the standard greedy search and beam search algorithms by\nlimiting the number of symbols that can be emitted per time step in transducer\ndecoding, making it more efficient to decode in parallel with batches.\nFurthermore, we propose an finite state automaton-based (FSA) parallel beam\nsearch algorithm that can run with graphs on GPU efficiently. The experiment\nresults show that we achieve slight word error rate (WER) improvement as well\nas significant speedup in decoding. Our work is open-sourced and publicly\navailable\\footnote{https://github.com/k2-fsa/icefall}.",
    "descriptor": "\nComments: Submitted to 2023 IEEE International Conference on Acoustics, Speech and Signal Processing\n",
    "authors": [
      "Wei Kang",
      "Liyong Guo",
      "Fangjun Kuang",
      "Long Lin",
      "Mingshuang Luo",
      "Zengwei Yao",
      "Xiaoyu Yang",
      "Piotr \u017belasko",
      "Daniel Povey"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.00484"
  },
  {
    "id": "arXiv:2211.00490",
    "title": "Delay-penalized transducer for low-latency streaming ASR",
    "abstract": "In streaming automatic speech recognition (ASR), it is desirable to reduce\nlatency as much as possible while having minimum impact on recognition\naccuracy. Although a few existing methods are able to achieve this goal, they\nare difficult to implement due to their dependency on external alignments. In\nthis paper, we propose a simple way to penalize symbol delay in transducer\nmodel, so that we can balance the trade-off between symbol delay and accuracy\nfor streaming models without external alignments. Specifically, our method adds\na small constant times (T/2 - t), where T is the number of frames and t is the\ncurrent frame, to all the non-blank log-probabilities (after normalization)\nthat are fed into the two dimensional transducer recursion. For both streaming\nConformer models and unidirectional long short-term memory (LSTM) models,\nexperimental results show that it can significantly reduce the symbol delay\nwith an acceptable performance degradation. Our method achieves similar\ndelay-accuracy trade-off to the previously published FastEmit, but we believe\nour method is preferable because it has a better justification: it is\nequivalent to penalizing the average symbol delay. Our work is open-sourced and\npublicly available (https://github.com/k2-fsa/k2).",
    "descriptor": "\nComments: Submitted to 2023 IEEE International Conference on Acoustics, Speech and Signal Processing\n",
    "authors": [
      "Wei Kang",
      "Zengwei Yao",
      "Fangjun Kuang",
      "Liyong Guo",
      "Xiaoyu Yang",
      "Long lin",
      "Piotr \u017belasko",
      "Daniel Povey"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.00490"
  },
  {
    "id": "arXiv:2211.00496",
    "title": "Can maker-taker fees prevent algorithmic cooperation in market making?",
    "abstract": "In a semi-realistic market simulator, independent reinforcement learning\nalgorithms may facilitate market makers to maintain wide spreads even without\ncommunication. This unexpected outcome challenges the current antitrust law\nframework. We study the effectiveness of maker-taker fee models in preventing\ncooperation via algorithms. After modeling market making as a repeated\ngeneral-sum game, we experimentally show that the relation between net\ntransaction costs and maker rebates is not necessarily monotone. Besides an\nupper bound on taker fees, we may also need a lower bound on maker rebates to\ndestabilize the cooperation. We also consider the taker-maker model and the\neffects of mid-price volatility, inventory risk, and the number of agents.",
    "descriptor": "",
    "authors": [
      "Bingyan Han"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.00496"
  },
  {
    "id": "arXiv:2211.00504",
    "title": "Fibonacci and digit-by-digit computation; An example of reverse  engineering in computational mathematics",
    "abstract": "The Fibonacci numbers are familiar to all of us. They appear unexpectedly\noften in mathematics, so much there is an entire journal and a sequence of\nconferences dedicated to their study. However, there is also another sequence\nof numbers associated with Fibonacci. In The On-Line Encyclopedia of Integer\nSequences, a sequence of numbers which is an approximation to the real root of\nthe cubic polynomial. Fibonacci gave the first few numbers in the sequence in\nthe manuscript Flos from around 1215. Fibonacci stated an error in the last\nnumber and based on this error we try, in this paper to reconstruct the method\nused by Fibonacci. Fibonacci gave no indication on how he determined the\nnumbers and the problem of identifying possible methods was raised already the\nyear after the first transcribed version of the manuscript was published in\n1854. There are three possible methods available to Fibonacci to solve the\ncubic equation; two of the methods have been shown to give Fibonacci's result.\nIn this paper we show that also the third method gives the same result, and we\nargue that this is the most likely method.",
    "descriptor": "\nComments: Presented at NIK2022, 28 November - 1 December Kristiansand, Norway\n",
    "authors": [
      "Trond Steihaug"
    ],
    "subjectives": [
      "History and Overview (math.HO)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.00504"
  },
  {
    "id": "arXiv:2211.00508",
    "title": "Predicting Multi-Codebook Vector Quantization Indexes for Knowledge  Distillation",
    "abstract": "Knowledge distillation(KD) is a common approach to improve model performance\nin automatic speech recognition (ASR), where a student model is trained to\nimitate the output behaviour of a teacher model. However, traditional KD\nmethods suffer from teacher label storage issue, especially when the training\ncorpora are large. Although on-the-fly teacher label generation tackles this\nissue, the training speed is significantly slower as the teacher model has to\nbe evaluated every batch. In this paper, we reformulate the generation of\nteacher label as a codec problem. We propose a novel Multi-codebook Vector\nQuantization (MVQ) approach that compresses teacher embeddings to codebook\nindexes (CI). Based on this, a KD training framework (MVQ-KD) is proposed where\na student model predicts the CI generated from the embeddings of a\nself-supervised pre-trained teacher model. Experiments on the LibriSpeech\nclean-100 hour show that MVQ-KD framework achieves comparable performance as\ntraditional KD methods (l1, l2), while requiring 256 times less storage. When\nthe full LibriSpeech dataset is used, MVQ-KD framework results in 13.8% and\n8.2% relative word error rate reductions (WERRs) for non -streaming transducer\non test-clean and test-other and 4.0% and 4.9% for streaming transducer. The\nimplementation of this work is already released as a part of the open-source\nproject icefall.",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Liyong Guo",
      "Xiaoyu Yang",
      "Quandong Wang",
      "Yuxiang Kong",
      "Zengwei Yao",
      "Fan Cui",
      "Fangjun Kuang",
      "Wei Kang",
      "Long Lin",
      "Mingshuang Luo",
      "Piotr Zelasko",
      "Daniel Povey"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.00508"
  },
  {
    "id": "arXiv:2211.00511",
    "title": "A Comparative Study on multichannel Speaker-attributed automatic speech  recognition in Multi-party Meetings",
    "abstract": "Speaker-attributed automatic speech recognition (SA-ASR) in multiparty\nmeeting scenarios is one of the most valuable and challenging ASR task. It was\nshown that single-channel frame-level diarization with serialized output\ntraining (SC-FD-SOT), single-channel word-level diarization with SOT\n(SC-WD-SOT) and joint training of single-channel target-speaker separation and\nASR (SC-TS-ASR) can be exploited to partially solve this problem. SC-FD-SOT\nobtains the speaker-attributed transcriptions by aligning the speaker\ndiarization results with the ASR hypotheses, SC-WD-SOT uses word-level\ndiarization to get rid of the alignment dependence on timestamps, and SC-TS-ASR\njointly trains target-speaker separation and ASR modules, which achieves the\nbest performance. In this paper, we propose three corresponding multichannel\n(MC) SA-ASR approaches, namely MC-FD-SOT, MC-WD-SOT and MC-TS-ASR. For\ndifferent tasks/models, different multichannel data fusion strategies are\nconsidered, including channel-level cross-channel attention for MC-FD-SOT,\nframe-level cross-channel attention for MC-WD-SOT and neural beamforming for\nMC-TS-ASR. Experimental results on the AliMeeting corpus reveal that our\nproposed multichannel SA-ASR models can consistently outperform the\ncorresponding single-channel counterparts in terms of the speaker-dependent\ncharacter error rate (SD-CER).",
    "descriptor": "",
    "authors": [
      "Mohan Shi",
      "Jie Zhang",
      "Zhihao Du",
      "Fan Yu",
      "Shiliang Zhang",
      "Li-Rong Dai"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.00511"
  },
  {
    "id": "arXiv:2211.00527",
    "title": "Self-Supervised Learning with Limited Labeled Data for Prostate Cancer  Detection in High Frequency Ultrasound",
    "abstract": "Deep learning-based analysis of high-frequency, high-resolution\nmicro-ultrasound data shows great promise for prostate cancer detection.\nPrevious approaches to analysis of ultrasound data largely follow a supervised\nlearning paradigm. Ground truth labels for ultrasound images used for training\ndeep networks often include coarse annotations generated from the\nhistopathological analysis of tissue samples obtained via biopsy. This creates\ninherent limitations on the availability and quality of labeled data, posing\nmajor challenges to the success of supervised learning methods. On the other\nhand, unlabeled prostate ultrasound data are more abundant. In this work, we\nsuccessfully apply self-supervised representation learning to micro-ultrasound\ndata. Using ultrasound data from 1028 biopsy cores of 391 subjects obtained in\ntwo clinical centres, we demonstrate that feature representations learnt with\nthis method can be used to classify cancer from non-cancer tissue, obtaining an\nAUROC score of 91% on an independent test set. To the best of our knowledge,\nthis is the first successful end-to-end self-supervised learning approach for\nprostate cancer detection using ultrasound data. Our method outperforms\nbaseline supervised learning approaches, generalizes well between different\ndata centers, and scale well in performance as more unlabeled data are added,\nmaking it a promising approach for future research using large volumes of\nunlabeled data.",
    "descriptor": "",
    "authors": [
      "Paul F. R. Wilson",
      "Mahdi Gilany",
      "Amoon Jamzad",
      "Fahimeh Fooladgar",
      "Minh Nguyen Nhat To",
      "Brian Wodlinger",
      "Purang Abolmaesumi",
      "Parvin Mousavi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00527"
  },
  {
    "id": "arXiv:2211.00529",
    "title": "DOLPH: Diffusion Models for Phase Retrieval",
    "abstract": "Phase retrieval refers to the problem of recovering an image from the\nmagnitudes of its complex-valued linear measurements. Since the problem is\nill-posed, the recovery requires prior knowledge on the unknown image. We\npresent DOLPH as a new deep model-based architecture for phase retrieval that\nintegrates an image prior specified using a diffusion model with a nonconvex\ndata-fidelity term for phase retrieval. Diffusion models are a recent class of\ndeep generative models that are relatively easy to train due to their\nimplementation as image denoisers. DOLPH reconstructs high-quality solutions by\nalternating data-consistency updates with the sampling step of a diffusion\nmodel. Our numerical results show the robustness of DOLPH to noise and its\nability to generate several candidate solutions given a set of measurements.",
    "descriptor": "",
    "authors": [
      "Shirin Shoushtari",
      "Jailing Liu",
      "Ulugbek S. Kamilov"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00529"
  },
  {
    "id": "arXiv:2211.00531",
    "title": "Robustness of Deep Equilibrium Architectures to Changes in the  Measurement Model",
    "abstract": "Deep model-based architectures (DMBAs) are widely used in imaging inverse\nproblems to integrate physical measurement models and learned image priors.\nPlug-and-play priors (PnP) and deep equilibrium models (DEQ) are two DMBA\nframeworks that have received significant attention. The key difference between\nthe two is that the image prior in DEQ is trained by using a specific\nmeasurement model, while that in PnP is trained as a general image denoiser.\nThis difference is behind a common assumption that PnP is more robust to\nchanges in the measurement models compared to DEQ. This paper investigates the\nrobustness of DEQ priors to changes in the measurement models. Our results on\ntwo imaging inverse problems suggest that DEQ priors trained under mismatched\nmeasurement models outperform image denoisers.",
    "descriptor": "",
    "authors": [
      "Junhao Hu",
      "Shirin Shoushtari",
      "Zihao Zou",
      "Jiaming Liu",
      "Zhixin Sun",
      "Ulugbek S.Kamilov"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00531"
  },
  {
    "id": "arXiv:2211.00538",
    "title": "Reducing Two-Way Ranging Variance by Signal-Timing Optimization",
    "abstract": "Time-of-flight-based range measurements among transceivers with different\nclocks requires ranging protocols that accommodate for the varying rates of the\nclocks. Double-sided two-way ranging (DS-TWR) has recently been widely adopted\nas a standard protocol due to its accuracy; however, the precision of DS-TWR\nhas not been clearly addressed. In this paper, an analytical model of the\nvariance of DS-TWR is derived as a function of the user-programmed response\ndelays. Consequently, this allows formulating an optimization problem over the\nresponse delays in order to maximize the information gained from range\nmeasurements by addressing the effect of varying the response delays on the\nprecision and frequency of the measurements. The derived analytical variance\nmodel and proposed optimization formulation are validated experimentally with 2\nranging UWB transceivers, where 29 million range measurements are collected.",
    "descriptor": "\nComments: 5 pages, 4 figures, submitted to 2023 International Conference on Acoustics, Speech and Signal Processing (ICASSP)\n",
    "authors": [
      "Mohammed Ayman Shalaby",
      "Charles Champagne Cossette",
      "James Richard Forbes",
      "Jerome Le Ny"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.00538"
  },
  {
    "id": "arXiv:2211.00545",
    "title": "Conservative Likelihood Ratio Estimator for Infrequent Data Slightly  above a Frequency Threshold",
    "abstract": "A naive likelihood ratio (LR) estimation using the observed frequencies of\nevents can overestimate LRs for infrequent data. One approach to avoid this\nproblem is to use a frequency threshold and set the estimates to zero for\nfrequencies below the threshold. This approach eliminates the computation of\nsome estimates, thereby making practical tasks using LRs more efficient.\nHowever, it still overestimates LRs for low frequencies near the threshold.\nThis study proposes a conservative estimator for low frequencies, slightly\nabove the threshold. Our experiment used LRs to predict the occurrence contexts\nof named entities from a corpus. The experimental results demonstrate that our\nestimator improves the prediction accuracy while maintaining efficiency in the\ncontext prediction task.",
    "descriptor": "\nComments: The 9th International Conference on Advanced Informatics: Concepts, Theory and Applications (ICAICTA 2022)\n",
    "authors": [
      "Masato Kikuchi",
      "Yuhi Kusakabe",
      "Tadachika Ozono"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00545"
  },
  {
    "id": "arXiv:2211.00551",
    "title": "Data-driven generation of 4D velocity profiles in the aneurysmal  ascending aorta",
    "abstract": "Numerical simulations of blood flow are a valuable tool to investigate the\npathophysiology of ascending thoracic aortic aneurysms (ATAA). To accurately\nreproduce hemodynamics, computational fluid dynamics (CFD) models must employ\nrealistic inflow boundary conditions (BCs). However, the limited availability\nof in vivo velocity measurements still makes researchers resort to idealized\nBCs. In this study we generated and thoroughly characterized a large dataset of\nsynthetic 4D aortic velocity profiles suitable to be used as BCs for CFD\nsimulations. 4D flow MRI scans of 30 subjects with ATAA were processed to\nextract cross-sectional planes along the ascending aorta, ensuring spatial\nalignment among all planes and interpolating all velocity fields to a reference\nconfiguration. Velocity profiles of the clinical cohort were extensively\ncharacterized by computing flow morphology descriptors of both spatial and\ntemporal features. By exploiting principal component analysis (PCA), a\nstatistical shape model (SSM) of 4D aortic velocity profiles was built and a\ndataset of 437 synthetic cases with realistic properties was generated.\nComparison between clinical and synthetic datasets showed that the synthetic\ndata presented similar characteristics as the clinical population in terms of\nkey morphological parameters. The average velocity profile qualitatively\nresembled a parabolic-shaped profile, but was quantitatively characterized by\nmore complex flow patterns which an idealized profile would not replicate.\nStatistically significant correlations were found between PCA principal modes\nof variation and flow descriptors. We built a data-driven generative model of\n4D aortic velocity profiles, suitable to be used in computational studies of\nblood flow. The proposed software system also allows to map any of the\ngenerated velocity profiles to the inlet plane of any virtual subject given its\ncoordinate set.",
    "descriptor": "\nComments: 21 pages, 5 figures, 2 tables To be submitted to \"Computer methods and programs in biomedicine\" Scripts: this https URL Synthetic velocity profiles: //doi.org/10.5281/zenodo.7251987\n",
    "authors": [
      "Simone Saitta",
      "Ludovica Maga",
      "Chloe Armour",
      "Emiliano Votta",
      "Declan P. O'Regan",
      "M. Yousuf Salmasi",
      "Thanos Athanasiou",
      "Jonathan W. Weinsaft",
      "Xiao Yun Xu",
      "Selene Pirola",
      "Alberto Redaelli"
    ],
    "subjectives": [
      "Tissues and Organs (q-bio.TO)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Image and Video Processing (eess.IV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.00551"
  },
  {
    "id": "arXiv:2211.00569",
    "title": "Few-shot Bioacoustic Event Detection with Machine Learning Methods",
    "abstract": "Few-shot learning is a type of classification through which predictions are\nmade based on a limited number of samples for each class. This type of\nclassification is sometimes referred to as a meta-learning problem, in which\nthe model learns how to learn to identify rare cases. We seek to extract\ninformation from five exemplar vocalisations of mammals or birds and detect and\nclassify these sounds in field recordings [2]. This task was provided in the\nDetection and Classification of Acoustic Scenes and Events (DCASE) Challenge of\n2021. Rather than utilize deep learning, as is most commonly done, we\nformulated a novel solution using only machine learning methods. Various models\nwere tested, and it was found that logistic regression outperformed both linear\nregression and template matching. However, all of these methods over-predicted\nthe number of events in the field recordings.",
    "descriptor": "\nComments: 7 pages, 6 tables, 1 figure\n",
    "authors": [
      "Leah Chowenhill",
      "Gaurav Satyanath",
      "Shubhranshu Singh",
      "Madhav Mahendra Wagh"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.00569"
  },
  {
    "id": "arXiv:2211.00577",
    "title": "Fine-tuned Generative Adversarial Network-based Model for Medical Images  Super-Resolution",
    "abstract": "In medical image analysis, low-resolution images negatively affect the\nperformance of medical image interpretation and may cause misdiagnosis. Single\nimage super-resolution (SISR) methods can improve the resolution and quality of\nmedical images. Currently, super-resolution methods based on generative\nadversarial networks (GAN) are widely used and have shown very good\nperformance. In this work, we use the Real-Enhanced Super-Resolution Generative\nAdversarial Network (Real-ESRGAN) model to enhance the resolution and quality\nof medical images. Unlike natural datasets, medical datasets do not have very\nhigh spatial resolution. Transfer learning is one of the effective methods\nwhich uses models trained with external datasets (often natural datasets), and\nfine-tunes them to enhance medical images. In our proposed approach, the\npre-trained generator and discriminator networks of the Real-ESRGAN model are\nfine-tuned using medical image datasets. In this paper, we worked on retinal\nimages and chest X-ray images. We used the STARE dataset of retinal images and\nTuberculosis Chest X-rays (Shenzhen) dataset. The proposed model produces more\naccurate and natural textures, and the output images have better detail and\nresolution compared to the original Real-ESRGAN model.",
    "descriptor": "",
    "authors": [
      "Alireza Aghelan",
      "Modjtaba Rouhani"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00577"
  },
  {
    "id": "arXiv:2211.00583",
    "title": "Ambisonic Encoding of Signals From Spherical Microphone Arrays",
    "abstract": "This document illustrates how to process the signals from the microphones of\na rigid-sphere higher-order ambisonic microphone array so that they are encoded\nwith N3D normalization and ACN channel order and thereby can be used with the\nstandard ambisonic software tools such as SPARTA and the IEM Plugin Suite. A\nMATLAB script is provided.",
    "descriptor": "",
    "authors": [
      "Jens Ahrens"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.00583"
  },
  {
    "id": "arXiv:2211.00584",
    "title": "Ambisonic Encoding of Signals From Equatorial Microphone Arrays",
    "abstract": "The equatorial microphone array presented in (Ahrens et al., 2021) computes a\nspherical harmonic (SH) representation of a sound field based on pressure\nsensors along the equator of a rigid spherical baffle. The original formulation\nuses complex-valued SH basis functions. This is inconvenient if the SH\nrepresentation of the captured sound field is intended to be stored in time\ndomain by means of real-valued audio signals as it is common in the spatial\naudio format of ambisonics. The present document summarizes the modifications\nthat need to be applied to the mathematical formulation from (Ahrens et al.,\n2021) to produce an ambisonic representation of the captured sound field that\nis compatible with the established ambisonic software tools like SPARTA and the\nIEM Plugin Suite. An example MATLAB script that implements this formulation is\nprovided.",
    "descriptor": "",
    "authors": [
      "Jens Ahrens"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.00584"
  },
  {
    "id": "arXiv:2211.00585",
    "title": "Adapter-Based Extension of Multi-Speaker Text-to-Speech Model for New  Speakers",
    "abstract": "Fine-tuning is a popular method for adapting text-to-speech (TTS) models to\nnew speakers. However this approach has some challenges. Usually fine-tuning\nrequires several hours of high quality speech per speaker. There is also that\nfine-tuning will negatively affect the quality of speech synthesis for\npreviously learnt speakers. In this paper we propose an alternative approach\nfor TTS adaptation based on using parameter-efficient adapter modules. In the\nproposed approach, a few small adapter modules are added to the original\nnetwork. The original weights are frozen, and only the adapters are fine-tuned\non speech for new speaker. The parameter-efficient fine-tuning approach will\nproduce a new model with high level of parameter sharing with original model.\nOur experiments on LibriTTS, HiFi-TTS and VCTK datasets validate the\neffectiveness of adapter-based method through objective and subjective metrics.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Cheng-Ping Hsieh",
      "Subhankar Ghosh",
      "Boris Ginsburg"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.00585"
  },
  {
    "id": "arXiv:2211.00589",
    "title": "SCA: Streaming Cross-attention Alignment for Echo Cancellation",
    "abstract": "End-to-End deep learning has shown promising results for speech enhancement\ntasks, such as noise suppression, dereverberation, and speech separation.\nHowever, most state-of-the-art methods for echo cancellation are either\nclassical DSP-based or hybrid DSP-ML algorithms. Components such as the delay\nestimator and adaptive linear filter are based on traditional signal processing\nconcepts, and deep learning algorithms typically only serve to replace the\nnon-linear residual echo suppressor. This paper introduces an end-to-end echo\ncancellation network with a streaming cross-attention alignment (SCA). Our\nproposed method can handle unaligned inputs without requiring external\nalignment and generate high-quality speech without echoes. At the same time,\nthe end-to-end algorithm simplifies the current echo cancellation pipeline for\ntime-variant echo path cases. We test our proposed method on the ICASSP2022 and\nInterspeech2021 Microsoft deep echo cancellation challenge evaluation dataset,\nwhere our method outperforms some of the other hybrid and end-to-end methods.",
    "descriptor": "",
    "authors": [
      "Yang Liu",
      "Yangyang Shi",
      "Yun Li",
      "Kaustubh Kalgaonkar",
      "Sriram Srinivasan",
      "Xin Lei"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.00589"
  },
  {
    "id": "arXiv:2211.00601",
    "title": "A unified method of data assimilation and turbulence modeling for  separated flows at high Reynolds numbers",
    "abstract": "In recent years, machine learning methods represented by deep neural networks\n(DNN) have been a new paradigm of turbulence modeling. However, in the scenario\nof high Reynolds numbers, there are still some bottlenecks, including the lack\nof high-fidelity data and the convergence and stability problem in the coupling\nprocess of turbulence models and the RANS solvers. In this paper, we propose an\nimproved ensemble kalman inversion method as a unified approach of data\nassimilation and turbulence modeling for separated flows at high Reynolds\nnumbers. The trainable parameters of the DNN are optimized according to the\ngiven experimental surface pressure coefficients in the framework of mutual\ncoupling between the RANS equations and DNN eddy-viscosity models. In this way,\ndata assimilation and model training are combined into one step to get the\nhigh-fidelity turbulence models agree well with experiments efficiently. The\neffectiveness of the method is verified by cases of separated flows around\nairfoils(S809) at high Reynolds numbers. The results show that through joint\nassimilation of vary few experimental states, we can get turbulence models\ngeneralizing well to both attached and separated flows at different angles of\nattack. The errors of lift coefficients at high angles of attack are\nsignificantly reduced by more than three times compared with the traditional SA\nmodel. The models obtained also perform well in stability and robustness.",
    "descriptor": "",
    "authors": [
      "Z. Y. Wang",
      "W. W. Zhang"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00601"
  },
  {
    "id": "arXiv:2211.00603",
    "title": "On Medians of (Randomized) Pairwise Means",
    "abstract": "Tournament procedures, recently introduced in Lugosi & Mendelson (2016),\noffer an appealing alternative, from a theoretical perspective at least, to the\nprinciple of Empirical Risk Minimization in machine learning. Statistical\nlearning by Median-of-Means (MoM) basically consists in segmenting the training\ndata into blocks of equal size and comparing the statistical performance of\nevery pair of candidate decision rules on each data block: that with highest\nperformance on the majority of the blocks is declared as the winner. In the\ncontext of nonparametric regression, functions having won all their duels have\nbeen shown to outperform empirical risk minimizers w.r.t. the mean squared\nerror under minimal assumptions, while exhibiting robustness properties. It is\nthe purpose of this paper to extend this approach in order to address other\nlearning problems, in particular for which the performance criterion takes the\nform of an expectation over pairs of observations rather than over one single\nobservation, as may be the case in pairwise ranking, clustering or metric\nlearning. Precisely, it is proved here that the bounds achieved by MoM are\nessentially conserved when the blocks are built by means of independent\nsampling without replacement schemes instead of a simple segmentation. These\nresults are next extended to situations where the risk is related to a pairwise\nloss function and its empirical counterpart is of the form of a $U$-statistic.\nBeyond theoretical results guaranteeing the performance of the\nlearning/estimation methods proposed, some numerical experiments provide\nempirical evidence of their relevance in practice.",
    "descriptor": "",
    "authors": [
      "Pierre Laforgue",
      "Stephan Cl\u00e9men\u00e7on",
      "Patrice Bertail"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00603"
  },
  {
    "id": "arXiv:2211.00605",
    "title": "Verifying a stochastic model for the spread of a SARS-CoV-2-like  infection: opportunities and limitations",
    "abstract": "There is a growing interest in modeling and analyzing the spread of diseases\nlike the SARS-CoV-2 infection using stochastic models. These models are\ntypically analyzed quantitatively and are not often subject to validation using\nformal verification approaches, nor leverage policy syntheses and analysis\ntechniques developed in formal verification. In this paper, we take a Markovian\nstochastic model for the spread of a SARSCoV-2-like infection. A state of this\nmodel represents the number of subjects in different health conditions. The\nconsidered model considers the different parameters that may have an impact on\nthe spread of the disease and exposes the various decision variables that can\nbe used to control it. We show that the modeling of the problem within\nstate-of-the-art model checkers is feasible and it opens several opportunities.\nHowever, there are severe limitations due to i) the espressivity of the\nexisting stochastic model checkers on one side, and ii) the size of the\nresulting Markovian model even for small population sizes.",
    "descriptor": "\nComments: Accepted for pubblication in AIxIA 2022\n",
    "authors": [
      "Marco Roveri",
      "Franc Ivankovic",
      "Luigi Palopoli",
      "Daniele Fontanelli"
    ],
    "subjectives": [
      "Populations and Evolution (q-bio.PE)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.00605"
  },
  {
    "id": "arXiv:2211.00617",
    "title": "Convergence of policy gradient methods for finite-horizon stochastic  linear-quadratic control problems",
    "abstract": "We study the global linear convergence of policy gradient (PG) methods for\nfinite-horizon exploratory linear-quadratic control (LQC) problems. The setting\nincludes stochastic LQC problems with indefinite costs and allows additional\nentropy regularisers in the objective. We consider a continuous-time Gaussian\npolicy whose mean is linear in the state variable and whose covariance is\nstate-independent. Contrary to discrete-time problems, the cost is noncoercive\nin the policy and not all descent directions lead to bounded iterates. We\npropose geometry-aware gradient descents for the mean and covariance of the\npolicy using the Fisher geometry and the Bures-Wasserstein geometry,\nrespectively. The policy iterates are shown to satisfy an a-priori bound, and\nconverge globally to the optimal policy with a linear rate. We further propose\na novel PG method with discrete-time policies. The algorithm leverages the\ncontinuous-time analysis, and achieves a robust linear convergence across\ndifferent action frequencies. A numerical experiment confirms the convergence\nand robustness of the proposed algorithm.",
    "descriptor": "\nComments: 2 figures\n",
    "authors": [
      "Michael Giegrich",
      "Christoph Reisinger",
      "Yufei Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00617"
  },
  {
    "id": "arXiv:2211.00625",
    "title": "Machine learning can guide experimental approaches for protein  digestibility estimations",
    "abstract": "Food protein digestibility and bioavailability are critical aspects in\naddressing human nutritional demands, particularly when seeking sustainable\nalternatives to animal-based proteins. In this study, we propose a machine\nlearning approach to predict the true ileal digestibility coefficient of food\nitems. The model makes use of a unique curated dataset that combines\nnutritional information from different foods with FASTA sequences of some of\ntheir protein families. We extracted the biochemical properties of the proteins\nand combined these properties with embeddings from a Transformer-based protein\nLanguage Model (pLM). In addition, we used SHAP to identify features that\ncontribute most to the model prediction and provide interpretability. This\nfirst AI-based model for predicting food protein digestibility has an accuracy\nof 90% compared to existing experimental techniques. With this accuracy, our\nmodel can eliminate the need for lengthy in-vivo or in-vitro experiments,\nmaking the process of creating new foods faster, cheaper, and more ethical.",
    "descriptor": "\nComments: 50 pages, submitted to Nature Food\n",
    "authors": [
      "Sara Malvar",
      "Anvita Bhagavathula",
      "Maria Angels de Luis Balaguer",
      "Swati Sharma",
      "Ranveer Chandra"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00625"
  },
  {
    "id": "arXiv:2211.00627",
    "title": "Discrete Exponential-Family Models for Multivariate Binary Outcomes",
    "abstract": "Studies that collect multi-outcome data such as tobacco and alcohol use are\nbecoming increasingly common. In principle, multi-outcomes studies investigate\nthe correlations between outcomes, including, causal links and/or joint\ndistributions. Although there are many methods for studying multivariate\noutcomes, significant limitations regarding scale and interpretation persist.\nHere we introduce a model based on the exponential-family for discrete binary\noutcomes that provides a flexible framework for hypothesis testing of multiple\nbinary outcomes in a computationally efficient fashion.",
    "descriptor": "",
    "authors": [
      "Vega Yon",
      "George G.",
      "Pugh",
      "Mary Jo",
      "Valente",
      "Thomas W"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Mathematical Software (cs.MS)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.00627"
  },
  {
    "id": "arXiv:1605.03205",
    "title": "Profit-Driven Team Grouping in Social Networks",
    "abstract": "Profit-Driven Team Grouping in Social Networks",
    "descriptor": "",
    "authors": [
      "Shaojie Tang",
      "Jing Yuan",
      "Tao Li",
      "Yao Wang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/1605.03205"
  },
  {
    "id": "arXiv:1611.09569",
    "title": "Server Structure Proposal and Automatic Verification Technology on IaaS  Cloud of Plural Type Servers",
    "abstract": "Comments: Evaluations of server structure proposal were insufficient in section 4",
    "descriptor": "\nComments: Evaluations of server structure proposal were insufficient in section 4\n",
    "authors": [
      "Yoji Yamato"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/1611.09569"
  },
  {
    "id": "arXiv:1711.01490",
    "title": "Analyzing Material Recognition Performance of Thermal Tactile Sensing  using a Large Materials Database and a Real Robot",
    "abstract": "Comments: Published in IEEE ROBIO 2022",
    "descriptor": "\nComments: Published in IEEE ROBIO 2022\n",
    "authors": [
      "Haoping Bai",
      "Haofeng Chen",
      "Elizabeth Healy",
      "Charles C. Kemp",
      "Tapomayukh Bhattacharjee"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/1711.01490"
  },
  {
    "id": "arXiv:1804.04605",
    "title": "Analyzing Use of High Privileges on Android: An Empirical Case Study of  Screenshot and Screen Recording Applications",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Mark Huasong Meng",
      "Guangdong Bai",
      "Joseph K. Liu",
      "Xiapu Luo",
      "Yu Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/1804.04605"
  },
  {
    "id": "arXiv:1906.12304",
    "title": "Statistical Learning from Biased Training Samples",
    "abstract": "Statistical Learning from Biased Training Samples",
    "descriptor": "",
    "authors": [
      "Stephan Cl\u00e9men\u00e7on",
      "Pierre Laforgue"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1906.12304"
  },
  {
    "id": "arXiv:1907.05181",
    "title": "Learning Truthful, Efficient, and Welfare Maximizing Auction Rules",
    "abstract": "Learning Truthful, Efficient, and Welfare Maximizing Auction Rules",
    "descriptor": "",
    "authors": [
      "Andrea Tacchetti",
      "DJ Strouse",
      "Marta Garnelo",
      "Thore Graepel",
      "Yoram Bachrach"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1907.05181"
  },
  {
    "id": "arXiv:1912.12064",
    "title": "Efficient Data Analytics on Augmented Similarity Triplets",
    "abstract": "Comments: Accepted at IEEE International Conference on Big Data (IEEE Big Data) 2022",
    "descriptor": "\nComments: Accepted at IEEE International Conference on Big Data (IEEE Big Data) 2022\n",
    "authors": [
      "Sarwan Ali",
      "Muhammad Ahmad",
      "Umair ul Hassan",
      "Muhammad Asad Khan",
      "Shafiq Alam",
      "Imdadullah Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1912.12064"
  },
  {
    "id": "arXiv:2002.03848",
    "title": "Time Series Alignment with Global Invariances",
    "abstract": "Comments: Published in Transactions on Machine Learning (Oct 2022)",
    "descriptor": "\nComments: Published in Transactions on Machine Learning (Oct 2022)\n",
    "authors": [
      "Titouan Vayer",
      "Romain Tavenard",
      "Laetitia Chapel",
      "Nicolas Courty",
      "R\u00e9mi Flamary",
      "Yann Soullard"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2002.03848"
  },
  {
    "id": "arXiv:2004.05465",
    "title": "Robust Large-Margin Learning in Hyperbolic Space",
    "abstract": "Comments: Revision corrects error in section 3.1",
    "descriptor": "\nComments: Revision corrects error in section 3.1\n",
    "authors": [
      "Melanie Weber",
      "Manzil Zaheer",
      "Ankit Singh Rawat",
      "Aditya Menon",
      "Sanjiv Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.05465"
  },
  {
    "id": "arXiv:2005.03161",
    "title": "MAZE: Data-Free Model Stealing Attack Using Zeroth-Order Gradient  Estimation",
    "abstract": "MAZE: Data-Free Model Stealing Attack Using Zeroth-Order Gradient  Estimation",
    "descriptor": "",
    "authors": [
      "Sanjay Kariyappa",
      "Atul Prakash",
      "Moinuddin Qureshi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2005.03161"
  },
  {
    "id": "arXiv:2006.05956",
    "title": "Gradient Flows for Regularized Stochastic Control Problems",
    "abstract": "Gradient Flows for Regularized Stochastic Control Problems",
    "descriptor": "",
    "authors": [
      "David \u0160i\u0161ka",
      "\u0141ukasz Szpruch"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2006.05956"
  },
  {
    "id": "arXiv:2006.12683",
    "title": "Improving Workflow Integration with xPath: Design and Evaluation of a  Human-AI Diagnosis System in Pathology",
    "abstract": "Comments: 31 pages, 13 figures",
    "descriptor": "\nComments: 31 pages, 13 figures\n",
    "authors": [
      "Hongyan Gu",
      "Yuan Liang",
      "Yifan Xu",
      "Christopher Kazu Williams",
      "Shino Magaki",
      "Negar Khanlou",
      "Harry Vinters",
      "Zesheng Chen",
      "Shuo Ni",
      "Chunxu Yang",
      "Wenzhong Yan",
      "Xinhai Robert Zhang",
      "Yang Li",
      "Mohammad Haeri",
      "Xiang 'Anthony' Chen"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2006.12683"
  },
  {
    "id": "arXiv:2007.01722",
    "title": "Learning Utilities and Equilibria in Non-Truthful Auctions",
    "abstract": "Comments: A previous version of this paper has been accepted to NeurIPS 2020. This version fixes errors and updates references",
    "descriptor": "\nComments: A previous version of this paper has been accepted to NeurIPS 2020. This version fixes errors and updates references\n",
    "authors": [
      "Hu Fu",
      "Tao Lin"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2007.01722"
  },
  {
    "id": "arXiv:2007.06169",
    "title": "An Adversarial Approach to Structural Estimation",
    "abstract": "Comments: 56 pages, 3 tables, 11 figures",
    "descriptor": "\nComments: 56 pages, 3 tables, 11 figures\n",
    "authors": [
      "Tetsuya Kaji",
      "Elena Manresa",
      "Guillaume Pouliot"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.06169"
  },
  {
    "id": "arXiv:2008.08838",
    "title": "Training Matters: Unlocking Potentials of Deeper Graph Convolutional  Neural Networks",
    "abstract": "Training Matters: Unlocking Potentials of Deeper Graph Convolutional  Neural Networks",
    "descriptor": "",
    "authors": [
      "Sitao Luan",
      "Mingde Zhao",
      "Xiao-Wen Chang",
      "Doina Precup"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2008.08838"
  },
  {
    "id": "arXiv:2010.07510",
    "title": "A Human Eye-based Text Color Scheme Generation Method for Image  Synthesis",
    "abstract": "Comments: Accepted by EITCE 2022, No.QJE77JVOLU",
    "descriptor": "\nComments: Accepted by EITCE 2022, No.QJE77JVOLU\n",
    "authors": [
      "Shao Wei Wang",
      "Guan Jie Huang",
      "Xiang Yu Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2010.07510"
  },
  {
    "id": "arXiv:2101.05974",
    "title": "Inductive Representation Learning in Temporal Networks via Causal  Anonymous Walks",
    "abstract": "Comments: Published in ICLR 2021. A bug in previous versions is fixed",
    "descriptor": "\nComments: Published in ICLR 2021. A bug in previous versions is fixed\n",
    "authors": [
      "Yanbang Wang",
      "Yen-Yu Chang",
      "Yunyu Liu",
      "Jure Leskovec",
      "Pan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2101.05974"
  },
  {
    "id": "arXiv:2101.06561",
    "title": "GENIE: Toward Reproducible and Standardized Human Evaluation for Text  Generation",
    "abstract": "Comments: Accepted to EMNLP 2022 main conference, visit our project page at: this https URL",
    "descriptor": "\nComments: Accepted to EMNLP 2022 main conference, visit our project page at: this https URL\n",
    "authors": [
      "Daniel Khashabi",
      "Gabriel Stanovsky",
      "Jonathan Bragg",
      "Nicholas Lourie",
      "Jungo Kasai",
      "Yejin Choi",
      "Noah A. Smith",
      "Daniel S. Weld"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2101.06561"
  },
  {
    "id": "arXiv:2101.09617",
    "title": "A Comprehensive Evaluation Framework for Deep Model Robustness",
    "abstract": "Comments: Submitted to Pattern Recognition",
    "descriptor": "\nComments: Submitted to Pattern Recognition\n",
    "authors": [
      "Jun Guo",
      "Wei Bao",
      "Jiakai Wang",
      "Yuqing Ma",
      "Xinghai Gao",
      "Gang Xiao",
      "Aishan Liu",
      "Jian Dong",
      "Xianglong Liu",
      "Wenjun Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2101.09617"
  },
  {
    "id": "arXiv:2101.12640",
    "title": "Enhancing the Transformer Decoder with Transition-based Syntax",
    "abstract": "Comments: Accepted to CoNLL",
    "descriptor": "\nComments: Accepted to CoNLL\n",
    "authors": [
      "Leshem Choshen",
      "Omri Abend"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.12640"
  },
  {
    "id": "arXiv:2103.12531",
    "title": "CLIP: Cheap Lipschitz Training of Neural Networks",
    "abstract": "Comments: 12 pages, 2 figures, fixed a small mistake in the proof of Proposition 3, published at SSVM 2021",
    "descriptor": "\nComments: 12 pages, 2 figures, fixed a small mistake in the proof of Proposition 3, published at SSVM 2021\n",
    "authors": [
      "Leon Bungert",
      "Ren\u00e9 Raab",
      "Tim Roith",
      "Leo Schwinn",
      "Daniel Tenbrinck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.12531"
  },
  {
    "id": "arXiv:2103.13890",
    "title": "A Multigrid Preconditioner for Jacobian-free Newton-Krylov Methods",
    "abstract": "A Multigrid Preconditioner for Jacobian-free Newton-Krylov Methods",
    "descriptor": "",
    "authors": [
      "Hardik Kothari",
      "Alena Kopani\u010d\u00e1kov\u00e1",
      "Rolf Krause"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.13890"
  },
  {
    "id": "arXiv:2105.07536",
    "title": "Theoretical Foundations of t-SNE for Visualizing High-Dimensional  Clustered Data",
    "abstract": "Comments: Accepted by Journal of Machine Learning Research",
    "descriptor": "\nComments: Accepted by Journal of Machine Learning Research\n",
    "authors": [
      "T. Tony Cai",
      "Rong Ma"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2105.07536"
  },
  {
    "id": "arXiv:2105.13719",
    "title": "On the condition number of the shifted real Ginibre ensemble",
    "abstract": "Comments: 10 pages, 3 figures. Updated references",
    "descriptor": "\nComments: 10 pages, 3 figures. Updated references\n",
    "authors": [
      "Giorgio Cipolloni",
      "L\u00e1szl\u00f3 Erd\u0151s",
      "Dominik Schr\u00f6der"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2105.13719"
  },
  {
    "id": "arXiv:2106.01229",
    "title": "Lower Perplexity is Not Always Human-Like",
    "abstract": "Comments: Accepted by ACL 2021",
    "descriptor": "\nComments: Accepted by ACL 2021\n",
    "authors": [
      "Tatsuki Kuribayashi",
      "Yohei Oseki",
      "Takumi Ito",
      "Ryo Yoshida",
      "Masayuki Asahara",
      "Kentaro Inui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2106.01229"
  },
  {
    "id": "arXiv:2106.02393",
    "title": "Multitask Online Mirror Descent",
    "abstract": "Multitask Online Mirror Descent",
    "descriptor": "",
    "authors": [
      "Nicol\u00f2 Cesa-Bianchi",
      "Pierre Laforgue",
      "Andrea Paudice",
      "Massimiliano Pontil"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02393"
  },
  {
    "id": "arXiv:2106.10771",
    "title": "Multirate Training of Neural Networks",
    "abstract": "Comments: Appeared in ICML 2022 (errata added on 19 Oct., 2022)",
    "descriptor": "\nComments: Appeared in ICML 2022 (errata added on 19 Oct., 2022)\n",
    "authors": [
      "Tiffany Vlaar",
      "Benedict Leimkuhler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10771"
  },
  {
    "id": "arXiv:2106.11178",
    "title": "Thou Shalt Covet The Average Of Thy Neighbors' Cakes",
    "abstract": "Thou Shalt Covet The Average Of Thy Neighbors' Cakes",
    "descriptor": "",
    "authors": [
      "Jamie Tucker-Foltz"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2106.11178"
  },
  {
    "id": "arXiv:2107.03799",
    "title": "Contrastive Learning for Robust Android Malware Familial Classification",
    "abstract": "Contrastive Learning for Robust Android Malware Familial Classification",
    "descriptor": "",
    "authors": [
      "Yueming Wu",
      "Shihan Dou",
      "Deqing Zou",
      "Wei Yang",
      "Weizhong Qiang",
      "Hai Jin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2107.03799"
  },
  {
    "id": "arXiv:2107.07246",
    "title": "Estimation of spatially varying parameters with application to  hyperbolic SPDEs",
    "abstract": "Estimation of spatially varying parameters with application to  hyperbolic SPDEs",
    "descriptor": "",
    "authors": [
      "David Angwenyi"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.07246"
  },
  {
    "id": "arXiv:2108.13836",
    "title": "Explainable AI for engineering design: A unified approach of systems  engineering and component-based deep learning",
    "abstract": "Comments: 17 pages",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Philipp Geyer",
      "Manav Mahan Singh",
      "Xia Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.13836"
  },
  {
    "id": "arXiv:2109.02357",
    "title": "Fighting Selection Bias in Statistical Learning: Application to Visual  Recognition from Biased Image Databases",
    "abstract": "Fighting Selection Bias in Statistical Learning: Application to Visual  Recognition from Biased Image Databases",
    "descriptor": "",
    "authors": [
      "Stephan Cl\u00e9men\u00e7on",
      "Pierre Laforgue",
      "Robin Vogel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.02357"
  },
  {
    "id": "arXiv:2109.11078",
    "title": "IE-GAN: An Improved Evolutionary Generative Adversarial Network Using a  New Fitness Function and a Generic Crossover Operator",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2101.11186",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2101.11186\n",
    "authors": [
      "Junjie Li",
      "Jingyao Li",
      "Wenbo Zhou",
      "Shuai L\u00fc"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.11078"
  },
  {
    "id": "arXiv:2110.00620",
    "title": "SPEC: Seeing People in the Wild with an Estimated Camera",
    "abstract": "SPEC: Seeing People in the Wild with an Estimated Camera",
    "descriptor": "",
    "authors": [
      "Muhammed Kocabas",
      "Chun-Hao P. Huang",
      "Joachim Tesch",
      "Lea M\u00fcller",
      "Otmar Hilliges",
      "Michael J. Black"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.00620"
  },
  {
    "id": "arXiv:2110.06741",
    "title": "Dynamical Wasserstein Barycenters for Time-series Modeling",
    "abstract": "Comments: To appear at Neurips 2021",
    "descriptor": "\nComments: To appear at Neurips 2021\n",
    "authors": [
      "Kevin C. Cheng",
      "Shuchin Aeron",
      "Michael C. Hughes",
      "Eric L. Miller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06741"
  },
  {
    "id": "arXiv:2110.08412",
    "title": "Evaluating the Faithfulness of Importance Measures in NLP by Recursively  Masking Allegedly Important Tokens and Retraining",
    "abstract": "Evaluating the Faithfulness of Importance Measures in NLP by Recursively  Masking Allegedly Important Tokens and Retraining",
    "descriptor": "",
    "authors": [
      "Andreas Madsen",
      "Nicholas Meade",
      "Vaibhav Adlakha",
      "Siva Reddy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08412"
  },
  {
    "id": "arXiv:2111.00528",
    "title": "Calibrating the Dice loss to handle neural network overconfidence for  biomedical image segmentation",
    "abstract": "Calibrating the Dice loss to handle neural network overconfidence for  biomedical image segmentation",
    "descriptor": "",
    "authors": [
      "Michael Yeung",
      "Leonardo Rundo",
      "Yang Nan",
      "Evis Sala",
      "Carola-Bibiane Sch\u00f6nlieb",
      "Guang Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.00528"
  },
  {
    "id": "arXiv:2111.00607",
    "title": "A Systematic Investigation of Commonsense Knowledge in Large Language  Models",
    "abstract": "Comments: Accepted to EMNLP 2022",
    "descriptor": "\nComments: Accepted to EMNLP 2022\n",
    "authors": [
      "Xiang Lorraine Li",
      "Adhiguna Kuncoro",
      "Jordan Hoffmann",
      "Cyprien de Masson d'Autume",
      "Phil Blunsom",
      "Aida Nematzadeh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.00607"
  },
  {
    "id": "arXiv:2111.09050",
    "title": "Multi-Mobile Robot Localization and Navigation based on Visible Light  Positioning",
    "abstract": "Multi-Mobile Robot Localization and Navigation based on Visible Light  Positioning",
    "descriptor": "",
    "authors": [
      "Yanyi Chen",
      "Zhiqing Zhong",
      "Shangsheng Wen",
      "Weipeng Guan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.09050"
  },
  {
    "id": "arXiv:2111.13219",
    "title": "Differentially private stochastic expectation propagation (DP-SEP)",
    "abstract": "Differentially private stochastic expectation propagation (DP-SEP)",
    "descriptor": "",
    "authors": [
      "Margarita Vinaroz",
      "Mijung Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.13219"
  },
  {
    "id": "arXiv:2111.15414",
    "title": "Neuron with Steady Response Leads to Better Generalization",
    "abstract": "Comments: Accepted by NeurIPS'22",
    "descriptor": "\nComments: Accepted by NeurIPS'22\n",
    "authors": [
      "Qiang Fu",
      "Lun Du",
      "Haitao Mao",
      "Xu Chen",
      "Wei Fang",
      "Shi Han",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.15414"
  },
  {
    "id": "arXiv:2112.05106",
    "title": "Estimating the Longest Increasing Subsequence in Nearly Optimal Time",
    "abstract": "Comments: Full version of FOCS 2022 paper",
    "descriptor": "\nComments: Full version of FOCS 2022 paper\n",
    "authors": [
      "Alexandr Andoni",
      "Negev Shekel Nosatzki",
      "Sandip Sinha",
      "Clifford Stein"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.05106"
  },
  {
    "id": "arXiv:2112.05125",
    "title": "Rethinking the Authorship Verification Experimental Setups",
    "abstract": "Comments: Accepted as a short paper at the EMNLP 2022 conference. 10 pages, 5 figures, 9 tables",
    "descriptor": "\nComments: Accepted as a short paper at the EMNLP 2022 conference. 10 pages, 5 figures, 9 tables\n",
    "authors": [
      "Florin Brad",
      "Andrei Manolache",
      "Elena Burceanu",
      "Antonio Barbalau",
      "Radu Ionescu",
      "Marius Popescu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2112.05125"
  },
  {
    "id": "arXiv:2112.07144",
    "title": "GEO-BLEU: Similarity Measure for Geospatial Sequences",
    "abstract": "GEO-BLEU: Similarity Measure for Geospatial Sequences",
    "descriptor": "",
    "authors": [
      "Toru Shimizu",
      "Kota Tsubouchi",
      "Takahiro Yabe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.07144"
  },
  {
    "id": "arXiv:2112.13747",
    "title": "Modeling Occasion Evolution in Frequency Domain for Promotion-Aware  Click-Through Rate Prediction",
    "abstract": "Modeling Occasion Evolution in Frequency Domain for Promotion-Aware  Click-Through Rate Prediction",
    "descriptor": "",
    "authors": [
      "Xiaofeng Pan",
      "Yibin Shen",
      "Jing Zhang",
      "Xu He",
      "Yang Huang",
      "Hong Wen",
      "Chengjun Mao",
      "Bo Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.13747"
  },
  {
    "id": "arXiv:2201.00818",
    "title": "Graph Neural Networks for Multivariate Time Series Regression with  Application to Seismic Data",
    "abstract": "Comments: 18 pages, LaTeX; final revision; published in: International Journal of Data Science and Analytics, pages 1-16, 2022",
    "descriptor": "\nComments: 18 pages, LaTeX; final revision; published in: International Journal of Data Science and Analytics, pages 1-16, 2022\n",
    "authors": [
      "Stefan Bloemheuvel",
      "Jurgen van den Hoogen",
      "Dario Jozinovi\u0107",
      "Alberto Michelini",
      "Martin Atzmueller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.00818"
  },
  {
    "id": "arXiv:2201.03064",
    "title": "Stability Based Generalization Bounds for Exponential Family Langevin  Dynamics",
    "abstract": "Stability Based Generalization Bounds for Exponential Family Langevin  Dynamics",
    "descriptor": "",
    "authors": [
      "Arindam Banerjee",
      "Tiancong Chen",
      "Xinyan Li",
      "Yingxue Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.03064"
  },
  {
    "id": "arXiv:2201.04868",
    "title": "Interactive Data Analysis with Next-step Natural Language Query  Recommendation",
    "abstract": "Comments: 14 pages, 6 figures",
    "descriptor": "\nComments: 14 pages, 6 figures\n",
    "authors": [
      "Xingbo Wang",
      "Furui Cheng",
      "Yong Wang",
      "Ke Xu",
      "Jiang Long",
      "Hong Lu",
      "Huamin Qu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2201.04868"
  },
  {
    "id": "arXiv:2201.10439",
    "title": "Transformer-Based Video Front-Ends for Audio-Visual Speech Recognition  for Single and Multi-Person Video",
    "abstract": "Comments: 5 pages, 3 figures, published at Interspeech 2022",
    "descriptor": "\nComments: 5 pages, 3 figures, published at Interspeech 2022\n",
    "authors": [
      "Dmitriy Serdyuk",
      "Otavio Braga",
      "Olivier Siohan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2201.10439"
  },
  {
    "id": "arXiv:2201.11917",
    "title": "Task-Aware Network Coding Over Butterfly Network",
    "abstract": "Task-Aware Network Coding Over Butterfly Network",
    "descriptor": "",
    "authors": [
      "Jiangnan Cheng",
      "Sandeep Chinchali",
      "Ao Tang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11917"
  },
  {
    "id": "arXiv:2202.07262",
    "title": "Stochastic Gradient Descent-Ascent: Unified Theory and New Efficient  Methods",
    "abstract": "Comments: 72 pages, 4 figures, 3 tables. Changes in v2: new results were added (Theorem 2.5 and its corollaries), few typos were fixed, more clarifications were added. Code: this https URL",
    "descriptor": "\nComments: 72 pages, 4 figures, 3 tables. Changes in v2: new results were added (Theorem 2.5 and its corollaries), few typos were fixed, more clarifications were added. Code: this https URL\n",
    "authors": [
      "Aleksandr Beznosikov",
      "Eduard Gorbunov",
      "Hugo Berard",
      "Nicolas Loizou"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07262"
  },
  {
    "id": "arXiv:2203.01261",
    "title": "TAE: A Semi-supervised Controllable Behavior-aware Trajectory Generator  and Predictor",
    "abstract": "Comments: an updated version, change figures and references. 8 pages, robotics conference, about trajectory augmentation and prediction for intelligent vehicle systems",
    "descriptor": "\nComments: an updated version, change figures and references. 8 pages, robotics conference, about trajectory augmentation and prediction for intelligent vehicle systems\n",
    "authors": [
      "Ruochen Jiao",
      "Xiangguo Liu",
      "Bowen Zheng",
      "Dave Liang",
      "Qi Zhu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.01261"
  },
  {
    "id": "arXiv:2203.03668",
    "title": "A Typology to Explore the Mitigation of Shortcut Behavior",
    "abstract": "A Typology to Explore the Mitigation of Shortcut Behavior",
    "descriptor": "",
    "authors": [
      "Felix Friedrich",
      "Wolfgang Stammer",
      "Patrick Schramowski",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2203.03668"
  },
  {
    "id": "arXiv:2203.11926",
    "title": "Focal Modulation Networks",
    "abstract": "Comments: NeurIPS 2022 camera-ready extension",
    "descriptor": "\nComments: NeurIPS 2022 camera-ready extension\n",
    "authors": [
      "Jianwei Yang",
      "Chunyuan Li",
      "Xiyang Dai",
      "Lu Yuan",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11926"
  },
  {
    "id": "arXiv:2203.16794",
    "title": "Speech Emotion Recognition using Multi-task learning and a multimodal  dynamic fusion network",
    "abstract": "Comments: 6 + 2 pages",
    "descriptor": "\nComments: 6 + 2 pages\n",
    "authors": [
      "Sreyan Ghosh",
      "S Ramaneswaran",
      "Harshvardhan Srivastava",
      "S. Umesh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16794"
  },
  {
    "id": "arXiv:2203.17149",
    "title": "AEGNN: Asynchronous Event-based Graph Neural Networks",
    "abstract": "Comments: IEEE Conference on Computer Vision and Pattern Recognition (CVPR), New Orleans, 2022",
    "descriptor": "\nComments: IEEE Conference on Computer Vision and Pattern Recognition (CVPR), New Orleans, 2022\n",
    "authors": [
      "Simon Schaefer",
      "Daniel Gehrig",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.17149"
  },
  {
    "id": "arXiv:2204.00783",
    "title": "Supervised Robustness-preserving Data-free Neural Network Pruning",
    "abstract": "Supervised Robustness-preserving Data-free Neural Network Pruning",
    "descriptor": "",
    "authors": [
      "Mark Huasong Meng",
      "Guangdong Bai",
      "Sin Gee Teo",
      "Jin Song Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.00783"
  },
  {
    "id": "arXiv:2204.06422",
    "title": "Electric Motor Design Optimization: A Convex Surrogate Modeling Approach",
    "abstract": "Comments: 6 pages, 5 figures, final submission for the 10th IFAC Symposium on Advances in Automotive Control, 2022",
    "descriptor": "\nComments: 6 pages, 5 figures, final submission for the 10th IFAC Symposium on Advances in Automotive Control, 2022\n",
    "authors": [
      "Olaf Borsboom",
      "Mauro Salazar",
      "Theo Hofman"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.06422"
  },
  {
    "id": "arXiv:2204.07447",
    "title": "Stretching Sentence-pair NLI Models to Reason over Long Documents and  Clusters",
    "abstract": "Comments: Findings of EMNLP 2022",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Tal Schuster",
      "Sihao Chen",
      "Senaka Buthpitiya",
      "Alex Fabrikant",
      "Donald Metzler"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.07447"
  },
  {
    "id": "arXiv:2204.07628",
    "title": "On annular short-time stability conditions for generalized Persidskii  systems",
    "abstract": "On annular short-time stability conditions for generalized Persidskii  systems",
    "descriptor": "",
    "authors": [
      "Wenjie Mei",
      "Denis Efimov",
      "Rosane Ushirobira"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.07628"
  },
  {
    "id": "arXiv:2204.07693",
    "title": "Calibrating Trust of Multi-Hop Question Answering Systems with  Decompositional Probes",
    "abstract": "Comments: Accepted to EMNLP 2022 Findings",
    "descriptor": "\nComments: Accepted to EMNLP 2022 Findings\n",
    "authors": [
      "Kaige Xie",
      "Sarah Wiegreffe",
      "Mark Riedl"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.07693"
  },
  {
    "id": "arXiv:2204.11454",
    "title": "Natural Language to Code Translation with Execution",
    "abstract": "Comments: EMNLP 2022",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Freda Shi",
      "Daniel Fried",
      "Marjan Ghazvininejad",
      "Luke Zettlemoyer",
      "Sida I. Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2204.11454"
  },
  {
    "id": "arXiv:2205.02357",
    "title": "Hybrid Transformer with Multi-level Fusion for Multimodal Knowledge  Graph Completion",
    "abstract": "Comments: Accepted by SIGIR 2022. Fix a severe bug",
    "descriptor": "\nComments: Accepted by SIGIR 2022. Fix a severe bug\n",
    "authors": [
      "Xiang Chen",
      "Ningyu Zhang",
      "Lei Li",
      "Shumin Deng",
      "Chuanqi Tan",
      "Changliang Xu",
      "Fei Huang",
      "Luo Si",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.02357"
  },
  {
    "id": "arXiv:2205.06938",
    "title": "Generating Literal and Implied Subquestions to Fact-check Complex Claims",
    "abstract": "Generating Literal and Implied Subquestions to Fact-check Complex Claims",
    "descriptor": "",
    "authors": [
      "Jifan Chen",
      "Aniruddh Sriram",
      "Eunsol Choi",
      "Greg Durrett"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.06938"
  },
  {
    "id": "arXiv:2205.07728",
    "title": "Robust-RRT: Probabilistically-Complete Motion Planning for Uncertain  Nonlinear Systems",
    "abstract": "Comments: 16 pages of main text + 5 pages of appendix, 5 figures, submitted to the 2022 International Symposium on Robotics Research",
    "descriptor": "\nComments: 16 pages of main text + 5 pages of appendix, 5 figures, submitted to the 2022 International Symposium on Robotics Research\n",
    "authors": [
      "Albert Wu",
      "Thomas Lew",
      "Kiril Solovey",
      "Edward Schmerling",
      "Marco Pavone"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.07728"
  },
  {
    "id": "arXiv:2205.09315",
    "title": "A Sub-pixel Accurate Quantification of Joint Space Narrowing Progression  in Rheumatoid Arthritis",
    "abstract": "A Sub-pixel Accurate Quantification of Joint Space Narrowing Progression  in Rheumatoid Arthritis",
    "descriptor": "",
    "authors": [
      "Yafei Ou",
      "Prasoon Ambalathankandy",
      "Ryunosuke Furuya",
      "Seiya Kawada",
      "Tianyu Zeng",
      "Yujie An",
      "Tamotsu Kamishima",
      "Kenichi Tamura",
      "Masayuki Ikebe"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.09315"
  },
  {
    "id": "arXiv:2205.10309",
    "title": "A Fully Implicit Method for Robust Frictional Contact Handling in  Elastic Rods",
    "abstract": "Comments: * Equal contribution. A video summarizing this work is available on YouTube: this https URL",
    "descriptor": "\nComments: * Equal contribution. A video summarizing this work is available on YouTube: this https URL\n",
    "authors": [
      "Dezhong Tong",
      "Andrew Choi",
      "Jungseock Joo",
      "M. Khalid Jawed"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2205.10309"
  },
  {
    "id": "arXiv:2205.10489",
    "title": "Social Fragmentation Transitions in Large-Scale Parameter Sweep  Simulations of Adaptive Social Networks",
    "abstract": "Comments: 11 pages, 4 figures; to appear in the Proceedings of the 14th International Conference on Parallel Processing and Applied Mathematics (PPAM 2022), Springer, in press",
    "descriptor": "\nComments: 11 pages, 4 figures; to appear in the Proceedings of the 14th International Conference on Parallel Processing and Applied Mathematics (PPAM 2022), Springer, in press\n",
    "authors": [
      "Hiroki Sayama"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2205.10489"
  },
  {
    "id": "arXiv:2205.11463",
    "title": "Context Limitations Make Neural Language Models More Human-Like",
    "abstract": "Comments: Accepted by EMNLP2022 (main long)",
    "descriptor": "\nComments: Accepted by EMNLP2022 (main long)\n",
    "authors": [
      "Tatsuki Kuribayashi",
      "Yohei Oseki",
      "Ana Brassard",
      "Kentaro Inui"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11463"
  },
  {
    "id": "arXiv:2205.12533",
    "title": "Structured Uncertainty in the Observation Space of Variational  Autoencoders",
    "abstract": "Comments: Published in Transactions on Machine Learning Research (10/2022). Code available on this https URL",
    "descriptor": "\nComments: Published in Transactions on Machine Learning Research (10/2022). Code available on this https URL\n",
    "authors": [
      "James Langley",
      "Miguel Monteiro",
      "Charles Jones",
      "Nick Pawlowski",
      "Ben Glocker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.12533"
  },
  {
    "id": "arXiv:2205.12910",
    "title": "NaturalProver: Grounded Mathematical Proof Generation with Language  Models",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Sean Welleck",
      "Jiacheng Liu",
      "Ximing Lu",
      "Hannaneh Hajishirzi",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.12910"
  },
  {
    "id": "arXiv:2205.14317",
    "title": "A Confidence Machine for Sparse High-Order Interaction Model",
    "abstract": "A Confidence Machine for Sparse High-Order Interaction Model",
    "descriptor": "",
    "authors": [
      "Diptesh Das",
      "Eugene Ndiaye",
      "Ichiro Takeuchi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14317"
  },
  {
    "id": "arXiv:2205.15031",
    "title": "Neural Copula: A unified framework for estimating generic  high-dimensional Copula functions",
    "abstract": "Neural Copula: A unified framework for estimating generic  high-dimensional Copula functions",
    "descriptor": "",
    "authors": [
      "Zhi Zeng",
      "Ting Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.15031"
  },
  {
    "id": "arXiv:2206.01095",
    "title": "Clipped Stochastic Methods for Variational Inequalities with  Heavy-Tailed Noise",
    "abstract": "Comments: NeurIPS 2022. 74 pages, 18 figures. Changes in v2: few typos were fixed, new experiments with clipped-SEG were added. Code: this https URL",
    "descriptor": "\nComments: NeurIPS 2022. 74 pages, 18 figures. Changes in v2: few typos were fixed, new experiments with clipped-SEG were added. Code: this https URL\n",
    "authors": [
      "Eduard Gorbunov",
      "Marina Danilova",
      "David Dobre",
      "Pavel Dvurechensky",
      "Alexander Gasnikov",
      "Gauthier Gidel"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01095"
  },
  {
    "id": "arXiv:2206.02010",
    "title": "Variational regularization with oversmoothing penalty term in Banach  spaces",
    "abstract": "Variational regularization with oversmoothing penalty term in Banach  spaces",
    "descriptor": "",
    "authors": [
      "Robert Plato",
      "Bernd Hofmann"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.02010"
  },
  {
    "id": "arXiv:2206.02072",
    "title": "Deciding What to Model: Value-Equivalent Sampling for Reinforcement  Learning",
    "abstract": "Comments: Accepted to Neural Information Processing Systems (NeurIPS) 2022",
    "descriptor": "\nComments: Accepted to Neural Information Processing Systems (NeurIPS) 2022\n",
    "authors": [
      "Dilip Arumugam",
      "Benjamin Van Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.02072"
  },
  {
    "id": "arXiv:2206.02902",
    "title": "Goal-Space Planning with Subgoal Models",
    "abstract": "Goal-Space Planning with Subgoal Models",
    "descriptor": "",
    "authors": [
      "Chunlok Lo",
      "Gabor Mihucz",
      "Adam White",
      "Farzane Aminmansour",
      "Martha White"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.02902"
  },
  {
    "id": "arXiv:2206.03230",
    "title": "Shedding a PAC-Bayesian Light on Adaptive Sliced-Wasserstein Distances",
    "abstract": "Shedding a PAC-Bayesian Light on Adaptive Sliced-Wasserstein Distances",
    "descriptor": "",
    "authors": [
      "Ruben Ohana",
      "Kimia Nadjahi",
      "Alain Rakotomamonjy",
      "Liva Ralaivola"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03230"
  },
  {
    "id": "arXiv:2206.03956",
    "title": "The number of small-degree vertices in matchstick graphs",
    "abstract": "The number of small-degree vertices in matchstick graphs",
    "descriptor": "",
    "authors": [
      "J\u00e9r\u00e9my Lavoll\u00e9e",
      "Konrad J. Swanepoel"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2206.03956"
  },
  {
    "id": "arXiv:2206.05066",
    "title": "Experimental Evaluation of Visual-Inertial Odometry Systems for Arable  Farming",
    "abstract": "Comments: This paper has been accepted for publication in Journal of Field Robotics",
    "descriptor": "\nComments: This paper has been accepted for publication in Journal of Field Robotics\n",
    "authors": [
      "Javier Cremona",
      "Rom\u00e1n Comelli",
      "Taih\u00fa Pire"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.05066"
  },
  {
    "id": "arXiv:2206.08514",
    "title": "A Unified Evaluation of Textual Backdoor Learning: Frameworks and  Benchmarks",
    "abstract": "Comments: NeurIPS 2022 Datasets & Benchmarks; Toolkits avaliable at this https URL",
    "descriptor": "\nComments: NeurIPS 2022 Datasets & Benchmarks; Toolkits avaliable at this https URL\n",
    "authors": [
      "Ganqu Cui",
      "Lifan Yuan",
      "Bingxiang He",
      "Yangyi Chen",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.08514"
  },
  {
    "id": "arXiv:2206.08920",
    "title": "VectorMapNet: End-to-end Vectorized HD Map Learning",
    "abstract": "VectorMapNet: End-to-end Vectorized HD Map Learning",
    "descriptor": "",
    "authors": [
      "Yicheng Liu",
      "Yuantian Tuan",
      "Yue Wang",
      "Yilun Wang",
      "Hang Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.08920"
  },
  {
    "id": "arXiv:2206.09103",
    "title": "Identifying Source Speakers for Voice Conversion based Spoofing Attacks  on Speaker Verification Systems",
    "abstract": "Identifying Source Speakers for Voice Conversion based Spoofing Attacks  on Speaker Verification Systems",
    "descriptor": "",
    "authors": [
      "Danwei Cai",
      "Zexin Cai",
      "Ming Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.09103"
  },
  {
    "id": "arXiv:2206.09557",
    "title": "nuQmm: Quantized MatMul for Efficient Inference of Large-Scale  Generative Language Models",
    "abstract": "Comments: 15 pages (including 5 pages of References & Appendix), 14 figures, 7 tables",
    "descriptor": "\nComments: 15 pages (including 5 pages of References & Appendix), 14 figures, 7 tables\n",
    "authors": [
      "Gunho Park",
      "Baeseong Park",
      "Sungjae Lee",
      "Minsub Kim",
      "Byeongwook Kim",
      "Se Jung Kwon",
      "Youngjoo Lee",
      "Dongsoo Lee"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2206.09557"
  },
  {
    "id": "arXiv:2206.10898",
    "title": "Q-rMinRank attack: The first quantum approach for key recovery attacks  on Rainbow",
    "abstract": "Comments: The paper has been withdrawn because the research work is still in progress",
    "descriptor": "\nComments: The paper has been withdrawn because the research work is still in progress\n",
    "authors": [
      "Seong-Min Cho",
      "Seung-Hyun Seo"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.10898"
  },
  {
    "id": "arXiv:2206.11253",
    "title": "Towards Robust Blind Face Restoration with Codebook Lookup Transformer",
    "abstract": "Comments: Accepted by NeurIPS 2022. Code: this https URL",
    "descriptor": "\nComments: Accepted by NeurIPS 2022. Code: this https URL\n",
    "authors": [
      "Shangchen Zhou",
      "Kelvin C.K. Chan",
      "Chongyi Li",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.11253"
  },
  {
    "id": "arXiv:2206.12395",
    "title": "Data Leakage in Federated Averaging",
    "abstract": "Data Leakage in Federated Averaging",
    "descriptor": "",
    "authors": [
      "Dimitar I. Dimitrov",
      "Mislav Balunovi\u0107",
      "Nikola Konstantinov",
      "Martin Vechev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.12395"
  },
  {
    "id": "arXiv:2206.14359",
    "title": "TE2Rules: Extracting Rule Lists from Tree Ensembles",
    "abstract": "TE2Rules: Extracting Rule Lists from Tree Ensembles",
    "descriptor": "",
    "authors": [
      "G Roshan Lal",
      "Xiaotong Chen",
      "Varun Mithal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14359"
  },
  {
    "id": "arXiv:2207.02286",
    "title": "Cooperative Distribution Alignment via JSD Upper Bound",
    "abstract": "Comments: Accepted for publication in Advances in Neural Information Processing Systems 36 (NeurIPS 2022)",
    "descriptor": "\nComments: Accepted for publication in Advances in Neural Information Processing Systems 36 (NeurIPS 2022)\n",
    "authors": [
      "Wonwoong Cho",
      "Ziyu Gong",
      "David I. Inouye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.02286"
  },
  {
    "id": "arXiv:2207.03046",
    "title": "Self-Supervised RF Signal Representation Learning for NextG Signal  Classification with Deep Learning",
    "abstract": "Comments: 5 pages, 3 figures, 3 tables",
    "descriptor": "\nComments: 5 pages, 3 figures, 3 tables\n",
    "authors": [
      "Kemal Davaslioglu",
      "Serdar Boztas",
      "Mehmet Can Ertem",
      "Yalin E. Sagduyu",
      "Ender Ayanoglu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.03046"
  },
  {
    "id": "arXiv:2207.03477",
    "title": "VeriDark: A Large-Scale Benchmark for Authorship Verification on the  Dark Web",
    "abstract": "Comments: Accepted at the 36th Conference on Neural Information Processing Systems (NeurIPS 2022) Track on Datasets and Benchmarks. 21 pages, 4 figures, 11 tables",
    "descriptor": "\nComments: Accepted at the 36th Conference on Neural Information Processing Systems (NeurIPS 2022) Track on Datasets and Benchmarks. 21 pages, 4 figures, 11 tables\n",
    "authors": [
      "Andrei Manolache",
      "Florin Brad",
      "Antonio Barbalau",
      "Radu Tudor Ionescu",
      "Marius Popescu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2207.03477"
  },
  {
    "id": "arXiv:2207.04027",
    "title": "A Multi-tasking Model of Speaker-Keyword Classification for Keeping  Human in the Loop of Drone-assisted Inspection",
    "abstract": "Comments: Accepted by Engineering Applications of Artificial Intelligence journal on Oct 31th. Upload the accepted clean version",
    "descriptor": "\nComments: Accepted by Engineering Applications of Artificial Intelligence journal on Oct 31th. Upload the accepted clean version\n",
    "authors": [
      "Yu Li",
      "Anisha Parsan",
      "Bill Wang",
      "Penghao Dong",
      "Shanshan Yao",
      "Ruwen Qin"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2207.04027"
  },
  {
    "id": "arXiv:2207.04044",
    "title": "k-means Mask Transformer",
    "abstract": "Comments: ECCV 2022. arXiv v2: add results on ADE20K. arXiv v3: fix appendix. Codes and models are available at this https URL",
    "descriptor": "\nComments: ECCV 2022. arXiv v2: add results on ADE20K. arXiv v3: fix appendix. Codes and models are available at this https URL\n",
    "authors": [
      "Qihang Yu",
      "Huiyu Wang",
      "Siyuan Qiao",
      "Maxwell Collins",
      "Yukun Zhu",
      "Hartwig Adam",
      "Alan Yuille",
      "Liang-Chieh Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.04044"
  },
  {
    "id": "arXiv:2208.01238",
    "title": "Dynamic modeling of a sliding ring on an elastic rod with incremental  potential formulation",
    "abstract": "Comments: 15 pages, 9 figures",
    "descriptor": "\nComments: 15 pages, 9 figures\n",
    "authors": [
      "Weicheng Huang",
      "Peifei Xu",
      "Huaiwu Zou",
      "Hanwu Liu",
      "Wenmiao Yang",
      "Zhaowei Liu"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2208.01238"
  },
  {
    "id": "arXiv:2208.01619",
    "title": "On the Age of Status Updates in Unreliable Multi-Source M/G/1 Queueing  Systems",
    "abstract": "Comments: 5 pages, 6 figures, journal",
    "descriptor": "\nComments: 5 pages, 6 figures, journal\n",
    "authors": [
      "Muthukrishnan Senthil Kumar",
      "Aresh Dadlani",
      "Masoumeh Moradian",
      "Ahmad Khonsari",
      "Theodoros A. Tsiftsis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2208.01619"
  },
  {
    "id": "arXiv:2208.01721",
    "title": "Rumor Stance Classification in Online Social Networks: The  State-of-the-Art, Prospects, and Future Challenges",
    "abstract": "Comments: 16 pages, 3 figures, journal",
    "descriptor": "\nComments: 16 pages, 3 figures, journal\n",
    "authors": [
      "Sarina Jami",
      "Iman Sahebi",
      "Mohammad M. Sabermahani",
      "Seyed P. Shariatpanahi",
      "Aresh Dadlani",
      "Behrouz Maham"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2208.01721"
  },
  {
    "id": "arXiv:2208.07541",
    "title": "Social Interactions for Autonomous Driving: A Review and Perspectives",
    "abstract": "Comments: 183 pages, 36 figures",
    "descriptor": "\nComments: 183 pages, 36 figures\n",
    "authors": [
      "Wenshuo Wang",
      "Letian Wang",
      "Chengyuan Zhang",
      "Changliu Liu",
      "Lijun Sun"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2208.07541"
  },
  {
    "id": "arXiv:2208.10449",
    "title": "SCONE: Surface Coverage Optimization in Unknown Environments by  Volumetric Integration",
    "abstract": "Comments: NeurIPS 2022 Camera-Ready. Project Webpage: this https URL",
    "descriptor": "\nComments: NeurIPS 2022 Camera-Ready. Project Webpage: this https URL\n",
    "authors": [
      "Antoine Gu\u00e9don",
      "Pascal Monasse",
      "Vincent Lepetit"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.10449"
  },
  {
    "id": "arXiv:2208.10848",
    "title": "How to train your solver: Verification of boundary conditions for  smoothed particle hydrodynamics",
    "abstract": "How to train your solver: Verification of boundary conditions for  smoothed particle hydrodynamics",
    "descriptor": "",
    "authors": [
      "Pawan Negi",
      "Prabhu Ramachandran"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2208.10848"
  },
  {
    "id": "arXiv:2208.13070",
    "title": "Self-Supervised Face Presentation Attack Detection with Dynamic  Grayscale Snippets",
    "abstract": "Self-Supervised Face Presentation Attack Detection with Dynamic  Grayscale Snippets",
    "descriptor": "",
    "authors": [
      "Usman Muhammad",
      "Mourad Oussalah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.13070"
  },
  {
    "id": "arXiv:2208.13426",
    "title": "Will you infect me with your opinion?",
    "abstract": "Comments: 19 pages, 4 figures, accepted version, source code and simulation scripts available at this https URL",
    "descriptor": "\nComments: 19 pages, 4 figures, accepted version, source code and simulation scripts available at this https URL\n",
    "authors": [
      "Krzysztof Domino",
      "Jaros\u0142aw Adam Miszczak"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2208.13426"
  },
  {
    "id": "arXiv:2208.13723",
    "title": "Bayesian Continual Learning via Spiking Neural Networks",
    "abstract": "Comments: Accepted for publication in Frontiers in Computational Neuroscience",
    "descriptor": "\nComments: Accepted for publication in Frontiers in Computational Neuroscience\n",
    "authors": [
      "Nicolas Skatchkovsky",
      "Hyeryung Jang",
      "Osvaldo Simeone"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.13723"
  },
  {
    "id": "arXiv:2209.00107",
    "title": "Equivalence of SS-based MPC and ARX-based MPC",
    "abstract": "Comments: 8 pages, 4 figures",
    "descriptor": "\nComments: 8 pages, 4 figures\n",
    "authors": [
      "Liang Wu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.00107"
  },
  {
    "id": "arXiv:2209.01083",
    "title": "When Bioprocess Engineering Meets Machine Learning: A Survey from the  Perspective of Automated Bioprocess Development",
    "abstract": "When Bioprocess Engineering Meets Machine Learning: A Survey from the  Perspective of Automated Bioprocess Development",
    "descriptor": "",
    "authors": [
      "Nghia Duong-Trung",
      "Stefan Born",
      "Jong Woo Kim",
      "Marie-Therese Schermeyer",
      "Katharina Paulick",
      "Maxim Borisyak",
      "Mariano Nicolas Cruz-Bournazou",
      "Thorben Werner",
      "Randolf Scholz",
      "Lars Schmidt-Thieme",
      "Peter Neubauer",
      "Ernesto Martinez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.01083"
  },
  {
    "id": "arXiv:2209.01515",
    "title": "Do Large Language Models know what humans know?",
    "abstract": "Do Large Language Models know what humans know?",
    "descriptor": "",
    "authors": [
      "Sean Trott",
      "Cameron Jones",
      "Tyler Chang",
      "James Michaelov",
      "Benjamin Bergen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.01515"
  },
  {
    "id": "arXiv:2209.04113",
    "title": "Robust and Lossless Fingerprinting of Deep Neural Networks via Pooled  Membership Inference",
    "abstract": "Comments: this https URL&hl=en",
    "descriptor": "\nComments: this https URL&hl=en\n",
    "authors": [
      "Hanzhou Wu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.04113"
  },
  {
    "id": "arXiv:2209.04334",
    "title": "Design of a Supervisory Control System for Autonomous Operation of  Advanced Reactors",
    "abstract": "Comments: 19 pages, 12 figures",
    "descriptor": "\nComments: 19 pages, 12 figures\n",
    "authors": [
      "Akshay J. Dave",
      "Taeseung Lee",
      "Roberto Ponciroli",
      "Richard B. Vilim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.04334"
  },
  {
    "id": "arXiv:2209.06640",
    "title": "Revisiting Neural Scaling Laws in Language and Vision",
    "abstract": "Revisiting Neural Scaling Laws in Language and Vision",
    "descriptor": "",
    "authors": [
      "Ibrahim Alabdulmohsin",
      "Behnam Neyshabur",
      "Xiaohua Zhai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.06640"
  },
  {
    "id": "arXiv:2209.06865",
    "title": "Sketch of a novel approach to a neural model",
    "abstract": "Sketch of a novel approach to a neural model",
    "descriptor": "",
    "authors": [
      "Gabriele Scheler"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Molecular Networks (q-bio.MN)"
    ],
    "url": "https://arxiv.org/abs/2209.06865"
  },
  {
    "id": "arXiv:2209.07011",
    "title": "Error Controlled Feature Selection for Ultrahigh Dimensional and Highly  Correlated Feature Space Using Deep Learning",
    "abstract": "Error Controlled Feature Selection for Ultrahigh Dimensional and Highly  Correlated Feature Space Using Deep Learning",
    "descriptor": "",
    "authors": [
      "Arkaprabha Ganguli",
      "David Todem",
      "Tapabrata Maiti"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07011"
  },
  {
    "id": "arXiv:2209.08939",
    "title": "3D Cross-Pseudo Supervision (3D-CPS): A semi-supervised nnU-Net  architecture for abdominal organ segmentation",
    "abstract": "Comments: 14 pages, 5 figures",
    "descriptor": "\nComments: 14 pages, 5 figures\n",
    "authors": [
      "Yongzhi Huang",
      "Hanwen Zhang",
      "Yan Yan",
      "Haseeb Hassan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.08939"
  },
  {
    "id": "arXiv:2209.09233",
    "title": "Learning to Walk by Steering: Perceptive Quadrupedal Locomotion in  Dynamic Environments",
    "abstract": "Comments: Submitted to ICRA 2023",
    "descriptor": "\nComments: Submitted to ICRA 2023\n",
    "authors": [
      "Mingyo Seo",
      "Ryan Gupta",
      "Yifeng Zhu",
      "Alexy Skoutnev",
      "Luis Sentis",
      "Yuke Zhu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.09233"
  },
  {
    "id": "arXiv:2209.10437",
    "title": "Improvement of FTJ on-current by work function engineering for massive  parallel neuromorphic computing",
    "abstract": "Improvement of FTJ on-current by work function engineering for massive  parallel neuromorphic computing",
    "descriptor": "",
    "authors": [
      "Suzanne Lancaster",
      "Quang T. Duong",
      "Erika Covi",
      "Thomas Mikolajick",
      "Stefan Slesazeck"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2209.10437"
  },
  {
    "id": "arXiv:2209.10866",
    "title": "One-Shot Federated Learning for Model Clustering and Learning in  Heterogeneous Environments",
    "abstract": "Comments: Edited text, added figures, added funding information",
    "descriptor": "\nComments: Edited text, added figures, added funding information\n",
    "authors": [
      "Aleksandar Armacki",
      "Dragana Bajovic",
      "Dusan Jakovetic",
      "Soummya Kar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.10866"
  },
  {
    "id": "arXiv:2209.12243",
    "title": "Safety-compliant Generative Adversarial Networks for Human Trajectory  Forecasting",
    "abstract": "Comments: 12 pages, 7 figures, 8 tables; Added acknowledgement",
    "descriptor": "\nComments: 12 pages, 7 figures, 8 tables; Added acknowledgement\n",
    "authors": [
      "Parth Kothari",
      "Alexandre Alahi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.12243"
  },
  {
    "id": "arXiv:2209.13008",
    "title": "USE-Evaluator: Performance Metrics for Medical Image Segmentation Models  with Uncertain, Small or Empty Reference Annotations",
    "abstract": "Comments: 16 pages, 10 figures",
    "descriptor": "\nComments: 16 pages, 10 figures\n",
    "authors": [
      "Sophie Ostmeier",
      "Brian Axelrod",
      "Jeroen Bertels",
      "Fabian Isensee",
      "Maarten G.Lansberg",
      "Soren Christensen",
      "Gregory W. Albers",
      "Li-Jia Li",
      "Jeremy J. Heit"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.13008"
  },
  {
    "id": "arXiv:2209.14635",
    "title": "Compressed Gastric Image Generation Based on Soft-Label Dataset  Distillation for Medical Data Sharing",
    "abstract": "Comments: Published as a journal paper at Elsevier CMPB",
    "descriptor": "\nComments: Published as a journal paper at Elsevier CMPB\n",
    "authors": [
      "Guang Li",
      "Ren Togo",
      "Takahiro Ogawa",
      "Miki Haseyama"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.14635"
  },
  {
    "id": "arXiv:2210.01741",
    "title": "Neural Conservation Laws: A Divergence-Free Perspective",
    "abstract": "Comments: Accepted for publication at NeurIPS 2022",
    "descriptor": "\nComments: Accepted for publication at NeurIPS 2022\n",
    "authors": [
      "Jack Richter-Powell",
      "Yaron Lipman",
      "Ricky T. Q. Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01741"
  },
  {
    "id": "arXiv:2210.01808",
    "title": "Maximum-Likelihood Inverse Reinforcement Learning with Finite-Time  Guarantees",
    "abstract": "Comments: Two different versions (arXiv:2210.01808 and arXiv:2210.01282) of the same paper have been submitted to arxiv. To avoid to the overlap between two versions, we withdraw this version. For this paper, readers could refer to arXiv:2210.01282",
    "descriptor": "\nComments: Two different versions (arXiv:2210.01808 and arXiv:2210.01282) of the same paper have been submitted to arxiv. To avoid to the overlap between two versions, we withdraw this version. For this paper, readers could refer to arXiv:2210.01282\n",
    "authors": [
      "Siliang Zeng",
      "Chenliang Li",
      "Alfredo Garcia",
      "Mingyi Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.01808"
  },
  {
    "id": "arXiv:2210.02071",
    "title": "Advanced Deep Learning Architectures for Accurate Detection of  Subsurface Tile Drainage Pipes from Remote Sensing Images",
    "abstract": "Comments: Accepted at the SPIE Image and Signal Processing for Remote Sensing 2022. For code visit: this https URL",
    "descriptor": "\nComments: Accepted at the SPIE Image and Signal Processing for Remote Sensing 2022. For code visit: this https URL\n",
    "authors": [
      "Tom-Lukas Breitkopf",
      "Leonard W. Hackel",
      "Mahdyar Ravanbakhsh",
      "Anne-Karin Cooke",
      "Sandra Willkommen",
      "Stefan Broda",
      "Beg\u00fcm Demir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.02071"
  },
  {
    "id": "arXiv:2210.02498",
    "title": "Honest Students from Untrusted Teachers: Learning an Interpretable  Question-Answering Pipeline from a Pretrained Language Model",
    "abstract": "Honest Students from Untrusted Teachers: Learning an Interpretable  Question-Answering Pipeline from a Pretrained Language Model",
    "descriptor": "",
    "authors": [
      "Jacob Eisenstein",
      "Daniel Andor",
      "Bernd Bohnet",
      "Michael Collins",
      "David Mimno"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02498"
  },
  {
    "id": "arXiv:2210.03116",
    "title": "Content-Based Search for Deep Generative Models",
    "abstract": "Comments: Modelverse platform: this https URL GitHub: this https URL",
    "descriptor": "\nComments: Modelverse platform: this https URL GitHub: this https URL\n",
    "authors": [
      "Daohan Lu",
      "Sheng-Yu Wang",
      "Nupur Kumari",
      "Rohan Agarwal",
      "David Bau",
      "Jun-Yan Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.03116"
  },
  {
    "id": "arXiv:2210.04873",
    "title": "CORE: A Retrieve-then-Edit Framework for Counterfactual Data Generation",
    "abstract": "Comments: Findings EMNLP 2022",
    "descriptor": "\nComments: Findings EMNLP 2022\n",
    "authors": [
      "Tanay Dixit",
      "Bhargavi Paranjape",
      "Hannaneh Hajishirzi",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.04873"
  },
  {
    "id": "arXiv:2210.06792",
    "title": "SoK: How Not to Architect Your Next-Generation TEE Malware?",
    "abstract": "Comments: Kubilay Ahmet K\\\"u\\c{c}\\\"uk, Steve Moyle, Andrew Martin, Alexandru Mereacre, and Nicholas Allott. 2022. SoK: How Not to Architect Your Next-Generation TEE Malware?. In Hardware and Architectural Support for Security and Privacy (HASP 22), October 1, 2022, Chicago, IL, USA. ACM, New York, NY, USA, 10 pages. this https URL",
    "descriptor": "\nComments: Kubilay Ahmet K\\\"u\\c{c}\\\"uk, Steve Moyle, Andrew Martin, Alexandru Mereacre, and Nicholas Allott. 2022. SoK: How Not to Architect Your Next-Generation TEE Malware?. In Hardware and Architectural Support for Security and Privacy (HASP 22), October 1, 2022, Chicago, IL, USA. ACM, New York, NY, USA, 10 pages. this https URL\n",
    "authors": [
      "Kubilay Ahmet K\u00fc\u00e7\u00fck",
      "Steve Moyle",
      "Andrew Martin",
      "Alexandru Mereacre",
      "Nicholas Allott"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.06792"
  },
  {
    "id": "arXiv:2210.06983",
    "title": "Denoising Masked AutoEncoders are Certifiable Robust Vision Learners",
    "abstract": "Denoising Masked AutoEncoders are Certifiable Robust Vision Learners",
    "descriptor": "",
    "authors": [
      "Quanlin Wu",
      "Hang Ye",
      "Yuntian Gu",
      "Huishuai Zhang",
      "Liwei Wang",
      "Di He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.06983"
  },
  {
    "id": "arXiv:2210.08289",
    "title": "AI-powered mechanisms as judges: Breaking ties in chess and beyond",
    "abstract": "AI-powered mechanisms as judges: Breaking ties in chess and beyond",
    "descriptor": "",
    "authors": [
      "Nejat Anbarci",
      "Mehmet S. Ismail"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.08289"
  },
  {
    "id": "arXiv:2210.08336",
    "title": "DProtoNet: Decoupling Prototype Activation via Multiple Dynamic Masks",
    "abstract": "DProtoNet: Decoupling Prototype Activation via Multiple Dynamic Masks",
    "descriptor": "",
    "authors": [
      "Yitao Peng",
      "Yihang Liu",
      "Longzhen Yang",
      "Lianghua He"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08336"
  },
  {
    "id": "arXiv:2210.08355",
    "title": "A Simple and Strong Baseline for End-to-End Neural RST-style Discourse  Parsing",
    "abstract": "Comments: Accepted in Findings of EMNLP 2022",
    "descriptor": "\nComments: Accepted in Findings of EMNLP 2022\n",
    "authors": [
      "Naoki Kobayashi",
      "Tsutomu Hirao",
      "Hidetaka Kamigaito",
      "Manabu Okumura",
      "Masaaki Nagata"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08355"
  },
  {
    "id": "arXiv:2210.08753",
    "title": "MCP: Self-supervised Pre-training for Personalized Chatbots with  Multi-level Contrastive Sampling",
    "abstract": "MCP: Self-supervised Pre-training for Personalized Chatbots with  Multi-level Contrastive Sampling",
    "descriptor": "",
    "authors": [
      "Zhaoheng Huang",
      "Zhicheng Dou",
      "Yutao Zhu",
      "Zhengyi Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08753"
  },
  {
    "id": "arXiv:2210.08821",
    "title": "MoSE: Modality Split and Ensemble for Multimodal Knowledge Graph  Completion",
    "abstract": "Comments: Accepted by EMNLP 2022",
    "descriptor": "\nComments: Accepted by EMNLP 2022\n",
    "authors": [
      "Yu Zhao",
      "Xiangrui Cai",
      "Yike Wu",
      "Haiwei Zhang",
      "Ying Zhang",
      "Guoqing Zhao",
      "Ning Jiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.08821"
  },
  {
    "id": "arXiv:2210.09017",
    "title": "Robust Data-Driven Moving Horizon Estimation for Linear Discrete-Time  Systems",
    "abstract": "Comments: Submitted to IEEE Transactions on Automatic Control",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Automatic Control\n",
    "authors": [
      "Tobias M. Wolff",
      "Victor G. Lopez",
      "Matthias A. M\u00fcller"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.09017"
  },
  {
    "id": "arXiv:2210.09188",
    "title": "Sub-8-bit quantization for on-device speech recognition: a  regularization-free approach",
    "abstract": "Comments: Accepted for publication at IEEE SLT'22",
    "descriptor": "\nComments: Accepted for publication at IEEE SLT'22\n",
    "authors": [
      "Kai Zhen",
      "Martin Radfar",
      "Hieu Duy Nguyen",
      "Grant P. Strimel",
      "Nathan Susanj",
      "Athanasios Mouchtaris"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.09188"
  },
  {
    "id": "arXiv:2210.10572",
    "title": "Distributed Ledger Technologies for Managing Heterogenous Computing  Systems at the Edge",
    "abstract": "Comments: 8 pages, 8 figures, 5 tables and 2 algorithms",
    "descriptor": "\nComments: 8 pages, 8 figures, 5 tables and 2 algorithms\n",
    "authors": [
      "Daniel Montero Hern\u00e1ndez",
      "Jorge Pe\u00f1a Queralta",
      "Tomi Westerlund"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.10572"
  },
  {
    "id": "arXiv:2210.10638",
    "title": "Digital Human Interactive Recommendation Decision-Making Based on  Reinforcement Learning",
    "abstract": "Comments: 9 pages, 1 figure, 1 table, the paper has been accepted and this is the camera-ready for NeurIPS 2022 Workshop on Human in the Loop Learning, this https URL",
    "descriptor": "\nComments: 9 pages, 1 figure, 1 table, the paper has been accepted and this is the camera-ready for NeurIPS 2022 Workshop on Human in the Loop Learning, this https URL\n",
    "authors": [
      "Xiong Junwu",
      "Xiaoyun Feng",
      "YunZhou Shi",
      "James Zhang",
      "Zhongzhou Zhao",
      "Wei Zhou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10638"
  },
  {
    "id": "arXiv:2210.10946",
    "title": "Causally-guided Regularization of Graph Attention Improves  Generalizability",
    "abstract": "Causally-guided Regularization of Graph Attention Improves  Generalizability",
    "descriptor": "",
    "authors": [
      "Alexander P. Wu",
      "Thomas Markovich",
      "Bonnie Berger",
      "Nils Hammerla",
      "Rohit Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10946"
  },
  {
    "id": "arXiv:2210.11637",
    "title": "Slippage-robust Gaze Tracking for Near-eye Display",
    "abstract": "Comments: 7 pages, 8 figures",
    "descriptor": "\nComments: 7 pages, 8 figures\n",
    "authors": [
      "Wei Zhang",
      "Jiaxi Cao",
      "Xiang Wang",
      "Enqi Tian",
      "Bin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.11637"
  },
  {
    "id": "arXiv:2210.12357",
    "title": "Information-Transport-based Policy for Simultaneous Translation",
    "abstract": "Comments: Accept to EMNLP 2022 main conference. 22 pages, 16 figures, 8 tables",
    "descriptor": "\nComments: Accept to EMNLP 2022 main conference. 22 pages, 16 figures, 8 tables\n",
    "authors": [
      "Shaolei Zhang",
      "Yang Feng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.12357"
  },
  {
    "id": "arXiv:2210.12599",
    "title": "Transformers For Recognition In Overhead Imagery: A Reality Check",
    "abstract": "Comments: This paper has been accepted to WACV 2023, but this is not the final version",
    "descriptor": "\nComments: This paper has been accepted to WACV 2023, but this is not the final version\n",
    "authors": [
      "Francesco Luzi",
      "Aneesh Gupta",
      "Leslie Collins",
      "Kyle Bradbury",
      "Jordan Malof"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.12599"
  },
  {
    "id": "arXiv:2210.12767",
    "title": "Falsehoods that ML researchers believe about OOD detection",
    "abstract": "Comments: 5 pages",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Andi Zhang",
      "Damon Wischik"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.12767"
  },
  {
    "id": "arXiv:2210.13542",
    "title": "Scaling up and Stabilizing Differentiable Planning with Implicit  Differentiation",
    "abstract": "Comments: Minor update on institute",
    "descriptor": "\nComments: Minor update on institute\n",
    "authors": [
      "Linfeng Zhao",
      "Huazhe Xu",
      "Lawson L.S. Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.13542"
  },
  {
    "id": "arXiv:2210.13954",
    "title": "I Prefer not to Say: Operationalizing Fair and User-guided Data  Minimization",
    "abstract": "Comments: NeurIPS 2022 Workshop on Algorithmic Fairness through the Lens of Causality and Privacy (AFCP)",
    "descriptor": "\nComments: NeurIPS 2022 Workshop on Algorithmic Fairness through the Lens of Causality and Privacy (AFCP)\n",
    "authors": [
      "Tobias Leemann",
      "Martin Pawelczyk",
      "Christian Thomas Eberle",
      "Gjergji Kasneci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.13954"
  },
  {
    "id": "arXiv:2210.14005",
    "title": "Parametric PDF for Goodness of Fit",
    "abstract": "Parametric PDF for Goodness of Fit",
    "descriptor": "",
    "authors": [
      "Natan Katz",
      "Uri Itai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.14005"
  },
  {
    "id": "arXiv:2210.14044",
    "title": "SeismicNet: Physics-informed neural networks for seismic wave modeling  in semi-infinite domain",
    "abstract": "Comments: 22 pages",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Pu Ren",
      "Chengping Rao",
      "Su Chen",
      "Jian-sun Wang",
      "Hao Sun",
      "Yang Liu"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.14044"
  },
  {
    "id": "arXiv:2210.14531",
    "title": "Unifying Data Perspectivism and Personalization: An Application to  Social Norms",
    "abstract": "Unifying Data Perspectivism and Personalization: An Application to  Social Norms",
    "descriptor": "",
    "authors": [
      "Joan Plepi",
      "B\u00e9la Neuendorf",
      "Lucie Flek",
      "Charles Welch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.14531"
  },
  {
    "id": "arXiv:2210.14677",
    "title": "How precise are performance estimates for typical medical image  segmentation tasks?",
    "abstract": "How precise are performance estimates for typical medical image  segmentation tasks?",
    "descriptor": "",
    "authors": [
      "Rosana El Jurdi",
      "Olivier Colliot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2210.14677"
  },
  {
    "id": "arXiv:2210.14722",
    "title": "Online TSP with Known Locations",
    "abstract": "Online TSP with Known Locations",
    "descriptor": "",
    "authors": [
      "Evripidis Bampis",
      "Bruno Escoffier",
      "Niklas Hahn",
      "Michalis Xefteris"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.14722"
  },
  {
    "id": "arXiv:2210.14891",
    "title": "Broken Neural Scaling Laws",
    "abstract": "Broken Neural Scaling Laws",
    "descriptor": "",
    "authors": [
      "Ethan Caballero",
      "Kshitij Gupta",
      "Irina Rish",
      "David Krueger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.14891"
  },
  {
    "id": "arXiv:2210.15081",
    "title": "Bayesian Hyperbolic Multidimensional Scaling",
    "abstract": "Bayesian Hyperbolic Multidimensional Scaling",
    "descriptor": "",
    "authors": [
      "Bolun Liu",
      "Shane Lubold",
      "Adrian E. Raftery",
      "Tyler H. McCormick"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.15081"
  },
  {
    "id": "arXiv:2210.15303",
    "title": "Can language models handle recursively nested grammatical structures? A  case study on comparing models and humans",
    "abstract": "Can language models handle recursively nested grammatical structures? A  case study on comparing models and humans",
    "descriptor": "",
    "authors": [
      "Andrew Kyle Lampinen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15303"
  },
  {
    "id": "arXiv:2210.15395",
    "title": "Querying Incomplete Numerical Data: Between Certain and Possible Answers",
    "abstract": "Querying Incomplete Numerical Data: Between Certain and Possible Answers",
    "descriptor": "",
    "authors": [
      "Marco Console",
      "Leonid Libkin",
      "Liat Peterfreund"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2210.15395"
  },
  {
    "id": "arXiv:2210.15509",
    "title": "On Tsirelson pairs of C*-algebras",
    "abstract": "Comments: 13 pages; version 2; some errors from the Preliminaries section corrected",
    "descriptor": "\nComments: 13 pages; version 2; some errors from the Preliminaries section corrected\n",
    "authors": [
      "Isaac Goldbring",
      "Bradd Hart"
    ],
    "subjectives": [
      "Operator Algebras (math.OA)",
      "Computational Complexity (cs.CC)",
      "Logic (math.LO)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2210.15509"
  },
  {
    "id": "arXiv:2210.15630",
    "title": "In-stream Probabilistic Cardinality Estimation for Bloom Filters",
    "abstract": "Comments: 18 pages, 10 figures, 3 tables",
    "descriptor": "\nComments: 18 pages, 10 figures, 3 tables\n",
    "authors": [
      "Remy Scholler",
      "Jean-Francois Couchot",
      "Oumaima Alaoui-Ismaili",
      "Denis Renaud",
      "Eric Ballot"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.15630"
  },
  {
    "id": "arXiv:2210.15750",
    "title": "One-Shot Acoustic Matching Of Audio Signals -- Learning to Hear Music In  Any Room/ Concert Hall",
    "abstract": "Comments: 5 pages, 1 figure; fixed up broken url; added acknowledgments",
    "descriptor": "\nComments: 5 pages, 1 figure; fixed up broken url; added acknowledgments\n",
    "authors": [
      "Prateek Verma",
      "Chris Chafe",
      "Jonathan Berger"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15750"
  },
  {
    "id": "arXiv:2210.15777",
    "title": "Reinforced Question Rewriting for Conversational Question Answering",
    "abstract": "Comments: A cleaned version of our paper Accepted by EMNLP 2022 (Industry Track)",
    "descriptor": "\nComments: A cleaned version of our paper Accepted by EMNLP 2022 (Industry Track)\n",
    "authors": [
      "Zhiyu Chen",
      "Jie Zhao",
      "Anjie Fang",
      "Besnik Fetahu",
      "Oleg Rokhlenko",
      "Shervin Malmasi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.15777"
  },
  {
    "id": "arXiv:2210.15787",
    "title": "Convolutional Codes with Optimum Bidirectional Distance Profile",
    "abstract": "Comments: Submitted to IEEE Communications Letters",
    "descriptor": "\nComments: Submitted to IEEE Communications Letters\n",
    "authors": [
      "Ivan Stanojevi\u0107",
      "Vojin \u0160enk"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.15787"
  },
  {
    "id": "arXiv:2210.16107",
    "title": "SeaDroneSim: Simulation of Aerial Images for Detection of Objects Above  Water",
    "abstract": "SeaDroneSim: Simulation of Aerial Images for Detection of Objects Above  Water",
    "descriptor": "",
    "authors": [
      "Xiaomin Lin",
      "Cheng Liu",
      "Miao Yu",
      "Yiannis Aloimonous"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.16107"
  },
  {
    "id": "arXiv:2210.16234",
    "title": "Revisiting the matrix polynomial greatest common divisor",
    "abstract": "Revisiting the matrix polynomial greatest common divisor",
    "descriptor": "",
    "authors": [
      "Vanni Noferini",
      "Paul Van Dooren"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.16234"
  },
  {
    "id": "arXiv:2210.16346",
    "title": "Improving Hyperspectral Adversarial Robustness using Ensemble Networks  in the Presences of Multiple Attacks",
    "abstract": "Comments: 6 pages, 2 figures, 1 table, 1 algorithm",
    "descriptor": "\nComments: 6 pages, 2 figures, 1 table, 1 algorithm\n",
    "authors": [
      "Nicholas Soucy",
      "Salimeh Yasaei Sekeh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.16346"
  },
  {
    "id": "arXiv:2210.16506",
    "title": "Observable Perfect Equilibrium",
    "abstract": "Comments: fixed minor typo",
    "descriptor": "\nComments: fixed minor typo\n",
    "authors": [
      "Sam Ganzfried"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2210.16506"
  },
  {
    "id": "arXiv:2210.16636",
    "title": "Speaker Representation Learning via Contrastive Loss with Maximal  Speaker Separability",
    "abstract": "Comments: Accept by APSIPA ASC 2022, 6 pages, 2 figures",
    "descriptor": "\nComments: Accept by APSIPA ASC 2022, 6 pages, 2 figures\n",
    "authors": [
      "Zhe Li",
      "Man-Wai Mak"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.16636"
  },
  {
    "id": "arXiv:2210.16744",
    "title": "gMeta: Template-based Regular Expression Generation over Noisy Examples",
    "abstract": "gMeta: Template-based Regular Expression Generation over Noisy Examples",
    "descriptor": "",
    "authors": [
      "Shujun Wang",
      "Yongqiang Tian andDengcheng He"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.16744"
  },
  {
    "id": "arXiv:2210.16751",
    "title": "Formalizing Statistical Causality via Modal Logic",
    "abstract": "Formalizing Statistical Causality via Modal Logic",
    "descriptor": "",
    "authors": [
      "Yusuke Kawamoto",
      "Tetsuya Sato",
      "Kohei Suenaga"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.16751"
  },
  {
    "id": "arXiv:2210.16791",
    "title": "Adaptive Speech Quality Aware Complex Neural Network for Acoustic Echo  Cancellation with Supervised Contrastive Learning",
    "abstract": "Adaptive Speech Quality Aware Complex Neural Network for Acoustic Echo  Cancellation with Supervised Contrastive Learning",
    "descriptor": "",
    "authors": [
      "Bozhong Liu",
      "Xiaoxi Yu",
      "Hantao Huang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.16791"
  },
  {
    "id": "arXiv:2210.16819",
    "title": "Relative Attention-based One-Class Adversarial Autoencoder for  Continuous Authentication of Smartphone Users",
    "abstract": "Relative Attention-based One-Class Adversarial Autoencoder for  Continuous Authentication of Smartphone Users",
    "descriptor": "",
    "authors": [
      "Mingming Hu",
      "Kun Zhang",
      "Ruibang You",
      "Bibo Tu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2210.16819"
  },
  {
    "id": "arXiv:2210.16835",
    "title": "Robust Data Valuation via Variance Reduced Data Shapley",
    "abstract": "Robust Data Valuation via Variance Reduced Data Shapley",
    "descriptor": "",
    "authors": [
      "Mengmeng Wu",
      "Ruoxi Jia",
      "Changle Lin",
      "Wei Huang",
      "Xiangyu Chang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16835"
  },
  {
    "id": "arXiv:2210.16875",
    "title": "A Multi-modal Deformable Land-air Robot for Complex Environments",
    "abstract": "A Multi-modal Deformable Land-air Robot for Complex Environments",
    "descriptor": "",
    "authors": [
      "Xinyu Zhang",
      "Yuanhao Huang",
      "Kangyao Huang",
      "Xiaoyu Wang",
      "Dafeng Jin",
      "Huaping Liu",
      "Jun Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.16875"
  },
  {
    "id": "arXiv:2210.17016",
    "title": "Wespeaker: A Research and Production oriented Speaker Embedding Learning  Toolkit",
    "abstract": "Wespeaker: A Research and Production oriented Speaker Embedding Learning  Toolkit",
    "descriptor": "",
    "authors": [
      "Hongji Wang",
      "Chengdong Liang",
      "Shuai Wang",
      "Zhengyang Chen",
      "Binbin Zhang",
      "Xu Xiang",
      "Yanlei Deng",
      "Yanmin Qian"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.17016"
  },
  {
    "id": "arXiv:2210.17168",
    "title": "SDCL: Self-Distillation Contrastive Learning for Chinese Spell Checking",
    "abstract": "SDCL: Self-Distillation Contrastive Learning for Chinese Spell Checking",
    "descriptor": "",
    "authors": [
      "Xiaotian Zhang",
      "Hang Yan",
      "Sun Yu",
      "Xipeng Qiu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.17168"
  },
  {
    "id": "arXiv:2210.17239",
    "title": "RIS-Based Steerable Beamforming Antenna with Near-Field Eigenmode Feeder",
    "abstract": "RIS-Based Steerable Beamforming Antenna with Near-Field Eigenmode Feeder",
    "descriptor": "",
    "authors": [
      "Krishan K. Tiwari",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2210.17239"
  },
  {
    "id": "arXiv:2210.17349",
    "title": "Robust MelGAN: A robust universal neural vocoder for high-fidelity TTS",
    "abstract": "Robust MelGAN: A robust universal neural vocoder for high-fidelity TTS",
    "descriptor": "",
    "authors": [
      "Kun Song",
      "Jian Cong",
      "Xinsheng Wang",
      "Yongmao Zhang",
      "Lei Xie",
      "Ning Jiang",
      "Haiying Wu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.17349"
  },
  {
    "id": "arXiv:2210.17482",
    "title": "Low Complexity Detect and Avoid for Autonomous Agents in Cluttered  Environments",
    "abstract": "Low Complexity Detect and Avoid for Autonomous Agents in Cluttered  Environments",
    "descriptor": "",
    "authors": [
      "Mosab Diab",
      "Mostafa Mohammadkarimi",
      "Raj Thilak Rajan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.17482"
  },
  {
    "id": "arXiv:2210.17543",
    "title": "High order splitting methods for SDEs satisfying a commutativity  condition",
    "abstract": "Comments: 47 pages, 10 figures",
    "descriptor": "\nComments: 47 pages, 10 figures\n",
    "authors": [
      "James Foster",
      "Goncalo dos Reis",
      "Calum Strange"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2210.17543"
  },
  {
    "id": "arXiv:2210.17544",
    "title": "Compressed IF-TEM: Time Encoding Analog-To-Digital Compression",
    "abstract": "Compressed IF-TEM: Time Encoding Analog-To-Digital Compression",
    "descriptor": "",
    "authors": [
      "Saar Tarnopolsky",
      "Hila Naaman",
      "Yonina C. Eldar",
      "Alejandro Cohen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.17544"
  }
]
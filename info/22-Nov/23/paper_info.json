[
  {
    "id": "arXiv:2211.11747",
    "title": "NEVIS'22: A Stream of 100 Tasks Sampled from 30 Years of Computer Vision  Research",
    "abstract": "We introduce the Never Ending VIsual-classification Stream (NEVIS'22), a\nbenchmark consisting of a stream of over 100 visual classification tasks,\nsorted chronologically and extracted from papers sampled uniformly from\ncomputer vision proceedings spanning the last three decades. The resulting\nstream reflects what the research community thought was meaningful at any point\nin time. Despite being limited to classification, the resulting stream has a\nrich diversity of tasks from OCR, to texture analysis, crowd counting, scene\nrecognition, and so forth. The diversity is also reflected in the wide range of\ndataset sizes, spanning over four orders of magnitude. Overall, NEVIS'22 poses\nan unprecedented challenge for current sequential learning approaches due to\nthe scale and diversity of tasks, yet with a low entry barrier as it is limited\nto a single modality and each task is a classical supervised learning problem.\nMoreover, we provide a reference implementation including strong baselines and\na simple evaluation protocol to compare methods in terms of their trade-off\nbetween accuracy and compute. We hope that NEVIS'22 can be useful to\nresearchers working on continual learning, meta-learning, AutoML and more\ngenerally sequential learning, and help these communities join forces towards\nmore robust and efficient models that efficiently adapt to a never ending\nstream of data. Implementations have been made available at\nhttps://github.com/deepmind/dm_nevis.",
    "descriptor": "",
    "authors": [
      "Jorg Bornschein",
      "Alexandre Galashov",
      "Ross Hemsley",
      "Amal Rannen-Triki",
      "Yutian Chen",
      "Arslan Chaudhry",
      "Xu Owen He",
      "Arthur Douillard",
      "Massimo Caccia",
      "Qixuang Feng",
      "Jiajun Shen",
      "Sylvestre-Alvise Rebuffi",
      "Kitty Stacpoole",
      "Diego de las Casas",
      "Will Hawkins",
      "Angeliki Lazaridou",
      "Yee Whye Teh",
      "Andrei A. Rusu",
      "Razvan Pascanu",
      "Marc'Aurelio Ranzato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11747"
  },
  {
    "id": "arXiv:2211.11751",
    "title": "Robust AUC Optimization under the Supervision of Clean Data",
    "abstract": "AUC (area under the ROC curve) optimization algorithms have drawn much\nattention due to the incredible adaptability for seriously imbalanced data.\nReal-world datasets usually contain extensive noisy samples that seriously\nhinder the model performance, but a limited number of clean samples can be\nobtained easily. Although some AUC optimization studies make an effort to\ndispose of noisy samples, they do not utilize such clean samples well. In this\npaper, we propose a robust AUC optimization algorithm (RAUCO) with good use of\navailable clean samples. Expressly, our RAUCO algorithm can exclude noisy\nsamples from the training by employing the technology of self-paced learning\n(SPL) under the supervision of clean samples. Moreover, considering the impact\nof the data enhancement technology on SPL, we innovatively introduce the\nconsistency regularization term to SPL. Theoretical results on the convergence\nof our RAUCO algorithm are provided under mild assumptions. Comprehensive\nexperiments demonstrate that our RAUCO algorithm holds better robustness than\nexisting algorithms.",
    "descriptor": "",
    "authors": [
      "Chenkang Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11751"
  },
  {
    "id": "arXiv:2211.11752",
    "title": "RHCO: A Relation-aware Heterogeneous Graph Neural Network with  Contrastive Learning for Large-scale Graphs",
    "abstract": "Heterogeneous graph neural networks (HGNNs) have been widely applied in\nheterogeneous information network tasks, while most HGNNs suffer from poor\nscalability or weak representation when they are applied to large-scale\nheterogeneous graphs. To address these problems, we propose a novel\nRelation-aware Heterogeneous Graph Neural Network with Contrastive Learning\n(RHCO) for large-scale heterogeneous graph representation learning. Unlike\ntraditional heterogeneous graph neural networks, we adopt the contrastive\nlearning mechanism to deal with the complex heterogeneity of large-scale\nheterogeneous graphs. We first learn relation-aware node embeddings under the\nnetwork schema view. Then we propose a novel positive sample selection strategy\nto choose meaningful positive samples. After learning node embeddings under the\npositive sample graph view, we perform a cross-view contrastive learning to\nobtain the final node representations. Moreover, we adopt the label smoothing\ntechnique to boost the performance of RHCO. Extensive experiments on three\nlarge-scale academic heterogeneous graph datasets show that RHCO achieves best\nperformance over the state-of-the-art models.",
    "descriptor": "",
    "authors": [
      "Ziming Wan",
      "Deqing Wang",
      "Xuehua Ming",
      "Fuzhen Zhuang",
      "Chenguang Du",
      "Ting Jiang",
      "Zhengyang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11752"
  },
  {
    "id": "arXiv:2211.11753",
    "title": "SplitNet: Learnable Clean-Noisy Label Splitting for Learning with Noisy  Labels",
    "abstract": "Annotating the dataset with high-quality labels is crucial for performance of\ndeep network, but in real world scenarios, the labels are often contaminated by\nnoise. To address this, some methods were proposed to automatically split clean\nand noisy labels, and learn a semi-supervised learner in a Learning with Noisy\nLabels (LNL) framework. However, they leverage a handcrafted module for\nclean-noisy label splitting, which induces a confirmation bias in the\nsemi-supervised learning phase and limits the performance. In this paper, we\nfor the first time present a learnable module for clean-noisy label splitting,\ndubbed SplitNet, and a novel LNL framework which complementarily trains the\nSplitNet and main network for the LNL task. We propose to use a dynamic\nthreshold based on a split confidence by SplitNet to better optimize\nsemi-supervised learner. To enhance SplitNet training, we also present a risk\nhedging method. Our proposed method performs at a state-of-the-art level\nespecially in high noise ratio settings on various LNL benchmarks.",
    "descriptor": "",
    "authors": [
      "Daehwan Kim",
      "Kwangrok Ryoo",
      "Hansang Cho",
      "Seungryong Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11753"
  },
  {
    "id": "arXiv:2211.11754",
    "title": "An Algorithm for Routing Vectors in Sequences",
    "abstract": "We propose a routing algorithm that takes a sequence vectors and computes a\nnew sequence with specified length and vector size. Each output vector\nmaximizes ``bang per bit,'' the difference between a net benefit to use and net\ncost to ignore data, by better predicting the input vectors. We describe output\nvectors as geometric objects, as latent variables that assign credit, as query\nstates in a model of associative memory, and as agents in a model of a Society\nof Mind. We implement the algorithm with optimizations that reduce parameter\ncount, computation, and memory use by orders of magnitude, enabling us to route\nsequences of greater length than previously possible. We evaluate our\nimplementation on natural language and visual classification tasks, obtaining\ncompetitive or state-of-the-art accuracy and end-to-end credit assignments that\nare interpretable.",
    "descriptor": "\nComments: Source code and instructions for replicating our results are online at this https URL\n",
    "authors": [
      "Franz A. Heinsen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11754"
  },
  {
    "id": "arXiv:2211.11758",
    "title": "A Graph Regularized Point Process Model For Event Propagation Sequence",
    "abstract": "Point process is the dominant paradigm for modeling event sequences occurring\nat irregular intervals. In this paper we aim at modeling latent dynamics of\nevent propagation in graph, where the event sequence propagates in a directed\nweighted graph whose nodes represent event marks (e.g., event types). Most\nexisting works have only considered encoding sequential event history into\nevent representation and ignored the information from the latent graph\nstructure. Besides they also suffer from poor model explainability, i.e.,\nfailing to uncover causal influence across a wide variety of nodes. To address\nthese problems, we propose a Graph Regularized Point Process (GRPP) that can be\ndecomposed into: 1) a graph propagation model that characterizes the event\ninteractions across nodes with neighbors and inductively learns node\nrepresentations; 2) a temporal attentive intensity model, whose excitation and\ntime decay factors of past events on the current event are constructed via the\ncontextualization of the node embedding. Moreover, by applying a graph\nregularization method, GRPP provides model interpretability by uncovering\ninfluence strengths between nodes. Numerical experiments on various datasets\nshow that GRPP outperforms existing models on both the propagation time and\nnode prediction by notable margins.",
    "descriptor": "\nComments: IJCNN 2021\n",
    "authors": [
      "Siqiao Xue",
      "Xiaoming Shi",
      "Hongyan Hao",
      "Lintao Ma",
      "Shiyu Wang",
      "Shijun Wang",
      "James Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11758"
  },
  {
    "id": "arXiv:2211.11759",
    "title": "Learning Cooperative Oversubscription for Cloud by Chance-Constrained  Multi-Agent Reinforcement Learning",
    "abstract": "Oversubscription is a common practice for improving cloud resource\nutilization. It allows the cloud service provider to sell more resources than\nthe physical limit, assuming not all users would fully utilize the resources\nsimultaneously. However, how to design an oversubscription policy that improves\nutilization while satisfying the some safety constraints remains an open\nproblem. Existing methods and industrial practices are over-conservative,\nignoring the coordination of diverse resource usage patterns and probabilistic\nconstraints. To address these two limitations, this paper formulates the\noversubscription for cloud as a chance-constrained optimization problem and\npropose an effective Chance Constrained Multi-Agent Reinforcement Learning\n(C2MARL) method to solve this problem. Specifically, C2MARL reduces the number\nof constraints by considering their upper bounds and leverages a multi-agent\nreinforcement learning paradigm to learn a safe and optimal coordination\npolicy. We evaluate our C2MARL on an internal cloud platform and public cloud\ndatasets. Experiments show that our C2MARL outperforms existing methods in\nimproving utilization ($20\\%\\sim 86\\%$) under different levels of safety\nconstraints.",
    "descriptor": "",
    "authors": [
      "Junjie Sheng",
      "Lu Wang",
      "Fangkai Yang",
      "Bo Qiao",
      "Hang Dong",
      "Xiangfeng Wang",
      "Bo Jin",
      "Jun Wang",
      "Si Qin",
      "Saravan Rajmohan",
      "Qingwei Lin",
      "Dongmei Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.11759"
  },
  {
    "id": "arXiv:2211.11760",
    "title": "A Low Latency Adaptive Coding Spiking Framework for Deep Reinforcement  Learning",
    "abstract": "With the help of Deep Neural Networks, Deep Reinforcement Learning (DRL) has\nachieved great success on many complex tasks during the past few years. Spiking\nNeural Networks (SNNs) have been used for the implementation of Deep Neural\nNetworks with superb energy efficiency on dedicated neuromorphic hardware, and\nrecent years have witnessed increasing attention on combining SNNs with\nReinforcement Learning, whereas most approaches still work with huge energy\nconsumption and high latency. This work proposes the Adaptive Coding Spiking\nFramework (ACSF) for SNN-based DRL and achieves low latency and great energy\nefficiency at the same time. Inspired by classical conditioning in biology, we\nsimulate receptors, central interneurons, and effectors with spike encoders,\nSNNs, and spike decoders, respectively. We use our proposed ACSF to estimate\nthe value function in reinforcement learning and conduct extensive experiments\nto verify the effectiveness of our proposed framework.",
    "descriptor": "",
    "authors": [
      "Lang Qin",
      "Rui Yan",
      "Huajin Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.11760"
  },
  {
    "id": "arXiv:2211.11761",
    "title": "From Node Interaction to Hop Interaction: New Effective and Scalable  Graph Learning Paradigm",
    "abstract": "Existing Graph Neural Networks (GNNs) follow the message-passing mechanism\nthat conducts information interaction among nodes iteratively. While\nconsiderable progress has been made, such node interaction paradigms still have\nthe following limitation. First, the scalability limitation precludes the wide\napplication of GNNs in large-scale industrial settings since the node\ninteraction among rapidly expanding neighbors incurs high computation and\nmemory costs. Second, the over-smoothing problem restricts the discrimination\nability of nodes, i.e., node representations of different classes will converge\nto indistinguishable after repeated node interactions. In this work, we propose\na novel hop interaction paradigm to address these limitations simultaneously.\nThe core idea of hop interaction is to convert the target of message-passing\nfrom nodes into multi-hop features inside each node. Specifically, it first\npre-computed multi-hop features of nodes to reduce computation costs during\ntraining and inference. Then, it conducts a non-linear interaction among\nmulti-hop features to enhance the discrimination of nodes. We design a simple\nyet effective HopGNN framework that can easily utilize existing GNNs to achieve\nhop interaction. Furthermore, we propose a multi-task learning strategy with a\nself-supervised learning objective to enhance HopGNN. We conduct extensive\nexperiments on 12 benchmark datasets in a wide range of domains, scales, and\nsmoothness of graphs. Experimental results show that our methods achieve\nsuperior performance while maintaining high scalability and efficiency.",
    "descriptor": "",
    "authors": [
      "Jie Chen",
      "Zilong Li",
      "Yin Zhu",
      "Junping Zhang",
      "Jian Pu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11761"
  },
  {
    "id": "arXiv:2211.11762",
    "title": "Hierarchical Graph Structures for Congestion and ETA Prediction",
    "abstract": "Traffic4cast is an annual competition to predict spatio temporal traffic\nbased on real world data. We propose an approach using Graph Neural Networks\nthat directly works on the road graph topology which was extracted from\nOpenStreetMap data. Our architecture can incorporate a hierarchical graph\nrepresentation to improve the information flow between key intersections of the\ngraph and the shortest paths connecting them. Furthermore, we investigate how\nthe road graph can be compacted to ease the flow of information and make use of\na multi-task approach to predict congestion classes and ETA simultaneously. Our\ncode and models are released here:\nhttps://github.com/floriangroetschla/NeurIPS2022-traffic4cast",
    "descriptor": "",
    "authors": [
      "Florian Gr\u00f6tschla",
      "Jo\u00ebl Mathys"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11762"
  },
  {
    "id": "arXiv:2211.11763",
    "title": "DS-GPS : A Deep Statistical Graph Poisson Solver (for faster CFD  simulations)",
    "abstract": "This paper proposes a novel Machine Learning-based approach to solve a\nPoisson problem with mixed boundary conditions. Leveraging Graph Neural\nNetworks, we develop a model able to process unstructured grids with the\nadvantage of enforcing boundary conditions by design. By directly minimizing\nthe residual of the Poisson equation, the model attempts to learn the physics\nof the problem without the need for exact solutions, in contrast to most\nprevious data-driven processes where the distance with the available solutions\nis minimized.",
    "descriptor": "",
    "authors": [
      "Matthieu Nastorg",
      "Marc Schoenauer",
      "Guillaume Charpiat",
      "Thibault Faney",
      "Jean-Marc Gratien",
      "Michele-Alessandro Bucci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.11763"
  },
  {
    "id": "arXiv:2211.11772",
    "title": "The NCTE Transcripts: A Dataset of Elementary Math Classroom Transcripts",
    "abstract": "Classroom discourse is a core medium of instruction -- analyzing it can\nprovide a window into teaching and learning as well as driving the development\nof new tools for improving instruction. We introduce the largest dataset of\nmathematics classroom transcripts available to researchers, and demonstrate how\nthis data can help improve instruction. The dataset consists of 1,660 45-60\nminute long 4th and 5th grade elementary mathematics observations collected by\nthe National Center for Teacher Effectiveness (NCTE) between 2010-2013. The\nanonymized transcripts represent data from 317 teachers across 4 school\ndistricts that serve largely historically marginalized students. The\ntranscripts come with rich metadata, including turn-level annotations for\ndialogic discourse moves, classroom observation scores, demographic\ninformation, survey responses and student test scores. We demonstrate that our\nnatural language processing model, trained on our turn-level annotations, can\nlearn to identify dialogic discourse moves and these moves are correlated with\nbetter classroom observation scores and learning outcomes. This dataset opens\nup several possibilities for researchers, educators and policymakers to learn\nabout and improve K-12 instruction. The data and its terms of use can be\naccessed here: https://github.com/ddemszky/classroom-transcript-analysis",
    "descriptor": "",
    "authors": [
      "Dorottya Demszky",
      "Heather Hill"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11772"
  },
  {
    "id": "arXiv:2211.11797",
    "title": "Multi-Spectral Image Classification with Ultra-Lean Complex-Valued  Models",
    "abstract": "Multi-spectral imagery is invaluable for remote sensing due to different\nspectral signatures exhibited by materials that often appear identical in\ngreyscale and RGB imagery. Paired with modern deep learning methods, this\nmodality has great potential utility in a variety of remote sensing\napplications, such as humanitarian assistance and disaster recovery efforts.\nState-of-the-art deep learning methods have greatly benefited from large-scale\nannotations like in ImageNet, but existing MSI image datasets lack annotations\nat a similar scale. As an alternative to transfer learning on such data with\nfew annotations, we apply complex-valued co-domain symmetric models to classify\nreal-valued MSI images. Our experiments on 8-band xView data show that our\nultra-lean model trained on xView from scratch without data augmentations can\noutperform ResNet with data augmentation and modified transfer learning on\nxView. Our work is the first to demonstrate the value of complex-valued deep\nlearning on real-valued MSI data.",
    "descriptor": "\nComments: NeuRIPS 2022 HADR workshop submission\n",
    "authors": [
      "Utkarsh Singhal",
      "Stella X. Yu",
      "Zackery Steck",
      "Scott Kangas",
      "Aaron A. Reite"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11797"
  },
  {
    "id": "arXiv:2211.11798",
    "title": "Can You Label Less by Using Out-of-Domain Data? Active & Transfer  Learning with Few-shot Instructions",
    "abstract": "Labeling social-media data for custom dimensions of toxicity and social bias\nis challenging and labor-intensive. Existing transfer and active learning\napproaches meant to reduce annotation effort require fine-tuning, which suffers\nfrom over-fitting to noise and can cause domain shift with small sample sizes.\nIn this work, we propose a novel Active Transfer Few-shot Instructions (ATF)\napproach which requires no fine-tuning. ATF leverages the internal linguistic\nknowledge of pre-trained language models (PLMs) to facilitate the transfer of\ninformation from existing pre-labeled datasets (source-domain task) with\nminimum labeling effort on unlabeled target data (target-domain task). Our\nstrategy can yield positive transfer achieving a mean AUC gain of 10.5%\ncompared to no transfer with a large 22b parameter PLM. We further show that\nannotation of just a few target-domain samples via active learning can be\nbeneficial for transfer, but the impact diminishes with more annotation effort\n(26% drop in gain between 100 and 2000 annotated examples). Finally, we find\nthat not all transfer scenarios yield a positive gain, which seems related to\nthe PLMs initial performance on the target-domain task.",
    "descriptor": "\nComments: Accepted to NeurIPS Workshop on Transfer Learning for Natural Language Processing, 2022, New Orleans\n",
    "authors": [
      "Rafal Kocielnik",
      "Sara Kangaslahti",
      "Shrimai Prabhumoye",
      "Meena Hari",
      "R. Michael Alvarez",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11798"
  },
  {
    "id": "arXiv:2211.11799",
    "title": "Unsupervised extraction, labelling and clustering of segments from  clinical notes",
    "abstract": "This work is motivated by the scarcity of tools for accurate, unsupervised\ninformation extraction from unstructured clinical notes in computationally\nunderrepresented languages, such as Czech. We introduce a stepping stone to a\nbroad array of downstream tasks such as summarisation or integration of\nindividual patient records, extraction of structured information for national\ncancer registry reporting or building of semi-structured semantic patient\nrepresentations for computing patient embeddings. More specifically, we present\na method for unsupervised extraction of semantically-labelled textual segments\nfrom clinical notes and test it out on a dataset of Czech breast cancer\npatients, provided by Masaryk Memorial Cancer Institute (the largest Czech\nhospital specialising in oncology). Our goal was to extract, classify (i.e.\nlabel) and cluster segments of the free-text notes that correspond to specific\nclinical features (e.g., family background, comorbidities or toxicities). The\npresented results demonstrate the practical relevance of the proposed approach\nfor building more sophisticated extraction and analytical pipelines deployed on\nCzech clinical notes.",
    "descriptor": "\nComments: To be published at the IEEE BIBM 2022 conference\n",
    "authors": [
      "Petr Zelina",
      "Jana Hal\u00e1mkov\u00e1",
      "V\u00edt Nov\u00e1\u010dek"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11799"
  },
  {
    "id": "arXiv:2211.11801",
    "title": "Self-Supervised Pre-training of 3D Point Cloud Networks with Image Data",
    "abstract": "Reducing the quantity of annotations required for supervised training is\nvital when labels are scarce and costly. This reduction is especially important\nfor semantic segmentation tasks involving 3D datasets that are often\nsignificantly smaller and more challenging to annotate than their image-based\ncounterparts. Self-supervised pre-training on large unlabelled datasets is one\nway to reduce the amount of manual annotations needed. Previous work has\nfocused on pre-training with point cloud data exclusively; this approach often\nrequires two or more registered views. In the present work, we combine image\nand point cloud modalities, by first learning self-supervised image features\nand then using these features to train a 3D model. By incorporating image data,\nwhich is often included in many 3D datasets, our pre-training method only\nrequires a single scan of a scene. We demonstrate that our pre-training\napproach, despite using single scans, achieves comparable performance to other\nmulti-scan, point cloud-only methods.",
    "descriptor": "\nComments: Accepted to the Conference on Robot Learning (CoRL'22) Workshop on Pre-training Robot Learning, Auckland, New Zealand, December 14-18, 2022\n",
    "authors": [
      "Andrej Janda",
      "Brandon Wagstaff",
      "Edwin G. Ng",
      "Jonathan Kelly"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11801"
  },
  {
    "id": "arXiv:2211.11802",
    "title": "Improving TD3-BC: Relaxed Policy Constraint for Offline Learning and  Stable Online Fine-Tuning",
    "abstract": "The ability to discover optimal behaviour from fixed data sets has the\npotential to transfer the successes of reinforcement learning (RL) to domains\nwhere data collection is acutely problematic. In this offline setting, a key\nchallenge is overcoming overestimation bias for actions not present in data\nwhich, without the ability to correct for via interaction with the environment,\ncan propagate and compound during training, leading to highly sub-optimal\npolicies. One simple method to reduce this bias is to introduce a policy\nconstraint via behavioural cloning (BC), which encourages agents to pick\nactions closer to the source data. By finding the right balance between RL and\nBC such approaches have been shown to be surprisingly effective while requiring\nminimal changes to the underlying algorithms they are based on. To date this\nbalance has been held constant, but in this work we explore the idea of tipping\nthis balance towards RL following initial training. Using TD3-BC, we\ndemonstrate that by continuing to train a policy offline while reducing the\ninfluence of the BC component we can produce refined policies that outperform\nthe original baseline, as well as match or exceed the performance of more\ncomplex alternatives. Furthermore, we demonstrate such an approach can be used\nfor stable online fine-tuning, allowing policies to be safely improved during\ndeployment.",
    "descriptor": "\nComments: 3rd Offline Reinforcement Learning Workshop at Neural Information Processing Systems, 2022\n",
    "authors": [
      "Alex Beeson",
      "Giovanni Montana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.11802"
  },
  {
    "id": "arXiv:2211.11809",
    "title": "Real bird dataset with imprecise and uncertain values",
    "abstract": "The theory of belief functions allows the fusion of imperfect data from\ndifferent sources. Unfortunately, few real, imprecise and uncertain datasets\nexist to test approaches using belief functions. We have built real birds\ndatasets thanks to the collection of numerous human contributions that we make\navailable to the scientific community. The interest of our datasets is that\nthey are made of human contributions, thus the information is therefore\nnaturally uncertain and imprecise. These imperfections are given directly by\nthe persons. This article presents the data and their collection through\ncrowdsourcing and how to obtain belief functions from the data.",
    "descriptor": "",
    "authors": [
      "Constance Thierry",
      "Arthur Hoarau",
      "Arnaud Martin",
      "Jean-Christophe Dubois",
      "Yolande Le Gall"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.11809"
  },
  {
    "id": "arXiv:2211.11811",
    "title": "A minimum swept-volume metric structure for configuration space",
    "abstract": "Borrowing elementary ideas from solid mechanics and differential geometry,\nthis presentation shows that the volume swept by a regular solid undergoing a\nwide class of volume-preserving deformations induces a rather natural metric\nstructure with well-defined and computable geodesics on its configuration\nspace. This general result applies to concrete classes of articulated objects\nsuch as robot manipulators, and we demonstrate as a proof of concept the\ncomputation of geodesic paths for a free flying rod and planar robotic arms as\nwell as their use in path planning with many obstacles.",
    "descriptor": "",
    "authors": [
      "Yann de Mont-Marin",
      "Jean Ponce",
      "Jean-Paul Laumond"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.11811"
  },
  {
    "id": "arXiv:2211.11812",
    "title": "RIC-CNN: Rotation-Invariant Coordinate Convolutional Neural Network",
    "abstract": "In recent years, convolutional neural network has shown good performance in\nmany image processing and computer vision tasks. However, a standard CNN model\nis not invariant to image rotations. In fact, even slight rotation of an input\nimage will seriously degrade its performance. This shortcoming precludes the\nuse of CNN in some practical scenarios. Thus, in this paper, we focus on\ndesigning convolutional layer with good rotation invariance. Specifically,\nbased on a simple rotation-invariant coordinate system, we propose a new\nconvolutional operation, called Rotation-Invariant Coordinate Convolution\n(RIC-C). Without additional trainable parameters and data augmentation, RIC-C\nis naturally invariant to arbitrary rotations around the input center.\nFurthermore, we find the connection between RIC-C and deformable convolution,\nand propose a simple but efficient approach to implement RIC-C using Pytorch.\nBy replacing all standard convolutional layers in a CNN with the corresponding\nRIC-C, a RIC-CNN can be derived. Using MNIST dataset, we first evaluate the\nrotation invariance of RIC-CNN and compare its performance with most of\nexisting rotation-invariant CNN models. It can be observed that RIC-CNN\nachieves the state-of-the-art classification on the rotated test dataset of\nMNIST. Then, we deploy RIC-C to VGG, ResNet and DenseNet, and conduct the\nclassification experiments on two real image datasets. Also, a shallow CNN and\nthe corresponding RIC-CNN are trained to extract image patch descriptors, and\nwe compare their performance in patch verification. These experimental results\nagain show that RIC-C can be easily used as drop in replacement for standard\nconvolutions, and greatly enhances the rotation invariance of CNN models\ndesigned for different applications.",
    "descriptor": "",
    "authors": [
      "Hanlin Mo",
      "Guoying Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11812"
  },
  {
    "id": "arXiv:2211.11817",
    "title": "High-Quality Fault-Resiliency in Fat-Tree Networks (Extended Abstract)",
    "abstract": "Coupling regular topologies with optimized routing algorithms is key in\npushing the performance of interconnection networks of HPC systems. In this\npaper we present Dmodc, a fast deterministic routing algorithm for Parallel\nGeneralized Fat-Trees (PGFTs) which minimizes congestion risk even under\nmassive topology degradation caused by equipment failure. It applies a\nmodulo-based computation of forwarding tables among switches closer to the\ndestination, using only knowledge of subtrees for pre-modulo division. Dmodc\nallows complete rerouting of topologies with tens of thousands of nodes in less\nthan a second, which greatly helps centralized fabric management react to\nfaults with high-quality routing tables and no impact to running applications\nin current and future very large-scale HPC clusters. We compare Dmodc against\nrouting algorithms available in the InfiniBand control software (OpenSM) first\nfor routing execution time to show feasibility at scale, and then for\ncongestion risk under degradation to demonstrate robustness. The latter\ncomparison is done using static analysis of routing tables under random\npermutation (RP), shift permutation (SP) and all-to-all (A2A) traffic patterns.\nResults for Dmodc show A2A and RP congestion risks similar under heavy\ndegradation as the most stable algorithms compared, and near-optimal SP\ncongestion risk up to 1% of random degradation.",
    "descriptor": "",
    "authors": [
      "John Gliksberg",
      "Antoine Capra",
      "Alexandre Louvet",
      "Pedro Javier Garcia",
      "Devan Sohier"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.11817"
  },
  {
    "id": "arXiv:2211.11818",
    "title": "Node-Type-Based Load-Balancing Routing for Parallel Generalized  Fat-Trees",
    "abstract": "High-Performance Computing (HPC) clusters are made up of a variety of node\ntypes (usually compute, I/O, service, and GPGPU nodes) and applications don't\nuse nodes of a different type the same way. Resulting communication patterns\nreflect organization of groups of nodes, and current optimal routing algorithms\nfor all-to-all patterns will not always maximize performance for group-specific\ncommunications. Since application communication patterns are rarely available\nbeforehand, we choose to rely on node types as a good guess for node usage. We\nprovide a description of node type heterogeneity and analyse performance\ndegradation caused by unlucky repartition of nodes of the same type. We provide\nan extension to routing algorithms for Parallel Generalized Fat-Tree topologies\n(PGFTs) which balances load amongst groups of nodes of the same type. We show\nhow it removes these performance issues by comparing results in a variety of\nsituations against corresponding classical algorithms.",
    "descriptor": "",
    "authors": [
      "John Gliksberg",
      "Jean-Noel Quintin",
      "Pedro Javier Garcia"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.11818"
  },
  {
    "id": "arXiv:2211.11825",
    "title": "OrthoGAN: Multifaceted Semantics for Disentangled Face Editing",
    "abstract": "This paper describes a new technique for finding disentangled semantic\ndirections in the latent space of StyleGAN. OrthoGAN identifies meaningful\northogonal subspaces that allow editing of one human face attribute, while\nminimizing undesired changes in other attributes. Our model is capable of\nediting a single attribute in multiple directions. Resulting in a range of\npossible generated images. We compare our scheme with three state-of-the-art\nmodels and show that our method outperforms them in terms of face editing and\ndisentanglement capabilities. Additionally, we suggest quantitative measures\nfor evaluating attribute separation and disentanglement, and exhibit the\nsuperiority of our model with respect to those measures.",
    "descriptor": "",
    "authors": [
      "Chen Naveh",
      "Yacov Hel-Or"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11825"
  },
  {
    "id": "arXiv:2211.11828",
    "title": "Data analysis and visualization techniques for project tracking:  Experiences with the ITLingo-Cloud Platform",
    "abstract": "Considering the market's competitiveness and the complexity of organizations\nand projects, analyzing data is crucial to decision support on software\ndevelopment and project management processes. These practices are essential to\nincrease performance, reduce costs and risks of failure, and guarantee the\nquality of results, keeping the work organized and controlled. ITLingo-Cloud is\na multi-organization and multi-workspace collaborative platform to manage and\nanalyze data that can support translating project performance knowledge into\nimproved decision-making. This platform allows users to quickly set up their\nenvironment, manage workspaces and technical documentation, and analyze and\nobserve statistics to aid both technical and business decisions. ITLingo-Cloud\nsupports multiple technologies and languages, promotes data synchronization\nwith templates and reusable libraries, as well as automation tasks, namely\nautomatic data extraction, automatic validation, or document automation. The\nusability of ITLingo-Cloud was recently evaluated with two experiments and\ndiscussed with other related approaches.",
    "descriptor": "\nComments: 19 pages, 5 figures\n",
    "authors": [
      "Andre Nobre Barrocas",
      "Alberto Rodrigues Silva",
      "Joao Paulo Saraiva"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Human-Computer Interaction (cs.HC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.11828"
  },
  {
    "id": "arXiv:2211.11830",
    "title": "PhysQ: A Physics Informed Reinforcement Learning Framework for Building  Control",
    "abstract": "Large-scale integration of intermittent renewable energy sources calls for\nsubstantial demand side flexibility. Given that the built environment accounts\nfor approximately 40% of total energy consumption in EU, unlocking its\nflexibility is a key step in the energy transition process. This paper focuses\nspecifically on energy flexibility in residential buildings, leveraging their\nintrinsic thermal mass. Building on recent developments in the field of\ndata-driven control, we propose PhysQ. As a physics-informed reinforcement\nlearning framework for building control, PhysQ forms a step in bridging the gap\nbetween conventional model-based control and data-intensive control based on\nreinforcement learning. Through our experiments, we show that the proposed\nPhysQ framework can learn high quality control policies that outperform a\nbusiness-as-usual, as well as a rudimentary model predictive controller. Our\nexperiments indicate cost savings of about 9% compared to a business-as-usual\ncontroller. Further, we show that PhysQ efficiently leverages prior physics\nknowledge to learn such policies using fewer training samples than conventional\nreinforcement learning approaches, making PhysQ a scalable alternative for use\nin residential buildings. Additionally, the PhysQ control policy utilizes\nbuilding state representations that are intuitive and based on conventional\nbuilding models, that leads to better interpretation of the learnt policy over\nother data-driven controllers.",
    "descriptor": "\nComments: 15 pages, 4 figures,\n",
    "authors": [
      "Gargya Gokhale",
      "Bert Claessens",
      "Chris Develder"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.11830"
  },
  {
    "id": "arXiv:2211.11835",
    "title": "Fairness Increases Adversarial Vulnerability",
    "abstract": "The remarkable performance of deep learning models and their applications in\nconsequential domains (e.g., facial recognition) introduces important\nchallenges at the intersection of equity and security. Fairness and robustness\nare two desired notions often required in learning models. Fairness ensures\nthat models do not disproportionately harm (or benefit) some groups over\nothers, while robustness measures the models' resilience against small input\nperturbations.\nThis paper shows the existence of a dichotomy between fairness and\nrobustness, and analyzes when achieving fairness decreases the model robustness\nto adversarial samples. The reported analysis sheds light on the factors\ncausing such contrasting behavior, suggesting that distance to the decision\nboundary across groups as a key explainer for this behavior. Extensive\nexperiments on non-linear models and different architectures validate the\ntheoretical findings in multiple vision domains. Finally, the paper proposes a\nsimple, yet effective, solution to construct models achieving good tradeoffs\nbetween fairness and robustness.",
    "descriptor": "",
    "authors": [
      "Cuong Tran",
      "Keyu Zhu",
      "Ferdinando Fioretto",
      "Pascal Van Henternyck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.11835"
  },
  {
    "id": "arXiv:2211.11838",
    "title": "AdaFocal: Calibration-aware Adaptive Focal Loss",
    "abstract": "Much recent work has been devoted to the problem of ensuring that a neural\nnetwork's confidence scores match the true probability of being correct, i.e.\nthe calibration problem. Of note, it was found that training with focal loss\nleads to better calibration than cross-entropy while achieving similar level of\naccuracy \\cite{mukhoti2020}. This success stems from focal loss regularizing\nthe entropy of the model's prediction (controlled by the parameter $\\gamma$),\nthereby reining in the model's overconfidence. Further improvement is expected\nif $\\gamma$ is selected independently for each training sample\n(Sample-Dependent Focal Loss (FLSD-53) \\cite{mukhoti2020}). However, FLSD-53 is\nbased on heuristics and does not generalize well. In this paper, we propose a\ncalibration-aware adaptive focal loss called AdaFocal that utilizes the\ncalibration properties of focal (and inverse-focal) loss and adaptively\nmodifies $\\gamma_t$ for different groups of samples based on $\\gamma_{t-1}$\nfrom the previous step and the knowledge of model's under/over-confidence on\nthe validation set. We evaluate AdaFocal on various image recognition and one\nNLP task, covering a wide variety of network architectures, to confirm the\nimprovement in calibration while achieving similar levels of accuracy.\nAdditionally, we show that models trained with AdaFocal achieve a significant\nboost in out-of-distribution detection.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Arindam Ghosh",
      "Thomas Schaaf",
      "Matt Gormley"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11838"
  },
  {
    "id": "arXiv:2211.11839",
    "title": "Celeste is PSPACE-hard",
    "abstract": "We investigate the complexity of the platform video game Celeste. We prove\nthat navigating Celeste is PSPACE-hard in five different ways, corresponding to\ndifferent subsets of the game mechanics. In particular, we prove the game\nPSPACE-hard even without player input.",
    "descriptor": "\nComments: 15 pages, 13 figures. Presented at 23rd Thailand-Japan Conference on Discrete and Computational Geometry, Graphs, and Games\n",
    "authors": [
      "Lily Chung",
      "Erik D. Demaine"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.11839"
  },
  {
    "id": "arXiv:2211.11843",
    "title": "SLUGBOT, an Aplysia-inspired Robotic Grasper for Studying Control",
    "abstract": "Living systems can use a single periphery to perform a variety of tasks and\nadapt to a dynamic environment. This multifunctionality is achieved through the\nuse of neural circuitry that adaptively controls the reconfigurable\nmusculature. Current robotic systems struggle to flexibly adapt to unstructured\nenvironments. Through mimicry of the neuromechanical coupling seen in living\norganisms, robotic systems could potentially achieve greater autonomy. The\ntractable neuromechanics of the sea slug $\\textit{Aplysia californica's}$\nfeeding apparatus, or buccal mass, make it an ideal candidate for applying\nneuromechanical principles to the control of a soft robot. In this work, a\nrobotic grasper was designed to mimic specific morphology of the\n$\\textit{Aplysia}$ feeding apparatus. These include the use of soft actuators\nakin to biological muscle, a deformable grasping surface, and a similar\nmuscular architecture. A previously developed Boolean neural controller was\nthen adapted for the control of this soft robotic system. The robot was capable\nof qualitatively replicating swallowing behavior by cyclically ingesting a\nplastic tube. The robot's normalized translational and rotational kinematics of\nthe odontophore followed profiles observed $\\textit{in vivo}$ despite\nmorphological differences. This brings $\\textit{Aplysia}$-inspired control\n$\\textit{in roboto}$ one step closer to multifunctional neural control schema\n$\\textit{in vivo}$ and $\\textit{in silico}$. Future additions may improve\nSLUGBOT's viability as a neuromechanical research platform.",
    "descriptor": "\nComments: Submitted and accepted to Living Machines 2022 conference\n",
    "authors": [
      "Kevin Dai",
      "Ravesh Sukhnandan",
      "Michael Bennington",
      "Karen Whirley",
      "Ryan Bao",
      "Lu Li",
      "Jeffrey P. Gill",
      "Hillel J. Chiel",
      "Victoria A. Webster-Wood"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.11843"
  },
  {
    "id": "arXiv:2211.11846",
    "title": "Labeled Nearest Neighbor Search and Metric Spanners via Locality  Sensitive Orderings",
    "abstract": "Chan, Har-Peled, and Jones [SICOMP 2020] developed locality-sensitive\norderings (LSO) for Euclidean space. A $(\\tau,\\rho)$-LSO is a collection\n$\\Sigma$ of orderings such that for every $x,y\\in\\mathbb{R}^d$ there is an\nordering $\\sigma\\in\\Sigma$, where all the points between $x$ and $y$ w.r.t.\n$\\sigma$ are in the $\\rho$-neighborhood of either $x$ or $y$. In essence, LSO\nallow one to reduce problems to the $1$-dimensional line. Later, Filtser and Le\n[STOC 2022] developed LSO's for doubling metrics, general metric spaces, and\nminor free graphs.\nFor Euclidean and doubling spaces, the number of orderings in the LSO is\nexponential in the dimension, which made them mainly useful for the low\ndimensional regime. In this paper, we develop new LSO's for Euclidean,\n$\\ell_p$, and doubling spaces that allow us to trade larger stretch for a much\nsmaller number of orderings. We then use our new LSO's (as well as the previous\nones) to construct path reporting low hop spanners, fault tolerant spanners,\nreliable spanners, and light spanners for different metric spaces.\nWhile many nearest neighbor search (NNS) data structures were constructed for\nmetric spaces with implicit distance representations (where the distance\nbetween two metric points can be computed using their names, e.g. Euclidean\nspace), for other spaces almost nothing is known. In this paper we initiate the\nstudy of the labeled NNS problem, where one is allowed to artificially assign\nlabels (short names) to metric points. We use LSO's to construct efficient\nlabeled NNS data structures in this model.",
    "descriptor": "",
    "authors": [
      "Arnold Filtser"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2211.11846"
  },
  {
    "id": "arXiv:2211.11847",
    "title": "Towards Automated Polyp Segmentation Using Weakly- and Semi-Supervised  Learning and Deformable Transformers",
    "abstract": "Polyp segmentation is a crucial step towards computer-aided diagnosis of\ncolorectal cancer. However, most of the polyp segmentation methods require\npixel-wise annotated datasets. Annotated datasets are tedious and\ntime-consuming to produce, especially for physicians who must dedicate their\ntime to their patients. We tackle this issue by proposing a novel framework\nthat can be trained using only weakly annotated images along with exploiting\nunlabeled images. To this end, we propose three ideas to address this problem,\nmore specifically our contributions are: 1) a novel sparse foreground loss that\nsuppresses false positives and improves weakly-supervised training, 2) a\nbatch-wise weighted consistency loss utilizing predicted segmentation maps from\nidentical networks trained using different initialization during\nsemi-supervised training, 3) a deformable transformer encoder neck for feature\nenhancement by fusing information across levels and flexible spatial locations.\nExtensive experimental results demonstrate the merits of our ideas on five\nchallenging datasets outperforming some state-of-the-art fully supervised\nmodels. Also, our framework can be utilized to fine-tune models trained on\nnatural image segmentation datasets drastically improving their performance for\npolyp segmentation and impressively demonstrating superior performance to fully\nsupervised fine-tuning.",
    "descriptor": "",
    "authors": [
      "Guangyu Ren",
      "Michalis Lazarou",
      "Jing Yuan",
      "Tania Stathaki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11847"
  },
  {
    "id": "arXiv:2211.11853",
    "title": "Learnable Graph Convolutional Attention Networks",
    "abstract": "Existing Graph Neural Networks (GNNs) compute the message exchange between\nnodes by either aggregating uniformly (convolving) the features of all the\nneighboring nodes, or by applying a non-uniform score (attending) to the\nfeatures. Recent works have shown the strengths and weaknesses of the resulting\nGNN architectures, respectively, GCNs and GATs. In this work, we aim at\nexploiting the strengths of both approaches to their full extent. To this end,\nwe first introduce the graph convolutional attention layer (CAT), which relies\non convolutions to compute the attention scores. Unfortunately, as in the case\nof GCNs and GATs, we show that there exists no clear winner between the three\n(neither theoretically nor in practice) as their performance directly depends\non the nature of the data (i.e., of the graph and features). This result brings\nus to the main contribution of our work, the learnable graph convolutional\nattention network (L-CAT): a GNN architecture that automatically interpolates\nbetween GCN, GAT and CAT in each layer, by adding only two scalar parameters.\nOur results demonstrate that L-CAT is able to efficiently combine different GNN\nlayers along the network, outperforming competing methods in a wide range of\ndatasets, and resulting in a more robust model that reduces the need of\ncross-validating.",
    "descriptor": "\nComments: On review. 31 pages, 6 figures\n",
    "authors": [
      "Adri\u00e1n Javaloy",
      "Pablo Sanchez-Martin",
      "Amit Levi",
      "Isabel Valera"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11853"
  },
  {
    "id": "arXiv:2211.11855",
    "title": "MES-Attacks: Software-Controlled Covert Channels based on Mutual  Exclusion and Synchronization",
    "abstract": "Multi-process concurrency is effective in improving program efficiency and\nmaximizing CPU utilization. The correct execution of concurrency is ensured by\nthe mutual exclusion and synchronization mechanism (MESM) that manages the\nshared hardware and software resources. We propose MES-Attacks, a new set of\nsoftware-controlled covert channel attacks based on MESM to transmit\nconfidential information. MES-Attacks offer several advantages: 1) the covert\nchannels are constructed at software level and can be deployed on any hardware;\n2) closed share of resource ensures the quality of the channels with low\ninterference and makes them hard to be detected; and 3) it utilizes the\nsystem's software resources which are abound and hence difficult to isolate. We\nbuilt covert channels using different MESMs on Windows and Linux, including\nEvent, Timer, FileLockEX, Mutex, Semaphore and flock. Experimental results\ndemonstrate that these covert channels can achieve transmission rate of 13.105\nkb/s, 12.383 kb/s, and 6.552 kb/s, respectively in the scenarios of local,\ncross-sandbox and cross-VM, where the bit error rates are all under 1\\%.",
    "descriptor": "",
    "authors": [
      "Chaoqun Shen",
      "Jiliang Zhang",
      "Gang Qu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.11855"
  },
  {
    "id": "arXiv:2211.11856",
    "title": "String Covering: A Survey",
    "abstract": "The study of strings is an important combinatorial field that precedes the\ndigital computer. Strings can be very long, trillions of letters, so it is\nimportant to find compact representations. Here we first survey various forms\nof one potential compaction methodology, the cover of a given string x,\ninitially proposed in a simple form in 1990, but increasingly of interest as\nmore sophisticated variants have been discovered. We then consider covering by\na seed; that is, a cover of a superstring of x. We conclude with many proposals\nfor research directions that could make significant contributions to string\nprocessing in future.",
    "descriptor": "",
    "authors": [
      "Neerja Mhaskar",
      "W. F. Smyth"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.11856"
  },
  {
    "id": "arXiv:2211.11859",
    "title": "Capacity Analysis of the Fluctuating Double-Rayleigh with Line-of-Sight  Fading Channel",
    "abstract": "The proposed research performs the capacity analysis of the wireless channel\ndescribed by the fluctuating double-Rayleigh with the line-of-sight model. The\nclosed-form analytical expressions for the conditional capacity (in the case of\narbitrary noninteger fading parameter) and the ergodic capacity (in the case of\nthe integer fading parameter) are derived in terms of the extended generalized\nbivariate Meijer G-function. The exact solutions are succeeded by the\napproximating expressions deduced for the cases of small and large ratios\nbetween the Rician K-factor and the fading parameter. The performed numeric\nsimulation verifies the correctness of the derived results and analyzes the\nproposed capacity approximation quality performance.",
    "descriptor": "",
    "authors": [
      "Aleksey S. Gvozdarev"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.11859"
  },
  {
    "id": "arXiv:2211.11860",
    "title": "Upper and Lower Bounds on the Smoothed Complexity of the Simplex Method",
    "abstract": "The simplex method for linear programming is known to be highly efficient in\npractice, and understanding its performance from a theoretical perspective is\nan active research topic. The framework of smoothed analysis, first introduced\nby Spielman and Teng (JACM '04) for this purpose, defines the smoothed\ncomplexity of solving a linear program with $d$ variables and $n$ constraints\nas the expected running time when Gaussian noise of variance $\\sigma^2$ is\nadded to the LP data. We prove that the smoothed complexity of the simplex\nmethod is $O(\\sigma^{-3/2} d^{13/4}\\log^{7/4} n)$, improving the dependence on\n$1/\\sigma$ compared to the previous bound of $O(\\sigma^{-2} d^2\\sqrt{\\log n})$.\nWe accomplish this through a new analysis of the \\emph{shadow bound}, key to\nearlier analyses as well. Illustrating the power of our new method, we use our\nmethod to prove a nearly tight upper bound on the smoothed complexity of\ntwo-dimensional polygons.\nWe also establish the first non-trivial lower bound on the smoothed\ncomplexity of the simplex method, proving that the \\emph{shadow vertex simplex\nmethod} requires at least $\\Omega \\Big(\\min \\big(\\sigma^{-1/2}\nd^{-1/2}\\log^{-1/4} d,2^d \\big) \\Big)$ pivot steps with high probability. A key\npart of our analysis is a new variation on the extended formulation for the\nregular $2^k$-gon. We end with a numerical experiment that suggests this\nanalysis could be further improved.",
    "descriptor": "\nComments: 41 pages, 5 figures\n",
    "authors": [
      "Sophie Huiberts",
      "Yin Tat Lee",
      "Xinzhi Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.11860"
  },
  {
    "id": "arXiv:2211.11861",
    "title": "A plea for an upgrade to the digital craft of the historian and digital  methodology for discovering the past",
    "abstract": "This essay aims to bid analogue historians assume that digitisation is the\nfirst step to creating historical heritage based on the new language of\nScience: Computer Science. As we know, Humanities disciplines cannot easily be\nencapsulated in a few understandable numbers and names. However, historians\nmust boost Artificial Intelligence (such as Transkribus) and Neural Networks to\nlet the Machine infer meaning from the digitised historical primary source and\nbecome the most powerful tool to help historians understand what happened in\nthe Past. Historians (collaborating with data scientists, expert annotators,\nlibrarians, archivists, and others, who are crucial to the successful\nmanagement of digital data collection) have to create the primary ontology,\nstarting from coding manuscripts into digital text, as the Biscari Archive\n(Italy) study case.",
    "descriptor": "",
    "authors": [
      "Salvatore Spina"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2211.11861"
  },
  {
    "id": "arXiv:2211.11863",
    "title": "Twin-S: A Digital Twin for Skull-base Surgery",
    "abstract": "Purpose: Digital twins are virtual interactive models of the real world,\nexhibiting identical behavior and properties. In surgical applications,\ncomputational analysis from digital twins can be used, for example, to enhance\nsituational awareness. Methods: We present a digital twin framework for\nskull-base surgeries, named Twin-S, which can be integrated within various\nimage-guided interventions seamlessly. Twin-S combines high-precision optical\ntracking and real-time simulation. We rely on rigorous calibration routines to\nensure that the digital twin representation precisely mimics all real-world\nprocesses. Twin-S models and tracks the critical components of skull-base\nsurgery, including the surgical tool, patient anatomy, and surgical camera.\nSignificantly, Twin-S updates and reflects real-world drilling of the\nanatomical model in frame rate. Results: We extensively evaluate the accuracy\nof Twin-S, which achieves an average 1.39 mm error during the drilling process.\nWe further illustrate how segmentation masks derived from the continuously\nupdated digital twin can augment the surgical microscope view in a mixed\nreality setting, where bone requiring ablation is highlighted to provide\nsurgeons additional situational awareness. Conclusion: We present Twin-S, a\ndigital twin environment for skull-base surgery. Twin-S tracks and updates the\nvirtual model in real-time given measurements from modern tracking\ntechnologies. Future research on complementing optical tracking with\nhigher-precision vision-based approaches may further increase the accuracy of\nTwin-S.",
    "descriptor": "",
    "authors": [
      "Hongchao Shu",
      "Ruixing Liang",
      "Zhaoshuo Li",
      "Anna Goodridge",
      "Xiangyu Zhang",
      "Hao Ding",
      "Nimesh Nagururu",
      "Manish Sahu",
      "Francis X. Creighton",
      "Russell H. Taylor",
      "Adnan Munawar",
      "Mathias Unberath"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.11863"
  },
  {
    "id": "arXiv:2211.11867",
    "title": "The AMD Rome Memory Barrier",
    "abstract": "With the rapid growth of AMD as a competitor in the CPU industry, it is\nimperative that high-performance and architectural engineers analyze new AMD\nCPUs. By understanding new and unfamiliar architectures, engineers are able to\nadapt their algorithms to fully utilize new hardware. Furthermore, engineers\nare able to anticipate the limitations of an architecture and determine when an\nalternate platform is desirable for a particular workload. This paper presents\nresults which show that the AMD \"Rome\" architecture performance suffers once an\napplication's memory bandwidth exceeds 37.5 GiB/s for integer-heavy\napplications, or 100 GiB/s for floating-point-heavy workloads. Strong positive\ncorrelations between memory bandwidth and CPI are presented, as well as strong\npositive correlations between increased memory load and time-to-completion of\nbenchmarks from the SPEC CPU2017 benchmark suites.",
    "descriptor": "\nComments: Very, very early draft for IEEE SoutheastCon 2017, 9 pages (need to get down to 8), 6 figures, 7 tables\n",
    "authors": [
      "Phillip Allen Lane",
      "Jessica Lobrano"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2211.11867"
  },
  {
    "id": "arXiv:2211.11869",
    "title": "Examining Policy Entropy of Reinforcement Learning Agents for  Personalization Tasks",
    "abstract": "This effort is focused on examining the behavior of reinforcement learning\nsystems in personalization environments and detailing the differences in policy\nentropy associated with the type of learning algorithm utilized. We demonstrate\nthat Policy Optimization agents often possess low-entropy policies during\ntraining, which in practice results in agents prioritizing certain actions and\navoiding others. Conversely, we also show that Q-Learning agents are far less\nsusceptible to such behavior and generally maintain high-entropy policies\nthroughout training, which is often preferable in real-world applications. We\nprovide a wide range of numerical experiments as well as theoretical\njustification to show that these differences in entropy are due to the type of\nlearning being employed.",
    "descriptor": "",
    "authors": [
      "Anton Dereventsov",
      "Andrew Starnes",
      "Clayton G. Webster"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.11869"
  },
  {
    "id": "arXiv:2211.11870",
    "title": "LoopDA: Constructing Self-loops to Adapt Nighttime Semantic Segmentation",
    "abstract": "Due to the lack of training labels and the difficulty of annotating, dealing\nwith adverse driving conditions such as nighttime has posed a huge challenge to\nthe perception system of autonomous vehicles. Therefore, adapting knowledge\nfrom a labelled daytime domain to an unlabelled nighttime domain has been\nwidely researched. In addition to labelled daytime datasets, existing nighttime\ndatasets usually provide nighttime images with corresponding daytime reference\nimages captured at nearby locations for reference. The key challenge is to\nminimize the performance gap between the two domains. In this paper, we propose\nLoopDA for domain adaptive nighttime semantic segmentation. It consists of\nself-loops that result in reconstructing the input data using predicted\nsemantic maps, by rendering them into the encoded features. In a warm-up\ntraining stage, the self-loops comprise of an inner-loop and an outer-loop,\nwhich are responsible for intra-domain refinement and inter-domain alignment,\nrespectively. To reduce the impact of day-night pose shifts, in the later\nself-training stage, we propose a co-teaching pipeline that involves an offline\npseudo-supervision signal and an online reference-guided signal `DNA'\n(Day-Night Agreement), bringing substantial benefits to enhance nighttime\nsegmentation. Our model outperforms prior methods on Dark Zurich and Nighttime\nDriving datasets for semantic segmentation. Code and pretrained models are\navailable at https://github.com/fy-vision/LoopDA.",
    "descriptor": "\nComments: Accepted to WACV2023\n",
    "authors": [
      "Fengyi Shen",
      "Zador Pataki",
      "Akhil Gurram",
      "Ziyuan Liu",
      "He Wang",
      "Alois Knoll"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11870"
  },
  {
    "id": "arXiv:2211.11874",
    "title": "A Lightweight Modular Continuum Manipulator with IMU-based Force  Estimation",
    "abstract": "Most aerial manipulators use serial rigid-link designs, which results in\nlarge forces when initiating contacts during manipulation and could cause\nflight stability difficulty. This limitation could potentially be improved by\nthe compliance of continuum manipulators. To achieve this goal, we present the\nnovel design of a compact, lightweight, and modular cable-driven continuum\nmanipulator for aerial drones. We then derive a complete modeling framework for\nits kinematics, statics, and stiffness (compliance). The modeling framework can\nguide the control and design problems to integrate the manipulator to aerial\ndrones. In addition, thanks to the derived stiffness (compliance) matrix, and\nusing a low-cost IMU sensor to capture deformation angles, we present a simple\nmethod to estimate manipulation force at the tip of the manipulator. We report\npreliminary experimental validations of the hardware prototype, providing\ninsights on its manipulation feasibility. We also report preliminary results of\nthe IMU-based force estimation method.",
    "descriptor": "\nComments: 12 pages, submitted to ASME Journal of Mechanisms and Robotics 2022, under review. arXiv admin note: substantial text overlap with arXiv:2206.06246\n",
    "authors": [
      "Guoqing Zhang",
      "Qianwen Zhao",
      "Long Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.11874"
  },
  {
    "id": "arXiv:2211.11875",
    "title": "Enhancing Self-Consistency and Performance of Pre-Trained Language  Models through Natural Language Inference",
    "abstract": "While large pre-trained language models are powerful, their predictions often\nlack logical consistency across test inputs. For example, a state-of-the-art\nMacaw question-answering (QA) model answers 'Yes' to 'Is a sparrow a bird?' and\n'Does a bird have feet?' but answers 'No' to 'Does a sparrow have feet?'. To\naddress this failure mode, we propose a framework, Consistency Correction\nthrough Relation Detection, or ConCoRD, for boosting the consistency and\naccuracy of pre-trained NLP models using pre-trained natural language inference\n(NLI) models without fine-tuning or re-training. Given a batch of test inputs,\nConCoRD samples several candidate outputs for each input and instantiates a\nfactor graph that accounts for both the model's belief about the likelihood of\neach answer choice in isolation and the NLI model's beliefs about pair-wise\nanswer choice compatibility. We show that a weighted MaxSAT solver can\nefficiently compute high-quality answer choices under this factor graph,\nimproving over the raw model's predictions. Our experiments demonstrate that\nConCoRD consistently boosts accuracy and consistency of off-the-shelf\nclosed-book QA and VQA models using off-the-shelf NLI models, notably\nincreasing accuracy of LXMERT on ConVQA by 5% absolute. See\nhttps://ericmitchell.ai/emnlp-2022-concord/ for code and data.",
    "descriptor": "\nComments: 16 pages. EMNLP 2022 Camera Ready. See this https URL for code and data\n",
    "authors": [
      "Eric Mitchell",
      "Joseph J. Noh",
      "Siyan Li",
      "William S. Armstrong",
      "Ananth Agarwal",
      "Patrick Liu",
      "Chelsea Finn",
      "Christopher D. Manning"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11875"
  },
  {
    "id": "arXiv:2211.11879",
    "title": "Autocorrelation and Spectrum Analysis for Variable Symbol Length  Communications with Feedback",
    "abstract": "Variable-length feedback codes can provide advantages over fixed-length\nfeedback or non-feedback codes. This letter focuses on uncoded\nvariable-symbol-length feedback communication and analyzes the autocorrelation\nand spectrum of the signal. We provide a mathematical expression for the\nautocorrelation that can be evaluated numerically. We then numerically evaluate\nthe autocorrelation and spectrum for the variable-symbol-length signal in a\nfeedback-based communication system that attains a target reliability for every\nsymbol by adapting the symbol length to the noise realization. The analysis and\nnumerical results show that the spectrum changes with SNR when the average\nsymbol length is fixed, and approaches the fixed-length scheme at high SNR.",
    "descriptor": "",
    "authors": [
      "Chin-Wei Hsu",
      "Hun-Seok Kim",
      "Achilleas Anastasopoulos"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.11879"
  },
  {
    "id": "arXiv:2211.11880",
    "title": "Addressing Mistake Severity in Neural Networks with Semantic Knowledge",
    "abstract": "Robustness in deep neural networks and machine learning algorithms in general\nis an open research challenge. In particular, it is difficult to ensure\nalgorithmic performance is maintained on out-of-distribution inputs or\nanomalous instances that cannot be anticipated at training time. Embodied\nagents will be deployed in these conditions, and are likely to make incorrect\npredictions. An agent will be viewed as untrustworthy unless it can maintain\nits performance in dynamic environments. Most robust training techniques aim to\nimprove model accuracy on perturbed inputs; as an alternate form of robustness,\nwe aim to reduce the severity of mistakes made by neural networks in\nchallenging conditions. We leverage current adversarial training methods to\ngenerate targeted adversarial attacks during the training process in order to\nincrease the semantic similarity between a model's predictions and true labels\nof misclassified instances. Results demonstrate that our approach performs\nbetter with respect to mistake severity compared to standard and adversarially\ntrained models. We also find an intriguing role that non-robust features play\nwith regards to semantic similarity.",
    "descriptor": "",
    "authors": [
      "Natalie Abreu",
      "Nathan Vaska",
      "Victoria Helus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11880"
  },
  {
    "id": "arXiv:2211.11883",
    "title": "CodEval: Improving Student Success In Programming Assignments",
    "abstract": "CodEval is a code evaluation tool that integrates with the Canvas Learning\nManagement System to automatically evaluates students' work within a few\nminutes of the submission. This early feedback allows students to catch and\ncorrect problems in their submissions before their submission is graded and\ngives them a clear idea of the quality of their submission. CodEval handles the\ntedious aspects of grading, such as compiling and running tests, leaving\ngraders more time to spend on the qualitative aspect of grading.\nBefore using CodEval, instructors would not have a clear view of the\nstudent's comprehension of the concept evaluated by the assignment until after\nthe due date. CodeEval helps instructors identify and address the gaps in\nstudents' understanding and thus helps more students successfully complete the\nassignment.\nWe implemented CodEval using Python using the public Canvas API. Any\ninstructor or grader for a Canvas course can use CodEval to automatically\nevaluate submissions for programming assignments. We developed a syntax to\nexpress requirements of submissions such as compilation parameters, inputs,\noutputs, command-line arguments, timeouts, exit codes, functions used, files\ngenerated, output validators, and more. We have made CodEval open source.\nCodEval is an easy tool for students, graders, and instructors and seamlessly\nintegrates with Canvas. We share our experience with using CodEval in two\nclasses with a total of 90 students and multiple coding assignments.",
    "descriptor": "",
    "authors": [
      "Aditi Agrawal",
      "Archit Jain",
      "Benjamin Reed"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.11883"
  },
  {
    "id": "arXiv:2211.11885",
    "title": "Completeness Thresholds for Memory Safety: Early Preliminary Report",
    "abstract": "In this early preliminary report on an ongoing project, we present -- to the\nbest of our knowledge -- the first study of completeness thresholds for memory\nsafety proofs. Specifically we consider heap-manipulating programs that iterate\nover arrays without allocating or freeing memory. We present the first notion\nof completeness thresholds for program verification which reduce unbounded\nmemory safety proofs to bounded ones. Moreover, we present some preliminary\nideas on how completeness thresholds can be computed for concrete programs.",
    "descriptor": "\nComments: 20 pages, early preliminary report\n",
    "authors": [
      "Tobias Reinhard"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.11885"
  },
  {
    "id": "arXiv:2211.11886",
    "title": "Value-based CTDE Methods in Symmetric Two-team Markov Game: from  Cooperation to Team Competition",
    "abstract": "In this paper, we identify the best learning scenario to train a team of\nagents to compete against multiple possible strategies of opposing teams. We\nevaluate cooperative value-based methods in a mixed cooperative-competitive\nenvironment. We restrict ourselves to the case of a symmetric, partially\nobservable, two-team Markov game. We selected three training methods based on\nthe centralised training and decentralised execution (CTDE) paradigm: QMIX,\nMAVEN and QVMix. For each method, we considered three learning scenarios\ndifferentiated by the variety of team policies encountered during training. For\nour experiments, we modified the StarCraft Multi-Agent Challenge environment to\ncreate competitive environments where both teams could learn and compete\nsimultaneously. Our results suggest that training against multiple evolving\nstrategies achieves the best results when, for scoring their performances,\nteams are faced with several strategies.",
    "descriptor": "",
    "authors": [
      "Pascal Leroy",
      "Jonathan Pisane",
      "Damien Ernst"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.11886"
  },
  {
    "id": "arXiv:2211.11890",
    "title": "TEMPERA: Test-Time Prompting via Reinforcement Learning",
    "abstract": "Careful prompt design is critical to the use of large language models in\nzero-shot or few-shot learning. As a consequence, there is a growing interest\nin automated methods to design optimal prompts. In this work, we propose\nTest-time Prompt Editing using Reinforcement learning (TEMPERA). In contrast to\nprior prompt generation methods, TEMPERA can efficiently leverage prior\nknowledge, is adaptive to different queries and provides an interpretable\nprompt for every query. To achieve this, we design a novel action space that\nallows flexible editing of the initial prompts covering a wide set of\ncommonly-used components like instructions, few-shot exemplars, and\nverbalizers. The proposed method achieves significant gains compared with\nrecent SoTA approaches like prompt tuning, AutoPrompt, and RLPrompt, across a\nvariety of tasks including sentiment analysis, topic classification, natural\nlanguage inference, and reading comprehension. Our method achieves 5.33x on\naverage improvement in sample efficiency when compared to the traditional\nfine-tuning methods.",
    "descriptor": "",
    "authors": [
      "Tianjun Zhang",
      "Xuezhi Wang",
      "Denny Zhou",
      "Dale Schuurmans",
      "Joseph E. Gonzalez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11890"
  },
  {
    "id": "arXiv:2211.11896",
    "title": "Private Ad Modeling with DP-SGD",
    "abstract": "A well-known algorithm in privacy-preserving ML is differentially private\nstochastic gradient descent (DP-SGD). While this algorithm has been evaluated\non text and image data, it has not been previously applied to ads data, which\nare notorious for their high class imbalance and sparse gradient updates. In\nthis work we apply DP-SGD to several ad modeling tasks including predicting\nclick-through rates, conversion rates, and number of conversion events, and\nevaluate their privacy-utility trade-off on real-world datasets. Our work is\nthe first to empirically demonstrate that DP-SGD can provide both privacy and\nutility for ad modeling tasks.",
    "descriptor": "",
    "authors": [
      "Carson Denison",
      "Badih Ghazi",
      "Pritish Kamath",
      "Ravi Kumar",
      "Pasin Manurangsi",
      "Krishna Giri Narra",
      "Amer Sinha",
      "Avinash Varadarajan",
      "Chiyuan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.11896"
  },
  {
    "id": "arXiv:2211.11897",
    "title": "Continuous Functions on Final Comodels of Free Algebraic Theories",
    "abstract": "In 2009, Ghani, Hancock and Pattinson gave a tree-like representation of\nstream processors $A^{\\mathbb{N}} \\rightarrow B^{\\mathbb{N}}$. In 2021, Garner\nshowed that this representation can be established in terms of algebraic theory\nand comodels: the set of infinite streams $A^{\\mathbb{N}}$ is the final comodel\nof the algebraic theory of $A$-valued input $\\mathbb{T}_A$ and the set of\nstream processors $\\mathit{Top}(A^{\\mathbb{N}},B^{\\mathbb{N}})$ can be seen as\nthe final $\\mathbb{T}_A$-$\\mathbb{T}_B$-bimodel. In this paper, we generalize\nGarner's results to the case of free algebraic theories.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Tomoya Yoshida"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2211.11897"
  },
  {
    "id": "arXiv:2211.11902",
    "title": "Evaluating the Knowledge Dependency of Questions",
    "abstract": "The automatic generation of Multiple Choice Questions (MCQ) has the potential\nto reduce the time educators spend on student assessment significantly.\nHowever, existing evaluation metrics for MCQ generation, such as BLEU, ROUGE,\nand METEOR, focus on the n-gram based similarity of the generated MCQ to the\ngold sample in the dataset and disregard their educational value. They fail to\nevaluate the MCQ's ability to assess the student's knowledge of the\ncorresponding target fact. To tackle this issue, we propose a novel automatic\nevaluation metric, coined Knowledge Dependent Answerability (KDA), which\nmeasures the MCQ's answerability given knowledge of the target fact.\nSpecifically, we first show how to measure KDA based on student responses from\na human survey. Then, we propose two automatic evaluation metrics, KDA_disc and\nKDA_cont, that approximate KDA by leveraging pre-trained language models to\nimitate students' problem-solving behavior. Through our human studies, we show\nthat KDA_disc and KDA_soft have strong correlations with both (1) KDA and (2)\nusability in an actual classroom setting, labeled by experts. Furthermore, when\ncombined with n-gram based similarity metrics, KDA_disc and KDA_cont are shown\nto have a strong predictive power for various expert-labeled MCQ quality\nmeasures.",
    "descriptor": "\nComments: EMNLP 2022 (Main, Long)\n",
    "authors": [
      "Hyeongdon Moon",
      "Yoonseok Yang",
      "Jamin Shin",
      "Hangyeol Yu",
      "Seunghyun Lee",
      "Myeongho Jeong",
      "Juneyoung Park",
      "Minsam Kim",
      "Seungtaek Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11902"
  },
  {
    "id": "arXiv:2211.11903",
    "title": "FLEX: Full-Body Grasping Without Full-Body Grasps",
    "abstract": "Synthesizing 3D human avatars interacting realistically with a scene is an\nimportant problem with applications in AR/VR, video games and robotics. Towards\nthis goal, we address the task of generating a virtual human -- hands and full\nbody -- grasping everyday objects. Existing methods approach this problem by\ncollecting a 3D dataset of humans interacting with objects and training on this\ndata. However, 1) these methods do not generalize to different object positions\nand orientations, or to the presence of furniture in the scene, and 2) the\ndiversity of their generated full-body poses is very limited. In this work, we\naddress all the above challenges to generate realistic, diverse full-body\ngrasps in everyday scenes without requiring any 3D full-body grasping data. Our\nkey insight is to leverage the existence of both full-body pose and hand\ngrasping priors, composing them using 3D geometrical constraints to obtain\nfull-body grasps. We empirically validate that these constraints can generate a\nvariety of feasible human grasps that are superior to baselines both\nquantitatively and qualitatively. See our webpage for more details:\nhttps://flex.cs.columbia.edu/.",
    "descriptor": "",
    "authors": [
      "Purva Tendulkar",
      "D\u00eddac Sur\u00eds",
      "Carl Vondrick"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11903"
  },
  {
    "id": "arXiv:2211.11904",
    "title": "EM's Convergence in Gaussian Latent Tree Models",
    "abstract": "We study the optimization landscape of the log-likelihood function and the\nconvergence of the Expectation-Maximization (EM) algorithm in latent Gaussian\ntree models, i.e.~tree-structured Gaussian graphical models whose leaf nodes\nare observable and non-leaf nodes are unobservable. We show that the unique\nnon-trivial stationary point of the population log-likelihood is its global\nmaximum, and establish that the expectation-maximization algorithm is\nguaranteed to converge to it in the single latent variable case. Our results\nfor the landscape of the log-likelihood function in general latent tree models\nprovide support for the extensive practical use of maximum likelihood\nbased-methods in this setting. Our results for the EM algorithm extend an\nemerging line of work on obtaining global convergence guarantees for this\ncelebrated algorithm. We show our results for the non-trivial stationary points\nof the log-likelihood by arguing that a certain system of polynomial equations\nobtained from the EM updates has a unique non-trivial solution. The global\nconvergence of the EM algorithm follows by arguing that all trivial fixed\npoints are higher-order saddle points.",
    "descriptor": "",
    "authors": [
      "Yuval Dagan",
      "Constantinos Daskalakis",
      "Anthimos Vardis Kandiros"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.11904"
  },
  {
    "id": "arXiv:2211.11907",
    "title": "Robust Faber--Schauder approximation based on discrete observations of  an antiderivative",
    "abstract": "We study the problem of reconstructing the Faber--Schauder coefficients of a\ncontinuous function $f$ from discrete observations of its antiderivative $F$.\nOur approach starts with formulating this problem through piecewise quadratic\nspline interpolation. We then provide a closed-form solution and an in-depth\nerror analysis. These results lead to some surprising observations, which also\nthrow new light on the classical topic of quadratic spline interpolation\nitself: They show that the well-known instabilities of this method can be\nlocated exclusively within the final generation of estimated Faber--Schauder\ncoefficients, which suffer from non-locality and strong dependence on the\ninitial value and the given data. By contrast, all other Faber--Schauder\ncoefficients depend only locally on the data, are independent of the initial\nvalue, and admit uniform error bounds. We thus conclude that a robust and\nwell-behaved estimator for our problem can be obtained by simply dropping the\nfinal-generation coefficients from the estimated Faber--Schauder coefficients.",
    "descriptor": "",
    "authors": [
      "Xiyue Han",
      "Alexander Schied"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Statistical Finance (q-fin.ST)"
    ],
    "url": "https://arxiv.org/abs/2211.11907"
  },
  {
    "id": "arXiv:2211.11908",
    "title": "Contract-Based Specification Refinement and Repair for Mission Planning",
    "abstract": "We address the problem of modeling, refining, and repairing formal\nspecifications for robotic missions using assume-guarantee contracts. We show\nhow to model mission specifications at various levels of abstraction and\nimplement them using a library of pre-implemented specifications. Suppose the\nspecification cannot be met using components from the library. In that case, we\ncompute a proxy for the best approximation to the specification that can be\ngenerated using elements from the library. Afterward, we propose a systematic\nway to either 1) search for and refine the `missing part' of the specification\nthat the library cannot meet or 2) repair the current specification such that\nthe existing library can refine it. Our methodology for searching and repairing\nmission requirements leverages the quotient, separation, composition, and\nmerging operations between contracts.",
    "descriptor": "",
    "authors": [
      "Piergiuseppe Mallozzi",
      "Inigo Incer",
      "Pierluigi Nuzzo",
      "Alberto Sangiovanni-Vincentelli"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.11908"
  },
  {
    "id": "arXiv:2211.11912",
    "title": "Quasi-stable Coloring for Graph Compression: Approximating Max-Flow,  Linear Programs, and Centrality",
    "abstract": "We propose quasi-stable coloring, an approximate version of stable coloring.\nStable coloring, also called color refinement, is a well-studied technique in\ngraph theory for classifying vertices, which can be used to build compact,\nlossless representations of graphs. However, its usefulness is limited due to\nits reliance on strict symmetries. Real data compresses very poorly using color\nrefinement. We propose the first, to our knowledge, approximate color\nrefinement scheme, which we call quasi-stable coloring. By using approximation,\nwe alleviate the need for strict symmetry, and allow for a tradeoff between the\ndegree of compression and the accuracy of the representation. We study three\napplications: Linear Programming, Max-Flow, and Betweenness Centrality, and\nprovide theoretical evidence in each case that a quasi-stable coloring can lead\nto good approximations on the reduced graph. Next, we consider how to compute a\nmaximal quasi-stable coloring: we prove that, in general, this problem is\nNP-hard, and propose a simple, yet effective algorithm based on heuristics.\nFinally, we evaluate experimentally the quasi-stable coloring technique on\nseveral real graphs and applications, comparing with prior approximation\ntechniques.\nA reference implementation and the experiment code are available at\nhttps://github.com/mkyl/QuasiStableColors.jl",
    "descriptor": "\nComments: To be presented at VLDB 2023\n",
    "authors": [
      "Moe Kayali",
      "Dan Suciu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.11912"
  },
  {
    "id": "arXiv:2211.11916",
    "title": "Preprint: Open Source Compiling for V1Model RMT Switch: Making Data  Center Networking Innovation Accessible",
    "abstract": "Very few of the innovations in deep networking have seen data center scale\nimplementation. Because the Data Center network's extreme scale performance\nrequires hardware implementation, which is only accessible to a few. However,\nthe emergence of reconfigurable match-action table (RMT) paradigm-based\nswitches have finally opened up the development life cycle of data plane\ndevices. The P4 language is the dominant language choice for programming these\ndevices. Now, Network operators can implement the desired feature over white\nbox RMT switches. The process involves an innovator writing new algorithms in\nthe P4 language and getting them compiled for the target hardware. However,\nthere is still a roadblock. After designing an algorithm, the P4 program's\ncompilation technology is not fully open-source. Thus, it is very difficult for\nan average researcher to get deep insight into the performance of his/her\ninnovation when executed at the silicon level. There is no open-source compiler\nbackend available for this purpose. Proprietary compiler backends provided by\ndifferent hardware vendors are available for this purpose. However, they are\nclosed-source and do not provide access to the internal mapping mechanisms.\nWhich inhibits experimenting with new mapping algorithms and innovative\ninstruction sets for reconfigurable match-action table architecture. This paper\ndescribes our work toward an open-source compiler backend for compiling P416\ntargeted for the V1Model architecture-based programmable switches.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2208.12892\n",
    "authors": [
      "Debobroto Das Robin",
      "Javed I. Khan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.11916"
  },
  {
    "id": "arXiv:2211.11917",
    "title": "Latent Iterative Refinement for Modular Source Separation",
    "abstract": "Traditional source separation approaches train deep neural network models\nend-to-end with all the data available at once by minimizing the empirical risk\non the whole training set. On the inference side, after training the model, the\nuser fetches a static computation graph and runs the full model on some\nspecified observed mixture signal to get the estimated source signals.\nAdditionally, many of those models consist of several basic processing blocks\nwhich are applied sequentially. We argue that we can significantly increase\nresource efficiency during both training and inference stages by reformulating\na model's training and inference procedures as iterative mappings of latent\nsignal representations. First, we can apply the same processing block more than\nonce on its output to refine the input signal and consequently improve\nparameter efficiency. During training, we can follow a block-wise procedure\nwhich enables a reduction on memory requirements. Thus, one can train a very\ncomplicated network structure using significantly less computation compared to\nend-to-end training. During inference, we can dynamically adjust how many\nprocessing blocks and iterations of a specific block an input signal needs\nusing a gating module.",
    "descriptor": "",
    "authors": [
      "Dimitrios Bralios",
      "Efthymios Tzinis",
      "Gordon Wichern",
      "Paris Smaragdis",
      "Jonathan Le Roux"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.11917"
  },
  {
    "id": "arXiv:2211.11918",
    "title": "Predictive Display with Perspective Projection of Surroundings in  Vehicle Teleoperation to Account Time-delays",
    "abstract": "Teleoperation provides human operator sophisticated perceptual and cognitive\nskills into an over the network control loop. It gives hope of addressing some\nchallenges related to vehicular autonomy which is based on artificial\nintelligence by providing a backup plan. Variable network time delays in data\ntransmission is the major problem in teleoperating a vehicle. On 4G network,\nvariability of these delays is high. Due to this, both video streaming and\ndriving commands encounter variable time delay. This paper presents an approach\nof providing the human operator a forecast video stream which replicates future\nperspective of vehicle field of view accounting the delay present in the\nnetwork. Regarding the image transformation, perspective projection technique\nis combined with correction given by smith predictor in the control loop. This\nimage transformation accounts current time delay and tries to address both\nissues, time delays as well as its variability. For experiment sake, only\nfrontward field of view is forecast. Performance is evaluated by performing\nonline vehicle teleoperation on street edge case maneuvers and later comparing\nthe path deviation with and without perspective projection.",
    "descriptor": "",
    "authors": [
      "Jai Prakash",
      "Michele Vignati",
      "Daniele Vignarca",
      "Edoardo Sabbioni",
      "Federico Cheli"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.11918"
  },
  {
    "id": "arXiv:2211.11921",
    "title": "Confidence-guided Centroids for Unsupervised Person Re-Identification",
    "abstract": "Unsupervised person re-identification (ReID) aims to train a feature\nextractor for identity retrieval without exploiting identity labels. Due to the\nblind trust in imperfect clustering results, the learning is inevitably misled\nby unreliable pseudo labels. Albeit the pseudo label refinement has been\ninvestigated by previous works, they generally leverage auxiliary information\nsuch as camera IDs and body part predictions. This work explores the internal\ncharacteristics of clusters to refine pseudo labels. To this end,\nConfidence-Guided Centroids (CGC) are proposed to provide reliable cluster-wise\nprototypes for feature learning. Since samples with high confidence are\nexclusively involved in the formation of centroids, the identity information of\nlow-confidence samples, i.e., boundary samples, are NOT likely to contribute to\nthe corresponding centroid. Given the new centroids, current learning scheme,\nwhere samples are enforced to learn from their assigned centroids solely, is\nunwise. To remedy the situation, we propose to use Confidence-Guided pseudo\nLabel (CGL), which enables samples to approach not only the originally assigned\ncentroid but other centroids that are potentially embedded with their identity\ninformation. Empowered by confidence-guided centroids and labels, our method\nyields comparable performance with, or even outperforms, state-of-the-art\npseudo label refinement works that largely leverage auxiliary information.",
    "descriptor": "",
    "authors": [
      "Yunqi Miao",
      "Jiankang Deng",
      "Guiguang Ding",
      "Jungong Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11921"
  },
  {
    "id": "arXiv:2211.11922",
    "title": "Practice Makes Perfect: an iterative approach to achieve precise  tracking for legged robots",
    "abstract": "Precise trajectory tracking for legged robots can be challenging due to their\nhigh degrees of freedom, unmodeled nonlinear dynamics, or random disturbances\nfrom the environment. A commonly adopted solution to overcome these challenges\nis to use optimization-based algorithms and approximate the system with a\nsimplified, reduced-order model. Additionally, deep neural networks are\nbecoming a more promising option for achieving agile and robust legged\nlocomotion. These approaches, however, either require large amounts of onboard\ncalculations or the collection of millions of data points from a single robot.\nTo address these problems and improve tracking performance, this paper proposes\na method based on iterative learning control. This method lets a robot learn\nfrom its own mistakes by exploiting the repetitive nature of legged locomotion\nwithin only a few trials. Then, a torque library is created as a lookup table\nso that the robot does not need to repeat calculations or learn the same skill\nover and over again. This process resembles how animals learn their muscle\nmemories in nature. The proposed method is tested on the A1 robot in a\nsimulated environment, and it allows the robot to pronk at different speeds\nwhile precisely following the reference trajectories without heavy\ncalculations.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Jing Cheng",
      "Yasser G. Alqaham",
      "Amit K. Sanyal",
      "Zhenyu Gan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.11922"
  },
  {
    "id": "arXiv:2211.11923",
    "title": "Towards Optimal Coreset Construction for $(k,z)$-Clustering: Breaking  the Quadratic Dependency on $k$",
    "abstract": "Constructing small-sized coresets for various clustering problems has\nattracted significant attention recently. We provide efficient coreset\nconstruction algorithms for $(k, z)$-Clustering with improved coreset sizes in\nseveral metric spaces. In particular, we provide an\n$\\tilde{O}_z(k^{(2z+2)/(z+2)}\\varepsilon^{-2})$-sized coreset for $(k,\nz)$-Clustering for all $z\\geq 1$ in Euclidean space, improving upon the best\nknown $\\tilde{O}_z(k^2\\varepsilon^{-2})$ size upper bound [Cohen-Addad, Larsen,\nSaulpic, Schwiegelshohn. STOC'22], breaking the quadratic dependency on $k$ for\nthe first time (when $k\\leq \\varepsilon^{-1}$). For example, our coreset size\nfor Euclidean $k$-Median is $\\tilde{O}(k^{4/3} \\varepsilon^{-2})$, improving\nthe best known result $\\tilde{O}(\\min\\left\\{k^2\\varepsilon^{-2},\nk\\varepsilon^{-3}\\right\\})$ by a factor $k^{2/3}$ when $k\\leq\n\\varepsilon^{-1}$; for Euclidean $k$-Means, our coreset size is\n$\\tilde{O}(k^{3/2} \\varepsilon^{-2})$, improving the best known result\n$\\tilde{O}(\\min\\left\\{k^2\\varepsilon^{-2}, k\\varepsilon^{-4}\\right\\})$ by a\nfactor $k^{1/2}$ when $k\\leq \\varepsilon^{-2}$. We also obtain optimal or\nimproved coreset sizes for general metric space, metric space with bounded\ndoubling dimension, and shortest path metric when the underlying graph has\nbounded treewidth, for all $z\\geq 1$. Our algorithm largely follows the\nframework developed by Cohen-Addad et al. with some minor but useful changes.\nOur technical contribution mainly lies in the analysis. An important\nimprovement in our analysis is a new notion of $\\alpha$-covering of distance\nvectors with a novel error metric, which allows us to provide a tighter\nvariance bound. Another useful technical ingredient is terminal embedding with\nadditive errors, for bounding the covering number in the Euclidean case.",
    "descriptor": "",
    "authors": [
      "Lingxiao Huang",
      "Jian Li",
      "Xuan Wu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2211.11923"
  },
  {
    "id": "arXiv:2211.11924",
    "title": "Best-$k$ Search Algorithm for Neural Text Generation",
    "abstract": "Modern natural language generation paradigms require a good decoding strategy\nto obtain quality sequences out of the model. Beam search yields high-quality\nbut low diversity outputs; stochastic approaches suffer from high variance and\nsometimes low quality, but the outputs tend to be more natural and creative. In\nthis work, we propose a deterministic search algorithm balancing both quality\nand diversity. We first investigate the vanilla best-first search (BFS)\nalgorithm and then propose the Best-$k$ Search algorithm. Inspired by BFS, we\ngreedily expand the top $k$ nodes, instead of only the first node, to boost\nefficiency and diversity. Upweighting recently discovered nodes accompanied by\nheap pruning ensures the completeness of the search procedure. Experiments on\nfour NLG tasks, including question generation, commonsense generation, text\nsummarization, and translation, show that best-$k$ search yields more diverse\nand natural outputs compared to strong baselines, while our approach maintains\nhigh text quality. The proposed algorithm is parameter-free, lightweight,\nefficient, and easy to use.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Jiacheng Xu",
      "Caiming Xiong",
      "Silvio Savarese",
      "Yingbo Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11924"
  },
  {
    "id": "arXiv:2211.11925",
    "title": "Multimodal Data Augmentation for Visual-Infrared Person ReID with  Corrupted Data",
    "abstract": "The re-identification (ReID) of individuals over a complex network of cameras\nis a challenging task, especially under real-world surveillance conditions.\nSeveral deep learning models have been proposed for visible-infrared (V-I)\nperson ReID to recognize individuals from images captured using RGB and IR\ncameras. However, performance may decline considerably if RGB and IR images\ncaptured at test time are corrupted (e.g., noise, blur, and weather\nconditions). Although various data augmentation (DA) methods have been explored\nto improve the generalization capacity, these are not adapted for V-I person\nReID. In this paper, a specialized DA strategy is proposed to address this\nmultimodal setting. Given both the V and I modalities, this strategy allows to\ndiminish the impact of corruption on the accuracy of deep person ReID models.\nCorruption may be modality-specific, and an additional modality often provides\ncomplementary information. Our multimodal DA strategy is designed specifically\nto encourage modality collaboration and reinforce generalization capability.\nFor instance, punctual masking of modalities forces the model to select the\ninformative modality. Local DA is also explored for advanced selection of\nfeatures within and among modalities. The impact of training baseline fusion\nmodels for V-I person ReID using the proposed multimodal DA strategy is\nassessed on corrupted versions of the SYSU-MM01, RegDB, and ThermalWORLD\ndatasets in terms of complexity and efficiency. Results indicate that using our\nstrategy provides V-I ReID models the ability to exploit both shared and\nindividual modality knowledge so they can outperform models trained with no or\nunimodal DA. GitHub code: https://github.com/art2611/ML-MDA.",
    "descriptor": "\nComments: 8 pages of main content, 2 pages of references, 2 pages of supplementary material, 3 figures, WACV 2023 RWS workshop,\n",
    "authors": [
      "Arthur Josi",
      "Mahdi Alehdaghi",
      "Rafael M. O. Cruz",
      "Eric Granger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11925"
  },
  {
    "id": "arXiv:2211.11926",
    "title": "The weak Galerkin finite element method for Stokes interface problems  with curved interface",
    "abstract": "In this paper, we develop a new weak Galerkin finite element scheme for the\nStokes interface problem with curved interfaces. We take a unique vector-valued\nfunction at the interface and reflect the interface condition in the\nvariational problem. Theoretical analysis and numerical experiments show that\nthe errors can reach the optimal convergence order under the energy norm and\n$L^2$ norm.",
    "descriptor": "",
    "authors": [
      "Lin Yang",
      "Hui Peng",
      "Qilong Zhai",
      "Ran Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.11926"
  },
  {
    "id": "arXiv:2211.11928",
    "title": "A case study of proactive auto-scaling for an ecommerce workload",
    "abstract": "Preliminary data obtained from a partnership between the Federal University\nof Campina Grande and an ecommerce company indicates that some applications\nhave issues when dealing with variable demand. This happens because a delay in\nscaling resources leads to performance degradation and, in literature, is a\nmatter usually treated by improving the auto-scaling. To better understand the\ncurrent state-of-the-art on this subject, we re-evaluate an auto-scaling\nalgorithm proposed in the literature, in the context of ecommerce, using a\nlong-term real workload. Experimental results show that our proactive approach\nis able to achieve an accuracy of up to 94 percent and led the auto-scaling to\na better performance than the reactive approach currently used by the ecommerce\ncompany.",
    "descriptor": "",
    "authors": [
      "Marcella Medeiros Siqueira Coutinho de Almeida",
      "Thiago Emmanuel Pereira",
      "Fabio Morais"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.11928"
  },
  {
    "id": "arXiv:2211.11931",
    "title": "Layered-Garment Net: Generating Multiple Implicit Garment Layers from a  Single Image",
    "abstract": "Recent research works have focused on generating human models and garments\nfrom their 2D images. However, state-of-the-art researches focus either on only\na single layer of the garment on a human model or on generating multiple\ngarment layers without any guarantee of the intersection-free geometric\nrelationship between them. In reality, people wear multiple layers of garments\nin their daily life, where an inner layer of garment could be partially covered\nby an outer one. In this paper, we try to address this multi-layer modeling\nproblem and propose the Layered-Garment Net (LGN) that is capable of generating\nintersection-free multiple layers of garments defined by implicit function\nfields over the body surface, given the person's near front-view image. With a\nspecial design of garment indication fields (GIF), we can enforce an implicit\ncovering relationship between the signed distance fields (SDF) of different\nlayers to avoid self-intersections among different garment surfaces and the\nhuman body. Experiments demonstrate the strength of our proposed LGN framework\nin generating multi-layer garments as compared to state-of-the-art methods. To\nthe best of our knowledge, LGN is the first research work to generate\nintersection-free multiple layers of garments on the human body from a single\nimage.",
    "descriptor": "\nComments: 16th Asian Conference on Computer Vision (ACCV2022)\n",
    "authors": [
      "Alakh Aggarwal",
      "Jikai Wang",
      "Steven Hogue",
      "Saifeng Ni",
      "Madhukar Budagavi",
      "Xiaohu Guo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.11931"
  },
  {
    "id": "arXiv:2211.11936",
    "title": "One Eye is All You Need: Lightweight Ensembles for Gaze Estimation with  Single Encoders",
    "abstract": "Gaze estimation has grown rapidly in accuracy in recent years. However, these\nmodels often fail to take advantage of different computer vision (CV)\nalgorithms and techniques (such as small ResNet and Inception networks and\nensemble models) that have been shown to improve results for other CV problems.\nAdditionally, most current gaze estimation models require the use of either\nboth eyes or an entire face, whereas real-world data may not always have both\neyes in high resolution. Thus, we propose a gaze estimation model that\nimplements the ResNet and Inception model architectures and makes predictions\nusing only one eye image. Furthermore, we propose an ensemble calibration\nnetwork that uses the predictions from several individual architectures for\nsubject-specific predictions. With the use of lightweight architectures, we\nachieve high performance on the GazeCapture dataset with very low model\nparameter counts. When using two eyes as input, we achieve a prediction error\nof 1.591 cm on the test set without calibration and 1.439 cm with an ensemble\ncalibration model. With just one eye as input, we still achieve an average\nprediction error of 2.312 cm on the test set without calibration and 1.951 cm\nwith an ensemble calibration model. We also notice significantly lower errors\non the right eye images in the test set, which could be important in the design\nof future gaze estimation-based tools.",
    "descriptor": "",
    "authors": [
      "Rishi Athavale",
      "Lakshmi Sritan Motati",
      "Rohan Kalahasty"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11936"
  },
  {
    "id": "arXiv:2211.11937",
    "title": "Genetic Algorithm for Program Synthesis",
    "abstract": "A deductive program synthesis tool takes a specification as input and derives\na program that satisfies the specification. The drawback of this approach is\nthat search spaces for such correct programs tend to be enormous, making it\ndifficult to derive correct programs within a realistic timeout. To speed up\nsuch program derivation, we improve the search strategy of a deductive program\nsynthesis tool, SuSLik, using evolutionary computation. Our cross-validation\nshows that the improvement brought by evolutionary computation generalises to\nunforeseen problems.",
    "descriptor": "",
    "authors": [
      "Yutaka Nagashima"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11937"
  },
  {
    "id": "arXiv:2211.11938",
    "title": "Supervised Contrastive Learning on Blended Images for Long-tailed  Recognition",
    "abstract": "Real-world data often have a long-tailed distribution, where the number of\nsamples per class is not equal over training classes. The imbalanced data form\na biased feature space, which deteriorates the performance of the recognition\nmodel. In this paper, we propose a novel long-tailed recognition method to\nbalance the latent feature space. First, we introduce a MixUp-based data\naugmentation technique to reduce the bias of the long-tailed data. Furthermore,\nwe propose a new supervised contrastive learning method, named Supervised\ncontrastive learning on Mixed Classes (SMC), for blended images. SMC creates a\nset of positives based on the class labels of the original images. The\ncombination ratio of positives weights the positives in the training loss. SMC\nwith the class-mixture-based loss explores more diverse data space, enhancing\nthe generalization capability of the model. Extensive experiments on various\nbenchmarks show the effectiveness of our one-stage training method.",
    "descriptor": "",
    "authors": [
      "Minki Jeong",
      "Changick Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11938"
  },
  {
    "id": "arXiv:2211.11940",
    "title": "Decision-making with Imaginary Opponent Models",
    "abstract": "Opponent modeling has benefited a controlled agent's decision-making by\nconstructing models of other agents. Existing methods commonly assume access to\nopponents' observations and actions, which is infeasible when opponents'\nbehaviors are unobservable or hard to obtain. We propose a novel multi-agent\ndistributional actor-critic algorithm to achieve imaginary opponent modeling\nwith purely local information (i.e., the controlled agent's observations,\nactions, and rewards). Specifically, the actor maintains a speculated belief of\nthe opponents, which we call the \\textit{imaginary opponent models}, to predict\nopponents' actions using local observations and makes decisions accordingly.\nFurther, the distributional critic models the return distribution of the\npolicy. It reflects the quality of the actor and thus can guide the training of\nthe imaginary opponent model that the actor relies on. Extensive experiments\nconfirm that our method successfully models opponents' behaviors without their\ndata and delivers superior performance against baseline methods with a faster\nconvergence speed.",
    "descriptor": "\nComments: 13 pages, 27 figures\n",
    "authors": [
      "Jing Sun",
      "Shuo chen",
      "Cong Zhang",
      "Jie Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.11940"
  },
  {
    "id": "arXiv:2211.11941",
    "title": "Synthetic Data for Semantic Image Segmentation of Imagery of Unmanned  Spacecraft",
    "abstract": "Images of spacecraft photographed from other spacecraft operating in outer\nspace are difficult to come by, especially at a scale typically required for\ndeep learning tasks. Semantic image segmentation, object detection and\nlocalization, and pose estimation are well researched areas with powerful\nresults for many applications, and would be very useful in autonomous\nspacecraft operation and rendezvous. However, recent studies show that these\nstrong results in broad and common domains may generalize poorly even to\nspecific industrial applications on earth. To address this, we propose a method\nfor generating synthetic image data that are labelled for semantic\nsegmentation, generalizable to other tasks, and provide a prototype synthetic\nimage dataset consisting of 2D monocular images of unmanned spacecraft, in\norder to enable further research in the area of autonomous spacecraft\nrendezvous. We also present a strong benchmark result (S{\\o}rensen-Dice\ncoefficient 0.8723) on these synthetic data, suggesting that it is feasible to\ntrain well-performing image segmentation models for this task, especially if\nthe target spacecraft and its configuration are known.",
    "descriptor": "\nComments: 7 pages, 4 figures, conditionally accepted to 2023 IEEE Aerospace Conference\n",
    "authors": [
      "William S. Armstrong",
      "Spencer Drakontaidis",
      "Nicholas Lui"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11941"
  },
  {
    "id": "arXiv:2211.11942",
    "title": "A Pragmatic Approach to Stateful Partial Order Reduction",
    "abstract": "Partial order reduction (POR) is a classic technique for dealing with the\nstate explosion problem in model checking of concurrent programs. Theoretical\noptimality, i.e., avoiding enumerating equivalent interleavings, does not\nnecessarily guarantee optimal overall performance of the model checking\nalgorithm. The computational overhead required to guarantee optimality may by\nfar cancel out any benefits that an algorithm may have from exploring a smaller\nstate space of interleavings. With a focus on overall performance, we propose\nnew algorithms for stateful POR based on the recently proposed source sets,\nwhich are less precise but more efficient than the state of the art in\npractice. We evaluate efficiency using an implementation that extends Java\nPathfinder in the context of verifying concurrent data structures.",
    "descriptor": "",
    "authors": [
      "Berk Cirisci",
      "Constantin Enea",
      "Azadeh Farzan",
      "Suha Orhun Mutluergil"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.11942"
  },
  {
    "id": "arXiv:2211.11943",
    "title": "Conv2Former: A Simple Transformer-Style ConvNet for Visual Recognition",
    "abstract": "This paper does not attempt to design a state-of-the-art method for visual\nrecognition but investigates a more efficient way to make use of convolutions\nto encode spatial features. By comparing the design principles of the recent\nconvolutional neural networks ConvNets) and Vision Transformers, we propose to\nsimplify the self-attention by leveraging a convolutional modulation operation.\nWe show that such a simple approach can better take advantage of the large\nkernels (>=7x7) nested in convolutional layers. We build a family of\nhierarchical ConvNets using the proposed convolutional modulation, termed\nConv2Former. Our network is simple and easy to follow. Experiments show that\nour Conv2Former outperforms existent popular ConvNets and vision Transformers,\nlike Swin Transformer and ConvNeXt in all ImageNet classification, COCO object\ndetection and ADE20k semantic segmentation.",
    "descriptor": "",
    "authors": [
      "Qibin Hou",
      "Cheng-Ze Lu",
      "Ming-Ming Cheng",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11943"
  },
  {
    "id": "arXiv:2211.11944",
    "title": "COVID-Net Assistant: A Deep Learning-Driven Virtual Assistant for  COVID-19 Symptom Prediction and Recommendation",
    "abstract": "As the COVID-19 pandemic continues to put a significant burden on healthcare\nsystems worldwide, there has been growing interest in finding inexpensive\nsymptom pre-screening and recommendation methods to assist in efficiently using\navailable medical resources such as PCR tests. In this study, we introduce the\ndesign of COVID-Net Assistant, an efficient virtual assistant designed to\nprovide symptom prediction and recommendations for COVID-19 by analyzing users'\ncough recordings through deep convolutional neural networks. We explore a\nvariety of highly customized, lightweight convolutional neural network\narchitectures generated via machine-driven design exploration (which we refer\nto as COVID-Net Assistant neural networks) on the Covid19-Cough benchmark\ndataset. The Covid19-Cough dataset comprises 682 cough recordings from a\nCOVID-19 positive cohort and 642 from a COVID-19 negative cohort. Among the 682\ncough recordings labeled positive, 382 recordings were verified by PCR test.\nOur experimental results show promising, with the COVID-Net Assistant neural\nnetworks demonstrating robust predictive performance, achieving AUC scores of\nover 0.93, with the best score over 0.95 while being fast and efficient in\ninference. The COVID-Net Assistant models are made available in an open source\nmanner through the COVID-Net open initiative and, while not a production-ready\nsolution, we hope their availability acts as a good resource for clinical\nscientists, machine learning researchers, as well as citizen scientists to\ndevelop innovative solutions.",
    "descriptor": "",
    "authors": [
      "Pengyuan Shi",
      "Yuetong Wang",
      "Saad Abbasi",
      "Alexander Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.11944"
  },
  {
    "id": "arXiv:2211.11947",
    "title": "Measuring Belief Dynamics on Twitter",
    "abstract": "There is growing concern about misinformation and the role online media plays\nin social polarization. Analyzing belief dynamics is one way to enhance our\nunderstanding of these problems. Existing analytical tools, such as survey\nresearch or stance detection, lack the power to correlate contextual factors\nwith population-level changes in belief dynamics. In this exploratory study, I\npresent the Belief Landscape Framework, which uses data about people's\nprofessed beliefs in an online setting to measure belief dynamics with high\nresolution. I provide initial validation of the approach by comparing the\nmethod's output to a set of hypotheses drawn from the literature and by\ninspecting the \"belief landscape\" generated by the method. My analysis\nindicates that the method is relatively robust to different parameter settings,\nand results suggest that 1) there are many stable configurations of belief, or\nattractors, on the polarizing issue of climate change and 2) that people move\nin predictable ways around these attractors. The method paves the way for more\npowerful tools that can be used to understand how the modern digital media\necosystem impacts collective belief dynamics and what role misinformation plays\nin that process.",
    "descriptor": "\nComments: 11 pages, 5 figure, to appear in the Proceedings of ICWSM '23\n",
    "authors": [
      "Joshua Introne"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.11947"
  },
  {
    "id": "arXiv:2211.11949",
    "title": "A Reinforcement Learning Approach to Optimize Available Network  Bandwidth Utilization",
    "abstract": "Efficient data transfers over high-speed, long-distance shared networks\nrequire proper utilization of available network bandwidth. Using parallel TCP\nstreams enables an application to utilize network parallelism and can improve\ntransfer throughput; however, finding the optimum number of parallel TCP\nstreams is challenging due to nondeterministic background traffic sharing the\nsame network. Additionally, the non-stationary, multi-objectiveness, and\npartially-observable nature of network signals in the host systems add extra\ncomplexity in finding the current network condition. In this work, we present a\nnovel approach to finding the optimum number of parallel TCP streams using deep\nreinforcement learning (RL). We devise a learning-based algorithm capable of\ngeneralizing different network conditions and utilizing the available network\nbandwidth intelligently. Contrary to rule-based heuristics that do not\ngeneralize well in unknown network scenarios, our RL-based solution can\ndynamically discover and adapt the parallel TCP stream numbers to maximize the\nnetwork bandwidth utilization without congesting the network and ensure\nfairness among contending transfers. We extensively evaluated our RL-based\nalgorithm's performance, comparing it with several state-of-the-art online\noptimization algorithms. The results show that our RL-based algorithm can find\nnear-optimal solutions 40% faster while achieving up to 15% higher throughput.\nWe also show that, unlike a greedy algorithm, our devised RL-based algorithm\ncan avoid network congestion and fairly share the available network resources\namong contending transfers.",
    "descriptor": "\nComments: Submitted to ICC 2023, converted to 12 pages , conference submission was for 7 pages\n",
    "authors": [
      "Hasibul Jamil",
      "Elvis Rodrigues",
      "Jacob Goldverg",
      "Tevfik Kosar"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2211.11949"
  },
  {
    "id": "arXiv:2211.11950",
    "title": "UpCycling: Semi-supervised 3D Object Detection without Sharing Raw-level  Unlabeled Scenes",
    "abstract": "Semi-supervised Learning (SSL) has received increasing attention in\nautonomous driving to relieve enormous burden for 3D annotation. In this paper,\nwe propose UpCycling, a novel SSL framework for 3D object detection with zero\nadditional raw-level point cloud: learning from unlabeled de-identified\nintermediate features (i.e., smashed data) for privacy preservation. The\nintermediate features do not require additional computation on autonomous\nvehicles since they are naturally produced by the inference pipeline. However,\naugmenting 3D scenes at a feature level turns out to be a critical issue:\napplying the augmentation methods in the latest semi-supervised 3D object\ndetectors distorts intermediate features, which causes the pseudo-labels to\nsuffer from significant noise. To solve the distortion problem while achieving\nhighly effective SSL, we introduce hybrid pseudo labels, feature-level Ground\nTruth sampling (F-GT) and Rotation (F-RoT), which safely augment unlabeled\nmulti-type 3D scene features and provide high-quality supervision. We implement\nUpCycling on two representative 3D object detection models, SECOND-IoU and\nPV-RCNN, and perform experiments on widely-used datasets (Waymo, KITTI, and\nLyft). While preserving privacy with zero raw-point scene, UpCycling\nsignificantly outperforms the state-of-the-art SSL methods that utilize\nraw-point scenes, in both domain adaptation and partial-label scenarios.",
    "descriptor": "",
    "authors": [
      "Sunwook Hwang",
      "Youngseok Kim",
      "Seongwon Kim",
      "Saewoong Bahk",
      "Hyung-Sin Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11950"
  },
  {
    "id": "arXiv:2211.11951",
    "title": "On DoF of Active RIS-Assisted MIMO Interference Channel with Arbitrary  Antenna Configurations: When Will RIS Help?",
    "abstract": "An active reconfigurable intelligent surface (RIS) has been shown to be able\nto enhance the sum-of-degrees-of-freedom (DoF) of a two-user multiple-input\nmultiple-output (MIMO) interference channel (IC) with equal number of antennas\nat each transmitter and receiver. However, for any number of receive and\ntransmit antennas, when and how an active RIS can help to improve the sum-DoF\nare still unclear. This paper studies the sum-DoF of an active RIS-assisted\ntwo-user MIMO IC with arbitrary antenna configurations. In particular, RIS\nbeamforming, transmit zero-forcing, and interference decoding are integrated\ntogether to combat the interference problem. In order to maximize the\nachievable sum-DoF, an integer optimization problem is formulated to optimize\nthe number of eliminating interference links by RIS beamforming. As a result,\nthe derived achievable sum-DoF can be higher than the sum-DoF of two-user MIMO\nIC, leading to a RIS gain. Furthermore, a sufficient condition of the RIS gain\nis given as the relationship between the number of RIS elements and the antenna\nconfiguration.",
    "descriptor": "",
    "authors": [
      "Shuo Zheng",
      "Bojie Lv",
      "Tong Zhang",
      "Yinfei Xu",
      "Gaojie Chen",
      "Rui Wang",
      "P. C. Ching"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.11951"
  },
  {
    "id": "arXiv:2211.11953",
    "title": "Teach-DETR: Better Training DETR with Teachers",
    "abstract": "In this paper, we present a novel training scheme, namely Teach-DETR, to\nlearn better DETR-based detectors from versatile teacher detectors. We show\nthat the predicted boxes from teacher detectors are effective medium to\ntransfer knowledge of teacher detectors, which could be either RCNN-based or\nDETR-based detectors, to train a more accurate and robust DETR model. This new\ntraining scheme can easily incorporate the predicted boxes from multiple\nteacher detectors, each of which provides parallel supervisions to the student\nDETR. Our strategy introduces no additional parameters and adds negligible\ncomputational cost to the original detector during training. During inference,\nTeach-DETR brings zero additional overhead and maintains the merit of requiring\nno non-maximum suppression. Extensive experiments show that our method leads to\nconsistent improvement for various DETR-based detectors. Specifically, we\nimprove the state-of-the-art detector DINO with Swin-Large backbone and\n36-epoch training schedule, from 57.8% to 58.9% in terms of mean average\nprecision on MSCOCO 2017 validation set. Code will be available at\nhttps://github.com/LeonHLJ/Teach-DETR.",
    "descriptor": "",
    "authors": [
      "Linjiang Huang",
      "Kaixin Lu",
      "Guanglu Song",
      "Liang Wang",
      "Si Liu",
      "Yu Liu",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11953"
  },
  {
    "id": "arXiv:2211.11956",
    "title": "A Short Survey of Systematic Generalization",
    "abstract": "This survey includes systematic generalization and a history of how machine\nlearning addresses it. We aim to summarize and organize the related information\nof both conventional and recent improvements. We first look at the definition\nof systematic generalization, then introduce Classicist and Connectionist. We\nthen discuss different types of Connectionists and how they approach the\ngeneralization. Two crucial problems of variable binding and causality are\ndiscussed. We look into systematic generalization in language, vision, and VQA\nfields. Recent improvements from different aspects are discussed. Systematic\ngeneralization has a long history in artificial intelligence. We could cover\nonly a small portion of many contributions. We hope this paper provides a\nbackground and is beneficial for discoveries in future work.",
    "descriptor": "",
    "authors": [
      "Yuanpeng Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11956"
  },
  {
    "id": "arXiv:2211.11958",
    "title": "A Survey on Backdoor Attack and Defense in Natural Language Processing",
    "abstract": "Deep learning is becoming increasingly popular in real-life applications,\nespecially in natural language processing (NLP). Users often choose training\noutsourcing or adopt third-party data and models due to data and computation\nresources being limited. In such a situation, training data and models are\nexposed to the public. As a result, attackers can manipulate the training\nprocess to inject some triggers into the model, which is called backdoor\nattack. Backdoor attack is quite stealthy and difficult to be detected because\nit has little inferior influence on the model's performance for the clean\nsamples. To get a precise grasp and understanding of this problem, in this\npaper, we conduct a comprehensive review of backdoor attacks and defenses in\nthe field of NLP. Besides, we summarize benchmark datasets and point out the\nopen issues to design credible systems to defend against backdoor attacks.",
    "descriptor": "\nComments: 12 pages, QRS2022\n",
    "authors": [
      "Xuan Sheng",
      "Zhaoyang Han",
      "Piji Li",
      "Xiangmao Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.11958"
  },
  {
    "id": "arXiv:2211.11960",
    "title": "Disentangled Feature Learning for Real-Time Neural Speech Coding",
    "abstract": "Recently end-to-end neural audio/speech coding has shown its great potential\nto outperform traditional signal analysis based audio codecs. This is mostly\nachieved by following the VQ-VAE paradigm where blind features are learned,\nvector-quantized and coded. In this paper, instead of blind end-to-end\nlearning, we propose to learn disentangled features for real-time neural speech\ncoding. Specifically, more global-like speaker identity and local content\nfeatures are learned with disentanglement to represent speech. Such a compact\nfeature decomposition not only achieves better coding efficiency by exploiting\nbit allocation among different features but also provides the flexibility to do\naudio editing in embedding space, such as voice conversion in real-time\ncommunications. Both subjective and objective results demonstrate its coding\nefficiency and we find that the learned disentangled features show comparable\nperformance on any-to-any voice conversion with modern self-supervised speech\nrepresentation learning models with far less parameters and low latency,\nshowing the potential of our neural coding framework.",
    "descriptor": "\nComments: Submitted to ICASSP2023\n",
    "authors": [
      "Xue Jiang",
      "Xiulian Peng",
      "Yuan Zhang",
      "Yan Lu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.11960"
  },
  {
    "id": "arXiv:2211.11961",
    "title": "Online facility location with timed-requests and congestion",
    "abstract": "The classic online facility location problem deals with finding the optimal\nset of facilities in an online fashion when demand requests arrive one at a\ntime and facilities need to be opened to service these requests. In this work,\nwe study two variants of the online facility location problem; (1) timed\nrequests and (2) congestion. Both of these variants are motivated by the\napplications to real life and the previously known results on online facility\nlocation cannot be directly adapted to analyse them.\nTimed requests : In this variant, each demand request is a pair $(x,t)$ where\nthe $x$ is the standard location of the demand while $t$ is the corresponding\nweight of the request. The cost of servicing request $(x,t)$ at facility $F$ is\n$t\\cdot d(x,F')$ where $F'$ is the set of facilities available at the time of\nrequest $(x,t)$. For this variant, we present an online algorithm attaining a\ncompetitive ratio of $\\mathcal{O}(\\log n)$ in the secretarial model for the\ntimed requests and show that it is optimal.\nCongestion : The congestion variant considers the case when there is an\nadditional congestion cost that grows with the number of requests served by\neach request. For this variant, when the congestion cost is a monomial, we show\nthat there exists an algorithm attaining a constant competitive ratio. This\nconstant is a function of the exponent of the monomial and the facility opening\ncost but independent of the number of requests.",
    "descriptor": "\nComments: 25 pages, 6 figures\n",
    "authors": [
      "Arghya Chakraborty",
      "Rahul Vaze"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.11961"
  },
  {
    "id": "arXiv:2211.11962",
    "title": "Transformation-Equivariant 3D Object Detection for Autonomous Driving",
    "abstract": "3D object detection received increasing attention in autonomous driving\nrecently. Objects in 3D scenes are distributed with diverse orientations.\nOrdinary detectors do not explicitly model the variations of rotation and\nreflection transformations. Consequently, large networks and extensive data\naugmentation are required for robust detection. Recent equivariant networks\nexplicitly model the transformation variations by applying shared networks on\nmultiple transformed point clouds, showing great potential in object geometry\nmodeling. However, it is difficult to apply such networks to 3D object\ndetection in autonomous driving due to its large computation cost and slow\nreasoning speed. In this work, we present TED, an efficient\nTransformation-Equivariant 3D Detector to overcome the computation cost and\nspeed issues. TED first applies a sparse convolution backbone to extract\nmulti-channel transformation-equivariant voxel features; and then aligns and\naggregates these equivariant features into lightweight and compact\nrepresentations for high-performance 3D object detection. On the highly\ncompetitive KITTI 3D car detection leaderboard, TED ranked 1st among all\nsubmissions with competitive efficiency.",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Hai Wu",
      "Chenglu Wen",
      "Wei Li",
      "Xin Li",
      "Ruigang Yang",
      "Cheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11962"
  },
  {
    "id": "arXiv:2211.11963",
    "title": "Learning-based social coordination to improve safety and robustness of  cooperative autonomous vehicles in mixed traffic",
    "abstract": "It is expected that autonomous vehicles(AVs) and heterogeneous human-driven\nvehicles(HVs) will coexist on the same road. The safety and reliability of AVs\nwill depend on their social awareness and their ability to engage in complex\nsocial interactions in a socially accepted manner. However, AVs are still\ninefficient in terms of cooperating with HVs and struggle to understand and\nadapt to human behavior, which is particularly challenging in mixed autonomy.\nIn a road shared by AVs and HVs, the social preferences or individual traits of\nHVs are unknown to the AVs and different from AVs, which are expected to follow\na policy, HVs are particularly difficult to forecast since they do not\nnecessarily follow a stationary policy. To address these challenges, we frame\nthe mixed-autonomy problem as a multi-agent reinforcement learning (MARL)\nproblem and propose an approach that allows AVs to learn the decision-making of\nHVs implicitly from experience, account for all vehicles' interests, and safely\nadapt to other traffic situations. In contrast with existing works, we quantify\nAVs' social preferences and propose a distributed reward structure that\nintroduces altruism into their decision-making process, allowing the altruistic\nAVs to learn to establish coalitions and influence the behavior of HVs.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2202.00881\n",
    "authors": [
      "Rodolfo Valiente",
      "Behrad Toghi",
      "Mahdi Razzaghpour",
      "Ramtin Pedarsani",
      "Yaser P. Fallah"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.11963"
  },
  {
    "id": "arXiv:2211.11964",
    "title": "One for All, All for One: Learning and Transferring User Embeddings for  Cross-Domain Recommendation",
    "abstract": "Cross-domain recommendation is an important method to improve recommender\nsystem performance, especially when observations in target domains are sparse.\nHowever, most existing techniques focus on single-target or dual-target\ncross-domain recommendation (CDR) and are hard to be generalized to CDR with\nmultiple target domains. In addition, the negative transfer problem is\nprevalent in CDR, where the recommendation performance in a target domain may\nnot always be enhanced by knowledge learned from a source domain, especially\nwhen the source domain has sparse data. In this study, we propose CAT-ART, a\nmulti-target CDR method that learns to improve recommendations in all\nparticipating domains through representation learning and embedding transfer.\nOur method consists of two parts: a self-supervised Contrastive AuToencoder\n(CAT) framework to generate global user embeddings based on information from\nall participating domains, and an Attention-based Representation Transfer (ART)\nframework which transfers domain-specific user embeddings from other domains to\nassist with target domain recommendation. CAT-ART boosts the recommendation\nperformance in any target domain through the combined use of the learned global\nuser representation and knowledge transferred from other domains, in addition\nto the original user embedding in the target domain. We conducted extensive\nexperiments on a collected real-world CDR dataset spanning 5 domains and\ninvolving a million users. Experimental results demonstrate the superiority of\nthe proposed method over a range of prior arts. We further conducted ablation\nstudies to verify the effectiveness of the proposed components. Our collected\ndataset will be open-sourced to facilitate future research in the field of\nmulti-domain recommender systems and user modeling.",
    "descriptor": "\nComments: 9 pages, accepted by WSDM 2023\n",
    "authors": [
      "Chenglin Li",
      "Yuanzhen Xie",
      "Chenyun Yu",
      "Bo Hu",
      "Zang li",
      "Guoqiang Shu",
      "Xiaohu Qie",
      "Di Niu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.11964"
  },
  {
    "id": "arXiv:2211.11965",
    "title": "Predicting adverse outcomes following catheter ablation treatment for  atrial fibrillation",
    "abstract": "Objective: To develop prognostic survival models for predicting adverse\noutcomes after catheter ablation treatment for non-valvular atrial fibrillation\n(AF).\nMethods: We used a linked dataset including hospital administrative data,\nprescription medicine claims, emergency department presentations, and death\nregistrations of patients in New South Wales, Australia. The cohort included\npatients who received catheter ablation for AF. Traditional and deep survival\nmodels were trained to predict major bleeding events and a composite of heart\nfailure, stroke, cardiac arrest, and death.\nResults: Out of a total of 3285 patients in the cohort, 177 (5.3%)\nexperienced the composite outcomeheart failure, stroke, cardiac arrest,\ndeathand 167 (5.1%) experienced major bleeding events after catheter ablation\ntreatment. Models predicting the composite outcome had high risk discrimination\naccuracy, with the best model having a concordance index > 0.79 at the\nevaluated time horizons. Models for predicting major bleeding events had poor\nrisk discrimination performance, with all models having a concordance index <\n0.66. The most impactful features for the models predicting higher risk were\ncomorbidities indicative of poor health, older age, and therapies commonly used\nin sicker patients to treat heart failure and AF.\nConclusions: Diagnosis and medication history did not contain sufficient\ninformation for precise risk prediction of experiencing major bleeding events.\nThe models for predicting the composite outcome have the potential to enable\nclinicians to identify and manage high-risk patients following catheter\nablation proactively. Future research is needed to validate the usefulness of\nthese models in clinical practice.",
    "descriptor": "\nComments: Under journal review\n",
    "authors": [
      "Juan C. Quiroz",
      "David Brieger",
      "Louisa Jorm",
      "Raymond W Sy",
      "Benjumin Hsu",
      "Blanca Gallego"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Other Statistics (stat.OT)"
    ],
    "url": "https://arxiv.org/abs/2211.11965"
  },
  {
    "id": "arXiv:2211.11967",
    "title": "Support Size Estimation: The Power of Conditioning",
    "abstract": "We consider the problem of estimating the support size of a distribution $D$.\nOur investigations are pursued through the lens of distribution testing and\nseek to understand the power of conditional sampling (denoted as COND), wherein\none is allowed to query the given distribution conditioned on an arbitrary\nsubset $S$. The primary contribution of this work is to introduce a new\napproach to lower bounds for the COND model that relies on using powerful tools\nfrom information theory and communication complexity.\nOur approach allows us to obtain surprisingly strong lower bounds for the\nCOND model and its extensions.\n1) We bridge the longstanding gap between the upper ($O(\\log \\log n +\n\\frac{1}{\\epsilon^2})$) and the lower bound $\\Omega(\\sqrt{\\log \\log n})$ for\nCOND model by providing a nearly matching lower bound. Surprisingly, we show\nthat even if we get to know the actual probabilities along with COND samples,\nstill $\\Omega(\\log \\log n + \\frac{1}{\\epsilon^2 \\log (1/\\epsilon)})$ queries\nare necessary.\n2) We obtain the first non-trivial lower bound for COND equipped with an\nadditional oracle that reveals the conditional probabilities of the samples (to\nthe best of our knowledge, this subsumes all of the models previously studied):\nin particular, we demonstrate that $\\Omega(\\log \\log \\log n +\n\\frac{1}{\\epsilon^2 \\log (1/\\epsilon)})$ queries are necessary.",
    "descriptor": "",
    "authors": [
      "Diptarka Chakraborty",
      "Gunjan Kumar",
      "Kuldeep S. Meel"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.11967"
  },
  {
    "id": "arXiv:2211.11971",
    "title": "Multi-View Neural Surface Reconstruction with Structured Light",
    "abstract": "Three-dimensional (3D) object reconstruction based on differentiable\nrendering (DR) is an active research topic in computer vision. DR-based methods\nminimize the difference between the rendered and target images by optimizing\nboth the shape and appearance and realizing a high visual reproductivity.\nHowever, most approaches perform poorly for textureless objects because of the\ngeometrical ambiguity, which means that multiple shapes can have the same\nrendered result in such objects. To overcome this problem, we introduce active\nsensing with structured light (SL) into multi-view 3D object reconstruction\nbased on DR to learn the unknown geometry and appearance of arbitrary scenes\nand camera poses. More specifically, our framework leverages the\ncorrespondences between pixels in different views calculated by structured\nlight as an additional constraint in the DR-based optimization of implicit\nsurface, color representations, and camera poses. Because camera poses can be\noptimized simultaneously, our method realizes high reconstruction accuracy in\nthe textureless region and reduces efforts for camera pose calibration, which\nis required for conventional SL-based methods. Experiment results on both\nsynthetic and real data demonstrate that our system outperforms conventional\nDR- and SL-based methods in a high-quality surface reconstruction, particularly\nfor challenging objects with textureless or shiny surfaces.",
    "descriptor": "\nComments: Accepted by BMVC 2022\n",
    "authors": [
      "Chunyu Li",
      "Taisuke Hashimoto",
      "Eiichi Matsumoto",
      "Hiroharu Kato"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11971"
  },
  {
    "id": "arXiv:2211.11972",
    "title": "imitation: Clean Imitation Learning Implementations",
    "abstract": "imitation provides open-source implementations of imitation and reward\nlearning algorithms in PyTorch. We include three inverse reinforcement learning\n(IRL) algorithms, three imitation learning algorithms and a preference\ncomparison algorithm. The implementations have been benchmarked against\nprevious results, and automated tests cover 98% of the code. Moreover, the\nalgorithms are implemented in a modular fashion, making it simple to develop\nnovel algorithms in the framework. Our source code, including documentation and\nexamples, is available at https://github.com/HumanCompatibleAI/imitation",
    "descriptor": "",
    "authors": [
      "Adam Gleave",
      "Mohammad Taufeeque",
      "Juan Rocamonde",
      "Erik Jenner",
      "Steven H. Wang",
      "Sam Toyer",
      "Maximilian Ernestus",
      "Nora Belrose",
      "Scott Emmons",
      "Stuart Russell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11972"
  },
  {
    "id": "arXiv:2211.11975",
    "title": "Pred&Guide: Labeled Target Class Prediction for Guiding Semi-Supervised  Domain Adaptation",
    "abstract": "Semi-supervised domain adaptation aims to classify data belonging to a target\ndomain by utilizing a related label-rich source domain and very few labeled\nexamples of the target domain. Here, we propose a novel framework, Pred&Guide,\nwhich leverages the inconsistency between the predicted and the actual class\nlabels of the few labeled target examples to effectively guide the domain\nadaptation in a semi-supervised setting. Pred&Guide consists of three stages,\nas follows (1) First, in order to treat all the target samples equally, we\nperform unsupervised domain adaptation coupled with self-training; (2) Second\nis the label prediction stage, where the current model is used to predict the\nlabels of the few labeled target examples, and (3) Finally, the correctness of\nthe label predictions are used to effectively weigh source examples class-wise\nto better guide the domain adaptation process. Extensive experiments show that\nthe proposed Pred&Guide framework achieves state-of-the-art results for two\nlarge-scale benchmark datasets, namely Office-Home and DomainNet.",
    "descriptor": "",
    "authors": [
      "Megh Manoj Bhalerao",
      "Anurag Singh",
      "Soma Biswas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11975"
  },
  {
    "id": "arXiv:2211.11977",
    "title": "SemanticLoop: loop closure with 3D semantic graph matching",
    "abstract": "Loop closure can effectively correct the accumulated error in robot\nlocalization, which plays a critical role in the long-term navigation of the\nrobot. Traditional appearance-based methods rely on local features and are\nprone to failure in ambiguous environments. On the other hand, object\nrecognition can infer objects' category, pose, and extent. These objects can\nserve as stable semantic landmarks for viewpoint-independent and non-ambiguous\nloop closure. However, there is a critical object-level data association\nproblem due to the lack of efficient and robust algorithms.\nWe introduce a novel object-level data association algorithm, which\nincorporates IoU, instance-level embedding, and detection uncertainty,\nformulated as a linear assignment problem. Then, we model the objects as TSDF\nvolumes and represent the environment as a 3D graph with semantics and\ntopology. Next, we propose a graph matching-based loop detection based on the\nreconstructed 3D semantic graphs and correct the accumulated error by aligning\nthe matched objects. Finally, we refine the object poses and camera trajectory\nin an object-level pose graph optimization.\nExperimental results show that the proposed object-level data association\nmethod significantly outperforms the commonly used nearest-neighbor method in\naccuracy. Our graph matching-based loop closure is more robust to environmental\nappearance changes than existing appearance-based methods.",
    "descriptor": "",
    "authors": [
      "Junfeng Yu",
      "Shaojie Shen"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.11977"
  },
  {
    "id": "arXiv:2211.11978",
    "title": "A Bioinspired Bidirectional Stiffening Soft Actuator for Multimodal,  Compliant, and Robust Grasping",
    "abstract": "The stiffness modulation mechanism for soft robotics has gained considerable\nattention to improve deformability, controllability, and stability. However,\nfor the existing stiffness soft actuator, high lateral stiffness and a wide\nrange of bending stiffness are hard to be provided at the same time. This paper\npresents a bioinspired bidirectional stiffening soft actuator (BISA) combining\nthe air-tendon hybrid actuation (ATA) and a bone-like structure (BLS). The ATA\nis the main actuation of the BISA, and the bending stiffness can be modulated\nwith a maximum stiffness of about 0.7 N/mm and a maximum magnification of 3\ntimes when the bending angle is 45 deg. Inspired by the morphological structure\nof the phalanx, the lateral stiffness can be modulated by changing the pulling\nforce of the BLS. The lateral stiffness can be modulated by changing the\npulling force to it. The actuator with BLSs can improve the lateral stiffness\nabout 3.9 times compared to the one without BLSs. The maximum lateral stiffness\ncan reach 0.46 N/mm. And the lateral stiffness can be modulated decoupling\nabout 1.3 times (e.g., from 0.35 N/mm to 0.46 when the bending angle is 45\ndeg). The test results show the influence of the rigid structures on bending is\nsmall with about 1.5 mm maximum position errors of the distal point of actuator\nbending in different pulling forces. The advantages brought by the proposed\nmethod enable a soft four-finger gripper to operate in three modes: normal\ngrasping, inverse grasping, and horizontal lifting. The performance of this\ngripper is further characterized and versatile grasping on various objects is\nconducted, proving the robust performance and potential application of the\nproposed design method.",
    "descriptor": "",
    "authors": [
      "Jianfeng Lin",
      "Ruikang Xiao",
      "Miao Li",
      "Xiaohui Xiao",
      "Zhao Guo"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.11978"
  },
  {
    "id": "arXiv:2211.11979",
    "title": "Learnable Spectral Wavelets on Dynamic Graphs to Capture Global  Interactions",
    "abstract": "Learning on evolving(dynamic) graphs has caught the attention of researchers\nas static methods exhibit limited performance in this setting. The existing\nmethods for dynamic graphs learn spatial features by local neighborhood\naggregation, which essentially only captures the low pass signals and local\ninteractions. In this work, we go beyond current approaches to incorporate\nglobal features for effectively learning representations of a dynamically\nevolving graph. We propose to do so by capturing the spectrum of the dynamic\ngraph. Since static methods to learn the graph spectrum would not consider the\nhistory of the evolution of the spectrum as the graph evolves with time, we\npropose a novel approach to learn the graph wavelets to capture this evolving\nspectra. Further, we propose a framework that integrates the dynamically\ncaptured spectra in the form of these learnable wavelets into spatial features\nfor incorporating local and global interactions. Experiments on eight standard\ndatasets show that our method significantly outperforms related methods on\nvarious tasks for dynamic graphs.",
    "descriptor": "\nComments: Accepted for publication in AAAI 2023\n",
    "authors": [
      "Anson Bastos",
      "Abhishek Nadgeri",
      "Kuldeep Singh",
      "Toyotaro Suzumura",
      "Manish Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11979"
  },
  {
    "id": "arXiv:2211.11981",
    "title": "Bayesian Inversion with Neural Operator (BINO) for Modeling  Subdiffusion: Forward and Inverse Problems",
    "abstract": "Fractional diffusion equations have been an effective tool for modeling\nanomalous diffusion in complicated systems. However, traditional numerical\nmethods require expensive computation cost and storage resources because of the\nmemory effect brought by the convolution integral of time fractional\nderivative. We propose a Bayesian Inversion with Neural Operator (BINO) to\novercome the difficulty in traditional methods as follows. We employ a deep\noperator network to learn the solution operators for the fractional diffusion\nequations, allowing us to swiftly and precisely solve a forward problem for\ngiven inputs (including fractional order, diffusion coefficient, source terms,\netc.). In addition, we integrate the deep operator network with a Bayesian\ninversion method for modelling a problem by subdiffusion process and solving\ninverse subdiffusion problems, which reduces the time costs (without suffering\nfrom overwhelm storage resources) significantly. A large number of numerical\nexperiments demonstrate that the operator learning method proposed in this work\ncan efficiently solve the forward problems and Bayesian inverse problems of the\nsubdiffusion equation.",
    "descriptor": "",
    "authors": [
      "Xiong-bin Yan",
      "Zhi-Qin John Xu",
      "Zheng Ma"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11981"
  },
  {
    "id": "arXiv:2211.11982",
    "title": "BotSIM: An End-to-End Bot Simulation Framework for Commercial  Task-Oriented Dialog Systems",
    "abstract": "We present BotSIM, a data-efficient end-to-end Bot SIMulation toolkit for\ncommercial text-based task-oriented dialog (TOD) systems. BotSIM consists of\nthree major components: 1) a Generator that can infer semantic-level dialog\nacts and entities from bot definitions and generate user queries via\nmodel-based paraphrasing; 2) an agenda-based dialog user Simulator (ABUS) to\nsimulate conversations with the dialog agents; 3) a Remediator to analyze the\nsimulated conversations, visualize the bot health reports and provide\nactionable remediation suggestions for bot troubleshooting and improvement. We\ndemonstrate BotSIM's effectiveness in end-to-end evaluation, remediation and\nmulti-intent dialog generation via case studies on two commercial bot\nplatforms. BotSIM's \"generation-simulation-remediation\" paradigm accelerates\nthe end-to-end bot evaluation and iteration process by: 1) reducing manual test\ncases creation efforts; 2) enabling a holistic gauge of the bot in terms of NLU\nand end-to-end performance via extensive dialog simulation; 3) improving the\nbot troubleshooting process with actionable suggestions. A demo of our system\ncan be found at https://tinyurl.com/mryu74cd and a demo video at\nhttps://youtu.be/qLi5iSoly30.",
    "descriptor": "\nComments: Paper accepted by EMNLP 2022 Demo Track\n",
    "authors": [
      "Guangsen Wang",
      "Samson Tan",
      "Shafiq Joty",
      "Gang Wu",
      "Jimmy Au",
      "Steven Hoi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11982"
  },
  {
    "id": "arXiv:2211.11983",
    "title": "Weakly-supervised Pre-training for 3D Human Pose Estimation via  Perspective Knowledge",
    "abstract": "Modern deep learning-based 3D pose estimation approaches require plenty of 3D\npose annotations. However, existing 3D datasets lack diversity, which limits\nthe performance of current methods and their generalization ability. Although\nexisting methods utilize 2D pose annotations to help 3D pose estimation, they\nmainly focus on extracting 2D structural constraints from 2D poses, ignoring\nthe 3D information hidden in the images. In this paper, we propose a novel\nmethod to extract weak 3D information directly from 2D images without 3D pose\nsupervision. Firstly, we utilize 2D pose annotations and perspective prior\nknowledge to generate the relationship of that keypoint is closer or farther\nfrom the camera, called relative depth. We collect a 2D pose dataset (MCPC) and\ngenerate relative depth labels. Based on MCPC, we propose a weakly-supervised\npre-training (WSP) strategy to distinguish the depth relationship between two\npoints in an image. WSP enables the learning of the relative depth of two\nkeypoints on lots of in-the-wild images, which is more capable of predicting\ndepth and generalization ability for 3D human pose estimation. After\nfine-tuning on 3D pose datasets, WSP achieves state-of-the-art results on two\nwidely-used benchmarks.",
    "descriptor": "",
    "authors": [
      "Zhongwei Qiu",
      "Kai Qiu",
      "Jianlong Fu",
      "Dongmei Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11983"
  },
  {
    "id": "arXiv:2211.11987",
    "title": "The Tight Spanning Ratio of the Rectangle Delaunay Triangulation",
    "abstract": "Spanner construction is a well-studied problem and Delaunay triangulations\nare among the most popular spanners. Tight bounds are known if the Delaunay\ntriangulation is constructed using an equilateral triangle, a square, or a\nregular hexagon. However, all other shapes have remained elusive. In this paper\nwe extend the restricted class of spanners for which tight bounds are known. We\nprove that Delaunay triangulations constructed using rectangles with aspect\nratio $\\A$ have spanning ratio at most $\\sqrt{2} \\sqrt{1+\\A^2 + \\A \\sqrt{\\A^2 +\n1}}$, which matches the known lower bound.",
    "descriptor": "",
    "authors": [
      "Andr\u00e8 van Renssen",
      "Yuan Sha",
      "Yucheng Sun",
      "Sampson Wong"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2211.11987"
  },
  {
    "id": "arXiv:2211.11988",
    "title": "Vision-based localization methods under GPS-denied conditions",
    "abstract": "This paper reviews vision-based localization methods in GPS-denied\nenvironments and classifies the mainstream methods into Relative Vision\nLocalization (RVL) and Absolute Vision Localization (AVL). For RVL, we discuss\nthe broad application of optical flow in feature extraction-based Visual\nOdometry (VO) solutions and introduce advanced optical flow estimation methods.\nFor AVL, we review recent advances in Visual Simultaneous Localization and\nMapping (VSLAM) techniques, from optimization-based methods to Extended Kalman\nFilter (EKF) based methods. We also introduce the application of offline map\nregistration and lane vision detection schemes to achieve Absolute Visual\nLocalization. This paper compares the performance and applications of\nmainstream methods for visual localization and provides suggestions for future\nstudies.",
    "descriptor": "\nComments: 32 pages, 15 figures\n",
    "authors": [
      "Zihao Lu",
      "Fei Liu",
      "Xianke Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.11988"
  },
  {
    "id": "arXiv:2211.11990",
    "title": "DiME and AGVIS A Distributed Messaging Environment and Geographical  Visualizer for Large-scale Power System Simulation",
    "abstract": "This paper introduces the messaging environment and the geographical\nvisualization tool of the CURENT Large-scale Testbed (LTB) that can be used for\nlarge-scale power system closed-loop simulation. First, Distributed Messaging\nEnvironment (DiME) implements an asynchronous shared workspace to enable\nhigh-concurrent data exchange. Second, Another Grid Visualizer (AGVis) is\npresented as a geovisualization tool that facilitates the visualization of\nreal-time power system simulation. Third, case studies show the use of DiME and\nAGVis. The results demonstrate that, with the modular structure, the LTB is\ncapable of not only federal use for real-time, large-scale power system\nsimulation, but also independent use for customized power system research.",
    "descriptor": "\nComments: 5 pages, 7 figures, conference\n",
    "authors": [
      "Nicholas Parsly",
      "Jinning Wang",
      "Nick West",
      "Qiwei Zhang",
      "Hantao Cui",
      "Fangxing Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.11990"
  },
  {
    "id": "arXiv:2211.11993",
    "title": "Web-based Search: How Do Animated User Interface Elements Affect  Autistic and Non-Autistic Users?",
    "abstract": "Many websites and other user interfaces include animated elements,\nparticularly for advertisements. However, these can have a negative impact on\nusers, with some cohorts, such as autistic users, being more affected. In our\nmixed methods study on the effect of irrelevant animations on usability we\nobserved the effect on search activities. For those greatly impacted by\non-screen animation the effect was not always to slow down a task, but search\nterms were entered hastily to avoid more exposure, with shorter queries on\naverage and a greater tendency to copy and paste during query formulation.\nAutistic users found the task more mentally demanding, and were more distracted\nor annoyed by the animations.",
    "descriptor": "\nComments: Preprint. Accepted to the 17th International Conference on Evaluation of Novel Approaches to Software Engineering (ENASE 2022). Final version published by SCITEPRESS, this http URL\n",
    "authors": [
      "Alexandra L. Uitdenbogerd",
      "Maria Spichkova",
      "Mona Alzahrani"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.11993"
  },
  {
    "id": "arXiv:2211.11994",
    "title": "Another Round of Breaking and Making Quantum Money: How to Not Build It  from Lattices, and More",
    "abstract": "Public verification of quantum money has been one of the central objects in\nquantum cryptography ever since Wiesner's pioneering idea of using quantum\nmechanics to construct banknotes against counterfeiting. So far, we do not know\nany publicly-verifiable quantum money scheme that is provably secure from\nstandard assumptions.\nIn this work, we provide both negative and positive results for publicly\nverifiable quantum money.\n**In the first part, we give a general theorem, showing that a certain\nnatural class of quantum money schemes from lattices cannot be secure. We use\nthis theorem to break the recent quantum money scheme of Khesin, Lu, and Shor.\n**In the second part, we propose a framework for building quantum money and\nquantum lightning we call invariant money which abstracts some of the ideas of\nquantum money from knots by Farhi et al.(ITCS'12). In addition to formalizing\nthis framework, we provide concrete hard computational problems loosely\ninspired by classical knowledge-of-exponent assumptions, whose hardness would\nimply the security of quantum lightning, a strengthening of quantum money where\nnot even the bank can duplicate banknotes.\n**We discuss potential instantiations of our framework, including an oracle\nconstruction using cryptographic group actions and instantiations from\nrerandomizable functional encryption, isogenies over elliptic curves, and\nknots.",
    "descriptor": "",
    "authors": [
      "Hart Montgomery",
      "Jiahui Liu",
      "Mark Zhandry"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.11994"
  },
  {
    "id": "arXiv:2211.11997",
    "title": "REFINE: Reachability-based Trajectory Design using Robust Feedback  Linearization and Zonotopes",
    "abstract": "Performing real-time receding horizon motion planning for autonomous vehicles\nwhile providing safety guarantees remains difficult. This is because existing\nmethods to accurately predict ego vehicle behavior under a chosen controller\nuse online numerical integration that requires a fine time discretization and\nthereby adversely affects real-time performance. To address this limitation,\nseveral recent papers have proposed to apply offline reachability analysis to\nconservatively predict the behavior of the ego vehicle. This reachable set can\nbe constructed by utilizing a simplified model whose behavior is assumed a\npriori to conservatively bound the dynamics of a full-order model. However,\nguaranteeing that one satisfies this assumption is challenging. This paper\nproposes a framework named REFINE to overcome the limitations of these existing\napproaches. REFINE utilizes a parameterized robust controller that partially\nlinearizes the vehicle dynamics even in the presence of modeling error.\nZonotope-based reachability analysis is then performed on the closed-loop,\nfull-order vehicle dynamics to compute the corresponding control-parameterized,\nover-approximate Forward Reachable Sets (FRS). Because reachability analysis is\napplied to the full-order model, the potential conservativeness introduced by\nusing a simplified model is avoided. The pre-computed, control-parameterized\nFRS is then used online in an optimization framework to ensure safety. The\nproposed method is compared to several state of the art methods during a\nsimulation-based evaluation on a full-size vehicle model and is evaluated on a\n1/10th race car robot in real hardware testing. In contrast to existing\nmethods, REFINE is shown to enable the vehicle to safely navigate itself\nthrough complex environments.",
    "descriptor": "",
    "authors": [
      "Jinsun Liu",
      "Yifei Shao",
      "Lucas Lymburner",
      "Hansen Qin",
      "Vishrut Kaushik",
      "Lena Trang",
      "Ruiyang Wang",
      "Vladimir Ivanovic",
      "H. Eric Tseng",
      "Ram Vasudevan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.11997"
  },
  {
    "id": "arXiv:2211.12000",
    "title": "ArzEn-ST: A Three-way Speech Translation Corpus for Code-Switched  Egyptian Arabic - English",
    "abstract": "We present our work on collecting ArzEn-ST, a code-switched Egyptian Arabic -\nEnglish Speech Translation Corpus. This corpus is an extension of the ArzEn\nspeech corpus, which was collected through informal interviews with bilingual\nspeakers. In this work, we collect translations in both directions, monolingual\nEgyptian Arabic and monolingual English, forming a three-way speech translation\ncorpus. We make the translation guidelines and corpus publicly available. We\nalso report results for baseline systems for machine translation and speech\ntranslation tasks. We believe this is a valuable resource that can motivate and\nfacilitate further research studying the code-switching phenomenon from a\nlinguistic perspective and can be used to train and evaluate NLP systems.",
    "descriptor": "\nComments: Accepted to the Seventh Arabic Natural Language Processing Workshop (WANLP 2022)\n",
    "authors": [
      "Injy Hamed",
      "Nizar Habash",
      "Slim Abdennadher",
      "Ngoc Thang Vu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.12000"
  },
  {
    "id": "arXiv:2211.12002",
    "title": "Explainability of Traditional and Deep Learning Models on Longitudinal  Healthcare Records",
    "abstract": "Recent advances in deep learning have led to interest in training deep\nlearning models on longitudinal healthcare records to predict a range of\nmedical events, with models demonstrating high predictive performance.\nPredictive performance is necessary but insufficient, however, with\nexplanations and reasoning from models required to convince clinicians for\nsustained use. Rigorous evaluation of explainability is often missing, as\ncomparisons between models (traditional versus deep) and various explainability\nmethods have not been well-studied. Furthermore, ground truths needed to\nevaluate explainability can be highly subjective depending on the clinician's\nperspective. Our work is one of the first to evaluate explainability\nperformance between and within traditional (XGBoost) and deep learning (LSTM\nwith Attention) models on both a global and individual per-prediction level on\nlongitudinal healthcare data. We compared explainability using three popular\nmethods: 1) SHapley Additive exPlanations (SHAP), 2) Layer-Wise Relevance\nPropagation (LRP), and 3) Attention. These implementations were applied on\nsynthetically generated datasets with designed ground-truths and a real-world\nmedicare claims dataset. We showed that overall, LSTMs with SHAP or LRP\nprovides superior explainability compared to XGBoost on both the global and\nlocal level, while LSTM with dot-product attention failed to produce reasonable\nones. With the explosion of the volume of healthcare data and deep learning\nprogress, the need to evaluate explainability will be pivotal towards\nsuccessful adoption of deep learning models in healthcare settings.",
    "descriptor": "\nComments: 21 pages, 10 figures\n",
    "authors": [
      "Lin Lee Cheong",
      "Tesfagabir Meharizghi",
      "Wynona Black",
      "Yang Guang",
      "Weilin Meng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12002"
  },
  {
    "id": "arXiv:2211.12003",
    "title": "Application of property-based testing tools\\\\ for metamorphic testing",
    "abstract": "Metamorphic testing (MT) is a general approach for the testing of a specific\nkind of software systems -- so-called ``non-testable'', where the ``classical''\ntesting approaches are difficult to apply. MT is an effective approach for\naddressing the test oracle problem and test case generation problem. The test\noracle problem is when it is difficult to determine the correct expected output\nof a particular test case or to determine whether the actual outputs agree with\nthe expected outcomes. The core concept in MT is metamorphic relations (MRs)\nwhich provide formal specification of the system under test. One of the\nchallenges in MT is \\emph{effective test generation}. Property-based testing\n(PBT) is a testing methodology in which test cases are generated according to\ndesired properties of the software. In some sense, MT can be seen as a very\nspecific kind of PBT.\\\\ In this paper, we show how to use PBT tools to automate\ntest generation and verification of MT. In addition to automation benefit, the\nproposed method shows how to combine general PBT with MT under the same testing\nframework.",
    "descriptor": "\nComments: Preprint. Accepted to the 17th International Conference on Evaluation of Novel Approaches to Software Engineering (ENASE 2022). Final version published by SCITEPRESS, this http URL\n",
    "authors": [
      "Nasser Alzahrani",
      "Maria Spichkova",
      "James Harland"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2211.12003"
  },
  {
    "id": "arXiv:2211.12005",
    "title": "Self-Ensemble Protection: Training Checkpoints Are Good Data Protectors",
    "abstract": "As data become increasingly vital for deep learning, a company would be very\ncautious about releasing data, because the competitors could use the released\ndata to train high-performance models, thereby posing a tremendous threat to\nthe company's commercial competence. To prevent training good models on the\ndata, imperceptible perturbations could be added to it. Since such\nperturbations aim at hurting the entire training process, they should reflect\nthe vulnerability of DNN training, rather than that of a single model. Based on\nthis new idea, we seek adversarial examples that are always unrecognized (never\ncorrectly classified) in training. In this paper, we uncover them by modeling\ncheckpoints' gradients, forming the proposed self-ensemble protection (SEP),\nwhich is very effective because (1) learning on examples ignored during normal\ntraining tends to yield DNNs ignoring normal examples; (2) checkpoints'\ncross-model gradients are close to orthogonal, meaning that they are as diverse\nas DNNs with different architectures in conventional ensemble. That is, our\namazing performance of ensemble only requires the computation of training one\nmodel. By extensive experiments with 9 baselines on 3 datasets and 5\narchitectures, SEP is verified to be a new state-of-the-art, e.g., our small\n$\\ell_\\infty=2/255$ perturbations reduce the accuracy of a CIFAR-10 ResNet18\nfrom 94.56\\% to 14.68\\%, compared to 41.35\\% by the best-known method.Code is\navailable at https://github.com/Sizhe-Chen/SEP.",
    "descriptor": "",
    "authors": [
      "Sizhe Chen",
      "Geng Yuan",
      "Xinwen Cheng",
      "Yifan Gong",
      "Minghai Qin",
      "Yanzhi Wang",
      "Xiaolin Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.12005"
  },
  {
    "id": "arXiv:2211.12006",
    "title": "Differentiable Fuzzy $\\mathcal{ALC}$: A Neural-Symbolic Representation  Language for Symbol Grounding",
    "abstract": "Neural-symbolic computing aims at integrating robust neural learning and\nsound symbolic reasoning into a single framework, so as to leverage the\ncomplementary strengths of both of these, seemingly unrelated (maybe even\ncontradictory) AI paradigms. The central challenge in neural-symbolic computing\nis to unify the formulation of neural learning and symbolic reasoning into a\nsingle framework with common semantics, that is, to seek a joint representation\nbetween a neural model and a logical theory that can support the basic\ngrounding learned by the neural model and also stick to the semantics of the\nlogical theory. In this paper, we propose differentiable fuzzy $\\mathcal{ALC}$\n(DF-$\\mathcal{ALC}$) for this role, as a neural-symbolic representation\nlanguage with the desired semantics. DF-$\\mathcal{ALC}$ unifies the description\nlogic $\\mathcal{ALC}$ and neural models for symbol grounding; in particular, it\ninfuses an $\\mathcal{ALC}$ knowledge base into neural models through\ndifferentiable concept and role embeddings. We define a hierarchical loss to\nthe constraint that the grounding learned by neural models must be semantically\nconsistent with $\\mathcal{ALC}$ knowledge bases. And we find that capturing the\nsemantics in grounding solely by maximizing satisfiability cannot revise\ngrounding rationally. We further define a rule-based loss for DF adapting to\nsymbol grounding problems. The experiment results show that DF-$\\mathcal{ALC}$\nwith rule-based loss can improve the performance of image object detectors in\nan unsupervised learning way, even in low-resource situations.",
    "descriptor": "",
    "authors": [
      "Xuan Wu",
      "Xinhao Zhu",
      "Yizheng Zhao",
      "Xinyu Dai"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12006"
  },
  {
    "id": "arXiv:2211.12009",
    "title": "Deep-Learning-Based Computer Vision Approach For The Segmentation Of  Ball Deliveries And Tracking In Cricket",
    "abstract": "There has been a significant increase in the adoption of technology in\ncricket recently. This trend has created the problem of duplicate work being\ndone in similar computer vision-based research works. Our research tries to\nsolve one of these problems by segmenting ball deliveries in a cricket\nbroadcast using deep learning models, MobileNet and YOLO, thus enabling\nresearchers to use our work as a dataset for their research. The output from\nour research can be used by cricket coaches and players to analyze ball\ndeliveries which are played during the match. This paper presents an approach\nto segment and extract video shots in which only the ball is being delivered.\nThe video shots are a series of continuous frames that make up the whole scene\nof the video. Object detection models are applied to reach a high level of\naccuracy in terms of correctly extracting video shots. The proof of concept for\nbuilding large datasets of video shots for ball deliveries is proposed which\npaves the way for further processing on those shots for the extraction of\nsemantics. Ball tracking in these video shots is also done using a separate\nRetinaNet model as a sample of the usefulness of the proposed dataset. The\nposition on the cricket pitch where the ball lands is also extracted by\ntracking the ball along the y-axis. The video shot is then classified as a\nfull-pitched, good-length or short-pitched delivery.",
    "descriptor": "",
    "authors": [
      "Kumail Abbas",
      "Muhammad Saeed",
      "M. Imad Khan",
      "Khandakar Ahmed",
      "Hua Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12009"
  },
  {
    "id": "arXiv:2211.12016",
    "title": "Variation-based Cause Effect Identification",
    "abstract": "Mining genuine mechanisms underlying the complex data generation process in\nreal-world systems is a fundamental step in promoting interpretability of, and\nthus trust in, data-driven models. Therefore, we propose a variation-based\ncause effect identification (VCEI) framework for causal discovery in bivariate\nsystems from a single observational setting. Our framework relies on the\nprinciple of independence of cause and mechanism (ICM) under the assumption of\nan existing acyclic causal link, and offers a practical realization of this\nprinciple. Principally, we artificially construct two settings in which the\nmarginal distributions of one covariate, claimed to be the cause, are\nguaranteed to have non-negligible variations. This is achieved by re-weighting\nsamples of the marginal so that the resultant distribution is notably distinct\nfrom this marginal according to some discrepancy measure. In the causal\ndirection, such variations are expected to have no impact on the effect\ngeneration mechanism. Therefore, quantifying the impact of these variations on\nthe conditionals reveals the genuine causal direction. Moreover, we formulate\nour approach in the kernel-based maximum mean discrepancy, lifting all\nconstraints on the data types of cause-and-effect covariates, and rendering\nsuch artificial interventions a convex optimization problem. We provide a\nseries of experiments on real and synthetic data showing that VCEI is, in\nprinciple, competitive to other cause effect identification frameworks.",
    "descriptor": "",
    "authors": [
      "Mohamed Amine ben Salem",
      "Karim Said Barsim",
      "Bin Yang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.12016"
  },
  {
    "id": "arXiv:2211.12018",
    "title": "Level-S$^2$fM: Structure from Motion on Neural Level Set of Implicit  Surfaces",
    "abstract": "This paper presents a neural incremental Structure-from-Motion (SfM)\napproach, Level-S$^2$fM. In our formulation, we aim at simultaneously learning\ncoordinate MLPs for the implicit surfaces and the radiance fields, and\nestimating the camera poses and scene geometry, which is mainly sourced from\nthe established keypoint correspondences by SIFT. Our formulation would face\nsome new challenges due to inevitable two-view and few-view configurations at\nthe beginning of incremental SfM pipeline for the optimization of coordinate\nMLPs, but we found that the strong inductive biases conveying in the 2D\ncorrespondences are feasible and promising to avoid those challenges by\nexploiting the relationship between the ray sampling schemes used in volumetric\nrendering and the sphere tracing of finding the zero-level set of implicit\nsurfaces. Based on this, we revisit the pipeline of incremental SfM and renew\nthe key components of two-view geometry initialization, the camera pose\nregistration, and the 3D points triangulation, as well as the Bundle Adjustment\nin a novel perspective of neural implicit surfaces. Because the coordinate MLPs\nunified the scene geometry in small MLP networks, our Level-S$^2$fM treats the\nzero-level set of the implicit surface as an informative top-down\nregularization to manage the reconstructed 3D points, reject the outlier of\ncorrespondences by querying SDF, adjust the estimated geometries by NBA (Neural\nBA), finally yielding promising results of 3D reconstruction. Furthermore, our\nLevel-S$^2$fM alleviated the requirement of camera poses for neural 3D\nreconstruction.",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Yuxi Xiao",
      "Nan Xue",
      "Tianfu Wu",
      "Gui-Song Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12018"
  },
  {
    "id": "arXiv:2211.12020",
    "title": "PhAST: Physics-Aware, Scalable, and Task-specific GNNs for Accelerated  Catalyst Design",
    "abstract": "Mitigating the climate crisis requires a rapid transition towards lower\ncarbon energy. Catalyst materials play a crucial role in the electrochemical\nreactions involved in a great number of industrial processes key to this\ntransition, such as renewable energy storage and electrofuel synthesis. To\nreduce the amount of energy spent on such processes, we must quickly discover\nmore efficient catalysts to drive the electrochemical reactions. Machine\nlearning (ML) holds the potential to efficiently model the properties of\nmaterials from large amounts of data, and thus to accelerate electrocatalyst\ndesign. The Open Catalyst Project OC20 data set was constructed to that end.\nHowever, most existing ML models trained on OC20 are still neither scalable nor\naccurate enough for practical applications. Here, we propose several\ntask-specific innovations, applicable to most architectures, which increase\nboth computational efficiency and accuracy. In particular, we propose\nimprovements in (1) the graph creation step, (2) atom representations and (3)\nthe energy prediction head. We describe these contributions and evaluate them\non several architectures, showing up to 5$\\times$ reduction in inference time\nwithout sacrificing accuracy.",
    "descriptor": "\nComments: Accepted at the NeurIPS 2022 AI for Accelerated Materials Design Workshop\n",
    "authors": [
      "Alexandre Duval",
      "Victor Schmidt",
      "Santiago Miret",
      "Yoshua Bengio",
      "Alex Hern\u00e1ndez-Garc\u00eda",
      "David Rolnick"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.12020"
  },
  {
    "id": "arXiv:2211.12021",
    "title": "ViFi-Loc: Multi-modal Pedestrian Localization using GAN with  Camera-Phone Correspondences",
    "abstract": "In Smart City and Vehicle-to-Everything (V2X) systems, acquiring pedestrians'\naccurate locations is crucial to traffic safety. Current systems adopt cameras\nand wireless sensors to detect and estimate people's locations via sensor\nfusion. Standard fusion algorithms, however, become inapplicable when\nmulti-modal data is not associated. For example, pedestrians are out of the\ncamera field of view, or data from camera modality is missing. To address this\nchallenge and produce more accurate location estimations for pedestrians, we\npropose a Generative Adversarial Network (GAN) architecture. During training,\nit learns the underlying linkage between pedestrians' camera-phone data\ncorrespondences. During inference, it generates refined position estimations\nbased only on pedestrians' phone data that consists of GPS, IMU and FTM.\nResults show that our GAN produces 3D coordinates at 1 to 2 meter localization\nerror across 5 different outdoor scenes. We further show that the proposed\nmodel supports self-learning. The generated coordinates can be associated with\npedestrian's bounding box coordinates to obtain additional camera-phone data\ncorrespondences. This allows automatic data collection during inference. After\nfine-tuning on the expanded dataset, localization accuracy is improved by up to\n26%.",
    "descriptor": "",
    "authors": [
      "Hansi Liu",
      "Kristin Dana",
      "Marco Gruteser",
      "Hongsheng Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12021"
  },
  {
    "id": "arXiv:2211.12024",
    "title": "TaylorBeamixer: Learning Taylor-Inspired All-Neural Multi-Channel Speech  Enhancement from Beam-Space Dictionary Perspective",
    "abstract": "Despite the promising performance of existing frame-wise all-neural\nbeamformers in the speech enhancement field, it remains unclear what the\nunderlying mechanism exists. In this paper, we revisit the beamforming behavior\nfrom the beam-space dictionary perspective and formulate it into the learning\nand mixing of different beam-space components. Based on that, we propose an\nall-neural beamformer called TaylorBM to simulate Taylor's series expansion\noperation in which the 0th-order term serves as a spatial filter to conduct the\nbeam mixing, and several high-order terms are tasked with residual noise\ncancellation for post-processing. The whole system is devised to work in an\nend-to-end manner. Experiments are conducted on the spatialized LibriSpeech\ncorpus and results show that the proposed approach outperforms existing\nadvanced baselines in terms of evaluation metrics.",
    "descriptor": "\nComments: In submission to ICASSP 2023, 5 pages\n",
    "authors": [
      "Andong Li",
      "Guochen Yu",
      "Wenzhe Liu",
      "Xiaodong Li",
      "Chengshi Zheng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.12024"
  },
  {
    "id": "arXiv:2211.12030",
    "title": "Knowledge Prompting for Few-shot Action Recognition",
    "abstract": "Few-shot action recognition in videos is challenging for its lack of\nsupervision and difficulty in generalizing to unseen actions. To address this\ntask, we propose a simple yet effective method, called knowledge prompting,\nwhich leverages commonsense knowledge of actions from external resources to\nprompt a powerful pre-trained vision-language model for few-shot\nclassification. We first collect large-scale language descriptions of actions,\ndefined as text proposals, to build an action knowledge base. The collection of\ntext proposals is done by filling in handcraft sentence templates with external\naction-related corpus or by extracting action-related phrases from captions of\nWeb instruction videos.Then we feed these text proposals into the pre-trained\nvision-language model along with video frames to generate matching scores of\nthe proposals to each frame, and the scores can be treated as action semantics\nwith strong generalization. Finally, we design a lightweight temporal modeling\nnetwork to capture the temporal evolution of action semantics for\nclassification.Extensive experiments on six benchmark datasets demonstrate that\nour method generally achieves the state-of-the-art performance while reducing\nthe training overhead to 0.001 of existing methods.",
    "descriptor": "",
    "authors": [
      "Yuheng Shi",
      "Xinxiao Wu",
      "Hanxi Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12030"
  },
  {
    "id": "arXiv:2211.12031",
    "title": "A neuron-wise subspace correction method for the finite neuron method",
    "abstract": "In this paper, we propose a novel algorithm called Neuron-wise Parallel\nSubspace Correction Method (NPSC) for training ReLU neural networks for\nnumerical solution of partial differential equations (PDEs). Despite of\nextremely extensive research activities in applying neural networks for\nnumerical PDEs, there is still a serious lack of training algorithms that can\nbe used to obtain approximation with adequate accuracy. Based on recent results\non the spectral properties of linear layers and landscape analysis for single\nneuron problems, we develop a special type of subspace correction method that\ndeals with the linear layer and each neuron in the nonlinear layer separately.\nAn optimal preconditioner that resolves the ill-conditioning of the linear\nlayer is presented, so that the linear layer is trained in a uniform number of\niterations with respect to the number of neurons. In each single neuron\nproblem, a good local minimum is found by a superlinearly convergent algorithm,\navoiding regions where the loss function is flat. Performance of the proposed\nmethod is demonstrated through numerical experiments for function approximation\nproblems and PDEs.",
    "descriptor": "\nComments: 19 pages, 5 figures\n",
    "authors": [
      "Jongho Park",
      "Jinchao Xu",
      "Xiaofeng Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.12031"
  },
  {
    "id": "arXiv:2211.12032",
    "title": "PointCMC: Cross-Modal Multi-Scale Correspondences Learning for Point  Cloud Understanding",
    "abstract": "Some self-supervised cross-modal learning approaches have recently\ndemonstrated the potential of image signals for enhancing point cloud\nrepresentation. However, it remains a question on how to directly model\ncross-modal local and global correspondences in a self-supervised fashion. To\nsolve it, we proposed PointCMC, a novel cross-modal method to model multi-scale\ncorrespondences across modalities for self-supervised point cloud\nrepresentation learning. In particular, PointCMC is composed of: (1) a\nlocal-to-local (L2L) module that learns local correspondences through optimized\ncross-modal local geometric features, (2) a local-to-global (L2G) module that\naims to learn the correspondences between local and global features across\nmodalities via local-global discrimination, and (3) a global-to-global (G2G)\nmodule, which leverages auxiliary global contrastive loss between the point\ncloud and image to learn high-level semantic correspondences. Extensive\nexperiment results show that our approach outperforms existing state-of-the-art\nmethods in various downstream tasks such as 3D object classification and\nsegmentation. Code will be made publicly available upon acceptance.",
    "descriptor": "",
    "authors": [
      "Honggu Zhou",
      "Xiaogang Peng",
      "Jiawei Mao",
      "Zizhao Wu",
      "Ming Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12032"
  },
  {
    "id": "arXiv:2211.12033",
    "title": "BASM: A Bottom-up Adaptive Spatiotemporal Model for Online Food Ordering  Service",
    "abstract": "Online Food Ordering Service (OFOS) is a popular location-based service that\nhelps people to order what you want. Compared with traditional e-commerce\nrecommendation systems, users' interests may be diverse under different\nspatiotemporal contexts, leading to various spatiotemporal data distribution,\nwhich limits the fitting capacity of the model. However, numerous current works\nsimply mix all samples to train a set of model parameters, which makes it\ndifficult to capture the diversity in different spatiotemporal contexts.\nTherefore, we address this challenge by proposing a Bottom-up Adaptive\nSpatiotemporal Model(BASM) to adaptively fit the spatiotemporal data\ndistribution, which further improve the fitting capability of the model.\nSpecifically, a spatiotemporal-aware embedding layer performs weight adaptation\non field granularity in feature embedding, to achieve the purpose of\ndynamically perceiving spatiotemporal contexts. Meanwhile, we propose a\nspatiotemporal semantic transformation layer to explicitly convert the\nconcatenated input of the raw semantic to spatiotemporal semantic, which can\nfurther enhance the semantic representation under different spatiotemporal\ncontexts. Furthermore, we introduce a novel spatiotemporal adaptive bias tower\nto capture diverse spatiotemporal bias, reducing the difficulty to model\nspatiotemporal distinction. To further verify the effectiveness of BASM, we\nalso novelly propose two new metrics, Time-period-wise AUC (TAUC) and City-wise\nAUC (CAUC). Extensive offline evaluations on public and industrial datasets are\nconducted to demonstrate the effectiveness of our proposed modle. The online\nA/B experiment also further illustrates the practicability of the model online\nservice. This proposed method has now been implemented on the Ele.me, a major\nonline food ordering platform in China, serving more than 100 million online\nusers.",
    "descriptor": "",
    "authors": [
      "Boya Du",
      "Shaochuan Lin",
      "Jiong Gao",
      "Xiyu Ji",
      "Mengya Wang",
      "Taotao Zhou",
      "Hengxu He",
      "Jia Jia",
      "Ning Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12033"
  },
  {
    "id": "arXiv:2211.12034",
    "title": "Time Series Forecasting with Hypernetworks Generating Parameters in  Advance",
    "abstract": "Forecasting future outcomes from recent time series data is not easy,\nespecially when the future data are different from the past (i.e. time series\nare under temporal drifts). Existing approaches show limited performances under\ndata drifts, and we identify the main reason: It takes time for a model to\ncollect sufficient training data and adjust its parameters for complicated\ntemporal patterns whenever the underlying dynamics change. To address this\nissue, we study a new approach; instead of adjusting model parameters (by\ncontinuously re-training a model on new data), we build a hypernetwork that\ngenerates other target models' parameters expected to perform well on the\nfuture data. Therefore, we can adjust the model parameters beforehand (if the\nhypernetwork is correct). We conduct extensive experiments with 6 target\nmodels, 6 baselines, and 4 datasets, and show that our HyperGPA outperforms\nother baselines.",
    "descriptor": "\nComments: 7 pages, preprint (we open our code after being accepted)\n",
    "authors": [
      "Jaehoon Lee",
      "Chan Kim",
      "Gyumin Lee",
      "Haksoo Lim",
      "Jeongwhan Choi",
      "Kookjin Lee",
      "Dongeun Lee",
      "Sanghyun Hong",
      "Noseong Park"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12034"
  },
  {
    "id": "arXiv:2211.12035",
    "title": "FastFlow: AI for Fast Urban Wind Velocity Prediction",
    "abstract": "Data-driven approaches, including deep learning, have shown great promise as\nsurrogate models across many domains. These extend to various areas in\nsustainability. An interesting direction for which data-driven methods have not\nbeen applied much yet is in the quick quantitative evaluation of urban layouts\nfor planning and design. In particular, urban designs typically involve complex\ntrade-offs between multiple objectives, including limits on urban build-up\nand/or consideration of urban heat island effect. Hence, it can be beneficial\nto urban planners to have a fast surrogate model to predict urban\ncharacteristics of a hypothetical layout, e.g. pedestrian-level wind velocity,\nwithout having to run computationally expensive and time-consuming\nhigh-fidelity numerical simulations. This fast surrogate can then be\npotentially integrated into other design optimization frameworks, including\ngenerative models or other gradient-based methods. Here we present the use of\nCNNs for urban layout characterization that is typically done via high-fidelity\nnumerical simulation. We further apply this model towards a first demonstration\nof its utility for data-driven pedestrian-level wind velocity prediction. The\ndata set in this work comprises results from high-fidelity numerical\nsimulations of wind velocities for a diverse set of realistic urban layouts,\nbased on randomized samples from a real-world, highly built-up urban city. We\nthen provide prediction results obtained from the trained CNN, demonstrating\ntest errors of under 0.1 m/s for previously unseen urban layouts. We further\nillustrate how this can be useful for purposes such as rapid evaluation of\npedestrian wind velocity for a potential new layout. It is hoped that this data\nset will further accelerate research in data-driven urban AI, even as our\nbaseline model facilitates quantitative comparison to future methods.",
    "descriptor": "",
    "authors": [
      "Shi Jer Low",
      "Venugopalan",
      "S.G. Raghavan",
      "Harish Gopalan",
      "Jian Cheng Wong",
      "Justin Yeoh",
      "Chin Chun Ooi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2211.12035"
  },
  {
    "id": "arXiv:2211.12036",
    "title": "Domain Alignment and Temporal Aggregation for Unsupervised Video Object  Segmentation",
    "abstract": "Unsupervised video object segmentation aims at detecting and segmenting the\nmost salient object in videos. In recent times, two-stream approaches that\ncollaboratively leverage appearance cues and motion cues have attracted\nextensive attention thanks to their powerful performance. However, there are\ntwo limitations faced by those methods: 1) the domain gap between appearance\nand motion information is not well considered; and 2) long-term temporal\ncoherence within a video sequence is not exploited. To overcome these\nlimitations, we propose a domain alignment module (DAM) and a temporal\naggregation module (TAM). DAM resolves the domain gap between two modalities by\nforcing the values to be in the same range using a cross-correlation mechanism.\nTAM captures long-term coherence by extracting and leveraging global cues of a\nvideo. On public benchmark datasets, our proposed approach demonstrates its\neffectiveness, outperforming all existing methods by a substantial margin.",
    "descriptor": "",
    "authors": [
      "Suhwan Cho",
      "Minhyeok Lee",
      "Seunghoon Lee",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12036"
  },
  {
    "id": "arXiv:2211.12038",
    "title": "ONeRF: Unsupervised 3D Object Segmentation from Multiple Views",
    "abstract": "We present ONeRF, a method that automatically segments and reconstructs\nobject instances in 3D from multi-view RGB images without any additional manual\nannotations. The segmented 3D objects are represented using separate Neural\nRadiance Fields (NeRFs) which allow for various 3D scene editing and novel view\nrendering. At the core of our method is an unsupervised approach using the\niterative Expectation-Maximization algorithm, which effectively aggregates 2D\nvisual features and the corresponding 3D cues from multi-views for joint 3D\nobject segmentation and reconstruction. Unlike existing approaches that can\nonly handle simple objects, our method produces segmented full 3D NeRFs of\nindividual objects with complex shapes, topologies and appearance. The\nsegmented ONeRfs enable a range of 3D scene editing, such as object\ntransformation, insertion and deletion.",
    "descriptor": "",
    "authors": [
      "Shengnan Liang",
      "Yichen Liu",
      "Shangzhe Wu",
      "Yu-Wing Tai",
      "Chi-Keung Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12038"
  },
  {
    "id": "arXiv:2211.12039",
    "title": "Accelerating Diffusion Sampling with Classifier-based Feature  Distillation",
    "abstract": "Although diffusion model has shown great potential for generating higher\nquality images than GANs, slow sampling speed hinders its wide application in\npractice. Progressive distillation is thus proposed for fast sampling by\nprogressively aligning output images of $N$-step teacher sampler with\n$N/2$-step student sampler. In this paper, we argue that this\ndistillation-based accelerating method can be further improved, especially for\nfew-step samplers, with our proposed \\textbf{C}lassifier-based \\textbf{F}eature\n\\textbf{D}istillation (CFD). Instead of aligning output images, we distill\nteacher's sharpened feature distribution into the student with a\ndataset-independent classifier, making the student focus on those important\nfeatures to improve performance. We also introduce a dataset-oriented loss to\nfurther optimize the model. Experiments on CIFAR-10 show the superiority of our\nmethod in achieving high quality and fast sampling. Code will be released soon.",
    "descriptor": "",
    "authors": [
      "Wujie Sun",
      "Defang Chen",
      "Can Wang",
      "Deshi Ye",
      "Yan Feng",
      "Chun Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12039"
  },
  {
    "id": "arXiv:2211.12040",
    "title": "Rethinking Implicit Neural Representations for vision Learners",
    "abstract": "Implicit Neural Representations (INRs) are powerful to parameterize\ncontinuous signals in computer vision. However, almost all INRs methods are\nlimited to low-level tasks, e.g., image/video compression, super-resolution,\nand image generation. The questions on how to explore INRs to high-level tasks\nand deep networks are still under-explored. Existing INRs methods suffer from\ntwo problems: 1) narrow theoretical definitions of INRs are inapplicable to\nhigh-level tasks; 2) lack of representation capabilities to deep networks.\nMotivated by the above facts, we reformulate the definitions of INRs from a\nnovel perspective and propose an innovative Implicit Neural Representation\nNetwork (INRN), which is the first study of INRs to tackle both low-level and\nhigh-level tasks. Specifically, we present three key designs for basic blocks\nin INRN along with two different stacking ways and corresponding loss\nfunctions. Extensive experiments with analysis on both low-level tasks (image\nfitting) and high-level vision tasks (image classification, object detection,\ninstance segmentation) demonstrate the effectiveness of the proposed method.",
    "descriptor": "",
    "authors": [
      "Yiran Song",
      "Qianyu Zhou",
      "Lizhuang Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12040"
  },
  {
    "id": "arXiv:2211.12042",
    "title": "Robustness of Physics-Informed Neural Networks to Noise in Sensor Data",
    "abstract": "Physics-Informed Neural Networks (PINNs) have been shown to be an effective\nway of incorporating physics-based domain knowledge into neural network models\nfor many important real-world systems. They have been particularly effective as\na means of inferring system information based on data, even in cases where data\nis scarce. Most of the current work however assumes the availability of\nhigh-quality data. In this work, we further conduct a preliminary investigation\nof the robustness of physics-informed neural networks to the magnitude of noise\nin the data. Interestingly, our experiments reveal that the inclusion of\nphysics in the neural network is sufficient to negate the impact of noise in\ndata originating from hypothetical low quality sensors with high\nsignal-to-noise ratios of up to 1. The resultant predictions for this test case\nare seen to still match the predictive value obtained for equivalent data\nobtained from high-quality sensors with potentially 10x less noise. This\nfurther implies the utility of physics-informed neural network modeling for\nmaking sense of data from sensor networks in the future, especially with the\nadvent of Industry 4.0 and the increasing trend towards ubiquitous deployment\nof low-cost sensors which are typically noisier.",
    "descriptor": "",
    "authors": [
      "Jian Cheng Wong",
      "Pao-Hsiung Chiu",
      "Chin Chun Ooi",
      "My Ha Da"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.12042"
  },
  {
    "id": "arXiv:2211.12044",
    "title": "Backdoor Cleansing with Unlabeled Data",
    "abstract": "Due to the increasing computational demand of Deep Neural Networks (DNNs),\ncompanies and organizations have begun to outsource the training process.\nHowever, the externally trained DNNs can potentially be backdoor attacked. It\nis crucial to defend against such attacks, i.e., to postprocess a suspicious\nmodel so that its backdoor behavior is mitigated while its normal prediction\npower on clean inputs remain uncompromised. To remove the abnormal backdoor\nbehavior, existing methods mostly rely on additional labeled clean samples.\nHowever, such requirement may be unrealistic as the training data are often\nunavailable to end users. In this paper, we investigate the possibility of\ncircumventing such barrier. We propose a novel defense method that does not\nrequire training labels. Through a carefully designed layer-wise weight\nre-initialization and knowledge distillation, our method can effectively\ncleanse backdoor behaviors of a suspicious network {with negligible compromise\nin} its normal behavior. In experiments, we show that our method, trained\nwithout labels, is on-par with state-of-the-art defense methods trained using\nlabels. We also observe promising defense results even on out-of-distribution\ndata. This makes our method very practical.",
    "descriptor": "",
    "authors": [
      "Lu Pang",
      "Tao Sun",
      "Haibin Ling",
      "Chao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.12044"
  },
  {
    "id": "arXiv:2211.12045",
    "title": "Design and control of a collision-resilient aerial vehicle with an  icosahedron tensegrity structure",
    "abstract": "We present the tensegrity aerial vehicle, a design of collision-resilient\nrotor robots with icosahedron tensegrity structures. The tensegrity aerial\nvehicles can withstand high-speed impacts and resume operation after\ncollisions. To guide the design process of these aerial vehicles, we propose a\nmodel-based methodology that predicts the stresses in the structure with a\ndynamics simulation and selects components that can withstand the predicted\nstresses. Meanwhile, an autonomous re-orientation controller is created to help\nthe tensegrity aerial vehicles resume flight after collisions. The\nre-orientation controller can rotate the vehicles from arbitrary orientations\non the ground to ones easy for takeoff. With collision resilience and\nre-orientation ability, the tensegrity aerial vehicles can operate in cluttered\nenvironments without complex collision-avoidance strategies. Moreover, by\nadopting an inertial navigation strategy of replacing flight with short hops to\nmitigate the growth of state estimation error, the tensegrity aerial vehicles\ncan conduct short-range operations without external sensors. These capabilities\nare validated by a test of an experimental tensegrity aerial vehicle operating\nwith only onboard inertial sensors in a previously-unknown forest.",
    "descriptor": "\nComments: 12 pages, 16 figures\n",
    "authors": [
      "Jiaming Zha",
      "Xiangyu Wu",
      "Ryan Dimick",
      "Mark W. Mueller"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.12045"
  },
  {
    "id": "arXiv:2211.12046",
    "title": "Deblurred Neural Radiance Field with Physical Scene Priors",
    "abstract": "Neural Radiance Field(NeRF) has exhibited outstanding three-dimensional(3D)\nreconstruction quality via the novel view synthesis from multi-view images and\npaired calibrated camera parameters. However, previous NeRF-based systems have\nbeen demonstrated under strictly controlled settings, with little attention\npaid to less ideal scenarios, including with the presence of noise such as\nexposure, illumination changes, and blur. In particular, though blur frequently\noccurs in real situations, NeRF that can handle blurred images has received\nlittle attention. The few studies that have investigated NeRF for blurred\nimages have not considered geometric and appearance consistency in 3D space,\nwhich is one of the most important factors in 3D reconstruction. This leads to\ninconsistency and the degradation of the perceptual quality of the constructed\nscene. Hence, this paper proposes a DP-NeRF, a novel clean NeRF framework for\nblurred images, which is constrained with two physical priors. These priors are\nderived from the actual blurring process during image acquisition by the\ncamera. DP-NeRF proposes rigid blurring kernel to impose 3D consistency\nutilizing the physical priors and adaptive weight proposal to refine the color\ncomposition error in consideration of the relationship between depth and blur.\nWe present extensive experimental results for synthetic and real scenes with\ntwo types of blur: camera motion blur and defocus blur. The results demonstrate\nthat DP-NeRF successfully improves the perceptual quality of the constructed\nNeRF ensuring 3D geometric and appearance consistency. We further demonstrate\nthe effectiveness of our model with comprehensive ablation analysis.",
    "descriptor": "",
    "authors": [
      "Dogyoon Lee",
      "Minhyeok Lee",
      "Chajin Shin",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12046"
  },
  {
    "id": "arXiv:2211.12047",
    "title": "Convolutional Neural Generative Coding: Scaling Predictive Coding to  Natural Images",
    "abstract": "In this work, we develop convolutional neural generative coding (Conv-NGC), a\ngeneralization of predictive coding to the case of\nconvolution/deconvolution-based computation. Specifically, we concretely\nimplement a flexible neurobiologically-motivated algorithm that progressively\nrefines latent state maps in order to dynamically form a more accurate internal\nrepresentation/reconstruction model of natural images. The performance of the\nresulting sensory processing system is evaluated on several benchmark datasets\nsuch as Color-MNIST, CIFAR-10, and Street House View Numbers (SVHN). We study\nthe effectiveness of our brain-inspired neural system on the tasks of\nreconstruction and image denoising and find that it is competitive with\nconvolutional auto-encoding systems trained by backpropagation of errors and\nnotably outperforms them with respect to out-of-distribution reconstruction\n(including on the full 90k CINIC-10 test set).",
    "descriptor": "",
    "authors": [
      "Alexander Ororbia",
      "Ankur Mali"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12047"
  },
  {
    "id": "arXiv:2211.12048",
    "title": "Global-Local Aggregation with Deformable Point Sampling for Camouflaged  Object Detection",
    "abstract": "The camouflaged object detection (COD) task aims to find and segment objects\nthat have a color or texture that is very similar to that of the background.\nDespite the difficulties of the task, COD is attracting attention in medical,\nlifesaving, and anti-military fields. To overcome the difficulties of COD, we\npropose a novel global-local aggregation architecture with a deformable point\nsampling method. Further, we propose a global-local aggregation transformer\nthat integrates an object's global information, background, and boundary local\ninformation, which is important in COD tasks. The proposed transformer obtains\nglobal information from feature channels and effectively extracts important\nlocal information from the subdivided patch using the deformable point sampling\nmethod. Accordingly, the model effectively integrates global and local\ninformation for camouflaged objects and also shows that important boundary\ninformation in COD can be efficiently utilized. Our method is evaluated on\nthree popular datasets and achieves state-of-the-art performance. We prove the\neffectiveness of the proposed method through comparative experiments.",
    "descriptor": "",
    "authors": [
      "Minhyeok Lee",
      "Suhwan Cho",
      "Chaewon Park",
      "Dogyoon Lee",
      "Jungho Lee",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12048"
  },
  {
    "id": "arXiv:2211.12049",
    "title": "GitFL: Adaptive Asynchronous Federated Learning using Version Control",
    "abstract": "As a promising distributed machine learning paradigm that enables\ncollaborative training without compromising data privacy, Federated Learning\n(FL) has been increasingly used in AIoT (Artificial Intelligence of Things)\ndesign. However, due to the lack of efficient management of straggling devices,\nexisting FL methods greatly suffer from the problems of low inference accuracy\nand long training time. Things become even worse when taking various uncertain\nfactors (e.g., network delays, performance variances caused by process\nvariation) existing in AIoT scenarios into account. To address this issue, this\npaper proposes a novel asynchronous FL framework named GitFL, whose\nimplementation is inspired by the famous version control system Git. Unlike\ntraditional FL, the cloud server of GitFL maintains a master model (i.e., the\nglobal model) together with a set of branch models indicating the trained local\nmodels committed by selected devices, where the master model is updated based\non both all the pushed branch models and their version information, and only\nthe branch models after the pull operation are dispatched to devices. By using\nour proposed Reinforcement Learning (RL)-based device selection mechanism, a\npulled branch model with an older version will be more likely to be dispatched\nto a faster and less frequently selected device for the next round of local\ntraining. In this way, GitFL enables both effective control of model staleness\nand adaptive load balance of versioned models among straggling devices, thus\navoiding the performance deterioration. Comprehensive experimental results on\nwell-known models and datasets show that, compared with state-of-the-art\nasynchronous FL methods, GitFL can achieve up to 2.64X training acceleration\nand 7.88% inference accuracy improvements in various uncertain scenarios.",
    "descriptor": "",
    "authors": [
      "Ming Hu",
      "Zeke Xia",
      "Zhihao Yue",
      "Jun Xia",
      "Yihao Huang",
      "Yang Liu",
      "Mingsong Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12049"
  },
  {
    "id": "arXiv:2211.12050",
    "title": "Modeling Resources in Permissionless Longest-chain Total-order Broadcast",
    "abstract": "Blockchain protocols implement total-order broadcast in a permissionless\nsetting, where processes can freely join and leave. In such a setting, to\nsafeguard against Sybil attacks, correct processes rely on cryptographic proofs\ntied to a particular type of resource to make them eligible to order\ntransactions. For example, in the case of Proof-of-Work (PoW), this resource is\ncomputation, and the proof is a solution to a computationally hard puzzle.\nConversely, in Proof-of-Stake (PoS), the resource corresponds to the number of\ncoins that every process in the system owns, and a secure lottery selects a\nprocess for participation proportionally to its coin holdings.\nAlthough many resource-based blockchain protocols are formally proven secure\nin the literature, the existing security proofs fail to demonstrate why\nparticular types of resources cause the blockchain protocols to be vulnerable\nto distinct classes of attacks. For instance, PoS systems are more vulnerable\nto long-range attacks, where an adversary corrupts past processes to re-write\nthe history, than Proof-of-Work and Proof-of-Storage systems.\nProof-of-Storage-based and Proof-of-Stake-based protocols are both more\nsusceptible to private double-spending attacks than Proof-of-Work-based\nprotocols; in this case, an adversary mines its chain in secret without sharing\nits blocks with the rest of the processes until the end of the attack.\nIn this paper, we formally characterize the properties of resources through\nan abstraction called resource allocator and give a framework for understanding\nlongest-chain consensus protocols based on different underlying resources. In\naddition, we use this resource allocator to demonstrate security trade-offs\nbetween various resources focusing on well-known attacks (e.g., the long-range\nattack and nothing-at-stake attacks).",
    "descriptor": "",
    "authors": [
      "Sarah Azouvi",
      "Christian Cachin",
      "Duc V. Le",
      "Marko Vukolic",
      "Luca Zanolini"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.12050"
  },
  {
    "id": "arXiv:2211.12051",
    "title": "Adaptive Dynamic Filtering Network for Image Denoising",
    "abstract": "In image denoising networks, feature scaling is widely used to enlarge the\nreceptive field size and reduce computational costs. This practice, however,\nalso leads to the loss of high-frequency information and fails to consider\nwithin-scale characteristics. Recently, dynamic convolution has exhibited\npowerful capabilities in processing high-frequency information (e.g., edges,\ncorners, textures), but previous works lack sufficient spatial contextual\ninformation in filter generation. To alleviate these issues, we propose to\nemploy dynamic convolution to improve the learning of high-frequency and\nmulti-scale features. Specifically, we design a spatially enhanced kernel\ngeneration (SEKG) module to improve dynamic convolution, enabling the learning\nof spatial context information with a very low computational complexity. Based\non the SEKG module, we propose a dynamic convolution block (DCB) and a\nmulti-scale dynamic convolution block (MDCB). The former enhances the\nhigh-frequency information via dynamic convolution and preserves low-frequency\ninformation via skip connections. The latter utilizes shared adaptive dynamic\nkernels and the idea of dilated convolution to achieve efficient multi-scale\nfeature extraction. The proposed multi-dimension feature integration (MFI)\nmechanism further fuses the multi-scale features, providing precise and\ncontextually enriched feature representations. Finally, we build an efficient\ndenoising network with the proposed DCB and MDCB, named ADFNet. It achieves\nbetter performance with low computational complexity on real-world and\nsynthetic Gaussian noisy datasets. The source code is available at\nhttps://github.com/it-hao/ADFNet.",
    "descriptor": "\nComments: 9 pages, Accepted in AAAI Conference on Artificial Intelligence (AAAI) 2023\n",
    "authors": [
      "Hao Shen",
      "Zhong-Qiu Zhao",
      "Wandi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12051"
  },
  {
    "id": "arXiv:2211.12054",
    "title": "Visually Grounded Commonsense Knowledge Acquisition",
    "abstract": "Large-scale commonsense knowledge bases empower a broad range of AI\napplications, where the automatic extraction of commonsense knowledge (CKE) is\na fundamental and challenging problem. CKE from text is known for suffering\nfrom the inherent sparsity and reporting bias of commonsense in text. Visual\nperception, on the other hand, contains rich commonsense knowledge about\nreal-world entities, e.g., (person, can_hold, bottle), which can serve as\npromising sources for acquiring grounded commonsense knowledge. In this work,\nwe present CLEVER, which formulates CKE as a distantly supervised\nmulti-instance learning problem, where models learn to summarize commonsense\nrelations from a bag of images about an entity pair without any human\nannotation on image instances. To address the problem, CLEVER leverages\nvision-language pre-training models for deep understanding of each image in the\nbag, and selects informative instances from the bag to summarize commonsense\nentity relations via a novel contrastive attention mechanism. Comprehensive\nexperimental results in held-out and human evaluation show that CLEVER can\nextract commonsense knowledge in promising quality, outperforming pre-trained\nlanguage model-based methods by 3.9 AUC and 6.4 mAUC points. The predicted\ncommonsense scores show strong correlation with human judgment with a 0.78\nSpearman coefficient. Moreover, the extracted commonsense can also be grounded\ninto images with reasonable interpretability. The data and codes can be\nobtained at https://github.com/thunlp/CLEVER.",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Yuan Yao",
      "Tianyu Yu",
      "Ao Zhang",
      "Mengdi Li",
      "Ruobing Xie",
      "Cornelius Weber",
      "Zhiyuan Liu",
      "Haitao Zheng",
      "Stefan Wermter",
      "Tat-Seng Chua",
      "Maosong Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.12054"
  },
  {
    "id": "arXiv:2211.12063",
    "title": "Generalized Private Selection and Testing with High Confidence",
    "abstract": "Composition theorems are general and powerful tools that facilitate privacy\naccounting across multiple data accesses from per-access privacy bounds.\nHowever they often result in weaker bounds compared with end-to-end analysis.\nTwo popular tools that mitigate that are the exponential mechanism (or report\nnoisy max) and the sparse vector technique, generalized in a recent private\nselection framework by Liu and Talwar (STOC 2019). In this work, we propose a\nflexible framework of private selection and testing that generalizes the one\nproposed by Liu and Talwar, supporting a wide range of applications. We apply\nour framework to solve several fundamental tasks, including query releasing,\ntop-$k$ selection, and stable selection, with improved confidence-accuracy\ntradeoffs. Additionally, for online settings, we apply our private testing to\ndesign a mechanism for adaptive query releasing, which improves the sample\ncomplexity dependence on the confidence parameter for the celebrated private\nmultiplicative weights algorithm of Hardt and Rothblum (FOCS 2010).",
    "descriptor": "\nComments: Appearing in ITCS 2023\n",
    "authors": [
      "Edith Cohen",
      "Xin Lyu",
      "Jelani Nelson",
      "Tam\u00e1s Sarl\u00f3s",
      "Uri Stemmer"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.12063"
  },
  {
    "id": "arXiv:2211.12070",
    "title": "Adaptive Observers for MIMO Discrete-Time LTI Systems",
    "abstract": "In this paper, an adaptive observer is proposed for multi-input multi-output\n(MIMO) discrete-time linear time-invariant (LTI) systems. Unlike existing MIMO\nadaptive observer designs, the proposed approach is applicable to LTI systems\nin their general form. Further, the proposed method uses recursive least square\n(RLS) with covariance resetting for adaptation that is shown to guarantee that\nthe estimates are bounded, irrespective of any excitation condition, even in\nthe presence of a vanishing perturbation term in the error used for updation in\nRLS. Detailed analysis for convergence and boundedness has been provided along\nwith simulation results for illustrating the performance of the developed\ntheory.",
    "descriptor": "\nComments: 6 pages, 5 figures\n",
    "authors": [
      "Anchita Dey",
      "Shubhendu Bhasin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.12070"
  },
  {
    "id": "arXiv:2211.12072",
    "title": "Design and Performance Analysis of Hardware Realization of 3GPP Physical  Layer for 5G Cell Search",
    "abstract": "5G Cell Search (CS) is the first step for user equipment (UE) to initiate the\ncommunication with the 5G node B (gNB) every time it is powered ON. In cellular\nnetworks, CS is accomplished via synchronization signals (SS) broadcasted by\ngNB. 5G 3rd generation partnership project (3GPP) specifications offer a\ndetailed discussion on the SS generation at gNB but a limited understanding of\ntheir blind search, and detection is available. Unlike 4G, 5G SS may not be\ntransmitted at the center of carrier frequency and their frequency location is\nunknown to UE. In this work, we demonstrate the 5G CS by designing 3GPP\ncompatible hardware realization of the physical layer (PHY) of the gNB\ntransmitter and UE receiver. The proposed SS detection explores a novel\ndown-sampling approach resulting in a significant reduction in complexity and\nlatency. Via detailed performance analysis, we analyze the functional\ncorrectness, computational complexity, and latency of the proposed approach for\ndifferent word lengths, signal-to-noise ratio (SNR), and down-sampling factors.\nWe demonstrate the complete CS functionality on GNU Radio-based RFNoC framework\nand USRP-FPGA platform. The 3GPP compatibility and demonstration on hardware\nstrengthen the commercial significance of the proposed work.",
    "descriptor": "",
    "authors": [
      "Khalid Lodhi",
      "Jayant Chhillar",
      "Sumit J. Darak",
      "Divisha Sharma"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.12072"
  },
  {
    "id": "arXiv:2211.12075",
    "title": "Greedy based Value Representation for Optimal Coordination in  Multi-agent Reinforcement Learning",
    "abstract": "Due to the representation limitation of the joint Q value function,\nmulti-agent reinforcement learning methods with linear value decomposition\n(LVD) or monotonic value decomposition (MVD) suffer from relative\novergeneralization. As a result, they can not ensure optimal consistency (i.e.,\nthe correspondence between individual greedy actions and the maximal true Q\nvalue). In this paper, we derive the expression of the joint Q value function\nof LVD and MVD. According to the expression, we draw a transition diagram,\nwhere each self-transition node (STN) is a possible convergence. To ensure\noptimal consistency, the optimal node is required to be the unique STN.\nTherefore, we propose the greedy-based value representation (GVR), which turns\nthe optimal node into an STN via inferior target shaping and further eliminates\nthe non-optimal STNs via superior experience replay. In addition, GVR achieves\nan adaptive trade-off between optimality and stability. Our method outperforms\nstate-of-the-art baselines in experiments on various benchmarks. Theoretical\nproofs and empirical results on matrix games demonstrate that GVR ensures\noptimal consistency under sufficient exploration.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2112.04454\n",
    "authors": [
      "Lipeng Wan",
      "Zeyang Liu",
      "Xingyu Chen",
      "Xuguang Lan",
      "Nanning Zheng"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12075"
  },
  {
    "id": "arXiv:2211.12076",
    "title": "Leveraging Reinforcement Learning for Task Resource Allocation in  Scientific Workflows",
    "abstract": "Scientific workflows are designed as directed acyclic graphs (DAGs) and\nconsist of multiple dependent task definitions. They are executed over a large\namount of data, often resulting in thousands of tasks with heterogeneous\ncompute requirements and long runtimes, even on cluster infrastructures. In\norder to optimize the workflow performance, enough resources, e.g., CPU and\nmemory, need to be provisioned for the respective tasks. Typically, workflow\nsystems rely on user resource estimates which are known to be highly\nerror-prone and can result in over- or underprovisioning. While resource\noverprovisioning leads to high resource wastage, underprovisioning can result\nin long runtimes or even failed tasks.\nIn this paper, we propose two different reinforcement learning approaches\nbased on gradient bandits and Q-learning, respectively, in order to minimize\nresource wastage by selecting suitable CPU and memory allocations. We provide a\nprototypical implementation in the well-known scientific workflow management\nsystem Nextflow, evaluate our approaches with five workflows, and compare them\nagainst the default resource configurations and a state-of-the-art feedback\nloop baseline. The evaluation yields that our reinforcement learning approaches\nsignificantly reduce resource wastage compared to the default configuration.\nFurther, our approaches also reduce the allocated CPU hours compared to the\nstate-of-the-art feedback loop by 6.79% and 24.53%.",
    "descriptor": "\nComments: Paper accepted in 2022 IEEE International Conference on Big Data Workshop BPOD 2022\n",
    "authors": [
      "Jonathan Bader",
      "Nicolas Zunker",
      "Soeren Becker",
      "Odej Kao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.12076"
  },
  {
    "id": "arXiv:2211.12077",
    "title": "Design of an Autonomous Agriculture Robot for Real Time Weed Detection  using CNN",
    "abstract": "Agriculture has always remained an integral part of the world. As the human\npopulation keeps on rising, the demand for food also increases, and so is the\ndependency on the agriculture industry. But in today's scenario, because of low\nyield, less rainfall, etc., a dearth of manpower is created in this\nagricultural sector, and people are moving to live in the cities, and villages\nare becoming more and more urbanized. On the other hand, the field of robotics\nhas seen tremendous development in the past few years. The concepts like Deep\nLearning (DL), Artificial Intelligence (AI), and Machine Learning (ML) are\nbeing incorporated with robotics to create autonomous systems for various\nsectors like automotive, agriculture, assembly line management, etc. Deploying\nsuch autonomous systems in the agricultural sector help in many aspects like\nreducing manpower, better yield, and nutritional quality of crops. So, in this\npaper, the system design of an autonomous agricultural robot which primarily\nfocuses on weed detection is described. A modified deep-learning model for the\npurpose of weed detection is also proposed. The primary objective of this robot\nis the detection of weed on a real-time basis without any human involvement,\nbut it can also be extended to design robots in various other applications\ninvolved in farming like weed removal, plowing, harvesting, etc., in turn\nmaking the farming industry more efficient. Source code and other details can\nbe found at https://github.com/Dhruv2012/Autonomous-Farm-Robot",
    "descriptor": "\nComments: Published at the AVES 2021 conference. Source code and other details can be found at this https URL\n",
    "authors": [
      "Dhruv Patel",
      "Meet Gandhi",
      "Shankaranarayanan H.",
      "Anand D. Darji"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.12077"
  },
  {
    "id": "arXiv:2211.12080",
    "title": "OR-Gate: A Noisy Label Filtering Method for Speaker Verification",
    "abstract": "The deep learning models used for speaker verification are heavily dependent\non large-scale data and correct labels. However, noisy (wrong) labels often\noccur, which deteriorates the system's performance. Unfortunately, there are\nrelatively few studies in this area. In this paper, we propose a method to\ngradually filter noisy labels out at the training stage. We compare the network\npredictions at different training epochs with ground-truth labels, and select\nreliable (considered correct) labels by using the OR gate mechanism like that\nin logic circuits. Therefore, our proposed method is named as OR-Gate. We\nexperimentally demonstrated that the OR-Gate can effectively filter noisy\nlabels out and has excellent performance.",
    "descriptor": "\nComments: Submitted to 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP 2023)\n",
    "authors": [
      "Zhihua Fang",
      "Hanhan Ma",
      "Lin Li",
      "Liang He"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.12080"
  },
  {
    "id": "arXiv:2211.12081",
    "title": "CDDSA: Contrastive Domain Disentanglement and Style Augmentation for  Generalizable Medical Image Segmentation",
    "abstract": "Generalization to previously unseen images with potential domain shifts and\ndifferent styles is essential for clinically applicable medical image\nsegmentation, and the ability to disentangle domain-specific and\ndomain-invariant features is key for achieving Domain Generalization (DG).\nHowever, existing DG methods can hardly achieve effective disentanglement to\nget high generalizability. To deal with this problem, we propose an efficient\nContrastive Domain Disentanglement and Style Augmentation (CDDSA) framework for\ngeneralizable medical image segmentation. First, a disentangle network is\nproposed to decompose an image into a domain-invariant anatomical\nrepresentation and a domain-specific style code, where the former is sent to a\nsegmentation model that is not affected by the domain shift, and the\ndisentangle network is regularized by a decoder that combines the anatomical\nand style codes to reconstruct the input image. Second, to achieve better\ndisentanglement, a contrastive loss is proposed to encourage the style codes\nfrom the same domain and different domains to be compact and divergent,\nrespectively. Thirdly, to further improve generalizability, we propose a style\naugmentation method based on the disentanglement representation to synthesize\nimages in various unseen styles with shared anatomical structures. Our method\nwas validated on a public multi-site fundus image dataset for optic cup and\ndisc segmentation and an in-house multi-site Nasopharyngeal Carcinoma Magnetic\nResonance Image (NPC-MRI) dataset for nasopharynx Gross Tumor Volume (GTVnx)\nsegmentation. Experimental results showed that the proposed CDDSA achieved\nremarkable generalizability across different domains, and it outperformed\nseveral state-of-the-art methods in domain-generalizable segmentation.",
    "descriptor": "\nComments: 14 pages, 8 figures\n",
    "authors": [
      "Ran Gu",
      "Guotai Wang",
      "Jiangshan Lu",
      "Jingyang Zhang",
      "Wenhui Lei",
      "Yinan Chen",
      "Wenjun Liao",
      "Shichuan Zhang",
      "Kang Li",
      "Dimitris N. Metaxas",
      "Shaoting Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12081"
  },
  {
    "id": "arXiv:2211.12082",
    "title": "Brain MRI-to-PET Synthesis using 3D Convolutional Attention Networks",
    "abstract": "Accurate quantification of cerebral blood flow (CBF) is essential for the\ndiagnosis and assessment of a wide range of neurological diseases. Positron\nemission tomography (PET) with radiolabeled water (15O-water) is considered the\ngold-standard for the measurement of CBF in humans. PET imaging, however, is\nnot widely available because of its prohibitive costs and use of short-lived\nradiopharmaceutical tracers that typically require onsite cyclotron production.\nMagnetic resonance imaging (MRI), in contrast, is more readily accessible and\ndoes not involve ionizing radiation. This study presents a convolutional\nencoder-decoder network with attention mechanisms to predict gold-standard\n15O-water PET CBF from multi-sequence MRI scans, thereby eliminating the need\nfor radioactive tracers. Inputs to the prediction model include several\ncommonly used MRI sequences (T1-weighted, T2-FLAIR, and arterial spin\nlabeling). The model was trained and validated using 5-fold cross-validation in\na group of 126 subjects consisting of healthy controls and cerebrovascular\ndisease patients, all of whom underwent simultaneous $15O-water PET/MRI. The\nresults show that such a model can successfully synthesize high-quality PET CBF\nmeasurements (with an average SSIM of 0.924 and PSNR of 38.8 dB) and is more\naccurate compared to concurrent and previous PET synthesis methods. We also\ndemonstrate the clinical significance of the proposed algorithm by evaluating\nthe agreement for identifying the vascular territories with abnormally low CBF.\nSuch methods may enable more widespread and accurate CBF evaluation in larger\ncohorts who cannot undergo PET imaging due to radiation concerns, lack of\naccess, or logistic challenges.",
    "descriptor": "\nComments: 19 pages, 14 figures\n",
    "authors": [
      "Ramy Hussein",
      "David Shin",
      "Moss Zhao",
      "Jia Guo",
      "Guido Davidzon",
      "Michael Moseley",
      "Greg Zaharchuk"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.12082"
  },
  {
    "id": "arXiv:2211.12087",
    "title": "SoK: Inference Attacks and Defenses in Human-Centered Wireless Sensing",
    "abstract": "Human-centered wireless sensing aims to understand the fine-grained\nenvironment and activities of a human using the diverse wireless signals around\nher. The wireless sensing community has demonstrated the superiority of such\ntechniques in many applications such as smart homes, human-computer\ninteractions, and smart cities. Like many other technologies, wireless sensing\nis also a double-edged sword. While the sensed information about a human can be\nused for many good purposes such as enhancing life quality, an adversary can\nalso abuse it to steal private information about the human (e.g., location,\nliving habits, and behavioral biometric characteristics). However, the\nliterature lacks a systematic understanding of the privacy vulnerabilities of\nwireless sensing and the defenses against them.\nIn this work, we aim to bridge this gap. First, we propose a framework to\nsystematize wireless sensing-based inference attacks. Our framework consists of\nthree key steps: deploying a sniffing device, sniffing wireless signals, and\ninferring private information. Our framework can be used to guide the design of\nnew inference attacks since different attacks can instantiate these three steps\ndifferently. Second, we propose a defense-in-depth framework to systematize\ndefenses against such inference attacks. The prevention component of our\nframework aims to prevent inference attacks via obfuscating the wireless\nsignals around a human, while the detection component aims to detect and\nrespond to attacks. Third, based on our attack and defense frameworks, we\nidentify gaps in the existing literature and discuss future research\ndirections.",
    "descriptor": "",
    "authors": [
      "Wei Sun",
      "Tingjun Chen",
      "Neil Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.12087"
  },
  {
    "id": "arXiv:2211.12091",
    "title": "Online Detection Of Supply Chain Network Disruptions Using Sequential  Change-Point Detection for Hawkes Processes",
    "abstract": "In this paper, we attempt to detect an inflection or change-point resulting\nfrom the Covid-19 pandemic on supply chain data received from a large furniture\ncompany. To accomplish this, we utilize a modified CUSUM (Cumulative Sum)\nprocedure on the company's spatial-temporal order data as well as a GLR\n(Generalized Likelihood Ratio) based method. We model the order data using the\nHawkes Process Network, a multi-dimensional self and mutually exciting point\nprocess, by discretizing the spatial data and treating each order as an event\nthat has a corresponding node and time. We apply the methodologies on the\ncompany's most ordered item on a national scale and perform a deep dive into a\nsingle state. Because the item was ordered infrequently in the state compared\nto the nation, this approach allows us to show efficacy upon different degrees\nof data sparsity. Furthermore, it showcases use potential across differing\nlevels of spatial detail.",
    "descriptor": "\nComments: Accepted to AAAI 2023 Workshop on Graphs and more Complex structures for Learning and Reasoning\n",
    "authors": [
      "Khurram Yamin",
      "Haoyun Wang",
      "Benoit Montreuil",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12091"
  },
  {
    "id": "arXiv:2211.12092",
    "title": "Linear Interpolation In Parameter Space is Good Enough for Fine-Tuned  Language Models",
    "abstract": "The simplest way to obtain continuous interpolation between two points in\nhigh dimensional space is to draw a line between them. While previous works\nfocused on the general connectivity between model parameters, we explored\nlinear interpolation for parameters of pre-trained models after fine-tuning.\nSurprisingly, we could perform linear interpolation without a performance drop\nin intermediate points for fine-tuned models. For controllable text generation,\nsuch interpolation could be seen as moving a model towards or against the\ndesired text attribute (e.g., positive sentiment), which could be used as\ngrounds for further methods for controllable text generation without inference\nspeed overhead.",
    "descriptor": "",
    "authors": [
      "Mark Rofin",
      "Nikita Balagansky",
      "Daniil Gavrilov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12092"
  },
  {
    "id": "arXiv:2211.12094",
    "title": "Fast Multiplex Graph Association Rules for Link Prediction",
    "abstract": "Multiplex networks allow us to study a variety of complex systems where nodes\nconnect to each other in multiple ways, for example friend, family, and\nco-worker relations in social networks. Link prediction is the branch of\nnetwork analysis allowing us to forecast the future status of a network: which\nnew connections are the most likely to appear in the future? In multiplex link\nprediction we also ask: of which type? Because this last question is\nunanswerable with classical link prediction, here we investigate the use of\ngraph association rules to inform multiplex link prediction. We derive such\nrules by identifying all frequent patterns in a network via multiplex graph\nmining, and then score each unobserved link's likelihood by finding the\noccurrences of each rule in the original network. Association rules add new\nabilities to multiplex link prediction: to predict new node arrivals, to\nconsider higher order structures with four or more nodes, and to be memory\nefficient. We improve over previous work by creating a framework that is also\nefficient in terms of runtime, which enables an increase in prediction\nperformance. This increase in efficiency allows us to improve a case study on a\nsigned multiplex network, showing how graph association rules can provide\nvaluable insights to extend social balance theory.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2008.08351\n",
    "authors": [
      "Michele Coscia",
      "Christian Borgelt",
      "Michael Szell"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.12094"
  },
  {
    "id": "arXiv:2211.12098",
    "title": "Weak scalability of domain decomposition methods for discrete fracture  networks",
    "abstract": "Discrete Fracture Networks (DFNs) are complex three-dimensional structures\ncharacterized by the intersections of planar polygonal fractures, and are used\nto model flows in fractured media. Despite being suitable for Domain\nDecomposition (DD) techniques, there are relatively few works on the\napplication of DD methods to DFNs. In this manuscript, we present a theoretical\nstudy of Optimized Schwarz Methods (OSMs) applied to DFNs. Interestingly, we\nprove that the OSMs can be weakly scalable (that is, they converge to a given\ntolerance in a number of iterations independent of the number of fractures)\nunder suitable assumptions on the domain decomposition. This contribution fits\nin the renewed interest on the weak scalability of DD methods after recent\nworks showed weak scalability of DD methods for specific geometric\nconfigurations, even without coarse spaces. Despite simplifying assumptions\nwhich may be violated in practice, our analysis provides heuristics to minimize\nthe computational efforts in realistic settings. Finally, we emphasize that the\nmethodology proposed can be straightforwardly generalized to study other\nclassical DD methods applied to DFNs.",
    "descriptor": "\nComments: 9 pages, submitted to DDXXVII Proceedings\n",
    "authors": [
      "Stefano Berrone",
      "Tommaso Vanzan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.12098"
  },
  {
    "id": "arXiv:2211.12100",
    "title": "Simulating Human Gaze with Neural Visual Attention",
    "abstract": "Existing models of human visual attention are generally unable to incorporate\ndirect task guidance and therefore cannot model an intent or goal when\nexploring a scene. To integrate guidance of any downstream visual task into\nattention modeling, we propose the Neural Visual Attention (NeVA) algorithm. To\nthis end, we impose to neural networks the biological constraint of foveated\nvision and train an attention mechanism to generate visual explorations that\nmaximize the performance with respect to the downstream task. We observe that\nbiologically constrained neural networks generate human-like scanpaths without\nbeing trained for this objective. Extensive experiments on three common\nbenchmark datasets show that our method outperforms state-of-the-art\nunsupervised human attention models in generating human-like scanpaths.",
    "descriptor": "",
    "authors": [
      "Leo Schwinn",
      "Doina Precup",
      "Bjoern Eskofier",
      "Dario Zanca"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12100"
  },
  {
    "id": "arXiv:2211.12101",
    "title": "Efficient Sampling Algorithms for Approximate Motif Counting in Temporal  Graph Streams",
    "abstract": "A great variety of complex systems, from user interactions in communication\nnetworks to transactions in financial markets, can be modeled as temporal\ngraphs consisting of a set of vertices and a series of timestamped and directed\nedges. Temporal motifs are generalized from subgraph patterns in static graphs\nwhich consider edge orderings and durations in addition to topologies. Counting\nthe number of occurrences of temporal motifs is a fundamental problem for\ntemporal network analysis. However, existing methods either cannot support\ntemporal motifs or suffer from performance issues. Moreover, they cannot work\nin the streaming model where edges are observed incrementally over time. In\nthis paper, we focus on approximate temporal motif counting via random\nsampling. We first propose two sampling algorithms for temporal motif counting\nin the offline setting. The first is an edge sampling (ES) algorithm for\nestimating the number of instances of any temporal motif. The second is an\nimproved edge-wedge sampling (EWS) algorithm that hybridizes edge sampling with\nwedge sampling for counting temporal motifs with $3$ vertices and $3$ edges.\nFurthermore, we propose two algorithms to count temporal motifs incrementally\nin temporal graph streams by extending the ES and EWS algorithms referred to as\nSES and SEWS. We provide comprehensive analyses of the theoretical bounds and\ncomplexities of our proposed algorithms. Finally, we perform extensive\nexperimental evaluations of our proposed algorithms on several real-world\ntemporal graphs. The results show that ES and EWS have higher efficiency,\nbetter accuracy, and greater scalability than state-of-the-art sampling methods\nfor temporal motif counting in the offline setting. Moreover, SES and SEWS\nachieve up to three orders of magnitude speedups over ES and EWS while having\ncomparable estimation errors for temporal motif counting in the streaming\nsetting.",
    "descriptor": "\nComments: 27 pages, 11 figures; overlapped with arXiv:2007.14028\n",
    "authors": [
      "Jingjing Wang",
      "Yanhao Wang",
      "Wenjun Jiang",
      "Yuchen Li",
      "Kian-Lee Tan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.12101"
  },
  {
    "id": "arXiv:2211.12104",
    "title": "Energy Consumption of Automated Program Repair",
    "abstract": "Automated program repair (APR) aims to automatize the process of repairing\nsoftware bugs in order to reduce the cost of maintaining software programs.\nMoreover, the success (given by the accuracy metric) of APR approaches has been\nincreasing in recent years. However, no previous work has considered the energy\nimpact of repairing bugs automatically using APR. The field of green software\nresearch aims to measure the energy consumption required to develop, maintain\nand use software products. This paper combines, for the first time, the APR and\nGreen software research fields. We have as main goal to define the foundation\nfor measuring the energy consumption of the APR activity. For that, we present\na set of metrics specially crafted to measure the energy consumption of APR\ntools and a generic methodology to calculate them. We instantiate the\nmethodology in the context of Java program repair. We measure the energy\nconsumption of 10 program repair tools trying to repair real bugs from\nDefects4J, a set of real buggy programs. The initial results from this\nexperiment show the existing trade-off between energy consumption and the\nability to correctly repair bugs: Some APR tools are capable of achieving\nhigher accuracy by spending less energy than other tools.",
    "descriptor": "",
    "authors": [
      "Matias Martinez",
      "Silverio Mart\u00ednez-Fern\u00e1ndez",
      "Xavier Franch"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.12104"
  },
  {
    "id": "arXiv:2211.12105",
    "title": "AdaptDHM: Adaptive Distribution Hierarchical Model for Multi-Domain CTR  Prediction",
    "abstract": "Large-scale commercial platforms usually involve numerous business domains\nfor diverse business strategies and expect their recommendation systems to\nprovide click-through rate (CTR) predictions for multiple domains\nsimultaneously. Existing promising and widely-used multi-domain models discover\ndomain relationships by explicitly constructing domain-specific networks, but\nthe computation and memory boost significantly with the increase of domains. To\nreduce computational complexity, manually grouping domains with particular\nbusiness strategies is common in industrial applications. However, this\npre-defined data partitioning way heavily relies on prior knowledge, and it may\nneglect the underlying data distribution of each domain, hence limiting the\nmodel's representation capability. Regarding the above issues, we propose an\nelegant and flexible multi-distribution modeling paradigm, named Adaptive\nDistribution Hierarchical Model (AdaptDHM), which is an end-to-end optimization\nhierarchical structure consisting of a clustering process and classification\nprocess. Specifically, we design a distribution adaptation module with a\ncustomized dynamic routing mechanism. Instead of introducing prior knowledge\nfor pre-defined data allocation, this routing algorithm adaptively provides a\ndistribution coefficient for each sample to determine which cluster it belongs\nto. Each cluster corresponds to a particular distribution so that the model can\nsufficiently capture the commonalities and distinctions between these distinct\nclusters. Extensive experiments on both public and large-scale Alibaba\nindustrial datasets verify the effectiveness and efficiency of AdaptDHM: Our\nmodel achieves impressive prediction accuracy and its time cost during the\ntraining stage is more than 50% less than that of other models.",
    "descriptor": "",
    "authors": [
      "Jinyun Li",
      "Huiwen Zheng",
      "Yuanlin Liu",
      "Minfang Lu",
      "Lixia Wu",
      "Haoyuan Hu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12105"
  },
  {
    "id": "arXiv:2211.12108",
    "title": "Explaining YOLO: Leveraging Grad-CAM to Explain Object Detections",
    "abstract": "We investigate the problem of explainability for visual object detectors.\nSpecifically, we demonstrate on the example of the YOLO object detector how to\nintegrate Grad-CAM into the model architecture and analyze the results. We show\nhow to compute attribution-based explanations for individual detections and\nfind that the normalization of the results has a great impact on their\ninterpretation.",
    "descriptor": "",
    "authors": [
      "Armin Kirchknopf",
      "Djordje Slijepcevic",
      "Ilkay Wunderlich",
      "Michael Breiter",
      "Johannes Traxler",
      "Matthias Zeppelzauer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12108"
  },
  {
    "id": "arXiv:2211.12109",
    "title": "Video compression dataset and benchmark of learning-based video-quality  metrics",
    "abstract": "Video-quality measurement is a critical task in video processing. Nowadays,\nmany implementations of new encoding standards - such as AV1, VVC, and LCEVC -\nuse deep-learning-based decoding algorithms with perceptual metrics that serve\nas optimization objectives. But investigations of the performance of modern\nvideo- and image-quality metrics commonly employ videos compressed using older\nstandards, such as AVC. In this paper, we present a new benchmark for\nvideo-quality metrics that evaluates video compression. It is based on a new\ndataset consisting of about 2,500 streams encoded using different standards,\nincluding AVC, HEVC, AV1, VP9, and VVC. Subjective scores were collected using\ncrowdsourced pairwise comparisons. The list of evaluated metrics includes\nrecent ones based on machine learning and neural networks. The results\ndemonstrate that new no-reference metrics exhibit a high correlation with\nsubjective quality and approach the capability of top full-reference metrics.",
    "descriptor": "\nComments: 10 pages, 4 figures, 6 tables, 1 supplementary material\n",
    "authors": [
      "Anastasia Antsiferova",
      "Sergey Lavrushkin",
      "Maksim Smirnov",
      "Alexander Gushchin",
      "Dmitriy Vatolin",
      "Dmitriy Kulikov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.12109"
  },
  {
    "id": "arXiv:2211.12110",
    "title": "Improving Crowded Object Detection via Copy-Paste",
    "abstract": "Crowdedness caused by overlapping among similar objects is a ubiquitous\nchallenge in the field of 2D visual object detection. In this paper, we first\nunderline two main effects of the crowdedness issue: 1) IoU-confidence\ncorrelation disturbances (ICD) and 2) confused de-duplication (CDD). Then we\nexplore a pathway of cracking these nuts from the perspective of data\naugmentation. Primarily, a particular copy-paste scheme is proposed towards\nmaking crowded scenes. Based on this operation, we first design a \"consensus\nlearning\" method to further resist the ICD problem and then find out the\npasting process naturally reveals a pseudo \"depth\" of object in the scene,\nwhich can be potentially used for alleviating CDD dilemma. Both methods are\nderived from magical using of the copy-pasting without extra cost for\nhand-labeling. Experiments show that our approach can easily improve the\nstate-of-the-art detector in typical crowded detection task by more than 2%\nwithout any bells and whistles. Moreover, this work can outperform existing\ndata augmentation strategies in crowded scenario.",
    "descriptor": "\nComments: Accepted by AAAI2023\n",
    "authors": [
      "Jiangfan Deng",
      "Dewen Fan",
      "Xiaosong Qiu",
      "Feng Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12110"
  },
  {
    "id": "arXiv:2211.12111",
    "title": "Evaluation of MPC-based Imitation Learning for Human-like Autonomous  Driving",
    "abstract": "This work evaluates and analyzes the combination of imitation learning (IL)\nand differentiable model predictive control (MPC) for the application of\nhuman-like autonomous driving. We combine MPC with a hierarchical\nlearning-based policy, and measure its performance in open-loop and closed-loop\nwith metrics related to safety, comfort and similarity to human driving\ncharacteristics. We also demonstrate the value of augmenting open-loop\nbehavioral cloning with closed-loop training for a more robust learning,\napproximating the policy gradient through time with the state space model used\nby the MPC. We perform experimental evaluations on a lane keeping control\nsystem, learned from demonstrations collected on a fixed-base driving\nsimulator, and show that our imitative policies approach the human driving\nstyle preferences.",
    "descriptor": "\nComments: This work has been submitted to IFAC for possible publication. arXiv admin note: text overlap with arXiv:2206.12348\n",
    "authors": [
      "Flavia Sofia Acerbo",
      "Jan Swevers",
      "Tinne Tuytelaars",
      "Tong Duy Son"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.12111"
  },
  {
    "id": "arXiv:2211.12112",
    "title": "Human Evaluation of Text-to-Image Models on a Multi-Task Benchmark",
    "abstract": "We provide a new multi-task benchmark for evaluating text-to-image models. We\nperform a human evaluation comparing the most common open-source (Stable\nDiffusion) and commercial (DALL-E 2) models. Twenty computer science AI\ngraduate students evaluated the two models, on three tasks, at three difficulty\nlevels, across ten prompts each, providing 3,600 ratings. Text-to-image\ngeneration has seen rapid progress to the point that many recent models have\ndemonstrated their ability to create realistic high-resolution images for\nvarious prompts. However, current text-to-image methods and the broader body of\nresearch in vision-language understanding still struggle with intricate text\nprompts that contain many objects with multiple attributes and relationships.\nWe introduce a new text-to-image benchmark that contains a suite of thirty-two\ntasks over multiple applications that capture a model's ability to handle\ndifferent features of a text prompt. For example, asking a model to generate a\nvarying number of the same object to measure its ability to count or providing\na text prompt with several objects that each have a different attribute to\nidentify its ability to match objects and attributes correctly. Rather than\nsubjectively evaluating text-to-image results on a set of prompts, our new\nmulti-task benchmark consists of challenge tasks at three difficulty levels\n(easy, medium, and hard) and human ratings for each generated image.",
    "descriptor": "\nComments: NeurIPS 2022 Workshop on Human Evaluation of Generative Models (HEGM)\n",
    "authors": [
      "Vitali Petsiuk",
      "Alexander E. Siemenn",
      "Saisamrit Surbehera",
      "Zad Chin",
      "Keith Tyser",
      "Gregory Hunter",
      "Arvind Raghavan",
      "Yann Hicke",
      "Bryan A. Plummer",
      "Ori Kerret",
      "Tonio Buonassisi",
      "Kate Saenko",
      "Armando Solar-Lezama",
      "Iddo Drori"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12112"
  },
  {
    "id": "arXiv:2211.12117",
    "title": "Flow Guidance Deformable Compensation Network for Video Frame  Interpolation",
    "abstract": "Motion-based video frame interpolation (VFI) methods have made remarkable\nprogress with the development of deep convolutional networks over the past\nyears. While their performance is often jeopardized by the inaccuracy of flow\nmap estimation, especially in the case of large motion and occlusion. In this\npaper, we propose a flow guidance deformable compensation network (FGDCN) to\novercome the drawbacks of existing motion-based methods. FGDCN decomposes the\nframe sampling process into two steps: a flow step and a deformation step.\nSpecifically, the flow step utilizes a coarse-to-fine flow estimation network\nto directly estimate the intermediate flows and synthesizes an anchor frame\nsimultaneously. To ensure the accuracy of the estimated flow, a distillation\nloss and a task-oriented loss are jointly employed in this step. Under the\nguidance of the flow priors learned in step one, the deformation step designs a\npyramid deformable compensation network to compensate for the missing details\nof the flow step. In addition, a pyramid loss is proposed to supervise the\nmodel in both the image and frequency domain. Experimental results show that\nthe proposed algorithm achieves excellent performance on various datasets with\nfewer parameters.",
    "descriptor": "",
    "authors": [
      "Pengcheng Lei",
      "Faming Fang",
      "Guixu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12117"
  },
  {
    "id": "arXiv:2211.12118",
    "title": "HaRiM$^+$: Evaluating Summary Quality with Hallucination Risk",
    "abstract": "One of the challenges of developing a summarization model arises from the\ndifficulty in measuring the factual inconsistency of the generated text. In\nthis study, we reinterpret the decoder overconfidence-regularizing objective\nsuggested in (Miao et al., 2021) as a hallucination risk measurement to better\nestimate the quality of generated summaries. We propose a reference-free\nmetric, HaRiM+, which only requires an off-the-shelf summarization model to\ncompute the hallucination risk based on token likelihoods. Deploying it\nrequires no additional training of models or ad-hoc modules, which usually need\nalignment to human judgments. For summary-quality estimation, HaRiM+ records\nstate-of-the-art correlation to human judgment on three summary-quality\nannotation sets: FRANK, QAGS, and SummEval. We hope that our work, which merits\nthe use of summarization models, facilitates the progress of both automated\nevaluation and generation of summary.",
    "descriptor": "\nComments: 9 pages (+ 21 pages of Appendix), AACL 2022\n",
    "authors": [
      "Seonil Son",
      "Junsoo Park",
      "Jeong-in Hwang",
      "Junghwa Lee",
      "Hyungjong Noh",
      "Yeonsoo Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.12118"
  },
  {
    "id": "arXiv:2211.12123",
    "title": "Unsupervised Domain Adaptation GAN Inversion for Image Editing",
    "abstract": "Existing GAN inversion methods work brilliantly for high-quality image\nreconstruction and editing while struggling with finding the corresponding\nhigh-quality images for low-quality inputs. Therefore, recent works are\ndirected toward leveraging the supervision of paired high-quality and\nlow-quality images for inversion. However, these methods are infeasible in\nreal-world scenarios and further hinder performance improvement. In this paper,\nwe resolve this problem by introducing Unsupervised Domain Adaptation (UDA)\ninto the Inversion process, namely UDA-Inversion, for both high-quality and\nlow-quality image inversion and editing. Particularly, UDA-Inversion first\nregards the high-quality and low-quality images as the source domain and\nunlabeled target domain, respectively. Then, a discrepancy function is\npresented to measure the difference between two domains, after which we\nminimize the source error and the discrepancy between the distributions of two\ndomains in the latent space to obtain accurate latent codes for low-quality\nimages. Without direct supervision, constructive representations of\nhigh-quality images can be spontaneously learned and transformed into\nlow-quality images based on unsupervised domain adaptation. Experimental\nresults indicate that UDA-inversion is the first that achieves a comparable\nlevel of performance with supervised methods in low-quality images across\nmultiple domain datasets. We hope this work provides a unique inspiration for\nlatent embedding distributions in image process tasks.",
    "descriptor": "",
    "authors": [
      "Siyu Xing",
      "Chen Gong",
      "Hewei Guo",
      "Xiao-Yu Zhang",
      "Xinwen Hou",
      "Yu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12123"
  },
  {
    "id": "arXiv:2211.12124",
    "title": "A Large-Scale Dataset for Biomedical Keyphrase Generation",
    "abstract": "Keyphrase generation is the task consisting in generating a set of words or\nphrases that highlight the main topics of a document. There are few datasets\nfor keyphrase generation in the biomedical domain and they do not meet the\nexpectations in terms of size for training generative models. In this paper, we\nintroduce kp-biomed, the first large-scale biomedical keyphrase generation\ndataset with more than 5M documents collected from PubMed abstracts. We train\nand release several generative models and conduct a series of experiments\nshowing that using large scale datasets improves significantly the performances\nfor present and absent keyphrase generation. The dataset is available under\nCC-BY-NC v4.0 license at https://huggingface.co/ datasets/taln-ls2n/kpbiomed.",
    "descriptor": "\nComments: Accepted at the 13th International Workshop on Health Text Mining and Information Analysis (LOUHI 2022)\n",
    "authors": [
      "Mael Houbre",
      "Florian Boudin",
      "Beatrice Daille"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.12124"
  },
  {
    "id": "arXiv:2211.12130",
    "title": "Converge to the Truth: Factual Error Correction via Iterative  Constrained Editing",
    "abstract": "Given a possibly false claim sentence, how can we automatically correct it\nwith minimal editing? Existing methods either require a large number of pairs\nof false and corrected claims for supervised training or do not handle well\nerrors spanning over multiple tokens within an utterance. In this paper, we\npropose VENCE, a novel method for factual error correction (FEC) with minimal\nedits. VENCE formulates the FEC problem as iterative sampling editing actions\nwith respect to a target density function. We carefully design the target\nfunction with predicted truthfulness scores from an offline trained fact\nverification model. VENCE samples the most probable editing positions based on\nback-calculated gradients of the truthfulness score concerning input tokens and\nthe editing actions using a distantly-supervised language model (T5).\nExperiments on a public dataset show that VENCE improves the well-adopted SARI\nmetric by 5.3 (or a relative improvement of 11.8%) over the previous best\ndistantly-supervised methods.",
    "descriptor": "\nComments: Accepted to AAAI 2023\n",
    "authors": [
      "Jiangjie Chen",
      "Rui Xu",
      "Wenxuan Zeng",
      "Changzhi Sun",
      "Lei Li",
      "Yanghua Xiao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.12130"
  },
  {
    "id": "arXiv:2211.12131",
    "title": "DiffDreamer: Consistent Single-view Perpetual View Generation with  Conditional Diffusion Models",
    "abstract": "Perpetual view generation -- the task of generating long-range novel views by\nflying into a given image -- has been a novel yet promising task. We introduce\nDiffDreamer, an unsupervised framework capable of synthesizing novel views\ndepicting a long camera trajectory while training solely on internet-collected\nimages of nature scenes. We demonstrate that image-conditioned diffusion models\ncan effectively perform long-range scene extrapolation while preserving both\nlocal and global consistency significantly better than prior GAN-based methods.\nProject page: https://primecai.github.io/diffdreamer .",
    "descriptor": "",
    "authors": [
      "Shengqu Cai",
      "Eric Ryan Chan",
      "Songyou Peng",
      "Mohamad Shahbazi",
      "Anton Obukhov",
      "Luc Van Gool",
      "Gordon Wetzstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12131"
  },
  {
    "id": "arXiv:2211.12135",
    "title": "The End of Digital Humanities and the Future of Manuscript Studies",
    "abstract": "We are standing at the edge of a major transformation in manuscript studies.\nThe proliferation of digital surrogates, Digital Humanities analyses and the\nrise of new scientific analytical technologies, all provide hitherto unknown,\nand unknowable, information. This article looks at how the field can best\nintegrate these transformations. It argues that any separation between Digital\nHumanities, heritage science, and manuscript studies is becoming artificial.\nConcentrating on training programmes for advanced students as a way of\nreimagining the field, it provides concrete advice for the future of manuscript\nstudies.",
    "descriptor": "\nComments: 5 figures to be provided separately\n",
    "authors": [
      "Eyal Poleg"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2211.12135"
  },
  {
    "id": "arXiv:2211.12136",
    "title": "Minimum-Cost Temporal Walks under Waiting-Time Constraints in Linear  Time",
    "abstract": "In a temporal graph, each edge is available at specific points in time. Such\nan availability point is often represented by a ''temporal edge'' that can be\ntraversed from its tail only at a specific departure time, for arriving in its\nhead after a specific travel time. In such a graph, the connectivity from one\nnode to another is naturally captured by the existence of a temporal path where\ntemporal edges can be traversed one after the other. When imposing constraints\non how much time it is possible to wait at a node in-between two temporal\nedges, it then becomes interesting to consider temporal walks where it is\nallowed to visit several times the same node, possibly at different times. We\nstudy the complexity of computing minimum-cost temporal walks from a single\nsource under waiting-time constraints in a temporal graph, and ask under which\nconditions this problem can be solved in linear time. Our main result is a\nlinear time algorithm when temporal edges are provided in input by\nnon-decreasing departure time and also by non-decreasing arrival time. We use\nan algebraic framework for manipulating abstract costs, enabling the\noptimization of a large variety of criteria or even combinations of these. It\nallows to improve previous results for several criteria such as number of edges\nor overall waiting time. This result is somehow optimal: a logarithmic factor\nin the time complexity appears to be necessary if the input contains only one\nordering of the temporal edges (either by arrival times or departure times).",
    "descriptor": "",
    "authors": [
      "Filippo Brunelli",
      "Laurent Viennot"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.12136"
  },
  {
    "id": "arXiv:2211.12137",
    "title": "Implicit Inverse Force Identification Method of Acoustic  Liquid-structure Interaction Finite Element Model",
    "abstract": "The two-field vibroacoustic finite-element (FE) model requires a relatively\nlarge number of degrees of freedom compared to the monophysics model, and the\nconventional force identification method for structural vibration can be\nadjusted for multiphysics problems. In this study, an effective inverse force\nidentification method for an FE vibroacoustic interaction model of an interior\nfluid-structure system was proposed. The method consists of: (1) implicit\ninverse force identification based on the Newmark-$\\beta$ time integration\nalgorithm for stability and efficiency, (2) second-order ordinary differential\nformulation by avoiding the state-space form causing large degrees of freedom,\n(3) projection-based multiphysics reduced-order modeling for further reduction\nof degrees of freedom, and (4) Tikhonov regularization to alleviate the\nmeasurement noise. The proposed method can accurately identify the unmeasured\napplied forces on the in situ application and concurrently reconstruct the\nresponse fields. The accuracy, stability, and computational efficiency of the\nproposed method were evaluated using numerical models and an experimental\ntestbed. A comparative study with the augmented Kalman filter method was\nperformed to evaluate its relative performance.",
    "descriptor": "\nComments: 31 Pages, 20 Figures, 5 Tables\n",
    "authors": [
      "Seungin Oh",
      "Chang-uk Ahn",
      "Kwanghyun Ahn",
      "Jin-Gyun Kim"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.12137"
  },
  {
    "id": "arXiv:2211.12139",
    "title": "Mapping City-Wide Perceptions of Neighbourhood Quality using Street View  Images",
    "abstract": "The interactions of individuals with city neighbourhoods is determined, in\npart, by the perceived quality of urban environments. Perceived neighbourhood\nquality is a core component of urban vitality, influencing social cohesion,\nsense of community, safety, activity and mental health of residents.\nLarge-scale assessment of perceptions of neighbourhood quality was pioneered by\nthe Place Pulse projects. Researchers demonstrated the efficacy of\ncrowd-sourcing perception ratings of image pairs across 56 cities and training\na model to predict perceptions from street-view images. Variation across cities\nmay limit Place Pulse's usefulness for assessing within-city perceptions. In\nthis paper, we set forth a protocol for city-specific dataset collection for\nthe perception: 'On which street would you prefer to walk?'. This paper\ndescribes our methodology, based in London, including collection of images and\nratings, web development, model training and mapping. Assessment of within-city\nperceptions of neighbourhoods can identify inequities, inform planning\npriorities, and identify temporal dynamics. Code available:\nhttps://emilymuller1991.github.io/urban-perceptions/.",
    "descriptor": "",
    "authors": [
      "Emily Muller",
      "Emily Gemmell",
      "Ishmam Choudhury",
      "Ricky Nathvani",
      "Antje Barbara Metzler",
      "James Bennett",
      "Emily Denton",
      "Seth Flaxman",
      "Majid Ezzati"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.12139"
  },
  {
    "id": "arXiv:2211.12141",
    "title": "MGADN: A Multi-task Graph Anomaly Detection Network for Multivariate  Time Series",
    "abstract": "Anomaly detection of time series, especially multivariate time series(time\nseries with multiple sensors), has been focused on for several years. Though\nexisting method has achieved great progress, there are several challenging\nproblems to be solved. Firstly, existing method including neural network only\nconcentrate on the relationship in terms of timestamp. To be exact, they only\nwant to know how does the data in the past influence which in the future.\nHowever, one sensor sometimes intervenes in other sensor such as the speed of\nwind may cause decrease of temperature. Secondly, there exist two categories of\nmodel for time series anomaly detection: prediction model and reconstruction\nmodel. Prediction model is adept at learning timely representation while short\nof capability when faced with sparse anomaly. Conversely, reconstruction model\nis opposite. Therefore, how can we efficiently get the relationship both in\nterms of both timestamp and sensors becomes our main topic. Our approach uses\nGAT, which is originated from graph neural network, to obtain connection\nbetween sensors. And LSTM is used to obtain relationships timely. Our approach\nis also designed to be double headed to calculate both prediction loss and\nreconstruction loss via VAE(Variational Auto-Encoder). In order to take\nadvantage of two sorts of model, multi-task optimization algorithm is used in\nthis model.",
    "descriptor": "",
    "authors": [
      "Weixuan Xiong",
      "Xiaochen Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12141"
  },
  {
    "id": "arXiv:2211.12142",
    "title": "Coreference Resolution through a seq2seq Transition-Based System",
    "abstract": "Most recent coreference resolution systems use search algorithms over\npossible spans to identify mentions and resolve coreference. We instead present\na coreference resolution system that uses a text-to-text (seq2seq) paradigm to\npredict mentions and links jointly. We implement the coreference system as a\ntransition system and use multilingual T5 as an underlying language model. We\nobtain state-of-the-art accuracy on the CoNLL-2012 datasets with 83.3 F1-score\nfor English (a 2.3 higher F1-score than previous work (Dobrovolskii, 2021))\nusing only CoNLL data for training, 68.5 F1-score for Arabic (+4.1 higher than\nprevious work) and 74.3 F1-score for Chinese (+5.3). In addition we use the\nSemEval-2010 data sets for experiments in the zero-shot setting, a few-shot\nsetting, and supervised setting using all available training data. We get\nsubstantially higher zero-shot F1-scores for 3 out of 4 languages than previous\napproaches and significantly exceed previous supervised state-of-the-art\nresults for all five tested languages.",
    "descriptor": "",
    "authors": [
      "Bernd Bohnet",
      "Chris Alberti",
      "Michael Collins"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12142"
  },
  {
    "id": "arXiv:2211.12143",
    "title": "Automated, not Automatic: Needs and Practices in European Fact-checking  Organizations as a basis for Designing Human-centered AI Systems",
    "abstract": "To mitigate the negative effects of false information more effectively, the\ndevelopment of automated AI (artificial intelligence) tools assisting\nfact-checkers is needed. Despite the existing research, there is still a gap\nbetween the fact-checking practitioners' needs and pains and the current AI\nresearch. We aspire to bridge this gap by employing methods of information\nbehavior research to identify implications for designing better human-centered\nAI-based supporting tools.\nIn this study, we conducted semi-structured in-depth interviews with Central\nEuropean fact-checkers. The information behavior and requirements on desired\nsupporting tools were analyzed using iterative bottom-up content analysis,\nbringing the techniques from grounded theory. The most significant needs were\nvalidated with a survey extended to fact-checkers from across Europe, in which\nwe collected 24 responses from 20 European countries, i.e., 62% active European\nIFCN (International Fact-Checking Network) signatories.\nOur contributions are theoretical as well as practical. First, by being able\nto map our findings about the needs of fact-checking organizations to the\nrelevant tasks for AI research, we have shown that the methods of information\nbehavior research are relevant for studying the processes in the organizations\nand that these methods can be used to bridge the gap between the users and AI\nresearchers. Second, we have identified fact-checkers' needs and pains focusing\non so far unexplored dimensions and emphasizing the needs of fact-checkers from\nCentral and Eastern Europe as well as from low-resource language groups which\nhave implications for development of new resources (datasets) as well as for\nthe focus of AI research in this domain.",
    "descriptor": "\nComments: 41 pages, 13 figures, 1 table, 2 annexes\n",
    "authors": [
      "Andrea Hrckova",
      "Robert Moro",
      "Ivan Srba",
      "Jakub Simko",
      "Maria Bielikova"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.12143"
  },
  {
    "id": "arXiv:2211.12145",
    "title": "Uncertainty-aware Vision-based Metric Cross-view Geolocalization",
    "abstract": "This paper proposes a novel method for vision-based metric cross-view\ngeolocalization (CVGL) that matches the camera images captured from a\nground-based vehicle with an aerial image to determine the vehicle's geo-pose.\nSince aerial images are globally available at low cost, they represent a\npotential compromise between two established paradigms of autonomous driving,\ni.e. using expensive high-definition prior maps or relying entirely on the\nsensor data captured at runtime.\nWe present an end-to-end differentiable model that uses the ground and aerial\nimages to predict a probability distribution over possible vehicle poses. We\ncombine multiple vehicle datasets with aerial images from orthophoto providers\non which we demonstrate the feasibility of our method. Since the ground truth\nposes are often inaccurate w.r.t. the aerial images, we implement a\npseudo-label approach to produce more accurate ground truth poses and make them\npublicly available.\nWhile previous works require training data from the target region to achieve\nreasonable localization accuracy (i.e. same-area evaluation), our approach\novercomes this limitation and outperforms previous results even in the strictly\nmore challenging cross-area case. We improve the previous state-of-the-art by a\nlarge margin even without ground or aerial data from the test region, which\nhighlights the model's potential for global-scale application. We further\nintegrate the uncertainty-aware predictions in a tracking framework to\ndetermine the vehicle's trajectory over time resulting in a mean position error\non KITTI-360 of 0.78m.",
    "descriptor": "",
    "authors": [
      "Florian Fervers",
      "Sebastian Bullinger",
      "Christoph Bodensteiner",
      "Michael Arens",
      "Rainer Stiefelhagen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12145"
  },
  {
    "id": "arXiv:2211.12148",
    "title": "Aligning Source Visual and Target Language Domains for Unpaired Video  Captioning",
    "abstract": "Training supervised video captioning model requires coupled video-caption\npairs. However, for many targeted languages, sufficient paired data are not\navailable. To this end, we introduce the unpaired video captioning task aiming\nto train models without coupled video-caption pairs in target language. To\nsolve the task, a natural choice is to employ a two-step pipeline system: first\nutilizing video-to-pivot captioning model to generate captions in pivot\nlanguage and then utilizing pivot-to-target translation model to translate the\npivot captions to the target language. However, in such a pipeline system, 1)\nvisual information cannot reach the translation model, generating visual\nirrelevant target captions; 2) the errors in the generated pivot captions will\nbe propagated to the translation model, resulting in disfluent target captions.\nTo address these problems, we propose the Unpaired Video Captioning with Visual\nInjection system (UVC-VI). UVC-VI first introduces the Visual Injection Module\n(VIM), which aligns source visual and target language domains to inject the\nsource visual information into the target language domain. Meanwhile, VIM\ndirectly connects the encoder of the video-to-pivot model and the decoder of\nthe pivot-to-target model, allowing end-to-end inference by completely skipping\nthe generation of pivot captions. To enhance the cross-modality injection of\nthe VIM, UVC-VI further introduces a pluggable video encoder, i.e., Multimodal\nCollaborative Encoder (MCE). The experiments show that UVC-VI outperforms\npipeline systems and exceeds several supervised systems. Furthermore, equipping\nexisting supervised systems with our MCE can achieve 4% and 7% relative margins\non the CIDEr scores to current state-of-the-art models on the benchmark MSVD\nand MSR-VTT datasets, respectively.",
    "descriptor": "\nComments: Published at IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)\n",
    "authors": [
      "Fenglin Liu",
      "Xian Wu",
      "Chenyu You",
      "Shen Ge",
      "Yuexian Zou",
      "Xu Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12148"
  },
  {
    "id": "arXiv:2211.12150",
    "title": "The transport problem for non-additive measures",
    "abstract": "Non-additive measures, also known as fuzzy measures, capacities, and\nmonotonic games, are increasingly used in different fields. Applications have\nbeen built within computer science and artificial intelligence related to e.g.\ndecision making, image processing, machine learning for both classification,\nand regression. Tools for measure identification have been built. In short, as\nnon-additive measures are more general than additive ones (i.e., than\nprobabilities), they have better modeling capabilities allowing to model\nsituations and problems that cannot be modelled by the latter. See e.g. the\napplication of non-additive measures and the Choquet integral to model both\nEllsberg paradox and Allais paradox.\nBecause of that, there is an increasing need to analyze non-additive\nmeasures. The need for distances and similarities to compare them is no\nexception. Some work has been done for definining $f$-divergence for them. In\nthis work we tackle the problem of definining the transport problem for\nnon-additive measures, which has not been considered up to our knowledge up to\nnow. Distances for pairs of probability distributions based on the optimal\ntransport are extremely used in practical applications, and they are being\nstudied extensively for the mathematical properties. We consider that it is\nnecessary to provide appropriate definitions with a similar flavour, and that\ngeneralize the standard ones, for non-additive measures.\nWe provide definitions based on the M\\\"obius transform, but also based on the\n$(\\max, +)$-transform that we consider that has some advantages. We will\ndiscuss in this paper the problems that arise to define the transport problem\nfor non-additive measures, and discuss ways to solve them. In this paper we\nprovide the definitions of the optimal transport problem, and prove some\nproperties.",
    "descriptor": "",
    "authors": [
      "Vicen\u00e7 Torra"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.12150"
  },
  {
    "id": "arXiv:2211.12151",
    "title": "Reinforcement Causal Structure Learning on Order Graph",
    "abstract": "Learning directed acyclic graph (DAG) that describes the causality of\nobserved data is a very challenging but important task. Due to the limited\nquantity and quality of observed data, and non-identifiability of causal graph,\nit is almost impossible to infer a single precise DAG. Some methods approximate\nthe posterior distribution of DAGs to explore the DAG space via Markov chain\nMonte Carlo (MCMC), but the DAG space is over the nature of super-exponential\ngrowth, accurately characterizing the whole distribution over DAGs is very\nintractable. In this paper, we propose {Reinforcement Causal Structure Learning\non Order Graph} (RCL-OG) that uses order graph instead of MCMC to model\ndifferent DAG topological orderings and to reduce the problem size. RCL-OG\nfirst defines reinforcement learning with a new reward mechanism to approximate\nthe posterior distribution of orderings in an efficacy way, and uses deep\nQ-learning to update and transfer rewards between nodes. Next, it obtains the\nprobability transition model of nodes on order graph, and computes the\nposterior probability of different orderings. In this way, we can sample on\nthis model to obtain the ordering with high probability. Experiments on\nsynthetic and benchmark datasets show that RCL-OG provides accurate posterior\nprobability approximation and achieves better results than competitive causal\ndiscovery algorithms.",
    "descriptor": "\nComments: Accepted by the Thirty-Seventh AAAI Conference on Artificial Intelligence(AAAI2023)\n",
    "authors": [
      "Dezhi Yang",
      "Guoxian Yu",
      "Jun Wang",
      "Zhengtian Wu",
      "Maozu Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.12151"
  },
  {
    "id": "arXiv:2211.12154",
    "title": "Event Causality Identification with Causal News Corpus -- Shared Task 3,  CASE 2022",
    "abstract": "The Event Causality Identification Shared Task of CASE 2022 involved two\nsubtasks working on the Causal News Corpus. Subtask 1 required participants to\npredict if a sentence contains a causal relation or not. This is a supervised\nbinary classification task. Subtask 2 required participants to identify the\nCause, Effect and Signal spans per causal sentence. This could be seen as a\nsupervised sequence labeling task. For both subtasks, participants uploaded\ntheir predictions for a held-out test set, and ranking was done based on binary\nF1 and macro F1 scores for Subtask 1 and 2, respectively. This paper summarizes\nthe work of the 17 teams that submitted their results to our competition and 12\nsystem description papers that were received. The best F1 scores achieved for\nSubtask 1 and 2 were 86.19% and 54.15%, respectively. All the top-performing\napproaches involved pre-trained language models fine-tuned to the targeted\ntask. We further discuss these approaches and analyze errors across\nparticipants' systems in this paper.",
    "descriptor": "\nComments: Accepted to the 5th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE 2022)\n",
    "authors": [
      "Fiona Anting Tan",
      "Hansi Hettiarachchi",
      "Ali H\u00fcrriyeto\u011flu",
      "Tommaso Caselli",
      "Onur Uca",
      "Farhana Ferdousi Liza",
      "Nelleke Oostdijk"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.12154"
  },
  {
    "id": "arXiv:2211.12156",
    "title": "MSS-DepthNet: Depth Prediction with Multi-Step Spiking Neural Network",
    "abstract": "Event cameras are considered to have great potential for computer vision and\nrobotics applications because of their high temporal resolution and low power\nconsumption characteristics. However, the event stream output from event\ncameras has asynchronous, sparse characteristics that existing computer vision\nalgorithms cannot handle. Spiking neural network is a novel event-based\ncomputational paradigm that is considered to be well suited for processing\nevent camera tasks. However, direct training of deep SNNs suffers from\ndegradation problems. This work addresses these problems by proposing a spiking\nneural network architecture with a novel residual block designed and\nmulti-dimension attention modules combined, focusing on the problem of depth\nprediction. In addition, a novel event stream representation method is\nexplicitly proposed for SNNs. This model outperforms previous ANN networks of\nthe same size on the MVSEC dataset and shows great computational efficiency.",
    "descriptor": "",
    "authors": [
      "Xiaoshan Wu",
      "Weihua He",
      "Man Yao",
      "Ziyang Zhang",
      "Yaoyuan Wang",
      "Guoqi Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12156"
  },
  {
    "id": "arXiv:2211.12157",
    "title": "PESE: Event Structure Extraction using Pointer Network based  Encoder-Decoder Architecture",
    "abstract": "The task of event extraction (EE) aims to find the events and event-related\nargument information from the text and represent them in a structured format.\nMost previous works try to solve the problem by separately identifying multiple\nsubstructures and aggregating them to get the complete event structure. The\nproblem with the methods is that it fails to identify all the interdependencies\namong the event participants (event-triggers, arguments, and roles). In this\npaper, we represent each event record in a unique tuple format that contains\ntrigger phrase, trigger type, argument phrase, and corresponding role\ninformation. Our proposed pointer network-based encoder-decoder model generates\nan event tuple in each time step by exploiting the interactions among event\nparticipants and presenting a truly end-to-end solution to the EE task. We\nevaluate our model on the ACE2005 dataset, and experimental results demonstrate\nthe effectiveness of our model by achieving competitive performance compared to\nthe state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Alapan Kuila",
      "Sudeshan Sarkar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.12157"
  },
  {
    "id": "arXiv:2211.12164",
    "title": "OLGA : An Ontology and LSTM-based approach for generating Arithmetic  Word Problems (AWPs) of transfer type",
    "abstract": "Machine generation of Arithmetic Word Problems (AWPs) is challenging as they\nexpress quantities and mathematical relationships and need to be consistent.\nML-solvers require a large annotated training set of consistent problems with\nlanguage variations. Exploiting domain-knowledge is needed for consistency\nchecking whereas LSTM-based approaches are good for producing text with\nlanguage variations. Combining these we propose a system, OLGA, to generate\nconsistent word problems of TC (Transfer-Case) type, involving object transfers\namong agents. Though we provide a dataset of consistent 2-agent TC-problems for\ntraining, only about 36% of the outputs of an LSTM-based generator are found\nconsistent. We use an extension of TC-Ontology, proposed by us previously, to\ndetermine the consistency of problems. Among the remaining 64%, about 40% have\nminor errors which we repair using the same ontology. To check consistency and\nfor the repair process, we construct an instance-specific representation (ABox)\nof an auto-generated problem. We use a sentence classifier and BERT models for\nthis task. The training set for these LMs is problem-texts where sentence-parts\nare annotated with ontology class-names. As three-agent problems are longer,\nthe percentage of consistent problems generated by an LSTM-based approach drops\nfurther. Hence, we propose an ontology-based method that extends consistent\n2-agent problems into consistent 3-agent problems. Overall, our approach\ngenerates a large number of consistent TC-type AWPs involving 2 or 3 agents. As\nABox has all the information of a problem, any annotations can also be\ngenerated. Adopting the proposed approach to generate other types of AWPs is\ninteresting future work.",
    "descriptor": "",
    "authors": [
      "Suresh Kumar",
      "P Sreenivasa Kumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.12164"
  },
  {
    "id": "arXiv:2211.12173",
    "title": "Towards Human-Interpretable Prototypes for Visual Assessment of Image  Classification Models",
    "abstract": "Explaining black-box Artificial Intelligence (AI) models is a cornerstone for\ntrustworthy AI and a prerequisite for its use in safety critical applications\nsuch that AI models can reliably assist humans in critical decisions. However,\ninstead of trying to explain our models post-hoc, we need models which are\ninterpretable-by-design built on a reasoning process similar to humans that\nexploits meaningful high-level concepts such as shapes, texture or object\nparts. Learning such concepts is often hindered by its need for explicit\nspecification and annotation up front. Instead, prototype-based learning\napproaches such as ProtoPNet claim to discover visually meaningful prototypes\nin an unsupervised way. In this work, we propose a set of properties that those\nprototypes have to fulfill to enable human analysis, e.g. as part of a reliable\nmodel assessment case, and analyse such existing methods in the light of these\nproperties. Given a 'Guess who?' game, we find that these prototypes still have\na long way ahead towards definite explanations. We quantitatively validate our\nfindings by conducting a user study indicating that many of the learnt\nprototypes are not considered useful towards human understanding. We discuss\nabout the missing links in the existing methods and present a potential\nreal-world application motivating the need to progress towards truly\nhuman-interpretable prototypes.",
    "descriptor": "",
    "authors": [
      "Poulami Sinhamahapatra",
      "Lena Heidemann",
      "Maureen Monnet",
      "Karsten Roscher"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12173"
  },
  {
    "id": "arXiv:2211.12174",
    "title": "The Monocular Depth Estimation Challenge",
    "abstract": "This paper summarizes the results of the first Monocular Depth Estimation\nChallenge (MDEC) organized at WACV2023. This challenge evaluated the progress\nof self-supervised monocular depth estimation on the challenging SYNS-Patches\ndataset. The challenge was organized on CodaLab and received submissions from 4\nvalid teams. Participants were provided a devkit containing updated reference\nimplementations for 16 State-of-the-Art algorithms and 4 novel techniques. The\nthreshold for acceptance for novel techniques was to outperform every one of\nthe 16 SotA baselines. All participants outperformed the baseline in\ntraditional metrics such as MAE or AbsRel. However, pointcloud reconstruction\nmetrics were challenging to improve upon. We found predictions were\ncharacterized by interpolation artefacts at object boundaries and errors in\nrelative object positioning. We hope this challenge is a valuable contribution\nto the community and encourage authors to participate in future editions.",
    "descriptor": "\nComments: WACV-Workshops 2023\n",
    "authors": [
      "Jaime Spencer",
      "C. Stella Qian",
      "Chris Russell",
      "Simon Hadfield",
      "Erich Graf",
      "Wendy Adams",
      "Andrew J. Schofield",
      "James Elder",
      "Richard Bowden",
      "Heng Cong",
      "Stefano Mattoccia",
      "Matteo Poggi",
      "Zeeshan Khan Suri",
      "Yang Tang",
      "Fabio Tosi",
      "Hao Wang",
      "Youmin Zhang",
      "Yusheng Zhang",
      "Chaoqiang Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12174"
  },
  {
    "id": "arXiv:2211.12175",
    "title": "Randomized sketching of nonlinear eigenvalue problems",
    "abstract": "Rational approximation is a powerful tool to obtain accurate surrogates for\nnonlinear functions that are easy to evaluate and linearize. The interpolatory\nadaptive Antoulas--Anderson (AAA) method is one approach to construct such\napproximants numerically. For large-scale vector- and matrix-valued functions,\nhowever, the direct application of the set-valued variant of AAA becomes\ninefficient. We propose and analyze a new sketching approach for such functions\ncalled sketchAAA that, with high probability, leads to much better approximants\nthan previously suggested approaches while retaining efficiency. The sketching\napproach works in a black-box fashion where only evaluations of the nonlinear\nfunction at sampling points are needed. Numerical tests with nonlinear\neigenvalue problems illustrate the efficacy of our approach, with speedups\nabove 200 for sampling large-scale black-box functions without sacrificing on\naccuracy.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Stefan G\u00fcttel",
      "Daniel Kressner",
      "Bart Vandereycken"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.12175"
  },
  {
    "id": "arXiv:2211.12177",
    "title": "Analysis of the DoIP Protocol for Security Vulnerabilities",
    "abstract": "DoIP, which is defined in ISO 13400, is a transport protocol stack for\ndiagnostic data. Diagnostic data is a potential attack vector at vehicles, so\nsecure transmission must be guaranteed to protect sensitive data and the\nvehicle. Previous work analyzed a draft version and earlier versions of the\nDoIP protocol without Transport Layer Security (TLS). No formal analysis exists\nfor the DoIP protocol. The goal of this work is to investigate the DoIP\nprotocol for design flaws that may lead to security vulnerabilities and\npossible attacks to exploit them. For this purpose, we deductively analyze the\nDoIP protocol in a first step and subsequently confirm our conclusions\nformally. For the formal analysis, we use the prover Tamarin. Based on the\nresults, we propose countermeasures to improve the DoIP's security.We showthat\nthe DoIP protocol cannot be considered secure mainly because the security\nmechanisms TLS and client authentication in the DoIP protocol are not\nmandatory. We propose measures to mitigate the vulnerabilities thatwe confirm\nto remain after activating TLS. These require only a minor redesign of the\nprotocol.",
    "descriptor": "",
    "authors": [
      "Patrick Wachter",
      "Stephan Kleber"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.12177"
  },
  {
    "id": "arXiv:2211.12179",
    "title": "Stabilization of Capacitated Matching Games",
    "abstract": "An edge-weighted, vertex-capacitated graph G is called stable if the value of\na maximum-weight capacity-matching equals the value of a maximum-weight\nfractional capacity-matching. Stable graphs play a key role in characterizing\nthe existence of stable solutions for popular combinatorial games that involve\nthe structure of matchings in graphs, such as network bargaining games and\ncooperative matching games.\nThe vertex-stabilizer problem asks to compute a minimum number of players to\nblock (i.e., vertices of G to remove) in order to ensure stability for such\ngames. The problem has been shown to be solvable in polynomial-time, for\nunit-capacity graphs. This stays true also if we impose the restriction that\nthe set of players to block must not intersect with a given specified maximum\nmatching of G.\nIn this work, we investigate these algorithmic problems in the more general\nsetting of arbitrary capacities. We show that the vertex-stabilizer problem\nwith the additional restriction of avoiding a given maximum matching remains\npolynomial-time solvable. Differently, without this restriction, the\nvertex-stabilizer problem becomes NP-hard and even hard to approximate, in\ncontrast to the unit-capacity case.\nFinally, in unit-capacity graphs there is an equivalence between the\nstability of a graph, existence of a stable solution for network bargaining\ngames, and existence of a stable solution for cooperative matching games. We\nshow that this equivalence does not extend to the capacitated case.",
    "descriptor": "\nComments: 14 pages, 3 figures\n",
    "authors": [
      "Matthew Gerstbrein",
      "Laura Sanit\u00e0",
      "Lucy Verberk"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.12179"
  },
  {
    "id": "arXiv:2211.12181",
    "title": "User-Conditioned Neural Control Policies for Mobile Robotics",
    "abstract": "Recently, learning-based controllers have been shown to push mobile robotic\nsystems to their limits and provide the robustness needed for many real-world\napplications. However, only classical optimization-based control frameworks\noffer the inherent flexibility to be dynamically adjusted during execution by,\nfor example, setting target speeds or actuator limits. We present a framework\nto overcome this shortcoming of neural controllers by conditioning them on an\nauxiliary input. This advance is enabled by including a feature-wise linear\nmodulation layer (FiLM). We use model-free reinforcement-learning to train\nquadrotor control policies for the task of navigating through a sequence of\nwaypoints in minimum time. By conditioning the policy on the maximum available\nthrust or the viewing direction relative to the next waypoint, a user can\nregulate the aggressiveness of the quadrotor's flight during deployment. We\ndemonstrate in simulation and in real-world experiments that a single control\npolicy can achieve close to time-optimal flight performance across the entire\nperformance envelope of the robot, reaching up to 60 km/h and 4.5g in\nacceleration. The ability to guide a learned controller during task execution\nhas implications beyond agile quadrotor flight, as conditioning the control\npolicy on human intent helps safely bringing learning based systems out of the\nwell-defined laboratory environment into the wild.",
    "descriptor": "\nComments: 6 pages + 1 pages references\n",
    "authors": [
      "Leonard Bauersfeld",
      "Elia Kaufmann",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.12181"
  },
  {
    "id": "arXiv:2211.12184",
    "title": "Leveraging Memory Effects and Gradient Information in Consensus-Based  Optimization: On Global Convergence in Mean-Field Law",
    "abstract": "In this paper we study consensus-based optimization (CBO), a versatile,\nflexibel and customizable optimization method suitable for performing nonconvex\nand nonsmooth global optimizations in high dimensions. CBO is a multi-particle\nmetaheuristic, which is effective in various applications and at the same time\namenable to theoretical analysis thanks to its minimalistic design. The\nunderlying dynamics, however, is flexible enough to incorporate different\nmechanisms widely used in evolutionary computation and machine learning, as we\nshow by analyzing a variant of CBO which makes use of memory effects and\ngradient information. We rigorously prove that this dynamics converges to a\nglobal minimizer of the objective function in mean-field law for a vast class\nof functions under minimal assumptions on the initialization of the method. The\nproof in particular reveals how to leverage further, in some applications\nadvantageous, forces in the dynamics without loosing provable global\nconvergence. To demonstrate the benefit of the herein investigated memory\neffects and gradient information in certain applications, we present numerical\nevidence for the superiority of this CBO variant in applications such as\nmachine learning and compressed sensing, which en passant widen the scope of\napplications of CBO.",
    "descriptor": "\nComments: 31 pages, 6 figures\n",
    "authors": [
      "Konstantin Riedl"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Analysis of PDEs (math.AP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.12184"
  },
  {
    "id": "arXiv:2211.12185",
    "title": "Multimorbidity Content-Based Medical Image Retrieval Using Proxies",
    "abstract": "Content-based medical image retrieval is an important diagnostic tool that\nimproves the explainability of computer-aided diagnosis systems and provides\ndecision making support to healthcare professionals. Medical imaging data, such\nas radiology images, are often multimorbidity; a single sample may have more\nthan one pathology present. As such, image retrieval systems for the medical\ndomain must be designed for the multi-label scenario. In this paper, we propose\na novel multi-label metric learning method that can be used for both\nclassification and content-based image retrieval. In this way, our model is\nable to support diagnosis by predicting the presence of diseases and provide\nevidence for these predictions by returning samples with similar pathological\ncontent to the user. In practice, the retrieved images may also be accompanied\nby pathology reports, further assisting in the diagnostic process. Our method\nleverages proxy feature vectors, enabling the efficient learning of a robust\nfeature space in which the distance between feature vectors can be used as a\nmeasure of the similarity of those samples. Unlike existing proxy-based\nmethods, training samples are able to assign to multiple proxies that span\nmultiple class labels. This multi-label proxy assignment results in a feature\nspace that encodes the complex relationships between diseases present in\nmedical imaging data. Our method outperforms state-of-the-art image retrieval\nsystems and a set of baseline approaches. We demonstrate the efficacy of our\napproach to both classification and content-based image retrieval on two\nmultimorbidity radiology datasets.",
    "descriptor": "",
    "authors": [
      "Yunyan Xing",
      "Benjamin J. Meyer",
      "Mehrtash Harandi",
      "Tom Drummond",
      "Zongyuan Ge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12185"
  },
  {
    "id": "arXiv:2211.12190",
    "title": "A Combined Approach of Process Mining and Rule-based AI for Study  Planning and Monitoring in Higher Education",
    "abstract": "This paper presents an approach of using methods of process mining and\nrule-based artificial intelligence to analyze and understand study paths of\nstudents based on campus management system data and study program models.\nProcess mining techniques are used to characterize successful study paths, as\nwell as to detect and visualize deviations from expected plans. These insights\nare combined with recommendations and requirements of the corresponding study\nprograms extracted from examination regulations. Here, event calculus and\nanswer set programming are used to provide models of the study programs which\nsupport planning and conformance checking while providing feedback on possible\nstudy plan violations. In its combination, process mining and rule-based\nartificial intelligence are used to support study planning and monitoring by\nderiving rules and recommendations for guiding students to more suitable study\npaths with higher success rates. Two applications will be implemented, one for\nstudents and one for study program designers.",
    "descriptor": "\nComments: 12 pages, 4 figures, conference, 30 references\n",
    "authors": [
      "Miriam Wagner",
      "Hayyan Helal",
      "Rene Roepke",
      "Sven Judel",
      "Jens Doveren",
      "Sergej Goerzen",
      "Pouya Soudmand",
      "Gerhard Lakemeyer",
      "Ulrik Schroeder",
      "Wil van der Aalst"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.12190"
  },
  {
    "id": "arXiv:2211.12193",
    "title": "Anatomy-guided domain adaptation for 3D in-bed human pose estimation",
    "abstract": "3D human pose estimation is a key component of clinical monitoring systems.\nThe clinical applicability of deep pose estimation models, however, is limited\nby their poor generalization under domain shifts along with their need for\nsufficient labeled training data. As a remedy, we present a novel domain\nadaptation method, adapting a model from a labeled source to a shifted\nunlabeled target domain. Our method comprises two complementary adaptation\nstrategies based on prior knowledge about human anatomy. First, we guide the\nlearning process in the target domain by constraining predictions to the space\nof anatomically plausible poses. To this end, we embed the prior knowledge into\nan anatomical loss function that penalizes asymmetric limb lengths, implausible\nbone lengths, and implausible joint angles. Second, we propose to filter pseudo\nlabels for self-training according to their anatomical plausibility and\nincorporate the concept into the Mean Teacher paradigm. We unify both\nstrategies in a point cloud-based framework applicable to unsupervised and\nsource-free domain adaptation. Evaluation is performed for in-bed pose\nestimation under two adaptation scenarios, using the public SLP dataset and a\nnewly created dataset. Our method consistently outperforms various\nstate-of-the-art domain adaptation methods, surpasses the baseline model by\n31%/66%, and reduces the domain gap by 65%/82%. Source code is available at\nhttps://github.com/multimodallearning/da-3dhpe-anatomy.",
    "descriptor": "\nComments: submitted to Medical Image Analysis\n",
    "authors": [
      "Alexander Bigalke",
      "Lasse Hansen",
      "Jasper Diesel",
      "Carlotta Hennigs",
      "Philipp Rostalski",
      "Mattias P. Heinrich"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12193"
  },
  {
    "id": "arXiv:2211.12194",
    "title": "SadTalker: Learning Realistic 3D Motion Coefficients for Stylized  Audio-Driven Single Image Talking Face Animation",
    "abstract": "Generating talking head videos through a face image and a piece of speech\naudio still contains many challenges. ie, unnatural head movement, distorted\nexpression, and identity modification. We argue that these issues are mainly\nbecause of learning from the coupled 2D motion fields. On the other hand,\nexplicitly using 3D information also suffers problems of stiff expression and\nincoherent video. We present SadTalker, which generates 3D motion coefficients\n(head pose, expression) of the 3DMM from audio and implicitly modulates a novel\n3D-aware face render for talking head generation. To learn the realistic motion\ncoefficients, we explicitly model the connections between audio and different\ntypes of motion coefficients individually. Precisely, we present ExpNet to\nlearn the accurate facial expression from audio by distilling both coefficients\nand 3D-rendered faces. As for the head pose, we design PoseVAE via a\nconditional VAE to synthesize head motion in different styles. Finally, the\ngenerated 3D motion coefficients are mapped to the unsupervised 3D keypoints\nspace of the proposed face render, and synthesize the final video. We conduct\nextensive experiments to show the superior of our method in terms of motion and\nvideo quality.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Wenxuan Zhang",
      "Xiaodong Cun",
      "Xuan Wang",
      "Yong Zhang",
      "Xi Shen",
      "Yu Guo",
      "Ying Shan",
      "Fei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12194"
  },
  {
    "id": "arXiv:2211.12196",
    "title": "Quantifying impact on safety from cyber-attacks on cyber-physical  systems",
    "abstract": "We propose a novel framework for modelling attack scenarios in cyber-physical\ncontrol systems: we represent a cyber-physical system as a constrained\nswitching system, where a single model embeds the dynamics of the physical\nprocess, the attack patterns, and the attack detection schemes. We show that\nthis is compatible with established results in the analysis of hybrid automata,\nand, specifically, constrained switching systems. Moreover, we use the\ndeveloped models to compute the impact of cyber attacks on the safety\nproperties of the system. In particular, we characterise system safety as an\nasymptotic property, by calculating the maximal safe set. The resulting new\nimpact metrics intuitively quantify the degradation of safety under attack. We\nshowcase our results via illustrative examples.",
    "descriptor": "\nComments: 8 pages, 5 figures, submitted for presentation to IFAC World Congress 2023, Yokohama, JAPAN\n",
    "authors": [
      "Eleftherios Vlahakis",
      "Gregory Provan",
      "Gordon Werner",
      "Shanchieh Yang",
      "Nikolaos Athanasopoulos"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.12196"
  },
  {
    "id": "arXiv:2211.12198",
    "title": "Experimental Evaluation of Techniques to Lower Spectrum Consumption in  Wi-Red",
    "abstract": "Seamless redundancy layered atop Wi-Fi has been shown able to tangibly\nincrease communication quality, hence offering industry-grade reliability.\nHowever, it also implies much higher network traffic, which is often unbearable\nas the wireless spectrum is a shared and scarce resource. To deal with this\ndrawback the Wi-Red proposal includes suitable duplication avoidance\nmechanisms, which reduce spectrum consumption by preventing transmission on air\nof inessential frame duplicates.\nIn this paper, the ability of such mechanisms to save wireless bandwidth is\nexperimentally evaluated. To this purpose, specific post-analysis techniques\nhave been defined, which permit to carry out such an assessment on a simple\ntestbed that relies on plain redundancy and do not require any changes to the\nadapters' firmware. As results show, spectrum consumption decreases noticeably\nwithout communication quality is impaired. Further saving can be obtained if a\nslight worsening is tolerated for latencies.",
    "descriptor": "\nComments: preprint, 13 pages\n",
    "authors": [
      "Gianluca Cena",
      "Stefano Scanzio",
      "Adriano Valenzano"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.12198"
  },
  {
    "id": "arXiv:2211.12201",
    "title": "Distributed Resource Allocation for URLLC in IIoT Scenarios: A  Multi-Armed Bandit Approach",
    "abstract": "This paper addresses the problem of enabling inter-machine Ultra-Reliable\nLow-Latency Communication (URLLC) in future 6G Industrial Internet of Things\n(IIoT) networks. As far as the Radio Access Network (RAN) is concerned,\ncentralized pre-configured resource allocation requires scheduling grants to be\ndisseminated to the User Equipments (UEs) before uplink transmissions, which is\nnot efficient for URLLC, especially in case of flexible/unpredictable traffic.\nTo alleviate this burden, we study a distributed, user-centric scheme based on\nmachine learning in which UEs autonomously select their uplink radio resources\nwithout the need to wait for scheduling grants or preconfiguration of\nconnections. Using simulation, we demonstrate that a Multi-Armed Bandit (MAB)\napproach represents a desirable solution to allocate resources with URLLC in\nmind in an IIoT environment, in case of both periodic and aperiodic traffic,\neven considering highly populated networks and aggressive traffic.",
    "descriptor": "\nComments: 2022 IEEE Globecom Workshops (GC Wkshps): Future of Wireless Access and Sensing for Industrial IoT (FutureIIoT)\n",
    "authors": [
      "Francesco Pase",
      "Marco Giordani",
      "Giampaolo Cuozzo",
      "Sara Cavallero",
      "Joseph Eichinger",
      "Roberto Verdone",
      "Michele Zorzi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.12201"
  },
  {
    "id": "arXiv:2211.12203",
    "title": "Edge Multiway Cut and Node Multiway Cut are NP-complete on subcubic  graphs",
    "abstract": "We show that Edge Multiway Cut (also called Multiterminal Cut) and Node\nMultiway Cut are NP-complete on graphs of maximum degree $3$ (also known as\nsubcubic graphs). This improves on a previous degree bound of $11$. Our\nNP-completeness result holds even for subcubic graphs that are planar.",
    "descriptor": "",
    "authors": [
      "Matthew Johnson",
      "Barnaby Martin",
      "Siani Smith",
      "Sukanya Pandey",
      "Daniel Paulusma",
      "Erik Jan van Leeuwen"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.12203"
  },
  {
    "id": "arXiv:2211.12205",
    "title": "Utopia: Efficient Address Translation using Hybrid Virtual-to-Physical  Address Mapping",
    "abstract": "The conventional virtual-to-physical address mapping scheme enables a virtual\naddress to flexibly map to any physical address. This flexibility necessitates\nlarge data structures to store virtual-to-physical mappings, which incurs\nsignificantly high address translation latency and translation-induced\ninterference in the memory hierarchy, especially in data-intensive workloads.\nRestricting the address mapping so that a virtual address can map to only a\nspecific set of physical addresses can significantly reduce the overheads\nassociated with the conventional address translation by making use of compact\nand more efficient translation structures. However, restricting the address\nmapping flexibility across the entire main memory severely limits data sharing\nacross different processes and increases memory under-utilization. In this\nwork, we propose Utopia, a new hybrid virtual-to-physical address mapping\nscheme that allows both flexible and restrictive hash-based address mapping\nschemes to co-exist in a system. The key idea of Utopia is to manage the\nphysical memory using two types of physical memory segments: restrictive\nsegments and flexible segments. A restrictive segment uses a restrictive,\nhash-based address mapping scheme to map the virtual addresses to only a\nspecific set of physical addresses and enable faster address translation using\ncompact and efficient translation structures. A flexible segment is similar to\nthe conventional address mapping scheme and provides full virtual-to-physical\naddress mapping flexibility. By mapping data to a restrictive segment, Utopia\nenables faster address translation with lower translation-induced interference\nwhenever a flexible address mapping is not necessary. Our evaluation using 11\ndata-intensive workloads shows that Utopia improves performance by 32% on\naverage in single-core workloads over the baseline four-level radix-tree page\ntable design.",
    "descriptor": "",
    "authors": [
      "Konstantinos Kanellopoulos",
      "Rahul Bera",
      "Kosta Stojiljkovic",
      "Can Firtina",
      "Rachata Ausavarungnirun",
      "Nastaran Hajinazar",
      "Jisung Park",
      "Nandita Vijaykumar",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.12205"
  },
  {
    "id": "arXiv:2211.12206",
    "title": "Twitter has a Binary Privacy Setting, are Users Aware of How It Works?",
    "abstract": "Twitter accounts are public by default, but Twitter gives the option to\ncreate protected accounts, where only approved followers can see their tweets.\nThe publicly visible information changes based on the account type and the\nvisibility of tweets also depends solely on the poster's account type which can\ncause unintended disclosures especially when users interact. We surveyed 336\nTwitter users to understand users' awareness of account information visibility,\nas well as the tweet visibility when users interact. We find that our\nparticipants are aware of the visibility of their profile information and\nindividual tweets. However, the visibility of followed topics, lists, and\ninteractions with protected accounts is confusing. Only 31% of the participants\nwere aware that a reply by a public account to a protected account's tweet\nwould be publicly visible. Surprisingly, having a protected account does not\nresult in a better understanding of the account information or tweet\nvisibility.",
    "descriptor": "\nComments: Proceeding of the 2023 ACM SIGCHI Conference on Computer-Supported Cooperative Work & Social Computing (CSCW'23)\n",
    "authors": [
      "Dilara Kek\u00fcll\u00fco\u011flu",
      "Kami Vaniea",
      "Maria K. Wolters",
      "Walid Magdy"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.12206"
  },
  {
    "id": "arXiv:2211.12209",
    "title": "$S^2$-Flow: Joint Semantic and Style Editing of Facial Images",
    "abstract": "The high-quality images yielded by generative adversarial networks (GANs)\nhave motivated investigations into their application for image editing.\nHowever, GANs are often limited in the control they provide for performing\nspecific edits. One of the principal challenges is the entangled latent space\nof GANs, which is not directly suitable for performing independent and detailed\nedits. Recent editing methods allow for either controlled style edits or\ncontrolled semantic edits. In addition, methods that use semantic masks to edit\nimages have difficulty preserving the identity and are unable to perform\ncontrolled style edits. We propose a method to disentangle a GAN$\\text{'}$s\nlatent space into semantic and style spaces, enabling controlled semantic and\nstyle edits for face images independently within the same framework. To achieve\nthis, we design an encoder-decoder based network architecture ($S^2$-Flow),\nwhich incorporates two proposed inductive biases. We show the suitability of\n$S^2$-Flow quantitatively and qualitatively by performing various semantic and\nstyle edits.",
    "descriptor": "\nComments: Accepted to BMVC 2022\n",
    "authors": [
      "Krishnakant Singh",
      "Simone Schaub-Meyer",
      "Stefan Roth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12209"
  },
  {
    "id": "arXiv:2211.12216",
    "title": "Watch out! There may be a Human. Addressing Invisible Humans in Social  Navigation",
    "abstract": "Current approaches in human-aware or social robot navigation address the\nhumans that are visible to the robot. However, it is also important to address\nthe possible emergences of humans to avoid shocks or surprises to humans and\nerratic behavior of the robot planner. In this paper, we propose a novel\napproach to detect and address these human emergences called `invisible\nhumans'. We determine the places from which a human, currently not visible to\nthe robot, can appear suddenly and then adapt the path and speed of the robot\nwith the anticipation of potential collisions. This is done while still\nconsidering and adapting humans present in the robot's field of view. We also\nshow how this detection can be exploited to identify and address the doorways\nor narrow passages. Finally, the effectiveness of the proposed methodology is\nshown through several simulated and real-world experiments.",
    "descriptor": "",
    "authors": [
      "Phani Teja Singamaneni",
      "Anthony Favier",
      "Rachid Alami"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.12216"
  },
  {
    "id": "arXiv:2211.12217",
    "title": "Where Will Players Move Next? Dynamic Graphs and Hierarchical Fusion for  Movement Forecasting in Badminton",
    "abstract": "Sports analytics has captured increasing attention since analysis of the\nvarious data enables insights for training strategies, player evaluation, etc.\nIn this paper, we focus on predicting what types of returning strokes will be\nmade, and where players will move to based on previous strokes. As this problem\nhas not been addressed to date, movement forecasting can be tackled through\nsequence-based and graph-based models by formulating as a sequence prediction\ntask. However, existing sequence-based models neglect the effects of\ninteractions between players, and graph-based models still suffer from\nmultifaceted perspectives on the next movement. Moreover, there is no existing\nwork on representing strategic relations among players' shot types and\nmovements. To address these challenges, we first introduce the procedure of the\nPlayer Movements (PM) graph to exploit the structural movements of players with\nstrategic relations. Based on the PM graph, we propose a novel Dynamic Graphs\nand Hierarchical Fusion for Movement Forecasting model (DyMF) with interaction\nstyle extractors to capture the mutual interactions of players themselves and\nbetween both players within a rally, and dynamic players' tactics across time.\nIn addition, hierarchical fusion modules are designed to incorporate the style\ninfluence of both players and rally interactions. Extensive experiments show\nthat our model empirically outperforms both sequence- and graph-based methods\nand demonstrate the practical usage of movement forecasting.",
    "descriptor": "\nComments: Accepted by AAAI 2022, code is available at this https URL\n",
    "authors": [
      "Kai-Shiang Chang",
      "Wei-Yao Wang",
      "Wen-Chih Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12217"
  },
  {
    "id": "arXiv:2211.12219",
    "title": "Adaptive Sparse Structure Development with Pruning and Regeneration for  Spiking Neural Networks",
    "abstract": "Spiking Neural Networks (SNNs) are more biologically plausible and\ncomputationally efficient. Therefore, SNNs have the natural advantage of\ndrawing the sparse structural plasticity of brain development to alleviate the\nenergy problems of deep neural networks caused by their complex and fixed\nstructures. However, previous SNNs compression works are lack of in-depth\ninspiration from the brain development plasticity mechanism. This paper\nproposed a novel method for the adaptive structural development of SNN\n(SD-SNN), introducing dendritic spine plasticity-based synaptic constraint,\nneuronal pruning and synaptic regeneration. We found that synaptic constraint\nand neuronal pruning can detect and remove a large amount of redundancy in\nSNNs, coupled with synaptic regeneration can effectively prevent and repair\nover-pruning. Moreover, inspired by the neurotrophic hypothesis, neuronal\npruning rate and synaptic regeneration rate were adaptively adjusted during the\nlearning-while-pruning process, which eventually led to the structural\nstability of SNNs. Experimental results on spatial (MNIST, CIFAR-10) and\ntemporal neuromorphic (N-MNIST, DVS-Gesture) datasets demonstrate that our\nmethod can flexibly learn appropriate compression rate for various tasks and\neffectively achieve superior performance while massively reducing the network\nenergy consumption. Specifically, for the spatial MNIST dataset, our SD-SNN\nachieves 99.51\\% accuracy at the pruning rate 49.83\\%, which has a 0.05\\%\naccuracy improvement compared to the baseline without compression. For the\nneuromorphic DVS-Gesture dataset, 98.20\\% accuracy with 1.09\\% improvement is\nachieved by our method when the compression rate reaches 55.50\\%.",
    "descriptor": "",
    "authors": [
      "Bing Han",
      "Feifei Zhao",
      "Yi Zeng",
      "Wenxuan Pan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12219"
  },
  {
    "id": "arXiv:2211.12220",
    "title": "A Scope Sensitive and Result Attentive Model for Multi-Intent Spoken  Language Understanding",
    "abstract": "Multi-Intent Spoken Language Understanding (SLU), a novel and more complex\nscenario of SLU, is attracting increasing attention. Unlike traditional SLU,\neach intent in this scenario has its specific scope. Semantic information\noutside the scope even hinders the prediction, which tremendously increases the\ndifficulty of intent detection. More seriously, guiding slot filling with these\ninaccurate intent labels suffers error propagation problems, resulting in\nunsatisfied overall performance. To solve these challenges, in this paper, we\npropose a novel Scope-Sensitive Result Attention Network (SSRAN) based on\nTransformer, which contains a Scope Recognizer (SR) and a Result Attention\nNetwork (RAN). Scope Recognizer assignments scope information to each token,\nreducing the distraction of out-of-scope tokens. Result Attention Network\neffectively utilizes the bidirectional interaction between results of slot\nfilling and intent detection, mitigating the error propagation problem.\nExperiments on two public datasets indicate that our model significantly\nimproves SLU performance (5.4\\% and 2.1\\% on Overall accuracy) over the\nstate-of-the-art baseline.",
    "descriptor": "",
    "authors": [
      "Lizhi Cheng",
      "Wenmian Yang",
      "Weijia Jia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.12220"
  },
  {
    "id": "arXiv:2211.12221",
    "title": "Virtual Reality in University Teaching: Experiences from a Computer  Science Seminar",
    "abstract": "Due to the corona pandemic, numerous courses were held using digital\nsolutions in order to be able to continue teaching. Conventional collaboration\ntools (Zoom, Big Blue Button, etc.) were used in particular to digitally map a\nsynchronous session for teaching and learning purposes. While these\nconventional collaboration tools offer a solid basis for communication between\nlearners and teachers, aspects such as presence or a realistic type of\ninteraction are neglected. In this work, we report on the experiences from a\ncomputer science seminar where virtual reality (VR) technology was used as an\nalternative solution for teaching and group work. The benefits of VR compared\nto conventional collaboration tools were examined using questionnaires and\ninterviews with the participants. On the one hand, the results show the high\npotential of VR to increase the clarity and experienceability of learning\ncontent and to promote cooperation through social presence. On the other hand,\nthe use of VR brings with it some technical and organizational difficulties\nthat should be taken into account in the didactic implementation.",
    "descriptor": "\nComments: accepted as publication for \"die hochschullehre\", preprint of my Scholarship of Teaching and Learning project\n",
    "authors": [
      "Enes Yigitbas"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.12221"
  },
  {
    "id": "arXiv:2211.12222",
    "title": "Event Transformer+. A multi-purpose solution for efficient event data  processing",
    "abstract": "Event cameras record sparse illumination changes with high temporal\nresolution and high dynamic range. Thanks to their sparse recording and low\nconsumption, they are increasingly used in applications such as AR/VR and\nautonomous driving. Current top-performing methods often ignore specific\nevent-data properties, leading to the development of generic but\ncomputationally expensive algorithms, while event-aware methods do not perform\nas well. We propose Event Transformer+, that improves our seminal work evtprev\nEvT with a refined patch-based event representation and a more robust backbone\nto achieve more accurate results, while still benefiting from event-data\nsparsity to increase its efficiency. Additionally, we show how our system can\nwork with different data modalities and propose specific output heads, for\nevent-stream predictions (i.e. action recognition) and per-pixel predictions\n(dense depth estimation). Evaluation results show better performance to the\nstate-of-the-art while requiring minimal computation resources, both on GPU and\nCPU.",
    "descriptor": "",
    "authors": [
      "Alberto Sabater",
      "Luis Montesano",
      "Ana C. Murillo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12222"
  },
  {
    "id": "arXiv:2211.12223",
    "title": "KGMM -- A Maturity Model for Scholarly Knowledge Graphs based on  Intertwined Human-Machine Collaboration",
    "abstract": "Knowledge Graphs (KG) have gained increasing importance in science, business\nand society in the last years. However, most knowledge graphs were either\nextracted or compiled from existing sources. There are only relatively few\nexamples where knowledge graphs were genuinely created by an intertwined\nhuman-machine collaboration. Also, since the quality of data and knowledge\ngraphs is of paramount importance, a number of data quality assessment models\nhave been proposed. However, they do not take the specific aspects of\nintertwined human-machine curated knowledge graphs into account. In this work,\nwe propose a graded maturity model for scholarly knowledge graphs (KGMM), which\nspecifically focuses on aspects related to the joint, evolutionary curation of\nknowledge graphs for digital libraries. Our model comprises 5 maturity stages\nwith 20 quality measures. We demonstrate the implementation of our model in a\nlarge scale scholarly knowledge graph curation effort.",
    "descriptor": "\nComments: Accepted as a full paper at the ICADL 2022: International Conference on Asian Digital Libraries 2022\n",
    "authors": [
      "Hassan Hussein",
      "Allard Oelen",
      "Oliver Karras",
      "S\u00f6ren Auer"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.12223"
  },
  {
    "id": "arXiv:2211.12224",
    "title": "Sustainable Wireless Services with UAV Swarms Tailored to Renewable  Energy Sources",
    "abstract": "Unmanned Aerial Vehicle (UAV) swarms are often required in off-grid\nscenarios, such as disaster-struck, war-torn or rural areas, where the UAVs\nhave no access to the power grid and instead rely on renewable energy.\nConsidering a main battery fed from two renewable sources, wind and solar, we\nscale such a system based on the financial budget, environmental\ncharacteristics, and seasonal variations. Interestingly, the source of energy\nis correlated with the energy expenditure of the UAVs, since strong winds cause\nUAV hovering to become increasingly energy-hungry. The aim is to maximize the\ncost efficiency of coverage at a particular location, which is a combinatorial\noptimization problem for dimensioning of the multivariate energy generation\nsystem under non-convex criteria. We have devised a customized algorithm by\nlowering the processing complexity and reducing the solution space through\nsampling. Evaluation is done with condensed real-world data on wind, solar\nenergy, and traffic load per unit area, driven by vendor-provided prices. The\nimplementation was tested in four locations, with varying wind or solar\nintensity. The best results were achieved in locations with mild wind presence\nand strong solar irradiation, while locations with strong winds and low solar\nintensity require higher Caital Expenditure (CAPEX) allocation.",
    "descriptor": "\nComments: To be published in Transactions on Smart Grid\n",
    "authors": [
      "Igor Donevski",
      "Marco Virgili",
      "Nithin Babu",
      "Jimmy Jessen Nielsen",
      "Andrew J. Forsyth",
      "Constantinos B. Papadias",
      "Petar Popovski"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.12224"
  },
  {
    "id": "arXiv:2211.12225",
    "title": "Reversible Programming: A Case Study of Two String-Matching Algorithms",
    "abstract": "String matching is a fundamental problem in algorithm. This study examines\nthe development and construction of two reversible string-matching algorithms:\na naive string-matching algorithm and the Rabin-Karp algorithm. The algorithms\nare used to introduce reversible computing concepts, beginning from basic\nreversible programming techniques to more advanced considerations about the\ninjectivization of the polynomial hash-update function employed by the\nRabin-Karp algorithm. The results are two clean input-preserving reversible\nalgorithms that require no additional space and have the same asymptotic time\ncomplexity as their classic irreversible originals. This study aims to\ncontribute to the body of reversible algorithms and to the discipline of\nreversible programming.",
    "descriptor": "\nComments: In Proceedings HCVS/VPT 2022, arXiv:2211.10675\n",
    "authors": [
      "Robert Gl\u00fcck",
      "Tetsuo Yokoyama"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.12225"
  },
  {
    "id": "arXiv:2211.12226",
    "title": "On Structural Parameterizations of Star Coloring",
    "abstract": "A Star Coloring of a graph G is a proper vertex coloring such that every path\non four vertices uses at least three distinct colors. The minimum number of\ncolors required for such a star coloring of G is called star chromatic number,\ndenoted by \\chi_s(G). Given a graph G and a positive integer k, the STAR\nCOLORING PROBLEM asks whether $G$ has a star coloring using at most k colors.\nThis problem is NP-complete even on restricted graph classes such as bipartite\ngraphs.\nIn this paper, we initiate a study of STAR COLORING from the parameterized\ncomplexity perspective. We show that STAR COLORING is fixed-parameter tractable\nwhen parameterized by (a) neighborhood diversity, (b) twin-cover, and (c) the\ncombined parameters clique-width and the number of colors.",
    "descriptor": "",
    "authors": [
      "Sriram Bhyravarapu",
      "I. Vinod Reddy"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.12226"
  },
  {
    "id": "arXiv:2211.12227",
    "title": "The Security Protocol Verifier ProVerif and its Horn Clause Resolution  Algorithm",
    "abstract": "ProVerif is a widely used security protocol verifier. Internally, ProVerif\nuses an abstract representation of the protocol by Horn clauses and a\nresolution algorithm on these clauses, in order to prove security properties of\nthe protocol or to find attacks. In this paper, we present an overview of\nProVerif and discuss some specificities of its resolution algorithm, related to\nthe particular application domain and the particular clauses that ProVerif\ngenerates. This paper is a short summary that gives pointers to publications on\nProVerif in which the reader will find more details.",
    "descriptor": "\nComments: In Proceedings HCVS/VPT 2022, arXiv:2211.10675\n",
    "authors": [
      "Bruno Blanchet"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.12227"
  },
  {
    "id": "arXiv:2211.12228",
    "title": "Contract Strengthening through Constrained Horn Clause Verification",
    "abstract": "The functional properties of a program are often specified by providing a\ncontract for each of its functions. A contract of a function consists of a pair\nof formulas, called a precondition and a postcondition, which, respectively,\nshould hold before and after execution of that function. It might be the case\nthat the contracts supplied by the programmer are not adequate to allow a\nverification system to prove program correctness, that is, to show that for\nevery function, if the precondition holds and the execution of the function\nterminates, then the postcondition holds. We address this problem by providing\na technique which may strengthen the postconditions of the functions, thereby\nimproving the ability of the verifier to show program correctness. Our\ntechnique consists of four steps. First, the translation of the given program,\nwhich may manipulate algebraic data structures (ADTs), and its contracts into a\nset of constrained Horn clauses (CHCs) whose satisfiability implies the\nvalidity of the given contracts. Then, the derivation, via CHC transformation\nperformed by the VeriCaT tool, of a new set of CHCs that manipulate only basic\nsorts (such as booleans or integers) and whose satisfiability implies the\nsatisfiability of the original set of clauses. Then, the construction of a\nmodel, if any, of the new, derived CHCs using the CHC solver SPACER for basic\nsorts. Finally, the translation of that model into the formulas that suitably\nstrengthen the postconditions of the given contracts. We will present our\ntechnique through an example consisting of a Scala program for reversing lists.\nNote that the Stainless verifier is not able to prove the correctness of that\nprogram when considering the given contracts, while it succeeds when\nconsidering the contracts with the strengthened postconditions constructed by\napplying our technique.",
    "descriptor": "\nComments: In Proceedings HCVS/VPT 2022, arXiv:2211.10675\n",
    "authors": [
      "Emanuele De Angelis",
      "Fabio Fioravanti",
      "Alberto Pettorossi",
      "Maurizio Proietti"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.12228"
  },
  {
    "id": "arXiv:2211.12229",
    "title": "OptiRica: Towards an Efficient Optimizing Horn Solver",
    "abstract": "This paper describes an ongoing effort to develop an optimizing version of\nthe Eldarica Horn solver. The work starts from the observation that many kinds\nof optimization problems, and in particular the MaxSAT/SMT problem, can be seen\nas search problems on lattices. The paper presents a Scala library providing a\ndomain-specific language (DSL) to uniformly model optimization problems of this\nkind, by defining, manipulating, and systematically exploring lattices with\nassociated objective functions. The framework can be instantiated to obtain an\noptimizing Horn solver. As an illustration, the application of an optimizing\nsolver for repairing software-defined networks is described.",
    "descriptor": "\nComments: In Proceedings HCVS/VPT 2022, arXiv:2211.10675\n",
    "authors": [
      "Hossein Hojjat",
      "Philipp R\u00fcmmer"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.12229"
  },
  {
    "id": "arXiv:2211.12230",
    "title": "Towards Optimal Decoding for Polar Codes",
    "abstract": "In the conventional successive cancellation (SC) decoder for polar codes, all\nthe future bits to be estimated later are treated as random variables. However,\npolar codes inevitably involve frozen bits, and their concatenated coding\nschemes also include parity bits causally generated from the past bits\nestimated earlier. We refer to the frozen and parity bits located behind a\ntarget decoding bit as its future constraints (FCs). Although the values of FCs\nare deterministic given the past estimates, they have not been exploited in the\nconventional SC-based decoders, not leading to optimality. In this paper, we\npropose SC-check (SCC) and belief-propagation SCC (BP-SCC) decoding algorithms\nin order to leverage FCs in decoding.We further devise a tree search technique\nbased on stack-based backjumping (SBJ) to solve dynamic constraint satisfaction\nproblems (CSPs) formulated by FCs. Over the binary erasure channel (BEC),\nnumerical results show that a combination of the BP-SCC algorithm and the SBJ\ntree search technique achieves the erasure recovery performance close to the\ndependence testing (DT) bound, a bound of achievable finite-length performance.",
    "descriptor": "",
    "authors": [
      "Min Jang",
      "Jong-Hwan Kim",
      "Seho Myung",
      "Kyeongcheol Yang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.12230"
  },
  {
    "id": "arXiv:2211.12231",
    "title": "CHC-COMP 2022: Competition Report",
    "abstract": "CHC-COMP 2022 is the fifth edition of the competition of solvers for\nConstrained Horn Clauses. The competition was run in March 2022; the results\nwere presented at the 9th Workshop on Horn Clauses for Verification and\nSynthesis held in Munich, Germany, on April 3, 2022. This edition featured six\nsolvers, and eight tracks consisting of sets of linear and nonlinear clauses\nwith constraints over linear integer arithmetic, linear real arithmetic,\narrays, and algebraic data types. This report provides an overview of the\norganization behind the competition runs: it includes the technical details of\nthe competition setup as well as presenting the results of the 2022 edition.",
    "descriptor": "\nComments: In Proceedings HCVS/VPT 2022, arXiv:2211.10675. arXiv admin note: text overlap with arXiv:2109.04635, arXiv:2008.02939 by other authors\n",
    "authors": [
      "Emanuele De Angelis",
      "Hari Govind V K"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2211.12231"
  },
  {
    "id": "arXiv:2211.12232",
    "title": "AERO: Audio Super Resolution in the Spectral Domain",
    "abstract": "We present AERO, a audio super-resolution model that processes speech and\nmusic signals in the spectral domain. AERO is based on an encoder-decoder\narchitecture with U-Net like skip connections. We optimize the model using both\ntime and frequency domain loss functions. Specifically, we consider a set of\nreconstruction losses together with perceptual ones in the form of adversarial\nand feature discriminator loss functions. To better handle phase information\nthe proposed method operates over the complex-valued spectrogram using two\nseparate channels. Unlike prior work which mainly considers low and high\nfrequency concatenation for audio super-resolution, the proposed method\ndirectly predicts the full frequency range. We demonstrate high performance\nacross a wide range of sample rates considering both speech and music. AERO\noutperforms the evaluated baselines considering Log-Spectral Distance, ViSQOL,\nand the subjective MUSHRA test. Audio samples and code are available at\nhttps://pages.cs.huji.ac.il/adiyoss-lab/aero",
    "descriptor": "",
    "authors": [
      "Moshe Mandel",
      "Or Tal",
      "Yossi Adi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.12232"
  },
  {
    "id": "arXiv:2211.12234",
    "title": "A Reinforcement Learning Badminton Environment for Simulating Player  Tactics (Student Abstract)",
    "abstract": "Recent techniques for analyzing sports precisely has stimulated various\napproaches to improve player performance and fan engagement. However, existing\napproaches are only able to evaluate offline performance since testing in\nreal-time matches requires exhaustive costs and cannot be replicated. To test\nin a safe and reproducible simulator, we focus on turn-based sports and\nintroduce a badminton environment by simulating rallies with different angles\nof view and designing the states, actions, and training procedures. This\nbenefits not only coaches and players by simulating past matches for tactic\ninvestigation, but also researchers from rapidly evaluating their novel\nalgorithms.",
    "descriptor": "\nComments: Accepted by AAAI 2023 Student Abstract, code is available at this https URL\n",
    "authors": [
      "Li-Chun Huang",
      "Nai-Zen Hseuh",
      "Yen-Che Chien",
      "Wei-Yao Wang",
      "Kuang-Da Wang",
      "Wen-Chih Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12234"
  },
  {
    "id": "arXiv:2211.12237",
    "title": "On a reduced digit-by-digit component-by-component construction of  lattice point sets",
    "abstract": "In this paper, we study an efficient algorithm for constructing point sets\nunderlying quasi-Monte Carlo integration rules for weighted Korobov classes.\nThe algorithm presented is a reduced fast component-by-component digit-by-digit\n(CBC-DBD) algorithm, which useful for to situations where the weights in the\nfunction space show a sufficiently fast decay. The advantage of the algorithm\npresented here is that the computational effort can be independent of the\ndimension of the integration problem to be treated if suitable assumptions on\nthe integrand are met. The new reduced CBC-DBD algorithm is designed to work\nfor the construction of lattice point sets, and the corresponding integration\nrules (so-called lattice rules) can be used to treat functions in different\nkinds of function spaces. We show that the integration rules constructed by our\nalgorithm satisfy error bounds of almost optimal convergence order.\nFurthermore, we give details on an efficient implementation such that we obtain\na considerable speed-up of a previously known CBC-DBD algorithm that has been\nstudied before. This improvement is illustrated by numerical results.",
    "descriptor": "",
    "authors": [
      "Peter Kritzer",
      "Onyekachi Osisiogu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.12237"
  },
  {
    "id": "arXiv:2211.12238",
    "title": "Generalized Random Gilbert-Varshamov Codes: Typical Error Exponent and  Concentration Properties",
    "abstract": "We find the exact typical error exponent of constant composition generalized\nrandom Gilbert-Varshamov (RGV) codes over DMCs channels with generalized\nlikelihood decoding. We show that the typical error exponent of the RGV\nensemble is equal to the expurgated error exponent, provided that the RGV\ncodebook parameters are chosen appropriately. We also prove that the random\ncoding exponent converges in probability to the typical error exponent, and the\ncorresponding non-asymptotic concentration rates are derived. Our results show\nthat the decay rate of the lower tail is exponential while that of the upper\ntail is double exponential above the expurgated error exponent. The explicit\ndependence of the decay rates on the RGV distance functions is characterized.",
    "descriptor": "\nComments: 60 pages, 2 figures\n",
    "authors": [
      "Lan V. Truong",
      "Albert Guill\u00e9n i F\u00e0bregas"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.12238"
  },
  {
    "id": "arXiv:2211.12239",
    "title": "Photonic Spiking Neural Networks with Highly Efficient Training  Protocols for Ultrafast Neuromorphic Computing Systems",
    "abstract": "Photonic technologies offer great prospects for novel ultrafast,\nenergy-efficient and hardware-friendly neuromorphic (brain-like) computing\nplatforms. Moreover, neuromorphic photonic approaches based upon ubiquitous,\ntechnology-mature and low-cost Vertical-Cavity Surface Emitting Lasers (VCSELs)\n(devices found in fibre-optic transmitters, mobile phones, automotive sensors,\netc.) are of particular interest. Given VCSELs have shown the ability to\nrealise neuronal optical spiking responses (at ultrafast GHz rates), their use\nfor spike-based information processing systems has been proposed. In this work,\nSpiking Neural Network (SNN) operation, based on a hardware-friendly photonic\nsystem of just one Vertical Cavity Surface Emitting Laser (VCSEL), is reported\nalongside a novel binary weight 'significance' training scheme that fully\ncapitalises on the discrete nature of the optical spikes used by the SNN to\nprocess input information. The VCSEL-based photonic SNN is tested with a highly\ncomplex, multivariate, classification task (MADELON) before performance is\ncompared using a traditional least-squares training method and the alternative\nnovel binary weighting scheme. Excellent classification accuracies of >94% are\nreached by both training methods, exceeding the benchmark performance of the\ndataset in a fraction of processing time. The newly reported training scheme\nalso dramatically reduces training set size requirements as well as the number\nof trained nodes (<1% of the total network node count). This VCSEL-based\nphotonic SNN, in combination with the reported 'significance' weighting scheme,\ntherefore grants ultrafast spike-based optical processing with highly reduced\ntraining requirements and hardware complexity for potential application in\nfuture neuromorphic systems and artificial intelligence applications.",
    "descriptor": "",
    "authors": [
      "Dafydd Owen-Newns",
      "Joshua Robertson",
      "Matej Hejda",
      "Antonio Hurtado"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2211.12239"
  },
  {
    "id": "arXiv:2211.12244",
    "title": "FE-Fusion-VPR: Attention-based Multi-Scale Network Architecture for  Visual Place Recognition by Fusing Frames and Events",
    "abstract": "Traditional visual place recognition (VPR), usually using standard cameras,\nis easy to fail due to glare or high-speed motion. By contrast, event cameras\nhave the advantages of low latency, high temporal resolution, and high dynamic\nrange, which can deal with the above issues. Nevertheless, event cameras are\nprone to failure in weakly textured or motionless scenes, while standard\ncameras can still provide appearance information in this case. Thus, exploiting\nthe complementarity of standard cameras and event cameras can effectively\nimprove the performance of VPR algorithms. In the paper, we propose\nFE-Fusion-VPR, an attention-based multi-scale network architecture for VPR by\nfusing frames and events. First, the intensity frame and event volume are fed\ninto the two-stream feature extraction network for shallow feature fusion.\nNext, the three-scale features are obtained through the multi-scale fusion\nnetwork and aggregated into three sub-descriptors using the VLAD layer.\nFinally, the weight of each sub-descriptor is learned through the descriptor\nre-weighting network to obtain the final refined descriptor. Experimental\nresults show that on the Brisbane-Event-VPR and DDD20 datasets, the Recall@1 of\nour FE-Fusion-VPR is 25.20% and 37.21% higher than Event-VPR and\nEnsemble-EventVPR, and is 2.55% and 15.89% higher than MultiRes-NetVLAD and\nNetVLAD. To our knowledge, this is the first end-to-end network that goes\nbeyond the existing event-based and frame-based SOTA methods to fuse frame and\nevents directly for VPR.",
    "descriptor": "",
    "authors": [
      "Kuanxu Hou",
      "Delei Kong",
      "Junjie Jiang",
      "Hao Zhuang",
      "Xinjie Huang",
      "Zheng Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.12244"
  },
  {
    "id": "arXiv:2211.12249",
    "title": "Enabling On-Demand Cyber-Physical Control Applications with UAV Access  Points",
    "abstract": "Achieving cyber-physical control over a wireless channel requires satisfying\nboth the timeliness of a single packet and preserving the latency reliability\nacross several consecutive packets. To satisfy those requirements as an\nubiquitous service requires big infrastructural developments, or flexible\non-demand equipment such as UAVs. To avoid the upfront cost in terms of finance\nand energy, this paper analyzes the capability of UAV access points (UAVAPs) to\nsatisfy the requirements for cyber-physical traffic. To investigate this, we\nperform a Gilbert-Eliott burst-error analysis that is analytically derived as a\ncombination of two separate latency measurement campaigns and provide an\nupper-bound analysis of the UAVAP system. The analysis is centered around a\nUAVAP that uses its LTE connection to reach the backhaul, while providing\nservice to ground nodes (GNs) with a Wi-Fi access point (AP). Thus, we combine\nboth measurement campaigns to analyze the plausibility of the described setup\nin casual, crowded or mixed network settings.",
    "descriptor": "\nComments: To be published in proceedings of VTC-fall 2022\n",
    "authors": [
      "Igor Donevski",
      "Jimmy Jessen Nielsen"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.12249"
  },
  {
    "id": "arXiv:2211.12250",
    "title": "Efficient Frequency Domain-based Transformers for High-Quality Image  Deblurring",
    "abstract": "We present an effective and efficient method that explores the properties of\nTransformers in the frequency domain for high-quality image deblurring. Our\nmethod is motivated by the convolution theorem that the correlation or\nconvolution of two signals in the spatial domain is equivalent to an\nelement-wise product of them in the frequency domain. This inspires us to\ndevelop an efficient frequency domain-based self-attention solver (FSAS) to\nestimate the scaled dot-product attention by an element-wise product operation\ninstead of the matrix multiplication in the spatial domain. In addition, we\nnote that simply using the naive feed-forward network (FFN) in Transformers\ndoes not generate good deblurred results. To overcome this problem, we propose\na simple yet effective discriminative frequency domain-based FFN (DFFN), where\nwe introduce a gated mechanism in the FFN based on the Joint Photographic\nExperts Group (JPEG) compression algorithm to discriminatively determine which\nlow- and high-frequency information of the features should be preserved for\nlatent clear image restoration. We formulate the proposed FSAS and DFFN into an\nasymmetrical network based on an encoder and decoder architecture, where the\nFSAS is only used in the decoder module for better image deblurring.\nExperimental results show that the proposed method performs favorably against\nthe state-of-the-art approaches. Code will be available at\n\\url{https://github.com/kkkls/FFTformer}.",
    "descriptor": "\nComments: Code will be available at \\url{this https URL}\n",
    "authors": [
      "Lingshun Kong",
      "Jiangxin Dong",
      "Mingqiang Li",
      "Jianjun Ge",
      "Jinshan Pan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12250"
  },
  {
    "id": "arXiv:2211.12254",
    "title": "SPIn-NeRF: Multiview Segmentation and Perceptual Inpainting with Neural  Radiance Fields",
    "abstract": "Neural Radiance Fields (NeRFs) have emerged as a popular approach for novel\nview synthesis. While NeRFs are quickly being adapted for a wider set of\napplications, intuitively editing NeRF scenes is still an open challenge. One\nimportant editing task is the removal of unwanted objects from a 3D scene, such\nthat the replaced region is visually plausible and consistent with its context.\nWe refer to this task as 3D inpainting. In 3D, solutions must be both\nconsistent across multiple views and geometrically valid. In this paper, we\npropose a novel 3D inpainting method that addresses these challenges. Given a\nsmall set of posed images and sparse annotations in a single input image, our\nframework first rapidly obtains a 3D segmentation mask for a target object.\nUsing the mask, a perceptual optimizationbased approach is then introduced that\nleverages learned 2D image inpainters, distilling their information into 3D\nspace, while ensuring view consistency. We also address the lack of a diverse\nbenchmark for evaluating 3D scene inpainting methods by introducing a dataset\ncomprised of challenging real-world scenes. In particular, our dataset contains\nviews of the same scene with and without a target object, enabling more\nprincipled benchmarking of the 3D inpainting task. We first demonstrate the\nsuperiority of our approach on multiview segmentation, comparing to NeRFbased\nmethods and 2D segmentation approaches. We then evaluate on the task of 3D\ninpainting, establishing state-ofthe-art performance against other NeRF\nmanipulation algorithms, as well as a strong 2D image inpainter baseline",
    "descriptor": "\nComments: Project Page: this https URL\n",
    "authors": [
      "Ashkan Mirzaei",
      "Tristan Aumentado-Armstrong",
      "Konstantinos G. Derpanis",
      "Jonathan Kelly",
      "Marcus A. Brubaker",
      "Igor Gilitschenski",
      "Alex Levinshtein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12254"
  },
  {
    "id": "arXiv:2211.12256",
    "title": "VBLC: Visibility Boosting and Logit-Constraint Learning for Domain  Adaptive Semantic Segmentation under Adverse Conditions",
    "abstract": "Generalizing models trained on normal visual conditions to target domains\nunder adverse conditions is demanding in the practical systems. One prevalent\nsolution is to bridge the domain gap between clear- and adverse-condition\nimages to make satisfactory prediction on the target. However, previous methods\noften reckon on additional reference images of the same scenes taken from\nnormal conditions, which are quite tough to collect in reality. Furthermore,\nmost of them mainly focus on individual adverse condition such as nighttime or\nfoggy, weakening the model versatility when encountering other adverse\nweathers. To overcome the above limitations, we propose a novel framework,\nVisibility Boosting and Logit-Constraint learning (VBLC), tailored for superior\nnormal-to-adverse adaptation. VBLC explores the potential of getting rid of\nreference images and resolving the mixture of adverse conditions\nsimultaneously. In detail, we first propose the visibility boost module to\ndynamically improve target images via certain priors in the image level. Then,\nwe figure out the overconfident drawback in the conventional cross-entropy loss\nfor self-training method and devise the logit-constraint learning, which\nenforces a constraint on logit outputs during training to mitigate this pain\npoint. To the best of our knowledge, this is a new perspective for tackling\nsuch a challenging task. Extensive experiments on two normal-to-adverse domain\nadaptation benchmarks, i.e., Cityscapes -> ACDC and Cityscapes ->\nFoggyCityscapes + RainCityscapes, verify the effectiveness of VBLC, where it\nestablishes the new state of the art. Code is available at\nhttps://github.com/BIT-DA/VBLC.",
    "descriptor": "\nComments: Camera ready for AAAI 2023. Code is available at this https URL\n",
    "authors": [
      "Mingjia Li",
      "Binhui Xie",
      "Shuang Li",
      "Chi Harold Liu",
      "Xinjing Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12256"
  },
  {
    "id": "arXiv:2211.12265",
    "title": "High-Throughput GPU Implementation of Dilithium Post-Quantum Digital  Signature",
    "abstract": "In this work, we present a well-optimized GPU implementation of Dilithium,\none of the NIST post-quantum standard digital signature algorithms. We focus on\nwarp-level design and exploit several strategies to improve performance,\nincluding memory pool, kernel fusing, batching, streaming, etc. All the above\nefforts lead to an efficient and high-throughput solution. We profile on both\ndesktop and server-grade GPUs, and achieve up to 57.7$\\times$, 93.0$\\times$,\nand 63.1$\\times$ higher throughput on RTX 3090Ti for key generation, signing,\nand verification, respectively, compared to single-thread CPU. Additionally, we\nstudy the performance in real-world applications to demonstrate the\neffectiveness and applicability of our solution.",
    "descriptor": "",
    "authors": [
      "Shiyu Shen",
      "Hao Yang",
      "Wangchen Dai",
      "Zhe Liu",
      "Yunlei Zhao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.12265"
  },
  {
    "id": "arXiv:2211.12266",
    "title": "Relation-dependent Contrastive Learning with Cluster Sampling for  Inductive Relation Prediction",
    "abstract": "Relation prediction is a task designed for knowledge graph completion which\naims to predict missing relationships between entities. Recent subgraph-based\nmodels for inductive relation prediction have received increasing attention,\nwhich can predict relation for unseen entities based on the extracted subgraph\nsurrounding the candidate triplet. However, they are not completely inductive\nbecause of their disability of predicting unseen relations. Moreover, they fail\nto pay sufficient attention to the role of relation as they only depend on the\nmodel to learn parameterized relation embedding, which leads to inaccurate\nprediction on long-tail relations. In this paper, we introduce\nRelation-dependent Contrastive Learning (ReCoLe) for inductive relation\nprediction, which adapts contrastive learning with a novel sampling method\nbased on clustering algorithm to enhance the role of relation and improve the\ngeneralization ability to unseen relations. Instead of directly learning\nembedding for relations, ReCoLe allocates a pre-trained GNN-based encoder to\neach relation to strengthen the influence of relation. The GNN-based encoder is\noptimized by contrastive learning, which ensures satisfactory performance on\nlong-tail relations. In addition, the cluster sampling method equips ReCoLe\nwith the ability to handle both unseen relations and entities. Experimental\nresults suggest that ReCoLe outperforms state-of-the-art methods on commonly\nused inductive datasets.",
    "descriptor": "",
    "authors": [
      "Jianfeng Wu",
      "Sijie Mai",
      "Haifeng Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.12266"
  },
  {
    "id": "arXiv:2211.12268",
    "title": "Out-of-Candidate Rectification for Weakly Supervised Semantic  Segmentation",
    "abstract": "Weakly supervised semantic segmentation is typically inspired by class\nactivation maps, which serve as pseudo masks with class-discriminative regions\nhighlighted. Although tremendous efforts have been made to recall precise and\ncomplete locations for each class, existing methods still commonly suffer from\nthe unsolicited Out-of-Candidate (OC) error predictions that not belongs to the\nlabel candidates, which could be avoidable since the contradiction with\nimage-level class tags is easy to be detected. In this paper, we develop a\ngroup ranking-based Out-of-Candidate Rectification (OCR) mechanism in a\nplug-and-play fashion. Firstly, we adaptively split the semantic categories\ninto In-Candidate (IC) and OC groups for each OC pixel according to their prior\nannotation correlation and posterior prediction correlation. Then, we derive a\ndifferentiable rectification loss to force OC pixels to shift to the IC group.\nIncorporating our OCR with seminal baselines (e.g., AffinityNet, SEAM,\nMCTformer), we can achieve remarkable performance gains on both Pascal VOC\n(+3.2%, +3.3%, +0.8% mIoU) and MS COCO (+1.0%, +1.3%, +0.5% mIoU) datasets with\nnegligible extra training overhead, which justifies the effectiveness and\ngenerality of our OCR.",
    "descriptor": "",
    "authors": [
      "Zesen Cheng",
      "Pengchong Qiao",
      "Kehan Li",
      "Siheng Li",
      "Pengxu Wei",
      "Xiangyang Ji",
      "Li Yuan",
      "Chang Liu",
      "Jie Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12268"
  },
  {
    "id": "arXiv:2211.12270",
    "title": "Causal Abstraction with Soft Interventions",
    "abstract": "Causal abstraction provides a theory describing how several causal models can\nrepresent the same system at different levels of detail. Existing theoretical\nproposals limit the analysis of abstract models to \"hard\" interventions fixing\ncausal variables to be constant values. In this work, we extend causal\nabstraction to \"soft\" interventions, which assign possibly non-constant\nfunctions to variables without adding new causal connections. Specifically, (i)\nwe generalize $\\tau$-abstraction from Beckers and Halpern (2019) to soft\ninterventions, (ii) we propose a further definition of soft abstraction to\nensure a unique map $\\omega$ between soft interventions, and (iii) we prove\nthat our constructive definition of soft abstraction guarantees the\nintervention map $\\omega$ has a specific and necessary explicit form.",
    "descriptor": "",
    "authors": [
      "Riccardo Massidda",
      "Atticus Geiger",
      "Thomas Icard",
      "Davide Bacciu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12270"
  },
  {
    "id": "arXiv:2211.12271",
    "title": "Global $k$-means$++$: an effective relaxation of the global $k$-means  clustering algorithm",
    "abstract": "The $k$-means algorithm is a very prevalent clustering method because of its\nsimplicity, effectiveness, and speed, but its main disadvantage is its high\nsensitivity to the initial positions of the cluster centers. The global\n$k$-means is a deterministic algorithm proposed to tackle the random\ninitialization problem of k-means but requires high computational cost. It\npartitions the data to $K$ clusters by solving all $k$-means sub-problems\nincrementally for $k=1,\\ldots, K$. For each $k$ cluster problem, the method\nexecutes the $k$-means algorithm $N$ times, where $N$ is the number of data\npoints. In this paper, we propose the global $k$-means$++$ clustering\nalgorithm, which is an effective way of acquiring quality clustering solutions\nakin to those of global $k$-means with a reduced computational load. This is\nachieved by exploiting the center section probability that is used in the\neffective $k$-means$++$ algorithm. The proposed method has been tested and\ncompared in various well-known real and synthetic datasets yielding very\nsatisfactory results in terms of clustering quality and execution speed.",
    "descriptor": "",
    "authors": [
      "Georgios Vardakas",
      "Aristidis Likas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12271"
  },
  {
    "id": "arXiv:2211.12277",
    "title": "Semantic Guided Level-Category Hybrid Prediction Network for  Hierarchical Image Classification",
    "abstract": "Hierarchical classification (HC) assigns each object with multiple labels\norganized into a hierarchical structure. The existing deep learning based HC\nmethods usually predict an instance starting from the root node until a leaf\nnode is reached. However, in the real world, images interfered by noise,\nocclusion, blur, or low resolution may not provide sufficient information for\nthe classification at subordinate levels. To address this issue, we propose a\nnovel semantic guided level-category hybrid prediction network (SGLCHPN) that\ncan jointly perform the level and category prediction in an end-to-end manner.\nSGLCHPN comprises two modules: a visual transformer that extracts feature\nvectors from the input images, and a semantic guided cross-attention module\nthat uses categories word embeddings as queries to guide learning\ncategory-specific representations. In order to evaluate the proposed method, we\nconstruct two new datasets in which images are at a broad range of quality and\nthus are labeled to different levels (depths) in the hierarchy according to\ntheir individual quality. Experimental results demonstrate the effectiveness of\nour proposed HC method.",
    "descriptor": "\nComments: 3 figures\n",
    "authors": [
      "Peng Wang",
      "Jingzhou Chen",
      "Yuntao Qian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12277"
  },
  {
    "id": "arXiv:2211.12280",
    "title": "Transformer Based Multi-Grained Features for Unsupervised Person  Re-Identification",
    "abstract": "Multi-grained features extracted from convolutional neural networks (CNNs)\nhave demonstrated their strong discrimination ability in supervised person\nre-identification (Re-ID) tasks. Inspired by them, this work investigates the\nway of extracting multi-grained features from a pure transformer network to\naddress the unsupervised Re-ID problem that is label-free but much more\nchallenging. To this end, we build a dual-branch network architecture based\nupon a modified Vision Transformer (ViT). The local tokens output in each\nbranch are reshaped and then uniformly partitioned into multiple stripes to\ngenerate part-level features, while the global tokens of two branches are\naveraged to produce a global feature. Further, based upon offline-online\nassociated camera-aware proxies (O2CAP) that is a top-performing unsupervised\nRe-ID method, we define offline and online contrastive learning losses with\nrespect to both global and part-level features to conduct unsupervised\nlearning. Extensive experiments on three person Re-ID datasets show that the\nproposed method outperforms state-of-the-art unsupervised methods by a\nconsiderable margin, greatly mitigating the gap to supervised counterparts.\nCode will be available soon at https://github.com/RikoLi/WACV23-workshop-TMGF.",
    "descriptor": "\nComments: Accepted by WACVW 2023, 3rd Workshop on Real-World Surveillance: Applications and Challenges\n",
    "authors": [
      "Jiachen Li",
      "Menglin Wang",
      "Xiaojin Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12280"
  },
  {
    "id": "arXiv:2211.12281",
    "title": "BESS: Balanced Entity Sampling and Sharing for Large-Scale Knowledge  Graph Completion",
    "abstract": "We present the award-winning submission to the WikiKG90Mv2 track of\nOGB-LSC@NeurIPS 2022. The task is link-prediction on the large-scale knowledge\ngraph WikiKG90Mv2, consisting of 90M+ nodes and 600M+ edges. Our solution uses\na diverse ensemble of $85$ Knowledge Graph Embedding models combining five\ndifferent scoring functions (TransE, TransH, RotatE, DistMult, ComplEx) and two\ndifferent loss functions (log-sigmoid, sampled softmax cross-entropy). Each\nindividual model is trained in parallel on a Graphcore Bow Pod$_{16}$ using\nBESS (Balanced Entity Sampling and Sharing), a new distribution framework for\nKGE training and inference based on balanced collective communications between\nworkers. Our final model achieves a validation MRR of 0.2922 and a\ntest-challenge MRR of 0.2562, winning the first place in the competition. The\ncode is publicly available at:\nhttps://github.com/graphcore/distributed-kge-poplar/tree/2022-ogb-submission.",
    "descriptor": "\nComments: First place in the WikiKG90Mv2 track of the Open Graph Benchmark Large-Scale Challenge @NeurIPS2022\n",
    "authors": [
      "Alberto Cattaneo",
      "Daniel Justus",
      "Harry Mellor",
      "Douglas Orr",
      "Jerome Maloberti",
      "Zhenying Liu",
      "Thorin Farnsworth",
      "Andrew Fitzgibbon",
      "Blazej Banaszewski",
      "Carlo Luschi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12281"
  },
  {
    "id": "arXiv:2211.12285",
    "title": "Exact-NeRF: An Exploration of a Precise Volumetric Parameterization for  Neural Radiance Fields",
    "abstract": "Neural Radiance Fields (NeRF) have attracted significant attention due to\ntheir ability to synthesize novel scene views with great accuracy. However,\ninherent to their underlying formulation, the sampling of points along a ray\nwith zero width may result in ambiguous representations that lead to further\nrendering artifacts such as aliasing in the final scene. To address this issue,\nthe recent variant mip-NeRF proposes an Integrated Positional Encoding (IPE)\nbased on a conical view frustum. Although this is expressed with an integral\nformulation, mip-NeRF instead approximates this integral as the expected value\nof a multivariate Gaussian distribution. This approximation is reliable for\nshort frustums but degrades with highly elongated regions, which arises when\ndealing with distant scene objects under a larger depth of field. In this\npaper, we explore the use of an exact approach for calculating the IPE by using\na pyramid-based integral formulation instead of an approximated conical-based\none. We denote this formulation as Exact-NeRF and contribute the first approach\nto offer a precise analytical solution to the IPE within the NeRF domain. Our\nexploratory work illustrates that such an exact formulation Exact-NeRF matches\nthe accuracy of mip-NeRF and furthermore provides a natural extension to more\nchallenging scenarios without further modification, such as in the case of\nunbounded scenes. Our contribution aims to both address the hitherto unexplored\nissues of frustum approximation in earlier NeRF work and additionally provide\ninsight into the potential future consideration of analytical solutions in\nfuture NeRF extensions.",
    "descriptor": "\nComments: 15 pages,10 figures\n",
    "authors": [
      "Brian K. S. Isaac-Medina",
      "Chris G. Willcocks",
      "Toby P. Breckon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.12285"
  },
  {
    "id": "arXiv:2211.12286",
    "title": "Breaking Free from Fusion Rule: A Fully Semantic-driven Infrared and  Visible Image Fusion",
    "abstract": "Infrared and visible image fusion plays a vital role in the field of computer\nvision. Previous approaches make efforts to design various fusion rules in the\nloss functions. However, these experimental designed fusion rules make the\nmethods more and more complex. Besides, most of them only focus on boosting the\nvisual effects, thus showing unsatisfactory performance for the follow-up\nhigh-level vision tasks. To address these challenges, in this letter, we\ndevelop a semantic-level fusion network to sufficiently utilize the semantic\nguidance, emancipating the experimental designed fusion rules. In addition, to\nachieve a better semantic understanding of the feature fusion process, a fusion\nblock based on the transformer is presented in a multi-scale manner. Moreover,\nwe devise a regularization loss function, together with a training strategy, to\nfully use semantic guidance from the high-level vision tasks. Compared with\nstate-of-the-art methods, our method does not depend on the hand-crafted fusion\nloss function. Still, it achieves superior performance on visual quality along\nwith the follow-up high-level vision tasks.",
    "descriptor": "",
    "authors": [
      "Yuhui Wu",
      "Zhu Liu",
      "Jinyuan Liu",
      "Xin Fan",
      "Risheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12286"
  },
  {
    "id": "arXiv:2211.12287",
    "title": "RiSi: Spectro-temporal RAN-agnostic Modulation Identification for OFDMA  Signals",
    "abstract": "Blind modulation identification is essential for 6G's RAN-agnostic\ncommunications, which identifies the modulation type of an incompatible\nwireless signal without any prior knowledge. Nowadays, research on blind\nmodulation identification relies on deep convolutional networks that deal with\na received signal's raw I/Q samples, but they mostly are limited to\nsingle-carrier signal recognition thus not pragmatic for identifying\nspectro-temporal OFDM/OFDMA signals whose modulation varies with time and\nfrequency. Therefore, this paper proposes RiSi, a semantic segmentation neural\nnetwork designed to work on OFDMA's spectrograms, by replacing vanilla\nDeepLabV3+'s 2D convolutions with 'flattened' convolutions to enforce the\ntime-frequency orthogonality constraint and to achieve the grid-like pattern of\nOFDMA's resource blocks, and by introducing three-channel inputs consisting of\nI/Q/amplitude. Then, we synthesized a realistic and effective dataset\nconsisting of OFDMA signals with various channel impairments to train the\nproposed network. Moreover, we treated varying communication parameters as\ndifferent domains to apply domain generalization methods, to enhance our\nmodel's adaptability to diverse communication environments. Extensive\nevaluation shows that RiSi's modulation identification accuracy reaches 86%\naveraged over four modulation types (BPSK, QPSK, 16-QAM, 64-QAM), while its\ndomain generalization performance for unseen data has been also shown to be\nreliable.",
    "descriptor": "\nComments: 10 pages, 10 figures\n",
    "authors": [
      "Daulet Kurmantayev",
      "Dohyun Kwun",
      "Hyoil Kim",
      "Sung Whan Yoon"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.12287"
  },
  {
    "id": "arXiv:2211.12292",
    "title": "Gated Class-Attention with Cascaded Feature Drift Compensation for  Exemplar-free Continual Learning of Vision Transformers",
    "abstract": "In this paper we propose a new method for exemplar-free class incremental\ntraining of ViTs. The main challenge of exemplar-free continual learning is\nmaintaining plasticity of the learner without causing catastrophic forgetting\nof previously learned tasks. This is often achieved via exemplar replay which\ncan help recalibrate previous task classifiers to the feature drift which\noccurs when learning new tasks. Exemplar replay, however, comes at the cost of\nretaining samples from previous tasks which for some applications may not be\npossible. To address the problem of continual ViT training, we first propose\ngated class-attention to minimize the drift in the final ViT transformer block.\nThis mask-based gating is applied to class-attention mechanism of the last\ntransformer block and strongly regulates the weights crucial for previous\ntasks. Secondly, we propose a new method of feature drift compensation that\naccommodates feature drift in the backbone when learning new tasks. The\ncombination of gated class-attention and cascaded feature drift compensation\nallows for plasticity towards new tasks while limiting forgetting of previous\nones. Extensive experiments performed on CIFAR-100, Tiny-ImageNet and\nImageNet100 demonstrate that our method outperforms existing exemplar-free\nstate-of-the-art methods without the need to store any representative exemplars\nof past tasks.",
    "descriptor": "",
    "authors": [
      "Marco Cotogni",
      "Fei Yang",
      "Claudio Cusano",
      "Andrew D. Bagdanov",
      "Joost van de Weijer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12292"
  },
  {
    "id": "arXiv:2211.12294",
    "title": "PointCA: Evaluating the Robustness of 3D Point Cloud Completion Models  Against Adversarial Examples",
    "abstract": "Point cloud completion, as the upstream procedure of 3D recognition and\nsegmentation, has become an essential part of many tasks such as navigation and\nscene understanding. While various point cloud completion models have\ndemonstrated their powerful capabilities, their robustness against adversarial\nattacks, which have been proven to be fatally malicious towards deep neural\nnetworks, remains unknown. In addition, existing attack approaches towards\npoint cloud classifiers cannot be applied to the completion models due to\ndifferent output forms and attack purposes. In order to evaluate the robustness\nof the completion models, we propose PointCA, the first adversarial attack\nagainst 3D point cloud completion models. PointCA can generate adversarial\npoint clouds that maintain high similarity with the original ones, while being\ncompleted as another object with totally different semantic information.\nSpecifically, we minimize the representation discrepancy between the\nadversarial example and the target point set to jointly explore the adversarial\npoint clouds in the geometry space and the feature space. Furthermore, to\nlaunch a stealthier attack, we innovatively employ the neighbourhood density\ninformation to tailor the perturbation constraint, leading to geometry-aware\nand distribution-adaptive modifications for each point. Extensive experiments\nagainst different premier point cloud completion networks show that PointCA can\ncause a performance degradation from 77.9% to 16.7%, with the structure chamfer\ndistance kept below 0.01. We conclude that existing completion models are\nseverely vulnerable to adversarial examples, and state-of-the-art defenses for\npoint cloud classification will be partially invalid when applied to incomplete\nand uneven point cloud data.",
    "descriptor": "\nComments: Accepted by the 37th AAAI Conference on Artificial Intelligence (AAAI-23)\n",
    "authors": [
      "Shengshan Hu",
      "Junwei Zhang",
      "Wei Liu",
      "Junhui Hou",
      "Minghui Li",
      "Leo Yu Zhang",
      "Hai Jin",
      "Lichao Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.12294"
  },
  {
    "id": "arXiv:2211.12301",
    "title": "Is this correct? Let's check!",
    "abstract": "Societal accumulation of knowledge is a complex process. The correctness of\nnew units of knowledge depends not only on the correctness of new reasoning,\nbut also on the correctness of old units that the new one builds on. The errors\nin such accumulation processes are often remedied by error correction and\ndetection heuristics.\nMotivating examples include the scientific process based on scientific\npublications, and software development based on libraries of code.\nNatural processes that aim to keep errors under control, such as peer review\nin scientific publications, and testing and debugging in software development,\nwould typically check existing pieces of knowledge -- both for the reasoning\nthat generated them and the previous facts they rely on. In this work, we\npresent a simple process that models such accumulation of knowledge and study\nthe persistence (or lack thereof) of errors.\nWe consider a simple probabilistic model for the generation of new units of\nknowledge based on the preferential attachment growth model, which additionally\nallows for errors. Furthermore, the process includes checks aimed at catching\nthese errors. We investigate when effects of errors persist forever in the\nsystem (with positive probability) and when they get rooted out completely by\nthe checking process.\nThe two basic parameters associated with the checking process are the {\\em\nprobability} of conducting a check and the depth of the check. We show that\nerrors are rooted out if checks are sufficiently frequent and sufficiently\ndeep. In contrast, shallow or infrequent checks are insufficient to root out\nerrors.",
    "descriptor": "\nComments: 29 pages\n",
    "authors": [
      "Omri Ben-Eliezer",
      "Dan Mikulincer",
      "Elchanan Mossel",
      "Madhu Sudan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.12301"
  },
  {
    "id": "arXiv:2211.12311",
    "title": "Generalizable Industrial Visual Anomaly Detection with Self-Induction  Vision Transformer",
    "abstract": "Industrial vision anomaly detection plays a critical role in the advanced\nintelligent manufacturing process, while some limitations still need to be\naddressed under such a context. First, existing reconstruction-based methods\nstruggle with the identity mapping of trivial shortcuts where the\nreconstruction error gap is legible between the normal and abnormal samples,\nleading to inferior detection capabilities. Then, the previous studies mainly\nconcentrated on the convolutional neural network (CNN) models that capture the\nlocal semantics of objects and neglect the global context, also resulting in\ninferior performance. Moreover, existing studies follow the individual learning\nfashion where the detection models are only capable of one category of the\nproduct while the generalizable detection for multiple categories has not been\nexplored. To tackle the above limitations, we proposed a self-induction vision\nTransformer(SIVT) for unsupervised generalizable multi-category industrial\nvisual anomaly detection and localization. The proposed SIVT first extracts\ndiscriminatory features from pre-trained CNN as property descriptors. Then, the\nself-induction vision Transformer is proposed to reconstruct the extracted\nfeatures in a self-supervisory fashion, where the auxiliary induction tokens\nare additionally introduced to induct the semantics of the original signal.\nFinally, the abnormal properties can be detected using the semantic feature\nresidual difference. We experimented with the SIVT on existing Mvtec AD\nbenchmarks, the results reveal that the proposed method can advance\nstate-of-the-art detection performance with an improvement of 2.8-6.3 in AUROC,\nand 3.3-7.6 in AP.",
    "descriptor": "\nComments: 8 pages, 6 figures,\n",
    "authors": [
      "Haiming Yao",
      "Xue Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12311"
  },
  {
    "id": "arXiv:2211.12312",
    "title": "Interpreting Neural Networks through the Polytope Lens",
    "abstract": "Mechanistic interpretability aims to explain what a neural network has\nlearned at a nuts-and-bolts level. What are the fundamental primitives of\nneural network representations? Previous mechanistic descriptions have used\nindividual neurons or their linear combinations to understand the\nrepresentations a network has learned. But there are clues that neurons and\ntheir linear combinations are not the correct fundamental units of description:\ndirections cannot describe how neural networks use nonlinearities to structure\ntheir representations. Moreover, many instances of individual neurons and their\ncombinations are polysemantic (i.e. they have multiple unrelated meanings).\nPolysemanticity makes interpreting the network in terms of neurons or\ndirections challenging since we can no longer assign a specific feature to a\nneural unit. In order to find a basic unit of description that does not suffer\nfrom these problems, we zoom in beyond just directions to study the way that\npiecewise linear activation functions (such as ReLU) partition the activation\nspace into numerous discrete polytopes. We call this perspective the polytope\nlens. The polytope lens makes concrete predictions about the behavior of neural\nnetworks, which we evaluate through experiments on both convolutional image\nclassifiers and language models. Specifically, we show that polytopes can be\nused to identify monosemantic regions of activation space (while directions are\nnot in general monosemantic) and that the density of polytope boundaries\nreflect semantic boundaries. We also outline a vision for what mechanistic\ninterpretability might look like through the polytope lens.",
    "descriptor": "\nComments: 22/11/22 initial upload\n",
    "authors": [
      "Sid Black",
      "Lee Sharkey",
      "Leo Grinsztajn",
      "Eric Winsor",
      "Dan Braun",
      "Jacob Merizian",
      "Kip Parker",
      "Carlos Ram\u00f3n Guevara",
      "Beren Millidge",
      "Gabriel Alfour",
      "Connor Leahy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12312"
  },
  {
    "id": "arXiv:2211.12316",
    "title": "Simplicity Bias in Transformers and their Ability to Learn Sparse  Boolean Functions",
    "abstract": "Despite the widespread success of Transformers on NLP tasks, recent works\nhave found that they struggle to model several formal languages when compared\nto recurrent models. This raises the question of why Transformers perform well\nin practice and whether they have any properties that enable them to generalize\nbetter than recurrent models. In this work, we conduct an extensive empirical\nstudy on Boolean functions to demonstrate the following: (i) Random\nTransformers are relatively more biased towards functions of low sensitivity.\n(ii) When trained on Boolean functions, both Transformers and LSTMs prioritize\nlearning functions of low sensitivity, with Transformers ultimately converging\nto functions of lower sensitivity. (iii) On sparse Boolean functions which have\nlow sensitivity, we find that Transformers generalize near perfectly even in\nthe presence of noisy labels whereas LSTMs overfit and achieve poor\ngeneralization accuracy. Overall, our results provide strong quantifiable\nevidence that suggests differences in the inductive biases of Transformers and\nrecurrent models which may help explain Transformer's effective generalization\nperformance despite relatively limited expressiveness.",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Satwik Bhattamishra",
      "Arkil Patel",
      "Varun Kanade",
      "Phil Blunsom"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.12316"
  },
  {
    "id": "arXiv:2211.12318",
    "title": "A Categorical Normalization Proof for the Modal Lambda-Calculus",
    "abstract": "We investigate a simply typed modal $\\lambda$-calculus,\n$\\lambda^{\\to\\square}$, due to Pfenning, Wong and Davies, where we define a\nwell-typed term with respect to a context stack that captures the possible\nworld semantics in a syntactic way. It provides logical foundation for\nmulti-staged meta-programming. Our main contribution in this paper is a\nnormalization by evaluation (NbE) algorithm for $\\lambda^{\\to\\square}$ which we\nprove sound and complete. The NbE algorithm is a moderate extension to the\nstandard presheaf model of simply typed $\\lambda$-calculus. However, central to\nthe model construction and the NbE algorithm is the observation of Kripke-style\nsubstitutions on context stacks which brings together two previously separate\nconcepts, structural modal transformations on context stacks and substitutions\nfor individual assumptions. Moreover, Kripke-style substitutions allow us to\ngive a formulation for contextual types, which can represent open code in a\nmeta-programming setting. Our work lays the foundation for extending the\nlogical foundation by Pfenning, Wong, and Davies towards building a practical,\ndependently typed foundation for meta-programming.",
    "descriptor": "",
    "authors": [
      "Jason Z. S. Hu",
      "Brigitte Pientka"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.12318"
  },
  {
    "id": "arXiv:2211.12320",
    "title": "A Cross-Residual Learning for Image Recognition",
    "abstract": "ResNets and its variants play an important role in various fields of image\nrecognition. This paper gives another variant of ResNets, a kind of\ncross-residual learning networks called C-ResNets, which has less computation\nand parameters than ResNets. C-ResNets increases the information interaction\nbetween modules by densifying jumpers and enriches the role of jumpers. In\naddition, some meticulous designs on jumpers and channels counts can further\nreduce the resource consumption of C-ResNets and increase its classification\nperformance. In order to test the effectiveness of C-ResNets, we use the same\nhyperparameter settings as fine-tuned ResNets in the experiments.\nWe test our C-ResNets on datasets MNIST, FashionMnist, CIFAR-10, CIFAR-100,\nCALTECH-101 and SVHN. Compared with fine-tuned ResNets, C-ResNets not only\nmaintains the classification performance, but also enormously reduces the\namount of calculations and parameters which greatly save the utilization rate\nof GPUs and GPU memory resources. Therefore, our C-ResNets is competitive and\nviable alternatives to ResNets in various scenarios. Code is available at\nhttps://github.com/liangjunhello/C-ResNet",
    "descriptor": "\nComments: After being added into fine training tricks and several key components from the current SOTA, the performance of C-ResNet may can be greatly improved\n",
    "authors": [
      "Jun Liang",
      "Songsen Yu",
      "Huan Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12320"
  },
  {
    "id": "arXiv:2211.12322",
    "title": "TranViT: An Integrated Vision Transformer Framework for Discrete Transit  Travel Time Range Prediction",
    "abstract": "Accurate travel time estimation is paramount for providing transit users with\nreliable schedules and dependable real-time information. This paper proposes\nand evaluates a novel end-to-end framework for transit and roadside image data\nacquisition, labeling, and model training to predict transit travel times\nacross a segment of interest. General Transit Feed Specification (GTFS)\nreal-time data is used as an activation mechanism for a roadside camera unit\nmonitoring a segment of Massachusetts Avenue in Cambridge, MA. Ground truth\nlabels are generated for the acquired images dataset based on transit travel\ntime across the monitored segment acquired from Automated Vehicle Location\n(AVL) data. The generated labeled image dataset is then used to train and\nevaluate a Vision Transformer (ViT) model to predict a discrete transit travel\ntime range (band) based on the observed travel time percentiles. The results of\nthis exploratory study illustrate that the ViT model is able to learn image\nfeatures and contents that best help it deduce the expected travel time range\nwith an average validation accuracy ranging between 80%-85%. We also\ndemonstrate how this discrete travel time band prediction can subsequently be\nutilized to improve continuous transit travel time estimation. The workflow and\nresults presented in this study provide an end-to-end, scalable, automated, and\nhighly efficient approach for integrating traditional transit data sources and\nroadside imagery to estimate traffic states and predict transit travel\nduration, which can have major implications for improving operations and\npassenger real-time information.",
    "descriptor": "",
    "authors": [
      "Awad Abdelhalim",
      "Jinhua Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12322"
  },
  {
    "id": "arXiv:2211.12324",
    "title": "Pushing the Limits of Asynchronous Graph-based Object Detection with  Event Cameras",
    "abstract": "State-of-the-art machine-learning methods for event cameras treat events as\ndense representations and process them with conventional deep neural networks.\nThus, they fail to maintain the sparsity and asynchronous nature of event data,\nthereby imposing significant computation and latency constraints on downstream\nsystems. A recent line of work tackles this issue by modeling events as\nspatiotemporally evolving graphs that can be efficiently and asynchronously\nprocessed using graph neural networks. These works showed impressive\ncomputation reductions, yet their accuracy is still limited by the small scale\nand shallow depth of their network, both of which are required to reduce\ncomputation. In this work, we break this glass ceiling by introducing several\narchitecture choices which allow us to scale the depth and complexity of such\nmodels while maintaining low computation. On object detection tasks, our\nsmallest model shows up to 3.7 times lower computation, while outperforming\nstate-of-the-art asynchronous methods by 7.4 mAP. Even when scaling to larger\nmodel sizes, we are 13% more efficient than state-of-the-art while\noutperforming it by 11.5 mAP. As a result, our method runs 3.7 times faster\nthan a dense graph neural network, taking only 8.4 ms per forward pass. This\nopens the door to efficient, and accurate object detection in edge-case\nscenarios.",
    "descriptor": "",
    "authors": [
      "Daniel Gehrig",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12324"
  },
  {
    "id": "arXiv:2211.12326",
    "title": "PreMa: Predictive Maintenance of Solenoid Valve in Real-Time at Embedded  Edge-Level",
    "abstract": "In industrial process automation, sensors (pressure, temperature, etc.),\ncontrollers, and actuators (solenoid valves, electro-mechanical relays, circuit\nbreakers, motors, etc.) make sure that production lines are working under the\npre-defined conditions. When these systems malfunction or sometimes completely\nfail, alerts have to be generated in real-time to make sure not only production\nquality is not compromised but also safety of humans and equipment is assured.\nIn this work, we describe the construction of a smart and real-time edge-based\nelectronic product called PreMa, which is basically a sensor for monitoring the\nhealth of a Solenoid Valve (SV). PreMa is compact, low power, easy to install,\nand cost effective. It has data fidelity and measurement accuracy comparable to\nsignals captured using high end equipment. The smart solenoid sensor runs\nTinyML, a compact version of TensorFlow (a.k.a. TFLite) machine learning\nframework. While fault detection inferencing is in-situ, model training uses\nmobile phones to accomplish the `on-device' training. Our product evaluation\nshows that the sensor is able to differentiate between the distinct types of\nfaults. These faults include: (a) Spool stuck (b) Spring failure and (c) Under\nvoltage. Furthermore, the product provides maintenance personnel, the remaining\nuseful life (RUL) of the SV. The RUL provides assistance to decide valve\nreplacement or otherwise. We perform an extensive evaluation on optimizing\nmetrics related to performance of the entire system (i.e. embedded platform and\nthe neural network model). The proposed implementation is such that, given any\nelectro-mechanical actuator with similar transient response to that of the SV,\nthe system is capable of condition monitoring, hence presenting a first of its\nkind generic infrastructure.",
    "descriptor": "",
    "authors": [
      "Prajwal BN",
      "Harsha Yelchuri",
      "Vishwanath Shastry",
      "T. V. Prabhakar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12326"
  },
  {
    "id": "arXiv:2211.12328",
    "title": "A survey on knowledge-enhanced multimodal learning",
    "abstract": "Multimodal learning has been a field of increasing interest, aiming to\ncombine various modalities in a single joint representation. Especially in the\narea of visiolinguistic (VL) learning multiple models and techniques have been\ndeveloped, targeting a variety of tasks that involve images and text. VL models\nhave reached unprecedented performances by extending the idea of Transformers,\nso that both modalities can learn from each other. Massive pre-training\nprocedures enable VL models to acquire a certain level of real-world\nunderstanding, although many gaps can be identified: the limited comprehension\nof commonsense, factual, temporal and other everyday knowledge aspects\nquestions the extendability of VL tasks. Knowledge graphs and other knowledge\nsources can fill those gaps by explicitly providing missing information,\nunlocking novel capabilities of VL models. In the same time, knowledge graphs\nenhance explainability, fairness and validity of decision making, issues of\noutermost importance for such complex implementations. The current survey aims\nto unify the fields of VL representation learning and knowledge graphs, and\nprovides a taxonomy and analysis of knowledge-enhanced VL models.",
    "descriptor": "",
    "authors": [
      "Maria Lymperaiou",
      "Giorgos Stamou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12328"
  },
  {
    "id": "arXiv:2211.12334",
    "title": "A Graph-Based Method for Soccer Action Spotting Using Unsupervised  Player Classification",
    "abstract": "Action spotting in soccer videos is the task of identifying the specific time\nwhen a certain key action of the game occurs. Lately, it has received a large\namount of attention and powerful methods have been introduced. Action spotting\ninvolves understanding the dynamics of the game, the complexity of events, and\nthe variation of video sequences. Most approaches have focused on the latter,\ngiven that their models exploit the global visual features of the sequences. In\nthis work, we focus on the former by (a) identifying and representing the\nplayers, referees, and goalkeepers as nodes in a graph, and by (b) modeling\ntheir temporal interactions as sequences of graphs. For the player\nidentification, or player classification task, we obtain an accuracy of 97.72%\nin our annotated benchmark. For the action spotting task, our method obtains an\noverall performance of 57.83% average-mAP by combining it with other\naudiovisual modalities. This performance surpasses similar graph-based methods\nand has competitive results with heavy computing methods. Code and data are\navailable at https://github.com/IPCV/soccer_action_spotting.",
    "descriptor": "\nComments: Accepted at the 5th International ACM Workshop on Multimedia Content Analysis in Sports (MMSports 2022)\n",
    "authors": [
      "Alejandro Cartas",
      "Coloma Ballester",
      "Gloria Haro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.12334"
  },
  {
    "id": "arXiv:2211.12337",
    "title": "Quality-diversity in dissimilarity spaces",
    "abstract": "The theory of magnitude provides a mathematical framework for quantifying and\nmaximizing diversity. We apply this framework to formulate quality-diversity\nalgorithms in generic dissimilarity spaces. In particular, we instantiate and\ndemonstrate a very general version of Go-Explore with promising performance.",
    "descriptor": "",
    "authors": [
      "Steve Huntsman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.12337"
  },
  {
    "id": "arXiv:2211.12339",
    "title": "Neural Dependencies Emerging from Learning Massive Categories",
    "abstract": "This work presents two astonishing findings on neural networks learned for\nlarge-scale image classification. 1) Given a well-trained model, the logits\npredicted for some category can be directly obtained by linearly combining the\npredictions of a few other categories, which we call \\textbf{neural\ndependency}. 2) Neural dependencies exist not only within a single model, but\neven between two independently learned models, regardless of their\narchitectures. Towards a theoretical analysis of such phenomena, we demonstrate\nthat identifying neural dependencies is equivalent to solving the Covariance\nLasso (CovLasso) regression problem proposed in this paper. Through\ninvestigating the properties of the problem solution, we confirm that neural\ndependency is guaranteed by a redundant logit covariance matrix, which\ncondition is easily met given massive categories, and that neural dependency is\nhighly sparse, implying that one category correlates to only a few others. We\nfurther empirically show the potential of neural dependencies in understanding\ninternal data correlations, generalizing models to unseen categories, and\nimproving model robustness with a dependency-derived regularizer. Code for this\nwork will be made publicly available.",
    "descriptor": "",
    "authors": [
      "Ruili Feng",
      "Kecheng Zheng",
      "Kai Zhu",
      "Yujun Shen",
      "Jian Zhao",
      "Yukun Huang",
      "Deli Zhao",
      "Jingren Zhou",
      "Michael Jordan",
      "Zheng-Jun Zha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12339"
  },
  {
    "id": "arXiv:2211.12343",
    "title": "Diffusion Model Based Posterior Sampling for Noisy Linear Inverse  Problems",
    "abstract": "We consider the ubiquitous linear inverse problems with additive Gaussian\nnoise and propose an unsupervised general-purpose sampling approach called\ndiffusion model based posterior sampling (DMPS) to reconstruct the unknown\nsignal from noisy linear measurements. Specifically, the prior of the unknown\nsignal is implicitly modeled by one pre-trained diffusion model (DM). In\nposterior sampling, to address the intractability of exact noise-perturbed\nlikelihood score, a simple yet effective noise-perturbed pseudo-likelihood\nscore is introduced under the uninformative prior assumption. While DMPS\napplies to any kind of DM with proper modifications, we focus on the ablated\ndiffusion model (ADM) as one specific example and evaluate its efficacy on a\nvariety of linear inverse problems such as image super-resolution, denoising,\ndeblurring, colorization. Experimental results demonstrate that, for both\nin-distribution and out-of-distribution samples, DMPS achieves highly\ncompetitive or even better performances on various tasks while being 3 times\nfaster than the leading competitor. The code to reproduce the results is\navailable at https://github.com/mengxiangming/dmps.",
    "descriptor": "\nComments: 20 pages. The code is available at this https URL\n",
    "authors": [
      "Xiangming Meng",
      "Yoshiyuki Kabashima"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12343"
  },
  {
    "id": "arXiv:2211.12345",
    "title": "Learning Deep Neural Networks by Iterative Linearisation",
    "abstract": "The excellent real-world performance of deep neural networks has received\nincreasing attention. Despite the capacity to overfit significantly, such large\nmodels work better than smaller ones. This phenomenon is often referred to as\nthe scaling law by practitioners. It is of fundamental interest to study why\nthe scaling law exists and how it avoids/controls overfitting. One approach has\nbeen looking at infinite width limits of neural networks (e.g., Neural Tangent\nKernels, Gaussian Processes); however, in practise, these do not fully explain\nfinite networks as their infinite counterparts do not learn features.\nFurthermore, the empirical kernel for finite networks (i.e., the inner product\nof feature vectors), changes significantly during training in contrast to\ninfinite width networks. In this work we derive an iterative linearised\ntraining method. We justify iterative lineralisation as an interpolation\nbetween finite analogs of the infinite width regime, which do not learn\nfeatures, and standard gradient descent training which does. We show some\npreliminary results where iterative linearised training works well, noting in\nparticular how much feature learning is required to achieve comparable\nperformance. We also provide novel insights into the training behaviour of\nneural networks.",
    "descriptor": "",
    "authors": [
      "Adrian Goldwaser",
      "Hong Ge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.12345"
  },
  {
    "id": "arXiv:2211.12347",
    "title": "The Euclidean Space is Evil: Hyperbolic Attribute Editing for Few-shot  Image Generation",
    "abstract": "Few-shot image generation is a challenging task since it aims to generate\ndiverse new images for an unseen category with only a few images. Existing\nmethods suffer from the trade-off between the quality and diversity of\ngenerated images. To tackle this problem, we propose Hyperbolic Attribute\nEditing (HAE), a simple yet effective method. Unlike other methods that work in\nEuclidean space, HAE captures the hierarchy among images using data from seen\ncategories in hyperbolic space. Given a well-trained HAE, images of unseen\ncategories can be generated by moving the latent code of a given image toward\nany meaningful directions in the Poincar\\'e disk with a fixing radius. Most\nimportantly, the hyperbolic space allows us to control the semantic diversity\nof the generated images by setting different radii in the disk. Extensive\nexperiments and visualizations demonstrate that HAE is capable of not only\ngenerating images with promising quality and diversity using limited data but\nachieving a highly controllable and interpretable editing process.",
    "descriptor": "",
    "authors": [
      "Lingxiao Li",
      "Yi Zhang",
      "Shuhui Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12347"
  },
  {
    "id": "arXiv:2211.12352",
    "title": "GlowGAN: Unsupervised Learning of HDR Images from LDR Images in the Wild",
    "abstract": "Most in-the-wild images are stored in Low Dynamic Range (LDR) form, serving\nas a partial observation of the High Dynamic Range (HDR) visual world. Despite\nlimited dynamic range, these LDR images are often captured with different\nexposures, implicitly containing information about the underlying HDR image\ndistribution. Inspired by this intuition, in this work we present, to the best\nof our knowledge, the first method for learning a generative model of HDR\nimages from in-the-wild LDR image collections in a fully unsupervised manner.\nThe key idea is to train a generative adversarial network (GAN) to generate HDR\nimages which, when projected to LDR under various exposures, are\nindistinguishable from real LDR images. The projection from HDR to LDR is\nachieved via a camera model that captures the stochasticity in exposure and\ncamera response function. Experiments show that our method GlowGAN can\nsynthesize photorealistic HDR images in many challenging cases such as\nlandscapes, lightning, or windows, where previous supervised generative models\nproduce overexposed images. We further demonstrate the new application of\nunsupervised inverse tone mapping (ITM) enabled by GlowGAN. Our ITM method does\nnot need HDR images or paired multi-exposure images for training, yet it\nreconstructs more plausible information for overexposed regions than\nstate-of-the-art supervised learning models trained on such data.",
    "descriptor": "",
    "authors": [
      "Chao Wang",
      "Ana Serrano",
      "Xingang Pan",
      "Bin Chen",
      "Hans-Peter Seidel",
      "Christian Theobalt",
      "Karol Myszkowski",
      "Thomas Leimkuehler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.12352"
  },
  {
    "id": "arXiv:2211.12353",
    "title": "U-Flow: A U-shaped Normalizing Flow for Anomaly Detection with  Unsupervised Threshold",
    "abstract": "In this work we propose a non-contrastive method for anomaly detection and\nsegmentation in images, that benefits both from a modern machine learning\napproach and a more classic statistical detection theory. The method consists\nof three phases. First, features are extracted by making use of a multi-scale\nimage Transformer architecture. Then, these features are fed into a U-shaped\nNormalizing Flow that lays the theoretical foundations for the last phase,\nwhich computes a pixel-level anomaly map, and performs a segmentation based on\nthe a contrario framework. This multiple hypothesis testing strategy permits to\nderive a robust automatic detection threshold, which is key in many real-world\napplications, where an operational point is needed. The segmentation results\nare evaluated using the Intersection over Union (IoU) metric, and for assessing\nthe generated anomaly maps we report the area under the Receiver Operating\nCharacteristic curve (ROC-AUC) at both image and pixel level. For both metrics,\nthe proposed approach produces state-of-the-art results, ranking first in most\nMvTec-AD categories, with a mean pixel-level ROC- AUC of 98.74%. Code and\ntrained models are available at https://github.com/mtailanian/uflow.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Mat\u00edas Tailanian",
      "\u00c1lvaro Pardo",
      "Pablo Mus\u00e9"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12353"
  },
  {
    "id": "arXiv:2211.12354",
    "title": "Resource Allocation for Uplink Cell-Free Massive MIMO enabled URLLC in a  Smart Factory",
    "abstract": "Smart factories need to support the simultaneous communication of multiple\nindustrial Internet-of-Things (IIoT) devices with ultra-reliability and\nlow-latency communication (URLLC). Meanwhile, short packet transmission for\nIIoT applications incurs performance loss compared to traditional long packet\ntransmission for human-to-human communications. On the other hand, cell-free\nmassive multiple-input and multiple-output (CF mMIMO) technology can provide\nuniform services for all devices by deploying distributed access points (APs).\nIn this paper, we adopt CF mMIMO to support URLLC in a smart factory.\nSpecifically, we first derive the lower bound (LB) on achievable uplink data\nrate under the finite blocklength (FBL) with imperfect channel state\ninformation (CSI) for both maximum-ratio combining (MRC) and full-pilot\nzero-forcing (FZF) decoders. \\textcolor{black}{The derived LB rates based on\nthe MRC case have the same trends as the ergodic rate, while LB rates using the\nFZF decoder tightly match the ergodic rates}, which means that resource\nallocation can be performed based on the LB data rate rather the exact ergodic\ndata rate under FBL. The \\textcolor{black}{log-function method} and successive\nconvex approximation (SCA) are then used to approximately transform the\nnon-convex weighted sum rate problem into a series of geometric program (GP)\nproblems, and an iterative algorithm is proposed to jointly optimize the pilot\nand payload power allocation. Simulation results demonstrate that CF mMIMO\nsignificantly improves the average weighted sum rate (AWSR) compared to\ncentralized mMIMO. An interesting observation is that increasing the number of\ndevices improves the AWSR for CF mMIMO whilst the AWSR remains relatively\nconstant for centralized mMIMO.",
    "descriptor": "\nComments: Accepted by Transactions on Communications\n",
    "authors": [
      "Qihao Peng",
      "Hong Ren",
      "Cunhua Pan",
      "Nan Liu",
      "Maged Elkashlan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.12354"
  },
  {
    "id": "arXiv:2211.12358",
    "title": "Unsourced Random Access with Threshold$-$Based Feedback",
    "abstract": "In this paper we focus on a feedback mechanism for unsourced random access\n(URA) communications. We propose an algorithm to construct feedback packets\nbroadcasted to the users by the base station (BS) as well as the feedback\npacket format that allows the users to estimate their channels and infer\npositive or negative feedback based on the presented thresholding algorithm. We\ndemonstrate that the proposed feedback imposes a much smaller complexity burden\non the users compared to the feedback that positively acknowledges all\nsuccessful or negatively acknowledges all undecoded users. We also show that\nthe proposed feedback technique can lead to a substantial reduction in the\npacket error rates and signal-to-noise ratios (SNR)s required to support\nvarious numbers of active users in the system.",
    "descriptor": "",
    "authors": [
      "Murwan Bashir",
      "Ehsan Nassaji",
      "Dmitri Truhachev",
      "Alireza Bayesteh",
      "Monirosharieh Vameghestahbanati"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.12358"
  },
  {
    "id": "arXiv:2211.12360",
    "title": "GDPR Compliant Collection of Therapist-Patient-Dialogues",
    "abstract": "According to the Global Burden of Disease list provided by the World Health\nOrganization (WHO), mental disorders are among the most debilitating\ndisorders.To improve the diagnosis and the therapy effectiveness in recent\nyears, researchers have tried to identify individual biomarkers. Gathering\nneurobiological data however, is costly and time-consuming. Another potential\nsource of information, which is already part of the clinical routine, are\ntherapist-patient dialogues. While there are some pioneering works\ninvestigating the role of language as predictors for various therapeutic\nparameters, for example patient-therapist alliance, there are no large-scale\nstudies. A major obstacle to conduct these studies is the availability of\nsizeable datasets, which are needed to train machine learning models. While\nthese conversations are part of the daily routine of clinicians, gathering them\nis usually hindered by various ethical (purpose of data usage), legal (data\nprivacy) and technical (data formatting) limitations. Some of these limitations\nare particular to the domain of therapy dialogues, like the increased\ndifficulty in anonymisation, or the transcription of the recordings. In this\npaper, we elaborate on the challenges we faced in starting our collection of\ntherapist-patient dialogues in a psychiatry clinic under the General Data\nPrivacy Regulation of the European Union with the goal to use the data for\nNatural Language Processing (NLP) research. We give an overview of each step in\nour procedure and point out the potential pitfalls to motivate further research\nin this field.",
    "descriptor": "",
    "authors": [
      "Tobias Mayer",
      "Neha Warikoo",
      "Oliver Grimm",
      "Andreas Reif",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.12360"
  },
  {
    "id": "arXiv:2211.12363",
    "title": "Electric Autonomous Mobility-on-Demand: Joint Optimization of Routing  and Charging Infrastructure Siting",
    "abstract": "The advent of vehicle autonomy, connectivity and electric powertrains is\nexpected to enable the deployment of Autonomous Mobility-on-Demand systems.\nCrucially, the routing and charging activities of these fleets are impacted by\nthe design of the individual vehicles and the surrounding charging\ninfrastructure which, in turn, should be designed to account for the intended\nfleet operation. This paper presents a modeling and optimization framework\nwhere we optimize the activities of the fleet jointly with the placement of the\ncharging infrastructure. We adopt a mesoscopic planning perspective and devise\na time-invariant model of the fleet activities in terms of routes and charging\npatterns, explicitly capturing the state of charge of the vehicles by\nresampling the road network as a digraph with iso-energy arcs. Then, we cast\nthe problem as a mixed-integer linear program that guarantees global optimality\nand can be solved in less than 10 min. Finally, we showcase two case studies\nwith real-world taxi data in Manhattan, NYC: The first one captures the optimal\ntrade-off between charging infrastructure prevalence and the empty-mileage\ndriven by the fleet. We observe that jointly optimizing the infrastructure\nsiting significantly outperforms heuristic placement policies, and that\nincreasing the number of stations is beneficial only up to a certain point. The\nsecond case focuses on vehicle design and shows that deploying vehicles\nequipped with a smaller battery results in the lowest energy consumption:\nAlthough necessitating more trips to the charging stations, such fleets require\nabout 12% less energy than the vehicles with a larger battery capacity.",
    "descriptor": "",
    "authors": [
      "Fabio Paparella",
      "Karni Chauhan",
      "Theo Hofman",
      "Mauro Salazar"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.12363"
  },
  {
    "id": "arXiv:2211.12364",
    "title": "Method for Determining the Similarity of Text Documents for the Kazakh  language, Taking Into Account Synonyms: Extension to TF-IDF",
    "abstract": "The task of determining the similarity of text documents has received\nconsiderable attention in many areas such as Information Retrieval, Text\nMining, Natural Language Processing (NLP) and Computational Linguistics.\nTransferring data to numeric vectors is a complex task where algorithms such as\ntokenization, stopword filtering, stemming, and weighting of terms are used.\nThe term frequency - inverse document frequency (TF-IDF) is the most widely\nused term weighting method to facilitate the search for relevant documents. To\nimprove the weighting of terms, a large number of TF-IDF extensions are made.\nIn this paper, another extension of the TF-IDF method is proposed where\nsynonyms are taken into account. The effectiveness of the method is confirmed\nby experiments on functions such as Cosine, Dice and Jaccard to measure the\nsimilarity of text documents for the Kazakh language.",
    "descriptor": "\nComments: 2022 International Conference on Smart Information Systems and Technologies (SIST)\n",
    "authors": [
      "Bakhyt Bakiyev"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.12364"
  },
  {
    "id": "arXiv:2211.12368",
    "title": "Real-time Neural Radiance Talking Portrait Synthesis via Audio-spatial  Decomposition",
    "abstract": "While dynamic Neural Radiance Fields (NeRF) have shown success in\nhigh-fidelity 3D modeling of talking portraits, the slow training and inference\nspeed severely obstruct their potential usage. In this paper, we propose an\nefficient NeRF-based framework that enables real-time synthesizing of talking\nportraits and faster convergence by leveraging the recent success of grid-based\nNeRF. Our key insight is to decompose the inherently high-dimensional talking\nportrait representation into three low-dimensional feature grids. Specifically,\na Decomposed Audio-spatial Encoding Module models the dynamic head with a 3D\nspatial grid and a 2D audio grid. The torso is handled with another 2D grid in\na lightweight Pseudo-3D Deformable Module. Both modules focus on efficiency\nunder the premise of good rendering quality. Extensive experiments demonstrate\nthat our method can generate realistic and audio-lips synchronized talking\nportrait videos, while also being highly efficient compared to previous\nmethods.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Jiaxiang Tang",
      "Kaisiyuan Wang",
      "Hang Zhou",
      "Xiaokang Chen",
      "Dongliang He",
      "Tianshu Hu",
      "Jingtuo Liu",
      "Gang Zeng",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12368"
  },
  {
    "id": "arXiv:2211.12371",
    "title": "LiCamGait: Gait Recognition in the Wild by Using LiDAR and Camera  Multi-modal Visual Sensors",
    "abstract": "LiDAR can capture accurate depth information in large-scale scenarios without\nthe effect of light conditions, and the captured point cloud contains\ngait-related 3D geometric properties and dynamic motion characteristics. We\nmake the first attempt to leverage LiDAR to remedy the limitation of\nview-dependent and light-sensitive camera for more robust and accurate gait\nrecognition. In this paper, we propose a LiDAR-camera-based gait recognition\nmethod with an effective multi-modal feature fusion strategy, which fully\nexploits advantages of both point clouds and images. In particular, we propose\na new in-the-wild gait dataset, LiCamGait, involving multi-modal visual data\nand diverse 2D/3D representations. Our method achieves state-of-the-art\nperformance on the new dataset. Code and dataset will be released when this\npaper is published.",
    "descriptor": "",
    "authors": [
      "Xiao Han",
      "Peishan Cong",
      "Lan Xu",
      "Jingya Wang",
      "Jingyi Yu",
      "Yuexin Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12371"
  },
  {
    "id": "arXiv:2211.12374",
    "title": "An Emotion-Aware Multi-Task Approach to Fake News and Rumour Detection  using Transfer Learning",
    "abstract": "Social networking sites, blogs, and online articles are instant sources of\nnews for internet users globally. However, in the absence of strict regulations\nmandating the genuineness of every text on social media, it is probable that\nsome of these texts are fake news or rumours. Their deceptive nature and\nability to propagate instantly can have an adverse effect on society. This\nnecessitates the need for more effective detection of fake news and rumours on\nthe web. In this work, we annotate four fake news detection and rumour\ndetection datasets with their emotion class labels using transfer learning. We\nshow the correlation between the legitimacy of a text with its intrinsic\nemotion for fake news and rumour detection, and prove that even within the same\nemotion class, fake and real news are often represented differently, which can\nbe used for improved feature extraction. Based on this, we propose a multi-task\nframework for fake news and rumour detection, predicting both the emotion and\nlegitimacy of the text. We train a variety of deep learning models in\nsingle-task and multi-task settings for a more comprehensive comparison. We\nfurther analyze the performance of our multi-task approach for fake news\ndetection in cross-domain settings to verify its efficacy for better\ngeneralization across datasets, and to verify that emotions act as a\ndomain-independent feature. Experimental results verify that our multi-task\nmodels consistently outperform their single-task counterparts in terms of\naccuracy, precision, recall, and F1 score, both for in-domain and cross-domain\nsettings. We also qualitatively analyze the difference in performance in\nsingle-task and multi-task learning models.",
    "descriptor": "\nComments: 18 pages 5 figures\n",
    "authors": [
      "Arjun Choudhry",
      "Inder Khatri",
      "Minni Jain",
      "Dinesh Kumar Vishwakarma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12374"
  },
  {
    "id": "arXiv:2211.12380",
    "title": "OCTET: Object-aware Counterfactual Explanations",
    "abstract": "Nowadays, deep vision models are being widely deployed in safety-critical\napplications, e.g., autonomous driving, and explainability of such models is\nbecoming a pressing concern. Among explanation methods, counterfactual\nexplanations aim to find minimal and interpretable changes to the input image\nthat would also change the output of the model to be explained. Such\nexplanations point end-users at the main factors that impact the decision of\nthe model. However, previous methods struggle to explain decision models\ntrained on images with many objects, e.g., urban scenes, which are more\ndifficult to work with but also arguably more critical to explain. In this\nwork, we propose to tackle this issue with an object-centric framework for\ncounterfactual explanation generation. Our method, inspired by recent\ngenerative modeling works, encodes the query image into a latent space that is\nstructured in a way to ease object-level manipulations. Doing so, it provides\nthe end-user with control over which search directions (e.g., spatial\ndisplacement of objects, style modification, etc.) are to be explored during\nthe counterfactual generation. We conduct a set of experiments on\ncounterfactual explanation benchmarks for driving scenes, and we show that our\nmethod can be adapted beyond classification, e.g., to explain semantic\nsegmentation models. To complete our analysis, we design and run a user study\nthat measures the usefulness of counterfactual explanations in understanding a\ndecision model. Code is available at https://github.com/valeoai/OCTET.",
    "descriptor": "\nComments: 8 pages + references + appendix\n",
    "authors": [
      "Mehdi Zemni",
      "Micka\u00ebl Chen",
      "\u00c9loi Zablocki",
      "H\u00e9di Ben-Younes",
      "Patrick P\u00e9rez",
      "Matthieu Cord"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12380"
  },
  {
    "id": "arXiv:2211.12385",
    "title": "MCD: A Modified Community Diversity Approach for Detecting Influential  Nodes in Social Networks",
    "abstract": "Over the last couple of decades, Social Networks have connected people on the\nweb from across the globe and have become a crucial part of our daily life.\nThese networks have also rapidly grown as platforms for propagating products,\nideas, and opinions to target a wider audience. This calls for the need to find\ninfluential nodes in a network for a variety of reasons, including the curb of\nmisinformation being spread across the networks, advertising products\nefficiently, finding prominent protein structures in biological networks, etc.\nIn this paper, we propose Modified Community Diversity (MCD), a novel method\nfor finding influential nodes in a network by exploiting community detection\nand a modified community diversity approach. We extend the concept of community\ndiversity to a two-hop scenario. This helps us evaluate a node's possible\ninfluence over a network more accurately and also avoids the selection of seed\nnodes with an overlapping scope of influence. Experimental results verify that\nMCD outperforms various other state-of-the-art approaches on eight datasets\ncumulatively across three performance metrics.",
    "descriptor": "\nComments: 18 pages 4 Figures\n",
    "authors": [
      "Aaryan Gupta",
      "Inder Khatri",
      "Arjun Choudhry",
      "Sanjay Kumar"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.12385"
  },
  {
    "id": "arXiv:2211.12386",
    "title": "A Recursively Recurrent Neural Network (R2N2) Architecture for Learning  Iterative Algorithms",
    "abstract": "Meta-learning of numerical algorithms for a given task consist of the\ndata-driven identification and adaptation of an algorithmic structure and the\nassociated hyperparameters. To limit the complexity of the meta-learning\nproblem, neural architectures with a certain inductive bias towards favorable\nalgorithmic structures can, and should, be used. We generalize our previously\nintroduced Runge-Kutta neural network to a recursively recurrent neural network\n(R2N2) superstructure for the design of customized iterative algorithms. In\ncontrast to off-the-shelf deep learning approaches, it features a distinct\ndivision into modules for generation of information and for the subsequent\nassembly of this information towards a solution. Local information in the form\nof a subspace is generated by subordinate, inner, iterations of recurrent\nfunction evaluations starting at the current outer iterate. The update to the\nnext outer iterate is computed as a linear combination of these evaluations,\nreducing the residual in this space, and constitutes the output of the network.\nWe demonstrate that regular training of the weight parameters inside the\nproposed superstructure on input/output data of various computational problem\nclasses yields iterations similar to Krylov solvers for linear equation\nsystems, Newton-Krylov solvers for nonlinear equation systems, and Runge-Kutta\nintegrators for ordinary differential equations. Due to its modularity, the\nsuperstructure can be readily extended with functionalities needed to represent\nmore general classes of iterative algorithms traditionally based on Taylor\nseries expansions.",
    "descriptor": "\nComments: manuscript (21 pages, 10 figures), supporting information (2 pages, 1 figure)\n",
    "authors": [
      "Danimir T. Doncevic",
      "Alexander Mitsos",
      "Yue Guo",
      "Qianxiao Li",
      "Felix Dietrich",
      "Manuel Dahmen",
      "Ioannis G. Kevrekidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.12386"
  },
  {
    "id": "arXiv:2211.12393",
    "title": "Efficient wPINN-Approximations to Entropy Solutions of Hyperbolic  Conservation Laws",
    "abstract": "We consider the approximation of weak solutions of nonlinear hyperbolic PDEs\nusing neural networks, similar to the classical PINNs approach, but using a\nweak (dual) norm of the residual. This is a variant of what was termed \"weak\nPINNs\" recently. We provide some explicit computations that highlight why\nclassical PINNs will not work well for discontinuous solutions to nonlinear\nhyperbolic conservation laws and we suggest some modifications to the weak PINN\nmethodology that lead to more efficient computations and smaller errors.",
    "descriptor": "",
    "authors": [
      "Aidan Chaumet",
      "Jan Giesselmann"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.12393"
  },
  {
    "id": "arXiv:2211.12400",
    "title": "DeepJoin: Learning a Joint Occupancy, Signed Distance, and Normal Field  Function for Shape Repair",
    "abstract": "We introduce DeepJoin, an automated approach to generate high-resolution\nrepairs for fractured shapes using deep neural networks. Existing approaches to\nperform automated shape repair operate exclusively on symmetric objects,\nrequire a complete proxy shape, or predict restoration shapes using\nlow-resolution voxels which are too coarse for physical repair. We generate a\nhigh-resolution restoration shape by inferring a corresponding complete shape\nand a break surface from an input fractured shape. We present a novel implicit\nshape representation for fractured shape repair that combines the occupancy\nfunction, signed distance function, and normal field. We demonstrate repairs\nusing our approach for synthetically fractured objects from ShapeNet, 3D scans\nfrom the Google Scanned Objects dataset, objects in the style of ancient Greek\npottery from the QP Cultural Heritage dataset, and real fractured objects. We\noutperform three baseline approaches in terms of chamfer distance and normal\nconsistency. Unlike existing approaches and restorations using subtraction,\nDeepJoin restorations do not exhibit surface artifacts and join closely to the\nfractured region of the fractured shape. Our code is available at:\nhttps://github.com/Terascale-All-sensing-Research-Studio/DeepJoin.",
    "descriptor": "\nComments: To be published at SIGGRAPH Asia 2022 (Journal)\n",
    "authors": [
      "Nikolas Lamb",
      "Sean Banerjee",
      "Natasha Kholgade Banerjee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12400"
  },
  {
    "id": "arXiv:2211.12402",
    "title": "X$^2$-VLM: All-In-One Pre-trained Model For Vision-Language Tasks",
    "abstract": "Vision language pre-training aims to learn alignments between vision and\nlanguage from a large amount of data. We proposed multi-grained vision language\npre-training, a unified approach which can learn vision language alignments in\nmultiple granularity. This paper advances the proposed method by unifying image\nand video encoding in one model and scaling up the model with large-scale data.\nWe present X$^2$-VLM, a pre-trained VLM with a modular architecture for both\nimage-text tasks and video-text tasks. Experiment results show that X$^2$-VLM\nperforms the best on base and large scale for both image-text and video-text\ntasks, making a good trade-off between performance and model scale. Moreover,\nwe show that the modular design of X$^2$-VLM results in high transferability\nfor X$^2$-VLM to be utilized in any language or domain. For example, by simply\nreplacing the text encoder with XLM-R, X$^2$-VLM outperforms state-of-the-art\nmultilingual multi-modal pre-trained models without any multilingual\npre-training. The code and pre-trained models will be available at\ngithub.com/zengyan-97/X2-VLM.",
    "descriptor": "\nComments: 21 pages, 8 figures\n",
    "authors": [
      "Yan Zeng",
      "Xinsong Zhang",
      "Hang Li",
      "Jiawei Wang",
      "Jipeng Zhang",
      "Wangchunshu Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.12402"
  },
  {
    "id": "arXiv:2211.12408",
    "title": "Bimanual Motor Strategies and Handedness Role During Human-Exoskeleton  Haptic Interaction",
    "abstract": "Bimanual object manipulation involves multiple visuo-haptic sensory feedbacks\narising from the interaction with the environment that are managed from the\ncentral nervous system and consequently translated in motor commands. Kinematic\nstrategies that occur during bimanual coupled tasks are still a scientific\ndebate despite modern advances in haptics and robotics. Current technologies\nmay have the potential to provide realistic scenarios involving the entire\nupper limb extremities during multi-joint movements but are not yet exploited\nto their full potential. The present study explores how hands dynamically\ninteract when manipulating a shared object through the use of two\nimpedance-controlled exoskeletons programmed to simulate bimanually coupled\nmanipulation of virtual objects. We enrolled twenty-six participants (2 groups:\nright-handed and left-handed) who were requested to use both hands to grab\nsimulated objects across the robot workspace and place them in specific\nlocations. The virtual objects were rendered with different dynamic proprieties\nand textures influencing the manipulation strategies to complete the tasks.\nResults revealed that the roles of hands are related to the movement direction,\nthe haptic features, and the handedness preference. Outcomes suggested that the\nhaptic feedback affects bimanual strategies depending on the movement\ndirection. However, left-handers show better control of the force applied\nbetween the two hands, probably due to environmental pressures for right-handed\nmanipulations.",
    "descriptor": "",
    "authors": [
      "Elisa Galofaro",
      "Erika D'Antonio",
      "Nicola Lotti",
      "Fabrizio Patane'",
      "Maura Casadio",
      "Lorenzo Masia"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.12408"
  },
  {
    "id": "arXiv:2211.12416",
    "title": "Risk-Aware Stability of Discrete-Time Systems",
    "abstract": "We develop a generalized stability framework for stochastic discrete-time\nsystems, where the generality pertains to the ways in which the distribution of\nthe state energy can be characterized. We use tools from finance and operations\nresearch called risk functionals (i.e., risk measures) to facilitate diverse\ndistributional characterizations. In contrast, classical stochastic stability\nnotions characterize the state energy on average or in probability, which can\nobscure the variability of stochastic system behavior. After drawing\nconnections between various risk-aware stability concepts for nonlinear\nsystems, we specialize to linear systems and derive sufficient conditions for\nthe satisfaction of some risk-aware stability properties. These results pertain\nto real-valued coherent risk functionals and a mean-conditional-variance\nfunctional. The results reveal novel noise-to-state stability properties, which\nassess disturbances in ways that reflect the chosen measure of risk. We\nillustrate the theory through examples about robustness, parameter choices, and\nstate-feedback controllers.",
    "descriptor": "",
    "authors": [
      "Margaret P. Chapman",
      "Dionysios S. Kalogerias"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.12416"
  },
  {
    "id": "arXiv:2211.12417",
    "title": "ProCC: Progressive Cross-primitive Consistency for Open-World  Compositional Zero-Shot Learning",
    "abstract": "Open-World Compositional Zero-shot Learning (OW-CZSL) aims to recognize novel\ncompositions of state and object primitives in images with no priors on the\ncompositional space, which induces a tremendously large output space containing\nall possible state-object compositions. Existing works either learn the joint\ncompositional state-object embedding or predict simple primitives with separate\nclassifiers. However, the former heavily relies on external word embedding\nmethods, and the latter ignores the interactions of interdependent primitives,\nrespectively. In this paper, we revisit the primitive prediction approach and\npropose a novel method, termed Progressive Cross-primitive Consistency (ProCC),\nto mimic the human learning process for OW-CZSL tasks. Specifically, the\ncross-primitive consistency module explicitly learns to model the interactions\nof state and object features with the trainable memory units, which efficiently\nacquires cross-primitive visual attention and avoids cross-primitive\nfeasibility scores. Moreover, considering the partial-supervision setting\n(pCZSL) as well as the imbalance issue of multiple tasks prediction, we design\na progressive training paradigm to enable the primitive classifiers to interact\nto obtain discriminative information in an easy-to-hard manner. Extensive\nexperiments on three widely used benchmark datasets demonstrate that our method\noutperforms other representative methods on both OW-CZSL and pCZSL settings by\nl",
    "descriptor": "",
    "authors": [
      "Fushuo Huo",
      "Wenchao Xu",
      "Song Guo",
      "Jingcai Guo",
      "Haozhao Wang",
      "Ziming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12417"
  },
  {
    "id": "arXiv:2211.12419",
    "title": "Accuracy Prediction for NAS Acceleration using Feature Selection and  Extrapolation",
    "abstract": "Predicting the accuracy of candidate neural architectures is an important\ncapability of NAS-based solutions. When a candidate architecture has properties\nthat are similar to other known architectures, the prediction task is rather\nstraightforward using off-the-shelf regression algorithms. However, when a\ncandidate architecture lies outside of the known space of architectures, a\nregression model has to perform extrapolated predictions, which is not only a\nchallenging task, but also technically impossible using the most popular\nregression algorithm families, which are based on decision trees. In this work,\nwe are trying to address two problems. The first one is improving regression\naccuracy using feature selection, whereas the other one is the evaluation of\nregression algorithms on extrapolating accuracy prediction tasks. We extend the\nNAAP-440 dataset with new tabular features and introduce NAAP-440e, which we\nuse for evaluation. We observe a dramatic improvement from the old baseline,\nnamely, the new baseline requires 3x shorter training processes of candidate\narchitectures, while maintaining the same mean-absolute-error and achieving\nalmost 2x fewer monotonicity violations, compared to the old baseline's best\nreported performance. The extended dataset and code used in the study have been\nmade public in the NAAP-440 repository.",
    "descriptor": "",
    "authors": [
      "Tal Hakim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12419"
  },
  {
    "id": "arXiv:2211.12422",
    "title": "PiRL: Participant-Invariant Representation Learning for Healthcare",
    "abstract": "Due to individual heterogeneity, performance gaps are observed between\ngeneric (one-size-fits-all) models and person-specific models in data-driven\nhealth applications. However, in real-world applications, generic models are\nusually more favorable due to new-user-adaptation issues and system\ncomplexities, etc. To improve the performance of the generic model, we propose\na representation learning framework that learns participant-invariant\nrepresentations, named PiRL. The proposed framework utilizes maximum mean\ndiscrepancy (MMD) loss and domain-adversarial training to encourage the model\nto learn participant-invariant representations. Further, a triplet loss, which\nconstrains the model for inter-class alignment of the representations, is\nutilized to optimize the learned representations for downstream health\napplications. We evaluated our frameworks on two public datasets related to\nphysical and mental health, for detecting sleep apnea and stress, respectively.\nAs preliminary results, we found the proposed approach shows around a 5%\nincrease in accuracy compared to the baseline.",
    "descriptor": "",
    "authors": [
      "Zhaoyang Cao",
      "Han Yu",
      "Huiyuan Yang",
      "Akane Sano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.12422"
  },
  {
    "id": "arXiv:2211.12423",
    "title": "On Narrative Information and the Distillation of Stories",
    "abstract": "The act of telling stories is a fundamental part of what it means to be\nhuman. This work introduces the concept of narrative information, which we\ndefine to be the overlap in information space between a story and the items\nthat compose the story. Using contrastive learning methods, we show how modern\nartificial neural networks can be leveraged to distill stories and extract a\nrepresentation of the narrative information. We then demonstrate how\nevolutionary algorithms can leverage this to extract a set of narrative\ntemplates and how these templates -- in tandem with a novel curve-fitting\nalgorithm we introduce -- can reorder music albums to automatically induce\nstories in them. In the process of doing so, we give strong statistical\nevidence that these narrative information templates are present in existing\nalbums. While we experiment only with music albums here, the premises of our\nwork extend to any form of (largely) independent media.",
    "descriptor": "\nComments: presented in the Information-Theoretic Principles in Cognitive Systems Workshop at the 36th Conference on Neural Information Processing Systems; 4 pages in main text + 2 pages of references + 8 pages of appendices, 2 figures in main text + 3 in appendices, 1 table in main text, 2 algorithms in appendices; source code available at this https URL\n",
    "authors": [
      "Dylan R. Ashley",
      "Vincent Herrmann",
      "Zachary Friggstad",
      "J\u00fcrgen Schmidhuber"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.12423"
  },
  {
    "id": "arXiv:2211.12424",
    "title": "One Venue, Two Conferences: The Separation of Chinese and American  Citation Networks",
    "abstract": "At NeurIPS, American and Chinese institutions cite papers from each other's\nregions substantially less than they cite endogamously. We build a citation\ngraph to quantify this divide, compare it to European connectivity, and discuss\nthe causes and consequences of the separation.",
    "descriptor": "\nComments: Workshop on Cultures of AI and AI for Culture @ NeurIPS 2022\n",
    "authors": [
      "Bingchen Zhao",
      "Yuling Gu",
      "Jessica Zosa Forde",
      "Naomi Saphra"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12424"
  },
  {
    "id": "arXiv:2211.12425",
    "title": "Progressive Learning with Cross-Window Consistency for Semi-Supervised  Semantic Segmentation",
    "abstract": "Semi-supervised semantic segmentation focuses on the exploration of a small\namount of labeled data and a large amount of unlabeled data, which is more in\nline with the demands of real-world image understanding applications. However,\nit is still hindered by the inability to fully and effectively leverage\nunlabeled images. In this paper, we reveal that cross-window consistency (CWC)\nis helpful in comprehensively extracting auxiliary supervision from unlabeled\ndata. Additionally, we propose a novel CWC-driven progressive learning\nframework to optimize the deep network by mining weak-to-strong constraints\nfrom massive unlabeled data. More specifically, this paper presents a biased\ncross-window consistency (BCC) loss with an importance factor, which helps the\ndeep network explicitly constrain confidence maps from overlapping regions in\ndifferent windows to maintain semantic consistency with larger contexts. In\naddition, we propose a dynamic pseudo-label memory bank (DPM) to provide\nhigh-consistency and high-reliability pseudo-labels to further optimize the\nnetwork. Extensive experiments on three representative datasets of urban views,\nmedical scenarios, and satellite scenes demonstrate our framework consistently\noutperforms the state-of-the-art methods with a large margin. Code will be\navailable publicly.",
    "descriptor": "",
    "authors": [
      "Bo Dang",
      "Yansheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12425"
  },
  {
    "id": "arXiv:2211.12431",
    "title": "Choose your witnesses wisely",
    "abstract": "This paper addresses a graph optimization problem, called the Witness Tree\nproblem, which seeks a spanning tree of a graph minimizing a certain non-linear\nobjective function. This problem is of interest because it plays a crucial role\nin the analysis of the best approximation algorithms for two fundamental\nnetwork design problems: Steiner Tree and Node-Tree Augmentation. We will show\nhow a wiser choice of witness trees leads to an improved approximation for\nNode-Tree Augmentation, and for Steiner Tree in special classes of graphs.",
    "descriptor": "\nComments: 33 pages, 7 figures, submitted to IPCO 2023\n",
    "authors": [
      "Dylan Hyatt-Denesik",
      "Afrouz Jabal Ameli",
      "Laura Sanit\u00e0"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.12431"
  },
  {
    "id": "arXiv:2211.12432",
    "title": "Multi-task Learning for Camera Calibration",
    "abstract": "For a number of tasks, such as 3D reconstruction, robotic interface,\nautonomous driving, etc., camera calibration is essential. In this study, we\npresent a unique method for predicting intrinsic (principal point offset and\nfocal length) and extrinsic (baseline, pitch, and translation) properties from\na pair of images. We suggested a novel method where camera model equations are\nrepresented as a neural network in a multi-task learning framework, in contrast\nto existing methods, which build a comprehensive solution. By reconstructing\nthe 3D points using a camera model neural network and then using the loss in\nreconstruction to obtain the camera specifications, this innovative camera\nprojection loss (CPL) method allows us that the desired parameters should be\nestimated. As far as we are aware, our approach is the first one that uses an\napproach to multi-task learning that includes mathematical formulas in a\nframework for learning to estimate camera parameters to predict both the\nextrinsic and intrinsic parameters jointly. Additionally, we provided a new\ndataset named as CVGL Camera Calibration Dataset [1] which has been collected\nusing the CARLA Simulator [2]. Actually, we show that our suggested strategy\nout performs both conventional methods and methods based on deep learning on 8\nout of 10 parameters that were assessed using both real and synthetic data. Our\ncode and generated dataset are available at\nhttps://github.com/thanif/Camera-Calibration-through-Camera-Projection-Loss.",
    "descriptor": "\nComments: 20 pages, 12 figures, 8 tables\n",
    "authors": [
      "Talha Hanif Butt",
      "Murtaza Taj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12432"
  },
  {
    "id": "arXiv:2211.12433",
    "title": "TF-GridNet: Integrating Full- and Sub-Band Modeling for Speech  Separation",
    "abstract": "We propose TF-GridNet for speech separation. The model is a novel multi-path\ndeep neural network (DNN) integrating full- and sub-band modeling in the\ntime-frequency (T-F) domain. It stacks several multi-path blocks, each\nconsisting of an intra-frame full-band module, a sub-band temporal module, and\na cross-frame self-attention module. It is trained to perform complex spectral\nmapping, where the real and imaginary (RI) components of input signals are\nstacked as features to predict target RI components. We first evaluate it on\nmonaural anechoic speaker separation. Without using data augmentation and\ndynamic mixing, it obtains a state-of-the-art 23.5 dB improvement in\nscale-invariant signal-to-distortion ratio (SI-SDR) on WSJ0-2mix, a standard\ndataset for two-speaker separation. To show its robustness to noise and\nreverberation, we evaluate it on monaural reverberant speaker separation using\nthe SMS-WSJ dataset and on noisy-reverberant speaker separation using WHAMR!,\nand obtain state-of-the-art performance on both datasets. We then extend\nTF-GridNet to multi-microphone conditions through multi-microphone complex\nspectral mapping, and integrate it into a two-DNN system with a beamformer in\nbetween (named as MISO-BF-MISO in earlier studies), where the beamformer\nproposed in this paper is a novel multi-frame Wiener filter computed based on\nthe outputs of the first DNN. State-of-the-art performance is obtained on the\nmulti-channel tasks of SMS-WSJ and WHAMR!. Besides speaker separation, we apply\nthe proposed algorithms to speech dereverberation and noisy-reverberant speech\nenhancement. State-of-the-art performance is obtained on a dereverberation\ndataset and on the dataset of the recent L3DAS22 multi-channel speech\nenhancement challenge.",
    "descriptor": "\nComments: In submission. A sound demo is available at this https URL\n",
    "authors": [
      "Zhong-Qiu Wang",
      "Samuele Cornell",
      "Shukjae Choi",
      "Younglo Lee",
      "Byeong-Yeol Kim",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.12433"
  },
  {
    "id": "arXiv:2211.12434",
    "title": "Expansive Participatory AI: Supporting Dreaming within Inequitable  Institutions",
    "abstract": "Participatory Artificial Intelligence (PAI) has recently gained interest by\nresearchers as means to inform the design of technology through collective's\nlived experience. PAI has a greater promise than that of providing useful input\nto developers, it can contribute to the process of democratizing the design of\ntechnology, setting the focus on what should be designed. However, in the\nprocess of PAI there existing institutional power dynamics that hinder the\nrealization of expansive dreams and aspirations of the relevant stakeholders.\nIn this work we propose co-design principals for AI that address institutional\npower dynamics focusing on Participatory AI with youth.",
    "descriptor": "\nComments: 3 pages, Human-Centered AI workshop\n",
    "authors": [
      "Michael Alan Chang",
      "Shiran Dudy"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12434"
  },
  {
    "id": "arXiv:2211.12436",
    "title": "Depth-Supervised NeRF for Multi-View RGB-D Operating Room Images",
    "abstract": "Neural Radiance Fields (NeRF) is a powerful novel technology for the\nreconstruction of 3D scenes from a set of images captured by static cameras.\nRenders of these reconstructions could play a role in virtual presence in the\noperating room (OR), e.g. for training purposes. In contrast to existing\nsystems for virtual presence, NeRF can provide real instead of simulated\nsurgeries. This work shows how NeRF can be used for view synthesis in the OR. A\ndepth-supervised NeRF (DS-NeRF) is trained with three or five synchronised\ncameras that capture the surgical field in knee replacement surgery videos from\nthe 4D-OR dataset. The algorithm is trained and evaluated for images in five\ndistinct phases before and during the surgery. With qualitative analysis, we\ninspect views synthesised by a virtual camera that moves in 180 degrees around\nthe surgical field. Additionally, we quantitatively inspect view synthesis from\nan unseen camera position in terms of PSNR, SSIM and LPIPS for the colour\nchannels and in terms of MAE and error percentage for the estimated depth.\nDS-NeRF generates geometrically consistent views, also from interpolated camera\npositions. Views are generated from an unseen camera pose with an average PSNR\nof 17.8 and a depth estimation error of 2.10%. However, due to artefacts and\nmissing of fine details, the synthesised views do not look photo-realistic. Our\nresults show the potential of NeRF for view synthesis in the OR. Recent\ndevelopments, such as NeRF for video synthesis and training speedups, require\nfurther exploration to reveal its full potential.",
    "descriptor": "\nComments: 12 pages, 4 figures, submitted to the 14th International Conference on Information Processing in Computer-Assisted Interventions\n",
    "authors": [
      "Beerend G.A. Gerats",
      "Jelmer M. Wolterink",
      "Ivo A.M.J. Broeders"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12436"
  },
  {
    "id": "arXiv:2211.12441",
    "title": "Query Complexity of Inversion Minimization on Trees",
    "abstract": "We consider the following computational problem: Given a rooted tree and a\nranking of its leaves, what is the minimum number of inversions of the leaves\nthat can be attained by ordering the tree? This variation of the problem of\ncounting inversions in arrays originated in mathematical psychology, with the\nevaluation of the Mann--Whitney statistic for detecting differences between\ndistributions as a special case.\nWe study the complexity of the problem in the comparison-query model, used\nfor problems like sorting and selection. For many types of trees with $n$\nleaves, we establish lower bounds close to the strongest known in the model,\nnamely the lower bound of $\\log_2(n!)$ for sorting $n$ items. We show:\n(a) $\\log_2((\\alpha(1-\\alpha)n)!) - O(\\log n)$ queries are needed whenever\nthe tree has a subtree that contains a fraction $\\alpha$ of the leaves. This\nimplies a lower bound of $\\log_2((\\frac{k}{(k+1)^2}n)!) - O(\\log n)$ for trees\nof degree $k$.\n(b) $\\log_2(n!) - O(\\log n)$ queries are needed in case the tree is binary.\n(c) $\\log_2(n!) - O(k \\log k)$ queries are needed for certain classes of\ntrees of degree $k$, including perfect trees with even $k$.\nThe lower bounds are obtained by developing two novel techniques for a\ngeneric problem $\\Pi$ in the comparison-query model and applying them to\ninversion minimization on trees. Both techniques can be described in terms of\nthe Cayley graph of the symmetric group with adjacent-rank transpositions as\nthe generating set. Consider the subgraph consisting of the edges between\nvertices with the same value under $\\Pi$. We show that the size of any decision\ntree for $\\Pi$ must be at least:\n(i) the number of connected components of this subgraph, and\n(ii) the factorial of the average degree of the complementary subgraph,\ndivided by $n$.\nLower bounds on query complexity then follow by taking the base-2 logarithm.",
    "descriptor": "\nComments: 54 pages, 18 figures, full version of paper appearing in the Proceedings of the 2023 ACM-SIAM Symposium on Discrete Algorithms\n",
    "authors": [
      "Ivan Hu",
      "Dieter van Melkebeek",
      "Andrew Morgan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.12441"
  },
  {
    "id": "arXiv:2211.12445",
    "title": "SinDiffusion: Learning a Diffusion Model from a Single Natural Image",
    "abstract": "We present SinDiffusion, leveraging denoising diffusion models to capture\ninternal distribution of patches from a single natural image. SinDiffusion\nsignificantly improves the quality and diversity of generated samples compared\nwith existing GAN-based approaches. It is based on two core designs. First,\nSinDiffusion is trained with a single model at a single scale instead of\nmultiple models with progressive growing of scales which serves as the default\nsetting in prior work. This avoids the accumulation of errors, which cause\ncharacteristic artifacts in generated results. Second, we identify that a\npatch-level receptive field of the diffusion network is crucial and effective\nfor capturing the image's patch statistics, therefore we redesign the network\nstructure of the diffusion model. Coupling these two designs enables us to\ngenerate photorealistic and diverse images from a single image. Furthermore,\nSinDiffusion can be applied to various applications, i.e., text-guided image\ngeneration, and image outpainting, due to the inherent capability of diffusion\nmodels. Extensive experiments on a wide range of images demonstrate the\nsuperiority of our proposed method for modeling the patch distribution.",
    "descriptor": "",
    "authors": [
      "Weilun Wang",
      "Jianmin Bao",
      "Wengang Zhou",
      "Dongdong Chen",
      "Dong Chen",
      "Lu Yuan",
      "Houqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12445"
  },
  {
    "id": "arXiv:2211.12446",
    "title": "EDICT: Exact Diffusion Inversion via Coupled Transformations",
    "abstract": "Finding an initial noise vector that produces an input image when fed into\nthe diffusion process (known as inversion) is an important problem in denoising\ndiffusion models (DDMs), with applications for real image editing. The\nstate-of-the-art approach for real image editing with inversion uses denoising\ndiffusion implicit models (DDIMs) to deterministically noise the image to the\nintermediate state along the path that the denoising would follow given the\noriginal conditioning. However, DDIM inversion for real images is unstable as\nit relies on local linearization assumptions, which result in the propagation\nof errors, leading to incorrect image reconstruction and loss of content. To\nalleviate these problems, we propose Exact Diffusion Inversion via Coupled\nTransformations (EDICT), an inversion method that draws inspiration from affine\ncoupling layers. EDICT enables mathematically exact inversion of real and\nmodel-generated images by maintaining two coupled noise vectors which are used\nto invert each other in an alternating fashion. Using Stable Diffusion, a\nstate-of-the-art latent diffusion model, we demonstrate that EDICT successfully\nreconstructs real images with high fidelity. On complex image datasets like\nMS-COCO, EDICT reconstruction significantly outperforms DDIM, improving the\nmean square error of reconstruction by a factor of two. Using noise vectors\ninverted from real images, EDICT enables a wide range of image edits--from\nlocal and global semantic edits to image stylization--while maintaining\nfidelity to the original image structure. EDICT requires no model\ntraining/finetuning, prompt tuning, or extra data and can be combined with any\npretrained DDM. Code will be made available shortly.",
    "descriptor": "\nComments: 24 pages, 22 figures\n",
    "authors": [
      "Bram Wallace",
      "Akash Gokul",
      "Nikhil Naik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12446"
  },
  {
    "id": "arXiv:2211.12451",
    "title": "Fault-Tolerant Dispersion of Mobile Robots",
    "abstract": "We consider the mobile robot dispersion problem in the presence of faulty\nrobots (crash-fault). Mobile robot dispersion consists of $k\\leq n$ robots in\nan $n$-node anonymous graph. The goal is to ensure that regardless of the\ninitial placement of the robots over the nodes, the final configuration\nconsists of having at most one robot at each node. In a crash-fault setting, up\nto $f \\leq k$ robots may fail by crashing arbitrarily and subsequently lose all\nthe information stored at the robots, rendering them unable to communicate. In\nthis paper, we solve the dispersion problem in a crash-fault setting by\nconsidering two different initial configurations: i) the rooted configuration,\nand ii) the arbitrary configuration. In the rooted case, all robots are placed\ntogether at a single node at the start. The arbitrary configuration is a\ngeneral configuration (a.k.a. arbitrary configuration in the literature) where\nthe robots are placed in some $l<k$ clusters arbitrarily across the graph. For\nthe first case, we develop an algorithm solving dispersion in the presence of\nfaulty robots in $O(k^2)$ rounds, which improves over the previous\n$O(f\\cdot\\text{min}(m,k\\Delta))$-round result by \\cite{PS021}. For the\narbitrary configuration, we present an algorithm solving dispersion in\n$O((f+l)\\cdot\\text{min}(m, k \\Delta, k^2))$ rounds, when the number of edges\n$m$ and the maximum degree $\\Delta$ of the graph is known to the robots.",
    "descriptor": "",
    "authors": [
      "Prabhat Kumar Chand",
      "Manish Kumar",
      "Anisur Rahaman Molla",
      "Sumathi Sivasubramaniam"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.12451"
  },
  {
    "id": "arXiv:2211.12455",
    "title": "ISIM: Iterative Self-Improved Model for Weakly Supervised Segmentation",
    "abstract": "Weakly Supervised Semantic Segmentation (WSSS) is a challenging task aiming\nto learn the segmentation labels from class-level labels. In the literature,\nexploiting the information obtained from Class Activation Maps (CAMs) is widely\nused for WSSS studies. However, as CAMs are obtained from a classification\nnetwork, they are interested in the most discriminative parts of the objects,\nproducing non-complete prior information for segmentation tasks. In this study,\nto obtain more coherent CAMs with segmentation labels, we propose a framework\nthat employs an iterative approach in a modified encoder-decoder-based\nsegmentation model, which simultaneously supports classification and\nsegmentation tasks. As no ground-truth segmentation labels are given, the same\nmodel also generates the pseudo-segmentation labels with the help of dense\nConditional Random Fields (dCRF). As a result, the proposed framework becomes\nan iterative self-improved model. The experiments performed with DeepLabv3 and\nUNet models show a significant gain on the Pascal VOC12 dataset, and the\nDeepLabv3 application increases the current state-of-the-art metric by \\%2.5.\nThe implementation associated with the experiments can be found:\nhttps://github.com/cenkbircanoglu/isim.",
    "descriptor": "\nComments: This paper was submitted to IJCV on 15 Nov 2021. The reviewers decided to reject it. After getting the reviews, we wanted to study more. Unfortunately, one of the authors had severe issues (COVID-19 vaccination). After one year, the study was outdated and similar studies had been published. So, we leave the study by putting it in an archive in case it might have some effect on the literature\n",
    "authors": [
      "Cenk Bircanoglu",
      "Nafiz Arica"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12455"
  },
  {
    "id": "arXiv:2211.12456",
    "title": "Exponential separations using guarded extension variables",
    "abstract": "We study the complexity of proof systems augmenting resolution with inference\nrules that allow, given a formula $\\Gamma$ in conjunctive normal form, deriving\nclauses that are not necessarily logically implied by $\\Gamma$ but whose\naddition to $\\Gamma$ preserves satisfiability. When the derived clauses are\nallowed to introduce variables not occurring in $\\Gamma$, the systems we\nconsider become equivalent to extended resolution. We are concerned with the\nversions of these systems without new variables. They are called BC${}^-$,\nRAT${}^-$, SBC${}^-$, and GER${}^-$, denoting respectively blocked clauses,\nresolution asymmetric tautologies, set-blocked clauses, and generalized\nextended resolution. Each of these systems formalizes some restricted version\nof the ability to make assumptions that hold \"without loss of generality,\"\nwhich is commonly used informally to simplify or shorten proofs.\nExcept for SBC${}^-$, these systems are known to be exponentially weaker than\nextended resolution. They are, however, all equivalent to it under a relaxed\nnotion of simulation that allows the translation of the formula along with the\nproof when moving between proof systems. By taking advantage of this fact, we\nconstruct formulas that separate RAT${}^-$ from GER${}^-$ and vice versa. With\nthe same strategy, we also separate SBC${}^-$ from RAT${}^-$. Additionally, we\ngive polynomial-size SBC${}^-$ proofs of the pigeonhole principle, which\nseparates SBC${}^-$ from GER${}^-$ by a previously known lower bound. These\nresults also separate the three systems from BC${}^-$ since they all simulate\nit. We thus give an almost complete picture of their relative strengths.",
    "descriptor": "",
    "authors": [
      "Emre Yolcu",
      "Marijn J.H. Heule"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.12456"
  },
  {
    "id": "arXiv:2211.12464",
    "title": "Towards peer-to-peer sharing of wireless energy services",
    "abstract": "Crowdsourcing wireless energy services is a novel convenient alternative to\ncharge IoT devices. We demonstrate peer-to-peer wireless energy services\nsharing between smartphones over a distance. Our demo leverages (1) a\nservice-based technique to share energy services, (2) state-of-the-art power\ntransfer technology over a distance, and (3) a mobile application to enable\ncommunication between energy providers and consumers. In addition, our\napplication monitors the charging process between IoT devices to collect a\ndataset for further analysis. Moreover, in this demo, we compare the\npeer-to-peer energy transfer between two smartphones using different charging\ntechnologies, i.e., cable charging, reveres charging, and wireless charging\nover a distance. A set of preliminary experiments has been conducted on a real\ncollected dataset to analyze and demonstrate the behavior of the current\nwireless and traditional charging technologies.",
    "descriptor": "\nComments: 4 pages, 4 figures. This is an accepted demo paper and it will appear in the 20th International Conference on Service Oriented Computing (ICSOC 2022)\n",
    "authors": [
      "Pengwei Yang",
      "Amani Abusafia",
      "Abdallah Lakhdari",
      "Athman Bouguettaya"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.12464"
  },
  {
    "id": "arXiv:2211.12470",
    "title": "A Deep Reinforcement Learning Approach to Rare Event Estimation",
    "abstract": "An important step in the design of autonomous systems is to evaluate the\nprobability that a failure will occur. In safety-critical domains, the failure\nprobability is extremely small so that the evaluation of a policy through Monte\nCarlo sampling is inefficient. Adaptive importance sampling approaches have\nbeen developed for rare event estimation but do not scale well to sequential\nsystems with long horizons. In this work, we develop two adaptive importance\nsampling algorithms that can efficiently estimate the probability of rare\nevents for sequential decision making systems. The basis for these algorithms\nis the minimization of the Kullback-Leibler divergence between a\nstate-dependent proposal distribution and a target distribution over\ntrajectories, but the resulting algorithms resemble policy gradient and\nvalue-based reinforcement learning. We apply multiple importance sampling to\nreduce the variance of our estimate and to address the issue of multi-modality\nin the optimal proposal distribution. We demonstrate our approach on a control\ntask with both continuous and discrete actions spaces and show accuracy\nimprovements over several baselines.",
    "descriptor": "",
    "authors": [
      "Anthony Corso",
      "Kyu-Young Kim",
      "Shubh Gupta",
      "Grace Gao",
      "Mykel J. Kochenderfer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12470"
  },
  {
    "id": "arXiv:2211.12479",
    "title": "Adaptive Prototypical Networks",
    "abstract": "Prototypical network for Few shot learning tries to learn an embedding\nfunction in the encoder that embeds images with similar features close to one\nanother in the embedding space. However, in this process, the support set\nsamples for a task are embedded independently of one other, and hence, the\ninter-class closeness is not taken into account. Thus, in the presence of\nsimilar-looking classes in a task, the embeddings will tend to be close to each\nother in the embedding space and even possibly overlap in some regions, which\nis not desirable for classification. In this paper, we propose an approach that\nintuitively pushes the embeddings of each of the classes away from the others\nin the meta-testing phase, thereby grouping them closely based on the distinct\nclass labels rather than only the similarity of spatial features. This is\nachieved by training the encoder network for classification using the support\nset samples and labels of the new task. Extensive experiments conducted on\nbenchmark data sets show improvements in meta-testing accuracy when compared\nwith Prototypical Networks and also other standard few-shot learning models.",
    "descriptor": "",
    "authors": [
      "Manas Gogoi",
      "Sambhavi Tiwari",
      "Shekhar Verma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12479"
  },
  {
    "id": "arXiv:2211.12481",
    "title": "Quality Analysis of Battery Degradation Models with Real Battery Aging  Experiment Data",
    "abstract": "The installation capacity of energy storage system, especially the battery\nenergy storage system (BESS), has increased significantly in recent years,\nwhich is mainly applied to mitigate the fluctuation caused by renewable energy\nsources (RES) due to the fast response and high round-trip energy efficiency of\nBESS. The main components of majority of BESSs are lithium-ion batteries, which\nwill degrade during the BESS daily operation. Heuristic battery degradation\nmodels are proposed to consider the battery degradation in the operations of\nenergy systems to optimize the scheduling. However, those heuristic models are\nnot evaluated or demonstrated with real battery degradation data. Thus, this\npaper will perform a quality analysis on the popular heuristic battery\ndegradation models using the real battery aging experiment data to evaluate\ntheir performance. A benchmark model is also proposed to represent the real\nbattery degradation value based on the averaged cycle value of the experimental\ndata.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Cunzhi Zhao",
      "Xingpeng Li",
      "Yan Yao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.12481"
  },
  {
    "id": "arXiv:2211.12482",
    "title": "GRATIS: Deep Learning Graph Representation with Task-specific Topology  and Multi-dimensional Edge Features",
    "abstract": "Graph is powerful for representing various types of real-world data. The\ntopology (edges' presence) and edges' features of a graph decides the message\npassing mechanism among vertices within the graph. While most existing\napproaches only manually define a single-value edge to describe the\nconnectivity or strength of association between a pair of vertices,\ntask-specific and crucial relationship cues may be disregarded by such manually\ndefined topology and single-value edge features. In this paper, we propose the\nfirst general graph representation learning framework (called GRATIS) which can\ngenerate a strong graph representation with a task-specific topology and\ntask-specific multi-dimensional edge features from any arbitrary input. To\nlearn each edge's presence and multi-dimensional feature, our framework takes\nboth of the corresponding vertices pair and their global contextual information\ninto consideration, enabling the generated graph representation to have a\nglobally optimal message passing mechanism for different down-stream tasks. The\nprincipled investigation results achieved for various graph analysis tasks on\n11 graph and non-graph datasets show that our GRATIS can not only largely\nenhance pre-defined graphs but also learns a strong graph representation for\nnon-graph data, with clear performance improvements on all tasks. In\nparticular, the learned topology and multi-dimensional edge features provide\ncomplementary task-related cues for graph analysis tasks. Our framework is\neffective, robust and flexible, and is a plug-and-play module that can be\ncombined with different backbones and Graph Neural Networks (GNNs) to generate\na task-specific graph representation from various graph and non-graph data. Our\ncode is made publicly available at\nhttps://github.com/SSYSteve/Learning-Graph-Representation-with-Task-specific-Topology-and-Multi-dimensional-Edge-Features.",
    "descriptor": "",
    "authors": [
      "Siyang Song",
      "Yuxin Song",
      "Cheng Luo",
      "Zhiyuan Song",
      "Selim Kuzucu",
      "Xi Jia",
      "Zhijiang Guo",
      "Weicheng Xie",
      "Linlin Shen",
      "Hatice Gunes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12482"
  },
  {
    "id": "arXiv:2211.12483",
    "title": "PIC-Score: Probabilistic Interpretable Comparison Score for Optimal  Matching Confidence in Single- and Multi-Biometric (Face) Recognition",
    "abstract": "In the context of biometrics, matching confidence refers to the confidence\nthat a given matching decision is correct. Since many biometric systems operate\nin critical decision-making processes, such as in forensics investigations,\naccurately and reliably stating the matching confidence becomes of high\nimportance. Previous works on biometric confidence estimation can well\ndifferentiate between high and low confidence, but lack interpretability.\nTherefore, they do not provide accurate probabilistic estimates of the\ncorrectness of a decision. In this work, we propose a probabilistic\ninterpretable comparison (PIC) score that accurately reflects the probability\nthat the score originates from samples of the same identity. We prove that the\nproposed approach provides optimal matching confidence. Contrary to other\napproaches, it can also optimally combine multiple samples in a joint PIC score\nwhich further increases the recognition and confidence estimation performance.\nIn the experiments, the proposed PIC approach is compared against all biometric\nconfidence estimation methods available on four publicly available databases\nand five state-of-the-art face recognition systems. The results demonstrate\nthat PIC has a significantly more accurate probabilistic interpretation than\nsimilar approaches and is highly effective for multi-biometric recognition. The\ncode is publicly-available.",
    "descriptor": "",
    "authors": [
      "Pedro C. Neto",
      "Ana F. Sequeira",
      "Jaime S. Cardoso",
      "Philipp Terh\u00f6rst"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12483"
  },
  {
    "id": "arXiv:2211.12485",
    "title": "HyperTuning: Toward Adapting Large Language Models without  Back-propagation",
    "abstract": "Fine-tuning large language models for different tasks can be costly and\ninefficient, and even methods that reduce the number of tuned parameters still\nrequire full gradient-based optimization. We propose HyperTuning, a novel\napproach to model adaptation that uses a hypermodel to generate task-specific\nparameters for a fixed downstream model. We demonstrate a simple setup for\nhypertuning with HyperT5, a T5-based hypermodel that produces soft prefixes or\nLoRA parameters for a frozen T5 model from few-shot examples. We train HyperT5\nin two stages: first, hyperpretraining with a modified conditional language\nmodeling objective that trains a hypermodel to generate parameters; second,\nmulti-task fine-tuning (MTF) on a large number of diverse language tasks. We\nevaluate HyperT5 on P3, MetaICL and Super-NaturalInstructions datasets, and\nshow that it can effectively generate parameters for unseen tasks. Moreover, we\nshow that using hypermodel-generated parameters as initializations for further\nparameter-efficient fine-tuning improves performance. HyperTuning can thus be a\nflexible and efficient way to leverage large language models for diverse\ndownstream applications.",
    "descriptor": "",
    "authors": [
      "Jason Phang",
      "Yi Mao",
      "Pengcheng He",
      "Weizhu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.12485"
  },
  {
    "id": "arXiv:2211.12486",
    "title": "Shortcomings of Top-Down Randomization-Based Sanity Checks for  Evaluations of Deep Neural Network Explanations",
    "abstract": "While the evaluation of explanations is an important step towards trustworthy\nmodels, it needs to be done carefully, and the employed metrics need to be\nwell-understood. Specifically model randomization testing is often\noverestimated and regarded as a sole criterion for selecting or discarding\ncertain explanation methods. To address shortcomings of this test, we start by\nobserving an experimental gap in the ranking of explanation methods between\nrandomization-based sanity checks [1] and model output faithfulness measures\n(e.g. [25]). We identify limitations of model-randomization-based sanity checks\nfor the purpose of evaluating explanations. Firstly, we show that uninformative\nattribution maps created with zero pixel-wise covariance easily achieve high\nscores in this type of checks. Secondly, we show that top-down model\nrandomization preserves scales of forward pass activations with high\nprobability. That is, channels with large activations have a high probility to\ncontribute strongly to the output, even after randomization of the network on\ntop of them. Hence, explanations after randomization can only be expected to\ndiffer to a certain extent. This explains the observed experimental gap. In\nsummary, these results demonstrate the inadequacy of model-randomization-based\nsanity checks as a criterion to rank attribution methods.",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Alexander Binder",
      "Leander Weber",
      "Sebastian Lapuschkin",
      "Gr\u00e9goire Montavon",
      "Klaus-Robert M\u00fcller",
      "Wojciech Samek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12486"
  },
  {
    "id": "arXiv:2211.12487",
    "title": "An Incremental Tensor Train Decomposition Algorithm",
    "abstract": "We present a new algorithm for incrementally updating the tensor-train\ndecomposition of a stream of tensor data. This new algorithm, called the\ntensor-train incremental core expansion (TT-ICE) improves upon the current\nstate-of-the-art algorithms for compressing in tensor-train format by\ndeveloping a new adaptive approach that incurs significantly slower rank growth\nand guarantees compression accuracy. This capability is achieved by limiting\nthe number of new vectors appended to the TT-cores of an existing accumulation\ntensor after each data increment. These vectors represent directions orthogonal\nto the span of existing cores and are limited to those needed to represent a\nnewly arrived tensor to a target accuracy. We provide two versions of the\nalgorithm: TT-ICE and TT-ICE accelerated with heuristics (TT-ICE$^*$). We\nprovide a proof of correctness for TT-ICE and empirically demonstrate the\nperformance of the algorithms in compressing large-scale video and scientific\nsimulation datasets. Compared to existing approaches that also use rank\nadaptation, TT-ICE$^*$ achieves 57$\\times$ higher compression and up to 95%\nreduction in computational time.",
    "descriptor": "\nComments: 22 pages, 7 figures, for the python code of TT-ICE and TT-ICE$^*$ algorithms see this https URL\n",
    "authors": [
      "Doruk Aksoy",
      "David J. Gorsich",
      "Shravan Veerapaneni",
      "Alex A. Gorodetsky"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.12487"
  },
  {
    "id": "arXiv:2211.12490",
    "title": "Minimal positive stencils in meshfree finite difference methods for  linear elliptic equations in non-divergence form",
    "abstract": "We design a monotone meshfree finite difference method for linear elliptic\nequations in the non-divergence form on point clouds via a nonlocal relaxation\nmethod. Nonlocal approximations of linear elliptic equations are first\nintroduced to which a meshfree finite difference method applies. Minimal\npositive stencils are obtained through a local $l_1$-type optimization\nprocedure that automatically guarantees the stability and, therefore, the\nconvergence of the meshfree discretization for linear elliptic equations. The\nkey to the success of the method relies on the existence of positive stencils\nfor a given point cloud geometry. We provide sufficient conditions for the\nexistence of positive stencils by finding neighbors within an ellipse (2d) or\nellipsoid (3d) surrounding each interior point, generalizing the study for\nPoisson's equation by Seibold in 2008. It is well-known that wide stencils are\nin general needed for constructing consistent and monotone finite difference\nschemes for linear elliptic equations. Our study improves the known theoretical\nresults on the existence of positive stencils for linear elliptic equations\nwhen the ellipticity constant becomes small. Numerical algorithms and practical\nguidance are provided with an eye on the case of small ellipticity constant. We\npresent numerical results in 2d and 3d at the end.",
    "descriptor": "",
    "authors": [
      "Qihao Ye",
      "Xiaochuan Tian"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.12490"
  },
  {
    "id": "arXiv:2211.12491",
    "title": "ModelDiff: A Framework for Comparing Learning Algorithms",
    "abstract": "We study the problem of (learning) algorithm comparison, where the goal is to\nfind differences between models trained with two different learning algorithms.\nWe begin by formalizing this goal as one of finding distinguishing feature\ntransformations, i.e., input transformations that change the predictions of\nmodels trained with one learning algorithm but not the other. We then present\nModelDiff, a method that leverages the datamodels framework (Ilyas et al.,\n2022) to compare learning algorithms based on how they use their training data.\nWe demonstrate ModelDiff through three case studies, comparing models trained\nwith/without data augmentation, with/without pre-training, and with different\nSGD hyperparameters. Our code is available at\nhttps://github.com/MadryLab/modeldiff .",
    "descriptor": "",
    "authors": [
      "Harshay Shah",
      "Sung Min Park",
      "Andrew Ilyas",
      "Aleksander Madry"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.12491"
  },
  {
    "id": "arXiv:2211.12492",
    "title": "VideoMap: Video Editing in Latent Space",
    "abstract": "Video has become a dominant form of media. However, video editing interfaces\nhave remained largely unchanged over the past two decades. Such interfaces\ntypically consist of a grid-like asset management panel and a linear editing\ntimeline. When working with a large number of video clips, it can be difficult\nto sort through them all and identify patterns within (e.g. opportunities for\nsmooth transitions and storytelling). In this work, we imagine a new paradigm\nfor video editing by mapping videos into a 2D latent space and building a\nproof-of-concept interface.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022 Workshop on Machine Learning for Creativity and Design. Website: this https URL\n",
    "authors": [
      "David Chuan-En Lin",
      "Fabian Caba Heilbron",
      "Joon-Young Lee",
      "Oliver Wang",
      "Nikolas Martelaro"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.12492"
  },
  {
    "id": "arXiv:2211.12493",
    "title": "Videogenic: Video Highlights via Photogenic Moments",
    "abstract": "This paper investigates the challenge of extracting highlight moments from\nvideos. To perform this task, a system needs to understand what constitutes a\nhighlight for arbitrary video domains while at the same time being able to\nscale across different domains. Our key insight is that photographs taken by\nphotographers tend to capture the most remarkable or photogenic moments of an\nactivity. Drawing on this insight, we present Videogenic, a system capable of\ncreating domain-specific highlight videos for a wide range of domains. In a\nhuman evaluation study (N=50), we show that a high-quality photograph\ncollection combined with CLIP-based retrieval (which uses a neural network with\nsemantic knowledge of images) can serve as an excellent prior for finding video\nhighlights. In a within-subjects expert study (N=12), we demonstrate the\nusefulness of Videogenic in helping video editors create highlight videos with\nlighter workload, shorter task completion time, and better usability.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022 Workshop on Machine Learning for Creativity and Design. Website: this https URL\n",
    "authors": [
      "David Chuan-En Lin",
      "Fabian Caba Heilbron",
      "Joon-Young Lee",
      "Oliver Wang",
      "Nikolas Martelaro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.12493"
  },
  {
    "id": "arXiv:2211.12494",
    "title": "On the Transferability of Visual Features in Generalized Zero-Shot  Learning",
    "abstract": "Generalized Zero-Shot Learning (GZSL) aims to train a classifier that can\ngeneralize to unseen classes, using a set of attributes as auxiliary\ninformation, and the visual features extracted from a pre-trained convolutional\nneural network. While recent GZSL methods have explored various techniques to\nleverage the capacity of these features, there has been an extensive growth of\nrepresentation learning techniques that remain under-explored. In this work, we\ninvestigate the utility of different GZSL methods when using different feature\nextractors, and examine how these models' pre-training objectives, datasets,\nand architecture design affect their feature representation ability. Our\nresults indicate that 1) methods using generative components for GZSL provide\nmore advantages when using recent feature extractors; 2) feature extractors\npre-trained using self-supervised learning objectives and knowledge\ndistillation provide better feature representations, increasing up to 15%\nperformance when used with recent GZSL techniques; 3) specific feature\nextractors pre-trained with larger datasets do not necessarily boost the\nperformance of GZSL methods. In addition, we investigate how GZSL methods fare\nagainst CLIP, a more recent multi-modal pre-trained model with strong zero-shot\nperformance. We found that GZSL tasks still benefit from generative-based GZSL\nmethods along with CLIP's internet-scale pre-training to achieve\nstate-of-the-art performance in fine-grained datasets. We release a modular\nframework for analyzing representation learning issues in GZSL here:\nhttps://github.com/uvavision/TV-GZSL",
    "descriptor": "",
    "authors": [
      "Paola Cascante-Bonilla",
      "Leonid Karlinsky",
      "James Seale Smith",
      "Yanjun Qi",
      "Vicente Ordonez"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12494"
  },
  {
    "id": "arXiv:2211.12496",
    "title": "An Algorithmic Bridge Between Hamming and Levenshtein Distances",
    "abstract": "The edit distance between strings classically assigns unit cost to every\ncharacter insertion, deletion, and substitution, whereas the Hamming distance\nonly allows substitutions. In many real-life scenarios, insertions and\ndeletions (abbreviated indels) appear frequently but significantly less so than\nsubstitutions. To model this, we consider substitutions being cheaper than\nindels, with cost $1/a$ for a parameter $a\\ge 1$. This basic variant, denoted\n$ED_a$, bridges classical edit distance ($a=1$) with Hamming distance\n($a\\to\\infty$), leading to interesting algorithmic challenges: Does the time\ncomplexity of computing $ED_a$ interpolate between that of Hamming distance\n(linear time) and edit distance (quadratic time)? What about approximating\n$ED_a$?\nWe first present a simple deterministic exact algorithm for $ED_a$ and\nfurther prove that it is near-optimal assuming the Orthogonal Vectors\nConjecture. Our main result is a randomized algorithm computing a\n$(1+\\epsilon)$-approximation of $ED_a(X,Y)$, given strings $X,Y$ of total\nlength $n$ and a bound $k\\ge ED_a(X,Y)$. For simplicity, let us focus on $k\\ge\n1$ and a constant $\\epsilon > 0$; then, our algorithm takes $\\tilde{O}(n/a +\nak^3)$ time. Unless $a=\\tilde{O}(1)$ and for small enough $k$, this running\ntime is sublinear in $n$. We also consider a very natural version that asks to\nfind a $(k_I, k_S)$-alignment -- an alignment with at most $k_I$ indels and\n$k_S$ substitutions. In this setting, we give an exact algorithm and, more\nimportantly, an $\\tilde{O}(nk_I/k_S + k_S\\cdot k_I^3)$-time\n$(1,1+\\epsilon)$-bicriteria approximation algorithm. The latter solution is\nbased on the techniques we develop for $ED_a$ for $a=\\Theta(k_S / k_I)$. These\nbounds are in stark contrast to unit-cost edit distance, where state-of-the-art\nalgorithms are far from achieving $(1+\\epsilon)$-approximation in sublinear\ntime, even for a favorable choice of $k$.",
    "descriptor": "\nComments: The full version of a paper accepted to ITCS 2023; abstract shortened to meet arXiv requirements\n",
    "authors": [
      "Elazar Goldenberg",
      "Tomasz Kociumaka",
      "Robert Krauthgamer",
      "Barna Saha"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.12496"
  },
  {
    "id": "arXiv:2211.12497",
    "title": "MagicPony: Learning Articulated 3D Animals in the Wild",
    "abstract": "We consider the problem of learning a function that can estimate the 3D\nshape, articulation, viewpoint, texture, and lighting of an articulated animal\nlike a horse, given a single test image. We present a new method, dubbed\nMagicPony, that learns this function purely from in-the-wild single-view images\nof the object category, with minimal assumptions about the topology of\ndeformation. At its core is an implicit-explicit representation of articulated\nshape and appearance, combining the strengths of neural fields and meshes. In\norder to help the model understand an object's shape and pose, we distil the\nknowledge captured by an off-the-shelf self-supervised vision transformer and\nfuse it into the 3D model. To overcome common local optima in viewpoint\nestimation, we further introduce a new viewpoint sampling scheme that comes at\nno added training cost. Compared to prior works, we show significant\nquantitative and qualitative improvements on this challenging task. The model\nalso demonstrates excellent generalisation in reconstructing abstract drawings\nand artefacts, despite the fact that it is only trained on real images.",
    "descriptor": "\nComments: Project Page: this https URL\n",
    "authors": [
      "Shangzhe Wu",
      "Ruining Li",
      "Tomas Jakab",
      "Christian Rupprecht",
      "Andrea Vedaldi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12497"
  },
  {
    "id": "arXiv:2211.12498",
    "title": "Touch and Go: Learning from Human-Collected Vision and Touch",
    "abstract": "The ability to associate touch with sight is essential for tasks that require\nphysically interacting with objects in the world. We propose a dataset with\npaired visual and tactile data called Touch and Go, in which human data\ncollectors probe objects in natural environments using tactile sensors, while\nsimultaneously recording egocentric video. In contrast to previous efforts,\nwhich have largely been confined to lab settings or simulated environments, our\ndataset spans a large number of \"in the wild\" objects and scenes. To\ndemonstrate our dataset's effectiveness, we successfully apply it to a variety\nof tasks: 1) self-supervised visuo-tactile feature learning, 2) tactile-driven\nimage stylization, i.e., making the visual appearance of an object more\nconsistent with a given tactile signal, and 3) predicting future frames of a\ntactile signal from visuo-tactile inputs.",
    "descriptor": "\nComments: Accepted by NeurIPS 2022 Track of Datasets and Benchmarks\n",
    "authors": [
      "Fengyu Yang",
      "Chenyang Ma",
      "Jiacheng Zhang",
      "Jing Zhu",
      "Wenzhen Yuan",
      "Andrew Owens"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12498"
  },
  {
    "id": "arXiv:2211.12499",
    "title": "Instant Volumetric Head Avatars",
    "abstract": "We present Instant Volumetric Head Avatars (INSTA), a novel approach for\nreconstructing photo-realistic digital avatars instantaneously. INSTA models a\ndynamic neural radiance field based on neural graphics primitives embedded\naround a parametric face model. Our pipeline is trained on a single monocular\nRGB portrait video that observes the subject under different expressions and\nviews. While state-of-the-art methods take up to several days to train an\navatar, our method can reconstruct a digital avatar in less than 10 minutes on\nmodern GPU hardware, which is orders of magnitude faster than previous\nsolutions. In addition, it allows for the interactive rendering of novel poses\nand expressions. By leveraging the geometry prior of the underlying parametric\nface model, we demonstrate that INSTA extrapolates to unseen poses. In\nquantitative and qualitative studies on various subjects, INSTA outperforms\nstate-of-the-art methods regarding rendering quality and training time.",
    "descriptor": "\nComments: Website: this https URL Video: this https URL\n",
    "authors": [
      "Wojciech Zielonka",
      "Timo Bolkart",
      "Justus Thies"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12499"
  },
  {
    "id": "arXiv:2211.12500",
    "title": "Person Image Synthesis via Denoising Diffusion Model",
    "abstract": "The pose-guided person image generation task requires synthesizing\nphotorealistic images of humans in arbitrary poses. The existing approaches use\ngenerative adversarial networks that do not necessarily maintain realistic\ntextures or need dense correspondences that struggle to handle complex\ndeformations and severe occlusions. In this work, we show how denoising\ndiffusion models can be applied for high-fidelity person image synthesis with\nstrong sample diversity and enhanced mode coverage of the learnt data\ndistribution. Our proposed Person Image Diffusion Model (PIDM) disintegrates\nthe complex transfer problem into a series of simpler forward-backward\ndenoising steps. This helps in learning plausible source-to-target\ntransformation trajectories that result in faithful textures and undistorted\nappearance details. We introduce a 'texture diffusion module' based on\ncross-attention to accurately model the correspondences between appearance and\npose information available in source and target images. Further, we propose\n'disentangled classifier-free guidance' to ensure close resemblance between the\nconditional inputs and the synthesized output in terms of both pose and\nappearance information. Our extensive results on two large-scale benchmarks and\na user study demonstrate the photorealism of our proposed approach under\nchallenging scenarios. We also show how our generated images can help in\ndownstream tasks. Our code and models will be publicly released.",
    "descriptor": "",
    "authors": [
      "Ankan Kumar Bhunia",
      "Salman Khan",
      "Hisham Cholakkal",
      "Rao Muhammad Anwer",
      "Jorma Laaksonen",
      "Mubarak Shah",
      "Fahad Shahbaz Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12500"
  },
  {
    "id": "arXiv:2211.12501",
    "title": "AeDet: Azimuth-invariant Multi-view 3D Object Detection",
    "abstract": "Recent LSS-based multi-view 3D object detection has made tremendous progress,\nby processing the features in Brid-Eye-View (BEV) via the convolutional\ndetector. However, the typical convolution ignores the radial symmetry of the\nBEV features and increases the difficulty of the detector optimization. To\npreserve the inherent property of the BEV features and ease the optimization,\nwe propose an azimuth-equivariant convolution (AeConv) and an\nazimuth-equivariant anchor. The sampling grid of AeConv is always in the radial\ndirection, thus it can learn azimuth-invariant BEV features. The proposed\nanchor enables the detection head to learn predicting azimuth-irrelevant\ntargets. In addition, we introduce a camera-decoupled virtual depth to unify\nthe depth prediction for the images with different camera intrinsic parameters.\nThe resultant detector is dubbed Azimuth-equivariant Detector (AeDet).\nExtensive experiments are conducted on nuScenes, and AeDet achieves a 62.0%\nNDS, surpassing the recent multi-view 3D object detectors such as PETRv2 (58.2%\nNDS) and BEVDepth (60.0% NDS) by a large margin. Project page:\nhttps://fcjian.github.io/aedet.",
    "descriptor": "\nComments: Tech report\n",
    "authors": [
      "Chengjian Feng",
      "Zequn Jie",
      "Yujie Zhong",
      "Xiangxiang Chu",
      "Lin Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12501"
  },
  {
    "id": "arXiv:2211.11749",
    "title": "Towards Automatic Prediction of Outcome in Treatment of Cerebral  Aneurysms",
    "abstract": "Intrasaccular flow disruptors treat cerebral aneurysms by diverting the blood\nflow from the aneurysm sac. Residual flow into the sac after the intervention\nis a failure that could be due to the use of an undersized device, or to\nvascular anatomy and clinical condition of the patient. We report a machine\nlearning model based on over 100 clinical and imaging features that predict the\noutcome of wide-neck bifurcation aneurysm treatment with an intravascular\nembolization device. We combine clinical features with a diverse set of common\nand novel imaging measurements within a random forest model. We also develop\nneural network segmentation algorithms in 2D and 3D to contour the sac in\nangiographic images and automatically calculate the imaging features. These\ndeliver 90% overlap with manual contouring in 2D and 83% in 3D. Our predictive\nmodel classifies complete vs. partial occlusion outcomes with an accuracy of\n75.31%, and weighted F1-score of 0.74.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Ashutosh Jadhav",
      "Satyananda Kashyap",
      "Hakan Bulu",
      "Ronak Dholakia",
      "Amon Y. Liu",
      "Tanveer Syeda-Mahmood",
      "William R. Patterson",
      "Hussain Rangwala",
      "Mehdi Moradi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.11749"
  },
  {
    "id": "arXiv:2211.11750",
    "title": "Self-attention based high order sequence feature reconstruction of  dynamic functional connectivity networks with rs-fMRI for brain disease  classification",
    "abstract": "Dynamic functional connectivity networks (dFCN) based on rs-fMRI have\ndemonstrated tremendous potential for brain function analysis and brain disease\nclassification. Recently, studies have applied deep learning techniques (i.e.,\nconvolutional neural network, CNN) to dFCN classification, and achieved better\nperformance than the traditional machine learning methods. Nevertheless,\nprevious deep learning methods usually perform successive convolutional\noperations on the input dFCNs to obtain high-order brain network aggregation\nfeatures, extracting them from each sliding window using a series split, which\nmay neglect non-linear correlations among different regions and the\nsequentiality of information. Thus, important high-order sequence information\nof dFCNs, which could further improve the classification performance, is\nignored in these studies. Nowadays, inspired by the great success of\nTransformer in natural language processing and computer vision, some latest\nwork has also emerged on the application of Transformer for brain disease\ndiagnosis based on rs-fMRI data. Although Transformer is capable of capturing\nnon-linear correlations, it lacks accounting for capturing local spatial\nfeature patterns and modelling the temporal dimension due to parallel\ncomputing, even equipped with a positional encoding technique. To address these\nissues, we propose a self-attention (SA) based convolutional recurrent network\n(SA-CRN) learning framework for brain disease classification with rs-fMRI data.\nThe experimental results on a public dataset (i.e., ADNI) demonstrate the\neffectiveness of our proposed SA-CRN method.",
    "descriptor": "",
    "authors": [
      "Zhixiang Zhang",
      "Biao Jie",
      "Zhengdong Wang",
      "Jie Zhou",
      "Yang Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2211.11750"
  },
  {
    "id": "arXiv:2211.11803",
    "title": "Deep learning and American options via free boundary framework",
    "abstract": "We propose a deep learning method for solving the American options model with\na free boundary feature. To extract the free boundary known as the early\nexercise boundary from our proposed method, we introduce the Landau\ntransformation. For efficient implementation of our proposed method, we further\nconstruct a dual solution framework consisting of a novel auxiliary function\nand free boundary equations. The auxiliary function is formulated to include\nthe feed forward deep neural network (DNN) output and further mimic the far\nboundary behaviour, smooth pasting condition, and remaining boundary conditions\ndue to the second-order space derivative and first-order time derivative.\nBecause the early exercise boundary and its derivative are not a priori known,\nthe boundary values mimicked by the auxiliary function are in approximate form.\nConcurrently, we then establish equations that approximate the early exercise\nboundary and its derivative directly from the DNN output based on some linear\nrelationships at the left boundary. Furthermore, the option Greeks are obtained\nfrom the derivatives of this auxiliary function. We test our implementation\nwith several examples and compare them to the highly accurate sixth-order\ncompact scheme with left boundary improvement. All indicators show that our\nproposed deep learning method presents an efficient and alternative way of\npricing options with early exercise features.",
    "descriptor": "",
    "authors": [
      "Chinonso Nwankwo",
      "Nneka Umeorah",
      "Tony Ware",
      "Weizhong Dai"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)",
      "Mathematical Finance (q-fin.MF)",
      "Pricing of Securities (q-fin.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.11803"
  },
  {
    "id": "arXiv:2211.11810",
    "title": "Sample-optimal classical shadows for pure states",
    "abstract": "We consider the classical shadows task for pure states in the setting of both\njoint and independent measurements. The task is to measure few copies of an\nunknown pure state $\\rho$ in order to learn a classical description which\nsuffices to later estimate expectation values of observables. Specifically, the\ngoal is to approximate $\\mathrm{Tr}(O \\rho)$ for any Hermitian observable $O$\nto within additive error $\\epsilon$ provided $\\mathrm{Tr}(O^2)\\leq B$ and\n$\\lVert O \\rVert = 1$. Our main result applies to the joint measurement\nsetting, where we show $\\tilde{\\Theta}(\\sqrt{B}\\epsilon^{-1} + \\epsilon^{-2})$\nsamples of $\\rho$ are necessary and sufficient to succeed with high\nprobability. The upper bound is a quadratic improvement on the previous best\nsample complexity known for this problem. For the lower bound, we see that the\nbottleneck is not how fast we can learn the state but rather how much any\nclassical description of $\\rho$ can be compressed for observable estimation. In\nthe independent measurement setting, we show that $\\mathcal O(\\sqrt{Bd}\n\\epsilon^{-1} + \\epsilon^{-2})$ samples suffice. Notably, this implies that the\nrandom Clifford measurements algorithm of Huang, Kueng, and Preskill, which is\nsample-optimal for mixed states, is not optimal for pure states. Interestingly,\nour result also uses the same random Clifford measurements but employs a\ndifferent estimator.",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Daniel Grier",
      "Hakop Pashayan",
      "Luke Schaeffer"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11810"
  },
  {
    "id": "arXiv:2211.11820",
    "title": "Machine-learned climate model corrections from a global storm-resolving  model",
    "abstract": "Due to computational constraints, running global climate models (GCMs) for\nmany years requires a lower spatial grid resolution (${\\gtrsim}50$ km) than is\noptimal for accurately resolving important physical processes. Such processes\nare approximated in GCMs via subgrid parameterizations, which contribute\nsignificantly to the uncertainty in GCM predictions. One approach to improving\nthe accuracy of a coarse-grid global climate model is to add machine-learned\nstate-dependent corrections at each simulation timestep, such that the climate\nmodel evolves more like a high-resolution global storm-resolving model (GSRM).\nWe train neural networks to learn the state-dependent temperature, humidity,\nand radiative flux corrections needed to nudge a 200 km coarse-grid climate\nmodel to the evolution of a 3~km fine-grid GSRM. When these corrective ML\nmodels are coupled to a year-long coarse-grid climate simulation, the time-mean\nspatial pattern errors are reduced by 6-25% for land surface temperature and\n9-25% for land surface precipitation with respect to a no-ML baseline\nsimulation. The ML-corrected simulations develop other biases in climate and\ncirculation that differ from, but have comparable amplitude to, the baseline\nsimulation.",
    "descriptor": "",
    "authors": [
      "Anna Kwa",
      "Spencer K. Clark",
      "Brian Henn",
      "Noah D. Brenowitz",
      "Jeremy McGibbon",
      "W. Andre Perkins",
      "Oliver Watt-Meyer",
      "Lucas Harris",
      "Christopher S. Bretherton"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11820"
  },
  {
    "id": "arXiv:2211.11822",
    "title": "CONFIG: Constrained Efficient Global Optimization for Closed-Loop  Control System Optimization with Unmodeled Constraints",
    "abstract": "In this paper, the CONFIG algorithm, a simple and provably efficient\nconstrained global optimization algorithm, is applied to optimize the\nclosed-loop control performance of an unknown system with unmodeled\nconstraints. Existing Gaussian process based closed-loop optimization methods,\neither can only guarantee local convergence (e.g., SafeOPT), or have no known\noptimality guarantee (e.g., constrained expected improvement) at all, whereas\nthe recently introduced CONFIG algorithm has been proven to enjoy a theoretical\nglobal optimality guarantee. In this study, we demonstrate the effectiveness of\nCONFIG algorithm in the applications. The algorithm is first applied to an\nartificial numerical benchmark problem to corroborate its effectiveness. It is\nthen applied to a classical constrained steady-state optimization problem of a\ncontinuous stirred-tank reactor. Simulation results show that our CONFIG\nalgorithm can achieve performance competitive with the popular CEI (Constrained\nExpected Improvement) algorithm, which has no known optimality guarantee. As\nsuch, the CONFIG algorithm offers a new tool, with both a provable global\noptimality guarantee and competitive empirical performance, to optimize the\nclosed-loop control performance for a system with soft unmodeled constraints.\nLast, but not least, the open-source code is available as a python package to\nfacilitate future applications.",
    "descriptor": "",
    "authors": [
      "Wenjie Xu",
      "Yuning Jiang",
      "Bratislav Svetozarevic",
      "Colin N. Jones"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.11822"
  },
  {
    "id": "arXiv:2211.11827",
    "title": "High-Perceptual Quality JPEG Decoding via Posterior Sampling",
    "abstract": "JPEG is arguably the most popular image coding format, achieving high\ncompression ratios via lossy quantization that may create visual artifacts\ndegradation. Numerous attempts to remove these artifacts were conceived over\nthe years, and common to most of these is the use of deterministic\npost-processing algorithms that optimize some distortion measure (e.g., PSNR,\nSSIM). In this paper we propose a different paradigm for JPEG artifact\ncorrection: Our method is stochastic, and the objective we target is high\nperceptual quality -- striving to obtain sharp, detailed and visually pleasing\nreconstructed images, while being consistent with the compressed input. These\ngoals are achieved by training a stochastic conditional generator (conditioned\non the compressed input), accompanied by a theoretically well-founded loss\nterm, resulting in a sampler from the posterior distribution. Our solution\noffers a diverse set of plausible and fast reconstructions for a given input\nwith perfect consistency. We demonstrate our scheme's unique properties and its\nsuperiority to a variety of alternative methods on the FFHQ and ImageNet\ndatasets.",
    "descriptor": "",
    "authors": [
      "Sean Man",
      "Guy Ohayon",
      "Theo Adrai",
      "Michael Elad"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11827"
  },
  {
    "id": "arXiv:2211.11836",
    "title": "Towards Live 3D Reconstruction from Wearable Video: An Evaluation of  V-SLAM, NeRF, and Videogrammetry Techniques",
    "abstract": "Mixed reality (MR) is a key technology which promises to change the future of\nwarfare. An MR hybrid of physical outdoor environments and virtual military\ntraining will enable engagements with long distance enemies, both real and\nsimulated. To enable this technology, a large-scale 3D model of a physical\nenvironment must be maintained based on live sensor observations. 3D\nreconstruction algorithms should utilize the low cost and pervasiveness of\nvideo camera sensors, from both overhead and soldier-level perspectives.\nMapping speed and 3D quality can be balanced to enable live MR training in\ndynamic environments. Given these requirements, we survey several 3D\nreconstruction algorithms for large-scale mapping for military applications\ngiven only live video. We measure 3D reconstruction performance from common\nstructure from motion, visual-SLAM, and photogrammetry techniques. This\nincludes the open source algorithms COLMAP, ORB-SLAM3, and NeRF using\nInstant-NGP. We utilize the autonomous driving academic benchmark KITTI, which\nincludes both dashboard camera video and lidar produced 3D ground truth. With\nthe KITTI data, our primary contribution is a quantitative evaluation of 3D\nreconstruction computational speed when considering live video.",
    "descriptor": "\nComments: Accepted to 2022 Interservice/Industry Training, Simulation, and Education Conference (I/ITSEC), 13 pages\n",
    "authors": [
      "David Ramirez",
      "Suren Jayasuriya",
      "Andreas Spanias"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11836"
  },
  {
    "id": "arXiv:2211.11865",
    "title": "Bayesian Learning for Neural Networks: an algorithmic survey",
    "abstract": "The last decade witnessed a growing interest in Bayesian learning. Yet, the\ntechnicality of the topic and the multitude of ingredients involved therein,\nbesides the complexity of turning theory into practical implementations, limit\nthe use of the Bayesian learning paradigm, preventing its widespread adoption\nacross different fields and applications. This self-contained survey engages\nand introduces readers to the principles and algorithms of Bayesian Learning\nfor Neural Networks. It provides an introduction to the topic from an\naccessible, practical-algorithmic perspective. Upon providing a general\nintroduction to Bayesian Neural Networks, we discuss and present both standard\nand recent approaches for Bayesian inference, with an emphasis on solutions\nrelying on Variational Inference and the use of Natural gradients. We also\ndiscuss the use of manifold optimization as a state-of-the-art approach to\nBayesian learning. We examine the characteristic properties of all the\ndiscussed methods, and provide pseudo-codes for their implementation, paying\nattention to practical aspects, such as the computation of the gradients",
    "descriptor": "",
    "authors": [
      "Martin Magris",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11865"
  },
  {
    "id": "arXiv:2211.11872",
    "title": "Classification of Melanocytic Nevus Images using BigTransfer (BiT)",
    "abstract": "Skin cancer is a fatal disease that takes a heavy toll over human lives\nannually. The colored skin images show a significant degree of resemblance\nbetween different skin lesions such as melanoma and nevus, making\nidentification and diagnosis more challenging. Melanocytic nevi may mature to\ncause fatal melanoma. Therefore, the current management protocol involves the\nremoval of those nevi that appear intimidating. However, this necessitates\nresilient classification paradigms for classifying benign and malignant\nmelanocytic nevi. Early diagnosis necessitates a dependable automated system\nfor melanocytic nevi classification to render diagnosis efficient, timely, and\nsuccessful. An automated classification algorithm is proposed in the given\nresearch. A neural network previously-trained on a separate problem statement\nis leveraged in this technique for classifying melanocytic nevus images. The\nsuggested method uses BigTransfer (BiT), a ResNet-based transfer learning\napproach for classifying melanocytic nevi as malignant or benign. The results\nobtained are compared to that of current techniques, and the new method's\nclassification rate is proven to outperform that of existing methods.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Sanya Sinha",
      "Nilay Gupta"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11872"
  },
  {
    "id": "arXiv:2211.11891",
    "title": "A Bi-level Nonlinear Eigenvector Algorithm for Wasserstein Discriminant  Analysis",
    "abstract": "Much like the classical Fisher linear discriminant analysis, Wasserstein\ndiscriminant analysis (WDA) is a supervised linear dimensionality reduction\nmethod that seeks a projection matrix to maximize the dispersion of different\ndata classes and minimize the dispersion of same data classes. However, in\ncontrast, WDA can account for both global and local inter-connections between\ndata classes using a regularized Wasserstein distance. WDA is formulated as a\nbi-level nonlinear trace ratio optimization. In this paper, we present a\nbi-level nonlinear eigenvector (NEPv) algorithm, called WDA-nepv. The inner\nkernel of WDA-nepv for computing the optimal transport matrix of the\nregularized Wasserstein distance is formulated as an NEPv, and meanwhile the\nouter kernel for the trace ratio optimization is also formulated as another\nNEPv. Consequently, both kernels can be computed efficiently via\nself-consistent-field iterations and modern solvers for linear eigenvalue\nproblems. Comparing with the existing algorithms for WDA, WDA-nepv is\nderivative-free and surrogate-model-free. The computational efficiency and\napplications in classification accuracy of WDA-nepv are demonstrated using\nsynthetic and real-life datasets.",
    "descriptor": "",
    "authors": [
      "Dong Min Roh",
      "Zhaojun Bai"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11891"
  },
  {
    "id": "arXiv:2211.11892",
    "title": "Equality of Effort via Algorithmic Recourse",
    "abstract": "This paper proposes a method for measuring fairness through equality of\neffort by applying algorithmic recourse through minimal interventions. Equality\nof effort is a property that can be quantified at both the individual and the\ngroup level. It answers the counterfactual question: what is the minimal cost\nfor a protected individual or the average minimal cost for a protected group of\nindividuals to reverse the outcome computed by an automated system? Algorithmic\nrecourse increases the flexibility and applicability of the notion of equal\neffort: it overcomes its previous limitations by reconciling multiple treatment\nvariables, introducing feasibility and plausibility constraints, and\nintegrating the actual relative costs of interventions. We extend the existing\ndefinition of equality of effort and present an algorithm for its assessment\nvia algorithmic recourse. We validate our approach both on synthetic data and\non the German credit dataset.",
    "descriptor": "",
    "authors": [
      "Francesca E. D. Raimondi",
      "Andrew R. Lawrence",
      "Hana Chockler"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.11892"
  },
  {
    "id": "arXiv:2211.11957",
    "title": "Ranking Inferences Based on the Top Choice of Multiway Comparisons",
    "abstract": "This paper considers ranking inference of $n$ items based on the observed\ndata on the top choice among $M$ randomly selected items at each trial. This is\na useful modification of the Plackett-Luce model for $M$-way ranking with only\nthe top choice observed and is an extension of the celebrated\nBradley-Terry-Luce model that corresponds to $M=2$. Under a uniform sampling\nscheme in which any $M$ distinguished items are selected for comparisons with\nprobability $p$ and the selected $M$ items are compared $L$ times with\nmultinomial outcomes, we establish the statistical rates of convergence for\nunderlying $n$ preference scores using both $\\ell_2$-norm and\n$\\ell_\\infty$-norm, with the minimum sampling complexity. In addition, we\nestablish the asymptotic normality of the maximum likelihood estimator that\nallows us to construct confidence intervals for the underlying scores.\nFurthermore, we propose a novel inference framework for ranking items through a\nsophisticated maximum pairwise difference statistic whose distribution is\nestimated via a valid Gaussian multiplier bootstrap. The estimated distribution\nis then used to construct simultaneous confidence intervals for the differences\nin the preference scores and the ranks of individual items. They also enable us\nto address various inference questions on the ranks of these items. Extensive\nsimulation studies lend further support to our theoretical results. A real data\napplication illustrates the usefulness of the proposed methods convincingly.",
    "descriptor": "\nComments: In this paper, we build simultaneous confidence intervals for ranks\n",
    "authors": [
      "Jianqing Fan",
      "Zhipeng Lou",
      "Weichen Wang",
      "Mengxin Yu"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.11957"
  },
  {
    "id": "arXiv:2211.11959",
    "title": "Robust High-dimensional Tuning Free Multiple Testing",
    "abstract": "A stylized feature of high-dimensional data is that many variables have heavy\ntails, and robust statistical inference is critical for valid large-scale\nstatistical inference. Yet, the existing developments such as Winsorization,\nHuberization and median of means require the bounded second moments and involve\nvariable-dependent tuning parameters, which hamper their fidelity in\napplications to large-scale problems. To liberate these constraints, this paper\nrevisits the celebrated Hodges-Lehmann (HL) estimator for estimating location\nparameters in both the one- and two-sample problems, from a non-asymptotic\nperspective. Our study develops Berry-Esseen inequality and Cram\\'{e}r type\nmoderate deviation for the HL estimator based on newly developed non-asymptotic\nBahadur representation, and builds data-driven confidence intervals via a\nweighted bootstrap approach. These results allow us to extend the HL estimator\nto large-scale studies and propose \\emph{tuning-free} and \\emph{moment-free}\nhigh-dimensional inference procedures for testing global null and for\nlarge-scale multiple testing with false discovery proportion control. It is\nconvincingly shown that the resulting tuning-free and moment-free methods\ncontrol false discovery proportion at a prescribed level. The simulation\nstudies lend further support to our developed theory.",
    "descriptor": "\nComments: In this paper, we develop tuning-free and moment-free high dimensional inference procedures\n",
    "authors": [
      "Jianqing Fan",
      "Zhipeng Lou",
      "Mengxin Yu"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.11959"
  },
  {
    "id": "arXiv:2211.12004",
    "title": "Contextual Bandits in a Survey Experiment on Charitable Giving:  Within-Experiment Outcomes versus Policy Learning",
    "abstract": "We design and implement an adaptive experiment (a ``contextual bandit'') to\nlearn a targeted treatment assignment policy, where the goal is to use a\nparticipant's survey responses to determine which charity to expose them to in\na donation solicitation. The design balances two competing objectives:\noptimizing the outcomes for the subjects in the experiment (``cumulative regret\nminimization'') and gathering data that will be most useful for policy\nlearning, that is, for learning an assignment rule that will maximize welfare\nif used after the experiment (``simple regret minimization''). We evaluate\nalternative experimental designs by collecting pilot data and then conducting a\nsimulation study. Next, we implement our selected algorithm. Finally, we\nperform a second simulation study anchored to the collected data that evaluates\nthe benefits of the algorithm we chose. Our first result is that the value of a\nlearned policy in this setting is higher when data is collected via a uniform\nrandomization rather than collected adaptively using standard cumulative regret\nminimization or policy learning algorithms. We propose a simple heuristic for\nadaptive experimentation that improves upon uniform randomization from the\nperspective of policy learning at the expense of increasing cumulative regret\nrelative to alternative bandit algorithms. The heuristic modifies an existing\ncontextual bandit algorithm by (i) imposing a lower bound on assignment\nprobabilities that decay slowly so that no arm is discarded too quickly, and\n(ii) after adaptively collecting data, restricting policy learning to select\nfrom arms where sufficient data has been gathered.",
    "descriptor": "",
    "authors": [
      "Susan Athey",
      "Undral Byambadalai",
      "Vitor Hadad",
      "Sanath Kumar Krishnamurthy",
      "Weiwen Leung",
      "Joseph Jay Williams"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.12004"
  },
  {
    "id": "arXiv:2211.12084",
    "title": "Accelerated Solutions of Coupled Phase-Field Problems using Generative  Adversarial Networks",
    "abstract": "Multiphysics problems such as multicomponent diffusion, phase transformations\nin multiphase systems and alloy solidification involve numerical solution of a\ncoupled system of nonlinear partial differential equations (PDEs). Numerical\nsolutions of these PDEs using mesh-based methods require spatiotemporal\ndiscretization of these equations. Hence, the numerical solutions are often\nsensitive to discretization parameters and may have inaccuracies (resulting\nfrom grid-based approximations). Moreover, choice of finer mesh for higher\naccuracy make these methods computationally expensive. Neural network-based PDE\nsolvers are emerging as robust alternatives to conventional numerical methods\nbecause these use machine learnable structures that are grid-independent, fast\nand accurate. However, neural network based solvers require large amount of\ntraining data, thus affecting their generalizabilty and scalability. These\nconcerns become more acute for coupled systems of time-dependent PDEs. To\naddress these issues, we develop a new neural network based framework that uses\nencoder-decoder based conditional Generative Adversarial Networks with ConvLSTM\nlayers to solve a system of Cahn-Hilliard equations. These equations govern\nmicrostructural evolution of a ternary alloy undergoing spinodal decomposition\nwhen quenched inside a three-phase miscibility gap. We show that the trained\nmodels are mesh and scale-independent, thereby warranting application as\neffective neural operators.",
    "descriptor": "\nComments: 18 pages, 21 figures (including subfigures). Will be submitted to the journal: \"Computational Materials Science\" soon\n",
    "authors": [
      "Vir Karan",
      "A. Maruthi Indresh",
      "Saswata Bhattacharya"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.12084"
  },
  {
    "id": "arXiv:2211.12089",
    "title": "Ultrasound Detection of Subquadricipital Recess Distension",
    "abstract": "Joint bleeding is a common condition for people with hemophilia and, if\nuntreated, can result in hemophilic arthropathy. Ultrasound imaging has\nrecently emerged as an effective tool to diagnose joint recess distension\ncaused by joint bleeding. However, no computer-aided diagnosis tool exists to\nsupport the practitioner in the diagnosis process. This paper addresses the\nproblem of automatically detecting the recess and assessing whether it is\ndistended in knee ultrasound images collected in patients with hemophilia.\nAfter framing the problem, we propose two different approaches: the first one\nadopts a one-stage object detection algorithm, while the second one is a\nmulti-task approach with a classification and a detection branch. The\nexperimental evaluation, conducted with $483$ annotated images, shows that the\nsolution based on object detection alone has a balanced accuracy score of\n$0.74$ with a mean IoU value of $0.66$, while the multi-task approach has a\nhigher balanced accuracy value ($0.78$) at the cost of a slightly lower mean\nIoU value.",
    "descriptor": "",
    "authors": [
      "Marco Colussi",
      "Gabriele Civitarese",
      "Dragan Ahmetovic",
      "Claudio Bettini",
      "Roberta Gualtierotti",
      "Flora Peyvandi",
      "Sergio Mascetti"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12089"
  },
  {
    "id": "arXiv:2211.12116",
    "title": "Network coevolution drives segregation and enhances Pareto optimal  equilibrium selection in coordination games",
    "abstract": "In this work we assess the role played by the dynamical adaptation of the\ninteractions network, among agents playing Coordination Games, in reaching\nglobal coordination and in the equilibrium selection. Specifically, we analyze\na coevolution model that couples the changes in agents' actions with the\nnetwork dynamics, so that while agents play the game, they are able to sever\nsome of their current connections and connect with others. We focus on two\nupdate rules: Replicator Dynamics (RD) and Unconditional Imitation (UI). We\ninvestigate a Pure Coordination Game (PCG), in which choices are equivalent,\nand on a General Coordination Game (GCG), for which there is a risk-dominant\naction and a payoff-dominant one. The network plasticity is measured by the\nprobability to rewire links. Changing this plasticity parameter, there is a\ntransition from a regime in which the system fully coordinates in a single\nconnected component to a regime in which the system fragments in two connected\ncomponents, each one coordinated on a different action (either if both actions\nare equivalent or not). The nature of this fragmentation transition is\ndifferent for different update rules. Second, we find that both for RD and UI\nin a GCG, there is a regime of intermediate values of plasticity, before the\nfragmentation transition, for which the system is able to fully coordinate in a\nsingle component network on the payoff-dominant action, i. e., coevolution\nenhances payoff-dominant equilibrium selection for both update rules.",
    "descriptor": "\nComments: 13 pages, 8 figures, submitted to Scientific Reports\n",
    "authors": [
      "Miguel A. Gonz\u00e1lez Casado",
      "Angel S\u00e1nchez",
      "Maxi San Miguel"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Computer Science and Game Theory (cs.GT)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2211.12116"
  },
  {
    "id": "arXiv:2211.12121",
    "title": "Least squares approximations in linear statistical inverse learning  problems",
    "abstract": "Statistical inverse learning aims at recovering an unknown function $f$ from\nrandomly scattered and possibly noisy point evaluations of another function\n$g$, connected to $f$ via an ill-posed mathematical model. In this paper we\nblend statistical inverse learning theory with the classical regularization\nstrategy of applying finite-dimensional projections. Our key finding is that\ncoupling the number of random point evaluations with the choice of projection\ndimension, one can derive probabilistic convergence rates for the\nreconstruction error of the maximum likelihood (ML) estimator. Convergence\nrates in expectation are derived with a ML estimator complemented with a\nnorm-based cut-off operation. Moreover, we prove that the obtained rates are\nminimax optimal.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Tapio Helin"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.12121"
  },
  {
    "id": "arXiv:2211.12159",
    "title": "Modified Dynamic Programming Algorithms for GLOSA Systems with  Stochastic Signal Switching Times",
    "abstract": "A discrete-time stochastic optimal control problem was recently proposed to\naddress the GLOSA (Green Light Optimal Speed Advisory) problem in cases where\nthe next signal switching time is decided in real time and is therefore\nuncertain in advance. The corresponding numerical solution via SDP (Stochastic\nDynamic Programming) calls for substantial computation time, which excludes\nproblem solution in the vehicle's on-board computer in real time. To overcome\nthe computation time bottleneck, as a first attempt, a modified version of\nDynamic Programming, known as Discrete Differential Dynamic Programming (DDDP)\nwas recently employed for the numerical solution of the stochastic optimal\ncontrol problem. The DDDP algorithm was demonstrated to achieve results\nequivalent to those obtained with the ordinary SDP algorithm, albeit with\nsignificantly reduced computation times. The present work considers a different\nmodified version of Dynamic Programming, known as Differential Dynamic\nProgramming (DDP). For the stochastic GLOSA problem, it is demonstrated that\nDDP achieves quasi-instantaneous (extremely fast) solutions in terms of CPU\ntimes, which allows for the proposed approach to be readily executable online,\nin an MPC (Model Predictive Control) framework, in the vehicle's on-board\ncomputer. The approach is demonstrated by use of realistic examples. It should\nbe noted that DDP does not require discretization of variables, hence the\nobtained solutions may be slightly superior to the standard SDP solutions.",
    "descriptor": "",
    "authors": [
      "Panagiotis Typaldos",
      "Markos Papageorgiou"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.12159"
  },
  {
    "id": "arXiv:2211.12161",
    "title": "Probabilistic bounds with quadratic-exponential moments for quantum  stochastic systems",
    "abstract": "This paper is concerned with quadratic-exponential moments (QEMs) for dynamic\nvariables of quantum stochastic systems with position-momentum type canonical\ncommutation relations. The QEMs play an important role for statistical\n``localisation'' of the quantum dynamics in the form of upper bounds on the\ntail probability distribution for a positive definite quadratic function of the\nsystem variables. We employ a randomised representation of the QEMs in terms of\nthe moment-generating function (MGF) of the system variables, which is averaged\nover its parameters using an auxiliary classical Gaussian random vector. This\nrepresentation is combined with a family of weighted $L^2$-norms of the MGF,\nleading to upper bounds for the QEMs of the system variables. These bounds are\ndemonstrated for open quantum harmonic oscillators with vacuum input fields and\nnon-Gaussian initial states.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Igor G. Vladimirov"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.12161"
  },
  {
    "id": "arXiv:2211.12163",
    "title": "Bifurcation analysis of a two-dimensional magnetic Rayleigh-B\u00e9nard  problem",
    "abstract": "We perform bifurcation analysis of a two-dimensional magnetic\nRayleigh-B\\'enard problem using a numerical technique called deflated\ncontinuation. Our aim is to study the influence of the magnetic field on the\nbifurcation diagram as the Chandrasekhar number $Q$ increases, and compare it\nto the standard (non-magnetic) Rayleigh-B\\'enard problem. We compute steady\nstates at a high Chandrasekhar number of $Q=10^3$ over a range of the Rayleigh\nnumber $0\\leq \\text{Ra}\\leq 10^5$. These solutions are obtained by combining\ndeflation with a continuation of steady states at low Chandrasekhar number,\nwhich allows us to explore the influence of the strength of the magnetic field\nas $Q$ increases from low coupling, where the magnetic effect is almost\nnegligible, to strong coupling at $Q=10^3$. We discover a large profusion of\nstates with rich dynamics and observe a complex bifurcation structure with\nseveral pitchfork, Hopf and saddle-node bifurcations. Our numerical simulations\nshow that the onset of bifurcations in the problem is delayed when $Q$\nincreases, while solutions with fluid velocity patterns aligning with the\nbackground vertical magnetic field are privileged. Additionally, we report a\nbranch of states that stabilizes at high magnetic coupling, suggesting that one\nmay take advantage of the magnetic field to discriminate solutions.",
    "descriptor": "\nComments: 14 pages, 7 figures\n",
    "authors": [
      "Fabian Laakmann",
      "Nicolas Boull\u00e9"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.12163"
  },
  {
    "id": "arXiv:2211.12171",
    "title": "PromptTTS: Controllable Text-to-Speech with Text Descriptions",
    "abstract": "Using a text description as prompt to guide the generation of text or images\n(e.g., GPT-3 or DALLE-2) has drawn wide attention recently. Beyond text and\nimage generation, in this work, we explore the possibility of utilizing text\ndescriptions to guide speech synthesis. Thus, we develop a text-to-speech (TTS)\nsystem (dubbed as PromptTTS) that takes a prompt with both style and content\ndescriptions as input to synthesize the corresponding speech. Specifically,\nPromptTTS consists of a style encoder and a content encoder to extract the\ncorresponding representations from the prompt, and a speech decoder to\nsynthesize speech according to the extracted style and content representations.\nCompared with previous works in controllable TTS that require users to have\nacoustic knowledge to understand style factors such as prosody and pitch,\nPromptTTS is more user-friendly since text descriptions are a more natural way\nto express speech style (e.g., ''A lady whispers to her friend slowly''). Given\nthat there is no TTS dataset with prompts, to benchmark the task of PromptTTS,\nwe construct and release a dataset containing prompts with style and content\ninformation and the corresponding speech. Experiments show that PromptTTS can\ngenerate speech with precise style control and high speech quality. Audio\nsamples and our dataset are publicly available.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Zhifang Guo",
      "Yichong Leng",
      "Yihan Wu",
      "Sheng Zhao",
      "Xu Tan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.12171"
  },
  {
    "id": "arXiv:2211.12180",
    "title": "SRTGAN: Triplet Loss based Generative Adversarial Network for Real-World  Super-Resolution",
    "abstract": "Many applications such as forensics, surveillance, satellite imaging, medical\nimaging, etc., demand High-Resolution (HR) images. However, obtaining an HR\nimage is not always possible due to the limitations of optical sensors and\ntheir costs. An alternative solution called Single Image Super-Resolution\n(SISR) is a software-driven approach that aims to take a Low-Resolution (LR)\nimage and obtain the HR image. Most supervised SISR solutions use ground truth\nHR image as a target and do not include the information provided in the LR\nimage, which could be valuable. In this work, we introduce Triplet Loss-based\nGenerative Adversarial Network hereafter referred as SRTGAN for Image\nSuper-Resolution problem on real-world degradation. We introduce a new\ntriplet-based adversarial loss function that exploits the information provided\nin the LR image by using it as a negative sample. Allowing the patch-based\ndiscriminator with access to both HR and LR images optimizes to better\ndifferentiate between HR and LR images; hence, improving the adversary.\nFurther, we propose to fuse the adversarial loss, content loss, perceptual\nloss, and quality loss to obtain Super-Resolution (SR) image with high\nperceptual fidelity. We validate the superior performance of the proposed\nmethod over the other existing methods on the RealSR dataset in terms of\nquantitative and qualitative metrics.",
    "descriptor": "\nComments: Affiliated with the Sardar Vallabhbhai National Institute of Technology (SVNIT), India and Norwegian University of Science and Technology (NTNU), Norway. Presented at the 7th International Conference on Computer Vision and Image Processing (CVIP) 2022\n",
    "authors": [
      "Dhruv Patel",
      "Abhinav Jain",
      "Simran Bawkar",
      "Manav Khorasiya",
      "Kalpesh Prajapati",
      "Kishor Upla",
      "Kiran Raja",
      "Raghavendra Ramachandra",
      "Christoph Busch"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12180"
  },
  {
    "id": "arXiv:2211.12195",
    "title": "Ontology-aware Learning and Evaluation for Audio Tagging",
    "abstract": "This study defines a new evaluation metric for audio tagging tasks to\novercome the limitation of the conventional mean average precision (mAP)\nmetric, which treats different kinds of sound as independent classes without\nconsidering their relations. Also, due to the ambiguities in sound labeling,\nthe labels in the training and evaluation set are not guaranteed to be accurate\nand exhaustive, which poses challenges for robust evaluation with mAP. The\nproposed metric, ontology-aware mean average precision (OmAP) addresses the\nweaknesses of mAP by utilizing the AudioSet ontology information during the\nevaluation. Specifically, we reweight the false positive events in the model\nprediction based on the ontology graph distance to the target classes. The OmAP\nmeasure also provides more insights into model performance by evaluations with\ndifferent coarse-grained levels in the ontology graph. We conduct human\nevaluations and demonstrate that OmAP is more consistent with human perception\nthan mAP. To further verify the importance of utilizing the ontology\ninformation, we also propose a novel loss function (OBCE) that reweights binary\ncross entropy (BCE) loss based on the ontology distance. Our experiment shows\nthat OBCE can improve both mAP and OmAP metrics on the AudioSet tagging task.",
    "descriptor": "\nComments: Submitted to ICASSP 2023. The code is open-sourced at this https URL\n",
    "authors": [
      "Haohe Liu",
      "Qiuqiang Kong",
      "Xubo Liu",
      "Xinhao Mei",
      "Wenwu Wang",
      "Mark D. Plumbley"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.12195"
  },
  {
    "id": "arXiv:2211.12207",
    "title": "Photonic Quantum Computing For Polymer Classification",
    "abstract": "We present a hybrid classical-quantum approach to the binary classification\nof polymer structures. Two polymer classes visual (VIS) and near-infrared (NIR)\nare defined based on the size of the polymer gaps. The hybrid approach combines\none of the three methods, Gaussian Kernel Method, Quantum-Enhanced Random\nKitchen Sinks or Variational Quantum Classifier, implemented by linear quantum\nphotonic circuits (LQPCs), with a classical deep neural network (DNN) feature\nextractor. The latter extracts from the classical data information about\nsamples chemical structure. It also reduces the data dimensions yielding\ncompact 2-dimensional data vectors that are then fed to the LQPCs. We adopt the\nphotonic-based data-embedding scheme, proposed by Gan et al. [EPJ Quantum\nTechnol. 9, 16 (2022)] to embed the classical 2-dimensional data vectors into\nthe higher-dimensional Fock space. This hybrid classical-quantum strategy\npermits to obtain accurate noisy intermediate-scale quantum-compatible\nclassifiers by leveraging Fock states with only a few photons. The models\nobtained using either of the three hybrid methods successfully classified the\nVIS and NIR polymers. Their accuracy is comparable as measured by their scores\nranging from 0.86 to 0.88. These findings demonstrate that our hybrid approach\nthat uses photonic quantum computing captures chemistry and structure-property\ncorrelation patterns in real polymer data. They also open up perspectives of\nemploying quantum computing to complex chemical structures when a larger number\nof logical qubits is available.",
    "descriptor": "",
    "authors": [
      "Alexandrina Stoyanova",
      "Taha Hammadia",
      "Arno Ricou",
      "Bogdan Penkovsky"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.12207"
  },
  {
    "id": "arXiv:2211.12299",
    "title": "Harder, better, faster, stronger: understanding and improving the  tractability of large energy system models",
    "abstract": "Energy system models based on linear programming have been growing in size\nwith the increasing need to model renewables with high spatial and temporal\ndetail. Larger models lead to high computational requirements. Furthermore,\nseemingly small changes in a model can lead to drastic differences in runtime.\nHere, we investigate measures to address this issue. We review the mathematical\nstructure of a typical energy system model, and discuss issues of sparsity,\ndegeneracy and large numerical range. We introduce and test a method to\nautomatically scale models to improve numerical range. We test this method as\nwell as tweaks to model formulation and solver preferences, finding that\nadjustments can have a substantial impact on runtime. In particular, the\nbarrier method without crossover can be very fast, but affects the structure of\nthe resulting optimal solution. We conclude with a range of recommendations for\nenergy system modellers.",
    "descriptor": "",
    "authors": [
      "Manuel Br\u00f6chin",
      "Bryn Pickering",
      "Tim Tr\u00f6ndle",
      "Stefan Pfenninger"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.12299"
  },
  {
    "id": "arXiv:2211.12314",
    "title": "Attacking Image Splicing Detection and Localization Algorithms Using  Synthetic Traces",
    "abstract": "Recent advances in deep learning have enabled forensics researchers to\ndevelop a new class of image splicing detection and localization algorithms.\nThese algorithms identify spliced content by detecting localized\ninconsistencies in forensic traces using Siamese neural networks, either\nexplicitly during analysis or implicitly during training. At the same time,\ndeep learning has enabled new forms of anti-forensic attacks, such as\nadversarial examples and generative adversarial network (GAN) based attacks.\nThus far, however, no anti-forensic attack has been demonstrated against image\nsplicing detection and localization algorithms. In this paper, we propose a new\nGAN-based anti-forensic attack that is able to fool state-of-the-art splicing\ndetection and localization algorithms such as EXIF-Net, Noiseprint, and\nForensic Similarity Graphs. This attack operates by adversarially training an\nanti-forensic generator against a set of Siamese neural networks so that it is\nable to create synthetic forensic traces. Under analysis, these synthetic\ntraces appear authentic and are self-consistent throughout an image. Through a\nseries of experiments, we demonstrate that our attack is capable of fooling\nforensic splicing detection and localization algorithms without introducing\nvisually detectable artifacts into an attacked image. Additionally, we\ndemonstrate that our attack outperforms existing alternative attack approaches.\n%",
    "descriptor": "",
    "authors": [
      "Shengbang Fang",
      "Matthew C Stamm"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.12314"
  },
  {
    "id": "arXiv:2211.12333",
    "title": "Mixed Integer Linear Program model for optimized scheduling of a  vanadium redox flow battery with variable efficiencies, capacity fade, and  electrolyte maintenance",
    "abstract": "Redox Flow Batteries are a promising option for large-scale stationary energy\nstorage. The vanadium redox flow battery is the most widely commercialized\nsystem thanks to its chemical stability and performance. This work aims to\noptimize the scheduling of a vanadium flow battery that stores energy produced\nby a renewable power plant, keeping into account a thorough characterization of\nthe battery performance, with variable efficiencies and capacity fade effects.\nA detailed characterization of the battery performance improves the calculation\nof the optimal number of cycles and revenue associated with the battery use if\ncompared to the results obtained using simpler models, which take into account\nconstant efficiencies and no capacity fade effects. The presented problem is\nnonlinear due to the functions of the battery efficiency, which depend upon\ncharging and discharging powers and state of charge with nonlinear, non-convex\ncorrelations. The problem is linearized using convex hulls. The optimization\nprogram also calculates the progressive battery capacity fade due to undesired\nsecondary electrochemical reactions and the economic impact of capacity\nrestoration through periodic maintenance. The final problem is solved as a\nMixed-Integer Linear Program (MILP) to guarantee the global optimality of the\nlinearized problem. The proposed optimization model has been applied to two\ndifferent case studies: a case of energy arbitrage and a case of load-shifting.\nThe optimization results have been compared to those obtained with constant\nbattery efficiency models, which do not consider the capacity fade effects.\nResults show that simpler models overestimate the optimal number of cycles of\nthe battery and the revenue by up to 15% if they do not take into account the\ndegradation model of the battery, and respectively up to 32% and 42% if they\nalso assume constant efficiency for the battery.",
    "descriptor": "",
    "authors": [
      "Diana Cremoncini",
      "Guido Francesco Frate",
      "Aldo Bischi",
      "Lorenzo Ferrari"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.12333"
  },
  {
    "id": "arXiv:2211.12340",
    "title": "DOLCE: A Model-Based Probabilistic Diffusion Framework for Limited-Angle  CT Reconstruction",
    "abstract": "Limited-Angle Computed Tomography (LACT) is a non-destructive evaluation\ntechnique used in a variety of applications ranging from security to medicine.\nThe limited angle coverage in LACT is often a dominant source of severe\nartifacts in the reconstructed images, making it a challenging inverse problem.\nWe present DOLCE, a new deep model-based framework for LACT that uses a\nconditional diffusion model as an image prior. Diffusion models are a recent\nclass of deep generative models that are relatively easy to train due to their\nimplementation as image denoisers. DOLCE can form high-quality images from\nseverely under-sampled data by integrating data-consistency updates with the\nsampling updates of a diffusion model, which is conditioned on the transformed\nlimited-angle data. We show through extensive experimentation on several\nchallenging real LACT datasets that, the same pre-trained DOLCE model achieves\nthe SOTA performance on drastically different types of images. Additionally, we\nshow that, unlike standard LACT reconstruction methods, DOLCE naturally enables\nthe quantification of the reconstruction uncertainty by generating multiple\nsamples consistent with the measured data.",
    "descriptor": "\nComments: 29 pages, 21 figures\n",
    "authors": [
      "Jiaming Liu",
      "Rushil Anirudh",
      "Jayaraman J. Thiagarajan",
      "Stewart He",
      "K. Aditya Mohan",
      "Ulugbek S. Kamilov",
      "Hyojin Kim"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12340"
  },
  {
    "id": "arXiv:2211.12344",
    "title": "Injectable Bubbles for Physiological Pressure Measurement",
    "abstract": "Microbubbles - used as contrast agents in ultrasound imaging - are important\ntools in biomedical research, having been used together with ultrasound to\ndevelop significant diagnostic and therapeutic techniques. It has been\nsuggested that the dynamic behaviour of microbubbles is dependent on the\nsurrounding fluid's ambient (hydrostatic) pressure, and the potential to\nnon-invasively determine blood pressure has numerous medical applications. To\nstudy this dependence, a computational mathematical model was created based on\nMarmottant's dynamic model of a microbubble. A pulse inversion (PI) protocol\nwas incorporated into the model to emphasize the nonlinear behaviour of the\nmicrobubble's response. The mathematical model was also used to assess the\nsensitivity of the microbubbles to undesirable changes in parameters other than\nthe ambient pressure. It found that a variation in the microbubble's initial\nradius and surface tension would cause the most significant changes in signal\nenergy and hence pose a risk to ambient pressure measurements. To test the\npracticality of detecting a change in the dynamic behaviour of microbubbles, in\nvitro experiments were designed and carried out using clinically available\ncontrast agent with two different ultrasound systems. The experiments, while\npossessing certain limitations, confirmed that there is a change in\nmicrobubbles' dynamic behaviour when the ambient pressure is varied, in cases\nby as little as 7.36 mmHg (981 Pa - a 0.98% change in atmospheric pressure).\nThe experimental results establish a proof-of-principle that future\nexperimental work can build upon to verify the mathematical model, and hence\naid in developing a non-invasive blood pressure measurement procedure.",
    "descriptor": "\nComments: A thesis submitted in partial fulfilment of the requirements for the undergraduate degree of Master of Engineering (MEng) in the Department of Engineering Science, University of Oxford\n",
    "authors": [
      "Prashant Pandey"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.12344"
  },
  {
    "id": "arXiv:2211.12346",
    "title": "Cosmology from Galaxy Redshift Surveys with PointNet",
    "abstract": "In recent years, deep learning approaches have achieved state-of-the-art\nresults in the analysis of point cloud data. In cosmology, galaxy redshift\nsurveys resemble such a permutation invariant collection of positions in space.\nThese surveys have so far mostly been analysed with two-point statistics, such\nas power spectra and correlation functions. The usage of these summary\nstatistics is best justified on large scales, where the density field is linear\nand Gaussian. However, in light of the increased precision expected from\nupcoming surveys, the analysis of -- intrinsically non-Gaussian -- small\nangular separations represents an appealing avenue to better constrain\ncosmological parameters. In this work, we aim to improve upon two-point\nstatistics by employing a \\textit{PointNet}-like neural network to regress the\nvalues of the cosmological parameters directly from point cloud data. Our\nimplementation of PointNets can analyse inputs of $\\mathcal{O}(10^4) -\n\\mathcal{O}(10^5)$ galaxies at a time, which improves upon earlier work for\nthis application by roughly two orders of magnitude. Additionally, we\ndemonstrate the ability to analyse galaxy redshift survey data on the\nlightcone, as opposed to previously static simulation boxes at a given fixed\nredshift.",
    "descriptor": "",
    "authors": [
      "Sotiris Anagnostidis",
      "Arne Thomsen",
      "Tomasz Kacprzak",
      "Tilman Tr\u00f6ster",
      "Luca Biggio",
      "Alexandre Refregier",
      "Thomas Hofmann"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12346"
  },
  {
    "id": "arXiv:2211.12389",
    "title": "The Burer-Monteiro SDP method can fail even above the Barvinok-Pataki  bound",
    "abstract": "The most widely used technique for solving large-scale semidefinite programs\n(SDPs) in practice is the non-convex Burer-Monteiro method, which explicitly\nmaintains a low-rank SDP solution for memory efficiency. There has been much\nrecent interest in obtaining a better theoretical understanding of the\nBurer-Monteiro method. When the maximum allowed rank $p$ of the SDP solution is\nabove the Barvinok-Pataki bound (where a globally optimal solution of rank at\nmost $p$ is guaranteed to exist), a recent line of work established convergence\nto a global optimum for generic or smoothed instances of the problem. However,\nit was open whether there even exists an instance in this regime where the\nBurer-Monteiro method fails. We prove that the Burer-Monteiro method can fail\nfor the Max-Cut SDP on $n$ vertices when the rank is above the Barvinok-Pataki\nbound ($p \\ge \\sqrt{2n}$). We provide a family of instances that have spurious\nlocal minima even when the rank $p = n/2$. Combined with existing guarantees,\nthis settles the question of the existence of spurious local minima for the\nMax-Cut formulation in all ranges of the rank and justifies the use of beyond\nworst-case paradigms like smoothed analysis to obtain guarantees for the\nBurer-Monteiro method.",
    "descriptor": "",
    "authors": [
      "Liam O'Carroll",
      "Vaidehi Srinivas",
      "Aravindan Vijayaraghavan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.12389"
  },
  {
    "id": "arXiv:2211.12392",
    "title": "Continuous R-valuations",
    "abstract": "We introduce continuous $R$-valuations on directed-complete posets (dcpos,\nfor short), as a generalization of continuous valuations in domain theory, by\nextending values of continuous valuations from reals to so-called Abelian\nd-rags $R$.\nLike the valuation monad $\\mathbf{V}$ introduced by Jones and Plotkin, we\nshow that the construction of continuous $R$-valuations extends to a strong\nmonad $\\mathbf{V}^R$ on the category of dcpos and Scott-continuous maps.\nAdditionally, and as in recent work by the two authors and C. Th\\'eron, and by\nthe second author, B. Lindenhovius, M. Mislove and V. Zamdzhiev, we show that\nwe can extract a commutative monad $\\mathbf{V}^R_m$ out of it, whose elements\nwe call minimal $R$-valuations.\nWe also show that continuous $R$-valuations have close connections to\nmeasures when $R$ is taken to be $\\mathbf{I}\\mathbb{R}^\\star_+$, the interval\ndomain of the extended nonnegative reals: (1) On every coherent topological\nspace, every non-zero, bounded $\\tau$-smooth measure $\\mu$ (defined on the\nBorel $\\sigma$-algebra), canonically determines a continuous\n$\\mathbf{I}\\mathbb{R}^\\star_+$-valuation; and (2) such a continuous\n$\\mathbf{I}\\mathbb{R}^\\star_+$-valuation is the most precise (in a certain\nsense) continuous $\\mathbf{I}\\mathbb{R}^\\star_+$-valuation that approximates\n$\\mu$, when the support of $\\mu$ is a compact Hausdorff subspace of a\nsecond-countable stably compact topological space. This in particular applies\nto Lebesgue measure on the unit interval. As a result, the Lebesgue measure can\nbe identified as a continuous $\\mathbf{I}\\mathbb{R}^\\star_+$-valuation.\nAdditionally, we show that the latter is minimal.",
    "descriptor": "",
    "authors": [
      "Jean Goubault-Larrecq",
      "Xiaodong Jia"
    ],
    "subjectives": [
      "General Topology (math.GN)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.12392"
  },
  {
    "id": "arXiv:2211.12420",
    "title": "Brain informed transfer learning for categorizing construction hazards",
    "abstract": "A transfer learning paradigm is proposed for \"knowledge\" transfer between the\nhuman brain and convolutional neural network (CNN) for a construction hazard\ncategorization task. Participants' brain activities are recorded using\nelectroencephalogram (EEG) measurements when viewing the same images (target\ndataset) as the CNN. The CNN is pretrained on the EEG data and then fine-tuned\non the construction scene images. The results reveal that the EEG-pretrained\nCNN achieves a 9 % higher accuracy compared with a network with same\narchitecture but randomly initialized parameters on a three-class\nclassification task. Brain activity from the left frontal cortex exhibits the\nhighest performance gains, thus indicating high-level cognitive processing\nduring hazard recognition. This work is a step toward improving machine\nlearning algorithms by learning from human-brain signals recorded via a\ncommercially available brain-computer interface. More generalized visual\nrecognition systems can be effectively developed based on this approach of\n\"keep human in the loop\".",
    "descriptor": "",
    "authors": [
      "Xiaoshan Zhou",
      "Pin-Chao Liao"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.12420"
  },
  {
    "id": "arXiv:2211.12421",
    "title": "Data-Driven Network Neuroscience: On Data Collection and Benchmark",
    "abstract": "This paper presents a comprehensive and quality collection of functional\nhuman brain network data for potential research in the intersection of\nneuroscience, machine learning, and graph analytics. Anatomical and functional\nMRI images of the brain have been used to understand the functional\nconnectivity of the human brain and are particularly important in identifying\nunderlying neurodegenerative conditions such as Alzheimer's, Parkinson's, and\nAutism. Recently, the study of the brain in the form of brain networks using\nmachine learning and graph analytics has become increasingly popular,\nespecially to predict the early onset of these conditions. A brain network,\nrepresented as a graph, retains richer structural and positional information\nthat traditional examination methods are unable to capture. However, the lack\nof brain network data transformed from functional MRI images prevents\nresearchers from data-driven explorations. One of the main difficulties lies in\nthe complicated domain-specific preprocessing steps and the exhaustive\ncomputation required to convert data from MRI images into brain networks. We\nbridge this gap by collecting a large amount of available MRI images from\nexisting studies, working with domain experts to make sensible design choices,\nand preprocessing the MRI images to produce a collection of brain network\ndatasets. The datasets originate from 5 different sources, cover 3\nneurodegenerative conditions, and consist of a total of 2,642 subjects. We test\nour graph datasets on 5 machine learning models commonly used in neuroscience\nand on a recent graph-based analysis model to validate the data quality and to\nprovide domain baselines. To lower the barrier to entry and promote the\nresearch in this interdisciplinary field, we release our complete preprocessing\ndetails, codes, and brain network data.",
    "descriptor": "",
    "authors": [
      "David Tse Jung Huang",
      "Sophi Shilpa Gururajapathy",
      "Yiping Ke",
      "Miao Qiao",
      "Alan Wang",
      "Haribalan Kumar",
      "Yunhan Yang"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.12421"
  },
  {
    "id": "arXiv:2211.12443",
    "title": "Learning context-aware adaptive solvers to accelerate quadratic  programming",
    "abstract": "Convex quadratic programming (QP) is an important sub-field of mathematical\noptimization. The alternating direction method of multipliers (ADMM) is a\nsuccessful method to solve QP. Even though ADMM shows promising results in\nsolving various types of QP, its convergence speed is known to be highly\ndependent on the step-size parameter $\\rho$. Due to the absence of a general\nrule for setting $\\rho$, it is often tuned manually or heuristically. In this\npaper, we propose CA-ADMM (Context-aware Adaptive ADMM)) which learns to\nadaptively adjust $\\rho$ to accelerate ADMM. CA-ADMM extracts the\nspatio-temporal context, which captures the dependency of the primal and dual\nvariables of QP and their temporal evolution during the ADMM iterations.\nCA-ADMM chooses $\\rho$ based on the extracted context. Through extensive\nnumerical experiments, we validated that CA-ADMM effectively generalizes to\nunseen QP problems with different sizes and classes (i.e., having different QP\nparameter structures). Furthermore, we verified that CA-ADMM could dynamically\nadjust $\\rho$ considering the stage of the optimization process to accelerate\nthe convergence speed further.",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Haewon Jung",
      "Junyoung Park",
      "Jinkyoo Park"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12443"
  },
  {
    "id": "arXiv:2211.12444",
    "title": "Can denoising diffusion probabilistic models generate realistic  astrophysical fields?",
    "abstract": "Score-based generative models have emerged as alternatives to generative\nadversarial networks (GANs) and normalizing flows for tasks involving learning\nand sampling from complex image distributions. In this work we investigate the\nability of these models to generate fields in two astrophysical contexts: dark\nmatter mass density fields from cosmological simulations and images of\ninterstellar dust. We examine the fidelity of the sampled cosmological fields\nrelative to the true fields using three different metrics, and identify\npotential issues to address. We demonstrate a proof-of-concept application of\nthe model trained on dust in denoising dust images. To our knowledge, this is\nthe first application of this class of models to the interstellar medium.",
    "descriptor": "\nComments: 8 pages, 3 figures, Accepted at the Machine Learning and the Physical Sciences workshop, NeurIPS 2022\n",
    "authors": [
      "Nayantara Mudur",
      "Douglas P. Finkbeiner"
    ],
    "subjectives": [
      "Cosmology and Nongalactic Astrophysics (astro-ph.CO)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12444"
  },
  {
    "id": "arXiv:2211.12447",
    "title": "Quantum algorithms and the power of forgetting",
    "abstract": "The so-called welded tree problem provides an example of a black-box problem\nthat can be solved exponentially faster by a quantum walk than by any classical\nalgorithm. Given the name of a special ENTRANCE vertex, a quantum walk can find\nanother distinguished EXIT vertex using polynomially many queries, though\nwithout finding any particular path from ENTRANCE to EXIT. It has been an open\nproblem for twenty years whether there is an efficient quantum algorithm for\nfinding such a path, or if the path-finding problem is hard even for quantum\ncomputers. We show that a natural class of efficient quantum algorithms\nprovably cannot find a path from ENTRANCE to EXIT. Specifically, we consider\nalgorithms that, within each branch of their superposition, always store a set\nof vertex labels that form a connected subgraph including the ENTRANCE, and\nthat only provide these vertex labels as inputs to the oracle. While this does\nnot rule out the possibility of a quantum algorithm that efficiently finds a\npath, it is unclear how an algorithm could benefit by deviating from this\nbehavior. Our no-go result suggests that, for some problems, quantum algorithms\nmust necessarily forget the path they take to reach a solution in order to\noutperform classical computation.",
    "descriptor": "\nComments: 49 pages, 9 figures\n",
    "authors": [
      "Andrew M. Childs",
      "Matthew Coudron",
      "Amin Shiraz Gilani"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.12447"
  },
  {
    "id": "arXiv:2211.12459",
    "title": "A generalized machine learning framework for brittle crack problems  using transfer learning and graph neural networks",
    "abstract": "Despite their recent success, machine learning (ML) models such as graph\nneural networks (GNNs), suffer from drawbacks such as the need for large\ntraining datasets and poor performance for unseen cases. In this work, we use\ntransfer learning (TL) approaches to circumvent the need for retraining with\nlarge datasets. We apply TL to an existing ML framework, trained to predict\nmultiple crack propagation and stress evolution in brittle materials under\nMode-I loading. The new framework, ACCelerated Universal fRAcTure Emulator\n(ACCURATE), is generalized to a variety of crack problems by using a sequence\nof TL update steps including (i) arbitrary crack lengths, (ii) arbitrary crack\norientations, (iii) square domains, (iv) horizontal domains, and (v) shear\nloadings. We show that using small training datasets of 20 simulations for each\nTL update step, ACCURATE achieved high prediction accuracy in Mode-I and\nMode-II stress intensity factors, and crack paths for these problems. %case\nstudies (i) - (iv). We demonstrate ACCURATE's ability to predict crack growth\nand stress evolution with high accuracy for unseen cases involving the\ncombination of new boundary dimensions with arbitrary crack lengths and crack\norientations in both tensile and shear loading. We also demonstrate\nsignificantly accelerated simulation times of up to 2 orders of magnitude\nfaster (200x) compared to an XFEM-based fracture model. The ACCURATE framework\nprovides a universal computational fracture mechanics model that can be easily\nmodified or extended in future work.",
    "descriptor": "",
    "authors": [
      "Roberto Perera",
      "Vinamra Agrawal"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12459"
  },
  {
    "id": "arXiv:2211.12461",
    "title": "A Neural-Network-Based Convex Regularizer for Image Reconstruction",
    "abstract": "The emergence of deep-learning-based methods for solving inverse problems has\nenabled a significant increase in reconstruction quality. Unfortunately, these\nnew methods often lack reliability and explainability, and there is a growing\ninterest to address these shortcomings while retaining the performance. In this\nwork, this problem is tackled by revisiting regularizers that are the sum of\nconvex-ridge functions. The gradient of such regularizers is parametrized by a\nneural network that has a single hidden layer with increasing and learnable\nactivation functions. This neural network is trained within a few minutes as a\nmulti-step Gaussian denoiser. The numerical experiments for denoising, CT, and\nMRI reconstruction show improvements over methods that offer similar\nreliability guarantees.",
    "descriptor": "",
    "authors": [
      "Alexis Goujon",
      "Sebastian Neumayer",
      "Pakshal Bohra",
      "Stanislas Ducotterd",
      "Michael Unser"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12461"
  },
  {
    "id": "arXiv:2211.12475",
    "title": "The impact of moving expenses on social segregation: a simulation with  RL and ABM",
    "abstract": "Over the past decades, breakthroughs such as Reinforcement Learning (RL) and\nAgent-based modeling (ABM) have made simulations of economic models feasible.\nRecently, there has been increasing interest in applying ABM to study the\nimpact of residential preferences on neighborhood segregation in the Schelling\nSegregation Model. In this paper, RL is combined with ABM to simulate a\nmodified Schelling Segregation model, which incorporates moving expenses as an\ninput parameter. In particular, deep Q network (DQN) is adopted as RL agents'\nlearning algorithm to simulate the behaviors of households and their\npreferences. This paper studies the impact of moving expenses on the overall\nsegregation pattern and its role in social integration. A more comprehensive\nsimulation of the segregation model is built for policymakers to forecast the\npotential consequences of their policies.",
    "descriptor": "\nComments: 7 pages with 1 table and 1 figure\n",
    "authors": [
      "Xinyu Li"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12475"
  },
  {
    "id": "arXiv:1902.02201",
    "title": "Toward a Dichotomy for Approximation of $H$-coloring",
    "abstract": "Toward a Dichotomy for Approximation of $H$-coloring",
    "descriptor": "",
    "authors": [
      "Akbar Rafiey",
      "Arash Rafiey",
      "Thiago Santos"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1902.02201"
  },
  {
    "id": "arXiv:1908.07092",
    "title": "Linear stability analysis for large dynamical systems on directed random  graphs",
    "abstract": "Comments: 35 pages, 8 figures, a few typo's have been corrected in the new version",
    "descriptor": "\nComments: 35 pages, 8 figures, a few typo's have been corrected in the new version\n",
    "authors": [
      "Izaak Neri",
      "Fernando Lucas Metz"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/1908.07092"
  },
  {
    "id": "arXiv:2007.06665",
    "title": "A CMOS Ising Machines with Coupled Bistable Nodes",
    "abstract": "Comments: 25 pages, 18 figures, 1 tables, 5 sections,",
    "descriptor": "\nComments: 25 pages, 18 figures, 1 tables, 5 sections,\n",
    "authors": [
      "Richard Afoakwa",
      "Yiqiao Zhang",
      "Uday Kumar Reddy Vengalam",
      "Zeljko Ignjatovic",
      "Michael Huang"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2007.06665"
  },
  {
    "id": "arXiv:2007.09946",
    "title": "Program algebra for random access machine programs",
    "abstract": "Comments: 27 pages, revision of v2 with presentation improved. arXiv admin note: substantial text overlap with arXiv:1901.08840, arXiv:1808.04264",
    "descriptor": "\nComments: 27 pages, revision of v2 with presentation improved. arXiv admin note: substantial text overlap with arXiv:1901.08840, arXiv:1808.04264\n",
    "authors": [
      "C. A. Middelburg"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2007.09946"
  },
  {
    "id": "arXiv:2009.04614",
    "title": "End-to-end Kernel Learning via Generative Random Fourier Features",
    "abstract": "Comments: Accepted by Pattern Recognition",
    "descriptor": "\nComments: Accepted by Pattern Recognition\n",
    "authors": [
      "Kun Fang",
      "Fanghui Liu",
      "Xiaolin Huang",
      "Jie Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.04614"
  },
  {
    "id": "arXiv:2102.11578",
    "title": "A Graphical Framework to Study the Correlation between Geometric Design  and Simulation",
    "abstract": "A Graphical Framework to Study the Correlation between Geometric Design  and Simulation",
    "descriptor": "",
    "authors": [
      "Daniela Cabiddu",
      "Giuseppe Patan\u00e8",
      "Michela Spagnuolo"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2102.11578"
  },
  {
    "id": "arXiv:2103.01698",
    "title": "Super-resolving Compressed Images via Parallel and Series Integration of  Artifact Reduction and Resolution Enhancement",
    "abstract": "Comments: This paper have been accepted by Elsevier Signal Processing",
    "descriptor": "\nComments: This paper have been accepted by Elsevier Signal Processing\n",
    "authors": [
      "Hongming Luo",
      "Fei Zhou",
      "Guangsen Liao",
      "Guoping Qiu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.01698"
  },
  {
    "id": "arXiv:2103.09118",
    "title": "Balancing Biases and Preserving Privacy on Balanced Faces in the Wild",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2102.08941",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2102.08941\n",
    "authors": [
      "Joseph P Robinson",
      "Can Qin",
      "Yann Henon",
      "Samson Timoner",
      "Yun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.09118"
  },
  {
    "id": "arXiv:2103.17132",
    "title": "Empirically explaining SGD from a line search perspective",
    "abstract": "Comments: Empirical Analysis , Optimization, Line Search, SGD",
    "descriptor": "\nComments: Empirical Analysis , Optimization, Line Search, SGD\n",
    "authors": [
      "Maximus Mutschler",
      "Andreas Zell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2103.17132"
  },
  {
    "id": "arXiv:2104.03591",
    "title": "Unitary Subgroup Testing",
    "abstract": "Unitary Subgroup Testing",
    "descriptor": "",
    "authors": [
      "Zvika Brakerski",
      "Devika Sharma",
      "Guy Weissenberg"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2104.03591"
  },
  {
    "id": "arXiv:2104.04901",
    "title": "Global Convergence of Policy Gradient Primal-dual Methods for  Risk-constrained LQRs",
    "abstract": "Global Convergence of Policy Gradient Primal-dual Methods for  Risk-constrained LQRs",
    "descriptor": "",
    "authors": [
      "Feiran Zhao",
      "Keyou You",
      "Tamer Ba\u015far"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.04901"
  },
  {
    "id": "arXiv:2105.14528",
    "title": "Fast Nearest Neighbor Machine Translation",
    "abstract": "Comments: To appear at ACL 2022 Findings",
    "descriptor": "\nComments: To appear at ACL 2022 Findings\n",
    "authors": [
      "Yuxian Meng",
      "Xiaoya Li",
      "Xiayu Zheng",
      "Fei Wu",
      "Xiaofei Sun",
      "Tianwei Zhang",
      "Jiwei Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14528"
  },
  {
    "id": "arXiv:2105.15010",
    "title": "QueryNet: Attack by Multi-Identity Surrogates",
    "abstract": "Comments: QueryNet reduces queries by about an order of magnitude against SOTA black-box attacks",
    "descriptor": "\nComments: QueryNet reduces queries by about an order of magnitude against SOTA black-box attacks\n",
    "authors": [
      "Sizhe Chen",
      "Zhehao Huang",
      "Qinghua Tao",
      "Xiaolin Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.15010"
  },
  {
    "id": "arXiv:2108.03388",
    "title": "Jointly Attacking Graph Neural Network and its Explanations",
    "abstract": "Comments: Accepted by ICDE 2023 (39th IEEE International Conference on Data Engineering)",
    "descriptor": "\nComments: Accepted by ICDE 2023 (39th IEEE International Conference on Data Engineering)\n",
    "authors": [
      "Wenqi Fan",
      "Wei Jin",
      "Xiaorui Liu",
      "Han Xu",
      "Xianfeng Tang",
      "Suhang Wang",
      "Qing Li",
      "Jiliang Tang",
      "Jianping Wang",
      "Charu Aggarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2108.03388"
  },
  {
    "id": "arXiv:2108.06062",
    "title": "Worst-Case Services and State-Based Scheduling",
    "abstract": "Worst-Case Services and State-Based Scheduling",
    "descriptor": "",
    "authors": [
      "Yike Xu",
      "Mark S. Andersland"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2108.06062"
  },
  {
    "id": "arXiv:2108.07749",
    "title": "AGNet: Weighing Black Holes with Deep Learning",
    "abstract": "Comments: 8 pages, 7 figures, 1 table, Accepted by MNRAS",
    "descriptor": "\nComments: 8 pages, 7 figures, 1 table, Accepted by MNRAS\n",
    "authors": [
      "Joshua Yao-Yu Lin",
      "Sneh Pandya",
      "Devanshi Pratap",
      "Xin Liu",
      "Matias Carrasco Kind",
      "Volodymyr Kindratenko"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.07749"
  },
  {
    "id": "arXiv:2108.10718",
    "title": "Convexity via Weak Distributive Laws",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2012.14778",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2012.14778\n",
    "authors": [
      "Filippo Bonchi",
      "Alessio Santamaria"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2108.10718"
  },
  {
    "id": "arXiv:2109.05250",
    "title": "Towards Evaluation of Cross-document Coreference Resolution Models Using  Datasets with Diverse Annotation Schemes",
    "abstract": "Comments: The paper was accepted at LREC 2022: this https URL",
    "descriptor": "\nComments: The paper was accepted at LREC 2022: this https URL\n",
    "authors": [
      "Anastasia Zhukova",
      "Felix Hamborg",
      "Bela Gipp"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.05250"
  },
  {
    "id": "arXiv:2109.07270",
    "title": "Distract Your Attention: Multi-head Cross Attention Network for Facial  Expression Recognition",
    "abstract": "Distract Your Attention: Multi-head Cross Attention Network for Facial  Expression Recognition",
    "descriptor": "",
    "authors": [
      "Zhengyao Wen",
      "Wenzhong Lin",
      "Tao Wang",
      "Ge Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.07270"
  },
  {
    "id": "arXiv:2109.08745",
    "title": "Sublinear-Time Computation in the Presence of Online Erasures",
    "abstract": "Comments: 31 pages, 1 figure",
    "descriptor": "\nComments: 31 pages, 1 figure\n",
    "authors": [
      "Iden Kalemaj",
      "Sofya Raskhodnikova",
      "Nithin Varma"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2109.08745"
  },
  {
    "id": "arXiv:2109.10053",
    "title": "Toward a Fairness-Aware Scoring System for Algorithmic Decision-Making",
    "abstract": "Toward a Fairness-Aware Scoring System for Algorithmic Decision-Making",
    "descriptor": "",
    "authors": [
      "Yi Yang",
      "Ying Wu",
      "Mei Li",
      "Xiangyu Chang",
      "Yong Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2109.10053"
  },
  {
    "id": "arXiv:2110.00726",
    "title": "Domain-Specific Bias Filtering for Single Labeled Domain Generalization",
    "abstract": "Comments: Accepted by International Journal of Computer Vision (IJCV)",
    "descriptor": "\nComments: Accepted by International Journal of Computer Vision (IJCV)\n",
    "authors": [
      "Junkun Yuan",
      "Xu Ma",
      "Defang Chen",
      "Kun Kuang",
      "Fei Wu",
      "Lanfen Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.00726"
  },
  {
    "id": "arXiv:2110.05734",
    "title": "Learning Efficient Multi-Agent Cooperative Visual Exploration",
    "abstract": "Comments: First three authors share equal contribution. This paper has been accepted by ECCV (this https URL)",
    "descriptor": "\nComments: First three authors share equal contribution. This paper has been accepted by ECCV (this https URL)\n",
    "authors": [
      "Chao Yu",
      "Xinyi Yang",
      "Jiaxuan Gao",
      "Huazhong Yang",
      "Yu Wang",
      "Yi Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2110.05734"
  },
  {
    "id": "arXiv:2110.12081",
    "title": "Off-policy Reinforcement Learning with Optimistic Exploration and  Distribution Correction",
    "abstract": "Comments: Deep RL Workshop, NeurIPS 2022",
    "descriptor": "\nComments: Deep RL Workshop, NeurIPS 2022\n",
    "authors": [
      "Jiachen Li",
      "Shuo Cheng",
      "Zhenyu Liao",
      "Huayan Wang",
      "William Yang Wang",
      "Qinxun Bai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.12081"
  },
  {
    "id": "arXiv:2110.13521",
    "title": "Machine learning spectral functions in lattice QCD",
    "abstract": "Comments: 25 pages, 14 figures. Investigations on the dependences of output spectral functions on the noise model of mock correlators, and detailed derivation of formulae for the output spectral function are added",
    "descriptor": "\nComments: 25 pages, 14 figures. Investigations on the dependences of output spectral functions on the noise model of mock correlators, and detailed derivation of formulae for the output spectral function are added\n",
    "authors": [
      "S.-Y. Chen",
      "H.-T. Ding",
      "F.-Y. Liu",
      "G. Papp",
      "C.-B. Yang"
    ],
    "subjectives": [
      "High Energy Physics - Lattice (hep-lat)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)",
      "High Energy Physics - Theory (hep-th)",
      "Nuclear Theory (nucl-th)"
    ],
    "url": "https://arxiv.org/abs/2110.13521"
  },
  {
    "id": "arXiv:2110.13769",
    "title": "Interpretable Identification of Comorbidities Associated with Recurrent  ED and Inpatient Visits",
    "abstract": "Interpretable Identification of Comorbidities Associated with Recurrent  ED and Inpatient Visits",
    "descriptor": "",
    "authors": [
      "Luoluo Liu",
      "Eran Simhon",
      "Chaitanya Kulkarni",
      "David Noren",
      "Ronny Mans"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.13769"
  },
  {
    "id": "arXiv:2110.14258",
    "title": "Scattering and uniform in time error estimates for splitting method in  NLS",
    "abstract": "Comments: 31 pages, final version, including a new conclusive section",
    "descriptor": "\nComments: 31 pages, final version, including a new conclusive section\n",
    "authors": [
      "R\u00e9mi Carles",
      "Chunmei Su"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.14258"
  },
  {
    "id": "arXiv:2111.05329",
    "title": "Self-Supervised Audio-Visual Representation Learning with Relaxed  Cross-Modal Synchronicity",
    "abstract": "Comments: Accepted in AAAI 2023",
    "descriptor": "\nComments: Accepted in AAAI 2023\n",
    "authors": [
      "Pritam Sarkar",
      "Ali Etemad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.05329"
  },
  {
    "id": "arXiv:2111.06833",
    "title": "Frequency Estimation in the Shuffle Model with Almost a Single Message",
    "abstract": "Frequency Estimation in the Shuffle Model with Almost a Single Message",
    "descriptor": "",
    "authors": [
      "Qiyao Luo",
      "Yilei Wang",
      "Ke Yi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2111.06833"
  },
  {
    "id": "arXiv:2111.08418",
    "title": "Complete topological asymptotic expansion for $L_2$ and $H^1$  tracking-type cost functionals in dimension two and three",
    "abstract": "Comments: Formulas of Theorem 2.14 and Theorem 3.2 fixed, section including a special case added",
    "descriptor": "\nComments: Formulas of Theorem 2.14 and Theorem 3.2 fixed, section including a special case added\n",
    "authors": [
      "Phillip Baumann",
      "Peter Gangl",
      "Kevin Sturm"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2111.08418"
  },
  {
    "id": "arXiv:2111.11294",
    "title": "Scaling Law for Recommendation Models: Towards General-purpose User  Representations",
    "abstract": "Comments: Accepted at AAAI 2023. This version includes the technical appendix",
    "descriptor": "\nComments: Accepted at AAAI 2023. This version includes the technical appendix\n",
    "authors": [
      "Kyuyong Shin",
      "Hanock Kwak",
      "Su Young Kim",
      "Max Nihlen Ramstrom",
      "Jisu Jeong",
      "Jung-Woo Ha",
      "Kyung-Min Kim"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.11294"
  },
  {
    "id": "arXiv:2112.00386",
    "title": "Spurious Valleys, NP-hardness, and Tractability of Sparse Matrix  Factorization With Fixed Support",
    "abstract": "Spurious Valleys, NP-hardness, and Tractability of Sparse Matrix  Factorization With Fixed Support",
    "descriptor": "",
    "authors": [
      "Quoc-Tung Le",
      "Elisa Riccietti",
      "R\u00e9mi Gribonval"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2112.00386"
  },
  {
    "id": "arXiv:2112.02884",
    "title": "Social Sourcing: Incorporating Social Networks Into Crowdsourcing  Contest Design",
    "abstract": "Comments: IEEE/ACM Transactions on Networking",
    "descriptor": "\nComments: IEEE/ACM Transactions on Networking\n",
    "authors": [
      "Qi Shi",
      "Dong Hao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2112.02884"
  },
  {
    "id": "arXiv:2112.04674",
    "title": "DualFormer: Local-Global Stratified Transformer for Efficient Video  Recognition",
    "abstract": "Comments: Accepted by ECCV 2022",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Yuxuan Liang",
      "Pan Zhou",
      "Roger Zimmermann",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.04674"
  },
  {
    "id": "arXiv:2112.05120",
    "title": "On Convergence of Federated Averaging Langevin Dynamics",
    "abstract": "On Convergence of Federated Averaging Langevin Dynamics",
    "descriptor": "",
    "authors": [
      "Wei Deng",
      "Qian Zhang",
      "Yi-An Ma",
      "Zhao Song",
      "Guang Lin"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.05120"
  },
  {
    "id": "arXiv:2112.05666",
    "title": "An Ensemble 1D-CNN-LSTM-GRU Model with Data Augmentation for Speech  Emotion Recognition",
    "abstract": "Comments: This paper is currently under revision process at expert systems with applications journal",
    "descriptor": "\nComments: This paper is currently under revision process at expert systems with applications journal\n",
    "authors": [
      "Md. Rayhan Ahmed",
      "Salekul Islam",
      "Ph. D",
      "A. K. M. Muzahidul Islam",
      "Ph. D",
      "Swakkhar Shatabda",
      "Ph. D"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.05666"
  },
  {
    "id": "arXiv:2112.08458",
    "title": "Curriculum learning for data-driven modeling of dynamical systems",
    "abstract": "Curriculum learning for data-driven modeling of dynamical systems",
    "descriptor": "",
    "authors": [
      "Alessandro Bucci",
      "Onofrio Semeraro",
      "Alexandre Allauzen",
      "Sergio Chibbaro",
      "Lionel Mathelin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2112.08458"
  },
  {
    "id": "arXiv:2112.11027",
    "title": "More is Less: Inducing Sparsity via Overparameterization",
    "abstract": "More is Less: Inducing Sparsity via Overparameterization",
    "descriptor": "",
    "authors": [
      "Hung-Hsu Chou",
      "Johannes Maly",
      "Holger Rauhut"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.11027"
  },
  {
    "id": "arXiv:2112.12980",
    "title": "Disentanglement by Cyclic Reconstruction",
    "abstract": "Disentanglement by Cyclic Reconstruction",
    "descriptor": "",
    "authors": [
      "David Bertoin",
      "Emmanuel Rachelson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12980"
  },
  {
    "id": "arXiv:2112.15596",
    "title": "A Strongly Monotonic Polygonal Euler Scheme",
    "abstract": "A Strongly Monotonic Polygonal Euler Scheme",
    "descriptor": "",
    "authors": [
      "Tim Johnston",
      "Sotirios Sabanis"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.15596"
  },
  {
    "id": "arXiv:2201.00785",
    "title": "IAE: Implicit Autoencoder for Point Cloud Self-supervised Representation  Learning",
    "abstract": "Comments: Code available at this https URL",
    "descriptor": "\nComments: Code available at this https URL\n",
    "authors": [
      "Siming Yan",
      "Zhenpei Yang",
      "Haoxiang Li",
      "Li Guan",
      "Hao Kang",
      "Gang Hua",
      "Qixing Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.00785"
  },
  {
    "id": "arXiv:2201.05047",
    "title": "TransVOD: End-to-End Video Object Detection with Spatial-Temporal  Transformers",
    "abstract": "Comments: Accepted to IEEE Transactions on Pattern Analysis and Machine Intelligence (IEEE TPAMI), extended version of arXiv:2105.10920",
    "descriptor": "\nComments: Accepted to IEEE Transactions on Pattern Analysis and Machine Intelligence (IEEE TPAMI), extended version of arXiv:2105.10920\n",
    "authors": [
      "Qianyu Zhou",
      "Xiangtai Li",
      "Lu He",
      "Yibo Yang",
      "Guangliang Cheng",
      "Yunhai Tong",
      "Lizhuang Ma",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.05047"
  },
  {
    "id": "arXiv:2201.08988",
    "title": "Faster Algorithms for Sparse ILP and Hypergraph  Multi-Packing/Multi-Cover Problems",
    "abstract": "Faster Algorithms for Sparse ILP and Hypergraph  Multi-Packing/Multi-Cover Problems",
    "descriptor": "",
    "authors": [
      "Dmitry Gribanov",
      "Dmitry Malyshev",
      "Nikolai Zolotykh"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2201.08988"
  },
  {
    "id": "arXiv:2201.10259",
    "title": "t-Deletion-s-Insertion-Burst Correcting Codes",
    "abstract": "Comments: Part of this work (the (t,1)-burst model) was presented at ISIT2022. This full version has been submitted to IEEE-IT in August 2022",
    "descriptor": "\nComments: Part of this work (the (t,1)-burst model) was presented at ISIT2022. This full version has been submitted to IEEE-IT in August 2022\n",
    "authors": [
      "Ziyang Lu",
      "Yiwei Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.10259"
  },
  {
    "id": "arXiv:2201.10872",
    "title": "A Data-Driven Surrogate Modeling Approach for Time-Dependent  Incompressible Navier-Stokes Equations with Dynamic Mode Decomposition and  Manifold Interpolation",
    "abstract": "A Data-Driven Surrogate Modeling Approach for Time-Dependent  Incompressible Navier-Stokes Equations with Dynamic Mode Decomposition and  Manifold Interpolation",
    "descriptor": "",
    "authors": [
      "Martin W. Hess",
      "Annalisa Quaini",
      "Gianluigi Rozza"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.10872"
  },
  {
    "id": "arXiv:2201.11676",
    "title": "Monitoring Model Deterioration with Explainable Uncertainty Estimation  via Non-parametric Bootstrap",
    "abstract": "Comments: 7+6 pages. Accepted at AAAI'23 Safe and Robust AI track",
    "descriptor": "\nComments: 7+6 pages. Accepted at AAAI'23 Safe and Robust AI track\n",
    "authors": [
      "Carlos Mougan",
      "Dan Saattrup Nielsen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.11676"
  },
  {
    "id": "arXiv:2202.02763",
    "title": "Riemannian Score-Based Generative Modelling",
    "abstract": "Comments: Neurips 2022 camera ready",
    "descriptor": "\nComments: Neurips 2022 camera ready\n",
    "authors": [
      "Valentin De Bortoli",
      "Emile Mathieu",
      "Michael Hutchinson",
      "James Thornton",
      "Yee Whye Teh",
      "Arnaud Doucet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.02763"
  },
  {
    "id": "arXiv:2202.04769",
    "title": "Spectral Propagation Graph Network for Few-shot Time Series  Classification",
    "abstract": "Spectral Propagation Graph Network for Few-shot Time Series  Classification",
    "descriptor": "",
    "authors": [
      "Ling Yang",
      "Shenda Hong",
      "Luxia Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04769"
  },
  {
    "id": "arXiv:2202.06464",
    "title": "Synthetic Data Can Also Teach: Synthesizing Effective Data for  Unsupervised Visual Representation Learning",
    "abstract": "Synthetic Data Can Also Teach: Synthesizing Effective Data for  Unsupervised Visual Representation Learning",
    "descriptor": "",
    "authors": [
      "Yawen Wu",
      "Zhepeng Wang",
      "Dewen Zeng",
      "Yiyu Shi",
      "Jingtong Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06464"
  },
  {
    "id": "arXiv:2202.08248",
    "title": "Preconditioners for computing multiple solutions in three-dimensional  fluid topology optimization",
    "abstract": "Preconditioners for computing multiple solutions in three-dimensional  fluid topology optimization",
    "descriptor": "",
    "authors": [
      "Ioannis P. A. Papadopoulos",
      "Patrick E. Farrell"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.08248"
  },
  {
    "id": "arXiv:2202.08549",
    "title": "Oracle-Efficient Online Learning for Beyond Worst-Case Adversaries",
    "abstract": "Comments: An extended abstract of this work was published under the title \"Oracle-efficient Online Learning for Smoothed Adversaries'' in the Proceedings of the 36th Conference on Neural Information Processing Systems",
    "descriptor": "\nComments: An extended abstract of this work was published under the title \"Oracle-efficient Online Learning for Smoothed Adversaries'' in the Proceedings of the 36th Conference on Neural Information Processing Systems\n",
    "authors": [
      "Nika Haghtalab",
      "Yanjun Han",
      "Abhishek Shetty",
      "Kunhe Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.08549"
  },
  {
    "id": "arXiv:2202.08938",
    "title": "Improving Intrinsic Exploration with Language Abstractions",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Jesse Mu",
      "Victor Zhong",
      "Roberta Raileanu",
      "Minqi Jiang",
      "Noah Goodman",
      "Tim Rockt\u00e4schel",
      "Edward Grefenstette"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.08938"
  },
  {
    "id": "arXiv:2202.09115",
    "title": "Towards Simple and Accurate Human Pose Estimation with Stair Network",
    "abstract": "Comments: The paper has been accepted by IEEE Transactions on Emerging Topics in Computational Intelligence",
    "descriptor": "\nComments: The paper has been accepted by IEEE Transactions on Emerging Topics in Computational Intelligence\n",
    "authors": [
      "Chenru Jiang",
      "Kaizhu Huang",
      "Shufei Zhang",
      "Shufei Zhang",
      "Jimin Xiao",
      "Zhenxing Niu",
      "Amir Hussain"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.09115"
  },
  {
    "id": "arXiv:2202.09171",
    "title": "Linearization and Identification of Multiple-Attractor Dynamical Systems  through Laplacian Eigenmaps",
    "abstract": "Comments: Paper Accepted at Journal of Machine Learning Research 23 (2022)",
    "descriptor": "\nComments: Paper Accepted at Journal of Machine Learning Research 23 (2022)\n",
    "authors": [
      "Bernardo Fichera",
      "Aude Billard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.09171"
  },
  {
    "id": "arXiv:2202.11550",
    "title": "Robust Geometric Metric Learning",
    "abstract": "Comments: Published in EUSIPCO 2022. Best student paper award",
    "descriptor": "\nComments: Published in EUSIPCO 2022. Best student paper award\n",
    "authors": [
      "Antoine Collas",
      "Arnaud Breloy",
      "Guillaume Ginolhac",
      "Chengfang Ren",
      "Jean-Philippe Ovarlez"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.11550"
  },
  {
    "id": "arXiv:2202.13870",
    "title": "Simulating Network Paths with Recurrent Buffering Units",
    "abstract": "Comments: Accepted in AAAI 2023, 20 pages, 12 figures",
    "descriptor": "\nComments: Accepted in AAAI 2023, 20 pages, 12 figures\n",
    "authors": [
      "Divyam Anshumaan",
      "Sriram Balasubramanian",
      "Shubham Tiwari",
      "Nagarajan Natarajan",
      "Sundararajan Sellamanickam",
      "Venkata N. Padmanabhan"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.13870"
  },
  {
    "id": "arXiv:2203.01779",
    "title": "Exchange distance of basis pairs in split matroids",
    "abstract": "Comments: 15 pages",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Krist\u00f3f B\u00e9rczi",
      "Tam\u00e1s Schwarcz"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2203.01779"
  },
  {
    "id": "arXiv:2203.02606",
    "title": "Sustainable Verbal Human-Robot Interaction Through Cloud Services",
    "abstract": "Comments: 15 pages, 10 figures, associated video on YouTube: this https URL",
    "descriptor": "\nComments: 15 pages, 10 figures, associated video on YouTube: this https URL\n",
    "authors": [
      "Lucrezia Grassi",
      "Carmine Tommaso Recchiuto",
      "Antonio Sgorbissa"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.02606"
  },
  {
    "id": "arXiv:2203.03382",
    "title": "Self-supervised Implicit Glyph Attention for Text Recognition",
    "abstract": "Self-supervised Implicit Glyph Attention for Text Recognition",
    "descriptor": "",
    "authors": [
      "Tongkun Guan",
      "Chaochen Gu",
      "Jingzheng Tu",
      "Xue Yang",
      "Qi Feng",
      "Yudi Zhao",
      "Wei Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.03382"
  },
  {
    "id": "arXiv:2203.05920",
    "title": "Generalized Bandit Regret Minimizer Framework in Imperfect Information  Extensive-Form Game",
    "abstract": "Comments: Our proof is wrong. Exactly, the convergence bound of our method is better than the best bound in information theory, which is impossible",
    "descriptor": "\nComments: Our proof is wrong. Exactly, the convergence bound of our method is better than the best bound in information theory, which is impossible\n",
    "authors": [
      "Linjian Meng",
      "Yang Gao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2203.05920"
  },
  {
    "id": "arXiv:2203.12232",
    "title": "Enhanced Contour Tracking: a Time-Varying Internal Model Principle-Based  Approach",
    "abstract": "Comments: 19 pages, 12 figures, 3 tables",
    "descriptor": "\nComments: 19 pages, 12 figures, 3 tables\n",
    "authors": [
      "Yue Cao",
      "Zhen Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.12232"
  },
  {
    "id": "arXiv:2203.13573",
    "title": "Unsupervised Learning of Temporal Abstractions with Slot-based  Transformers",
    "abstract": "Comments: accepted to Neural Computation journal",
    "descriptor": "\nComments: accepted to Neural Computation journal\n",
    "authors": [
      "Anand Gopalakrishnan",
      "Kazuki Irie",
      "J\u00fcrgen Schmidhuber",
      "Sjoerd van Steenkiste"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2203.13573"
  },
  {
    "id": "arXiv:2204.00315",
    "title": "State-feedback Abstractions for Optimal Control of Piecewise-affine  Systems",
    "abstract": "Comments: 10 pages, 3 figures, accepted to IEEE CDC 2022",
    "descriptor": "\nComments: 10 pages, 3 figures, accepted to IEEE CDC 2022\n",
    "authors": [
      "Lucas N. Egidio",
      "Thiago Alves Lima",
      "Rapha\u00ebl M. Jungers"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.00315"
  },
  {
    "id": "arXiv:2204.00453",
    "title": "Optimal Management of a Smart Port with Shore-Connection and Hydrogen  Supplying by Stochastic Model Predictive Control",
    "abstract": "Optimal Management of a Smart Port with Shore-Connection and Hydrogen  Supplying by Stochastic Model Predictive Control",
    "descriptor": "",
    "authors": [
      "Francesco Conte",
      "Fabio D'Agostino",
      "Daniele Kaza",
      "Stefano Massucco",
      "Gianluca Natrella",
      "Federico Silvestro"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.00453"
  },
  {
    "id": "arXiv:2204.01434",
    "title": "Circuit Model Reduction with Scaled Relative Graphs",
    "abstract": "Comments: Submitted to CDC2022",
    "descriptor": "\nComments: Submitted to CDC2022\n",
    "authors": [
      "Thomas Chaffey",
      "Alberto Padoan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.01434"
  },
  {
    "id": "arXiv:2204.04006",
    "title": "Analysis and transformations of voice level in singing voice",
    "abstract": "Comments: Submitted to ICASSP 2023",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Frederik Bous",
      "Axel Roebel"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.04006"
  },
  {
    "id": "arXiv:2204.09911",
    "title": "STFT-Domain Neural Speech Enhancement with Very Low Algorithmic Latency",
    "abstract": "Comments: in IEEE/ACM Transactions on Audio, Speech, and Language Processing",
    "descriptor": "\nComments: in IEEE/ACM Transactions on Audio, Speech, and Language Processing\n",
    "authors": [
      "Zhong-Qiu Wang",
      "Gordon Wichern",
      "Shinji Watanabe",
      "Jonathan Le Roux"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2204.09911"
  },
  {
    "id": "arXiv:2204.10040",
    "title": "Adapting Stable Matchings to Forced and Forbidden Pairs",
    "abstract": "Adapting Stable Matchings to Forced and Forbidden Pairs",
    "descriptor": "",
    "authors": [
      "Niclas Boehmer",
      "Klaus Heeger"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2204.10040"
  },
  {
    "id": "arXiv:2204.11942",
    "title": "Meta-AF: Meta-Learning for Adaptive Filters",
    "abstract": "Comments: Accepted to ACM/IEEE TASLP. Source code and audio examples: this https URL",
    "descriptor": "\nComments: Accepted to ACM/IEEE TASLP. Source code and audio examples: this https URL\n",
    "authors": [
      "Jonah Casebeer",
      "Nicholas J. Bryan",
      "Paris Smaragdis"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.11942"
  },
  {
    "id": "arXiv:2205.00617",
    "title": "A high-order deferred correction method for the solution of free  boundary problems using penalty iteration, with an application to American  option pricing",
    "abstract": "Comments: 40 pages",
    "descriptor": "\nComments: 40 pages\n",
    "authors": [
      "Dawei Wang",
      "Kirill Serkh",
      "Christina christara"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2205.00617"
  },
  {
    "id": "arXiv:2205.01733",
    "title": "Application of belief functions to medical image segmentation: A review",
    "abstract": "Comments: Accepted by Information fusion",
    "descriptor": "\nComments: Accepted by Information fusion\n",
    "authors": [
      "Ling Huang",
      "Su Ruan",
      "Thierry Denoeux"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01733"
  },
  {
    "id": "arXiv:2205.05345",
    "title": "Variational Autoencoder Leveraged MMSE Channel Estimation",
    "abstract": "Comments: Accepted for publication at Asilomar 2022",
    "descriptor": "\nComments: Accepted for publication at Asilomar 2022\n",
    "authors": [
      "Michael Baur",
      "Benedikt Fesl",
      "Michael Koller",
      "Wolfgang Utschick"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.05345"
  },
  {
    "id": "arXiv:2205.08818",
    "title": "Transparent Serverless execution of Python multiprocessing applications",
    "abstract": "Transparent Serverless execution of Python multiprocessing applications",
    "descriptor": "",
    "authors": [
      "Aitor Arjona",
      "Gerard Finol",
      "Pedro Garcia-Lopez"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2205.08818"
  },
  {
    "id": "arXiv:2205.10715",
    "title": "Policy-based Primal-Dual Methods for Convex Constrained Markov Decision  Processes",
    "abstract": "Comments: 29 pages, AAAI23",
    "descriptor": "\nComments: 29 pages, AAAI23\n",
    "authors": [
      "Donghao Ying",
      "Mengzi Amy Guo",
      "Yuhao Ding",
      "Javad Lavaei",
      "Zuo-Jun Max Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2205.10715"
  },
  {
    "id": "arXiv:2205.10972",
    "title": "Global Extreme Heat Forecasting Using Neural Weather Models",
    "abstract": "Global Extreme Heat Forecasting Using Neural Weather Models",
    "descriptor": "",
    "authors": [
      "Ignacio Lopez-Gomez",
      "Amy McGovern",
      "Shreya Agrawal",
      "Jason Hickey"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.10972"
  },
  {
    "id": "arXiv:2205.11169",
    "title": "PEVL: Position-enhanced Pre-training and Prompt Tuning for  Vision-language Models",
    "abstract": "Comments: Accepted by EMNLP 2022",
    "descriptor": "\nComments: Accepted by EMNLP 2022\n",
    "authors": [
      "Yuan Yao",
      "Qianyu Chen",
      "Ao Zhang",
      "Wei Ji",
      "Zhiyuan Liu",
      "Tat-Seng Chua",
      "Maosong Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.11169"
  },
  {
    "id": "arXiv:2205.11982",
    "title": "Holonomic equations and efficient random generation of binary trees",
    "abstract": "Holonomic equations and efficient random generation of binary trees",
    "descriptor": "",
    "authors": [
      "Pierre Lescanne"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.11982"
  },
  {
    "id": "arXiv:2205.12701",
    "title": "Eliciting and Understanding Cross-Task Skills with Task-Level  Mixture-of-Experts",
    "abstract": "Comments: Accepted to EMNLP 2022 Findings. Camera-ready version",
    "descriptor": "\nComments: Accepted to EMNLP 2022 Findings. Camera-ready version\n",
    "authors": [
      "Qinyuan Ye",
      "Juan Zha",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12701"
  },
  {
    "id": "arXiv:2205.13425",
    "title": "Do we really need temporal convolutions in action segmentation?",
    "abstract": "Do we really need temporal convolutions in action segmentation?",
    "descriptor": "",
    "authors": [
      "Dazhao Du",
      "Bing Su",
      "Yu Li",
      "Zhongang Qi",
      "Lingyu Si",
      "Ying Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.13425"
  },
  {
    "id": "arXiv:2205.13826",
    "title": "Multivariate Probabilistic Forecasting of Intraday Electricity Prices  using Normalizing Flows",
    "abstract": "Comments: manuscript (18 pages, 10 figures, 5 tables), supporting information (4 pages, 3 figures, 3 tables)",
    "descriptor": "\nComments: manuscript (18 pages, 10 figures, 5 tables), supporting information (4 pages, 3 figures, 3 tables)\n",
    "authors": [
      "Eike Cramer",
      "Dirk Witthaut",
      "Alexander Mitsos",
      "Manuel Dahmen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.13826"
  },
  {
    "id": "arXiv:2205.13879",
    "title": "MIMII DG: Sound Dataset for Malfunctioning Industrial Machine  Investigation and Inspection for Domain Generalization Task",
    "abstract": "MIMII DG: Sound Dataset for Malfunctioning Industrial Machine  Investigation and Inspection for Domain Generalization Task",
    "descriptor": "",
    "authors": [
      "Kota Dohi",
      "Tomoya Nishida",
      "Harsh Purohit",
      "Ryo Tanabe",
      "Takashi Endo",
      "Masaaki Yamamoto",
      "Yuki Nikaido",
      "Yohei Kawaguchi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2205.13879"
  },
  {
    "id": "arXiv:2205.14111",
    "title": "Optimal polynomial meshes exist on any multivariate convex domain",
    "abstract": "Optimal polynomial meshes exist on any multivariate convex domain",
    "descriptor": "",
    "authors": [
      "Feng Dai",
      "Andriy Prymak"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Classical Analysis and ODEs (math.CA)"
    ],
    "url": "https://arxiv.org/abs/2205.14111"
  },
  {
    "id": "arXiv:2206.01444",
    "title": "XPASC: Measuring Generalization in Weak Supervision by Explainability  and Association",
    "abstract": "Comments: 26 pages, 20 Figures, 5 Tables",
    "descriptor": "\nComments: 26 pages, 20 Figures, 5 Tables\n",
    "authors": [
      "Luisa M\u00e4rz",
      "Ehsaneddin Asgari",
      "Fabienne Braune",
      "Franziska Zimmermann",
      "Benjamin Roth"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2206.01444"
  },
  {
    "id": "arXiv:2206.02604",
    "title": "Rate-Distortion Theoretic Bounds on Generalization Error for Distributed  Learning",
    "abstract": "Comments: Accepted at NeurIPS 2022",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Milad Sefidgaran",
      "Romain Chor",
      "Abdellatif Zaidi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02604"
  },
  {
    "id": "arXiv:2206.02671",
    "title": "Canonical Cortical Graph Neural Networks and its Application for Speech  Enhancement in Future Audio-Visual Hearing Aids",
    "abstract": "Canonical Cortical Graph Neural Networks and its Application for Speech  Enhancement in Future Audio-Visual Hearing Aids",
    "descriptor": "",
    "authors": [
      "Leandro A. Passos",
      "Jo\u00e3o Paulo Papa",
      "Amir Hussain",
      "Ahsan Adeel"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.02671"
  },
  {
    "id": "arXiv:2206.03171",
    "title": "Look Back When Surprised: Stabilizing Reverse Experience Replay for  Neural Approximation",
    "abstract": "Look Back When Surprised: Stabilizing Reverse Experience Replay for  Neural Approximation",
    "descriptor": "",
    "authors": [
      "Ramnath Kumar",
      "Dheeraj Nagaraj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03171"
  },
  {
    "id": "arXiv:2206.05876",
    "title": "Description and Discussion on DCASE 2022 Challenge Task 2: Unsupervised  Anomalous Sound Detection for Machine Condition Monitoring Applying Domain  Generalization Techniques",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2106.04492",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2106.04492\n",
    "authors": [
      "Kota Dohi",
      "Keisuke Imoto",
      "Noboru Harada",
      "Daisuke Niizumi",
      "Yuma Koizumi",
      "Tomoya Nishida",
      "Harsh Purohit",
      "Takashi Endo",
      "Masaaki Yamamoto",
      "Yohei Kawaguchi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.05876"
  },
  {
    "id": "arXiv:2206.08853",
    "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale  Knowledge",
    "abstract": "Comments: Outstanding Paper Award at NeurIPS 2022. Project website: this https URL",
    "descriptor": "\nComments: Outstanding Paper Award at NeurIPS 2022. Project website: this https URL\n",
    "authors": [
      "Linxi Fan",
      "Guanzhi Wang",
      "Yunfan Jiang",
      "Ajay Mandlekar",
      "Yuncong Yang",
      "Haoyi Zhu",
      "Andrew Tang",
      "De-An Huang",
      "Yuke Zhu",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.08853"
  },
  {
    "id": "arXiv:2206.08965",
    "title": "KitBit: A New AI Model for Solving Intelligence Tests and Numerical  Series",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "V\u00edctor Corsino",
      "Jos\u00e9 Manuel Gilp\u00e9rez",
      "Luis Herrera"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.08965"
  },
  {
    "id": "arXiv:2206.09209",
    "title": "The Frenet Frame as a Generalization of the Park Transform",
    "abstract": "Comments: 11 pages, 2 figures, accepted for publication on the IEEE Transactions on Circuits and Systems I: Regular Papers",
    "descriptor": "\nComments: 11 pages, 2 figures, accepted for publication on the IEEE Transactions on Circuits and Systems I: Regular Papers\n",
    "authors": [
      "Federico Milano"
    ],
    "subjectives": [
      "Differential Geometry (math.DG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.09209"
  },
  {
    "id": "arXiv:2206.11739",
    "title": "Evidence fusion with contextual discounting for multi-modality medical  image segmentation",
    "abstract": "Comments: MICCAI2022",
    "descriptor": "\nComments: MICCAI2022\n",
    "authors": [
      "Ling Huang",
      "Thierry Denoeux",
      "Pierre Vera",
      "Su Ruan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.11739"
  },
  {
    "id": "arXiv:2206.15316",
    "title": "Interpretable Anomaly Detection in Echocardiograms with Dynamic  Variational Trajectory Models",
    "abstract": "Comments: accepted at IMLH workshop ICML 2022",
    "descriptor": "\nComments: accepted at IMLH workshop ICML 2022\n",
    "authors": [
      "Alain Ryser",
      "Laura Manduchi",
      "Fabian Laumer",
      "Holger Michel",
      "Sven Wellmann",
      "Julia E. Vogt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.15316"
  },
  {
    "id": "arXiv:2207.00050",
    "title": "Semantic Image Synthesis via Diffusion Models",
    "abstract": "Semantic Image Synthesis via Diffusion Models",
    "descriptor": "",
    "authors": [
      "Weilun Wang",
      "Jianmin Bao",
      "Wengang Zhou",
      "Dongdong Chen",
      "Dong Chen",
      "Lu Yuan",
      "Houqiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.00050"
  },
  {
    "id": "arXiv:2207.00610",
    "title": "A Temporal Fusion Transformer for Long-term Explainable Prediction of  Emergency Department Overcrowding",
    "abstract": "Comments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 16 pages",
    "descriptor": "\nComments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 16 pages\n",
    "authors": [
      "Francisco M. Caldas",
      "Cl\u00e1udia Soares"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.00610"
  },
  {
    "id": "arXiv:2207.04308",
    "title": "Dynamic Time Warping based Adversarial Framework for Time-Series Domain",
    "abstract": "Comments: Accepted for publication at IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)",
    "descriptor": "\nComments: Accepted for publication at IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)\n",
    "authors": [
      "Taha Belkhouja",
      "Yan Yan",
      "Janardhan Rao Doppa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.04308"
  },
  {
    "id": "arXiv:2207.04666",
    "title": "Improved bounds on the gain coefficients for digital nets in prime power  base",
    "abstract": "Comments: minor revision, 14 pages",
    "descriptor": "\nComments: minor revision, 14 pages\n",
    "authors": [
      "Takashi Goda",
      "Kosuke Suzuki"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.04666"
  },
  {
    "id": "arXiv:2207.04782",
    "title": "Exploiting Different Symmetries for Trajectory Tracking Control with  Application to Quadrotors",
    "abstract": "Exploiting Different Symmetries for Trajectory Tracking Control with  Application to Quadrotors",
    "descriptor": "",
    "authors": [
      "Matthew Hampsey",
      "Pieter van Goor",
      "Tarek Hamel",
      "Robert Mahony"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.04782"
  },
  {
    "id": "arXiv:2207.05426",
    "title": "A one-shot overlapping Schwarz method for component-based model  reduction: application to nonlinear elasticity",
    "abstract": "A one-shot overlapping Schwarz method for component-based model  reduction: application to nonlinear elasticity",
    "descriptor": "",
    "authors": [
      "Angelo Iollo",
      "Giulia Sambataro",
      "Tommaso Taddei"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2207.05426"
  },
  {
    "id": "arXiv:2207.05430",
    "title": "Learning Diverse Tone Styles for Image Retouching",
    "abstract": "Learning Diverse Tone Styles for Image Retouching",
    "descriptor": "",
    "authors": [
      "Haolin Wang",
      "Jiawei Zhang",
      "Ming Liu",
      "Xiaohe Wu",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.05430"
  },
  {
    "id": "arXiv:2207.05480",
    "title": "Temporal Disentanglement of Representations for Improved Generalisation  in Reinforcement Learning",
    "abstract": "Comments: NeurIPS 2022 Workshop on Deep Reinforcement Learning",
    "descriptor": "\nComments: NeurIPS 2022 Workshop on Deep Reinforcement Learning\n",
    "authors": [
      "Mhairi Dunion",
      "Trevor McInroe",
      "Kevin Sebastian Luck",
      "Josiah Hanna",
      "Stefano V. Albrecht"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.05480"
  },
  {
    "id": "arXiv:2207.05615",
    "title": "Contrastive Learning for Online Semi-Supervised General Continual  Learning",
    "abstract": "Comments: Accepted at ICIP'22 Oral presentation",
    "descriptor": "\nComments: Accepted at ICIP'22 Oral presentation\n",
    "authors": [
      "Nicolas Michel",
      "Romain Negrel",
      "Giovanni Chierchia",
      "Jean-Fran\u00e7ois Bercher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.05615"
  },
  {
    "id": "arXiv:2207.06572",
    "title": "i-Sim2Real: Reinforcement Learning of Robotic Policies in Tight  Human-Robot Interaction Loops",
    "abstract": "Comments: 8+24 pages",
    "descriptor": "\nComments: 8+24 pages\n",
    "authors": [
      "Saminda Abeyruwan",
      "Laura Graesser",
      "David B. D'Ambrosio",
      "Avi Singh",
      "Anish Shankar",
      "Alex Bewley",
      "Deepali Jain",
      "Krzysztof Choromanski",
      "Pannag R. Sanketi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2207.06572"
  },
  {
    "id": "arXiv:2207.07332",
    "title": "Stereo Co-capture System for Recording and Tracking Fish with Frame- and  Event Cameras",
    "abstract": "Comments: 4 pages, 5 figures, 1 table",
    "descriptor": "\nComments: 4 pages, 5 figures, 1 table\n",
    "authors": [
      "Friedhelm Hamann",
      "Guillermo Gallego"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.07332"
  },
  {
    "id": "arXiv:2207.09106",
    "title": "Explainable Human-in-the-loop Dynamic Data-Driven Digital Twins",
    "abstract": "Comments: 11 pages, 1 figure, accepted by the 4th International Conference on InfoSymbiotics/Dynamic Data Driven Applications Systems (DDDAS2022)",
    "descriptor": "\nComments: 11 pages, 1 figure, accepted by the 4th International Conference on InfoSymbiotics/Dynamic Data Driven Applications Systems (DDDAS2022)\n",
    "authors": [
      "Nan Zhang",
      "Rami Bahsoon",
      "Nikos Tziritas",
      "Georgios Theodoropoulos"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.09106"
  },
  {
    "id": "arXiv:2207.13121",
    "title": "Scheduling under Non-Uniform Job and Machine Delays",
    "abstract": "Scheduling under Non-Uniform Job and Machine Delays",
    "descriptor": "",
    "authors": [
      "Rajmohan Rajaraman",
      "David Stalfa",
      "Sheng Yang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.13121"
  },
  {
    "id": "arXiv:2207.13297",
    "title": "GPS-GLASS: Learning Nighttime Semantic Segmentation Using Daytime Video  and GPS data",
    "abstract": "GPS-GLASS: Learning Nighttime Semantic Segmentation Using Daytime Video  and GPS data",
    "descriptor": "",
    "authors": [
      "Hongjae Lee",
      "Changwoo Han",
      "Jun-Sang Yoo",
      "Seung-Won Jung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.13297"
  },
  {
    "id": "arXiv:2208.01018",
    "title": "BabelBERT: Massively Multilingual Transformers Meet a Massively  Multilingual Lexical Resource",
    "abstract": "Comments: Errors in reported results detected post-submission. The conclusions drawn in the paper do not hold",
    "descriptor": "\nComments: Errors in reported results detected post-submission. The conclusions drawn in the paper do not hold\n",
    "authors": [
      "Tommaso Green",
      "Simone Paolo Ponzetto",
      "Goran Glava\u0161"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.01018"
  },
  {
    "id": "arXiv:2208.01215",
    "title": "PAN: Pulse Ansatz on NISQ Machines",
    "abstract": "Comments: 13 pages, 13 figures",
    "descriptor": "\nComments: 13 pages, 13 figures\n",
    "authors": [
      "Zhiding Liang",
      "Jinglei Cheng",
      "Hang Ren",
      "Hanrui Wang",
      "Fei Hua",
      "Yongshan Ding",
      "Fred Chong",
      "Song Han",
      "Yiyu Shi",
      "Xuehai Qian"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.01215"
  },
  {
    "id": "arXiv:2208.06234",
    "title": "Ad Hoc HLA Simulation Model Derived From a Model-Based Traffic Scenario",
    "abstract": "Comments: submitted to SIMULATION: Transactions of The Society for Modeling and Simulation International",
    "descriptor": "\nComments: submitted to SIMULATION: Transactions of The Society for Modeling and Simulation International\n",
    "authors": [
      "David Reiher",
      "Axel Hahn"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2208.06234"
  },
  {
    "id": "arXiv:2208.09818",
    "title": "Rate-Splitting Multiple Access for Intelligent Reflecting Surface-Aided  Secure Transmission",
    "abstract": "Comments: 5 pages, 6 figures, accepted by IEEE Communications Letters",
    "descriptor": "\nComments: 5 pages, 6 figures, accepted by IEEE Communications Letters\n",
    "authors": [
      "Ying Gao",
      "Qingqing Wu",
      "Wen Chen",
      "Derrick Wing Kwan Ng"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2208.09818"
  },
  {
    "id": "arXiv:2208.11510",
    "title": "Quantum Multi-Agent Meta Reinforcement Learning",
    "abstract": "Quantum Multi-Agent Meta Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Won Joon Yun",
      "Jihong Park",
      "Joongheon Kim"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2208.11510"
  },
  {
    "id": "arXiv:2209.00517",
    "title": "The Neural Process Family: Survey, Applications and Perspectives",
    "abstract": "Comments: 55 pages, 13 figures, Added up-to-date literature",
    "descriptor": "\nComments: 55 pages, 13 figures, Added up-to-date literature\n",
    "authors": [
      "Saurav Jha",
      "Dong Gong",
      "Xuesong Wang",
      "Richard E. Turner",
      "Lina Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.00517"
  },
  {
    "id": "arXiv:2209.02045",
    "title": "Visualization Of Class Activation Maps To Explain AI Classification Of  Network Packet Captures",
    "abstract": "Visualization Of Class Activation Maps To Explain AI Classification Of  Network Packet Captures",
    "descriptor": "",
    "authors": [
      "Igor Cherepanov",
      "Alex Ulmer",
      "Jonathan Geraldi Joewono",
      "J\u00f6rn Kohlhammer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2209.02045"
  },
  {
    "id": "arXiv:2209.03126",
    "title": "DM$^2$S$^2$: Deep Multi-Modal Sequence Sets with Hierarchical Modality  Attention",
    "abstract": "Comments: 12 pages, 3 figures. Accepted by IEEE Access on Nov. 3, 2022",
    "descriptor": "\nComments: 12 pages, 3 figures. Accepted by IEEE Access on Nov. 3, 2022\n",
    "authors": [
      "Shunsuke Kitada",
      "Yuki Iwazaki",
      "Riku Togashi",
      "Hitoshi Iyatomi"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.03126"
  },
  {
    "id": "arXiv:2209.04142",
    "title": "Joint Non-parametric Point Process model for Treatments and Outcomes:  Counterfactual Time-series Prediction Under Policy Interventions",
    "abstract": "Comments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 7 pages. This article is the extended abstract version of the long article arXiv:2209.04142v1 (previous version)",
    "descriptor": "\nComments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 7 pages. This article is the extended abstract version of the long article arXiv:2209.04142v1 (previous version)\n",
    "authors": [
      "\u00c7a\u011flar H\u0131zl\u0131",
      "ST John",
      "Anne Juuti",
      "Tuure Saarinen",
      "Kirsi Pietil\u00e4inen",
      "Pekka Marttinen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2209.04142"
  },
  {
    "id": "arXiv:2209.06434",
    "title": "ConvNext Based Neural Network for Audio Anti-Spoofing",
    "abstract": "Comments: 7 pages",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Qiaowei Ma",
      "Jinghui Zhong",
      "Yitao Yang",
      "Weiheng Liu",
      "Ying Gao",
      "Wing W.Y. Ng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2209.06434"
  },
  {
    "id": "arXiv:2209.08908",
    "title": "Adaptive Output Feedback Model Predictive Control",
    "abstract": "Comments: 6 pages, 4 figures, 1 table",
    "descriptor": "\nComments: 6 pages, 4 figures, 1 table\n",
    "authors": [
      "Anchita Dey",
      "Abhishek Dhar",
      "Shubhendu Bhasin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2209.08908"
  },
  {
    "id": "arXiv:2209.09658",
    "title": "Lazy vs hasty: linearization in deep networks impacts learning schedule  based on example difficulty",
    "abstract": "Comments: 25 pages, 14 figures",
    "descriptor": "\nComments: 25 pages, 14 figures\n",
    "authors": [
      "Thomas George",
      "Guillaume Lajoie",
      "Aristide Baratin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.09658"
  },
  {
    "id": "arXiv:2209.10411",
    "title": "Metaball-Imaging Discrete Element Lattice Boltzmann Method for  fluid-particle system of complex morphologies with settling case study",
    "abstract": "Metaball-Imaging Discrete Element Lattice Boltzmann Method for  fluid-particle system of complex morphologies with settling case study",
    "descriptor": "",
    "authors": [
      "Yifeng Zhao",
      "Pei Zhang",
      "Liang Lei",
      "S.A. Galindo-Torres",
      "Stan Z.Li"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2209.10411"
  },
  {
    "id": "arXiv:2209.10897",
    "title": "Process Modeling and Conformance Checking in Healthcare: A COVID-19 Case  Study",
    "abstract": "Comments: 12 pages, 2 figures, 3 tables, 15 references",
    "descriptor": "\nComments: 12 pages, 2 figures, 3 tables, 15 references\n",
    "authors": [
      "Elisabetta Benevento",
      "Marco Pegoraro",
      "Mattia Antoniazzi",
      "Harry H. Beyel",
      "Viki Peeva",
      "Paul Balfanz",
      "Wil M.P. van der Aalst",
      "Lukas Martin",
      "Gernot Marx"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.10897"
  },
  {
    "id": "arXiv:2209.11767",
    "title": "Mental arithmetic task classification with convolutional neural network  based on spectral-temporal features from EEG",
    "abstract": "Comments: Updated Figure",
    "descriptor": "\nComments: Updated Figure\n",
    "authors": [
      "Zaineb Ajra",
      "Binbin Xu",
      "G\u00e9rard Dray",
      "Jacky Montmain",
      "Stephane Perrey"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2209.11767"
  },
  {
    "id": "arXiv:2209.12118",
    "title": "BURST: A Benchmark for Unifying Object Recognition, Segmentation and  Tracking in Video",
    "abstract": "BURST: A Benchmark for Unifying Object Recognition, Segmentation and  Tracking in Video",
    "descriptor": "",
    "authors": [
      "Ali Athar",
      "Jonathon Luiten",
      "Paul Voigtlaender",
      "Tarasha Khurana",
      "Achal Dave",
      "Bastian Leibe",
      "Deva Ramanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.12118"
  },
  {
    "id": "arXiv:2209.13094",
    "title": "Efficient Noise Filtration of Images by Low-Rank Singular Vector  Approximations of Geodesics' Gramian Matrix",
    "abstract": "Comments: 19 pages, 3 figures, submitted to ACM Transactions on Architecture and Code Optimization",
    "descriptor": "\nComments: 19 pages, 3 figures, submitted to ACM Transactions on Architecture and Code Optimization\n",
    "authors": [
      "Kelum Gajamannage",
      "Yonggi Park",
      "Mallikarjunaiah Muddamallappa",
      "Sunil Mathur"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.13094"
  },
  {
    "id": "arXiv:2209.14390",
    "title": "Neighborhood Gradient Clustering: An Efficient Decentralized Learning  Method for Non-IID Data Distributions",
    "abstract": "Comments: 19 pages, 5 figures, 16 tables",
    "descriptor": "\nComments: 19 pages, 5 figures, 16 tables\n",
    "authors": [
      "Sai Aparna Aketi",
      "Sangamesh Kodge",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2209.14390"
  },
  {
    "id": "arXiv:2209.14430",
    "title": "Minimax Optimal Kernel Operator Learning via Multilevel Training",
    "abstract": "Minimax Optimal Kernel Operator Learning via Multilevel Training",
    "descriptor": "",
    "authors": [
      "Jikai Jin",
      "Yiping Lu",
      "Jose Blanchet",
      "Lexing Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)",
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.14430"
  },
  {
    "id": "arXiv:2209.14462",
    "title": "What Can Cryptography Do For Decentralized Mechanism Design",
    "abstract": "What Can Cryptography Do For Decentralized Mechanism Design",
    "descriptor": "",
    "authors": [
      "Elaine Shi",
      "Hao Chung",
      "Ke Wu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2209.14462"
  },
  {
    "id": "arXiv:2209.14491",
    "title": "Re-Imagen: Retrieval-Augmented Text-to-Image Generator",
    "abstract": "Comments: 9 pages",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Wenhu Chen",
      "Hexiang Hu",
      "Chitwan Saharia",
      "William W. Cohen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.14491"
  },
  {
    "id": "arXiv:2209.14927",
    "title": "Spotlight: Mobile UI Understanding using Vision-Language Models with a  Focus",
    "abstract": "Spotlight: Mobile UI Understanding using Vision-Language Models with a  Focus",
    "descriptor": "",
    "authors": [
      "Gang Li",
      "Yang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.14927"
  },
  {
    "id": "arXiv:2209.15425",
    "title": "Spikformer: When Spiking Neural Network Meets Transformer",
    "abstract": "Spikformer: When Spiking Neural Network Meets Transformer",
    "descriptor": "",
    "authors": [
      "Zhaokun Zhou",
      "Yuesheng Zhu",
      "Chao He",
      "Yaowei Wang",
      "Shuicheng Yan",
      "Yonghong Tian",
      "Li Yuan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.15425"
  },
  {
    "id": "arXiv:2209.15575",
    "title": "Match to Win: Analysing Sequences Lengths for Efficient Self-supervised  Learning in Speech and Audio",
    "abstract": "Match to Win: Analysing Sequences Lengths for Efficient Self-supervised  Learning in Speech and Audio",
    "descriptor": "",
    "authors": [
      "Yan Gao",
      "Javier Fernandez-Marques",
      "Titouan Parcollet",
      "Pedro P. B. de Gusmao",
      "Nicholas D. Lane"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2209.15575"
  },
  {
    "id": "arXiv:2210.00131",
    "title": "Selection Induced Collider Bias: A Gender Pronoun Uncertainty Case Study",
    "abstract": "Comments: 16 pages, 21 figures. arXiv admin note: text overlap with arXiv:2208.10063",
    "descriptor": "\nComments: 16 pages, 21 figures. arXiv admin note: text overlap with arXiv:2208.10063\n",
    "authors": [
      "Emily McMilin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.00131"
  },
  {
    "id": "arXiv:2210.00417",
    "title": "Voice Spoofing Countermeasures: Taxonomy, State-of-the-art, experimental  analysis of generalizability, open challenges, and the way forward",
    "abstract": "Voice Spoofing Countermeasures: Taxonomy, State-of-the-art, experimental  analysis of generalizability, open challenges, and the way forward",
    "descriptor": "",
    "authors": [
      "Awais Khan",
      "Khalid Mahmood Malik",
      "James Ryan",
      "Mikul Saravanan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computers and Society (cs.CY)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.00417"
  },
  {
    "id": "arXiv:2210.00655",
    "title": "Online Pen Testing",
    "abstract": "Comments: To appear at ITCS 2023; v2 added discussion on a closely related work of Awerbuch, Azar, Fiat, and Leighton (1996)",
    "descriptor": "\nComments: To appear at ITCS 2023; v2 added discussion on a closely related work of Awerbuch, Azar, Fiat, and Leighton (1996)\n",
    "authors": [
      "Mingda Qiao",
      "Gregory Valiant"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2210.00655"
  },
  {
    "id": "arXiv:2210.00868",
    "title": "Strain energy density as a Gaussian process and its utilization in  stochastic finite element analysis: application to planar soft tissues",
    "abstract": "Strain energy density as a Gaussian process and its utilization in  stochastic finite element analysis: application to planar soft tissues",
    "descriptor": "",
    "authors": [
      "Ankush Aggarwal",
      "Bj\u00f8rn Sand Jensen",
      "Sanjay Pant",
      "Chung-Hao Lee"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Numerical Analysis (math.NA)",
      "Biological Physics (physics.bio-ph)",
      "Tissues and Organs (q-bio.TO)"
    ],
    "url": "https://arxiv.org/abs/2210.00868"
  },
  {
    "id": "arXiv:2210.04269",
    "title": "Data-driven framework for input/output lookup tables reduction -- with  application to hypersonic flows in chemical non-equilibrium",
    "abstract": "Comments: 24 pages, 16 figures, 2 tables",
    "descriptor": "\nComments: 24 pages, 16 figures, 2 tables\n",
    "authors": [
      "Cl\u00e9ment Scherding",
      "Georgios Rigas",
      "Denis Sipp",
      "Peter J. Schmid",
      "Taraneh Sayadi"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04269"
  },
  {
    "id": "arXiv:2210.05062",
    "title": "Relational Attention: Generalizing Transformers for Graph-Structured  Tasks",
    "abstract": "Relational Attention: Generalizing Transformers for Graph-Structured  Tasks",
    "descriptor": "",
    "authors": [
      "Cameron Diao",
      "Ricky Loynd"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.05062"
  },
  {
    "id": "arXiv:2210.05979",
    "title": "Adversarial Speaker-Consistency Learning Using Untranscribed Speech Data  for Zero-Shot Multi-Speaker Text-to-Speech",
    "abstract": "Comments: APSIPA 2022",
    "descriptor": "\nComments: APSIPA 2022\n",
    "authors": [
      "Byoung Jin Choi",
      "Myeonghun Jeong",
      "Minchan Kim",
      "Sung Hwan Mun",
      "Nam Soo Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.05979"
  },
  {
    "id": "arXiv:2210.09044",
    "title": "Hyper-differential sensitivity analysis with respect to model  discrepancy: Calibration and optimal solution updating",
    "abstract": "Hyper-differential sensitivity analysis with respect to model  discrepancy: Calibration and optimal solution updating",
    "descriptor": "",
    "authors": [
      "Joseph Hart",
      "Bart van Bloemen Waanders"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.09044"
  },
  {
    "id": "arXiv:2210.09276",
    "title": "Imagic: Text-Based Real Image Editing with Diffusion Models",
    "abstract": "Comments: Project page: this https URL",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Bahjat Kawar",
      "Shiran Zada",
      "Oran Lang",
      "Omer Tov",
      "Huiwen Chang",
      "Tali Dekel",
      "Inbar Mosseri",
      "Michal Irani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.09276"
  },
  {
    "id": "arXiv:2210.10084",
    "title": "On History-Deterministic One-Counter Nets",
    "abstract": "Comments: Fixed some typos, and minor inaccuracies in the proof of lemma 19. Redefined 'simulates' to be consistent with the literature",
    "descriptor": "\nComments: Fixed some typos, and minor inaccuracies in the proof of lemma 19. Redefined 'simulates' to be consistent with the literature\n",
    "authors": [
      "Aditya Prakash",
      "K. S. Thejaswini"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2210.10084"
  },
  {
    "id": "arXiv:2210.11833",
    "title": "Improving the Anomaly Detection in GPR Images by Fine-Tuning CNNs with  Synthetic Data",
    "abstract": "Improving the Anomaly Detection in GPR Images by Fine-Tuning CNNs with  Synthetic Data",
    "descriptor": "",
    "authors": [
      "Xiren Zhou",
      "Shikang Liu",
      "Ao Chen",
      "Yizhan Fan",
      "Huanhuan Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.11833"
  },
  {
    "id": "arXiv:2210.12241",
    "title": "FIND: An Unsupervised Implicit 3D Model of Articulated Human Feet",
    "abstract": "Comments: BMVC 2022",
    "descriptor": "\nComments: BMVC 2022\n",
    "authors": [
      "Oliver Boyne",
      "James Charles",
      "Roberto Cipolla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.12241"
  },
  {
    "id": "arXiv:2210.13952",
    "title": "KnowGL: Knowledge Generation and Linking from Text",
    "abstract": "Comments: AAAI-23 Demo Track",
    "descriptor": "\nComments: AAAI-23 Demo Track\n",
    "authors": [
      "Gaetano Rossiello",
      "Md Faisal Mahbub Chowdhury",
      "Nandana Mihindukulasooriya",
      "Owen Cornec",
      "Alfio Massimiliano Gliozzo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.13952"
  },
  {
    "id": "arXiv:2210.14335",
    "title": "A Depolarizing Noise-aware Transpiler for Optimal Amplitude  Amplification",
    "abstract": "A Depolarizing Noise-aware Transpiler for Optimal Amplitude  Amplification",
    "descriptor": "",
    "authors": [
      "Debashis Ganguly",
      "Wonsun Ahn"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2210.14335"
  },
  {
    "id": "arXiv:2210.14665",
    "title": "Desiderata for next generation of ML model serving",
    "abstract": "Comments: Accepted at NeurIPS 2022 Workshop on Challenges in Deploying and Monitoring Machine Learning Systems",
    "descriptor": "\nComments: Accepted at NeurIPS 2022 Workshop on Challenges in Deploying and Monitoring Machine Learning Systems\n",
    "authors": [
      "Sherif Akoush",
      "Andrei Paleyes",
      "Arnaud Van Looveren",
      "Clive Cox"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2210.14665"
  },
  {
    "id": "arXiv:2210.16107",
    "title": "SeaDroneSim: Simulation of Aerial Images for Detection of Objects Above  Water",
    "abstract": "SeaDroneSim: Simulation of Aerial Images for Detection of Objects Above  Water",
    "descriptor": "",
    "authors": [
      "Xiaomin Lin",
      "Cheng Liu",
      "Allen Pattillo",
      "Miao Yu",
      "Yiannis Aloimonous"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.16107"
  },
  {
    "id": "arXiv:2210.17239",
    "title": "RIS-Based Steerable Beamforming Antenna with Near-Field Eigenmode Feeder",
    "abstract": "RIS-Based Steerable Beamforming Antenna with Near-Field Eigenmode Feeder",
    "descriptor": "",
    "authors": [
      "Krishan K. Tiwari",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2210.17239"
  },
  {
    "id": "arXiv:2211.00539",
    "title": "Dungeons and Data: A Large-Scale NetHack Dataset",
    "abstract": "Comments: 9 pages, to be published in the Proceedings of the 36th Conference on Neural Information Processing Systems (NeurIPS 2022) Track on Datasets and Benchmarks",
    "descriptor": "\nComments: 9 pages, to be published in the Proceedings of the 36th Conference on Neural Information Processing Systems (NeurIPS 2022) Track on Datasets and Benchmarks\n",
    "authors": [
      "Eric Hambro",
      "Roberta Raileanu",
      "Danielle Rothermel",
      "Vegard Mella",
      "Tim Rockt\u00e4schel",
      "Heinrich K\u00fcttler",
      "Naila Murray"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.00539"
  },
  {
    "id": "arXiv:2211.00967",
    "title": "Multi-Speaker Multi-Style Speech Synthesis with Timbre and Style  Disentanglement",
    "abstract": "Multi-Speaker Multi-Style Speech Synthesis with Timbre and Style  Disentanglement",
    "descriptor": "",
    "authors": [
      "Wei Song",
      "Yanghao Yue",
      "Ya-jie Zhang",
      "Zhengchen Zhang",
      "Youzheng Wu",
      "Xiaodong He"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.00967"
  },
  {
    "id": "arXiv:2211.01357",
    "title": "Quasi-Newton Steps for Efficient Online Exp-Concave Optimization",
    "abstract": "Comments: 30 pages",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Zakaria Mhammedi",
      "Khashayar Gatmiry"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01357"
  },
  {
    "id": "arXiv:2211.03578",
    "title": "TLP: A Deep Learning-based Cost Model for Tensor Program Tuning",
    "abstract": "TLP: A Deep Learning-based Cost Model for Tensor Program Tuning",
    "descriptor": "",
    "authors": [
      "Yi Zhai",
      "Yu Zhang",
      "Shuo Liu",
      "Xiaomeng Chu",
      "Jie Peng",
      "Jianmin Ji",
      "Yanyong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2211.03578"
  },
  {
    "id": "arXiv:2211.04025",
    "title": "Complexity of directed Steiner path packing problem",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2208.08618, arXiv:2206.12092",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2208.08618, arXiv:2206.12092\n",
    "authors": [
      "Yuefang Sun"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.04025"
  },
  {
    "id": "arXiv:2211.05257",
    "title": "Single-Fingered Reconfigurable Robotic Gripper With a Folding Mechanism  for Narrow Working Spaces",
    "abstract": "Comments: This study was presented at IROS 2022",
    "descriptor": "\nComments: This study was presented at IROS 2022\n",
    "authors": [
      "Toshihiro Nishimura",
      "Tsubasa Muryoe",
      "Yoshitatsu Asama",
      "Hiroki Ikeuchi",
      "Ryo Toshima",
      "Tetsuyou Watanabe"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.05257"
  },
  {
    "id": "arXiv:2211.06146",
    "title": "An unobtrusive quality supervision approach for medical image annotation",
    "abstract": "Comments: 4 pages, 4 figures",
    "descriptor": "\nComments: 4 pages, 4 figures\n",
    "authors": [
      "Sonja Kunzmann",
      "Mathias \u00d6ttl",
      "Prathmesh Madhu",
      "Felix Denzinger",
      "Andreas Maier"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.06146"
  },
  {
    "id": "arXiv:2211.07045",
    "title": "Tracking control on homogeneous spaces: the Equivariant Regulator (EqR)",
    "abstract": "Tracking control on homogeneous spaces: the Equivariant Regulator (EqR)",
    "descriptor": "",
    "authors": [
      "Matthew Hampsey",
      "Pieter van Goor",
      "Robert Mahony"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.07045"
  },
  {
    "id": "arXiv:2211.07136",
    "title": "C3: Cross-instance guided Contrastive Clustering",
    "abstract": "Comments: 10 pages, 7 Figures, 2 Tables",
    "descriptor": "\nComments: 10 pages, 7 Figures, 2 Tables\n",
    "authors": [
      "Mohammadreza Sadeghi",
      "Hadi Hojjati",
      "Narges Armanfard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07136"
  },
  {
    "id": "arXiv:2211.08229",
    "title": "CorruptEncoder: Data Poisoning based Backdoor Attacks to Contrastive  Learning",
    "abstract": "CorruptEncoder: Data Poisoning based Backdoor Attacks to Contrastive  Learning",
    "descriptor": "",
    "authors": [
      "Jinghuai Zhang",
      "Hongbin Liu",
      "Jinyuan Jia",
      "Neil Zhenqiang Gong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08229"
  },
  {
    "id": "arXiv:2211.08405",
    "title": "Using multimodal learning and deep generative models for corporate  bankruptcy prediction",
    "abstract": "Using multimodal learning and deep generative models for corporate  bankruptcy prediction",
    "descriptor": "",
    "authors": [
      "Rogelio A. Mancisidor"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.08405"
  },
  {
    "id": "arXiv:2211.08864",
    "title": "PrivacyProber: Assessment and Detection of Soft-Biometric  Privacy-Enhancing Techniques",
    "abstract": "PrivacyProber: Assessment and Detection of Soft-Biometric  Privacy-Enhancing Techniques",
    "descriptor": "",
    "authors": [
      "Peter Rot",
      "Peter Peer",
      "Vitomir \u0160truc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08864"
  },
  {
    "id": "arXiv:2211.09613",
    "title": "Learning to Communicate with Intent: An Introduction",
    "abstract": "Comments: 7 pages, 4 figues, submitted to IEEE ICC 2023",
    "descriptor": "\nComments: 7 pages, 4 figues, submitted to IEEE ICC 2023\n",
    "authors": [
      "Miguel Angel Gutierrez-Estevez",
      "Yiqun Wu",
      "Chan Zhou"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.09613"
  },
  {
    "id": "arXiv:2211.09756",
    "title": "An Advantage Using Feature Selection with a Quantum Annealer",
    "abstract": "An Advantage Using Feature Selection with a Quantum Annealer",
    "descriptor": "",
    "authors": [
      "Andrew Vlasic",
      "Hunter Grant",
      "Salvatore Certo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09756"
  },
  {
    "id": "arXiv:2211.10024",
    "title": "Diagnostics for Deep Neural Networks with Automated Copy/Paste Attacks",
    "abstract": "Diagnostics for Deep Neural Networks with Automated Copy/Paste Attacks",
    "descriptor": "",
    "authors": [
      "Stephen Casper",
      "Kaivalya Hariharan",
      "Dylan Hadfield-Menell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.10024"
  },
  {
    "id": "arXiv:2211.10206",
    "title": "Multi-view Inverse Rendering for Large-scale Real-world Indoor Scenes",
    "abstract": "Comments: The project page is at: this https URL",
    "descriptor": "\nComments: The project page is at: this https URL\n",
    "authors": [
      "Zhen Li",
      "Lingli Wang",
      "Mofang Cheng",
      "Cihui Pan",
      "Jiaqi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10206"
  },
  {
    "id": "arXiv:2211.10298",
    "title": "Reinforcement Learning Methods for Wordle: A POMDP/Adaptive Control  Approach",
    "abstract": "Reinforcement Learning Methods for Wordle: A POMDP/Adaptive Control  Approach",
    "descriptor": "",
    "authors": [
      "Siddhant Bhambri",
      "Amrita Bhattacharjee",
      "Dimitri Bertsekas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10298"
  },
  {
    "id": "arXiv:2211.10381",
    "title": "Active Learning with Convolutional Gaussian Neural Processes for  Environmental Sensor Placement",
    "abstract": "Comments: Accepted to the NeurIPS 2022 Workshop on Gaussian Processes, Spatiotemporal Modeling, and Decision-making Systems",
    "descriptor": "\nComments: Accepted to the NeurIPS 2022 Workshop on Gaussian Processes, Spatiotemporal Modeling, and Decision-making Systems\n",
    "authors": [
      "Tom R. Andersson",
      "Wessel P. Bruinsma",
      "Stratis Markou",
      "James Requeima",
      "Alejandro Coca-Castro",
      "Anna Vaughan",
      "Anna-Louise Ellis",
      "Matthew Lazzara",
      "Daniel C. Jones",
      "J. Scott Hosking",
      "Richard E. Turner"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10381"
  },
  {
    "id": "arXiv:2211.10546",
    "title": "Evaluating COVID-19 Sequence Data Using Nearest-Neighbors Based Network  Model",
    "abstract": "Comments: Accepted at IEEE BigData 2022",
    "descriptor": "\nComments: Accepted at IEEE BigData 2022\n",
    "authors": [
      "Sarwan Ali"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2211.10546"
  },
  {
    "id": "arXiv:2211.10670",
    "title": "Towards Adversarial Robustness of Deep Vision Algorithms",
    "abstract": "Comments: PhD thesis",
    "descriptor": "\nComments: PhD thesis\n",
    "authors": [
      "Hanshu Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10670"
  },
  {
    "id": "arXiv:2211.10737",
    "title": "Accuracy Boosters: Epoch-Driven Mixed-Mantissa Block Floating-Point for  DNN Training",
    "abstract": "Accuracy Boosters: Epoch-Driven Mixed-Mantissa Block Floating-Point for  DNN Training",
    "descriptor": "",
    "authors": [
      "Simla Burcu Harma",
      "Canberk S\u00f6nmez",
      "Babak Falsafi",
      "Martin Jaggi",
      "Yunho Oh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10737"
  },
  {
    "id": "arXiv:2211.10916",
    "title": "ECM-OPCC: Efficient Context Model for Octree-based Point Cloud  Compression",
    "abstract": "ECM-OPCC: Efficient Context Model for Octree-based Point Cloud  Compression",
    "descriptor": "",
    "authors": [
      "Yiqi Jin",
      "Ziyu Zhu",
      "Tongda Xu",
      "Yuhuan Lin",
      "Yan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.10916"
  },
  {
    "id": "arXiv:2211.10976",
    "title": "Federated deep transfer learning for EEG decoding using multiple BCI  tasks",
    "abstract": "Comments: 4 pages, 3 figures",
    "descriptor": "\nComments: 4 pages, 3 figures\n",
    "authors": [
      "Xiaoxi Wei",
      "A. Aldo Faisal"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10976"
  },
  {
    "id": "arXiv:2211.11033",
    "title": "On the Complexity of Bayesian Generalization",
    "abstract": "On the Complexity of Bayesian Generalization",
    "descriptor": "",
    "authors": [
      "Yu-Zhe Shi",
      "Manjie Xu",
      "John E. Hopcroft",
      "Kun He",
      "Joshua B. Tenenbaum",
      "Song-Chun Zhu",
      "Ying Nian Wu",
      "Wenjuan Han",
      "Yixin Zhu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11033"
  },
  {
    "id": "arXiv:2211.11049",
    "title": "Explaining (Sarcastic) Utterances to Enhance Affect Understanding in  Multimodal Dialogues",
    "abstract": "Comments: Accepted at AAAI 2023. 11 Pages; 14 Tables; 3 Figures",
    "descriptor": "\nComments: Accepted at AAAI 2023. 11 Pages; 14 Tables; 3 Figures\n",
    "authors": [
      "Shivani Kumar",
      "Ishani Mondal",
      "Md Shad Akhtar",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11049"
  },
  {
    "id": "arXiv:2211.11070",
    "title": "Who Tracks Who? A Surveillance Capitalist Examination of Commercial  Bluetooth Tracking Networks",
    "abstract": "Comments: 14 pages",
    "descriptor": "\nComments: 14 pages\n",
    "authors": [
      "Hongrui Jin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.11070"
  },
  {
    "id": "arXiv:2211.11173",
    "title": "A min-max theorem for the minimum fleet-size problem",
    "abstract": "A min-max theorem for the minimum fleet-size problem",
    "descriptor": "",
    "authors": [
      "Tinghan Ye",
      "David Shmoys"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.11173"
  },
  {
    "id": "arXiv:2211.11174",
    "title": "On the Robustness, Generalization, and Forgetting of Shape-Texture  Debiased Continual Learning",
    "abstract": "On the Robustness, Generalization, and Forgetting of Shape-Texture  Debiased Continual Learning",
    "descriptor": "",
    "authors": [
      "Zenglin Shi",
      "Ying Sun",
      "Joo Hwee Lim",
      "Mengmi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11174"
  },
  {
    "id": "arXiv:2211.11175",
    "title": "CoPEM: Cooperative Perception Error Models for Autonomous Driving",
    "abstract": "Comments: Accepted at 2022 IEEE International Conference on Intelligent Transportation Systems - ITSC2022 6 pages, 6 figures",
    "descriptor": "\nComments: Accepted at 2022 IEEE International Conference on Intelligent Transportation Systems - ITSC2022 6 pages, 6 figures\n",
    "authors": [
      "Andrea Piazzoni",
      "Jim Cherian",
      "Roshan Vijay",
      "Lap-Pui Chau",
      "Justin Dauwels"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11175"
  },
  {
    "id": "arXiv:2211.11187",
    "title": "L3Cube-MahaSBERT and HindSBERT: Sentence BERT Models and Benchmarking  BERT Sentence Representations for Hindi and Marathi",
    "abstract": "Comments: Accepted at Computing Conference 2023",
    "descriptor": "\nComments: Accepted at Computing Conference 2023\n",
    "authors": [
      "Ananya Joshi",
      "Aditi Kajale",
      "Janhavi Gadre",
      "Samruddhi Deode",
      "Raviraj Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11187"
  },
  {
    "id": "arXiv:2211.11215",
    "title": "SegNeRF: 3D Part Segmentation with Neural Radiance Fields",
    "abstract": "Comments: Fixed abstract typo",
    "descriptor": "\nComments: Fixed abstract typo\n",
    "authors": [
      "Jesus Zarzar",
      "Sara Rojas",
      "Silvio Giancola",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11215"
  },
  {
    "id": "arXiv:2211.11220",
    "title": "STGlow: A Flow-based Generative Framework with Dual Graphormer for  Pedestrian Trajectory Prediction",
    "abstract": "Comments: 12 pages, 8 figures",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Rongqin Liang",
      "Yuanman Li",
      "Jiantao Zhou",
      "Xia Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11220"
  },
  {
    "id": "arXiv:2211.11308",
    "title": "Novel transfer learning schemes based on Siamese networks and synthetic  data",
    "abstract": "Novel transfer learning schemes based on Siamese networks and synthetic  data",
    "descriptor": "",
    "authors": [
      "Dominik Stallmann",
      "Philip Kenneweg",
      "Barbara Hammer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.11308"
  },
  {
    "id": "arXiv:2211.11379",
    "title": "Modelling spatiotemporal turbulent dynamics with the convolutional  autoencoder echo state network",
    "abstract": "Modelling spatiotemporal turbulent dynamics with the convolutional  autoencoder echo state network",
    "descriptor": "",
    "authors": [
      "Alberto Racca",
      "Nguyen Anh Khoa Doan",
      "Luca Magri"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2211.11379"
  },
  {
    "id": "arXiv:2211.11396",
    "title": "A Curriculum-Training-Based Strategy for Distributing Collocation Points  during Physics-Informed Neural Network Training",
    "abstract": "A Curriculum-Training-Based Strategy for Distributing Collocation Points  during Physics-Informed Neural Network Training",
    "descriptor": "",
    "authors": [
      "Marcus M\u00fcnzer",
      "Chris Bard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Plasma Physics (physics.plasm-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.11396"
  },
  {
    "id": "arXiv:2211.11410",
    "title": "Treedepth vs circumference",
    "abstract": "Treedepth vs circumference",
    "descriptor": "",
    "authors": [
      "Marcin Bria\u0144ski",
      "Gwena\u00ebl Joret",
      "Konrad Majewski",
      "Piotr Micek",
      "Micha\u0142 T. Seweryn",
      "Roohani Sharma"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.11410"
  },
  {
    "id": "arXiv:2211.11419",
    "title": "Sequentially Sampled Chunk Conformer for Streaming End-to-End ASR",
    "abstract": "Comments: This paper has been submitted to ICASSP 2023",
    "descriptor": "\nComments: This paper has been submitted to ICASSP 2023\n",
    "authors": [
      "Fangyuan Wang",
      "Xiyuan Wang",
      "Bo Xu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.11419"
  },
  {
    "id": "arXiv:2211.11446",
    "title": "SMAUG: Sparse Masked Autoencoder for Efficient Video-Language  Pre-training",
    "abstract": "SMAUG: Sparse Masked Autoencoder for Efficient Video-Language  Pre-training",
    "descriptor": "",
    "authors": [
      "Yuanze Lin",
      "Chen Wei",
      "Huiyu Wang",
      "Alan Yuille",
      "Cihang Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11446"
  },
  {
    "id": "arXiv:2211.11495",
    "title": "Global misinformation spillovers in the online vaccination debate before  and during COVID-19",
    "abstract": "Global misinformation spillovers in the online vaccination debate before  and during COVID-19",
    "descriptor": "",
    "authors": [
      "Jacopo Lenti",
      "Kyriaki Kalimeri",
      "Andr\u00e9 Panisson",
      "Daniela Paolotti",
      "Michele Tizzani",
      "Yelena Mejova",
      "Michele Starnini"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.11495"
  },
  {
    "id": "arXiv:2211.11500",
    "title": "Compositional Scene Modeling with Global Object-Centric Representations",
    "abstract": "Compositional Scene Modeling with Global Object-Centric Representations",
    "descriptor": "",
    "authors": [
      "Tonglin Chen",
      "Bin Li",
      "Zhimeng Shen",
      "Xiangyang Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11500"
  },
  {
    "id": "arXiv:2211.11533",
    "title": "Linear Modeling of the Glass Transition Temperature of the system  SiO2-Na2O-CaO",
    "abstract": "Comments: 5 pages, 3 figures, 2 tables",
    "descriptor": "\nComments: 5 pages, 3 figures, 2 tables\n",
    "authors": [
      "Patrick dos Anjos",
      "Lucas A. Quaresma",
      "Marcelo L. P. Machado"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Programming Languages (cs.PL)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.11533"
  },
  {
    "id": "arXiv:2211.11534",
    "title": "How Fraudster Detection Contributes to Robust Recommendation",
    "abstract": "How Fraudster Detection Contributes to Robust Recommendation",
    "descriptor": "",
    "authors": [
      "Yuni Lai",
      "Kai Zhou"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11534"
  },
  {
    "id": "arXiv:2211.11557",
    "title": "Decomposing 3D Neuroimaging into 2+1D Processing for Schizophrenia  Recognition",
    "abstract": "Decomposing 3D Neuroimaging into 2+1D Processing for Schizophrenia  Recognition",
    "descriptor": "",
    "authors": [
      "Mengjiao Hu",
      "Xudong Jiang",
      "Kang Sim",
      "Juan Helen Zhou",
      "Cuntai Guan"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11557"
  },
  {
    "id": "arXiv:2211.11646",
    "title": "NeRF-RPN: A general framework for object detection in NeRFs",
    "abstract": "NeRF-RPN: A general framework for object detection in NeRFs",
    "descriptor": "",
    "authors": [
      "Benran Hu",
      "Junkai Huang",
      "Yichen Liu",
      "Yu-Wing Tai",
      "Chi-Keung Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11646"
  },
  {
    "id": "arXiv:2211.11658",
    "title": "Binary $t_1$-Deletion-$t_2$-Insertion-Burst Correcting Codes and Codes  Correcting a Burst of Deletions",
    "abstract": "Comments: Results are covered by others' work",
    "descriptor": "\nComments: Results are covered by others' work\n",
    "authors": [
      "Zuo Ye",
      "Ohad Elishco"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.11658"
  },
  {
    "id": "arXiv:2211.11673",
    "title": "Asymptotically Normal Estimation of Local Latent Network Curvature",
    "abstract": "Comments: 77 pages",
    "descriptor": "\nComments: 77 pages\n",
    "authors": [
      "Steven Wilkins-Reeves",
      "Tyler McCormick"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.11673"
  },
  {
    "id": "arXiv:2211.11711",
    "title": "CLAWSAT: Towards Both Robust and Accurate Code Models",
    "abstract": "CLAWSAT: Towards Both Robust and Accurate Code Models",
    "descriptor": "",
    "authors": [
      "Jinghan Jia",
      "Shashank Srikant",
      "Tamara Mitrovska",
      "Chuang Gan",
      "Shiyu Chang",
      "Sijia Liu",
      "Una-May O'Reilly"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.11711"
  },
  {
    "id": "arXiv:2211.11720",
    "title": "Multitask Vision-Language Prompt Tuning",
    "abstract": "Comments: Preprint",
    "descriptor": "\nComments: Preprint\n",
    "authors": [
      "Sheng Shen",
      "Shijia Yang",
      "Tianjun Zhang",
      "Bohan Zhai",
      "Joseph E. Gonzalez",
      "Kurt Keutzer",
      "Trevor Darrell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.11720"
  },
  {
    "id": "arXiv:2211.11721",
    "title": "The Berlekamp-Massey Algorithm revisited",
    "abstract": "Comments: in English and French versions",
    "descriptor": "\nComments: in English and French versions\n",
    "authors": [
      "Nadia Ben Atti",
      "Gema M. Diaz--Toca",
      "Henri Lombardi"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2211.11721"
  },
  {
    "id": "arXiv:2211.11736",
    "title": "Robotic Skill Acquisition via Instruction Augmentation with  Vision-Language Models",
    "abstract": "Robotic Skill Acquisition via Instruction Augmentation with  Vision-Language Models",
    "descriptor": "",
    "authors": [
      "Ted Xiao",
      "Harris Chan",
      "Pierre Sermanet",
      "Ayzaan Wahid",
      "Anthony Brohan",
      "Karol Hausman",
      "Sergey Levine",
      "Jonathan Tompson"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11736"
  }
]
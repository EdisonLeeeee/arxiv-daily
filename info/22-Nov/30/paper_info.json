[
  {
    "id": "arXiv:2211.15664",
    "title": "Physics-guided deep learning for data scarcity",
    "abstract": "Data are the core of deep learning (DL), and the quality of data\nsignificantly affects the performance of DL models. However, high-quality and\nwell-annotated databases are hard or even impossible to acquire for use in many\napplications, such as structural risk estimation and medical diagnosis, which\nis an essential barrier that blocks the applications of DL in real life.\nPhysics-guided deep learning (PGDL) is a novel type of DL that can integrate\nphysics laws to train neural networks. It can be used for any systems that are\ncontrolled or governed by physics laws, such as mechanics, finance and medical\napplications. It has been shown that, with the additional information provided\nby physics laws, PGDL achieves great accuracy and generalisation when facing\ndata scarcity. In this review, the details of PGDL are elucidated, and a\nstructured overview of PGDL with respect to data scarcity in various\napplications is presented, including physics, engineering and medical\napplications. Moreover, the limitations and opportunities for current PGDL in\nterms of data scarcity are identified, and the future outlook for PGDL is\ndiscussed in depth.",
    "descriptor": "\nComments: 26 Pages, 4 figures, 2 tables, 112 references. This work is going to submit to Nature Machine Intelligence\n",
    "authors": [
      "Jinshuai Bai",
      "Laith Alzubaidi",
      "Qingxia Wang",
      "Ellen Kuhl",
      "Mohammed Bennamoun",
      "Yuantong Gu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.15664"
  },
  {
    "id": "arXiv:2211.15666",
    "title": "Learning Visual Planning Models from Partially Observed Images",
    "abstract": "There has been increasing attention on planning model learning in classical\nplanning. Most existing approaches, however, focus on learning planning models\nfrom structured data in symbolic representations. It is often difficult to\nobtain such structured data in real-world scenarios. Although a number of\napproaches have been developed for learning planning models from fully observed\nunstructured data (e.g., images), in many scenarios raw observations are often\nincomplete. In this paper, we provide a novel framework, \\aType{Recplan}, for\nlearning a transition model from partially observed raw image traces. More\nspecifically, by considering the preceding and subsequent images in a trace, we\nlearn the latent state representations of raw observations and then build a\ntransition model based on such representations. Additionally, we propose a\nneural-network-based approach to learn a heuristic model that estimates the\ndistance toward a given goal observation. Based on the learned transition model\nand heuristic model, we implement a classical planner for images. We exhibit\nempirically that our approach is more effective than a state-of-the-art\napproach of learning visual planning models in the environment with incomplete\nobservations.",
    "descriptor": "\nComments: 25 pages, 5 figures\n",
    "authors": [
      "Kebing Jin",
      "Zhanhao Xiao",
      "Hankui Hankz Zhuo",
      "Hai Wan",
      "Jiaran Cai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15666"
  },
  {
    "id": "arXiv:2211.15670",
    "title": "FETI-DP preconditioners for 2D Biot model with discontinuous Galerkin  discretization",
    "abstract": "Dual-primal FETI (FETI-DP) preconditioners are developed for a 2D Biot model.\nThe model is formulated with mixed-finite elements as a saddle-point problem.\nThe displacement $\\mathbf{u}$ and the Darcy flux flow $\\mathbf{z}$ are\nrepresented with $P_1$ piecewise continuous elements and pore-pressure $p$ with\n$P_0$ piecewise constant elements, {\\it i.e.}, overall three fields with a\nstabilizing term. We have tested the functionality of FETI-DP with and without\nDirichlet preconditioners. Numerical experiments show a signature of\nscalability of the resulting parallel algorithm in the compressible elasticity\nwith permeable Darcy flow as well as almost incompressible elasticity.",
    "descriptor": "\nComments: Submitted to the 27th International Conference on Domain Decomposition Methods (DD27), 8 pages. arXiv admin note: substantial text overlap with arXiv:2211.15025\n",
    "authors": [
      "Pilhwa Lee"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.15670"
  },
  {
    "id": "arXiv:2211.15671",
    "title": "Deep Semi-supervised Learning with Double-Contrast of Features and  Semantics",
    "abstract": "In recent years, the field of intelligent transportation systems (ITS) has\nachieved remarkable success, which is mainly due to the large amount of\navailable annotation data. However, obtaining these annotated data has to\nafford expensive costs in reality. Therefore, a more realistic strategy is to\nleverage semi-supervised learning (SSL) with a small amount of labeled data and\na large amount of unlabeled data. Typically, semantic consistency\nregularization and the two-stage learning methods of decoupling feature\nextraction and classification have been proven effective. Nevertheless,\nrepresentation learning only limited to semantic consistency regularization may\nnot guarantee the separation or discriminability of representations of samples\nwith different semantics; due to the inherent limitations of the two-stage\nlearning methods, the extracted features may not match the specific downstream\ntasks. In order to deal with the above drawbacks, this paper proposes an\nend-to-end deep semi-supervised learning double contrast of semantic and\nfeature, which extracts effective tasks specific discriminative features by\ncontrasting the semantics/features of positive and negative augmented samples\npairs. Moreover, we leverage information theory to explain the rationality of\ndouble contrast of semantics and features and slack mutual information to\ncontrastive loss in a simpler way. Finally, the effectiveness of our method is\nverified in benchmark datasets.",
    "descriptor": "",
    "authors": [
      "Quan Feng",
      "Jiayu Yao",
      "Zhison Pan",
      "Guojun Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15671"
  },
  {
    "id": "arXiv:2211.15672",
    "title": "ExpNet: A unified network for Expert-Level Classification",
    "abstract": "Different from the general visual classification, some classification tasks\nare more challenging as they need the professional categories of the images. In\nthe paper, we call them expert-level classification. Previous fine-grained\nvision classification (FGVC) has made many efforts on some of its specific\nsub-tasks. However, they are difficult to expand to the general cases which\nrely on the comprehensive analysis of part-global correlation and the\nhierarchical features interaction. In this paper, we propose Expert Network\n(ExpNet) to address the unique challenges of expert-level classification\nthrough a unified network. In ExpNet, we hierarchically decouple the part and\ncontext features and individually process them using a novel attentive\nmechanism, called Gaze-Shift. In each stage, Gaze-Shift produces a focal-part\nfeature for the subsequent abstraction and memorizes a context-related\nembedding. Then we fuse the final focal embedding with all memorized\ncontext-related embedding to make the prediction. Such an architecture realizes\nthe dual-track processing of partial and global information and hierarchical\nfeature interactions. We conduct the experiments over three representative\nexpert-level classification tasks: FGVC, disease classification, and artwork\nattributes classification. In these experiments, superior performance of our\nExpNet is observed comparing to the state-of-the-arts in a wide range of\nfields, indicating the effectiveness and generalization of our ExpNet. The code\nwill be made publicly available.",
    "descriptor": "",
    "authors": [
      "Junde Wu",
      "Huihui Fang",
      "Yehui Yang",
      "Yu Zhang",
      "Haoyi Xiong",
      "Huazhu Fu",
      "Yanwu Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15672"
  },
  {
    "id": "arXiv:2211.15673",
    "title": "PyTorch Adapt",
    "abstract": "PyTorch Adapt is a library for domain adaptation, a type of machine learning\nalgorithm that re-purposes existing models to work in new domains. It is a\nfully-featured toolkit, allowing users to create a complete train/test pipeline\nin a few lines of code. It is also modular, so users can import just the parts\nthey need, and not worry about being locked into a framework. One defining\nfeature of this library is its customizability. In particular, complex training\nalgorithms can be easily modified and combined, thanks to a system of\ncomposable, lazily-evaluated hooks. In this technical report, we explain in\ndetail these features and the overall design of the library. Code is available\nat https://www.github.com/KevinMusgrave/pytorch-adapt",
    "descriptor": "",
    "authors": [
      "Kevin Musgrave",
      "Serge Belongie",
      "Ser-Nam Lim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15673"
  },
  {
    "id": "arXiv:2211.15692",
    "title": "H3WB: Human3.6M 3D WholeBody Dataset and Benchmark",
    "abstract": "3D human whole-body pose estimation aims to localize precise 3D keypoints on\nthe entire human body, including the face, hands, body, and feet. Due to the\nlack of a large-scale fully annotated 3D whole-body dataset, a common approach\nhas been to train several deep networks separately on datasets dedicated to\nspecific body parts, and combine them during inference. This approach suffers\nfrom complex training and inference pipelines because of the different biases\nin each dataset used. It also lacks a common benchmark which makes it difficult\nto compare different methods. To address these issues, we introduce Human3.6M\n3D WholeBody (H3WB) which provides whole-body annotations for the Human3.6M\ndataset using the COCO Wholebody layout. H3WB is a large scale dataset with 133\nwhole-body keypoint annotations on 100K images, made possible by our new\nmulti-view pipeline.\nAlong with H3WB, we propose 3 tasks: i) 3D whole-body pose lifting from 2D\ncomplete whole-body pose, ii) 3D whole-body pose lifting from 2D incomplete\nwhole-body pose, iii) 3D whole-body pose estimation from a single RGB image. We\nalso report several baselines from popular methods for these tasks. The dataset\nis publicly available at \\url{https://github.com/wholebody3d/wholebody3d}.",
    "descriptor": "",
    "authors": [
      "Yue Zhu",
      "Nermin Samet",
      "David Picard"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15692"
  },
  {
    "id": "arXiv:2211.15716",
    "title": "Distributed Parallelization of xPU Stencil Computations in Julia",
    "abstract": "We present a straightforward approach for distributed parallelization of\nstencil-based xPU applications on a regular staggered grid, which is\ninstantiated in the package ImplicitGlobalGrid.jl. The approach allows to\nleverage remote direct memory access and enables close to ideal weak scaling of\nreal-world applications on thousands of GPUs. The communication costs can be\neasily hidden behind computation.",
    "descriptor": "\nComments: submitted to JuliaCon Proceedings 2022\n",
    "authors": [
      "Samuel Omlin",
      "Ludovic R\u00e4ss",
      "Ivan Utkin"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Computational Physics (physics.comp-ph)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.15716"
  },
  {
    "id": "arXiv:2211.15718",
    "title": "CoNAL: Anticipating Outliers with Large Language Models",
    "abstract": "In many task settings, text classification models are likely to encounter\nexamples from novel classes on which they cannot predict correctly. Selective\nprediction, in which models abstain on low-confidence examples, provides a\npossible solution, but existing models are often overly confident on OOD\nexamples. To remedy this overconfidence, we introduce Contrastive\nNovelty-Augmented Learning (CoNAL), a two-step method that generates OOD\nexamples representative of novel classes, then trains to decrease confidence on\nthem. First, we generate OOD examples by prompting a large language model\ntwice: we prompt it to enumerate relevant novel labels, then generate examples\nfrom each novel class matching the task format. Second, we train our classifier\nwith a novel contrastive objective that encourages lower confidence on\ngenerated OOD examples than training examples. When trained with CoNAL,\nclassifiers improve in their ability to detect and abstain on OOD examples over\nprior methods by an average of 2.3% AUAC and 5.5% AUROC across 4 NLP datasets,\nwith no cost to in-distribution accuracy.",
    "descriptor": "",
    "authors": [
      "Albert Xu",
      "Xiang Ren",
      "Robin Jia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15718"
  },
  {
    "id": "arXiv:2211.15724",
    "title": "Malign Overfitting: Interpolation Can Provably Preclude Invariance",
    "abstract": "Learned classifiers should often possess certain invariance properties meant\nto encourage fairness, robustness, or out-of-distribution generalization.\nHowever, multiple recent works empirically demonstrate that common\ninvariance-inducing regularizers are ineffective in the over-parameterized\nregime, in which classifiers perfectly fit (i.e. interpolate) the training\ndata. This suggests that the phenomenon of ``benign overfitting,\" in which\nmodels generalize well despite interpolating, might not favorably extend to\nsettings in which robustness or fairness are desirable.\nIn this work we provide a theoretical justification for these observations.\nWe prove that -- even in the simplest of settings -- any interpolating learning\nrule (with arbitrarily small margin) will not satisfy these invariance\nproperties. We then propose and analyze an algorithm that -- in the same\nsetting -- successfully learns a non-interpolating classifier that is provably\ninvariant. We validate our theoretical observations on simulated data and the\nWaterbirds dataset.",
    "descriptor": "",
    "authors": [
      "Yoav Wald",
      "Gal Yona",
      "Uri Shalit",
      "Yair Carmon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.15724"
  },
  {
    "id": "arXiv:2211.15728",
    "title": "Direct Heterogeneous Causal Learning for Resource Allocation Problems in  Marketing",
    "abstract": "Marketing is an important mechanism to increase user engagement and improve\nplatform revenue, and heterogeneous causal learning can help develop more\neffective strategies. Most decision-making problems in marketing can be\nformulated as resource allocation problems and have been studied for decades.\nExisting works usually divide the solution procedure into two fully decoupled\nstages, i.e., machine learning (ML) and operation research (OR) -- the first\nstage predicts the model parameters and they are fed to the optimization in the\nsecond stage. However, the error of the predicted parameters in ML cannot be\nrespected and a series of complex mathematical operations in OR lead to the\nincreased accumulative errors. Essentially, the improved precision on the\nprediction parameters may not have a positive correlation on the final solution\ndue to the side-effect from the decoupled design.\nIn this paper, we propose a novel approach for solving resource allocation\nproblems to mitigate the side-effects. Our key intuition is that we introduce\nthe decision factor to establish a bridge between ML and OR such that the\nsolution can be directly obtained in OR by only performing the sorting or\ncomparison operations on the decision factor. Furthermore, we design a\ncustomized loss function that can conduct direct heterogeneous causal learning\non the decision factor, an unbiased estimation of which can be guaranteed when\nthe loss converges. As a case study, we apply our approach to two crucial\nproblems in marketing: the binary treatment assignment problem and the budget\nallocation problem with multiple treatments. Both large-scale simulations and\nonline A/B Tests demonstrate that our approach achieves significant improvement\ncompared with state-of-the-art.",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Hao Zhou",
      "Shaoming Li",
      "Guibin Jiang",
      "Jiaqi Zheng",
      "Dong Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15728"
  },
  {
    "id": "arXiv:2211.15731",
    "title": "Controlled Language Generation for Language Learning Items",
    "abstract": "This work aims to employ natural language generation (NLG) to rapidly\ngenerate items for English language learning applications: this requires both\nlanguage models capable of generating fluent, high-quality English, and to\ncontrol the output of the generation to match the requirements of the relevant\nitems. We experiment with deep pretrained models for this task, developing\nnovel methods for controlling items for factors relevant in language learning:\ndiverse sentences for different proficiency levels and argument structure to\ntest grammar. Human evaluation demonstrates high grammatically scores for all\nmodels (3.4 and above out of 4), and higher length (24%) and complexity (9%)\nover the baseline for the advanced proficiency model. Our results show that we\ncan achieve strong performance while adding additional control to ensure\ndiverse, tailored content for individual users.",
    "descriptor": "\nComments: 9 pages, 3 figures. Accepted to Industry Track at EMNLP 2022\n",
    "authors": [
      "Kevin Stowe",
      "Debanjan Ghosh",
      "Mengxuan Zhao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15731"
  },
  {
    "id": "arXiv:2211.15732",
    "title": "Cache Me If You Can: Accuracy-Aware Inference Engine for Differentially  Private Data Exploration",
    "abstract": "Differential privacy (DP) allows data analysts to query databases that\ncontain users' sensitive information while providing a quantifiable privacy\nguarantee to users. Recent interactive DP systems such as APEx provide accuracy\nguarantees over the query responses, but fail to support a large number of\nqueries with a limited total privacy budget, as they process incoming queries\nindependently from past queries. We present an interactive, accuracy-aware DP\nquery engine, CacheDP, which utilizes a differentially private cache of past\nresponses, to answer the current workload at a lower privacy budget, while\nmeeting strict accuracy guarantees. We integrate complex DP mechanisms with our\nstructured cache, through novel cache-aware DP cost optimization. Our thorough\nevaluation illustrates that CacheDP can accurately answer various workload\nsequences, while lowering the privacy loss as compared to related work.",
    "descriptor": "\nComments: To appear in VLDB'23\n",
    "authors": [
      "Miti Mazmudar",
      "Thomas Humphries",
      "Jiaxiang Liu",
      "Matthew Rafuse",
      "Xi He"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.15732"
  },
  {
    "id": "arXiv:2211.15733",
    "title": "An Empirical Study of Library Usage and Dependency in Deep Learning  Frameworks",
    "abstract": "Recent advances in deep learning (dl) have led to the release of several dl\nsoftware libraries such as pytorch, Caffe, and TensorFlow, in order to assist\nmachine learning (ml) practitioners in developing and deploying\nstate-of-the-art deep neural networks (DNN), but they are not able to properly\ncope with limitations in the dl libraries such as testing or data processing.\nIn this paper, we present a qualitative and quantitative analysis of the most\nfrequent dl libraries combination, the distribution of dl library dependencies\nacross the ml workflow, and formulate a set of recommendations to (i) hardware\nbuilders for more optimized accelerators and (ii) library builder for more\nrefined future releases. Our study is based on 1,484 open-source dl projects\nwith 46,110 contributors selected based on their reputation. First, we found an\nincreasing trend in the usage of deep learning libraries. Second, we highlight\nseveral usage patterns of deep learning libraries. In addition, we identify\ndependencies between dl libraries and the most frequent combination where we\ndiscover that pytorch and Scikit-learn and, Keras and TensorFlow are the most\nfrequent combination in 18% and 14% of the projects. The developer uses two or\nthree dl libraries in the same projects and tends to use different multiple dl\nlibraries in both the same function and the same files. The developer shows\npatterns in using various deep-learning libraries and prefers simple functions\nwith fewer arguments and straightforward goals. Finally, we present the\nimplications of our findings for researchers, library maintainers, and hardware\nvendors.",
    "descriptor": "",
    "authors": [
      "Mohamed Raed El aoun",
      "Lionel Nganyewou Tidjon",
      "Ben Rombaut",
      "Foutse Khomh",
      "Ahmed E. Hassan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15733"
  },
  {
    "id": "arXiv:2211.15734",
    "title": "Predicting Football Match Outcomes with eXplainable Machine Learning and  the Kelly Index",
    "abstract": "In this work, a machine learning approach is developed for predicting the\noutcomes of football matches. The novelty of this research lies in the\nutilisation of the Kelly Index to first classify matches into categories where\neach one denotes the different levels of predictive difficulty. Classification\nmodels using a wide suite of algorithms were developed for each category of\nmatches in order to determine the efficacy of the approach. In conjunction to\nthis, a set of previously unexplored features were engineering including\nElo-based variables.\nThe dataset originated from the Premier League match data covering the\n2019-2021 seasons. The findings indicate that the process of decomposing the\npredictive problem into sub-tasks was effective and produced competitive\nresults with prior works, while the ensemble-based methods were the most\neffective.\nThe paper also devised an investment strategy in order to evaluate its\neffectiveness by benchmarking against bookmaker odds. An approach was developed\nthat minimises risk by combining the Kelly Index with the predefined confidence\nthresholds of the predictive models. The experiments found that the proposed\nstrategy can return a profit when following a conservative approach that\nfocuses primarily on easy-to-predict matches where the predictive models\ndisplay a high confidence level.",
    "descriptor": "",
    "authors": [
      "Yiming Ren",
      "Teo Susnjak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15734"
  },
  {
    "id": "arXiv:2211.15735",
    "title": "Implementing Software Defined Load Balancer and Firewall",
    "abstract": "Software-defined networking (SDN) is an architecture that aims to make\nnetworks fast and flexible. SDN's goal is to improve network control by\nenabling service providers as well as enterprises to respond quickly to\nchanging business needs. In SDN, the administrator can shape traffic from a\ncentralized control console without having to modify any of the individual\nswitches belonging to the network. The SDN controller which is centralized\ndirects the switches to deliver network services wherever they are needed,\nirrespective of the specific connections between a server and devices. This\nmethodology is a shift from traditional network architecture, in which\nindividual network devices make traffic decisions based on their configured\nrouting tables. In this paper, I built and tested an SDN load balancer and\nfirewall module using the Floodlight controller.",
    "descriptor": "",
    "authors": [
      "Shreya Rajkumar"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.15735"
  },
  {
    "id": "arXiv:2211.15736",
    "title": "Post-training Quantization on Diffusion Models",
    "abstract": "Denoising diffusion (score-based) generative models have recently achieved\nsignificant accomplishments in generating realistic and diverse data. These\napproaches define a forward diffusion process for transforming data into noise\nand a backward denoising process for sampling data from noise. Unfortunately,\nthe generation process of current denoising diffusion models is notoriously\nslow due to the lengthy iterative noise estimations, which rely on cumbersome\nneural networks. It prevents the diffusion models from being widely deployed,\nespecially on edge devices. Previous works accelerate the generation process of\ndiffusion model (DM) via finding shorter yet effective sampling trajectories.\nHowever, they overlook the cost of noise estimation with a heavy network in\nevery iteration. In this work, we accelerate generation from the perspective of\ncompressing the noise estimation network. Due to the difficulty of retraining\nDMs, we exclude mainstream training-aware compression paradigms and introduce\npost-training quantization (PTQ) into DM acceleration. However, the output\ndistributions of noise estimation networks change with time-step, making\nprevious PTQ methods fail in DMs since they are designed for single-time step\nscenarios. To devise a DM-specific PTQ method, we explore PTQ on DM in three\naspects: quantized operations, calibration dataset, and calibration metric. We\nsummarize and use several observations derived from all-inclusive\ninvestigations to formulate our method, which especially targets the unique\nmulti-time-step structure of DMs. Experimentally, our method can directly\nquantize full-precision DMs into 8-bit models while maintaining or even\nimproving their performance in a training-free manner. Importantly, our method\ncan serve as a plug-and-play module on other fast-sampling methods, e.g., DDIM.",
    "descriptor": "",
    "authors": [
      "Yuzhang Shang",
      "Zhihang Yuan",
      "Bin Xie",
      "Bingzhe Wu",
      "Yan Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15736"
  },
  {
    "id": "arXiv:2211.15739",
    "title": "CWD: A Machine Learning based Approach to Detect Unknown Cloud Workloads",
    "abstract": "Workloads in modern cloud data centers are becoming increasingly complex. The\nnumber of workloads running in cloud data centers has been growing\nexponentially for the last few years, and cloud service providers (CSP) have\nbeen supporting on-demand services in real-time. Realizing the growing\ncomplexity of cloud environment and cloud workloads, hardware vendors such as\nIntel and AMD are increasingly introducing cloud-specific workload acceleration\nfeatures in their CPU platforms. These features are typically targeted towards\npopular and commonly-used cloud workloads. Nonetheless, uncommon,\ncustomer-specific workloads (unknown workloads), if their characteristics are\ndifferent from common workloads (known workloads), may not realize the\npotential of the underlying platform. To address this problem of realizing the\nfull potential of the underlying platform, we develop a machine learning based\ntechnique to characterize, profile and predict workloads running in the cloud\nenvironment. Experimental evaluation of our technique demonstrates good\nprediction performance. We also develop techniques to analyze the performance\nof the model in a standalone manner.",
    "descriptor": "\nComments: 7 pages, 4 figures, Appeared at The MLSys'22 Workshop on Cloud Intelligence(AIOps), In conjunction with the 5th Conference on Machine Learning and Systems\n",
    "authors": [
      "Mohammad Hossain",
      "Derssie Mebratu",
      "Niranjan Hasabnis",
      "Jun Jin",
      "Gaurav Chaudhary",
      "Noah Shen"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15739"
  },
  {
    "id": "arXiv:2211.15741",
    "title": "Cooperate or not Cooperate: Transfer Learning with Multi-Armed Bandit  for Spatial Reuse in Wi-Fi",
    "abstract": "The exponential increase of wireless devices with highly demanding services\nsuch as streaming video, gaming and others has imposed several challenges to\nWireless Local Area Networks (WLANs). In the context of Wi-Fi, IEEE 802.11ax\nbrings high-data rates in dense user deployments. Additionally, it comes with\nnew flexible features in the physical layer as dynamic Clear-Channel-Assessment\n(CCA) threshold with the goal of improving spatial reuse (SR) in response to\nradio spectrum scarcity in dense scenarios. In this paper, we formulate the\nTransmission Power (TP) and CCA configuration problem with an objective of\nmaximizing fairness and minimizing station starvation. We present four main\ncontributions into distributed SR optimization using Multi-Agent Multi-Armed\nBandits (MAMABs). First, we propose to reduce the action space given the large\ncardinality of action combination of TP and CCA threshold values per Access\nPoint (AP). Second, we present two deep Multi-Agent Contextual MABs (MA-CMABs),\nnamed Sample Average Uncertainty (SAU)-Coop and SAU-NonCoop as cooperative and\nnon-cooperative versions to improve SR. In addition, we present an analysis\nwhether cooperation is beneficial using MA-MABs solutions based on the\ne-greedy, Upper Bound Confidence (UCB) and Thompson techniques. Finally, we\npropose a deep reinforcement transfer learning technique to improve\nadaptability in dynamic environments. Simulation results show that cooperation\nvia SAU-Coop algorithm contributes to an improvement of 14.7% in cumulative\nthroughput, and 32.5% improvement of PLR when compared with no cooperation\napproaches. Finally, under dynamic scenarios, transfer learning contributes to\nmitigation of service drops for at least 60% of the total of users.",
    "descriptor": "\nComments: 9 pages, 7 figures\n",
    "authors": [
      "Pedro Enrique Iturria-Rivera",
      "Marcel Chenier",
      "Bernard Herscovici",
      "Burak Kantarci",
      "Melike Erol-Kantarci"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.15741"
  },
  {
    "id": "arXiv:2211.15743",
    "title": "Towards Reliable Item Sampling for Recommendation Evaluation",
    "abstract": "Since Rendle and Krichene argued that commonly used sampling-based evaluation\nmetrics are ``inconsistent'' with respect to the global metrics (even in\nexpectation), there have been a few studies on the sampling-based recommender\nsystem evaluation. Existing methods try either mapping the sampling-based\nmetrics to their global counterparts or more generally, learning the empirical\nrank distribution to estimate the top-$K$ metrics. However, despite existing\nefforts, there is still a lack of rigorous theoretical understanding of the\nproposed metric estimators, and the basic item sampling also suffers from the\n``blind spot'' issue, i.e., estimation accuracy to recover the top-$K$ metrics\nwhen $K$ is small can still be rather substantial. In this paper, we provide an\nin-depth investigation into these problems and make two innovative\ncontributions. First, we propose a new item-sampling estimator that explicitly\noptimizes the error with respect to the ground truth, and theoretically\nhighlight its subtle difference against prior work. Second, we propose a new\nadaptive sampling method which aims to deal with the ``blind spot'' problem and\nalso demonstrate the expectation-maximization (EM) algorithm can be generalized\nfor such a setting. Our experimental results confirm our statistical analysis\nand the superiority of the proposed works. This study helps lay the theoretical\nfoundation for adopting item sampling metrics for recommendation evaluation,\nand provides strong evidence towards making item sampling a powerful and\nreliable tool for recommendation evaluation.",
    "descriptor": "\nComments: aaai2023\n",
    "authors": [
      "Dong Li",
      "Ruoming Jin",
      "Zhenming Liu",
      "Bin Ren",
      "Jing Gao",
      "Zhi Liu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2211.15743"
  },
  {
    "id": "arXiv:2211.15744",
    "title": "Sketch-and-solve approaches to k-means clustering by semidefinite  programming",
    "abstract": "We introduce a sketch-and-solve approach to speed up the Peng-Wei\nsemidefinite relaxation of k-means clustering. When the data is appropriately\nseparated we identify the k-means optimal clustering. Otherwise, our approach\nprovides a high-confidence lower bound on the optimal k-means value. This lower\nbound is data-driven; it does not make any assumption on the data nor how it is\ngenerated. We provide code and an extensive set of numerical experiments where\nwe use this approach to certify approximate optimality of clustering solutions\nobtained by k-means++.",
    "descriptor": "",
    "authors": [
      "Charles Clum",
      "Dustin G. Mixon",
      "Soledad Villar",
      "Kaiying Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.15744"
  },
  {
    "id": "arXiv:2211.15745",
    "title": "Mechanized Noninterference for Gradual Security",
    "abstract": "This paper presents the first machine-checked proof of noninterference for a\nlanguage with gradual information-flow control, thereby establishing a rock\nsolid foundation for secure programming languages that give programmers the\nchoice between runtime versus compile-time enforcement. Along the way we\nuncovered a flaw in one of the noninterference proofs in the literature, and\ngive a counterexample for one of the main lemmas. The particular language\nstudied in this paper, $\\lambda_{\\mathtt{SEC}}^\\star$, is based on the GLIO\nlanguage of Azevedo de Amorim et al. [2020]. To make the design more accessible\nto other researchers, this paper contributes the first traditional semantics\nfor the language, that is, we define compilation from\n$\\lambda_{\\mathtt{SEC}}^\\star$ to a cast calculus and design a reduction\nsemantics for the latter that includes blame tracking. In addition to the proof\nof noninterference, we also mechanize proofs of type safety, determinism, and\nthat compilation preserves types.",
    "descriptor": "\nComments: 32 pages, 18 figures\n",
    "authors": [
      "Tianyu Chen",
      "Jeremy G. Siek"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.15745"
  },
  {
    "id": "arXiv:2211.15747",
    "title": "Certain binary minimal codes constructed using simplicial complexes",
    "abstract": "In this article, we work over the non-chain ring $\\mathcal{R} =\n\\mathbb{Z}_2[u]/\\langle u^3 - u\\rangle $. Let $m\\in \\mathbb{N}$ and let $L, M,\nN \\subseteq [m]:=\\{1, 2, \\dots, m\\}$. For $X\\subseteq [m]$, define $\\Delta_{X}\n:= \\{v \\in \\mathbb{Z}_2^m : \\textnormal{Supp}(v)\\subseteq X\\}$ and $D:=\n(1+u^2)D_1 + u^2\\big(D_2 + (u+u^2)D_3\\big)$, a subset of $\\mathcal{R}^m$, where\n$D_1\\in \\{\\Delta_L, \\Delta_L^c\\}, D_2\\in \\{\\Delta_M, \\Delta_M^c\\}, D_3\\in\n\\{\\Delta_N, \\Delta_N^c\\}$. The linear code $C_D$ over $\\mathcal{R}$ defined by\n$\\{\\big(v\\cdot d\\big)_{d\\in D} : v \\in \\mathcal{R}^m \\}$ is studied for each\n$D$. For instance, we obtain the Lee weight distribution of $C_D$. The Gray map\n$\\Phi: \\mathcal{R} \\longrightarrow \\mathbb{Z}_2^3 $ given by $\\Phi(a+ub+u^2d) =\n(a+b, b+d, d)$ is utilized to derive a binary linear code, namely, $\\Phi(C_D)$\nfor each $D$. Sufficient conditions for each of these binary linear codes to be\nminimal are obtained. In fact, sufficient conditions for minimality are mild in\nnature, for example, $\\vert L\\vert , \\vert M\\vert , \\vert N\\vert < m-2 $ is a\nset of conditions for minimality of $\\Phi(C_D)$ for each $D$. Moreover, these\nbinary codes are self-orthogonal if each of $L, M$ and $N$ is nonempty.",
    "descriptor": "\nComments: 25 pages\n",
    "authors": [
      "Vidya Sagar",
      "Ritumoni Sarma"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.15747"
  },
  {
    "id": "arXiv:2211.15751",
    "title": "Deep Learning-Driven Edge Video Analytics: A Survey",
    "abstract": "Video, as a key driver in the global explosion of digital information, can\ncreate tremendous benefits for human society. Governments and enterprises are\ndeploying innumerable cameras for a variety of applications, e.g., law\nenforcement, emergency management, traffic control, and security surveillance,\nall facilitated by video analytics (VA). This trend is spurred by the rapid\nadvancement of deep learning (DL), which enables more precise models for object\nclassification, detection, and tracking. Meanwhile, with the proliferation of\nInternet-connected devices, massive amounts of data are generated daily,\noverwhelming the cloud. Edge computing, an emerging paradigm that moves\nworkloads and services from the network core to the network edge, has been\nwidely recognized as a promising solution. The resulting new intersection, edge\nvideo analytics (EVA), begins to attract widespread attention. Nevertheless,\nonly a few loosely-related surveys exist on this topic. A dedicated venue for\ncollecting and summarizing the latest advances of EVA is highly desired by the\ncommunity. Besides, the basic concepts of EVA (e.g., definition, architectures,\netc.) are ambiguous and neglected by these surveys due to the rapid development\nof this domain. A thorough clarification is needed to facilitate a consensus on\nthese concepts. To fill in these gaps, we conduct a comprehensive survey of the\nrecent efforts on EVA. In this paper, we first review the fundamentals of edge\ncomputing, followed by an overview of VA. The EVA system and its enabling\ntechniques are discussed next. In addition, we introduce prevalent frameworks\nand datasets to aid future researchers in the development of EVA systems.\nFinally, we discuss existing challenges and foresee future research directions.\nWe believe this survey will help readers comprehend the relationship between VA\nand edge computing, and spark new ideas on EVA.",
    "descriptor": "\nComments: 27 pages, 12 figures\n",
    "authors": [
      "Renjie Xu",
      "Saiedeh Razavi",
      "Rong Zheng"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15751"
  },
  {
    "id": "arXiv:2211.15752",
    "title": "Hierarchical Control Strategy for Moving A Robot Manipulator Between  Small Containers",
    "abstract": "In this paper, we study the implementation of a model predictive controller\n(MPC) for the task of object manipulation in a highly uncertain environment\n(e.g., picking objects from a semi-flexible array of densely packed bins). As a\nreal-time perception-driven feedback controller, MPC is robust to the\nuncertainties in this environment. However, our experiment shows MPC cannot\ncontrol a robot to complete a sequence of motions in a heavily occluded\nenvironment due to its myopic nature. It will benefit from adding a high-level\npolicy that adaptively adjusts the optimization problem for MPC.",
    "descriptor": "",
    "authors": [
      "Paolo Torrado",
      "Boling Yang",
      "Joshua Smith"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.15752"
  },
  {
    "id": "arXiv:2211.15755",
    "title": "Confidence-Aware Graph Neural Networks for Learning Reliability  Assessment Commitments",
    "abstract": "Reliability Assessment Commitment (RAC) Optimization is increasingly\nimportant in grid operations due to larger shares of renewable generations in\nthe generation mix and increased prediction errors. Independent System\nOperators (ISOs) also aim at using finer time granularities, longer time\nhorizons, and possibly stochastic formulations for additional economic and\nreliability benefits. The goal of this paper is to address the computational\nchallenges arising in extending the scope of RAC formulations. It presents\nRACLEARN that (1) uses Graph Neural Networks (GNN) to predict generator\ncommitments and active line constraints, (2) associates a confidence value to\neach commitment prediction, (3) selects a subset of the high-confidence\npredictions, which are (4) repaired for feasibility, and (5) seeds a\nstate-of-the-art optimization algorithm with the feasible predictions and the\nactive constraints. Experimental results on exact RAC formulations used by the\nMidcontinent Independent System Operator (MISO) and an actual transmission\nnetwork (8965 transmission lines, 6708 buses, 1890 generators, and 6262 load\nunits) show that the RACLEARN framework can speed up RAC optimization by\nfactors ranging from 2 to 4 with negligible loss in solution quality.",
    "descriptor": "\nComments: Submitted to IEEE Transactions on Power Systems\n",
    "authors": [
      "Seonho Park",
      "Wenbo Chen",
      "Dahye Han",
      "Mathieu Tanneau",
      "Pascal Van Hentenryck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.15755"
  },
  {
    "id": "arXiv:2211.15759",
    "title": "PIDS: Joint Point Interaction-Dimension Search for 3D Point Cloud",
    "abstract": "The interaction and dimension of points are two important axes in designing\npoint operators to serve hierarchical 3D models. Yet, these two axes are\nheterogeneous and challenging to fully explore. Existing works craft point\noperator under a single axis and reuse the crafted operator in all parts of 3D\nmodels. This overlooks the opportunity to better combine point interactions and\ndimensions by exploiting varying geometry/density of 3D point clouds. In this\nwork, we establish PIDS, a novel paradigm to jointly explore point interactions\nand point dimensions to serve semantic segmentation on point cloud data. We\nestablish a large search space to jointly consider versatile point interactions\nand point dimensions. This supports point operators with various\ngeometry/density considerations. The enlarged search space with heterogeneous\nsearch components calls for a better ranking of candidate models. To achieve\nthis, we improve the search space exploration by leveraging predictor-based\nNeural Architecture Search (NAS), and enhance the quality of prediction by\nassigning unique encoding to heterogeneous search components based on their\npriors. We thoroughly evaluate the networks crafted by PIDS on two semantic\nsegmentation benchmarks, showing ~1% mIOU improvement on SemanticKITTI and\nS3DIS over state-of-the-art 3D models.",
    "descriptor": "\nComments: To appear in WACV 2023\n",
    "authors": [
      "Tunhou Zhang",
      "Mingyuan Ma",
      "Feng Yan",
      "Hai Li",
      "Yiran Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15759"
  },
  {
    "id": "arXiv:2211.15762",
    "title": "Understanding the Impact of Adversarial Robustness on Accuracy Disparity",
    "abstract": "While it has long been empirically observed that adversarial robustness may\nbe at odds with standard accuracy and may have further disparate impacts on\ndifferent classes, it remains an open question to what extent such observations\nhold and how the class imbalance plays a role within. In this paper, we attempt\nto understand this question of accuracy disparity by taking a closer look at\nlinear classifiers under a Gaussian mixture model. We decompose the impact of\nadversarial robustness into two parts: an inherent effect that will degrade the\nstandard accuracy on all classes, and the other caused by the class imbalance\nratio, which will increase the accuracy disparity compared to standard\ntraining. Furthermore, we also extend our model to the general family of stable\ndistributions. We demonstrate that while the constraint of adversarial\nrobustness consistently degrades the standard accuracy in the balanced class\nsetting, the class imbalance ratio plays a fundamentally different role in\naccuracy disparity compared to the Gaussian case, due to the heavy tail of the\nstable distribution. We additionally perform experiments on both synthetic and\nreal-world datasets. The empirical results not only corroborate our theoretical\nfindings, but also suggest that the implications may extend to nonlinear models\nover real-world datasets.",
    "descriptor": "",
    "authors": [
      "Yuzheng Hu",
      "Fan Wu",
      "Hongyang Zhang",
      "Han Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.15762"
  },
  {
    "id": "arXiv:2211.15766",
    "title": "Superpoint Transformer for 3D Scene Instance Segmentation",
    "abstract": "Most existing methods realize 3D instance segmentation by extending those\nmodels used for 3D object detection or 3D semantic segmentation. However, these\nnon-straightforward methods suffer from two drawbacks: 1) Imprecise bounding\nboxes or unsatisfactory semantic predictions limit the performance of the\noverall 3D instance segmentation framework. 2) Existing method requires a\ntime-consuming intermediate step of aggregation. To address these issues, this\npaper proposes a novel end-to-end 3D instance segmentation method based on\nSuperpoint Transformer, named as SPFormer. It groups potential features from\npoint clouds into superpoints, and directly predicts instances through query\nvectors without relying on the results of object detection or semantic\nsegmentation. The key step in this framework is a novel query decoder with\ntransformers that can capture the instance information through the superpoint\ncross-attention mechanism and generate the superpoint masks of the instances.\nThrough bipartite matching based on superpoint masks, SPFormer can implement\nthe network training without the intermediate aggregation step, which\naccelerates the network. Extensive experiments on ScanNetv2 and S3DIS\nbenchmarks verify that our method is concise yet efficient. Notably, SPFormer\nexceeds compared state-of-the-art methods by 4.3% on ScanNetv2 hidden test set\nin terms of mAP and keeps fast inference speed (247ms per frame)\nsimultaneously. Code is available at https://github.com/sunjiahao1999/SPFormer.",
    "descriptor": "",
    "authors": [
      "Jiahao Sun",
      "Chunmei Qing",
      "Junpeng Tan",
      "Xiangmin Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15766"
  },
  {
    "id": "arXiv:2211.15770",
    "title": "Accelerated Nonnegative Tensor Completion via Integer Programming",
    "abstract": "The problem of tensor completion has applications in healthcare, computer\nvision, and other domains. However, past approaches to tensor completion have\nfaced a tension in that they either have polynomial-time computation but\nrequire exponentially more samples than the information-theoretic rate, or they\nuse fewer samples but require solving NP-hard problems for which there are no\nknown practical algorithms. A recent approach, based on integer programming,\nresolves this tension for nonnegative tensor completion. It achieves the\ninformation-theoretic sample complexity rate and deploys the Blended\nConditional Gradients algorithm, which requires a linear (in numerical\ntolerance) number of oracle steps to converge to the global optimum. The\ntradeoff in this approach is that, in the worst case, the oracle step requires\nsolving an integer linear program. Despite this theoretical limitation,\nnumerical experiments show that this algorithm can, on certain instances, scale\nup to 100 million entries while running on a personal computer. The goal of\nthis paper is to further enhance this algorithm, with the intention to expand\nboth the breadth and scale of instances that can be solved. We explore several\nvariants that can maintain the same theoretical guarantees as the algorithm,\nbut offer potentially faster computation. We consider different data\nstructures, acceleration of gradient descent steps, and the use of the Blended\nPairwise Conditional Gradients algorithm. We describe the original approach and\nthese variants, and conduct numerical experiments in order to explore various\ntradeoffs in these algorithmic design choices.",
    "descriptor": "\nComments: 18 pages. Abstract has been accepted by Frontiers in Applied Mathematics and Statistics. Full manuscript is to be submitted\n",
    "authors": [
      "Wenhao Pan",
      "Anil Aswani",
      "Chen Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.15770"
  },
  {
    "id": "arXiv:2211.15771",
    "title": "Approximate Gibbs Sampler for Efficient Inference of Hierarchical  Bayesian Models for Grouped Count Data",
    "abstract": "Hierarchical Bayesian Poisson regression models (HBPRMs) provide a flexible\nmodeling approach of the relationship between predictors and count response\nvariables. The applications of HBPRMs to large-scale datasets require efficient\ninference algorithms due to the high computational cost of inferring many model\nparameters based on random sampling. Although Markov Chain Monte Carlo (MCMC)\nalgorithms have been widely used for Bayesian inference, sampling using this\nclass of algorithms is time-consuming for applications with large-scale data\nand time-sensitive decision-making, partially due to the non-conjugacy of many\nmodels. To overcome this limitation, this research develops an approximate\nGibbs sampler (AGS) to efficiently learn the HBPRMs while maintaining the\ninference accuracy. In the proposed sampler, the data likelihood is\napproximated with Gaussian distribution such that the conditional posterior of\nthe coefficients has a closed-form solution. Numerical experiments using real\nand synthetic datasets with small and large counts demonstrate the superior\nperformance of AGS in comparison to the state-of-the-art sampling algorithm,\nespecially for large datasets.",
    "descriptor": "",
    "authors": [
      "Jin-Zhu Yu",
      "Hiba Baroud"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.15771"
  },
  {
    "id": "arXiv:2211.15774",
    "title": "Decentralized Learning with Multi-Headed Distillation",
    "abstract": "Decentralized learning with private data is a central problem in machine\nlearning. We propose a novel distillation-based decentralized learning\ntechnique that allows multiple agents with private non-iid data to learn from\neach other, without having to share their data, weights or weight updates. Our\napproach is communication efficient, utilizes an unlabeled public dataset and\nuses multiple auxiliary heads for each client, greatly improving training\nefficiency in the case of heterogeneous data. This approach allows individual\nmodels to preserve and enhance performance on their private tasks while also\ndramatically improving their performance on the global aggregated data\ndistribution. We study the effects of data and model architecture heterogeneity\nand the impact of the underlying communication graph topology on learning\nefficiency and show that our agents can significantly improve their performance\ncompared to learning in isolation.",
    "descriptor": "",
    "authors": [
      "Andrey Zhmoginov",
      "Mark Sandler",
      "Nolan Miller",
      "Gus Kristiansen",
      "Max Vladymyrov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15774"
  },
  {
    "id": "arXiv:2211.15775",
    "title": "VideoFACT: Detecting Video Forgeries Using Attention, Scene Context, and  Forensic Traces",
    "abstract": "Fake videos represent an important misinformation threat. While existing\nforensic networks have demonstrated strong performance on image forgeries,\nrecent results reported on the Adobe VideoSham dataset show that these networks\nfail to identify fake content in videos. In this paper, we propose a new\nnetwork that is able to detect and localize a wide variety of video forgeries\nand manipulations. To overcome challenges that existing networks face when\nanalyzing videos, our network utilizes both forensic embeddings to capture\ntraces left by manipulation, context embeddings to exploit forensic traces'\nconditional dependencies upon local scene content, and spatial attention\nprovided by a deep, transformer-based attention mechanism. We create several\nnew video forgery datasets and use these, along with publicly available data,\nto experimentally evaluate our network's performance. These results show that\nour proposed network is able to identify a diverse set of video forgeries,\nincluding those not encountered during training. Furthermore, our results\nreinforce recent findings that image forensic networks largely fail to identify\nfake content in videos.",
    "descriptor": "",
    "authors": [
      "Tai D. Nguyen",
      "Shengbang Fang",
      "Matthew C. Stamm"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15775"
  },
  {
    "id": "arXiv:2211.15779",
    "title": "Revisiting Over-smoothing and Over-squashing using Ollivier's Ricci  Curvature",
    "abstract": "Graph Neural Networks (GNNs) had been demonstrated to be inherently\nsusceptible to the problems of over-smoothing and over-squashing. These issues\nprohibit the ability of GNNs to model complex graph interactions by limiting\ntheir effectiveness at taking into account distant information. Our study\nreveals the key connection between the local graph geometry and the occurrence\nof both of these issues, thereby providing a unified framework for studying\nthem at a local scale using the Ollivier's Ricci curvature. Based on our\ntheory, a number of principled methods are proposed to alleviate the\nover-smoothing and over-squashing issues.",
    "descriptor": "\nComments: 19 pages, 4 figures\n",
    "authors": [
      "Khang Nguyen",
      "Tan Nguyen",
      "Nhat Ho",
      "Khuong Nguyen",
      "Hieu Nong",
      "Vinh Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.15779"
  },
  {
    "id": "arXiv:2211.15782",
    "title": "Towards Preserving Semantic Structure in Argumentative Multi-Agent via  Abstract Interpretation",
    "abstract": "Over the recent twenty years, argumentation has received considerable\nattention in the fields of knowledge representation, reasoning, and multi-agent\nsystems. However, argumentation in dynamic multi-agent systems encounters the\nproblem of significant arguments generated by agents, which comes at the\nexpense of representational complexity and computational cost. In this work, we\naim to investigate the notion of abstraction from the model-checking\nperspective, where several arguments are trying to defend the same position\nfrom various points of view, thereby reducing the size of the argumentation\nframework whilst preserving the semantic flow structure in the system.",
    "descriptor": "\nComments: 5 pages, 2 figures, The Online Handbook of Argumentation for AI (OHAAI) 2022, Vol. 3\n",
    "authors": [
      "Minal Suresh Patil"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15782"
  },
  {
    "id": "arXiv:2211.15783",
    "title": "Mathematically Modeling the Lexicon Entropy of Emergent Language",
    "abstract": "We formulate a stochastic process, FiLex, as a mathematical model of lexicon\nentropy in deep learning-based emergent language systems. Defining a model\nmathematically allows it to generate clear predictions which can be directly\nand decisively tested. We empirically verify across four different environments\nthat FiLex predicts the correct correlation between hyperparameters (training\nsteps, lexicon size, learning rate, rollout buffer size, and Gumbel-Softmax\ntemperature) and the emergent language's entropy in 20 out of 20\nenvironment-hyperparameter combinations. Furthermore, our experiments reveal\nthat different environments show diverse relationships between their\nhyperparameters and entropy which demonstrates the need for a model which can\nmake well-defined predictions at a precise level of granularity.",
    "descriptor": "\nComments: 12 pages, 3 figures\n",
    "authors": [
      "Brendon Boldt",
      "David Mortensen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15783"
  },
  {
    "id": "arXiv:2211.15784",
    "title": "A Survey of Relevant Text Mining Technology",
    "abstract": "Recent advances in text mining and natural language processing technology\nhave enabled researchers to detect an authors identity or demographic\ncharacteristics, such as age and gender, in several text genres by\nautomatically analysing the variation of linguistic characteristics. However,\napplying such techniques in the wild, i.e., in both cybercriminal and regular\nonline social media, differs from more general applications in that its\ndefining characteristics are both domain and process dependent. This gives rise\nto a number of challenges of which contemporary research has only scratched the\nsurface. More specifically, a text mining approach applied on social media\ncommunications typically has no control over the dataset size, the number of\navailable communications will vary across users. Hence, the system has to be\nrobust towards limited data availability. Additionally, the quality of the data\ncannot be guaranteed. As a result, the approach needs to be tolerant to a\ncertain degree of linguistic noise (for example, abbreviations, non-standard\nlanguage use, spelling variations and errors). Finally, in the context of\ncybercriminal fora, it has to be robust towards deceptive or adversarial\nbehaviour, i.e. offenders who attempt to hide their criminal intentions\n(obfuscation) or who assume a false digital persona (imitation), potentially\nusing coded language.\nIn this work we present a comprehensive survey that discusses the problems\nthat have already been addressed in current literature and review potential\nsolutions. Additionally, we highlight which areas need to be given more\nattention.",
    "descriptor": "",
    "authors": [
      "Claudia Peersman",
      "Matthew Edwards",
      "Emma Williams",
      "Awais Rashid"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.15784"
  },
  {
    "id": "arXiv:2211.15787",
    "title": "MuSFA: Improving Music Structural Function Analysis with Partially  Labeled Data",
    "abstract": "Music structure analysis (MSA) systems aim to segment a song recording into\nnon-overlapping sections with useful labels. Previous MSA systems typically\npredict abstract labels in a post-processing step and require the full context\nof the song. By contrast, we recently proposed a supervised framework, called\n\"Music Structural Function Analysis\" (MuSFA), that models and predicts\nmeaningful labels like 'verse' and 'chorus' directly from audio, without\nrequiring the full context of a song. However, the performance of this system\ndepends on the amount and quality of training data. In this paper, we propose\nto repurpose a public dataset, HookTheory Lead Sheet Dataset (HLSD), to improve\nthe performance. HLSD contains over 18K excerpts of music sections originally\ncollected for studying automatic melody harmonization. We treat each excerpt as\na partially labeled song and provide a label mapping, so that HLSD can be used\ntogether with other public datasets, such as SALAMI, RWC, and Isophonics. In\ncross-dataset evaluations, we find that including HLSD in training can improve\nstate-of-the-art boundary detection and section labeling scores by ~3% and ~1%\nrespectively.",
    "descriptor": "\nComments: ISMIR2022, LBD paper\n",
    "authors": [
      "Ju-Chiang Wang",
      "Jordan B. L. Smith",
      "Yun-Ning Hung"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.15787"
  },
  {
    "id": "arXiv:2211.15788",
    "title": "A Visual Active Search Framework for Geospatial Exploration",
    "abstract": "Many problems can be viewed as forms of geospatial search aided by aerial\nimagery, with examples ranging from detecting poaching activity to human\ntrafficking. We model this class of problems in a visual active search (VAS)\nframework, which takes as input an image of a broad area, and aims to identify\nas many examples of a target object as possible. It does this through a limited\nsequence of queries, each of which verifies whether an example is present in a\ngiven region. We propose a reinforcement learning approach for VAS that\nleverages a collection of fully annotated search tasks as training data to\nlearn a search policy, and combines features of the input image with a natural\nrepresentation of active search state. Additionally, we propose domain\nadaptation techniques to improve the policy at decision time when training data\nis not fully reflective of the test-time distribution of VAS tasks. Through\nextensive experiments on several satellite imagery datasets, we show that the\nproposed approach significantly outperforms several strong baselines. Code and\ndata will be made public.",
    "descriptor": "\nComments: 17 pages, 12 figures, Code at this https URL: this https URL\n",
    "authors": [
      "Anindya Sarkar",
      "Michael Lanier",
      "Scott Alfeld",
      "Roman Garnett",
      "Nathan Jacobs",
      "Yevgeniy Vorobeychik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15788"
  },
  {
    "id": "arXiv:2211.15790",
    "title": "Handling Image and Label Resolution Mismatch in Remote Sensing",
    "abstract": "Though semantic segmentation has been heavily explored in vision literature,\nunique challenges remain in the remote sensing domain. One such challenge is\nhow to handle resolution mismatch between overhead imagery and ground-truth\nlabel sources, due to differences in ground sample distance. To illustrate this\nproblem, we introduce a new dataset and use it to showcase weaknesses inherent\nin existing strategies that naively upsample the target label to match the\nimage resolution. Instead, we present a method that is supervised using\nlow-resolution labels (without upsampling), but takes advantage of an exemplar\nset of high-resolution labels to guide the learning process. Our method\nincorporates region aggregation, adversarial learning, and self-supervised\npretraining to generate fine-grained predictions, without requiring\nhigh-resolution annotations. Extensive experiments demonstrate the real-world\napplicability of our approach.",
    "descriptor": "\nComments: IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2023\n",
    "authors": [
      "Scott Workman",
      "Armin Hadzic",
      "M. Usman Rafique"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15790"
  },
  {
    "id": "arXiv:2211.15792",
    "title": "Provably Efficient Model-free RL in Leader-Follower MDP with Linear  Function Approximation",
    "abstract": "We consider a multi-agent episodic MDP setup where an agent (leader) takes\naction at each step of the episode followed by another agent (follower). The\nstate evolution and rewards depend on the joint action pair of the leader and\nthe follower. Such type of interactions can find applications in many domains\nsuch as smart grids, mechanism design, security, and policymaking. We are\ninterested in how to learn policies for both the players with provable\nperformance guarantee under a bandit feedback setting. We focus on a setup\nwhere both the leader and followers are {\\em non-myopic}, i.e., they both seek\nto maximize their rewards over the entire episode and consider a linear MDP\nwhich can model continuous state-space which is very common in many RL\napplications. We propose a {\\em model-free} RL algorithm and show that\n$\\tilde{\\mathcal{O}}(\\sqrt{d^3H^3T})$ regret bounds can be achieved for both\nthe leader and the follower, where $d$ is the dimension of the feature mapping,\n$H$ is the length of the episode, and $T$ is the total number of steps under\nthe bandit feedback information setup. Thus, our result holds even when the\nnumber of states becomes infinite. The algorithm relies on {\\em novel}\nadaptation of the LSVI-UCB algorithm. Specifically, we replace the standard\ngreedy policy (as the best response) with the soft-max policy for both the\nleader and the follower. This turns out to be key in establishing uniform\nconcentration bound for the value functions. To the best of our knowledge, this\nis the first sub-linear regret bound guarantee for the Markov games with\nnon-myopic followers with function approximation.",
    "descriptor": "",
    "authors": [
      "Arnob Ghosh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.15792"
  },
  {
    "id": "arXiv:2211.15804",
    "title": "Towards faster settlement in HTLC-based Cross-Chain Atomic Swaps",
    "abstract": "Hashed Timelock (HTLC)-based atomic swap protocols enable the exchange of\ncoins between two or more parties without relying on a trusted entity. This\nprotocol is like the American call option without premium. It allows the\nfinalization of a deal within a certain period. This puts the swap initiator at\nliberty to delay before deciding to proceed with the deal. If she finds the\ndeal unprofitable, she just waits for the time-period of the contract to\nelapse. However, the counterparty is at a loss since his assets remain locked\nin the contract. The best he can do is to predict the initiator's behavior\nbased on the asset's price fluctuation in the future. But it is difficult to\npredict as cryptocurrencies are quite volatile, and their price fluctuates\nabruptly. We perform a game theoretic analysis of HTLC-based atomic cross-chain\nswap to predict whether a swap will succeed or not. From the strategic behavior\nof the players, we infer that this model lacks fairness. We propose Quick Swap,\na two-party protocol based on hashlock and timelock that fosters faster\nsettlement of the swap. The parties are required to lock griefing-premium along\nwith the principal amount. If the party griefs, he ends up paying the\ngriefing-premium. If a party finds a deal unfavorable, he has the provision to\ncancel the swap. We prove that Quick Swap is more participant-friendly than\nHTLC-based atomic swap. Our work is the first to propose a protocol to ensure\nfairness of atomic-swap in a cyclic multi-party setting.",
    "descriptor": "\nComments: Invited Submission (Security and Privacy) to The Fourth IEEE International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications, 2022, 11 pages\n",
    "authors": [
      "Subhra Mazumdar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.15804"
  },
  {
    "id": "arXiv:2211.15809",
    "title": "On the Utility Recovery Incapability of Neural Net-based Differential  Private Tabular Training Data Synthesizer under Privacy Deregulation",
    "abstract": "Devising procedures for auditing generative model privacy-utility tradeoff is\nan important yet unresolved problem in practice. Existing works concentrates on\ninvestigating the privacy constraint side effect in terms of utility\ndegradation of the train on synthetic, test on real paradigm of synthetic data\ntraining. We push such understanding on privacy-utility tradeoff to next level\nby observing the privacy deregulation side effect on synthetic training data\nutility. Surprisingly, we discover the Utility Recovery Incapability of\nDP-CTGAN and PATE-CTGAN under privacy deregulation, raising concerns on their\npractical applications. The main message is Privacy Deregulation does NOT\nalways imply Utility Recovery.",
    "descriptor": "",
    "authors": [
      "Yucong Liu",
      "Chi-Hua Wang",
      "Guang Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15809"
  },
  {
    "id": "arXiv:2211.15810",
    "title": "Practical Challenges in Indoor Mobile Recommendation",
    "abstract": "Recommendation systems are present in multiple contexts as e-commerce,\nwebsites, and media streaming services. As scenarios get more complex,\ntechniques and tools have to consider a number of variables. When recommending\nservices/products to mobile users while they are in indoor environments next to\nthe object of the recommendation, variables as location, interests, route, and\ninteraction logs also need to be taken into account. In this context, this work\ndiscusses the practical challenges inherent to the context of indoor mobile\nrecommendation (e.g., mall, parking lot, museum, among others) grounded on a\ncase and a systematic review. With the presented results, one expects to\nsupport practitioners in the task of defining the proper approach, technology,\nand notification method when recommending services/products to mobile users in\nindoor environments.",
    "descriptor": "\nComments: 10 pages, 3 figures, 2 tables\n",
    "authors": [
      "Leandro Marega Ferreira Otani",
      "Vagner Figueredo de Santana"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.15810"
  },
  {
    "id": "arXiv:2211.15813",
    "title": "Vertical Airborne Wind Energy Farms with High Power Density per Ground  Area based on Multi-Aircraft Systems",
    "abstract": "This paper proposes and simulates vertical airborne wind energy (AWE) farms\nbased on multi-aircraft systems with high power density (PD) per ground area.\nThese farms consist of many independently ground located systems that are\nflying at the same inclination angle, but with different tether lengths, such\nthat all aircraft fly in a large planar elliptical area that is vertical to the\ntethers. The individual systems are assigned non-overlapping flight cylinders\ndepending on the wind direction. Detailed calculations that take into account\nBetz' limit, assuming a cubically averaged wind power density of 7 m/s, give a\npotential yearly average PD of 43 MW/km$^2$. A conventional wind farm with\ntypical packing density would yield a PD of 2.4 MW/km$^2$ in the same wind\nfield. More refined simulations using optimal control result in a more modest\nPD of 6 MW/km$^2$ for practically recommended flight trajectories. This PD can\nalready be achieved with small-scale aircraft with a wing span of 5.5 m. The\nsimulations additionally show that the achievable PD is more than an order of\nmagnitude higher than for a single-aircraft AWE system with the same wing span.",
    "descriptor": "\nComments: Submitted to European Control Conference (ECC) 2023. 6 pages\n",
    "authors": [
      "Jochem De Schutter",
      "Jakob Harzer",
      "Moritz Diehl"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.15813"
  },
  {
    "id": "arXiv:2211.15823",
    "title": "Personalized Reward Learning with Interaction-Grounded Learning (IGL)",
    "abstract": "In an era of countless content offerings, recommender systems alleviate\ninformation overload by providing users with personalized content suggestions.\nDue to the scarcity of explicit user feedback, modern recommender systems\ntypically optimize for the same fixed combination of implicit feedback signals\nacross all users. However, this approach disregards a growing body of work\nhighlighting that (i) implicit signals can be used by users in diverse ways,\nsignaling anything from satisfaction to active dislike, and (ii) different\nusers communicate preferences in different ways. We propose applying the recent\nInteraction Grounded Learning (IGL) paradigm to address the challenge of\nlearning representations of diverse user communication modalities. Rather than\ntaking a fixed, human-designed reward function, IGL is able to learn\npersonalized reward functions for different users and then optimize directly\nfor the latent user satisfaction. We demonstrate the success of IGL with\nexperiments using simulations as well as with real-world production traces.",
    "descriptor": "",
    "authors": [
      "Jessica Maghakian",
      "Paul Mineiro",
      "Kishan Panaganti",
      "Mark Rucker",
      "Akanksha Saran",
      "Cheng Tan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.15823"
  },
  {
    "id": "arXiv:2211.15824",
    "title": "CLAS: Coordinating Multi-Robot Manipulation with Central Latent Action  Spaces",
    "abstract": "Multi-robot manipulation tasks involve various control entities that can be\nseparated into dynamically independent parts. A typical example of such\nreal-world tasks is dual-arm manipulation. Learning to naively solve such tasks\nwith reinforcement learning is often unfeasible due to the sample complexity\nand exploration requirements growing with the dimensionality of the action and\nstate spaces. Instead, we would like to handle such environments as multi-agent\nsystems and have several agents control parts of the whole. However,\ndecentralizing the generation of actions requires coordination across agents\nthrough a channel limited to information central to the task. This paper\nproposes an approach to coordinating multi-robot manipulation through learned\nlatent action spaces that are shared across different agents. We validate our\nmethod in simulated multi-robot manipulation tasks and demonstrate improvement\nover previous baselines in terms of sample efficiency and learning performance.",
    "descriptor": "",
    "authors": [
      "Elie Aljalbout",
      "Maximilian Karl",
      "Patrick van der Smagt"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.15824"
  },
  {
    "id": "arXiv:2211.15833",
    "title": "Guiding Neural Entity Alignment with Compatibility",
    "abstract": "Entity Alignment (EA) aims to find equivalent entities between two Knowledge\nGraphs (KGs). While numerous neural EA models have been devised, they are\nmainly learned using labelled data only. In this work, we argue that different\nentities within one KG should have compatible counterparts in the other KG due\nto the potential dependencies among the entities. Making compatible predictions\nthus should be one of the goals of training an EA model along with fitting the\nlabelled data: this aspect however is neglected in current methods. To power\nneural EA models with compatibility, we devise a training framework by\naddressing three problems: (1) how to measure the compatibility of an EA model;\n(2) how to inject the property of being compatible into an EA model; (3) how to\noptimise parameters of the compatibility model. Extensive experiments on\nwidely-used datasets demonstrate the advantages of integrating compatibility\nwithin EA models. In fact, state-of-the-art neural EA models trained within our\nframework using just 5\\% of the labelled data can achieve comparable\neffectiveness with supervised training using 20\\% of the labelled data.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Bing Liu",
      "Harrisen Scells",
      "Wen Hua",
      "Guido Zuccon",
      "Genghong Zhao",
      "Xia Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15833"
  },
  {
    "id": "arXiv:2211.15834",
    "title": "OK Computer Analysis: An Audio Corpus Study of Radiohead",
    "abstract": "The application of music information retrieval techniques in popular music\nstudies has great promise. In the present work, a corpus of Radiohead songs\nacross their career from 1992 to 2017 are subjected to automated audio\nanalysis. We examine findings from a number of granularities and perspectives,\nincluding within song and between song examination of both timbral-rhythmic and\nharmonic features. Chronological changes include possible career spanning\neffects for a band's releases such as slowing tempi and reduced brightness, and\nthe timbral markers of Radiohead's expanding approach to instrumental resources\nmost identified with the Kid A and Amnesiac era. We conclude with a discussion\nhighlighting some challenges for this approach, and the potential for a field\nof audio file based career analysis.",
    "descriptor": "",
    "authors": [
      "Nick Collins"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Information Retrieval (cs.IR)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.15834"
  },
  {
    "id": "arXiv:2211.15836",
    "title": "On the Envy-free Allocation of Chores",
    "abstract": "We study the problem of allocating a set of indivisible chores to three\nagents, among whom two have additive cost functions, in a fair manner. Two\nfairness notions under consideration are envy-freeness up to any chore (EFX)\nand a relaxed notion, namely envy-freeness up to transferring any chore (tEFX).\nIn contrast to the case of goods, the case of chores remain relatively\nunexplored. In particular, our results constructively prove the existence of a\ntEFX allocation for three agents if two of them have additive cost functions\nand the ratio of their highest and lowest costs is bounded by two. In addition,\nif those two cost functions have identical ordering (IDO) on the costs of\nchores, then an EFX allocation exists even if the condition on the ratio bound\nis slightly relaxed. Throughout our entire framework, the third agent is\nunrestricted besides having a monotone cost function.",
    "descriptor": "",
    "authors": [
      "Lang Yin",
      "Ruta Mehta"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.15836"
  },
  {
    "id": "arXiv:2211.15837",
    "title": "Survey on Self-Supervised Multimodal Representation Learning and  Foundation Models",
    "abstract": "Deep learning has been the subject of growing interest in recent years.\nSpecifically, a specific type called Multimodal learning has shown great\npromise for solving a wide range of problems in domains such as language,\nvision, audio, etc. One promising research direction to improve this further\nhas been learning rich and robust low-dimensional data representation of the\nhigh-dimensional world with the help of large-scale datasets present on the\ninternet. Because of its potential to avoid the cost of annotating large-scale\ndatasets, self-supervised learning has been the de facto standard for this task\nin recent years. This paper summarizes some of the landmark research papers\nthat are directly or indirectly responsible to build the foundation of\nmultimodal self-supervised learning of representation today. The paper goes\nover the development of representation learning over the last few years for\neach modality and how they were combined to get a multimodal agent later.",
    "descriptor": "",
    "authors": [
      "Sushil Thapa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.15837"
  },
  {
    "id": "arXiv:2211.15839",
    "title": "Continuous Neural Algorithmic Planners",
    "abstract": "Neural algorithmic reasoning studies the problem of learning algorithms with\nneural networks, especially with graph architectures. A recent proposal, XLVIN,\nreaps the benefits of using a graph neural network that simulates the value\niteration algorithm in deep reinforcement learning agents. It allows model-free\nplanning without access to privileged information about the environment, which\nis usually unavailable. However, XLVIN only supports discrete action spaces,\nand is hence nontrivially applicable to most tasks of real-world interest. We\nexpand XLVIN to continuous action spaces by discretization, and evaluate\nseveral selective expansion policies to deal with the large planning graphs.\nOur proposal, CNAP, demonstrates how neural algorithmic reasoning can make a\nmeasurable impact in higher-dimensional continuous control settings, such as\nMuJoCo, bringing gains in low-data settings and outperforming model-free\nbaselines.",
    "descriptor": "",
    "authors": [
      "Yu He",
      "Petar Veli\u010dkovi\u0107",
      "Pietro Li\u00f2",
      "Andreea Deac"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15839"
  },
  {
    "id": "arXiv:2211.15841",
    "title": "MegaBlocks: Efficient Sparse Training with Mixture-of-Experts",
    "abstract": "We present MegaBlocks, a system for efficient Mixture-of-Experts (MoE)\ntraining on GPUs. Our system is motivated by the limitations of current\nframeworks, which restrict the dynamic routing in MoE layers to satisfy the\nconstraints of existing software and hardware. These formulations force a\ntradeoff between model quality and hardware efficiency, as users must choose\nbetween dropping tokens from the computation or wasting computation and memory\non padding. To address these limitations, we reformulate MoE computation in\nterms of block-sparse operations and develop new block-sparse GPU kernels that\nefficiently handle the dynamism present in MoEs. Our approach never drops\ntokens and maps efficiently to modern hardware, enabling end-to-end training\nspeedups of up to 40% over MoEs trained with the state-of-the-art Tutel library\nand 2.4x over DNNs trained with the highly-optimized Megatron-LM framework.",
    "descriptor": "",
    "authors": [
      "Trevor Gale",
      "Deepak Narayanan",
      "Cliff Young",
      "Matei Zaharia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.15841"
  },
  {
    "id": "arXiv:2211.15842",
    "title": "ICS-CTM2: Industrial Control System Cybersecurity Testbed Maturity Model",
    "abstract": "Industrial Control System (ICS) testbeds serve as a platform for evaluating\nand validating control system performances, cybersecurity tools and\ntechnologies. In order to build or enhance an ICS testbed, it is vital to have\na deeper understanding of its design specifications and characteristic\nattributes. Satisfying this prerequisite involves examination and assessment of\nthese attributes for existing testbeds. To further increase confidence in a\ntestbed's functionality, it is important to perform a comparative analysis of\nits specifications with other ICS testbeds. However, at present, there is no\nstandardized methodology available to provide a comparative assessment of\ndifferent testbeds. In this paper, we propose a methodology for analyzing ICS\ntestbeds, inspired by the Cybersecurity Capability Maturity Model (C2M2). In\nparticular, we then define a ICS Cybersecurity Testbed Maturity Model, its\ndomains, and the associated maturity indicator levels. To demonstrate the\nbenefit of the model, we have conducted a case study analysis for several ICS\ntestbeds, representing different industrial sectors. Our analysis provides\ndeeper insights into the relative strengths and limitations of these testbeds,\ntogether with scope for future enhancements, with respect to the domains\ndefined by the model.",
    "descriptor": "",
    "authors": [
      "Souradeep Bhattacharya",
      "Burhan Hyder",
      "Manimaran Govindarasu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.15842"
  },
  {
    "id": "arXiv:2211.15843",
    "title": "Sublinear Time Algorithms and Complexity of Approximate Maximum Matching",
    "abstract": "Sublinear time algorithms for approximating maximum matching size have long\nbeen studied. Much of the progress over the last two decades on this problem\nhas been on the algorithmic side. For instance, an algorithm of Behnezhad\n[FOCS'21] obtains a 1/2-approximation in $\\tilde{O}(n)$ time for $n$-vertex\ngraphs. A more recent algorithm by Behnezhad, Roghani, Rubinstein, and Saberi\n[SODA'23] obtains a slightly-better-than-1/2 approximation in\n$O(n^{1+\\epsilon})$ time. On the lower bound side, Parnas and Ron [TCS'07]\nshowed 15 years ago that obtaining any constant approximation of maximum\nmatching size requires $\\Omega(n)$ time. Proving any super-linear in $n$ lower\nbound, even for $(1-\\epsilon)$-approximations, has remained elusive since then.\nIn this paper, we prove the first super-linear in $n$ lower bound for this\nproblem. We show that at least $n^{1.2 - o(1)}$ queries in the adjacency list\nmodel are needed for obtaining a $(\\frac{2}{3} + \\Omega(1))$-approximation of\nmaximum matching size. This holds even if the graph is bipartite and is\npromised to have a matching of size $\\Theta(n)$. Our lower bound argument\nbuilds on techniques such as correlation decay that to our knowledge have not\nbeen used before in proving sublinear time lower bounds.\nWe complement our lower bound by presenting two algorithms that run in\nstrongly sublinear time of $n^{2-\\Omega(1)}$. The first algorithm achieves a\n$(\\frac{2}{3}-\\epsilon)$-approximation; this significantly improves prior\nclose-to-1/2 approximations. Our second algorithm obtains an even better\napproximation factor of $(\\frac{2}{3}+\\Omega(1))$ for bipartite graphs. This\nbreaks the prevalent $2/3$-approximation barrier and importantly shows that our\n$n^{1.2-o(1)}$ time lower bound for $(\\frac{2}{3}+\\Omega(1))$-approximations\ncannot be improved all the way to $n^{2-o(1)}$.",
    "descriptor": "",
    "authors": [
      "Soheil Behnezhad",
      "Mohammad Roghani",
      "Aviad Rubinstein"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.15843"
  },
  {
    "id": "arXiv:2211.15844",
    "title": "How Important are Good Method Names in Neural Code Generation? A Model  Robustness Perspective",
    "abstract": "Pre-trained code generation models (PCGMs) have been widely applied in neural\ncode generation which can generate executable code from functional descriptions\nin natural languages, possibly together with signatures. Despite substantial\nperformance improvement of PCGMs, the role of method names in neural code\ngeneration has not been thoroughly investigated. In this paper, we study and\ndemonstrate the potential of benefiting from method names to enhance the\nperformance of PCGMs, from a model robustness perspective. Specifically, we\npropose a novel approach, named RADAR (neuRAl coDe generAtor Robustifier).\nRADAR consists of two components: RADAR-Attack and RADAR-Defense. The former\nattacks a PCGM by generating adversarial method names as part of the input,\nwhich are semantic and visual similar to the original input, but may trick the\nPCGM to generate completely unrelated code snippets. As a countermeasure to\nsuch attacks, RADAR-Defense synthesizes a new method name from the functional\ndescription and supplies it to the PCGM. Evaluation results show that\nRADAR-Attack can, e.g., reduce the CodeBLEU of generated code by 19.72% to\n38.74% in three state-of-the-art PCGMs (i.e., CodeGPT, PLBART, and CodeT5).\nMoreover, RADAR-Defense is able to reinstate the performance of PCGMs with\nsynthesized method names. These results highlight the importance of good method\nnames in neural code generation and implicate the benefits of studying model\nrobustness in software engineering.",
    "descriptor": "\nComments: UNDER REVIEW\n",
    "authors": [
      "Guang Yang",
      "Yu Zhou",
      "Wenhua Yang",
      "Tao Yue",
      "Xiang Chen",
      "Taolue Chen"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.15844"
  },
  {
    "id": "arXiv:2211.15845",
    "title": "Lifelong Embedding Learning and Transfer for Growing Knowledge Graphs",
    "abstract": "Existing knowledge graph (KG) embedding models have primarily focused on\nstatic KGs. However, real-world KGs do not remain static, but rather evolve and\ngrow in tandem with the development of KG applications. Consequently, new facts\nand previously unseen entities and relations continually emerge, necessitating\nan embedding model that can quickly learn and transfer new knowledge through\ngrowth. Motivated by this, we delve into an expanding field of KG embedding in\nthis paper, i.e., lifelong KG embedding. We consider knowledge transfer and\nretention of the learning on growing snapshots of a KG without having to learn\nembeddings from scratch. The proposed model includes a masked KG autoencoder\nfor embedding learning and update, with an embedding transfer strategy to\ninject the learned knowledge into the new entity and relation embeddings, and\nan embedding regularization method to avoid catastrophic forgetting. To\ninvestigate the impacts of different aspects of KG growth, we construct four\ndatasets to evaluate the performance of lifelong KG embedding. Experimental\nresults show that the proposed model outperforms the state-of-the-art inductive\nand lifelong embedding baselines.",
    "descriptor": "\nComments: Accepted in the 37th AAAI Conference on Artificial Intelligence (AAAI 2023)\n",
    "authors": [
      "Yuanning Cui",
      "Yuxin Wang",
      "Zequn Sun",
      "Wenqiang Liu",
      "Yiqiao Jiang",
      "Kexin Han",
      "Wei Hu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15845"
  },
  {
    "id": "arXiv:2211.15846",
    "title": "LUMix: Improving Mixup by Better Modelling Label Uncertainty",
    "abstract": "Modern deep networks can be better generalized when trained with noisy\nsamples and regularization techniques. Mixup and CutMix have been proven to be\neffective for data augmentation to help avoid overfitting. Previous Mixup-based\nmethods linearly combine images and labels to generate additional training\ndata. However, this is problematic if the object does not occupy the whole\nimage as we demonstrate in Figure 1. Correctly assigning the label weights is\nhard even for human beings and there is no clear criterion to measure it. To\ntackle this problem, in this paper, we propose LUMix, which models such\nuncertainty by adding label perturbation during training. LUMix is simple as it\ncan be implemented in just a few lines of code and can be universally applied\nto any deep networks \\eg CNNs and Vision Transformers, with minimal\ncomputational cost. Extensive experiments show that our LUMix can consistently\nboost the performance for networks with a wide range of diversity and capacity\non ImageNet, \\eg $+0.7\\%$ for a small model DeiT-S and $+0.6\\%$ for a large\nvariant XCiT-L. We also demonstrate that LUMix can lead to better robustness\nwhen evaluated on ImageNet-O and ImageNet-A. The source code can be found\n\\href{https://github.com/kevin-ssy/LUMix}{here}",
    "descriptor": "",
    "authors": [
      "Shuyang Sun",
      "Jie-Neng Chen",
      "Ruifei He",
      "Alan Yuille",
      "Philip Torr",
      "Song Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15846"
  },
  {
    "id": "arXiv:2211.15848",
    "title": "ClueWeb22: 10 Billion Web Documents with Rich Information",
    "abstract": "ClueWeb22, the newest iteration of the ClueWeb line of datasets, provides 10\nbillion web pages affiliated with rich information. Its design was influenced\nby the need for a high quality, large scale web corpus to support a range of\nacademic and industry research, for example, in information systems,\nretrieval-augmented AI systems, and model pretraining. Compared with earlier\nClueWeb corpora, the ClueWeb22 corpus is larger, more varied, of\nhigher-quality, and aligned with the document distributions in commercial web\nsearch. Besides raw HTML, ClueWeb22 includes rich information about the web\npages provided by industry-standard document understanding systems, including\nthe visual representation of pages rendered by a web browser, parsed HTML\nstructure information from a neural network parser, and pre-processed cleaned\ndocument text to lower the barrier to entry. Many of these signals have been\nwidely used in industry but are available to the research community for the\nfirst time at this scale.",
    "descriptor": "",
    "authors": [
      "Arnold Overwijk",
      "Chenyan Xiong",
      "Xiao Liu",
      "Cameron VandenBerg",
      "Jamie Callan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15848"
  },
  {
    "id": "arXiv:2211.15853",
    "title": "Disentangling the Mechanisms Behind Implicit Regularization in SGD",
    "abstract": "A number of competing hypotheses have been proposed to explain why\nsmall-batch Stochastic Gradient Descent (SGD)leads to improved generalization\nover the full-batch regime, with recent work crediting the implicit\nregularization of various quantities throughout training. However, to date,\nempirical evidence assessing the explanatory power of these hypotheses is\nlacking. In this paper, we conduct an extensive empirical evaluation, focusing\non the ability of various theorized mechanisms to close the small-to-large\nbatch generalization gap. Additionally, we characterize how the quantities that\nSGD has been claimed to (implicitly) regularize change over the course of\ntraining. By using micro-batches, i.e. disjoint smaller subsets of each\nmini-batch, we empirically show that explicitly penalizing the gradient norm or\nthe Fisher Information Matrix trace, averaged over micro-batches, in the\nlarge-batch regime recovers small-batch SGD generalization, whereas\nJacobian-based regularizations fail to do so. This generalization performance\nis shown to often be correlated with how well the regularized model's gradient\nnorms resemble those of small-batch SGD. We additionally show that this\nbehavior breaks down as the micro-batch size approaches the batch size.\nFinally, we note that in this line of inquiry, positive experimental findings\non CIFAR10 are often reversed on other datasets like CIFAR100, highlighting the\nneed to test hypotheses on a wider collection of datasets.",
    "descriptor": "\nComments: Accepted as Spotlight at the NeurIPS 2022 Workshop for Higher Order Optimization in Machine Learning\n",
    "authors": [
      "Zachary Novack",
      "Simran Kaur",
      "Tanya Marwah",
      "Saurabh Garg",
      "Zachary C. Lipton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15853"
  },
  {
    "id": "arXiv:2211.15856",
    "title": "Beyond Ensemble Averages: Leveraging Climate Model Ensembles for  Subseasonal Forecasting",
    "abstract": "Producing high-quality forecasts of key climate variables such as temperature\nand precipitation on subseasonal time scales has long been a gap in operational\nforecasting. Recent studies have shown promising results using machine learning\n(ML) models to advance subseasonal forecasting (SSF), but several open\nquestions remain. First, several past approaches use the average of an ensemble\nof physics-based forecasts as an input feature of these models. However,\nensemble forecasts contain information that can aid prediction beyond only the\nensemble mean. Second, past methods have focused on average performance,\nwhereas forecasts of extreme events are far more important for planning and\nmitigation purposes. Third, climate forecasts correspond to a spatially-varying\ncollection of forecasts, and different methods account for spatial variability\nin the response differently. Trade-offs between different approaches may be\nmitigated with model stacking. This paper describes the application of a\nvariety of ML methods used to predict monthly average precipitation and two\nmeter temperature using physics-based predictions (ensemble forecasts) and\nobservational data such as relative humidity, pressure at sea level, or\ngeopotential height, two weeks in advance for the whole continental United\nStates. Regression, quantile regression, and tercile classification tasks using\nlinear models, random forests, convolutional neural networks, and stacked\nmodels are considered. The proposed models outperform common baselines such as\nhistorical averages (or quantiles) and ensemble averages (or quantiles). This\npaper further includes an investigation of feature importance, trade-offs\nbetween using the full ensemble or only the ensemble average, and different\nmodes of accounting for spatial variability.",
    "descriptor": "\nComments: Journal of Climate\n",
    "authors": [
      "Elena Orlova",
      "Haokun Liu",
      "Raphael Rossellini",
      "Benjamin Cash",
      "Rebecca Willett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.15856"
  },
  {
    "id": "arXiv:2211.15858",
    "title": "Distributed Energy Management and Demand Response in Smart Grids: A  Multi-Agent Deep Reinforcement Learning Framework",
    "abstract": "This paper presents a multi-agent Deep Reinforcement Learning (DRL) framework\nfor autonomous control and integration of renewable energy resources into smart\npower grid systems. In particular, the proposed framework jointly considers\ndemand response (DR) and distributed energy management (DEM) for residential\nend-users. DR has a widely recognized potential for improving power grid\nstability and reliability, while at the same time reducing end-users energy\nbills. However, the conventional DR techniques come with several shortcomings,\nsuch as the inability to handle operational uncertainties while incurring\nend-user disutility, which prevents widespread adoption in real-world\napplications. The proposed framework addresses these shortcomings by\nimplementing DR and DEM based on real-time pricing strategy that is achieved\nusing deep reinforcement learning. Furthermore, this framework enables the\npower grid service provider to leverage distributed energy resources (i.e., PV\nrooftop panels and battery storage) as dispatchable assets to support the smart\ngrid during peak hours, thus achieving management of distributed energy\nresources. Simulation results based on the Deep Q-Network (DQN) demonstrate\nsignificant improvements of the 24-hour accumulative profit for both prosumers\nand the power grid service provider, as well as major reductions in the\nutilization of the power grid reserve generators.",
    "descriptor": "\nComments: 16 pages, 10 figures\n",
    "authors": [
      "Amin Shojaeighadikolaei",
      "Arman Ghasemi",
      "Kailani Jones",
      "Yousif Dafalla",
      "Alexandru G. Bardas",
      "Reza Ahmadi",
      "Morteza Haashemi"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.15858"
  },
  {
    "id": "arXiv:2211.15860",
    "title": "Bayesian Experimental Design for Symbolic Discovery",
    "abstract": "This study concerns the formulation and application of Bayesian optimal\nexperimental design to symbolic discovery, which is the inference from\nobservational data of predictive models taking general functional forms. We\napply constrained first-order methods to optimize an appropriate selection\ncriterion, using Hamiltonian Monte Carlo to sample from the prior. A step for\ncomputing the predictive distribution, involving convolution, is computed via\neither numerical integration, or via fast transform methods.",
    "descriptor": "",
    "authors": [
      "Kenneth L. Clarkson",
      "Cristina Cornelio",
      "Sanjeeb Dash",
      "Joao Goncalves",
      "Lior Horesh",
      "Nimrod Megiddo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.15860"
  },
  {
    "id": "arXiv:2211.15864",
    "title": "Peano: Learning Formal Mathematical Reasoning",
    "abstract": "General mathematical reasoning is computationally undecidable, but humans\nroutinely solve new problems. Moreover, discoveries developed over centuries\nare taught to subsequent generations quickly. What structure enables this, and\nhow might that inform automated mathematical reasoning? We posit that central\nto both puzzles is the structure of procedural abstractions underlying\nmathematics. We explore this idea in a case study on 5 sections of beginning\nalgebra on the Khan Academy platform. To define a computational foundation, we\nintroduce Peano, a theorem-proving environment where the set of valid actions\nat any point is finite. We use Peano to formalize introductory algebra problems\nand axioms, obtaining well-defined search problems. We observe existing\nreinforcement learning methods for symbolic reasoning to be insufficient to\nsolve harder problems. Adding the ability to induce reusable abstractions\n(\"tactics\") from its own solutions allows an agent to make steady progress,\nsolving all problems. Furthermore, these abstractions induce an order to the\nproblems, seen at random during training. The recovered order has significant\nagreement with the expert-designed Khan Academy curriculum, and\nsecond-generation agents trained on the recovered curriculum learn\nsignificantly faster. These results illustrate the synergistic role of\nabstractions and curricula in the cultural transmission of mathematics.",
    "descriptor": "",
    "authors": [
      "Gabriel Poesia",
      "Noah D. Goodman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15864"
  },
  {
    "id": "arXiv:2211.15866",
    "title": "A Search and Detection Autonomous Drone System: from Design to  Implementation",
    "abstract": "Utilizing autonomous drones or unmanned aerial vehicles (UAVs) has shown\ngreat advantages over preceding methods in support of urgent scenarios such as\nsearch and rescue (SAR) and wildfire detection. In these operations, search\nefficiency in terms of the amount of time spent to find the target is crucial\nsince with the passing of time the survivability of the missing person\ndecreases or wildfire management becomes more difficult with disastrous\nconsequences. In this work, it is considered a scenario where a drone is\nintended to search and detect a missing person (e.g., a hiker or a mountaineer)\nor a potential fire spot in a given area. In order to obtain the shortest path\nto the target, a general framework is provided to model the problem of target\ndetection when the target's location is probabilistically known. To this end,\ntwo algorithms are proposed: Path planning and target detection. The path\nplanning algorithm is based on Bayesian inference and the target detection is\naccomplished by means of a residual neural network (ResNet) trained on the\nimage dataset captured by the drone as well as existing pictures and datasets\non the web. Through simulation and experiment, the proposed path planning\nalgorithm is compared with two benchmark algorithms. It is shown that the\nproposed algorithm significantly decreases the average time of the mission.",
    "descriptor": "",
    "authors": [
      "Mohammadjavad Khosravi",
      "Rushiv Arora",
      "Saeede Enayati",
      "Hossein Pishro-Nik"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15866"
  },
  {
    "id": "arXiv:2211.15868",
    "title": "Kinematic-aware Hierarchical Attention Network for Human Pose Estimation  in Videos",
    "abstract": "Previous video-based human pose estimation methods have shown promising\nresults by leveraging aggregated features of consecutive frames. However, most\napproaches compromise accuracy to mitigate jitter or do not sufficiently\ncomprehend the temporal aspects of human motion. Furthermore, occlusion\nincreases uncertainty between consecutive frames, which results in unsmooth\nresults. To address these issues, we design an architecture that exploits the\nkeypoint kinematic features with the following components. First, we\neffectively capture the temporal features by leveraging individual keypoint's\nvelocity and acceleration. Second, the proposed hierarchical transformer\nencoder aggregates spatio-temporal dependencies and refines the 2D or 3D input\npose estimated from existing estimators. Finally, we provide an online\ncross-supervision between the refined input pose generated from the encoder and\nthe final pose from our decoder to enable joint optimization. We demonstrate\ncomprehensive results and validate the effectiveness of our model in various\ntasks: 2D pose estimation, 3D pose estimation, body mesh recovery, and sparsely\nannotated multi-human pose estimation. Our code is available at\nhttps://github.com/KyungMinJin/HANet.",
    "descriptor": "",
    "authors": [
      "Kyung-Min Jin",
      "Byoung-Sung Lim",
      "Gun-Hee Lee",
      "Tae-Kyung Kang",
      "Seong-Whan Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15868"
  },
  {
    "id": "arXiv:2211.15869",
    "title": "Fast Hyperparameter Tuning for Ising Machines",
    "abstract": "In this paper, we propose a novel technique to accelerate Ising machines\nhyperparameter tuning. Firstly, we define Ising machine performance and explain\nthe goal of hyperparameter tuning in regard to this performance definition.\nSecondly, we compare well-known hyperparameter tuning techniques, namely random\nsampling and Tree-structured Parzen Estimator (TPE) on different combinatorial\noptimization problems. Thirdly, we propose a new convergence acceleration\nmethod for TPE which we call \"FastConvergence\".It aims at limiting the number\nof required TPE trials to reach best performing hyperparameter values\ncombination. We compare FastConvergence to previously mentioned well-known\nhyperparameter tuning techniques to show its effectiveness. For experiments,\nwell-known Travel Salesman Problem (TSP) and Quadratic Assignment Problem (QAP)\ninstances are used as input. The Ising machine used is Fujitsu's third\ngeneration Digital Annealer (DA). Results show, in most cases, FastConvergence\ncan reach similar results to TPE alone within less than half the number of\ntrials.",
    "descriptor": "\nComments: This work has been submitted and accepted at IEEE ICCE2023. Copyright will be transferred to IEEE, please cite the DOI on IEEExplore once ready\n",
    "authors": [
      "Matthieu Parizy",
      "Norihiro Kakuko",
      "Nozomu Togawa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.15869"
  },
  {
    "id": "arXiv:2211.15871",
    "title": "Simultaneous Estimation of Hand Configurations and Finger Joint Angles  using Forearm Ultrasound",
    "abstract": "With the advancement in computing and robotics, it is necessary to develop\nfluent and intuitive methods for interacting with digital systems,\naugmented/virtual reality (AR/VR) interfaces, and physical robotic systems.\nHand motion recognition is widely used to enable these interactions. Hand\nconfiguration classification and MCP joint angle detection is important for a\ncomprehensive reconstruction of hand motion. sEMG and other technologies have\nbeen used for the detection of hand motions. Forearm ultrasound images provide\na musculoskeletal visualization that can be used to understand hand motion.\nRecent work has shown that these ultrasound images can be classified using\nmachine learning to estimate discrete hand configurations. Estimating both hand\nconfiguration and MCP joint angles based on forearm ultrasound has not been\naddressed in the literature. In this paper, we propose a CNN based deep\nlearning pipeline for predicting the MCP joint angles. The results for the hand\nconfiguration classification were compared by using different machine learning\nalgorithms. SVC with different kernels, MLP, and the proposed CNN have been\nused to classify the ultrasound images into 11 hand configurations based on\nactivities of daily living. Forearm ultrasound images were acquired from 6\nsubjects instructed to move their hands according to predefined hand\nconfigurations. Motion capture data was acquired to get the finger angles\ncorresponding to the hand movements at different speeds. Average classification\naccuracy of 82.7% for the proposed CNN and over 80% for SVC for different\nkernels was observed on a subset of the dataset. An average RMSE of 7.35\ndegrees was obtained between the predicted and the true MCP joint angles. A low\nlatency (6.25 - 9.1 Hz) pipeline has been proposed for estimating both MCP\njoint angles and hand configuration aimed at real-time control of human-machine\ninterfaces.",
    "descriptor": "\nComments: Manuscript ACCEPTED for publication in IEEE Transactions on Medical Robotics and Bionics (TMRB). 13 pages, 11 figures, and 5 tables. arXiv admin note: text overlap with arXiv:2109.11093\n",
    "authors": [
      "Keshav Bimbraw",
      "Christopher J. Nycz",
      "Matt Schueler",
      "Ziming Zhang",
      "Haichong K. Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.15871"
  },
  {
    "id": "arXiv:2211.15875",
    "title": "Training Time Adversarial Attack Aiming the Vulnerability of Continual  Learning",
    "abstract": "Generally, regularization-based continual learning models limit access to the\nprevious task data to imitate the real-world setting which has memory and\nprivacy issues. However, this introduces a problem in these models by not being\nable to track the performance on each task. In other words, current continual\nlearning methods are vulnerable to attacks done on the previous task. We\ndemonstrate the vulnerability of regularization-based continual learning\nmethods by presenting simple task-specific training time adversarial attack\nthat can be used in the learning process of a new task. Training data generated\nby the proposed attack causes performance degradation on a specific task\ntargeted by the attacker. Experiment results justify the vulnerability proposed\nin this paper and demonstrate the importance of developing continual learning\nmodels that are robust to adversarial attack.",
    "descriptor": "\nComments: Accepted at NeurIPS 2022 ML Safety Workshop\n",
    "authors": [
      "Gyojin Han",
      "Jaehyun Choi",
      "Hyeong Gwon Hong",
      "Junmo Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15875"
  },
  {
    "id": "arXiv:2211.15876",
    "title": "Instance-Specific Image Goal Navigation: Training Embodied Agents to  Find Object Instances",
    "abstract": "We consider the problem of embodied visual navigation given an image-goal\n(ImageNav) where an agent is initialized in an unfamiliar environment and\ntasked with navigating to a location 'described' by an image. Unlike related\nnavigation tasks, ImageNav does not have a standardized task definition which\nmakes comparison across methods difficult. Further, existing formulations have\ntwo problematic properties; (1) image-goals are sampled from random locations\nwhich can lead to ambiguity (e.g., looking at walls), and (2) image-goals match\nthe camera specification and embodiment of the agent; this rigidity is limiting\nwhen considering user-driven downstream applications. We present the\nInstance-specific ImageNav task (InstanceImageNav) to address these\nlimitations. Specifically, the goal image is 'focused' on some particular\nobject instance in the scene and is taken with camera parameters independent of\nthe agent. We instantiate InstanceImageNav in the Habitat Simulator using\nscenes from the Habitat-Matterport3D dataset (HM3D) and release a standardized\nbenchmark to measure community progress.",
    "descriptor": "",
    "authors": [
      "Jacob Krantz",
      "Stefan Lee",
      "Jitendra Malik",
      "Dhruv Batra",
      "Devendra Singh Chaplot"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15876"
  },
  {
    "id": "arXiv:2211.15877",
    "title": "Effective Utilisation of Multiple Open-Source Datasets to Improve  Generalisation Performance of Point Cloud Segmentation Models",
    "abstract": "Semantic segmentation of aerial point cloud data can be utilised to\ndifferentiate which points belong to classes such as ground, buildings, or\nvegetation. Point clouds generated from aerial sensors mounted to drones or\nplanes can utilise LIDAR sensors or cameras along with photogrammetry. Each\nmethod of data collection contains unique characteristics which can be learnt\nindependently with state-of-the-art point cloud segmentation models. Utilising\na single point cloud segmentation model can be desirable in situations where\npoint cloud sensors, quality, and structures can change. In these situations it\nis desirable that the segmentation model can handle these variations with\npredictable and consistent results. Although deep learning can segment point\nclouds accurately it often suffers in generalisation, adapting poorly to data\nwhich is different than the training data. To address this issue, we propose to\nutilise multiple available open source fully annotated datasets to train and\ntest models that are better able to generalise.\nIn this paper we discuss the combination of these datasets into a simple\ntraining set and challenging test set. Combining datasets allows us to evaluate\ngeneralisation performance on known variations in the point cloud data. We show\nthat a naive combination of datasets produces a model with improved\ngeneralisation performance as expected. We go on to show that an improved\nsampling strategy which decreases sampling variations increases the\ngeneralisation performance substantially on top of this. Experiments to find\nwhich sample variations give this performance boost found that consistent\ndensities are the most important.",
    "descriptor": "\nComments: Accepted into The International Conference on Digital Image Computing: Techniques and Applications (DICTA) 2022\n",
    "authors": [
      "Matthew Howe",
      "Boris Repasky",
      "Timothy Payne"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15877"
  },
  {
    "id": "arXiv:2211.15880",
    "title": "Mirror descent of Hopfield model",
    "abstract": "Mirror descent is a gradient descent method that uses a dual space of\nparametric models. The great idea has been developed in convex optimization,\nbut not yet widely applied in machine learning. In this study, we provide a\npossible way that the mirror descent can help data-driven parameter\ninitialization of neural networks. We adopt the Hopfield model as a prototype\nof neural networks, we demonstrate that the mirror descent can train the model\nmore effectively than the usual gradient descent with random parameter\ninitialization.",
    "descriptor": "\nComments: 3 figures\n",
    "authors": [
      "Hyungjoon Soh",
      "Dongyeob Kim",
      "Juno Hwang",
      "Junghyo Jo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.15880"
  },
  {
    "id": "arXiv:2211.15886",
    "title": "Approximating Martingale Process for Variance Reduction in Deep  Reinforcement Learning with Large State Space",
    "abstract": "Approximating Martingale Process (AMP) is proven to be effective for variance\nreduction in reinforcement learning (RL) in specific cases such as Multiclass\nQueueing Networks. However, in the already proven cases, the state space is\nrelatively small and all possible state transitions can be iterated through. In\nthis paper, we consider systems in which state space is large and have\nuncertainties when considering state transitions, thus making AMP a generalized\nvariance-reduction method in RL. Specifically, we will investigate the\napplication of AMP in ride-hailing systems like Uber, where Proximal Policy\nOptimization (PPO) is incorporated to optimize the policy of matching drivers\nand customers.",
    "descriptor": "",
    "authors": [
      "Charlie Ruan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.15886"
  },
  {
    "id": "arXiv:2211.15890",
    "title": "On Robust Learning from Noisy Labels: A Permutation Layer Approach",
    "abstract": "The existence of label noise imposes significant challenges (e.g., poor\ngeneralization) on the training process of deep neural networks (DNN). As a\nremedy, this paper introduces a permutation layer learning approach termed\nPermLL to dynamically calibrate the training process of the DNN subject to\ninstance-dependent and instance-independent label noise. The proposed method\naugments the architecture of a conventional DNN by an instance-dependent\npermutation layer. This layer is essentially a convex combination of\npermutation matrices that is dynamically calibrated for each sample. The\nprimary objective of the permutation layer is to correct the loss of noisy\nsamples mitigating the effect of label noise. We provide two variants of PermLL\nin this paper: one applies the permutation layer to the model's prediction,\nwhile the other applies it directly to the given noisy label. In addition, we\nprovide a theoretical comparison between the two variants and show that\nprevious methods can be seen as one of the variants. Finally, we validate\nPermLL experimentally and show that it achieves state-of-the-art performance on\nboth real and synthetic datasets.",
    "descriptor": "",
    "authors": [
      "Salman Alsubaihi",
      "Mohammed Alkhrashi",
      "Raied Aljadaany",
      "Fahad Albalawi",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15890"
  },
  {
    "id": "arXiv:2211.15891",
    "title": "An Extreme-Adaptive Time Series Prediction Model Based on  Probability-Enhanced LSTM Neural Networks",
    "abstract": "Forecasting time series with extreme events has been a challenging and\nprevalent research topic, especially when the time series data are affected by\ncomplicated uncertain factors, such as is the case in hydrologic prediction.\nDiverse traditional and deep learning models have been applied to discover the\nnonlinear relationships and recognize the complex patterns in these types of\ndata. However, existing methods usually ignore the negative influence of\nimbalanced data, or severe events, on model training. Moreover, methods are\nusually evaluated on a small number of generally well-behaved time series,\nwhich does not show their ability to generalize. To tackle these issues, we\npropose a novel probability-enhanced neural network model, called NEC+, which\nconcurrently learns extreme and normal prediction functions and a way to choose\namong them via selective back propagation. We evaluate the proposed model on\nthe difficult 3-day ahead hourly water level prediction task applied to 9\nreservoirs in California. Experimental results demonstrate that the proposed\nmodel significantly outperforms state-of-the-art baselines and exhibits\nsuperior generalization ability on data with diverse distributions.",
    "descriptor": "\nComments: Data and code available at this https URL Paper accepted to AAAI 2023\n",
    "authors": [
      "Yanhong Li",
      "Jack Xu",
      "David C. Anastasiu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15891"
  },
  {
    "id": "arXiv:2211.15893",
    "title": "Adap DP-FL: Differentially Private Federated Learning with Adaptive  Noise",
    "abstract": "Federated learning seeks to address the issue of isolated data islands by\nmaking clients disclose only their local training models. However, it was\ndemonstrated that private information could still be inferred by analyzing\nlocal model parameters, such as deep neural network model weights. Recently,\ndifferential privacy has been applied to federated learning to protect data\nprivacy, but the noise added may degrade the learning performance much.\nTypically, in previous work, training parameters were clipped equally and\nnoises were added uniformly. The heterogeneity and convergence of training\nparameters were simply not considered. In this paper, we propose a\ndifferentially private scheme for federated learning with adaptive noise (Adap\nDP-FL). Specifically, due to the gradient heterogeneity, we conduct adaptive\ngradient clipping for different clients and different rounds; due to the\ngradient convergence, we add decreasing noises accordingly. Extensive\nexperiments on real-world datasets demonstrate that our Adap DP-FL outperforms\nprevious methods significantly.",
    "descriptor": "",
    "authors": [
      "Jie Fu",
      "Zhili Chen",
      "Xiao Han"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.15893"
  },
  {
    "id": "arXiv:2211.15894",
    "title": "HashEncoding: Autoencoding with Multiscale Coordinate Hashing",
    "abstract": "We present HashEncoding, a novel autoencoding architecture that leverages a\nnon-parametric multiscale coordinate hash function to facilitate a per-pixel\ndecoder without convolutions. By leveraging the space-folding behaviour of\nhashing functions, HashEncoding allows for an inherently multiscale embedding\nspace that remains much smaller than the original image. As a result, the\ndecoder requires very few parameters compared with decoders in traditional\nautoencoders, approaching a non-parametric reconstruction of the original image\nand allowing for greater generalizability. Finally, by allowing backpropagation\ndirectly to the coordinate space, we show that HashEncoding can be exploited\nfor geometric tasks such as optical flow.",
    "descriptor": "",
    "authors": [
      "Lukas Zhornyak",
      "Zhengjie Xu",
      "Haoran Tang",
      "Jianbo Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15894"
  },
  {
    "id": "arXiv:2211.15897",
    "title": "Learning Antidote Data to Individual Unfairness",
    "abstract": "Fairness is an essential factor for machine learning systems deployed in\nhigh-stake applications. Among all fairness notions, individual fairness,\nfollowing a consensus that `similar individuals should be treated similarly,'\nis a vital notion to guarantee fair treatment for individual cases. Previous\nmethods typically characterize individual fairness as a prediction-invariant\nproblem when perturbing sensitive attributes, and solve it by adopting the\nDistributionally Robust Optimization (DRO) paradigm. However, adversarial\nperturbations along a direction covering sensitive information do not consider\nthe inherent feature correlations or innate data constraints, and thus mislead\nthe model to optimize at off-manifold and unrealistic samples. In light of\nthis, we propose a method to learn and generate antidote data that\napproximately follows the data distribution to remedy individual unfairness.\nThese on-manifold antidote data can be used through a generic optimization\nprocedure with original training data, resulting in a pure pre-processing\napproach to individual unfairness, or can also fit well with the in-processing\nDRO paradigm. Through extensive experiments, we demonstrate our antidote data\nresists individual unfairness at a minimal or zero cost to the model's\npredictive utility.",
    "descriptor": "",
    "authors": [
      "Peizhao Li",
      "Ethan Xia",
      "Hongfu Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.15897"
  },
  {
    "id": "arXiv:2211.15899",
    "title": "FakeEdge: Alleviate Dataset Shift in Link Prediction",
    "abstract": "Link prediction is a crucial problem in graph-structured data. Due to the\nrecent success of graph neural networks (GNNs), a variety of GNN-based models\nwere proposed to tackle the link prediction task. Specifically, GNNs leverage\nthe message passing paradigm to obtain node representation, which relies on\nlink connectivity. However, in a link prediction task, links in the training\nset are always present while ones in the testing set are not yet formed,\nresulting in a discrepancy of the connectivity pattern and bias of the learned\nrepresentation. It leads to a problem of dataset shift which degrades the model\nperformance. In this paper, we first identify the dataset shift problem in the\nlink prediction task and provide theoretical analyses on how existing link\nprediction methods are vulnerable to it. We then propose FakeEdge, a\nmodel-agnostic technique, to address the problem by mitigating the graph\ntopological gap between training and testing sets. Extensive experiments\ndemonstrate the applicability and superiority of FakeEdge on multiple datasets\nacross various domains.",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Kaiwen Dong",
      "Yijun Tian",
      "Zhichun Guo",
      "Yang Yang",
      "Nitesh V. Chawla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.15899"
  },
  {
    "id": "arXiv:2211.15900",
    "title": "Towards More Robust Interpretation via Local Gradient Alignment",
    "abstract": "Neural network interpretation methods, particularly feature attribution\nmethods, are known to be fragile with respect to adversarial input\nperturbations. To address this, several methods for enhancing the local\nsmoothness of the gradient while training have been proposed for attaining\n\\textit{robust} feature attributions. However, the lack of considering the\nnormalization of the attributions, which is essential in their visualizations,\nhas been an obstacle to understanding and improving the robustness of feature\nattribution methods. In this paper, we provide new insights by taking such\nnormalization into account. First, we show that for every non-negative\nhomogeneous neural network, a naive $\\ell_2$-robust criterion for gradients is\n\\textit{not} normalization invariant, which means that two functions with the\nsame normalized gradient can have different values. Second, we formulate a\nnormalization invariant cosine distance-based criterion and derive its upper\nbound, which gives insight for why simply minimizing the Hessian norm at the\ninput, as has been done in previous work, is not sufficient for attaining\nrobust feature attribution. Finally, we propose to combine both $\\ell_2$ and\ncosine distance-based criteria as regularization terms to leverage the\nadvantages of both in aligning the local gradient. As a result, we\nexperimentally show that models trained with our method produce much more\nrobust interpretations on CIFAR-10 and ImageNet-100 without significantly\nhurting the accuracy, compared to the recent baselines. To the best of our\nknowledge, this is the first work to verify the robustness of interpretation on\na larger-scale dataset beyond CIFAR-10, thanks to the computational efficiency\nof our method.",
    "descriptor": "\nComments: 22 pages (9 pages in paper, 13 pages in Appendix), 9 figures, 6 tables Accepted in AAAI 23 (Association for the Advancement of Artificial Intelligence)\n",
    "authors": [
      "Sunghwan Joo",
      "Seokhyeon Jeong",
      "Juyeon Heo",
      "Adrian Weller",
      "Taesup Moon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15900"
  },
  {
    "id": "arXiv:2211.15901",
    "title": "Multi-robot Social-aware Cooperative Planning in Pedestrian Environments  Using Multi-agent Reinforcement Learning",
    "abstract": "Safe and efficient co-planning of multiple robots in pedestrian participation\nenvironments is promising for applications. In this work, a novel multi-robot\nsocial-aware efficient cooperative planner that on the basis of off-policy\nmulti-agent reinforcement learning (MARL) under partial dimension-varying\nobservation and imperfect perception conditions is proposed. We adopt\ntemporal-spatial graph (TSG)-based social encoder to better extract the\nimportance of social relation between each robot and the pedestrians in its\nfield of view (FOV). Also, we introduce K-step lookahead reward setting in\nmulti-robot RL framework to avoid aggressive, intrusive, short-sighted, and\nunnatural motion decisions generated by robots. Moreover, we improve the\ntraditional centralized critic network with multi-head global attention module\nto better aggregates local observation information among different robots to\nguide the process of individual policy update. Finally, multi-group\nexperimental results verify the effectiveness of the proposed cooperative\nmotion planner.",
    "descriptor": "",
    "authors": [
      "Zichen He",
      "Chunwei Song",
      "Lu Dong"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15901"
  },
  {
    "id": "arXiv:2211.15902",
    "title": "Simultaneous Spatial and Temporal Assignment for Fast UAV Trajectory  Optimization using Bilevel Optimization",
    "abstract": "In this paper, we propose a framework for fast trajectory planning for\nunmanned aerial vehicles (UAVs). Our framework is reformulated from an existing\nbilevel optimization, in which the lower-level problem solves for the optimal\ntrajectory with a fixed time allocation, whereas the upper-level problem\nupdates the time allocation using analytical gradients. The lower-level problem\nincorporates the safety-set constraints (in the form of inequality constraints)\nand is cast as a convex quadratic program (QP). Our formulation modifies the\nlower-level QP by excluding the inequality constraints for the safety sets,\nwhich significantly reduces the computation time. The safety-set constraints\nare moved to the upper-level problem, where the feasible waypoints are updated\ntogether with the time allocation using analytical gradients enabled by the\nOptNet. We validate our approach in simulations, where our method's computation\ntime scales linearly with respect to the number of safety sets, in contrast to\nthe state-of-the-art that scales exponentially.",
    "descriptor": "",
    "authors": [
      "Qianzhong Chen",
      "Sheng Cheng",
      "Naira Hovakimyan"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.15902"
  },
  {
    "id": "arXiv:2211.15903",
    "title": "Equivalence Between SE(3) Equivariant Networks via Steerable Kernels and  Group Convolution",
    "abstract": "A wide range of techniques have been proposed in recent years for designing\nneural networks for 3D data that are equivariant under rotation and translation\nof the input. Most approaches for equivariance under the Euclidean group\n$\\mathrm{SE}(3)$ of rotations and translations fall within one of the two major\ncategories. The first category consists of methods that use\n$\\mathrm{SE}(3)$-convolution which generalizes classical\n$\\mathbb{R}^3$-convolution on signals over $\\mathrm{SE}(3)$. Alternatively, it\nis possible to use \\textit{steerable convolution} which achieves\n$\\mathrm{SE}(3)$-equivariance by imposing constraints on\n$\\mathbb{R}^3$-convolution of tensor fields. It is known by specialists in the\nfield that the two approaches are equivalent, with steerable convolution being\nthe Fourier transform of $\\mathrm{SE}(3)$ convolution. Unfortunately, these\nresults are not widely known and moreover the exact relations between deep\nlearning architectures built upon these two approaches have not been precisely\ndescribed in the literature on equivariant deep learning. In this work we\nprovide an in-depth analysis of both methods and their equivalence and relate\nthe two constructions to multiview convolutional networks. Furthermore, we\nprovide theoretical justifications of separability of $\\mathrm{SE}(3)$ group\nconvolution, which explain the applicability and success of some recent\napproaches. Finally, we express different methods using a single coherent\nformalism and provide explicit formulas that relate the kernels learned by\ndifferent methods. In this way, our work helps to unify different\npreviously-proposed techniques for achieving roto-translational equivariance,\nand helps to shed light on both the utility and precise differences between\nvarious alternatives. We also derive new TFN non-linearities from our\nequivalence principle and test them on practical benchmark datasets.",
    "descriptor": "",
    "authors": [
      "Adrien Poulenard",
      "Maks Ovsjanikov",
      "Leonidas J. Guibas"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15903"
  },
  {
    "id": "arXiv:2211.15907",
    "title": "Performance Evaluation, Optimization and Dynamic Decision in Blockchain  Systems: A Recent Overview",
    "abstract": "With rapid development of blockchain technology as well as integration of\nvarious application areas, performance evaluation, performance optimization,\nand dynamic decision in blockchain systems are playing an increasingly\nimportant role in developing new blockchain technology. This paper provides a\nrecent systematic overview of this class of research, and especially,\ndeveloping mathematical modeling and basic theory of blockchain systems.\nImportant examples include (a) performance evaluation: Markov processes,\nqueuing theory, Markov reward processes, random walks, fluid and diffusion\napproximations, and martingale theory; (b) performance optimization: Linear\nprogramming, nonlinear programming, integer programming, and multi-objective\nprogramming; (c) optimal control and dynamic decision: Markov decision\nprocesses, and stochastic optimal control; and (d) artificial intelligence:\nMachine learning, deep reinforcement learning, and federated learning. So far,\na little research has focused on these research lines. We believe that the\nbasic theory with mathematical methods, algorithms and simulations of\nblockchain systems discussed in this paper will strongly support future\ndevelopment and continuous innovation of blockchain technology.",
    "descriptor": "\nComments: 42 pages, 9 figures\n",
    "authors": [
      "Quan-Lin Li",
      "Yan-Xia Chang",
      "Qing Wang"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.15907"
  },
  {
    "id": "arXiv:2211.15910",
    "title": "Low-overhead Beam Training Scheme for Extremely Large-Scale RIS in  Near-field",
    "abstract": "Extremely large-scale reconfigurable intelligent surface (XL-RIS) has\nrecently been proposed and is recognized as a promising technology that can\nfurther enhance the capacity of communication systems and compensate for severe\npath loss . However, the pilot overhead of beam training in XL-RIS-assisted\nwireless communication systems is enormous because the near-field channel model\nneeds to be taken into account, and the number of candidate codewords in the\ncodebook increases dramatically accordingly. To tackle this problem, we propose\ntwo deep learning-based near-field beam training schemes in XL-RIS-assisted\ncommunication systems, where deep residual networks are employed to determine\nthe optimal near-field RIS codeword. Specifically, we first propose a far-field\nbeam-based beam training (FBT) scheme in which the received signals of all\nfar-field RIS codewords are fed into the neural network to estimate the optimal\nnear-field RIS codeword. In order to further reduce the pilot overhead, a\npartial near-field beam-based beam training (PNBT) scheme is proposed, where\nonly the received signals corresponding to the partial near-field XL-RIS\ncodewords are served as input to the neural network. Moreover, we further\npropose an improved PNBT scheme to enhance the performance of beam training by\nfully exploring the neural network's output. Finally, simulation results show\nthat the proposed schemes outperform the existing beam training schemes and can\nreduce the beam sweeping overhead by approximately 95\\%.",
    "descriptor": "\nComments: This paper has been submitted to IEEE Transactions on Communications\n",
    "authors": [
      "Wang Liu",
      "Cunhua Pan",
      "Hong Ren",
      "Feng Shu",
      "Shi Jin",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.15910"
  },
  {
    "id": "arXiv:2211.15913",
    "title": "Branch-Well-Structured Transition Systems and Extensions",
    "abstract": "We propose a relaxation to the definition of a well-structured transition\nsystems (WSTS) while retaining the decidability of boundedness and termination.\nIn our class, we ease the well-quasi-ordered (wqo) condition to be applicable\nonly between states that are reachable one from another. Furthermore, we also\nrelax the monotony condition in the same way. While this retains the\ndecidability of termination and boundedness, it appears that the coverability\nproblem is undecidable. To this end, we define a new notion of monotony, called\ncover-monotony, which is strictly more general than the usual monotony and\nstill allows us to decide a restricted form of the coverability problem.",
    "descriptor": "",
    "authors": [
      "Benedikt Bollig",
      "Alain Finkel",
      "Amrita Suresh"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.15913"
  },
  {
    "id": "arXiv:2211.15914",
    "title": "Zero-Shot Opinion Summarization with GPT-3",
    "abstract": "Very large language models such as GPT-3 have shown impressive performance\nacross a wide variety of tasks, including text summarization. In this paper, we\nshow that this strong performance extends to opinion summarization. We explore\nseveral pipeline methods for applying GPT-3 to summarize a large collection of\nuser reviews in a zero-shot fashion, notably approaches based on recursive\nsummarization and selecting salient content to summarize through supervised\nclustering or extraction. On two datasets, an aspect-oriented summarization\ndataset of hotel reviews and a generic summarization dataset of Amazon and Yelp\nreviews, we show that the GPT-3 models achieve very strong performance in human\nevaluation. We argue that standard evaluation metrics do not reflect this, and\nevaluate against several new measures targeting faithfulness, factuality, and\ngenericity to contrast these different methods.",
    "descriptor": "\nComments: 16 pages, 9 figures\n",
    "authors": [
      "Adithya Bhaskar",
      "Alexander R. Fabbri",
      "Greg Durrett"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15914"
  },
  {
    "id": "arXiv:2211.15916",
    "title": "BotSIM: An End-to-End Bot Simulation Toolkit for Commercial  Task-Oriented Dialog Systems",
    "abstract": "We introduce BotSIM, a modular, open-source Bot SIMulation environment with\ndialog generation, user simulation and conversation analytics capabilities.\nBotSIM aims to serve as a one-stop solution for large-scale data-efficient\nend-to-end evaluation, diagnosis and remediation of commercial task-oriented\ndialog (TOD) systems to significantly accelerate commercial bot development and\nevaluation, reduce cost and time-to-market. BotSIM adopts a layered design\ncomprising the infrastructure layer, the adaptor layer and the application\nlayer. The infrastructure layer hosts key models and components to support\nBotSIM's major functionalities via a streamlined\n\"generation-simulation-remediation\" pipeline. The adaptor layer is used to\nextend BotSIM to accommodate new bot platforms. The application layer provides\na suite of command line tools and a Web App to significantly lower the entry\nbarrier for BotSIM users such as bot admins or practitioners. In this report,\nwe focus on the technical designs of various system components. A detailed case\nstudy using Einstein BotBuilder is also presented to show how to apply BotSIM\npipeline for bot evaluation and remediation. The detailed system descriptions\ncan be found in our system demo paper. The toolkit is available at:\nhttps://github.com/salesforce/BotSIM .",
    "descriptor": "\nComments: Accompanying code documentation at this https URL arXiv admin note: text overlap with arXiv:2211.11982\n",
    "authors": [
      "Guangsen Wang",
      "Shafiq Joty",
      "Junnan Li",
      "Steven Hoi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15916"
  },
  {
    "id": "arXiv:2211.15918",
    "title": "Similarity Distribution based Membership Inference Attack on Person  Re-identification",
    "abstract": "While person Re-identification (Re-ID) has progressed rapidly due to its wide\nreal-world applications, it also causes severe risks of leaking personal\ninformation from training data. Thus, this paper focuses on quantifying this\nrisk by membership inference (MI) attack. Most of the existing MI attack\nalgorithms focus on classification models, while Re-ID follows a totally\ndifferent training and inference paradigm. Re-ID is a fine-grained recognition\ntask with complex feature embedding, and model outputs commonly used by\nexisting MI like logits and losses are not accessible during inference. Since\nRe-ID focuses on modelling the relative relationship between image pairs\ninstead of individual semantics, we conduct a formal and empirical analysis\nwhich validates that the distribution shift of the inter-sample similarity\nbetween training and test set is a critical criterion for Re-ID membership\ninference. As a result, we propose a novel membership inference attack method\nbased on the inter-sample similarity distribution. Specifically, a set of\nanchor images are sampled to represent the similarity distribution conditioned\non a target image, and a neural network with a novel anchor selection module is\nproposed to predict the membership of the target image. Our experiments\nvalidate the effectiveness of the proposed approach on both the Re-ID task and\nconventional classification task.",
    "descriptor": "\nComments: 9 pages, 7 figures, Accepted by AAAI 2023\n",
    "authors": [
      "Junyao Gao",
      "Xinyang Jiang",
      "Huishuai Zhang",
      "Yifan Yang",
      "Shuguang Dou",
      "Dongsheng Li",
      "Duoqian Miao",
      "Cheng Deng",
      "Cairong Zhao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.15918"
  },
  {
    "id": "arXiv:2211.15920",
    "title": "Discrete Control in Real-World Driving Environments using Deep  Reinforcement Learning",
    "abstract": "Training self-driving cars is often challenging since they require a vast\namount of labeled data in multiple real-world contexts, which is\ncomputationally and memory intensive. Researchers often resort to driving\nsimulators to train the agent and transfer the knowledge to a real-world\nsetting. Since simulators lack realistic behavior, these methods are quite\ninefficient. To address this issue, we introduce a framework (perception,\nplanning, and control) in a real-world driving environment that transfers the\nreal-world environments into gaming environments by setting up a reliable\nMarkov Decision Process (MDP). We propose variations of existing Reinforcement\nLearning (RL) algorithms in a multi-agent setting to learn and execute the\ndiscrete control in real-world environments. Experiments show that the\nmulti-agent setting outperforms the single-agent setting in all the scenarios.\nWe also propose reliable initialization, data augmentation, and training\ntechniques that enable the agents to learn and generalize to navigate in a\nreal-world environment with minimal input video data, and with minimal\ntraining. Additionally, to show the efficacy of our proposed algorithm, we\ndeploy our method in the virtual driving environment TORCS.",
    "descriptor": "",
    "authors": [
      "Avinash Amballa",
      "Advaith P.",
      "Pradip Sasmal",
      "Sumohana Channappayya"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.15920"
  },
  {
    "id": "arXiv:2211.15923",
    "title": "Frequency Domain Gaussian Process Models for $H^\\infty$ Uncertainties",
    "abstract": "Complex-valued Gaussian processes are used in Bayesian frequency-domain\nsystem identification as prior models for regression. If each realization of\nsuch a process were an $H_\\infty$ function with probability one, then the same\nmodel could be used for probabilistic robust control, allowing for robustly\nsafe learning. We investigate sufficient conditions for a general\ncomplex-domain Gaussian process to have this property. For the special case of\nprocesses whose Hermitian covariance is stationary, we provide an explicit\nparameterization of the covariance structure in terms of a summable sequence of\nnonnegative numbers.",
    "descriptor": "\nComments: Extended version of a submission to Learning for Dynamics and Control 2023. 18 pages, 2 figures\n",
    "authors": [
      "Alex Devonport",
      "Peter Seiler",
      "Murat Arcak"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.15923"
  },
  {
    "id": "arXiv:2211.15924",
    "title": "Weakly Supervised Learning Significantly Reduces the Number of Labels  Required for Intracranial Hemorrhage Detection on Head CT",
    "abstract": "Modern machine learning pipelines, in particular those based on deep learning\n(DL) models, require large amounts of labeled data. For classification\nproblems, the most common learning paradigm consists of presenting labeled\nexamples during training, thus providing strong supervision on what constitutes\npositive and negative samples. This constitutes a major obstacle for the\ndevelopment of DL models in radiology--in particular for cross-sectional\nimaging (e.g., computed tomography [CT] scans)--where labels must come from\nmanual annotations by expert radiologists at the image or slice-level. These\ndiffer from examination-level annotations, which are coarser but cheaper, and\ncould be extracted from radiology reports using natural language processing\ntechniques. This work studies the question of what kind of labels should be\ncollected for the problem of intracranial hemorrhage detection in brain CT. We\ninvestigate whether image-level annotations should be preferred to\nexamination-level ones. By framing this task as a multiple instance learning\nproblem, and employing modern attention-based DL architectures, we analyze the\ndegree to which different levels of supervision improve detection performance.\nWe find that strong supervision (i.e., learning with local image-level\nannotations) and weak supervision (i.e., learning with only global\nexamination-level labels) achieve comparable performance in examination-level\nhemorrhage detection (the task of selecting the images in an examination that\nshow signs of hemorrhage) as well as in image-level hemorrhage detection\n(highlighting those signs within the selected images). Furthermore, we study\nthis behavior as a function of the number of labels available during training.\nOur results suggest that local labels may not be necessary at all for these\ntasks, drastically reducing the time and cost involved in collecting and\ncurating datasets.",
    "descriptor": "",
    "authors": [
      "Jacopo Teneggi",
      "Paul H. Yi",
      "Jeremias Sulam"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15924"
  },
  {
    "id": "arXiv:2211.15925",
    "title": "Device Modeling Bias in ReRAM-based Neural Network Simulations",
    "abstract": "Data-driven modeling approaches such as jump tables are promising techniques\nto model populations of resistive random-access memory (ReRAM) or other\nemerging memory devices for hardware neural network simulations. As these\ntables rely on data interpolation, this work explores the open questions about\ntheir fidelity in relation to the stochastic device behavior they model. We\nstudy how various jump table device models impact the attained network\nperformance estimates, a concept we define as modeling bias. Two methods of\njump table device modeling, binning and Optuna-optimized binning, are explored\nusing synthetic data with known distributions for benchmarking purposes, as\nwell as experimental data obtained from TiOx ReRAM devices. Results on a\nmulti-layer perceptron trained on MNIST show that device models based on\nbinning can behave unpredictably particularly at low number of points in the\ndevice dataset, sometimes over-promising, sometimes under-promising target\nnetwork accuracy. This paper also proposes device level metrics that indicate\nsimilar trends with the modeling bias metric at the network level. The proposed\napproach opens the possibility for future investigations into statistical\ndevice models with better performance, as well as experimentally verified\nmodeling bias in different in-memory computing and neural network\narchitectures.",
    "descriptor": "",
    "authors": [
      "Osama Yousuf",
      "Imtiaz Hossen",
      "Matthew W. Daniels",
      "Martin Lueker-Boden",
      "Andrew Dienstfrey",
      "Gina C. Adam"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15925"
  },
  {
    "id": "arXiv:2211.15926",
    "title": "Interpretations Cannot Be Trusted: Stealthy and Effective Adversarial  Perturbations against Interpretable Deep Learning",
    "abstract": "Deep learning methods have gained increased attention in various applications\ndue to their outstanding performance. For exploring how this high performance\nrelates to the proper use of data artifacts and the accurate problem\nformulation of a given task, interpretation models have become a crucial\ncomponent in developing deep learning-based systems. Interpretation models\nenable the understanding of the inner workings of deep learning models and\noffer a sense of security in detecting the misuse of artifacts in the input\ndata. Similar to prediction models, interpretation models are also susceptible\nto adversarial inputs. This work introduces two attacks, AdvEdge and\nAdvEdge$^{+}$, that deceive both the target deep learning model and the coupled\ninterpretation model. We assess the effectiveness of proposed attacks against\ntwo deep learning model architectures coupled with four interpretation models\nthat represent different categories of interpretation models. Our experiments\ninclude the attack implementation using various attack frameworks. We also\nexplore the potential countermeasures against such attacks. Our analysis shows\nthe effectiveness of our attacks in terms of deceiving the deep learning models\nand their interpreters, and highlights insights to improve and circumvent the\nattacks.",
    "descriptor": "",
    "authors": [
      "Eldor Abdukhamidov",
      "Mohammed Abuhamad",
      "Simon S. Woo",
      "Eric Chan-Tin",
      "Tamer Abuhmed"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15926"
  },
  {
    "id": "arXiv:2211.15927",
    "title": "Compressing Cross-Lingual Multi-Task Models at Qualtrics",
    "abstract": "Experience management is an emerging business area where organizations focus\non understanding the feedback of customers and employees in order to improve\ntheir end-to-end experiences. This results in a unique set of machine learning\nproblems to help understand how people feel, discover issues they care about,\nand find which actions need to be taken on data that are different in content\nand distribution from traditional NLP domains. In this paper, we present a case\nstudy of building text analysis applications that perform multiple\nclassification tasks efficiently in 12 languages in the nascent business area\nof experience management. In order to scale up modern ML methods on experience\ndata, we leverage cross lingual and multi-task modeling techniques to\nconsolidate our models into a single deployment to avoid overhead. We also make\nuse of model compression and model distillation to reduce overall inference\nlatency and hardware cost to the level acceptable for business needs while\nmaintaining model prediction quality. Our findings show that multi-task\nmodeling improves task performance for a subset of experience management tasks\nin both XLM-R and mBert architectures. Among the compressed architectures we\nexplored, we found that MiniLM achieved the best compression/performance\ntradeoff. Our case study demonstrates a speedup of up to 15.61x with 2.60%\naverage task degradation (or 3.29x speedup with 1.71% degradation) and\nestimated savings of 44% over using the original full-size model. These results\ndemonstrate a successful scaling up of text classification for the challenging\nnew area of ML for experience management.",
    "descriptor": "\nComments: accepted to IAAI-23 (part of AAAI-23)\n",
    "authors": [
      "Daniel Campos",
      "Daniel Perry",
      "Samir Joshi",
      "Yashmeet Gambhir",
      "Wei Du",
      "Zhengzheng Xing",
      "Aaron Colak"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15927"
  },
  {
    "id": "arXiv:2211.15929",
    "title": "Backdoor Vulnerabilities in Normally Trained Deep Learning Models",
    "abstract": "We conduct a systematic study of backdoor vulnerabilities in normally trained\nDeep Learning models. They are as dangerous as backdoors injected by data\npoisoning because both can be equally exploited. We leverage 20 different types\nof injected backdoor attacks in the literature as the guidance and study their\ncorrespondences in normally trained models, which we call natural backdoor\nvulnerabilities. We find that natural backdoors are widely existing, with most\ninjected backdoor attacks having natural correspondences. We categorize these\nnatural backdoors and propose a general detection framework. It finds 315\nnatural backdoors in the 56 normally trained models downloaded from the\nInternet, covering all the different categories, while existing scanners\ndesigned for injected backdoors can at most detect 65 backdoors. We also study\nthe root causes and defense of natural backdoors.",
    "descriptor": "",
    "authors": [
      "Guanhong Tao",
      "Zhenting Wang",
      "Siyuan Cheng",
      "Shiqing Ma",
      "Shengwei An",
      "Yingqi Liu",
      "Guangyu Shen",
      "Zhuo Zhang",
      "Yunshu Mao",
      "Xiangyu Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15929"
  },
  {
    "id": "arXiv:2211.15931",
    "title": "Posterior Sampling for Continuing Environments",
    "abstract": "We develop an extension of posterior sampling for reinforcement learning\n(PSRL) that is suited for a continuing agent-environment interface and\nintegrates naturally into agent designs that scale to complex environments. The\napproach maintains a statistically plausible model of the environment and\nfollows a policy that maximizes expected $\\gamma$-discounted return in that\nmodel. At each time, with probability $1-\\gamma$, the model is replaced by a\nsample from the posterior distribution over environments. For a suitable\nschedule of $\\gamma$, we establish an $\\tilde{O}(\\tau S \\sqrt{A T})$ bound on\nthe Bayesian regret, where $S$ is the number of environment states, $A$ is the\nnumber of actions, and $\\tau$ denotes the reward averaging time, which is a\nbound on the duration required to accurately estimate the average reward of any\npolicy.",
    "descriptor": "",
    "authors": [
      "Wanqiao Xu",
      "Shi Dong",
      "Benjamin Van Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.15931"
  },
  {
    "id": "arXiv:2211.15933",
    "title": "Maximal Atomic irRedundant Sets: a Usage-based Dataflow Partitioning  Algorithm",
    "abstract": "Programs admitting a polyhedral representation can be transformed in many\nways for locality and parallelism, notably loop tiling. Data flow analysis can\nthen compute dependence relations between iterations and between tiles. When\ntiling is applied, certain iteration-wise dependences cross tile boundaries,\ncreating the need for inter-tile data communication. Previous work computes it\nas the flow-in and flow-out sets of iteration tiles.\nIn this paper, we propose a partitioning of the flow-out of a tile into the\nmaximal sets of iterations that are entirely consumed and incur no redundant\nstorage or transfer. The computation is described as an algorithm and performed\non a selection of polyhedral programs. We then suggest possible applications of\nthis decomposition in compression and memory allocation.",
    "descriptor": "\nComments: 8 pages, 5 figures, 1 table\n",
    "authors": [
      "Corentin Ferry",
      "Steven Derrien",
      "Sanjay Rajopadhye"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.15933"
  },
  {
    "id": "arXiv:2211.15936",
    "title": "Finding mixed-strategy equilibria of continuous-action games without  gradients using randomized policy networks",
    "abstract": "We study the problem of computing an approximate Nash equilibrium of\ncontinuous-action game without access to gradients. Such game access is common\nin reinforcement learning settings, where the environment is typically treated\nas a black box. To tackle this problem, we apply zeroth-order optimization\ntechniques that combine smoothed gradient estimators with equilibrium-finding\ndynamics. We model players' strategies using artificial neural networks. In\nparticular, we use randomized policy networks to model mixed strategies. These\ntake noise in addition to an observation as input and can flexibly represent\narbitrary observation-dependent, continuous-action distributions. Being able to\nmodel such mixed strategies is crucial for tackling continuous-action games\nthat lack pure-strategy equilibria. We evaluate the performance of our method\nusing an approximation of the Nash convergence metric from game theory, which\nmeasures how much players can benefit from unilaterally changing their\nstrategy. We apply our method to continuous Colonel Blotto games, single-item\nand multi-item auctions, and a visibility game. The experiments show that our\nmethod can quickly find high-quality approximate equilibria. Furthermore, they\nshow that the dimensionality of the input noise is crucial for performance. To\nour knowledge, this paper is the first to solve general continuous-action games\nwith unrestricted mixed strategies and without any gradient information.",
    "descriptor": "",
    "authors": [
      "Carlos Martin",
      "Tuomas Sandholm"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.15936"
  },
  {
    "id": "arXiv:2211.15937",
    "title": "Robustness Disparities in Face Detection",
    "abstract": "Facial analysis systems have been deployed by large companies and critiqued\nby scholars and activists for the past decade. Many existing algorithmic audits\nexamine the performance of these systems on later stage elements of facial\nanalysis systems like facial recognition and age, emotion, or perceived gender\nprediction; however, a core component to these systems has been vastly\nunderstudied from a fairness perspective: face detection, sometimes called face\nlocalization. Since face detection is a pre-requisite step in facial analysis\nsystems, the bias we observe in face detection will flow downstream to the\nother components like facial recognition and emotion prediction. Additionally,\nno prior work has focused on the robustness of these systems under various\nperturbations and corruptions, which leaves open the question of how various\npeople are impacted by these phenomena. We present the first of its kind\ndetailed benchmark of face detection systems, specifically examining the\nrobustness to noise of commercial and academic models. We use both standard and\nrecently released academic facial datasets to quantitatively analyze trends in\nface detection robustness. Across all the datasets and systems, we generally\nfind that photos of individuals who are $\\textit{masculine presenting}$,\n$\\textit{older}$, of $\\textit{darker skin type}$, or have $\\textit{dim\nlighting}$ are more susceptible to errors than their counterparts in other\nidentities.",
    "descriptor": "\nComments: NeurIPS Datasets & Benchmarks Track 2022\n",
    "authors": [
      "Samuel Dooley",
      "George Z. Wei",
      "Tom Goldstein",
      "John P. Dickerson"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15937"
  },
  {
    "id": "arXiv:2211.15940",
    "title": "PiggyBack: Pretrained Visual Question Answering Environment for Backing  up Non-deep Learning Professionals",
    "abstract": "We propose a PiggyBack, a Visual Question Answering platform that allows\nusers to apply the state-of-the-art visual-language pretrained models easily.\nThe PiggyBack supports the full stack of visual question answering tasks,\nspecifically data processing, model fine-tuning, and result visualisation. We\nintegrate visual-language models, pretrained by HuggingFace, an open-source API\nplatform of deep learning technologies; however, it cannot be runnable without\nprogramming skills or deep learning understanding. Hence, our PiggyBack\nsupports an easy-to-use browser-based user interface with several deep learning\nvisual language pretrained models for general users and domain experts. The\nPiggyBack includes the following benefits: Free availability under the MIT\nLicense, Portability due to web-based and thus runs on almost any platform, A\ncomprehensive data creation and processing technique, and ease of use on deep\nlearning-based visual language pretrained models. The demo video is available\non YouTube and can be found at https://youtu.be/iz44RZ1lF4s.",
    "descriptor": "\nComments: Accepted by WSDM 2023\n",
    "authors": [
      "Zhihao Zhang",
      "Siwen Luo",
      "Junyi Chen",
      "Sijia Lai",
      "Siqu Long",
      "Hyunsuk Chung",
      "Soyeon Caren Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15940"
  },
  {
    "id": "arXiv:2211.15941",
    "title": "When Quantum Information Technologies Meet Blockchain in Web 3.0",
    "abstract": "With the drive to create a decentralized digital economy, Web 3.0 has become\na cornerstone of digital transformation, developed on the basis of\ncomputing-force networking, distributed data storage, and blockchain. With the\nrapid realization of quantum devices, Web 3.0 is being developed in parallel\nwith the deployment of quantum cloud computing and quantum Internet. In this\nregard, quantum computing first disrupts the original cryptographic systems\nthat protect data security while reshaping modern cryptography with the\nadvantages of quantum computing and communication. Therefore, in this paper, we\nintroduce a quantum blockchain-driven Web 3.0 framework that provides\ninformation-theoretic security for decentralized data transferring and payment\ntransactions. First, we present the framework of quantum blockchain-driven Web\n3.0 with future-proof security during the transmission of data and transaction\ninformation. Next, we discuss the potential applications and challenges of\nimplementing quantum blockchain in Web 3.0. Finally, we describe a use case for\nquantum non-fungible tokens (NFTs) and propose a quantum deep learning-based\noptimal auction for NFT trading to maximize the achievable revenue for\nsufficient liquidity in Web 3.0. In this way, the proposed framework can\nachieve proven security and sustainability for the next-generation\ndecentralized digital society.",
    "descriptor": "",
    "authors": [
      "Minrui Xu",
      "Xiaoxu Ren",
      "Dusit Niyato",
      "Jiawen Kang",
      "Chao Qiu",
      "Zehui Xiong",
      "Xiaofei Wang",
      "Victor C. M. Leung"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15941"
  },
  {
    "id": "arXiv:2211.15944",
    "title": "The Surprising Effectiveness of Latent World Models for Continual  Reinforcement Learning",
    "abstract": "We study the use of model-based reinforcement learning methods, in\nparticular, world models for continual reinforcement learning. In continual\nreinforcement learning, an agent is required to solve one task and then another\nsequentially while retaining performance and preventing forgetting on past\ntasks. World models offer a task-agnostic solution: they do not require\nknowledge of task changes. World models are a straight-forward baseline for\ncontinual reinforcement learning for three main reasons. Firstly, forgetting in\nthe world model is prevented by persisting existing experience replay buffers\nacross tasks, experience from previous tasks is replayed for learning the world\nmodel. Secondly, they are sample efficient. Thirdly and finally, they offer a\ntask-agnostic exploration strategy through the uncertainty in the trajectories\ngenerated by the world model. We show that world models are a simple and\neffective continual reinforcement learning baseline. We study their\neffectiveness on Minigrid and Minihack continual reinforcement learning\nbenchmarks and show that it outperforms state of the art task-agnostic\ncontinual reinforcement learning methods.",
    "descriptor": "\nComments: 13 pages, 6 figures, accepted at the Deep RL workshop NeurIPS 22\n",
    "authors": [
      "Samuel Kessler",
      "Piotr Mi\u0142o\u015b",
      "Jack Parker-Holder",
      "Stephen J. Roberts"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15944"
  },
  {
    "id": "arXiv:2211.15945",
    "title": "Quantum Speed-ups for String Synchronizing Sets, Longest Common  Substring, and k-mismatch Matching",
    "abstract": "Longest Common Substring (LCS) is an important text processing problem, which\nhas recently been investigated in the quantum query model. The decisional\nversion of this problem, LCS with threshold $d$, asks whether two length-$n$\ninput strings have a common substring of length $d$. The two extreme cases,\n$d=1$ and $d=n$, correspond respectively to Element Distinctness and\nUnstructured Search, two fundamental problems in quantum query complexity.\nHowever, the intermediate case $1\\ll d\\ll n$ was not fully understood. We show\nthat the complexity of LCS with threshold $d$ smoothly interpolates between the\ntwo extreme cases up to $n^{o(1)}$ factors: LCS with threshold $d$ has a\nquantum algorithm in $n^{2/3+o(1)}/d^{1/6}$ query complexity and time\ncomplexity, and requires at least $\\Omega(n^{2/3}/d^{1/6})$ quantum query\ncomplexity. Our result improves upon previous upper bounds $\\tilde O(\\min\n\\{n/d^{1/2}, n^{2/3}\\})$ (Le Gall and Seddighin ITCS 2022, Akmal and Jin SODA\n2022), and answers an open question of Akmal and Jin.\nOur main technical contribution is a quantum speed-up of the powerful String\nSynchronizing Set technique introduced by Kempa and Kociumaka (STOC 2019). It\nconsistently samples $n/\\tau^{1-o(1)}$ synchronizing positions in the string\ndepending on their length-$\\Theta(\\tau)$ contexts, and each synchronizing\nposition can be reported by a quantum algorithm in $\\tilde O(\\tau^{1/2+o(1)})$\ntime.\nAs another application of our quantum string synchronizing set, we study the\n$k$-mismatch Matching problem, which asks if the pattern has an occurrence in\nthe text with at most $k$ Hamming mismatches. Using a structural result of\nCharalampopoulos, Kociumaka, and Wellnitz (FOCS 2020), we obtain a quantum\nalgorithm for $k$-mismatch matching with $k^{3/4} n^{1/2+o(1)}$ query\ncomplexity and $\\tilde O(kn^{1/2})$ time complexity.",
    "descriptor": "\nComments: SODA 2023. Abstract shortened to meet arXiv requirements\n",
    "authors": [
      "Ce Jin",
      "Jakob Nogler"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.15945"
  },
  {
    "id": "arXiv:2211.15948",
    "title": "Neural Vocoder Feature Estimation for Dry Singing Voice Separation",
    "abstract": "Singing voice separation (SVS) is a task that separates singing voice audio\nfrom its mixture with instrumental audio. Previous SVS studies have mainly\nemployed the spectrogram masking method which requires a large dimensionality\nin predicting the binary masks. In addition, they focused on extracting a vocal\nstem that retains the wet sound with the reverberation effect. This result may\nhinder the reusability of the isolated singing voice. This paper addresses the\nissues by predicting mel-spectrogram of dry singing voices from the mixed audio\nas neural vocoder features and synthesizing the singing voice waveforms from\nthe neural vocoder. We experimented with two separation methods. One is\npredicting binary masks in the mel-spectrogram domain and the other is directly\npredicting the mel-spectrogram. Furthermore, we add a singing voice detector to\nidentify the singing voice segments over time more explicitly. We measured the\nmodel performance in terms of audio, dereverberation, separation, and overall\nquality. The results show that our proposed model outperforms state-of-the-art\nsinging voice separation models in both objective and subjective evaluation\nexcept the audio quality.",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Jaekwon Im",
      "Soonbeom Choi",
      "Sangeon Yong",
      "Juhan Nam"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.15948"
  },
  {
    "id": "arXiv:2211.15951",
    "title": "Feature-based Adaptive Contrastive Distillation for Efficient Single  Image Super-Resolution",
    "abstract": "Convolution Neural Networks (CNNs) have been used in various fields and are\nshowing demonstrated excellent performance, especially in Single-Image Super\nResolution (SISR). However, recently, CNN-based SISR has numerous parameters\nand computational costs for obtaining better performance. As one of the methods\nto make the network efficient, Knowledge Distillation (KD) which optimizes the\nperformance trade-off by adding a loss term to the existing network\narchitecture is currently being studied. KD for SISR is mainly proposed as a\nfeature distillation (FD) to minimize L1-distance loss of feature maps between\nteacher and student networks, but it does not fully take into account the\namount and importance of information that the student can accept. In this\npaper, we propose a feature-based adaptive contrastive distillation (FACD)\nmethod for efficiently training lightweight SISR networks. We show the\nlimitations of the existing feature-distillation (FD) with L1-distance loss,\nand propose a feature-based contrastive loss that maximizes the mutual\ninformation between the feature maps of the teacher and student networks. The\nexperimental results show that the proposed FACD improves not only the PSNR\nperformance of the entire benchmark datasets and scales but also the subjective\nimage quality compared to the conventional FD approach.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "HyeonCheol Moon",
      "JinWoo Jeong",
      "SungJei Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.15951"
  },
  {
    "id": "arXiv:2211.15953",
    "title": "A Decentralized Framework for Kernel PCA with Projection Consensus  Constraints",
    "abstract": "This paper studies kernel PCA in a decentralized setting, where data are\ndistributively observed with full features in local nodes and a fusion center\nis prohibited. Compared with linear PCA, the use of kernel brings challenges to\nthe design of decentralized consensus optimization: the local projection\ndirections are data-dependent. As a result, the consensus constraint in\ndistributed linear PCA is no longer valid. To overcome this problem, we propose\na projection consensus constraint and obtain an effective decentralized\nconsensus framework, where local solutions are expected to be the projection of\nthe global solution on the column space of local dataset. We also derive a\nfully non-parametric, fast and convergent algorithm based on alternative\ndirection method of multiplier, of which each iteration is analytic and\ncommunication-effcient. Experiments on a truly parallel architecture are\nconducted on real-world data, showing that the proposed decentralized algorithm\nis effective to utilize information of other nodes and takes great advantages\nin running time over the central kernel PCA.",
    "descriptor": "",
    "authors": [
      "Fan He",
      "Ruikai Yang",
      "Lei Shi",
      "Xiaolin Huang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.15953"
  },
  {
    "id": "arXiv:2211.15955",
    "title": "Generalized Face Anti-Spoofing via Multi-Task Learning and One-Side Meta  Triplet Loss",
    "abstract": "With the increasing variations of face presentation attacks, model\ngeneralization becomes an essential challenge for a practical face\nanti-spoofing system. This paper presents a generalized face anti-spoofing\nframework that consists of three tasks: depth estimation, face parsing, and\nlive/spoof classification. With the pixel-wise supervision from the face\nparsing and depth estimation tasks, the regularized features can better\ndistinguish spoof faces. While simulating domain shift with meta-learning\ntechniques, the proposed one-side triplet loss can further improve the\ngeneralization capability by a large margin. Extensive experiments on four\npublic datasets demonstrate that the proposed framework and training strategies\nare more effective than previous works for model generalization to unseen\ndomains.",
    "descriptor": "\nComments: 2023 IEEE International Conference on Automatic Face and Gesture Recognition (FG)\n",
    "authors": [
      "Chu-Chun Chuang",
      "Chien-Yi Wang",
      "Shang-Hong Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15955"
  },
  {
    "id": "arXiv:2211.15956",
    "title": "Offline Reinforcement Learning with Closed-Form Policy Improvement  Operators",
    "abstract": "Behavior constrained policy optimization has been demonstrated to be a\nsuccessful paradigm for tackling Offline Reinforcement Learning. By exploiting\nhistorical transitions, a policy is trained to maximize a learned value\nfunction while constrained by the behavior policy to avoid a significant\ndistributional shift. In this paper, we propose our closed-form policy\nimprovement operators. We make a novel observation that the behavior constraint\nnaturally motivates the use of first-order Taylor approximation, leading to a\nlinear approximation of the policy objective. Additionally, as practical\ndatasets are usually collected by heterogeneous policies, we model the behavior\npolicies as a Gaussian Mixture and overcome the induced optimization\ndifficulties by leveraging the LogSumExp's lower bound and Jensen's Inequality,\ngiving rise to a closed-form policy improvement operator. We instantiate\noffline RL algorithms with our novel policy improvement operators and\nempirically demonstrate their effectiveness over state-of-the-art algorithms on\nthe standard D4RL benchmark.",
    "descriptor": "",
    "authors": [
      "Jiachen Li",
      "Edwin Zhang",
      "Ming Yin",
      "Qinxun Bai",
      "Yu-Xiang Wang",
      "William Yang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15956"
  },
  {
    "id": "arXiv:2211.15957",
    "title": "Advisory Tool for Managing Failure Cascades in Systems with Wind Power",
    "abstract": "This paper concerns the resilience of systems with wind power upon wind\nreduction by evaluating the potential of corrective actions, such as generation\nand load dispatch, on minimizing the effects of transmission line failures.\nThree functions (grid, consumer-centric loss, and resilience impact) are used\nto statistically evaluate the criticality of initial contingent failures and\nwind reductions. Our model is learned with Monte Carlo, convex optimization,\nand adaptive selection, illustrated on the IEEE-30 and IEEE-300 bus systems\nwith both AC and DC models. We highlight the impact of wind reductions and\npropose physically implementable solutions.",
    "descriptor": "\nComments: Preprint. Submitted to the 2023 IEEE Power & Energy Society General Meeting (GM). arXiv admin note: substantial text overlap with arXiv:2211.01442\n",
    "authors": [
      "Siyu Liu",
      "Marija Ilic"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.15957"
  },
  {
    "id": "arXiv:2211.15959",
    "title": "Enabling Personalized Video Quality Optimization with VidHoc",
    "abstract": "The emerging video applications greatly increase the demand in network\nbandwidth that is not easy to scale. To provide higher quality of experience\n(QoE) under limited bandwidth, a recent trend is to leverage the heterogeneity\nof quality preferences across individual users. Although these efforts have\nsuggested the great potential benefits, service providers still have not\ndeployed them to realize the promised QoE improvement. The missing piece is an\nautomation of online per-user QoE modeling and optimization scheme for new\nusers. Previous efforts either optimize QoE by known per-user QoE models or\nlearn a user's QoE model by offline approaches, such as analysis of video\nviewing history and in-lab user study. Relying on such offline modeling is\nproblematic, because QoE optimization will start late for collecting enough\ndata to train an unbiased QoE model. In this paper, we propose VidHoc, the\nfirst automatic system that jointly personalizes QoE model and optimizes QoE in\nan online manner for each new user. VidHoc can build per-user QoE models within\na small number of video sessions as well as maintain good QoE. We evaluate\nVidHoc in a pilot deployment to fifteen users for four months with the care of\nstatistical validity. Compared with other baselines, the results show that\nVidHoc can save 17.3% bandwidth while maintaining the same QoE or improve QoE\nby 13.9% with the same bandwidth.",
    "descriptor": "",
    "authors": [
      "Xu Zhang",
      "Paul Schmitt",
      "Marshini Chetty",
      "Nick Feamster",
      "Junchen Jiang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.15959"
  },
  {
    "id": "arXiv:2211.15960",
    "title": "Fourier Continuation for Exact Derivative Computation in  Physics-Informed Neural Operators",
    "abstract": "The physics-informed neural operator (PINO) is a machine learning\narchitecture that has shown promising empirical results for learning partial\ndifferential equations. PINO uses the Fourier neural operator (FNO)\narchitecture to overcome the optimization challenges often faced by\nphysics-informed neural networks. Since the convolution operator in PINO uses\nthe Fourier series representation, its gradient can be computed exactly on the\nFourier space. While Fourier series cannot represent nonperiodic functions,\nPINO and FNO still have the expressivity to learn nonperiodic problems with\nFourier extension via padding. However, computing the Fourier extension in the\nphysics-informed optimization requires solving an ill-conditioned system,\nresulting in inaccurate derivatives which prevent effective optimization. In\nthis work, we present an architecture that leverages Fourier continuation (FC)\nto apply the exact gradient method to PINO for nonperiodic problems. This paper\ninvestigates three different ways that FC can be incorporated into PINO by\ntesting their performance on a 1D blowup problem. Experiments show that FC-PINO\noutperforms padded PINO, improving equation loss by several orders of\nmagnitude, and it can accurately capture the third order derivatives of\nnonsmooth solution functions.",
    "descriptor": "",
    "authors": [
      "Haydn Maust",
      "Zongyi Li",
      "Yixuan Wang",
      "Daniel Leibovici",
      "Oscar Bruno",
      "Thomas Hou",
      "Anima Anandkumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15960"
  },
  {
    "id": "arXiv:2211.15961",
    "title": "Balanced Semi-Supervised Generative Adversarial Network for Damage  Assessment from Low-Data Imbalanced-Class Regime",
    "abstract": "In recent years, applying deep learning (DL) to assess structural damages has\ngained growing popularity in vision-based structural health monitoring (SHM).\nHowever, both data deficiency and class-imbalance hinder the wide adoption of\nDL in practical applications of SHM. Common mitigation strategies include\ntransfer learning, over-sampling, and under-sampling, yet these ad-hoc methods\nonly provide limited performance boost that varies from one case to another. In\nthis work, we introduce one variant of the Generative Adversarial Network\n(GAN), named the balanced semi-supervised GAN (BSS-GAN). It adopts the\nsemi-supervised learning concept and applies balanced-batch sampling in\ntraining to resolve low-data and imbalanced-class problems. A series of\ncomputer experiments on concrete cracking and spalling classification were\nconducted under the low-data imbalanced-class regime with limited computing\npower. The results show that the BSS-GAN is able to achieve better damage\ndetection in terms of recall and $F_\\beta$ score than other conventional\nmethods, indicating its state-of-the-art performance.",
    "descriptor": "",
    "authors": [
      "Yuqing Gao",
      "Pengyuan Zhai",
      "Khalid M. Mosalam"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.15961"
  },
  {
    "id": "arXiv:2211.15965",
    "title": "Extending the Subwording Model of Multilingual Pretrained Models for New  Languages",
    "abstract": "Multilingual pretrained models are effective for machine translation and\ncross-lingual processing because they contain multiple languages in one model.\nHowever, they are pretrained after their tokenizers are fixed; therefore it is\ndifficult to change the vocabulary after pretraining. When we extend the\npretrained models to new languages, we must modify the tokenizers\nsimultaneously. In this paper, we add new subwords to the SentencePiece\ntokenizer to apply a multilingual pretrained model to new languages (Inuktitut\nin this paper). In our experiments, we segmented Inuktitut sentences into\nsubwords without changing the segmentation of already pretrained languages, and\napplied the mBART-50 pretrained model to English-Inuktitut translation.",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Kenji Imamura",
      "Eiichiro Sumita"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15965"
  },
  {
    "id": "arXiv:2211.15969",
    "title": "Isolation and Impartial Aggregation: A Paradigm of Incremental Learning  without Interference",
    "abstract": "This paper focuses on the prevalent performance imbalance in the stages of\nincremental learning. To avoid obvious stage learning bottlenecks, we propose a\nbrand-new stage-isolation based incremental learning framework, which leverages\na series of stage-isolated classifiers to perform the learning task of each\nstage without the interference of others. To be concrete, to aggregate multiple\nstage classifiers as a uniform one impartially, we first introduce a\ntemperature-controlled energy metric for indicating the confidence score levels\nof the stage classifiers. We then propose an anchor-based energy\nself-normalization strategy to ensure the stage classifiers work at the same\nenergy level. Finally, we design a voting-based inference augmentation strategy\nfor robust inference. The proposed method is rehearsal free and can work for\nalmost all continual learning scenarios. We evaluate the proposed method on\nfour large benchmarks. Extensive results demonstrate the superiority of the\nproposed method in setting up new state-of-the-art overall performance.\n\\emph{Code is available at} \\url{https://github.com/iamwangyabin/ESN}.",
    "descriptor": "\nComments: This is the accepted version of the Paper & Supp to appear in AAAI 2023. Please cite the final published version. Code is available at this https URL\n",
    "authors": [
      "Yabin Wang",
      "Zhiheng Ma",
      "Zhiwu Huang",
      "Yaowei Wang",
      "Zhou Su",
      "Xiaopeng Hong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15969"
  },
  {
    "id": "arXiv:2211.15971",
    "title": "Democratizing Machine Learning for Interdisciplinary Scholars: Report on  Organizing the NLP+CSS Online Tutorial Series",
    "abstract": "Many scientific fields -- including biology, health, education, and the\nsocial sciences -- use machine learning (ML) to help them analyze data at an\nunprecedented scale. However, ML researchers who develop advanced methods\nrarely provide detailed tutorials showing how to apply these methods. Existing\ntutorials are often costly to participants, presume extensive programming\nknowledge, and are not tailored to specific application fields. In an attempt\nto democratize ML methods, we organized a year-long, free, online tutorial\nseries targeted at teaching advanced natural language processing (NLP) methods\nto computational social science (CSS) scholars. Two organizers worked with\nfifteen subject matter experts to develop one-hour presentations with hands-on\nPython code for a range of ML methods and use cases, from data pre-processing\nto analyzing temporal variation of language change. Although live participation\nwas more limited than expected, a comparison of pre- and post-tutorial surveys\nshowed an increase in participants' perceived knowledge of almost one point on\na 7-point Likert scale. Furthermore, participants asked thoughtful questions\nduring tutorials and engaged readily with tutorial content afterwards, as\ndemonstrated by 10K~total views of posted tutorial recordings. In this report,\nwe summarize our organizational efforts and distill five principles for\ndemocratizing ML+X tutorials. We hope future organizers improve upon these\nprinciples and continue to lower barriers to developing ML skills for\nresearchers of all fields.",
    "descriptor": "",
    "authors": [
      "Ian Stewart",
      "Katherine Keith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15971"
  },
  {
    "id": "arXiv:2211.15974",
    "title": "Neural Speech Phase Prediction based on Parallel Estimation Architecture  and Anti-Wrapping Losses",
    "abstract": "This paper presents a novel speech phase prediction model which predicts\nwrapped phase spectra directly from amplitude spectra by neural networks. The\nproposed model is a cascade of a residual convolutional network and a parallel\nestimation architecture. The parallel estimation architecture is composed of\ntwo parallel linear convolutional layers and a phase calculation formula,\nimitating the process of calculating the phase spectra from the real and\nimaginary parts of complex spectra and strictly restricting the predicted phase\nvalues to the principal value interval. To avoid the error expansion issue\ncaused by phase wrapping, we design anti-wrapping training losses defined\nbetween the predicted wrapped phase spectra and natural ones by activating the\ninstantaneous phase error, group delay error and instantaneous angular\nfrequency error using an anti-wrapping function. Experimental results show that\nour proposed neural speech phase prediction model outperforms the iterative\nGriffin-Lim algorithm and other neural network-based method, in terms of both\nreconstructed speech quality and generation speed.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Yang Ai",
      "Zhen-Hua Ling"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.15974"
  },
  {
    "id": "arXiv:2211.15975",
    "title": "Analyzing Infrastructure LiDAR Placement with Realistic LiDAR",
    "abstract": "Recently, Vehicle-to-Everything(V2X) cooperative perception has attracted\nincreasing attention. Infrastructure sensors play a critical role in this\nresearch field, however, how to find the optimal placement of infrastructure\nsensors is rarely studied. In this paper, we investigate the problem of\ninfrastructure sensor placement and propose a pipeline that can efficiently and\neffectively find optimal installation positions for infrastructure sensors in a\nrealistic simulated environment. To better simulate and evaluate LiDAR\nplacement, we establish a Realistic LiDAR Simulation library that can simulate\nthe unique characteristics of different popular LiDARs and produce\nhigh-fidelity LiDAR point clouds in the CARLA simulator. Through simulating\npoint cloud data in different LiDAR placements, we can evaluate the perception\naccuracy of these placements using multiple detection models. Then, we analyze\nthe correlation between the point cloud distribution and perception accuracy by\ncalculating the density and uniformity of regions of interest. Experiments show\nthat the placement of infrastructure LiDAR can heavily affect the accuracy of\nperception. We also analyze the correlation between perception performance in\nthe region of interest and LiDAR point cloud distribution and validate that\ndensity and uniformity can be indicators of performance.",
    "descriptor": "\nComments: 7 pages, 6 figures\n",
    "authors": [
      "Xinyu Cai",
      "Wentao Jiang",
      "Runsheng Xu",
      "Wenquan Zhao",
      "Jiaqi Ma",
      "Si Liu",
      "Yikang Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15975"
  },
  {
    "id": "arXiv:2211.15977",
    "title": "One is All: Bridging the Gap Between Neural Radiance Fields  Architectures with Progressive Volume Distillation",
    "abstract": "Neural Radiance Fields (NeRF) methods have proved effective as compact,\nhigh-quality and versatile representations for 3D scenes, and enable downstream\ntasks such as editing, retrieval, navigation, etc. Various neural architectures\nare vying for the core structure of NeRF, including the plain Multi-Layer\nPerceptron (MLP), sparse tensors, low-rank tensors, hashtables and their\ncompositions. Each of these representations has its particular set of\ntrade-offs. For example, the hashtable-based representations admit faster\ntraining and rendering but their lack of clear geometric meaning hampers\ndownstream tasks like spatial-relation-aware editing. In this paper, we propose\nProgressive Volume Distillation (PVD), a systematic distillation method that\nallows any-to-any conversions between different architectures, including MLP,\nsparse or low-rank tensors, hashtables and their compositions. PVD consequently\nempowers downstream applications to optimally adapt the neural representations\nfor the task at hand in a post hoc fashion. The conversions are fast, as\ndistillation is progressively performed on different levels of volume\nrepresentations, from shallower to deeper. We also employ special treatment of\ndensity to deal with its specific numerical instability problem. Empirical\nevidence is presented to validate our method on the NeRF-Synthetic, LLFF and\nTanksAndTemples datasets. For example, with PVD, an MLP-based NeRF model can be\ndistilled from a hashtable-based Instant-NGP model at a 10X~20X faster speed\nthan being trained the original NeRF from scratch, while achieving a superior\nlevel of synthesis quality. Code is available at\nhttps://github.com/megvii-research/AAAI2023-PVD.",
    "descriptor": "\nComments: Accepted by AAAI2023. Project Page: this http URL\n",
    "authors": [
      "Shuangkang Fang",
      "Weixin Xu",
      "Heng Wang",
      "Yi Yang",
      "Yufeng Wang",
      "Shuchang Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15977"
  },
  {
    "id": "arXiv:2211.15980",
    "title": "End-to-End Neural Discourse Deixis Resolution in Dialogue",
    "abstract": "We adapt Lee et al.'s (2018) span-based entity coreference model to the task\nof end-to-end discourse deixis resolution in dialogue, specifically by\nproposing extensions to their model that exploit task-specific characteristics.\nThe resulting model, dd-utt, achieves state-of-the-art results on the four\ndatasets in the CODI-CRAC 2021 shared task.",
    "descriptor": "\nComments: Accepted as a long paper to EMNLP 2022\n",
    "authors": [
      "Shengjie Li",
      "Vincent Ng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15980"
  },
  {
    "id": "arXiv:2211.15987",
    "title": "Towards Generalized Open Information Extraction",
    "abstract": "Open Information Extraction (OpenIE) facilitates the open-domain discovery of\ntextual facts. However, the prevailing solutions evaluate OpenIE models on\nin-domain test sets aside from the training corpus, which certainly violates\nthe initial task principle of domain-independence. In this paper, we propose to\nadvance OpenIE towards a more realistic scenario: generalizing over unseen\ntarget domains with different data distributions from the source training\ndomains, termed Generalized OpenIE. For this purpose, we first introduce GLOBE,\na large-scale human-annotated multi-domain OpenIE benchmark, to examine the\nrobustness of recent OpenIE models to domain shifts, and the relative\nperformance degradation of up to 70% implies the challenges of generalized\nOpenIE. Then, we propose DragonIE, which explores a minimalist graph expression\nof textual fact: directed acyclic graph, to improve the OpenIE generalization.\nExtensive experiments demonstrate that DragonIE beats the previous methods in\nboth in-domain and out-of-domain settings by as much as 6.0% in F1 score\nabsolutely, but there is still ample room for improvement.",
    "descriptor": "\nComments: EMNLP 2022\n",
    "authors": [
      "Bowen Yu",
      "Zhenyu Zhang",
      "Jingyang Li",
      "Haiyang Yu",
      "Tingwen Liu",
      "Jian Sun",
      "Yongbin Li",
      "Bin Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15987"
  },
  {
    "id": "arXiv:2211.15988",
    "title": "Characterizing Engagement Dynamics across Topics on Facebook",
    "abstract": "Social media platforms heavily changed how users consume and digest\ninformation and, thus, how the popularity of topics evolves. In this paper, we\nexplore the interplay between the virality of controversial topics and how they\nmay trigger heated discussions and eventually increase users' polarization. We\nperform a quantitative analysis on Facebook by collecting $\\sim57M$ posts from\n$\\sim2M$ pages and groups between 2018 and 2022, focusing on engaging topics\ninvolving scandals, tragedies, and social and political issues. Using logistic\nfunctions, we quantitatively assess the evolution of these topics finding\nsimilar patterns in their engagement dynamics. Finally, we show that initial\nburstiness may predict the rise of users' future adverse reactions regardless\nof the discussed topic.",
    "descriptor": "",
    "authors": [
      "Gabriele Etta",
      "Emanuele Sangiorgio",
      "Niccol\u00f2 Di Marco",
      "Michele Avalle",
      "Antonio Scala",
      "Matteo Cinelli",
      "Walter Quattrociocchi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.15988"
  },
  {
    "id": "arXiv:2211.15990",
    "title": "Optimal Beam Training for mmWave Massive MIMO using 802.11ay",
    "abstract": "Beam training of 802.11 ad is a technology that helps accelerate the analog\nweighting vector (AWV) selection process under the constraint of the existing\ncode-book for AWV. However, 5G milli-meter wave (mmWave)\nmultiple-input-multiple-output (MIMO) system brings challenges to this new\ntechnology due to the higher order of complexity of antennae. Hence, the\nexisting codebook of 11ad is unlikely to even include the near-optimal AWV and\nthe data rate will degrade severely. To cope with this situation, this paper\nproposed a new beam training protocol combined with the state-of-the-art\ncompressed sensing channel estimation in order to find the AWV to maximize the\noptimal data-rate. Simulation is implemented to show the data-rate of AWV\nachieved by 11 ad is worse than the proposed protocol.",
    "descriptor": "",
    "authors": [
      "Lyutianyang Zhang",
      "Sumit Roy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.15990"
  },
  {
    "id": "arXiv:2211.15992",
    "title": "MoDA: Map style transfer for self-supervised Domain Adaptation of  embodied agents",
    "abstract": "We propose a domain adaptation method, MoDA, which adapts a pretrained\nembodied agent to a new, noisy environment without ground-truth supervision.\nMap-based memory provides important contextual information for visual\nnavigation, and exhibits unique spatial structure mainly composed of flat walls\nand rectangular obstacles. Our adaptation approach encourages the inherent\nregularities on the estimated maps to guide the agent to overcome the prevalent\ndomain discrepancy in a novel environment. Specifically, we propose an\nefficient learning curriculum to handle the visual and dynamics corruptions in\nan online manner, self-supervised with pseudo clean maps generated by style\ntransfer networks. Because the map-based representation provides spatial\nknowledge for the agent's policy, our formulation can deploy the pretrained\npolicy networks from simulators in a new setting. We evaluate MoDA in various\npractical scenarios and show that our proposed method quickly enhances the\nagent's performance in downstream tasks including localization, mapping,\nexploration, and point-goal navigation.",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Eun Sun Lee",
      "Junho Kim",
      "SangWon Park",
      "Young Min Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15992"
  },
  {
    "id": "arXiv:2211.15993",
    "title": "An Empirical Study on Snapshot DAOs",
    "abstract": "Decentralized Autonomous Organization (DAO) is an organization constructed by\nautomatically executed rules such as via smart contracts, holding features of\nthe permissionless committee, transparent proposals, and fair contribution by\nstakeholders. As of Nov 2022, DAO has impacted over \\$11.2B market caps.\nHowever, there are no substantial studies focused on this emerging field. To\nfill the gap, we start from the ground truth by empirically studying the\nbreadth and depth of the DAO markets in mainstream public chain ecosystems in\nthis paper. We dive into the most widely adoptable DAO launchpad,\n\\textit{Snapshot}, which covers 95\\% in the wild DAO projects for data\ncollection and analysis. By integrating extensive enrolled DAOs and\ncorresponding data measurements, we explore statistical data from Snapshot and\ntry to demystify its undiscovered truths by delivering a series of summarised\ninsights. We also present DAO status, patterns, distribution, and trends. To\nour knowledge, this is the first empirical study putting concentration on DAO\nspaces.",
    "descriptor": "",
    "authors": [
      "Qin Wang",
      "Guangsheng Yu",
      "Yilin Sai",
      "Caijun Sun",
      "Lam Duc Nguyen",
      "Sherry Xu",
      "Shiping Chen"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.15993"
  },
  {
    "id": "arXiv:2211.15999",
    "title": "Impact of Automatic Image Classification and Blind Deconvolution in  Improving Text Detection Performance of the CRAFT Algorithm",
    "abstract": "Text detection in natural scenes has been a significant and active research\nsubject in computer vision and document analysis because of its wide range of\napplications as evidenced by the emergence of the Robust Reading Competition.\nOne of the algorithms which has good text detection performance in the said\ncompetition is the Character Region Awareness for Text Detection (CRAFT).\nEmploying the ICDAR 2013 dataset, this study investigates the impact of\nautomatic image classification and blind deconvolution as image pre-processing\nsteps to further enhance the text detection performance of CRAFT. The proposed\ntechnique automatically classifies the scene images into two categories, blurry\nand non-blurry, by utilizing of a Laplacian operator with 100 as threshold.\nPrior to applying the CRAFT algorithm, images that are categorized as blurry\nare further pre-processed using blind deconvolution to reduce the blur. The\nresults revealed that the proposed method significantly enhanced the detection\nperformance of CRAFT, as demonstrated by its IoU h-mean of 94.47% compared to\nthe original 91.42% h-mean of CRAFT and this even outperformed the top-ranked\nSenseTime, whose h-mean is 93.62%.",
    "descriptor": "\nComments: 18 pages, 7 figures, 3rd International Conference on Machine Learning Techniques and Data Science\n",
    "authors": [
      "Clarisa V. Albarillo",
      "Proceso L. Fernandez Jr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15999"
  },
  {
    "id": "arXiv:2211.16000",
    "title": "Asymptotic consistency of the WSINDy algorithm in the limit of continuum  data",
    "abstract": "In this work we study the asymptotic consistency of the weak-form sparse\nidentification of nonlinear dynamics algorithm (WSINDy) in the identification\nof differential equations from noisy samples of solutions. We prove that the\nWSINDy estimator is unconditionally asymptotically consistent for a wide class\nof models which includes the Navier-Stokes equations and the\nKuramoto-Sivashinsky equation. We thus provide a mathematically rigorous\nexplanation for the observed robustness to noise of weak-form equation\nlearning. Conversely, we also show that in general the WSINDy estimator is only\nconditionally asymptotically consistent, yielding discovery of spurious terms\nwith probability one if the noise level is above some critical threshold and\nthe nonlinearities exhibit sufficiently fast growth. We derive explicit bounds\non the critical noise threshold in the case of Gaussian white noise and provide\nan explicit characterization of these spurious terms in the case of\ntrigonometric and/or polynomial model nonlinearities. However, a silver lining\nto this negative result is that if the data is suitably denoised (a simple\nmoving average filter is sufficient), then we recover unconditional asymptotic\nconsistency on the class of models with locally-Lipschitz nonlinearities.\nAltogether, our results reveal several important aspects of weak-form equation\nlearning which may be used to improve future algorithms. We demonstrate our\nresults numerically using the Lorenz system, the cubic oscillator, a viscous\nBurgers growth model, and a Kuramoto-Sivashinsky-type higher-order PDE.",
    "descriptor": "",
    "authors": [
      "Daniel A. Messenger",
      "David M. Bortz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.16000"
  },
  {
    "id": "arXiv:2211.16001",
    "title": "A two-scale solver for linear elasticity problems in the context of  parallel message passing",
    "abstract": "This paper pushes further the intrinsic capabilities of the GFEM$^{gl}$\nglobal-local approach introduced initially in [1]. We develop a distributed\ncomputing approach using MPI (Message Passing Interface) both for the global\nand local problems. Regarding local problems, a specific scheduling strategy is\nintroduced. Then, to measure correctly the convergence of the iterative\nprocess, we introduce a reference solution that revisits the product of\nclassical and enriched functions. As a consequence, we are able to propose a\npurely matrix-based implementation of the global-local problem. The distributed\napproach is then compared to other parallel solvers either direct or iterative\nwith domain decomposition. The comparison addresses the scalability as well as\nthe elapsed time. Numerical examples deal with linear elastic problems: a\npolynomial exact solution problem, a complex micro-structure, and, finally, a\npull-out test (with different crack extent).\n1: C. A. Duarte, D.-J. Kim, and I. Babu\\v{s}ka. A global-local approach for\nthe construction of enrichment functions for the generalized fem and its\napplication to three-dimensional cracks. In Advances in Meshfree Techniques,\nDordrecht, 2007. Springer",
    "descriptor": "\nComments: Under submition to Computer Methods in Applied Mechanics and Engineering\n",
    "authors": [
      "Alexis Salzman",
      "Nicolas Mo\u00ebs"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.16001"
  },
  {
    "id": "arXiv:2211.16002",
    "title": "DiffG-RL: Leveraging Difference between State and Common Sense",
    "abstract": "Taking into account background knowledge as the context has always been an\nimportant part of solving tasks that involve natural language. One\nrepresentative example of such tasks is text-based games, where players need to\nmake decisions based on both description text previously shown in the game, and\ntheir own background knowledge about the language and common sense. In this\nwork, we investigate not simply giving common sense, as can be seen in prior\nresearch, but also its effective usage. We assume that a part of the\nenvironment states different from common sense should constitute one of the\ngrounds for action selection. We propose a novel agent, DiffG-RL, which\nconstructs a Difference Graph that organizes the environment states and common\nsense by means of interactive objects with a dedicated graph encoder. DiffG-RL\nalso contains a framework for extracting the appropriate amount and\nrepresentation of common sense from the source to support the construction of\nthe graph. We validate DiffG-RL in experiments with text-based games that\nrequire common sense and show that it outperforms baselines by 17% of scores.\nThe code is available at https://github.com/ibm/diffg-rl",
    "descriptor": "\nComments: Findings of EMNLP 2022. Code available at: this https URL\n",
    "authors": [
      "Tsunehiko Tanaka",
      "Daiki Kimura",
      "Michiaki Tatsubori"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16002"
  },
  {
    "id": "arXiv:2211.16005",
    "title": "Convex Relaxations for Isometric and Equiareal NRSfM",
    "abstract": "Extensible objects form a challenging case for NRSfM, owing to the lack of a\nsufficiently constrained extensible model of the point-cloud. We tackle the\nchallenge by proposing 1) convex relaxations of the isometric model up to\nquasi-isometry, and 2) convex relaxations involving the equiareal deformation\nmodel, which preserves local area and has not been used in NRSfM. The equiareal\nmodel is appealing because it is physically plausible and widely applicable.\nHowever, it has two main difficulties: first, when used on its own, it is\nambiguous, and second, it involves quartic, hence highly nonconvex,\nconstraints. Our approach handles the first difficulty by mixing the equiareal\nwith the isometric model and the second difficulty by new convex relaxations.\nWe validate our methods on multiple real and synthetic data, including\nwell-known benchmarks.",
    "descriptor": "",
    "authors": [
      "Agniva Sengupta",
      "Adrien Bartoli"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16005"
  },
  {
    "id": "arXiv:2211.16006",
    "title": "Lie Group Forced Variational Integrator Networks for Learning and  Control of Robot Systems",
    "abstract": "Incorporating prior knowledge of physics laws and structural properties of\ndynamical systems into the design of deep learning architectures has proven to\nbe a powerful technique for improving their computational efficiency and\ngeneralization capacity. Learning accurate models of robot dynamics is critical\nfor safe and stable control. Autonomous mobile robots, including wheeled,\naerial, and underwater vehicles, can be modeled as controlled Lagrangian or\nHamiltonian rigid-body systems evolving on matrix Lie groups. In this paper, we\nintroduce a new structure-preserving deep learning architecture, the Lie group\nForced Variational Integrator Network (LieFVIN), capable of learning controlled\nLagrangian or Hamiltonian dynamics on Lie groups, either from position-velocity\nor position-only data. By design, LieFVINs preserve both the Lie group\nstructure on which the dynamics evolve and the symplectic structure underlying\nthe Hamiltonian or Lagrangian systems of interest. The proposed architecture\nlearns surrogate discrete-time flow maps instead of surrogate vector fields,\nwhich allows better and faster prediction without requiring the use of a\nnumerical integrator, neural ODE, or adjoint techniques. Furthermore, the\nlearnt discrete-time dynamics can be combined seamlessly with computationally\nscalable discrete-time (optimal) control strategies.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Valentin Duruisseaux",
      "Thai Duong",
      "Melvin Leok",
      "Nikolay Atanasov"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.16006"
  },
  {
    "id": "arXiv:2211.16008",
    "title": "A Charge Domain P-8T SRAM Compute-In-Memory with Low-Cost DAC/ADC  Operation for 4-bit Input Processing",
    "abstract": "This paper presents a low cost PMOS-based 8T (P-8T) SRAM Compute-In-Memory\n(CIM) architecture that efficiently per-forms the multiply-accumulate (MAC)\noperations between 4-bit input activations and 8-bit weights. First, bit-line\n(BL) charge-sharing technique is employed to design the low-cost and reliable\ndigital-to-analog conversion of 4-bit input activations in the pro-posed SRAM\nCIM, where the charge domain analog computing provides variation tolerant and\nlinear MAC outputs. The 16 local arrays are also effectively exploited to\nimplement the analog mul-tiplication unit (AMU) that simultaneously produces 16\nmultipli-cation results between 4-bit input activations and 1-bit weights. For\nthe hardware cost reduction of analog-to-digital converter (ADC) without\nsacrificing DNN accuracy, hardware aware sys-tem simulations are performed to\ndecide the ADC bit-resolutions and the number of activated rows in the proposed\nCIM macro. In addition, for the ADC operation, the AMU-based reference col-umns\nare utilized for generating ADC reference voltages, with which low-cost 4-bit\ncoarse-fine flash ADC has been designed. The 256X80 P-8T SRAM CIM macro\nimplementation using 28nm CMOS process shows that the proposed CIM shows the\naccuracies of 91.46% and 66.67% with CIFAR-10 and CIFAR-100 dataset,\nrespectively, with the energy efficiency of 50.07-TOPS/W.",
    "descriptor": "\nComments: Presented at ISLPED 2022\n",
    "authors": [
      "Joonhyung Kim",
      "Kyeongho Lee",
      "Jongsun Park"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16008"
  },
  {
    "id": "arXiv:2211.16010",
    "title": "Graph Search based Polar Code Design",
    "abstract": "It is well known that to fulfill their full potential, the design of polar\ncodes must be tailored to their intended decoding algorithm. While for\nsuccessive cancellation (SC) decoding, information theoretically optimal\nconstructions are available, the code design for other decoding algorithms\n(such as belief propagation (BP) decoding) can only be optimized using\nextensive Monte Carlo simulations. We propose to view the design process of\npolar codes as a graph search problem and thereby approaching it more\nsystematically. Based on this formalism, the design-time complexity can be\nsignificantly reduced compared to state-of-the-art Genetic Algorithm (GenAlg)\nand deep learning-based design algorithms. Moreover, sequences of\nrate-compatible polar codes can be efficiently found. Finally, we analyze both\nthe complexity of the proposed algorithm and the error-rate performance of the\nconstructed codes.",
    "descriptor": "\nComments: 5 pages, 8 figures, accepted to the 2022 Asilomar Conference on Signals, Systems, and Computers\n",
    "authors": [
      "Marvin Geiselhart",
      "Andreas Zunker",
      "Ahmed Elkelesh",
      "Jannis Clausius",
      "Stephan ten Brink"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.16010"
  },
  {
    "id": "arXiv:2211.16011",
    "title": "Incorporating Multi-armed Bandit with Local Search for MaxSAT",
    "abstract": "Partial MaxSAT (PMS) and Weighted PMS (WPMS) are two practical\ngeneralizations of the MaxSAT problem. In this paper, we propose a local search\nalgorithm for these problems, called BandHS, which applies two multi-armed\nbandits to guide the search directions when escaping local optima. One bandit\nis combined with all the soft clauses to help the algorithm select to satisfy\nappropriate soft clauses, and the other bandit with all the literals in hard\nclauses to help the algorithm select appropriate literals to satisfy the hard\nclauses. These two bandits can improve the algorithm's search ability in both\nfeasible and infeasible solution spaces. We further propose an initialization\nmethod for (W)PMS that prioritizes both unit and binary clauses when producing\nthe initial solutions. Extensive experiments demonstrate the excellent\nperformance and generalization capability of our proposed methods, that greatly\nboost the state-of-the-art local search algorithm, SATLike3.0, and the\nstate-of-the-art SAT-based incomplete solver, NuWLS-c.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2201.05544\n",
    "authors": [
      "Jiongzhi Zheng",
      "Kun He",
      "Jianrong Zhou",
      "Yan Jin",
      "Chu-Min Li",
      "Felip Many\u00e0"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16011"
  },
  {
    "id": "arXiv:2211.16016",
    "title": "UDE: A Unified Driving Engine for Human Motion Generation",
    "abstract": "Generating controllable and editable human motion sequences is a key\nchallenge in 3D Avatar generation. It has been labor-intensive to generate and\nanimate human motion for a long time until learning-based approaches have been\ndeveloped and applied recently. However, these approaches are still\ntask-specific or modality-specific\\cite\n{ahuja2019language2pose}\\cite{ghosh2021synthesis}\\cite{ferreira2021learning}\\cite{li2021ai}.\nIn this paper, we propose ``UDE\", the first unified driving engine that enables\ngenerating human motion sequences from natural language or audio sequences (see\nFig.~\\ref{fig:teaser}). Specifically, UDE consists of the following key\ncomponents: 1) a motion quantization module based on VQVAE that represents\ncontinuous motion sequence as discrete latent code\\cite{van2017neural}, 2) a\nmodality-agnostic transformer encoder\\cite{vaswani2017attention} that learns to\nmap modality-aware driving signals to a joint space, and 3) a unified token\ntransformer (GPT-like\\cite{radford2019language}) network to predict the\nquantized latent code index in an auto-regressive manner. 4) a diffusion motion\ndecoder that takes as input the motion tokens and decodes them into motion\nsequences with high diversity. We evaluate our method on\nHumanML3D\\cite{Guo_2022_CVPR} and AIST++\\cite{li2021learn} benchmarks, and the\nexperiment results demonstrate our method achieves state-of-the-art\nperformance. Project website: \\url{https://github.com/zixiangzhou916/UDE/",
    "descriptor": "\nComments: 14 pages, 10 figures, 6 tables\n",
    "authors": [
      "Zixiang Zhou",
      "Baoyuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16016"
  },
  {
    "id": "arXiv:2211.16019",
    "title": "PatchMix Augmentation to Identify Causal Features in Few-shot Learning",
    "abstract": "The task of Few-shot learning (FSL) aims to transfer the knowledge learned\nfrom base categories with sufficient labelled data to novel categories with\nscarce known information. It is currently an important research question and\nhas great practical values in the real-world applications. Despite extensive\nprevious efforts are made on few-shot learning tasks, we emphasize that most\nexisting methods did not take into account the distributional shift caused by\nsample selection bias in the FSL scenario. Such a selection bias can induce\nspurious correlation between the semantic causal features, that are causally\nand semantically related to the class label, and the other non-causal features.\nCritically, the former ones should be invariant across changes in\ndistributions, highly related to the classes of interest, and thus well\ngeneralizable to novel classes, while the latter ones are not stable to changes\nin the distribution. To resolve this problem, we propose a novel data\naugmentation strategy dubbed as PatchMix that can break this spurious\ndependency by replacing the patch-level information and supervision of the\nquery images with random gallery images from different classes from the query\nones. We theoretically show that such an augmentation mechanism, different from\nexisting ones, is able to identify the causal features. To further make these\nfeatures to be discriminative enough for classification, we propose\nCorrelation-guided Reconstruction (CGR) and Hardness-Aware module for instance\ndiscrimination and easier discrimination between similar classes. Moreover,\nsuch a framework can be adapted to the unsupervised FSL scenario.",
    "descriptor": "",
    "authors": [
      "Chengming Xu",
      "Chen Liu",
      "Xinwei Sun",
      "Siqian Yang",
      "Yabiao Wang",
      "Chengjie Wang",
      "Yanwei Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16019"
  },
  {
    "id": "arXiv:2211.16022",
    "title": "Textual Enhanced Contrastive Learning for Solving Math Word Problems",
    "abstract": "Solving math word problems is the task that analyses the relation of\nquantities and requires an accurate understanding of contextual natural\nlanguage information. Recent studies show that current models rely on shallow\nheuristics to predict solutions and could be easily misled by small textual\nperturbations. To address this problem, we propose a Textual Enhanced\nContrastive Learning framework, which enforces the models to distinguish\nsemantically similar examples while holding different mathematical logic. We\nadopt a self-supervised manner strategy to enrich examples with subtle textual\nvariance by textual reordering or problem re-construction. We then retrieve the\nhardest to differentiate samples from both equation and textual perspectives\nand guide the model to learn their representations. Experimental results show\nthat our method achieves state-of-the-art on both widely used benchmark\ndatasets and also exquisitely designed challenge datasets in English and\nChinese. \\footnote{Our code and data is available at\n\\url{https://github.com/yiyunya/Textual_CL_MWP}",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Yibin Shen",
      "Qianying Liu",
      "Zhuoyuan Mao",
      "Fei Cheng",
      "Sadao Kurohashi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.16022"
  },
  {
    "id": "arXiv:2211.16023",
    "title": "Novelty Detection for Election Fraud: A Case Study with Agent-Based  Simulation Data",
    "abstract": "In this paper, we propose a robust election simulation model and\nindependently developed election anomaly detection algorithm that demonstrates\nthe simulation's utility. The simulation generates artificial elections with\nsimilar properties and trends as elections from the real world, while giving\nusers control and knowledge over all the important components of the elections.\nWe generate a clean election results dataset without fraud as well as datasets\nwith varying degrees of fraud. We then measure how well the algorithm is able\nto successfully detect the level of fraud present. The algorithm determines how\nsimilar actual election results are as compared to the predicted results from\npolling and a regression model of other regions that have similar demographics.\nWe use k-means to partition electoral regions into clusters such that\ndemographic homogeneity is maximized among clusters. We then use a novelty\ndetection algorithm implemented as a one-class Support Vector Machine where the\nclean data is provided in the form of polling predictions and regression\npredictions. The regression predictions are built from the actual data in such\na way that the data supervises itself. We show both the effectiveness of the\nsimulation technique and the machine learning model in its success in\nidentifying fraudulent regions.",
    "descriptor": "\nComments: 7 pages, 2 figures, to be published in the 2023 AAAI AI for Credible Elections Workshop\n",
    "authors": [
      "Khurram Yamin",
      "Nima Jadali",
      "Dima Nazzal",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.16023"
  },
  {
    "id": "arXiv:2211.16029",
    "title": "Diverse Multi-Answer Retrieval with Determinantal Point Processes",
    "abstract": "Often questions provided to open-domain question answering systems are\nambiguous. Traditional QA systems that provide a single answer are incapable of\nanswering ambiguous questions since the question may be interpreted in several\nways and may have multiple distinct answers. In this paper, we address\nmulti-answer retrieval which entails retrieving passages that can capture\nmajority of the diverse answers to the question. We propose a re-ranking based\napproach using Determinantal point processes utilizing BERT as kernels. Our\nmethod jointly considers query-passage relevance and passage-passage\ncorrelation to retrieve passages that are both query-relevant and diverse.\nResults demonstrate that our re-ranking technique outperforms state-of-the-art\nmethod on the AmbigQA dataset.",
    "descriptor": "\nComments: Published as a conference paper at COLING 2022\n",
    "authors": [
      "Poojitha Nandigam",
      "Nikhil Rayaprolu",
      "Manish Shrivastava"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.16029"
  },
  {
    "id": "arXiv:2211.16030",
    "title": "Graph Based Semi-supervised Learning Using Spatial Segregation Theory",
    "abstract": "In this work we address graph based semi-supervised learning using the theory\nof the spatial segregation of competitive systems. First, we define a discrete\ncounterpart over connected graphs by using direct analogue of the corresponding\ncompetitive system. This model turns out doesn't have a unique solution as we\nexpected. Nevertheless, we suggest gradient projected and regularization\nmethods to reach some of the solutions. Then we focus on a slightly different\nmodel motivated from the recent numerical results on the spatial segregation of\nreaction-diffusion systems. In this case we show that the model has a unique\nsolution and propose a novel classification algorithm based on it. Finally, we\npresent numerical experiments showing the method is efficient and comparable to\nother semi-supervised learning algorithms at high and low label rates.",
    "descriptor": "\nComments: 27 pages, 45 figures, 2 tables; Key words and phrases. Free boundary, Semi-supervised learning, Laplace learning\n",
    "authors": [
      "Farid Bozorgnia",
      "Morteza Fotouhi",
      "Avetik Arakelyan",
      "Abderrahim Elmoataz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.16030"
  },
  {
    "id": "arXiv:2211.16031",
    "title": "Syntactic Substitutability as Unsupervised Dependency Syntax",
    "abstract": "Syntax is a latent hierarchical structure which underpins the robust and\ncompositional nature of human language. An active line of inquiry is whether\nlarge pretrained language models (LLMs) are able to acquire syntax by training\non text alone; understanding a model's syntactic capabilities is essential to\nunderstanding how it processes and makes use of language. In this paper, we\npropose a new method, SSUD, which allows for the induction of syntactic\nstructures without supervision from gold-standard parses. Instead, we seek to\ndefine formalism-agnostic, model-intrinsic syntactic parses by using a property\nof syntactic relations: syntactic substitutability. We demonstrate both\nquantitative and qualitative gains on dependency parsing tasks using SSUD, and\ninduce syntactic structures which we hope provide clarity into LLMs and\nlinguistic representations, alike.",
    "descriptor": "",
    "authors": [
      "Jasper Jian",
      "Siva Reddy"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.16031"
  },
  {
    "id": "arXiv:2211.16032",
    "title": "Dimensionality-Varying Diffusion Process",
    "abstract": "Diffusion models, which learn to reverse a signal destruction process to\ngenerate new data, typically require the signal at each step to have the same\ndimension. We argue that, considering the spatial redundancy in image signals,\nthere is no need to maintain a high dimensionality in the evolution process,\nespecially in the early generation phase. To this end, we make a theoretical\ngeneralization of the forward diffusion process via signal decomposition.\nConcretely, we manage to decompose an image into multiple orthogonal components\nand control the attenuation of each component when perturbing the image. That\nway, along with the noise strength increasing, we are able to diminish those\ninconsequential components and thus use a lower-dimensional signal to represent\nthe source, barely losing information. Such a reformulation allows to vary\ndimensions in both training and inference of diffusion models. Extensive\nexperiments on a range of datasets suggest that our approach substantially\nreduces the computational cost and achieves on-par or even better synthesis\nperformance compared to baseline methods. We also show that our strategy\nfacilitates high-resolution image synthesis and improves FID of diffusion model\ntrained on FFHQ at $1024\\times1024$ resolution from 52.40 to 10.46. Code and\nmodels will be made publicly available.",
    "descriptor": "",
    "authors": [
      "Han Zhang",
      "Ruili Feng",
      "Zhantao Yang",
      "Lianghua Huang",
      "Yu Liu",
      "Yifei Zhang",
      "Yujun Shen",
      "Deli Zhao",
      "Jingren Zhou",
      "Fan Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16032"
  },
  {
    "id": "arXiv:2211.16034",
    "title": "Learn to See Faster: Pushing the Limits of High-Speed Camera with Deep  Underexposed Image Denoising",
    "abstract": "The ability to record high-fidelity videos at high acquisition rates is\ncentral to the study of fast moving phenomena. The difficulty of imaging fast\nmoving scenes lies in a trade-off between motion blur and underexposure noise:\nOn the one hand, recordings with long exposure times suffer from motion blur\neffects caused by movements in the recorded scene. On the other hand, the\namount of light reaching camera photosensors decreases with exposure times so\nthat short-exposure recordings suffer from underexposure noise. In this paper,\nwe propose to address this trade-off by treating the problem of high-speed\nimaging as an underexposed image denoising problem. We combine recent advances\non underexposed image denoising using deep learning and adapt these methods to\nthe specificity of the high-speed imaging problem. Leveraging large external\ndatasets with a sensor-specific noise model, our method is able to speedup the\nacquisition rate of a High-Speed Camera over one order of magnitude while\nmaintaining similar image quality.",
    "descriptor": "",
    "authors": [
      "Weihao Zhuang",
      "Tristan Hascoet",
      "Ryoichi Takashima",
      "Tetsuya Takiguchi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.16034"
  },
  {
    "id": "arXiv:2211.16035",
    "title": "Query Timing Analysis for Content-based Wake-up Realizing Informative  IoT Data Collection",
    "abstract": "Information freshness and high energy-efficiency are key requirements for\nsensor nodes serving Industrial Internet of Things (IIoT) applications, where a\nsink node must collect informative data before a deadline to control an\nexternal element. Pull-based communication is an interesting approach for\noptimizing information freshness and saving wasteful energy. To this end, we\napply Content-based Wake-up (CoWu), in which the sink can activate a subset of\nnodes observing informative data at the time that wake-up signal is received.\nIn this case, the timing of the wake-up signal plays an important role: early\ntransmission leads to high reliability in data collection, but the received\ndata may become obsolete by the deadline, while later transmission ensures a\nhigher timeliness of the sensed data, but some nodes might not manage to\ncommunicate their data before the deadline. This letter investigates the timing\nfor data collection using CoWu and characterizes the gain of CoWu. The obtained\nnumerical results show that CoWu improves accuracy, while reducing energy\nconsumption by about 75% with respect to round-robin scheduling.",
    "descriptor": "\nComments: Accepted to IEEE Wireless Communications Letters\n",
    "authors": [
      "Junya Shiraishi",
      "Anders E. Kal\u00f8r",
      "Federico Chiariotti",
      "Israel Leyva-Mayorga",
      "Petar Popovski",
      "Hiroyuki Yoma"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.16035"
  },
  {
    "id": "arXiv:2211.16038",
    "title": "Data-efficient Modeling of Optical Matrix Multipliers Using Transfer  Learning",
    "abstract": "We demonstrate transfer learning-assisted neural network models for optical\nmatrix multipliers with scarce measurement data. Our approach uses <10\\% of\nexperimental data needed for best performance and outperforms analytical models\nfor a Mach-Zehnder interferometer mesh.",
    "descriptor": "\nComments: 2 pages, 2 figues, submitted to CLEO\n",
    "authors": [
      "Ali Cem",
      "Ognjen Jovanovic",
      "Siqi Yan",
      "Yunhong Ding",
      "Darko Zibar",
      "Francesco Da Ros"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Emerging Technologies (cs.ET)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.16038"
  },
  {
    "id": "arXiv:2211.16040",
    "title": "AdvMask: A Sparse Adversarial Attack Based Data Augmentation Method for  Image Classification",
    "abstract": "Data augmentation is a widely used technique for enhancing the generalization\nability of convolutional neural networks (CNNs) in image classification tasks.\nOcclusion is a critical factor that affects on the generalization ability of\nimage classification models. In order to generate new samples, existing data\naugmentation methods based on information deletion simulate occluded samples by\nrandomly removing some areas in the images. However, those methods cannot\ndelete areas of the images according to their structural features of the\nimages. To solve those problems, we propose a novel data augmentation method,\nAdvMask, for image classification tasks. Instead of randomly removing areas in\nthe images, AdvMask obtains the key points that have the greatest influence on\nthe classification results via an end-to-end sparse adversarial attack module.\nTherefore, we can find the most sensitive points of the classification results\nwithout considering the diversity of various image appearance and shapes of the\nobject of interest. In addition, a data augmentation module is employed to\ngenerate structured masks based on the key points, thus forcing the CNN\nclassification models to seek other relevant content when the most\ndiscriminative content is hidden. AdvMask can effectively improve the\nperformance of classification models in the testing process. The experimental\nresults on various datasets and CNN models verify that the proposed method\noutperforms other previous data augmentation methods in image classification\ntasks.",
    "descriptor": "",
    "authors": [
      "Suorong Yang",
      "Jinqiao Li",
      "Jian Zhao",
      "Furao Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16040"
  },
  {
    "id": "arXiv:2211.16043",
    "title": "Interpolation of subdivision features for curved geometry modeling",
    "abstract": "We present a nodal interpolation method to approximate a subdivision model.\nThe main application is to model and represent curved geometry without gaps and\npreserving the required simulation intent. Accordingly, we devise the technique\nto maintain the necessary sharp features and smooth the indicated ones. This\nsharp-to-smooth modeling capability handles unstructured configurations of the\nsimulation points, curves, and surfaces. The surfaces correspond to initial\nlinear triangulations that determine the sharp point and curve features. The\nmethod automatically suggests a subset of sharp features to smooth which the\nuser modifies to obtain a limit model preserving the initial points. This model\nreconstructs the curvature by subdivision of the initial mesh, with no need of\nan underlying curved geometry model. Finally, given a polynomial degree and a\nnodal distribution, the method generates a piece-wise polynomial representation\ninterpolating the limit model. We show numerical evidence that this\napproximation, naturally aligned to the subdivision features, converges to the\nmodel geometrically with the polynomial degree for nodal distributions with\nsub-optimal Lebesgue constant. We also apply the method to prescribe the curved\nboundary of a high-order volume mesh. We conclude that our sharp-to-smooth\nmodeling capability leads to curved geometry representations with enhanced\npreservation of the simulation intent.",
    "descriptor": "",
    "authors": [
      "Albert Jim\u00e9nez-Ramos",
      "Abel Gargallo-Peir\u00f3",
      "Xevi Roca"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.16043"
  },
  {
    "id": "arXiv:2211.16044",
    "title": "Model Extraction Attack against Self-supervised Speech Models",
    "abstract": "Self-supervised learning (SSL) speech models generate meaningful\nrepresentations of given clips and achieve incredible performance across\nvarious downstream tasks. Model extraction attack (MEA) often refers to an\nadversary stealing the functionality of the victim model with only query\naccess. In this work, we study the MEA problem against SSL speech model with a\nsmall number of queries. We propose a two-stage framework to extract the model.\nIn the first stage, SSL is conducted on the large-scale unlabeled corpus to\npre-train a small speech model. Secondly, we actively sample a small portion of\nclips from the unlabeled corpus and query the target model with these clips to\nacquire their representations as labels for the small model's second-stage\ntraining. Experiment results show that our sampling methods can effectively\nextract the target model without knowing any information about its model\narchitecture.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Tsu-Yuan Hsu",
      "Chen-An Li",
      "Tung-Yu Wu",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.16044"
  },
  {
    "id": "arXiv:2211.16047",
    "title": "Neural Feature-Adaptation for Symbolic Predictions Using Pre-Training  and Semantic Loss",
    "abstract": "We are interested in neurosymbolic systems consisting of a high-level\nsymbolic layer for explainable prediction in terms of human-intelligible\nconcepts; and a low-level neural layer for extracting symbols required to\ngenerate the symbolic explanation. Real data is often imperfect meaning that\neven if the symbolic theory remains unchanged, we may still need to address the\nproblem of mapping raw data to high-level symbols, each time there is a change\nin the data acquisition environment or equipment. Manual (re-)annotation of the\nraw data each time this happens is laborious and expensive; and automated\nlabelling methods are often imperfect, especially for complex problems.\nNEUROLOG proposed the use of a semantic loss function that allows an existing\nfeature-based symbolic model to guide the extraction of feature-values from raw\ndata, using `abduction'. However, the experiments demonstrating the use of\nsemantic loss through abduction appear to rely heavily on a domain-specific\npre-processing step that enables a prior delineation of feature locations in\nthe raw data. We examine the use of semantic loss in domains where such\npre-processing is not possible, or is not obvious. We show that without any\nprior information about the features, the NEUROLOG approach can continue to\npredict accurately even with substantially incorrect feature predictions. We\nshow also that prior information about the features in the form of even\nimperfect pre-training can help correct this situation. These findings are\nreplicated on the original problem considered by NEUROLOG, without the use of\nfeature-delineation. This suggests that symbolic explanations constructed for\ndata in a domain could be re-used in a related domain, by `feature-adaptation'\nof pre-trained neural extractors using the semantic loss function constrained\nby abductive feedback.",
    "descriptor": "",
    "authors": [
      "Vedant Shah",
      "Aditya Agrawal",
      "Lovekesh Vig",
      "Ashwin Srinivasan",
      "Gautam Shroff",
      "Tanmay Verlekar"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.16047"
  },
  {
    "id": "arXiv:2211.16051",
    "title": "Regret-Optimal Online Caching for Adversarial and Stochastic Arrivals",
    "abstract": "We consider the online caching problem for a cache of limited size. In a\ntime-slotted system, a user requests one file from a large catalog in each\nslot. If the requested file is cached, the policy receives a unit reward and\nzero rewards otherwise. We show that a Follow the Perturbed Leader (FTPL)-based\nanytime caching policy is simultaneously regret-optimal for both adversarial\nand i.i.d. stochastic arrivals. Further, in the setting where there is a cost\nassociated with switching the cached contents, we propose a variant of FTPL\nthat is order-optimal with respect to time for both adversarial and stochastic\narrivals and has a significantly better performance compared to FTPL with\nrespect to the switching cost for stochastic arrivals. We also show that these\nresults can be generalized to the setting where there are constraints on the\nfrequency with which cache contents can be changed. Finally, we validate the\nresults obtained on various synthetic as well as real-world traces.",
    "descriptor": "\nComments: 42 pages\n",
    "authors": [
      "Fathima Zarin Faizal",
      "Priya Singh",
      "Nikhil Karamchandani",
      "Sharayu Moharir"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2211.16051"
  },
  {
    "id": "arXiv:2211.16056",
    "title": "NoisyQuant: Noisy Bias-Enhanced Post-Training Activation Quantization  for Vision Transformers",
    "abstract": "The complicated architecture and high training cost of vision transformers\nurge the exploration of post-training quantization. However, the heavy-tailed\ndistribution of vision transformer activations hinders the effectiveness of\nprevious post-training quantization methods, even with advanced quantizer\ndesigns. Instead of tuning the quantizer to better fit the complicated\nactivation distribution, this paper proposes NoisyQuant, a quantizer-agnostic\nenhancement for the post-training activation quantization performance of vision\ntransformers. We make a surprising theoretical discovery that for a given\nquantizer, adding a fixed Uniform noisy bias to the values being quantized can\nsignificantly reduce the quantization error under provable conditions. Building\non the theoretical insight, NoisyQuant achieves the first success on actively\naltering the heavy-tailed activation distribution with additive noisy bias to\nfit a given quantizer. Extensive experiments show NoisyQuant largely improves\nthe post-training quantization performance of vision transformer with minimal\ncomputation overhead. For instance, on linear uniform 6-bit activation\nquantization, NoisyQuant improves SOTA top-1 accuracy on ImageNet by up to\n1.7%, 1.1% and 0.5% for ViT, DeiT, and Swin Transformer respectively, achieving\non-par or even higher performance than previous nonlinear, mixed-precision\nquantization.",
    "descriptor": "",
    "authors": [
      "Yijiang Liu",
      "Huanrui Yang",
      "Zhen Dong",
      "Kurt Keutzer",
      "Li Du",
      "Shanghang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16056"
  },
  {
    "id": "arXiv:2211.16066",
    "title": "Analysis of Training Object Detection Models with Synthetic Data",
    "abstract": "Recently, the use of synthetic training data has been on the rise as it\noffers correctly labelled datasets at a lower cost. The downside of this\ntechnique is that the so-called domain gap between the real target images and\nsynthetic training data leads to a decrease in performance. In this paper, we\nattempt to provide a holistic overview of how to use synthetic data for object\ndetection. We analyse aspects of generating the data as well as techniques used\nto train the models. We do so by devising a number of experiments, training\nmodels on the Dataset of Industrial Metal Objects (DIMO). This dataset contains\nboth real and synthetic images. The synthetic part has different subsets that\nare either exact synthetic copies of the real data or are copies with certain\naspects randomised. This allows us to analyse what types of variation are good\nfor synthetic training data and which aspects should be modelled to closely\nmatch the target data. Furthermore, we investigate what types of training\ntechniques are beneficial towards generalisation to real data, and how to use\nthem. Additionally, we analyse how real images can be leveraged when training\non synthetic images. All these experiments are validated on real data and\nbenchmarked to models trained on real data. The results offer a number of\ninteresting takeaways that can serve as basic guidelines for using synthetic\ndata for object detection. Code to reproduce results is available at\nhttps://github.com/EDM-Research/DIMO_ObjectDetection.",
    "descriptor": "\nComments: published in BMVC 2022, this https URL\n",
    "authors": [
      "Bram Vanherle",
      "Steven Moonen",
      "Frank Van Reeth",
      "Nick Michiels"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16066"
  },
  {
    "id": "arXiv:2211.16068",
    "title": "ACE: Cooperative Multi-agent Q-learning with Bidirectional  Action-Dependency",
    "abstract": "Multi-agent reinforcement learning (MARL) suffers from the non-stationarity\nproblem, which is the ever-changing targets at every iteration when multiple\nagents update their policies at the same time. Starting from first principle,\nin this paper, we manage to solve the non-stationarity problem by proposing\nbidirectional action-dependent Q-learning (ACE). Central to the development of\nACE is the sequential decision-making process wherein only one agent is allowed\nto take action at one time. Within this process, each agent maximizes its value\nfunction given the actions taken by the preceding agents at the inference\nstage. In the learning phase, each agent minimizes the TD error that is\ndependent on how the subsequent agents have reacted to their chosen action.\nGiven the design of bidirectional dependency, ACE effectively turns a\nmultiagent MDP into a single-agent MDP. We implement the ACE framework by\nidentifying the proper network representation to formulate the action\ndependency, so that the sequential decision process is computed implicitly in\none forward pass. To validate ACE, we compare it with strong baselines on two\nMARL benchmarks. Empirical experiments demonstrate that ACE outperforms the\nstate-of-the-art algorithms on Google Research Football and StarCraft\nMulti-Agent Challenge by a large margin. In particular, on SMAC tasks, ACE\nachieves 100% success rate on almost all the hard and super-hard maps. We\nfurther study extensive research problems regarding ACE, including extension,\ngeneralization, and practicability. Code is made available to facilitate\nfurther research.",
    "descriptor": "\nComments: Accepted by the Thirty-Seventh AAAI Conference on Artificial Intelligence(AAAI2023)\n",
    "authors": [
      "Chuming Li",
      "Jie Liu",
      "Yinmin Zhang",
      "Yuhong Wei",
      "Yazhe Niu",
      "Yaodong Yang",
      "Yu Liu",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.16068"
  },
  {
    "id": "arXiv:2211.16069",
    "title": "Interpreting Primal-Dual Algorithms for Constrained MARL",
    "abstract": "Constrained multiagent reinforcement learning (C-MARL) is gaining importance\nas MARL algorithms find new applications in real-world systems ranging from\nenergy systems to drone swarms. Most C-MARL algorithms use a primal-dual\napproach to enforce constraints through a penalty function added to the reward.\nIn this paper, we study the structural effects of the primal-dual approach on\nthe constraints and value function. First, we show that using the constraint\nevaluation as the penalty leads to a weak notion of safety, but by making\nsimple modifications to the penalty function, we can enforce meaningful\nprobabilistic safety constraints. Second, we exploit the structural effects of\nprimal-dual methods on value functions, leading to improved value estimates.\nSimulations in a simple constrained multiagent environment show that our\nreinterpretation of the primal-dual method in terms of probabilistic\nconstraints is meaningful, and that our proposed value estimation procedure\nimproves convergence to a safe joint policy.",
    "descriptor": "\nComments: 17 pages, 7 figures. To be submitted to L4DC 2023\n",
    "authors": [
      "Daniel Tabas",
      "Ahmed S. Zamzam",
      "Baosen Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.16069"
  },
  {
    "id": "arXiv:2211.16073",
    "title": "Abstract Interpretation-Based Data Leakage Static Analysis",
    "abstract": "Data leakage is a well-known problem in machine learning. Data leakage occurs\nwhen information from outside the training dataset is used to create a model.\nThis phenomenon renders a model excessively optimistic or even useless in the\nreal world since the model tends to leverage greatly on the unfairly acquired\ninformation. To date, detection of data leakages occurs post-mortem using\nrun-time methods. However, due to the insidious nature of data leakage, it may\nnot be apparent to a data scientist that a data leakage has occurred in the\nfirst place. For this reason, it is advantageous to detect data leakages as\nearly as possible in the development life cycle. In this paper, we propose a\nnovel static analysis to detect several instances of data leakages during\ndevelopment time. We define our analysis using the framework of abstract\ninterpretation: we define a concrete semantics that is sound and complete, from\nwhich we derive a sound and computable abstract semantics. We implement our\nstatic analysis inside the open-source NBLyzer static analysis framework and\ndemonstrate its utility by evaluating its performance and precision on over\n2000 Kaggle competition notebooks.",
    "descriptor": "",
    "authors": [
      "Filip Drobnjakovi\u0107",
      "Pavle Suboti\u0107",
      "Caterina Urban"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.16073"
  },
  {
    "id": "arXiv:2211.16074",
    "title": "Fingerprinting and Analysis of Bluetooth Devices with Automata Learning",
    "abstract": "Automata learning is a technique to automatically infer behavioral models of\nblack-box systems. Today's learning algorithms enable the deduction of models\nthat describe complex system properties, e.g., timed or stochastic behavior.\nDespite recent improvements in the scalability of learning algorithms, their\npractical applicability is still an open issue. Little work exists that\nactually learns models of physical black-box systems. To fill this gap in the\nliterature, we present a case study on applying automata learning on the\nBluetooth Low Energy (BLE) protocol. It shows that not only the size of the\nsystem limits the applicability of automata learning.\nAlso, the interaction with the system under learning creates a major\nbottleneck that is rarely discussed. In this article, we propose a general\nautomata learning architecture for learning a behavioral model of the BLE\nprotocol implemented by a physical device. With this framework, we can\nsuccessfully learn the behavior of six investigated BLE devices. Furthermore,\nwe extended the learning technique to learn security critical behavior, e.g.,\nkey-exchange procedures for encrypted communication. The learned models depict\nseveral behavioral differences and inconsistencies to the BLE specification.\nThis shows that automata learning can be used for fingerprinting black-box\ndevices, i.e., characterizing systems via their specific learned models.\nMoreover, learning revealed a crashing scenario for one device.",
    "descriptor": "\nComments: This is a preprint of an extended version of the conference paper \"Fingerprinting Bluetooth Low Energy Devices via Active Automata Learning\" accepted for presentation at FM 2021, Formal Methods - 24th International Symposium, Virtual Event. The extended version is currently under review\n",
    "authors": [
      "Andrea Pferscher",
      "Bernhard K. Aichernig"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2211.16074"
  },
  {
    "id": "arXiv:2211.16076",
    "title": "Finlay, Thames, Dufay, and Paget color screen process collections: Using  digital registration of viewing screens to reveal original color",
    "abstract": "We discuss digitization, subsequent digital analysis and processing of\nnegatives (and diapositives) made by Finlay, Thames, Dufay, Paget, and similar\nadditive color screen processes. These early color processes (introduced in the\n1890s and popular until the 1950s) used a special color screen filter and a\nmonochromatic negative. Due to poor stability of dyes used to produce color\nscreens many of the photographs appear faded; others exist only in the form of\n(monochromatic) negatives. We discuss the possibility of digitally\nreconstructing the original color from scans of original negatives or by virtue\nof infrared imaging of original transparencies (which eliminates the physically\ncoupled color filters) and digitally recreating the original color filter\npattern using a new open-source software tool. Photographs taken using additive\ncolor screen processes are some of the very earliest color images of our shared\ncultural heritage. They depict people, places, and events for which there are\nno other surviving color images. We hope that our new software tool can bring\nthese images back to life.",
    "descriptor": "\nComments: 8 figures, 9 pages; submitted to the proceedings of Colour Photography and Film: sharing knowledge of analysis, preservation, conservation, migration of analogue and digital materials\n",
    "authors": [
      "Geoffrey Barker",
      "Jan Hubi\u010dka",
      "Mark Jacobs",
      "Linda Kimrov\u00e1",
      "Kendra Meyer",
      "Doug Peterson"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.16076"
  },
  {
    "id": "arXiv:2211.16078",
    "title": "Behavior Estimation from Multi-Source Data for Offline Reinforcement  Learning",
    "abstract": "Offline reinforcement learning (RL) have received rising interest due to its\nappealing data efficiency. The present study addresses behavior estimation, a\ntask that lays the foundation of many offline RL algorithms. Behavior\nestimation aims at estimating the policy with which training data are\ngenerated. In particular, this work considers a scenario where the data are\ncollected from multiple sources. In this case, neglecting data heterogeneity,\nexisting approaches for behavior estimation suffers from behavior\nmisspecification. To overcome this drawback, the present study proposes a\nlatent variable model to infer a set of policies from data, which allows an\nagent to use as behavior policy the policy that best describes a particular\ntrajectory. This model provides with a agent fine-grained characterization for\nmulti-source data and helps it overcome behavior misspecification. This work\nalso proposes a learning algorithm for this model and illustrates its practical\nusage via extending an existing offline RL algorithm. Lastly, with extensive\nevaluation this work confirms the existence of behavior misspecification and\nthe efficacy of the proposed model.",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Guoxi Zhang",
      "Hisashi Kashima"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.16078"
  },
  {
    "id": "arXiv:2211.16080",
    "title": "Understanding and Enhancing Robustness of Concept-based Models",
    "abstract": "Rising usage of deep neural networks to perform decision making in critical\napplications like medical diagnosis and financial analysis have raised concerns\nregarding their reliability and trustworthiness. As automated systems become\nmore mainstream, it is important their decisions be transparent, reliable and\nunderstandable by humans for better trust and confidence. To this effect,\nconcept-based models such as Concept Bottleneck Models (CBMs) and\nSelf-Explaining Neural Networks (SENN) have been proposed which constrain the\nlatent space of a model to represent high level concepts easily understood by\ndomain experts in the field. Although concept-based models promise a good\napproach to both increasing explainability and reliability, it is yet to be\nshown if they demonstrate robustness and output consistent concepts under\nsystematic perturbations to their inputs. To better understand performance of\nconcept-based models on curated malicious samples, in this paper, we aim to\nstudy their robustness to adversarial perturbations, which are also known as\nthe imperceptible changes to the input data that are crafted by an attacker to\nfool a well-learned concept-based model. Specifically, we first propose and\nanalyze different malicious attacks to evaluate the security vulnerability of\nconcept based models. Subsequently, we propose a potential general adversarial\ntraining-based defense mechanism to increase robustness of these systems to the\nproposed malicious attacks. Extensive experiments on one synthetic and two\nreal-world datasets demonstrate the effectiveness of the proposed attacks and\nthe defense approach.",
    "descriptor": "\nComments: Accepted at AAAI 2023. Extended Version\n",
    "authors": [
      "Sanchit Sinha",
      "Mengdi Huai",
      "Jianhui Sun",
      "Aidong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16080"
  },
  {
    "id": "arXiv:2211.16082",
    "title": "Data Privacy Protection in DeFi Protocols",
    "abstract": "With the development of decentralized finance (DeFi), the inherent\nlimitations caused by the blockchain system have come to the surface. Because\nrecorded data on the blockchain is available to system participants, DeFi\nprotocols may not collect the private data of users. Otherwise, the information\nleakage may result in serious financial losses or cause legal issues.\nTherefore, DeFi protocols could hardly offer different users customized\nsolutions, and the capital utilization is limited. To address this challenge in\nDeFi, we propose a solution, which is a trustful protocol that allows users to\nprovide personal private data to DeFi protocols without worrying that such\ninformation would be disclosed. By implementing asymmetric encryption,\nzero-knowledge proof, and homomorphic encryption, we ensure that users' data\nwill not be controlled by any centralized authorities and avoid potential\nfinancial losses or legal disputes due to information leakage. We further\ndiscuss the application scenarios of financial data privacy protection in\npublic blockchain DeFi ecosystems and cross-border financial applications, such\nas credit aggregation.",
    "descriptor": "",
    "authors": [
      "Jiawei Zhu",
      "Zhuangtong Huang",
      "Yixin Xu",
      "Jerome Yen",
      "Ye Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.16082"
  },
  {
    "id": "arXiv:2211.16090",
    "title": "Compliant Suction Gripper with Seamless Deployment and Retraction for  Robust Picking against Depth and Tilt Errors",
    "abstract": "Applying suction grippers in unstructured environments is a challenging task\nbecause of depth and tilt errors in vision systems, requiring additional costs\nin elaborate sensing and control. To reduce additional costs, suction grippers\nwith compliant bodies or mechanisms have been proposed; however, their\nbulkiness and limited allowable error hinder their use in complex environments\nwith large errors. Here, we propose a compact suction gripper that can pick\nobjects over a wide range of distances and tilt angles without elaborate\nsensing and control. The spring-inserted gripper body deploys and conforms to\ndistant and tilted objects until the suction cup completely seals with the\nobject and retracts immediately after, while holding the object. This seamless\ndeployment and retraction is enabled by connecting the gripper body and suction\ncup to the same vacuum source, which couples the vacuum picking and retraction\nof the gripper body. Experimental results validated that the proposed gripper\ncan pick objects within 79 mm, which is 1.4 times the initial length, and can\npick objects with tilt angles up to 60{\\deg}. The feasibility of the gripper\nwas verified by demonstrations, including picking objects of different heights\nfrom the same picking height and the bin picking of transparent objects.",
    "descriptor": "\nComments: 8 pages, 11 figures\n",
    "authors": [
      "Yuna Yoo",
      "Jaemin Eom",
      "Min Jo Park",
      "Kyu-Jin Cho"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.16090"
  },
  {
    "id": "arXiv:2211.16092",
    "title": "Unsupervised Visual Defect Detection with Score-Based Generative Model",
    "abstract": "Anomaly Detection (AD), as a critical problem, has been widely discussed. In\nthis paper, we specialize in one specific problem, Visual Defect Detection\n(VDD), in many industrial applications. And in practice, defect image samples\nare very rare and difficult to collect. Thus, we focus on the unsupervised\nvisual defect detection and localization tasks and propose a novel framework\nbased on the recent score-based generative models, which synthesize the real\nimage by iterative denoising through stochastic differential equations (SDEs).\nOur work is inspired by the fact that with noise injected into the original\nimage, the defects may be changed into normal cases in the denoising process\n(i.e., reconstruction). First, based on the assumption that the anomalous data\nlie in the low probability density region of the normal data distribution, we\nexplain a common phenomenon that occurs when reconstruction-based approaches\nare applied to VDD: normal pixels also change during the reconstruction\nprocess. Second, due to the differences in normal pixels between the\nreconstructed and original images, a time-dependent gradient value (i.e.,\nscore) of normal data distribution is utilized as a metric, rather than\nreconstruction loss, to gauge the defects. Third, a novel $T$ scales approach\nis developed to dramatically reduce the required number of iterations,\naccelerating the inference process. These practices allow our model to\ngeneralize VDD in an unsupervised manner while maintaining reasonably good\nperformance. We evaluate our method on several datasets to demonstrate its\neffectiveness.",
    "descriptor": "",
    "authors": [
      "Yapeng Teng",
      "Haoyang Li",
      "Fuzhen Cai",
      "Ming Shao",
      "Siyu Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16092"
  },
  {
    "id": "arXiv:2211.16093",
    "title": "Penalizing Confident Predictions on Largely Perturbed Inputs Does Not  Improve Out-of-Distribution Generalization in Question Answering",
    "abstract": "Question answering (QA) models are shown to be insensitive to large\nperturbations to inputs; that is, they make correct and confident predictions\neven when given largely perturbed inputs from which humans can not correctly\nderive answers. In addition, QA models fail to generalize to other domains and\nadversarial test sets, while humans maintain high accuracy. Based on these\nobservations, we assume that QA models do not use intended features necessary\nfor human reading but rely on spurious features, causing the lack of\ngeneralization ability. Therefore, we attempt to answer the question: If the\noverconfident predictions of QA models for various types of perturbations are\npenalized, will the out-of-distribution (OOD) generalization be improved? To\nprevent models from making confident predictions on perturbed inputs, we first\nfollow existing studies and maximize the entropy of the output probability for\nperturbed inputs. However, we find that QA models trained to be sensitive to a\ncertain perturbation type are often insensitive to unseen types of\nperturbations. Thus, we simultaneously maximize the entropy for the four\nperturbation types (i.e., word- and sentence-level shuffling and deletion) to\nfurther close the gap between models and humans. Contrary to our expectations,\nalthough models become sensitive to the four types of perturbations, we find\nthat the OOD generalization is not improved. Moreover, the OOD generalization\nis sometimes degraded after entropy maximization. Making unconfident\npredictions on largely perturbed inputs per se may be beneficial to gaining\nhuman trust. However, our negative results suggest that researchers should pay\nattention to the side effect of entropy maximization.",
    "descriptor": "\nComments: Accepted to the KnowledgeNLP workshop at AAAI 2023\n",
    "authors": [
      "Kazutoshi Shinoda",
      "Saku Sugawara",
      "Akiko Aizawa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.16093"
  },
  {
    "id": "arXiv:2211.16095",
    "title": "Better Generalized Few-Shot Learning Even Without Base Data",
    "abstract": "This paper introduces and studies zero-base generalized few-shot learning\n(zero-base GFSL), which is an extreme yet practical version of few-shot\nlearning problem. Motivated by the cases where base data is not available due\nto privacy or ethical issues, the goal of zero-base GFSL is to newly\nincorporate the knowledge of few samples of novel classes into a pretrained\nmodel without any samples of base classes. According to our analysis, we\ndiscover the fact that both mean and variance of the weight distribution of\nnovel classes are not properly established, compared to those of base classes.\nThe existing GFSL methods attempt to make the weight norms balanced, which we\nfind helps only the variance part, but discard the importance of mean of\nweights particularly for novel classes, leading to the limited performance in\nthe GFSL problem even with base data. In this paper, we overcome this\nlimitation by proposing a simple yet effective normalization method that can\neffectively control both mean and variance of the weight distribution of novel\nclasses without using any base samples and thereby achieve a satisfactory\nperformance on both novel and base classes. Our experimental results somewhat\nsurprisingly show that the proposed zero-base GFSL method that does not utilize\nany base samples even outperforms the existing GFSL methods that make the best\nuse of base data.",
    "descriptor": "\nComments: Accepted in AAAI-2023\n",
    "authors": [
      "Seongwoong Kim",
      "Dong-Wan Choi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16095"
  },
  {
    "id": "arXiv:2211.16096",
    "title": "Construction of Multiple Constrained DNA Codes",
    "abstract": "DNA sequences are prone to creating secondary structures by folding back on\nthemselves by non-specific hybridization among its nucleotides. The formation\nof secondary structures makes the sequences chemically inactive towards\nsynthesis and sequencing processes. In this letter, our goal is to tackle the\nproblems due to the creation of secondary structures in DNA sequences along\nwith constraints such as not having a large homopolymer run length. In this\npaper, we have presented families of DNA codes with secondary structures of\nstem length at most two and homopolymer run length at most four. By mapping the\nerror correcting codes over $\\Z_{11}$ to DNA nucleotides, we obtained DNA codes\nwith rates $0.5765$ times the rate of corresponding code over $\\Z_{11}$, which\ninclude some new secondary structure free and better-performing codes for DNA\nbased data storage and DNA computing purposes.",
    "descriptor": "\nComments: 10 pages, 2 figures\n",
    "authors": [
      "Siddhartha Siddhiprada Bhoi",
      "Paramapalli Udaya",
      "Abhay Kumar Singh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.16096"
  },
  {
    "id": "arXiv:2211.16098",
    "title": "Three-stage binarization of color document images based on discrete  wavelet transform and generative adversarial networks",
    "abstract": "The efficient segmentation of foreground text information from the background\nin degraded color document images is a hot research topic. Due to the imperfect\npreservation of ancient documents over a long period of time, various types of\ndegradation, including staining, yellowing, and ink seepage, have seriously\naffected the results of image binarization. In this paper, a three-stage method\nis proposed for image enhancement and binarization of degraded color document\nimages by using discrete wavelet transform (DWT) and generative adversarial\nnetwork (GAN). In Stage-1, we use DWT and retain the LL subband images to\nachieve the image enhancement. In Stage-2, the original input image is split\ninto four (Red, Green, Blue and Gray) single-channel images, each of which\ntrains the independent adversarial networks. The trained adversarial network\nmodels are used to extract the color foreground information from the images. In\nStage-3, in order to combine global and local features, the output image from\nStage-2 and the original input image are used to train the independent\nadversarial networks for document binarization. The experimental results\ndemonstrate that our proposed method outperforms many classical and\nstate-of-the-art (SOTA) methods on the Document Image Binarization Contest\n(DIBCO) dataset. We release our implementation code at\nhttps://github.com/abcpp12383/ThreeStageBinarization.",
    "descriptor": "",
    "authors": [
      "Yu-Shian Lin",
      "Rui-Yang Ju",
      "Chih-Chia Chen",
      "Ting-Yu Lin",
      "Jen-Shiun Chiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16098"
  },
  {
    "id": "arXiv:2211.16101",
    "title": "Dependency-aware Self-training for Entity Alignment",
    "abstract": "Entity Alignment (EA), which aims to detect entity mappings (i.e. equivalent\nentity pairs) in different Knowledge Graphs (KGs), is critical for KG fusion.\nNeural EA methods dominate current EA research but still suffer from their\nreliance on labelled mappings. To solve this problem, a few works have explored\nboosting the training of EA models with self-training, which adds confidently\npredicted mappings into the training data iteratively. Though the effectiveness\nof self-training can be glimpsed in some specific settings, we still have very\nlimited knowledge about it. One reason is the existing works concentrate on\ndevising EA models and only treat self-training as an auxiliary tool. To fill\nthis knowledge gap, we change the perspective to self-training to shed light on\nit. In addition, the existing self-training strategies have limited impact\nbecause they introduce either much False Positive noise or a low quantity of\nTrue Positive pseudo mappings. To improve self-training for EA, we propose\nexploiting the dependencies between entities, a particularity of EA, to\nsuppress the noise without hurting the recall of True Positive mappings.\nThrough extensive experiments, we show that the introduction of dependency\nmakes the self-training strategy for EA reach a new level. The value of\nself-training in alleviating the reliance on annotation is actually much higher\nthan what has been realised. Furthermore, we suggest future study on smart data\nannotation to break the ceiling of EA performance.",
    "descriptor": "\nComments: WSDM 2023\n",
    "authors": [
      "Bing Liu",
      "Tiancheng Lan",
      "Wen Hua",
      "Guido Zuccon"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16101"
  },
  {
    "id": "arXiv:2211.16103",
    "title": "Text Representation Enrichment Utilizing Graph based Approaches: Stock  Market Technical Analysis Case Study",
    "abstract": "Graph neural networks (GNNs) have been utilized for various natural language\nprocessing (NLP) tasks lately. The ability to encode corpus-wide features in\ngraph representation made GNN models popular in various tasks such as document\nclassification. One major shortcoming of such models is that they mainly work\non homogeneous graphs, while representing text datasets as graphs requires\nseveral node types which leads to a heterogeneous schema. In this paper, we\npropose a transductive hybrid approach composed of an unsupervised node\nrepresentation learning model followed by a node classification/edge prediction\nmodel. The proposed model is capable of processing heterogeneous graphs to\nproduce unified node embeddings which are then utilized for node classification\nor link prediction as the downstream task. The proposed model is developed to\nclassify stock market technical analysis reports, which to our knowledge is the\nfirst work in this domain. Experiments, which are carried away using a\nconstructed dataset, demonstrate the ability of the model in embedding\nextraction and the downstream tasks.",
    "descriptor": "",
    "authors": [
      "Sara Salamat",
      "Nima Tavassoli",
      "Behnam Sabeti",
      "Reza Fahmi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Finance (q-fin.CP)"
    ],
    "url": "https://arxiv.org/abs/2211.16103"
  },
  {
    "id": "arXiv:2211.16104",
    "title": "Non-uniform complexity via non-wellfounded proofs",
    "abstract": "Cyclic and non-wellfounded proofs are now increasingly employed to establish\nmetalogical results in a variety of settings, in particular for type systems\nwith forms of (co)induction. Under the Curry-Howard correspondence, a cyclic\nproof can be seen as a typing derivation 'with loops', closer to low-level\nmachine models, and so comprise a highly expressive computational model that\nnonetheless enjoys excellent metalogical properties.\nIn recent work, we showed how the cyclic proof setting can be further\nemployed to model computational complexity, yielding characterisations of the\npolynomial time and elementary computable functions. These characterisations\nare 'implicit', inspired by Bellantoni and Cook's famous algebra of safe\nrecursion, but exhibit greater expressivity thanks to the looping capacity of\ncyclic proofs.\nIn this work we investigate the capacity for non-wellfounded proofs, where\nfinite presentability is relaxed, to model non-uniformity in complexity theory.\nIn particular, we present a characterisation of the class $\\mathsf{FP/poly}$ of\nfunctions computed by polynomial-size circuits. While relating\nnon-wellfoundedness to non-uniformity is a natural idea, the precise amount of\nirregularity, informally speaking, required to capture $\\mathsf{FP/poly}$ is\ngiven by proof-level conditions novel to cyclic proof theory. Along the way, we\nformalise some (presumably) folklore techniques for characterising non-uniform\nclasses in relativised function algebras with appropriate oracles.",
    "descriptor": "",
    "authors": [
      "Gianluca Curzi",
      "Anupam Das"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.16104"
  },
  {
    "id": "arXiv:2211.16106",
    "title": "Encoder-Decoder Model for Suffix Prediction in Predictive Monitoring",
    "abstract": "Predictive monitoring is a subfield of process mining that aims to predict\nhow a running case will unfold in the future. One of its main challenges is\nforecasting the sequence of activities that will occur from a given point in\ntime -- suffix prediction -- . Most approaches to the suffix prediction problem\nlearn to predict the suffix by learning how to predict the next activity only,\nnot learning from the whole suffix during the training phase. This paper\nproposes a novel architecture based on an encoder-decoder model with an\nattention mechanism that decouples the representation learning of the prefixes\nfrom the inference phase, predicting only the activities of the suffix. During\nthe inference phase, this architecture is extended with a heuristic search\nalgorithm that improves the selection of the activity for each index of the\nsuffix. Our approach has been tested using 12 public event logs against 6\ndifferent state-of-the-art proposals, showing that it significantly outperforms\nthese proposals.",
    "descriptor": "",
    "authors": [
      "Efr\u00e9n Rama-Maneiro",
      "Pablo Monteagudo-Lago",
      "Juan C. Vidal",
      "Manuel Lama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16106"
  },
  {
    "id": "arXiv:2211.16110",
    "title": "PAC-Bayes Bounds for Bandit Problems: A Survey and Experimental  Comparison",
    "abstract": "PAC-Bayes has recently re-emerged as an effective theory with which one can\nderive principled learning algorithms with tight performance guarantees.\nHowever, applications of PAC-Bayes to bandit problems are relatively rare,\nwhich is a great misfortune. Many decision-making problems in healthcare,\nfinance and natural sciences can be modelled as bandit problems. In many of\nthese applications, principled algorithms with strong performance guarantees\nwould be very much appreciated. This survey provides an overview of PAC-Bayes\nperformance bounds for bandit problems and an experimental comparison of these\nbounds. Our experimental comparison has revealed that available PAC-Bayes upper\nbounds on the cumulative regret are loose, whereas available PAC-Bayes lower\nbounds on the expected reward can be surprisingly tight. We found that an\noffline contextual bandit algorithm that learns a policy by optimising a\nPAC-Bayes bound was able to learn randomised neural network polices with\ncompetitive expected reward and non-vacuous performance guarantees.",
    "descriptor": "\nComments: 30 pages, 8 figures\n",
    "authors": [
      "Hamish Flynn",
      "David Reeb",
      "Melih Kandemir",
      "Jan Peters"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.16110"
  },
  {
    "id": "arXiv:2211.16113",
    "title": "Timing-Based Backpropagation in Spiking Neural Networks Without  Single-Spike Restrictions",
    "abstract": "We propose a novel backpropagation algorithm for training spiking neural\nnetworks (SNNs) that encodes information in the relative multiple spike timing\nof individual neurons without single-spike restrictions. The proposed algorithm\ninherits the advantages of conventional timing-based methods in that it\ncomputes accurate gradients with respect to spike timing, which promotes ideal\ntemporal coding. Unlike conventional methods where each neuron fires at most\nonce, the proposed algorithm allows each neuron to fire multiple times. This\nextension naturally improves the computational capacity of SNNs. Our SNN model\noutperformed comparable SNN models and achieved as high accuracy as\nnon-convolutional artificial neural networks. The spike count property of our\nnetworks was altered depending on the time constant of the postsynaptic current\nand the membrane potential. Moreover, we found that there existed the optimal\ntime constant with the maximum test accuracy. That was not seen in conventional\nSNNs with single-spike restrictions on time-to-fast-spike (TTFS) coding. This\nresult demonstrates the computational properties of SNNs that biologically\nencode information into the multi-spike timing of individual neurons. Our code\nwould be publicly available.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Kakei Yamamoto",
      "Yusuke Sakemi",
      "Kazuyuki Aihara"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16113"
  },
  {
    "id": "arXiv:2211.16117",
    "title": "A High Availability Management Model based on VM Significance Ranking  and Resource Estimation for Cloud Applications",
    "abstract": "Massive upsurge in cloud resource usage stave off service availability\nresulting into outages, resource contention, and excessive power-consumption.\nThe existing approaches have addressed this challenge by providing multi-cloud,\nVM migration, and running multiple replicas of each VM which accounts for high\nexpenses of cloud data centre (CDC). In this context, a novel VM Significance\nRanking and Resource Estimation based High Availability Management (SRE-HM)\nModel is proposed to enhance service availability for users with optimized cost\nfor CDC. The model estimates resource contention based server failure and\norganises needed resources beforehand for maintaining desired level of service\navailability. A significance ranking parameter is introduced and computed for\neach VM, executing critical or non-critical tasks followed by the selection of\nan admissible High Availability (HA) strategy respective to its significance\nand user specified constraints. It enables cost optimization for CDC by\nrendering failure tolerance strategies for significant VMs only instead of all\nthe VMs. The proposed model is evaluated and compared against state-of-the-arts\nby executing experiments using Google Cluster dataset. SRE-HM improved the\nservices availability up to 19.56% and scales down the number of active servers\nand power-consumption up to 26.67% and 19.1%, respectively over HA without\nSRE-HM.",
    "descriptor": "",
    "authors": [
      "Deepika Saxena",
      "Ashutosh Kumar Singh"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.16117"
  },
  {
    "id": "arXiv:2211.16118",
    "title": "Inferring Attack Relations for Gradual Semantics",
    "abstract": "A gradual semantics takes a weighted argumentation framework as input and\noutputs a final acceptability degree for each argument, with different\nsemantics performing the computation in different manners. In this work, we\nconsider the problem of attack inference. That is, given a gradual semantics, a\nset of arguments with associated initial weights, and the final desirable\nacceptability degrees associated with each argument, we seek to determine\nwhether there is a set of attacks on those arguments such that we can obtain\nthese acceptability degrees. The main contribution of our work is to\ndemonstrate that the associated decision problem, i.e., whether a set of\nattacks can exist which allows the final acceptability degrees to occur for\ngiven initial weights, is NP-complete for the weighted h-categoriser and\ncardinality-based semantics, and is polynomial for the weighted max-based\nsemantics, even for the complete version of the problem (where all initial\nweights and final acceptability degrees are known). We then briefly discuss how\nthis decision problem can be modified to find the attacks themselves and\nconclude by examining the partial problem where not all initial weights or\nfinal acceptability degrees may be known.",
    "descriptor": "",
    "authors": [
      "Nir Oren",
      "Bruno Yun"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16118"
  },
  {
    "id": "arXiv:2211.16122",
    "title": "G-CMP: Graph-enhanced Contextual Matrix Profile for unsupervised anomaly  detection in sensor-based remote health monitoring",
    "abstract": "Sensor-based remote health monitoring is used in industrial, urban and\nhealthcare settings to monitor ongoing operation of equipment and human health.\nAn important aim is to intervene early if anomalous events or adverse health is\ndetected. In the wild, these anomaly detection approaches are challenged by\nnoise, label scarcity, high dimensionality, explainability and wide variability\nin operating environments. The Contextual Matrix Profile (CMP) is a\nconfigurable 2-dimensional version of the Matrix Profile (MP) that uses the\ndistance matrix of all subsequences of a time series to discover patterns and\nanomalies. The CMP is shown to enhance the effectiveness of the MP and other\nSOTA methods at detecting, visualising and interpreting true anomalies in noisy\nreal world data from different domains. It excels at zooming out and\nidentifying temporal patterns at configurable time scales. However, the CMP\ndoes not address cross-sensor information, and cannot scale to high dimensional\ndata. We propose a novel, self-supervised graph-based approach for temporal\nanomaly detection that works on context graphs generated from the CMP distance\nmatrix. The learned graph embeddings encode the anomalous nature of a time\ncontext. In addition, we evaluate other graph outlier algorithms for the same\ntask. Given our pipeline is modular, graph construction, generation of graph\nembeddings, and pattern recognition logic can all be chosen based on the\nspecific pattern detection application. We verified the effectiveness of\ngraph-based anomaly detection and compared it with the CMP and 3 state-of-the\nart methods on two real-world healthcare datasets with different anomalies. Our\nproposed method demonstrated better recall, alert rate and generalisability.",
    "descriptor": "\nComments: 12 pages, 7 figures, Accepted to British Machine Vision Conference 2022\n",
    "authors": [
      "Nivedita Bijlani",
      "Oscar Mendez Maldonado",
      "Samaneh Kouchaki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16122"
  },
  {
    "id": "arXiv:2211.16124",
    "title": "Peculiarities of gender disambiguation and ordering of non-English  authors' names for Economic papers beyond core databases",
    "abstract": "This paper presents the results of further exploration of Crossref data\nrelated to Ukrainian Economics research (the first part can be found in\n[Mryglod, O., Nazarovets, S. & Kozmenko, S. (2021) Scientometrics, 126, 8187]).\nOur purpose is to supplement the quantitative portrait of Ukrainian Economics\ndiscipline with the results of gender and author ordering analysis at the level\nof individual authors, special methods of working with bibliographic data with\na predominant share of non-English authors are used. The properties of gender\nmixing, the likelihood of male and female authors occupying the first position\nin the authorship list, as well as the arrangements of names are studied. A\ndata set containing bibliographic records related to Ukrainian journal\npublications in the field of Economics is constructed using Crossref metadata.\nThe described stages for working with such specific data help to work at the\nlevel of authors and analyse, in particular, gender issues. Despite the larger\nnumber of female authors, gender equality is more likely to be reported at the\nindividual level for the discipline of Ukrainian Economics. The tendencies\ntowards collaborative or solo-publications and gender mixing patterns are found\nto be dependent on the journal: the differences for publications indexed in\nScopus and/or Web of Science databases are found. It has also been found that\nUkrainian Economics research is characterized by rather a non-alphabetical\norder of authors. To our knowledge, this is the first large-scale quantitative\nstudy of Ukrainian Economic discipline. The results obtained are valuable not\nonly at the national level, but also contribute to general knowledge about\nEconomic research, gender issues and authors' names ordering. Here, for the\nfirst time, attention is drawn to the explicit use of the features of the\nSlavic authors' names.",
    "descriptor": "\nComments: 1 figure\n",
    "authors": [
      "O. Mryglod",
      "S. Nazarovets",
      "S. Kozmenko"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2211.16124"
  },
  {
    "id": "arXiv:2211.16126",
    "title": "Joint Neural Architecture and Hyperparameter Search for Correlated Time  Series Forecasting",
    "abstract": "Sensors in cyber-physical systems often capture interconnected processes and\nthus emit correlated time series (CTS), the forecasting of which enables\nimportant applications. The key to successful CTS forecasting is to uncover the\ntemporal dynamics of time series and the spatial correlations among time\nseries. Deep learning-based solutions exhibit impressive performance at\ndiscerning these aspects. In particular, automated CTS forecasting, where the\ndesign of an optimal deep learning architecture is automated, enables\nforecasting accuracy that surpasses what has been achieved by manual\napproaches. However, automated CTS solutions remain in their infancy and are\nonly able to find optimal architectures for predefined hyperparameters and\nscale poorly to large-scale CTS. To overcome these limitations, we propose\nSEARCH, a joint, scalable framework, to automatically devise effective CTS\nforecasting models. Specifically, we encode each candidate architecture and\naccompanying hyperparameters into a joint graph representation. We introduce an\nefficient Architecture-Hyperparameter Comparator (AHC) to rank all\narchitecture-hyperparameter pairs, and we then further evaluate the top-ranked\npairs to select a final result. Extensive experiments on six benchmark datasets\ndemonstrate that SEARCH not only eliminates manual efforts but also is capable\nof better performance than manually designed and existing automatically\ndesigned CTS models. In addition, it shows excellent scalability to large CTS.",
    "descriptor": "\nComments: accepted by SIGMOD 2023\n",
    "authors": [
      "Xinle Wu",
      "Dalin Zhang",
      "Miao Zhang",
      "Chenjuan Guo",
      "Bin Yang",
      "Christian S. Jensen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.16126"
  },
  {
    "id": "arXiv:2211.16128",
    "title": "Trustless unknown-order groups",
    "abstract": "Groups of unknown order are of major interest due to their applications\nincluding time-lock puzzles, verifiable delay functions, and accumulators. In\nthis paper we focus on trustless setup: in this setting, the most popular\nunknown-order group construction is ideal class groups of imaginary quadratic\nfields.We argue that the full impact of Sutherland's generic group-order\nalgorithm has not been recognised in this context, and show that group sizes\ncurrently being proposed in practice (namely, approximately 830 bits) do not\nmeet the claimed security level. Instead, we claim that random group orders\nshould be at least 3300 bits to meet a 128-bit security level. For ideal class\ngroups this leads to discriminants of around 6656 bits, which are much larger\nthan desirable.One drawback of class groups is that current approaches require\napproximately 2log\\_2(N) bits to represent an element in a group of order N. We\nprovide two solutions to mitigate this blow-up in the size of representations.\nFirst, we explain how an idea of Bleichenbacher can be used to compress class\ngroup elements to (3/2)log\\_2(N) bits. Second, we note that using Jacobians of\nhyperelliptic curves (in other words, class groups of quadratic function\nfields) allows efficient compression to the optimal element representation size\nof log\\_2(N) bits. We discuss point-counting approaches for hyperelliptic\ncurves and argue that genus-3 curves are secure in the trustless unknown-order\nsetting. We conclude that in practice, Jacobians of hyperelliptic curves are\nmore efficient in practice than ideal class groups at the same security level\n-- both in the group operation and in the size of the element representation.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Samuel Dobson",
      "Steven Galbraith",
      "Benjamin Smith"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2211.16128"
  },
  {
    "id": "arXiv:2211.16135",
    "title": "AdaEnlight: Energy-aware Low-light Video Stream Enhancement on Mobile  Devices",
    "abstract": "The ubiquity of camera-embedded devices and the advances in deep learning\nhave stimulated various intelligent mobile video applications. These\napplications often demand on-device processing of video streams to deliver\nreal-time, high-quality services for privacy and robustness concerns. However,\nthe performance of these applications is constrained by the raw video streams,\nwhich tend to be taken with small-aperture cameras of ubiquitous mobile\nplatforms in dim light. Despite extensive low-light video enhancement\nsolutions, they are unfit for deployment to mobile devices due to their complex\nmodels and and ignorance of system dynamics like energy budgets. In this paper,\nwe propose AdaEnlight, an energy-aware low-light video stream enhancement\nsystem on mobile devices. It achieves real-time video enhancement with\ncompetitive visual quality while allowing runtime behavior adaptation to the\nplatform-imposed dynamic energy budgets. We report extensive experiments on\ndiverse datasets, scenarios, and platforms and demonstrate the superiority of\nAdaEnlight compared with state-of-the-art low-light image and video enhancement\nsolutions.",
    "descriptor": "",
    "authors": [
      "Sicong Liu",
      "Xiaochen Li",
      "Zimu Zhou",
      "Bin Guo",
      "Meng Zhang",
      "Haochen Shen",
      "Zhiwen Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16135"
  },
  {
    "id": "arXiv:2211.16143",
    "title": "Fair Division with Prioritized Agents",
    "abstract": "We consider the fair division problem of indivisible items. It is well-known\nthat an envy-free allocation may not exist, and a relaxed version of\nenvy-freeness, envy-freeness up to one item (EF1), has been widely considered.\nIn an EF1 allocation, an agent may envy others' allocated shares, but only up\nto one item. In many applications, we may wish to specify a subset of\nprioritized agents where strict envy-freeness needs to be guaranteed from these\nagents to the remaining agents, while ensuring the whole allocation is still\nEF1. Prioritized agents may be those agents who are envious in a previous EF1\nallocation, those agents who belong to underrepresented groups, etc. Motivated\nby this, we propose a new fairness notion named envy-freeness with prioritized\nagents \"EFPrior\", and study the existence and the algorithmic aspects for the\nproblem of computing an EFPrior allocation. With additive valuations, the\nsimple round-robin algorithm is able to compute an EFPrior allocation. In this\npaper, we mainly focus on general valuations. In particular, we present a\npolynomial-time algorithm that outputs an EFPrior allocation with most of the\nitems allocated. When all the items need to be allocated, we also present\npolynomial-time algorithms for some well-motivated special cases.",
    "descriptor": "\nComments: 15 pages, 1 figure; accepted in AAAI'23\n",
    "authors": [
      "Xiaolin Bu",
      "Zihao Li",
      "Shengxin Liu",
      "Jiaxin Song",
      "Biaoshuai Tao"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.16143"
  },
  {
    "id": "arXiv:2211.16145",
    "title": "Lettuce modelling for growth control in precision agriculture",
    "abstract": "Improving the efficiency of agriculture is a growing priority due to food\nsecurity issues, environmental concerns, and economics. Using precision\nagriculture, remote sensing, and variable rate application technology we can\npotentially improve the efficiency of fertiliser use in agriculture while\nmaintaining or increasing yields. However, this requires the development of\ncontrol algorithms suitable for the challenges of the agricultural industry.\nIn this paper, we propose a new mechanistic open model of lettuce crop growth\nfor use in control of precision agriculture. We demonstrate that our model is\ncooperative and we validate it through experimental data. We use the model to\nshow, via simulations, that a simple proportional distributed control law\nincreases crop uniformity and yield, even in the presence of sparse actuation\nand noisy observations.",
    "descriptor": "\nComments: 8 pages, Submitted to ECC23\n",
    "authors": [
      "William Rohde",
      "Fulvio Forni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.16145"
  },
  {
    "id": "arXiv:2211.16147",
    "title": "New Results for the Text Recognition of Arabic Maghrib{\u012b} Manuscripts  -- Managing an Under-resourced Script",
    "abstract": "HTR models development has become a conventional step for digital humanities\nprojects. The performance of these models, often quite high, relies on manual\ntranscription and numerous handwritten documents. Although the method has\nproven successful for Latin scripts, a similar amount of data is not yet\nachievable for scripts considered poorly-endowed, like Arabic scripts. In that\nrespect, we are introducing and assessing a new modus operandi for HTR models\ndevelopment and fine-tuning dedicated to the Arabic Maghrib{\\=i} scripts. The\ncomparison between several state-of-the-art HTR demonstrates the relevance of a\nword-based neural approach specialized for Arabic, capable to achieve an error\nrate below 5% with only 10 pages manually transcribed. These results open new\nperspectives for Arabic scripts processing and more generally for\npoorly-endowed languages processing. This research is part of the development\nof RASAM dataset in partnership with the GIS MOMM and the BULAC.",
    "descriptor": "",
    "authors": [
      "Lucas No\u00ebmie",
      "Cl\u00e9ment Salah",
      "Chahan Vidal-Gor\u00e8ne"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16147"
  },
  {
    "id": "arXiv:2211.16152",
    "title": "Wavelet Diffusion Models are fast and scalable Image Generators",
    "abstract": "Diffusion models are rising as a powerful solution for high-fidelity image\ngeneration, which exceeds GANs in quality in many circumstances. However, their\nslow training and inference speed is a huge bottleneck, blocking them from\nbeing used in real-time applications. A recent DiffusionGAN method\nsignificantly decreases the models' running time by reducing the number of\nsampling steps from thousands to several, but their speeds still largely lag\nbehind the GAN counterparts. This paper aims to reduce the speed gap by\nproposing a novel wavelet-based diffusion structure. We extract low-and-high\nfrequency components from both image and feature levels via wavelet\ndecomposition and adaptively handle these components for faster processing\nwhile maintaining good generation quality. Furthermore, we propose to use a\nreconstruction term, which effectively boosts the model training convergence.\nExperimental results on CelebA-HQ, CIFAR-10, LSUN-Church, and STL-10 datasets\nprove our solution is a stepping-stone to offering real-time and high-fidelity\ndiffusion models. Our code and pre-trained checkpoints will be available at\n\\url{https://github.com/VinAIResearch/WaveDiff.git}.",
    "descriptor": "",
    "authors": [
      "Hao Phung",
      "Quan Dao",
      "Anh Tran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.16152"
  },
  {
    "id": "arXiv:2211.16158",
    "title": "Out-Of-Distribution Detection Is Not All You Need",
    "abstract": "The usage of deep neural networks in safety-critical systems is limited by\nour ability to guarantee their correct behavior. Runtime monitors are\ncomponents aiming to identify unsafe predictions and discard them before they\ncan lead to catastrophic consequences. Several recent works on runtime\nmonitoring have focused on out-of-distribution (OOD) detection, i.e.,\nidentifying inputs that are different from the training data. In this work, we\nargue that OOD detection is not a well-suited framework to design efficient\nruntime monitors and that it is more relevant to evaluate monitors based on\ntheir ability to discard incorrect predictions. We call this setting\nout-ofmodel-scope detection and discuss the conceptual differences with OOD. We\nalso conduct extensive experiments on popular datasets from the literature to\nshow that studying monitors in the OOD setting can be misleading: 1. very good\nOOD results can give a false impression of safety, 2. comparison under the OOD\nsetting does not allow identifying the best monitor to detect errors. Finally,\nwe also show that removing erroneous training data samples helps to train\nbetter monitors.",
    "descriptor": "",
    "authors": [
      "Joris Gu\u00e9rin",
      "Kevin Delmas",
      "Raul Sena Ferreira",
      "J\u00e9r\u00e9mie Guiochet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.16158"
  },
  {
    "id": "arXiv:2211.16162",
    "title": "Multi-Server Over-the-Air Federated Learning",
    "abstract": "In this work, we propose a communication-efficient two-layer federated\nlearning algorithm for distributed setups including a core server and multiple\nedge servers with clusters of devices. Assuming different learning tasks,\nclusters with a same task collaborate. To implement the algorithm over wireless\nlinks, we propose a scalable clustered over-the-air aggregation scheme for the\nuplink with a bandwidth-limited broadcast scheme for the downlink that requires\nonly two single resource blocks for each algorithm iteration, independent of\nthe number of edge servers and devices. This setup is faced with interference\nof devices in the uplink and interference of edge servers in the downlink that\nare to be modeled rigorously. We first develop a spatial model for the setup by\nmodeling devices as a Poisson cluster process over the edge servers and\nquantify uplink and downlink error terms due to the interference. Accordingly,\nwe present a comprehensive mathematical approach to derive the convergence\nbound for the proposed algorithm including any number of collaborating clusters\nin the setup and provide important special cases and design remarks. Finally,\nwe show that despite the interference in the proposed uplink and downlink\nschemes, the proposed algorithm achieves high learning accuracy for a variety\nof parameters.",
    "descriptor": "",
    "authors": [
      "Seyed Mohammad Azimi-Abarghouyi",
      "Viktoria Fodor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16162"
  },
  {
    "id": "arXiv:2211.16164",
    "title": "Few-shot Query-Focused Summarization with Prefix-Merging",
    "abstract": "Query-focused summarization has been considered as an important extension for\ntext summarization. It aims to generate a concise highlight for a given query.\nDifferent from text summarization, query-focused summarization has long been\nplagued by the problem of lacking high-quality large-scale datasets. In this\npaper, we investigate the idea that whether we can integrate and transfer the\nknowledge of text summarization and question answering to assist the few-shot\nlearning in query-focused summarization. Here, we propose prefix-merging, a\nprefix-based pretraining strategy for few-shot learning in query-focused\nsummarization. Drawn inspiration from prefix-tuning, we are allowed to\nintegrate the task knowledge from text summarization and question answering\ninto a properly designed prefix and apply the merged prefix to query-focused\nsummarization. With only a small amount of trainable parameters, prefix-merging\noutperforms fine-tuning on query-focused summarization. We further discuss the\ninfluence of different prefix designs and propose a visualized explanation for\nhow prefix-merging works.",
    "descriptor": "\nComments: Accepted by EMNLP2022\n",
    "authors": [
      "Ruifeng Yuan",
      "Zili Wang",
      "Ziqiang Cao",
      "Wenjie Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16164"
  },
  {
    "id": "arXiv:2211.16168",
    "title": "Robust boundary integral equations for the solution of elastic  scattering problems via Helmholtz decompositions",
    "abstract": "Helmholtz decompositions of the elastic fields open up new avenues for the\nsolution of linear elastic scattering problems via boundary integral equations\n(BIE) [Dong, Lai, Li, Mathematics of Computation,2021]. The main appeal of this\napproach is that the ensuing systems of BIE feature only integral operators\nassociated with the Helmholtz equation. However, these BIE involve non standard\nboundary integral operators that do not result after the application of either\nthe Dirichlet or the Neumann trace to Helmholtz single and double layer\npotentials. Rather, the Helmholtz decomposition approach leads to BIE\nformulations of elastic scattering problems with Neumann boundary conditions\nthat involve boundary traces of the Hessians of Helmholtz layer potential. As a\nconsequence, the classical combined field approach applied in the framework of\nthe Helmholtz decompositions leads to BIE formulations which, although robust,\nare not of the second kind. Following the regularizing methodology introduced\nin [Boubendir, Dominguez, Levadoux, Turc, SIAM Journal on Applied Mathematics\n2015] we design and analyze novel robust Helmholtz decomposition BIE for the\nsolution of elastic scattering that are of the second kind in the case of\nsmooth scatterers in two dimensions. We present a variety of numerical results\nbased on Nystrom discretizations that illustrate the good performance of the\nsecond kind regularized formulations in connections to iterative solvers.",
    "descriptor": "\nComments: 36 pages, 10 figures\n",
    "authors": [
      "V. Dominguez",
      "C. Turc"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.16168"
  },
  {
    "id": "arXiv:2211.16172",
    "title": "Learnings from Technological Interventions in a Low Resource Language:  Enhancing Information Access in Gondi",
    "abstract": "The primary obstacle to developing technologies for low-resource languages is\nthe lack of representative, usable data. In this paper, we report the\ndeployment of technology-driven data collection methods for creating a corpus\nof more than 60,000 translations from Hindi to Gondi, a low-resource vulnerable\nlanguage spoken by around 2.3 million tribal people in south and central India.\nDuring this process, we help expand information access in Gondi across 2\ndifferent dimensions (a) The creation of linguistic resources that can be used\nby the community, such as a dictionary, children's stories, Gondi translations\nfrom multiple sources and an Interactive Voice Response (IVR) based mass\nawareness platform; (b) Enabling its use in the digital domain by developing a\nHindi-Gondi machine translation model, which is compressed by nearly 4 times to\nenable it's edge deployment on low-resource edge devices and in areas of little\nto no internet connectivity. We also present preliminary evaluations of\nutilizing the developed machine translation model to provide assistance to\nvolunteers who are involved in collecting more data for the target language.\nThrough these interventions, we not only created a refined and evaluated corpus\nof 26,240 Hindi-Gondi translations that was used for building the translation\nmodel but also engaged nearly 850 community members who can help take Gondi\nonto the internet.",
    "descriptor": "\nComments: In Submission (Revised) to Language Resources and Evaluation Journal. arXiv admin note: text overlap with arXiv:2004.10270\n",
    "authors": [
      "Devansh Mehta",
      "Harshita Diddee",
      "Ananya Saxena",
      "Anurag Shukla",
      "Sebastin Santy",
      "Ramaravind Kommiya Mothilal",
      "Brij Mohan Lal Srivastava",
      "Alok Sharma",
      "Vishnu Prasad",
      "Venkanna U",
      "Kalika Bali"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.16172"
  },
  {
    "id": "arXiv:2211.16174",
    "title": "CUNI Submission in WMT22 General Task",
    "abstract": "We present the CUNI-Bergamot submission for the WMT22 General translation\ntask. We compete in English$\\rightarrow$Czech direction. Our submission further\nexplores block backtranslation techniques. Compared to the previous work, we\nmeasure performance in terms of COMET score and named entities translation\naccuracy. We evaluate performance of MBR decoding compared to traditional mixed\nbacktranslation training and we show a possible synergy when using both of the\ntechniques simultaneously. The results show that both approaches are effective\nmeans of improving translation quality and they yield even better results when\ncombined.",
    "descriptor": "\nComments: 8 pages, WMT22\n",
    "authors": [
      "Josef Jon",
      "Martin Popel",
      "Ond\u0159ej Bojar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.16174"
  },
  {
    "id": "arXiv:2211.16175",
    "title": "Context-Aware Robust Fine-Tuning",
    "abstract": "Contrastive Language-Image Pre-trained (CLIP) models have zero-shot ability\nof classifying an image belonging to \"[CLASS]\" by using similarity between the\nimage and the prompt sentence \"a [CONTEXT] of [CLASS]\". Based on exhaustive\ntext cues in \"[CONTEXT]\", CLIP model is aware of different contexts, e.g.\nbackground, style, viewpoint, and exhibits unprecedented robustness against a\nwide range of distribution shifts. However, recent works find further\nfine-tuning of CLIP models improves accuracy but sacrifices the robustness on\ndownstream tasks. We conduct an empirical investigation to show fine-tuning\nwill corrupt the context-aware ability of pre-trained CLIP features. To solve\nthis problem, we propose Context-Aware Robust Fine-tuning (CAR-FT). CAR-FT\nregularizes the model during fine-tuning to capture the context information.\nSpecifically, we use zero-shot prompt weights to get the context distribution\ncontained in the image. By minimizing the Kullback-Leibler Divergence (KLD)\nbetween context distributions induced by original/fine-tuned CLIP models,\nCAR-FT makes the context-aware ability of CLIP inherited into downstream tasks,\nand achieves both higher In-Distribution (ID) and Out-Of-Distribution (OOD)\naccuracy. The experimental results show CAR-FT achieves superior robustness on\nfive OOD test datasets of ImageNet, and meanwhile brings accuracy gains on nine\ndownstream tasks. Additionally, CAR-FT surpasses previous Domain Generalization\n(DG) methods and gets 78.5% averaged accuracy on DomainBed benchmark, building\nthe new state-of-the-art.",
    "descriptor": "",
    "authors": [
      "Xiaofeng Mao",
      "Yuefeng Chen",
      "Xiaojun Jia",
      "Rong Zhang",
      "Hui Xue",
      "Zhao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16175"
  },
  {
    "id": "arXiv:2211.16177",
    "title": "Rao-Burbea centroids applied to the statistical characterisation of time  series and images through ordinal patterns",
    "abstract": "Divergences or similarity measures between probability distributions have\nbecome a very useful tool for studying different aspects of statistical objects\nsuch as time series, networks and images. Notably not every divergence provides\nidentical results when applied to the same problem. Therefore it is convenient\nto have the widest possible set of divergences to be applied to the problems\nunder study. Besides this choice an essential step in the analysis of every\nstatistical object is the mapping of each one of their representing values into\nan alphabet of symbols conveniently chosen. In this work we attack both\nproblems, that is, the choice of a family of divergences and the way to do the\nmap into a symbolic sequence. For advancing in the first task we work with the\nfamily of divergences known as the Burbea-Rao centroids (BRC) and for the\nsecond one we proceed by mapping the original object into a symbolic sequence\nthrough the use of ordinal patterns. Finally we apply our proposals to analyse\nsimulated and real time series and to real textured images. The main conclusion\nof our work is that the best BRC, at least in the studied cases, is the Jensen\nShannon divergence, besides the fact that it verifies some interesting formal\nproperties.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Diego M. Mateos",
      "Leonardo E. Riveaud",
      "Pedro W. Lamberti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.16177"
  },
  {
    "id": "arXiv:2211.16183",
    "title": "Active 3D Double-RIS-Aided Multi-User Communications:  Two-Timescale-Based Separate Channel Estimation via Bayesian Learning",
    "abstract": "Double-reconfigurable intelligent surface (RIS) is a promising technique,\nachieving a substantial gain improvement compared to single-RIS techniques.\nHowever, in double-RIS-aided systems, accurate channel estimation is more\nchallenging than in single-RIS-aided systems. This work solves the problem of\ndouble-RIS-based channel estimation based on active RIS architectures with only\none radio frequency (RF) chain. Since the slow time-varying channels, i.e., the\nBS-RIS 1, BS-RIS 2, and RIS 1-RIS 2 channels, can be obtained with active RIS\narchitectures, a novel multi-user two-timescale channel estimation protocol is\nproposed to minimize the pilot overhead. First, we propose an uplink training\nscheme for slow time-varying channel estimation, which can effectively address\nthe double-reflection channel estimation problem. With channels' sparisty, a\nlow-complexity Singular Value Decomposition Multiple Measurement Vector-Based\nCompressive Sensing (SVD-MMV-CS) framework with the line-of-sight (LoS)-aided\noff-grid MMV expectation maximization-based generalized approximate message\npassing (M-EM-GAMP) algorithm is proposed for channel parameter recovery. For\nfast time-varying channel estimation, based on the estimated large-timescale\nchannels, a measurements-augmentation-estimate (MAE) framework is developed to\ndecrease the pilot overhead.Additionally, a comprehensive analysis of pilot\noverhead and computing complexity is conducted. Finally, the simulation results\ndemonstrate the effectiveness of our proposed multi-user two-timescale\nestimation strategy and the low-complexity Bayesian CS framework.",
    "descriptor": "",
    "authors": [
      "Songjie Yang",
      "Wanting Lyu",
      "Yue Xiu",
      "Zhongpei Zhang",
      "Chau Yuen"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.16183"
  },
  {
    "id": "arXiv:2211.16185",
    "title": "Disentangled Generation with Information Bottleneck for Few-Shot  Learning",
    "abstract": "Few-shot learning (FSL), which aims to classify unseen classes with few\nsamples, is challenging due to data scarcity. Although various generative\nmethods have been explored for FSL, the entangled generation process of these\nmethods exacerbates the distribution shift in FSL, thus greatly limiting the\nquality of generated samples. To these challenges, we propose a novel\nInformation Bottleneck (IB) based Disentangled Generation Framework for FSL,\ntermed as DisGenIB, that can simultaneously guarantee the discrimination and\ndiversity of generated samples. Specifically, we formulate a novel framework\nwith information bottleneck that applies for both disentangled representation\nlearning and sample generation. Different from existing IB-based methods that\ncan hardly exploit priors, we demonstrate our DisGenIB can effectively utilize\npriors to further facilitate disentanglement. We further prove in theory that\nsome previous generative and disentanglement methods are special cases of our\nDisGenIB, which demonstrates the generality of the proposed DisGenIB. Extensive\nexperiments on challenging FSL benchmarks confirm the effectiveness and\nsuperiority of DisGenIB, together with the validity of our theoretical\nanalyses. Our codes will be open-source upon acceptance.",
    "descriptor": "",
    "authors": [
      "Zhuohang Dang",
      "Jihong Wang",
      "Minnan Luo",
      "Chengyou Jia",
      "Caixia Yan",
      "Qinghua Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16185"
  },
  {
    "id": "arXiv:2211.16187",
    "title": "Quantization-aware Interval Bound Propagation for Training Certifiably  Robust Quantized Neural Networks",
    "abstract": "We study the problem of training and certifying adversarially robust\nquantized neural networks (QNNs). Quantization is a technique for making neural\nnetworks more efficient by running them using low-bit integer arithmetic and is\ntherefore commonly adopted in industry. Recent work has shown that\nfloating-point neural networks that have been verified to be robust can become\nvulnerable to adversarial attacks after quantization, and certification of the\nquantized representation is necessary to guarantee robustness. In this work, we\npresent quantization-aware interval bound propagation (QA-IBP), a novel method\nfor training robust QNNs. Inspired by advances in robust learning of\nnon-quantized networks, our training algorithm computes the gradient of an\nabstract representation of the actual network. Unlike existing approaches, our\nmethod can handle the discrete semantics of QNNs. Based on QA-IBP, we also\ndevelop a complete verification procedure for verifying the adversarial\nrobustness of QNNs, which is guaranteed to terminate and produce a correct\nanswer. Compared to existing approaches, the key advantage of our verification\nprocedure is that it runs entirely on GPU or other accelerator devices. We\ndemonstrate experimentally that our approach significantly outperforms existing\nmethods and establish the new state-of-the-art for training and certifying the\nrobustness of QNNs.",
    "descriptor": "\nComments: Accepted at AAAI 2023\n",
    "authors": [
      "Mathias Lechner",
      "\u0110or\u0111e \u017dikeli\u0107",
      "Krishnendu Chatterjee",
      "Thomas A. Henzinger",
      "Daniela Rus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16187"
  },
  {
    "id": "arXiv:2211.16190",
    "title": "Physics Informed Neural Network for Dynamic Stress Prediction",
    "abstract": "Structural failures are often caused by catastrophic events such as\nearthquakes and winds. As a result, it is crucial to predict dynamic stress\ndistributions during highly disruptive events in real time. Currently available\nhigh-fidelity methods, such as Finite Element Models (FEMs), suffer from their\ninherent high complexity. Therefore, to reduce computational cost while\nmaintaining accuracy, a Physics Informed Neural Network (PINN), PINN-Stress\nmodel, is proposed to predict the entire sequence of stress distribution based\non Finite Element simulations using a partial differential equation (PDE)\nsolver. Using automatic differentiation, we embed a PDE into a deep neural\nnetwork's loss function to incorporate information from measurements and PDEs.\nThe PINN-Stress model can predict the sequence of stress distribution in almost\nreal-time and can generalize better than the model without PINN.",
    "descriptor": "\nComments: 14 pages, 13 figures\n",
    "authors": [
      "Hamed Bolandi",
      "Gautam Sreekumar",
      "Xuyang Li",
      "Nizar Lajnef",
      "Vishnu Naresh Boddeti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16190"
  },
  {
    "id": "arXiv:2211.16191",
    "title": "SgVA-CLIP: Semantic-guided Visual Adapting of Vision-Language Models for  Few-shot Image Classification",
    "abstract": "Although significant progress has been made in few-shot learning, most of\nexisting few-shot learning methods require supervised pre-training on a large\namount of samples of base classes, which limits their generalization ability in\nreal world application. Recently, large-scale self-supervised vision-language\nmodels (e.g., CLIP) have provided a new paradigm for transferable visual\nrepresentation learning. However, the pre-trained VLPs may neglect detailed\nvisual information that is difficult to describe by language sentences, but\nimportant for learning an effective classifier in few-shot classification. To\naddress the above problem, we propose a new framework, named Semantic-guided\nVisual Adapting (SgVA), which can effectively extend vision-language\npre-trained models to produce discriminative task-specific visual features by\ncomprehensively using a vision-specific contrastive loss, a cross-modal\ncontrastive loss, and an implicit knowledge distillation. The implicit\nknowledge distillation is designed to transfer the fine-grained cross-modal\nknowledge to guide the updating of the vision adapter. State-of-the-art results\non 13 datasets demonstrate that the adapted visual features can well complement\nthe cross-modal features to improve few-shot image classification.",
    "descriptor": "",
    "authors": [
      "Fang Peng",
      "Xiaoshan Yang",
      "Changsheng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.16191"
  },
  {
    "id": "arXiv:2211.16192",
    "title": "Be Careful with Rotation: A Uniform Backdoor Pattern for 3D Shape",
    "abstract": "For saving cost, many deep neural networks (DNNs) are trained on third-party\ndatasets downloaded from internet, which enables attacker to implant backdoor\ninto DNNs. In 2D domain, inherent structures of different image formats are\nsimilar. Hence, backdoor attack designed for one image format will suite for\nothers. However, when it comes to 3D world, there is a huge disparity among\ndifferent 3D data structures. As a result, backdoor pattern designed for one\ncertain 3D data structure will be disable for other data structures of the same\n3D scene. Therefore, this paper designs a uniform backdoor pattern: NRBdoor\n(Noisy Rotation Backdoor) which is able to adapt for heterogeneous 3D data\nstructures. Specifically, we start from the unit rotation and then search for\nthe optimal pattern by noise generation and selection process. The proposed\nNRBdoor is natural and imperceptible, since rotation is a common operation\nwhich usually contains noise due to both the miss match between a pair of\npoints and the sensor calibration error for real-world 3D scene. Extensive\nexperiments on 3D mesh and point cloud show that the proposed NRBdoor achieves\nstate-of-the-art performance, with negligible shape variation.",
    "descriptor": "",
    "authors": [
      "Linkun Fan",
      "Fazhi He",
      "Qing Guo",
      "Wei Tang",
      "Xiaolin Hong",
      "Bing Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.16192"
  },
  {
    "id": "arXiv:2211.16193",
    "title": "In-Hand 3D Object Scanning from an RGB Sequence",
    "abstract": "We propose a method for in-hand 3D scanning of an unknown object from a\nsequence of color images. We cast the problem as reconstructing the object\nsurface from un-posed multi-view images and rely on a neural implicit surface\nrepresentation that captures both the geometry and the appearance of the\nobject. By contrast with most NeRF-based methods, we do not assume that the\ncamera-object relative poses are known and instead simultaneously optimize both\nthe object shape and the pose trajectory. As global optimization over all the\nshape and pose parameters is prone to fail without coarse-level initialization\nof the poses, we propose an incremental approach which starts by splitting the\nsequence into carefully selected overlapping segments within which the\noptimization is likely to succeed. We incrementally reconstruct the object\nshape and track the object poses independently within each segment, and later\nmerge all the segments by aligning poses estimated at the overlapping frames.\nFinally, we perform a global optimization over all the aligned segments to\nachieve full reconstruction. We experimentally show that the proposed method is\nable to reconstruct the shape and color of both textured and challenging\ntexture-less objects, outperforms classical methods that rely only on\nappearance features, and its performance is close to recent methods that assume\nknown camera poses.",
    "descriptor": "",
    "authors": [
      "Shreyas Hampali",
      "Tomas Hodan",
      "Luan Tran",
      "Lingni Ma",
      "Cem Keskin",
      "Vincent Lepetit"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16193"
  },
  {
    "id": "arXiv:2211.16195",
    "title": "Easy and complex: new perspectives for metadata modeling using RDF-star  and Named Graphs",
    "abstract": "The Resource Description Framework is well-established as a lingua franca for\ndata modeling and is designed to integrate heterogeneous data at instance and\nschema level using statements. While RDF is conceptually simple, data models\nnevertheless get complex, when complex data needs to be represented. Additional\nlevels of indirection with intermediate resources instead of simple properties\nlead to higher barriers for prospective users of the data. Based on three\npatterns, we argue that shifting information to a meta-level can not only be\nused to (1) provide provenance information, but can also help to (2) maintain\nbackwards compatibility for existing models, and to (3) reduce the complexity\nof a data model. There are, however, multiple ways in RDF to use a meta-level,\ni.e., to provide additional statements about statements. With Named Graphs,\nthere exists a well-established mechanism to describe groups of statements.\nSince its inception, however, it has been hard to make statements about single\nstatements. With the introduction of RDF-star, a new way to provide data about\nsingle statements is now available. We show that the combination of RDF-star\nand Named Graphs is a viable solution to express data on a meta-level and\npropose that this meta-level should be used as first class citizen in data\nmodeling.",
    "descriptor": "\nComments: The Version of Record of this contribution is published in Knowledge Graphs and Semantic Web . KGSWC 2022. Communications in Computer and Information Science, vol 1686. Springer, Cham and is available online at this https URL\n",
    "authors": [
      "Florian Rupp",
      "Benjamin Schnabel",
      "Kai Eckert"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.16195"
  },
  {
    "id": "arXiv:2211.16197",
    "title": "FJMP: Factorized Joint Multi-Agent Motion Prediction over Learned  Directed Acyclic Interaction Graphs",
    "abstract": "Predicting the future motion of road agents is a critical task in an\nautonomous driving pipeline. In this work, we address the problem of generating\na set of scene-level, or joint, future trajectory predictions in multi-agent\ndriving scenarios. To this end, we propose FJMP, a Factorized Joint Motion\nPrediction framework for multi-agent interactive driving scenarios. FJMP models\nthe future scene interaction dynamics as a sparse directed interaction graph,\nwhere edges denote explicit interactions between agents. We then prune the\ngraph into a directed acyclic graph (DAG) and decompose the joint prediction\ntask into a sequence of marginal and conditional predictions according to the\npartial ordering of the DAG, where joint future trajectories are decoded using\na directed acyclic graph neural network (DAGNN). We conduct experiments on the\nINTERACTION and Argoverse 2 datasets and demonstrate that FJMP produces more\naccurate and scene-consistent joint trajectory predictions than non-factorized\napproaches, especially on the most interactive and kinematically interesting\nagents. FJMP ranks 1st on the multi-agent test leaderboard of the INTERACTION\ndataset.",
    "descriptor": "",
    "authors": [
      "Luke Rowe",
      "Martin Ethier",
      "Eli-Henry Dykhne",
      "Krzysztof Czarnecki"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.16197"
  },
  {
    "id": "arXiv:2211.16198",
    "title": "SuS-X: Training-Free Name-Only Transfer of Vision-Language Models",
    "abstract": "Contrastive Language-Image Pre-training (CLIP) has emerged as a simple yet\neffective way to train large-scale vision-language models. CLIP demonstrates\nimpressive zero-shot classification and retrieval on diverse downstream tasks.\nHowever, to leverage its full potential, fine-tuning still appears to be\nnecessary. Fine-tuning the entire CLIP model can be resource-intensive and\nunstable. Moreover, recent methods that aim to circumvent this need for\nfine-tuning still require access to images from the target distribution. In\nthis paper, we pursue a different approach and explore the regime of\ntraining-free \"name-only transfer\" in which the only knowledge we possess about\nthe downstream task comprises the names of downstream target categories. We\npropose a novel method, SuS-X, consisting of two key building blocks -- SuS and\nTIP-X, that requires neither intensive fine-tuning nor costly labelled data.\nSuS-X achieves state-of-the-art zero-shot classification results on 19\nbenchmark datasets. We further show the utility of TIP-X in the training-free\nfew-shot setting, where we again achieve state-of-the-art results over strong\ntraining-free baselines. Code is available at\nhttps://github.com/vishaal27/SuS-X.",
    "descriptor": "",
    "authors": [
      "Vishaal Udandarao",
      "Ankush Gupta",
      "Samuel Albanie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.16198"
  },
  {
    "id": "arXiv:2211.16199",
    "title": "Latent Graph Inference using Product Manifolds",
    "abstract": "Graph Neural Networks usually rely on the assumption that the graph topology\nis available to the network as well as optimal for the downstream task. Latent\ngraph inference allows models to dynamically learn the intrinsic graph\nstructure of problems where the connectivity patterns of data may not be\ndirectly accessible. In this work, we generalize the discrete Differentiable\nGraph Module (dDGM) for latent graph learning. The original dDGM architecture\nused the Euclidean plane to encode latent features based on which the latent\ngraphs were generated. By incorporating Riemannian geometry into the model and\ngenerating more complex embedding spaces, we can improve the performance of the\nlatent graph inference system. In particular, we propose a computationally\ntractable approach to produce product manifolds of constant curvature model\nspaces that can encode latent features of varying structure. The latent\nrepresentations mapped onto the inferred product manifold are used to compute\nricher similarity measures that are leveraged by the latent graph learning\nmodel to obtain optimized latent graphs. Moreover, the curvature of the product\nmanifold is learned during training alongside the rest of the network\nparameters and based on the downstream task, rather than it being a static\nembedding space. Our novel approach is tested on a wide range of datasets, and\noutperforms the original dDGM model.",
    "descriptor": "",
    "authors": [
      "Haitz S\u00e1ez de Oc\u00e1riz Borde",
      "Anees Kazi",
      "Federico Barbero",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16199"
  },
  {
    "id": "arXiv:2211.16200",
    "title": "From Forks to Forceps: A New Framework for Instance Segmentation of  Surgical Instruments",
    "abstract": "Minimally invasive surgeries and related applications demand surgical tool\nclassification and segmentation at the instance level. Surgical tools are\nsimilar in appearance and are long, thin, and handled at an angle. The\nfine-tuning of state-of-the-art (SOTA) instance segmentation models trained on\nnatural images for instrument segmentation has difficulty discriminating\ninstrument classes. Our research demonstrates that while the bounding box and\nsegmentation mask are often accurate, the classification head mis-classifies\nthe class label of the surgical instrument. We present a new neural network\nframework that adds a classification module as a new stage to existing instance\nsegmentation models. This module specializes in improving the classification of\ninstrument masks generated by the existing model. The module comprises\nmulti-scale mask attention, which attends to the instrument region and masks\nthe distracting background features. We propose training our classifier module\nusing metric learning with arc loss to handle low inter-class variance of\nsurgical instruments. We conduct exhaustive experiments on the benchmark\ndatasets EndoVis2017 and EndoVis2018. We demonstrate that our method\noutperforms all (more than 18) SOTA methods compared with, and improves the\nSOTA performance by at least 12 points (20%) on the EndoVis2017 benchmark\nchallenge and generalizes effectively across the datasets.",
    "descriptor": "\nComments: WACV 2023\n",
    "authors": [
      "Britty Baby",
      "Daksh Thapar",
      "Mustafa Chasmai",
      "Tamajit Banerjee",
      "Kunal Dargan",
      "Ashish Suri",
      "Subhashis Banerjee",
      "Chetan Arora"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16200"
  },
  {
    "id": "arXiv:2211.16201",
    "title": "Lifelong Person Re-Identification via Knowledge Refreshing and  Consolidation",
    "abstract": "Lifelong person re-identification (LReID) is in significant demand for\nreal-world development as a large amount of ReID data is captured from diverse\nlocations over time and cannot be accessed at once inherently. However, a key\nchallenge for LReID is how to incrementally preserve old knowledge and\ngradually add new capabilities to the system. Unlike most existing LReID\nmethods, which mainly focus on dealing with catastrophic forgetting, our focus\nis on a more challenging problem, which is, not only trying to reduce the\nforgetting on old tasks but also aiming to improve the model performance on\nboth new and old tasks during the lifelong learning process. Inspired by the\nbiological process of human cognition where the somatosensory neocortex and the\nhippocampus work together in memory consolidation, we formulated a model called\nKnowledge Refreshing and Consolidation (KRC) that achieves both positive\nforward and backward transfer. More specifically, a knowledge refreshing scheme\nis incorporated with the knowledge rehearsal mechanism to enable bi-directional\nknowledge transfer by introducing a dynamic memory model and an adaptive\nworking model. Moreover, a knowledge consolidation scheme operating on the dual\nspace further improves model stability over the long term. Extensive\nevaluations show KRC's superiority over the state-of-the-art LReID methods on\nchallenging pedestrian benchmarks.",
    "descriptor": "\nComments: Accepted by AAAI2023\n",
    "authors": [
      "Chunlin Yu",
      "Ye Shi",
      "Zimo Liu",
      "Shenghua Gao",
      "Jingya Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16201"
  },
  {
    "id": "arXiv:2211.16202",
    "title": "AutoCAD: Automatically Generating Counterfactuals for Mitigating  Shortcut Learning",
    "abstract": "Recent studies have shown the impressive efficacy of counterfactually\naugmented data (CAD) for reducing NLU models' reliance on spurious features and\nimproving their generalizability. However, current methods still heavily rely\non human efforts or task-specific designs to generate counterfactuals, thereby\nimpeding CAD's applicability to a broad range of NLU tasks. In this paper, we\npresent AutoCAD, a fully automatic and task-agnostic CAD generation framework.\nAutoCAD first leverages a classifier to unsupervisedly identify rationales as\nspans to be intervened, which disentangles spurious and causal features. Then,\nAutoCAD performs controllable generation enhanced by unlikelihood training to\nproduce diverse counterfactuals. Extensive evaluations on multiple\nout-of-domain and challenge benchmarks demonstrate that AutoCAD consistently\nand significantly boosts the out-of-distribution performance of powerful\npre-trained models across different NLU tasks, which is comparable or even\nbetter than previous state-of-the-art human-in-the-loop or task-specific CAD\nmethods. The code is publicly available at https://github.com/thu-coai/AutoCAD.",
    "descriptor": "\nComments: Accepted by EMNLP 2022 findings\n",
    "authors": [
      "Jiaxin Wen",
      "Yeshuang Zhu",
      "Jinchao Zhang",
      "Jie Zhou",
      "Minlie Huang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.16202"
  },
  {
    "id": "arXiv:2211.16206",
    "title": "Exploring adaptation of VideoMAE for Audio-Visual Diarization & Social @  Ego4d Looking at me Challenge",
    "abstract": "In this report, we present the transferring pretrained video mask\nautoencoders(VideoMAE) to egocentric tasks for Ego4d Looking at me Challenge.\nVideoMAE is the data-efficient pretraining model for self-supervised video\npre-training and can easily transfer to downstream tasks. We show that the\nrepresentation transferred from VideoMAE has good Spatio-temporal modeling and\nthe ability to capture small actions. We only need to use egocentric data to\ntrain 10 epochs based on VideoMAE which pretrained by the ordinary videos\nacquired from a third person's view, and we can get better results than the\nbaseline on Ego4d Looking at me Challenge.",
    "descriptor": "",
    "authors": [
      "Yinan He",
      "Guo Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16206"
  },
  {
    "id": "arXiv:2211.16208",
    "title": "SLAN: Self-Locator Aided Network for Cross-Modal Understanding",
    "abstract": "Learning fine-grained interplay between vision and language allows to a more\naccurate understanding for VisionLanguage tasks. However, it remains\nchallenging to extract key image regions according to the texts for semantic\nalignments. Most existing works are either limited by textagnostic and\nredundant regions obtained with the frozen detectors, or failing to scale\nfurther due to its heavy reliance on scarce grounding (gold) data to pre-train\ndetectors. To solve these problems, we propose Self-Locator Aided Network\n(SLAN) for cross-modal understanding tasks without any extra gold data. SLAN\nconsists of a region filter and a region adaptor to localize regions of\ninterest conditioned on different texts. By aggregating cross-modal\ninformation, the region filter selects key regions and the region adaptor\nupdates their coordinates with text guidance. With detailed region-word\nalignments, SLAN can be easily generalized to many downstream tasks. It\nachieves fairly competitive results on five cross-modal understanding tasks\n(e.g., 85.7% and 69.2% on COCO image-to-text and text-to-image retrieval,\nsurpassing previous SOTA methods). SLAN also demonstrates strong zero-shot and\nfine-tuned transferability to two localization tasks.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Jiang-Tian Zhai",
      "Qi Zhang",
      "Tong Wu",
      "Xing-Yu Chen",
      "Jiang-Jiang Liu",
      "Bo Ren",
      "Ming-Ming Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16208"
  },
  {
    "id": "arXiv:2211.16209",
    "title": "The Vanishing Decision Boundary Complexity and the Strong First  Component",
    "abstract": "We show that unlike machine learning classifiers, there are no complex\nboundary structures in the decision boundaries for well-trained deep models.\nHowever, we found that the complicated structures do appear in training but\nthey vanish shortly after shaping. This is a pessimistic news if one seeks to\ncapture different levels of complexity in the decision boundary for\nunderstanding generalization, which works well in machine learning.\nNonetheless, we found that the decision boundaries of predecessor models on the\ntraining data are reflective of the final model's generalization. We show how\nto use the predecessor decision boundaries for studying the generalization of\ndeep models. We have three major findings. One is on the strength of the first\nprinciple component of deep models, another about the singularity of\noptimizers, and the other on the effects of the skip connections in ResNets.\nCode is at https://github.com/hengshu1/decision_boundary_github.",
    "descriptor": "",
    "authors": [
      "Hengshuai Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16209"
  },
  {
    "id": "arXiv:2211.16210",
    "title": "PaCMO: Partner Dependent Human Motion Generation in Dyadic Human  Activity using Neural Operators",
    "abstract": "We address the problem of generating 3D human motions in dyadic activities.\nIn contrast to the concurrent works, which mainly focus on generating the\nmotion of a single actor from the textual description, we generate the motion\nof one of the actors from the motion of the other participating actor in the\naction. This is a particularly challenging, under-explored problem, that\nrequires learning intricate relationships between the motion of two actors\nparticipating in an action and also identifying the action from the motion of\none actor. To address these, we propose partner conditioned motion operator\n(PaCMO), a neural operator-based generative model which learns the distribution\nof human motion conditioned by the partner's motion in function spaces through\nadversarial training. Our model can handle long unlabeled action sequences at\narbitrary time resolution. We also introduce the \"Functional Frechet Inception\nDistance\" ($F^2ID$) metric for capturing similarity between real and generated\ndata for function spaces. We test PaCMO on NTU RGB+D and DuetDance datasets and\nour model produces realistic results evidenced by the $F^2ID$ score and the\nconducted user study.",
    "descriptor": "",
    "authors": [
      "Md Ashiqur Rahman",
      "Jasorsi Ghosh",
      "Hrishikesh Viswanath",
      "Kamyar Azizzadenesheli",
      "Aniket Bera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16210"
  },
  {
    "id": "arXiv:2211.16211",
    "title": "ResNeRF: Geometry-Guided Residual Neural Radiance Field for Indoor Scene  Novel View Synthesis",
    "abstract": "We represent the ResNeRF, a novel geometry-guided two-stage framework for\nindoor scene novel view synthesis. Be aware of that a good geometry would\ngreatly boost the performance of novel view synthesis, and to avoid the\ngeometry ambiguity issue, we propose to characterize the density distribution\nof the scene based on a base density estimated from scene geometry and a\nresidual density parameterized by the geometry. In the first stage, we focus on\ngeometry reconstruction based on SDF representation, which would lead to a good\ngeometry surface of the scene and also a sharp density. In the second stage,\nthe residual density is learned based on the SDF learned in the first stage for\nencoding more details about the appearance. In this way, our method can better\nlearn the density distribution with the geometry prior for high-fidelity novel\nview synthesis while preserving the 3D structures. Experiments on large-scale\nindoor scenes with many less-observed and textureless areas show that with the\ngood 3D surface, our method achieves state-of-the-art performance for novel\nview synthesis.",
    "descriptor": "\nComments: 8+2 pages,5 figures\n",
    "authors": [
      "Yuting Xiao",
      "Yiqun Zhao",
      "Yanyu Xu",
      "Shenghua Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16211"
  },
  {
    "id": "arXiv:2211.16212",
    "title": "Control-Flow Integrity at RISC: Attacking RISC-V by Jump-Oriented  Programming",
    "abstract": "RISC-V is an open instruction set architecture recently developed for\nembedded real-time systems. To achieve a lasting security on these systems and\ndesign efficient countermeasures, a better understanding of vulnerabilities to\nnovel and potential future attacks is mandatory. This paper demonstrates that\nRISC-V is sensible to Jump-Oriented Programming, a class of complex code-reuse\nattacks, able to bypass existing protections. We provide a first analysis of\nRISC-V systems' attack surface exploitable by such attacks, and show how they\ncan be chained together in order to build a full-fledged attack. We use a\nconservative hypothesis on exploited registers and instruction patterns, in an\napproach we called reserved registers. This approach is implemented on a\nvulnerable RISC-V application, and successfully applied to expose an AES256\nsecret.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Olivier Gilles",
      "Franck Viguier",
      "Nikolai Kosmatov",
      "Daniel Gracia P\u00e9rez"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.16212"
  },
  {
    "id": "arXiv:2211.16216",
    "title": "Online Unrelated-Machine Load Balancing and Generalized Flow with  Recourse",
    "abstract": "We consider the online unrelated-machine load balancing problem with\nrecourse, where the algorithm is allowed to re-assign prior jobs. We give a\n$(2+\\epsilon)$-competitive algorithm for the problem with $O_\\epsilon(\\log n)$\namortized recourse per job. This is the first $O(1)$-competitive algorithm for\nthe problem with reasonable recourse, and the competitive ratio nearly matches\nthe long-standing best-known offline approximation guarantee. We also show an\n$O(\\log\\log n/\\log\\log\\log n)$-competitive algorithm for the problem with\n$O(1)$ amortized recourse. The best-known bounds from prior work are\n$O(\\log\\log n)$-competitive algorithms with $O(1)$ amortized recourse due to\n[GKS14], for the special case of the restricted assignment model.\nAlong the way, we design an algorithm for the online generalized network flow\nproblem (also known as network flow problem with gains) with recourse. In the\nproblem, any edge $uv$ in the network has a gain parameter $\\gamma_{uv} > 0$\nand $\\theta$-units of flow sent across $uv$ from $u$'s side becomes\n$\\gamma_{uv} \\theta$ units of flow on the $v$'th side. In the online problem,\nthere is one sink, and sources come one by one. Upon arrival of a source, we\nneed to send 1 unit flow from the source. A recourse occurs if we change the\nflow value of an edge. We give an online algorithm for the problem with\nrecourse at most $O(1/\\epsilon)$ times the optimum cost for the instance with\ncapacities scaled by $\\frac{1}{1+\\epsilon}$. The $(1+\\epsilon)$-factor improves\nupon the corresponding $(2+\\epsilon)$-factor of [GKS14], which only works for\nthe ordinary network flow problem. As an immediate corollary, we also give an\nimproved algorithm for the online $b$-matching problem with reassignment costs.",
    "descriptor": "",
    "authors": [
      "Ravishankar Krishnaswamy",
      "Shi Li",
      "Varun Suriyanarayana"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.16216"
  },
  {
    "id": "arXiv:2211.16219",
    "title": "Metal-conscious Embedding for CBCT Projection Inpainting",
    "abstract": "The existence of metallic implants in projection images for cone-beam\ncomputed tomography (CBCT) introduces undesired artifacts which degrade the\nquality of reconstructed images. In order to reduce metal artifacts, projection\ninpainting is an essential step in many metal artifact reduction algorithms. In\nthis work, a hybrid network combining the shift window (Swin) vision\ntransformer (ViT) and a convolutional neural network is proposed as a baseline\nnetwork for the inpainting task. To incorporate metal information for the Swin\nViT-based encoder, metal-conscious self-embedding and neighborhood-embedding\nmethods are investigated. Both methods have improved the performance of the\nbaseline network. Furthermore, by choosing appropriate window size, the model\nwith neighborhood-embedding could achieve the lowest mean absolute error of\n0.079 in metal regions and the highest peak signal-to-noise ratio of 42.346 in\nCBCT projections. At the end, the efficiency of metal-conscious embedding on\nboth simulated and real cadaver CBCT data has been demonstrated, where the\ninpainting capability of the baseline network has been enhanced.",
    "descriptor": "",
    "authors": [
      "Fuxin Fan",
      "Yangkong Wang",
      "Ludwig Ritschl",
      "Ramyar Biniazan",
      "Marcel Beister",
      "Bj\u00f6rn Kreher",
      "Yixing Huang",
      "Steffen Kappler",
      "Andreas Maier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.16219"
  },
  {
    "id": "arXiv:2211.16220",
    "title": "Which Shortcut Solution Do Question Answering Models Prefer to Learn?",
    "abstract": "Question answering (QA) models for reading comprehension tend to learn\nshortcut solutions rather than the solutions intended by QA datasets. QA models\nthat have learned shortcut solutions can achieve human-level performance in\nshortcut examples where shortcuts are valid, but these same behaviors degrade\ngeneralization potential on anti-shortcut examples where shortcuts are invalid.\nVarious methods have been proposed to mitigate this problem, but they do not\nfully take the characteristics of shortcuts themselves into account. We assume\nthat the learnability of shortcuts, i.e., how easy it is to learn a shortcut,\nis useful to mitigate the problem. Thus, we first examine the learnability of\nthe representative shortcuts on extractive and multiple-choice QA datasets.\nBehavioral tests using biased training sets reveal that shortcuts that exploit\nanswer positions and word-label correlations are preferentially learned for\nextractive and multiple-choice QA, respectively. We find that the more\nlearnable a shortcut is, the flatter and deeper the loss landscape is around\nthe shortcut solution in the parameter space. We also find that the\navailability of the preferred shortcuts tends to make the task easier to\nperform from an information-theoretic viewpoint. Lastly, we experimentally show\nthat the learnability of shortcuts can be utilized to construct an effective QA\ntraining set; the more learnable a shortcut is, the smaller the proportion of\nanti-shortcut examples required to achieve comparable performance on shortcut\nand anti-shortcut examples. We claim that the learnability of shortcuts should\nbe considered when designing mitigation methods.",
    "descriptor": "\nComments: Accepted to AAAI 2023\n",
    "authors": [
      "Kazutoshi Shinoda",
      "Saku Sugawara",
      "Akiko Aizawa"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.16220"
  },
  {
    "id": "arXiv:2211.16221",
    "title": "Configurable Agent With Reward As Input: A Play-Style Continuum  Generation",
    "abstract": "Modern video games are becoming richer and more complex in terms of game\nmechanics. This complexity allows for the emergence of a wide variety of ways\nto play the game across the players. From the point of view of the game\ndesigner, this means that one needs to anticipate a lot of different ways the\ngame could be played. Machine Learning (ML) could help address this issue. More\nprecisely, Reinforcement Learning is a promising answer to the need of\nautomating video game testing. In this paper we present a video game\nenvironment which lets us define multiple play-styles. We then introduce CARI:\na Configurable Agent with Reward as Input. An agent able to simulate a wide\ncontinuum range of play-styles. It is not constrained to extreme archetypal\nbehaviors like current methods using reward shaping. In addition it achieves\nthis through a single training loop, instead of the usual one loop per\nplay-style. We compare this novel training approach with the more classic\nreward shaping approach and conclude that CARI can also outperform the baseline\non archetypes generation. This novel agent could be used to investigate\nbehaviors and balancing during the production of a video game with a realistic\namount of training time.",
    "descriptor": "\nComments: 2021 IEEE Conference on Games (CoG), 2021\n",
    "authors": [
      "Pierre Le Pelletier de Woillemont",
      "R\u00e9mi Labory",
      "Vincent Corruble"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16221"
  },
  {
    "id": "arXiv:2211.16227",
    "title": "ReAssigner: A Plug-and-Play Virtual Machine Scheduling Intensifier for  Heterogeneous Requests",
    "abstract": "With the rapid development of cloud computing, virtual machine scheduling has\nbecome one of the most important but challenging issues for the cloud computing\ncommunity, especially for practical heterogeneous request sequences. By\nanalyzing the impact of request heterogeneity on some popular heuristic\nschedulers, it can be found that existing scheduling algorithms can not handle\nthe request heterogeneity properly and efficiently. In this paper, a\nplug-and-play virtual machine scheduling intensifier, called Resource Assigner\n(ReAssigner), is proposed to enhance the scheduling efficiency of any given\nscheduler for heterogeneous requests. The key idea of ReAssigner is to\npre-assign roles to physical resources and let resources of the same role form\na virtual cluster to handle homogeneous requests. ReAssigner can cooperate with\narbitrary schedulers by restricting their scheduling space to virtual clusters.\nWith evaluations on the real dataset from Huawei Cloud, the proposed ReAssigner\nachieves significant scheduling performance improvement compared with some\nstate-of-the-art scheduling methods.",
    "descriptor": "",
    "authors": [
      "Haochuan Cui",
      "Junjie Sheng",
      "Bo Jin",
      "Yiqiu Hu",
      "Li Su",
      "Lei Zhu",
      "Wenli Zhou",
      "Xiangfeng Wang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16227"
  },
  {
    "id": "arXiv:2211.16228",
    "title": "Building Resilience to Out-of-Distribution Visual Data via Input  Optimization and Model Finetuning",
    "abstract": "A major challenge in machine learning is resilience to out-of-distribution\ndata, that is data that exists outside of the distribution of a model's\ntraining data. Training is often performed using limited, carefully curated\ndatasets and so when a model is deployed there is often a significant\ndistribution shift as edge cases and anomalies not included in the training\ndata are encountered. To address this, we propose the Input Optimisation\nNetwork, an image preprocessing model that learns to optimise input data for a\nspecific target vision model. In this work we investigate several\nout-of-distribution scenarios in the context of semantic segmentation for\nautonomous vehicles, comparing an Input Optimisation based solution to existing\napproaches of finetuning the target model with augmented training data and an\nadversarially trained preprocessing model. We demonstrate that our approach can\nenable performance on such data comparable to that of a finetuned model, and\nsubsequently that a combined approach, whereby an input optimization network is\noptimised to target a finetuned model, delivers superior performance to either\nmethod in isolation. Finally, we propose a joint optimisation approach, in\nwhich input optimization network and target model are trained simultaneously,\nwhich we demonstrate achieves significant further performance gains,\nparticularly in challenging edge-case scenarios. We also demonstrate that our\narchitecture can be reduced to a relatively compact size without a significant\nperformance impact, potentially facilitating real time embedded applications.",
    "descriptor": "",
    "authors": [
      "Christopher J. Holder",
      "Majid Khonji",
      "Jorge Dias",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16228"
  },
  {
    "id": "arXiv:2211.16229",
    "title": "Triadic Temporal Exponential Random Graph Models (TTERGM)",
    "abstract": "Temporal exponential random graph models (TERGM) are powerful statistical\nmodels that can be used to infer the temporal pattern of edge formation and\nelimination in complex networks (e.g., social networks). TERGMs can also be\nused in a generative capacity to predict longitudinal time series data in these\nevolving graphs. However, parameter estimation within this framework fails to\ncapture many real-world properties of social networks, including: triadic\nrelationships, small world characteristics, and social learning theories which\ncould be used to constrain the probabilistic estimation of dyadic covariates.\nHere, we propose triadic temporal exponential random graph models (TTERGM) to\nfill this void, which includes these hierarchical network relationships within\nthe graph model. We represent social network learning theory as an additional\nprobability distribution that optimizes Markov chains in the graph vector\nspace. The new parameters are then approximated via Monte Carlo maximum\nlikelihood estimation. We show that our TTERGM model achieves improved fidelity\nand more accurate predictions compared to several benchmark methods on GitHub\nnetwork data.",
    "descriptor": "",
    "authors": [
      "Yifan Huang",
      "Clayton Barham",
      "Eric Page",
      "Pamela K Douglas"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.16229"
  },
  {
    "id": "arXiv:2211.16231",
    "title": "Curriculum Temperature for Knowledge Distillation",
    "abstract": "Most existing distillation methods ignore the flexible role of the\ntemperature in the loss function and fix it as a hyper-parameter that can be\ndecided by an inefficient grid search. In general, the temperature controls the\ndiscrepancy between two distributions and can faithfully determine the\ndifficulty level of the distillation task. Keeping a constant temperature,\ni.e., a fixed level of task difficulty, is usually sub-optimal for a growing\nstudent during its progressive learning stages. In this paper, we propose a\nsimple curriculum-based technique, termed Curriculum Temperature for Knowledge\nDistillation (CTKD), which controls the task difficulty level during the\nstudent's learning career through a dynamic and learnable temperature.\nSpecifically, following an easy-to-hard curriculum, we gradually increase the\ndistillation loss w.r.t. the temperature, leading to increased distillation\ndifficulty in an adversarial manner. As an easy-to-use plug-in technique, CTKD\ncan be seamlessly integrated into existing knowledge distillation frameworks\nand brings general improvements at a negligible additional computation cost.\nExtensive experiments on CIFAR-100, ImageNet-2012, and MS-COCO demonstrate the\neffectiveness of our method. Our code is available at\nhttps://github.com/zhengli97/CTKD.",
    "descriptor": "\nComments: AAAI 2023\n",
    "authors": [
      "Zheng Li",
      "Xiang Li",
      "Lingfeng Yang",
      "Borui Zhao",
      "Renjie Song",
      "Lei Luo",
      "Jun Li",
      "Jian Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16231"
  },
  {
    "id": "arXiv:2211.16234",
    "title": "SimCS: Simulation for Online Domain-Incremental Continual Segmentation",
    "abstract": "Continual Learning is a step towards lifelong intelligence where models\ncontinuously learn from recently collected data without forgetting previous\nknowledge. Existing continual learning approaches mostly focus on image\nclassification in the class-incremental setup with clear task boundaries and\nunlimited computational budget. This work explores Online Domain-Incremental\nContinual Segmentation~(ODICS), a real-world problem that arises in many\napplications, \\eg, autonomous driving. In ODICS, the model is continually\npresented with batches of densely labeled images from different domains;\ncomputation is limited and no information about the task boundaries is\navailable. In autonomous driving, this may correspond to the realistic scenario\nof training a segmentation model over time on a sequence of cities. We analyze\nseveral existing continual learning methods and show that they do not perform\nwell in this setting despite working well in class-incremental segmentation. We\npropose SimCS, a parameter-free method complementary to existing ones that\nleverages simulated data as a continual learning regularizer. Extensive\nexperiments show consistent improvements over different types of continual\nlearning methods that use regularizers and even replay.",
    "descriptor": "\nComments: 13 pages, 5 figures, and 8 tables\n",
    "authors": [
      "Motasem Alfarra",
      "Zhipeng Cai",
      "Adel Bibi",
      "Bernard Ghanem",
      "Matthias M\u00fcller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16234"
  },
  {
    "id": "arXiv:2211.16235",
    "title": "DCDetector: An IoT terminal vulnerability mining system based on  distributed deep ensemble learning under source code representation",
    "abstract": "Context: The IoT system infrastructure platform facility vulnerability attack\nhas become the main battlefield of network security attacks. Most of the\ntraditional vulnerability mining methods rely on vulnerability detection tools\nto realize vulnerability discovery. However, due to the inflexibility of tools\nand the limitation of file size, its scalability It is relatively low and\ncannot be applied to large-scale power big data fields. Objective: The goal of\nthe research is to intelligently detect vulnerabilities in source codes of\nhigh-level languages such as C/C++. This enables us to propose a code\nrepresentation of sensitive sentence-related slices of source code, and to\ndetect vulnerabilities by designing a distributed deep ensemble learning model.\nMethod: In this paper, a new directional vulnerability mining method of\nparallel ensemble learning is proposed to solve the problem of large-scale data\nvulnerability mining. By extracting sensitive functions and statements, a\nsensitive statement library of vulnerable codes is formed. The AST stream-based\nvulnerability code slice with higher granularity performs doc2vec sentence\nvectorization on the source code through the random sampling module, obtains\ndifferent classification results through distributed training through the\nBi-LSTM trainer, and obtains the final classification result by voting.\nResults: This method designs and implements a distributed deep ensemble\nlearning system software vulnerability mining system called DCDetector. It can\nmake accurate predictions by using the syntactic information of the code, and\nis an effective method for analyzing large-scale vulnerability data.\nConclusion: Experiments show that this method can reduce the false positive\nrate of traditional static analysis and improve the performance and accuracy of\nmachine learning.",
    "descriptor": "",
    "authors": [
      "Wen Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16235"
  },
  {
    "id": "arXiv:2211.16237",
    "title": "Closing the gap between SVRG and TD-SVRG with Gradient Splitting",
    "abstract": "Temporal difference (TD) learning is a simple algorithm for policy evaluation\nin reinforcement learning. The performance of TD learning is affected by high\nvariance and it can be naturally enhanced with variance reduction techniques,\nsuch as the Stochastic Variance Reduced Gradient (SVRG) method. Recently,\nmultiple works have sought to fuse TD learning with SVRG to obtain a policy\nevaluation method with a geometric rate of convergence. However, the resulting\nconvergence rate is significantly weaker than what is achieved by SVRG in the\nsetting of convex optimization. In this work we utilize a recent interpretation\nof TD-learning as the splitting of the gradient of an appropriately chosen\nfunction, thus simplifying the algorithm and fusing TD with SVRG. We prove a\ngeometric convergence bound with predetermined learning rate of 1/8, that is\nidentical to the convergence bound available for SVRG in the convex setting.",
    "descriptor": "\nComments: 28 pages, 3 figures\n",
    "authors": [
      "Arsenii Mustafin",
      "Alex Olshevsky",
      "Ioannis Ch. Paschalidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16237"
  },
  {
    "id": "arXiv:2211.16238",
    "title": "A Cross-Conformal Predictor for Multi-label Classification",
    "abstract": "Unlike the typical classification setting where each instance is associated\nwith a single class, in multi-label learning each instance is associated with\nmultiple classes simultaneously. Therefore the learning task in this setting is\nto predict the subset of classes to which each instance belongs. This work\nexamines the application of a recently developed framework called Conformal\nPrediction (CP) to the multi-label learning setting. CP complements the\npredictions of machine learning algorithms with reliable measures of\nconfidence. As a result the proposed approach instead of just predicting the\nmost likely subset of classes for a new unseen instance, also indicates the\nlikelihood of each predicted subset being correct. This additional information\nis especially valuable in the multi-label setting where the overall uncertainty\nis extremely high.",
    "descriptor": "\nComments: 10 Pages\n",
    "authors": [
      "Harris Papadopoulos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16238"
  },
  {
    "id": "arXiv:2211.16242",
    "title": "Based on particle swarm optimization support vector machine model of the  electric car sales strategy research",
    "abstract": "From the perspective of constructing the classification model, this paper\nuses the weight coefficient (influencing factors) in the model to analyze the\nsales impact on different brands of electric vehicles, and optimizes the\nexisting sales strategy.",
    "descriptor": "",
    "authors": [
      "Wen Zhou"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16242"
  },
  {
    "id": "arXiv:2211.16246",
    "title": "Causal Inference with Conditional Instruments using Deep Generative  Models",
    "abstract": "The instrumental variable (IV) approach is a widely used way to estimate the\ncausal effects of a treatment on an outcome of interest from observational data\nwith latent confounders. A standard IV is expected to be related to the\ntreatment variable and independent of all other variables in the system.\nHowever, it is challenging to search for a standard IV from data directly due\nto the strict conditions. The conditional IV (CIV) method has been proposed to\nallow a variable to be an instrument conditioning on a set of variables,\nallowing a wider choice of possible IVs and enabling broader practical\napplications of the IV approach. Nevertheless, there is not a data-driven\nmethod to discover a CIV and its conditioning set directly from data. To fill\nthis gap, in this paper, we propose to learn the representations of the\ninformation of a CIV and its conditioning set from data with latent confounders\nfor average causal effect estimation. By taking advantage of deep generative\nmodels, we develop a novel data-driven approach for simultaneously learning the\nrepresentation of a CIV from measured variables and generating the\nrepresentation of its conditioning set given measured variables. Extensive\nexperiments on synthetic and real-world datasets show that our method\noutperforms the existing IV methods.",
    "descriptor": "\nComments: 10 pages, 4 figures and 3 tables. Accepted by AAAI2023\n",
    "authors": [
      "Debo Cheng",
      "Ziqi Xu",
      "Jiuyong Li",
      "Lin Liu",
      "Jixue Liu",
      "Thuc Duy Le"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.16246"
  },
  {
    "id": "arXiv:2211.16247",
    "title": "Ada3Diff: Defending against 3D Adversarial Point Clouds via Adaptive  Diffusion",
    "abstract": "Deep 3D point cloud models are sensitive to adversarial attacks, which poses\nthreats to safety-critical applications such as autonomous driving. Robust\ntraining and defend-by-denoise are typical strategies for defending adversarial\nperturbations, including adversarial training and statistical filtering,\nrespectively. However, they either induce massive computational overhead or\nrely heavily upon specified noise priors, limiting generalized robustness\nagainst attacks of all kinds. This paper introduces a new defense mechanism\nbased on denoising diffusion models that can adaptively remove diverse noises\nwith a tailored intensity estimator. Specifically, we first estimate\nadversarial distortions by calculating the distance of the points to their\nneighborhood best-fit plane. Depending on the distortion degree, we choose\nspecific diffusion time steps for the input point cloud and perform the forward\ndiffusion to disrupt potential adversarial shifts. Then we conduct the reverse\ndenoising process to restore the disrupted point cloud back to a clean\ndistribution. This approach enables effective defense against adaptive attacks\nwith varying noise budgets, achieving accentuated robustness of existing 3D\ndeep recognition models.",
    "descriptor": "",
    "authors": [
      "Kui Zhang",
      "Hang Zhou",
      "Jie Zhang",
      "Qidong Huang",
      "Weiming Zhang",
      "Nenghai Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16247"
  },
  {
    "id": "arXiv:2211.16250",
    "title": "Data-driven identification of a 2D wave equation model with  port-Hamiltonian structure",
    "abstract": "We consider a two-dimensional wave equation, for which the discretized\nversion preserves the passive port-Hamiltoninan form. In this work, we detail a\nprocedure to construct a reduced order model of this use-case, on the basis of\nfrequency-domain data, that preserves the passivity property and the\nport-Hamiltonian structure. The proposed scheme is based on Benner et al.\ncontribution, which has been adapted to handle non-strictly passive model, and\nto handle numerical issues observed when applying the Loewner framework on such\na complex configuration.",
    "descriptor": "",
    "authors": [
      "Charles Poussot-Vassal",
      "Denis Matignon",
      "Ghilslain Haine",
      "Pierre Vuillemin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.16250"
  },
  {
    "id": "arXiv:2211.16251",
    "title": "Utility Maximizer or Value Maximizer: Mechanism Design for Mixed Bidders  in Online Advertising",
    "abstract": "Digital advertising constitutes one of the main revenue sources for online\nplatforms. In recent years, some advertisers tend to adopt auto-bidding tools\nto facilitate advertising performance optimization, making the classical\n\\emph{utility maximizer} model in auction theory not fit well. Some recent\nstudies proposed a new model, called \\emph{value maximizer}, for auto-bidding\nadvertisers with return-on-investment (ROI) constraints. However, the model of\neither utility maximizer or value maximizer could only characterize partial\nadvertisers in real-world advertising platforms. In a mixed environment where\nutility maximizers and value maximizers coexist, the truthful ad auction design\nwould be challenging since bidders could manipulate both their values and\naffiliated classes, leading to a multi-parameter mechanism design problem. In\nthis work, we address this issue by proposing a payment rule which combines the\ncorresponding ones in classical VCG and GSP mechanisms in a novel way. Based on\nthis payment rule, we propose a truthful auction mechanism with an\napproximation ratio of $2$ on social welfare, which is close to the lower bound\nof at least $\\frac{5}{4}$ that we also prove. The designed auction mechanism is\na generalization of VCG for utility maximizers and GSP for value maximizers.",
    "descriptor": "\nComments: accepted by AAAI2023\n",
    "authors": [
      "Hongtao Lv",
      "Zhilin Zhang",
      "Zhenzhe Zheng",
      "Jinghan Liu",
      "Chuan Yu",
      "Lei Liu",
      "Lizhen Cui",
      "Fan Wu"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.16251"
  },
  {
    "id": "arXiv:2211.16253",
    "title": "Advancing Deep Metric Learning Through Multiple Batch Norms And  Multi-Targeted Adversarial Examples",
    "abstract": "Deep Metric Learning (DML) is a prominent field in machine learning with\nextensive practical applications that concentrate on learning visual\nsimilarities. It is known that inputs such as Adversarial Examples (AXs), which\nfollow a distribution different from that of clean data, result in false\npredictions from DML systems. This paper proposes MDProp, a framework to\nsimultaneously improve the performance of DML models on clean data and inputs\nfollowing multiple distributions. MDProp utilizes multi-distribution data\nthrough an AX generation process while leveraging disentangled learning through\nmultiple batch normalization layers during the training of a DML model. MDProp\nis the first to generate feature space multi-targeted AXs to perform targeted\nregularization on the training model's denser embedding space regions,\nresulting in improved embedding space densities contributing to the improved\ngeneralization in the trained models. From a comprehensive experimental\nanalysis, we show that MDProp results in up to 2.95% increased clean data\nRecall@1 scores and up to 2.12 times increased robustness against different\ninput distributions compared to the conventional methods.",
    "descriptor": "\nComments: Under Review at CVPR 2023\n",
    "authors": [
      "Inderjeet Singh",
      "Kazuya Kakizaki",
      "Toshinori Araki"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16253"
  },
  {
    "id": "arXiv:2211.16254",
    "title": "Positivity-preserving and entropy-bounded discontinuous Galerkin method  for the chemically reacting, compressible Euler equations. Part I: The  one-dimensional case",
    "abstract": "In this paper, we develop a fully conservative, positivity-preserving, and\nentropy-bounded discontinuous Galerkin scheme for simulating the chemically\nreacting, compressible Euler equations with complex thermodynamics. The\nproposed formulation is an extension of the conservative, high-order numerical\nmethod previously developed by Johnson and Kercher [J. Comput. Phys., 423\n(2020), 109826] that maintains pressure equilibrium between adjacent elements.\nIn this first part of our two-part paper, we focus on the one-dimensional case.\nOur methodology is rooted in the minimum entropy principle satisfied by entropy\nsolutions to the multicomponent, compressible Euler equations, which was proved\nby Gouasmi et al. [ESAIM: Math. Model. Numer. Anal., 54 (2020), 373--389] for\nnonreacting flows. We first show that the minimum entropy principle holds in\nthe reacting case as well. Next, we introduce the ingredients required for the\nsolution to have nonnegative species concentrations, positive density, positive\npressure, and bounded entropy. We also discuss how to retain the aforementioned\nability to preserve pressure equilibrium between elements. Operator splitting\nis employed to handle stiff chemical reactions. To guarantee satisfaction of\nthe minimum entropy principle in the reaction step, we develop an\nentropy-stable discontinuous Galerkin method based on diagonal-norm\nsummation-by-parts operators for solving ordinary differential equations. The\ndeveloped formulation is used to compute canonical one-dimensional test cases,\nnamely thermal-bubble advection, multicomponent shock-tube flow, and a moving\nhydrogen-oxygen detonation wave with detailed chemistry. We find that the\nenforcement of an entropy bound can considerably reduce the large-scale\nnonlinear instabilities that emerge when only the positivity property is\nenforced, to an even greater extent than in the monocomponent, calorically\nperfect case.",
    "descriptor": "",
    "authors": [
      "Eric J. Ching",
      "Ryan F. Johnson",
      "Andrew D. Kercher"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2211.16254"
  },
  {
    "id": "arXiv:2211.16259",
    "title": "Measuring the Measuring Tools: An Automatic Evaluation of Semantic  Metrics for Text Corpora",
    "abstract": "The ability to compare the semantic similarity between text corpora is\nimportant in a variety of natural language processing applications. However,\nstandard methods for evaluating these metrics have yet to be established. We\npropose a set of automatic and interpretable measures for assessing the\ncharacteristics of corpus-level semantic similarity metrics, allowing sensible\ncomparison of their behavior. We demonstrate the effectiveness of our\nevaluation measures in capturing fundamental characteristics by evaluating them\non a collection of classical and state-of-the-art metrics. Our measures\nrevealed that recently-developed metrics are becoming better in identifying\nsemantic distributional mismatch while classical metrics are more sensitive to\nperturbations in the surface text levels.",
    "descriptor": "\nComments: Published at GEM (this https URL) workshop at the Empirical Methods in Natural Language Processing (EMNLP) conference in 2022\n",
    "authors": [
      "George Kour",
      "Samuel Ackerman",
      "Orna Raz",
      "Eitan Farchi",
      "Boaz Carmeli",
      "Ateret Anaby-Tavor"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.16259"
  },
  {
    "id": "arXiv:2211.16264",
    "title": "Intra-class Adaptive Augmentation with Neighbor Correction for Deep  Metric Learning",
    "abstract": "Deep metric learning aims to learn an embedding space, where semantically\nsimilar samples are close together and dissimilar ones are repelled against. To\nexplore more hard and informative training signals for augmentation and\ngeneralization, recent methods focus on generating synthetic samples to boost\nmetric learning losses. However, these methods just use the deterministic and\nclass-independent generations (e.g., simple linear interpolation), which only\ncan cover the limited part of distribution spaces around original samples. They\nhave overlooked the wide characteristic changes of different classes and can\nnot model abundant intra-class variations for generations. Therefore, generated\nsamples not only lack rich semantics within the certain class, but also might\nbe noisy signals to disturb training. In this paper, we propose a novel\nintra-class adaptive augmentation (IAA) framework for deep metric learning. We\nreasonably estimate intra-class variations for every class and generate\nadaptive synthetic samples to support hard samples mining and boost metric\nlearning losses. Further, for most datasets that have a few samples within the\nclass, we propose the neighbor correction to revise the inaccurate estimations,\naccording to our correlation discovery where similar classes generally have\nsimilar variation distributions. Extensive experiments on five benchmarks show\nour method significantly improves and outperforms the state-of-the-art methods\non retrieval performances by 3%-6%. Our code is available at\nhttps://github.com/darkpromise98/IAA",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Multimedia\n",
    "authors": [
      "Zheren Fu",
      "Zhendong Mao",
      "Bo Hu",
      "An-An Liu",
      "Yongdong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.16264"
  },
  {
    "id": "arXiv:2211.16266",
    "title": "PatchMatch-Stereo-Panorama, a fast dense reconstruction from 360\u00b0  video images",
    "abstract": "This work proposes a new method for real-time dense 3d reconstruction for\ncommon 360{\\deg} action cams, which can be mounted on small scouting UAVs\nduring USAR missions. The proposed method extends a feature based Visual\nmonocular SLAM (OpenVSLAM, based on the popular ORB-SLAM) for robust long-term\nlocalization on equirectangular video input by adding an additional\ndensification thread that computes dense correspondences for any given keyframe\nwith respect to a local keyframe-neighboorhood using a\nPatchMatch-Stereo-approach. While PatchMatch-Stereo-types of algorithms are\nconsidered state of the art for large scale Mutli-View-Stereo they had not been\nadapted so far for real-time dense 3d reconstruction tasks. This work describes\na new massively parallel variant of the PatchMatch-Stereo-algorithm that\ndiffers from current approaches in two ways: First it supports the\nequirectangular camera model while other solutions are limited to the pinhole\ncamera model. Second it is optimized for low latency while keeping a high level\nof completeness and accuracy. To achieve this it operates only on small\nsequences of keyframes, but employs techniques to compensate for the potential\nloss of accuracy due to the limited number of frames. Results demonstrate that\ndense 3d reconstruction is possible on a consumer grade laptop with a recent\nmobile GPU and that it is possible with improved accuracy and completeness over\ncommon offline-MVS solutions with comparable quality settings.",
    "descriptor": "\nComments: 7 pages, SSRR 2022, this https URL\n",
    "authors": [
      "Hartmut Surmann",
      "Marc Thurow",
      "Dominik Slomma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.16266"
  },
  {
    "id": "arXiv:2211.16268",
    "title": "Learning to Optimize with Dynamic Mode Decomposition",
    "abstract": "Designing faster optimization algorithms is of ever-growing interest. In\nrecent years, learning to learn methods that learn how to optimize demonstrated\nvery encouraging results. Current approaches usually do not effectively include\nthe dynamics of the optimization process during training. They either omit it\nentirely or only implicitly assume the dynamics of an isolated parameter. In\nthis paper, we show how to utilize the dynamic mode decomposition method for\nextracting informative features about optimization dynamics. By employing those\nfeatures, we show that our learned optimizer generalizes much better to unseen\noptimization problems in short. The improved generalization is illustrated on\nmultiple tasks where training the optimizer on one neural network generalizes\nto different architectures and distinct datasets.",
    "descriptor": "",
    "authors": [
      "Petr \u0160im\u00e1nek",
      "Daniel Va\u0161ata",
      "Pavel Kord\u00edk"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.16268"
  },
  {
    "id": "arXiv:2211.16270",
    "title": "Neural Transducer Training: Reduced Memory Consumption with Sample-wise  Computation",
    "abstract": "The neural transducer is an end-to-end model for automatic speech recognition\n(ASR). While the model is well-suited for streaming ASR, the training process\nremains challenging. During training, the memory requirements may quickly\nexceed the capacity of state-of-the-art GPUs, limiting batch size and sequence\nlengths. In this work, we analyze the time and space complexity of a typical\ntransducer training setup. We propose a memory-efficient training method that\ncomputes the transducer loss and gradients sample by sample. We present\noptimizations to increase the efficiency and parallelism of the sample-wise\nmethod. In a set of thorough benchmarks, we show that our sample-wise method\nsignificantly reduces memory usage, and performs at competitive speed when\ncompared to the default batched computation. As a highlight, we manage to\ncompute the transducer loss and gradients for a batch size of 1024, and audio\nlength of 40 seconds, using only 6 GB of memory.",
    "descriptor": "\nComments: 5 pages, 4 figures, 1 table, 1 algorithm\n",
    "authors": [
      "Stefan Braun",
      "Erik McDermott",
      "Roger Hsiao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.16270"
  },
  {
    "id": "arXiv:2211.16274",
    "title": "NCTV: Neural Clamping Toolkit and Visualization for Neural Network  Calibration",
    "abstract": "With the advancement of deep learning technology, neural networks have\ndemonstrated their excellent ability to provide accurate predictions in many\ntasks. However, a lack of consideration for neural network calibration will not\ngain trust from humans, even for high-accuracy models. In this regard, the gap\nbetween the confidence of the model's predictions and the actual correctness\nlikelihood must be bridged to derive a well-calibrated model. In this paper, we\nintroduce the Neural Clamping Toolkit, the first open-source framework designed\nto help developers employ state-of-the-art model-agnostic calibrated models.\nFurthermore, we provide animations and interactive sections in the\ndemonstration to familiarize researchers with calibration in neural networks. A\nColab tutorial on utilizing our toolkit is also introduced.",
    "descriptor": "\nComments: AAAI 2023 Demo Track; The demonstration is at this https URL\n",
    "authors": [
      "Lei Hsiung",
      "Yung-Chen Tang",
      "Pin-Yu Chen",
      "Tsung-Yi Ho"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.16274"
  },
  {
    "id": "arXiv:2211.16276",
    "title": "Hardware-Aware Pilot Decontamination Precoding for Multi-cell mMIMO  Systems With Rician Fading",
    "abstract": "We consider a hardware-impaired multi-cell Rician faded massive multi-input\nmulti-output (mMIMO) system with two-layer pilot decontamination precoding,\nalso known as large-scale fading precoding (LSFP). Each BS is equipped with a\nflexible dynamic analog-to-digital converter (ADC)/digital-to-analog converter\n(DAC) architecture and the user equipments (UEs) have low-resolution ADCs.\nFurther, both BS and UEs have hardwareimpaired radio frequency chains. The\ndynamic ADC/DAC architecture allows us to vary the resolution of ADC/DAC\nconnected to each BS antenna, and suitably choose them to maximize the SE. We\npropose a distortion-aware minimum mean squared error (DA-MMSE) precoder and\ninvestigate its usage with two-layer LSFP and conventional single-layer\nprecoding (SLP) for hardware-impaired mMIMO systems. We discuss the use cases\nof LSFP and SLP with DA-MMSE and distortion-unaware MMSE (DU-MMSE) precoders,\nwhich will provide critical insights to the system designer regarding their\nusage in practical systems.",
    "descriptor": "\nComments: This paper is accepted for presentation in 2022 IEEE Global Communications Conference: Wireless Communications (Globecom 2022 WC), 7 pages and 4 figures\n",
    "authors": [
      "Harshit Kesarwani",
      "Dheeraj Naidu Amudala",
      "Venkatesh Tentu",
      "Rohit Budhiraja"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.16276"
  },
  {
    "id": "arXiv:2211.16277",
    "title": "Differentiable User Models",
    "abstract": "Probabilistic user modeling is essential for building collaborative AI\nsystems within probabilistic frameworks. However, modern advanced user models,\noften designed as cognitive behavior simulators, are computationally\nprohibitive for interactive use in cooperative AI assistants. In this extended\nabstract, we address this problem by introducing widely-applicable\ndifferentiable surrogates for bypassing this computational bottleneck; the\nsurrogates enable using modern behavioral models with online computational cost\nwhich is independent of their original computational cost. We show\nexperimentally that modeling capabilities comparable to likelihood-free\ninference methods are achievable, with over eight orders of magnitude reduction\nin computational time. Finally, we demonstrate how AI-assistants can\ncomputationally feasibly use cognitive models in a previously studied\nmenu-search task.",
    "descriptor": "\nComments: This is an extended abstract accepted for presentation in NeurIPS 2022 HILL workshop\n",
    "authors": [
      "Alex H\u00e4m\u00e4l\u00e4inen",
      "Mustafa Mert \u00c7elikok",
      "Samuel Kaski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.16277"
  },
  {
    "id": "arXiv:2211.16280",
    "title": "Distance Teaching Experience of Campus-based Teachers at Times of  Pandemic Confinement",
    "abstract": "Amidst the outbreak of the coronavirus (COVID 19) pandemic, distance\neducation, where the learning process is conducted online, has become the norm.\nCampus-based programs and courses have been redesigned in a timely manner which\nwas a challenge for teachers not used to distance teaching. Students engagement\nand active participation become an issue; add to that new emerging effects\nassociating with this set-up, such as the so called 'Zoom fatigue', which was\ncoined recently by some authors. In realising this problem, solutions were\nsuggested in the literature to help trigger students engagement and enhance\nteachers experience in online teaching. This study analyses these effects along\nwith our teachers experience in the new learning environment and concludes by\ndevising some recommendations. To attain the above objectives, we conducted\nonline interviews with six of our teachers, transcribed the content of the\nvideos and then applied the inductive research approach to assess the results.",
    "descriptor": "\nComments: Abbas Cheddad and Christian Nordahl. Distance Teaching Experience of Campus-based Teachers at Times of Pandemic Confinement, ACM 5th International Conference on Education Technology Management (ICETM 2022), University of Lincoln, UK, December 16-18, 2022\n",
    "authors": [
      "Abbas Cheddad",
      "Christian Nordahl"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.16280"
  },
  {
    "id": "arXiv:2211.16281",
    "title": "DAGFiNN: A Conversational Conference Assistant",
    "abstract": "DAGFiNN is a conversational conference assistant that can be made available\nfor a given conference both as a chatbot on the website and as a Furhat robot\nphysically exhibited at the conference venue. Conference participants can\ninteract with the assistant to get advice on various questions, ranging from\nwhere to eat in the city or how to get to the airport to which sessions we\nrecommend them to attend based on the information we have about them. The\noverall objective is to provide a personalized and engaging experience and\nallow users to ask a broad range of questions that naturally arise before and\nduring the conference.",
    "descriptor": "",
    "authors": [
      "Ivica Kostric",
      "Krisztian Balog",
      "T\u00f8ll\u00f8v Alexander Aresvik",
      "Nolwenn Bernard",
      "Eyvinn Thu D\u00f8rheim",
      "Pholit Hantula",
      "Sander Havn-S\u00f8rensen",
      "Rune Henriksen",
      "Hengameh Hosseini",
      "Ekaterina Khlybova",
      "Weronika Lajewska",
      "Sindre Ekrheim Mosand",
      "Narmin Orujova"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.16281"
  },
  {
    "id": "arXiv:2211.16284",
    "title": "Common Knowledge of Abstract Groups",
    "abstract": "Epistemic logics typically talk about knowledge of individual agents or\ngroups of explicitly listed agents. Often, however, one wishes to express\nknowledge of groups of agents specified by a given property, as in `it is\ncommon knowledge among economists'. We introduce such a logic of common\nknowledge, which we term abstract-group epistemic logic (AGEL). That is, AGEL\nfeatures a common knowledge operator for groups of agents given by concepts in\na separate agent logic that we keep generic, with one possible agent logic\nbeing ALC. We show that AGEL is EXPTIME-complete, with the lower bound\nestablished by reduction from standard group epistemic logic, and the upper\nbound by a satisfiability-preserving embedding into the full $\\mu$-calculus.\nFurther main results include a finite model property (not enjoyed by the full\n$\\mu$-calculus) and a complete axiomatization.",
    "descriptor": "\nComments: Version with appendix of the AAAI23 publication\n",
    "authors": [
      "Merlin Humml",
      "Lutz Schr\u00f6der"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.16284"
  },
  {
    "id": "arXiv:2211.16285",
    "title": "Evaluating Unsupervised Text Classification: Zero-shot and  Similarity-based Approaches",
    "abstract": "Text classification of unseen classes is a challenging Natural Language\nProcessing task and is mainly attempted using two different types of\napproaches. Similarity-based approaches attempt to classify instances based on\nsimilarities between text document representations and class description\nrepresentations. Zero-shot text classification approaches aim to generalize\nknowledge gained from a training task by assigning appropriate labels of\nunknown classes to text documents. Although existing studies have already\ninvestigated individual approaches to these categories, the experiments in\nliterature do not provide a consistent comparison. This paper addresses this\ngap by conducting a systematic evaluation of different similarity-based and\nzero-shot approaches for text classification of unseen classes. Different\nstate-of-the-art approaches are benchmarked on four text classification\ndatasets, including a new dataset from the medical domain. Additionally, novel\nSimCSE and SBERT-based baselines are proposed, as other baselines used in\nexisting work yield weak classification results and are easily outperformed.\nFinally, the novel similarity-based Lbl2TransformerVec approach is presented,\nwhich outperforms previous state-of-the-art approaches in unsupervised text\nclassification. Our experiments show that similarity-based approaches\nsignificantly outperform zero-shot approaches in most cases. Additionally,\nusing SimCSE or SBERT embeddings instead of simpler text representations\nincreases similarity-based classification results even further.",
    "descriptor": "\nComments: Accepted to 6th International Conference on Natural Language Processing and Information Retrieval (NLPIR '22)\n",
    "authors": [
      "Tim Schopf",
      "Daniel Braun",
      "Florian Matthes"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16285"
  },
  {
    "id": "arXiv:2211.16289",
    "title": "Lightweight Structure-Aware Attention for Visual Understanding",
    "abstract": "Vision Transformers (ViTs) have become a dominant paradigm for visual\nrepresentation learning with self-attention operators. Although these operators\nprovide flexibility to the model with their adjustable attention kernels, they\nsuffer from inherent limitations: (1) the attention kernel is not\ndiscriminative enough, resulting in high redundancy of the ViT layers, and (2)\nthe complexity in computation and memory is quadratic in the sequence length.\nIn this paper, we propose a novel attention operator, called lightweight\nstructure-aware attention (LiSA), which has a better representation power with\nlog-linear complexity. Our operator learns structural patterns by using a set\nof relative position embeddings (RPEs). To achieve log-linear complexity, the\nRPEs are approximated with fast Fourier transforms. Our experiments and\nablation studies demonstrate that ViTs based on the proposed operator\noutperform self-attention and other existing operators, achieving\nstate-of-the-art results on ImageNet, and competitive results on other visual\nunderstanding benchmarks such as COCO and Something-Something-V2. The source\ncode of our approach will be released online.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Heeseung Kwon",
      "Francisco M. Castro",
      "Manuel J. Marin-Jimenez",
      "Nicolas Guil",
      "Karteek Alahari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16289"
  },
  {
    "id": "arXiv:2211.16290",
    "title": "Finer-Grained Correlations: Location Priors for Unseen Object Pose  Estimation",
    "abstract": "We present a new method which provides object location priors for previously\nunseen object 6D pose estimation. Existing approaches build upon a template\nmatching strategy and convolve a set of reference images with the query.\nUnfortunately, their performance is affected by the object scale mismatches\nbetween the references and the query. To address this issue, we present a\nfiner-grained correlation estimation module, which handles the object scale\nmismatches by computing correlations with adjustable receptive fields. We also\npropose to decouple the correlations into scale-robust and scale-aware\nrepresentations to estimate the object location and size, respectively. Our\nmethod achieves state-of-the-art unseen object localization and 6D pose\nestimation results on LINEMOD and GenMOP. We further construct a challenging\nsynthetic dataset, where the results highlight the better robustness of our\nmethod to varying backgrounds, illuminations, and object sizes, as well as to\nthe reference-query domain gap.",
    "descriptor": "",
    "authors": [
      "Chen Zhao",
      "Yinlin Hu",
      "Mathieu Salzmann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.16290"
  },
  {
    "id": "arXiv:2211.16297",
    "title": "Positivity-preserving and entropy-bounded discontinuous Galerkin method  for the chemically reacting, compressible Euler equations. Part II: The  multidimensional case",
    "abstract": "In this second part of our two-part paper, we extend to multiple spatial\ndimensions the one-dimensional, fully conservative, positivity-preserving, and\nentropy-bounded discontinuous Galerkin scheme developed in the first part for\nthe chemically reacting Euler equations. Our primary objective is to enable\nrobust and accurate solutions to complex reacting-flow problems using the\nhigh-order discontinuous Galerkin method without requiring extremely high\nresolution. Variable thermodynamics and detailed chemistry are considered. Our\nmultidimensional framework can be regarded as a further generalization of\nsimilar positivity-preserving and/or entropy-bounded discontinuous Galerkin\nschemes in the literature. In particular, the proposed formulation is\ncompatible with curved elements of arbitrary shape, a variety of numerical flux\nfunctions, general quadrature rules with positive weights, and mixtures of\nthermally perfect gases. Preservation of pressure equilibrium between adjacent\nelements, especially crucial in simulations of multicomponent flows, is\ndiscussed. Complex detonation waves in two and three dimensions are accurately\ncomputed using high-order polynomials. Enforcement of an entropy bound, as\nopposed to solely the positivity property, is found to significantly improve\nstability. Mass, total energy, and atomic elements are shown to be discretely\nconserved.",
    "descriptor": "",
    "authors": [
      "Eric J. Ching",
      "Ryan F. Johnson",
      "Andrew D. Kercher"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2211.16297"
  },
  {
    "id": "arXiv:2211.16299",
    "title": "Transferability Estimation Based On Principal Gradient Expectation",
    "abstract": "Deep transfer learning has been widely used for knowledge transmission in\nrecent years. The standard approach of pre-training and subsequently\nfine-tuning, or linear probing, has shown itself to be effective in many\ndown-stream tasks. Therefore, a challenging and ongoing question arises: how to\nquantify cross-task transferability that is compatible with transferred results\nwhile keeping self-consistency? Existing transferability metrics are estimated\non the particular model by conversing source and target tasks. They must be\nrecalculated with all existing source tasks whenever a novel unknown target\ntask is encountered, which is extremely computationally expensive. In this\nwork, we highlight what properties should be satisfied and evaluate existing\nmetrics in light of these characteristics. Building upon this, we propose\nPrincipal Gradient Expectation (PGE), a simple yet effective method for\nassessing transferability across tasks. Specifically, we use a restart scheme\nto calculate every batch gradient over each weight unit more than once, and\nthen we take the average of all the gradients to get the expectation. Thus, the\ntransferability between the source and target task is estimated by computing\nthe distance of normalized principal gradients. Extensive experiments show that\nthe proposed transferability metric is more stable, reliable and efficient than\nSOTA methods.",
    "descriptor": "\nComments: With Additional Material\n",
    "authors": [
      "Huiyan Qi",
      "Lechao Cheng",
      "Jingjing Chen",
      "Yue Yu",
      "Zunlei Feng",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16299"
  },
  {
    "id": "arXiv:2211.16300",
    "title": "Dual adaptive MPC using an exact set-membership reformulation",
    "abstract": "Adaptive model predictive control (MPC) methods using set-membership\nidentification to reduce parameter uncertainty are considered in this work.\nStrong duality is used to reformulate the set-membership equations exactly\nwithin the MPC optimization. A predicted worst-case cost is then used to enable\nperformance-oriented exploration. The proposed approach guarantees robust\nconstraint satisfaction and recursive feasibility. It is shown that method can\nbe implemented using homothetic tube and flexible tube parameterizations of\nstate tubes, and a simulation study demonstrates performance improvement over\nstate-of-the-art controllers.",
    "descriptor": "\nComments: Submitted to IFAC World Congress 2023\n",
    "authors": [
      "Anilkumar Parsi",
      "Diyou Liu",
      "Andrea Iannelli",
      "Roy S. Smith"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.16300"
  },
  {
    "id": "arXiv:2211.16301",
    "title": "Challenging the Universal Representation of Deep Models for 3D Point  Cloud Registration",
    "abstract": "Learning universal representations across different applications domain is an\nopen research problem. In fact, finding universal architecture within the same\napplication but across different types of datasets is still unsolved problem\ntoo, especially in applications involving processing 3D point clouds. In this\nwork we experimentally test several state-of-the-art learning-based methods for\n3D point cloud registration against the proposed non-learning baseline\nregistration method. The proposed method either outperforms or achieves\ncomparable results w.r.t. learning based methods. In addition, we propose a\ndataset on which learning based methods have a hard time to generalize. Our\nproposed method and dataset, along with the provided experiments, can be used\nin further research in studying effective solutions for universal\nrepresentations. Our source code is available at:\ngithub.com/DavidBoja/greedy-grid-search.",
    "descriptor": "\nComments: Accepted at the BMVC 2022 workshop: Universal Representations for Computer Vison (URCV) (this https URL)\n",
    "authors": [
      "David Bojani\u0107",
      "Kristijan Bartol",
      "Josep Forest",
      "Stefan Gumhold",
      "Tomislav Petkovi\u0107",
      "Tomislav Pribani\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16301"
  },
  {
    "id": "arXiv:2211.16304",
    "title": "Analysis of Anomalous Behavior in Network Systems Using Deep  Reinforcement Learning with CNN Architecture",
    "abstract": "In order to gain access to networks, different types of intrusion attacks\nhave been designed, and the attackers are working on improving them. Computer\nnetworks have become increasingly important in daily life due to the increasing\nreliance on them. In light of this, it is quite evident that algorithms with\nhigh detection accuracy and reliability are needed for various types of\nattacks. The purpose of this paper is to develop an intrusion detection system\nthat is based on deep reinforcement learning. Based on the Markov decision\nprocess, the proposed system can generate informative representations suitable\nfor classification tasks based on vast data. Reinforcement learning is\nconsidered from two different perspectives, deep Q learning, and double deep Q\nlearning. Different experiments have demonstrated that the proposed systems\nhave an accuracy of $99.17\\%$ over the UNSW-NB15 dataset in both approaches, an\nimprovement over previous methods based on contrastive learning and\nLSTM-Autoencoders. The performance of the model trained on UNSW-NB15 has also\nbeen evaluated on BoT-IoT datasets, resulting in competitive performance",
    "descriptor": "",
    "authors": [
      "Mohammad Hossein Modirrousta",
      "Parisa Forghani",
      "Mahdi Aliyari Shoorehdeli"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.16304"
  },
  {
    "id": "arXiv:2211.16305",
    "title": "How Many Tweets DoWe Need?: Efficient Mining of Short-Term Polarized  Topics on Twitter: A Case Study From Japan",
    "abstract": "In recent years, social media has been criticized for yielding polarization.\nIdentifying emerging disagreements and growing polarization is important for\njournalists to create alerts and provide more balanced coverage. While recent\nstudies have shown the existence of polarization on social media, they\nprimarily focused on limited topics such as politics with a large volume of\ndata collected in the long term, especially over months or years. While these\nfindings are helpful, they are too late to create an alert immediately. To\naddress this gap, we develop a domain-agnostic mining method to identify\npolarized topics on Twitter in a short-term period, namely 12 hours. As a\nresult, we find that daily Japanese news-related topics in early 2022 were\npolarized by 31.6\\% within a 12-hour range. We also analyzed that they tend to\nconstruct information diffusion networks with a relatively high average degree,\nand half of the tweets are created by a relatively small number of people.\nHowever, it is very costly and impractical to collect a large volume of tweets\ndaily on many topics and monitor the polarization due to the limitations of the\nTwitter API. To make it more cost-efficient, we also develop a prediction\nmethod using machine learning techniques to estimate the polarization level\nusing randomly collected tweets leveraging the network information. Extensive\nexperiments show a significant saving in collection costs compared to baseline\nmethods. In particular, our approach achieves F-score of 0.85, requiring 4,000\ntweets, 4x savings than the baseline. To the best of our knowledge, our work is\nthe first to predict the polarization level of the topics with low-resource\ntweets. Our findings have profound implications for the news media, allowing\njournalists to detect and disseminate polarizing information quickly and\nefficiently.",
    "descriptor": "\nComments: 9 pages, 9 figures\n",
    "authors": [
      "Tomoki Fukuma",
      "Koki Noda",
      "Hiroki Kumagai",
      "Hiroki Yamamoto",
      "Yoshiharu Ichikawa",
      "Kyosuke Kambe",
      "Yu Maubuchi",
      "Fujio Toriumi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.16305"
  },
  {
    "id": "arXiv:2211.16307",
    "title": "Controllable speech synthesis by learning discrete phoneme-level  prosodic representations",
    "abstract": "In this paper, we present a novel method for phoneme-level prosody control of\nF0 and duration using intuitive discrete labels. We propose an unsupervised\nprosodic clustering process which is used to discretize phoneme-level F0 and\nduration features from a multispeaker speech dataset. These features are fed as\nan input sequence of prosodic labels to a prosody encoder module which augments\nan autoregressive attention-based text-to-speech model. We utilize various\nmethods in order to improve prosodic control range and coverage, such as\naugmentation, F0 normalization, balanced clustering for duration and\nspeaker-independent clustering. The final model enables fine-grained\nphoneme-level prosody control for all speakers contained in the training set,\nwhile maintaining the speaker identity. Instead of relying on reference\nutterances for inference, we introduce a prior prosody encoder which learns the\nstyle of each speaker and enables speech synthesis without the requirement of\nreference audio. We also fine-tune the multispeaker model to unseen speakers\nwith limited amounts of data, as a realistic application scenario and show that\nthe prosody control capabilities are maintained, verifying that the\nspeaker-independent prosodic clustering is effective. Experimental results show\nthat the model has high output speech quality and that the proposed method\nallows efficient prosody control within each speaker's range despite the\nvariability that a multispeaker setting introduces.",
    "descriptor": "\nComments: Final published version available at: Speech Communication. arXiv admin note: substantial text overlap with arXiv:2111.10168\n",
    "authors": [
      "Nikolaos Ellinas",
      "Myrsini Christidou",
      "Alexandra Vioni",
      "June Sig Sung",
      "Aimilios Chalamandaris",
      "Pirros Tsiakoulis",
      "Paris Mastorocostas"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.16307"
  },
  {
    "id": "arXiv:2211.16309",
    "title": "A Contextual Bandit Approach for Learning to Plan in Environments with  Probabilistic Goal Configurations",
    "abstract": "Object-goal navigation (Object-nav) entails searching, recognizing and\nnavigating to a target object. Object-nav has been extensively studied by the\nEmbodied-AI community, but most solutions are often restricted to considering\nstatic objects (e.g., television, fridge, etc.). We propose a modular framework\nfor object-nav that is able to efficiently search indoor environments for not\njust static objects but also movable objects (e.g. fruits, glasses, phones,\netc.) that frequently change their positions due to human intervention. Our\ncontextual-bandit agent efficiently explores the environment by showing\noptimism in the face of uncertainty and learns a model of the likelihood of\nspotting different objects from each navigable location. The likelihoods are\nused as rewards in a weighted minimum latency solver to deduce a trajectory for\nthe robot. We evaluate our algorithms in two simulated environments and a\nreal-world setting, to demonstrate high sample efficiency and reliability.",
    "descriptor": "\nComments: Shorter version accepted at NeurIPS 2022 Workshop on Robot Learning: Trustworthy Robotics\n",
    "authors": [
      "Sohan Rudra",
      "Saksham Goel",
      "Anirban Santara",
      "Claudio Gentile",
      "Laurent Perron",
      "Fei Xia",
      "Vikas Sindhwani",
      "Carolina Parada",
      "Gaurav Aggarwal"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.16309"
  },
  {
    "id": "arXiv:2211.16312",
    "title": "Language-driven Open-Vocabulary 3D Scene Understanding",
    "abstract": "Open-vocabulary scene understanding aims to localize and recognize unseen\ncategories beyond the annotated label space. The recent breakthrough of 2D\nopen-vocabulary perception is largely driven by Internet-scale paired\nimage-text data with rich vocabulary concepts. However, this success cannot be\ndirectly transferred to 3D scenarios due to the inaccessibility of large-scale\n3D-text pairs. To this end, we propose to distill knowledge encoded in\npre-trained vision-language (VL) foundation models through captioning\nmulti-view images from 3D, which allows explicitly associating 3D and\nsemantic-rich captions. Further, to facilitate coarse-to-fine visual-semantic\nrepresentation learning from captions, we design hierarchical 3D-caption pairs,\nleveraging geometric constraints between 3D scenes and multi-view images.\nFinally, by employing contrastive learning, the model learns language-aware\nembeddings that connect 3D and text for open-vocabulary tasks. Our method not\nonly remarkably outperforms baseline methods by 25.8% $\\sim$ 44.7% hIoU and\n14.5% $\\sim$ 50.4% hAP$_{50}$ on open-vocabulary semantic and instance\nsegmentation, but also shows robust transferability on challenging zero-shot\ndomain transfer tasks. Code will be available at\nhttps://github.com/CVMI-Lab/PLA.",
    "descriptor": "",
    "authors": [
      "Runyu Ding",
      "Jihan Yang",
      "Chuhui Xue",
      "Wenqing Zhang",
      "Song Bai",
      "Xiaojuan Qi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16312"
  },
  {
    "id": "arXiv:2211.16314",
    "title": "Approximating Intersections and Differences Between Statistical Shape  Models",
    "abstract": "To date, the comparison of Statistical Shape Models (SSMs) is often solely\nperformance-based and carried out by means of simplistic metrics such as\ncompactness, generalization, or specificity. Any similarities or differences\nbetween the actual shape spaces can neither be visualized nor quantified. In\nthis paper, we present a first method to compare two SSMs in dense\ncorrespondence by computing approximate intersection spaces and set-theoretic\ndifferences between the affine vector spaces spanned by the models. To this\nend, we approximate the distribution of shapes lying in the intersection space\nusing Markov Chain Monte Carlo, and then apply Principal Component Analysis\n(PCA) to its samples. By representing the resulting spaces again as an SSM, our\nmethod enables an easy and intuitive analysis of similarities between two\nmodel's shape spaces. We estimate differences between SSMs in a similar manner;\nhere, however, the resulting shape spaces are not linear vector spaces anymore\nand we do not apply PCA but instead use the posterior samples for\nvisualization. We showcase the proposed algorithm qualitatively by computing\nand analyzing intersection spaces and differences between publicly available\nface models focusing on gender-specific male and female as well as identity and\nexpression models. Our quantitative evaluation based on SSMs built from\nsynthetic and real-world data sets provides detailed evidence that the\nintroduced method is able to recover ground-truth intersection spaces and\ndifferences. Finally, we demonstrate that the proposed algorithm can be easily\nadapted to also compute intersections and differences between color spaces.",
    "descriptor": "\nComments: 13 pages, 7 figures\n",
    "authors": [
      "Maximilian Weiherer",
      "Finn Klein",
      "Bernhard Egger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16314"
  },
  {
    "id": "arXiv:2211.16315",
    "title": "Learning and Understanding a Disentangled Feature Representation for  Hidden Parameters in Reinforcement Learning",
    "abstract": "Hidden parameters are latent variables in reinforcement learning (RL)\nenvironments that are constant over the course of a trajectory. Understanding\nwhat, if any, hidden parameters affect a particular environment can aid both\nthe development and appropriate usage of RL systems. We present an unsupervised\nmethod to map RL trajectories into a feature space where distance represents\nthe relative difference in system behavior due to hidden parameters. Our\napproach disentangles the effects of hidden parameters by leveraging a\nrecurrent neural network (RNN) world model as used in model-based RL. First, we\nalter the standard world model training algorithm to isolate the hidden\nparameter information in the world model memory. Then, we use a metric learning\napproach to map the RNN memory into a space with a distance metric\napproximating a bisimulation metric with respect to the hidden parameters. The\nresulting disentangled feature space can be used to meaningfully relate\ntrajectories to each other and analyze the hidden parameter. We demonstrate our\napproach on four hidden parameters across three RL environments. Finally we\npresent two methods to help identify and understand the effects of hidden\nparameters on systems.",
    "descriptor": "\nComments: Appears in Proceedings of AAAI FSS-22 Symposium \"Lessons Learned for Autonomous Assessment of Machine Abilities (LLAAMA)\"\n",
    "authors": [
      "Christopher Reale",
      "Rebecca Russell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16315"
  },
  {
    "id": "arXiv:2211.16316",
    "title": "A3T: Accuracy Aware Adversarial Training",
    "abstract": "Adversarial training has been empirically shown to be more prone to\noverfitting than standard training. The exact underlying reasons still need to\nbe fully understood. In this paper, we identify one cause of overfitting\nrelated to current practices of generating adversarial samples from\nmisclassified samples. To address this, we propose an alternative approach that\nleverages the misclassified samples to mitigate the overfitting problem. We\nshow that our approach achieves better generalization while having comparable\nrobustness to state-of-the-art adversarial training methods on a wide range of\ncomputer vision, natural language processing, and tabular tasks.",
    "descriptor": "",
    "authors": [
      "Enes Altinisik",
      "Safa Messaoud",
      "Husrev Taha Sencar",
      "Sanjay Chawla"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16316"
  },
  {
    "id": "arXiv:2211.16317",
    "title": "TF-Net: Deep Learning Empowered Tiny Feature Network for Night-time UAV  Detection",
    "abstract": "Technological advancements have normalized the usage of unmanned aerial\nvehicles (UAVs) in every sector, spanning from military to commercial but they\nalso pose serious security concerns due to their enhanced functionalities and\neasy access to private and highly secured areas. Several instances related to\nUAVs have raised security concerns, leading to UAV detection research studies.\nVisual techniques are widely adopted for UAV detection, but they perform poorly\nat night, in complex backgrounds, and in adverse weather conditions. Therefore,\na robust night vision-based drone detection system is required to that could\nefficiently tackle this problem. Infrared cameras are increasingly used for\nnighttime surveillance due to their wide applications in night vision\nequipment. This paper uses a deep learning-based TinyFeatureNet (TF-Net), which\nis an improved version of YOLOv5s, to accurately detect UAVs during the night\nusing infrared (IR) images. In the proposed TF-Net, we introduce architectural\nchanges in the neck and backbone of the YOLOv5s. We also simulated four\ndifferent YOLOv5 models (s,m,n,l) and proposed TF-Net for a fair comparison.\nThe results showed better performance for the proposed TF-Net in terms of\nprecision, IoU, GFLOPS, model size, and FPS compared to the YOLOv5s. TF-Net\nyielded the best results with 95.7\\% precision, 84\\% mAp, and 44.8\\% $IoU$.",
    "descriptor": "",
    "authors": [
      "Maham Misbah",
      "Misha Urooj Khan",
      "Zhaohui Yang",
      "Zeeshan Kaleem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16317"
  },
  {
    "id": "arXiv:2211.16318",
    "title": "BBOB Instance Analysis: Landscape Properties and Algorithm Performance  across Problem Instances",
    "abstract": "Benchmarking is a key aspect of research into optimization algorithms, and as\nsuch the way in which the most popular benchmark suites are designed implicitly\nguides some parts of algorithm design. One of these suites is the black-box\noptimization benchmarking (BBOB) suite of 24 single-objective noiseless\nfunctions, which has been a standard for over a decade. Within this problem\nsuite, different instances of a single problem can be created, which is\nbeneficial for testing the stability and invariance of algorithms under\ntransformations. In this paper, we investigate the BBOB instance creation\nprotocol by considering a set of 500 instances for each BBOB problem. Using\nexploratory landscape analysis, we show that the distribution of landscape\nfeatures across BBOB instances is highly diverse for a large set of problems.\nIn addition, we run a set of eight algorithms across these 500 instances, and\ninvestigate for which cases statistically significant differences in\nperformance occur. We argue that, while the transformations applied in BBOB\ninstances do indeed seem to preserve the high-level properties of the\nfunctions, their difference in practice should not be overlooked, particularly\nwhen treating the problems as box-constrained instead of unconstrained.",
    "descriptor": "",
    "authors": [
      "Fu Xing Long",
      "Diederick Vermetten",
      "Bas van Stein",
      "Anna V. Kononova"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.16318"
  },
  {
    "id": "arXiv:2211.16327",
    "title": "On the power of foundation models",
    "abstract": "With infinitely many high-quality data points, infinite computational power,\nan infinitely large foundation model with a perfect training algorithm and\nguaranteed zero generalization error on the pretext task, can the model be used\nfor everything? This question cannot be answered by the existing theory of\nrepresentation, optimization or generalization, because the issues they mainly\ninvestigate are assumed to be nonexistent here. In this paper, we show that\ncategory theory provides powerful machinery to answer this question. We have\nproved three results. The first one limits the power of prompt-based learning,\nsaying that the model can solve a downstream task with prompts if and only if\nthe task is representable. The second one says fine tuning does not have this\nlimit, as a foundation model with the minimum power (up to symmetry) can\ntheoretically solve downstream tasks with fine tuning and enough resources. Our\nfinal result can be seen as a new type of generalization theorem, showing that\nthe foundation model can generate unseen objects from the target category\n(e.g., images) using the structural information from the source category (e.g.,\ntexts). Along the way, we provide a categorical framework for supervised and\nself-supervised learning, which might be of independent interest.",
    "descriptor": "",
    "authors": [
      "Yang Yuan"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16327"
  },
  {
    "id": "arXiv:2211.16330",
    "title": "Reasoning about Promises in Weak Memory Models with Event Structures  (Extended Version)",
    "abstract": "Modern processors such as ARMv8 and RISC-V allow executions in which\nindependent instructions within a process may be reordered. To cope with such\nphenomena, so called promising semantics have been developed, which permit\nthreads to read values that have not yet been written. Each promise is a\nspeculative update that is later validated (fulfilled) by an actual write.\nPromising semantics are operational, providing a pathway for developing proof\ncalculi. In this paper, we develop an incorrectness-style logic, resulting in a\nframework for reasoning about state reachability. Like incorrectness logic, our\nassertions are underapproximating, since the set of all valid promises are not\nknown at the start of execution. Our logic uses event structures as assertions\nto compactly represent the ordering among events such as promised and fulfilled\nwrites. We prove soundness and completeness of our proof calculus and\ndemonstrate its applicability by proving reachability properties of standard\nweak memory litmus tests.",
    "descriptor": "\nComments: Extended version of the paper to appear at FM 2023\n",
    "authors": [
      "Heike Wehrheim",
      "Lara Bargmann",
      "Brijesh Dongol"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.16330"
  },
  {
    "id": "arXiv:2211.16333",
    "title": "Outlier-Robust Sparse Mean Estimation for Heavy-Tailed Distributions",
    "abstract": "We study the fundamental task of outlier-robust mean estimation for\nheavy-tailed distributions in the presence of sparsity. Specifically, given a\nsmall number of corrupted samples from a high-dimensional heavy-tailed\ndistribution whose mean $\\mu$ is guaranteed to be sparse, the goal is to\nefficiently compute a hypothesis that accurately approximates $\\mu$ with high\nprobability. Prior work had obtained efficient algorithms for robust sparse\nmean estimation of light-tailed distributions. In this work, we give the first\nsample-efficient and polynomial-time robust sparse mean estimator for\nheavy-tailed distributions under mild moment assumptions. Our algorithm\nachieves the optimal asymptotic error using a number of samples scaling\nlogarithmically with the ambient dimension. Importantly, the sample complexity\nof our method is optimal as a function of the failure probability $\\tau$,\nhaving an additive $\\log(1/\\tau)$ dependence. Our algorithm leverages the\nstability-based approach from the algorithmic robust statistics literature,\nwith crucial (and necessary) adaptations required in our setting. Our analysis\nmay be of independent interest, involving the delicate design of a\n(non-spectral) decomposition for positive semi-definite matrices satisfying\ncertain sparsity properties.",
    "descriptor": "\nComments: To appear in NeurIPS 2022\n",
    "authors": [
      "Ilias Diakonikolas",
      "Daniel M. Kane",
      "Jasper C.H. Lee",
      "Ankit Pensia"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.16333"
  },
  {
    "id": "arXiv:2211.16335",
    "title": "X-ICP: Localizability-Aware LiDAR Registration for Robust Localization  in Extreme Environments",
    "abstract": "Modern robotic systems are required to operate in challenging environments,\nwhich demand reliable localization under challenging conditions. LiDAR-based\nlocalization methods, such as the Iterative Closest Point (ICP) algorithm, can\nsuffer in geometrically uninformative environments that are known to\ndeteriorate registration performance and push optimization toward divergence\nalong weakly constrained directions. To overcome this issue, this work proposes\ni) a robust multi-category (non-)localizability detection module, and ii) a\nlocalizability-aware constrained ICP optimization module and couples both in a\nunified manner. The proposed localizability detection is achieved by utilizing\nthe correspondences between the scan and the map to analyze the alignment\nstrength against the principal directions of the optimization as part of its\nmulti-category LiDAR localizability analysis. In the second part, this\nlocalizability analysis is then tightly integrated into the scan-to-map point\ncloud registration to generate drift-free pose updates along well-constrained\ndirections. The proposed method is thoroughly evaluated and compared to\nstate-of-the-art methods in simulation and during real-world experiments1,\nunderlying the gain in performance and reliability in LiDAR-challenging\nscenarios. In all experiments, the proposed framework demonstrates accurate and\ngeneralizable localizability detection and robust pose estimation without\nenvironment-specific parameter tuning.",
    "descriptor": "\nComments: 17 Pages, 17 Figures Submitted to IEEE Transactions On Robotics. Supplementary Video: this https URL Project Website: this https URL\n",
    "authors": [
      "Turcan Tuna",
      "Julian Nubert",
      "Yoshua Nava",
      "Shehryar Khattak",
      "Marco Hutter"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.16335"
  },
  {
    "id": "arXiv:2211.16342",
    "title": "Fourier-Net: Fast Image Registration with Band-limited Deformation",
    "abstract": "Unsupervised image registration commonly adopts U-Net style networks to\npredict dense displacement fields in the full-resolution spatial domain. For\nhigh-resolution volumetric image data, this process is however resource\nintensive and time-consuming. To tackle this problem, we propose the\nFourier-Net, replacing the expansive path in a U-Net style network with a\nparameter-free model-driven decoder. Specifically, instead of our Fourier-Net\nlearning to output a full-resolution displacement field in the spatial domain,\nwe learn its low-dimensional representation in a band-limited Fourier domain.\nThis representation is then decoded by our devised model-driven decoder\n(consisting of a zero padding layer and an inverse discrete Fourier transform\nlayer) to the dense, full-resolution displacement field in the spatial domain.\nThese changes allow our unsupervised Fourier-Net to contain fewer parameters\nand computational operations, resulting in faster inference speeds. Fourier-Net\nis then evaluated on two public 3D brain datasets against various\nstate-of-the-art approaches. For example, when compared to a recent\ntransformer-based method, i.e., TransMorph, our Fourier-Net, only using\n0.22$\\%$ of its parameters and 6.66$\\%$ of the mult-adds, achieves a 0.6\\%\nhigher Dice score and an 11.48$\\times$ faster inference speed. Code is\navailable at \\url{https://github.com/xi-jia/Fourier-Net}.",
    "descriptor": "\nComments: This version was submitted to and accepted by AAAI 2023. (Some of) The content will be changed according to the reviewers' comments\n",
    "authors": [
      "Xi Jia",
      "Joseph Bartlett",
      "Wei Chen",
      "Siyang Song",
      "Tianyang Zhang",
      "Xinxing Cheng",
      "Wenqi Lu",
      "Zhaowen Qiu",
      "Jinming Duan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16342"
  },
  {
    "id": "arXiv:2211.16349",
    "title": "BARTSmiles: Generative Masked Language Models for Molecular  Representations",
    "abstract": "We discover a robust self-supervised strategy tailored towards molecular\nrepresentations for generative masked language models through a series of\ntailored, in-depth ablations. Using this pre-training strategy, we train\nBARTSmiles, a BART-like model with an order of magnitude more compute than\nprevious self-supervised molecular representations. In-depth evaluations show\nthat BARTSmiles consistently outperforms other self-supervised representations\nacross classification, regression, and generation tasks setting a new\nstate-of-the-art on 11 tasks. We then quantitatively show that when applied to\nthe molecular domain, the BART objective learns representations that implicitly\nencode our downstream tasks of interest. For example, by selecting seven\nneurons from a frozen BARTSmiles, we can obtain a model having performance\nwithin two percentage points of the full fine-tuned model on task Clintox.\nLastly, we show that standard attribution interpretability methods, when\napplied to BARTSmiles, highlight certain substructures that chemists use to\nexplain specific properties of molecules. The code and the pretrained model are\npublicly available.",
    "descriptor": "\nComments: 27 pages (including appendix)\n",
    "authors": [
      "Gayane Chilingaryan",
      "Hovhannes Tamoyan",
      "Ani Tevosyan",
      "Nelly Babayan",
      "Lusine Khondkaryan",
      "Karen Hambardzumyan",
      "Zaven Navoyan",
      "Hrant Khachatrian",
      "Armen Aghajanyan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2211.16349"
  },
  {
    "id": "arXiv:2211.16350",
    "title": "On \"Deep Learning\" Misconduct",
    "abstract": "This is a theoretical paper, as a companion paper of the plenary talk for the\nsame conference ISAIC 2022. In contrast to conscious learning, which develops a\nsingle network for a normal life and is the main topic of the plenary talk, it\nis necessary to address the currently widespread approach, so-called \"Deep\nLearning\". Although \"Deep Learning\" may use different learning modes, including\nsupervised, reinforcement and adversarial modes, almost all \"Deep Learning\"\nprojects apparently suffer from the same misconduct, called \"data deletion\" and\n\"test on training data\". Consequently, Deep Learning almost always was not\ntested at all. Why? The so-called \"test set\" was used in the Post-Selection\nstep of the training stage. This paper establishes a theorem that a simple\nmethod called Pure-Guess Nearest Neighbor (PGNN) reaches any required errors on\nvalidation set and test set, including zero-error requirements, through the\n\"Deep Learning\" misconduct, as long as the test set is in the possession of the\nauthor and both the amount of storage space and the time of training are finite\nbut unbounded. However, Deep Learning methods, like the PGNN method, apparently\nare not generalizable since they have never been tested at all by a valid test\nset.",
    "descriptor": "\nComments: Manuscript submitted to ISAIC 2022, 6 pages, three figures. arXiv admin note: text overlap with arXiv:2208.11228\n",
    "authors": [
      "Juyang Weng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16350"
  },
  {
    "id": "arXiv:2211.16352",
    "title": "D\u00e9couvrir de nouvelles classes dans des donn\u00e9es tabulaires",
    "abstract": "In Novel Class Discovery (NCD), the goal is to find new classes in an\nunlabeled set given a labeled set of known but different classes. While NCD has\nrecently gained attention from the community, no framework has yet been\nproposed for heterogeneous tabular data, despite being a very common\nrepresentation of data. In this paper, we propose TabularNCD, a new method for\ndiscovering novel classes in tabular data. We show a way to extract knowledge\nfrom already known classes to guide the discovery process of novel classes in\nthe context of tabular data which contains heterogeneous variables. A part of\nthis process is done by a new method for defining pseudo labels, and we follow\nrecent findings in Multi-Task Learning to optimize a joint objective function.\nOur method demonstrates that NCD is not only applicable to images but also to\nheterogeneous tabular data.",
    "descriptor": "\nComments: 8 pages, in french\n",
    "authors": [
      "Colin Troisemaine",
      "Joachim Flocon-Cholet",
      "St\u00e9phane Gosselin",
      "Sandrine Vaton",
      "Alexandre Reiffers-Masson",
      "Vincent Lemaire"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16352"
  },
  {
    "id": "arXiv:2211.16353",
    "title": "Outfit Generation and Recommendation -- An Experimental Study",
    "abstract": "Over the past years, fashion-related challenges have gained a lot of\nattention in the research community. Outfit generation and recommendation,\ni.e., the composition of a set of items of different types (e.g., tops, bottom,\nshoes, accessories) that go well together, are among the most challenging ones.\nThat is because items have to be both compatible amongst each other and also\npersonalized to match the taste of the customer. Recently there has been a\nplethora of work targeted at tackling these problems by adopting various\ntechniques and algorithms from the machine learning literature. However, to\ndate, there is no extensive comparison of the performance of the different\nalgorithms for outfit generation and recommendation. In this paper, we close\nthis gap by providing a broad evaluation and comparison of various algorithms,\nincluding both personalized and non-personalized approaches, using online,\nreal-world user data from one of Europe's largest fashion stores. We present\nthe adaptations we made to some of those models to make them suitable for\npersonalized outfit generation. Moreover, we provide insights for models that\nhave not yet been evaluated on this task, specifically, GPT, BERT and\nSeq-to-Seq LSTM.",
    "descriptor": "\nComments: fashionXrecsys '20: Workshop on Recommender Systems in Fashion, 14th ACM Conference on Recommender Systems, September 22--26, 2020, Virtual Event, Brazil\n",
    "authors": [
      "Marjan Celikik",
      "Matthias Kirmse",
      "Timo Denk",
      "Pierre Gagliardi",
      "Sahar Mbarek",
      "Duy Pham",
      "Ana Peleteiro Ramallo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16353"
  },
  {
    "id": "arXiv:2211.16356",
    "title": "Real-time Blind Deblurring Based on Lightweight Deep-Wiener-Network",
    "abstract": "In this paper, we address the problem of blind deblurring with high\nefficiency. We propose a set of lightweight deep-wiener-network to finish the\ntask with real-time speed. The Network contains a deep neural network for\nestimating parameters of wiener networks and a wiener network for deblurring.\nExperimental evaluations show that our approaches have an edge on State of the\nArt in terms of inference times and numbers of parameters. Two of our models\ncan reach a speed of 100 images per second, which is qualified for real-time\ndeblurring. Further research may focus on some real-world applications of\ndeblurring with our models.",
    "descriptor": "",
    "authors": [
      "Runjia Li",
      "Yang Yu",
      "Charlie Haywood"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.16356"
  },
  {
    "id": "arXiv:2211.16360",
    "title": "Is Twitter Enough? Investigating Situational Awareness in Social and  Print Media during the Second COVID-19 Wave in India",
    "abstract": "The pandemic required efficient allocation of public resources and\ntransforming existing ways of societal functions. To manage any crisis,\ngovernments and public health researchers exploit the information available to\nthem in order to make informed decisions, also defined as situational\nawareness. Gathering situational awareness using social media has been\nfunctional to manage epidemics. Previous research focused on using discussions\nduring periods of epidemic crises on social media platforms like Twitter,\nReddit, or Facebook and developing NLP techniques to filter out relevant\ndiscussions from a huge corpus of messages and posts. Social media usage varies\nwith internet penetration and other socioeconomic factors, which might induce\ndisparity in analyzing discussions across different geographies. However, print\nmedia is a ubiquitous information source, irrespective of geography. Further,\ntopics discussed in news articles are already newsworthy, while on social media\nnewsworthiness is a product of techno-social processes. Developing this\nfundamental difference, we study Twitter data during the second wave in India\nfocused on six high-population cities with varied macroeconomic factors.\nThrough a mixture of qualitative and quantitative methods, we further analyze\ntwo Indian newspapers during the same period and compare topics from both\nTwitter and the newspapers to evaluate situational awareness around the second\nphase of COVID on each of these platforms. We conclude that factors like\ninternet penetration and GDP in a specific city influence the discourse\nsurrounding situational updates on social media. Thus, augmenting information\nfrom newspapers with information extracted from social media would provide a\nmore comprehensive perspective in resource deficit cities.",
    "descriptor": "\nComments: Published at 2022 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)\n",
    "authors": [
      "Ishita Vohra",
      "Meher Shashwat Nigam",
      "Aryan Sakaria",
      "Amey Kudari",
      "Nimmi Rangaswamy"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.16360"
  },
  {
    "id": "arXiv:2211.16366",
    "title": "Reusable Self-Attention-based Recommender System for Fashion",
    "abstract": "A large number of empirical studies on applying self-attention models in the\ndomain of recommender systems are based on offline evaluation and metrics\ncomputed on standardized datasets, without insights on how these models perform\nin real life scenarios. Moreover, many of them do not consider information such\nas item and customer metadata, although deep-learning recommenders live up to\ntheir full potential only when numerous features of heterogeneous types are\nincluded. Also, typically recommendation models are designed to serve well only\na single use case, which increases modeling complexity and maintenance costs,\nand may lead to inconsistent customer experience. In this work, we present a\nreusable Attention-based Fashion Recommendation Algorithm (AFRA), that utilizes\nvarious interaction types with different fashion entities such as items (e.g.,\nshirt), outfits and influencers, and their heterogeneous features. Moreover, we\nleverage temporal and contextual information to address both short and\nlong-term customer preferences. We show its effectiveness on outfit\nrecommendation use cases, in particular: 1) personalized ranked feed; 2) outfit\nrecommendations by style; 3) similar item recommendation and 4) in-session\nrecommendations inspired by most recent customer actions. We present both\noffline and online experimental results demonstrating substantial improvements\nin customer retention and engagement.",
    "descriptor": "\nComments: FashionXRecSys'22: Workshop on Recommender Systems in Fashion, September 23, 2022, Seattle, WA. Parts published in RecSys 2022 (industry track)\n",
    "authors": [
      "Marjan Celikik",
      "Jacek Wasilewski",
      "Sahar Mbarek",
      "Pablo Celayes",
      "Pierre Gagliardi",
      "Duy Pham",
      "Nour Karessli",
      "Ana Peleteiro Ramallo"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16366"
  },
  {
    "id": "arXiv:2211.16368",
    "title": "DBA: Efficient Transformer with Dynamic Bilinear Low-Rank Attention",
    "abstract": "Many studies have been conducted to improve the efficiency of Transformer\nfrom quadric to linear. Among them, the low-rank-based methods aim to learn the\nprojection matrices to compress the sequence length. However, the projection\nmatrices are fixed once they have been learned, which compress sequence length\nwith dedicated coefficients for tokens in the same position. Adopting such\ninput-invariant projections ignores the fact that the most informative part of\na sequence varies from sequence to sequence, thus failing to preserve the most\nuseful information that lies in varied positions. In addition, previous\nefficient Transformers only focus on the influence of sequence length while\nneglecting the effect of hidden state dimension. To address the aforementioned\nproblems, we present an efficient yet effective attention mechanism, namely the\nDynamic Bilinear Low-Rank Attention (DBA), which compresses the sequence length\nby input-sensitive dynamic projection matrices and achieves linear time and\nspace complexity by jointly optimizing the sequence length and hidden state\ndimension while maintaining state-of-the-art performance. Specifically, we\nfirst theoretically demonstrate that the sequence length can be compressed\nnon-destructively from a novel perspective of information theory, with\ncompression matrices dynamically determined by the input sequence. Furthermore,\nwe show that the hidden state dimension can be approximated by extending the\nJohnson-Lindenstrauss lemma, optimizing the attention in bilinear form.\nTheoretical analysis shows that DBA is proficient in capturing high-order\nrelations in cross-attention problems. Experiments over tasks with diverse\nsequence length conditions show that DBA achieves state-of-the-art performance\ncompared with various strong baselines while maintaining less memory\nconsumption with higher speed.",
    "descriptor": "\nComments: 19 pages, 4 figures\n",
    "authors": [
      "Bosheng Qin",
      "Juncheng Li",
      "Siliang Tang",
      "Yueting Zhuang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16368"
  },
  {
    "id": "arXiv:2211.16374",
    "title": "DATID-3D: Diversity-Preserved Domain Adaptation Using Text-to-Image  Diffusion for 3D Generative Model",
    "abstract": "Recent 3D generative models have achieved remarkable performance in\nsynthesizing high resolution photorealistic images with view consistency and\ndetailed 3D shapes, but training them for diverse domains is challenging since\nit requires massive training images and their camera distribution information.\nText-guided domain adaptation methods have shown impressive performance on\nconverting the 2D generative model on one domain into the models on other\ndomains with different styles by leveraging the CLIP (Contrastive\nLanguage-Image Pre-training), rather than collecting massive datasets for those\ndomains. However, one drawback of them is that the sample diversity in the\noriginal generative model is not well-preserved in the domain-adapted\ngenerative models due to the deterministic nature of the CLIP text encoder.\nText-guided domain adaptation will be even more challenging for 3D generative\nmodels not only because of catastrophic diversity loss, but also because of\ninferior text-image correspondence and poor image quality. Here we propose\nDATID-3D, a domain adaptation method tailored for 3D generative models using\ntext-to-image diffusion models that can synthesize diverse images per text\nprompt without collecting additional images and camera information for the\ntarget domain. Unlike 3D extensions of prior text-guided domain adaptation\nmethods, our novel pipeline was able to fine-tune the state-of-the-art 3D\ngenerator of the source domain to synthesize high resolution, multi-view\nconsistent images in text-guided targeted domains without additional data,\noutperforming the existing text-guided domain adaptation methods in diversity\nand text-image correspondence. Furthermore, we propose and demonstrate diverse\n3D image manipulations such as one-shot instance-selected adaptation and\nsingle-view manipulated 3D reconstruction to fully enjoy diversity in text.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Gwanghyun Kim",
      "Se Young Chun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16374"
  },
  {
    "id": "arXiv:2211.16381",
    "title": "Symmetry Detection in Trajectory Data for More Meaningful Reinforcement  Learning Representations",
    "abstract": "Knowledge of the symmetries of reinforcement learning (RL) systems can be\nused to create compressed and semantically meaningful representations of a\nlow-level state space. We present a method of automatically detecting RL\nsymmetries directly from raw trajectory data without requiring active control\nof the system. Our method generates candidate symmetries and trains a recurrent\nneural network (RNN) to discriminate between the original trajectories and the\ntransformed trajectories for each candidate symmetry. The RNN discriminator's\naccuracy for each candidate reveals how symmetric the system is under that\ntransformation. This information can be used to create high-level\nrepresentations that are invariant to all symmetries on a dataset level and to\ncommunicate properties of the RL behavior to users. We show in experiments on\ntwo simulated RL use cases (a pusher robot and a UAV flying in wind) that our\nmethod can determine the symmetries underlying both the environment physics and\nthe trained RL policy.",
    "descriptor": "\nComments: Appears in Proceedings of AAAI FSS-22 Symposium \"Lessons Learned for Autonomous Assessment of Machine Abilities (LLAAMA)\"\n",
    "authors": [
      "Marissa D'Alonzo",
      "Rebecca Russell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.16381"
  },
  {
    "id": "arXiv:2211.16385",
    "title": "Multi-Agent Reinforcement Learning for Microprocessor Design Space  Exploration",
    "abstract": "Microprocessor architects are increasingly resorting to domain-specific\ncustomization in the quest for high-performance and energy-efficiency. As the\nsystems grow in complexity, fine-tuning architectural parameters across\nmultiple sub-systems (e.g., datapath, memory blocks in different hierarchies,\ninterconnects, compiler optimization, etc.) quickly results in a combinatorial\nexplosion of design space. This makes domain-specific customization an\nextremely challenging task. Prior work explores using reinforcement learning\n(RL) and other optimization methods to automatically explore the large design\nspace. However, these methods have traditionally relied on single-agent RL/ML\nformulations. It is unclear how scalable single-agent formulations are as we\nincrease the complexity of the design space (e.g., full stack System-on-Chip\ndesign). Therefore, we propose an alternative formulation that leverages\nMulti-Agent RL (MARL) to tackle this problem. The key idea behind using MARL is\nan observation that parameters across different sub-systems are more or less\nindependent, thus allowing a decentralized role assigned to each agent. We test\nthis hypothesis by designing domain-specific DRAM memory controller for several\nworkload traces. Our evaluation shows that the MARL formulation consistently\noutperforms single-agent RL baselines such as Proximal Policy Optimization and\nSoft Actor-Critic over different target objectives such as low power and\nlatency. To this end, this work opens the pathway for new and promising\nresearch in MARL solutions for hardware architecture search.",
    "descriptor": "\nComments: Workshop on ML for Systems at NeurIPS 2022\n",
    "authors": [
      "Srivatsan Krishnan",
      "Natasha Jaques",
      "Shayegan Omidshafiei",
      "Dan Zhang",
      "Izzeddin Gur",
      "Vijay Janapa Reddi",
      "Aleksandra Faust"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.16385"
  },
  {
    "id": "arXiv:2211.16386",
    "title": "Compressing Volumetric Radiance Fields to 1 MB",
    "abstract": "Approximating radiance fields with volumetric grids is one of promising\ndirections for improving NeRF, represented by methods like Plenoxels and DVGO,\nwhich achieve super-fast training convergence and real-time rendering. However,\nthese methods typically require a tremendous storage overhead, costing up to\nhundreds of megabytes of disk space and runtime memory for a single scene. We\naddress this issue in this paper by introducing a simple yet effective\nframework, called vector quantized radiance fields (VQRF), for compressing\nthese volume-grid-based radiance fields. We first present a robust and adaptive\nmetric for estimating redundancy in grid models and performing voxel pruning by\nbetter exploring intermediate outputs of volumetric rendering. A trainable\nvector quantization is further proposed to improve the compactness of grid\nmodels. In combination with an efficient joint tuning strategy and\npost-processing, our method can achieve a compression ratio of 100$\\times$ by\nreducing the overall model size to 1 MB with negligible loss on visual quality.\nExtensive experiments demonstrate that the proposed framework is capable of\nachieving unrivaled performance and well generalization across multiple methods\nwith distinct volumetric structures, facilitating the wide use of volumetric\nradiance fields methods in real-world applications. Code Available at\n\\url{https://github.com/AlgoHunt/VQRF}",
    "descriptor": "",
    "authors": [
      "Lingzhi Li",
      "Zhen Shen",
      "Zhongshu Wang",
      "Li Shen",
      "Liefeng Bo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16386"
  },
  {
    "id": "arXiv:2211.16398",
    "title": "Self-Supervised Mental Disorder Classifiers via Time Reversal",
    "abstract": "Data scarcity is a notable problem, especially in the medical domain, due to\npatient data laws. Therefore, efficient Pre-Training techniques could help in\ncombating this problem. In this paper, we demonstrate that a model trained on\nthe time direction of functional neuro-imaging data could help in any\ndownstream task, for example, classifying diseases from healthy controls in\nfMRI data. We train a Deep Neural Network on Independent components derived\nfrom fMRI data using the Independent component analysis (ICA) technique. It\nlearns time direction in the ICA-based data. This pre-trained model is further\ntrained to classify brain disorders in different datasets. Through various\nexperiments, we have shown that learning time direction helps a model learn\nsome causal relation in fMRI data that helps in faster convergence, and\nconsequently, the model generalizes well in downstream classification tasks\neven with fewer data records.",
    "descriptor": "\nComments: 10 pages, 7 figures\n",
    "authors": [
      "Zafar Iqbal",
      "Usman Mehmood",
      "Zening Fu",
      "Sergey Plis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.16398"
  },
  {
    "id": "arXiv:2211.16401",
    "title": "Sample Complexity of the Robust Linear Observers under Coprime Factors  Uncertainty",
    "abstract": "This paper addresses the end-to-end sample complexity bound for learning the\nH2 linear observer-based robust Linear Quadratic (LQ) regulators with unknown\ndynamics for stable Linear Time Invariant (LTI) systems, when given a fixed\nstate feedback gain. The robust synthesis procedure is performed by considering\nbounded additive model uncertainty on the coprime factors of the plant. The\nclosed-loop identification scheme follows Zhang et al. (2021), where the\nnominal model of the true plant is identified by constructing a Hankel-like\nmatrix from a single time-series of noisy, finite length input-output data by\nusing the ordinary least squares algorithm from Sarkar et al. (2020). Next, an\nH-infinity bound on the estimated model error is provided, and the robust\nobserver is designed via convex optimization while considering bounded additive\nuncertainty on the coprime factors of the model. Our results are consistent\nwith previous methods on learning the linear observer.",
    "descriptor": "\nComments: 18 pages. arXiv admin note: substantial text overlap with arXiv:2109.14164\n",
    "authors": [
      "Yifei Zhang",
      "Sourav Kumar Ukil",
      "Serban Sabau"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.16401"
  },
  {
    "id": "arXiv:2211.16402",
    "title": "Query complexity of Boolean functions on slices",
    "abstract": "We study the deterministic query complexity of Boolean functions on slices of\nthe hypercube. The $k^{th}$ slice $\\binom{[n]}{k}$ of the hypercube $\\{0,1\\}^n$\nis the set of all $n$-bit strings with Hamming weight $k$. We show that there\nexists a function on the balanced slice $\\binom{[n]}{n/2}$ requiring $n -\nO(\\log \\log n)$ queries. We give an explicit function on the balanced slice\nrequiring $n - O(\\log n)$ queries based on independent sets in Johnson graphs.\nOn the weight-2 slice, we show that hard functions are closely related to\nRamsey graphs. Further we describe a simple way of transforming functions on\nthe hypercube to functions on the balanced slice while preserving several\ncomplexity measures.",
    "descriptor": "",
    "authors": [
      "Farzan Byramji"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.16402"
  },
  {
    "id": "arXiv:2211.16406",
    "title": "Design Space Exploration and Explanation via Conditional Variational  Autoencoders in Meta-model-based Conceptual Design of Pedestrian Bridges",
    "abstract": "For conceptual design, engineers rely on conventional iterative (often\nmanual) techniques. Emerging parametric models facilitate design space\nexploration based on quantifiable performance metrics, yet remain\ntime-consuming and computationally expensive. Pure optimisation methods,\nhowever, ignore qualitative aspects (e.g. aesthetics or construction methods).\nThis paper provides a performance-driven design exploration framework to\naugment the human designer through a Conditional Variational Autoencoder\n(CVAE), which serves as forward performance predictor for given design features\nas well as an inverse design feature predictor conditioned on a set of\nperformance requests. The CVAE is trained on 18'000 synthetically generated\ninstances of a pedestrian bridge in Switzerland. Sensitivity analysis is\nemployed for explainability and informing designers about (i) relations of the\nmodel between features and/or performances and (ii) structural improvements\nunder user-defined objectives. A case study proved our framework's potential to\nserve as a future co-pilot for conceptual design studies of pedestrian bridges\nand beyond.",
    "descriptor": "",
    "authors": [
      "Vera M. Balmer",
      "Sophia V. Kuhn",
      "Rafael Bischof",
      "Luis Salamanca",
      "Walter Kaufmann",
      "Fernando Perez-Cruz",
      "Michael A. Kraus"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16406"
  },
  {
    "id": "arXiv:2211.16412",
    "title": "Procedural Image Programs for Representation Learning",
    "abstract": "Learning image representations using synthetic data allows training neural\nnetworks without some of the concerns associated with real images, such as\nprivacy and bias. Existing work focuses on a handful of curated generative\nprocesses which require expert knowledge to design, making it hard to scale up.\nTo overcome this, we propose training with a large dataset of twenty-one\nthousand programs, each one generating a diverse set of synthetic images. These\nprograms are short code snippets, which are easy to modify and fast to execute\nusing OpenGL. The proposed dataset can be used for both supervised and\nunsupervised representation learning, and reduces the gap between pre-training\nwith real and procedurally generated images by 38%.",
    "descriptor": "\nComments: 29 pages, Accepted in the Conference on Neural Information Processing Systems 2022 (NeurIPS 2022)\n",
    "authors": [
      "Manel Baradad",
      "Chun-Fu Chen",
      "Jonas Wulff",
      "Tongzhou Wang",
      "Rogerio Feris",
      "Antonio Torralba",
      "Phillip Isola"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16412"
  },
  {
    "id": "arXiv:2211.16414",
    "title": "Parameterisation of Reasoning on Temporal Markov Logic Networks",
    "abstract": "We aim at improving reasoning on inconsistent and uncertain data. We focus on\nknowledge-graph data, extended with time intervals to specify their validity,\nas regularly found in historical sciences. We propose principles on semantics\nfor efficient Maximum A-Posteriori inference on the new Temporal Markov Logic\nNetworks (TMLN) which extend the Markov Logic Networks (MLN) by uncertain\ntemporal facts and rules. We examine total and partial temporal (in)consistency\nrelations between sets of temporal formulae. Then we propose a new Temporal\nParametric Semantics, which may combine several sub-functions, allowing to use\ndifferent assessment strategies. Finally, we expose the constraints that\nsemantics must respect to satisfy our principles.",
    "descriptor": "\nComments: 12 pages + refs (2 pages) + supplementary (proofs, 7 pages). Under review\n",
    "authors": [
      "Victor David",
      "Rapha\u00ebl Fournier-S'niehotta",
      "Nicolas Travers"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.16414"
  },
  {
    "id": "arXiv:2211.16415",
    "title": "Distributed Computation of Exact Average Degree and Network Size in  Finite Number of Steps under Quantized Communication",
    "abstract": "We consider the problems of computing the average degree and the size of a\ngiven network in a distributed fashion under quantized communication. We\npresent two distributed algorithms which rely on quantized operation (i.e.,\nnodes process and transmit quantized messages), and are able to calculate the\nexact solutions in a finite number of steps. Furthermore, during the operation\nof our algorithms, each node is able to determine in a distributed manner\nwhether convergence has been achieved and thus terminate its operation. To the\nbest of the authors' knowledge these algorithms are the first to find the exact\nsolutions under quantized communication (i.e., there is no error in the final\ncalculation). Additionally, note that our network size calculation algorithm is\nthe first in the literature which calculates the exact size of a network in a\nfinite number of steps without introducing a final error. This error in other\nalgorithms can be either due to quantization or asymptotic convergence. In our\ncase, no error is introduced since the desired result is calculated in the form\nof a fraction involving a quantized numerator and a quantized denominator.\nFinally, we demonstrate the operation of our algorithms and their potential\nadvantages.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2104.03126\n",
    "authors": [
      "Apostolos I. Rikos",
      "Themistoklis Charalambous",
      "Christoforos N. Hadjicostis",
      "Karl H. Johansson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.16415"
  },
  {
    "id": "arXiv:2211.16421",
    "title": "RGB no more: Minimally-decoded JPEG Vision Transformers",
    "abstract": "Most neural networks for computer vision are designed to infer using RGB\nimages. However, these RGB images are commonly encoded in JPEG before saving to\ndisk; decoding them imposes an unavoidable overhead for RGB networks. Instead,\nour work focuses on training Vision Transformers (ViT) directly from the\nencoded features of JPEG. This way, we can avoid most of the decoding overhead,\naccelerating data load. Existing works have studied this aspect but they focus\non CNNs. Due to how these encoded features are structured, CNNs require heavy\nmodification to their architecture to accept such data. Here, we show that this\nis not the case for ViTs. In addition, we tackle data augmentation directly on\nthese encoded features, which to our knowledge, has not been explored in-depth\nfor training in this setting. With these two improvements -- ViT and data\naugmentation -- we show that our ViT-Ti model achieves up to 39.2% faster\ntraining and 17.9% faster inference with no accuracy loss compared to the RGB\ncounterpart.",
    "descriptor": "\nComments: 17 pages, 6 figures, 3 tables\n",
    "authors": [
      "Jeongsoo Park",
      "Justin Johnson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.16421"
  },
  {
    "id": "arXiv:2211.16422",
    "title": "Massively Parallel Open Modification Spectral Library Searching with  Hyperdimensional Computing",
    "abstract": "Mass spectrometry, commonly used for protein identification, generates a\nmassive number of spectra that need to be matched against a large database. In\nreality, most of them remain unidentified or mismatched due to unexpected\npost-translational modifications. Open modification search (OMS) has been\nproposed as a strategy to improve the identification rate by considering every\npossible change in spectra, but it expands the search space exponentially. In\nthis work, we propose HyperOMS, which redesigns OMS based on hyperdimensional\ncomputing to cope with such challenges. Unlike existing algorithms that\nrepresent spectral data with floating point numbers, HyperOMS encodes them with\nhigh dimensional binary vectors and performs the efficient OMS in\nhigh-dimensional space. With the massive parallelism and simple boolean\noperations, HyperOMS can be efficiently handled on parallel computing\nplatforms. Experimental results show that HyperOMS on GPU is up to $17\\times$\nfaster and $6.4\\times$ more energy efficient than the state-of-the-art\nGPU-based OMS tool while providing comparable search quality to competing\nsearch tools.",
    "descriptor": "\nComments: 6 pages, 7 figures\n",
    "authors": [
      "Jaeyoung Kang",
      "Weihong Xu",
      "Wout Bittremieux",
      "Tajana Rosing"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.16422"
  },
  {
    "id": "arXiv:2211.16429",
    "title": "Exploring the Long-Term Generalization of Counting Behavior in RNNs",
    "abstract": "In this study, we investigate the generalization of LSTM, ReLU and GRU models\non counting tasks over long sequences. Previous theoretical work has\nestablished that RNNs with ReLU activation and LSTMs have the capacity for\ncounting with suitable configuration, while GRUs have limitations that prevent\ncorrect counting over longer sequences. Despite this and some positive\nempirical results for LSTMs on Dyck-1 languages, our experimental results show\nthat LSTMs fail to learn correct counting behavior for sequences that are\nsignificantly longer than in the training data. ReLUs show much larger variance\nin behavior and in most cases worse generalization. The long sequence\ngeneralization is empirically related to validation loss, but reliable long\nsequence generalization seems not practically achievable through\nbackpropagation with current techniques. We demonstrate different failure modes\nfor LSTMs, GRUs and ReLUs. In particular, we observe that the saturation of\nactivation functions in LSTMs and the correct weight setting for ReLUs to\ngeneralize counting behavior are not achieved in standard training regimens. In\nsummary, learning generalizable counting behavior is still an open problem and\nwe discuss potential approaches for further research.",
    "descriptor": "\nComments: Published in I Can't Believe It's Not Better: Understanding Deep Learning Through Empirical Falsification Workshop at NeurIPS 2022\n",
    "authors": [
      "Nadine El-Naggar",
      "Pranava Madhyastha",
      "Tillman Weyde"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16429"
  },
  {
    "id": "arXiv:2211.16431",
    "title": "NeuralLift-360: Lifting An In-the-wild 2D Photo to A 3D Object with  360\u00b0 Views",
    "abstract": "Virtual reality and augmented reality (XR) bring increasing demand for 3D\ncontent. However, creating high-quality 3D content requires tedious work that a\nhuman expert must do. In this work, we study the challenging task of lifting a\nsingle image to a 3D object and, for the first time, demonstrate the ability to\ngenerate a plausible 3D object with 360{\\deg} views that correspond well with\nthe given reference image. By conditioning on the reference image, our model\ncan fulfill the everlasting curiosity for synthesizing novel views of objects\nfrom images. Our technique sheds light on a promising direction of easing the\nworkflows for 3D artists and XR designers. We propose a novel framework, dubbed\nNeuralLift-360, that utilizes a depth-aware neural radiance representation\n(NeRF) and learns to craft the scene guided by denoising diffusion models. By\nintroducing a ranking loss, our NeuralLift-360 can be guided with rough depth\nestimation in the wild. We also adopt a CLIP-guided sampling strategy for the\ndiffusion prior to provide coherent guidance. Extensive experiments demonstrate\nthat our NeuralLift-360 significantly outperforms existing state-of-the-art\nbaselines. Project page: https://vita-group.github.io/NeuralLift-360/",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Dejia Xu",
      "Yifan Jiang",
      "Peihao Wang",
      "Zhiwen Fan",
      "Yi Wang",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16431"
  },
  {
    "id": "arXiv:2211.16433",
    "title": "On Robust Observer Design for System Motion on SE(3) Using Onboard  Visual Sensors",
    "abstract": "Onboard visual sensing has been widely used in the unmanned ground vehicle\n(UGV) and/or unmanned aerial vehicle (UAV), which can be modeled as dynamic\nsystems on SE(3). The onboard sensing outputs of the dynamic system can usually\nbe applied to derive the relative position between the feature marks and the\nsystem, but bearing with explicit geometrical constraint. Such a visual\ngeometrical constraint makes the design of the visual observer on SE(3) very\nchallenging, as it will cause a time-varying or switching visible set due to\nthe varying number of feature marks in this set along different trajectories.\nMoreover, the possibility of having mis-identified feature marks and modeling\nuncertainties might result in a divergent estimation error. This paper proposes\na new robust observer design method that can accommodate these uncertainties\nfrom onboard visual sensing. The key design idea for this observer is to\nestimate the visible set and identify the mis-identified features from the\nmeasurements. Based on the identified uncertainties, a switching strategy is\nproposed to ensure bounded estimation error for any given trajectory over a\nfixed time interval. Simulation results are provided to demonstrate the\neffectiveness of the proposed robust observer.",
    "descriptor": "",
    "authors": [
      "Tong Zhang",
      "Ying Tan",
      "Xiang Chen",
      "Zike Lei"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.16433"
  },
  {
    "id": "arXiv:2211.16444",
    "title": "Holding AI to Account: Challenges for the Delivery of Trustworthy AI in  Healthcare",
    "abstract": "The need for AI systems to provide explanations for their behaviour is now\nwidely recognised as key to their adoption. In this paper, we examine the\nproblem of trustworthy AI and explore what delivering this means in practice,\nwith a focus on healthcare applications. Work in this area typically treats\ntrustworthy AI as a problem of Human-Computer Interaction involving the\nindividual user and an AI system. However, we argue here that this overlooks\nthe important part played by organisational accountability in how people reason\nabout and trust AI in socio-technical settings. To illustrate the importance of\norganisational accountability, we present findings from ethnographic studies of\nbreast cancer screening and cancer treatment planning in multidisciplinary team\nmeetings to show how participants made themselves accountable both to each\nother and to the organisations of which they are members. We use these findings\nto enrich existing understandings of the requirements for trustworthy AI and to\noutline some candidate solutions to the problems of making AI accountable both\nto individual users and organisationally. We conclude by outlining the\nimplications of this for future work on the development of trustworthy AI,\nincluding ways in which our proposed solutions may be re-used in different\napplication settings.",
    "descriptor": "\nComments: 35 pages, 5 figures\n",
    "authors": [
      "Rob Procter",
      "Peter Tolmie",
      "Mark Rouncefield"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.16444"
  },
  {
    "id": "arXiv:2211.16452",
    "title": "Interactive-Rate Supervisory Control for Arbitrarily-Routed Multi-Tendon  Robots via Motion Planning",
    "abstract": "Tendon-driven robots, where one or more tendons under tension bend and\nmanipulate a flexible backbone, can improve minimally invasive surgeries\ninvolving difficult-to-reach regions in the human body. Planning motions safely\nwithin constrained anatomical environments requires accuracy and efficiency in\nshape estimation and collision checking. Tendon robots that employ\narbitrarily-routed tendons can achieve complex and interesting shapes, enabling\nthem to travel to difficult-to-reach anatomical regions. Arbitrarily-routed\ntendon-driven robots have unintuitive nonlinear kinematics. Therefore, we\nenvision clinicians leveraging an assistive interactive-rate motion planner to\nautomatically generate collision-free trajectories to clinician-specified\ndestinations during minimally-invasive surgical procedures. Standard\nmotion-planning techniques cannot achieve interactive-rate motion planning with\nthe current expensive tendon robot kinematic models. In this work, we present a\n3-phase motion-planning system for arbitrarily-routed tendon-driven robots with\na Precompute phase, a Load phase, and a Supervisory Control phase. Our system\nachieves an interactive rate by developing a fast kinematic model (over 1,000\ntimes faster than current models), a fast voxel collision method (27.6 times\nfaster than standard methods), and leveraging a precomputed roadmap of the\nentire robot workspace with pre-voxelized vertices and edges. In simulated\nexperiments, we show that our motion-planning method achieves high tip-position\naccuracy and generates plans at 14.8 Hz on average in a segmented collapsed\nlung pleural space anatomical environment. Our results show that our method is\n17,700 times faster than popular off-the-shelf motion planning algorithms with\nstandard FK and collision detection approaches. Our open-source code is\navailable online.",
    "descriptor": "\nComments: 21 pages, 11 figures, preprint of the accepted version to IEEE Access published in July 2022; copyright retained by the authors\n",
    "authors": [
      "Michael Bentley",
      "Caleb Rucker",
      "Alan Kuntz"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.16452"
  },
  {
    "id": "arXiv:2211.16459",
    "title": "A Revenue Function for Comparison-Based Hierarchical Clustering",
    "abstract": "Comparison-based learning addresses the problem of learning when, instead of\nexplicit features or pairwise similarities, one only has access to comparisons\nof the form: \\emph{Object $A$ is more similar to $B$ than to $C$.} Recently, it\nhas been shown that, in Hierarchical Clustering, single and complete linkage\ncan be directly implemented using only such comparisons while several\nalgorithms have been proposed to emulate the behaviour of average linkage.\nHence, finding hierarchies (or dendrograms) using only comparisons is a well\nunderstood problem. However, evaluating their meaningfulness when no\nground-truth nor explicit similarities are available remains an open question.\nIn this paper, we bridge this gap by proposing a new revenue function that\nallows one to measure the goodness of dendrograms using only comparisons. We\nshow that this function is closely related to Dasgupta's cost for hierarchical\nclustering that uses pairwise similarities. On the theoretical side, we use the\nproposed revenue function to resolve the open problem of whether one can\napproximately recover a latent hierarchy using few triplet comparisons. On the\npractical side, we present principled algorithms for comparison-based\nhierarchical clustering based on the maximisation of the revenue and we\nempirically compare them with existing methods.",
    "descriptor": "\nComments: 25 pages, 5 figures, 7 tables\n",
    "authors": [
      "Aishik Mandal",
      "Micha\u00ebl Perrot",
      "Debarghya Ghoshdastidar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.16459"
  },
  {
    "id": "arXiv:2211.16462",
    "title": "Will My Robot Achieve My Goals? Predicting the Probability that an MDP  Policy Reaches a User-Specified Behavior Target",
    "abstract": "As an autonomous system performs a task, it should maintain a calibrated\nestimate of the probability that it will achieve the user's goal. If that\nprobability falls below some desired level, it should alert the user so that\nappropriate interventions can be made. This paper considers settings where the\nuser's goal is specified as a target interval for a real-valued performance\nsummary, such as the cumulative reward, measured at a fixed horizon $H$. At\neach time $t \\in \\{0, \\ldots, H-1\\}$, our method produces a calibrated estimate\nof the probability that the final cumulative reward will fall within a\nuser-specified target interval $[y^-,y^+].$ Using this estimate, the autonomous\nsystem can raise an alarm if the probability drops below a specified threshold.\nWe compute the probability estimates by inverting conformal prediction. Our\nstarting point is the Conformalized Quantile Regression (CQR) method of Romano\net al., which applies split-conformal prediction to the results of quantile\nregression. CQR is not invertible, but by using the conditional cumulative\ndistribution function (CDF) as the non-conformity measure, we show how to\nobtain an invertible modification that we call \\textbf{P}robability-space\n\\textbf{C}onformalized \\textbf{Q}uantile \\textbf{R}egression (PCQR). Like CQR,\nPCQR produces well-calibrated conditional prediction intervals with\nfinite-sample marginal guarantees. By inverting PCQR, we obtain marginal\nguarantees for the probability that the cumulative reward of an autonomous\nsystem will fall within an arbitrary user-specified target intervals.\nExperiments on two domains confirm that these probabilities are\nwell-calibrated.",
    "descriptor": "\nComments: 12 pages, 4 figures. Appears in Proceedings of AAAI FSS-22 Symposium \"Lessons Learned for Autonomous Assessment of Machine Abilities (LLAAMA)\"\n",
    "authors": [
      "Alexander Guyer",
      "Thomas G. Dietterich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.16462"
  },
  {
    "id": "arXiv:2211.16465",
    "title": "\"I Want to Figure Things Out\": Supporting Exploration in Navigation for  People with Visual Impairments",
    "abstract": "Navigation assistance systems (NASs) aim to help visually impaired people\n(VIPs) navigate unfamiliar environments. Most of today's NASs support VIPs via\nturn-by-turn navigation, but a growing body of work highlights the importance\nof exploration as well. It is unclear, however, how NASs should be designed to\nhelp VIPs explore unfamiliar environments. In this paper, we perform a\nqualitative study to understand VIPs' information needs and challenges with\nrespect to exploring unfamiliar environments, with the aim of informing the\ndesign of NASs that support exploration. Our findings reveal the types of\nspatial information that VIPs need as well as factors that affect VIPs'\ninformation preferences. We also discover specific challenges that VIPs face\nthat future NASs can address such as orientation and mobility education and\ncollaborating effectively with others. We present design implications for NASs\nthat support exploration, and we identify specific research opportunities and\ndiscuss open socio-technical challenges for making such NASs possible. We\nconclude by reflecting on our study procedure to inform future approaches in\nresearch on ethical considerations that may be adopted while interacting with\nthe broader VIP community.",
    "descriptor": "\nComments: To appear in the Proceedings of the ACM on Human-Computer Interaction, CSCW1, April 2023 issue. To be presented at CSCW 2023\n",
    "authors": [
      "Gaurav Jain",
      "Yuanyang Teng",
      "Dong Heon Cho",
      "Yunhao Xing",
      "Maryam Aziz",
      "Brian A. Smith"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.16465"
  },
  {
    "id": "arXiv:2211.16466",
    "title": "Birds of a Feather Trust Together: Knowing When to Trust a Classifier  via Adaptive Neighborhood Aggregation",
    "abstract": "How do we know when the predictions made by a classifier can be trusted? This\nis a fundamental problem that also has immense practical applicability,\nespecially in safety-critical areas such as medicine and autonomous driving.\nThe de facto approach of using the classifier's softmax outputs as a proxy for\ntrustworthiness suffers from the over-confidence issue; while the most recent\nworks incur problems such as additional retraining cost and accuracy versus\ntrustworthiness trade-off. In this work, we argue that the trustworthiness of a\nclassifier's prediction for a sample is highly associated with two factors: the\nsample's neighborhood information and the classifier's output. To combine the\nbest of both worlds, we design a model-agnostic post-hoc approach NeighborAgg\nto leverage the two essential information via an adaptive neighborhood\naggregation. Theoretically, we show that NeighborAgg is a generalized version\nof a one-hop graph convolutional network, inheriting the powerful modeling\nability to capture the varying similarity between samples within each class. We\nalso extend our approach to the closely related task of mislabel detection and\nprovide a theoretical coverage guarantee to bound the false negative.\nEmpirically, extensive experiments on image and tabular benchmarks verify our\ntheory and suggest that NeighborAgg outperforms other methods, achieving\nstate-of-the-art trustworthiness performance.",
    "descriptor": "\nComments: Published in Transactions on Machine Learning Research (TMLR) 2022\n",
    "authors": [
      "Miao Xiong",
      "Shen Li",
      "Wenjie Feng",
      "Ailin Deng",
      "Jihai Zhang",
      "Bryan Hooi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16466"
  },
  {
    "id": "arXiv:2211.16468",
    "title": "Finding Front-Door Adjustment Sets in Linear Time",
    "abstract": "Front-door adjustment is a classic technique to estimate causal effects from\na specified directed acyclic graph (DAG) and observed data. The advantage of\nthis approach is that it uses observed mediators to identify causal effects,\nwhich is possible even in the presence of unobserved confounding. While the\nstatistical properties of the front-door estimation are quite well understood,\nits algorithmic aspects remained unexplored for a long time. Recently, Jeong,\nTian, and Barenboim [NeurIPS 2022] have presented the first polynomial-time\nalgorithm for finding sets satisfying the front-door criterion in a given DAG,\nwith an $O(n^3(n+m))$ run time, where $n$ denotes the number of variables and\n$m$ the number of edges of the graph. In our work, we give the first\nlinear-time, i.e. $O(n+m)$, algorithm for this task, which thus reaches the\nasymptotically optimal time complexity, as the size of the input is\n$\\Omega(n+m)$. We also provide an algorithm to enumerate all front-door\nadjustment sets in a given DAG with delay $O(n(n + m))$. These results improve\nthe algorithms by Jeong et al. [2022] for the two tasks by a factor of $n^3$,\nrespectively.",
    "descriptor": "",
    "authors": [
      "Marcel Wien\u00f6bst",
      "Benito van der Zander",
      "Maciej Li\u015bkiewicz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.16468"
  },
  {
    "id": "arXiv:2211.16479",
    "title": "Approaches to the Parallelization of Merge Sort in Python",
    "abstract": "The theory of divide-and-conquer parallelization has been well-studied in the\npast, providing a solid basis upon which to explore different approaches to the\nparallelization of merge sort in Python. Python's simplicity and extensive\nselection of libraries make it the most popular scientific programming\nlanguage, so it is a fitting language in which to implement and analyze these\nalgorithms.\nIn this paper, we use Python packages multiprocessing and mpi4py to implement\nseveral different parallel merge sort algorithms. Experiments are conducted on\nan academic supercomputer, upon which benchmarks are performed using Cloudmesh.\nWe find that hybrid multiprocessing merge sort outperforms several other\nalgorithms, achieving a 1.5x speedup compared to the built-in Python sorted()\nand a 34x speedup compared to sequential merge sort. Our results provide\ninsight into different approaches to implementing parallel merge sort in Python\nand contribute to the understanding of general divide-and-conquer\nparallelization in Python on both shared and distributed memory systems.",
    "descriptor": "\nComments: 13 pages, 12 figures\n",
    "authors": [
      "Alexandra Yang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.16479"
  },
  {
    "id": "arXiv:2211.16480",
    "title": "Retweets Distort Exposure to Polarized Information",
    "abstract": "The growing prominence of social media in public discourse has led to greater\nscrutiny of the quality of information spreading online and the role that\npolarization plays in this process. However, studies of information spread on\nsocial media platforms like Twitter have been hampered by the difficulty of\ncollecting data about the social graph, specifically follow links that shape\nwhat users see in their timelines. As a proxy of the follower graph,\nresearchers use retweets to construct the diffusion graph, although it is not\nclear how these proxies affect studies of online information ecosystems. Using\na dataset containing a sample of the Twitter follower graph and the tweets\nposted by users within it, we reconstruct the retweet graph and quantify its\nimpact on the measures of exposure. While we find that echo chambers exist in\nboth networks, they are more pronounced in the retweet neighborhood. We compare\nthe polarization of information users see via their follower and retweet graphs\nto show that retweeted accounts systematically share more politically extreme\ncontent and misinformation. This bias cannot be explained by the activity or\npolarization within users' own social neighborhoods but by the increased\nattention they pay to more polarized sources. Our results suggest that studies\nrelying on the follower graphs underestimate the polarization of information\nusers pay attention to online.",
    "descriptor": "\nComments: 10 pages, 8 figures\n",
    "authors": [
      "Ashwin Rao",
      "Fred Morstatter",
      "Kristina Lerman"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.16480"
  },
  {
    "id": "arXiv:2211.16482",
    "title": "Chaining Simultaneous Thoughts for Numerical Reasoning",
    "abstract": "Given that rich information is hidden behind ubiquitous numbers in text,\nnumerical reasoning over text should be an essential skill of AI systems. To\nderive precise equations to solve numerical reasoning problems, previous work\nfocused on modeling the structures of equations, and has proposed various\nstructured decoders. Though structure modeling proves to be effective, these\nstructured decoders construct a single equation in a pre-defined autoregressive\norder, potentially placing an unnecessary restriction on how a model should\ngrasp the reasoning process. Intuitively, humans may have numerous pieces of\nthoughts popping up in no pre-defined order; thoughts are not limited to the\nproblem at hand, and can even be concerned with other related problems. By\ncomparing diverse thoughts and chaining relevant pieces, humans are less prone\nto errors. In this paper, we take this inspiration and propose CANTOR, a\nnumerical reasoner that models reasoning steps using a directed acyclic graph\nwhere we produce diverse reasoning steps simultaneously without pre-defined\ndecoding dependencies, and compare and chain relevant ones to reach a solution.\nExtensive experiments demonstrated the effectiveness of CANTOR under both\nfully-supervised and weakly-supervised settings.",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Zhihong Shao",
      "Fei Huang",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.16482"
  },
  {
    "id": "arXiv:2211.16484",
    "title": "A Finite Axiomatisation of Finite-State Automata Using String Diagrams",
    "abstract": "We develop a fully diagrammatic approach to finite-state automata, based on\nreinterpreting their usual state-transition graphical representation as a\ntwo-dimensional syntax of string diagrams. In this setting, we are able to\nprovide a complete equational theory for language equivalence, with two notable\nfeatures. First, the proposed axiomatisation is finite. Second, the Kleene star\nis a derived concept, as it can be decomposed into more primitive algebraic\nblocks.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2009.14576\n",
    "authors": [
      "Robin Piedeleu",
      "Fabio Zanasi"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2211.16484"
  },
  {
    "id": "arXiv:2211.16487",
    "title": "DiffPose: Multi-hypothesis Human Pose Estimation using Diffusion models",
    "abstract": "Traditionally, monocular 3D human pose estimation employs a machine learning\nmodel to predict the most likely 3D pose for a given input image. However, a\nsingle image can be highly ambiguous and induces multiple plausible solutions\nfor the 2D-3D lifting step which results in overly confident 3D pose\npredictors. To this end, we propose \\emph{DiffPose}, a conditional diffusion\nmodel, that predicts multiple hypotheses for a given input image. In comparison\nto similar approaches, our diffusion model is straightforward and avoids\nintensive hyperparameter tuning, complex network structures, mode collapse, and\nunstable training. Moreover, we tackle a problem of the common two-step\napproach that first estimates a distribution of 2D joint locations via\njoint-wise heatmaps and consecutively approximates them based on first- or\nsecond-moment statistics. Since such a simplification of the heatmaps removes\nvalid information about possibly correct, though labeled unlikely, joint\nlocations, we propose to represent the heatmaps as a set of 2D joint candidate\nsamples. To extract information about the original distribution from these\nsamples we introduce our \\emph{embedding transformer} that conditions the\ndiffusion model. Experimentally, we show that DiffPose slightly improves upon\nthe state of the art for multi-hypothesis pose estimation for simple poses and\noutperforms it by a large margin for highly ambiguous poses.",
    "descriptor": "",
    "authors": [
      "Karl Holmquist",
      "Bastian Wandt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16487"
  },
  {
    "id": "arXiv:2211.16488",
    "title": "Taming a Generative Model",
    "abstract": "Generative models are becoming ever more powerful, being able to synthesize\nhighly realistic images. We propose an algorithm for taming these models -\nchanging the probability that the model will produce a specific image or image\ncategory. We consider generative models that are powered by normalizing flows,\nwhich allows us to reason about the exact generation probability likelihood for\na given image. Our method is general purpose, and we exemplify it using models\nthat generate human faces, a subdomain with many interesting privacy and bias\nconsiderations. Our method can be used in the context of privacy, e.g.,\nremoving a specific person from the output of a model, and also in the context\nof de-biasing by forcing a model to output specific image categories according\nto a given target distribution. Our method uses a fast fine-tuning process\nwithout retraining the model from scratch, achieving the goal in less than 1%\nof the time taken to initially train the generative model. We evaluate\nqualitatively and quantitatively, to examine the success of the taming process\nand output quality.",
    "descriptor": "",
    "authors": [
      "Shimon Malnick",
      "Shai Avidan",
      "Ohad Fried"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16488"
  },
  {
    "id": "arXiv:2211.16490",
    "title": "Coder Reviewer Reranking for Code Generation",
    "abstract": "Sampling diverse programs from a code language model and reranking with model\nlikelihood is a popular method for code generation but it is prone to\npreferring degenerate solutions. Inspired by collaborative programming, we\npropose Coder-Reviewer reranking. We augment Coder language models from past\nwork, which generate programs given language instructions, with Reviewer\nmodels, which evaluate the likelihood of the instruction given the generated\nprograms. We perform an extensive study across six datasets with eight models\nfrom three model families. Experimental results show that Coder-Reviewer\nreranking leads to consistent and significant improvement (up to 17% absolute\naccuracy gain) over reranking with the Coder model only. When combined with\nexecutability filtering, Coder-Reviewer reranking can often outperform the\nminimum Bayes risk method. Coder-Reviewer reranking is easy to implement by\nprompting, can generalize to different programming languages, and works well\nwith off-the-shelf hyperparameters.",
    "descriptor": "",
    "authors": [
      "Tianyi Zhang",
      "Tao Yu",
      "Tatsunori B. Hashimoto",
      "Mike Lewis",
      "Wen-tau Yih",
      "Daniel Fried",
      "Sida I. Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.16490"
  },
  {
    "id": "arXiv:2211.16492",
    "title": "Abstract Visual Reasoning with Tangram Shapes",
    "abstract": "We introduce KiloGram, a resource for studying abstract visual reasoning in\nhumans and machines. Drawing on the history of tangram puzzles as stimuli in\ncognitive science, we build a richly annotated dataset that, with >1k distinct\nstimuli, is orders of magnitude larger and more diverse than prior resources.\nIt is both visually and linguistically richer, moving beyond whole shape\ndescriptions to include segmentation maps and part labels. We use this resource\nto evaluate the abstract visual reasoning capacities of recent multi-modal\nmodels. We observe that pre-trained weights demonstrate limited abstract\nreasoning, which dramatically improves with fine-tuning. We also observe that\nexplicitly describing parts aids abstract reasoning for both humans and models,\nespecially when jointly encoding the linguistic and visual inputs. KiloGram is\navailable at https://lil.nlp.cornell.edu/kilogram .",
    "descriptor": "\nComments: EMNLP 2022 long paper\n",
    "authors": [
      "Anya Ji",
      "Noriyuki Kojima",
      "Noah Rush",
      "Alane Suhr",
      "Wai Keen Vong",
      "Robert D. Hawkins",
      "Yoav Artzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16492"
  },
  {
    "id": "arXiv:2211.16494",
    "title": "On the Ability of Graph Neural Networks to Model Interactions Between  Vertices",
    "abstract": "Graph neural networks (GNNs) are widely used for modeling complex\ninteractions between entities represented as vertices of a graph. Despite\nrecent efforts to theoretically analyze the expressive power of GNNs, a formal\ncharacterization of their ability to model interactions is lacking. The current\npaper aims to address this gap. Formalizing strength of interactions through an\nestablished measure known as separation rank, we quantify the ability of\ncertain GNNs to model interaction between a given subset of vertices and its\ncomplement, i.e. between sides of a given partition of input vertices. Our\nresults reveal that the ability to model interaction is primarily determined by\nthe partition's walk index -- a graph-theoretical characteristic that we define\nby the number of walks originating from the boundary of the partition.\nExperiments with common GNN architectures corroborate this finding. As a\npractical application of our theory, we design an edge sparsification algorithm\nnamed Walk Index Sparsification (WIS), which preserves the ability of a GNN to\nmodel interactions when input edges are removed. WIS is simple, computationally\nefficient, and markedly outperforms alternative methods in terms of induced\nprediction accuracy. More broadly, it showcases the potential of improving GNNs\nby theoretically analyzing the interactions they can model.",
    "descriptor": "",
    "authors": [
      "Noam Razin",
      "Tom Verbin",
      "Nadav Cohen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.16494"
  },
  {
    "id": "arXiv:2211.16495",
    "title": "Graph Neural Networks: A Powerful and Versatile Tool for Advancing  Design, Reliability, and Security of ICs",
    "abstract": "Graph neural networks (GNNs) have pushed the state-of-the-art (SOTA) for\nperformance in learning and predicting on large-scale data present in social\nnetworks, biology, etc. Since integrated circuits (ICs) can naturally be\nrepresented as graphs, there has been a tremendous surge in employing GNNs for\nmachine learning (ML)-based methods for various aspects of IC design. Given\nthis trajectory, there is a timely need to review and discuss some powerful and\nversatile GNN approaches for advancing IC design.\nIn this paper, we propose a generic pipeline for tailoring GNN models toward\nsolving challenging problems for IC design. We outline promising options for\neach pipeline element, and we discuss selected and promising works, like\nleveraging GNNs to break SOTA logic obfuscation. Our comprehensive overview of\nGNNs frameworks covers (i) electronic design automation (EDA) and IC design in\ngeneral, (ii) design of reliable ICs, and (iii) design as well as analysis of\nsecure ICs. We provide our overview and related resources also in the GNN4IC\nhub at https://github.com/DfX-NYUAD/GNN4IC. Finally, we discuss interesting\nopen problems for future research.",
    "descriptor": "\nComments: to appear at ASPDAC'23\n",
    "authors": [
      "Lilas Alrahis",
      "Johann Knechtel",
      "Ozgur Sinanoglu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Hardware Architecture (cs.AR)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.16495"
  },
  {
    "id": "arXiv:2211.16496",
    "title": "TyDiP: A Dataset for Politeness Classification in Nine Typologically  Diverse Languages",
    "abstract": "We study politeness phenomena in nine typologically diverse languages.\nPoliteness is an important facet of communication and is sometimes argued to be\ncultural-specific, yet existing computational linguistic study is limited to\nEnglish. We create TyDiP, a dataset containing three-way politeness annotations\nfor 500 examples in each language, totaling 4.5K examples. We evaluate how well\nmultilingual models can identify politeness levels -- they show a fairly robust\nzero-shot transfer ability, yet fall short of estimated human accuracy\nsignificantly. We further study mapping the English politeness strategy lexicon\ninto nine languages via automatic translation and lexicon induction, analyzing\nwhether each strategy's impact stays consistent across languages. Lastly, we\nempirically study the complicated relationship between formality and politeness\nthrough transfer experiments. We hope our dataset will support various research\nquestions and applications, from evaluating multilingual models to constructing\npolite multilingual agents.",
    "descriptor": "\nComments: EMNLP 2022 Findings. 16 pages, 8 figures, 11 tables. The data and code is publicly available at this https URL\n",
    "authors": [
      "Anirudh Srinivasan",
      "Eunsol Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.16496"
  },
  {
    "id": "arXiv:2211.16497",
    "title": "Development of End-to-End Low-Cost IoT System for Densely Deployed PM  Monitoring Network: An Indian Case Study",
    "abstract": "Particulate matter (PM) is considered the primary contributor to air\npollution and has severe implications for general health. PM concentration has\nhigh spatial variability and thus needs to be monitored locally. Traditional PM\nmonitoring setups are bulky, expensive and cannot be scaled for dense\ndeployments. This paper argues for a densely deployed network of IoT-enabled PM\nmonitoring devices using low-cost sensors. In this work, 49 devices were\ndeployed in a region of the Indian metropolitan city of Hyderabad out-of this,\n43 devices were developed as part of this work and 6 devices were taken off the\nshelf. The low-cost sensors were calibrated for seasonal variations using a\nprecise reference sensor. A thorough analysis of data collected for seven\nmonths has been presented to establish the need for dense deployment of PM\nmonitoring devices. Different analyses such as mean, variance, spatial\ninterpolation and correlation have been employed to generate interesting\ninsights about temporal and seasonal variations of PM. In addition,\nevent-driven spatio-temporal analysis is done for PM values to understand the\nimpact of the bursting of firecrackers on the evening of the Diwali festival. A\nweb-based dashboard is designed for real-time data visualization.",
    "descriptor": "\nComments: Submitted to IEEE IoT Journal for review\n",
    "authors": [
      "Ayu Parmar",
      "Spanddhana Sara",
      "Ayush Kumar Dwivedi",
      "C. Rajashekar Reddy",
      "Ishan Patwardhan",
      "Sai Dinesh Bijjam",
      "Sachin Chaudhari",
      "K. S. Rajan",
      "Kavita Vemuri"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.16497"
  },
  {
    "id": "arXiv:2211.16499",
    "title": "Finding Differences Between Transformers and ConvNets Using  Counterfactual Simulation Testing",
    "abstract": "Modern deep neural networks tend to be evaluated on static test sets. One\nshortcoming of this is the fact that these deep neural networks cannot be\neasily evaluated for robustness issues with respect to specific scene\nvariations. For example, it is hard to study the robustness of these networks\nto variations of object scale, object pose, scene lighting and 3D occlusions.\nThe main reason is that collecting real datasets with fine-grained naturalistic\nvariations of sufficient scale can be extremely time-consuming and expensive.\nIn this work, we present Counterfactual Simulation Testing, a counterfactual\nframework that allows us to study the robustness of neural networks with\nrespect to some of these naturalistic variations by building realistic\nsynthetic scenes that allow us to ask counterfactual questions to the models,\nultimately providing answers to questions such as \"Would your classification\nstill be correct if the object were viewed from the top?\" or \"Would your\nclassification still be correct if the object were partially occluded by\nanother object?\". Our method allows for a fair comparison of the robustness of\nrecently released, state-of-the-art Convolutional Neural Networks and Vision\nTransformers, with respect to these naturalistic variations. We find evidence\nthat ConvNext is more robust to pose and scale variations than Swin, that\nConvNext generalizes better to our simulated domain and that Swin handles\npartial occlusion better than ConvNext. We also find that robustness for all\nnetworks improves with network scale and with data scale and variety. We\nrelease the Naturalistic Variation Object Dataset (NVD), a large simulated\ndataset of 272k images of everyday objects with naturalistic variations such as\nobject pose, scale, viewpoint, lighting and occlusions. Project page:\nhttps://counterfactualsimulation.github.io",
    "descriptor": "\nComments: Published at the Conference on Neural Information Processing Systems (NeurIPS) 2022\n",
    "authors": [
      "Nataniel Ruiz",
      "Sarah Adel Bargal",
      "Cihang Xie",
      "Kate Saenko",
      "Stan Sclaroff"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16499"
  },
  {
    "id": "arXiv:2211.16504",
    "title": "Improving Commonsense in Vision-Language Models via Knowledge Graph  Riddles",
    "abstract": "This paper focuses on analyzing and improving the commonsense ability of\nrecent popular vision-language (VL) models. Despite the great success, we\nobserve that existing VL-models still lack commonsense knowledge/reasoning\nability (e.g., \"Lemons are sour\"), which is a vital component towards\nartificial general intelligence. Through our analysis, we find one important\nreason is that existing large-scale VL datasets do not contain much commonsense\nknowledge, which motivates us to improve the commonsense of VL-models from the\ndata perspective. Rather than collecting a new VL training dataset, we propose\na more scalable strategy, i.e., \"Data Augmentation with kNowledge graph\nlinearization for CommonsensE capability\" (DANCE). It can be viewed as one type\nof data augmentation technique, which can inject commonsense knowledge into\nexisting VL datasets on the fly during training. More specifically, we leverage\nthe commonsense knowledge graph (e.g., ConceptNet) and create variants of text\ndescription in VL datasets via bidirectional sub-graph sequentialization. For\nbetter commonsense evaluation, we further propose the first retrieval-based\ncommonsense diagnostic benchmark. By conducting extensive experiments on some\nrepresentative VL-models, we demonstrate that our DANCE technique is able to\nsignificantly improve the commonsense ability while maintaining the performance\non vanilla retrieval tasks. The code and data are available at\nhttps://github.com/pleaseconnectwifi/DANCE",
    "descriptor": "\nComments: Code: this https URL Project page: shuquanye.com/DANCE_website\n",
    "authors": [
      "Shuquan Ye",
      "Yujia Xie",
      "Dongdong Chen",
      "Yichong Xu",
      "Lu Yuan",
      "Chenguang Zhu",
      "Jing Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16504"
  },
  {
    "id": "arXiv:2211.15146",
    "title": "Simple Random Order Contention Resolution for Graphic Matroids with  Almost no Prior Information",
    "abstract": "Random order online contention resolution schemes (ROCRS) are structured\nonline rounding algorithms with numerous applications and links to other\nwell-known online selection problems, like the matroid secretary conjecture. We\nare interested in ROCRS subject to a matroid constraint, which is among the\nmost studied constraint families. Previous ROCRS required to know upfront the\nfull fractional point to be rounded as well as the matroid. It is unclear to\nwhat extent this is necessary. Fu, Lu, Tang, Turkieltaub, Wu, Wu, and Zhang\n(SOSA 2022) shed some light on this question by proving that no strong\n(constant-selectable) online or even offline contention resolution scheme\nexists if the fractional point is unknown, not even for graphic matroids.\nIn contrast, we show, in a setting with slightly more knowledge and where the\nfractional point reveals one by one, that there is hope to obtain strong ROCRS\nby providing a simple constant-selectable ROCRS for graphic matroids that only\nrequires to know the size of the ground set in advance. Moreover, our procedure\nholds in the more general adversarial order with a sample setting, where, after\nsampling a random constant fraction of the elements, all remaining\n(non-sampled) elements may come in adversarial order.",
    "descriptor": "\nComments: To be published in SOSA23\n",
    "authors": [
      "Richard Santiago",
      "Ivan Sergeev",
      "Rico Zenklusen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.15146"
  },
  {
    "id": "arXiv:2211.15667",
    "title": "Artificial Intelligence-based Eosinophil Counting in Gastrointestinal  Biopsies",
    "abstract": "Normally eosinophils are present in the gastrointestinal (GI) tract of\nhealthy individuals. When the eosinophils increase beyond their usual amount in\nthe GI tract, a patient gets varied symptoms. Clinicians find it difficult to\ndiagnose this condition called eosinophilia. Early diagnosis can help in\ntreating patients. Histopathology is the gold standard in the diagnosis for\nthis condition. As this is an under-diagnosed condition, counting eosinophils\nin the GI tract biopsies is important. In this study, we trained and tested a\ndeep neural network based on UNet to detect and count eosinophils in GI tract\nbiopsies. We used connected component analysis to extract the eosinophils. We\nstudied correlation of eosinophilic infiltration counted by AI with a manual\ncount. GI tract biopsy slides were stained with H&E stain. Slides were scanned\nusing a camera attached to a microscope and five high-power field images were\ntaken per slide. Pearson correlation coefficient was 85% between the\nmachine-detected and manual eosinophil counts on 300 held-out (test) images.",
    "descriptor": "\nComments: 4 pages, 2 figures\n",
    "authors": [
      "Harsh Shah",
      "Thomas Jacob",
      "Amruta Parulekar",
      "Anjali Amarapurkar",
      "Amit Sethi"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.15667"
  },
  {
    "id": "arXiv:2211.15669",
    "title": "PINNet: a deep neural network with pathway prior knowledge for  Alzheimer's disease",
    "abstract": "Identification of Alzheimer's Disease (AD)-related transcriptomic signatures\nfrom blood is important for early diagnosis of the disease. Deep learning\ntechniques are potent classifiers for AD diagnosis, but most have been unable\nto identify biomarkers because of their lack of interpretability. To address\nthese challenges, we propose a pathway information-based neural network\n(PINNet) to predict AD patients and analyze blood and brain transcriptomic\nsignatures using an interpretable deep learning model. PINNet is a deep neural\nnetwork (DNN) model with pathway prior knowledge from either the Gene Ontology\nor Kyoto Encyclopedia of Genes and Genomes databases. Then, a\nbackpropagation-based model interpretation method was applied to reveal\nessential pathways and genes for predicting AD. We compared the performance of\nPINNet with a DNN model without a pathway. Performances of PINNet outperformed\nor were similar to those of DNN without a pathway using blood and brain gene\nexpressions, respectively. Moreover, PINNet considers more AD-related genes as\nessential features than DNN without a pathway in the learning process. Pathway\nanalysis of protein-protein interaction modules of highly contributed genes\nshowed that AD-related genes in blood were enriched with cell migration,\nPI3K-Akt, MAPK signaling, and apoptosis in blood. The pathways enriched in the\nbrain module included cell migration, PI3K-Akt, MAPK signaling, apoptosis,\nprotein ubiquitination, and t-cell activation. Collectively, with prior\nknowledge about pathways, PINNet reveals essential pathways related to AD.",
    "descriptor": "",
    "authors": [
      "Yeojin Kim",
      "Hyunju Lee"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15669"
  },
  {
    "id": "arXiv:2211.15688",
    "title": "Neural networks: solving the chemistry of the interstellar medium",
    "abstract": "Non-equilibrium chemistry is a key process in the study of the InterStellar\nMedium (ISM), in particular the formation of molecular clouds and thus stars.\nHowever, computationally it is among the most difficult tasks to include in\nastrophysical simulations, because of the typically high (>40) number of\nreactions, the short evolutionary timescales (about $10^4$ times less than the\nISM dynamical time) and the characteristic non-linearity and stiffness of the\nassociated Ordinary Differential Equations system (ODEs). In this proof of\nconcept work, we show that Physics Informed Neural Networks (PINN) are a viable\nalternative to traditional ODE time integrators for stiff thermo-chemical\nsystems, i.e. up to molecular hydrogen formation (9 species and 46 reactions).\nTesting different chemical networks in a wide range of densities ($-2< \\log\nn/{\\rm cm}^{-3}< 3$) and temperatures ($1 < \\log T/{\\rm K}< 5$), we find that a\nbasic architecture can give a comfortable convergence only for simplified\nchemical systems: to properly capture the sudden chemical and thermal\nvariations a Deep Galerkin Method is needed. Once trained ($\\sim 10^3$ GPUhr),\nthe PINN well reproduces the strong non-linear nature of the solutions (errors\n$\\lesssim 10\\%$) and can give speed-ups up to a factor of $\\sim 200$ with\nrespect to traditional ODE solvers. Further, the latter have completion times\nthat vary by about $\\sim 30\\%$ for different initial $n$ and $T$, while the\nPINN method gives negligible variations. Both the speed-up and the potential\nimprovement in load balancing imply that PINN-powered simulations are a very\npalatable way to solve complex chemical calculation in astrophysical and\ncosmological problems.",
    "descriptor": "\nComments: 16 pages, 12 figures, accepted for publication on MNRAS\n",
    "authors": [
      "Lorenzo Branca",
      "Andrea Pallottini"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15688"
  },
  {
    "id": "arXiv:2211.15717",
    "title": "Train smarter, not harder: learning deep abdominal CT registration on  scarce data",
    "abstract": "Purpose: This study aims to explore training strategies to improve\nconvolutional neural network-based image-to-image registration for abdominal\nimaging. Methods: Different training strategies, loss functions, and transfer\nlearning schemes were considered. Furthermore, an augmentation layer which\ngenerates artificial training image pairs on-the-fly was proposed, in addition\nto a loss layer that enables dynamic loss weighting. Results: Guiding\nregistration using segmentations in the training step proved beneficial for\ndeep-learning-based image registration. Finetuning the pretrained model from\nthe brain MRI dataset to the abdominal CT dataset further improved performance\non the latter application, removing the need for a large dataset to yield\nsatisfactory performance. Dynamic loss weighting also marginally improved\nperformance, all without impacting inference runtime. Conclusion: Using simple\nconcepts, we improved the performance of a commonly used deep image\nregistration architecture, VoxelMorph. In future work, our framework, DDMR,\nshould be validated on different datasets to further assess its value.",
    "descriptor": "\nComments: 17 pages, 1 figure, 4 tables\n",
    "authors": [
      "Javier P\u00e9rez de Frutos",
      "Andr\u00e9 Pedersen",
      "Egidijus Pelanis",
      "David Bouget",
      "Shanmugapriya Survarachakan",
      "Thomas Lang\u00f8",
      "Ole-Jakob Elle",
      "Frank Lindseth"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15717"
  },
  {
    "id": "arXiv:2211.15720",
    "title": "Predicting pathways for old and new metabolites through clustering",
    "abstract": "The diverse metabolic pathways are fundamental to all living organisms, as\nthey harvest energy, synthesize biomass components, produce molecules to\ninteract with the microenvironment, and neutralize toxins. While discovery of\nnew metabolites and pathways continues, the prediction of pathways for new\nmetabolites can be challenging. It can take vast amounts of time to elucidate\npathways for new metabolites; thus, according to HMDB only 60% of metabolites\nget assigned to pathways. Here, we present an approach to identify pathways\nbased on metabolite structure. We extracted 201 features from SMILES\nannotations, and identified new metabolites from PubMed abstracts and HMDB.\nAfter applying clustering algorithms to both groups of features, we quantified\ncorrelations between metabolites, and found the clusters accurately linked 92%\nof known metabolites to their respective pathways. Thus, this approach could be\nvaluable for predicting metabolic pathways for new metabolites.",
    "descriptor": "\nComments: 11 pages, 8 figures\n",
    "authors": [
      "Thiru Siddharth",
      "Nathan Lewis"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)",
      "Molecular Networks (q-bio.MN)"
    ],
    "url": "https://arxiv.org/abs/2211.15720"
  },
  {
    "id": "arXiv:2211.15757",
    "title": "Reducing Runtime Overhead via Use-Based Migration in Neutral Atom  Quantum Architectures",
    "abstract": "Neutral atoms are a promising choice for scalable quantum computing\narchitectures. Features such as long distance interactions and native\nmultiqubit gates offer reductions in communication costs and operation count.\nHowever, the trapped atoms used as qubits can be lost over the course of\ncomputation and due to adverse environmental factors. The value of a lost\ncomputation qubit cannot be recovered and requires the reloading of the array\nand rerunning of the computation, greatly increasing the number of runs of a\ncircuit. Software mitigation strategies exist but exhaust the original mapped\nlocations of the circuit slowly and create more spread out clusters of qubits\nacross the architecture decreasing the probability of success. We increase\nflexibility by developing strategies that find all reachable qubits, rather\nonly adjacent hardware qubits. Second, we divide the architecture into separate\nsections, and run the circuit in each section, free of lost atoms. Provided the\narchitecture is large enough, this resets the circuit without having to reload\nthe entire architecture. This increases the number of effective shots before\nreloading by a factor of two for a circuit that utilizes 30% of the\narchitecture. We also explore using these sections to parallelize execution of\ncircuits, reducing the overall runtime by a total 50% for 30 qubit circuit.\nThese techniques contribute to a dynamic new set of strategies to combat the\ndetrimental effects of lost computational space.",
    "descriptor": "\nComments: 11 pages, 11 Figures, In QCE22: 2022 IEEE International Conference on Quantum Computing & Engineering\n",
    "authors": [
      "Andrew Litteken",
      "Jonathan M. Baker",
      "Frederic T. Chong"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Hardware Architecture (cs.AR)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2211.15757"
  },
  {
    "id": "arXiv:2211.15776",
    "title": "Families of Perfect Tensors",
    "abstract": "Perfect tensors are the tensors corresponding to the absolutely maximally\nentangled states, a special type of quantum states that is interested in\nquantum information theory. We establish a method to compute parameterized\nfamilies of perfect tensors in $(\\mathbb{C}^d)^{\\otimes 4}$ using exponential\nmaps from Lie theory. With this method, we find explicit examples of\nnon-classical perfect tensors in $(\\mathbb{C}^3)^{\\otimes 4}$.",
    "descriptor": "",
    "authors": [
      "Runshi Geng"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.15776"
  },
  {
    "id": "arXiv:2211.15795",
    "title": "Adding Workflow Management Flexibility to LSST Pipelines Execution",
    "abstract": "Data processing pipelines need to be executed at scales ranging from small\nruns up through large production data release runs resulting in millions of\ndata products. As part of the Rubin Observatory's pipeline execution system,\nBPS is the abstraction layer that provides an interface to different Workflow\nManagement Systems (WMS) such as HTCondor and PanDA. During the submission\nprocess, the pipeline execution system interacts with the Data Butler to\nproduce a science-oriented execution graph from algorithmic tasks. BPS converts\nthis execution graph to a workflow graph and then uses a WMS-specific plugin to\nsubmit and manage the workflow. Here we will discuss the architectural design\nof this interface and report briefly on the recent production of the Data\nPreview 0.2 release and how the system is used by pipeline developers.",
    "descriptor": "\nComments: 4 pages, submitted to Astronomical Data Analysis Software and Systems XXXII, October 2022\n",
    "authors": [
      "Michelle Gower",
      "Mikolaj Kowalik",
      "Nate B. Lust",
      "James F. Bosch",
      "Tim Jenness"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.15795"
  },
  {
    "id": "arXiv:2211.15807",
    "title": "Using a Conditional Generative Adversarial Network to Control the  Statistical Characteristics of Generated Images for IACT Data Analysis",
    "abstract": "Generative adversarial networks are a promising tool for image generation in\nthe astronomy domain. Of particular interest are conditional generative\nadversarial networks (cGANs), which allow you to divide images into several\nclasses according to the value of some property of the image, and then specify\nthe required class when generating new images. In the case of images from\nImaging Atmospheric Cherenkov Telescopes (IACTs), an important property is the\ntotal brightness of all image pixels (image size), which is in direct\ncorrelation with the energy of primary particles. We used a cGAN technique to\ngenerate images similar to whose obtained in the TAIGA-IACT experiment. As a\ntraining set, we used a set of two-dimensional images generated using the TAIGA\nMonte Carlo simulation software. We artificiallly divided the training set into\n10 classes, sorting images by size and defining the boundaries of the classes\nso that the same number of images fall into each class. These classes were used\nwhile training our network. The paper shows that for each class, the size\ndistribution of the generated images is close to normal with the mean value\nlocated approximately in the middle of the corresponding class. We also show\nthat for the generated images, the total image size distribution obtained by\nsumming the distributions over all classes is close to the original\ndistribution of the training set. The results obtained will be useful for more\naccurate generation of realistic synthetic images similar to the ones taken by\nIACTs.",
    "descriptor": "",
    "authors": [
      "Julia Dubenskaya",
      "Alexander Kryukov",
      "Andrey Demichev",
      "Stanislav Polyakov",
      "Elizaveta Gres",
      "Anna Vlaskina"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.15807"
  },
  {
    "id": "arXiv:2211.15817",
    "title": "COVID-19 Classification Using Deep Learning Two-Stage Approach",
    "abstract": "In this paper, deep-learning-based approaches namely fine-tuning of\npretrained convolutional neural networks (VGG16 and VGG19), and end-to-end\ntraining of a developed CNN model, have been used in order to classify X-Ray\nimages into four different classes that include COVID-19, normal, opacity and\npneumonia cases. A dataset containing more than 20,000 X-ray scans was\nretrieved from Kaggle and used in this experiment. A two-stage classification\napproach was implemented to be compared to the one-shot classification\napproach. Our hypothesis was that a two-stage model will be able to achieve\nbetter performance than a one-shot model. Our results show otherwise as VGG16\nachieved 95% accuracy using one-shot approach over 5-fold of training. Future\nwork will focus on a more robust implementation of the two-stage classification\nmodel Covid-TSC. The main improvement will be allowing data to flow from the\noutput of stage-1 to the input of stage-2, where stage-1 and stage-2 models are\nVGG16 models fine-tuned on the Covid-19 dataset.",
    "descriptor": "",
    "authors": [
      "Mostapha Alsaidi",
      "Ali Saleem Altaher",
      "Muhammad Tanveer Jan",
      "Ahmed Altaher",
      "Zahra Salekshahrezaee"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15817"
  },
  {
    "id": "arXiv:2211.15851",
    "title": "CSI-PPPNet: A One-Sided Deep Learning Framework for Massive MIMO CSI  Feedback",
    "abstract": "To reduce multiuser interference and maximize the spectrum efficiency in\nfrequency division duplexing massive multiple-input multiple-output (MIMO)\nsystems, the downlink channel state information (CSI) estimated at the user\nequipment (UE) is required at the base station (BS). This paper presents a\nnovel method for massive MIMO CSI feedback via a one-sided deep learning\nframework. The CSI is compressed via linear projections at the UE, and is\nrecovered at the BS using deep plug-and-play priors (PPP). Instead of using\nhandcrafted regularizers for the wireless channel responses, the proposed\napproach, namely CSI-PPPNet, exploits a deep learning (DL) based denoisor in\nplace of the proximal operator of the prior in an alternating optimization\nscheme. This way, a DL model trained once for denoising can be repurposed for\nCSI recovery tasks with arbitrary linear projections. In addition to the\none-for-all property, in comparison to the two-sided autoencoder-based CSI\nfeedback architecture, the one-sided framework relieves the burden of joint\nmodel training and model delivery, and could be applied at UEs with limited\ndevice memories and computation power. This opens new perspectives in the field\nof DL-based CSI feedback. Extensive experiments over the open indoor and urban\nmacro scenarios show the effectiveness of the proposed method.",
    "descriptor": "",
    "authors": [
      "Wei Chen",
      "Weixiao Wan",
      "Shiyue Wang",
      "Peng Sun",
      "Bo Ai"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.15851"
  },
  {
    "id": "arXiv:2211.15888",
    "title": "UQ-ARMED: Uncertainty quantification of adversarially-regularized mixed  effects deep learning for clustered non-iid data",
    "abstract": "This work demonstrates the ability to produce readily interpretable\nstatistical metrics for model fit, fixed effects covariance coefficients, and\nprediction confidence. Importantly, this work compares 4 suitable and commonly\napplied epistemic UQ approaches, BNN, SWAG, MC dropout, and ensemble approaches\nin their ability to calculate these statistical metrics for the ARMED MEDL\nmodels. In our experiment for AD prognosis, not only do the UQ methods provide\nthese benefits, but several UQ methods maintain the high performance of the\noriginal ARMED method, some even provide a modest (but not statistically\nsignificant) performance improvement. The ensemble models, especially the\nensemble method with a 90% subsampling, performed well across all metrics we\ntested with (1) high performance that was comparable to the non-UQ ARMED model,\n(2) properly deweights the confounds probes and assigns them statistically\ninsignificant p-values, (3) attains relatively high calibration of the output\nprediction confidence. Based on the results, the ensemble approaches,\nespecially with a subsampling of 90%, provided the best all-round performance\nfor prediction and uncertainty estimation, and achieved our goals to provide\nstatistical significance for model fit, statistical significance covariate\ncoefficients, and confidence in prediction, while maintaining the baseline\nperformance of MEDL using ARMED",
    "descriptor": "",
    "authors": [
      "Alex Treacher",
      "Kevin Nguyen",
      "Dylan Owens",
      "Daniel Heitjan",
      "Albert Montillo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.15888"
  },
  {
    "id": "arXiv:2211.15889",
    "title": "Best Subset Selection in Reduced Rank Regression",
    "abstract": "Sparse reduced rank regression is an essential statistical learning method.\nIn the contemporary literature, estimation is typically formulated as a\nnonconvex optimization that often yields to a local optimum in numerical\ncomputation. Yet, their theoretical analysis is always centered on the global\noptimum, resulting in a discrepancy between the statistical guarantee and the\nnumerical computation. In this research, we offer a new algorithm to address\nthe problem and establish an almost optimal rate for the algorithmic solution.\nWe also demonstrate that the algorithm achieves the estimation with a\npolynomial number of iterations. In addition, we present a generalized\ninformation criterion to simultaneously ensure the consistency of support set\nrecovery and rank estimation. Under the proposed criterion, we show that our\nalgorithm can achieve the oracle reduced rank estimation with a significant\nprobability. The numerical studies and an application in the ovarian cancer\ngenetic data demonstrate the effectiveness and scalability of our approach.",
    "descriptor": "\nComments: 19 pages, 5 figures\n",
    "authors": [
      "Canhong Wen",
      "Ruipeng Dong",
      "Xueqin Wang",
      "Weiyu Li",
      "Heping Zhang"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2211.15889"
  },
  {
    "id": "arXiv:2211.15895",
    "title": "Composition based oxidation state prediction of materials using deep  learning",
    "abstract": "Oxidation states are the charges of atoms after their ionic approximation of\ntheir bonds, which have been widely used in charge-neutrality verification,\ncrystal structure determination, and reaction estimation. Currently only\nheuristic rules exist for guessing the oxidation states of a given compound\nwith many exceptions. Recent work has developed machine learning models based\non heuristic structural features for predicting the oxidation states of metal\nions. However, composition based oxidation state prediction still remains\nelusive so far, which is more important in new material discovery for which the\nstructures are not even available. This work proposes a novel deep learning\nbased BERT transformer language model BERTOS for predicting the oxidation\nstates of all elements of inorganic compounds given only their chemical\ncomposition. Our model achieves 96.82\\% accuracy for all-element oxidation\nstates prediction benchmarked on the cleaned ICSD dataset and achieves 97.61\\%\naccuracy for oxide materials. We also demonstrate how it can be used to conduct\nlarge-scale screening of hypothetical material compositions for materials\ndiscovery.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Nihang Fu",
      "Jeffrey Hu",
      "Ying Feng",
      "Gregory Morrison",
      "Hans-Conrad zur Loye",
      "Jianjun Hu"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15895"
  },
  {
    "id": "arXiv:2211.15912",
    "title": "Optimizing Stock Option Forecasting with the Assembly of Machine  Learning Models and Improved Trading Strategies",
    "abstract": "This paper introduced key aspects of applying Machine Learning (ML) models,\nimproved trading strategies, and the Quasi-Reversibility Method (QRM) to\noptimize stock option forecasting and trading results. It presented the\nfindings of the follow-up project of the research \"Application of Convolutional\nNeural Networks with Quasi-Reversibility Method Results for Option\nForecasting\". First, the project included an application of Recurrent Neural\nNetworks (RNN) and Long Short-Term Memory (LSTM) networks to provide a novel\nway of predicting stock option trends. Additionally, it examined the dependence\nof the ML models by evaluating the experimental method of combining multiple ML\nmodels to improve prediction results and decision-making. Lastly, two improved\ntrading strategies and simulated investing results were presented. The Binomial\nAsset Pricing Model with discrete time stochastic process analysis and\nportfolio hedging was applied and suggested an optimized investment\nexpectation. These results can be utilized in real-life trading strategies to\noptimize stock option investment results based on historical data.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Zheng Cao",
      "Raymond Guo",
      "Wenyu Du",
      "Jiayi Gao",
      "Kirill V. Golubnichiy"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15912"
  },
  {
    "id": "arXiv:2211.15930",
    "title": "Offline Supervised Learning V.S. Online Direct Policy Optimization: A  Comparative Study and A Unified Training Paradigm for Neural Network-Based  Optimal Feedback Control",
    "abstract": "This work is concerned with solving neural network-based feedback controllers\nefficiently for optimal control problems. We first conduct a comparative study\nof two mainstream approaches: offline supervised learning and online direct\npolicy optimization. Albeit the training part of the supervised learning\napproach is relatively easy, the success of the method heavily depends on the\noptimal control dataset generated by open-loop optimal control solvers. In\ncontrast, direct optimization turns the optimal control problem into an\noptimization problem directly without any requirement of pre-computing, but the\ndynamics-related objective can be hard to optimize when the problem is\ncomplicated. Our results highlight the priority of offline supervised learning\nin terms of both optimality and training time. To overcome the main challenges,\ndataset, and optimization, in the two approaches respectively, we complement\nthem and propose the Pre-train and Fine-tune strategy as a unified training\nparadigm for optimal feedback control, which further improves the performance\nand robustness significantly. Our code is available at\nhttps://github.com/yzhao98/DeepOptimalControl.",
    "descriptor": "",
    "authors": [
      "Yue Zhao",
      "Jiequn Han"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15930"
  },
  {
    "id": "arXiv:2211.15938",
    "title": "Segment-based fusion of multi-sensor multi-scale satellite soil moisture  retrievals",
    "abstract": "Synergetic use of sensors for soil moisture retrieval is attracting\nconsiderable interest due to the different advantages of different sensors.\nActive, passive, and optic data integration could be a comprehensive solution\nfor exploiting the advantages of different sensors aimed at preparing soil\nmoisture maps. Typically, pixel-based methods are used for multi-sensor fusion.\nSince, different applications need different scales of soil moisture maps,\npixel-based approaches are limited for this purpose. Object-based image\nanalysis employing an image object instead of a pixel could help us to meet\nthis need. This paper proposes a segment-based image fusion framework to\nevaluate the possibility of preparing a multi-scale soil moisture map through\nintegrated Sentinel-1, Sentinel-2, and Soil Moisture Active Passive (SMAP)\ndata. The results confirmed that the proposed methodology was able to improve\nsoil moisture estimation in different scales up to 20% better compared to\npixel-based fusion approach.",
    "descriptor": "",
    "authors": [
      "Reza Attarzadeh",
      "Hossein Bagheri",
      "Iman Khosravi",
      "Saeid Niazmardi",
      "Davood Akbarid"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15938"
  },
  {
    "id": "arXiv:2211.15939",
    "title": "An Adaptive and Robust Deep Learning Framework for THz Ultra-Massive  MIMO Channel Estimation",
    "abstract": "Terahertz ultra-massive MIMO (THz UM-MIMO) is envisioned as one of the key\nenablers of 6G wireless networks, for which channel estimation is highly\nchallenging. Traditional analytical estimation methods are no longer effective,\nas the enlarged array aperture and the small wavelength result in a mixture of\nfar-field and near-field paths, constituting a hybrid-field channel. Deep\nlearning (DL)-based methods, despite the competitive performance, generally\nlack theoretical guarantees and scale poorly with the size of the array. In\nthis paper, we propose a general DL framework for THz UM-MIMO channel\nestimation, which leverages existing iterative channel estimators and is with\nprovable guarantees. Each iteration is implemented by a fixed point network\n(FPN), consisting of a closed-form linear estimator and a DL-based non-linear\nestimator. The proposed method perfectly matches the THz UM-MIMO channel\nestimation due to several unique advantages. First, the complexity is low and\nadaptive. It enjoys provable linear convergence with a low per-iteration cost\nand monotonically increasing accuracy, which enables an adaptive\naccuracy-complexity tradeoff. Second, it is robust to practical distribution\nshifts and can directly generalize to a variety of heavily out-of-distribution\nscenarios with almost no performance loss, which is suitable for the\ncomplicated THz channel conditions. Theoretical analysis and extensive\nsimulation results are provided to illustrate the advantages over the\nstate-of-the-art methods in estimation accuracy, convergence rate, complexity,\nand robustness.",
    "descriptor": "\nComments: 13 pages, 10 figures, 5 tables, submitted to IEEE journal\n",
    "authors": [
      "Wentao Yu",
      "Yifei Shen",
      "Hengtao He",
      "Xianghao Yu",
      "Shenghui Song",
      "Jun Zhang",
      "Khaled B. Letaief"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.15939"
  },
  {
    "id": "arXiv:2211.15950",
    "title": "Enhanced artificial intelligence-based diagnosis using CBCT with  internal denoising: Clinical validation for discrimination of fungal ball,  sinusitis, and normal cases in the maxillary sinus",
    "abstract": "The cone-beam computed tomography (CBCT) provides 3D volumetric imaging of a\ntarget with low radiation dose and cost compared with conventional computed\ntomography, and it is widely used in the detection of paranasal sinus disease.\nHowever, it lacks the sensitivity to detect soft tissue lesions owing to\nreconstruction constraints. Consequently, only physicians with expertise in\nCBCT reading can distinguish between inherent artifacts or noise and diseases,\nrestricting the use of this imaging modality. The development of artificial\nintelligence (AI)-based computer-aided diagnosis methods for CBCT to overcome\nthe shortage of experienced physicians has attracted substantial attention.\nHowever, advanced AI-based diagnosis addressing intrinsic noise in CBCT has not\nbeen devised, discouraging the practical use of AI solutions for CBCT. To\naddress this issue, we propose an AI-based computer-aided diagnosis method\nusing CBCT with a denoising module. This module is implemented before diagnosis\nto reconstruct the internal ground-truth full-dose scan corresponding to an\ninput CBCT image and thereby improve the diagnostic performance. The external\nvalidation results for the unified diagnosis of sinus fungal ball, chronic\nrhinosinusitis, and normal cases show that the proposed method improves the\nmicro-, macro-average AUC, and accuracy by 7.4, 5.6, and 9.6% (from 86.2, 87.0,\nand 73.4 to 93.6, 92.6, and 83.0%), respectively, compared with a baseline\nwhile improving human diagnosis accuracy by 11% (from 71.7 to 83.0%),\ndemonstrating technical differentiation and clinical effectiveness. This\npioneering study on AI-based diagnosis using CBCT indicates denoising can\nimprove diagnostic performance and reader interpretability in images from the\nsinonasal area, thereby providing a new approach and direction to radiographic\nimage reconstruction regarding the development of AI-based diagnostic\nsolutions.",
    "descriptor": "",
    "authors": [
      "Kyungsu Kim",
      "Chae Yeon Lim",
      "Joong Bo Shin",
      "Myung Jin Chung",
      "Yong Gi Jung"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15950"
  },
  {
    "id": "arXiv:2211.15979",
    "title": "AirFormer: Predicting Nationwide Air Quality in China with Transformers",
    "abstract": "Air pollution is a crucial issue affecting human health and livelihoods, as\nwell as one of the barriers to economic and social growth. Forecasting air\nquality has become an increasingly important endeavor with significant social\nimpacts, especially in emerging countries like China. In this paper, we present\na novel Transformer architecture termed AirFormer to collectively predict\nnationwide air quality in China, with an unprecedented fine spatial granularity\ncovering thousands of locations. AirFormer decouples the learning process into\ntwo stages -- 1) a bottom-up deterministic stage that contains two new types of\nself-attention mechanisms to efficiently learn spatio-temporal representations;\n2) a top-down stochastic stage with latent variables to capture the intrinsic\nuncertainty of air quality data. We evaluate AirFormer with 4-year data from\n1,085 stations in the Chinese Mainland. Compared to the state-of-the-art model,\nAirFormer reduces prediction errors by 5%~8% on 72-hour future predictions. Our\nsource code is available at https://github.com/yoshall/airformer.",
    "descriptor": "\nComments: Published at AAAI-23\n",
    "authors": [
      "Yuxuan Liang",
      "Yutong Xia",
      "Songyu Ke",
      "Yiwei Wang",
      "Qingsong Wen",
      "Junbo Zhang",
      "Yu Zheng",
      "Roger Zimmermann"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15979"
  },
  {
    "id": "arXiv:2211.15997",
    "title": "MedalCare-XL: 16,900 healthy and pathological 12 lead ECGs obtained  through electrophysiological simulations",
    "abstract": "Mechanistic cardiac electrophysiology models allow for personalized\nsimulations of the electrical activity in the heart and the ensuing\nelectrocardiogram (ECG) on the body surface. As such, synthetic signals possess\nknown ground truth labels of the underlying disease and can be employed for\nvalidation of machine learning ECG analysis tools in addition to clinical\nsignals. Recently, synthetic ECGs were used to enrich sparse clinical data or\neven replace them completely during training leading to improved performance on\nreal-world clinical test data. We thus generated a novel synthetic database\ncomprising a total of 16,900 12 lead ECGs based on electrophysiological\nsimulations equally distributed into healthy control and 7 pathology classes.\nThe pathological case of myocardial infraction had 6 sub-classes. A comparison\nof extracted features between the virtual cohort and a publicly available\nclinical ECG database demonstrated that the synthetic signals represent\nclinical ECGs for healthy and pathological subpopulations with high fidelity.\nThe ECG database is split into training, validation, and test folds for\ndevelopment and objective assessment of novel machine learning algorithms.",
    "descriptor": "",
    "authors": [
      "Karli Gillette",
      "Matthias A.F. Gsell",
      "Claudia Nagel",
      "Jule Bender",
      "Bejamin Winkler",
      "Steven E. Williams",
      "Markus B\u00e4r",
      "Tobias Sch\u00e4ffter",
      "Olaf D\u00f6ssel",
      "Gernot Plank",
      "Axel Loewe"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.15997"
  },
  {
    "id": "arXiv:2211.16028",
    "title": "jaCappella Corpus: A Japanese a Cappella Vocal Ensemble Corpus",
    "abstract": "We construct a corpus of Japanese a cappella vocal ensembles (jaCappella\ncorpus) for vocal ensemble separation and synthesis. It consists of 35\ncopyright-cleared vocal ensemble songs and their audio recordings of individual\nvoice parts. These songs were arranged from out-of-copyright Japanese\nchildren's songs and have six voice parts (lead vocal, soprano, alto, tenor,\nbass, and vocal percussion). They are divided into seven subsets, each of which\nfeatures typical characteristics of a music genre such as jazz and enka. The\nvariety in genre and voice part match vocal ensembles recently widespread in\nsocial media services such as YouTube, although the main targets of\nconventional vocal ensemble datasets are choral singing made up of soprano,\nalto, tenor, and bass. Experimental evaluation demonstrates that our corpus is\na challenging resource for vocal ensemble separation. Our corpus is available\non our project page (https://tomohikonakamura.github.io/jaCappella_corpus/).",
    "descriptor": "\nComments: Submitted to ICASSP2023\n",
    "authors": [
      "Tomohiko Nakamura",
      "Shinnosuke Takamichi",
      "Naoko Tanji",
      "Satoru Fukayama",
      "Hiroshi Saruwatari"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.16028"
  },
  {
    "id": "arXiv:2211.16049",
    "title": "Evaluating and reducing the distance between synthetic and real speech  distributions",
    "abstract": "While modern Text-to-Speech (TTS) systems can produce speech rated highly in\nterms of subjective evaluation, the distance between real and synthetic speech\ndistributions remains understudied, where we use the term \\textit{distribution}\nto mean the sample space of all possible real speech recordings from a given\nset of speakers; or of the synthetic samples that could be generated for the\nsame set of speakers. We evaluate the distance of real and synthetic speech\ndistributions along the dimensions of the acoustic environment, speaker\ncharacteristics and prosody using a range of speech processing measures and the\nrespective Wasserstein distances of their distributions. We reduce these\ndistribution distances along said dimensions by providing utterance-level\ninformation derived from the measures to the model and show they can be\ngenerated at inference time. The improvements to the dimensions translate to\noverall distribution distance reduction approximated using Automatic Speech\nRecognition (ASR) by evaluating the fitness of the synthetic data as training\ndata.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Christoph Minixhofer",
      "Ond\u0159ej Klejch",
      "Peter Bell"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.16049"
  },
  {
    "id": "arXiv:2211.16059",
    "title": "On Large-Scale Multiple Testing Over Networks: An Asymptotic Approach",
    "abstract": "This work concerns developing communication- and computation-efficient\nmethods for large-scale multiple testing over networks, which is of interest to\nmany practical applications. We take an asymptotic approach and propose two\nmethods, proportion-matching and greedy aggregation, tailored to distributed\nsettings. The proportion-matching method achieves the global BH performance yet\nonly requires a one-shot communication of the (estimated) proportion of true\nnull hypotheses as well as the number of p-values at each node. By focusing on\nthe asymptotic optimal power, we go beyond the BH procedure by providing an\nexplicit characterization of the asymptotic optimal solution. This leads to the\ngreedy aggregation method that effectively approximate the optimal rejection\nregions at each node, while computation-efficiency comes from the greedy-type\napproach naturally. Extensive numerical results over a variety of challenging\nsettings are provided to support our theoretical findings.",
    "descriptor": "",
    "authors": [
      "Mehrdad Pournaderi",
      "Yu Xiang"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.16059"
  },
  {
    "id": "arXiv:2211.16065",
    "title": "Hiding speaker's sex in speech using zero-evidence speaker  representation in an analysis/synthesis pipeline",
    "abstract": "The use of modern vocoders in an analysis/synthesis pipeline allows us to\ninvestigate high-quality voice conversion that can be used for privacy\npurposes. Here, we propose to transform the speaker embedding and the pitch in\norder to hide the sex of the speaker. ECAPA-TDNN-based speaker representation\nfed into a HiFiGAN vocoder is protected using a neural-discriminant analysis\napproach, which is consistent with the zero-evidence concept of privacy. This\napproach significantly reduces the information in speech related to the\nspeaker's sex while preserving speech content and some consistency in the\nresulting protected voices.",
    "descriptor": "\nComments: Submitted to ICASSP 2023, not peer-reviewed yet\n",
    "authors": [
      "Paul-Gauthier No\u00e9",
      "Xiaoxiao Miao",
      "Xin Wang",
      "Junichi Yamagishi",
      "Jean-Fran\u00e7ois Bonastre",
      "Driss Matrouf"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.16065"
  },
  {
    "id": "arXiv:2211.16112",
    "title": "On Word Error Rate Definitions and their Efficient Computation for  Multi-Speaker Speech Recognition Systems",
    "abstract": "We present a general framework to compute the word error rate (WER) of ASR\nsystems that process recordings containing multiple speakers at their input and\nthat produce multiple output word sequences (MIMO). Such ASR systems are\ntypically required, e.g., for meeting transcription. We provide an efficient\nimplementation based on a dynamic programming search in a multi-dimensional\nLevenshtein distance tensor under the constraint that a reference utterance\nmust be matched consistently with one hypothesis output. This also results in\nan efficient implementation of the ORC WER which previously suffered from\nexponential complexity. We give an overview of commonly used WER definitions\nfor multi-speaker scenarios and show that they are specializations of the above\nMIMO WER tuned to particular application scenarios. We conclude with a\ndiscussion of the pros and cons of the various WER definitions and a\nrecommendation when to use which.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Thilo von Neumann",
      "Christoph Boeddeker",
      "Keisuke Kinoshita",
      "Marc Delcroix",
      "Reinhold Haeb-Umbach"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.16112"
  },
  {
    "id": "arXiv:2211.16116",
    "title": "Machine learning emulation of a local-scale UK climate model",
    "abstract": "Climate change is causing the intensification of rainfall extremes.\nPrecipitation projections with high spatial resolution are important for\nsociety to prepare for these changes, e.g. to model flooding impacts.\nPhysics-based simulations for creating such projections are very\ncomputationally expensive. This work demonstrates the effectiveness of\ndiffusion models, a form of deep generative models, for generating much more\ncheaply realistic high resolution rainfall samples for the UK conditioned on\ndata from a low resolution simulation. We show for the first time a machine\nlearning model that is able to produce realistic samples of high-resolution\nrainfall based on a physical model that resolves atmospheric convection, a key\nprocess behind extreme rainfall. By adding self-learnt, location-specific\ninformation to low resolution relative vorticity, quantiles and time-mean of\nthe samples match well their counterparts from the high-resolution simulation.",
    "descriptor": "\nComments: 8 pages, 5 figures, Tackling Climate Change with Machine Learning workshop at NeurIPS 2022\n",
    "authors": [
      "Henry Addison",
      "Elizabeth Kendon",
      "Suman Ravuri",
      "Laurence Aitchison",
      "Peter AG Watson"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16116"
  },
  {
    "id": "arXiv:2211.16141",
    "title": "Mind the Gap: Scanner-induced domain shifts pose challenges for  representation learning in histopathology",
    "abstract": "Computer-aided systems in histopathology are often challenged by various\nsources of domain shift that impact the performance of these algorithms\nconsiderably. We investigated the potential of using self-supervised\npre-training to overcome scanner-induced domain shifts for the downstream task\nof tumor segmentation. For this, we present the Barlow Triplets to learn\nscanner-invariant representations from a multi-scanner dataset with local image\ncorrespondences. We show that self-supervised pre-training successfully aligned\ndifferent scanner representations, which, interestingly only results in a\nlimited benefit for our downstream task. We thereby provide insights into the\ninfluence of scanner characteristics for downstream applications and contribute\nto a better understanding of why established self-supervised methods have not\nyet shown the same success on histopathology data as they have for natural\nimages.",
    "descriptor": "\nComments: 5 pages, 4 figures, 1 table. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Frauke Wilm",
      "Marco Fragoso",
      "Christof A. Bertram",
      "Nikolas Stathonikos",
      "Mathias \u00d6ttl",
      "Jingna Qiu",
      "Robert Klopfleisch",
      "Andreas Maier",
      "Marc Aubreville",
      "Katharina Breininger"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16141"
  },
  {
    "id": "arXiv:2211.16144",
    "title": "Mid-point embedding of Hamiltonian systems and variational integrators",
    "abstract": "Following the discrete embedding formalism, we give a new derivation of the\nmid-point variational integrators as developed by J.M. Wendlandt and J.E.\nMarsden by defining an adapted order two discrete differential and integral\ncalculus. This allows us to obtain a clearer correspondence between the\ndiscrete and continuous case. We also discuss the corresponding definition of a\ndiscrete Hamiltonian system. A complete comparaison with the results of J.M.\nWendlandt and J.E. Marsden is provided.",
    "descriptor": "",
    "authors": [
      "Jacky Cresson",
      "Rouba Safi"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.16144"
  },
  {
    "id": "arXiv:2211.16161",
    "title": "Artifact Removal in Histopathology Images",
    "abstract": "In the clinical setting of histopathology, whole-slide image (WSI) artifacts\nfrequently arise, distorting regions of interest, and having a pernicious\nimpact on WSI analysis. Image-to-image translation networks such as CycleGANs\nare in principle capable of learning an artifact removal function from unpaired\ndata. However, we identify a surjection problem with artifact removal, and\npropose an weakly-supervised extension to CycleGAN to address this. We assemble\na pan-cancer dataset comprising artifact and clean tiles from the TCGA\ndatabase. Promising results highlight the soundness of our method.",
    "descriptor": "",
    "authors": [
      "Cameron Dahan",
      "Stergios Christodoulidis",
      "Maria Vakalopoulou",
      "Joseph Boyd"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16161"
  },
  {
    "id": "arXiv:2211.16213",
    "title": "Identification of Rare Cortical Folding Patterns using Unsupervised Deep  Learning",
    "abstract": "Like fingerprints, cortical folding patterns are unique to each brain even\nthough they follow a general species-specific organization. Some folding\npatterns have been linked with neurodevelopmental disorders. However, due to\nthe high inter-individual variability, the identification of rare folding\npatterns that could become biomarkers remains a very complex task. This paper\nproposes a novel unsupervised deep learning approach to identify rare folding\npatterns and assess the degree of deviations that can be detected. To this end,\nwe preprocess the brain MR images to focus the learning on the folding\nmorphology and train a beta-VAE to model the inter-individual variability of\nthe folding. We compare the detection power of the latent space and of the\nreconstruction errors, using synthetic benchmarks and one actual rare\nconfiguration related to the central sulcus. Finally, we assess the\ngeneralization of our method on a developmental anomaly located in another\nregion. Our results suggest that this method enables encoding relevant folding\ncharacteristics that can be enlightened and better interpreted based on the\ngenerative power of the beta-VAE. The latent space and the reconstruction\nerrors bring complementary information and enable the identification of rare\npatterns of different nature. This method generalizes well to a different\nregion on another dataset. Code is available at\nhttps://github.com/neurospin-projects/2022_lguillon_rare_folding_detection.",
    "descriptor": "",
    "authors": [
      "Louise Guillon",
      "Jo\u00ebl Chavas",
      "Audrey B\u00e9n\u00e9zit",
      "Marie-Laure Moutard",
      "Denis Rivi\u00e8re",
      "Jean-Fran\u00e7ois Mangin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16213"
  },
  {
    "id": "arXiv:2211.16275",
    "title": "A survey on multi-player bandits",
    "abstract": "Due mostly to its application to cognitive radio networks, multiplayer\nbandits gained a lot of interest in the last decade. A considerable progress\nhas been made on its theoretical aspect. However, the current algorithms are\nfar from applicable and many obstacles remain between these theoretical results\nand a possible implementation of multiplayer bandits algorithms in real\ncognitive radio networks. This survey contextualizes and organizes the rich\nmultiplayer bandits literature. In light of the existing works, some clear\ndirections for future research appear. We believe that a further study of these\ndifferent directions might lead to theoretical algorithms adapted to real-world\nsituations.",
    "descriptor": "\nComments: works released after June 2022 are not considered in this survey\n",
    "authors": [
      "Etienne Boursier",
      "Vianney Perchet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16275"
  },
  {
    "id": "arXiv:2211.16291",
    "title": "On Controller Reduction in Linear Quadratic Gaussian Control with  Performance Bounds",
    "abstract": "The problem of controller reduction has a rich history in control theory.\nYet, many questions remain open. In particular, there exist very few results on\nthe order reduction of general non-observer based controllers and the\nsubsequent quantification of the closed-loop performance. Recent developments\nin model-free policy optimization for Linear Quadratic Gaussian (LQG) control\nhave highlighted the importance of this question. In this paper, we first\npropose a new set of sufficient conditions ensuring that a perturbed controller\nremains internally stabilizing. Based on this result, we illustrate how to\nperform order reduction of general non-observer based controllers using\nbalanced truncation and modal truncation. We also provide explicit bounds on\nthe LQG performance of the reduced-order controller. Furthermore, for\nsingle-input-single-output (SISO) systems, we introduce a new controller\nreduction technique by truncating unstable modes. We illustrate our theoretical\nresults with numerical simulations. Our results will serve as valuable tools to\ndesign direct policy search algorithms for control problems with partial\nobservations.",
    "descriptor": "",
    "authors": [
      "Zhaolin Ren",
      "Yang Zheng",
      "Maryam Fazel",
      "Na Li"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.16291"
  },
  {
    "id": "arXiv:2211.16293",
    "title": "The Adversary Bound Revisited: From Optimal Query Algorithms to Optimal  Control",
    "abstract": "This note complements the upcoming paper \"One-Way Ticket to Las Vegas and the\nQuantum Adversary\" by Belovs and Yolcu, to be presented at QIP 2023. I develop\nthe ideas behind the adversary bound - universal algorithm duality therein in a\ndifferent form. This form may be faster to understand for a general quantum\ninformation audience: It avoids defining the \"unidirectional filtered $\\gamma\n_{2}$-bound\" and relating it to query algorithms explicitly. This proof is also\nmore general because the lower bound (and universal query algorithm) apply to a\nclass of optimal control problems rather than just query problems. That is in\naddition to the advantages to be discussed in Belovs-Yolcu, namely the more\nelementary algorithm and correctness proof that avoids phase estimation and\nspectral analysis, allows for limited treatment of noise, and removes another\n$\\Theta(\\log(1/\\epsilon))$ factor from the runtime compared to the previous\ndiscrete-time algorithm.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Duyal Yolcu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.16293"
  },
  {
    "id": "arXiv:2211.16319",
    "title": "Benchmarking Evaluation Metrics for Code-Switching Automatic Speech  Recognition",
    "abstract": "Code-switching poses a number of challenges and opportunities for\nmultilingual automatic speech recognition. In this paper, we focus on the\nquestion of robust and fair evaluation metrics. To that end, we develop a\nreference benchmark data set of code-switching speech recognition hypotheses\nwith human judgments. We define clear guidelines for minimal editing of\nautomatic hypotheses. We validate the guidelines using 4-way inter-annotator\nagreement. We evaluate a large number of metrics in terms of correlation with\nhuman judgments. The metrics we consider vary in terms of representation\n(orthographic, phonological, semantic), directness (intrinsic vs extrinsic),\ngranularity (e.g. word, character), and similarity computation method. The\nhighest correlation to human judgment is achieved using transliteration\nfollowed by text normalization. We release the first corpus for human\nacceptance of code-switching speech recognition results in dialectal\nArabic/English conversation speech.",
    "descriptor": "\nComments: Accepted to SLT 2022\n",
    "authors": [
      "Injy Hamed",
      "Amir Hussein",
      "Oumnia Chellah",
      "Shammur Chowdhury",
      "Hamdy Mubarak",
      "Sunayana Sitaram",
      "Nizar Habash",
      "Ahmed Ali"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.16319"
  },
  {
    "id": "arXiv:2211.16328",
    "title": "Evaluation of Entropy and Fractal Dimension as Biomarkers for Tumor  Growth and Treatment Response using Cellular Automata",
    "abstract": "Cell-based models provide a helpful approach for simulating complex systems\nthat exhibit adaptive, resilient qualities, such as cancer. Their focus on\nindividual cell interactions makes them a particularly appropriate strategy to\nstudy the effects of cancer therapies, which often are designed to disrupt\nsingle-cell dynamics. In this work, we also propose them as viable methods for\nstudying the time evolution of cancer imaging biomarkers (IBM). We propose a\ncellular automata model for tumor growth and three different therapies:\nchemotherapy, radiotherapy, and immunotherapy, following well-established\nmodeling procedures documented in the literature. The model generates a\nsequence of tumor images, from which time series of two biomarkers: entropy and\nfractal dimension, is obtained. Our model shows that the fractal dimension\nincreased faster at the onset of cancer cell dissemination, while entropy was\nmore responsive to changes induced in the tumor by the different therapy\nmodalities. These observations suggest that the predictive value of the\nproposed biomarkers could vary considerably with time. Thus, it is important to\nassess their use at different stages of cancer and for different imaging\nmodalities. Another observation derived from the results was that both\nbiomarkers varied slowly when the applied therapy attacked cancer cells in a\nscattered fashion along the automatons' area, leaving multiple independent\nclusters of cells at the end of the treatment. Thus, patterns of change of\nsimulated biomarkers time series could reflect on essential qualities of the\nspatial action of a given cancer intervention.",
    "descriptor": "\nComments: 19 pages, 11 figures\n",
    "authors": [
      "Juan Uriel Legaria-Pe\u00f1a",
      "F\u00e9lix S\u00e1nchez-Morales",
      "Yuriria Cort\u00e9s-Poza"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Discrete Mathematics (cs.DM)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.16328"
  },
  {
    "id": "arXiv:2211.16359",
    "title": "POLCOVID: a multicenter multiclass chest X-ray database (Poland,  2020-2021)",
    "abstract": "The outbreak of the SARS-CoV-2 pandemic has put healthcare systems worldwide\nto their limits, resulting in increased waiting time for diagnosis and required\nmedical assistance. With chest radiographs (CXR) being one of the most common\nCOVID-19 diagnosis methods, many artificial intelligence tools for image-based\nCOVID-19 detection have been developed, often trained on a small number of\nimages from COVID-19-positive patients. Thus, the need for high-quality and\nwell-annotated CXR image databases increased. This paper introduces POLCOVID\ndataset, containing chest X-ray (CXR) images of patients with COVID-19 or\nother-type pneumonia, and healthy individuals gathered from 15 Polish\nhospitals. The original radiographs are accompanied by the preprocessed images\nlimited to the lung area and the corresponding lung masks obtained with the\nsegmentation model. Moreover, the manually created lung masks are provided for\na part of POLCOVID dataset and the other four publicly available CXR image\ncollections. POLCOVID dataset can help in pneumonia or COVID-19 diagnosis,\nwhile the set of matched images and lung masks may serve for the development of\nlung segmentation solutions.",
    "descriptor": "\nComments: 12 pages, 3 figures\n",
    "authors": [
      "Aleksandra Suwalska",
      "Joanna Tobiasz",
      "Wojciech Prazuch",
      "Marek Socha",
      "Pawel Foszner",
      "Jerzy Jaroszewicz",
      "Katarzyna Gruszczynska",
      "Magdalena Sliwinska",
      "Jerzy Walecki",
      "Tadeusz Popiela",
      "Grzegorz Przybylski",
      "Mateusz Nowak",
      "Piotr Fiedor",
      "Malgorzata Pawlowska",
      "Robert Flisiak",
      "Krzysztof Simon",
      "Gabriela Zapolska",
      "Barbara Gizycka",
      "Edyta Szurowska",
      "Michal Marczyk",
      "Andrzej Cieszanowski",
      "Joanna Polanska"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.16359"
  },
  {
    "id": "arXiv:2211.16363",
    "title": "Analysis of constant-Q filterbank based representations for speech  emotion recognition",
    "abstract": "This work analyzes the constant-Q filterbank-based time-frequency\nrepresentations for speech emotion recognition (SER). Constant-Q filterbank\nprovides non-linear spectro-temporal representation with higher frequency\nresolution at low frequencies. Our investigation reveals how the increased\nlow-frequency resolution benefits SER. The time-domain comparative analysis\nbetween short-term mel-frequency spectral coefficients (MFSCs) and constant-Q\nfilterbank-based features, namely constant-Q transform (CQT) and continuous\nwavelet transform (CWT), reveals that constant-Q representations provide higher\ntime-invariance at low-frequencies. This provides increased robustness against\nemotion irrelevant temporal variations in pitch, especially for low-arousal\nemotions. The corresponding frequency-domain analysis over different emotion\nclasses shows better resolution of pitch harmonics in constant-Q-based\ntime-frequency representations than MFSC. These advantages of constant-Q\nrepresentations are further consolidated by SER performance in the extensive\nevaluation of features over four publicly available databases with six advanced\ndeep neural network architectures as the back-end classifiers. Our inferences\nin this study hint toward the suitability and potentiality of constant-Q\nfeatures for SER.",
    "descriptor": "\nComments: Accepted for publication in Elsevier's Digital Signal Processing Journal\n",
    "authors": [
      "Premjeet Singh",
      "Shefali Waldekar",
      "Md Sahidullah",
      "Goutam Saha"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.16363"
  },
  {
    "id": "arXiv:2211.16367",
    "title": "Optimisation of a global climate model ensemble for prediction of  extreme heat days",
    "abstract": "Adaptation-relevant predictions of climate change are often derived by\ncombining climate models in a multi-model ensemble. Model evaluation methods\nused in performance-based ensemble weighting schemes have limitations in the\ncontext of high-impact extreme events. We introduce a locally time-invariant\nmodel evaluation method with focus on assessing the simulation of extremes. We\nexplore the behaviour of the proposed method in predicting extreme heat days in\nNairobi.",
    "descriptor": "",
    "authors": [
      "Mala Virdee",
      "Emily Shuckburgh",
      "Carl Henrik Ek",
      "Ieva Kazlauskaite",
      "Markus Kaiser"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16367"
  },
  {
    "id": "arXiv:2211.16379",
    "title": "Elfs, trees and quantum walks",
    "abstract": "We study an elementary Markov process on graphs based on electric flow\nsampling (elfs). The elfs process repeatedly samples from an electric flow on a\ngraph. While the sinks of the flow are fixed, the source is updated using the\nelectric flow sample, and the process ends when it hits a sink vertex.\nWe argue that this process naturally connects to many key quantities of\ninterest. E.g., we describe a random walk coupling which implies that the elfs\nprocess has the same arrival distribution as a random walk. We also analyze the\nelectric hitting time, which is the expected time before the process hits a\nsink vertex. As our main technical contribution, we show that the electric\nhitting time on trees is logarithmic in the graph size and weights.\nThe initial motivation behind the elfs process is that quantum walks can\nsample from electric flows, and they can hence implement this process very\nnaturally. This yields a quantum walk algorithm for sampling from the random\nwalk arrival distribution, which has widespread applications. It complements\nthe existing line of quantum walk search algorithms which only return an\nelement from the sink, but yield no insight in the distribution of the returned\nelement. By our bound on the electric hitting time on trees, the quantum walk\nalgorithm on trees requires quadratically fewer steps than the random walk\nhitting time, up to polylog factors.",
    "descriptor": "",
    "authors": [
      "Simon Apers",
      "Stephen Piddock"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.16379"
  },
  {
    "id": "arXiv:2211.16384",
    "title": "Numerical Schemes for Effective Calibration of Elliptic and  Hypo-elliptic Diffusions",
    "abstract": "This work aims at making a comprehensive contribution in the general area of\nparametric inference for partially observed diffusion processes. Established\napproaches for likelihood-based estimation invoke a numerical\ntime-discretisation scheme for the approximation of the (typically intractable)\ntransition dynamics of the Stochastic Differential Equation (SDE) model over\nfinite time periods. The scheme is applied for a step-size that is either a\nuser-selected tuning parameter or determined by the data. Recent research has\nhighlighted the critical effect of the choice of numerical scheme on the\nbehaviour of derived parameter estimates in the setting of hypo-elliptic SDEs.\nIn brief, in our work, first, we develop two weak second order `sampling\nschemes' (to cover both the hypo-elliptic and elliptic SDE classes) and\ngenerate accompanying `transition density schemes' of the SDE (i.e.,\napproximations of the SDE transition density). Then, we produce a collection of\nanalytic results, providing a complete theoretical framework that solidifies\nthe proposed schemes and showcases advantages from their incorporation within\nSDE calibration methods. We present numerical results from carrying out\nclassical or Bayesian inference, for both elliptic and hypo-elliptic SDE\nmodels.",
    "descriptor": "",
    "authors": [
      "Yuga Iguchi",
      "Alexandros Beskos",
      "Matthew M. Graham"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.16384"
  },
  {
    "id": "arXiv:2211.16393",
    "title": "Bayesian Semiparametric Model for Sequential Treatment Decisions with  Informative Timing",
    "abstract": "We develop a Bayesian semi-parametric model for the estimating the impact of\ndynamic treatment rules on survival among patients diagnosed with pediatric\nacute myeloid leukemia (AML). The data consist of a subset of patients enrolled\nin the phase III AAML1031 clinical trial in which patients move through a\nsequence of four treatment courses. At each course, they undergo treatment that\nmay or may not include anthracyclines (ACT). While ACT is known to be effective\nat treating AML, it is also cardiotoxic and can lead to early death for some\npatients. Our task is to estimate the potential survival probability under\nhypothetical dynamic ACT treatment strategies, but there are several\nimpediments. First, since ACT was not randomized in the trial, its effect on\nsurvival is confounded over time. Second, subjects initiate the next course\ndepending on when they recover from the previous course, making timing\npotentially informative of subsequent treatment and survival. Third, patients\nmay die or drop out before ever completing the full treatment sequence. We\ndevelop a generative Bayesian semi-parametric model based on Gamma Process\npriors to address these complexities. At each treatment course, the model\ncaptures subjects' transition to subsequent treatment or death in continuous\ntime under a given rule. A g-computation procedure is used to compute a\nposterior over potential survival probability that is adjusted for time-varying\nconfounding. Using this approach, we conduct posterior inference for the\nefficacy of hypothetical treatment rules that dynamically modify ACT based on\nevolving cardiac function.",
    "descriptor": "",
    "authors": [
      "Arman Oganisian",
      "Kelly D. Getz",
      "Todd A. Alonzo",
      "Richard Aplenc",
      "Jason A. Roy"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.16393"
  },
  {
    "id": "arXiv:2211.16427",
    "title": "Multi-agent reinforcement learning for wall modeling in LES of flow over  periodic hills",
    "abstract": "We develop a wall model for large-eddy simulation (LES) that takes into\naccount various pressure-gradient effects using multi-agent reinforcement\nlearning (MARL). The model is trained using low-Reynolds-number flow over\nperiodic hills with agents distributed on the wall along the computational grid\npoints. The model utilizes a wall eddy-viscosity formulation as the boundary\ncondition, which is shown to provide better predictions of the mean velocity\nfield, rather than the typical wall-shear stress formulation. Each agent\nreceives states based on local instantaneous flow quantities at an off-wall\nlocation, computes a reward based on the estimated wall-shear stress, and\nprovides an action to update the wall eddy viscosity at each time step. The\ntrained wall model is validated in wall-modeled LES (WMLES) of flow over\nperiodic hills at higher Reynolds numbers, and the results show the\neffectiveness of the model on flow with pressure gradients. The analysis of the\ntrained model indicates that the model is capable of distinguishing between the\nvarious pressure gradient regimes present in the flow.",
    "descriptor": "",
    "authors": [
      "Di Zhou",
      "Michael P. Whitmore",
      "Kevin P. Griffin",
      "H. Jane Bae"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.16427"
  },
  {
    "id": "arXiv:2211.16442",
    "title": "An Approximation Algorithm for Indefinite Mixed Integer Quadratic  Programming",
    "abstract": "In this paper, we give an algorithm that finds an epsilon-approximate\nsolution to a mixed integer quadratic programming (MIQP) problem. The algorithm\nruns in polynomial time if the rank of the quadratic function and the number of\ninteger variables are fixed. The running time of the algorithm is expected\nunless P=NP. In order to design this algorithm we introduce the novel concepts\nof spherical form MIQP and of aligned vectors, and we provide a number of\nresults of independent interest. In particular, we give a strongly polynomial\nalgorithm to find a symmetric decomposition of a matrix, and show a related\nresult on simultaneous diagonalization of matrices.",
    "descriptor": "",
    "authors": [
      "Alberto Del Pia"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.16442"
  },
  {
    "id": "arXiv:2211.16443",
    "title": "Synthetic data enable experiments in atomistic machine learning",
    "abstract": "Machine-learning models are increasingly used to predict properties of atoms\nin chemical systems. There have been major advances in developing descriptors\nand regression frameworks for this task, typically starting from (relatively)\nsmall sets of quantum-mechanical reference data. Larger datasets of this kind\nare becoming available, but remain expensive to generate. Here we demonstrate\nthe use of a large dataset that we have \"synthetically\" labelled with per-atom\nenergies from an existing ML potential model. The cheapness of this process,\ncompared to the quantum-mechanical ground truth, allows us to generate millions\nof datapoints, in turn enabling rapid experimentation with atomistic ML models\nfrom the small- to the large-data regime. This approach allows us here to\ncompare regression frameworks in depth, and to explore visualisation based on\nlearned representations. We also show that learning synthetic data labels can\nbe a useful pre-training task for subsequent fine-tuning on small datasets. In\nthe future, we expect that our open-sourced dataset, and similar ones, will be\nuseful in rapidly exploring deep-learning models in the limit of abundant\nchemical data.",
    "descriptor": "",
    "authors": [
      "John L. A. Gardner",
      "Zo\u00e9 Faure Beaulieu",
      "Volker L. Deringer"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16443"
  },
  {
    "id": "arXiv:2211.16454",
    "title": "Local canonical labeling of Erd\u0151s--R\u00e9nyi random graphs",
    "abstract": "We study local canonical labeling algorithms on an Erd\\H{o}s--R\\'enyi random\ngraph $G(n,p_n)$. A canonical labeling algorithm assigns a unique label to each\nvertex of an unlabeled graph such that the labels are invariant under\nisomorphism. Here we focus on local algorithms, where the label of each vertex\ndepends only on its low-depth neighborhood. Czajka and Pandurangan showed that\nthe degree profile of a vertex (i.e., the sorted list of the degrees of its\nneighbors) gives a canonical labeling with high probability when $n p_n =\n\\omega( \\log^{4}(n) / \\log \\log n )$ (and $p_{n} \\leq 1/2$); subsequently,\nMossel and Ross showed that the same holds when $n p_n = \\omega( \\log^{2}(n)\n)$. Our first result shows that their analysis essentially cannot be improved:\nwe prove that when $n p_n = o( \\log^{2}(n) / (\\log \\log n)^{3} )$, with high\nprobability there exist distinct vertices with isomorphic $2$-neighborhoods.\nOur main result is a positive counterpart to this, showing that\n$3$-neighborhoods give a canonical labeling when $n p_n \\geq (1+\\delta) \\log n$\n(and $p_n \\leq 1/2$); this improves a recent result of Ding, Ma, Wu, and Xu,\ncompleting the picture above the connectivity threshold. We also discuss\nimplications for random graph isomorphism and shotgun assembly of random\ngraphs.",
    "descriptor": "\nComments: 20 pages, 2 figures\n",
    "authors": [
      "Julia Gaudio",
      "Mikl\u00f3s Z. R\u00e1cz",
      "Anirudh Sridhar"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.16454"
  },
  {
    "id": "arXiv:2211.16467",
    "title": "Linear Causal Disentanglement via Interventions",
    "abstract": "Causal disentanglement seeks a representation of data involving latent\nvariables that relate to one another via a causal model. A representation is\nidentifiable if both the latent model and the transformation from latent to\nobserved variables are unique. In this paper, we study observed variables that\nare a linear transformation of a linear latent causal model. Data from\ninterventions are necessary for identifiability: if one latent variable is\nmissing an intervention, we show that there exist distinct models that cannot\nbe distinguished. Conversely, we show that a single intervention on each latent\nvariable is sufficient for identifiability. Our proof uses a generalization of\nthe RQ decomposition of a matrix that replaces the usual orthogonal and upper\ntriangular conditions with analogues depending on a partial order on the rows\nof the matrix, with partial order determined by a latent causal model. We\ncorroborate our theoretical results with a method for causal disentanglement\nthat accurately recovers a latent causal model.",
    "descriptor": "",
    "authors": [
      "Anna Seigal",
      "Chandler Squires",
      "Caroline Uhler"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16467"
  },
  {
    "id": "arXiv:2211.16469",
    "title": "Communication Trade Offs in Intermediate Qudit Circuits",
    "abstract": "Quantum computing promises speedup of classical algorithms in the long term.\nCurrent hardware is unable to support this goal and programs must be\nefficiently compiled to use of the devices through reduction of qubits used,\ngate count and circuit duration.\nMany quantum systems have access to higher levels, expanding the\ncomputational space for a device. We develop higher level qudit communication\ncircuits, compilation pipelines, and circuits that take advantage of this extra\nspace by temporarily pushing qudits into these higher levels. We show how these\nmethods are able to more efficiently use the device, and where they see\ndiminishing returns.",
    "descriptor": "\nComments: 7 pages, 9 Figures, In ISVML22: 2022 IEEE 52nd International Symposium on Multiple-Valued Logic\n",
    "authors": [
      "Andrew Litteken",
      "Jonathan M. Baker",
      "Frederic T. Chong"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Hardware Architecture (cs.AR)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2211.16469"
  },
  {
    "id": "arXiv:2211.16486",
    "title": "AdsorbML: Accelerating Adsorption Energy Calculations with Machine  Learning",
    "abstract": "Computational catalysis is playing an increasingly significant role in the\ndesign of catalysts across a wide range of applications. A common task for many\ncomputational methods is the need to accurately compute the minimum binding\nenergy - the adsorption energy - for an adsorbate and a catalyst surface of\ninterest. Traditionally, the identification of low energy adsorbate-surface\nconfigurations relies on heuristic methods and researcher intuition. As the\ndesire to perform high-throughput screening increases, it becomes challenging\nto use heuristics and intuition alone. In this paper, we demonstrate machine\nlearning potentials can be leveraged to identify low energy adsorbate-surface\nconfigurations more accurately and efficiently. Our algorithm provides a\nspectrum of trade-offs between accuracy and efficiency, with one balanced\noption finding the lowest energy configuration, within a 0.1 eV threshold,\n86.63% of the time, while achieving a 1387x speedup in computation. To\nstandardize benchmarking, we introduce the Open Catalyst Dense dataset\ncontaining nearly 1,000 diverse surfaces and 87,045 unique configurations.",
    "descriptor": "\nComments: 20 pages, 5 figures\n",
    "authors": [
      "Janice Lan",
      "Aini Palizhati",
      "Muhammed Shuaibi",
      "Brandon M. Wood",
      "Brook Wander",
      "Abhishek Das",
      "Matt Uyttendaele",
      "C. Lawrence Zitnick",
      "Zachary W. Ulissi"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.16486"
  },
  {
    "id": "arXiv:1805.11854",
    "title": "Convergence rates of nonlinear inverse problems in Banach spaces:  conditional stability and weaker norms",
    "abstract": "Comments: 09 pages",
    "descriptor": "\nComments: 09 pages\n",
    "authors": [
      "Gaurav Mittal",
      "Ankik Kumar Giri"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1805.11854"
  },
  {
    "id": "arXiv:1808.09670",
    "title": "Proximal boosting: aggregating weak learners to minimize  non-differentiable losses",
    "abstract": "Proximal boosting: aggregating weak learners to minimize  non-differentiable losses",
    "descriptor": "",
    "authors": [
      "Erwan Fouillen",
      "Claire Boyer",
      "Maxime Sangnier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1808.09670"
  },
  {
    "id": "arXiv:1907.10586",
    "title": "Distilled Siamese Networks for Visual Tracking",
    "abstract": "Comments: Accepted by IEEE T-PAMI",
    "descriptor": "\nComments: Accepted by IEEE T-PAMI\n",
    "authors": [
      "Jianbing Shen",
      "Yuanpei Liu",
      "Xingping Dong",
      "Xiankai Lu",
      "Fahad Shahbaz Khan",
      "Steven Hoi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1907.10586"
  },
  {
    "id": "arXiv:1912.04800",
    "title": "Approximate Strategyproofness in Large, Two-Sided Matching Markets",
    "abstract": "Approximate Strategyproofness in Large, Two-Sided Matching Markets",
    "descriptor": "",
    "authors": [
      "Lars Lien Ankile",
      "Kjartan Krange",
      "Yuto Yagi"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/1912.04800"
  },
  {
    "id": "arXiv:2002.05651",
    "title": "Towards the Systematic Reporting of the Energy and Carbon Footprints of  Machine Learning",
    "abstract": "Comments: Published in JMLR: this https URL",
    "descriptor": "\nComments: Published in JMLR: this https URL\n",
    "authors": [
      "Peter Henderson",
      "Jieru Hu",
      "Joshua Romoff",
      "Emma Brunskill",
      "Dan Jurafsky",
      "Joelle Pineau"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2002.05651"
  },
  {
    "id": "arXiv:2004.00891",
    "title": "Kernel Autocovariance Operators of Stationary Processes: Estimation and  Convergence",
    "abstract": "Kernel Autocovariance Operators of Stationary Processes: Estimation and  Convergence",
    "descriptor": "",
    "authors": [
      "Mattes Mollenhauer",
      "Stefan Klus",
      "Christof Sch\u00fctte",
      "P\u00e9ter Koltai"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.00891"
  },
  {
    "id": "arXiv:2006.15578",
    "title": "Generalisable 3D Fabric Architecture for Streamlined Universal  Multi-Dataset Medical Image Segmentation",
    "abstract": "Generalisable 3D Fabric Architecture for Streamlined Universal  Multi-Dataset Medical Image Segmentation",
    "descriptor": "",
    "authors": [
      "Siyu Liu",
      "Wei Dai",
      "Craig Engstrom",
      "Jurgen Fripp",
      "Stuart Crozier",
      "Jason A. Dowling",
      "Shekhar S. Chandra"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2006.15578"
  },
  {
    "id": "arXiv:2007.02777",
    "title": "Parametric machines: a fresh approach to architecture search",
    "abstract": "Comments: 28 pages, 4 figures",
    "descriptor": "\nComments: 28 pages, 4 figures\n",
    "authors": [
      "Pietro Vertechi",
      "Mattia G. Bergomi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.02777"
  },
  {
    "id": "arXiv:2010.06631",
    "title": "Succinct Explanations With Cascading Decision Trees",
    "abstract": "Succinct Explanations With Cascading Decision Trees",
    "descriptor": "",
    "authors": [
      "Jialu Zhang",
      "Yitan Wang",
      "Mark Santolucito",
      "Ruzica Piskac"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2010.06631"
  },
  {
    "id": "arXiv:2011.12151",
    "title": "Tensor Kernel Recovery for Spatio-Temporal Hawkes Processes",
    "abstract": "Comments: 24 pages",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Heejune Sheen",
      "Xiaonan Zhu",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.12151"
  },
  {
    "id": "arXiv:2012.09804",
    "title": "Maximum cut on interval graphs of interval count four is NP-complete",
    "abstract": "Maximum cut on interval graphs of interval count four is NP-complete",
    "descriptor": "",
    "authors": [
      "Celina M. H. de Figueiredo",
      "Alexsander A. de Melo",
      "Fabiano S. Oliveira",
      "Ana Silva"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2012.09804"
  },
  {
    "id": "arXiv:2012.11965",
    "title": "Tractable Orders for Direct Access to Ranked Answers of Conjunctive  Queries",
    "abstract": "Comments: 44 pages",
    "descriptor": "\nComments: 44 pages\n",
    "authors": [
      "Nofar Carmeli",
      "Nikolaos Tziavelis",
      "Wolfgang Gatterbauer",
      "Benny Kimelfeld",
      "Mirek Riedewald"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2012.11965"
  },
  {
    "id": "arXiv:2101.02246",
    "title": "Safer Motion Planning of Steerable Needles via a Shaft-to-Tissue Force  Model",
    "abstract": "Comments: 17 pages, 12 figures, preprint of an article submitted for consideration in Journal of Medical Robotics Research (JMRR) in 2022",
    "descriptor": "\nComments: 17 pages, 12 figures, preprint of an article submitted for consideration in Journal of Medical Robotics Research (JMRR) in 2022\n",
    "authors": [
      "Michael Bentley",
      "Caleb Rucker",
      "Chakravarthy Reddy",
      "Oren Salzman",
      "Alan Kuntz"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2101.02246"
  },
  {
    "id": "arXiv:2103.06615",
    "title": "Controlled Gaussian Process Dynamical Models with Application to Robotic  Cloth Manipulation",
    "abstract": "Controlled Gaussian Process Dynamical Models with Application to Robotic  Cloth Manipulation",
    "descriptor": "",
    "authors": [
      "Fabio Amadio",
      "Juan Antonio Delgado-Guerrero",
      "Adri\u00e0 Colom\u00e9",
      "Carme Torras"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.06615"
  },
  {
    "id": "arXiv:2103.12434",
    "title": "Recent Ice Trends in Swiss Mountain Lakes: 20-year Analysis of MODIS  Imagery",
    "abstract": "Comments: This version of the article has been accepted for publication, after peer review but is not the Version of Record and does not reflect post-acceptance improvements, or any corrections. The Version of Record is available online at: this http URL",
    "descriptor": "\nComments: This version of the article has been accepted for publication, after peer review but is not the Version of Record and does not reflect post-acceptance improvements, or any corrections. The Version of Record is available online at: this http URL\n",
    "authors": [
      "Manu Tom",
      "Tianyu Wu",
      "Emmanuel Baltsavias",
      "Konrad Schindler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.12434"
  },
  {
    "id": "arXiv:2104.01231",
    "title": "Diverse Gaussian Noise Consistency Regularization for Robustness and  Uncertainty Calibration",
    "abstract": "Comments: Under review. Preliminary version accepted to ICML 2021 Uncertainty & Robustness in Deep Learning Workshop",
    "descriptor": "\nComments: Under review. Preliminary version accepted to ICML 2021 Uncertainty & Robustness in Deep Learning Workshop\n",
    "authors": [
      "Theodoros Tsiligkaridis",
      "Athanasios Tsiligkaridis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2104.01231"
  },
  {
    "id": "arXiv:2104.10267",
    "title": "On reduction and normalization in the computational core",
    "abstract": "On reduction and normalization in the computational core",
    "descriptor": "",
    "authors": [
      "Claudia Faggian",
      "Giulio Guerrieri",
      "Ugo de'Liguoro",
      "Riccardo Treglia"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2104.10267"
  },
  {
    "id": "arXiv:2104.12928",
    "title": "If your data distribution shifts, use self-learning",
    "abstract": "Comments: Web: this https URL",
    "descriptor": "\nComments: Web: this https URL\n",
    "authors": [
      "Evgenia Rusak",
      "Steffen Schneider",
      "George Pachitariu",
      "Luisa Eck",
      "Peter Gehler",
      "Oliver Bringmann",
      "Wieland Brendel",
      "Matthias Bethge"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.12928"
  },
  {
    "id": "arXiv:2105.00769",
    "title": "Partial Information Decomposition via Deficiency for Multivariate  Gaussians",
    "abstract": "Comments: Presented at ISIT 2022. This version has been updated to reflect the final conference publication, including appendices. It also corrects technical errors in Remark 1 and Appendix C, adds a new experiment, and has a substantially improved presentation as well as additional detail in the appendix, compared to the previous arxiv version",
    "descriptor": "\nComments: Presented at ISIT 2022. This version has been updated to reflect the final conference publication, including appendices. It also corrects technical errors in Remark 1 and Appendix C, adds a new experiment, and has a substantially improved presentation as well as additional detail in the appendix, compared to the previous arxiv version\n",
    "authors": [
      "Praveen Venkatesh",
      "Gabriel Schamberg"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2105.00769"
  },
  {
    "id": "arXiv:2106.03097",
    "title": "Preservation of the Global Knowledge by Not-True Distillation in  Federated Learning",
    "abstract": "Comments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)",
    "descriptor": "\nComments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Gihun Lee",
      "Minchan Jeong",
      "Yongjin Shin",
      "Sangmin Bae",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.03097"
  },
  {
    "id": "arXiv:2106.11929",
    "title": "Joint Deep Reversible Regression Model and Physics-Informed Unsupervised  Learning for Temperature Field Reconstruction",
    "abstract": "Comments: Accepted by Engineering Applications of Artificial Intelligence",
    "descriptor": "\nComments: Accepted by Engineering Applications of Artificial Intelligence\n",
    "authors": [
      "Zhiqiang Gong",
      "Weien Zhou",
      "Jun Zhang",
      "Wei Peng",
      "Wen Yao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.11929"
  },
  {
    "id": "arXiv:2107.00211",
    "title": "A Few Interactions Improve Distributed Nonparametric Estimation,  Optimally",
    "abstract": "Comments: Revised to improve the presentation of the paper and correct minor mistakes",
    "descriptor": "\nComments: Revised to improve the presentation of the paper and correct minor mistakes\n",
    "authors": [
      "Jingbo Liu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2107.00211"
  },
  {
    "id": "arXiv:2107.01153",
    "title": "A Survey on Deep Learning Technique for Video Segmentation",
    "abstract": "Comments: Accepted by TPAMI. Website: this https URL",
    "descriptor": "\nComments: Accepted by TPAMI. Website: this https URL\n",
    "authors": [
      "Tianfei Zhou",
      "Fatih Porikli",
      "David Crandall",
      "Luc Van Gool",
      "Wenguan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2107.01153"
  },
  {
    "id": "arXiv:2107.02654",
    "title": "Adaptive Parameters tuning based on energy-preserving splitting  integration for Hamiltonian Monte Carlo Method",
    "abstract": "Adaptive Parameters tuning based on energy-preserving splitting  integration for Hamiltonian Monte Carlo Method",
    "descriptor": "",
    "authors": [
      "F. Diele",
      "C.Marangi",
      "C. Tamborrino",
      "C. Tarantino"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.02654"
  },
  {
    "id": "arXiv:2107.05128",
    "title": "Karchmer-Wigderson Games for Hazard-free Computation",
    "abstract": "Comments: 34 pages, To appear in ITCS 2023",
    "descriptor": "\nComments: 34 pages, To appear in ITCS 2023\n",
    "authors": [
      "Christian Ikenmeyer",
      "Balagopal Komarath",
      "Nitin Saurabh"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2107.05128"
  },
  {
    "id": "arXiv:2107.09092",
    "title": "Learning a Joint Embedding of Multiple Satellite Sensors: A Case Study  for Lake Ice Monitoring",
    "abstract": "Learning a Joint Embedding of Multiple Satellite Sensors: A Case Study  for Lake Ice Monitoring",
    "descriptor": "",
    "authors": [
      "Manu Tom",
      "Yuchang Jiang",
      "Emmanuel Baltsavias",
      "Konrad Schindler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2107.09092"
  },
  {
    "id": "arXiv:2107.10057",
    "title": "A linear Galerkin numerical method for a quasilinear subdiffusion  equation",
    "abstract": "Comments: This is the accepted version of the manuscript published in Applied Numerical Mathematics",
    "descriptor": "\nComments: This is the accepted version of the manuscript published in Applied Numerical Mathematics\n",
    "authors": [
      "\u0141ukasz P\u0142ociniczak"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.10057"
  },
  {
    "id": "arXiv:2107.14022",
    "title": "Ann wins the nonrepetitive game over four letters and the  erase-repetition game over six letters",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2104.09965",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2104.09965\n",
    "authors": [
      "Matthieu Rosenfeld"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2107.14022"
  },
  {
    "id": "arXiv:2108.12647",
    "title": "An axiomatic characterization of mutual information",
    "abstract": "Comments: No figures, no logarithms",
    "descriptor": "\nComments: No figures, no logarithms\n",
    "authors": [
      "James Fullwood"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2108.12647"
  },
  {
    "id": "arXiv:2109.00084",
    "title": "Program Merge Conflict Resolution via Neural Transformers",
    "abstract": "Comments: ESEC/FSE '22 camera ready version. 12 pages, 4 figures, online appendix",
    "descriptor": "\nComments: ESEC/FSE '22 camera ready version. 12 pages, 4 figures, online appendix\n",
    "authors": [
      "Alexey Svyatkovskiy",
      "Sarah Fakhoury",
      "Negar Ghorbani",
      "Todd Mytkowicz",
      "Elizabeth Dinella",
      "Christian Bird",
      "Jinu Jang",
      "Neel Sundaresan",
      "Shuvendu Lahiri"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.00084"
  },
  {
    "id": "arXiv:2109.12516",
    "title": "Prioritized Experience-based Reinforcement Learning with Human Guidance  for Autonomous Driving",
    "abstract": "Prioritized Experience-based Reinforcement Learning with Human Guidance  for Autonomous Driving",
    "descriptor": "",
    "authors": [
      "Jingda Wu",
      "Zhiyu Huang",
      "Wenhui Huang",
      "Chen Lv"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.12516"
  },
  {
    "id": "arXiv:2109.14420",
    "title": "FastCorrect 2: Fast Error Correction on Multiple Candidates for  Automatic Speech Recognition",
    "abstract": "Comments: Findings of EMNLP 2021",
    "descriptor": "\nComments: Findings of EMNLP 2021\n",
    "authors": [
      "Yichong Leng",
      "Xu Tan",
      "Rui Wang",
      "Linchen Zhu",
      "Jin Xu",
      "Wenjie Liu",
      "Linquan Liu",
      "Tao Qin",
      "Xiang-Yang Li",
      "Edward Lin",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2109.14420"
  },
  {
    "id": "arXiv:2110.01732",
    "title": "A faster algorithm for counting the integer points number in  $\u0394$-modular polyhedra",
    "abstract": "A faster algorithm for counting the integer points number in  $\u0394$-modular polyhedra",
    "descriptor": "",
    "authors": [
      "D. V. Gribanov",
      "D. S. Malyshev"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.01732"
  },
  {
    "id": "arXiv:2110.05388",
    "title": "Quantitative Equality in Substructural Logic via Lipschitz Doctrines",
    "abstract": "Quantitative Equality in Substructural Logic via Lipschitz Doctrines",
    "descriptor": "",
    "authors": [
      "Francesco Dagnino",
      "Fabio Pasquali"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2110.05388"
  },
  {
    "id": "arXiv:2110.07178",
    "title": "Symbolic Knowledge Distillation: from General Language Models to  Commonsense Models",
    "abstract": "Symbolic Knowledge Distillation: from General Language Models to  Commonsense Models",
    "descriptor": "",
    "authors": [
      "Peter West",
      "Chandra Bhagavatula",
      "Jack Hessel",
      "Jena D. Hwang",
      "Liwei Jiang",
      "Ronan Le Bras",
      "Ximing Lu",
      "Sean Welleck",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.07178"
  },
  {
    "id": "arXiv:2110.11940",
    "title": "Logical Activation Functions: Logit-space equivalents of Probabilistic  Boolean Operators",
    "abstract": "Logical Activation Functions: Logit-space equivalents of Probabilistic  Boolean Operators",
    "descriptor": "",
    "authors": [
      "Scott C. Lowe",
      "Robert Earle",
      "Jason d'Eon",
      "Thomas Trappenberg",
      "Sageev Oore"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.11940"
  },
  {
    "id": "arXiv:2110.15108",
    "title": "Multi-Class Anomaly Detection",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Suresh Singh",
      "Minwei Luo",
      "Yu Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15108"
  },
  {
    "id": "arXiv:2111.04279",
    "title": "Batch Reinforcement Learning from Crowds",
    "abstract": "Comments: 16 pages. Accepted by ECML-PKDD 2022",
    "descriptor": "\nComments: 16 pages. Accepted by ECML-PKDD 2022\n",
    "authors": [
      "Guoxi Zhang",
      "Hisashi Kashima"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.04279"
  },
  {
    "id": "arXiv:2111.05995",
    "title": "Parallel Quantum Annealing",
    "abstract": "Comments: 13 pages. v4: format improvements",
    "descriptor": "\nComments: 13 pages. v4: format improvements\n",
    "authors": [
      "Elijah Pelofske",
      "Georg Hahn",
      "Hristo N. Djidjev"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2111.05995"
  },
  {
    "id": "arXiv:2111.06079",
    "title": "Cops and robber on subclasses of $P_5$-free graphs",
    "abstract": "Cops and robber on subclasses of $P_5$-free graphs",
    "descriptor": "",
    "authors": [
      "Uttam K. Gupta",
      "Suchismita Mishra",
      "Dinabandhu Pradhan"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2111.06079"
  },
  {
    "id": "arXiv:2111.09692",
    "title": "SUB-Depth: Self-distillation and Uncertainty Boosting Self-supervised  Monocular Depth Estimation",
    "abstract": "Comments: bmvc version",
    "descriptor": "\nComments: bmvc version\n",
    "authors": [
      "Hang Zhou",
      "Sarah Taylor",
      "David Greenwood",
      "Michal Mackiewicz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.09692"
  },
  {
    "id": "arXiv:2111.11745",
    "title": "Intriguing Findings of Frequency Selection for Image Deblurring",
    "abstract": "Comments: AAAI 2023",
    "descriptor": "\nComments: AAAI 2023\n",
    "authors": [
      "Xintian Mao",
      "Yiming Liu",
      "Fengze Liu",
      "Qingli Li",
      "Wei Shen",
      "Yan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.11745"
  },
  {
    "id": "arXiv:2111.14843",
    "title": "Catch Me If You Hear Me: Audio-Visual Navigation in Complex Unmapped  Environments with Moving Sounds",
    "abstract": "Catch Me If You Hear Me: Audio-Visual Navigation in Complex Unmapped  Environments with Moving Sounds",
    "descriptor": "",
    "authors": [
      "Abdelrahman Younes",
      "Daniel Honerkamp",
      "Tim Welschehold",
      "Abhinav Valada"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.14843"
  },
  {
    "id": "arXiv:2112.05856",
    "title": "An Adaptive Bounded-Confidence Model of Opinion Dynamics on Networks",
    "abstract": "Comments: accepted by Journal of Complex Networks; further cosmetic polishing from the last version",
    "descriptor": "\nComments: accepted by Journal of Complex Networks; further cosmetic polishing from the last version\n",
    "authors": [
      "Unchitta Kan",
      "Michelle Feng",
      "Mason A. Porter"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Dynamical Systems (math.DS)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2112.05856"
  },
  {
    "id": "arXiv:2112.06833",
    "title": "Beyond Ads: Sequential Decision-Making Algorithms in Law and Public  Policy",
    "abstract": "Comments: Version 1 presented at Causal Inference Challenges in Sequential Decision Making: Bridging Theory and Practice (2021), a NeurIPS 2021 Workshop; Version 2 presented at the 2nd ACM Symposium on Computer Science and Law (2022) (DOI: this https URL)",
    "descriptor": "\nComments: Version 1 presented at Causal Inference Challenges in Sequential Decision Making: Bridging Theory and Practice (2021), a NeurIPS 2021 Workshop; Version 2 presented at the 2nd ACM Symposium on Computer Science and Law (2022) (DOI: this https URL)\n",
    "authors": [
      "Peter Henderson",
      "Ben Chugg",
      "Brandon Anderson",
      "Daniel E. Ho"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2112.06833"
  },
  {
    "id": "arXiv:2112.08359",
    "title": "3D Question Answering",
    "abstract": "Comments: To Appear at IEEE Transactions on Visualization and Computer Graphics (TVCG) 2022",
    "descriptor": "\nComments: To Appear at IEEE Transactions on Visualization and Computer Graphics (TVCG) 2022\n",
    "authors": [
      "Shuquan Ye",
      "Dongdong Chen",
      "Songfang Han",
      "Jing Liao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.08359"
  },
  {
    "id": "arXiv:2112.09093",
    "title": "Network Realization Functions for Optimal Distributed Control",
    "abstract": "Comments: 12 pages, 6 figures, 1 table",
    "descriptor": "\nComments: 12 pages, 6 figures, 1 table\n",
    "authors": [
      "\u015eerban Sab\u0103u",
      "Andrei Speril\u0103",
      "Cristian Oar\u0103",
      "Ali Jadbabaie"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.09093"
  },
  {
    "id": "arXiv:2112.09162",
    "title": "Nonparametric Two-Sample Testing by Betting",
    "abstract": "Comments: 47 pages, 3 figures",
    "descriptor": "\nComments: 47 pages, 3 figures\n",
    "authors": [
      "Shubhanshu Shekhar",
      "Aaditya Ramdas"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2112.09162"
  },
  {
    "id": "arXiv:2112.12883",
    "title": "Backhaul-aware Drone Base Station Placement and Resource Management for  FSO-based Drone-assisted Mobile Networks",
    "abstract": "Backhaul-aware Drone Base Station Placement and Resource Management for  FSO-based Drone-assisted Mobile Networks",
    "descriptor": "",
    "authors": [
      "Liangkun Yu",
      "Xiang Sun",
      "Sihua Shao",
      "Yougan Chen",
      "Rana Albelaihi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2112.12883"
  },
  {
    "id": "arXiv:2112.13121",
    "title": "The Curse of Zero Task Diversity: On the Failure of Transfer Learning to  Outperform MAML and their Empirical Equivalence",
    "abstract": "Comments: An updated version with updated correction is at arXiv:2208.01545 and it's acompanying neurips submission is at this https URL",
    "descriptor": "\nComments: An updated version with updated correction is at arXiv:2208.01545 and it's acompanying neurips submission is at this https URL\n",
    "authors": [
      "Brando Miranda",
      "Yu-Xiong Wang",
      "Sanmi Koyejo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.13121"
  },
  {
    "id": "arXiv:2201.00308",
    "title": "DiffuseVAE: Efficient, Controllable and High-Fidelity Generation from  Low-Dimensional Latents",
    "abstract": "Comments: 12 pages main content. Camera-Ready version accepted at Transactions on Machine Learning Research",
    "descriptor": "\nComments: 12 pages main content. Camera-Ready version accepted at Transactions on Machine Learning Research\n",
    "authors": [
      "Kushagra Pandey",
      "Avideep Mukherjee",
      "Piyush Rai",
      "Abhishek Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.00308"
  },
  {
    "id": "arXiv:2201.08518",
    "title": "Optimal variance-reduced stochastic approximation in Banach spaces",
    "abstract": "Optimal variance-reduced stochastic approximation in Banach spaces",
    "descriptor": "",
    "authors": [
      "Wenlong Mou",
      "Koulik Khamaru",
      "Martin J. Wainwright",
      "Peter L. Bartlett",
      "Michael I. Jordan"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.08518"
  },
  {
    "id": "arXiv:2201.08988",
    "title": "Faster Algorithms for Sparse ILP and Hypergraph  Multi-Packing/Multi-Cover Problems",
    "abstract": "Faster Algorithms for Sparse ILP and Hypergraph  Multi-Packing/Multi-Cover Problems",
    "descriptor": "",
    "authors": [
      "Dmitry Gribanov",
      "Dmitry Malyshev",
      "Nikolai Zolotykh"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2201.08988"
  },
  {
    "id": "arXiv:2202.01113",
    "title": "Tailoring Gradient Methods for Differentially-Private Distributed  Optimization",
    "abstract": "Tailoring Gradient Methods for Differentially-Private Distributed  Optimization",
    "descriptor": "",
    "authors": [
      "Yongqiang Wang",
      "Angelia Nedic"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.01113"
  },
  {
    "id": "arXiv:2202.01793",
    "title": "Incorporating Sum Constraints into Multitask Gaussian Processes",
    "abstract": "Incorporating Sum Constraints into Multitask Gaussian Processes",
    "descriptor": "",
    "authors": [
      "Philipp Pilar",
      "Carl Jidling",
      "Thomas B. Sch\u00f6n",
      "Niklas Wahlstr\u00f6m"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01793"
  },
  {
    "id": "arXiv:2202.04520",
    "title": "Obtaining Dyadic Fairness by Optimal Transport",
    "abstract": "Obtaining Dyadic Fairness by Optimal Transport",
    "descriptor": "",
    "authors": [
      "Moyi Yang",
      "Junjie Sheng",
      "Xiangfeng Wang",
      "Wenyan Liu",
      "Bo Jin",
      "Jun Wang",
      "Hongyuan Zha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04520"
  },
  {
    "id": "arXiv:2202.06383",
    "title": "Surgical Scheduling via Optimization and Machine Learning with  Long-Tailed Data",
    "abstract": "Surgical Scheduling via Optimization and Machine Learning with  Long-Tailed Data",
    "descriptor": "",
    "authors": [
      "Yuan Shi",
      "Saied Mahdian",
      "Jose Blanchet",
      "Peter Glynn",
      "Andrew Y. Shin",
      "David Scheinker"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.06383"
  },
  {
    "id": "arXiv:2202.06949",
    "title": "Consensus Division in an Arbitrary Ratio",
    "abstract": "Comments: Accepted to ITCS 2023",
    "descriptor": "\nComments: Accepted to ITCS 2023\n",
    "authors": [
      "Paul W. Goldberg",
      "Jiawei Li"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.06949"
  },
  {
    "id": "arXiv:2202.07105",
    "title": "A Survey on Model Compression and Acceleration for Pretrained Language  Models",
    "abstract": "Comments: Accepted to AAAI 2023",
    "descriptor": "\nComments: Accepted to AAAI 2023\n",
    "authors": [
      "Canwen Xu",
      "Julian McAuley"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07105"
  },
  {
    "id": "arXiv:2202.07123",
    "title": "Rethinking Network Design and Local Geometry in Point Cloud: A Simple  Residual MLP Framework",
    "abstract": "Comments: Accepted by ICLR 2022. Codes are made publically available at this https URL; updated some errors",
    "descriptor": "\nComments: Accepted by ICLR 2022. Codes are made publically available at this https URL; updated some errors\n",
    "authors": [
      "Xu Ma",
      "Can Qin",
      "Haoxuan You",
      "Haoxi Ran",
      "Yun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07123"
  },
  {
    "id": "arXiv:2202.08712",
    "title": "Mining On Alzheimer's Diseases Related Knowledge Graph to Identity  Potential AD-related Semantic Triples for Drug Repurposing",
    "abstract": "Comments: BMC Bioinformatics",
    "descriptor": "\nComments: BMC Bioinformatics\n",
    "authors": [
      "Yi Nian",
      "Xinyue Hu",
      "Rui Zhang",
      "Jingna Feng",
      "Jingcheng Du",
      "Fang Li",
      "Yong Chen",
      "Cui Tao"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.08712"
  },
  {
    "id": "arXiv:2202.11908",
    "title": "Learning Program Synthesis for Integer Sequences from Scratch",
    "abstract": "Learning Program Synthesis for Integer Sequences from Scratch",
    "descriptor": "",
    "authors": [
      "Thibault Gauthier",
      "Josef Urban"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2202.11908"
  },
  {
    "id": "arXiv:2202.13388",
    "title": "PanoFlow: Learning 360\u00b0 Optical Flow for Surrounding Temporal  Understanding",
    "abstract": "Comments: Code and dataset are publicly available at this https URL",
    "descriptor": "\nComments: Code and dataset are publicly available at this https URL\n",
    "authors": [
      "Hao Shi",
      "Yifan Zhou",
      "Kailun Yang",
      "Xiaoting Yin",
      "Ze Wang",
      "Yaozu Ye",
      "Zhe Yin",
      "Shi Meng",
      "Peng Li",
      "Kaiwei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.13388"
  },
  {
    "id": "arXiv:2203.00807",
    "title": "InCloud: Incremental Learning for Point Cloud Place Recognition",
    "abstract": "Comments: 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022)",
    "descriptor": "\nComments: 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022)\n",
    "authors": [
      "Joshua Knights",
      "Peyman Moghadam",
      "Milad Ramezani",
      "Sridha Sridharan",
      "Clinton Fookes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.00807"
  },
  {
    "id": "arXiv:2203.01937",
    "title": "BoMD: Bag of Multi-label Descriptors for Noisy Chest X-ray  Classification",
    "abstract": "BoMD: Bag of Multi-label Descriptors for Noisy Chest X-ray  Classification",
    "descriptor": "",
    "authors": [
      "Yuanhong Chen",
      "Fengbei Liu",
      "Hu Wang",
      "Chong Wang",
      "Yu Tian",
      "Yuyuan Liu",
      "Gustavo Carneiro"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.01937"
  },
  {
    "id": "arXiv:2203.08921",
    "title": "Hybrid Pixel-Unshuffled Network for Lightweight Image Super-Resolution",
    "abstract": "Hybrid Pixel-Unshuffled Network for Lightweight Image Super-Resolution",
    "descriptor": "",
    "authors": [
      "Bin Sun",
      "Yulun Zhang",
      "Songyao Jiang",
      "Yun Fu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.08921"
  },
  {
    "id": "arXiv:2203.09517",
    "title": "TensoRF: Tensorial Radiance Fields",
    "abstract": "Comments: Project Page: this https URL",
    "descriptor": "\nComments: Project Page: this https URL\n",
    "authors": [
      "Anpei Chen",
      "Zexiang Xu",
      "Andreas Geiger",
      "Jingyi Yu",
      "Hao Su"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09517"
  },
  {
    "id": "arXiv:2204.04186",
    "title": "The Complexity of Infinite-Horizon General-Sum Stochastic Games",
    "abstract": "Comments: accepted at ITCS 2023",
    "descriptor": "\nComments: accepted at ITCS 2023\n",
    "authors": [
      "Yujia Jin",
      "Vidya Muthukumar",
      "Aaron Sidford"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.04186"
  },
  {
    "id": "arXiv:2204.07054",
    "title": "BrainGB: A Benchmark for Brain Network Analysis with Graph Neural  Networks",
    "abstract": "Comments: IEEE Transactions on Medical Imaging",
    "descriptor": "\nComments: IEEE Transactions on Medical Imaging\n",
    "authors": [
      "Hejie Cui",
      "Wei Dai",
      "Yanqiao Zhu",
      "Xuan Kan",
      "Antonio Aodong Chen Gu",
      "Joshua Lukemire",
      "Liang Zhan",
      "Lifang He",
      "Ying Guo",
      "Carl Yang"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2204.07054"
  },
  {
    "id": "arXiv:2204.07172",
    "title": "Diagnosing and Fixing Manifold Overfitting in Deep Generative Models",
    "abstract": "Comments: Accepted for publication in TMLR",
    "descriptor": "\nComments: Accepted for publication in TMLR\n",
    "authors": [
      "Gabriel Loaiza-Ganem",
      "Brendan Leigh Ross",
      "Jesse C. Cresswell",
      "Anthony L. Caterini"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2204.07172"
  },
  {
    "id": "arXiv:2204.08697",
    "title": "A Multi-Opinion Based Method for Quantifying Polarization on Social  Networks",
    "abstract": "Comments: 14 pages, 4 figures and 1 table",
    "descriptor": "\nComments: 14 pages, 4 figures and 1 table\n",
    "authors": [
      "Maneet Singh",
      "S.R.S. Iyengar",
      "Rishemjit Kaur"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2204.08697"
  },
  {
    "id": "arXiv:2204.09319",
    "title": "Logarithmic Morphological Neural Nets robust to lighting variations",
    "abstract": "Logarithmic Morphological Neural Nets robust to lighting variations",
    "descriptor": "",
    "authors": [
      "Guillaume Noyel",
      "Emile Barbier--Renard",
      "Michel Jourlin",
      "Thierry Fournel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2204.09319"
  },
  {
    "id": "arXiv:2205.00816",
    "title": "Semantic localization on BIM-generated maps using a 3D LiDAR sensor",
    "abstract": "Comments: Accepted by Automation in Construction. Please refer to the published version online. A video demonstration is at this https URL",
    "descriptor": "\nComments: Accepted by Automation in Construction. Please refer to the published version online. A video demonstration is at this https URL\n",
    "authors": [
      "Huan Yin",
      "Zhiyi Lin",
      "Justin K.W. Yeoh"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.00816"
  },
  {
    "id": "arXiv:2205.02003",
    "title": "Multi-subgoal Robot Navigation in Crowds with History Information and  Interactions",
    "abstract": "Multi-subgoal Robot Navigation in Crowds with History Information and  Interactions",
    "descriptor": "",
    "authors": [
      "Xinyi Yu",
      "Jianan Hu",
      "Yuehai Fan",
      "Wancai Zheng",
      "Linlin Ou"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.02003"
  },
  {
    "id": "arXiv:2205.07709",
    "title": "Polynomial formulations as a barrier for reduction-based hardness proofs",
    "abstract": "Polynomial formulations as a barrier for reduction-based hardness proofs",
    "descriptor": "",
    "authors": [
      "Tatiana Belova",
      "Alexander Golovnev",
      "Alexander S. Kulikov",
      "Ivan Mihajlin",
      "Denil Sharipov"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.07709"
  },
  {
    "id": "arXiv:2205.09045",
    "title": "POViT: Vision Transformer for Multi-objective Design and  Characterization of Nanophotonic Devices",
    "abstract": "Comments: Withdrawn due to a potential error in the design of the neural network structure and a possibly false reporting of the training trends",
    "descriptor": "\nComments: Withdrawn due to a potential error in the design of the neural network structure and a possibly false reporting of the training trends\n",
    "authors": [
      "Xinyu Chen",
      "Renjie Li",
      "Yueyao Yu",
      "Yuanwen Shen",
      "Wenye Li",
      "Zhaoyu Zhang",
      "Yin Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applied Physics (physics.app-ph)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2205.09045"
  },
  {
    "id": "arXiv:2205.12154",
    "title": "Arbitrarily high-order energy-preserving schemes for the  Zakharov-Rubenchik equation",
    "abstract": "Comments: 29 pages, 14 figures",
    "descriptor": "\nComments: 29 pages, 14 figures\n",
    "authors": [
      "Gengen Zhang",
      "Chaolong Jiang",
      "Hao Huang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.12154"
  },
  {
    "id": "arXiv:2205.12247",
    "title": "GeoMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained  Language Models",
    "abstract": "Comments: EMNLP 2022. Code and data are released at this https URL",
    "descriptor": "\nComments: EMNLP 2022. Code and data are released at this https URL\n",
    "authors": [
      "Da Yin",
      "Hritik Bansal",
      "Masoud Monajatipoor",
      "Liunian Harold Li",
      "Kai-Wei Chang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12247"
  },
  {
    "id": "arXiv:2205.12264",
    "title": "Efficient Update of Redundancy Matrices for Truss and Frame Structures",
    "abstract": "Efficient Update of Redundancy Matrices for Truss and Frame Structures",
    "descriptor": "",
    "authors": [
      "Tim Krake",
      "Malte von Scheven",
      "Jan Gade",
      "Moataz Abdelaal",
      "Daniel Weiskopf",
      "Manfred Bischoff"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2205.12264"
  },
  {
    "id": "arXiv:2205.12674",
    "title": "Training Language Models with Memory Augmentation",
    "abstract": "Comments: EMNLP 2022. Our code and models are available at this https URL",
    "descriptor": "\nComments: EMNLP 2022. Our code and models are available at this https URL\n",
    "authors": [
      "Zexuan Zhong",
      "Tao Lei",
      "Danqi Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.12674"
  },
  {
    "id": "arXiv:2205.14297",
    "title": "Fake It Till You Make It: Towards Accurate Near-Distribution Novelty  Detection",
    "abstract": "Fake It Till You Make It: Towards Accurate Near-Distribution Novelty  Detection",
    "descriptor": "",
    "authors": [
      "Hossein Mirzaei",
      "Mohammadreza Salehi",
      "Sajjad Shahabi",
      "Efstratios Gavves",
      "Cees G. M. Snoek",
      "Mohammad Sabokrou",
      "Mohammad Hossein Rohban"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14297"
  },
  {
    "id": "arXiv:2205.14298",
    "title": "MC-GEN:Multi-level Clustering for Private Synthetic Data Generation",
    "abstract": "MC-GEN:Multi-level Clustering for Private Synthetic Data Generation",
    "descriptor": "",
    "authors": [
      "Mingchen Li",
      "Di Zhuang",
      "J. Morris Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.14298"
  },
  {
    "id": "arXiv:2205.14320",
    "title": "RIAV-MVS: Recurrent-Indexing an Asymmetric Volume for Multi-View Stereo",
    "abstract": "RIAV-MVS: Recurrent-Indexing an Asymmetric Volume for Multi-View Stereo",
    "descriptor": "",
    "authors": [
      "Changjiang Cai",
      "Pan Ji",
      "Qingan Yan",
      "Yi Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.14320"
  },
  {
    "id": "arXiv:2205.14807",
    "title": "BinauralGrad: A Two-Stage Conditional Diffusion Probabilistic Model for  Binaural Audio Synthesis",
    "abstract": "Comments: NeurIPS 2022 camera version",
    "descriptor": "\nComments: NeurIPS 2022 camera version\n",
    "authors": [
      "Yichong Leng",
      "Zehua Chen",
      "Junliang Guo",
      "Haohe Liu",
      "Jiawei Chen",
      "Xu Tan",
      "Danilo Mandic",
      "Lei He",
      "Xiang-Yang Li",
      "Tao Qin",
      "Sheng Zhao",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2205.14807"
  },
  {
    "id": "arXiv:2205.15371",
    "title": "Optimal and Adaptive Monteiro-Svaiter Acceleration",
    "abstract": "Optimal and Adaptive Monteiro-Svaiter Acceleration",
    "descriptor": "",
    "authors": [
      "Yair Carmon",
      "Danielle Hausler",
      "Arun Jambulapati",
      "Yujia Jin",
      "Aaron Sidford"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.15371"
  },
  {
    "id": "arXiv:2206.01003",
    "title": "Shortest Path Networks for Graph Property Prediction",
    "abstract": "Comments: Accepted as a spotlight paper at the first Learning on Graphs (LoG) conference. Code available at: this https URL",
    "descriptor": "\nComments: Accepted as a spotlight paper at the first Learning on Graphs (LoG) conference. Code available at: this https URL\n",
    "authors": [
      "Ralph Abboud",
      "Radoslav Dimitrov",
      "\u0130smail \u0130lkan Ceylan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.01003"
  },
  {
    "id": "arXiv:2206.01298",
    "title": "A memory-efficient neural ODE framework based on high-level adjoint  differentiation",
    "abstract": "A memory-efficient neural ODE framework based on high-level adjoint  differentiation",
    "descriptor": "",
    "authors": [
      "Hong Zhang",
      "Wenjun Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.01298"
  },
  {
    "id": "arXiv:2206.05149",
    "title": "Referring Image Matting",
    "abstract": "Comments: The dataset, code and models are available at this https URL",
    "descriptor": "\nComments: The dataset, code and models are available at this https URL\n",
    "authors": [
      "Jizhizi Li",
      "Jing Zhang",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05149"
  },
  {
    "id": "arXiv:2206.06346",
    "title": "Bringing Image Scene Structure to Video via Frame-Clip Consistency of  Object Tokens",
    "abstract": "Comments: Tech report",
    "descriptor": "\nComments: Tech report\n",
    "authors": [
      "Elad Ben-Avraham",
      "Roei Herzig",
      "Karttikeya Mangalam",
      "Amir Bar",
      "Anna Rohrbach",
      "Leonid Karlinsky",
      "Trevor Darrell",
      "Amir Globerson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.06346"
  },
  {
    "id": "arXiv:2206.07277",
    "title": "A Gift from Label Smoothing: Robust Training with Adaptive Label  Smoothing via Auxiliary Classifier under Label Noise",
    "abstract": "Comments: THE 37TH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-23)",
    "descriptor": "\nComments: THE 37TH AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-23)\n",
    "authors": [
      "Jongwoo Ko",
      "Bongsoo Yi",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.07277"
  },
  {
    "id": "arXiv:2206.08169",
    "title": "Deterministic and Random Perturbations of the Kepler Problem",
    "abstract": "Comments: Honors thesis submitted to Department of Mathematics of the College of Staten Island City University of New York in partial fulfillment of the requirements for the degree of Bachelor of Science in Mathematics with Honors. Signatures not included due to privacy concerns. Updated to correct certain figures and fixed citations",
    "descriptor": "\nComments: Honors thesis submitted to Department of Mathematics of the College of Staten Island City University of New York in partial fulfillment of the requirements for the degree of Bachelor of Science in Mathematics with Honors. Signatures not included due to privacy concerns. Updated to correct certain figures and fixed citations\n",
    "authors": [
      "Jesse Dimino"
    ],
    "subjectives": [
      "Classical Physics (physics.class-ph)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2206.08169"
  },
  {
    "id": "arXiv:2206.08843",
    "title": "AutoML Two-Sample Test",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Jonas M. K\u00fcbler",
      "Vincent Stimper",
      "Simon Buchholz",
      "Krikamol Muandet",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.08843"
  },
  {
    "id": "arXiv:2206.14293",
    "title": "Human-Multirobot Collaborative Mobile Manipulation: the Omnid Mocobots",
    "abstract": "Comments: 8 pages, 10 figures. Videos available at this https URL Submitted to IEEE Robotics and Automation Letters (RA-L)",
    "descriptor": "\nComments: 8 pages, 10 figures. Videos available at this https URL Submitted to IEEE Robotics and Automation Letters (RA-L)\n",
    "authors": [
      "Matthew L. Elwin",
      "Billie Strong",
      "Randy A. Freeman",
      "Kevin M. Lynch"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2206.14293"
  },
  {
    "id": "arXiv:2207.00220",
    "title": "Pile of Law: Learning Responsible Data Filtering from the Law and a  256GB Open-Source Legal Dataset",
    "abstract": "Comments: Presented at NeurIPS Datasets & Benchmarks (2022)",
    "descriptor": "\nComments: Presented at NeurIPS Datasets & Benchmarks (2022)\n",
    "authors": [
      "Peter Henderson",
      "Mark S. Krass",
      "Lucia Zheng",
      "Neel Guha",
      "Christopher D. Manning",
      "Dan Jurafsky",
      "Daniel E. Ho"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2207.00220"
  },
  {
    "id": "arXiv:2207.00328",
    "title": "TopicFM: Robust and Interpretable Topic-Assisted Feature Matching",
    "abstract": "Comments: Accepted at AAAI-23. This version includes both main text and supplementary materials",
    "descriptor": "\nComments: Accepted at AAAI-23. This version includes both main text and supplementary materials\n",
    "authors": [
      "Khang Truong Giang",
      "Soohwan Song",
      "Sungho Jo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.00328"
  },
  {
    "id": "arXiv:2207.00625",
    "title": "Projectivity revisited",
    "abstract": "Comments: 30 pages",
    "descriptor": "\nComments: 30 pages\n",
    "authors": [
      "Felix Weitk\u00e4mper"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2207.00625"
  },
  {
    "id": "arXiv:2207.01848",
    "title": "TabPFN: A Transformer That Solves Small Tabular Classification Problems  in a Second",
    "abstract": "TabPFN: A Transformer That Solves Small Tabular Classification Problems  in a Second",
    "descriptor": "",
    "authors": [
      "Noah Hollmann",
      "Samuel M\u00fcller",
      "Katharina Eggensperger",
      "Frank Hutter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.01848"
  },
  {
    "id": "arXiv:2207.02101",
    "title": "Distributed Adaptive Backstepping Control for Vehicular Platoons with  Mismatched Disturbances Using Vector String Lyapunov Functions",
    "abstract": "Comments: 11 pages, 18 figures, 1 table to be submitted to CSL/ACC 2023",
    "descriptor": "\nComments: 11 pages, 18 figures, 1 table to be submitted to CSL/ACC 2023\n",
    "authors": [
      "Zihao Song",
      "Shirantha Welikala",
      "Panos J. Antsaklis",
      "Hai Lin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.02101"
  },
  {
    "id": "arXiv:2207.02633",
    "title": "Simulations for Event-Clock Automata",
    "abstract": "Simulations for Event-Clock Automata",
    "descriptor": "",
    "authors": [
      "S Akshay",
      "Paul Gastin",
      "R Govind",
      "B Srivathsan"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2207.02633"
  },
  {
    "id": "arXiv:2207.02862",
    "title": "The Union of Manifolds Hypothesis",
    "abstract": "The Union of Manifolds Hypothesis",
    "descriptor": "",
    "authors": [
      "Bradley C.A. Brown",
      "Anthony L. Caterini",
      "Brendan Leigh Ross",
      "Jesse C. Cresswell",
      "Gabriel Loaiza-Ganem"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.02862"
  },
  {
    "id": "arXiv:2207.02910",
    "title": "Ant Hill Colonization optimization algorithm(AHCOA) for controlling the  side lobe of a uniform linear array",
    "abstract": "Comments: Withdrawn for major modifications",
    "descriptor": "\nComments: Withdrawn for major modifications\n",
    "authors": [
      "Sunit Shantanu Digamber Fulari"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2207.02910"
  },
  {
    "id": "arXiv:2207.03482",
    "title": "Bridging the Gap between Object and Image-level Representations for  Open-Vocabulary Detection",
    "abstract": "Comments: Accepted at NeurIPS 2022",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Hanoona Rasheed",
      "Muhammad Maaz",
      "Muhammad Uzair Khattak",
      "Salman Khan",
      "Fahad Shahbaz Khan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.03482"
  },
  {
    "id": "arXiv:2207.04025",
    "title": "Rate-Optimal Streaming Codes Over the Three-Node Decode-And-Forward  Relay Network",
    "abstract": "Comments: Published at ISIT 2022",
    "descriptor": "\nComments: Published at ISIT 2022\n",
    "authors": [
      "Shubhransh Singhvi",
      "Gayathri R.",
      "P. Vijay Kumar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2207.04025"
  },
  {
    "id": "arXiv:2207.04046",
    "title": "Optimal Pattern synthesis of linear antenna array using Ant Hill  Colonization Optimization algorithm(AHCOA)",
    "abstract": "Optimal Pattern synthesis of linear antenna array using Ant Hill  Colonization Optimization algorithm(AHCOA)",
    "descriptor": "",
    "authors": [
      "Sunit Shantanu Digamber Fulari"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2207.04046"
  },
  {
    "id": "arXiv:2207.08824",
    "title": "Energy-Motivated Equivariant Pretraining for 3D Molecular Graphs",
    "abstract": "Comments: AAAI 2023",
    "descriptor": "\nComments: AAAI 2023\n",
    "authors": [
      "Rui Jiao",
      "Jiaqi Han",
      "Wenbing Huang",
      "Yu Rong",
      "Yang Liu"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.08824"
  },
  {
    "id": "arXiv:2207.09775",
    "title": "Rectifying Open-set Object Detection: A Taxonomy, Practical  Applications, and Proper Evaluation",
    "abstract": "Comments: 17 pages, 7 figures",
    "descriptor": "\nComments: 17 pages, 7 figures\n",
    "authors": [
      "Yusuke Hosoya",
      "Masanori Suganuma",
      "Takayuki Okatani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09775"
  },
  {
    "id": "arXiv:2208.01893",
    "title": "Flow Annealed Importance Sampling Bootstrap",
    "abstract": "Flow Annealed Importance Sampling Bootstrap",
    "descriptor": "",
    "authors": [
      "Laurence Illing Midgley",
      "Vincent Stimper",
      "Gregor N. C. Simm",
      "Bernhard Sch\u00f6lkopf",
      "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.01893"
  },
  {
    "id": "arXiv:2208.02592",
    "title": "Resilient Risk based Adaptive Authentication and Authorization (RAD-AA)  Framework",
    "abstract": "Resilient Risk based Adaptive Authentication and Authorization (RAD-AA)  Framework",
    "descriptor": "",
    "authors": [
      "Jaimandeep Singh",
      "Chintan Patel",
      "Naveen Kumar Chaudhary"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2208.02592"
  },
  {
    "id": "arXiv:2208.04010",
    "title": "Application of Guessing to Sequential Decoding of Polarization-Adjusted  Convolutional (PAC) Codes",
    "abstract": "Application of Guessing to Sequential Decoding of Polarization-Adjusted  Convolutional (PAC) Codes",
    "descriptor": "",
    "authors": [
      "Mohsen Moradi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2208.04010"
  },
  {
    "id": "arXiv:2208.07798",
    "title": "Counterfactual Supervision-based Information Bottleneck for  Out-of-Distribution Generalization",
    "abstract": "Comments: Theoretical Understanding of OOD generalization",
    "descriptor": "\nComments: Theoretical Understanding of OOD generalization\n",
    "authors": [
      "Bin Deng",
      "Kui Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.07798"
  },
  {
    "id": "arXiv:2208.10354",
    "title": "Quantifying probabilistic robustness of tree-based classifiers against  natural distortions",
    "abstract": "Comments: 9 pages, 5 figures",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Christoph Schweimer",
      "Sebastian Scher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10354"
  },
  {
    "id": "arXiv:2208.10451",
    "title": "Minimax AUC Fairness: Efficient Algorithm with Provable Convergence",
    "abstract": "Minimax AUC Fairness: Efficient Algorithm with Provable Convergence",
    "descriptor": "",
    "authors": [
      "Zhenhuan Yang",
      "Yan Lok Ko",
      "Kush R. Varshney",
      "Yiming Ying"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2208.10451"
  },
  {
    "id": "arXiv:2209.00546",
    "title": "MSGNN: A Spectral Graph Neural Network Based on a Novel Magnetic Signed  Laplacian",
    "abstract": "Comments: 39 pages, 10 pages for the main text, accepted to LoG 2022",
    "descriptor": "\nComments: 39 pages, 10 pages for the main text, accepted to LoG 2022\n",
    "authors": [
      "Yixuan He",
      "Michael Permultter",
      "Gesine Reinert",
      "Mihai Cucuringu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2209.00546"
  },
  {
    "id": "arXiv:2209.02681",
    "title": "How important are activation functions in regression and classification?  A survey, performance comparison, and future directions",
    "abstract": "Comments: 48 pages, 15 figures",
    "descriptor": "\nComments: 48 pages, 15 figures\n",
    "authors": [
      "Ameya D. Jagtap",
      "George Em Karniadakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.02681"
  },
  {
    "id": "arXiv:2209.02948",
    "title": "Assessing Software Privacy using the Privacy Flow-Graph",
    "abstract": "Comments: Published at International Workshop on Mining Software Repositories Applications for Privacy and Security (MSR4P&S) 2022",
    "descriptor": "\nComments: Published at International Workshop on Mining Software Repositories Applications for Privacy and Security (MSR4P&S) 2022\n",
    "authors": [
      "Feiyang Tang",
      "Bjarte M. \u00d8stvold"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2209.02948"
  },
  {
    "id": "arXiv:2209.03299",
    "title": "Multimodal learning with graphs",
    "abstract": "Comments: 27 pages, 5 figures, 2 boxes",
    "descriptor": "\nComments: 27 pages, 5 figures, 2 boxes\n",
    "authors": [
      "Yasha Ektefaie",
      "George Dasoulas",
      "Ayush Noori",
      "Maha Farhat",
      "Marinka Zitnik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.03299"
  },
  {
    "id": "arXiv:2209.05992",
    "title": "List recoloring of planar graphs",
    "abstract": "List recoloring of planar graphs",
    "descriptor": "",
    "authors": [
      "L. Sunil Chandran",
      "Uttam K. Gupta",
      "Dinabandhu Pradhan"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2209.05992"
  },
  {
    "id": "arXiv:2209.06579",
    "title": "C^2:Co-design of Robots via Concurrent Networks Coupling Online and  Offline Reinforcement Learning",
    "abstract": "C^2:Co-design of Robots via Concurrent Networks Coupling Online and  Offline Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Ci Chen",
      "Pingyu Xiang",
      "Haojian Lu",
      "Yue Wang",
      "Rong Xiong"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.06579"
  },
  {
    "id": "arXiv:2209.07738",
    "title": "DMFormer: Closing the Gap Between CNN and Vision Transformers",
    "abstract": "DMFormer: Closing the Gap Between CNN and Vision Transformers",
    "descriptor": "",
    "authors": [
      "Zimian Wei",
      "Hengyue Pan",
      "Lujun Li",
      "Menglong Lu",
      "Xin Niu",
      "Peijie Dong",
      "Dongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07738"
  },
  {
    "id": "arXiv:2209.08676",
    "title": "Adaptive Attitude Control for Foldable Quadrotors",
    "abstract": "Comments: Submitted to IEEE LCSS ; 6 Pages, 4 Figures",
    "descriptor": "\nComments: Submitted to IEEE LCSS ; 6 Pages, 4 Figures\n",
    "authors": [
      "Karishma Patnaik",
      "Wenlong Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.08676"
  },
  {
    "id": "arXiv:2209.08932",
    "title": "OPR-Miner: Order-preserving rule mining for time series",
    "abstract": "OPR-Miner: Order-preserving rule mining for time series",
    "descriptor": "",
    "authors": [
      "Youxi Wu",
      "Xiaoqian Zhao",
      "Yan Li",
      "Lei Guo",
      "Xingquan Zhu",
      "Philippe Fournier-Viger",
      "Xindong Wu"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2209.08932"
  },
  {
    "id": "arXiv:2209.09338",
    "title": "Revisiting Embeddings for Graph Neural Networks",
    "abstract": "Revisiting Embeddings for Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "S. Purchase",
      "A. Zhao",
      "R. D. Mullins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.09338"
  },
  {
    "id": "arXiv:2209.11209",
    "title": "Improved Approximation Algorithms by Generalizing the Primal-Dual Method  Beyond Uncrossable Functions",
    "abstract": "Comments: Updated v1, updated title and abstract, added/revised results and proofs, added another application of main theorem, and now, v1 is obsolete",
    "descriptor": "\nComments: Updated v1, updated title and abstract, added/revised results and proofs, added another application of main theorem, and now, v1 is obsolete\n",
    "authors": [
      "Ishan Bansal",
      "Joseph Cheriyan",
      "Logan Grout",
      "Sharat Ibrahimpur"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2209.11209"
  },
  {
    "id": "arXiv:2209.12635",
    "title": "ImmunoLingo: Linguistics-based formalization of the antibody language",
    "abstract": "Comments: 19 pages, 3 figures",
    "descriptor": "\nComments: 19 pages, 3 figures\n",
    "authors": [
      "Mai Ha Vu",
      "Philippe A. Robert",
      "Rahmad Akbar",
      "Bartlomiej Swiatczak",
      "Geir Kjetil Sandve",
      "Dag Trygve Truslew Haug",
      "Victor Greiff"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.12635"
  },
  {
    "id": "arXiv:2209.14292",
    "title": "Proceedings of the AI-HRI Symposium at AAAI-FSS 2022",
    "abstract": "Proceedings of the AI-HRI Symposium at AAAI-FSS 2022",
    "descriptor": "",
    "authors": [
      "Zhao Han",
      "Emmanuel Senft",
      "Muneeb I. Ahmad",
      "Shelly Bagchi",
      "Amir Yazdani",
      "Jason R. Wilson",
      "Boyoung Kim",
      "Ruchen Wen",
      "Justin W. Hart",
      "Daniel Hern\u00e1ndez Garc\u00eda",
      "Matteo Leonetti",
      "Ross Mead",
      "Reuth Mirsky",
      "Ahalya Prabhakar",
      "Megan L. Zimmerman"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2209.14292"
  },
  {
    "id": "arXiv:2209.15130",
    "title": "Nonconvex Matrix Factorization is Geodesically Convex: Global Landscape  Analysis for Fixed-rank Matrix Optimization From a Riemannian Perspective",
    "abstract": "Comments: The abstract is shortened to meet the arXiv submission requirement",
    "descriptor": "\nComments: The abstract is shortened to meet the arXiv submission requirement\n",
    "authors": [
      "Yuetian Luo",
      "Nicolas Garcia Trillos"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.15130"
  },
  {
    "id": "arXiv:2209.15285",
    "title": "QUAK: A Synthetic Quality Estimation Dataset for Korean-English Neural  Machine Translation",
    "abstract": "QUAK: A Synthetic Quality Estimation Dataset for Korean-English Neural  Machine Translation",
    "descriptor": "",
    "authors": [
      "Sugyeong Eo",
      "Chanjun Park",
      "Hyeonseok Moon",
      "Jaehyung Seo",
      "Gyeongmin Kim",
      "Jungseob Lee",
      "Heuiseok Lim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.15285"
  },
  {
    "id": "arXiv:2210.00312",
    "title": "Multimodal Analogical Reasoning over Knowledge Graphs",
    "abstract": "Comments: Work in progress",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Ningyu Zhang",
      "Lei Li",
      "Xiang Chen",
      "Xiaozhuan Liang",
      "Shumin Deng",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.00312"
  },
  {
    "id": "arXiv:2210.02671",
    "title": "Transformers Can Be Translated to First-Order Logic with Majority  Quantifiers",
    "abstract": "Transformers Can Be Translated to First-Order Logic with Majority  Quantifiers",
    "descriptor": "",
    "authors": [
      "William Merrill",
      "Ashish Sabharwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2210.02671"
  },
  {
    "id": "arXiv:2210.03137",
    "title": "Deep Inventory Management",
    "abstract": "Deep Inventory Management",
    "descriptor": "",
    "authors": [
      "Dhruv Madeka",
      "Kari Torkkola",
      "Carson Eisenach",
      "Anna Luo",
      "Dean P. Foster",
      "Sham M. Kakade"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.03137"
  },
  {
    "id": "arXiv:2210.03581",
    "title": "Synthetic Voice Detection and Audio Splicing Detection using  SE-Res2Net-Conformer Architecture",
    "abstract": "Comments: Accepted by the 13th International Symposium on Chinese Spoken Language Processing (ISCSLP 2022)",
    "descriptor": "\nComments: Accepted by the 13th International Symposium on Chinese Spoken Language Processing (ISCSLP 2022)\n",
    "authors": [
      "Lei Wang",
      "Benedict Yeoh",
      "Jun Wah Ng"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.03581"
  },
  {
    "id": "arXiv:2210.04975",
    "title": "MACARONS: A Modular and Open-Sourced Automation System for Vertical  Farming",
    "abstract": "MACARONS: A Modular and Open-Sourced Automation System for Vertical  Farming",
    "descriptor": "",
    "authors": [
      "Vijja Wichitwechkarn",
      "Charles Fox"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.04975"
  },
  {
    "id": "arXiv:2210.05308",
    "title": "Learning Control Policies for Stochastic Systems with Reach-avoid  Guarantees",
    "abstract": "Comments: Accepted at AAAI 2023",
    "descriptor": "\nComments: Accepted at AAAI 2023\n",
    "authors": [
      "\u0110or\u0111e \u017dikeli\u0107",
      "Mathias Lechner",
      "Thomas A. Henzinger",
      "Krishnendu Chatterjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.05308"
  },
  {
    "id": "arXiv:2210.05557",
    "title": "OPERA: Omni-Supervised Representation Learning with Hierarchical  Supervisions",
    "abstract": "Comments: Source code available at: this https URL",
    "descriptor": "\nComments: Source code available at: this https URL\n",
    "authors": [
      "Chengkun Wang",
      "Wenzhao Zheng",
      "Zheng Zhu",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.05557"
  },
  {
    "id": "arXiv:2210.06455",
    "title": "Token-Label Alignment for Vision Transformers",
    "abstract": "Comments: Source code available at this https URL",
    "descriptor": "\nComments: Source code available at this https URL\n",
    "authors": [
      "Han Xiao",
      "Wenzhao Zheng",
      "Zheng Zhu",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.06455"
  },
  {
    "id": "arXiv:2210.06901",
    "title": "Entropy Approximation by Machine Learning Regression: Application for  Irregularity Evaluation of Images in Remote Sensing",
    "abstract": "Comments: 25 pages, 24 figures, 4 tables",
    "descriptor": "\nComments: 25 pages, 24 figures, 4 tables\n",
    "authors": [
      "Andrei Velichko",
      "Maksim Belyaev",
      "Matthias P. Wagner",
      "Alireza Taravat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2210.06901"
  },
  {
    "id": "arXiv:2210.08772",
    "title": "Signal Processing for Implicit Neural Representations",
    "abstract": "Comments: Advances in Neural Information Processing Systems (NeurIPS), 2022",
    "descriptor": "\nComments: Advances in Neural Information Processing Systems (NeurIPS), 2022\n",
    "authors": [
      "Dejia Xu",
      "Peihao Wang",
      "Yifan Jiang",
      "Zhiwen Fan",
      "Zhangyang Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08772"
  },
  {
    "id": "arXiv:2210.08923",
    "title": "RPoA: Redefined Proof of Activity",
    "abstract": "Comments: 11 pages with 1 figure",
    "descriptor": "\nComments: 11 pages with 1 figure\n",
    "authors": [
      "Sina Kamali",
      "Shayan Shabihi",
      "Mohammad Taha Fakharian",
      "Alireza Arbabi",
      "Pouriya Tajmehrabi",
      "Mohammad Saadati",
      "Behnam Bahrak"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.08923"
  },
  {
    "id": "arXiv:2210.10311",
    "title": "Latency Aware Semi-synchronous Client Selection and Model Aggregation  for Wireless Federated Learning",
    "abstract": "Latency Aware Semi-synchronous Client Selection and Model Aggregation  for Wireless Federated Learning",
    "descriptor": "",
    "authors": [
      "Liangkun Yu",
      "Xiang Sun",
      "Rana Albelaihi",
      "Chen Yi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10311"
  },
  {
    "id": "arXiv:2210.10837",
    "title": "On Learning Fairness and Accuracy on Multiple Subgroups",
    "abstract": "Comments: NeurIPS-2022 Camera-ready",
    "descriptor": "\nComments: NeurIPS-2022 Camera-ready\n",
    "authors": [
      "Changjian Shui",
      "Gezheng Xu",
      "Qi Chen",
      "Jiaqi Li",
      "Charles Ling",
      "Tal Arbel",
      "Boyu Wang",
      "Christian Gagn\u00e9"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.10837"
  },
  {
    "id": "arXiv:2210.12045",
    "title": "Optimization of side lobe level of linear antenna array using nature  optimized ants bridging solutions(NOABS)",
    "abstract": "Optimization of side lobe level of linear antenna array using nature  optimized ants bridging solutions(NOABS)",
    "descriptor": "",
    "authors": [
      "Sunit Shantanu Digamber Fulari"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.12045"
  },
  {
    "id": "arXiv:2210.12342",
    "title": "Detection of Risk Predictors of COVID-19 Mortality with Classifier  Machine Learning Models Operated with Routine Laboratory Biomarkers",
    "abstract": "Comments: 29 pages, 14 figures, 6 tables",
    "descriptor": "\nComments: 29 pages, 14 figures, 6 tables\n",
    "authors": [
      "Mehmet Tahir Huyut",
      "Andrei Velichko",
      "Maksim Belyaev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2210.12342"
  },
  {
    "id": "arXiv:2210.14100",
    "title": "The capacity of a finite field matrix channel",
    "abstract": "Comments: 32 pages, 1 figure. Minor typos corrected",
    "descriptor": "\nComments: 32 pages, 1 figure. Minor typos corrected\n",
    "authors": [
      "Simon R. Blackburn",
      "Jessica Claridge"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2210.14100"
  },
  {
    "id": "arXiv:2210.16395",
    "title": "Ensure Differential Privacy and Convergence Accuracy in Consensus  Tracking and Aggregative Games with Coupling Constraints",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2209.01486",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2209.01486\n",
    "authors": [
      "Yongqiang Wang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Cryptography and Security (cs.CR)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2210.16395"
  },
  {
    "id": "arXiv:2210.17429",
    "title": "The power of the Binary Value Principle",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Yaroslav Alekseev",
      "Edward A. Hirsch"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2210.17429"
  },
  {
    "id": "arXiv:2211.00151",
    "title": "A Close Look into the Calibration of Pre-trained Language Models",
    "abstract": "Comments: Code is available at: this https URL",
    "descriptor": "\nComments: Code is available at: this https URL\n",
    "authors": [
      "Yangyi Chen",
      "Lifan Yuan",
      "Ganqu Cui",
      "Zhiyuan Liu",
      "Heng Ji"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.00151"
  },
  {
    "id": "arXiv:2211.01562",
    "title": "PINTO: Faithful Language Reasoning Using Prompt-Generated Rationales",
    "abstract": "Comments: 19 pages, 6 figures, preprint",
    "descriptor": "\nComments: 19 pages, 6 figures, preprint\n",
    "authors": [
      "Peifeng Wang",
      "Aaron Chan",
      "Filip Ilievski",
      "Muhao Chen",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.01562"
  },
  {
    "id": "arXiv:2211.02941",
    "title": "Small Language Models for Tabular Data",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Benjamin L. Badger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02941"
  },
  {
    "id": "arXiv:2211.03174",
    "title": "Wheel-SLAM: Simultaneous Localization and Terrain Mapping Using One  Wheel-mounted IMU",
    "abstract": "Comments: Accepted to IEEE Robotics and Automation Letters",
    "descriptor": "\nComments: Accepted to IEEE Robotics and Automation Letters\n",
    "authors": [
      "Yibin Wu",
      "Jian Kuang",
      "Xiaoji Niu",
      "Jens Behley",
      "Lasse Klingbeil",
      "Heiner Kuhlmann"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.03174"
  },
  {
    "id": "arXiv:2211.03812",
    "title": "Posterior samples of source galaxies in strong gravitational lenses with  score-based priors",
    "abstract": "Comments: 5+6 pages, 3 figures, Accepted (poster + contributed talk) for the Machine Learning and the Physical Sciences Workshop at the 36th conference on Neural Information Processing Systems (NeurIPS 2022); Corrected style file and added authors checklist",
    "descriptor": "\nComments: 5+6 pages, 3 figures, Accepted (poster + contributed talk) for the Machine Learning and the Physical Sciences Workshop at the 36th conference on Neural Information Processing Systems (NeurIPS 2022); Corrected style file and added authors checklist\n",
    "authors": [
      "Alexandre Adam",
      "Adam Coogan",
      "Nikolay Malkin",
      "Ronan Legin",
      "Laurence Perreault-Levasseur",
      "Yashar Hezaveh",
      "Yoshua Bengio"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.03812"
  },
  {
    "id": "arXiv:2211.05163",
    "title": "Multimodal Dyadic Impression Recognition via Listener Adaptive  Cross-Domain Fusion",
    "abstract": "Comments: submitted to ICASSP2023. arXiv admin note: substantial text overlap with arXiv:2203.13932",
    "descriptor": "\nComments: submitted to ICASSP2023. arXiv admin note: substantial text overlap with arXiv:2203.13932\n",
    "authors": [
      "Yuanchao Li",
      "Peter Bell",
      "Catherine Lai"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.05163"
  },
  {
    "id": "arXiv:2211.05952",
    "title": "Efficient Domain Coverage for Vehicles with Second Order Dynamics via  Multi-Agent Reinforcement Learning",
    "abstract": "Comments: This paper has been submitted to IEEE Robotics and Automation Letters. Includes 8 pages with 5 figures",
    "descriptor": "\nComments: This paper has been submitted to IEEE Robotics and Automation Letters. Includes 8 pages with 5 figures\n",
    "authors": [
      "Xinyu Zhao",
      "Razvan C. Fetecau",
      "Mo Chen"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.05952"
  },
  {
    "id": "arXiv:2211.07394",
    "title": "Composed Image Retrieval with Text Feedback via Multi-grained  Uncertainty Regularization",
    "abstract": "Composed Image Retrieval with Text Feedback via Multi-grained  Uncertainty Regularization",
    "descriptor": "",
    "authors": [
      "Yiyang Chen",
      "Zhedong Zheng",
      "Wei Ji",
      "Leigang Qu",
      "Tat-Seng Chua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07394"
  },
  {
    "id": "arXiv:2211.07791",
    "title": "A Robust Dynamic Average Consensus Algorithm that Ensures both  Differential Privacy and Accurate Convergence",
    "abstract": "Comments: IEEE CDC. arXiv admin note: substantial text overlap with arXiv:2210.16395; text overlap with arXiv:2209.01486",
    "descriptor": "\nComments: IEEE CDC. arXiv admin note: substantial text overlap with arXiv:2210.16395; text overlap with arXiv:2209.01486\n",
    "authors": [
      "Yongqiang Wang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.07791"
  },
  {
    "id": "arXiv:2211.08540",
    "title": "VGFlow: Visibility guided Flow Network for Human Reposing",
    "abstract": "Comments: 9 pages, 18 figures, computer vision",
    "descriptor": "\nComments: 9 pages, 18 figures, computer vision\n",
    "authors": [
      "Rishabh Jain",
      "Krishna Kumar Singh",
      "Mayur Hemani",
      "Jingwan Lu",
      "Mausooom Sarkar",
      "Duygu Ceylan",
      "Balaji Krishnamurthy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.08540"
  },
  {
    "id": "arXiv:2211.09174",
    "title": "CASPR: Customer Activity Sequence-based Prediction and Representation",
    "abstract": "Comments: Presented at the Table Representation Learning Workshop, NeurIPS 2022, New Orleans. Authors listed in random order",
    "descriptor": "\nComments: Presented at the Table Representation Learning Workshop, NeurIPS 2022, New Orleans. Authors listed in random order\n",
    "authors": [
      "Pin-Jung Chen",
      "Sahil Bhatnagar",
      "Sagar Goyal",
      "Damian Konrad Kowalczyk",
      "Mayank Shrivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.09174"
  },
  {
    "id": "arXiv:2211.09634",
    "title": "On the Sample Complexity of Two-Layer Networks: Lipschitz vs.  Element-Wise Lipschitz Activation",
    "abstract": "Comments: 9 pages with additional 15 pages of supplementary",
    "descriptor": "\nComments: 9 pages with additional 15 pages of supplementary\n",
    "authors": [
      "Amit Daniely",
      "Elad Granot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09634"
  },
  {
    "id": "arXiv:2211.09894",
    "title": "Supervised Feature Compression based on Counterfactual Analysis",
    "abstract": "Comments: 29 pages, 12 figures",
    "descriptor": "\nComments: 29 pages, 12 figures\n",
    "authors": [
      "Veronica Piccialli",
      "Dolores Romero Morales",
      "Cecilia Salvatore"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.09894"
  },
  {
    "id": "arXiv:2211.11912",
    "title": "Quasi-stable Coloring for Graph Compression: Approximating Max-Flow,  Linear Programs, and Centrality",
    "abstract": "Comments: To be presented at VLDB 2023",
    "descriptor": "\nComments: To be presented at VLDB 2023\n",
    "authors": [
      "Moe Kayali",
      "Dan Suciu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.11912"
  },
  {
    "id": "arXiv:2211.12024",
    "title": "TaylorBeamixer: Learning Taylor-Inspired All-Neural Multi-Channel Speech  Enhancement from Beam-Space Dictionary Perspective",
    "abstract": "Comments: In submission to ICASSP 2023, 5 pages",
    "descriptor": "\nComments: In submission to ICASSP 2023, 5 pages\n",
    "authors": [
      "Andong Li",
      "Guochen Yu",
      "Wenzhe Liu",
      "Xiaodong Li",
      "Chengshi Zheng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.12024"
  },
  {
    "id": "arXiv:2211.12271",
    "title": "Global $k$-means$++$: an effective relaxation of the global $k$-means  clustering algorithm",
    "abstract": "Global $k$-means$++$: an effective relaxation of the global $k$-means  clustering algorithm",
    "descriptor": "",
    "authors": [
      "Georgios Vardakas",
      "Aristidis Likas"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12271"
  },
  {
    "id": "arXiv:2211.12311",
    "title": "Generalizable Industrial Visual Anomaly Detection with Self-Induction  Vision Transformer",
    "abstract": "Comments: 8 pages, 6 figures,",
    "descriptor": "\nComments: 8 pages, 6 figures,\n",
    "authors": [
      "Haiming Yao",
      "Wenyong Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12311"
  },
  {
    "id": "arXiv:2211.12498",
    "title": "Touch and Go: Learning from Human-Collected Vision and Touch",
    "abstract": "Comments: Accepted by NeurIPS 2022 Track of Datasets and Benchmarks",
    "descriptor": "\nComments: Accepted by NeurIPS 2022 Track of Datasets and Benchmarks\n",
    "authors": [
      "Fengyu Yang",
      "Chenyang Ma",
      "Jiacheng Zhang",
      "Jing Zhu",
      "Wenzhen Yuan",
      "Andrew Owens"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12498"
  },
  {
    "id": "arXiv:2211.12588",
    "title": "Program of Thoughts Prompting: Disentangling Computation from Reasoning  for Numerical Reasoning Tasks",
    "abstract": "Program of Thoughts Prompting: Disentangling Computation from Reasoning  for Numerical Reasoning Tasks",
    "descriptor": "",
    "authors": [
      "Wenhu Chen",
      "Xueguang Ma",
      "Xinyi Wang",
      "William W. Cohen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12588"
  },
  {
    "id": "arXiv:2211.12634",
    "title": "Image Anomaly Detection and Localization with Position and Neighborhood  Information",
    "abstract": "Image Anomaly Detection and Localization with Position and Neighborhood  Information",
    "descriptor": "",
    "authors": [
      "Jaehyeok Bae",
      "Jae-Han Lee",
      "Seyun Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12634"
  },
  {
    "id": "arXiv:2211.12732",
    "title": "Wild-Places: A Large-Scale Dataset for Lidar Place Recognition in  Unstructured Natural Environments",
    "abstract": "Comments: Equal Contribution from first two authors Under Review Website link: this https URL",
    "descriptor": "\nComments: Equal Contribution from first two authors Under Review Website link: this https URL\n",
    "authors": [
      "Joshua Knights",
      "Kavisha Vidanapathirana",
      "Milad Ramezani",
      "Sridha Sridharan",
      "Clinton Fookes",
      "Peyman Moghadam"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.12732"
  },
  {
    "id": "arXiv:2211.13328",
    "title": "Search Behavior Prediction: A Hypergraph Perspective",
    "abstract": "Comments: WSDM 2023",
    "descriptor": "\nComments: WSDM 2023\n",
    "authors": [
      "Yan Han",
      "Edward W Huang",
      "Wenqing Zheng",
      "Nikhil Rao",
      "Zhangyang Wang",
      "Karthik Subbian"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.13328"
  },
  {
    "id": "arXiv:2211.13523",
    "title": "Roboflow 100: A Rich, Multi-Domain Object Detection Benchmark",
    "abstract": "Roboflow 100: A Rich, Multi-Domain Object Detection Benchmark",
    "descriptor": "",
    "authors": [
      "Floriana Ciaglia",
      "Francesco Saverio Zuppichini",
      "Paul Guerrie",
      "Mark McQuade",
      "Jacob Solawetz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13523"
  },
  {
    "id": "arXiv:2211.13813",
    "title": "Multi-label Few-shot ICD Coding as Autoregressive Generation with Prompt",
    "abstract": "Comments: To be appear in AAAI2023",
    "descriptor": "\nComments: To be appear in AAAI2023\n",
    "authors": [
      "Zhichao Yang",
      "Sunjae Kwon",
      "Zonghai Yao",
      "Hong Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13813"
  },
  {
    "id": "arXiv:2211.13929",
    "title": "XKD: Cross-modal Knowledge Distillation with Domain Alignment for Video  Representation Learning",
    "abstract": "XKD: Cross-modal Knowledge Distillation with Domain Alignment for Video  Representation Learning",
    "descriptor": "",
    "authors": [
      "Pritam Sarkar",
      "Ali Etemad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13929"
  },
  {
    "id": "arXiv:2211.13977",
    "title": "CLIP-ReID: Exploiting Vision-Language Model for Image Re-Identification  without Concrete Text Labels",
    "abstract": "CLIP-ReID: Exploiting Vision-Language Model for Image Re-Identification  without Concrete Text Labels",
    "descriptor": "",
    "authors": [
      "Siyuan Li",
      "Li Sun",
      "Qingli Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13977"
  },
  {
    "id": "arXiv:2211.13979",
    "title": "BatmanNet: Bi-branch Masked Graph Transformer Autoencoder for Molecular  Representation",
    "abstract": "Comments: 11 pages, 3 figures",
    "descriptor": "\nComments: 11 pages, 3 figures\n",
    "authors": [
      "Zhen Wang",
      "Zheng Feng",
      "Yanjun Li",
      "Bowen Li",
      "Yongrui Wang",
      "Chulin Sha",
      "Min He",
      "Xiaolin Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2211.13979"
  },
  {
    "id": "arXiv:2211.14099",
    "title": "Fuzzy clustering for the within-season estimation of cotton phenology",
    "abstract": "Comments: also contained in arXiv:2211.12584",
    "descriptor": "\nComments: also contained in arXiv:2211.12584\n",
    "authors": [
      "Vasileios Sitokonstantinou",
      "Alkiviadis Koukos",
      "Ilias Tsoumas",
      "Nikolaos S. Bartsotas",
      "Charalampos Kontoes",
      "Vassilia Karathanassi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14099"
  },
  {
    "id": "arXiv:2211.14228",
    "title": "GPT-3-driven pedagogical agents for training children's curious  question-asking skills",
    "abstract": "GPT-3-driven pedagogical agents for training children's curious  question-asking skills",
    "descriptor": "",
    "authors": [
      "Rania Abdelghani",
      "Yen-Hsiang Wang",
      "Xingdi Yuan",
      "Tong Wang",
      "H\u00e9l\u00e8ne Sauz\u00e9on",
      "Pierre-Yves Oudeyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.14228"
  },
  {
    "id": "arXiv:2211.14401",
    "title": "Elements of effective machine learning datasets in astronomy",
    "abstract": "Comments: 5 pages, 1 figure, accepted to the peer-reviewed NeurIPS Machine Learning in the Physical Sciences Workshop, 2022",
    "descriptor": "\nComments: 5 pages, 1 figure, accepted to the peer-reviewed NeurIPS Machine Learning in the Physical Sciences Workshop, 2022\n",
    "authors": [
      "Bernie Boscoe",
      "Tuan Do",
      "Evan Jones",
      "Yunqi Li",
      "Kevin Alfaro",
      "Christy Ma"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14401"
  },
  {
    "id": "arXiv:2211.14466",
    "title": "SKDBERT: Compressing BERT via Stochastic Knowledge Distillation",
    "abstract": "Comments: This paper has been accepted by AAAI2023",
    "descriptor": "\nComments: This paper has been accepted by AAAI2023\n",
    "authors": [
      "Zixiang Ding",
      "Guoqing Jiang",
      "Shuai Zhang",
      "Lin Guo",
      "Wei Lin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.14466"
  },
  {
    "id": "arXiv:2211.14502",
    "title": "Learning Single Image Defocus Deblurring with Misaligned Training Pairs",
    "abstract": "Comments: this https URL",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Yu Li",
      "Dongwei Ren",
      "Xinya Shu",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14502"
  },
  {
    "id": "arXiv:2211.14521",
    "title": "Robust One-shot Segmentation of Brain Tissues via Image-aligned Style  Transformation",
    "abstract": "Comments: Accepted by AAAI-2023",
    "descriptor": "\nComments: Accepted by AAAI-2023\n",
    "authors": [
      "Jinxin Lv",
      "Xiaoyu Zeng",
      "Sheng Wang",
      "Ran Duan",
      "Zhiwei Wang",
      "Qiang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14521"
  },
  {
    "id": "arXiv:2211.14670",
    "title": "Mediated Cheap Talk Design (with proofs)",
    "abstract": "Comments: To be presented at AAAI'23",
    "descriptor": "\nComments: To be presented at AAAI'23\n",
    "authors": [
      "Itai Arieli",
      "Ivan Geffner",
      "Moshe Tennenholtz"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.14670"
  },
  {
    "id": "arXiv:2211.14703",
    "title": "Exploring Consistency in Cross-Domain Transformer for Domain Adaptive  Semantic Segmentation",
    "abstract": "Exploring Consistency in Cross-Domain Transformer for Domain Adaptive  Semantic Segmentation",
    "descriptor": "",
    "authors": [
      "Kaihong Wang",
      "Donghyun Kim",
      "Rogerio Feris",
      "Kate Saenko",
      "Margrit Betke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14703"
  },
  {
    "id": "arXiv:2211.14720",
    "title": "Rectified Pessimistic-Optimistic Learning for Stochastic Continuum-armed  Bandit with Constraints",
    "abstract": "Rectified Pessimistic-Optimistic Learning for Stochastic Continuum-armed  Bandit with Constraints",
    "descriptor": "",
    "authors": [
      "Hengquan Guo",
      "Qi Zhu",
      "Xin Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.14720"
  },
  {
    "id": "arXiv:2211.14722",
    "title": "Convergence Rate Analysis for Optimal Computing Budget Allocation  Algorithms",
    "abstract": "Convergence Rate Analysis for Optimal Computing Budget Allocation  Algorithms",
    "descriptor": "",
    "authors": [
      "Yanwen Li",
      "Siyang Gao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.14722"
  },
  {
    "id": "arXiv:2211.14731",
    "title": "BALF: Simple and Efficient Blur Aware Local Feature Detector",
    "abstract": "BALF: Simple and Efficient Blur Aware Local Feature Detector",
    "descriptor": "",
    "authors": [
      "Zhenjun Zhao",
      "Yu Zhai",
      "Ben M. Chen",
      "Peidong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14731"
  },
  {
    "id": "arXiv:2211.14802",
    "title": "Neural Font Rendering",
    "abstract": "Neural Font Rendering",
    "descriptor": "",
    "authors": [
      "Daniel Anderson",
      "Ariel Shamir",
      "Ohad Fried"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.14802"
  },
  {
    "id": "arXiv:2211.14829",
    "title": "AWTE-BERT:Attending to Wordpiece Tokenization Explicitly on BERT for  Joint Intent Classification and SlotFilling",
    "abstract": "AWTE-BERT:Attending to Wordpiece Tokenization Explicitly on BERT for  Joint Intent Classification and SlotFilling",
    "descriptor": "",
    "authors": [
      "Yu Guo",
      "Zhilong Xie",
      "Xingyan Chen",
      "Leilei Wang",
      "Yu Zhao",
      "Gang Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.14829"
  },
  {
    "id": "arXiv:2211.14844",
    "title": "Estimating the number of communities in weighted networks",
    "abstract": "Estimating the number of communities in weighted networks",
    "descriptor": "",
    "authors": [
      "Huan Qing"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2211.14844"
  },
  {
    "id": "arXiv:2211.14851",
    "title": "Performance evaluation of deep segmentation models on Landsat-8 imagery",
    "abstract": "Comments: Accepted to Tackling Climate Change with Machine Learning: workshop at NeurIPS 2022",
    "descriptor": "\nComments: Accepted to Tackling Climate Change with Machine Learning: workshop at NeurIPS 2022\n",
    "authors": [
      "Akshat Bhandari",
      "Sriya Rallabandi",
      "Sanchit Singhal",
      "Aditya Kasliwal aand Pratinav Seth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14851"
  },
  {
    "id": "arXiv:2211.14982",
    "title": "Two Is Better Than One: Dual Embeddings for Complementary Product  Recommendations",
    "abstract": "Comments: Accepted at ICKG 2022",
    "descriptor": "\nComments: Accepted at ICKG 2022\n",
    "authors": [
      "Giorgi Kvernadze",
      "Putu Ayu G. Sudyanti",
      "Nishan Subedi",
      "Mohammad Hajiaghayi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.14982"
  },
  {
    "id": "arXiv:2211.15003",
    "title": "STAGE: Span Tagging and Greedy Inference Scheme for Aspect Sentiment  Triplet Extraction",
    "abstract": "Comments: Accepted by AAAI 2023",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Shuo Liang",
      "Wei Wei",
      "Xian-Ling Mao",
      "Yuanyuan Fu",
      "Rui Fang",
      "Dangyang Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15003"
  },
  {
    "id": "arXiv:2211.15225",
    "title": "Meet-in-the-middle: Multi-scale upsampling and matching for  cross-resolution face recognition",
    "abstract": "Meet-in-the-middle: Multi-scale upsampling and matching for  cross-resolution face recognition",
    "descriptor": "",
    "authors": [
      "Klemen Grm",
      "Berk Kemal \u00d6zata",
      "Vitomir \u0160truc",
      "Haz\u0131m Kemal Ekenel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15225"
  },
  {
    "id": "arXiv:2211.15271",
    "title": "The Myth of Culturally Agnostic AI Models",
    "abstract": "Comments: Accepted for \"Cultures in AI/AI in Culture\" NeurIPS 2022 Workshop",
    "descriptor": "\nComments: Accepted for \"Cultures in AI/AI in Culture\" NeurIPS 2022 Workshop\n",
    "authors": [
      "Eva Cetinic"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.15271"
  },
  {
    "id": "arXiv:2211.15320",
    "title": "RankDNN: Learning to Rank for Few-shot Learning",
    "abstract": "Comments: 12 pages, 4 figures. Accepted to AAAI2023. The code is available at: this https URL",
    "descriptor": "\nComments: 12 pages, 4 figures. Accepted to AAAI2023. The code is available at: this https URL\n",
    "authors": [
      "Qianyu Guo",
      "Hongtong Gong",
      "Xujun Wei",
      "Yanwei Fu",
      "Weifeng Ge",
      "Yizhou Yu",
      "Wenqiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15320"
  },
  {
    "id": "arXiv:2211.15335",
    "title": "You Can Have Better Graph Neural Networks by Not Training Weights at  All: Finding Untrained GNNs Tickets",
    "abstract": "Comments: Accepted by the LoG conference 2022 as a spotlight",
    "descriptor": "\nComments: Accepted by the LoG conference 2022 as a spotlight\n",
    "authors": [
      "Tianjin Huang",
      "Tianlong Chen",
      "Meng Fang",
      "Vlado Menkovski",
      "Jiaxu Zhao",
      "Lu Yin",
      "Yulong Pei",
      "Decebal Constantin Mocanu",
      "Zhangyang Wang",
      "Mykola Pechenizkiy",
      "Shiwei Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.15335"
  },
  {
    "id": "arXiv:2211.15474",
    "title": "Unsupervised Superpixel Generation using Edge-Sparse Embedding",
    "abstract": "Unsupervised Superpixel Generation using Edge-Sparse Embedding",
    "descriptor": "",
    "authors": [
      "Jakob Geusen",
      "Gustav Bredell",
      "Tianfei Zhou",
      "Ender Konukoglu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15474"
  },
  {
    "id": "arXiv:2211.15494",
    "title": "Automated Routing of Droplets for DNA Storage on a Digital Microfluidics  Platform",
    "abstract": "Comments: 16 pages, 23 figures, 59 references. To be submitted to the \"Royal Society of Chemistry: Lab on a Chip\" journal",
    "descriptor": "\nComments: 16 pages, 23 figures, 59 references. To be submitted to the \"Royal Society of Chemistry: Lab on a Chip\" journal\n",
    "authors": [
      "Ajay Manicka",
      "Andrew Stephan",
      "Sriram Chari",
      "Gemma Mendonsa",
      "Peyton Okubo",
      "John Stolzberg-Schray",
      "Anil Reddy",
      "Marc Riedel"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2211.15494"
  },
  {
    "id": "arXiv:2211.15661",
    "title": "What learning algorithm is in-context learning? Investigations with  linear models",
    "abstract": "Comments: fix url in the abstract",
    "descriptor": "\nComments: fix url in the abstract\n",
    "authors": [
      "Ekin Aky\u00fcrek",
      "Dale Schuurmans",
      "Jacob Andreas",
      "Tengyu Ma",
      "Denny Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.15661"
  },
  {
    "id": "arXiv:2211.15662",
    "title": "High-fidelity 3D GAN Inversion by Pseudo-multi-view Optimization",
    "abstract": "Comments: Project website: this https URL ; Github link: this https URL",
    "descriptor": "\nComments: Project website: this https URL ; Github link: this https URL\n",
    "authors": [
      "Jiaxin Xie",
      "Hao Ouyang",
      "Jingtan Piao",
      "Chenyang Lei",
      "Qifeng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.15662"
  }
]
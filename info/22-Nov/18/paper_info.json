[
  {
    "id": "arXiv:2211.09124",
    "title": "A Review of Intelligent Music Generation Systems",
    "abstract": "Intelligent music generation, one of the most popular subfields of computer\ncreativity, can lower the creative threshold for non-specialists and increase\nthe efficiency of music creation. In the last five years, the quality of\nalgorithm-based automatic music generation has increased significantly,\nmotivated by the use of modern generative algorithms to learn the patterns\nimplicit within a piece of music based on rule constraints or a musical corpus,\nthus generating music samples in various styles. Some of the available\nliterature reviews lack a systematic benchmark of generative models and are\ntraditional and conservative in their perspective, resulting in a vision of the\nfuture development of the field that is not deeply integrated with the current\nrapid scientific progress. In this paper, we conduct a comprehensive survey and\nanalysis of recent intelligent music generation techniques,provide a critical\ndiscussion, explicitly identify their respective characteristics, and present\nthem in a general table. We first introduce how music as a stream of\ninformation is encoded and the relevant datasets, then compare different types\nof generation algorithms, summarize their strengths and weaknesses, and discuss\nexisting methods for evaluation. Finally, the development of artificial\nintelligence in composition is studied, especially by comparing the different\ncharacteristics of music generation techniques in the East and West and\nanalyzing the development prospects in this field.",
    "descriptor": "\nComments: Overall 24 Pages, 11 Figures, 2 Tables, 96 References items\n",
    "authors": [
      "Ziyi Zhao",
      "Hanwei Liu",
      "Song Li",
      "Junwei Pang",
      "Maoqing Zhang",
      "Yi Qin",
      "Lei Wang",
      "Qidi Wu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.09124"
  },
  {
    "id": "arXiv:2211.09146",
    "title": "A Unified Multimodal De- and Re-coupling Framework for RGB-D Motion  Recognition",
    "abstract": "Motion recognition is a promising direction in computer vision, but the\ntraining of video classification models is much harder than images due to\ninsufficient data and considerable parameters. To get around this, some works\nstrive to explore multimodal cues from RGB-D data. Although improving motion\nrecognition to some extent, these methods still face sub-optimal situations in\nthe following aspects: (i) Data augmentation, i.e., the scale of the RGB-D\ndatasets is still limited, and few efforts have been made to explore novel data\naugmentation strategies for videos; (ii) Optimization mechanism, i.e., the\ntightly space-time-entangled network structure brings more challenges to\nspatiotemporal information modeling; And (iii) cross-modal knowledge fusion,\ni.e., the high similarity between multimodal representations caused to\ninsufficient late fusion. To alleviate these drawbacks, we propose to improve\nRGB-D-based motion recognition both from data and algorithm perspectives in\nthis paper. In more detail, firstly, we introduce a novel video data\naugmentation method dubbed ShuffleMix, which acts as a supplement to MixUp, to\nprovide additional temporal regularization for motion recognition. Secondly, a\nUnified Multimodal De-coupling and multi-stage Re-coupling framework, termed\nUMDR, is proposed for video representation learning. Finally, a novel\ncross-modal Complement Feature Catcher (CFCer) is explored to mine potential\ncommonalities features in multimodal information as the auxiliary fusion\nstream, to improve the late fusion results. The seamless combination of these\nnovel designs forms a robust spatiotemporal representation and achieves better\nperformance than state-of-the-art methods on four public motion datasets.\nSpecifically, UMDR achieves unprecedented improvements of +4.5% on the Chalearn\nIsoGD dataset.Our code is available at\nhttps://github.com/zhoubenjia/MotionRGBD-PAMI.",
    "descriptor": "",
    "authors": [
      "Benjia Zhou",
      "Pichao Wang",
      "Jun Wan",
      "Yanyan Liang",
      "Fan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.09146"
  },
  {
    "id": "arXiv:2211.09155",
    "title": "Learnable Graph Convolutional Network and Feature Fusion for Multi-view  Learning",
    "abstract": "In practical applications, multi-view data depicting objectives from assorted\nperspectives can facilitate the accuracy increase of learning algorithms.\nHowever, given multi-view data, there is limited work for learning\ndiscriminative node relationships and graph information simultaneously via\ngraph convolutional network that has drawn the attention from considerable\nresearchers in recent years. Most of existing methods only consider the\nweighted sum of adjacency matrices, yet a joint neural network of both feature\nand graph fusion is still under-explored. To cope with these issues, this paper\nproposes a joint deep learning framework called Learnable Graph Convolutional\nNetwork and Feature Fusion (LGCN-FF), consisting of two stages: feature fusion\nnetwork and learnable graph convolutional network. The former aims to learn an\nunderlying feature representation from heterogeneous views, while the latter\nexplores a more discriminative graph fusion via learnable weights and a\nparametric activation function dubbed Differentiable Shrinkage Activation (DSA)\nfunction. The proposed LGCN-FF is validated to be superior to various\nstate-of-the-art methods in multi-view semi-supervised classification.",
    "descriptor": "",
    "authors": [
      "Zhaoliang Chen",
      "Lele Fu",
      "Jie Yao",
      "Wenzhong Guo",
      "Claudia Plant",
      "Shiping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09155"
  },
  {
    "id": "arXiv:2211.09156",
    "title": "Occlusion-Aware MPC for Guaranteed Safe Robot Navigation with Unseen  Dynamic Obstacles",
    "abstract": "For safe navigation in dynamic uncertain environments, robotic systems rely\non the perception and prediction of other agents. Particularly, in occluded\nareas where cameras and LiDAR give no data, the robot must be able to reason\nabout potential movements of invisible dynamic agents. This work presents a\nprovably safe motion planning scheme for real-time navigation in an a priori\nunmapped environment, where occluded dynamic agents are present. Safety\nguarantees are provided based on reachability analysis. Forward reachable sets\nassociated with potential occluded agents, such as pedestrians, are computed\nand incorporated into planning. An iterative optimization-based planner is\npresented that alternates between two optimizations: nonlinear Model Predictive\nControl (NMPC) and collision avoidance. Recursive feasibility of the MPC is\nguaranteed by introducing a terminal stopping constraint. The effectiveness of\nthe proposed algorithm is demonstrated through simulation studies and hardware\nexperiments with a TurtleBot robot. A video of experimental results is\navailable at \\url{https://youtu.be/OUnkB5Feyuk}.",
    "descriptor": "",
    "authors": [
      "Roya Firoozi",
      "Alexandre Mir",
      "Gadi Sznaier Camps",
      "Mac Schwager"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.09156"
  },
  {
    "id": "arXiv:2211.09159",
    "title": "Unified Question Answering in Slovene",
    "abstract": "Question answering is one of the most challenging tasks in language\nunderstanding. Most approaches are developed for English, while less-resourced\nlanguages are much less researched. We adapt a successful English\nquestion-answering approach, called UnifiedQA, to the less-resourced Slovene\nlanguage. Our adaptation uses the encoder-decoder transformer SloT5 and mT5\nmodels to handle four question-answering formats: yes/no, multiple-choice,\nabstractive, and extractive. We use existing Slovene adaptations of four\ndatasets, and machine translate the MCTest dataset. We show that a general\nmodel can answer questions in different formats at least as well as specialized\nmodels. The results are further improved using cross-lingual transfer from\nEnglish. While we produce state-of-the-art results for Slovene, the performance\nstill lags behind English.",
    "descriptor": "\nComments: 4 pages,published in Proceedings of the 25th International Multiconference INFORMATION SOCIETY - IS 2012, Volume A -Slovenian Conference on Artificial Intelligence SCAI 2022, Ljubljana, 2022, pp. 23-26\n",
    "authors": [
      "Katja Logar",
      "Marko Robnik-\u0160ikonja"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.09159"
  },
  {
    "id": "arXiv:2211.09162",
    "title": "Performance Comparison of DAOS and Lustre for Object Data Storage  Approaches",
    "abstract": "High-performance object stores are an emerging technology which offers an\nalternative solution in the field of HPC storage, with potential to address\nlong-standing scalability issues in traditional distributed POSIX file systems\ndue to excessive consistency assurance and metadata prescriptiveness.\nIn this paper we assess the performance of storing object-like data within a\nstandard file system, where the configuration and access mechanisms have not\nbeen optimised for object access behaviour, and compare with and investigate\nthe benefits of using an object storage system.\nWhilst this approach is not exploiting the file system in a standard way,\nthis work allows us to investigate whether the underlying storage technology\nperformance is more or less important than the software interface and\ninfrastructure a file system or object store provides.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2208.06752\n",
    "authors": [
      "Nicolau Manubens",
      "Simon D. Smart",
      "Tiago Quintino",
      "Adrian Jackson"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.09162"
  },
  {
    "id": "arXiv:2211.09165",
    "title": "Improving Effectiveness of Seamless Redundancy in Real Industrial Wi-Fi  Networks",
    "abstract": "Reliability and determinism of Wi-Fi can be tangibly improved by means of\nseamless redundancy, to the point of making this technology suitable for\nindustrial environments. As pointed out in recent papers, the most benefits can\nbe achieved when no phenomena can simultaneously affect transmissions on all\nchannels of a redundant link. In this paper, several aspects are analyzed\nwhich, if not properly counteracted, may worsen seamless redundancy\neffectiveness. Effects they cause on communication have been experimentally\nevaluated in real testbeds, which rely on commercial Wi-Fi devices. Then,\npractical guidelines are provided, which aim at preventing joint interference\nthrough a careful system design. Results show that measured communication\nquality can be made as good as expected in theory.",
    "descriptor": "\nComments: preprint, 13 pages\n",
    "authors": [
      "Gianluca Cena",
      "Stefano Scanzio",
      "Adriano Valenzano"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.09165"
  },
  {
    "id": "arXiv:2211.09169",
    "title": "Engineering Monosemanticity in Toy Models",
    "abstract": "In some neural networks, individual neurons correspond to natural\n``features'' in the input. Such \\emph{monosemantic} neurons are of great help\nin interpretability studies, as they can be cleanly understood. In this work we\nreport preliminary attempts to engineer monosemanticity in toy models. We find\nthat models can be made more monosemantic without increasing the loss by just\nchanging which local minimum the training process finds. More monosemantic loss\nminima have moderate negative biases, and we are able to use this fact to\nengineer highly monosemantic models. We are able to mechanistically interpret\nthese models, including the residual polysemantic neurons, and uncover a simple\nyet surprising algorithm. Finally, we find that providing models with more\nneurons per layer makes the models more monosemantic, albeit at increased\ncomputational cost. These findings point to a number of new questions and\navenues for engineering monosemanticity, which we intend to study these in\nfuture work.",
    "descriptor": "\nComments: 31 pages, 26 figures\n",
    "authors": [
      "Adam S. Jermyn",
      "Nicholas Schiefer",
      "Evan Hubinger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.09169"
  },
  {
    "id": "arXiv:2211.09171",
    "title": "Efficient URLLC with a Reconfigurable Intelligent Surface and Imperfect  Device Tracking",
    "abstract": "The use of Reconfigurable Intelligent Surfaces (RIS) technology to extend\ncoverage and allow for better control of the wireless environment has been\nproposed in several use cases, including Ultra-Reliable Low-Latency\nCommunications (URLLC), communications. However, the extremely challenging\nlatency constraint makes explicit channel estimation difficult, so positioning\ninformation is often used to configure the RIS and illuminate the receiver\ndevice. In this work, we analyze the effect of imperfections in the positioning\ninformation on the reliability, deriving an upper bound to the outage\nprobability. We then use this bound to perform power control, efficiently\nfinding the minimum power that respects the URLLC constraints under positioning\nuncertainty. The optimization is conservative, so that all points respect the\nURLLC constraints, and the bound is relatively tight, with an optimality gap\nbetween 1.5 and 4.5~dB.",
    "descriptor": "\nComments: Submitted to ICC 2023, the copyright may be transferred without further notice\n",
    "authors": [
      "Fabio Saggese",
      "Federico Chiariotti",
      "Kimmo Kansanen",
      "Petar Popovski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.09171"
  },
  {
    "id": "arXiv:2211.09172",
    "title": "Deep Emotion Recognition in Textual Conversations: A Survey",
    "abstract": "While Emotion Recognition in Conversations (ERC) has seen a tremendous\nadvancement in the last few years, new applications and implementation\nscenarios present novel challenges and opportunities. These range from\nleveraging the conversational context, speaker and emotion dynamics modelling,\nto interpreting common sense expressions, informal language and sarcasm,\naddressing challenges of real time ERC and recognizing emotion causes. This\nsurvey starts by introducing ERC, elaborating on the challenges and\nopportunities pertaining to this task. It proceeds with a description of the\nmain emotion taxonomies and methods to deal with subjectivity in annotations.\nIt then describes Deep Learning methods relevant for ERC, word embeddings, and\nelaborates on the use of performance metrics for the task and methods to deal\nwith the typically unbalanced ERC datasets. This is followed by a description\nand benchmark of key ERC works along with comprehensive tables comparing\nseveral works regarding their methods and performance across different\ndatasets. The survey highlights the advantage of leveraging techniques to\naddress unbalanced data, the exploration of mixed emotions and the benefits of\nincorporating annotation subjectivity in the learning phase.",
    "descriptor": "",
    "authors": [
      "Patr\u00edcia Pereira",
      "Helena Moniz",
      "Joao Paulo Carvalho"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.09172"
  },
  {
    "id": "arXiv:2211.09174",
    "title": "CASPR: Customer Activity Sequence-based Prediction and Representation",
    "abstract": "Tasks critical to enterprise profitability, such as customer churn\nprediction, fraudulent account detection or customer lifetime value estimation,\nare often tackled by models trained on features engineered from customer data\nin tabular format. Application-specific feature engineering adds development,\noperationalization and maintenance costs over time. Recent advances in\nrepresentation learning present an opportunity to simplify and generalize\nfeature engineering across applications. When applying these advancements to\ntabular data researchers deal with data heterogeneity, variations in customer\nengagement history or the sheer volume of enterprise datasets. In this paper,\nwe propose a novel approach to encode tabular data containing customer\ntransactions, purchase history and other interactions into a generic\nrepresentation of a customer's association with the business. We then evaluate\nthese embeddings as features to train multiple models spanning a variety of\napplications. CASPR, Customer Activity Sequence-based Prediction and\nRepresentation, applies Transformer architecture to encode activity sequences\nto improve model performance and avoid bespoke feature engineering across\napplications. Our experiments at scale validate CASPR for both small \\& large\nenterprise applications.",
    "descriptor": "\nComments: Presented at the Table Representation Learning Workshop, NeurIPS 2022, New Orleans\n",
    "authors": [
      "Pin-Jung Chen",
      "Sahil Bhatnagar",
      "Damian Konrad Kowalczyk",
      "Mayank Shrivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.09174"
  },
  {
    "id": "arXiv:2211.09178",
    "title": "Bayesian Optimization for Online Management in Dynamic Mobile Edge  Computing",
    "abstract": "Recent years have witnessed the emergence of mobile edge computing (MEC), on\nthe premise of a cost-effective enhancement in the computational ability of\nhardware-constrained wireless devices (WDs) comprising the Internet of Things\n(IoT). In a general multi-server multi-user MEC system, each WD has a\ncomputational task to execute and has to select binary (off)loading decisions,\nalong with the analog-amplitude resource allocation variables in an online\nmanner, with the goal of minimizing the overall energy-delay cost (EDC) with\ndynamic system states. While past works typically rely on the explicit\nexpression of the EDC function, the present contribution considers a practical\nsetting, where in lieu of system state information, the EDC function is not\navailable in analytical form, and instead only the function values at queried\npoints are revealed. Towards tackling such a challenging online combinatorial\nproblem with only bandit information, novel Bayesian optimization (BO) based\napproaches are put forth by leveraging the multi-armed bandit (MAB) framework.\nPer time slot, the discrete offloading decisions are first obtained via the MAB\nmethod, and the analog resource allocation variables are subsequently optimized\nusing the BO selection rule. By exploiting both temporal and contextual\ninformation, two novel BO approaches, termed time-varying BO and contextual\ntime-varying BO, are developed. Numerical tests validate the merits of the\nproposed BO approaches compared with contemporary benchmarks under different\nMEC network sizes.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Jia Yan",
      "Qin Lu",
      "Georgios B. Giannakis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.09178"
  },
  {
    "id": "arXiv:2211.09185",
    "title": "Which tweets 'deserve' to be included in news stories? Chronemics of  tweet embedding",
    "abstract": "The use and selection of user-generated social media content, specifically\ntweets, as a news source has become an integral part of news production\npractice. Yet, the mapping and the extent of the nature of the practices in\nwhich news outlets integrate social media use are still lacking. This study\nfocuses on the pressures of immediacy on the media ecosystems, i.e., as\norganizational practices of news outlets that make choices related to social\nmedia content integration. By analyzing a large corpora of news outlets that\nhave embedded tweets, this study analyzes tweet embedding practices by\nspecifically focusing on the concept of chronemics, conceptualized here as the\ntime needed to embed tweets. Temporal constraints are particularly pressing for\njournalistic practices, given the continuous pressures of the 24/7 news cycle.\nWe ask two main questions: which types of outlets are quicker to embed tweets,\nand which types of users' tweets are more likely to be embedded quickly?",
    "descriptor": "",
    "authors": [
      "Munif Ishad Mujib",
      "Asta Zelenkauskaite",
      "Jake Ryland Williams"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.09185"
  },
  {
    "id": "arXiv:2211.09198",
    "title": "Cooperative 2D Reconfiguration using Spatio-Temporal Planning and Load  Transferring",
    "abstract": "We present progress on the problem of reconfiguring a 2D arrangement of\nbuilding material by a cooperative set of robots. These robots are subjected to\nthe constraints of avoiding obstacles and maintaining connectivity of the\nstructure. We develop two reconfiguration methods, one based on spatio-temporal\nplanning, and one based on target swapping. Both methods achieve coordinated\nmotion of robots by avoiding deadlocks and maintaining all constraints. Both\nmethods also increase efficiency by reducing the amount of waiting times and\nlowering combined travel costs. The resulting progress is validated by\nsimulations that also scale the number of robots.",
    "descriptor": "\nComments: seven pages, eight figures\n",
    "authors": [
      "Javier Garcia",
      "Michael Yannuzzi",
      "Peter Kramer",
      "Christian Rieck",
      "S\u00e1ndor P. Fekete",
      "Aaron T. Becker"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2211.09198"
  },
  {
    "id": "arXiv:2211.09200",
    "title": "Power-Estimation Trade-off of Vector-valued Witsenhausen Counterexample  with Causal Decoder",
    "abstract": "The vector-valued extension of the famous Witsenhausen counterexample setup\nis studied where the encoder, i.e. the first decision maker, non-causally knows\nand encodes the i.i.d. state sequence and the decoder, i.e. the second decision\nmaker, causally estimates the interim state. The coding scheme is transferred\nfrom the finite alphabet coordination problem for which it is proved to be\noptimal. The extension to the Gaussian setup is based on a non-standard weak\ntypicality approach and requires a careful average estimation error analysis\nsince the interim state is estimated by the decoder. We provide a single-letter\nexpression that characterizes the optimal trade-off between the Witsenhausen\npower cost and estimation cost. The two auxiliary random variables improve the\ncommunication with the decoder, while performing the dual role of the channel\ninput, which also controls the state of the system. Interestingly, we show that\na pair of discrete and continuous auxiliary random variables, outperforms both\nWitsenhausen two point strategy and the best affine policies. The optimal\nchoice of random variables remains unknown.",
    "descriptor": "",
    "authors": [
      "Ma\u00ebl Le Treust",
      "Tobias Oechtering"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.09200"
  },
  {
    "id": "arXiv:2211.09203",
    "title": "Multidimensional Eigenwave Multiplexing Modulation for Non-Stationary  Channels",
    "abstract": "While interference in time domain (caused by path difference) is mitigated by\nOFDM modulation, interference in frequency domain (due to velocity difference),\ncan be mitigated by OTFS modulation. However, in non-stationary channels, the\nrelative difference in acceleration will cause Inter-Doppler Interference (IDI)\nand a modulation method for mitigating IDI does not exist in the literature.\nBoth methods in the literature use carriers in a specific domain which achieve\northogonality in the target domain to mitigate interference. Moreover, those\nmodulation cannot directly incorporate space domain, which requires additional\nprecoding technique to mitigate inter-user interference (IUI) for MU-MIMO\nchannels. This work presents a generalized modulation for any multidimensional\nchannel. Recently, Higher Order Mercer's Theorem (HOGMT) [1] has been proposed\nto decompose multi-user non-stationary channels into independent fading\nsubchannels (Eigenwaves). Based on HOGMT decomposition, we develop\nMultidimensional Eigenwaves Multiplexing (MEM) modulation which uses jointly\northogonal eigenwaves, decomposed from the multidimensional channel as\nsubcarriers. Data symbols modulated by these eigenwaves can achieve\northogonality across each degree of freedom(e.g. space (users/antennas),\ntime-frequency and delay-Doppler). Consequently, the transmitted remain\nindependent over the high dimensional channel, thereby avoiding interference\nfrom other symbols.",
    "descriptor": "",
    "authors": [
      "Zhibin Zou",
      "Aveek Dutta"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.09203"
  },
  {
    "id": "arXiv:2211.09206",
    "title": "Learning to Kindle the Starlight",
    "abstract": "Capturing highly appreciated star field images is extremely challenging due\nto light pollution, the requirements of specialized hardware, and the high\nlevel of photographic skills needed. Deep learning-based techniques have\nachieved remarkable results in low-light image enhancement (LLIE) but have not\nbeen widely applied to star field image enhancement due to the lack of training\ndata. To address this problem, we construct the first Star Field Image\nEnhancement Benchmark (SFIEB) that contains 355 real-shot and 854\nsemi-synthetic star field images, all having the corresponding reference\nimages. Using the presented dataset, we propose the first star field image\nenhancement approach, namely StarDiffusion, based on conditional denoising\ndiffusion probabilistic models (DDPM). We introduce dynamic stochastic\ncorruptions to the inputs of conditional DDPM to improve the performance and\ngeneralization of the network on our small-scale dataset. Experiments show\npromising results of our method, which outperforms state-of-the-art low-light\nimage enhancement algorithms. The dataset and codes will be open-sourced.",
    "descriptor": "",
    "authors": [
      "Yu Yuan",
      "Jiaqi Wu",
      "Lindong Wang",
      "Zhongliang Jing",
      "Henry Leung",
      "Shuyuan Zhu",
      "Han Pan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.09206"
  },
  {
    "id": "arXiv:2211.09207",
    "title": "A Graph-Based Context-Aware Model to Understand Online Conversations",
    "abstract": "Online forums that allow for participatory engagement between users have been\ntransformative for the public discussion of many important issues. However,\nsuch conversations can sometimes escalate into full-blown exchanges of hate and\nmisinformation. Existing approaches in natural language processing (NLP), such\nas deep learning models for classification tasks, use as inputs only a single\ncomment or a pair of comments depending upon whether the task concerns the\ninference of properties of the individual comments or the replies between pairs\nof comments, respectively. But in online conversations, comments and replies\nmay be based on external context beyond the immediately relevant information\nthat is input to the model. Therefore, being aware of the conversations'\nsurrounding contexts should improve the model's performance for the inference\ntask at hand.\nWe propose GraphNLI, a novel graph-based deep learning architecture that uses\ngraph walks to incorporate the wider context of a conversation in a principled\nmanner. Specifically, a graph walk starts from a given comment and samples\n\"nearby\" comments in the same or parallel conversation threads, which results\nin additional embeddings that are aggregated together with the initial\ncomment's embedding. We then use these enriched embeddings for downstream NLP\nprediction tasks that are important for online conversations. We evaluate\nGraphNLI on two such tasks - polarity prediction and misogynistic hate speech\ndetection - and found that our model consistently outperforms all relevant\nbaselines for both tasks. Specifically, GraphNLI with a biased root-seeking\nrandom walk performs with a macro-F1 score of 3 and 6 percentage points better\nthan the best-performing BERT-based baselines for the polarity prediction and\nhate speech detection tasks, respectively.",
    "descriptor": "\nComments: 25 pages, 9 figures. arXiv admin note: text overlap with arXiv:2202.08175\n",
    "authors": [
      "Vibhor Agarwal",
      "Anthony P. Young",
      "Sagar Joglekar",
      "Nishanth Sastry"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.09207"
  },
  {
    "id": "arXiv:2211.09208",
    "title": "Low Complexity Dirty Paper Coding for MU-MIMO Channels",
    "abstract": "Dirty Paper Coding (DPC) is considered as the optimal precoding which\nachieves capacity for the Gaussian Multiple-Input Multiple-Output (MIMO)\nbroadcast channel (BC). However, to find the optimal precoding order, it needs\nto repeat N! times for N users as there are N! possible precoding orders. This\nextremely high complexity limits its practical use in modern wireless networks.\nIn this paper, we show the equivalence of DPC and the recently proposed Higher\nOrder Mercer's Theorem (HOGMT) precoding [1] in 2-D (spatial) case, which\nprovides an alternate implementation for DPC. Furthermore, we show that the\nproposed implementation method is linear over the permutation operator when\npermuting over multi-user channels. Therefore, we present a low complexity\nalgorithm that optimizes the precoding order for DPC with beamforming,\neliminating repeated computation of DPC for each precoding order. Simulations\nshow that our method can achieve the same result as conventional DPC with near\n30 dB lower complexity for N = 10 users.",
    "descriptor": "",
    "authors": [
      "Zhibin Zou",
      "Aveek Dutta"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.09208"
  },
  {
    "id": "arXiv:2211.09210",
    "title": "edBB-Demo: Biometrics and Behavior Analysis for Online Educational  Platforms",
    "abstract": "We present edBB-Demo, a demonstrator of an AI-powered research platform for\nstudent monitoring in remote education. The edBB platform aims to study the\nchallenges associated to user recognition and behavior understanding in digital\nplatforms. This platform has been developed for data collection, acquiring\nsignals from a variety of sensors including keyboard, mouse, webcam,\nmicrophone, smartwatch, and an Electroencephalography band. The information\ncaptured from the sensors during the student sessions is modelled in a\nmultimodal learning framework. The demonstrator includes: i) Biometric user\nauthentication in an unsupervised environment; ii) Human action recognition\nbased on remote video analysis; iii) Heart rate estimation from webcam video;\nand iv) Attention level estimation from facial expression analysis.",
    "descriptor": "\nComments: Accepted in \"AAAI-23 Conference on Artificial Intelligence (Demonstration Program)\"\n",
    "authors": [
      "Roberto Daza",
      "Aythami Morales",
      "Ruben Tolosana",
      "Luis F. Gomez",
      "Julian Fierrez",
      "Javier Ortega-Garcia"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09210"
  },
  {
    "id": "arXiv:2211.09224",
    "title": "Are we certain it's anomalous?",
    "abstract": "The progress in modelling time series and, more generally, sequences of\nstructured-data has recently revamped research in anomaly detection. The task\nstands for identifying abnormal behaviours in financial series, IT systems,\naerospace measurements, and the medical domain, where anomaly detection may aid\nin isolating cases of depression and attend the elderly. Anomaly detection in\ntime series is a complex task since anomalies are rare due to highly non-linear\ntemporal correlations and since the definition of anomalous is sometimes\nsubjective. Here we propose the novel use of Hyperbolic uncertainty for Anomaly\nDetection (HypAD). HypAD learns self-supervisedly to reconstruct the input\nsignal. We adopt best practices from the state-of-the-art to encode the\nsequence by an LSTM, jointly learnt with a decoder to reconstruct the signal,\nwith the aid of GAN critics. Uncertainty is estimated end-to-end by means of a\nhyperbolic neural network. By using uncertainty, HypAD may assess whether it is\ncertain about the input signal but it fails to reconstruct it because this is\nanomalous; or whether the reconstruction error does not necessarily imply\nanomaly, as the model is uncertain, e.g. a complex but regular input signal.\nThe novel key idea is that a detectable anomaly is one where the model is\ncertain but it predicts wrongly. HypAD outperforms the current state-of-the-art\nfor univariate anomaly detection on established benchmarks based on data from\nNASA, Yahoo, Numenta, Amazon, Twitter. It also yields state-of-the-art\nperformance on a multivariate dataset of anomaly activities in elderly home\nresidences, and it outperforms the baseline on SWaT. Overall, HypAD yields the\nlowest false alarms at the best performance rate, thanks to successfully\nidentifying detectable anomalies.",
    "descriptor": "\nComments: Submitted at IEEE Transactions on Neural Networks and Learning Systems\n",
    "authors": [
      "Alessandro Flaborea",
      "Bardh Prenkaj",
      "Bharti Munjal",
      "Marco Aurelio Sterpa",
      "Dario Aragona",
      "Luca Podo",
      "Fabio Galasso"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09224"
  },
  {
    "id": "arXiv:2211.09229",
    "title": "Improved Monotonicity Testers via Hypercube Embeddings",
    "abstract": "We show improved monotonicity testers for the Boolean hypercube under the\n$p$-biased measure, as well as over the hypergrid $[m]^n$. Our results are:\n1. For any $p\\in (0,1)$, for the $p$-biased hypercube we show a non-adaptive\ntester that makes $\\tilde{O}(\\sqrt{n}/\\varepsilon^2)$ queries, accepts monotone\nfunctions with probability $1$ and rejects functions that are $\\varepsilon$-far\nfrom monotone with probability at least $2/3$.\n2. For all $m\\in\\mathbb{N}$, we show an\n$\\tilde{O}(\\sqrt{n}m^3/\\varepsilon^2)$ query monotonicity tester over $[m]^n$.\nWe also establish corresponding directed isoperimetric inequalities in these\ndomains. Previously, the best known tester due to Black, Chakrabarty and\nSeshadhri had $\\Omega(n^{5/6})$ query complexity. Our results are optimal up to\npoly-logarithmic factors and the dependency on $m$.\nOur proof uses a notion of monotone embeddings of measures into the Boolean\nhypercube that can be used to reduce the problem of monotonicity testing over\nan arbitrary product domains to the Boolean cube. The embedding maps a function\nover a product domain of dimension $n$ into a function over a Boolean cube of a\nlarger dimension $n'$, while preserving its distance from being monotone; an\nembedding is considered efficient if $n'$ is not much larger than $n$, and we\nshow how to construct efficient embeddings in the above mentioned settings.",
    "descriptor": "",
    "authors": [
      "Mark Braverman",
      "Subhash Khot",
      "Guy Kindler",
      "Dor Minzer"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.09229"
  },
  {
    "id": "arXiv:2211.09231",
    "title": "The Surprising Effectiveness of Equivariant Models in Domains with  Latent Symmetry",
    "abstract": "Extensive work has demonstrated that equivariant neural networks can\nsignificantly improve sample efficiency and generalization by enforcing an\ninductive bias in the network architecture. These applications typically assume\nthat the domain symmetry is fully described by explicit transformations of the\nmodel inputs and outputs. However, many real-life applications contain only\nlatent or partial symmetries which cannot be easily described by simple\ntransformations of the input. In these cases, it is necessary to learn symmetry\nin the environment instead of imposing it mathematically on the network\narchitecture. We discover, surprisingly, that imposing equivariance constraints\nthat do not exactly match the domain symmetry is very helpful in learning the\ntrue symmetry in the environment. We differentiate between extrinsic and\nincorrect symmetry constraints and show that while imposing incorrect symmetry\ncan impede the model's performance, imposing extrinsic symmetry can actually\nimprove performance. We demonstrate that an equivariant model can significantly\noutperform non-equivariant methods on domains with latent symmetries both in\nsupervised learning and in reinforcement learning for robotic manipulation and\ncontrol problems.",
    "descriptor": "",
    "authors": [
      "Dian Wang",
      "Jung Yeon Park",
      "Neel Sortur",
      "Lawson L.S. Wong",
      "Robin Walters",
      "Robert Platt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.09231"
  },
  {
    "id": "arXiv:2211.09233",
    "title": "Prompt Tuning for Parameter-efficient Medical Image Segmentation",
    "abstract": "Neural networks pre-trained on a self-supervision scheme have become the\nstandard when operating in data rich environments with scarce annotations. As\nsuch, fine-tuning a model to a downstream task in a parameter-efficient but\neffective way, e.g. for a new set of classes in the case of semantic\nsegmentation, is of increasing importance. In this work, we propose and\ninvestigate several contributions to achieve a parameter-efficient but\neffective adaptation for semantic segmentation on two medical imaging datasets.\nRelying on the recently popularized prompt tuning approach, we provide a\nprompt-able UNet (PUNet) architecture, that is frozen after pre-training, but\nadaptable throughout the network by class-dependent learnable prompt tokens. We\npre-train this architecture with a dedicated dense self-supervision scheme\nbased on assignments to online generated prototypes (contrastive prototype\nassignment, CPA) of a student teacher combination alongside a concurrent\nsegmentation loss on a subset of classes. We demonstrate that the resulting\nneural network model is able to attenuate the gap between fully fine-tuned and\nparameter-efficiently adapted models on CT imaging datasets. As such, the\ndifference between fully fine-tuned and prompt-tuned variants amounts to only\n3.83 pp for the TCIA/BTCV dataset and 2.67 pp for the CT-ORG dataset in the\nmean Dice Similarity Coefficient (DSC, in %) while only prompt tokens,\ncorresponding to 0.85% of the pre-trained backbone model with 6.8M frozen\nparameters, are adjusted. The code for this work is available on\nhttps://github.com/marcdcfischer/PUNet .",
    "descriptor": "",
    "authors": [
      "Marc Fischer",
      "Alexander Bartler",
      "Bin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09233"
  },
  {
    "id": "arXiv:2211.09235",
    "title": "Artificial Disfluency Detection, Uh No, Disfluency Generation for the  Masses",
    "abstract": "Existing approaches for disfluency detection typically require the existence\nof large annotated datasets. However, current datasets for this task are\nlimited, suffer from class imbalance, and lack some types of disfluencies that\ncan be encountered in real-world scenarios. This work proposes LARD, a method\nfor automatically generating artificial disfluencies from fluent text. LARD can\nsimulate all the different types of disfluencies (repetitions, replacements and\nrestarts) based on the reparandum/interregnum annotation scheme. In addition,\nit incorporates contextual embeddings into the disfluency generation to produce\nrealistic context-aware artificial disfluencies. Since the proposed method\nrequires only fluent text, it can be used directly for training, bypassing the\nrequirement of annotated disfluent data. Our empirical evaluation demonstrates\nthat LARD can indeed be effectively used when no or only a few data are\navailable. Furthermore, our detailed analysis suggests that the proposed method\ngenerates realistic disfluencies and increases the accuracy of existing\ndisfluency detectors.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "T. Passali",
      "T. Mavropoulos",
      "G. Tsoumakas",
      "G. Meditskos",
      "S. Vrochidis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.09235"
  },
  {
    "id": "arXiv:2211.09238",
    "title": "Learning unfolded networks with a cyclic group structure",
    "abstract": "Deep neural networks lack straightforward ways to incorporate domain\nknowledge and are notoriously considered black boxes. Prior works attempted to\ninject domain knowledge into architectures implicitly through data\naugmentation. Building on recent advances on equivariant neural networks, we\npropose networks that explicitly encode domain knowledge, specifically\nequivariance with respect to rotations. By using unfolded architectures, a rich\nframework that originated from sparse coding and has theoretical guarantees, we\npresent interpretable networks with sparse activations. The equivariant\nunfolded networks compete favorably with baselines, with only a fraction of\ntheir parameters, as showcased on (rotated) MNIST and CIFAR-10.",
    "descriptor": "\nComments: Accepted as an extended abstract in NeurIPS Workshop on Symmetry and Geometry in Neural Representations\n",
    "authors": [
      "Emmanouil Theodosis",
      "Demba Ba"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09238"
  },
  {
    "id": "arXiv:2211.09245",
    "title": "High-energy-density 3D-printed Composite Springs for Lightweight and  Energy-efficient Compliant Robots",
    "abstract": "Springs store mechanical energy similar to batteries storing electrical\nenergy. However, conventional springs are heavy and store limited amounts of\nmechanical energy relative to batteries, i.e they have low mass-energy-density.\nNext-generation 3D printing technology could potentially enable manufacturing\nlow cost lightweight springs with high energy storage capacity. Here we present\na novel design of a high-energy-density 3D printed torsional spiral spring\nusing structural optimization. By optimizing the internal structure of the\nspring we obtained a 45% increase in the mass energy density, compared to a\ntorsional spiral spring of uniform thickness. Our result suggests that\noptimally designed 3D printed springs could enable robots to recycle more\nmechanical energy per unit mass, potentially reducing the energy required to\ncontrol robots.",
    "descriptor": "\nComments: This work has been submitted to the IEEE International Conference on Robotics and Automation 2023 for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Amanda Sutrisno",
      "David J. Braun"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.09245"
  },
  {
    "id": "arXiv:2211.09251",
    "title": "On the Power of Learning-Augmented BSTs",
    "abstract": "We present the first Learning-Augmented Binary Search Tree(BST) that attains\nStatic Optimality and Working-Set Bound given rough predictions. Following the\nrecent studies in algorithms with predictions and learned index structures,\nLin, Luo, and Woodruff (ICML 2022) introduced the concept of Learning-Augmented\nBSTs, which aim to improve BSTs with learned advice. Unfortunately, their\nconstruction gives only static optimality under strong assumptions on the\ninput.\nIn this paper, we present a simple BST maintenance scheme that benefits from\nlearned advice. With proper predictions, the scheme achieves Static Optimality\nand Working-Set Bound, respectively, which are important performance measures\nfor BSTs. Moreover, the scheme is robust to prediction errors and makes no\nassumption on the input.",
    "descriptor": "",
    "authors": [
      "Jingbang Chen",
      "Li Chen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09251"
  },
  {
    "id": "arXiv:2211.09253",
    "title": "Beurling-Selberg Extremization for Dual-Blind Deconvolution Recovery in  Joint Radar-Communications",
    "abstract": "Recent interest in integrated sensing and communications has led to the\ndesign of novel signal processing techniques to recover information from an\noverlaid radar-communications signal. Here, we focus on a spectral coexistence\nscenario, wherein the channels and transmit signals of both radar and\ncommunications systems are unknown to the common receiver. In this dual-blind\ndeconvolution (DBD) problem, the receiver admits a multi-carrier wireless\ncommunications signal that is overlaid with the radar signal reflected off\nmultiple targets. The communications and radar channels are represented by\ncontinuous-valued range-times or delays corresponding to multiple transmission\npaths and targets, respectively. Prior works addressed recovery of unknown\nchannels and signals in this ill-posed DBD problem through atomic norm\nminimization but contingent on individual minimum separation conditions for\nradar and communications channels. In this paper, we provide an optimal joint\nseparation condition using extremal functions from the Beurling-Selberg\ninterpolation theory. Thereafter, we formulate DBD as a low-rank modified\nHankel matrix retrieval and solve it via nuclear norm minimization. We estimate\nthe unknown target and communications parameters from the recovered low-rank\nmatrix using multiple signal classification (MUSIC) method. We show that the\njoint separation condition also guarantees that the underlying Vandermonde\nmatrix for MUSIC is well-conditioned. Numerical experiments validate our\ntheoretical findings.",
    "descriptor": "\nComments: 7 pages, 2 figures\n",
    "authors": [
      "Jonathan Monsalve",
      "Edwin Vargas",
      "Kumar Vijay Mishra",
      "Brian M. Sadler",
      "Henry Arguello"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Functional Analysis (math.FA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.09253"
  },
  {
    "id": "arXiv:2211.09257",
    "title": "An Integrated Optical Circuit Architecture for Inverse-Designed Silicon  Photonic Components",
    "abstract": "In this work, we demonstrate a compact toolkit of inverse-designed\ntopologically optimized silicon-photonic devices that are arranged in a\nplug-and-play fashion to realize many different photonic integrated circuits,\nboth passive and active, each with a small footprint. The silicon-on-insulator\n1550-nm toolkit contains a 2x2 3dB splitter-combiner, a 2x2 waveguide crossover\nand a 2x2 all-forward add-drop resonator. The resonator can become a 2x2\nelectro-optical crossbar switch by means of the thermo-optical effect or\nphase-change cladding or free-carrier injection. For each of the ten circuits\ndemonstrated in this work, the toolkit of photonic devices enables the compact\ncircuit to achieve low insertion loss and low crosstalk. By adopting the\nsophisticated inverse-design approach, the design structure, shape, and sizing\nof each individual device can be made more flexible to better suit the\narchitecture of the greater circuit. For a compact architecture, we present a\nunified, parallel waveguide circuit framework into which the devices are\ndesigned to fit seamlessly, thus enabling low-complexity circuit design.",
    "descriptor": "\nComments: 8 pages, 14 figures\n",
    "authors": [
      "Richard Soref",
      "Dusan Gostimirovic"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2211.09257"
  },
  {
    "id": "arXiv:2211.09259",
    "title": "The Missing Indicator Method: From Low to High Dimensions",
    "abstract": "Missing data is common in applied data science, particularly for tabular data\nsets found in healthcare, social sciences, and natural sciences. Most\nsupervised learning methods work only on complete data, thus requiring\npreprocessing, such as missing value imputation, to work on incomplete data\nsets. However, imputation discards potentially useful information encoded by\nthe pattern of missing values. For data sets with informative missing patterns,\nthe Missing Indicator Method (MIM), which adds indicator variables to indicate\nthe missing pattern, can be used in conjunction with imputation to improve\nmodel performance. We show experimentally that MIM improves performance for\ninformative missing values, and we prove that MIM does not hurt linear models\nasymptotically for uninformative missing values. Nonetheless, MIM can increase\nvariance if many of the added indicators are uninformative, causing harm\nparticularly for high-dimensional data sets. To address this issue, we\nintroduce Selective MIM (SMIM), a method that adds missing indicators only for\nfeatures that have informative missing patterns. We show empirically that SMIM\nperforms at least as well as MIM across a range of experimental settings, and\nimproves MIM for high-dimensional data.",
    "descriptor": "",
    "authors": [
      "Mike Van Ness",
      "Tomas M. Bosschieter",
      "Roberto Halpin-Gregorio",
      "Madeleine Udell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.09259"
  },
  {
    "id": "arXiv:2211.09260",
    "title": "Task-aware Retrieval with Instructions",
    "abstract": "We study the problem of retrieval with instructions, where users of a\nretrieval system explicitly describe their intent along with their queries,\nmaking the system task-aware. We aim to develop a general-purpose task-aware\nretrieval systems using multi-task instruction tuning that can follow\nhuman-written instructions to find the best documents for a given query. To\nthis end, we introduce the first large-scale collection of approximately 40\nretrieval datasets with instructions, and present TART, a multi-task retrieval\nsystem trained on the diverse retrieval tasks with instructions. TART shows\nstrong capabilities to adapt to a new task via instructions and advances the\nstate of the art on two zero-shot retrieval benchmarks, BEIR and LOTTE,\noutperforming models up to three times larger. We further introduce a new\nevaluation setup to better reflect real-world scenarios, pooling diverse\ndocuments and tasks. In this setup, TART significantly outperforms competitive\nbaselines, further demonstrating the effectiveness of guiding retrieval with\ninstructions.",
    "descriptor": "",
    "authors": [
      "Akari Asai",
      "Timo Schick",
      "Patrick Lewis",
      "Xilun Chen",
      "Gautier Izacard",
      "Sebastian Riedel",
      "Hannaneh Hajishirzi",
      "Wen-tau Yih"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.09260"
  },
  {
    "id": "arXiv:2211.09263",
    "title": "Informative Initialization and Kernel Selection Improves t-SNE for  Biological Sequences",
    "abstract": "The t-distributed stochastic neighbor embedding (t- SNE) is a method for\ninterpreting high dimensional (HD) data by mapping each point to a low\ndimensional (LD) space (usually two-dimensional). It seeks to retain the\nstructure of the data. An important component of the t-SNE algorithm is the\ninitialization procedure, which begins with the random initialization of an LD\nvector. Points in this initial vector are then updated to minimize the loss\nfunction (the KL divergence) iteratively using gradient descent. This leads\ncomparable points to attract one another while pushing dissimilar points apart.\nWe believe that, by default, these algorithms should employ some form of\ninformative initialization. Another essential component of the t-SNE is using a\nkernel matrix, a similarity matrix comprising the pairwise distances among the\nsequences. For t-SNE-based visualization, the Gaussian kernel is employed by\ndefault in the literature. However, we show that kernel selection can also play\na crucial role in the performance of t-SNE. In this work, we assess the\nperformance of t-SNE with various alternative initialization methods and\nkernels, using four different sets, out of which three are biological sequences\n(nucleotide, protein, etc.) datasets obtained from various sources, such as the\nwell-known GISAID database for sequences of the SARS- CoV-2 virus. We perform\nsubjective and objective assessments of these alternatives. We use the\nresulting t-SNE plots and k- ary neighborhood agreement (k-ANA) to evaluate and\ncompare the proposed methods with the baselines. We show that by using\ndifferent techniques, such as informed initialization and kernel matrix\nselection, that t-SNE performs significantly better. Moreover, we show that\nt-SNE also takes fewer iterations to converge faster with more intelligent\ninitialization.",
    "descriptor": "\nComments: Accepted to IEEE BigData 2022\n",
    "authors": [
      "Prakash Chourasia",
      "Sarwan Ali",
      "Murray Patterson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09263"
  },
  {
    "id": "arXiv:2211.09267",
    "title": "Reflect, Not Reflex: Inference-Based Common Ground Improves Dialogue  Response Quality",
    "abstract": "Human communication relies on common ground (CG), the mutual knowledge and\nbeliefs shared by participants, to produce coherent and interesting\nconversations. In this paper, we demonstrate that current response generation\n(RG) models produce generic and dull responses in dialogues because they act\nreflexively, failing to explicitly model CG, both due to the lack of CG in\ntraining data and the standard RG training procedure. We introduce Reflect, a\ndataset that annotates dialogues with explicit CG (materialized as inferences\napproximating shared knowledge and beliefs) and solicits 9k diverse\nhuman-generated responses each following one common ground. Using Reflect, we\nshowcase the limitations of current dialogue data and RG models: less than half\nof the responses in current data are rated as high quality (sensible, specific,\nand interesting) and models trained using this data have even lower quality,\nwhile most Reflect responses are judged high quality. Next, we analyze whether\nCG can help models produce better-quality responses by using Reflect CG to\nguide RG models. Surprisingly, we find that simply prompting GPT3 to \"think\"\nabout CG generates 30% more quality responses, showing promising benefits to\nintegrating CG into the RG process.",
    "descriptor": "\nComments: Accepted at EMNLP-2022. 19 pages, 17 figures, 4 tables\n",
    "authors": [
      "Pei Zhou",
      "Hyundong Cho",
      "Pegah Jandaghi",
      "Dong-Ho Lee",
      "Bill Yuchen Lin",
      "Jay Pujara",
      "Xiang Ren"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09267"
  },
  {
    "id": "arXiv:2211.09273",
    "title": "Privacy against Real-Time Speech Emotion Detection via Acoustic  Adversarial Evasion of Machine Learning",
    "abstract": "Emotional Surveillance is an emerging area with wide-reaching privacy\nconcerns. These concerns are exacerbated by ubiquitous IoT devices with\nmultiple sensors that can support these surveillance use cases. The work\npresented here considers one such use case: the use of a speech emotion\nrecognition (SER) classifier tied to a smart speaker. This work demonstrates\nthe ability to evade black-box SER classifiers tied to a smart speaker without\ncompromising the utility of the smart speaker. This privacy concern is\nconsidered through the lens of adversarial evasion of machine learning. Our\nsolution, Defeating Acoustic Recognition of Emotion via Genetic Programming\n(DARE-GP), uses genetic programming to generate non-invasive additive audio\nperturbations (AAPs). By constraining the evolution of these AAPs,\ntranscription accuracy can be protected while simultaneously degrading SER\nclassifier performance. The additive nature of these AAPs, along with an\napproach that generates these AAPs for a fixed set of users in an utterance and\nuser location-independent manner, supports real-time, real-world evasion of SER\nclassifiers. DARE-GP's use of spectral features, which underlay the emotional\ncontent of speech, allows the transferability of AAPs to previously unseen\nblack-box SER classifiers. Further, DARE-GP outperforms state-of-the-art SER\nevasion techniques and is robust against defenses employed by a knowledgeable\nadversary. The evaluations in this work culminate with acoustic evaluations\nagainst two off-the-shelf commercial smart speakers, where a single AAP could\nevade a black box classifier over 70% of the time. The final evaluation\ndeployed AAP playback on a small-form-factor system (raspberry pi) integrated\nwith a wake-word system to evaluate the efficacy of a real-world, real-time\ndeployment where DARE-GP is automatically invoked with the smart speaker's wake\nword.",
    "descriptor": "",
    "authors": [
      "Brian Testa",
      "Yi Xiao",
      "Avery Gump",
      "Asif Salekin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.09273"
  },
  {
    "id": "arXiv:2211.09283",
    "title": "Active Learning with Expected Error Reduction",
    "abstract": "Active learning has been studied extensively as a method for efficient data\ncollection. Among the many approaches in literature, Expected Error Reduction\n(EER) (Roy and McCallum) has been shown to be an effective method for active\nlearning: select the candidate sample that, in expectation, maximally decreases\nthe error on an unlabeled set. However, EER requires the model to be retrained\nfor every candidate sample and thus has not been widely used for modern deep\nneural networks due to this large computational cost. In this paper we\nreformulate EER under the lens of Bayesian active learning and derive a\ncomputationally efficient version that can use any Bayesian parameter sampling\nmethod (such as arXiv:1506.02142). We then compare the empirical performance of\nour method using Monte Carlo dropout for parameter sampling against state of\nthe art methods in the deep active learning literature. Experiments are\nperformed on four standard benchmark datasets and three WILDS datasets\n(arXiv:2012.07421). The results indicate that our method outperforms all other\nmethods except one in the data shift scenario: a model dependent,\nnon-information theoretic method that requires an order of magnitude higher\ncomputational cost (arXiv:1906.03671).",
    "descriptor": "",
    "authors": [
      "Stephen Mussmann",
      "Julia Reisler",
      "Daniel Tsai",
      "Ehsan Mousavi",
      "Shayne O'Brien",
      "Moises Goldszmidt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09283"
  },
  {
    "id": "arXiv:2211.09285",
    "title": "Optimizing Function Layout for Mobile Applications",
    "abstract": "Function layout, also referred to as function reordering or function\nplacement, is one of the most effective profile-guided compiler optimizations.\nBy reordering functions in a binary, compilers are able to greatly improve the\nperformance of large-scale applications or reduce the compressed size of mobile\napplications. Although the technique has been studied in the context of\nlarge-scale binaries, no recent study has investigated the impact of function\nlayout on mobile applications.\nIn this paper we develop the first principled solution for optimizing\nfunction layouts in the mobile space. To this end, we identify two important\noptimization goals, the compressed code size and the cold start-up time of a\nmobile application. Then we propose a formal model for the layout problem,\nwhose objective closely matches the goals. Our novel algorithm to optimize the\nlayout is inspired by the classic balanced graph partitioning problem. We\ncarefully engineer and implement the algorithm in an open source compiler,\nLLVM. An extensive evaluation of the new method on large commercial mobile\napplications indicates up to 2% compressed size reduction and up to 3% start-up\ntime improvement on top of the state-of-the-art approach.",
    "descriptor": "",
    "authors": [
      "Ellis Hoag",
      "Kyungwoo Lee",
      "Juli\u00e1n Mestre",
      "Sergey Pupyrev"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.09285"
  },
  {
    "id": "arXiv:2211.09286",
    "title": "Permutation-Invariant Tabular Data Synthesis",
    "abstract": "Tabular data synthesis is an emerging approach to circumvent strict\nregulations on data privacy while discovering knowledge through big data.\nAlthough state-of-the-art AI-based tabular data synthesizers, e.g., table-GAN,\nCTGAN, TVAE, and CTAB-GAN, are effective at generating synthetic tabular data,\ntheir training is sensitive to column permutations of input data. In this\npaper, we first conduct an extensive empirical study to disclose such a\nproperty of permutation invariance and an in-depth analysis of the existing\nsynthesizers. We show that changing the input column order worsens the\nstatistical difference between real and synthetic data by up to 38.67% due to\nthe encoding of tabular data and the network architectures. To fully unleash\nthe potential of big synthetic tabular data, we propose two solutions: (i)\nAE-GAN, a synthesizer that uses an autoencoder network to represent the tabular\ndata and GAN networks to synthesize the latent representation, and (ii) a\nfeature sorting algorithm to find the suitable column order of input data for\nCNN-based synthesizers. We evaluate the proposed solutions on five datasets in\nterms of the sensitivity to the column permutation, the quality of synthetic\ndata, and the utility in downstream analyses. Our results show that we enhance\nthe property of permutation-invariance when training synthesizers and further\nimprove the quality and utility of synthetic data, up to 22%, compared to the\nexisting synthesizers.",
    "descriptor": "\nComments: Paper is accepted in 2022 IEEE International Conference Big Data in Special Session Privacy and Security of Big Data (PSBD)\n",
    "authors": [
      "Yujin Zhu",
      "Zilong Zhao",
      "Robert Birke",
      "Lydia Y. Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09286"
  },
  {
    "id": "arXiv:2211.09288",
    "title": "Longitudinal thermal imaging for scalable non-residential HVAC and  occupant behaviour characterization",
    "abstract": "This work presents a study on the characterization of the air-conditioning\n(AC) usage pattern of non-residential buildings from thermal images collected\nfrom an urban-scale infrared (IR) observatory. To achieve this first, an image\nprocessing scheme, for cleaning and extraction of the temperature time series\nfrom the thermal images is implemented. To test the accuracy of the thermal\nmeasurements using IR camera, the extracted temperature is compared against the\nground truth surface temperature measurements. It is observed that the\ndetrended thermal measurements match well with the ground truth surface\ntemperature measurements. Subsequently, the operational pattern of the\nwater-cooled systems and window AC units are extracted from the analysis of the\nthermal signature. It is observed that for the water-cooled system, the\ndifference between the rate of change of the window and wall can be used to\nextract the operational pattern. While, in the case of the window AC units,\nwavelet transform of the AC unit temperature is used to extract the frequency\nand time domain information of the AC unit operation. The results of the\nanalysis are compared against the indoor temperature sensors installed in the\noffice spaces of the building. It is realized that the accuracy in the\nprediction of the operational pattern is highest between 8 pm to 10 am, and it\nreduces during the day because of solar radiation and high daytime temperature.\nSubsequently, a characterization study is conducted for eight window/split AC\nunits from the thermal image collected during the nighttime. This forms one of\nthe first studies on the operational behavior of HVAC systems for\nnon-residential buildings using the longitudinal thermal imaging technique. The\noutput from this study can be used to better understand the operational and\noccupant behavior, without requiring to deploy a large array of sensors in the\nbuilding space.",
    "descriptor": "",
    "authors": [
      "Vasantha Ramani",
      "Miguel Martin",
      "Pandarasamy Arjunan",
      "Adrian Chong",
      "Kameshwar Poolla",
      "Clayton Miller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.09288"
  },
  {
    "id": "arXiv:2211.09298",
    "title": "Asymptotic behaviour of a conservative reaction-diffusion system  associated with a Markov process algebra model",
    "abstract": "This paper demonstrates a lower and upper solution method to investigate the\nasymptotic behaviour of the conservative reaction-diffusion systems associated\nwith Markovian process algebra models. In particular, we have proved the\nuniform convergence of the solution to its constant equilibrium for a case\nstudy as time tends to infinity, together with experimental results\nillustrations.",
    "descriptor": "",
    "authors": [
      "Jie Ding",
      "Ruiming Ma",
      "Zhigui Lin",
      "Zhi Ling"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Analysis of PDEs (math.AP)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.09298"
  },
  {
    "id": "arXiv:2211.09299",
    "title": "FedFA: Federated Learning with Feature Anchors to Align Feature and  Classifier for Heterogeneous Data",
    "abstract": "Federated learning allows multiple clients to collaboratively train a model\nwithout exchanging their data, thus preserving data privacy. Unfortunately, it\nsuffers significant performance degradation under heterogeneous data at\nclients. Common solutions in local training involve designing a specific\nauxiliary loss to regularize weight divergence or feature inconsistency.\nHowever, we discover that these approaches fall short of the expected\nperformance because they ignore the existence of a vicious cycle between\nclassifier divergence and feature mapping inconsistency across clients, such\nthat client models are updated in inconsistent feature space with diverged\nclassifiers. We then propose a simple yet effective framework named Federated\nlearning with Feature Anchors (FedFA) to align the feature mappings and\ncalibrate classifier across clients during local training, which allows client\nmodels updating in a shared feature space with consistent classifiers. We\ndemonstrate that this modification brings similar classifiers and a virtuous\ncycle between feature consistency and classifier similarity across clients.\nExtensive experiments show that FedFA significantly outperforms the\nstate-of-the-art federated learning algorithms on various image classification\ndatasets under label and feature distribution skews.",
    "descriptor": "",
    "authors": [
      "Tailin Zhou",
      "Jun Zhang",
      "Danny Tsang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09299"
  },
  {
    "id": "arXiv:2211.09302",
    "title": "You Only Label Once: 3D Box Adaptation from Point Cloud to Image via  Semi-Supervised Learning",
    "abstract": "The image-based 3D object detection task expects that the predicted 3D\nbounding box has a ``tightness'' projection (also referred to as cuboid), which\nfits the object contour well on the image while still keeping the geometric\nattribute on the 3D space, e.g., physical dimension, pairwise orthogonal, etc.\nThese requirements bring significant challenges to the annotation. Simply\nprojecting the Lidar-labeled 3D boxes to the image leads to non-trivial\nmisalignment, while directly drawing a cuboid on the image cannot access the\noriginal 3D information. In this work, we propose a learning-based 3D box\nadaptation approach that automatically adjusts minimum parameters of the\n360$^{\\circ}$ Lidar 3D bounding box to perfectly fit the image appearance of\npanoramic cameras. With only a few 2D boxes annotation as guidance during the\ntraining phase, our network can produce accurate image-level cuboid annotations\nwith 3D properties from Lidar boxes. We call our method ``you only label\nonce'', which means labeling on the point cloud once and automatically adapting\nto all surrounding cameras. As far as we know, we are the first to focus on\nimage-level cuboid refinement, which balances the accuracy and efficiency well\nand dramatically reduces the labeling effort for accurate cuboid annotation.\nExtensive experiments on the public Waymo and NuScenes datasets show that our\nmethod can produce human-level cuboid annotation on the image without needing\nmanual adjustment.",
    "descriptor": "",
    "authors": [
      "Jieqi Shi",
      "Peiliang Li",
      "Xiaozhi Chen",
      "Shaojie Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09302"
  },
  {
    "id": "arXiv:2211.09303",
    "title": "A Bird's-eye View of Reranking: from List Level to Page Level",
    "abstract": "Reranking, as the final stage of multi-stage recommender systems, refines the\ninitial lists to maximize the total utility. With the development of multimedia\nand user interface design, the recommendation page has evolved to a multi-list\nstyle. Separately employing traditional list-level reranking methods for\ndifferent lists overlooks the inter-list interactions and the effect of\ndifferent page formats, thus yielding suboptimal reranking performance.\nMoreover, simply applying a shared network for all the lists fails to capture\nthe commonalities and distinctions in user behaviors on different lists. To\nthis end, we propose to draw a bird's-eye view of \\textbf{page-level reranking}\nand design a novel Page-level Attentional Reranking (PAR) model. We introduce a\nhierarchical dual-side attention module to extract personalized intra- and\ninter-list interactions. A spatial-scaled attention network is devised to\nintegrate the spatial relationship into pairwise item influences, which\nexplicitly models the page format. The multi-gated mixture-of-experts module is\nfurther applied to capture the commonalities and differences of user behaviors\nbetween different lists. Extensive experiments on a public dataset and a\nproprietary dataset show that PAR significantly outperforms existing baseline\nmodels.",
    "descriptor": "\nComments: WSDM 2023. More readable and full version\n",
    "authors": [
      "Yunjia Xi",
      "Jianghao Lin",
      "Weiwen Liu",
      "Xinyi Dai",
      "Weinan Zhang",
      "Rui Zhang",
      "Ruiming Tang",
      "Yong Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.09303"
  },
  {
    "id": "arXiv:2211.09307",
    "title": "Proactive Resilient Transmission and Scheduling Mechanisms for mmWave  Networks",
    "abstract": "This paper aims to develop resilient transmission mechanisms to suitably\ndistribute traffic across multiple paths in an arbitrary millimeter-wave\n(mmWave) network. The main contributions include: (a) the development of\nproactive transmission mechanisms that build resilience against network\ndisruptions in advance, while achieving a high end-to-end packet rate; (b) the\ndesign of a heuristic path selection algorithm that efficiently selects (in\npolynomial time in the network size) multiple proactively resilient paths with\nhigh packet rates; and (c) the development of a hybrid scheduling algorithm\nthat combines the proposed path selection algorithm with a deep reinforcement\nlearning (DRL) based online approach for decentralized adaptation to blocked\nlinks and failed paths. To achieve resilience to link failures, a\nstate-of-the-art Soft Actor-Critic DRL algorithm, which adapts the information\nflow through the network, is investigated. The proposed scheduling algorithm\nrobustly adapts to link failures over different topologies, channel and\nblockage realizations while offering a superior performance to alternative\nalgorithms.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2108.00548\n",
    "authors": [
      "Mine Gokce Dogan",
      "Martina Cardone",
      "Christina Fragouli"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09307"
  },
  {
    "id": "arXiv:2211.09310",
    "title": "Problem Behaviors Recognition in Videos using Language-Assisted Deep  Learning Model for Children with Autism",
    "abstract": "Correctly recognizing the behaviors of children with Autism Spectrum Disorder\n(ASD) is of vital importance for the diagnosis of Autism and timely early\nintervention. However, the observation and recording during the treatment from\nthe parents of autistic children may not be accurate and objective. In such\ncases, automatic recognition systems based on computer vision and machine\nlearning (in particular deep learning) technology can alleviate this issue to a\nlarge extent. Existing human action recognition models can now achieve\npersuasive performance on challenging activity datasets, e.g. daily activity,\nand sports activity. However, problem behaviors in children with ASD are very\ndifferent from these general activities, and recognizing these problem\nbehaviors via computer vision is less studied. In this paper, we first evaluate\na strong baseline for action recognition, i.e. Video Swin Transformer, on two\nautism behaviors datasets (SSBD and ESBD) and show that it can achieve high\naccuracy and outperform the previous methods by a large margin, demonstrating\nthe feasibility of vision-based problem behaviors recognition. Moreover, we\npropose language-assisted training to further enhance the action recognition\nperformance. Specifically, we develop a two-branch multimodal deep learning\nframework by incorporating the \"freely available\" language description for each\ntype of problem behavior. Experimental results demonstrate that incorporating\nadditional language supervision can bring an obvious performance boost for the\nautism problem behaviors recognition task as compared to using the video\ninformation only (i.e. 3.49% improvement on ESBD and 1.46% on SSBD).",
    "descriptor": "",
    "authors": [
      "Andong Deng",
      "Taojiannan Yang",
      "Chen Chen",
      "Qian Chen",
      "Leslie Neely",
      "Sakiko Oyama"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09310"
  },
  {
    "id": "arXiv:2211.09317",
    "title": "Explainable, Domain-Adaptive, and Federated Artificial Intelligence in  Medicine",
    "abstract": "Artificial intelligence (AI) continues to transform data analysis in many\ndomains. Progress in each domain is driven by a growing body of annotated data,\nincreased computational resources, and technological innovations. In medicine,\nthe sensitivity of the data, the complexity of the tasks, the potentially high\nstakes, and a requirement of accountability give rise to a particular set of\nchallenges. In this review, we focus on three key methodological approaches\nthat address some of the particular challenges in AI-driven medical decision\nmaking. (1) Explainable AI aims to produce a human-interpretable justification\nfor each output. Such models increase confidence if the results appear\nplausible and match the clinicians expectations. However, the absence of a\nplausible explanation does not imply an inaccurate model. Especially in highly\nnon-linear, complex models that are tuned to maximize accuracy, such\ninterpretable representations only reflect a small portion of the\njustification. (2) Domain adaptation and transfer learning enable AI models to\nbe trained and applied across multiple domains. For example, a classification\ntask based on images acquired on different acquisition hardware. (3) Federated\nlearning enables learning large-scale models without exposing sensitive\npersonal health information. Unlike centralized AI learning, where the\ncentralized learning machine has access to the entire training data, the\nfederated learning process iteratively updates models across multiple sites by\nexchanging only parameter updates, not personal health data. This narrative\nreview covers the basic concepts, highlights relevant corner-stone and\nstate-of-the-art research in the field, and discusses perspectives.",
    "descriptor": "\nComments: This paper is accepted in IEEE CAA Journal of Automatica Sinica, Nov. 10 2022\n",
    "authors": [
      "Ahmad Chaddad",
      "Qizong lu",
      "Jiali Li",
      "Yousef Katib",
      "Reem Kateb",
      "Camel Tanougast",
      "Ahmed Bouridane",
      "Ahmed Abdulkadir"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.09317"
  },
  {
    "id": "arXiv:2211.09320",
    "title": "Improving Federated Learning Communication Efficiency with Global  Momentum Fusion for Gradient Compression Schemes",
    "abstract": "Communication costs within Federated learning hinder the system scalability\nfor reaching more data from more clients. The proposed FL adopts a\nhub-and-spoke network topology. All clients communicate through the central\nserver. Hence, reducing communication overheads via techniques such as data\ncompression has been proposed to mitigate this issue. Another challenge of\nfederated learning is unbalanced data distribution, data on each client are not\nindependent and identically distributed (non-IID) in a typical federated\nlearning setting. In this paper, we proposed a new compression compensation\nscheme called Global Momentum Fusion (GMF) which reduces communication\noverheads between FL clients and the server and maintains comparable model\naccuracy in the presence of non-IID data. GitHub repository:\nhttps://github.com/tony92151/global-momentum-fusion-fl",
    "descriptor": "",
    "authors": [
      "Chun-Chih Kuo",
      "Ted Tsei Kuo",
      "Chia-Yu Lin"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.09320"
  },
  {
    "id": "arXiv:2211.09321",
    "title": "Interpretable Dimensionality Reduction by Feature Preserving Manifold  Approximation and Projection",
    "abstract": "Nonlinear dimensionality reduction lacks interpretability due to the absence\nof source features in low-dimensional embedding space. We propose an\ninterpretable method featMAP to preserve source features by tangent space\nembedding. The core of our proposal is to utilize local singular value\ndecomposition (SVD) to approximate the tangent space which is embedded to\nlow-dimensional space by maintaining the alignment. Based on the embedding\ntangent space, featMAP enables the interpretability by locally demonstrating\nthe source features and feature importance. Furthermore, featMAP embeds the\ndata points by anisotropic projection to preserve the local similarity and\noriginal density. We apply featMAP to interpreting digit classification, object\ndetection and MNIST adversarial examples. FeatMAP uses source features to\nexplicitly distinguish the digits and objects and to explain the\nmisclassification of adversarial examples. We also compare featMAP with other\nstate-of-the-art methods on local and global metrics.",
    "descriptor": "",
    "authors": [
      "Yang Yang",
      "Hongjian Sun",
      "Jialei Gong",
      "Yali Du",
      "Di Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09321"
  },
  {
    "id": "arXiv:2211.09322",
    "title": "Targeted Attention for Generalized- and Zero-Shot Learning",
    "abstract": "The Zero-Shot Learning (ZSL) task attempts to learn concepts without any\nlabeled data. Unlike traditional classification/detection tasks, the evaluation\nenvironment is provided unseen classes never encountered during training. As\nsuch, it remains both challenging, and promising on a variety of fronts,\nincluding unsupervised concept learning, domain adaptation, and dataset drift\ndetection. Recently, there have been a variety of approaches towards solving\nZSL, including improved metric learning methods, transfer learning,\ncombinations of semantic and image domains using, e.g. word vectors, and\ngenerative models to model the latent space of known classes to classify unseen\nclasses. We find many approaches require intensive training augmentation with\nattributes or features that may be commonly unavailable (attribute-based\nlearning) or susceptible to adversarial attacks (generative learning). We\npropose combining approaches from the related person re-identification task for\nZSL, with key modifications to ensure sufficiently improved performance in the\nZSL setting without the need for feature or training dataset augmentation. We\nare able to achieve state-of-the-art performance on the CUB200 and Cars196\ndatasets in the ZSL setting compared to recent works, with NMI (normalized\nmutual inference) of 63.27 and top-1 of 61.04 for CUB200, and NMI 66.03 with\ntop-1 82.75% in Cars196. We also show state-of-the-art results in the\nGeneralized Zero-Shot Learning (GZSL) setting, with Harmonic Mean R-1 of 66.14%\non the CUB200 dataset.",
    "descriptor": "",
    "authors": [
      "Abhijit Suprem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09322"
  },
  {
    "id": "arXiv:2211.09324",
    "title": "Perturbation-Recovery Method for Recommendation",
    "abstract": "Collaborative filtering is one of the most influential recommender system\ntypes. Various methods have been proposed for collaborative filtering, ranging\nfrom matrix factorization to graph convolutional methods. Being inspired by\nrecent successes of GF-CF and diffusion models, we present a novel concept of\nblurring-sharpening process model (BSPM). Diffusion models and BSPMs share the\nsame processing philosophy in that new information is discovered (e.g., a new\nimage is generated in the case of diffusion models) while original information\nis first perturbed and then recovered to its original form. However, diffusion\nmodels and our BSPMs deal with different types of information, and their\noptimal perturbation and recovery processes have a fundamental discrepancy.\nTherefore, our BSPMs have different forms from diffusion models. In addition,\nour concept not only theoretically subsumes many existing collaborative\nfiltering models but also outperforms them in terms of Recall and NDCG in the\nthree benchmark datasets, Gowalla, Yelp2018, and Amazon-book. Our model marks\nthe best accuracy in them. In addition, the processing time of our method is\none of the shortest cases ever in collaborative filtering. Our proposed concept\nhas much potential in the future to be enhanced by designing better blurring\n(i.e., perturbation) and sharpening (i.e., recovery) processes than what we use\nin this paper.",
    "descriptor": "",
    "authors": [
      "Jeongwhan Choi",
      "Seoyoung Hong",
      "Noseong Park",
      "Sung-Bae Cho"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09324"
  },
  {
    "id": "arXiv:2211.09325",
    "title": "TAX-Pose: Task-Specific Cross-Pose Estimation for Robot Manipulation",
    "abstract": "How do we imbue robots with the ability to efficiently manipulate unseen\nobjects and transfer relevant skills based on demonstrations? End-to-end\nlearning methods often fail to generalize to novel objects or unseen\nconfigurations. Instead, we focus on the task-specific pose relationship\nbetween relevant parts of interacting objects. We conjecture that this\nrelationship is a generalizable notion of a manipulation task that can transfer\nto new objects in the same category; examples include the relationship between\nthe pose of a pan relative to an oven or the pose of a mug relative to a mug\nrack. We call this task-specific pose relationship ``cross-pose\" and provide a\nmathematical definition of this concept. We propose a vision-based system that\nlearns to estimate the cross-pose between two objects for a given manipulation\ntask using learned cross-object correspondences. The estimated cross-pose is\nthen used to guide a downstream motion planner to manipulate the objects into\nthe desired pose relationship (placing a pan into the oven or the mug onto the\nmug rack). We demonstrate our method's capability to generalize to unseen\nobjects, in some cases after training on only 10 demonstrations in the real\nworld. Results show that our system achieves state-of-the-art performance in\nboth simulated and real-world experiments across a number of tasks.\nSupplementary information and videos can be found at\nhttps://sites.google.com/view/tax-pose/home.",
    "descriptor": "\nComments: Conference on Robot Learning (CoRL), 2022. Supplementary material is available at this https URL\n",
    "authors": [
      "Chuer Pan",
      "Brian Okorn",
      "Harry Zhang",
      "Ben Eisner",
      "David Held"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.09325"
  },
  {
    "id": "arXiv:2211.09330",
    "title": "ACon$^2$: Adaptive Conformal Consensus for Provable Blockchain Oracles",
    "abstract": "Blockchains with smart contracts are distributed ledger systems which achieve\nblock state consistency among distributed nodes by only allowing deterministic\noperations of smart contracts. However, the power of smart contracts is enabled\nby interacting with stochastic off-chain data, which in turn opens the\npossibility to undermine the block state consistency. To address this issue, an\noracle smart contract is used to provide a single consistent source of external\ndata; but, simultaneously this introduces a single point of failure, which is\ncalled the oracle problem. To address the oracle problem, we propose an\nadaptive conformal consensus (ACon$^2$) algorithm, which derives consensus from\nmultiple oracle contracts via the recent advance in online uncertainty\nquantification learning. In particular, the proposed algorithm returns a\nconsensus set, which quantifies the uncertainty of data and achieves a desired\ncorrectness guarantee in the presence of Byzantine adversaries and distribution\nshift. We demonstrate the efficacy of the proposed algorithm on two price\ndatasets and an Ethereum case study. In particular, the Solidity implementation\nof the proposed algorithm shows the practicality of the proposed algorithm,\nimplying that online machine learning algorithms are applicable to address\nissues in blockchains.",
    "descriptor": "",
    "authors": [
      "Sangdon Park",
      "Osbert Bastani",
      "Taesoo Kim"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09330"
  },
  {
    "id": "arXiv:2211.09332",
    "title": "iNavFIter-M: Matrix Formulation of Functional Iteration for Inertial  Navigation Computation",
    "abstract": "The acquisition of attitude, velocity, and position is an essential task in\nthe field of inertial navigation, achieved by integrating the measurements from\ninertial sensors. Recently, the ultra-precision inertial navigation computation\nhas been tackled by the functional iteration approach (iNavFIter) that drives\nthe non-commutativity errors almost to the computer truncation error level.\nThis paper proposes a computationally efficient matrix formulation of the\nfunctional iteration approach, named the iNavFIter-M. The Chebyshev polynomial\ncoefficients in two consecutive iterations are explicitly connected through the\nmatrix formulation, in contrast to the implicit iterative relationship in the\noriginal iNavFIter. By so doing, it allows a straightforward algorithmic\nimplementation and a number of matrix factors can be pre-calculated for more\nefficient computation. Numerical results demonstrate that the proposed\niNavFIter-M algorithm is able to achieve the same high computation accuracy as\nthe original iNavFIter does, at the computational cost comparable to the\ntypical two-sample algorithm. The iNavFIter-M algorithm is also implemented on\na FPGA board to demonstrate its potential in real time applications.",
    "descriptor": "\nComments: 30 pages, 7 figures\n",
    "authors": [
      "Hongyan Jiang",
      "Maoran Zhu",
      "Yanyan Fu",
      "Yuanxin Wu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.09332"
  },
  {
    "id": "arXiv:2211.09334",
    "title": "Estimation of physical activities of people in offices from time-series  point-cloud data",
    "abstract": "This paper proposes an edge computing system that enables estimating physical\nactivities of people in offices from time-series point-cloud data, obtained by\nusing a light-detection-and-ranging (LIDAR) sensor network. The paper presents\nthat the proposed system successfully constructs the model for estimating the\nnumber of typed characters from time-series point-cloud data, through an\nexperiment using real LIDAR sensors.",
    "descriptor": "",
    "authors": [
      "Koki Kizawa",
      "Ryoichi Shinkuma",
      "Gabriele Trovato"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.09334"
  },
  {
    "id": "arXiv:2211.09337",
    "title": "Optimal Beamforming and Outage Analysis for Max Mean SNR under RIS-aided  Communication",
    "abstract": "This paper considers beamforming for a reconfigurable intelligent surface\n(RIS)-aided multiple input single output (MISO) communication system in the\npresence of Rician multipath fading. Our aim is to jointly optimize the\ntransmit beamformer and RIS phase shift matrix for maximizing the mean\nsignal-to-noise (SNR) of the combined signal received over direct and indirect\nlinks. While numerical solutions are known for such optimization problems, this\nis the first paper to derive closed-form expressions for the optimal beamformer\nand the phase shifter for a closely related problem. In particular, we maximize\na carefully constructed lower bound of the mean SNR, which is more conducive to\nanalytical treatment. Further, we show that effective channel gain under\noptimal beamforming follows Rice distribution. Next, we use these results to\ncharacterize a closed-form expression for the outage probability under the\nproposed beamforming scheme, which is subsequently employed to derive an\nanalytical expression for the ergodic capacity. Finally, we numerically\ndemonstrate the efficacy of the proposed beamformer solution in comparison with\nthe existing algorithmically obtained optimal solution for the exact mean SNR\nmaximization.",
    "descriptor": "\nComments: 6 pages, 4 figures, conference\n",
    "authors": [
      "Kali Krishna Kota",
      "Praful D. Mankar",
      "Harpreet S. Dhillon"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.09337"
  },
  {
    "id": "arXiv:2211.09340",
    "title": "Adaptive user interfaces in systems targeting chronic disease: a  systematic literature review",
    "abstract": "eHealth technologies have been increasingly used to foster proactive\nself-management skills for patients with chronic diseases. However, it is\nchallenging to provide each user with the desired support due to the dynamic\nand diverse nature of the chronic disease. Many such eHealth applications\nsupport aspects of 'adaptive user interfaces' -- that change or can be changed\nto accommodate the user and usage context differences. To identify the\nstate-of-art in adaptive user interfaces in the field of chronic diseases, we\nsystematically located and analysed 48 key studies in the literature with the\naim of categorising the key approaches used to date and identifying\nlimitations, gaps and trends in research. Our data synthesis, revolves around\nthe data sources used for interface adaptation, the data collection techniques\nused to extract the data, the adaptive mechanisms used to process the data and\nthe adaptive elements generated at the interface. The findings of this review\nwill aid researchers and developers in understanding where adaptive user\ninterface approaches can be applied and necessary considerations for employing\nadaptive user interfaces to different chronic disease-related eHealth\napplications.",
    "descriptor": "\nComments: 35 pages, 10 figures, 9 tables, This work has been submitted to the ACM for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Wei Wang",
      "Hourieh Khalajzadeh",
      "Anuradha Madugalla",
      "Jennifer Mcintosh",
      "Humphrey Obie"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.09340"
  },
  {
    "id": "arXiv:2211.09341",
    "title": "Approaching the Soundness Barrier: A Near Optimal Analysis of the Cube  versus Cube Test",
    "abstract": "The Cube versus Cube test is a variant of the well-known Plane versus Plane\ntest of Raz and Safra, in which to each $3$-dimensional affine subspace $C$ of\n$\\mathbb{F}_q^n$, a polynomial of degree at most $d$, $T(C)$, is assigned in a\nsomewhat locally consistent manner: taking two cubes $C_1, C_2$ that intersect\nin a plane uniformly at random, the probability that $T(C_1)$ and $T(C_2)$\nagree on $C_1\\cap C_2$ is at least some $\\epsilon$. An element of interest is\nthe soundness threshold of this test, i.e. the smallest value of $\\epsilon$,\nsuch that this amount of local consistency implies a global structure; namely,\nthat there is a global degree $d$ function $g$ such that $g|_{C} \\equiv T(C)$\nfor at least $\\Omega(\\epsilon)$ fraction of the cubes.\nWe show that the cube versus cube low degree test has soundness ${\\sf\npoly}(d)/q$. This result achieves the optimal dependence on $q$ for soundness\nin low degree testing and improves upon previous soundness results of ${\\sf\npoly}(d)/q^{1/2}$ due to Bhangale, Dinur and Navon.",
    "descriptor": "\nComments: SODA 2023, 19 pages\n",
    "authors": [
      "Dor Minzer",
      "Kai Zheng"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.09341"
  },
  {
    "id": "arXiv:2211.09342",
    "title": "I see you: A Vehicle-Pedestrian Interaction Dataset from Traffic  Surveillance Cameras",
    "abstract": "The development of autonomous vehicles arises new challenges in urban traffic\nscenarios where vehicle-pedestrian interactions are frequent e.g. vehicle\nyields to pedestrians, pedestrian slows down due approaching to the vehicle.\nOver the last years, several datasets have been developed to model these\ninteractions. However, available datasets do not cover near-accident scenarios\nthat our dataset covers. We introduce I see you, a new vehicle-pedestrian\ninteraction dataset that tackles the lack of trajectory data in near-accident\nscenarios using YOLOv5 and camera calibration methods. I see you consist of 170\nnear-accident occurrences in seven intersections in Cusco-Peru. This new\ndataset and pipeline code are available on Github.",
    "descriptor": "\nComments: paper accepted at LXAI workshop at NeurIPS 2022, github repository this https URL\n",
    "authors": [
      "Hanan Quispe",
      "Jorshinno Sumire",
      "Patricia Condori",
      "Edwin Alvarez",
      "Harley Vera"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.09342"
  },
  {
    "id": "arXiv:2211.09345",
    "title": "More Effective Centrality-Based Attacks on Weighted Networks",
    "abstract": "Only when understanding hackers' tactics, can we thwart their attacks. With\nthis spirit, this paper studies how hackers can effectively launch the\nso-called 'targeted node attacks', in which iterative attacks are staged on a\nnetwork, and in each iteration the most important node is removed. In the\nexisting attacks for weighted networks, the node importance is typically\nmeasured by the centralities related to shortest-path lengths, and the attack\neffectiveness is also measured mostly by length-related metrics. However, this\npaper argues that flows can better reflect network functioning than\nshortest-path lengths for those networks with carrying traffic as the main\nfunctionality. Thus, this paper proposes metrics based on flows for measuring\nthe node importance and the attack effectiveness, respectively. Our node\nimportance metrics include three flow-based centralities (flow betweenness,\ncurrent-flow betweenness and current-flow closeness), which have not been\nproposed for use in the attacks on weighted networks yet. Our attack\neffectiveness metric is a new one proposed by us based on average network flow.\nExtensive experiments on both artificial and real-world networks show that the\nattack methods with our three suggested centralities are more effective than\nthe existing attack methods when evaluated under our proposed attack\neffectiveness metric.",
    "descriptor": "",
    "authors": [
      "Balume Mburano",
      "Weisheng Si",
      "Qing Cao",
      "Wei Xing Zheng"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.09345"
  },
  {
    "id": "arXiv:2211.09346",
    "title": "A class of inexact block factorization preconditioners for indefinite  matrices with a three-by-three block structure",
    "abstract": "We consider using the preconditioned-Krylov subspace method to solve the\nsystem of linear equations with a three-by-three block structure. By making use\nof the three-by-three block structure, eight inexact block factorization\npreconditioners, which can be put into a same theoretical analysis frame, are\nproposed based on a kind of inexact factorization. By generalizing Bendixson\nTheorem and developing a unified technique of spectral equivalence, the bounds\nof the real and imaginary parts of eigenvalues of the preconditioned matrices\nare obtained. The comparison to eleven existed exact and inexact\npreconditioners shows that three of the proposed preconditioners can lead to\nhigh-speed and effective preconditioned-GMRES in most tests.",
    "descriptor": "",
    "authors": [
      "Sheng-Zhong Song",
      "Zheng-Da Huang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.09346"
  },
  {
    "id": "arXiv:2211.09348",
    "title": "Continuous Prediction of Web User Visual Attention on short span Windows  based on Gaze Data Analytics",
    "abstract": "The existing approaches to identify personalized salience zones of a Web page\ndo not consider the dynamic behavior in time of the Web user's gaze or the\nalterations of its content. For this reason, this paper proposes the concept of\nvisit intention, an indicator of the visual attention of a Web user in a\ncertain period of time, short span time windows, in different areas of\ninterest. This indicator gives information on the areas of interest of a\nwebsite that will be visited by a user over a time window, without requiring to\nknow the structure of the site in each window. Our approach leverages the\npopulation-level general gaze patterns and the user's visual kinetics. We show\nexperimentally that it is possible to conduct such a prediction through\nmultilabel classification models using a small number of users, obtaining an\naverage area under curve of 84.3 %, an average accuracy of 79 %, and an\nindividual area of interest accuracy of 77 %. Furthermore, the user's visual\nkinetics features are consistently selected in every set of a cross-validation\nevaluation.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "F. Diaz-Guerra",
      "A. Jimenez-Molina"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.09348"
  },
  {
    "id": "arXiv:2211.09350",
    "title": "Learning Domain and Pose Invariance for Thermal-to-Visible Face  Recognition",
    "abstract": "Interest in thermal to visible face recognition has grown significantly over\nthe last decade due to advancements in thermal infrared cameras and analytics\nbeyond the visible spectrum. Despite large discrepancies between thermal and\nvisible spectra, existing approaches bridge domain gaps by either synthesizing\nvisible faces from thermal faces or by learning the cross-spectrum image\nrepresentations. These approaches typically work well with frontal facial\nimagery collected at varying ranges and expressions, but exhibit significantly\nreduced performance when matching thermal faces with varying poses to frontal\nvisible faces. We propose a novel Domain and Pose Invariant Framework that\nsimultaneously learns domain and pose invariant representations. Our proposed\nframework is composed of modified networks for extracting the most correlated\nintermediate representations from off-pose thermal and frontal visible face\nimagery, a sub-network to jointly bridge domain and pose gaps, and a joint-loss\nfunction comprised of cross-spectrum and pose-correction losses. We demonstrate\nefficacy and advantages of the proposed method by evaluating on three\nthermal-visible datasets: ARL Visible-to-Thermal Face, ARL Multimodal Face, and\nTufts Face. Although DPIF focuses on learning to match off-pose thermal to\nfrontal visible faces, we also show that DPIF enhances performance when\nmatching frontal thermal face images to frontal visible face images.",
    "descriptor": "",
    "authors": [
      "Cedric Nimpa Fondje",
      "Shuowen Hu",
      "Benjamin S. Riggan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09350"
  },
  {
    "id": "arXiv:2211.09353",
    "title": "Securer and Faster Privacy-Preserving Distributed Machine Learning",
    "abstract": "With the development of machine learning, it is difficult for a single server\nto process all the data. So machine learning tasks need to be spread across\nmultiple servers, turning centralized machine learning into a distributed one.\nHowever, privacy remains an unsolved problem in distributed machine learning.\nMulti-key homomorphic encryption over torus (MKTFHE) is one of the suitable\ncandidates to solve the problem. However, there may be security risks in the\ndecryption of MKTFHE and the most recent result about MKFHE only supports the\nBoolean operation and linear operation. So, MKTFHE cannot compute the\nnon-linear function like Sigmoid directly and it is still hard to perform\ncommon machine learning such as logistic regression and neural networks in high\nperformance.\nThis paper first introduces secret sharing to propose a new distributed\ndecryption protocol for MKTFHE, then designs an MKTFHE-friendly activation\nfunction, and finally utilizes them to implement logistic regression and neural\nnetwork training in MKTFHE. We prove the correctness and security of our\ndecryption protocol and compare the efficiency and accuracy between using\nTaylor polynomials of Sigmoid and our proposed function as an activation\nfunction. The experiments show that the efficiency of our function is 10 times\nhigher than using 7-order Taylor polynomials straightly and the accuracy of the\ntraining model is similar to that of using a high-order polynomial as an\nactivation function scheme.",
    "descriptor": "",
    "authors": [
      "Hongxiao Wang",
      "Zoe L. Jiang",
      "Yanmin Zhao",
      "Siu-Ming Yiu",
      "Peng Yang",
      "Zejiu Tan",
      "Bohan Jin",
      "Shiyuan Xu",
      "Shimin Pan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09353"
  },
  {
    "id": "arXiv:2211.09359",
    "title": "How to Fine-Tune Vision Models with SGD",
    "abstract": "SGD (with momentum) and AdamW are the two most used optimizers for\nfine-tuning large neural networks in computer vision. When the two methods\nperform the same, SGD is preferable because it uses less memory (12\nbytes/parameter) than AdamW (16 bytes/parameter). However, on a suite of\ndownstream tasks, especially those with distribution shifts, we show that\nfine-tuning with AdamW performs substantially better than SGD on modern Vision\nTransformer and ConvNeXt models. We find that large gaps in performance between\nSGD and AdamW occur when the fine-tuning gradients in the first \"embedding\"\nlayer are much larger than in the rest of the model. Our analysis suggests an\neasy fix that works consistently across datasets and models: merely freezing\nthe embedding layer (less than 1\\% of the parameters) leads to SGD performing\ncompetitively with AdamW while using less memory. Our insights result in\nstate-of-the-art accuracies on five popular distribution shift benchmarks:\nWILDS-FMoW, WILDS-Camelyon, Living-17, Waterbirds, and DomainNet.",
    "descriptor": "",
    "authors": [
      "Ananya Kumar",
      "Ruoqi Shen",
      "S\u00e9bastien Bubeck",
      "Suriya Gunasekar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09359"
  },
  {
    "id": "arXiv:2211.09360",
    "title": "Achieving Social Optimality for Energy Communities via Dynamic NEM  Pricing",
    "abstract": "We propose a social welfare maximizing mechanism for an energy community that\naggregates individual and shared community resources under a general net energy\nmetering (NEM) policy. Referred to as Dynamic NEM, the proposed mechanism\nadopts the standard NEM tariff model and sets NEM prices dynamically based on\nthe total shared renewables within the community. We show that Dynamic NEM\nguarantees a higher benefit to each community member than possible outside the\ncommunity. We further show that Dynamic NEM aligns the individual member's\nincentive with that of the overall community; each member optimizing individual\nsurplus under Dynamic NEM results in maximum community's social welfare.\nDynamic NEM is also shown to satisfy the cost-causation principle. Empirical\nstudies using real data on a hypothetical energy community demonstrate the\nbenefits to community members and grid operators.",
    "descriptor": "\nComments: 9 pages, 5 figures\n",
    "authors": [
      "Ahmed S. Alahmed",
      "Lang Tong"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Theoretical Economics (econ.TH)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.09360"
  },
  {
    "id": "arXiv:2211.09362",
    "title": "Multiresolution ORKA: fast and resolution independent object  reconstruction using a K-approximation graph",
    "abstract": "Object recognition and reconstruction is of great interest in many research\nfields. Detecting pedestrians or cars in traffic cameras or tracking seismic\nwaves in geophysical exploration are only two of many applications. Recently,\nthe authors developed a new method - Object reconstruction using\nK-approximation (ORKA) - to extract such objects out of given data. In this\nmethod a special object model is used where the movement and deformation of the\nobject can be controlled to fit the application. ORKA in its current form is\nhighly dependent on the data resolution. On the one hand, the movement of the\nobject can only be reconstructed on a grid that depends on the data resolution.\nOn the other hand, the runtime increases exponentially with the resolution.\nHence, the resolution of the data needs to be in a small range where the\nreconstruction is accurate enough but the runtime is not too high. In this\nwork, we present a multiresolution approach, where we combine ORKA with a\nwavelet decomposition of the data. The object is then reconstructed iteratively\nwhat drastically reduces the runtime. Moreover, we can increase the data\nresolution such that the movement reconstruction no longer depends on the\noriginal grid. We also give a brief introduction on the original ORKA\nalgorithm. Hence, knowledge of the previous work is not required.",
    "descriptor": "",
    "authors": [
      "Florian Bossmann",
      "Wenze Wu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.09362"
  },
  {
    "id": "arXiv:2211.09363",
    "title": "Generalizable Deepfake Detection with Phase-Based Motion Analysis",
    "abstract": "We propose PhaseForensics, a DeepFake (DF) video detection method that\nleverages a phase-based motion representation of facial temporal dynamics.\nExisting methods relying on temporal inconsistencies for DF detection present\nmany advantages over the typical frame-based methods. However, they still show\nlimited cross-dataset generalization and robustness to common distortions.\nThese shortcomings are partially due to error-prone motion estimation and\nlandmark tracking, or the susceptibility of the pixel intensity-based features\nto spatial distortions and the cross-dataset domain shifts. Our key insight to\novercome these issues is to leverage the temporal phase variations in the\nband-pass components of the Complex Steerable Pyramid on face sub-regions. This\nnot only enables a robust estimate of the temporal dynamics in these regions,\nbut is also less prone to cross-dataset variations. Furthermore, the band-pass\nfilters used to compute the local per-frame phase form an effective defense\nagainst the perturbations commonly seen in gradient-based adversarial attacks.\nOverall, with PhaseForensics, we show improved distortion and adversarial\nrobustness, and state-of-the-art cross-dataset generalization, with 91.2%\nvideo-level AUC on the challenging CelebDFv2 (a recent state-of-the-art\ncompares at 86.9%).",
    "descriptor": "",
    "authors": [
      "Ekta Prashnani",
      "Michael Goebel",
      "B. S. Manjunath"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09363"
  },
  {
    "id": "arXiv:2211.09365",
    "title": "Low-Resource Mongolian Speech Synthesis Based on Automatic Prosody  Annotation",
    "abstract": "While deep learning-based text-to-speech (TTS) models such as VITS have shown\nexcellent results, they typically require a sizable set of high-quality <text,\naudio> pairs to train, which is expensive to collect. So far, most languages in\nthe world still lack the training data needed to develop TTS systems. This\npaper proposes two improvement methods for the two problems faced by\nlow-resource Mongolian speech synthesis: a) In view of the lack of high-quality\n<text, audio> pairs of data, it is difficult to model the mapping problem from\nlinguistic features to acoustic features. Improvements are made using\npre-trained VITS model and transfer learning methods. b) In view of the problem\nof less labeled information, this paper proposes to use an automatic prosodic\nannotation method to label the prosodic information of text and corresponding\nspeech, thereby improving the naturalness and intelligibility of low-resource\nMongolian language. Through empirical research, the N-MOS of the method\nproposed in this paper is 4.195, and the I-MOS is 4.228.",
    "descriptor": "\nComments: submitted to NCMMSC2022\n",
    "authors": [
      "Xin Yuan",
      "Robin Feng",
      "Mingming Ye"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.09365"
  },
  {
    "id": "arXiv:2211.09368",
    "title": "MDS and $I$-Perfect Codes in Pomset block Metric",
    "abstract": "In this paper, we establish the Singleton bound for pomset block codes\n($(Pm,\\pi)$-codes) of length $N$ over the ring $\\mathbb{Z}_m$. We give a\nnecessary condition for a code to be MDS in the pomset (block) metric and prove\nthat every MDS $(Pm,\\pi)$-code is an MDS $(P,\\pi)$-code. Then we proceed on to\nfind $I$-perfect and $r$-perfect codes. Further, given an ideal with partial\nand full counts, we look into how MDS and $I$-perfect codes relate to one\nanother. For chain pomset, we obtain the duality theorem for pomset block codes\nof length $N$ over $\\mathbb{Z}_m$; and, the weight distribution of MDS pomset\nblock codes is then determined.",
    "descriptor": "\nComments: 14 Pages. arXiv admin note: text overlap with arXiv:2210.15363\n",
    "authors": [
      "Atul Kumar Shriwastva",
      "R. S. Selvaraj"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.09368"
  },
  {
    "id": "arXiv:2211.09371",
    "title": "CapEnrich: Enriching Caption Semantics for Web Images via Cross-modal  Pre-trained Knowledge",
    "abstract": "Automatically generating textual descriptions for massive unlabeled images on\nthe web can greatly benefit realistic web applications, e.g. multimodal\nretrieval and recommendation. However, existing models suffer from the problem\nof generating ``over-generic'' descriptions, such as their tendency to generate\nrepetitive sentences with common concepts for different images. These generic\ndescriptions fail to provide sufficient textual semantics for ever-changing web\nimages. Inspired by the recent success of Vision-Language Pre-training (VLP)\nmodels that learn diverse image-text concept alignment during pretraining, we\nexplore leveraging their cross-modal pre-trained knowledge to automatically\nenrich the textual semantics of image descriptions. With no need for additional\nhuman annotations, we propose a plug-and-play framework, i.e CapEnrich, to\ncomplement the generic image descriptions with more semantic details.\nSpecifically, we first propose an automatic data-building strategy to get\ndesired training sentences, based on which we then adopt prompting strategies,\ni.e. learnable and template prompts, to incentivize VLP models to generate more\ntextual details. For learnable templates, we fix the whole VLP model and only\ntune the prompt vectors, which leads to two advantages: 1) the pre-training\nknowledge of VLP models can be reserved as much as possible to describe diverse\nvisual concepts; 2) only lightweight trainable parameters are required, so it\nis friendly to low data resources. Extensive experiments show that our method\nsignificantly improves the descriptiveness and diversity of generated sentences\nfor web images. Our code will be released.",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Linli Yao",
      "Weijing Chen",
      "Qin Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.09371"
  },
  {
    "id": "arXiv:2211.09373",
    "title": "Graph Neural Network-based Surrogate Models for Finite Element Analysis",
    "abstract": "Current simulation of metal forging processes use advanced finite element\nmethods. Such methods consist of solving mathematical equations, which takes a\nsignificant amount of time for the simulation to complete. Computational time\ncan be prohibitive for parametric response surface exploration tasks. In this\npaper, we propose as an alternative, a Graph Neural Network-based graph\nprediction model to act as a surrogate model for parameters search space\nexploration and which exhibits a time cost reduced by an order of magnitude.\nNumerical experiments show that this new model outperforms the Point-Net model\nand the Dynamic Graph Convolutional Neural Net model.",
    "descriptor": "",
    "authors": [
      "Meduri Venkata Shivadity",
      "Jos\u00e9 Alves",
      "Francesca Bugiotti",
      "Frederic Magoules"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.09373"
  },
  {
    "id": "arXiv:2211.09374",
    "title": "Execution-based Evaluation for Data Science Code Generation Models",
    "abstract": "Code generation models can benefit data scientists' productivity by\nautomatically generating code from context and text descriptions. An important\nmeasure of the modeling progress is whether a model can generate code that can\ncorrectly execute to solve the task. However, due to the lack of an evaluation\ndataset that directly supports execution-based model evaluation, existing work\nrelies on code surface form similarity metrics (e.g., BLEU, CodeBLEU) for model\nselection, which can be inaccurate.\nTo remedy this, we introduce ExeDS, an evaluation dataset for execution\nevaluation for data science code generation tasks. ExeDS contains a set of 534\nproblems from Jupyter Notebooks, each consisting of code context, task\ndescription, reference program, and the desired execution output. With ExeDS,\nwe evaluate the execution performance of five state-of-the-art code generation\nmodels that have achieved high surface-form evaluation scores. Our experiments\nshow that models with high surface-form scores do not necessarily perform well\non execution metrics, and execution-based metrics can better capture model code\ngeneration errors. Source code and data can be found at\nhttps://github.com/Jun-jie-Huang/ExeDS",
    "descriptor": "\nComments: Accepted by the 4th Workshop on Data Science with Human-in-the-loop (DaSH) at EMNLP 2022\n",
    "authors": [
      "Junjie Huang",
      "Chenglong Wang",
      "Jipeng Zhang",
      "Cong Yan",
      "Haotian Cui",
      "Jeevana Priya Inala",
      "Colin Clement",
      "Nan Duan",
      "Jianfeng Gao"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.09374"
  },
  {
    "id": "arXiv:2211.09375",
    "title": "3D-QueryIS: A Query-based Framework for 3D Instance Segmentation",
    "abstract": "Previous top-performing methods for 3D instance segmentation often maintain\ninter-task dependencies and the tendency towards a lack of robustness. Besides,\ninevitable variations of different datasets make these methods become\nparticularly sensitive to hyper-parameter values and manifest poor\ngeneralization capability. In this paper, we address the aforementioned\nchallenges by proposing a novel query-based method, termed as 3D-QueryIS, which\nis detector-free, semantic segmentation-free, and cluster-free. Specifically,\nwe propose to generate representative points in an implicit manner, and use\nthem together with the initial queries to generate the informative instance\nqueries. Then, the class and binary instance mask predictions can be produced\nby simply applying MLP layers on top of the instance queries and the extracted\npoint cloud embeddings. Thus, our 3D-QueryIS is free from the accumulated\nerrors caused by the inter-task dependencies. Extensive experiments on multiple\nbenchmark datasets demonstrate the effectiveness and efficiency of our proposed\n3D-QueryIS method.",
    "descriptor": "",
    "authors": [
      "Jiaheng Liu",
      "Tong He",
      "Honghui Yang",
      "Rui Su",
      "Jiayi Tian",
      "Junran Wu",
      "Hongcheng Guo",
      "Ke Xu",
      "Wanli Ouyang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09375"
  },
  {
    "id": "arXiv:2211.09376",
    "title": "Balanced Deep CCA for Bird Vocalization Detection",
    "abstract": "Event detection improves when events are captured by two different modalities\nrather than just one. But to train detection systems on multiple modalities is\nchallenging, in particular when there is abundance of unlabelled data but\nlimited amounts of labeled data. We develop a novel self-supervised learning\ntechnique for multi-modal data that learns (hidden) correlations between\nsimultaneously recorded microphone (sound) signals and accelerometer (body\nvibration) signals. The key objective of this work is to learn useful\nembeddings associated with high performance in downstream event detection tasks\nwhen labeled data is scarce and the audio events of interest (songbird\nvocalizations) are sparse. We base our approach on deep canonical correlation\nanalysis (DCCA) that suffers from event sparseness. We overcome the sparseness\nof positive labels by first learning a data sampling model from the labelled\ndata and by applying DCCA on the output it produces. This method that we term\nbalanced DCCA (b-DCCA) improves the performance of the unsupervised embeddings\non the downstream supervised audio detection task compared to classsical DCCA.\nBecause data labels are frequently imbalanced, our method might be of broad\nutility in low-resource scenarios.",
    "descriptor": "",
    "authors": [
      "Sumit Kumar",
      "B. Anshuman",
      "Linus Ruettimann",
      "Richard H.R. Hahnloser",
      "Vipul Arora"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.09376"
  },
  {
    "id": "arXiv:2211.09378",
    "title": "Outracing Human Racers with Model-based Autonomous Racing",
    "abstract": "Autonomous racing has become a popular sub-topic of autonomous driving in\nrecent years. The goal of autonomous racing research is to develop software to\ncontrol the vehicle at its limit of handling and achieve human-level racing\nperformance. In this work, we investigate how to approach human expert-level\nracing performance with model-based planning and control methods using the\nhigh-fidelity racing simulator Gran Turismo Sport (GTS). GTS enables a unique\nopportunity for autonomous racing research, as many recordings of racing from\nhighly skilled human players can served as expert emonstrations. By comparing\nthe performance of the autonomous racing software with human experts, we better\nunderstand the performance gap of existing software and explore new\nmethodologies in a principled manner. In particular, we focus on the commonly\nadopted model-based racing framework, consisting of an offline trajectory\nplanner and an online Model Predictive Control-based (MPC) tracking controller.\nWe thoroughly investigate the design challenges from three perspective, namely\nvehicle model, planning algorithm, and controller design, and propose novel\nsolutions to improve the baseline approach toward human expert-level\nperformance. We showed that the proposed control framework can achieve top\n0.95% lap time among human-expert players in GTS. Furthermore, we conducted\ncomprehensive ablation studies to validate the necessity of proposed modules,\nand pointed out potential future directions to reach human-best performance.",
    "descriptor": "\nComments: 12 pages, 10 figures, 2 tables\n",
    "authors": [
      "Ce Hao",
      "Chen Tang",
      "Eric Bergkvist",
      "Catherine Weaver",
      "Liting Sun",
      "Wei Zhan",
      "Masayoshi Tomizuka"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.09378"
  },
  {
    "id": "arXiv:2211.09379",
    "title": "Self-Training with Purpose Preserving Augmentation Improves Few-shot  Generative Dialogue State Tracking",
    "abstract": "In dialogue state tracking (DST), labeling the dataset involves considerable\nhuman labor. We propose a new self-training framework for few-shot generative\nDST that utilize unlabeled data. Our self-training method iteratively improves\nthe model by pseudo labeling and employs Purpose Preserving Augmentation\n(PPAug) to prevent overfitting. We increaese the few-shot 10% performance by\napproximately 4% on MultiWOZ 2.1 and enhances the slot-recall 8.34% for unseen\nvalues compared to baseline.",
    "descriptor": "",
    "authors": [
      "Jihyun Lee",
      "Chaebin Lee",
      "Yunsu Kim",
      "Gary Geunbae Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.09379"
  },
  {
    "id": "arXiv:2211.09380",
    "title": "Multilayer Perceptron-based Surrogate Models for Finite Element Analysis",
    "abstract": "Many Partial Differential Equations (PDEs) do not have analytical solution,\nand can only be solved by numerical methods. In this context, Physics-Informed\nNeural Networks (PINN) have become important in the last decades, since it uses\na neural network and physical conditions to approximate any functions. This\npaper focuses on hypertuning of a PINN, used to solve a PDE. The behavior of\nthe approximated solution when we change the learning rate or the activation\nfunction (sigmoid, hyperbolic tangent, GELU, ReLU and ELU) is here analyzed. A\ncomparative study is done to determine the best characteristics in the problem,\nas well as to find a learning rate that allows fast and satisfactory learning.\nGELU and hyperbolic tangent activation functions exhibit better performance\nthan other activation functions. A suitable choice of the learning rate results\nin higher accuracy and faster convergence.",
    "descriptor": "",
    "authors": [
      "Lawson Oliveira Lima",
      "Julien Rosenberger",
      "Esteban Antier",
      "Frederic Magoules"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.09380"
  },
  {
    "id": "arXiv:2211.09381",
    "title": "Token-level Speaker Change Detection Using Speaker Difference and Speech  Content via Continuous Integrate-and-fire",
    "abstract": "In multi-talker scenarios such as meetings and conversations, speech\nprocessing systems are usually required to segment the audio and then\ntranscribe each segmentation. These two stages are addressed separately by\nspeaker change detection (SCD) and automatic speech recognition (ASR). Most\nprevious SCD systems rely solely on speaker information and ignore the\nimportance of speech content. In this paper, we propose a novel SCD system that\nconsiders both cues of speaker difference and speech content. These two cues\nare converted into token-level representations by the continuous\nintegrate-and-fire (CIF) mechanism and then combined for detecting speaker\nchanges on the token acoustic boundaries. We evaluate the performance of our\napproach on a public real-recorded meeting dataset, AISHELL-4. The experiment\nresults show that our method outperforms a competitive frame-level baseline\nsystem by 2.45% equal coverage-purity (ECP). In addition, we demonstrate the\nimportance of speech content and speaker difference to the SCD task, and the\nadvantages of conducting SCD on the token acoustic boundaries compared with\nconducting SCD frame by frame.",
    "descriptor": "",
    "authors": [
      "Zhiyun Fan",
      "Zhenlin Liang",
      "Linhao Dong",
      "Yi Liu",
      "Shiyu Zhou",
      "Meng Cai",
      "Jun Zhang",
      "Zejun Ma",
      "Bo Xu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.09381"
  },
  {
    "id": "arXiv:2211.09382",
    "title": "Planning Irregular Object Packing via Hierarchical Reinforcement  Learning",
    "abstract": "Object packing by autonomous robots is an im-portant challenge in warehouses\nand logistics industry. Most conventional data-driven packing planning\napproaches focus on regular cuboid packing, which are usually heuristic and\nlimit the practical use in realistic applications with everyday objects. In\nthis paper, we propose a deep hierarchical reinforcement learning approach to\nsimultaneously plan packing sequence and placement for irregular object\npacking. Specifically, the top manager network infers packing sequence from six\nprincipal view heightmaps of all objects, and then the bottom worker network\nreceives heightmaps of the next object to predict the placement position and\norientation. The two networks are trained hierarchically in a self-supervised\nQ-Learning framework, where the rewards are provided by the packing results\nbased on the top height , object volume and placement stability in the box. The\nframework repeats sequence and placement planning iteratively until all objects\nhave been packed into the box or no space is remained for unpacked items. We\ncompare our approach with existing robotic packing methods for irregular\nobjects in a physics simulator. Experiments show that our approach can pack\nmore objects with less time cost than the state-of-the-art packing methods of\nirregular objects. We also implement our packing plan with a robotic\nmanipulator to show the generalization ability in the real world.",
    "descriptor": "\nComments: This work is accepted by IEEE RAL. 8 pages, 6 figures\n",
    "authors": [
      "Sichao Huang",
      "Ziwei Wang",
      "Jie Zhou",
      "Jiwen Lu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09382"
  },
  {
    "id": "arXiv:2211.09385",
    "title": "ComMU: Dataset for Combinatorial Music Generation",
    "abstract": "Commercial adoption of automatic music composition requires the capability of\ngenerating diverse and high-quality music suitable for the desired context\n(e.g., music for romantic movies, action games, restaurants, etc.). In this\npaper, we introduce combinatorial music generation, a new task to create\nvarying background music based on given conditions. Combinatorial music\ngeneration creates short samples of music with rich musical metadata, and\ncombines them to produce a complete music. In addition, we introduce ComMU, the\nfirst symbolic music dataset consisting of short music samples and their\ncorresponding 12 musical metadata for combinatorial music generation. Notable\nproperties of ComMU are that (1) dataset is manually constructed by\nprofessional composers with an objective guideline that induces regularity, and\n(2) it has 12 musical metadata that embraces composers' intentions. Our results\nshow that we can generate diverse high-quality music only with metadata, and\nthat our unique metadata such as track-role and extended chord quality improves\nthe capacity of the automatic composition. We highly recommend watching our\nvideo before reading the paper (https://pozalabs.github.io/ComMU).",
    "descriptor": "\nComments: 19 pages, 12 figures\n",
    "authors": [
      "Lee Hyun",
      "Taehyun Kim",
      "Hyolim Kang",
      "Minjoo Ki",
      "Hyeonchan Hwang",
      "Kwanho Park",
      "Sharang Han",
      "Seon Joo Kim"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.09385"
  },
  {
    "id": "arXiv:2211.09386",
    "title": "BEVDistill: Cross-Modal BEV Distillation for Multi-View 3D Object  Detection",
    "abstract": "3D object detection from multiple image views is a fundamental and\nchallenging task for visual scene understanding. Owing to its low cost and high\nefficiency, multi-view 3D object detection has demonstrated promising\napplication prospects. However, accurately detecting objects through\nperspective views is extremely difficult due to the lack of depth information.\nCurrent approaches tend to adopt heavy backbones for image encoders, making\nthem inapplicable for real-world deployment. Different from the images, LiDAR\npoints are superior in providing spatial cues, resulting in highly precise\nlocalization. In this paper, we explore the incorporation of LiDAR-based\ndetectors for multi-view 3D object detection. Instead of directly training a\ndepth prediction network, we unify the image and LiDAR features in the\nBird-Eye-View (BEV) space and adaptively transfer knowledge across\nnon-homogenous representations in a teacher-student paradigm. To this end, we\npropose \\textbf{BEVDistill}, a cross-modal BEV knowledge distillation (KD)\nframework for multi-view 3D object detection. Extensive experiments demonstrate\nthat the proposed method outperforms current KD approaches on a\nhighly-competitive baseline, BEVFormer, without introducing any extra cost in\nthe inference phase. Notably, our best model achieves 59.4 NDS on the nuScenes\ntest leaderboard, achieving new state-of-the-art in comparison with various\nimage-based detectors. Code will be available at\nhttps://github.com/zehuichen123/BEVDistill.",
    "descriptor": "",
    "authors": [
      "Zehui Chen",
      "Zhenyu Li",
      "Shiquan Zhang",
      "Liangji Fang",
      "Qinhong Jiang",
      "Feng Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09386"
  },
  {
    "id": "arXiv:2211.09388",
    "title": "Data-Efficient Autoregressive Document Retrieval for Fact Verification",
    "abstract": "Document retrieval is a core component of many knowledge-intensive natural\nlanguage processing task formulations such as fact verification and question\nanswering. Sources of textual knowledge, such as Wikipedia articles, condition\nthe generation of answers from the models. Recent advances in retrieval use\nsequence-to-sequence models to incrementally predict the title of the\nappropriate Wikipedia page given a query. However, this method requires\nsupervision in the form of human annotation to label which Wikipedia pages\ncontain appropriate context. This paper introduces a distant-supervision method\nthat does not require any annotation to train autoregressive retrievers that\nattain competitive R-Precision and Recall in a zero-shot setting. Furthermore\nwe show that with task-specific supervised fine-tuning, autoregressive\nretrieval performance for two Wikipedia-based fact verification tasks can\napproach or even exceed full supervision using less than $1/4$ of the annotated\ndata indicating possible directions for data-efficient autoregressive\nretrieval.",
    "descriptor": "\nComments: To appear at SustaiNLP@EMNLP 2022. Code is available: this https URL\n",
    "authors": [
      "James Thorne"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09388"
  },
  {
    "id": "arXiv:2211.09390",
    "title": "A Study of Adoption and Effects of DevOps Practices",
    "abstract": "Many organizations adopt DevOps practices and tools in order to break down\nsilos within the organization, improve software quality and delivery, and\nincrease customer satisfaction. However, the impact of the individual practices\non the performance of the organization is not well known. In this paper, we\ncollect evidence on the effects of DevOps practices and tools on organizational\nperformance. In an extensive literature search we identified 14 DevOps\npractices, consisting of 47 subpractices. Based on these practices, we\nconducted a global survey to study their effects in practice, and measure\nDevOps maturity. Across 123 respondents, working in 11 different industries, we\nfound that 13 of the 14 DevOps practices are adopted, determined by 50\\% of the\nparticipants indicating that practices are `always', `most of the time', and\n'about half of the time' applied. There is a positive correlation between the\nadoption of all practices and independently measured maturity. In particular,\npractices concerning sandboxes for minimum deployment, test-driven development,\nand trunk based development show the lowest correlations in our data. Effects\nof software delivery and organizational performance are mainly perceived\npositive. Yet, DevOps is also considered by some to have a negative impact such\nas respondents mentioning the predictability of product delivery has decreased\nand work is less fun. Concluding, our detailed overview of DevOps practices\nallows more targeted application of DevOps practices to obtain its positive\neffects while minimizing any negative effects.",
    "descriptor": "\nComments: to be published in conference proceedings of 28th IEEE ICE/ITMC & 31st IAMOT Conference IEEE\n",
    "authors": [
      "Tyron Offerman",
      "Robert Blinde",
      "Christoph Johann Stettina",
      "Joost Visser"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.09390"
  },
  {
    "id": "arXiv:2211.09392",
    "title": "Data Dimension Reduction makes ML Algorithms efficient",
    "abstract": "Data dimension reduction (DDR) is all about mapping data from high dimensions\nto low dimensions, various techniques of DDR are being used for image dimension\nreduction like Random Projections, Principal Component Analysis (PCA), the\nVariance approach, LSA-Transform, the Combined and Direct approaches, and the\nNew Random Approach. Auto-encoders (AE) are used to learn end-to-end mapping.\nIn this paper, we demonstrate that pre-processing not only speeds up the\nalgorithms but also improves accuracy in both supervised and unsupervised\nlearning. In pre-processing of DDR, first PCA based DDR is used for supervised\nlearning, then we explore AE based DDR for unsupervised learning. In PCA based\nDDR, we first compare supervised learning algorithms accuracy and time before\nand after applying PCA. Similarly, in AE based DDR, we compare unsupervised\nlearning algorithm accuracy and time before and after AE representation\nlearning. Supervised learning algorithms including support-vector machines\n(SVM), Decision Tree with GINI index, Decision Tree with entropy and Stochastic\nGradient Descent classifier (SGDC) and unsupervised learning algorithm\nincluding K-means clustering, are used for classification purpose. We used two\ndatasets MNIST and FashionMNIST Our experiment shows that there is massive\nimprovement in accuracy and time reduction after pre-processing in both\nsupervised and unsupervised learning.",
    "descriptor": "\nComments: Our paper is accepted at International Conference On Emerging Technologies In Electronics, Computing And Communication (ICETECC) 2022\n",
    "authors": [
      "Wisal Khan",
      "Muhammad Turab",
      "Waqas Ahmad",
      "Syed Hasnat Ahmad",
      "Kelash Kumar",
      "Bin Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09392"
  },
  {
    "id": "arXiv:2211.09394",
    "title": "ConNER: Consistency Training for Cross-lingual Named Entity Recognition",
    "abstract": "Cross-lingual named entity recognition (NER) suffers from data scarcity in\nthe target languages, especially under zero-shot settings. Existing\ntranslate-train or knowledge distillation methods attempt to bridge the\nlanguage gap, but often introduce a high level of noise. To solve this problem,\nconsistency training methods regularize the model to be robust towards\nperturbations on data or hidden states. However, such methods are likely to\nviolate the consistency hypothesis, or mainly focus on coarse-grain\nconsistency. We propose ConNER as a novel consistency training framework for\ncross-lingual NER, which comprises of: (1) translation-based consistency\ntraining on unlabeled target-language data, and (2) dropoutbased consistency\ntraining on labeled source-language data. ConNER effectively leverages\nunlabeled target-language data and alleviates overfitting on the source\nlanguage to enhance the cross-lingual adaptability. Experimental results show\nour ConNER achieves consistent improvement over various baseline methods.",
    "descriptor": "\nComments: Accepted by EMNLP 2022\n",
    "authors": [
      "Ran Zhou",
      "Xin Li",
      "Lidong Bing",
      "Erik Cambria",
      "Luo Si",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.09394"
  },
  {
    "id": "arXiv:2211.09395",
    "title": "Multi-level Design for Multiple-Symbol Non-Coherent Unitary  Constellations for Massive SIMO Systems",
    "abstract": "This paper investigates non-coherent detection of single-input\nmultiple-output (SIMO) systems over block Rayleigh fading channels. Using the\nKullback-Leibler divergence as the design criterion, we formulate a\nmultiple-symbol constellation optimization problem, which turns out to have\nhigh computational complexity to construct and detect. We exploit the structure\nof the formulated problem and decouple it into a unitary constellation design\nand a multi-level design. The proposed multi-level design has low complexity in\nboth construction and detection. Simulation results show that our multi-level\ndesign has better performance than traditional pilot-based schemes and other\nexisting low-complexity multi-level designs.",
    "descriptor": "\nComments: 5 pages, 3 figures, submitted to IEEE Wireless Communications Letters\n",
    "authors": [
      "Son T. Duong",
      "Ha H. Nguyen",
      "Ebrahim Bedeer"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.09395"
  },
  {
    "id": "arXiv:2211.09397",
    "title": "Charting Visual Impression of Robot Hands",
    "abstract": "A wide variety of robotic hands have been designed to date. Yet, we do not\nknow how users perceive these hands and feel about interacting with them. To\ninform hand design for social robots, we compiled a dataset of 73 robot hands\nand ran an online study, in which 160 users rated their impressions of the\nhands using 17 rating scales. Next, we developed 17 regression models that can\npredict user ratings (e.g., humanlike) from the design features of the hands\n(e.g., number of fingers). The models have less than a 10-point error in\npredicting the user ratings on a 0-100 scale. The shape of the fingertips,\ncolor scheme, and size of the hands influence the user ratings the most. We\npresent simple guidelines to improve user impression of robot hands and outline\nremaining questions for future work.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Hasti Seifi",
      "Steven A. Vasquez",
      "Hyunyoung Kim",
      "Pooyan Fazli"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.09397"
  },
  {
    "id": "arXiv:2211.09401",
    "title": "Open-Domain Conversational Question Answering with Historical Answers",
    "abstract": "Open-domain conversational question answering can be viewed as two tasks:\npassage retrieval and conversational question answering, where the former\nrelies on selecting candidate passages from a large corpus and the latter\nrequires better understanding of a question with contexts to predict the\nanswers. This paper proposes ConvADR-QA that leverages historical answers to\nboost retrieval performance and further achieves better answering performance.\nIn our proposed framework, the retrievers use a teacher-student framework to\nreduce noises from previous turns. Our experiments on the benchmark dataset,\nOR-QuAC, demonstrate that our model outperforms existing baselines in both\nextractive and generative reader settings, well justifying the effectiveness of\nhistorical answers for open-domain conversational question answering.",
    "descriptor": "\nComments: AACL-IJCNLP 2022\n",
    "authors": [
      "Hung-Chieh Fang",
      "Kuo-Han Hung",
      "Chao-Wei Huang",
      "Yun-Nung Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.09401"
  },
  {
    "id": "arXiv:2211.09402",
    "title": "Improved uniform error bounds on a Lawson-type exponential integrator  for the long-time dynamics of sine--Gordon equation",
    "abstract": "We establish the improved uniform error bounds on a Lawson-type exponential\nintegrator Fourier pseudospectral (LEI-FP) method for the long-time dynamics of\nsine-Gordon equation where the amplitude of the initial data is\n$O(\\varepsilon)$ with $0 < \\varepsilon \\ll 1$ a dimensionless parameter up to\nthe time at $O(1/\\varepsilon^2)$. The numerical scheme combines a Lawson-type\nexponential integrator in time with a Fourier pseudospectral method for spatial\ndiscretization, which is fully explicit and efficient in practical computation\nthanks to the fast Fourier transform. By separating the linear part from the\nsine function and employing the regularity compensation oscillation (RCO)\ntechnique which is introduced to deal with the polynomial nonlinearity by phase\ncancellation, we carry out the improved error bounds for the semi-discreization\nat $O(\\varepsilon^2\\tau)$ instead of $O(\\tau)$ according to classical error\nestimates and at $O(h^m+\\varepsilon^2\\tau)$ for the full-discretization up to\nthe time $T_{\\varepsilon} = T/\\varepsilon^2$ with $T>0$ fixed. This is the\nfirst work to establish the improved uniform error bound for the long-time\ndynamics of the NKGE with non-polynomial nonlinearity. The improved error bound\nis extended to an oscillatory sine-Gordon equation with $O(\\varepsilon^2)$\nwavelength in time and $O(\\varepsilon^{-2})$ wave speed, which indicates that\nthe temporal error is independent of $\\varepsilon$ when the time step size is\nchosen as $O(\\varepsilon^2)$. Finally, numerical examples are shown to confirm\nthe improved error bounds and to demonstrate that they are sharp.",
    "descriptor": "\nComments: 24 pages, 3 figures\n",
    "authors": [
      "Yue Feng",
      "Katharina Schratz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.09402"
  },
  {
    "id": "arXiv:2211.09406",
    "title": "Personalized Federated Learning for Multi-task Fault Diagnosis of  Rotating Machinery",
    "abstract": "Intelligent fault diagnosis is essential to safe operation of machinery.\nHowever, due to scarce fault samples and data heterogeneity in field machinery,\ndeep learning based diagnosis methods are prone to over-fitting with poor\ngeneralization ability. To solve the problem, this paper proposes a\npersonalized federated learning framework, enabling multi-task fault diagnosis\nmethod across multiple factories in a privacypreserving manner. Firstly,\nrotating machines from different factories with similar vibration feature data\nare categorized into machine groups using a federated clustering method. Then,\na multi-task deep learning model based on convolutional neural network is\nconstructed to diagnose the multiple faults of machinery with heterogeneous\ninformation fusion. Finally, a personalized federated learning framework is\nproposed to solve data heterogeneity across different machines using adaptive\nhierarchical aggregation strategy. The case study on collected data from real\nmachines verifies the effectiveness of the proposed framework. The result shows\nthat the diagnosis accuracy could be improved significantly using the proposed\npersonalized federated learning, especially for those machines with scarce\nfault samples.",
    "descriptor": "",
    "authors": [
      "Sheng Guo",
      "Zengxiang Li",
      "Hui Liu",
      "Shubao Zhao",
      "Cheng Hao Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.09406"
  },
  {
    "id": "arXiv:2211.09407",
    "title": "NANSY++: Unified Voice Synthesis with Neural Analysis and Synthesis",
    "abstract": "Various applications of voice synthesis have been developed independently\ndespite the fact that they generate \"voice\" as output in common. In addition,\nmost of the voice synthesis models still require a large number of audio data\npaired with annotated labels (e.g., text transcription and music score) for\ntraining. To this end, we propose a unified framework of synthesizing and\nmanipulating voice signals from analysis features, dubbed NANSY++. The backbone\nnetwork of NANSY++ is trained in a self-supervised manner that does not require\nany annotations paired with audio. After training the backbone network, we\nefficiently tackle four voice applications - i.e. voice conversion,\ntext-to-speech, singing voice synthesis, and voice designing - by partially\nmodeling the analysis features required for each task. Extensive experiments\nshow that the proposed framework offers competitive advantages such as\ncontrollability, data efficiency, and fast training convergence, while\nproviding high quality synthesis. Audio samples: tinyurl.com/8tnsy3uc.",
    "descriptor": "\nComments: Submitted to ICLR 2023\n",
    "authors": [
      "Hyeong-Seok Choi",
      "Jinhyeok Yang",
      "Juheon Lee",
      "Hyeongju Kim"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.09407"
  },
  {
    "id": "arXiv:2211.09412",
    "title": "LongFNT: Long-form Speech Recognition with Factorized Neural Transducer",
    "abstract": "Traditional automatic speech recognition~(ASR) systems usually focus on\nindividual utterances, without considering long-form speech with useful\nhistorical information, which is more practical in real scenarios. Simply\nattending longer transcription history for a vanilla neural transducer model\nshows no much gain in our preliminary experiments, since the prediction network\nis not a pure language model. This motivates us to leverage the factorized\nneural transducer structure, containing a real language model, the vocabulary\npredictor. We propose the {LongFNT-Text} architecture, which fuses the\nsentence-level long-form features directly with the output of the vocabulary\npredictor and then embeds token-level long-form features inside the vocabulary\npredictor, with a pre-trained contextual encoder RoBERTa to further boost the\nperformance. Moreover, we propose the {LongFNT} architecture by extending the\nlong-form speech to the original speech input and achieve the best performance.\nThe effectiveness of our LongFNT approach is validated on LibriSpeech and\nGigaSpeech corpora with 19% and 12% relative word error rate~(WER) reduction,\nrespectively.",
    "descriptor": "\nComments: Submitted to ICASSP2023\n",
    "authors": [
      "Xun Gong",
      "Yu Wu",
      "Jinyu Li",
      "Shujie Liu",
      "Rui Zhao",
      "Xie Chen",
      "Yanmin Qian"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.09412"
  },
  {
    "id": "arXiv:2211.09415",
    "title": "Near-Optimal Distributed Computation of Small Vertex Cuts",
    "abstract": "We present near-optimal algorithms for detecting small vertex cuts in the\nCONGEST model of distributed computing. Despite extensive research in this\narea, our understanding of the vertex connectivity of a graph is still\nincomplete, especially in the distributed setting. To this date, all\ndistributed algorithms for detecting cut vertices suffer from an inherent\ndependency in the maximum degree of the graph, $\\Delta$. Hence, in particular,\nthere is no truly sub-linear time algorithm for this problem, not even for\ndetecting a single cut vertex. We take a new algorithmic approach for vertex\nconnectivity which allows us to bypass the existing $\\Delta$ barrier. As a\nwarm-up to our approach, we show a simple $\\widetilde{O}(D)$-round randomized\nalgorithm for computing all cut vertices in a $D$-diameter $n$-vertex graph.\nThis improves upon the $O(D+\\Delta/\\log n)$-round algorithm of [Pritchard and\nThurimella, ICALP 2008]. Our key technical contribution is an\n$\\widetilde{O}(D)$-round randomized algorithm for computing all cut pairs in\nthe graph, improving upon the state-of-the-art $O(\\Delta \\cdot D)^4$-round\nalgorithm by [Parter, DISC '19]. Note that even for the considerably simpler\nsetting of edge cuts, currently $\\widetilde{O}(D)$-round algorithms are known\nonly for detecting pairs of cut edges. Our approach is based on employing the\nwell-known linear graph sketching technique [Ahn, Guha and McGregor, SODA 2012]\nalong with the heavy-light tree decomposition of [Sleator and Tarjan, STOC\n1981]. Combining this with a careful characterization of the survivable\nsubgraphs, allows us to determine the connectivity of $G \\setminus \\{x,y\\}$ for\nevery pair $x,y \\in V$, using $\\widetilde{O}(D)$-rounds. We believe that the\ntools provided in this paper are useful for omitting the $\\Delta$-dependency\neven for larger cut values.",
    "descriptor": "\nComments: DISC 2022\n",
    "authors": [
      "Merav Parter",
      "Asaf Petruschka"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.09415"
  },
  {
    "id": "arXiv:2211.09417",
    "title": "Some Results on Digital Segments and Balanced Words",
    "abstract": "We exhibit combinatorial results on Christoffel words and binary balanced\nwords that are motivated by their geometric interpretation as approximations of\ndigital segments. We show that for every pair $(a,b)$ of positive integers, all\nthe binary balanced words with $a$ zeroes and $b$ ones are good approximations\nof the Euclidean segment from $(0,0)$ to $(a,b)$, in the sense that they encode\npaths that are contained within the digital bar delimited by the lower and the\nupper Christoffel words of slope $b/a$. We then give a closed formula for\ncounting the exact number of balanced words with $a$ zeroes and $b$ ones. We\nalso study minimal non-balanced words and prefixes of Christoffel words.",
    "descriptor": "\nComments: Submitted\n",
    "authors": [
      "Alessandro De Luca",
      "Gabriele Fici"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.09417"
  },
  {
    "id": "arXiv:2211.09419",
    "title": "Physics-Informed Koopman Network",
    "abstract": "Koopman operator theory is receiving increased attention due to its promise\nto linearize nonlinear dynamics. Neural networks that are developed to\nrepresent Koopman operators have shown great success thanks to their ability to\napproximate arbitrarily complex functions. However, despite their great\npotential, they typically require large training data-sets either from\nmeasurements of a real system or from high-fidelity simulations. In this work,\nwe propose a novel architecture inspired by physics-informed neural networks,\nwhich leverage automatic differentiation to impose the underlying physical laws\nvia soft penalty constraints during model training. We demonstrate that it not\nonly reduces the need of large training data-sets, but also maintains high\neffectiveness in approximating Koopman eigenfunctions.",
    "descriptor": "\nComments: 26 pages, 5 figures\n",
    "authors": [
      "Yuying Liu",
      "Aleksei Sholokhov",
      "Hassan Mansour",
      "Saleh Nabi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Dynamical Systems (math.DS)",
      "Operator Algebras (math.OA)"
    ],
    "url": "https://arxiv.org/abs/2211.09419"
  },
  {
    "id": "arXiv:2211.09421",
    "title": "FedSiam-DA: Dual-aggregated Federated Learning via Siamese Networks  under Non-IID Data",
    "abstract": "Federated learning is a distributed learning that allows each client to keep\nthe original data locally and only upload the parameters of the local model to\nthe server. Despite federated learning can address data island, it remains\nchallenging to train with data heterogeneous in a real application. In this\npaper, we propose FedSiam-DA, a novel dual-aggregated contrastive federated\nlearning approach, to personalize both local and global models, under various\nsettings of data heterogeneity. Firstly, based on the idea of contrastive\nlearning in the Siamese Network, FedSiam-DA regards the local and global model\nas different branches of the Siamese Network during the local training and\ncontrols the update direction of the model by constantly changing model\nsimilarity to personalize the local model. Secondly, FedSiam-DA introduces\ndynamic weights based on model similarity for each local model and exercises\nthe dual-aggregated mechanism to further improve the generalization of the\nglobal model. Moreover, we provide extensive experiments on benchmark datasets,\nthe results demonstrate that FedSiam-DA achieves outperforming several previous\nFL approaches on heterogeneous datasets.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Ming Yang",
      "Yanhan Wang",
      "Xin Wang",
      "Zhenyong Zhang",
      "Xiaoming Wu",
      "Peng Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09421"
  },
  {
    "id": "arXiv:2211.09423",
    "title": "DexPoint: Generalizable Point Cloud Reinforcement Learning for  Sim-to-Real Dexterous Manipulation",
    "abstract": "We propose a sim-to-real framework for dexterous manipulation which can\ngeneralize to new objects of the same category in the real world. The key of\nour framework is to train the manipulation policy with point cloud inputs and\ndexterous hands. We propose two new techniques to enable joint learning on\nmultiple objects and sim-to-real generalization: (i) using imagined hand point\nclouds as augmented inputs; and (ii) designing novel contact-based rewards. We\nempirically evaluate our method using an Allegro Hand to grasp novel objects in\nboth simulation and real world. To the best of our knowledge, this is the first\npolicy learning-based framework that achieves such generalization results with\ndexterous hands. Our project page is available at\nhttps://yzqin.github.io/dexpoint",
    "descriptor": "\nComments: Conference on Robot Learning (CoRL) 2022\n",
    "authors": [
      "Yuzhe Qin",
      "Binghao Huang",
      "Zhao-Heng Yin",
      "Hao Su",
      "Xiaolong Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09423"
  },
  {
    "id": "arXiv:2211.09425",
    "title": "Machine Learning for Software Engineering: A Tertiary Study",
    "abstract": "Machine learning (ML) techniques increase the effectiveness of software\nengineering (SE) lifecycle activities. We systematically collected,\nquality-assessed, summarized, and categorized 83 reviews in ML for SE published\nbetween 2009-2022, covering 6,117 primary studies. The SE areas most tackled\nwith ML are software quality and testing, while human-centered areas appear\nmore challenging for ML. We propose a number of ML for SE research challenges\nand actions including: conducting further empirical validation and industrial\nstudies on ML; reconsidering deficient SE methods; documenting and automating\ndata collection and pipeline processes; reexamining how industrial\npractitioners distribute their proprietary data; and implementing incremental\nML approaches.",
    "descriptor": "\nComments: 37 pages, 6 figures, 7 tables, journal article\n",
    "authors": [
      "Zoe Kotti",
      "Rafaila Galanopoulou",
      "Diomidis Spinellis"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09425"
  },
  {
    "id": "arXiv:2211.09427",
    "title": "Feedback is Needed for Retakes: An Explainable Poor Image Notification  Framework for the Visually Impaired",
    "abstract": "We propose a simple yet effective image captioning framework that can\ndetermine the quality of an image and notify the user of the reasons for any\nflaws in the image. Our framework first determines the quality of images and\nthen generates captions using only those images that are determined to be of\nhigh quality. The user is notified by the flaws feature to retake if image\nquality is low, and this cycle is repeated until the input image is deemed to\nbe of high quality. As a component of the framework, we trained and evaluated a\nlow-quality image detection model that simultaneously learns difficulty in\nrecognizing images and individual flaws, and we demonstrated that our proposal\ncan explain the reasons for flaws with a sufficient score. We also evaluated a\ndataset with low-quality images removed by our framework and found improved\nvalues for all four common metrics (e.g., BLEU-4, METEOR, ROUGE-L, CIDEr),\nconfirming an improvement in general-purpose image captioning capability. Our\nframework would assist the visually impaired, who have difficulty judging image\nquality.",
    "descriptor": "\nComments: 6 pages, 4 figures. Accepted at 2022 IEEE 19th International Conference on Smart Communities: Improving Quality of Life Using ICT, IoT and AI (HONET) as a full paper\n",
    "authors": [
      "Kazuya Ohata",
      "Shunsuke Kitada",
      "Hitoshi Iyatomi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09427"
  },
  {
    "id": "arXiv:2211.09434",
    "title": "Robust peak-to-peak gain analysis using integral quadratic constraints",
    "abstract": "This work provides a framework to compute an upper bound on the robust\npeak-to-peak gain of discrete-time uncertain linear systems using integral\nquadratic constraints (IQCs). Such bounds are of particular interest in the\ncomputation of reachable sets and the $\\ell_1$-norm, as well as when\nsafety-critical constraints need to be satisfied pointwise in time. The use of\n$\\rho$-hard IQCs with a terminal cost enables us to deal with a wide variety of\nuncertainty classes, for example, we provide $\\rho$-hard IQCs with a terminal\ncost for the class of parametric uncertainties. This approach unifies,\ngeneralizes, and significantly improves state-of-the-art methods, which is also\ndemonstrated in a numerical example.",
    "descriptor": "\nComments: 6 pages, submitted to IFAC WC 2023\n",
    "authors": [
      "Lukas Schwenkel",
      "Johannes K\u00f6hler",
      "Matthias A. M\u00fcller",
      "Frank Allg\u00f6wer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.09434"
  },
  {
    "id": "arXiv:2211.09438",
    "title": "Feature-augmented Machine Reading Comprehension with Auxiliary Tasks",
    "abstract": "While most successful approaches for machine reading comprehension rely on\nsingle training objective, it is assumed that the encoder layer can learn great\nrepresentation through the loss function we define in the predict layer, which\nis cross entropy in most of time, in the case that we first use neural networks\nto encode the question and paragraph, then directly fuse the encoding result of\nthem. However, due to the distantly loss backpropagating in reading\ncomprehension, the encoder layer cannot learn effectively and be directly\nsupervised. Thus, the encoder layer can not learn the representation well at\nany time. Base on this, we propose to inject multi granularity information to\nthe encoding layer. Experiments demonstrate the effect of adding multi\ngranularity information to the encoding layer can boost the performance of\nmachine reading comprehension system. Finally, empirical study shows that our\napproach can be applied to many existing MRC models.",
    "descriptor": "",
    "authors": [
      "Yifeng Xie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.09438"
  },
  {
    "id": "arXiv:2211.09440",
    "title": "Learning to Control Rapidly Changing Synaptic Connections: An  Alternative Type of Memory in Sequence Processing Artificial Neural Networks",
    "abstract": "Short-term memory in standard, general-purpose, sequence-processing recurrent\nneural networks (RNNs) is stored as activations of nodes or \"neurons.\"\nGeneralising feedforward NNs to such RNNs is mathematically straightforward and\nnatural, and even historical: already in 1943, McCulloch and Pitts proposed\nthis as a surrogate to \"synaptic modifications\" (in effect, generalising the\nLenz-Ising model, the first non-sequence processing RNN architecture of the\n1920s). A lesser known alternative approach to storing short-term memory in\n\"synaptic connections\" -- by parameterising and controlling the dynamics of a\ncontext-sensitive time-varying weight matrix through another NN -- yields\nanother \"natural\" type of short-term memory in sequence processing NNs: the\nFast Weight Programmers (FWPs) of the early 1990s. FWPs have seen a recent\nrevival as generic sequence processors, achieving competitive performance\nacross various tasks. They are formally closely related to the now popular\nTransformers. Here we present them in the context of artificial NNs as an\nabstraction of biological NNs -- a perspective that has not been stressed\nenough in previous FWP work. We first review aspects of FWPs for pedagogical\npurposes, then discuss connections to related works motivated by insights from\nneuroscience.",
    "descriptor": "\nComments: Presented at NeurIPS 2022 Workshop on Memory in Artificial and Real Intelligence\n",
    "authors": [
      "Kazuki Irie",
      "J\u00fcrgen Schmidhuber"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09440"
  },
  {
    "id": "arXiv:2211.09443",
    "title": "LEAST: a Low-Energy Adaptive Scalable Tree-based routing protocol for  Wireless Sensor Networks",
    "abstract": "Routing is one of the critical and ongoing challenges in Wireless Sensor\nNetworks. The main challenge has always been to have a routing protocol that\nreduces the communication overhead, hence saving the energy of the sensors in\nthe network. Hierarchical routing protocols are known to be the most\nenergy-efficient routing protocols for Wireless Sensor Networks. In this paper,\na more generalized hierarchical routing protocol is introduced for Wireless\nSensor Network, which is based on tree data structures. The clustering in the\nproposed protocol has the format of a general tree, which is constructed in an\nadaptive manner based on the distance of the sensors. Results show that the\nproposed tree-based protocol introduces a significant benefit in energy\nconsumption and lifetime of the network over the existing hierarchical\napproaches.",
    "descriptor": "",
    "authors": [
      "Amirmohammad Farzaneh",
      "Mihai-Alin Badiu",
      "Justin P. Coon"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.09443"
  },
  {
    "id": "arXiv:2211.09445",
    "title": "aiMotive Dataset: A Multimodal Dataset for Robust Autonomous Driving  with Long-Range Perception",
    "abstract": "Autonomous driving is a popular research area within the computer vision\nresearch community. Since autonomous vehicles are highly safety-critical,\nensuring robustness is essential for real-world deployment. While several\npublic multimodal datasets are accessible, they mainly comprise two sensor\nmodalities (camera, LiDAR) which are not well suited for adverse weather. In\naddition, they lack far-range annotations, making it harder to train neural\nnetworks that are the base of a highway assistant function of an autonomous\nvehicle. Therefore, we introduce a multimodal dataset for robust autonomous\ndriving with long-range perception. The dataset consists of 176 scenes with\nsynchronized and calibrated LiDAR, camera, and radar sensors covering a\n360-degree field of view. The collected data was captured in highway, urban,\nand suburban areas during daytime, night, and rain and is annotated with 3D\nbounding boxes with consistent identifiers across frames. Furthermore, we\ntrained unimodal and multimodal baseline models for 3D object detection. Data\nare available at \\url{https://github.com/aimotive/aimotive_dataset}.",
    "descriptor": "",
    "authors": [
      "Tam\u00e1s Matuszka",
      "Iv\u00e1n Barton",
      "\u00c1d\u00e1m Butykai",
      "P\u00e9ter Hajas",
      "D\u00e1vid Kiss",
      "Domonkos Kov\u00e1cs",
      "S\u00e1ndor Kuns\u00e1gi-M\u00e1t\u00e9",
      "P\u00e9ter Lengyel",
      "G\u00e1bor N\u00e9meth",
      "Levente Pet\u0151",
      "Dezs\u0151 Ribli",
      "D\u00e1vid Szeghy",
      "Szabolcs Vajna",
      "B\u00e1lint Varga"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09445"
  },
  {
    "id": "arXiv:2211.09446",
    "title": "Detecting Arbitrary Keypoints on Limbs and Skis with Sparse Partly  Correct Segmentation Masks",
    "abstract": "Analyses based on the body posture are crucial for top-class athletes in many\nsports disciplines. If at all, coaches label only the most important keypoints,\nsince manual annotations are very costly. This paper proposes a method to\ndetect arbitrary keypoints on the limbs and skis of professional ski jumpers\nthat requires a few, only partly correct segmentation masks during training.\nOur model is based on the Vision Transformer architecture with a special design\nfor the input tokens to query for the desired keypoints. Since we use\nsegmentation masks only to generate ground truth labels for the freely\nselectable keypoints, partly correct segmentation masks are sufficient for our\ntraining procedure. Hence, there is no need for costly hand-annotated\nsegmentation masks. We analyze different training techniques for freely\nselected and standard keypoints, including pseudo labels, and show in our\nexperiments that only a few partly correct segmentation masks are sufficient\nfor learning to detect arbitrary keypoints on limbs and skis.",
    "descriptor": "\nComments: accepted at CV4WS2023 (WACV 2023 Workshops)\n",
    "authors": [
      "Katja Ludwig",
      "Daniel Kienzle",
      "Julian Lorenz",
      "Rainer Lienhart"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09446"
  },
  {
    "id": "arXiv:2211.09454",
    "title": "DeepPrivacy2: Towards Realistic Full-Body Anonymization",
    "abstract": "Generative Adversarial Networks (GANs) are widely adapted for anonymization\nof human figures. However, current state-of-the-art limit anonymization to the\ntask of face anonymization. In this paper, we propose a novel anonymization\nframework (DeepPrivacy2) for realistic anonymization of human figures and\nfaces. We introduce a new large and diverse dataset for human figure synthesis,\nwhich significantly improves image quality and diversity of generated images.\nFurthermore, we propose a style-based GAN that produces high quality, diverse\nand editable anonymizations. We demonstrate that our full-body anonymization\nframework provides stronger privacy guarantees than previously proposed\nmethods.",
    "descriptor": "\nComments: Accepted at WACV2023\n",
    "authors": [
      "H\u00e5kon Hukkel\u00e5s",
      "Frank Lindseth"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09454"
  },
  {
    "id": "arXiv:2211.09455",
    "title": "Consultation Checklists: Standardising the Human Evaluation of Medical  Note Generation",
    "abstract": "Evaluating automatically generated text is generally hard due to the\ninherently subjective nature of many aspects of the output quality. This\ndifficulty is compounded in automatic consultation note generation by differing\nopinions between medical experts both about which patient statements should be\nincluded in generated notes and about their respective importance in arriving\nat a diagnosis. Previous real-world evaluations of note-generation systems saw\nsubstantial disagreement between expert evaluators. In this paper we propose a\nprotocol that aims to increase objectivity by grounding evaluations in\nConsultation Checklists, which are created in a preliminary step and then used\nas a common point of reference during quality assessment. We observed good\nlevels of inter-annotator agreement in a first evaluation study using the\nprotocol; further, using Consultation Checklists produced in the study as\nreference for automatic metrics such as ROUGE or BERTScore improves their\ncorrelation with human judgements compared to using the original human note.",
    "descriptor": "\nComments: Accepted for publication at EMNLP 2022\n",
    "authors": [
      "Aleksandar Savkov",
      "Francesco Moramarco",
      "Alex Papadopoulos Korfiatis",
      "Mark Perera",
      "Anya Belz",
      "Ehud Reiter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.09455"
  },
  {
    "id": "arXiv:2211.09456",
    "title": "Intelligent Reflecting Surfaces for Enhanced Physical Layer Security in  NOMA VLC Systems",
    "abstract": "The rise of intelligent reflecting surfaces (IRSs) is opening the door for\nunprecedented capabilities in visible light communication (VLC) systems. By\ncontrolling light propagation in indoor environments, it is possible to\nmanipulate the channel conditions to achieve specific key performance\nindicators. In this paper, we investigate the role that IRSs can play in\nboosting the secrecy capacity of non-orthogonal multiple access (NOMA) VLC\nsystems. More specifically, we propose an IRS-based physical layer security\n(PLS) mechanism that mitigates the information leakage risk inherent in NOMA.\nOur results demonstrate that the achieved secrecy capacity can be enhanced by\nup to 105% for a number of 80 IRS elements. To the best of our knowledge, this\nis the first paper that examines the PLS of NOMA-based IRS-assisted VLC\nsystems.",
    "descriptor": "",
    "authors": [
      "Hanaa Abumarshoud",
      "Cheng Chen",
      "Iman Tavakkolnia",
      "Harald Haas",
      "Muhammad Ali Imran"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.09456"
  },
  {
    "id": "arXiv:2211.09458",
    "title": "Abstractive Summarization Guided by Latent Hierarchical Document  Structure",
    "abstract": "Sequential abstractive neural summarizers often do not use the underlying\nstructure in the input article or dependencies between the input sentences.\nThis structure is essential to integrate and consolidate information from\ndifferent parts of the text. To address this shortcoming, we propose a\nhierarchy-aware graph neural network (HierGNN) which captures such dependencies\nthrough three main steps: 1) learning a hierarchical document structure through\na latent structure tree learned by a sparse matrix-tree computation; 2)\npropagating sentence information over this structure using a novel\nmessage-passing node propagation mechanism to identify salient information; 3)\nusing graph-level attention to concentrate the decoder on salient information.\nExperiments confirm HierGNN improves strong sequence models such as BART, with\na 0.55 and 0.75 margin in average ROUGE-1/2/L for CNN/DM and XSum. Further\nhuman evaluation demonstrates that summaries produced by our model are more\nrelevant and less redundant than the baselines, into which HierGNN is\nincorporated. We also find HierGNN synthesizes summaries by fusing multiple\nsource sentences more, rather than compressing a single source sentence, and\nthat it processes long inputs more effectively.",
    "descriptor": "\nComments: EMNLP 2022, 15 pages\n",
    "authors": [
      "Yifu Qiu",
      "Shay B. Cohen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.09458"
  },
  {
    "id": "arXiv:2211.09460",
    "title": "Progressive Tree-Structured Prototype Network for End-to-End Image  Captioning",
    "abstract": "Studies of image captioning are shifting towards a trend of a fully\nend-to-end paradigm by leveraging powerful visual pre-trained models and\ntransformer-based generation architecture for more flexible model training and\nfaster inference speed. State-of-the-art approaches simply extract isolated\nconcepts or attributes to assist description generation. However, such\napproaches do not consider the hierarchical semantic structure in the textual\ndomain, which leads to an unpredictable mapping between visual representations\nand concept words. To this end, we propose a novel Progressive Tree-Structured\nprototype Network (dubbed PTSN), which is the first attempt to narrow down the\nscope of prediction words with appropriate semantics by modeling the\nhierarchical textual semantics. Specifically, we design a novel embedding\nmethod called tree-structured prototype, producing a set of hierarchical\nrepresentative embeddings which capture the hierarchical semantic structure in\ntextual space. To utilize such tree-structured prototypes into visual\ncognition, we also propose a progressive aggregation module to exploit semantic\nrelationships within the image and prototypes. By applying our PTSN to the\nend-to-end captioning framework, extensive experiments conducted on MSCOCO\ndataset show that our method achieves a new state-of-the-art performance with\n144.2% (single model) and 146.5% (ensemble of 4 models) CIDEr scores on\n`Karpathy' split and 141.4% (c5) and 143.9% (c40) CIDEr scores on the official\nonline test server. Trained models and source code have been released at:\nhttps://github.com/NovaMind-Z/PTSN.",
    "descriptor": "",
    "authors": [
      "Pengpeng Zeng",
      "Jinkuan Zhu",
      "Jingkuan Song",
      "Lianli Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09460"
  },
  {
    "id": "arXiv:2211.09461",
    "title": "A Super-Localized Generalized Finite Element Method",
    "abstract": "This paper presents a novel multi-scale method for elliptic partial\ndifferential equations with arbitrarily rough coefficients. In the spirit of\nnumerical homogenization, the method constructs problem-adapted ansatz spaces\nwith uniform algebraic approximation rates. Localized basis functions with the\nsame super-exponential localization properties as the recently proposed\nSuper-Localized Orthogonal Decomposition enable an efficient implementation.\nThe method's basis stability is enforced using a partition of unity approach. A\nnatural extension to higher order is presented, resulting in higher\napproximation rates and enhanced localization properties. We perform a rigorous\na priori and a posteriori error analysis and confirm our theoretical findings\nin a series of numerical experiments. In particular, we demonstrate the\nmethod's applicability for challenging high-contrast channeled coefficients.",
    "descriptor": "\nComments: 24 pages, 6 figures\n",
    "authors": [
      "Philip Freese",
      "Moritz Hauck",
      "Tim Keil",
      "Daniel Peterseim"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.09461"
  },
  {
    "id": "arXiv:2211.09466",
    "title": "Integrated Sensing and Communication for Large Networks using a Dynamic  Transmission Strategy and Full Duplex",
    "abstract": "A large network employing integrated sensing and communication (ISAC) where a\nsingle transmit signal by the base station (BS) serves both the radar and\ncommunication modes is studied. Typically in ISAC, bistatic radar detection is\ndone at a passive radar. The radar-mode performance is significantly more\nvulnerable than the communication-mode due to the double path-loss in the\nsignal component while interferers have direct links. To combat this, we\npropose: 1) monostatic radar detection at the BS via full-duplex (FD), 2) a\nnovel dynamic transmission strategy (DTS). With FD monostatic detection we are\nable to improve radar-mode performance over bistatic detection in certain\nscenarios, while bistatic detection dominates in others. We also analyze the\nperformance of joint bistatic and FD monostatic detection. Significant\nimprovements in radar-performance can be attained with joint detection in\ncertain scenarios, while using one strategy is beneficial in others. Our\nresults highlight that with the DTS we are able to significantly improve\nquality of radar detection at the cost of quantity. Further, DTS causes some\nperformance deterioration to the communication-mode; however, the gains\nattained for the radar-mode are much higher. We show that joint detection and\nDTS together can significantly improve radar performance from a traditional\nradar-network.",
    "descriptor": "",
    "authors": [
      "Konpal Shaukat Ali",
      "Marwa Chafii"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.09466"
  },
  {
    "id": "arXiv:2211.09469",
    "title": "Visual Commonsense-aware Representation Network for Video Captioning",
    "abstract": "Generating consecutive descriptions for videos, i.e., Video Captioning,\nrequires taking full advantage of visual representation along with the\ngeneration process. Existing video captioning methods focus on making an\nexploration of spatial-temporal representations and their relationships to\nproduce inferences. However, such methods only exploit the superficial\nassociation contained in the video itself without considering the intrinsic\nvisual commonsense knowledge that existed in a video dataset, which may hinder\ntheir capabilities of knowledge cognitive to reason accurate descriptions. To\naddress this problem, we propose a simple yet effective method, called Visual\nCommonsense-aware Representation Network (VCRN), for video captioning.\nSpecifically, we construct a Video Dictionary, a plug-and-play component,\nobtained by clustering all video features from the total dataset into multiple\nclustered centers without additional annotation. Each center implicitly\nrepresents a visual commonsense concept in the video domain, which is utilized\nin our proposed Visual Concept Selection (VCS) to obtain a video-related\nconcept feature. Next, a Conceptual Integration Generation (CIG) is proposed to\nenhance the caption generation. Extensive experiments on three publicly video\ncaptioning benchmarks: MSVD, MSR-VTT, and VATEX, demonstrate that our method\nreaches state-of-the-art performance, indicating the effectiveness of our\nmethod. In addition, our approach is integrated into the existing method of\nvideo question answering and improves this performance, further showing the\ngeneralization of our method. Source code has been released at\nhttps://github.com/zchoi/VCRN.",
    "descriptor": "",
    "authors": [
      "Pengpeng Zeng",
      "Haonan Zhang",
      "Lianli Gao",
      "Xiangpeng Li",
      "Jin Qian",
      "Heng Tao Shen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09469"
  },
  {
    "id": "arXiv:2211.09479",
    "title": "Solar Power driven EV Charging Optimization with Deep Reinforcement  Learning",
    "abstract": "Power sector decarbonization plays a vital role in the upcoming energy\ntransition towards a more sustainable future. Decentralized energy resources,\nsuch as Electric Vehicles (EV) and solar photovoltaic systems (PV), are\ncontinuously integrated in residential power systems, increasing the risk of\nbottlenecks in power distribution networks. This paper aims to address the\nchallenge of domestic EV charging while prioritizing clean, solar energy\nconsumption. Real Time-of-Use tariffs are treated as a price-based Demand\nResponse (DR) mechanism that can incentivize end-users to optimally shift EV\ncharging load in hours of high solar PV generation with the use of Deep\nReinforcement Learning (DRL). Historical measurements from the Pecan Street\ndataset are analyzed to shape a flexibility potential reward to describe\nend-user charging preferences. Experimental results show that the proposed DQN\nEV optimal charging policy is able to reduce electricity bills by an average\n11.5\\% by achieving an average utilization of solar power 88.4",
    "descriptor": "",
    "authors": [
      "Stavros Sykiotis",
      "Christoforos Menos-Aikateriniadis",
      "Anastasios Doulamis",
      "Nikolaos Doulamis",
      "Pavlos S. Georgilakis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.09479"
  },
  {
    "id": "arXiv:2211.09480",
    "title": "ArcAid: Analysis of Archaeological Artifacts using Drawings",
    "abstract": "Archaeology is an intriguing domain for computer vision. It suffers not only\nfrom shortage in (labeled) data, but also from highly-challenging data, which\nis often extremely abraded and damaged. This paper proposes a novel\nsemi-supervised model for classification and retrieval of images of\narchaeological artifacts. This model utilizes unique data that exists in the\ndomain -- manual drawings made by special artists.These are used during\ntraining to implicitly transfer the domain knowledge from the drawings to their\ncorresponding images, improving their classification results. We show that\nwhile learning how to classify, our model also learns how to generate drawings\nof the artifacts, an important documentation task, which is currently performed\nmanually. Last but not least, we collected a new dataset of stamp-seals of the\nSouthern Levant.",
    "descriptor": "\nComments: 8 pages, 9 figures\n",
    "authors": [
      "Offry Hayon",
      "Stefan M\u00fcnger",
      "Ilan Shimshoni",
      "Ayellet Tal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09480"
  },
  {
    "id": "arXiv:2211.09482",
    "title": "Unique-Neighbor-Like Expansion and Group-Independent Cosystolic  Expansion",
    "abstract": "In recent years, high dimensional expanders have been found to have a variety\nof applications in theoretical computer science, such as efficient CSPs\napproximations, improved sampling and list-decoding algorithms, and more.\nWithin that, an important high dimensional expansion notion is \\emph{cosystolic\nexpansion}, which has found applications in the construction of efficiently\ndecodable quantum codes and in proving lower bounds for CSPs.\nCosystolic expansion is considered with systems of equations over a group\nwhere the variables and equations correspond to faces of the complex. Previous\nworks that studied cosystolic expansion were tailored to the specific group\n$\\mathbb{F}_2$. In particular, Kaufman, Kazhdan and Lubotzky (FOCS 2014), and\nEvra and Kaufman (STOC 2016) in their breakthrough works, who solved a famous\nopen question of Gromov, have studied a notion which we term ``parity''\nexpansion for small sets. They showed that small sets of $k$-faces have\nproportionally many $(k+1)$-faces that contain \\emph{an odd number} of\n$k$-faces from the set. Parity expansion for small sets could be used to imply\ncosystolic expansion only over $\\mathbb{F}_2$.\nIn this work we introduce a stronger \\emph{unique-neighbor-like} expansion\nfor small sets. We show that small sets of $k$-faces have proportionally many\n$(k+1)$-faces that contain \\emph{exactly one} $k$-face from the set. This\nnotion is fundamentally stronger than parity expansion and cannot be implied by\nprevious works.\nWe then show, utilizing the new unique-neighbor-like expansion notion\nintroduced in this work, that cosystolic expansion can be made\n\\emph{group-independent}, i.e., unique-neighbor-like expansion for small sets\nimplies cosystolic expansion \\emph{over any group}.",
    "descriptor": "",
    "authors": [
      "Tali Kaufman",
      "David Mass"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.09482"
  },
  {
    "id": "arXiv:2211.09485",
    "title": "Double Balanced Sets in High Dimensional Expanders",
    "abstract": "Recent works have shown that expansion of pseudorandom sets is of great\nimportance. However, all current works on pseudorandom sets are limited only to\nproduct (or approximate product) spaces, where Fourier Analysis methods could\nbe applied. In this work we ask the natural question whether pseudorandom sets\nare relevant in domains where Fourier Analysis methods cannot be applied, e.g.,\none-sided local spectral expanders.\nWe take the first step in the path of answering this question. We put forward\na new definition for pseudorandom sets, which we call ``double balanced sets''.\nWe demonstrate the strength of our new definition by showing that small double\nbalanced sets in one-sided local spectral expanders have very strong expansion\nproperties, such as unique-neighbor-like expansion. We further show that\ncohomologies in cosystolic expanders are double balanced, and use the newly\nderived strong expansion properties of double balanced sets in order to obtain\nan exponential improvement over the current state of the art lower bound on\ntheir minimal distance.",
    "descriptor": "",
    "authors": [
      "Tali Kaufman",
      "David Mass"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.09485"
  },
  {
    "id": "arXiv:2211.09487",
    "title": "Trace-based Deductive Verification",
    "abstract": "Contracts specifying a procedure's behavior in terms of pre- and\npostconditions are essential for scalable software verification, but cannot\nexpress any constraints on the events occurring during execution of the\nprocedure. This necessitates to annotate code with intermediate assertions,\npreventing full specification abstraction.\nWe propose a logic over symbolic traces able to specify recursive procedures\nin a modular manner that refers to specified programs only in terms of events.\nWe also provide a deduction system based on symbolic execution and induction\nthat we prove to be sound relative to a trace semantics.\nOur work generalizes contract-based to trace-based deductive verification.",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Richard Bubel",
      "Dilian Gurov",
      "Reiner H\u00e4hnle",
      "Marco Scaletta"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.09487"
  },
  {
    "id": "arXiv:2211.09488",
    "title": "EPCS: Endpoint-based Part-aware Curve Skeleton Extraction for  Low-quality Point Clouds",
    "abstract": "The curve skeleton is an important shape descriptor that has been utilized in\nvarious applications in computer graphics, machine vision, and artificial\nintelligence. In this study, the endpoint-based part-aware curve skeleton\n(EPCS) extraction method for low-quality point clouds is proposed. The novel\nrandom center shift (RCS) method is first proposed for detecting the endpoints\non point clouds. The endpoints are used as the initial seed points for dividing\neach part into layers, and then the skeletal points are obtained by computing\nthe center points of the oriented bounding box (OBB) of the layers.\nSubsequently, the skeletal points are connected, thus forming the branches.\nFurthermore, the multi-vector momentum-driven (MVMD) method is also proposed\nfor locating the junction points that connect the branches. Due to the shape\ndifferences between different parts on point clouds, the global topology of the\nskeleton is finally optimized by removing the redundant junction points,\nre-connecting some branches using the proposed MVMD method, and applying an\ninterpolation method based on the splitting operator. Consequently, a complete\nand smooth curve skeleton is achieved. The proposed EPCS method is compared\nwith several state-of-the-art methods, and the experimental results verify its\nrobustness, effectiveness, and efficiency. Furthermore, the skeleton extraction\nand model segmentation results on the point clouds of broken Terracotta also\nhighlight the utility of the proposed method.",
    "descriptor": "",
    "authors": [
      "Chunhui Li",
      "Mingquan Zhou",
      "Zehua Liu",
      "Yuhe Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09488"
  },
  {
    "id": "arXiv:2211.09495",
    "title": "Back-Translation-Style Data Augmentation for Mandarin Chinese Polyphone  Disambiguation",
    "abstract": "Conversion of Chinese Grapheme-to-Phoneme (G2P) plays an important role in\nMandarin Chinese Text-To-Speech (TTS) systems, where one of the biggest\nchallenges is the task of polyphone disambiguation. Most of the previous\npolyphone disambiguation models are trained on manually annotated datasets, and\npublicly available datasets for polyphone disambiguation are scarce. In this\npaper we propose a simple back-translation-style data augmentation method for\nmandarin Chinese polyphone disambiguation, utilizing a large amount of\nunlabeled text data. Inspired by the back-translation technique proposed in the\nfield of machine translation, we build a Grapheme-to-Phoneme (G2P) model to\npredict the pronunciation of polyphonic character, and a Phoneme-to-Grapheme\n(P2G) model to predict pronunciation into text. Meanwhile, a window-based\nmatching strategy and a multi-model scoring strategy are proposed to judge the\ncorrectness of the pseudo-label. We design a data balance strategy to improve\nthe accuracy of some typical polyphonic characters in the training set with\nimbalanced distribution or data scarcity. The experimental result shows the\neffectiveness of the proposed back-translation-style data augmentation method.",
    "descriptor": "\nComments: Published to APSIPA ASC 2022\n",
    "authors": [
      "Chunyu Qiang",
      "Peng Yang",
      "Hao Che",
      "Jinba Xiao",
      "Xiaorui Wang",
      "Zhongyuan Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.09495"
  },
  {
    "id": "arXiv:2211.09498",
    "title": "Automatic Construction of Parallel Algorithm Portfolios for  Multi-objective Optimization",
    "abstract": "It has been widely observed that there exists no universal best\nMulti-objective Evolutionary Algorithm (MOEA) dominating all other MOEAs on all\npossible Multi-objective Optimization Problems (MOPs). In this work, we\nadvocate using the Parallel Algorithm Portfolio (PAP), which runs multiple\nMOEAs independently in parallel and gets the best out of them, to combine the\nadvantages of different MOEAs. Since the manual construction of PAPs is\nnon-trivial and tedious, we propose to automatically construct high-performance\nPAPs for solving MOPs. Specifically, we first propose a variant of PAPs, namely\nMOEAs/PAP, which can better determine the output solution set for MOPs than\nconventional PAPs. Then, we present an automatic construction approach for\nMOEAs/PAP with a novel performance metric for evaluating the performance of\nMOEAs across multiple MOPs. Finally, we use the proposed approach to construct\na MOEAs/PAP based on a training set of MOPs and an algorithm configuration\nspace defined by several variants of NSGA-II. Experimental results show that\nthe automatically constructed MOEAs/PAP can even rival the state-of-the-art\nmulti-operator-based MOEAs designed by human experts, demonstrating the huge\npotential of automatic construction of PAPs in multi-objective optimization.",
    "descriptor": "",
    "authors": [
      "Xiasheng Ma",
      "Shengcai Liu",
      "Wenjing Hong"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.09498"
  },
  {
    "id": "arXiv:2211.09500",
    "title": "An Audit Framework for Technical Assessment of Binary Classifiers",
    "abstract": "Multilevel models using logistic regression (MLogRM) and random forest models\n(RFM) are increasingly deployed in industry for the purpose of binary\nclassification. The European Commission's proposed Artificial Intelligence Act\n(AIA) necessitates, under certain conditions, that application of such models\nis fair, transparent, and ethical, which consequently implies technical\nassessment of these models. This paper proposes and demonstrates an audit\nframework for technical assessment of RFMs and MLogRMs by focussing on model-,\ndiscrimination-, and transparency & explainability-related aspects. To measure\nthese aspects 20 KPIs are proposed, which are paired to a traffic light risk\nassessment method. An open-source dataset is used to train a RFM and a MLogRM\nmodel and these KPIs are computed and compared with the traffic lights. The\nperformance of popular explainability methods such as kernel- and tree-SHAP are\nassessed. The framework is expected to assist regulatory bodies in performing\nconformity assessments of binary classifiers and also benefits providers and\nusers deploying such AI-systems to comply with the AIA.",
    "descriptor": "",
    "authors": [
      "Debarati Bhaumik",
      "Diptish Dey"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.09500"
  },
  {
    "id": "arXiv:2211.09503",
    "title": "Adaptive Representations of Sound for Automatic Insect Recognition",
    "abstract": "Insects are an integral part of our ecosystem. These often small and evasive\nanimals have a big impact on their surroundings, providing a large part of the\npresent biodiversity and pollination duties, forming the foundation of the food\nchain and many biological and ecological processes. Due to factors of human\ninfluence, population numbers and biodiversity have been rapidly declining with\ntime. Monitoring this decline has become increasingly important for\nconservation measures to be effectively implemented. But monitoring methods are\noften invasive, time and resource intense, and prone to various biases. Many\ninsect species produce characteristic mating sounds that can easily be detected\nand recorded without large cost or effort. Using deep learning methods, insect\nsounds from field recordings could be automatically detected and classified to\nmonitor biodiversity and species distribution ranges. In this project, I\nimplement this using existing datasets of insect sounds (Orthoptera and\nCicadidae) and machine learning methods and evaluate their potential for\nacoustic insect monitoring. I compare the performance of the conventional\nspectrogram-based deep learning method against the new adaptive and\nwaveform-based approach LEAF. The waveform-based frontend achieved\nsignificantly better classification performance than the Mel-spectrogram\nfrontend by adapting its feature extraction parameters during training. This\nresult is encouraging for future implementations of deep learning technology\nfor automatic insect sound recognition, especially if larger datasets become\navailable.",
    "descriptor": "\nComments: 30 pages, 9 figures Dataset: this https URL\n",
    "authors": [
      "Marius Fai\u00df"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.09503"
  },
  {
    "id": "arXiv:2211.09505",
    "title": "Optimized Operation of Available Energy Resources Based on Energy  Consumption",
    "abstract": "Energy consumption and energy ananlytics has gained increased focus and\nconsideration in industrial applications especially process lines to upgrade\ntheir performance and efficiency in the competitive world. A competent\nanalytics method will be highly advantageous to provide the correct direction\nof energy saving for an industry. Energy analytics method was introduced into\nenergy consumption time analysis model and is developed in this paper. Energy\nconsumption of a camplate production plant was analysed as a case study. The\nresult shows that energy utilization is dependent on the time of operation of\nthe equipments in the plant. Energy sparing obtained via technical innovation\nin unit process maybe misplaced due to the expanding time of operation within\nthe plant. Energy loss and the distribution of energy loss in the camplate\nproduction plant were analysed and the probable energy saving methods were\nidentified from the results.",
    "descriptor": "",
    "authors": [
      "Parvathy Sobha",
      "Nita R Patne"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.09505"
  },
  {
    "id": "arXiv:2211.09507",
    "title": "Attacking Digital Twins of Robotic Systems to Compromise Security and  Safety",
    "abstract": "Security and safety are of paramount importance to human-robot interaction,\neither for autonomous robots or human-robot collaborative manufacturing. The\nintertwined relationship between security and safety has imposed new challenges\non the emerging digital twin systems of various types of robots. To be\nspecific, the attack of either the cyber-physical system or the digital-twin\nsystem could cause severe consequences to the other. Particularly, the attack\nof a digital-twin system that is synchronized with a cyber-physical system\ncould cause lateral damage to humans and other surrounding facilities. This\npaper demonstrates that for Robot Operating System (ROS) driven systems,\nattacks such as the person-in-the-middle attack of the digital-twin system\ncould eventually lead to a collapse of the cyber-physical system, whether it is\nan industrial robot or an autonomous mobile robot, causing unexpected\nconsequences. We also discuss potential solutions to alleviate such attacks.",
    "descriptor": "\nComments: 4 pages, 1 figure\n",
    "authors": [
      "Christopher Carr",
      "Shenglin Wang",
      "Peng Wang",
      "Liangxiu Han"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.09507"
  },
  {
    "id": "arXiv:2211.09510",
    "title": "Self-supervised Trajectory Representation Learning with Temporal  Regularities and Travel Semantics",
    "abstract": "Trajectory Representation Learning (TRL) is a powerful tool for\nspatial-temporal data analysis and management. TRL aims to convert complicated\nraw trajectories into low-dimensional representation vectors, which can be\napplied to various downstream tasks, such as trajectory classification,\nclustering, and similarity computation. Existing TRL works usually treat\ntrajectories as ordinary sequence data, while some important spatial-temporal\ncharacteristics, such as temporal regularities and travel semantics, are not\nfully exploited. To fill this gap, we propose a novel Self-supervised\ntrajectory representation learning framework with TemporAl Regularities and\nTravel semantics, namely START. The proposed method consists of two stages. The\nfirst stage is a Trajectory Pattern-Enhanced Graph Attention Network (TPE-GAT),\nwhich converts the road network features and travel semantics into\nrepresentation vectors of road segments. The second stage is a Time-Aware\nTrajectory Encoder (TAT-Enc), which encodes representation vectors of road\nsegments in the same trajectory as a trajectory representation vector,\nmeanwhile incorporating temporal regularities with the trajectory\nrepresentation. Moreover, we also design two self-supervised tasks, i.e.,\nspan-masked trajectory recovery and trajectory contrastive learning, to\nintroduce spatial-temporal characteristics of trajectories into the training\nprocess of our START framework. The effectiveness of the proposed method is\nverified by extensive experiments on two large-scale real-world datasets for\nthree downstream tasks. The experiments also demonstrate that our method can be\ntransferred across different cities to adapt heterogeneous trajectory datasets.",
    "descriptor": "\nComments: Accepted by ICDE 2023\n",
    "authors": [
      "Jiawei Jiang",
      "Dayan Pan",
      "Houxing Ren",
      "Xiaohan Jiang",
      "Chao Li",
      "Jingyuan Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09510"
  },
  {
    "id": "arXiv:2211.09511",
    "title": "Hey ASR System! Why Aren't You More Inclusive? Automatic Speech  Recognition Systems' Bias and Proposed Bias Mitigation Techniques. A  Literature Review",
    "abstract": "Speech is the fundamental means of communication between humans. The advent\nof AI and sophisticated speech technologies have led to the rapid proliferation\nof human-to-computer-based interactions, fueled primarily by Automatic Speech\nRecognition (ASR) systems. ASR systems normally take human speech in the form\nof audio and convert it into words, but for some users, it cannot decode the\nspeech, and any output text is filled with errors that are incomprehensible to\nthe human reader. These systems do not work equally for everyone and actually\nhinder the productivity of some users. In this paper, we present research that\naddresses ASR biases against gender, race, and the sick and disabled, while\nexploring studies that propose ASR debiasing techniques for mitigating these\ndiscriminations. We also discuss techniques for designing a more accessible and\ninclusive ASR technology. For each approach surveyed, we also provide a summary\nof the investigation and methods applied, the ASR systems and corpora used, and\nthe research findings, and highlight their strengths and/or weaknesses.\nFinally, we propose future opportunities for Natural Language Processing\nresearchers to explore in the next level creation of ASR technologies.",
    "descriptor": "\nComments: In press at HCI International 2022 - Late Breaking Papers: Interacting with eXtended Reality and Artificial Intelligence, LNCS 13518\n",
    "authors": [
      "Mikel K. Ngueajio",
      "Gloria Washington"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.09511"
  },
  {
    "id": "arXiv:2211.09518",
    "title": "ImLiDAR: Cross-Sensor Dynamic Message Propagation Network for 3D Object  Detection",
    "abstract": "LiDAR and camera, as two different sensors, supply geometric (point clouds)\nand semantic (RGB images) information of 3D scenes. However, it is still\nchallenging for existing methods to fuse data from the two cross sensors,\nmaking them complementary for quality 3D object detection (3OD). We propose\nImLiDAR, a new 3OD paradigm to narrow the cross-sensor discrepancies by\nprogressively fusing the multi-scale features of camera Images and LiDAR point\nclouds. ImLiDAR enables to provide the detection head with cross-sensor yet\nrobustly fused features. To achieve this, two core designs exist in ImLiDAR.\nFirst, we propose a cross-sensor dynamic message propagation module to combine\nthe best of the multi-scale image and point features. Second, we raise a direct\nset prediction problem that allows designing an effective set-based detector to\ntackle the inconsistency of the classification and localization confidences,\nand the sensitivity of hand-tuned hyperparameters. Besides, the novel set-based\ndetector can be detachable and easily integrated into various detection\nnetworks. Comparisons on both the KITTI and SUN-RGBD datasets show clear visual\nand numerical improvements of our ImLiDAR over twenty-three state-of-the-art\n3OD methods.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Yiyang Shen",
      "Rongwei Yu",
      "Peng Wu",
      "Haoran Xie",
      "Lina Gong",
      "Jing Qin",
      "Mingqiang Wei"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09518"
  },
  {
    "id": "arXiv:2211.09519",
    "title": "A Human-friendly Verbal Communication Platform for Multi-Robot Systems:  Design and Principles",
    "abstract": "While multi-robot systems have been broadly researched and deployed, their\nsuccess is built chiefly upon the dependency on network infrastructures,\nwhether wired or wireless. Aiming at the first steps toward de-coupling the\napplication of multi-robot systems from the reliance on network\ninfrastructures, this paper proposes a human-friendly verbal communication\nplatform for multi-robot systems, following the deliberately designed\nprinciples of being adaptable, transparent, and secure. The platform is network\nindependent and is subsequently capable of functioning in network\ninfrastructure lacking environments from underwater to planet explorations. A\nseries of experiments were conducted to demonstrate the platform's capability\nin multi-robot systems communication and task coordination, showing its\npotential in infrastructure-free applications. To benefit the community, we\nhave made the codes open source at https://github.com/jynxmagic/MSc_AI_project",
    "descriptor": "\nComments: 7 pages and 7 figures\n",
    "authors": [
      "Christopher Carr",
      "Peng Wang",
      "Shenglin Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.09519"
  },
  {
    "id": "arXiv:2211.09524",
    "title": "Towards Effective Cybercrime Intervention",
    "abstract": "Cybercrimes are on the rise, in part due to technological advancements, as\nwell as increased avenues of exploitation. Sophisticated threat actors are\nleveraging on such advancements to execute their malicious intentions. The\nincrease in cybercrimes is prevalent, and it seems unlikely that they can be\neasily eradicated. A more serious concern is that the community may come to\naccept the notion that this will become the trend. As such, the key question\nrevolves around how we can reduce cybercrime in this evolving landscape. In our\npaper, we propose to build a systematic framework through the lens of a cyber\nthreat actor. We explore the motivation factors behind the crimes and the crime\nstages of the threat actors. We then formulate intervention plans so as to\ndiscourage the act of committing malicious cyber activities and also aim to\nintegrate ex-cyber offenders back into society.",
    "descriptor": "\nComments: Crime motivations, crime prevention, cybercrime, ex-cyber criminals\n",
    "authors": [
      "Jonathan W. Z. Lim",
      "Vrizlynn L. L. Thing"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.09524"
  },
  {
    "id": "arXiv:2211.09527",
    "title": "Ignore Previous Prompt: Attack Techniques For Language Models",
    "abstract": "Transformer-based large language models (LLMs) provide a powerful foundation\nfor natural language tasks in large-scale customer-facing applications.\nHowever, studies that explore their vulnerabilities emerging from malicious\nuser interaction are scarce. By proposing PromptInject, a prosaic alignment\nframework for mask-based iterative adversarial prompt composition, we examine\nhow GPT-3, the most widely deployed language model in production, can be easily\nmisaligned by simple handcrafted inputs. In particular, we investigate two\ntypes of attacks -- goal hijacking and prompt leaking -- and demonstrate that\neven low-aptitude, but sufficiently ill-intentioned agents, can easily exploit\nGPT-3's stochastic nature, creating long-tail risks. The code for PromptInject\nis available at https://github.com/agencyenterprise/PromptInject.",
    "descriptor": "\nComments: ML Safety Workshop NeurIPS 2022\n",
    "authors": [
      "F\u00e1bio Perez",
      "Ian Ribeiro"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.09527"
  },
  {
    "id": "arXiv:2211.09529",
    "title": "InternVideo-Ego4D: A Pack of Champion Solutions to Ego4D Challenges",
    "abstract": "In this report, we present our champion solutions to five tracks at Ego4D\nchallenge. We leverage our developed InternVideo, a video foundation model, for\nfive Ego4D tasks, including Moment Queries, Natural Language Queries, Future\nHand Prediction, State Change Object Detection, and Short-term Object\nInteraction Anticipation. InternVideo-Ego4D is an effective paradigm to adapt\nthe strong foundation model to the downstream ego-centric video understanding\ntasks with simple head designs. In these five tasks, the performance of\nInternVideo-Ego4D comprehensively surpasses the baseline methods and the\nchampions of CVPR2022, demonstrating the powerful representation ability of\nInternVideo as a video foundation model. Our code will be released at\nhttps://github.com/OpenGVLab/ego4d-eccv2022-solutions",
    "descriptor": "\nComments: Technical report in 2nd International Ego4D Workshop@ECCV 2022. Code will be released at this https URL\n",
    "authors": [
      "Guo Chen",
      "Sen Xing",
      "Zhe Chen",
      "Yi Wang",
      "Kunchang Li",
      "Yizhuo Li",
      "Yi Liu",
      "Jiahao Wang",
      "Yin-Dong Zheng",
      "Bingkun Huang",
      "Zhiyu Zhao",
      "Junting Pan",
      "Yifei Huang",
      "Zun Wang",
      "Jiashuo Yu",
      "Yinan He",
      "Hongjie Zhang",
      "Tong Lu",
      "Yali Wang",
      "Limin Wang",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09529"
  },
  {
    "id": "arXiv:2211.09536",
    "title": "Towards Building Text-To-Speech Systems for the Next Billion Users",
    "abstract": "Deep learning based text-to-speech (TTS) systems have been evolving rapidly\nwith advances in model architectures, training methodologies, and\ngeneralization across speakers and languages. However, these advances have not\nbeen thoroughly investigated for Indian language speech synthesis. Such\ninvestigation is computationally expensive given the number and diversity of\nIndian languages, relatively lower resource availability, and the diverse set\nof advances in neural TTS that remain untested. In this paper, we evaluate the\nchoice of acoustic models, vocoders, supplementary loss functions, training\nschedules, and speaker and language diversity for Dravidian and Indo-Aryan\nlanguages. Based on this, we identify monolingual models with FastPitch and\nHiFi-GAN V1, trained jointly on male and female speakers to perform the best.\nWith this setup, we train and evaluate TTS models for 13 languages and find our\nmodels to significantly improve upon existing models in all languages as\nmeasured by mean opinion scores. We open-source all models on the Bhashini\nplatform.",
    "descriptor": "\nComments: Under review in ICASSP 2023. First two authors contributed equally\n",
    "authors": [
      "Gokul Karthik Kumar",
      "Praveen S V",
      "Pratyush Kumar",
      "Mitesh M. Khapra",
      "Karthik Nandakumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.09536"
  },
  {
    "id": "arXiv:2211.09537",
    "title": "Neural Langevin Dynamics: towards interpretable Neural Stochastic  Differential Equations",
    "abstract": "Neural Stochastic Differential Equations (NSDE) have been trained as both\nVariational Autoencoders, and as GANs. However, the resulting Stochastic\nDifferential Equations can be hard to interpret or analyse due to the generic\nnature of the drift and diffusion fields. By restricting our NSDE to be of the\nform of Langevin dynamics, and training it as a VAE, we obtain NSDEs that lend\nthemselves to more elaborate analysis and to a wider range of visualisation\ntechniques than a generic NSDE. More specifically, we obtain an energy\nlandscape, the minima of which are in one-to-one correspondence with latent\nstates underlying the used data. This not only allows us to detect states\nunderlying the data dynamics in an unsupervised manner, but also to infer the\ndistribution of time spent in each state according to the learned SDE. More in\ngeneral, restricting an NSDE to Langevin dynamics enables the use of a large\nset of tools from computational molecular dynamics for the analysis of the\nobtained results.",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Simon M. Koop",
      "Mark A. Peletier",
      "Jacobus W. Portegies",
      "Vlado Menkovski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09537"
  },
  {
    "id": "arXiv:2211.09544",
    "title": "Robust Downlink Multi-Antenna Beamforming with Heterogenous CSI:  Enabling eMBB and URLLC Coexistence",
    "abstract": "Two of the main problems to achieve ultra-reliable low-latency communications\n(URLLC) are related to instantaneous channel state information (I-CSI)\nacquisition and the coexistence with other service modes such as enhanced\nmobile broadband (eMBB). The former comes from the non-negligible time required\nfor accurate I-CSI acquisition, while the latter, from the heterogeneous and\nconflicting requirements of different nodes sharing the same network resources.\nIn this paper, we leverage the I-CSI of multiple eMBB links and the channel\nmeasurement's history of a URLLC user for multi-antenna beamforming design.\nSpecifically, we propose a precoding design that minimizes the transmit power\nof a base station (BS) providing eMBB and URLLC services with\nsignal-to-interference-plus-noise ratio (SINR) and outage constraints,\nrespectively, by modifying existing I-CSI-based precoding schemes to account\nfor URLLC channel history information. Moreover, we illustrate and validate the\nproposed method by adopting zero-forcing (ZF) and the transmit power\nminimization (TPM) precoding with SINR constraints. We show that the ZF\nimplementation outperforms TPM in adverse channel conditions as in Rayleigh\nfading, while the situation is rapidly reversed as the channel experiences some\nline-of-sight (LOS). Finally, we determine the confidence levels at which the\ntarget outage probabilities are reached. For instance, we show that outage\nprobabilities below $10^{-3}$ are achievable with more than 99$\\%$ confidence\nfor both precoding schemes under favorable LOS conditions with 16 transmit\nantennas and 500 samples of URLLC channel history.",
    "descriptor": "\nComments: 11 pages, 9 figures. Journal paper accepted for publication in IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Dian Echevarr\u00eda P\u00e9rez",
      "Onel L. Alcaraz L\u00f3pez",
      "Hirley Alves"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.09544"
  },
  {
    "id": "arXiv:2211.09545",
    "title": "A Reinforcement Learning Approach for Process Parameter Optimization in  Additive Manufacturing",
    "abstract": "Process optimization for metal additive manufacturing (AM) is crucial to\nensure repeatability, control microstructure, and minimize defects. Despite\nefforts to address this via the traditional design of experiments and\nstatistical process mapping, there is limited insight on an on-the-fly\noptimization framework that can be integrated into a metal AM system.\nAdditionally, most of these methods, being data-intensive, cannot be supported\nby a metal AM alloy or system due to budget restrictions. To tackle this issue,\nthe article introduces a Reinforcement Learning (RL) methodology transformed\ninto an optimization problem in the realm of metal AM. An off-policy RL\nframework based on Q-learning is proposed to find optimal laser power ($P$) -\nscan velocity ($v$) combinations with the objective of maintaining steady-state\nmelt pool depth. For this, an experimentally validated Eagar-Tsai formulation\nis used to emulate the Laser-Directed Energy Deposition environment, where the\nlaser operates as the agent across the $P-v$ space such that it maximizes\nrewards for a melt pool depth closer to the optimum. The culmination of the\ntraining process yields a Q-table where the state ($P,v$) with the highest\nQ-value corresponds to the optimized process parameter. The resultant melt pool\ndepths and the mapping of Q-values to the $P-v$ space show congruence with\nexperimental observations. The framework, therefore, provides a model-free\napproach to learning without any prior.",
    "descriptor": "",
    "authors": [
      "Susheel Dharmadhikari",
      "Nandana Menon",
      "Amrita Basak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.09545"
  },
  {
    "id": "arXiv:2211.09552",
    "title": "UniFormerV2: Spatiotemporal Learning by Arming Image ViTs with Video  UniFormer",
    "abstract": "Learning discriminative spatiotemporal representation is the key problem of\nvideo understanding. Recently, Vision Transformers (ViTs) have shown their\npower in learning long-term video dependency with self-attention.\nUnfortunately, they exhibit limitations in tackling local video redundancy, due\nto the blind global comparison among tokens. UniFormer has successfully\nalleviated this issue, by unifying convolution and self-attention as a relation\naggregator in the transformer format. However, this model has to require a\ntiresome and complicated image-pretraining phrase, before being finetuned on\nvideos. This blocks its wide usage in practice. On the contrary, open-sourced\nViTs are readily available and well-pretrained with rich image supervision.\nBased on these observations, we propose a generic paradigm to build a powerful\nfamily of video networks, by arming the pretrained ViTs with efficient\nUniFormer designs. We call this family UniFormerV2, since it inherits the\nconcise style of the UniFormer block. But it contains brand-new local and\nglobal relation aggregators, which allow for preferable accuracy-computation\nbalance by seamlessly integrating advantages from both ViTs and UniFormer.\nWithout any bells and whistles, our UniFormerV2 gets the state-of-the-art\nrecognition performance on 8 popular video benchmarks, including scene-related\nKinetics-400/600/700 and Moments in Time, temporal-related Something-Something\nV1/V2, untrimmed ActivityNet and HACS. In particular, it is the first model to\nachieve 90% top-1 accuracy on Kinetics-400, to our best knowledge. Code will be\navailable at https://github.com/OpenGVLab/UniFormerV2.",
    "descriptor": "\nComments: 24 pages, 4 figures, 20 tables\n",
    "authors": [
      "Kunchang Li",
      "Yali Wang",
      "Yinan He",
      "Yizhuo Li",
      "Yi Wang",
      "Limin Wang",
      "Yu Qiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09552"
  },
  {
    "id": "arXiv:2211.09554",
    "title": "Systematic Literature Review of Gender and Software Engineering in Asia",
    "abstract": "It is essential to discuss the role, difficulties, and opportunities\nconcerning people of different gender in the field of software engineering\nresearch, education, and industry. Although some literature reviews address\nsoftware engineering and gender, it is still unclear how research and practices\nin Asia exist for handling gender aspects in software development and\nengineering. We conducted a systematic literature review to grasp the\ncomprehensive view of gender research and practices in Asia. We analyzed the 32\nidentified papers concerning countries and publication years among 463\npublications. Researchers and practitioners from various organizations actively\nwork on gender research and practices in some countries, including China,\nIndia, and Turkey. We identified topics and classified them into seven\ncategories varying from personal mental health and team building to\norganization. Future research directions include investigating the synergy\nbetween (regional) gender aspects and cultural concerns and considering\npossible contributions and dependency among different topics to have a solid\nfoundation for accelerating further research and getting actionable practices.",
    "descriptor": "\nComments: Asia-Pacific Software Engineering and Diversity, Equity, and Inclusion (APSEDEI) workshop collocated with APSEC 2022, December 6th, 2022\n",
    "authors": [
      "Hironori Washizaki"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "General Literature (cs.GL)"
    ],
    "url": "https://arxiv.org/abs/2211.09554"
  },
  {
    "id": "arXiv:2211.09555",
    "title": "UAV Assisted Data Collection for Internet of Things: A Survey",
    "abstract": "Thanks to the advantages of flexible deployment and high mobility, unmanned\naerial vehicles (UAVs) have been widely applied in the areas of disaster\nmanagement, agricultural plant protection, environment monitoring and so on.\nWith the development of UAV and sensor technologies, UAV assisted data\ncollection for Internet of Things (IoT) has attracted increasing attentions. In\nthis article, the scenarios and key technologies of UAV assisted data\ncollection are comprehensively reviewed. First, we present the system model\nincluding the network model and mathematical model of UAV assisted data\ncollection for IoT. Then, we review the key technologies including clustering\nof sensors, UAV data collection mode as well as joint path planning and\nresource allocation. Finally, the open problems are discussed from the\nperspectives of efficient multiple access as well as joint sensing and data\ncollection. This article hopefully provides some guidelines and insights for\nresearchers in the area of UAV assisted data collection for IoT.",
    "descriptor": "",
    "authors": [
      "Zhiqing Wei",
      "Mingyue Zhu",
      "Ning Zhang",
      "Lin Wang",
      "Yingying Zou",
      "Zeyang Meng",
      "Huici Wu",
      "Zhiyong Feng"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.09555"
  },
  {
    "id": "arXiv:2211.09558",
    "title": "ReLER@ZJU Submission to the Ego4D Moment Queries Challenge 2022",
    "abstract": "In this report, we present the ReLER@ZJU1 submission to the Ego4D Moment\nQueries Challenge in ECCV 2022. In this task, the goal is to retrieve and\nlocalize all instances of possible activities in egocentric videos. Ego4D\ndataset is challenging for the temporal action localization task as the\ntemporal duration of the videos is quite long and each video contains multiple\naction instances with fine-grained action classes. To address these problems,\nwe utilize a multi-scale transformer to classify different action categories\nand predict the boundary of each instance. Moreover, in order to better capture\nthe long-term temporal dependencies in the long videos, we propose a\nsegment-level recurrence mechanism. Compared with directly feeding all video\nfeatures to the transformer encoder, the proposed segment-level recurrence\nmechanism alleviates the optimization difficulties and achieves better\nperformance. The final submission achieved Recall@1,tIoU=0.5 score of 37.24,\naverage mAP score of 17.67 and took 3-rd place on the leaderboard.",
    "descriptor": "\nComments: 3rd place in Ego4D Moment Query Challenge\n",
    "authors": [
      "Jiayi Shao",
      "Xiaohan Wang",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09558"
  },
  {
    "id": "arXiv:2211.09562",
    "title": "Convolutional neural networks for medical image segmentation",
    "abstract": "In this article, we look into some essential aspects of convolutional neural\nnetworks (CNNs) with the focus on medical image segmentation. First, we discuss\nthe CNN architecture, thereby highlighting the spatial origin of the data,\nvoxel-wise classification and the receptive field. Second, we discuss the\nsampling of input-output pairs, thereby highlighting the interaction between\nvoxel-wise classification, patch size and the receptive field. Finally, we give\na historical overview of crucial changes to CNN architectures for\nclassification and segmentation, giving insights in the relation between three\npivotal CNN architectures: FCN, U-Net and DeepMedic.",
    "descriptor": "\nComments: 10 pages, 6 figures, part of PhD thesis KU Leuven 2022 \"Understanding Final Infarct Prediction in Acute Ischemic Stroke Using Convolutional Neural Networks\"\n",
    "authors": [
      "Jeroen Bertels",
      "David Robben",
      "Robin Lemmens",
      "Dirk Vandermeulen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09562"
  },
  {
    "id": "arXiv:2211.09565",
    "title": "Towards Good Practices in Evaluating Transfer Adversarial Attacks",
    "abstract": "Transfer adversarial attacks raise critical security concerns in real-world,\nblack-box scenarios. However, the actual progress of attack methods is\ndifficult to assess due to two main limitations in existing evaluations. First,\nexisting evaluations are unsystematic and sometimes unfair since new methods\nare often directly added to old ones without complete comparisons to similar\nmethods. Second, existing evaluations mainly focus on transferability but\noverlook another key attack property: stealthiness. In this work, we design\ngood practices to address these limitations. We first introduce a new attack\ncategorization, which enables our systematic analyses of similar attacks in\neach specific category. Our analyses lead to new findings that complement or\neven challenge existing knowledge. Furthermore, we comprehensively evaluate 23\nrepresentative attacks against 9 defenses on ImageNet. We pay particular\nattention to stealthiness, by adopting diverse imperceptibility metrics and\nlooking into new, finer-grained characteristics. Our evaluation reveals new\nimportant insights: 1) Transferability is highly contextual, and some white-box\ndefenses may give a false sense of security since they are actually vulnerable\nto (black-box) transfer attacks; 2) All transfer attacks are less stealthy, and\ntheir stealthiness can vary dramatically under the same $L_{\\infty}$ bound.",
    "descriptor": "\nComments: Our code and a list of categorized attacks are publicly available at this https URL\n",
    "authors": [
      "Zhengyu Zhao",
      "Hanwei Zhang",
      "Renjue Li",
      "Ronan Sicre",
      "Laurent Amsaleg",
      "Michael Backes"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09565"
  },
  {
    "id": "arXiv:2211.09568",
    "title": "Where Did My Variable Go? Poking Holes in Incomplete Debug Information",
    "abstract": "The availability of debug information for optimized executables can largely\nease crucial tasks such as crash analysis. Source-level debuggers use this\ninformation to display program state in terms of source code, allowing users to\nreason on it even when optimizations alter program structure extensively. A few\nrecent endeavors have proposed effective methodologies for identifying\nincorrect instances of debug information, which can mislead users by presenting\nthem with an inconsistent program state.\nIn this work, we identify and study a related important problem: the\ncompleteness of debug information. Unlike correctness issues for which an\nunoptimized executable can serve as reference, we find there is no analogous\noracle to deem when the cause behind an unreported part of program state is an\nunavoidable effect of optimization or a compiler implementation defect. In this\nscenario, we argue that empirically derived conjectures on the expected\navailability of debug information can serve as an effective means to expose\nclasses of these defects.\nWe propose three conjectures involving variable values and study how often\nsynthetic programs compiled with different configurations of the popular gcc\nand LLVM compilers deviate from them. We then discuss techniques to pinpoint\nthe optimizations behind such violations and minimize bug reports accordingly.\nOur experiments revealed, among others, 24 bugs already confirmed by the\ndevelopers of the gcc-gdb and clang-lldb ecosystems.",
    "descriptor": "\nComments: Full online version (includes an Appendix not in the ASPLOS proceedings)\n",
    "authors": [
      "Cristian Assaiante",
      "Daniele Cono D'Elia",
      "Giuseppe Antonio Di Luna",
      "Leonardo Querzoni"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.09568"
  },
  {
    "id": "arXiv:2211.09569",
    "title": "DeepVoxNet2: Yet another CNN framework",
    "abstract": "We know that both the CNN mapping function and the sampling scheme are of\nparamount importance for CNN-based image analysis. It is clear that both\nfunctions operate in the same space, with an image axis $\\mathcal{I}$ and a\nfeature axis $\\mathcal{F}$. Remarkably, we found that no frameworks existed\nthat unified the two and kept track of the spatial origin of the data\nautomatically. Based on our own practical experience, we found the latter to\noften result in complex coding and pipelines that are difficult to exchange.\nThis article introduces our framework for 1, 2 or 3D image classification or\nsegmentation: DeepVoxNet2 (DVN2). This article serves as an interactive\ntutorial, and a pre-compiled version, including the outputs of the code blocks,\ncan be found online in the public DVN2 repository. This tutorial uses data from\nthe multimodal Brain Tumor Image Segmentation Benchmark (BRATS) of 2018 to show\nan example of a 3D segmentation pipeline.",
    "descriptor": "\nComments: 15 pages, part of PhD thesis KU Leuven 2022 \"Understanding Final Infarct Prediction in Acute Ischemic Stroke Using Convolutional Neural Networks\"\n",
    "authors": [
      "Jeroen Bertels",
      "David Robben",
      "Robin Lemmens",
      "Dirk Vandermeulen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09569"
  },
  {
    "id": "arXiv:2211.09571",
    "title": "Reaching Individually Stable Coalition Structures",
    "abstract": "The formal study of coalition formation in multi-agent systems is typically\nrealized in the framework of hedonic games, which originate from economic\ntheory. The main focus of this branch of research has been on the existence and\nthe computational complexity of deciding the existence of coalition structures\nthat satisfy various stability criteria. The actual process of forming\ncoalitions based on individual behavior has received little attention. In this\npaper, we study the convergence of simple dynamics leading to stable partitions\nin a variety of established classes of hedonic games including anonymous,\ndichotomous, fractional, and hedonic diversity games. The dynamics we consider\nis based on individual stability: an agent will join another coalition if she\nis better off and no member of the welcoming coalition is worse off.\nOur results are threefold. First, we identify conditions for the (fast)\nconvergence of our dynamics. To this end, we develop new techniques based on\nthe simultaneous usage of multiple intertwined potential functions and\nestablish a reduction uncovering a close relationship between anonymous hedonic\ngames and hedonic diversity games. Second, we provide elaborate counterexamples\ndetermining tight boundaries for the existence of individually stable\npartitions. Third, we study the computational complexity of problems related to\nthe coalition formation dynamics. In particular, we settle open problems\nsuggested by Bogomolnaia and Jackson (2002), Brandl et al. (2005), and Boehmer\nand Elkind (2020).",
    "descriptor": "\nComments: A preliminary version of this article appeared in the Proceedings of the 35th AAAI Conference on Artificial Intelligence (2021)\n",
    "authors": [
      "Felix Brandt",
      "Martin Bullinger",
      "Ana\u00eblle Wilczynski"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.09571"
  },
  {
    "id": "arXiv:2211.09572",
    "title": "Completeness in static analysis by abstract interpretation, a personal  point of view",
    "abstract": "Static analysis by abstract interpretation is generally designed to be\n''sound'', that is, it should not claim to establish properties that do not\nhold-in other words, not provide ''false negatives'' about possible bugs. A\nrarer requirement is that it should be ''complete'', meaning that it should be\nable to infer certain properties if they hold. This paper describes a number of\npractical issues and questions related to completeness that I have come across\nover the years.",
    "descriptor": "",
    "authors": [
      "David Monniaux"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.09572"
  },
  {
    "id": "arXiv:2211.09587",
    "title": "Spatial Graph Convolution Neural Networks for Water Distribution Systems",
    "abstract": "We investigate the task of missing value estimation in graphs as given by\nwater distribution systems (WDS) based on sparse signals as a representative\nmachine learning challenge in the domain of critical infrastructure. The\nunderlying graphs have a comparably low node degree and high diameter, while\ninformation in the graph is globally relevant, hence graph neural networks face\nthe challenge of long-term dependencies. We propose a specific architecture\nbased on message passing which displays excellent results for a number of\nbenchmark tasks in the WDS domain. Further, we investigate a multi-hop\nvariation, which requires considerably less resources and opens an avenue\ntowards big WDS graphs.",
    "descriptor": "\nComments: Under submission. Python code will be made available soon\n",
    "authors": [
      "Inaam Ashraf",
      "Luca Hermes",
      "Andr\u00e9 Artelt",
      "Barbara Hammer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09587"
  },
  {
    "id": "arXiv:2211.09590",
    "title": "Hypergraph Transformer for Skeleton-based Action Recognition",
    "abstract": "Skeleton-based action recognition aims to predict human actions given human\njoint coordinates with skeletal interconnections. To model such off-grid data\npoints and their co-occurrences, Transformer-based formulations would be a\nnatural choice. However, Transformers still lag behind state-of-the-art methods\nusing graph convolutional networks (GCNs). Transformers assume that the input\nis permutation-invariant and homogeneous (partially alleviated by positional\nencoding), which ignores an important characteristic of skeleton data, i.e.,\nbone connectivity. Furthermore, each type of body joint has a clear physical\nmeaning in human motion, i.e., motion retains an intrinsic relationship\nregardless of the joint coordinates, which is not explored in Transformers. In\nfact, certain re-occurring groups of body joints are often involved in specific\nactions, such as the subconscious hand movement for keeping balance. Vanilla\nattention is incapable of describing such underlying relations that are\npersistent and beyond pair-wise. In this work, we aim to exploit these unique\naspects of skeleton data to close the performance gap between Transformers and\nGCNs. Specifically, we propose a new self-attention (SA) extension, named\nHypergraph Self-Attention (HyperSA), to incorporate inherently higher-order\nrelations into the model. The K-hop relative positional embeddings are also\nemployed to take bone connectivity into account. We name the resulting model\nHyperformer, and it achieves comparable or better performance w.r.t. accuracy\nand efficiency than state-of-the-art GCN architectures on NTU RGB+D, NTU RGB+D\n120, and Northwestern-UCLA datasets. On the largest NTU RGB+D 120 dataset, the\nsignificantly improved performance reached by our Hyperformer demonstrates the\nunderestimated potential of Transformer models in this field.",
    "descriptor": "",
    "authors": [
      "Yuxuan Zhou",
      "Chao Li",
      "Zhi-Qi Cheng",
      "Yifeng Geng",
      "Xuansong Xie",
      "Margret Keuper"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09590"
  },
  {
    "id": "arXiv:2211.09593",
    "title": "NorMatch: Matching Normalizing Flows with Discriminative Classifiers for  Semi-Supervised Learning",
    "abstract": "Semi-Supervised Learning (SSL) aims to learn a model using a tiny labeled set\nand massive amounts of unlabeled data. To better exploit the unlabeled data the\nlatest SSL methods use pseudo-labels predicted from a single discriminative\nclassifier. However, the generated pseudo-labels are inevitably linked to\ninherent confirmation bias and noise which greatly affects the model\nperformance. In this work we introduce a new framework for SSL named NorMatch.\nFirstly, we introduce a new uncertainty estimation scheme based on normalizing\nflows, as an auxiliary classifier, to enforce highly certain pseudo-labels\nyielding a boost of the discriminative classifiers. Secondly, we introduce a\nthreshold-free sample weighting strategy to exploit better both high and low\nconfidence pseudo-labels. Furthermore, we utilize normalizing flows to model,\nin an unsupervised fashion, the distribution of unlabeled data. This modelling\nassumption can further improve the performance of generative classifiers via\nunlabeled data, and thus, implicitly contributing to training a better\ndiscriminative classifier. We demonstrate, through numerical and visual\nresults, that NorMatch achieves state-of-the-art performance on several\ndatasets.",
    "descriptor": "",
    "authors": [
      "Zhongying Deng",
      "Rihuan Ke",
      "Carola-Bibiane Schonlieb",
      "Angelica I Aviles-Rivero"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09593"
  },
  {
    "id": "arXiv:2211.09599",
    "title": "Fading in reflective and heavily shadowed industrial environments with  large arrays",
    "abstract": "One of the use cases for 5G systems and beyond is ultra-reliability\nlow-latency communication (URLLC). An enabling technology for URLLC is massive\nmultiple-input multiple-output (MIMO), which can increase reliability due to\nimproved user separation, array gain and the channel hardening effect.\nMeasurements have been performed in an operating factory environment at 3.7 GHz\nwith a co-located massive MIMO array and a unique randomly distributed array.\nChannel hardening can appear when the number of antennas is increased such that\nthe variations of channel gain (small-scale fading) is decreased and it is here\nquantified. The cumulative distribution function (CDF) of the channel gains\nthen becomes steeper and its tail is reduced. This CDF is modeled and the\nrequired fading margins are quantified. By deploying a distributed array, the\nlarge-scale power variations can also be reduced, further improving\nreliability. The large array in this rich scattering environment, creates a\nmore reliable channel as it approaches an independent identically distributed\n(i.i.d.) complex Gaussian channel, indicating that one can rethink the system\ndesign in terms of e.g. channel coding and re-transmission strategies, in order\nto reduce latency. To conclude, massive MIMO is a highly interesting technology\nfor reliable connectivity in reflective and heavily shadowed industrial\nenvironments.",
    "descriptor": "\nComments: Submitted to JSAC\n",
    "authors": [
      "Sara Willhammar",
      "Liesbet Van der Perre",
      "Fredrik Tufvesson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.09599"
  },
  {
    "id": "arXiv:2211.09603",
    "title": "(Re)packing Equal Disks into Rectangle",
    "abstract": "The problem of packing of equal disks (or circles) into a rectangle is a\nfundamental geometric problem. (By a packing here we mean an arrangement of\ndisks in a rectangle without overlapping.) We consider the following\nalgorithmic generalization of the equal disk packing problem. In this problem,\nfor a given packing of equal disks into a rectangle, the question is whether by\nchanging positions of a small number of disks, we can allocate space for\npacking more disks. More formally, in the repacking problem, for a given set of\n$n$ equal disks packed into a rectangle and integers $k$ and $h$, we ask\nwhether it is possible by changing positions of at most $h$ disks to pack $n+k$\ndisks. Thus the problem of packing equal disks is the special case of our\nproblem with $n=h=0$.\nWhile the computational complexity of packing equal disks into a rectangle\nremains open, we prove that the repacking problem is NP-hard already for $h=0$.\nOur main algorithmic contribution is an algorithm that solves the repacking\nproblem in time $(h+k)^{O(h+k)}\\cdot |I|^{O(1)}$, where $I$ is the input size.\nThat is, the problem is fixed-parameter tractable parameterized by $k$ and $h$.",
    "descriptor": "\nComments: Full version of ICALP 2022 paper\n",
    "authors": [
      "Fedor V. Fomin",
      "Petr A. Golovach",
      "Tanmay Inamdar",
      "Saket Saurabh",
      "Meirav Zehavi"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.09603"
  },
  {
    "id": "arXiv:2211.09606",
    "title": "Incremental Approximate Maximum Flow in $m^{1/2+o(1)}$ update time",
    "abstract": "We show an $(1+\\epsilon)$-approximation algorithm for maintaining maximum\n$s$-$t$ flow under $m$ edge insertions in $m^{1/2+o(1)} \\epsilon^{-1/2}$\namortized update time for directed, unweighted graphs. This constitutes the\nfirst sublinear dynamic maximum flow algorithm in general sparse graphs with\narbitrarily good approximation guarantee.",
    "descriptor": "",
    "authors": [
      "Gramoz Goranci",
      "Monika Henzinger"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.09606"
  },
  {
    "id": "arXiv:2211.09607",
    "title": "Adaptive Reduced Basis Methods for Multiscale Problems and Large-scale  PDE-constrained Optimization",
    "abstract": "This thesis presents recent advances in model order reduction methods with\nthe primary aim to construct online-efficient reduced surrogate models for\nparameterized multiscale phenomena and accelerate large-scale PDE-constrained\nparameter optimization methods. In particular, we present several different\nadaptive RB approaches that can be used in an error-aware trust-region\nframework for progressive construction of a surrogate model used during a\ncertified outer optimization loop. In addition, we elaborate on several\ndifferent enhancements for the trust-region reduced basis (TR-RB) algorithm and\ngeneralize it for parameter constraints. Thanks to the a posteriori error\nestimation of the reduced model, the resulting algorithm can be considered\ncertified with respect to the high-fidelity model. Moreover, we use the\nfirst-optimize-then-discretize approach in order to take maximum advantage of\nthe underlying optimality system of the problem. In the first part of this\nthesis, the theory is based on global RB techniques that use an accurate FEM\ndiscretization as the high-fidelity model. In the second part, we focus on\nlocalized model order reduction methods and develop a novel online efficient\nreduced model for the localized orthogonal decomposition (LOD) multiscale\nmethod. The reduced model is internally based on a two-scale formulation of the\nLOD and, in particular, is independent of the coarse and fine discretization of\nthe LOD. The last part of this thesis is devoted to combining both results on\nTR-RB methods and localized RB approaches for the LOD. To this end, we present\nan algorithm that uses adaptive localized reduced basis methods in the\nframework of a trust-region localized reduced basis (TR-LRB) algorithm. The\nbasic ideas from the TR-RB are followed, but FEM evaluations of the involved\nsystems are entirely avoided.",
    "descriptor": "\nComments: PhD thesis, defended on 06/22/2022\n",
    "authors": [
      "Tim Keil"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.09607"
  },
  {
    "id": "arXiv:2211.09609",
    "title": "Efficiency of Learning from Proof Blocks Versus Writing Proofs",
    "abstract": "Proof Blocks is a software tool that provides students with a scaffolded\nproof-writing experience, allowing them to drag and drop prewritten proof lines\ninto the correct order instead of starting from scratch. In this paper we\ndescribe a randomized controlled trial designed to measure the learning gains\nof using Proof Blocks for students learning proof by induction. The study\nparticipants were 332 students recruited after completing the first month of\ntheir discrete mathematics course. Students in the study completed a pretest on\nproof writing and a brief (less than 1 hour) learning activity and then\nreturned one week later to complete the posttest. Depending on the experimental\ncondition that each student was assigned to, they either completed only Proof\nBlocks problems, completed some Proof Blocks problems and some written proofs,\nor completed only written proofs for their learning activity. We find that\nstudents in the early phases of learning about proof by induction are able to\nlearn just as much by using Proof Blocks as by writing proofs from scratch, but\nin far less time on task. This finding that Proof Blocks are an effective\nlearning tool complements previous findings that Proof Blocks are useful exam\nquestions and are viewed positively by students.",
    "descriptor": "\nComments: To be presented at SIGCSE 2023\n",
    "authors": [
      "Seth Poulsen",
      "Yael Gertner",
      "Benjamin Cosman",
      "Matthew West",
      "Geoffrey L. Herman"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.09609"
  },
  {
    "id": "arXiv:2211.09612",
    "title": "Dynamic Pricing with Volume Discounts in Online Settings",
    "abstract": "According to the main international reports, more pervasive industrial and\nbusiness-process automation, thanks to machine learning and advanced analytic\ntools, will unlock more than 14 trillion USD worldwide annually by 2030. In the\nspecific case of pricing problems-which constitute the class of problems we\ninvestigate in this paper-, the estimated unlocked value will be about 0.5\ntrillion USD per year. In particular, this paper focuses on pricing in\ne-commerce when the objective function is profit maximization and only\ntransaction data are available. This setting is one of the most common in\nreal-world applications. Our work aims to find a pricing strategy that allows\ndefining optimal prices at different volume thresholds to serve different\nclasses of users. Furthermore, we face the major challenge, common in\nreal-world settings, of dealing with limited data available. We design a\ntwo-phase online learning algorithm, namely PVD-B, capable of exploiting the\ndata incrementally in an online fashion. The algorithm first estimates the\ndemand curve and retrieves the optimal average price, and subsequently it\noffers discounts to differentiate the prices for each volume threshold. We ran\na real-world 4-month-long A/B testing experiment in collaboration with an\nItalian e-commerce company, in which our algorithm PVD-B-corresponding to A\nconfiguration-has been compared with human pricing specialists-corresponding to\nB configuration. At the end of the experiment, our algorithm produced a total\nturnover of about 300 KEuros, outperforming the B configuration performance by\nabout 55%. The Italian company we collaborated with decided to adopt our\nalgorithm for more than 1,200 products since January 2022.",
    "descriptor": "\nComments: Accepted to IAAI 2023\n",
    "authors": [
      "Marco Mussi",
      "Gianmarco Genalti",
      "Alessandro Nuara",
      "Francesco Trov\u00f2",
      "Marcello Restelli",
      "Nicola Gatti"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09612"
  },
  {
    "id": "arXiv:2211.09618",
    "title": "A (simple) classical algorithm for estimating Betti numbers",
    "abstract": "We describe a simple algorithm for estimating the $k$-th normalized Betti\nnumber of a simplicial complex over $n$ elements using the path integral Monte\nCarlo method. For a general simplicial complex, the running time of our\nalgorithm is $n^{O(\\frac{1}{\\gamma}\\log\\frac{1}{\\varepsilon})}$ with $\\gamma$\nmeasuring the spectral gap of the combinatorial Laplacian and $\\varepsilon \\in\n(0,1)$ the additive precision. In the case of a clique complex, the running\ntime of our algorithm improves to\n$(n/\\lambda_{\\max})^{O(\\frac{1}{\\gamma}\\log\\frac{1}{\\varepsilon})}$ with\n$\\lambda_{\\max} \\geq k$ the maximum eigenvalue of the combinatorial Laplacian.\nOur algorithm provides a classical benchmark for a line of quantum algorithms\nfor estimating Betti numbers, and it matches their running time on clique\ncomplexes when the spectral gap is constant and $k \\in \\Omega(n)$ or\n$\\lambda_{\\max} \\in \\Omega(n)$.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Simon Apers",
      "Sayantan Sen",
      "D\u00e1niel Szab\u00f3"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.09618"
  },
  {
    "id": "arXiv:2211.09619",
    "title": "Introduction to Online Nonstochastic Control",
    "abstract": "This text presents an introduction to an emerging paradigm in control of\ndynamical systems and differentiable reinforcement learning called online\nnonstochastic control. The new approach applies techniques from online convex\noptimization and convex relaxations to obtain new methods with provable\nguarantees for classical settings in optimal and robust control.\nThe primary distinction between online nonstochastic control and other\nframeworks is the objective. In optimal control, robust control, and other\ncontrol methodologies that assume stochastic noise, the goal is to perform\ncomparably to an offline optimal strategy. In online nonstochastic control,\nboth the cost functions as well as the perturbations from the assumed dynamical\nmodel are chosen by an adversary. Thus the optimal policy is not defined a\npriori. Rather, the target is to attain low regret against the best policy in\nhindsight from a benchmark class of policies.\nThis objective suggests the use of the decision making framework of online\nconvex optimization as an algorithmic methodology. The resulting methods are\nbased on iterative mathematical optimization algorithms, and are accompanied by\nfinite-time regret and computational complexity guarantees.",
    "descriptor": "\nComments: Draft; comments/suggestions welcome at nonstochastic.control@gmail.com\n",
    "authors": [
      "Elad Hazan",
      "Karan Singh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.09619"
  },
  {
    "id": "arXiv:2211.09620",
    "title": "TrafficCAM: A Versatile Dataset for Traffic Flow Segmentation",
    "abstract": "Traffic flow analysis is revolutionising traffic management. Qualifying\ntraffic flow data, traffic control bureaus could provide drivers with real-time\nalerts, advising the fastest routes and therefore optimising transportation\nlogistics and reducing congestion. The existing traffic flow datasets have two\nmajor limitations. They feature a limited number of classes, usually limited to\none type of vehicle, and the scarcity of unlabelled data. In this paper, we\nintroduce a new benchmark traffic flow image dataset called TrafficCAM. Our\ndataset distinguishes itself by two major highlights. Firstly, TrafficCAM\nprovides both pixel-level and instance-level semantic labelling along with a\nlarge range of types of vehicles and pedestrians. It is composed of a large and\ndiverse set of video sequences recorded in streets from eight Indian cities\nwith stationary cameras. Secondly, TrafficCAM aims to establish a new benchmark\nfor developing fully-supervised tasks, and importantly, semi-supervised\nlearning techniques. It is the first dataset that provides a vast amount of\nunlabelled data, helping to better capture traffic flow qualification under a\nlow cost annotation requirement. More precisely, our dataset has 4,402 image\nframes with semantic and instance annotations along with 59,944 unlabelled\nimage frames. We validate our new dataset through a large and comprehensive\nrange of experiments on several state-of-the-art approaches under four\ndifferent settings: fully-supervised semantic and instance segmentation, and\nsemi-supervised semantic and instance segmentation tasks. Our benchmark dataset\nwill be released.",
    "descriptor": "",
    "authors": [
      "Zhongying Deng",
      "Yanqi Chen",
      "Lihao Liu",
      "Shujun Wang",
      "Rihuan Ke",
      "Carola-Bibiane Schonlieb",
      "Angelica I Aviles-Rivero"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09620"
  },
  {
    "id": "arXiv:2211.09622",
    "title": "AlphaSnake: Policy Iteration on a Nondeterministic NP-hard Markov  Decision Process",
    "abstract": "Reinforcement learning has recently been used to approach well-known NP-hard\ncombinatorial problems in graph theory. Among these problems, Hamiltonian cycle\nproblems are exceptionally difficult to analyze, even when restricted to\nindividual instances of structurally complex graphs. In this paper, we use\nMonte Carlo Tree Search (MCTS), the search algorithm behind many\nstate-of-the-art reinforcement learning algorithms such as AlphaZero, to create\nautonomous agents that learn to play the game of Snake, a game centered on\nproperties of Hamiltonian cycles on grid graphs. The game of Snake can be\nformulated as a single-player discounted Markov Decision Process (MDP) where\nthe agent must behave optimally in a stochastic environment. Determining the\noptimal policy for Snake, defined as the policy that maximizes the probability\nof winning - or win rate - with higher priority and minimizes the expected\nnumber of time steps to win with lower priority, is conjectured to be NP-hard.\nPerformance-wise, compared to prior work in the Snake game, our algorithm is\nthe first to achieve a win rate over $0.5$ (a uniform random policy achieves a\nwin rate $< 2.57 \\times 10^{-15}$), demonstrating the versatility of AlphaZero\nin approaching NP-hard environments.",
    "descriptor": "",
    "authors": [
      "Kevin Du",
      "Ian Gemp",
      "Yi Wu",
      "Yingying Wu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.09622"
  },
  {
    "id": "arXiv:2211.09623",
    "title": "Cross-Modal Adapter for Text-Video Retrieval",
    "abstract": "Text-video retrieval is an important multi-modal learning task, where the\ngoal is to retrieve the most relevant video for a given text query. Recently,\npre-trained models, e.g., CLIP, show great potential on this task. However, as\npre-trained models are scaling up, fully fine-tuning them on text-video\nretrieval datasets has a high risk of overfitting. Moreover, in practice, it\nwould be costly to train and store a large model for each task. To overcome the\nabove issues, we present a novel $\\textbf{Cross-Modal Adapter}$ for\nparameter-efficient fine-tuning. Inspired by adapter-based methods, we adjust\nthe pre-trained model with a few parameterization layers. However, there are\ntwo notable differences. First, our method is designed for the multi-modal\ndomain. Secondly, it allows early cross-modal interactions between CLIP's two\nencoders. Although surprisingly simple, our approach has three notable\nbenefits: (1) reduces $\\textbf{99.6}\\%$ of fine-tuned parameters, and\nalleviates the problem of overfitting, (2) saves approximately 30% of training\ntime, and (3) allows all the pre-trained parameters to be fixed, enabling the\npre-trained model to be shared across datasets. Extensive experiments\ndemonstrate that, without bells and whistles, it achieves superior or\ncomparable performance compared to fully fine-tuned methods on MSR-VTT, MSVD,\nVATEX, ActivityNet, and DiDeMo datasets. The code will be available at\n\\url{https://github.com/LeapLabTHU/Cross-Modal-Adapter}.",
    "descriptor": "\nComments: Tech Report\n",
    "authors": [
      "Haojun Jiang",
      "Jianke Zhang",
      "Rui Huang",
      "Chunjiang Ge",
      "Zanlin Ni",
      "Jiwen Lu",
      "Jie Zhou",
      "Shiji Song",
      "Gao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.09623"
  },
  {
    "id": "arXiv:2211.09625",
    "title": "Predicting Human Mobility via Self-supervised Disentanglement Learning",
    "abstract": "Deep neural networks have recently achieved considerable improvements in\nlearning human behavioral patterns and individual preferences from massive\nspatial-temporal trajectories data. However, most of the existing research\nconcentrates on fusing different semantics underlying sequential trajectories\nfor mobility pattern learning which, in turn, yields a narrow perspective on\ncomprehending human intrinsic motions. In addition, the inherent sparsity and\nunder-explored heterogeneous collaborative items pertaining to human check-ins\nhinder the potential exploitation of human diverse periodic regularities as\nwell as common interests. Motivated by recent advances in disentanglement\nlearning, in this study we propose a novel disentangled solution called SSDL\nfor tackling the next POI prediction problem. SSDL primarily seeks to\ndisentangle the potential time-invariant and time-varying factors into\ndifferent latent spaces from massive trajectories data, providing an\ninterpretable view to understand the intricate semantics underlying human\ndiverse mobility representations. To address the data sparsity issue, we\npresent two realistic trajectory augmentation approaches to enhance the\nunderstanding of both the human intrinsic periodicity and constantly-changing\nintents. In addition, we devise a POI-centric graph structure to explore\nheterogeneous collaborative signals underlying historical check-ins. Extensive\nexperiments conducted on four real-world datasets demonstrate that our proposed\nSSDL significantly outperforms the state-of-the-art approaches -- for example,\nit yields up to 8.57% improvements on ACC@1.",
    "descriptor": "\nComments: 15 pages, 9 figures\n",
    "authors": [
      "Qiang Gao",
      "Jinyu Hong",
      "Xovee Xu",
      "Ping Kuang",
      "Fan Zhou",
      "Goce Trajcevski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.09625"
  },
  {
    "id": "arXiv:2211.09626",
    "title": "A Modified Mesh with Individually Monitored Interferometers for Fast  Programmable Optical Processors",
    "abstract": "We demonstrate a novel mesh of interferometers for programmable optical\nprocessors. Employing an efficient programming scheme, the proposed\narchitecture improves energy efficiency by 83% maintaining the same computation\naccuracy for weight matrix changes at 2 kHz.",
    "descriptor": "",
    "authors": [
      "Kaveh",
      "Rahbardar Mojaver",
      "Bokun Zhao",
      "Odile Liboiron-Ladouceur"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2211.09626"
  },
  {
    "id": "arXiv:2211.09632",
    "title": "Optimal Constrained Task Planning as Mixed Integer Programming",
    "abstract": "For robots to successfully execute tasks assigned to them, they must be\ncapable of planning the right sequence of actions. These actions must be both\noptimal with respect to a specified objective and satisfy whatever constraints\nexist in their world. We propose an approach for robot task planning that is\ncapable of planning the optimal sequence of grounded actions to accomplish a\ntask given a specific objective function while satisfying all specified\nnumerical constraints. Our approach accomplishes this by encoding the entire\ntask planning problem as a single mixed integer convex program, which it then\nsolves using an off-the-shelf Mixed Integer Programming solver. We evaluate our\napproach on several mobile manipulation tasks in both simulation and on a\nphysical humanoid robot. Our approach is able to consistently produce optimal\nplans while accounting for all specified numerical constraints in the mobile\nmanipulation tasks. Open-source implementations of the components of our\napproach as well as videos of robots executing planned grounded actions in both\nsimulation and the physical world can be found at this url:\nhttps://adubredu.github.io/gtpmip",
    "descriptor": "\nComments: International Conference on Intelligent Robots and Systems (IROS), 2022\n",
    "authors": [
      "Alphonsus Adu-Bredu",
      "Nikhil Devraj",
      "Odest Chadwicke Jenkins"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.09632"
  },
  {
    "id": "arXiv:2211.09634",
    "title": "On the Sample Complexity of Two-Layer Networks: Lipschitz vs.  Element-Wise Lipschitz Activation",
    "abstract": "We investigate the sample complexity of bounded two-layer neural networks\nusing different activation functions.\nIn particular, we consider the class\n\\[\n\\mathcal{H} = \\left\\{\\textbf{x}\\mapsto \\langle \\textbf{v}, \\sigma \\circ\nW\\textbf{x} + \\textbf{b} \\rangle :\n\\textbf{b}\\in\\mathbb{R}^d, W \\in \\mathbb{R}^{T\\times d}, \\textbf{v} \\in\n\\mathbb{R}^{T}\\right\\}\n\\]\nwhere the spectral norm of $W$ and $\\textbf{v}$ is bounded by $O(1)$, the\nFrobenius norm of $W$ is bounded from its initialization by $R > 0$, and\n$\\sigma$ is a Lipschitz activation function.\nWe prove that if $\\sigma$ is element-wise, then the sample complexity of\n$\\mathcal{H}$ is width independent and that this complexity is tight.\nMoreover, we show that the element-wise property of $\\sigma$ is essential for\nwidth-independent bound, in the sense that there exist non-element-wise\nactivation functions whose sample complexity is provably width-dependent.\nFor the upper bound, we use the recent approach for norm-based bounds named\nApproximate Description Length (ADL) by arXiv:1910.05697.\nWe further develop new techniques and tools for this approach, that will\nhopefully inspire future works.",
    "descriptor": "\nComments: 9 pages with additional 15 pages of supplementary\n",
    "authors": [
      "Amit Daniely",
      "Elad Granot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09634"
  },
  {
    "id": "arXiv:2211.09639",
    "title": "Why Deep Learning Generalizes",
    "abstract": "Very large deep learning models trained using gradient descent are remarkably\nresistant to memorization given their huge capacity, but are at the same time\ncapable of fitting large datasets of pure noise. Here methods are introduced by\nwhich models may be trained to memorize datasets that normally are generalized.\nWe find that memorization is difficult relative to generalization, but that\nadding noise makes memorization easier. Increasing the dataset size exaggerates\nthe characteristics of that dataset: model access to more training samples\nmakes overfitting easier for random data, but somewhat harder for natural\nimages. The bias of deep learning towards generalization is explored\ntheoretically, and we show that generalization results from a model's\nparameters being attracted to points of maximal stability with respect to that\nmodel's inputs during gradient descent.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Benjamin L. Badger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09639"
  },
  {
    "id": "arXiv:2211.09643",
    "title": "CPT-V: A Contrastive Approach to Post-Training Quantization of Vision  Transformers",
    "abstract": "When considering post-training quantization, prior work has typically focused\non developing a mixed precision scheme or learning the best way to partition a\nnetwork for quantization. In our work, CPT-V, we look at a general way to\nimprove the accuracy of networks that have already been quantized, simply by\nperturbing the quantization scales. Borrowing the idea of contrastive loss from\nself-supervised learning, we find a robust way to jointly minimize a loss\nfunction using just 1,000 calibration images. In order to determine the best\nperforming quantization scale, CPT-V contrasts the features of quantized and\nfull precision models in a self-supervised fashion.\nUnlike traditional reconstruction-based loss functions, the use of a\ncontrastive loss function not only rewards similarity between the quantized and\nfull precision outputs but also helps in distinguishing the quantized output\nfrom other outputs within a given batch. In addition, in contrast to prior\nworks, CPT-V proposes a block-wise evolutionary search to minimize a global\ncontrastive loss objective, allowing for accuracy improvement of existing\nvision transformer (ViT) quantization schemes. For example, CPT-V improves the\ntop-1 accuracy of a fully quantized ViT-Base by 10.30%, 0.78%, and 0.15% for\n3-bit, 4-bit, and 8-bit weight quantization levels. Extensive experiments on a\nvariety of other ViT architectures further demonstrate its robustness in\nextreme quantization scenarios. Our code is available at <link>.",
    "descriptor": "",
    "authors": [
      "Natalia Frumkin",
      "Dibakar Gope",
      "Diana Marculescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.09643"
  },
  {
    "id": "arXiv:2211.09646",
    "title": "Language Conditioned Spatial Relation Reasoning for 3D Object Grounding",
    "abstract": "Localizing objects in 3D scenes based on natural language requires\nunderstanding and reasoning about spatial relations. In particular, it is often\ncrucial to distinguish similar objects referred by the text, such as \"the left\nmost chair\" and \"a chair next to the window\". In this work we propose a\nlanguage-conditioned transformer model for grounding 3D objects and their\nspatial relations. To this end, we design a spatial self-attention layer that\naccounts for relative distances and orientations between objects in input 3D\npoint clouds. Training such a layer with visual and language inputs enables to\ndisambiguate spatial relations and to localize objects referred by the text. To\nfacilitate the cross-modal learning of relations, we further propose a\nteacher-student approach where the teacher model is first trained using\nground-truth object labels, and then helps to train a student model using point\ncloud inputs. We perform ablation studies showing advantages of our approach.\nWe also demonstrate our model to significantly outperform the state of the art\non the challenging Nr3D, Sr3D and ScanRefer 3D object grounding datasets.",
    "descriptor": "\nComments: Accepted in NeurIPS 2022; Project website: this https URL\n",
    "authors": [
      "Shizhe Chen",
      "Pierre-Louis Guhur",
      "Makarand Tapaswi",
      "Cordelia Schmid",
      "Ivan Laptev"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09646"
  },
  {
    "id": "arXiv:2211.09648",
    "title": "HARDVS: Revisiting Human Activity Recognition with Dynamic Vision  Sensors",
    "abstract": "The main streams of human activity recognition (HAR) algorithms are developed\nbased on RGB cameras which are suffered from illumination, fast motion,\nprivacy-preserving, and large energy consumption. Meanwhile, the biologically\ninspired event cameras attracted great interest due to their unique features,\nsuch as high dynamic range, dense temporal but sparse spatial resolution, low\nlatency, low power, etc. As it is a newly arising sensor, even there is no\nrealistic large-scale dataset for HAR. Considering its great practical value,\nin this paper, we propose a large-scale benchmark dataset to bridge this gap,\ntermed HARDVS, which contains 300 categories and more than 100K event\nsequences. We evaluate and report the performance of multiple popular HAR\nalgorithms, which provide extensive baselines for future works to compare. More\nimportantly, we propose a novel spatial-temporal feature learning and fusion\nframework, termed ESTF, for event stream based human activity recognition. It\nfirst projects the event streams into spatial and temporal embeddings using\nStemNet, then, encodes and fuses the dual-view representations using\nTransformer networks. Finally, the dual features are concatenated and fed into\na classification head for activity prediction. Extensive experiments on\nmultiple datasets fully validated the effectiveness of our model. Both the\ndataset and source code will be released on\n\\url{https://github.com/Event-AHU/HARDVS}.",
    "descriptor": "",
    "authors": [
      "Xiao Wang",
      "Zongzhen Wu",
      "Bo Jiang",
      "Zhimin Bao",
      "Lin Zhu",
      "Guoqi Li",
      "Yaowei Wang",
      "Yonghong Tian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.09648"
  },
  {
    "id": "arXiv:2211.09655",
    "title": "Categorical Semantics for Model Comparison Games for Description Logics",
    "abstract": "A categorical approach to study model comparison games in terms of comonads\nwas recently initiated by Abramsky et al. In this work, we analyse games that\nappear naturally in the context of description logics and supplement them with\nsuitable game comonads. More precisely, we consider expressive sublogics of\nALCSelfIbO, namely, the logics that extend ALC with any combination of\ninverses, nominals, safe boolean roles combinations, and Self operator. Our\nconstruction augments and modifies the so-called modal comonad by Abramsky and\nShah. The approach that we took heavily relies on the use of relative comonads,\nwhich we leverage to encapsulate additional capabilities within the\nbisimulation games in a compositional manner.",
    "descriptor": "\nComments: Description Logics 2022; Master thesis, an extended and revised version of this https URL\n",
    "authors": [
      "Mateusz Urba\u0144czyk"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2211.09655"
  },
  {
    "id": "arXiv:2211.09656",
    "title": "Social Networks are Divulging Your Identity behind Crypto Addresses",
    "abstract": "Cryptocurrencies, such as Bitcoin and Ethereum, are becoming increasingly\nprevalent mainly due to their anonymity, decentralization, transparency, and\nsecurity. However, the completely public ledger makes the trace and analysis of\neach account possible as long as the identity behind the public address is\nrevealed. Theoretically, social networks could make that happen when addresses\nare posted on social network platforms using accounts containing personal\ninformation. To verify such a possibility, we have collected public data from\ntwo major platforms, i.e. Twitter and Reddit, aiming to find potential privacy\nleakage behind the ETH public address. In the end, an easy-to-use retrieval\napplication is also built for a better illustration.",
    "descriptor": "",
    "authors": [
      "Shuo Chen",
      "Shaikh Muhammad Uzair Norman"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.09656"
  },
  {
    "id": "arXiv:2211.09657",
    "title": "A Spreader Ranking Algorithm for Extremely Low-budget Influence  Maximization in Social Networks using Community Bridge Nodes",
    "abstract": "In recent years, social networking platforms have gained significant\npopularity among the masses like connecting with people and propagating ones\nthoughts and opinions. This has opened the door to user-specific advertisements\nand recommendations on these platforms, bringing along a significant focus on\nInfluence Maximisation (IM) on social networks due to its wide applicability in\ntarget advertising, viral marketing, and personalized recommendations. The aim\nof IM is to identify certain nodes in the network which can help maximize the\nspread of certain information through a diffusion cascade. While several works\nhave been proposed for IM, most were inefficient in exploiting community\nstructures to their full extent. In this work, we propose a community\nstructures-based approach, which employs a K-Shell algorithm in order to\ngenerate a score for the connections between seed nodes and communities for\nlow-budget scenarios. Further, our approach employs entropy within communities\nto ensure the proper spread of information within the communities. We choose\nthe Independent Cascade (IC) model to simulate information spread and evaluate\nit on four evaluation metrics. We validate our proposed approach on eight\npublicly available networks and find that it significantly outperforms the\nbaseline approaches on these metrics, while still being relatively efficient.",
    "descriptor": "\nComments: 21 pages, 7 figures\n",
    "authors": [
      "Aaryan Gupta",
      "Inder Khatri",
      "Arjun Choudhry",
      "Pranav Chandhok",
      "Dinesh Kumar Vishwakarma",
      "Mukesh Prasad"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.09657"
  },
  {
    "id": "arXiv:2211.09658",
    "title": "Energy-Efficient Driving in Connected Corridors via Minimum Principle  Control: Vehicle-in-the-Loop Experimental Verification in Mixed Fleets",
    "abstract": "Connected and automated vehicles (CAVs) can plan and actuate control that\nexplicitly considers performance, system safety, and actuation constraints in a\nmanner more efficient than their human-driven counterparts. In particular,\neco-driving is enabled through connected exchange of information from\nsignalized corridors that share their upcoming signal phase and timing (SPaT).\nThis is accomplished in the proposed control approach, which follows first\nprinciples to plan a free-flow acceleration-optimal trajectory through green\ntraffic light intervals by Pontryagin's Minimum Principle in a feedback manner.\nUrban conditions are then imposed from exogeneous traffic comprised of a\nmixture of human-driven vehicles (HVs) - as well as other CAVs. As such, safe\ndisturbance compensation is achieved by implementing a model predictive\ncontroller (MPC) to anticipate and avoid collisions by issuing braking commands\nas necessary. The control strategy is experimentally vetted through\nvehicle-in-the-loop (VIL) of a prototype CAV that is embedded into a virtual\ntraffic corridor realized through microsimulation. Up to 36% fuel savings are\nmeasured with the proposed control approach over a human-modelled driver, and\nit was found connectivity in the automation approach improved fuel economy by\nup to 26% over automation without. Additionally, the passive energy benefits\nrealizable for human drivers when driving behind downstream CAVs are measured,\nshowing up to 22% fuel savings in a HV when driving behind a small penetration\nof connectivity-enabled automated vehicles.",
    "descriptor": "\nComments: 13 Figures\n",
    "authors": [
      "Tyler Ard",
      "Longxiang Guo",
      "Jihun Han",
      "Yunyi Jia",
      "Ardalan Vahidi",
      "Dominik Karbowski"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.09658"
  },
  {
    "id": "arXiv:2211.09659",
    "title": "Minimum Path Cover in Parameterized Linear Time",
    "abstract": "A minimum path cover (MPC) of a directed acyclic graph (DAG) $G = (V,E)$ is a\nminimum-size set of paths that together cover all the vertices of the DAG.\nComputing an MPC is a basic polynomial problem, dating back to Dilworth's and\nFulkerson's results in the 1950s. Since the size $k$ of an MPC (also known as\nthe width) can be small in practical applications, research has also studied\nalgorithms whose running time is parameterized on $k$.\nWe obtain a new MPC parameterized algorithm for DAGs running in time\n$O(k^2|V| + |E|)$. Our algorithm is the first solving the problem in\nparameterized linear time. Additionally, we obtain an edge sparsification\nalgorithm preserving the width of a DAG but reducing $|E|$ to less than $2|V|$.\nThis algorithm runs in time $O(k^2|V|)$ and requires an MPC of a DAG as input,\nthus its total running time is the same as the running time of our MPC\nalgorithm.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2107.05717\n",
    "authors": [
      "Manuel Caceres",
      "Massimo Cairo",
      "Brendan Mumey",
      "Romeo Rizzi",
      "Alexandru I. Tomescu"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.09659"
  },
  {
    "id": "arXiv:2211.09660",
    "title": "On the Impact of LTE-U on Wi-Fi Performance",
    "abstract": "With the exponential growth in mobile data traffic taking place currently and\nprojected into the future, mobile operators need cost effective ways to manage\nthe load of their networks. Traditionally, this has been achieved by offloading\nmobile traffic onto Wi-Fi networks due to their low cost and ubiquitous\ndeployment. Recently, LTE operating in the unlicensed spectrum has drawn\nsignificant interests from mobile operators due to the availability of the\nunlicensed spectrum. However, the deployment of LTE networks in the unlicensed\nband poses significant challenges to the performance of current and future\nWi-Fi networks. We discuss the LTE and Wi-Fi coexistence challenges and present\nanalysis on performance degradation of the Wi-Fi networks at the presence of\nLTE.",
    "descriptor": "\nComments: 2014 IEEE 25th Annual International Symposium on Personal, Indoor, and Mobile Radio Communication (PIMRC)\n",
    "authors": [
      "Alireza Babaei",
      "Jennifer Andreoli-Fang",
      "Belal Hamzeh"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.09660"
  },
  {
    "id": "arXiv:2211.09663",
    "title": "Multi-Camera Multi-Object Tracking on the Move via Single-Stage Global  Association Approach",
    "abstract": "The development of autonomous vehicles generates a tremendous demand for a\nlow-cost solution with a complete set of camera sensors capturing the\nenvironment around the car. It is essential for object detection and tracking\nto address these new challenges in multi-camera settings. In order to address\nthese challenges, this work introduces novel Single-Stage Global Association\nTracking approaches to associate one or more detection from multi-cameras with\ntracked objects. These approaches aim to solve fragment-tracking issues caused\nby inconsistent 3D object detection. Moreover, our models also improve the\ndetection accuracy of the standard vision-based 3D object detectors in the\nnuScenes detection challenge. The experimental results on the nuScenes dataset\ndemonstrate the benefits of the proposed method by outperforming prior\nvision-based tracking methods in multi-camera settings.",
    "descriptor": "\nComments: In review PR journal. arXiv admin note: text overlap with arXiv:2204.09151\n",
    "authors": [
      "Pha Nguyen",
      "Kha Gia Quach",
      "Chi Nhan Duong",
      "Son Lam Phung",
      "Ngan Le",
      "Khoa Luu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09663"
  },
  {
    "id": "arXiv:2211.09664",
    "title": "Influencer Detection with Dynamic Graph Neural Networks",
    "abstract": "Leveraging network information for prediction tasks has become a common\npractice in many domains. Being an important part of targeted marketing,\ninfluencer detection can potentially benefit from incorporating dynamic network\nrepresentation. In this work, we investigate different dynamic Graph Neural\nNetworks (GNNs) configurations for influencer detection and evaluate their\nprediction performance using a unique corporate data set. We show that using\ndeep multi-head attention in GNN and encoding temporal attributes significantly\nimproves performance. Furthermore, our empirical evaluation illustrates that\ncapturing neighborhood representation is more beneficial that using network\ncentrality measures.",
    "descriptor": "\nComments: Conference workshop camera-ready paper - accepted at NeurIPS TGL 2022. 8 pages, 4 figures\n",
    "authors": [
      "Elena Tiukhova",
      "Emiliano Penaloza",
      "Mar\u00eda \u00d3skarsd\u00f3ttir",
      "Hernan Garcia",
      "Alejandro Correa Bahnsen",
      "Bart Baesens",
      "Monique Snoeck",
      "Cristi\u00e1n Bravo"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09664"
  },
  {
    "id": "arXiv:2211.09665",
    "title": "Features for the 0-1 knapsack problem based on inclusionwise maximal  solutions",
    "abstract": "Decades of research on the 0-1 knapsack problem led to very efficient\nalgorithms that are able to quickly solve large problem instances to\noptimality. This prompted researchers to also investigate whether relatively\nsmall problem instances exist that are hard for existing solvers and\ninvestigate which features characterize their hardness. Previously the authors\nproposed a new class of hard 0-1 knapsack problem instances and demonstrated\nthat the properties of so-called inclusionwise maximal solutions (IMSs) can be\nimportant hardness indicators for this class. In the current paper, we\nformulate several new computationally challenging problems related to the IMSs\nof arbitrary 0-1 knapsack problem instances. Based on generalizations of\nprevious work and new structural results about IMSs, we formulate polynomial\nand pseudopolynomial time algorithms for solving these problems. From this we\nderive a set of 14 computationally expensive features, which we calculate for\ntwo large datasets on a supercomputer in approximately 540 CPU-hours. We show\nthat the proposed features contain important information related to the\nempirical hardness of a problem instance that was missing in earlier features\nfrom the literature by training machine learning models that can accurately\npredict the empirical hardness of a wide variety of 0-1 knapsack problem\ninstances. Using the instance space analysis methodology, we also show that\nhard 0-1 knapsack problem instances are clustered together around a relatively\ndense region of the instance space and several features behave differently in\nthe easy and hard parts of the instance space.",
    "descriptor": "",
    "authors": [
      "Jorik Jooken",
      "Pieter Leyman",
      "Patrick De Causmaecker"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.09665"
  },
  {
    "id": "arXiv:2211.09672",
    "title": "Network-Wide Task Offloading With LEO Satellites: A Computation and  Transmission Fusion Approach",
    "abstract": "Computing tasks are ubiquitous in space missions. Conventionally, these tasks\nare offloaded to ground servers for computation, where the transmission of raw\ndata on satellite-to-ground links severely constrains the performance. To\novercome this limitation, recent works offload tasks to visible low-earth-orbit\n(LEO) satellites. However, this offloading scheme is difficult to achieve good\nperformance in actual networks with uneven loads because visible satellites\nover hotspots tend to be overloaded. Therefore, it is urgent to extend the\noffloading targets to the entire network.\nTo address the network-wide offloading problem, we propose a metagraph-based\ncomputation and transmission fusion offloading scheme for multi-tier networks.\nSpecifically, virtual edges, between the original network and its duplicate,\nare generated to fuse computation and transmission in single-tier networks.\nThen, a metagraph is employed to integrate the fusion in multi-tier networks.\nAfter assigning appropriate edge weights to the metagraph, the network-wide\noffloading problem can be solved by searching the shortest path.\nIn addition, we apply the proposed scheme to solve the spatial computation\noffloading problem in a real multi-tier network. The superiority of the\nproposed scheme over two benchmark schemes are proved theoretically and\nempirically.\nSimulation results show that the proposed scheme decreases the weighted\naverage delay by up to 87.51% and 18.70% compared with the ground offloading\nscheme and the visible offloading scheme, respectively.",
    "descriptor": "",
    "authors": [
      "Jiaqi Cao",
      "Shengli Zhang",
      "Qingxia Chen",
      "Houtian Wang",
      "Mingzhe Wang",
      "Naijin Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.09672"
  },
  {
    "id": "arXiv:2211.09676",
    "title": "Verified Reversible Programming for Verified Lossless Compression",
    "abstract": "Lossless compression implementations typically contain two programs, an\nencoder and a decoder, which are required to be inverse to one another.\nMaintaining consistency between two such programs during development requires\ncare, and incorrect data decoding can be costly and difficult to debug. We\nobserve that a significant class of compression methods, based on asymmetric\nnumeral systems (ANS), have shared structure between the encoder and decoder --\nthe decoder program is the 'reverse' of the encoder program -- allowing both to\nbe simultaneously specified by a single, reversible, 'codec' function. To\nexploit this, we have implemented a small reversible language, embedded in\nAgda, which we call 'Flipper'. Agda supports formal verification of program\nproperties, and the compiler for our reversible language (which is implemented\nas an Agda macro), produces not just an encoder/decoder pair of functions but\nalso a proof that they are inverse to one another. Thus users of the language\nget formal verification 'for free'. We give a small example use-case of Flipper\nin this paper, and plan to publish a full compression implementation soon.",
    "descriptor": "",
    "authors": [
      "James Townsend",
      "Jan-Willem van de Meent"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.09676"
  },
  {
    "id": "arXiv:2211.09678",
    "title": "Towards Automated Design of Bayesian Optimization via Exploratory  Landscape Analysis",
    "abstract": "Bayesian optimization (BO) algorithms form a class of surrogate-based\nheuristics, aimed at efficiently computing high-quality solutions for numerical\nblack-box optimization problems. The BO pipeline is highly modular, with\ndifferent design choices for the initial sampling strategy, the surrogate\nmodel, the acquisition function (AF), the solver used to optimize the AF, etc.\nWe demonstrate in this work that a dynamic selection of the AF can benefit the\nBO design. More precisely, we show that already a na\\\"ive random forest\nregression model, built on top of exploratory landscape analysis features that\nare computed from the initial design points, suffices to recommend AFs that\noutperform any static choice, when considering performance over the classic\nBBOB benchmark suite for derivative-free numerical optimization methods on the\nCOCO platform. Our work hence paves a way towards AutoML-assisted, on-the-fly\nBO designs that adjust their behavior on a run-by-run basis.",
    "descriptor": "\nComments: 6th Workshop on Meta-Learning at NeurIPS 2022, New Orleans\n",
    "authors": [
      "Carolin Benjamins",
      "Anja Jankovic",
      "Elena Raponi",
      "Koen van der Blom",
      "Marius Lindauer",
      "Carola Doerr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09678"
  },
  {
    "id": "arXiv:2211.09680",
    "title": "Analyse der Entwicklungstreiber milit\u00e4rischer Schwarmdrohnen durch  Natural Language Processing",
    "abstract": "Military drones are taking an increasingly prominent role in armed conflict,\nand the use of multiple drones in a swarm can be useful. Who the drivers of the\nresearch are and what sub-domains exist is analyzed and visually presented in\nthis research using NLP techniques based on 946 studies. Most research is\nconducted in the Western world, led by the United States, the United Kingdom,\nand Germany. Through Tf-idf scoring, it is shown that countries have\nsignificant differences in the subdomains studied. Overall, 2019 and 2020 saw\nthe most works published, with significant interest in military swarm drones as\nearly as 2008. This study provides a first glimpse into research in this area\nand prompts further investigation.",
    "descriptor": "\nComments: 5 pages, in German, 4 figures\n",
    "authors": [
      "Manuel Mundt"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.09680"
  },
  {
    "id": "arXiv:2211.09681",
    "title": "Did They Really Tweet That? Querying Fact-Checking Sites and Politwoops  to Determine Tweet Misattribution",
    "abstract": "Screenshots of social media posts have become common place on social media\nsites. While screenshots definitely serve a purpose, their ubiquity enables the\nspread of fabricated screenshots of posts that were never actually made,\nthereby proliferating misattribution disinformation. With the motivation of\ndetecting this type of disinformation, we researched developing methods of\nquerying the Web for evidence of a tweet's existence. We developed software\nthat automatically makes search queries utilizing the body of alleged tweets to\na variety of services (Google, Snopes built-in search, and Reuters built-in\nsearch) in an effort to find fact-check articles and other evidence of\nsupposedly made tweets. We also developed tools to automatically search the\nsite Politwoops for a particular tweet that may have been made and deleted by\nan elected official. In addition, we developed software to scrape fact-check\narticles from the sites Reuters.com and Snopes.com in order to derive a ``truth\nrating\" from any given article from these sites. For evaluation, we began the\nconstruction of a ground truth dataset of tweets with known evidence (currently\nonly Snopes fact-check articles) on the live web, and we gathered MRR and P@1\nvalues based on queries made using only the bodies of those tweets. These\nqueries showed that the Snopes built-in search was effective at finding\nappropriate articles about half of the time with MRR=0.5500 and P@1=0.5333,\nwhile Google when used with the site:snopes.com operator was generally\neffective at finding the articles in question, with MRR=0.8667 and P@1=0.8667.",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Caleb Bradford",
      "Michael L. Nelson"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.09681"
  },
  {
    "id": "arXiv:2211.09682",
    "title": "AligNeRF: High-Fidelity Neural Radiance Fields via Alignment-Aware  Training",
    "abstract": "Neural Radiance Fields (NeRFs) are a powerful representation for modeling a\n3D scene as a continuous function. Though NeRF is able to render complex 3D\nscenes with view-dependent effects, few efforts have been devoted to exploring\nits limits in a high-resolution setting. Specifically, existing NeRF-based\nmethods face several limitations when reconstructing high-resolution real\nscenes, including a very large number of parameters, misaligned input data, and\noverly smooth details. In this work, we conduct the first pilot study on\ntraining NeRF with high-resolution data and propose the corresponding\nsolutions: 1) marrying the multilayer perceptron (MLP) with convolutional\nlayers which can encode more neighborhood information while reducing the total\nnumber of parameters; 2) a novel training strategy to address misalignment\ncaused by moving objects or small camera calibration errors; and 3) a\nhigh-frequency aware loss. Our approach is nearly free without introducing\nobvious training/testing costs, while experiments on different datasets\ndemonstrate that it can recover more high-frequency details compared with the\ncurrent state-of-the-art NeRF models. Project page:\n\\url{https://yifanjiang.net/alignerf.}",
    "descriptor": "",
    "authors": [
      "Yifan Jiang",
      "Peter Hedman",
      "Ben Mildenhall",
      "Dejia Xu",
      "Jonathan T. Barron",
      "Zhangyang Wang",
      "Tianfan Xue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09682"
  },
  {
    "id": "arXiv:2211.09683",
    "title": "Influence Maximization in Social Networks using Discretized Harris Hawks  Optimization Algorithm and Neighbour Scout Strategy",
    "abstract": "Influence Maximization (IM) is the task of determining k optimal influential\nnodes in a social network to maximize the influence spread using a propagation\nmodel. IM is a prominent problem for viral marketing, and helps significantly\nin social media advertising. However, developing effective algorithms with\nminimal time complexity for real-world social networks still remains a\nchallenge. While traditional heuristic approaches have been applied for IM,\nthey often result in minimal performance gains over the computationally\nexpensive Greedy-based and Reverse Influence Sampling-based approaches. In this\npaper, we propose the discretization of the nature-inspired Harris Hawks\nOptimisation meta-heuristic algorithm using community structures for optimal\nselection of seed nodes for influence spread. In addition to Harris Hawks\nintelligence, we employ a neighbour scout strategy algorithm to avoid blindness\nand enhance the searching ability of the hawks. Further, we use a candidate\nnodes-based random population initialization approach, and these candidate\nnodes aid in accelerating the convergence process for the entire populace. We\nevaluate the efficacy of our proposed DHHO approach on six social networks\nusing the Independent Cascade model for information diffusion. We observe that\nDHHO is comparable or better than competing meta-heuristic approaches for\nInfluence Maximization across five metrics, and performs noticeably better than\ncompeting heuristic approaches.",
    "descriptor": "\nComments: 24 pages, 7 figures\n",
    "authors": [
      "Inder Khatri",
      "Arjun Choudhry",
      "Aryaman Rao",
      "Aryan Tyagi",
      "Dinesh Kumar Vishwakarma",
      "Mukesh Prasad"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.09683"
  },
  {
    "id": "arXiv:2211.09690",
    "title": "The Effectiveness of Bidirectional Generative Patent Language Models",
    "abstract": "Generative patent language models can assist humans to write patent text more\neffectively. The question is how to measure effectiveness from a human-centric\nperspective and how to improve effectiveness. In this manuscript, a simplified\ndesign of the autocomplete function is proposed to increase effectiveness by\nmore than 10%. With the new design, the effectiveness of autocomplete can reach\nmore than 60%, which means that more than 60% of keystrokes can be saved by\nautocomplete. Since writing patent text does not necessarily start from the\nbeginning to the end, a question is whether the generative model can assist a\nuser no matter where to start writing. To answer the question, the generative\nmodels in this manuscript are pre-trained with training data in both\ndirections. The generative models become bidirectional. Since text generation\nis bidirectional, the calculation of autocomplete effectiveness can be\nbidirectional and starts from anywhere in the text. After thorough experiments,\na key finding is that the autocomplete effectiveness of a model for the same\ntext remains similar no matter where the calculation starts. The finding\nindicates that such bidirectional models can assist a user at a similar level,\nno matter where the user starts to write.",
    "descriptor": "\nComments: 10 pages, 3 figures, 5 tables\n",
    "authors": [
      "Jieh-Sheng Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09690"
  },
  {
    "id": "arXiv:2211.09691",
    "title": "Synthesizing Quantum-Circuit Optimizers",
    "abstract": "Near-term quantum computers are expected to work in an environment where each\noperation is noisy, with no error correction. Therefore, quantum-circuit\noptimizers are applied to minimize the number of noisy operations. Today,\nphysicists are constantly experimenting with novel devices and architectures.\nFor every new physical substrate and for every modification of a quantum\ncomputer, we need to modify or rewrite major pieces of the optimizer to run\nsuccessful experiments. In this paper, we present QUESO, an efficient approach\nfor automatically synthesizing a quantum-circuit optimizer for a given quantum\ndevice. For instance, in 1.2 minutes, QUESO can synthesize a verified optimizer\nfor IBM computers that significantly outperforms leading compilers, such as\nIBM's Qiskit and TKET, on the majority (85%) of the circuits in a diverse\nbenchmark suite.\nA number of theoretical and algorithmic insights underlie QUESO: (1) An\nalgebraic approach for representing rewrite rules and their semantics. This\nfacilitates reasoning about complex symbolic rewrite rules that are beyond the\nscope of existing techniques. (2) A fast approach for verifying equivalence of\nquantum circuits by reducing the problem to a special form of polynomial\nidentity testing. (3) A novel probabilistic data structure, called a polynomial\nidentity filter (PIF), for efficiently synthesizing rewrite rules. (4) A\nbeam-search-based algorithm that efficiently applies the synthesized symbolic\nrewrite rules to optimize quantum circuits.",
    "descriptor": "",
    "authors": [
      "Amanda Xu",
      "Abtin Molavi",
      "Lauren Pick",
      "Swamit Tannu",
      "Aws Albarghouthi"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.09691"
  },
  {
    "id": "arXiv:2211.09699",
    "title": "PromptCap: Prompt-Guided Task-Aware Image Captioning",
    "abstract": "Image captioning aims to describe an image with a natural language sentence,\nallowing powerful language models to understand images. The framework of\ncombining image captioning with language models has been successful on various\nvision-language tasks. However, an image contains much more information than a\nsingle sentence, leading to underspecification of which visual entities should\nbe described in the caption sentence. For example, when performing visual\nquestioning answering (VQA), generic image captions often miss visual details\nthat are essential for the language model to answer correctly. To address this\nchallenge, we propose PromptCap, a captioning model that takes a\nnatural-language prompt to control the contents of the generated caption. The\nprompt contains a question that the caption should help to answer, and also\nsupports taking auxiliary text inputs such as scene text within the image\nitself. To finetune a general image caption model for prompt-guided captioning,\nwe propose a pipeline to synthesize and filter training examples with GPT-3 and\nexisting VQA datasets. For evaluation, we start with an existing pipeline in\nwhich a language model is prompted with image captions to carry out VQA. With\nthe same language model, a higher QA accuracy shows that our generated captions\nare more relevant to the question prompts. PromptCap outperforms generic\ncaptions by a large margin on a variety of VQA tasks and achieves the\nstate-of-the-art accuracy of 58.8 % on OK-VQA and 58.0 % on A-OKVQA. Zero-shot\nexperiments on WebQA show that PromptCap generalizes well to unseen domains.",
    "descriptor": "",
    "authors": [
      "Yushi Hu",
      "Hang Hua",
      "Zhengyuan Yang",
      "Weijia Shi",
      "Noah A. Smith",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.09699"
  },
  {
    "id": "arXiv:2211.09700",
    "title": "Granular F-transform and its application",
    "abstract": "This contribution introduces the concept of granular F-transform and\ninvestigates its basic properties by using the theory of fuzzy numbers and\nhorizontal membership functions. Further, we present a numerical method based\non granular F-transform to solve a fuzzy prey-predator model consisting of two\nprey and one predator due to its natural variability and investigate the\nexistence of the equilibrium points and their stability",
    "descriptor": "",
    "authors": [
      "Abha Tripathi",
      "S. P. Tiwari",
      "J. Kavikumar"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.09700"
  },
  {
    "id": "arXiv:2211.09702",
    "title": "Deep Reinforcement Learning Based Joint Downlink Beamforming and RIS  Configuration in RIS-aided MU-MISO Systems Under Hardware Impairments and  Imperfect CSI",
    "abstract": "We investigate the joint transmit beamforming and reconfigurable intelligent\nsurface (RIS) configuration problem to maximize the sum downlink rate of a\nRIS-aided cellular multiuser multiple input single output (MU-MISO) system\nunder imperfect channel state information (CSI) and hardware impairments by\nconsidering a practical phase-dependent RIS amplitude model. To this end, we\npresent a novel deep reinforcement learning (DRL) framework and compare its\nperformance against a vanilla DRL agent under two scenarios: the golden\nstandard where the base station (BS) knows the channel and the phase-dependent\nRIS amplitude model perfectly, and the mismatch scenario where the BS has\nimperfect CSI and assumes ideal RIS reflections. Our numerical results show\nthat the introduced framework substantially outperforms the vanilla DRL agent\nunder mismatch and approaches the golden standard.",
    "descriptor": "",
    "authors": [
      "Baturay Saglam",
      "Doga Gurgunoglu",
      "Suleyman S. Kozat"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.09702"
  },
  {
    "id": "arXiv:2211.09703",
    "title": "EfficientTrain: Exploring Generalized Curriculum Learning for Training  Visual Backbones",
    "abstract": "The superior performance of modern deep networks usually comes at the price\nof a costly training procedure. In this paper, we present a novel curriculum\nlearning approach for the efficient training of visual backbones (e.g., vision\nTransformers). The proposed method is inspired by the phenomenon that deep\nnetworks mainly learn to recognize some 'easier-to-learn' discriminative\npatterns within each example at earlier stages of training, e.g., the\nlower-frequency components of images and the original information before data\naugmentation. Driven by this observation, we propose a curriculum where the\nmodel always leverages all the training data at each epoch, while the\ncurriculum starts with only exposing the 'easier-to-learn' patterns of each\nexample, and introduces gradually more difficult patterns. To implement this\nidea, we 1) introduce a cropping operation in the Fourier spectrum of the\ninputs, which enables the model to learn from only the lower-frequency\ncomponents efficiently, and 2) demonstrate that exposing the features of\noriginal images amounts to adopting weaker data augmentation. Our resulting\nalgorithm, EfficientTrain, is simple, general, yet surprisingly effective. For\nexample, it reduces the training time of a wide variety of popular models\n(e.g., ConvNeXts, DeiT, PVT, and Swin/CSWin Transformers) by more than\n${1.5\\times}$ on ImageNet-1K/22K without sacrificing the accuracy. It is\neffective for self-supervised learning (i.e., MAE) as well. Code is available\nat https://github.com/LeapLabTHU/EfficientTrain.",
    "descriptor": "",
    "authors": [
      "Yulin Wang",
      "Yang Yue",
      "Rui Lu",
      "Tianjiao Liu",
      "Zhao Zhong",
      "Shiji Song",
      "Gao Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09703"
  },
  {
    "id": "arXiv:2211.09706",
    "title": "A Synthetic Dataset for 5G UAV Attacks Based on Observable Network  Parameters",
    "abstract": "Synthetic datasets are beneficial for machine learning researchers due to the\npossibility of experimenting with new strategies and algorithms in the training\nand testing phases. These datasets can easily include more scenarios that might\nbe costly to research with real data or can complement and, in some cases,\nreplace real data measurements, depending on the quality of the synthetic data.\nThey can also solve the unbalanced data problem, avoid overfitting, and can be\nused in training while testing can be done with real data. In this paper, we\npresent, to the best of our knowledge, the first synthetic dataset for Unmanned\nAerial Vehicle (UAV) attacks in 5G and beyond networks based on the following\nkey observable network parameters that indicate power levels: the Received\nSignal Strength Indicator (RSSI) and the Signal to Interference-plus-Noise\nRatio (SINR). The main objective of this data is to enable deep network\ndevelopment for UAV communication security. Especially, for algorithm\ndevelopment or the analysis of time-series data applied to UAV attack\nrecognition. Our proposed dataset provides insights into network functionality\nwhen static or moving UAV attackers target authenticated UAVs in an urban\nenvironment. The dataset also considers the presence and absence of\nauthenticated terrestrial users in the network, which may decrease the deep\nnetworks ability to identify attacks. Furthermore, the data provides deeper\ncomprehension of the metrics available in the 5G physical and MAC layers for\nmachine learning and statistics research. The dataset will available at link\narchive-beta.ics.uci.edu",
    "descriptor": "\nComments: 6 pages, 4 figures, 1 table\n",
    "authors": [
      "Joseanne Viana",
      "Hamed Farkhari",
      "Pedro Sebastiao",
      "Sandra Lagen",
      "Katerina Koutlia",
      "Biljana Bojovic",
      "Rui Dinis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09706"
  },
  {
    "id": "arXiv:2211.09707",
    "title": "Listen, denoise, action! Audio-driven motion synthesis with diffusion  models",
    "abstract": "Diffusion models have experienced a surge of interest as highly expressive\nyet efficiently trainable probabilistic models. We show that these models are\nan excellent fit for synthesising human motion that co-occurs with audio, for\nexample co-speech gesticulation, since motion is complex and highly ambiguous\ngiven audio, calling for a probabilistic description. Specifically, we adapt\nthe DiffWave architecture to model 3D pose sequences, putting Conformers in\nplace of dilated convolutions for improved accuracy. We also demonstrate\ncontrol over motion style, using classifier-free guidance to adjust the\nstrength of the stylistic expression. Gesture-generation experiments on the\nTrinity Speech-Gesture and ZeroEGGS datasets confirm that the proposed method\nachieves top-of-the-line motion quality, with distinctive styles whose\nexpression can be made more or less pronounced. We also synthesise dance motion\nand path-driven locomotion using the same model architecture. Finally, we\nextend the guidance procedure to perform style interpolation in a manner that\nis appealing for synthesis tasks and has connections to product-of-experts\nmodels, a contribution we believe is of independent interest. Video examples\nare available at https://www.speech.kth.se/research/listen-denoise-action/",
    "descriptor": "\nComments: 15 pages, 6 figures\n",
    "authors": [
      "Simon Alexanderson",
      "Rajmund Nagy",
      "Jonas Beskow",
      "Gustav Eje Henter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Human-Computer Interaction (cs.HC)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.09707"
  },
  {
    "id": "arXiv:2211.09708",
    "title": "Sources of performance variability in deep learning-based polyp  detection",
    "abstract": "Validation metrics are a key prerequisite for the reliable tracking of\nscientific progress and for deciding on the potential clinical translation of\nmethods. While recent initiatives aim to develop comprehensive theoretical\nframeworks for understanding metric-related pitfalls in image analysis\nproblems, there is a lack of experimental evidence on the concrete effects of\ncommon and rare pitfalls on specific applications. We address this gap in the\nliterature in the context of colon cancer screening. Our contribution is\ntwofold. Firstly, we present the winning solution of the Endoscopy computer\nvision challenge (EndoCV) on colon cancer detection, conducted in conjunction\nwith the IEEE International Symposium on Biomedical Imaging (ISBI) 2022.\nSecondly, we demonstrate the sensitivity of commonly used metrics to a range of\nhyperparameters as well as the consequences of poor metric choices. Based on\ncomprehensive validation studies performed with patient data from six clinical\ncenters, we found all commonly applied object detection metrics to be subject\nto high inter-center variability. Furthermore, our results clearly demonstrate\nthat the adaptation of standard hyperparameters used in the computer vision\ncommunity does not generally lead to the clinically most plausible results.\nFinally, we present localization criteria that correspond well to clinical\nrelevance. Our work could be a first step towards reconsidering common\nvalidation strategies in automatic colon cancer screening applications.",
    "descriptor": "\nComments: 12 pages, 9 figures, 3 tables. Submitted to IPCAI 2023\n",
    "authors": [
      "Thuy Nuong Tran",
      "Tim Adler",
      "Amine Yamlahi",
      "Evangelia Christodoulou",
      "Patrick Godau",
      "Annika Reinke",
      "Minu Dietlinde Tizabi",
      "Peter Sauer",
      "Tillmann Persicke",
      "J\u00f6rg Gerhard Albert",
      "Lena Maier-Hein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09708"
  },
  {
    "id": "arXiv:2211.09710",
    "title": "Style Classification of Rabbinic Literature for Detection of Lost  Midrash Tanhuma Material",
    "abstract": "Midrash collections are complex rabbinic works that consist of text in\nmultiple languages, which evolved through long processes of unstable oral and\nwritten transmission. Determining the origin of a given passage in such a\ncompilation is not always straightforward and is often a matter of dispute\namong scholars, yet it is essential for scholars' understanding of the passage\nand its relationship to other texts in the rabbinic corpus.\nTo help solve this problem, we propose a system for classification of\nrabbinic literature based on its style, leveraging recently released pretrained\nTransformer models for Hebrew. Additionally, we demonstrate how our method can\nbe applied to uncover lost material from Midrash Tanhuma.",
    "descriptor": "",
    "authors": [
      "Shlomo Tannor",
      "Nachum Dershowitz",
      "Moshe Lavee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09710"
  },
  {
    "id": "arXiv:2211.09711",
    "title": "Design Considerations For Hypothesis Rejection Modules In Spoken  Language Understanding Systems",
    "abstract": "Spoken Language Understanding (SLU) systems typically consist of a set of\nmachine learning models that operate in conjunction to produce an SLU\nhypothesis. The generated hypothesis is then sent to downstream components for\nfurther action. However, it is desirable to discard an incorrect hypothesis\nbefore sending it downstream. In this work, we present two designs for SLU\nhypothesis rejection modules: (i) scheme R1 that performs rejection on domain\nspecific SLU hypothesis and, (ii) scheme R2 that performs rejection on\nhypothesis generated from the overall SLU system. Hypothesis rejection modules\nin both schemes reject/accept a hypothesis based on features drawn from the\nutterance directed to the SLU system, the associated SLU hypothesis and SLU\nconfidence score. Our experiments suggest that both the schemes yield similar\nresults (scheme R1: 2.5% FRR @ 4.5% FAR, scheme R2: 2.5% FRR @ 4.6% FAR), with\nthe best performing systems using all the available features. We argue that\nwhile either of the rejection schemes can be chosen over the other, they carry\nsome inherent differences which need to be considered while making this choice.\nAdditionally, we incorporate ASR features in the rejection module (obtaining an\n1.9% FRR @ 3.8% FAR) and analyze the improvements.",
    "descriptor": "\nComments: 5 pages. ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\n",
    "authors": [
      "Aman Alok",
      "Rahul Gupta",
      "Shankar Ananthakrishnan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.09711"
  },
  {
    "id": "arXiv:2211.09712",
    "title": "SigT: An Efficient End-to-End MIMO-OFDM Receiver Framework Based on  Transformer",
    "abstract": "Multiple-input multiple-output and orthogonal frequency-division multiplexing\n(MIMO-OFDM) are the key technologies in 4G and subsequent wireless\ncommunication systems. Conventionally, the MIMO-OFDM receiver is performed by\nmultiple cascaded blocks with different functions and the algorithm in each\nblock is designed based on ideal assumptions of wireless channel distributions.\nHowever, these assumptions may fail in practical complex wireless environments.\nThe deep learning (DL) method has the ability to capture key features from\ncomplex and huge data. In this paper, a novel end-to-end MIMO-OFDM receiver\nframework based on \\textit{transformer}, named SigT, is proposed. By regarding\nthe signal received from each antenna as a token of the transformer, the\nspatial correlation of different antennas can be learned and the critical\nzero-shot problem can be mitigated. Furthermore, the proposed SigT framework\ncan work well without the inserted pilots, which improves the useful data\ntransmission efficiency. Experiment results show that SigT achieves much higher\nperformance in terms of signal recovery accuracy than benchmark methods, even\nin a low SNR environment or with a small number of training samples. Code is\navailable at https://github.com/SigTransformer/SigT.",
    "descriptor": "",
    "authors": [
      "Ziyou Ren",
      "Nan Cheng",
      "Ruijin Sun",
      "Xiucheng Wang",
      "Ning Lu",
      "Wenchao Xu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.09712"
  },
  {
    "id": "arXiv:2211.09713",
    "title": "Deep Reinforcement Learning for Combined Coverage and Resource  Allocation in UAV-aided RAN-slicing",
    "abstract": "Network slicing is a well assessed approach enabling virtualization of the\nmobile core and radio access network (RAN) in the emerging 5th Generation New\nRadio. Slicing is of paramount importance when dealing with the emerging and\ndiverse vertical applications entailing heterogeneous sets of requirements. 5G\nis also envisioning Unmanned Aerial Vehicles (UAVs) to be a key element in the\ncellular network standard, aiming at their use as aerial base stations and\nexploiting their flexible and quick deployment to enhance the wireless network\nperformance. This work presents a UAV-assisted 5G network, where the aerial\nbase stations (UAV-BS) are empowered with network slicing capabilities aiming\nat optimizing the Service Level Agreement (SLA) satisfaction ratio of a set of\nusers. The users belong to three heterogeneous categories of 5G service type,\nnamely, enhanced mobile broadband (eMBB), ultra-reliable low-latency\ncommunication (URLLC), and massive machine-type communication (mMTC). A first\napplication of multi-agent and multi-decision deep reinforcement learning for\nUAV-BS in a network slicing context is introduced, aiming at the optimization\nof the SLA satisfaction ratio of users through the joint allocation of radio\nresources to slices and refinement of the UAV-BSs 2-dimensional trajectories.\nThe performance of the presented strategy have been tested and compared to\nbenchmark heuristics, highlighting a higher percentage of satisfied users (at\nleast 27% more) in a variety of scenarios.",
    "descriptor": "\nComments: 6 pages, 4 figures, submitted to IEEE ICC'23 - SAC-08 MLCN Track\n",
    "authors": [
      "Lorenzo Bellone",
      "Boris Galkin",
      "Emiliano Traversi",
      "Enrico Natalizio"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09713"
  },
  {
    "id": "arXiv:2211.09716",
    "title": "A Flexible MATLAB/Simulink Simulator for Robotic Floating-base Systems  in Contact with the Ground",
    "abstract": "Physics simulators are widely used in robotics fields, from mechanical design\nto dynamic simulation, and controller design. This paper presents an\nopen-source MATLAB/Simulink simulator for rigid-body articulated systems,\nincluding manipulators and floating-base robots. Thanks to MATLAB/Simulink\nfeatures like MATLAB system classes and Simulink function blocks, the presented\nsimulator combines a programmatic and block-based approach, resulting in a\nflexible design in the sense that different parts, including its physics\nengine, robot-ground interaction model, and state evolution algorithm are\nsimply accessible and editable. Moreover, through the use of Simulink dynamic\nmask blocks, the proposed simulation framework supports robot models\nintegrating open-chain and closed-chain kinematics with any desired number of\nlinks interacting with the ground. The simulator can also integrate\nsecond-order actuator dynamics. Furthermore, the simulator benefits from a\none-line installation and an easy-to-use Simulink interface.",
    "descriptor": "\nComments: To be published in IEEE-IRC 2022 proceedings, 5 pages with 6 figures, equal contribution by authors Nuno Guedelha and Venus Pasandi\n",
    "authors": [
      "Nuno Guedelha",
      "Venus Pasandi",
      "Giuseppe L'Erario",
      "Silvio Traversaro",
      "Daniele Pucci"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.09716"
  },
  {
    "id": "arXiv:2211.09717",
    "title": "UPTON: Unattributable Authorship Text via Data Poisoning",
    "abstract": "In online medium such as opinion column in Bloomberg, The Guardian and\nWestern Journal, aspiring writers post their writings for various reasons with\ntheir names often proudly open. However, it may occur that such a writer wants\nto write in other venues anonymously or under a pseudonym (e.g., activist,\nwhistle-blower). However, if an attacker has already built an accurate\nauthorship attribution (AA) model based off of the writings from such\nplatforms, attributing an anonymous writing to the known authorship is\npossible. Therefore, in this work, we ask a question \"can one make the writings\nand texts, T, in the open spaces such as opinion sharing platforms\nunattributable so that AA models trained from T cannot attribute authorship\nwell?\" Toward this question, we present a novel solution, UPTON, that exploits\ntextual data poisoning method to disturb the training process of AA models.\nUPTON uses data poisoning to destroy the authorship feature only in training\nsamples by perturbing them, and try to make released textual data unlearnable\non deep neuron networks. It is different from previous obfuscation works, that\nuse adversarial attack to modify the test samples and mislead an AA model, and\nalso the backdoor works, which use trigger words both in test and training\nsamples and only change the model output when trigger words occur. Using four\nauthorship datasets (e.g., IMDb10, IMDb64, Enron and WJO), then, we present\nempirical validation where: (1)UPTON is able to downgrade the test accuracy to\nabout 30% with carefully designed target-selection methods. (2)UPTON poisoning\nis able to preserve most of the original semantics. The BERTSCORE between the\nclean and UPTON poisoned texts are higher than 0.95. The number is very closed\nto 1.00, which means no sematic change. (3)UPTON is also robust towards\nspelling correction systems.",
    "descriptor": "",
    "authors": [
      "Ziyao Wang",
      "Thai Le",
      "Dongwon Lee"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.09717"
  },
  {
    "id": "arXiv:2211.09718",
    "title": "Numerical Optimizations for Weighted Low-rank Estimation on Language  Model",
    "abstract": "Singular value decomposition (SVD) is one of the most popular compression\nmethods that approximate a target matrix with smaller matrices. However,\nstandard SVD treats the parameters within the matrix with equal importance,\nwhich is a simple but unrealistic assumption. The parameters of a trained\nneural network model may affect task performance unevenly, which suggests\nnon-equal importance among the parameters. Compared to SVD, the decomposition\nmethod aware of parameter importance is the more practical choice in real\ncases. Unlike standard SVD, weighted value decomposition is a non-convex\noptimization problem that lacks a closed-form solution. We systematically\ninvestigated multiple optimization strategies to tackle the problem and\nexamined our method by compressing Transformer-based language models. Further,\nwe designed a metric to predict when the SVD may introduce a significant\nperformance drop, for which our method can be a rescue strategy. The extensive\nevaluations demonstrate that our method can perform better than current SOTA\nmethods in compressing Transformer-based language models.",
    "descriptor": "\nComments: long paper EMNLP 2022\n",
    "authors": [
      "Ting Hua",
      "Yen-Chang Hsu",
      "Felicity Wang",
      "Qian Lou",
      "Yilin Shen",
      "Hongxia Jin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09718"
  },
  {
    "id": "arXiv:2211.09719",
    "title": "Learning Adaptive Evolutionary Computation for Solving Multi-Objective  Optimization Problems",
    "abstract": "Multi-objective evolutionary algorithms (MOEAs) are widely used to solve\nmulti-objective optimization problems. The algorithms rely on setting\nappropriate parameters to find good solutions. However, this parameter tuning\ncould be very computationally expensive in solving non-trial (combinatorial)\noptimization problems. This paper proposes a framework that integrates MOEAs\nwith adaptive parameter control using Deep Reinforcement Learning (DRL). The\nDRL policy is trained to adaptively set the values that dictate the intensity\nand probability of mutation for solutions during optimization. We test the\nproposed approach with a simple benchmark problem and a real-world, complex\nwarehouse design and control problem. The experimental results demonstrate the\nadvantages of our method in terms of solution quality and computation time to\nreach good solutions. In addition, we show the learned policy is transferable,\ni.e., the policy trained on a simple benchmark problem can be directly applied\nto solve the complex warehouse optimization problem, effectively, without the\nneed for retraining.",
    "descriptor": "",
    "authors": [
      "Remco Coppens",
      "Robbert Reijnen",
      "Yingqian Zhang",
      "Laurens Bliek",
      "Berend Steenhuisen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09719"
  },
  {
    "id": "arXiv:2211.09721",
    "title": "A Finite-Particle Convergence Rate for Stein Variational Gradient  Descent",
    "abstract": "We provide a first finite-particle convergence rate for Stein variational\ngradient descent (SVGD). Specifically, whenever the target distribution\nsatisfies Talagrand's T1 inequality, SVGD with n particles and an appropriate\nstep size sequence drives the kernel Stein discrepancy to zero at an order\n1/sqrt(log log n) rate. We suspect that the dependence on n can be improved,\nand we hope that our explicit, non-asymptotic proof strategy will serve as a\ntemplate for future refinements.",
    "descriptor": "",
    "authors": [
      "Jiaxin Shi",
      "Lester Mackey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.09721"
  },
  {
    "id": "arXiv:2211.09722",
    "title": "Federated Multilingual Models for Medical Transcript Analysis",
    "abstract": "Federated Learning (FL) is a novel machine learning approach that allows the\nmodel trainer to access more data samples, by training the model across\nmultiple decentralized data sources, while data access constraints are in\nplace. Such trained models can achieve significantly higher performance beyond\nwhat can be done when trained on a single data source. As part of FL's\npromises, none of the training data is ever transmitted to any central\nlocation, ensuring that sensitive data remains local and private. These\ncharacteristics make FL perfectly suited for large-scale applications in\nhealthcare, where a variety of compliance constraints restrict how data may be\nhandled, processed, and stored. Despite the apparent benefits of federated\nlearning, the heterogeneity in the local data distributions pose significant\nchallenges, and such challenges are even more pronounced in the case of\nmultilingual data providers. In this paper we present a federated learning\nsystem for training a large-scale multi-lingual model suitable for fine-tuning\non downstream tasks such as medical entity tagging. Our work represents one of\nthe first such production-scale systems, capable of training across multiple\nhighly heterogeneous data providers, and achieving levels of accuracy that\ncould not be otherwise achieved by using central training with public data.\nFinally, we show that the global model performance can be further improved by a\ntraining step performed locally.",
    "descriptor": "",
    "authors": [
      "Andre Manoel",
      "Mirian Hipolito Garcia",
      "Tal Baumel",
      "Shize Su",
      "Jialei Chen",
      "Dan Miller",
      "Danny Karmon",
      "Robert Sim",
      "Dimitrios Dimitriadis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09722"
  },
  {
    "id": "arXiv:2211.09723",
    "title": "Fair and Efficient Distributed Edge Learning with Hybrid Multipath TCP",
    "abstract": "The bottleneck of distributed edge learning (DEL) over wireless has shifted\nfrom computing to communication, primarily the aggregation-averaging (Agg-Avg)\nprocess of DEL. The existing transmission control protocol (TCP)-based data\nnetworking schemes for DEL are application-agnostic and fail to deliver\nadjustments according to application layer requirements. As a result, they\nintroduce massive excess time and undesired issues such as unfairness and\nstragglers. Other prior mitigation solutions have significant limitations as\nthey balance data flow rates from workers across paths but often incur\nimbalanced backlogs when the paths exhibit variance, causing stragglers. To\nfacilitate a more productive DEL, we develop a hybrid multipath TCP (MPTCP) by\ncombining model-based and deep reinforcement learning (DRL) based MPTCP for DEL\nthat strives to realize quicker iteration of DEL and better fairness (by\nameliorating stragglers). Hybrid MPTCP essentially integrates two radical TCP\ndevelopments: i) successful existing model-based MPTCP control strategies and\nii) advanced emerging DRL-based techniques, and introduces a novel hybrid MPTCP\ndata transport for easing the communication of the Agg-Avg process. Extensive\nemulation results demonstrate that the proposed hybrid MPTCP can overcome\nexcess time consumption and ameliorate the application layer unfairness of DEL\neffectively without injecting additional inconstancy and stragglers.",
    "descriptor": "\nComments: 13 pages, 15 figures\n",
    "authors": [
      "Shiva Raj Pokhrel",
      "Jinho Choi",
      "Anwar Walid"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.09723"
  },
  {
    "id": "arXiv:2211.09726",
    "title": "Deep Reinforcement Learning for IRS Phase Shift Design in  Spatiotemporally Correlated Environments",
    "abstract": "The paper studies the problem of designing the Intelligent Reflecting Surface\n(IRS) phase shifters for Multiple Input Single Output (MISO) communication\nsystems in spatiotemporally correlated channel environments, where the\ndestination can move within a confined area. The objective is to maximize the\nexpected sum of SNRs at the receiver over infinite time horizons. The problem\nformulation gives rise to a Markov Decision Process (MDP). We propose a deep\nactor-critic algorithm that accounts for channel correlations and destination\nmotion by constructing the state representation to include the current position\nof the receiver and the phase shift values and receiver positions that\ncorrespond to a window of previous time steps. The channel variability induces\nhigh frequency components on the spectrum of the underlying value function. We\npropose the preprocessing of the critic's input with a Fourier kernel which\nenables stable value learning. Finally, we investigate the use of the\ndestination SNR as a component of the designed MDP state, which is common\npractice in previous work. We provide empirical evidence that, when the\nchannels are spatiotemporally correlated, the inclusion of the SNR in the state\nrepresentation interacts with function approximation in ways that inhibit\nconvergence.",
    "descriptor": "",
    "authors": [
      "Spilios Evmorfos",
      "Athina P. Petropulu",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.09726"
  },
  {
    "id": "arXiv:2211.09728",
    "title": "Generative Adversarial Training Can Improve Neural Language Models",
    "abstract": "While deep learning in the form of recurrent neural networks (RNNs) has\ncaused a significant improvement in neural language modeling, the fact that\nthey are extremely prone to overfitting is still a mainly unresolved issue. In\nthis paper we propose a regularization method based on generative adversarial\nnetworks (GANs) and adversarial training (AT), that can prevent overfitting in\nneural language models. Unlike common adversarial training methods such as the\nfast gradient sign method (FGSM) that require a second back-propagation through\ntime, and therefore effectively require at least twice the amount of time for\nregular training, the overhead of our method does not exceed more than 20% of\nthe training of the baselines.",
    "descriptor": "\nComments: An extended abstract selected for poster presentation at the Eastern European Machine Learning Summer School 2019\n",
    "authors": [
      "Sajad Movahedi",
      "Azadeh Shakery"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09728"
  },
  {
    "id": "arXiv:2211.09729",
    "title": "Rounding via Low Dimensional Embeddings",
    "abstract": "A regular graph $G = (V,E)$ is an $(\\varepsilon,\\gamma)$ small-set expander\nif for any set of vertices of fractional size at most $\\varepsilon$, at least\n$\\gamma$ of the edges that are adjacent to it go outside. In this paper, we\ngive a unified approach to several known complexity-theoretic results on\nsmall-set expanders. In particular, we show:\n1. Max-Cut: we show that if a regular graph $G = (V,E)$ is an\n$(\\varepsilon,\\gamma)$ small-set expander that contains a cut of fractional\nsize at least $1-\\delta$, then one can find in $G$ a cut of fractional size at\nleast $1-O\\left(\\frac{\\delta}{\\varepsilon\\gamma^6}\\right)$ in polynomial time.\n2. Improved spectral partitioning, Cheeger's inequality and the parallel\nrepetition theorem over small-set expanders. The general form of each one of\nthese results involves square-root loss that comes from certain rounding\nprocedure, and we show how this can be avoided over small set expanders.\nOur main idea is to project a high dimensional vector solution into a\nlow-dimensional space while roughly maintaining $\\ell_2^2$ distances, and then\nperform a pre-processing step using low-dimensional geometry and the properties\nof $\\ell_2^2$ distances over it. This pre-processing leverages the small-set\nexpansion property of the graph to transform a vector valued solution to a\ndifferent vector valued solution with additional structural properties, which\ngive rise to more efficient integral-solution rounding schemes.",
    "descriptor": "",
    "authors": [
      "Mark Braverman",
      "Dor Minzer"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.09729"
  },
  {
    "id": "arXiv:2211.09731",
    "title": "Stutter-TTS: Controlled Synthesis and Improved Recognition of Stuttered  Speech",
    "abstract": "Stuttering is a speech disorder where the natural flow of speech is\ninterrupted by blocks, repetitions or prolongations of syllables, words and\nphrases. The majority of existing automatic speech recognition (ASR) interfaces\nperform poorly on utterances with stutter, mainly due to lack of matched\ntraining data. Synthesis of speech with stutter thus presents an opportunity to\nimprove ASR for this type of speech. We describe Stutter-TTS, an end-to-end\nneural text-to-speech model capable of synthesizing diverse types of stuttering\nutterances. We develop a simple, yet effective prosody-control strategy whereby\nadditional tokens are introduced into source text during training to represent\nspecific stuttering characteristics. By choosing the position of the stutter\ntokens, Stutter-TTS allows word-level control of where stuttering occurs in the\nsynthesized utterance. We are able to synthesize stutter events with high\naccuracy (F1-scores between 0.63 and 0.84, depending on stutter type). By\nfine-tuning an ASR model on synthetic stuttered speech we are able to reduce\nword error by 5.7% relative on stuttered utterances, with only minor (<0.2%\nrelative) degradation for fluent utterances.",
    "descriptor": "\nComments: 8 pages, 3 figures, 2 tables\n",
    "authors": [
      "Xin Zhang",
      "Iv\u00e1n Vall\u00e9s-P\u00e9rez",
      "Andreas Stolcke",
      "Chengzhu Yu",
      "Jasha Droppo",
      "Olabanji Shonibare",
      "Roberto Barra-Chicote",
      "Venkatesh Ravichandran"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.09731"
  },
  {
    "id": "arXiv:2211.09732",
    "title": "Extending Logic Explained Networks to Text Classification",
    "abstract": "Recently, Logic Explained Networks (LENs) have been proposed as\nexplainable-by-design neural models providing logic explanations for their\npredictions. However, these models have only been applied to vision and tabular\ndata, and they mostly favour the generation of global explanations, while local\nones tend to be noisy and verbose. For these reasons, we propose LENp,\nimproving local explanations by perturbing input words, and we test it on text\nclassification. Our results show that (i) LENp provides better local\nexplanations than LIME in terms of sensitivity and faithfulness, and (ii) logic\nexplanations are more useful and user-friendly than feature scoring provided by\nLIME as attested by a human survey.",
    "descriptor": "\nComments: Accepted as short paper at the EMNLP 2022 conference\n",
    "authors": [
      "Rishabh Jain",
      "Gabriele Ciravegna",
      "Pietro Barbiero",
      "Francesco Giannini",
      "Davide Buffelli",
      "Pietro Lio"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.09732"
  },
  {
    "id": "arXiv:2211.09733",
    "title": "BERT-Deep CNN: State-of-the-Art for Sentiment Analysis of COVID-19  Tweets",
    "abstract": "The free flow of information has been accelerated by the rapid development of\nsocial media technology. There has been a significant social and psychological\nimpact on the population due to the outbreak of Coronavirus disease (COVID-19).\nThe COVID-19 pandemic is one of the current events being discussed on social\nmedia platforms. In order to safeguard societies from this pandemic, studying\npeople's emotions on social media is crucial. As a result of their particular\ncharacteristics, sentiment analysis of texts like tweets remains challenging.\nSentiment analysis is a powerful text analysis tool. It automatically detects\nand analyzes opinions and emotions from unstructured data. Texts from a wide\nrange of sources are examined by a sentiment analysis tool, which extracts\nmeaning from them, including emails, surveys, reviews, social media posts, and\nweb articles. To evaluate sentiments, natural language processing (NLP) and\nmachine learning techniques are used, which assign weights to entities, topics,\nthemes, and categories in sentences or phrases. Machine learning tools learn\nhow to detect sentiment without human intervention by examining examples of\nemotions in text. In a pandemic situation, analyzing social media texts to\nuncover sentimental trends can be very helpful in gaining a better\nunderstanding of society's needs and predicting future trends. We intend to\nstudy society's perception of the COVID-19 pandemic through social media using\nstate-of-the-art BERT and Deep CNN models. The superiority of BERT models over\nother deep models in sentiment analysis is evident and can be concluded from\nthe comparison of the various research studies mentioned in this article.",
    "descriptor": "\nComments: 19 pages, 5 figures\n",
    "authors": [
      "Javad Hassannataj Joloudari",
      "Sadiq Hussain",
      "Mohammad Ali Nematollahi",
      "Rouhollah Bagheri",
      "Fatemeh Fazl",
      "Roohallah Alizadehsani",
      "Reza Lashgari"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.09733"
  },
  {
    "id": "arXiv:2211.09740",
    "title": "Sub-Graph Learning for Spatiotemporal Forecasting via Knowledge  Distillation",
    "abstract": "One of the challenges in studying the interactions in large graphs is to\nlearn their diverse pattern and various interaction types. Hence, considering\nonly one distribution and model to study all nodes and ignoring their diversity\nand local features in their neighborhoods, might severely affect the overall\nperformance. Based on the structural information of the nodes in the graph and\nthe interactions between them, the main graph can be divided into multiple\nsub-graphs. This graph partitioning can tremendously affect the learning\nprocess, however the overall performance is highly dependent on the clustering\nmethod to avoid misleading the model. In this work, we present a new framework\ncalled KD-SGL to effectively learn the sub-graphs, where we define one global\nmodel to learn the overall structure of the graph and multiple local models for\neach sub-graph. We assess the performance of the proposed framework and\nevaluate it on public datasets. Based on the achieved results, it can improve\nthe performance of the state-of-the-arts spatiotemporal models with comparable\nresults compared to ensemble of models with less complexity.",
    "descriptor": "",
    "authors": [
      "Mehrtash Mehrabi",
      "Yingxue Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09740"
  },
  {
    "id": "arXiv:2211.09741",
    "title": "Learning 4DVAR inversion directly from observations",
    "abstract": "Variational data assimilation and deep learning share many algorithmic\naspects in common. While the former focuses on system state estimation, the\nlatter provides great inductive biases to learn complex relationships. We here\ndesign a hybrid architecture learning the assimilation task directly from\npartial and noisy observations, using the mechanistic constraint of the 4DVAR\nalgorithm. Finally, we show in an experiment that the proposed method was able\nto learn the desired inversion with interesting regularizing properties and\nthat it also has computational interests.",
    "descriptor": "\nComments: submitted to ICASSP 2023\n",
    "authors": [
      "Arthur Filoche",
      "Julien Brajard",
      "Anastase Charantonis",
      "Dominique B\u00e9r\u00e9ziat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09741"
  },
  {
    "id": "arXiv:2211.09744",
    "title": "Zero-Shot Dynamic Quantization for Transformer Inference",
    "abstract": "We introduce a novel run-time method for significantly reducing the accuracy\nloss associated with quantizing BERT-like models to 8-bit integers. Existing\nmethods for quantizing models either modify the training procedure,or they\nrequire an additional calibration step to adjust parameters that also requires\na selected held-out dataset. Our method permits taking advantage of\nquantization without the need for these adjustments. We present results on\nseveral NLP tasks demonstrating the usefulness of this technique.",
    "descriptor": "\nComments: To appear in EMNLP 2022 industry track\n",
    "authors": [
      "Yousef El-Kurdi",
      "Jerry Quinn",
      "Avirup Sil"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.09744"
  },
  {
    "id": "arXiv:2211.09747",
    "title": "Extensions of the $(p,q)$-Flexible-Graph-Connectivity model",
    "abstract": "We present approximation algorithms for network design problems in some\nmodels related to the $(p,q)$-FGC model. Adjiashvili, Hommelsheim and\nM\\\"uhlenthaler introduced the model of Flexible Graph Connectivity that we\ndenote by FGC. Boyd, Cheriyan, Haddadan and Ibrahimpur introduced a\ngeneralization of FGC. Let $p\\geq 1$ and $q\\geq 0$ be integers. In an instance\nof the $(p,q)$-Flexible Graph Connectivity problem, denoted $(p,q)$-FGC, we\nhave an undirected connected graph $G = (V,E)$, a partition of $E$ into a set\nof safe edges and a set of unsafe edges, and nonnegative costs\n$c\\in\\mathbb{R}_{\\geq0}^E$ on the edges. A subset $F \\subseteq E$ of edges is\nfeasible for the $(p,q)$-FGC problem if for any set of unsafe edges, $F'$, with\n$|F'|\\leq q$, the subgraph $(V, F \\setminus F')$ is $p$-edge connected. The\nalgorithmic goal is to find a feasible edge-set $F$ that minimizes $c(F) =\n\\sum_{e \\in F} c_e$.",
    "descriptor": "",
    "authors": [
      "Ishan Bansal",
      "Joseph Cheriyan",
      "Logan Grout",
      "Sharat Ibrahimpur"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.09747"
  },
  {
    "id": "arXiv:2211.09748",
    "title": "Probing for Incremental Parse States in Autoregressive Language Models",
    "abstract": "Next-word predictions from autoregressive neural language models show\nremarkable sensitivity to syntax. This work evaluates the extent to which this\nbehavior arises as a result of a learned ability to maintain implicit\nrepresentations of incremental syntactic structures. We extend work in\nsyntactic probing to the incremental setting and present several probes for\nextracting incomplete syntactic structure (operationalized through parse states\nfrom a stack-based parser) from autoregressive language models. We find that\nour probes can be used to predict model preferences on ambiguous sentence\nprefixes and causally intervene on model representations and steer model\nbehavior. This suggests implicit incremental syntactic inferences underlie\nnext-word predictions in autoregressive neural language models.",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Tiwalayo Eisape",
      "Vineet Gangireddy",
      "Roger P. Levy",
      "Yoon Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09748"
  },
  {
    "id": "arXiv:2211.09751",
    "title": "Heart Abnormality Detection from Heart Sound Signals using MFCC Feature  and Dual Stream Attention Based Network",
    "abstract": "Cardiovascular diseases are one of the leading cause of death in today's\nworld and early screening of heart condition plays a crucial role in preventing\nthem. The heart sound signal is one of the primary indicator of heart condition\nand can be used to detect abnormality in the heart. The acquisition of heart\nsound signal is non-invasive, cost effective and requires minimum equipment.\nBut currently the detection of heart abnormality from heart sound signal\ndepends largely on the expertise and experience of the physician. As such an\nautomatic detection system for heart abnormality detection from heart sound\nsignal can be a great asset for the people living in underdeveloped areas. In\nthis paper we propose a novel deep learning based dual stream network with\nattention mechanism that uses both the raw heart sound signal and the MFCC\nfeatures to detect abnormality in heart condition of a patient. The deep neural\nnetwork has a convolutional stream that uses the raw heart sound signal and a\nrecurrent stream that uses the MFCC features of the signal. The features from\nthese two streams are merged together using a novel attention network and\npassed through the classification network. The model is trained on the largest\npublicly available dataset of PCG signal and achieves an accuracy of 87.11,\nsensitivity of 82.41, specificty of 91.8 and a MACC of 87.12.",
    "descriptor": "",
    "authors": [
      "Nayeeb Rashid",
      "Swapnil Saha",
      "Mohseu Rashid Subah",
      "Rizwan Ahmed Robin",
      "Syed Mortuza Hasan Fahim",
      "Shahed Ahmed",
      "Talha Ibn Mahmud"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)",
      "Medical Physics (physics.med-ph)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.09751"
  },
  {
    "id": "arXiv:2211.09752",
    "title": "Learning to Counterfactually Explain Recommendations",
    "abstract": "Recommender system practitioners are facing increasing pressure to explain\nrecommendations. We explore how to explain recommendations using counterfactual\nlogic, i.e. \"Had you not interacted with the following items before, it is\nlikely we would not recommend this item.\" Compared to traditional explanation\nlogic, counterfactual explanations are easier to understand and more\ntechnically verifiable. The major challenge of generating such explanations is\nthe computational cost because it requires repeatedly retraining the models to\nobtain the effect on a recommendation caused by removing user (interaction)\nhistory. We propose a learning-based framework to generate counterfactual\nexplanations. The key idea is to train a surrogate model to learn the effect of\nremoving a subset of user history on the recommendation. To this end, we first\nartificially simulate the counterfactual outcomes on the recommendation after\ndeleting subsets of history. Then we train surrogate models to learn the\nmapping between a history deletion and the change in the recommendation caused\nby the deletion. Finally, to generate an explanation, we find the history\nsubset predicted by the surrogate model that is most likely to remove the\nrecommendation. Through offline experiments and online user studies, we show\nour method, compared to baselines, can generate explanations that are more\ncounterfactually valid and more satisfactory considered by users.",
    "descriptor": "",
    "authors": [
      "Yuanshun Yao",
      "Chong Wang",
      "Hang Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.09752"
  },
  {
    "id": "arXiv:2211.09760",
    "title": "VeLO: Training Versatile Learned Optimizers by Scaling Up",
    "abstract": "While deep learning models have replaced hand-designed features across many\ndomains, these models are still trained with hand-designed optimizers. In this\nwork, we leverage the same scaling approach behind the success of deep learning\nto learn versatile optimizers. We train an optimizer for deep learning which is\nitself a small neural network that ingests gradients and outputs parameter\nupdates. Meta-trained with approximately four thousand TPU-months of compute on\na wide variety of optimization tasks, our optimizer not only exhibits\ncompelling performance, but optimizes in interesting and unexpected ways. It\nrequires no hyperparameter tuning, instead automatically adapting to the\nspecifics of the problem being optimized. We open source our learned optimizer,\nmeta-training code, the associated train and test data, and an extensive\noptimizer benchmark suite with baselines at velo-code.github.io.",
    "descriptor": "",
    "authors": [
      "Luke Metz",
      "James Harrison",
      "C. Daniel Freeman",
      "Amil Merchant",
      "Lucas Beyer",
      "James Bradbury",
      "Naman Agrawal",
      "Ben Poole",
      "Igor Mordatch",
      "Adam Roberts",
      "Jascha Sohl-Dickstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.09760"
  },
  {
    "id": "arXiv:2211.09761",
    "title": "Efficient Transformers with Dynamic Token Pooling",
    "abstract": "Transformers achieve unrivalled performance in modelling language, but remain\ninefficient in terms of memory and time complexity. A possible remedy is to\nreduce the sequence length in the intermediate layers by pooling fixed-length\nsegments of tokens. Nevertheless, natural units of meaning, such as words or\nphrases, display varying sizes. To address this mismatch, we equip language\nmodels with a dynamic-pooling mechanism, which predicts segment boundaries in\nan autoregressive fashion. We compare several methods to infer boundaries,\nincluding end-to-end learning through stochastic re-parameterisation,\nsupervised learning (based on segmentations from subword tokenizers or spikes\nin conditional entropy), as well as linguistically motivated boundaries. We\nperform character-level evaluation on texts from multiple datasets and\nmorphologically diverse languages. The results demonstrate that dynamic\npooling, which jointly segments and models language, is often both faster and\nmore accurate than vanilla Transformers and fixed-length pooling within the\nsame computational budget.",
    "descriptor": "",
    "authors": [
      "Piotr Nawrot",
      "Jan Chorowski",
      "Adrian \u0141a\u0144cucki",
      "Edoardo M. Ponti"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.09761"
  },
  {
    "id": "arXiv:2211.09768",
    "title": "D$^3$ETR: Decoder Distillation for Detection Transformer",
    "abstract": "While various knowledge distillation (KD) methods in CNN-based detectors show\ntheir effectiveness in improving small students, the baselines and recipes for\nDETR-based detectors are yet to be built. In this paper, we focus on the\ntransformer decoder of DETR-based detectors and explore KD methods for them.\nThe outputs of the transformer decoder lie in random order, which gives no\ndirect correspondence between the predictions of the teacher and the student,\nthus posing a challenge for knowledge distillation. To this end, we propose\nMixMatcher to align the decoder outputs of DETR-based teachers and students,\nwhich mixes two teacher-student matching strategies, i.e., Adaptive Matching\nand Fixed Matching. Specifically, Adaptive Matching applies bipartite matching\nto adaptively match the outputs of the teacher and the student in each decoder\nlayer, while Fixed Matching fixes the correspondence between the outputs of the\nteacher and the student with the same object queries, with the teacher's fixed\nobject queries fed to the decoder of the student as an auxiliary group.\nBased on MixMatcher, we build \\textbf{D}ecoder \\textbf{D}istillation for\n\\textbf{DE}tection \\textbf{TR}ansformer (D$^3$ETR), which distills knowledge in\ndecoder predictions and attention maps from the teachers to students. D$^3$ETR\nshows superior performance on various DETR-based detectors with different\nbackbones. For example, D$^3$ETR improves Conditional DETR-R50-C5 by\n$\\textbf{7.8}/\\textbf{2.4}$ mAP under $12/50$ epochs training settings with\nConditional DETR-R101-C5 as the teacher.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Xiaokang Chen",
      "Jiahui Chen",
      "Yan Liu",
      "Gang Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09768"
  },
  {
    "id": "arXiv:2211.09770",
    "title": "3DLatNav: Navigating Generative Latent Spaces for Semantic-Aware 3D  Object Manipulation",
    "abstract": "3D generative models have been recently successful in generating realistic 3D\nobjects in the form of point clouds. However, most models do not offer\ncontrollability to manipulate the shape semantics of component object parts\nwithout extensive semantic attribute labels or other reference point clouds.\nMoreover, beyond the ability to perform simple latent vector arithmetic or\ninterpolations, there is a lack of understanding of how part-level semantics of\n3D shapes are encoded in their corresponding generative latent spaces. In this\npaper, we propose 3DLatNav; a novel approach to navigating pretrained\ngenerative latent spaces to enable controlled part-level semantic manipulation\nof 3D objects. First, we propose a part-level weakly-supervised shape semantics\nidentification mechanism using latent representations of 3D shapes. Then, we\ntransfer that knowledge to a pretrained 3D object generative latent space to\nunravel disentangled embeddings to represent different shape semantics of\ncomponent parts of an object in the form of linear subspaces, despite the\nunavailability of part-level labels during the training. Finally, we utilize\nthose identified subspaces to show that controllable 3D object part\nmanipulation can be achieved by applying the proposed framework to any\npretrained 3D generative model. With two novel quantitative metrics to evaluate\nthe consistency and localization accuracy of part-level manipulations, we show\nthat 3DLatNav outperforms existing unsupervised latent disentanglement methods\nin identifying latent directions that encode part-level shape semantics of 3D\nobjects. With multiple ablation studies and testing on state-of-the-art\ngenerative models, we show that 3DLatNav can implement controlled part-level\nsemantic manipulations on an input point cloud while preserving other features\nand the realistic nature of the object.",
    "descriptor": "",
    "authors": [
      "Amaya Dharmasiri",
      "Dinithi Dissanayake",
      "Mohamed Afham",
      "Isuru Dissanayake",
      "Ranga Rodrigo",
      "Kanchana Thilakarathna"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09770"
  },
  {
    "id": "arXiv:2211.09771",
    "title": "Boosting Object Representation Learning via Motion and Object Continuity",
    "abstract": "Recent unsupervised multi-object detection models have shown impressive\nperformance improvements, largely attributed to novel architectural inductive\nbiases. Unfortunately, they may produce suboptimal object encodings for\ndownstream tasks. To overcome this, we propose to exploit object motion and\ncontinuity, i.e., objects do not pop in and out of existence. This is\naccomplished through two mechanisms: (i) providing priors on the location of\nobjects through integration of optical flow, and (ii) a contrastive object\ncontinuity loss across consecutive image frames. Rather than developing an\nexplicit deep architecture, the resulting Motion and Object Continuity (MOC)\nscheme can be instantiated using any baseline object detection model. Our\nresults show large improvements in the performances of a SOTA model in terms of\nobject discovery, convergence speed and overall latent object representations,\nparticularly for playing Atari games. Overall, we show clear benefits of\nintegrating motion and object continuity for downstream tasks, moving beyond\nobject representation learning based only on reconstruction.",
    "descriptor": "\nComments: 8 pages main text, 32 tables, 21 Figures\n",
    "authors": [
      "Quentin Delfosse",
      "Wolfgang Stammer",
      "Thomas Rothenbacher",
      "Dwarak Vittal",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09771"
  },
  {
    "id": "arXiv:2211.09773",
    "title": "T-SEA: Transfer-based Self-Ensemble Attack on Object Detection",
    "abstract": "Compared to query-based black-box attacks, transfer-based black-box attacks\ndo not require any information of the attacked models, which ensures their\nsecrecy. However, most existing transfer-based approaches rely on ensembling\nmultiple models to boost the attack transferability, which is time- and\nresource-intensive, not to mention the difficulty of obtaining diverse models\non the same task. To address this limitation, in this work, we focus on the\nsingle-model transfer-based black-box attack on object detection, utilizing\nonly one model to achieve a high-transferability adversarial attack on multiple\nblack-box detectors. Specifically, we first make observations on the patch\noptimization process of the existing method and propose an enhanced attack\nframework by slightly adjusting its training strategies. Then, we analogize\npatch optimization with regular model optimization, proposing a series of\nself-ensemble approaches on the input data, the attacked model, and the\nadversarial patch to efficiently make use of the limited information and\nprevent the patch from overfitting. The experimental results show that the\nproposed framework can be applied with multiple classical base attack methods\n(e.g., PGD and MIM) to greatly improve the black-box transferability of the\nwell-optimized patch on multiple mainstream detectors, meanwhile boosting\nwhite-box performance. Our code is available at\nhttps://github.com/VDIGPKU/T-SEA.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Hao Huang",
      "Ziyan Chen",
      "Huanran Chen",
      "Yongtao Wang",
      "Kevin Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.09773"
  },
  {
    "id": "arXiv:2211.09776",
    "title": "Cheeger Inequalities for Directed Graphs and Hypergraphs Using  Reweighted Eigenvalues",
    "abstract": "We derive Cheeger inequalities for directed graphs and hypergraphs using the\nreweighted eigenvalue approach that was recently developed for vertex expansion\nin undirected graphs [OZ22,KLT22,JPV22]. The goal is to develop a new spectral\ntheory for directed graphs and an alternative spectral theory for hypergraphs.\nThe first main result is a Cheeger inequality relating the vertex expansion\n$\\vec{\\psi}(G)$ of a directed graph $G$ to the vertex-capacitated maximum\nreweighted second eigenvalue $\\vec{\\lambda}_2^{v*}$: \\[ \\vec{\\lambda}_2^{v*}\n\\lesssim \\vec{\\psi}(G) \\lesssim \\sqrt{\\vec{\\lambda}_2^{v*} \\cdot \\log\n(\\Delta/\\vec{\\lambda}_2^{v*})}. \\] This provides a combinatorial\ncharacterization of the fastest mixing time of a directed graph by vertex\nexpansion, and builds a new connection between reweighted eigenvalued, vertex\nexpansion, and fastest mixing time for directed graphs.\nThe second main result is a stronger Cheeger inequality relating the edge\nconductance $\\vec{\\phi}(G)$ of a directed graph $G$ to the edge-capacitated\nmaximum reweighted second eigenvalue $\\vec{\\lambda}_2^{e*}$: \\[\n\\vec{\\lambda}_2^{e*} \\lesssim \\vec{\\phi}(G) \\lesssim \\sqrt{\\vec{\\lambda}_2^{e*}\n\\cdot \\log (1/\\vec{\\lambda}_2^{e*})}. \\] This provides a certificate for a\ndirected graph to be an expander and a spectral algorithm to find a sparse cut\nin a directed graph, playing a similar role as Cheeger's inequality in\ncertifying graph expansion and in the spectral partitioning algorithm for\nundirected graphs.\nWe also use this reweighted eigenvalue approach to derive the improved\nCheeger inequality for directed graphs, and furthermore to derive several\nCheeger inequalities for hypergraphs that match and improve the existing\nresults in [Lou15,CLTZ18]. These are supporting results that this provides a\nunifying approach to lift the spectral theory for undirected graphs to more\ngeneral settings.",
    "descriptor": "\nComments: 51 pages, 3 figures\n",
    "authors": [
      "Lap Chi Lau",
      "Kam Chuen Tung",
      "Robert Wang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)",
      "Combinatorics (math.CO)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.09776"
  },
  {
    "id": "arXiv:2211.09778",
    "title": "I Can't Believe There's No Images! Learning Visual Tasks Using only  Language Data",
    "abstract": "Many high-level skills that are required for computer vision tasks, such as\nparsing questions, comparing and contrasting semantics, and writing\ndescriptions, are also required in other domains such as natural language\nprocessing. In this paper, we ask whether this makes it possible to learn those\nskills from text data and then use them to complete vision tasks without ever\ntraining on visual training data. Key to our approach is exploiting the joint\nembedding space of contrastively trained vision and language encoders. In\npractice, there can be systematic differences between embedding spaces for\ndifferent modalities in contrastive models, and we analyze how these\ndifferences affect our approach and study a variety of strategies to mitigate\nthis concern. We produce models using only text training data on three tasks:\nimage captioning, visual entailment and visual question answering, and evaluate\nthem on standard benchmarks using images. We find that this kind of transfer is\npossible and results in only a small drop in performance relative to models\ntrained on images. We also showcase a variety of stylistic image captioning\nmodels that were trained using no image data and no human-curated language\ndata, but instead text data from books, the web, or language models.",
    "descriptor": "",
    "authors": [
      "Sophia Gu",
      "Christopher Clark",
      "Aniruddha Kembhavi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09778"
  },
  {
    "id": "arXiv:2211.09782",
    "title": "Assessing Neural Network Robustness via Adversarial Pivotal Tuning",
    "abstract": "The ability to assess the robustness of image classifiers to a diverse set of\nmanipulations is essential to their deployment in the real world. Recently,\nsemantic manipulations of real images have been considered for this purpose, as\nthey may not arise using standard adversarial settings. However, such semantic\nmanipulations are often limited to style, color or attribute changes. While\nexpressive, these manipulations do not consider the full capacity of a\npretrained generator to affect adversarial image manipulations. In this work,\nwe aim at leveraging the full capacity of a pretrained image generator to\ngenerate highly detailed, diverse and photorealistic image manipulations.\nInspired by recent GAN-based image inversion methods, we propose a method\ncalled Adversarial Pivotal Tuning (APT). APT first finds a pivot latent space\ninput to a pretrained generator that best reconstructs an input image. It then\nadjusts the weights of the generator to create small, but semantic,\nmanipulations which fool a pretrained classifier. Crucially, APT changes both\nthe input and the weights of the pretrained generator, while preserving its\nexpressive latent editing capability, thus allowing the use of its full\ncapacity in creating semantic adversarial manipulations. We demonstrate that\nAPT generates a variety of semantic image manipulations, which preserve the\ninput image class, but which fool a variety of pretrained classifiers. We\nfurther demonstrate that classifiers trained to be robust to other robustness\nbenchmarks, are not robust to our generated manipulations and propose an\napproach to improve the robustness towards our generated manipulations. Code\navailable at: https://captaine.github.io/apt/",
    "descriptor": "",
    "authors": [
      "Peter Ebert Christensen",
      "V\u00e9steinn Sn\u00e6bjarnarson",
      "Andrea Dittadi",
      "Serge Belongie",
      "Sagie Benaim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09782"
  },
  {
    "id": "arXiv:2211.09783",
    "title": "UniSumm: Unified Few-shot Summarization with Multi-Task Pre-Training and  Prefix-Tuning",
    "abstract": "The diverse demands of different summarization tasks and their high\nannotation costs are driving a need for few-shot summarization. However,\ndespite the emergence of many summarization tasks and datasets, the current\ntraining paradigm for few-shot summarization systems ignores potentially\nshareable knowledge in heterogeneous datasets. To this end, we propose\n\\textsc{UniSumm}, a unified few-shot summarization model pre-trained with\nmultiple summarization tasks and can be prefix-tuned to excel at any few-shot\nsummarization datasets. Meanwhile, to better evaluate few-shot summarization\nsystems, under the principles of diversity and robustness, we assemble and\npublicize a new benchmark \\textsc{SummZoo}. It consists of $8$ diverse\nsummarization tasks with multiple sets of few-shot samples for each task,\ncovering both monologue and dialogue domains. Experimental results and ablation\nstudies show that \\textsc{UniSumm} outperforms strong baseline systems by a\nlarge margin across all tasks in \\textsc{SummZoo} under both automatic and\nhuman evaluations. We release our code and benchmark at\n\\url{https://github.com/microsoft/UniSumm}.",
    "descriptor": "",
    "authors": [
      "Yulong Chen",
      "Yang Liu",
      "Ruochen Xu",
      "Ziyi Yang",
      "Chenguang Zhu",
      "Michael Zeng",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.09783"
  },
  {
    "id": "arXiv:2211.09786",
    "title": "SE(3)-Equivariant Relational Rearrangement with Neural Descriptor Fields",
    "abstract": "We present a method for performing tasks involving spatial relations between\nnovel object instances initialized in arbitrary poses directly from point cloud\nobservations. Our framework provides a scalable way for specifying new tasks\nusing only 5-10 demonstrations. Object rearrangement is formalized as the\nquestion of finding actions that configure task-relevant parts of the object in\na desired alignment. This formalism is implemented in three steps: assigning a\nconsistent local coordinate frame to the task-relevant object parts,\ndetermining the location and orientation of this coordinate frame on unseen\nobject instances, and executing an action that brings these frames into the\ndesired alignment. We overcome the key technical challenge of determining\ntask-relevant local coordinate frames from a few demonstrations by developing\nan optimization method based on Neural Descriptor Fields (NDFs) and a single\nannotated 3D keypoint. An energy-based learning scheme to model the joint\nconfiguration of the objects that satisfies a desired relational task further\nimproves performance. The method is tested on three multi-object rearrangement\ntasks in simulation and on a real robot. Project website, videos, and code:\nhttps://anthonysimeonov.github.io/r-ndf/",
    "descriptor": "\nComments: CoRL 2022, first two authors contributed equally, website and code: this https URL\n",
    "authors": [
      "Anthony Simeonov",
      "Yilun Du",
      "Lin Yen-Chen",
      "Alberto Rodriguez",
      "Leslie Pack Kaelbling",
      "Tomas Lozano-Perez",
      "Pulkit Agrawal"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09786"
  },
  {
    "id": "arXiv:2211.09787",
    "title": "Auction-based Operation in LEO Satellite Systems for High-Efficiency  Communications",
    "abstract": "We propose an auction-based mechanism to improve the efficiency of low earth\norbit satellite communication systems. The mechanism allows the ground stations\nto bid for downlink resources such as spectrum, satellite links, or radios,\nwithout the need to send channel status back to satellites. Simulation and\nexperimental results show that this mechanism improves total channel capacity\nby dynamically leveraging the diversity among satellite-station links; reduces\nuplink overhead by providing lightweight and effective channel status feedback;\nsimplifies computational complexity and improves scalability; and also provides\nimplicit resource information stemming from the auction dynamics. This new\noperation mechanism provides a feasible solution for low earth orbit satellites\nwhich are sensitive to power consumption and overheating.",
    "descriptor": "",
    "authors": [
      "Lin Cheng",
      "Bernardo A. Huberman"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.09787"
  },
  {
    "id": "arXiv:2211.09788",
    "title": "DiffusionDet: Diffusion Model for Object Detection",
    "abstract": "We propose DiffusionDet, a new framework that formulates object detection as\na denoising diffusion process from noisy boxes to object boxes. During training\nstage, object boxes diffuse from ground-truth boxes to random distribution, and\nthe model learns to reverse this noising process. In inference, the model\nrefines a set of randomly generated boxes to the output results in a\nprogressive way. The extensive evaluations on the standard benchmarks,\nincluding MS-COCO and LVIS, show that DiffusionDet achieves favorable\nperformance compared to previous well-established detectors. Our work brings\ntwo important findings in object detection. First, random boxes, although\ndrastically different from pre-defined anchors or learned queries, are also\neffective object candidates. Second, object detection, one of the\nrepresentative perception tasks, can be solved by a generative way. Our code is\navailable at https://github.com/ShoufaChen/DiffusionDet.",
    "descriptor": "\nComments: Tech report. Code is available at this https URL\n",
    "authors": [
      "Shoufa Chen",
      "Peize Sun",
      "Yibing Song",
      "Ping Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09788"
  },
  {
    "id": "arXiv:2211.09790",
    "title": "ConStruct-VL: Data-Free Continual Structured VL Concepts Learning",
    "abstract": "Recently, large-scale pre-trained Vision-and-Language (VL) foundation models\nhave demonstrated remarkable capabilities in many zero-shot downstream tasks,\nachieving competitive results for recognizing objects defined by as little as\nshort text prompts. However, it has also been shown that VL models are still\nbrittle in Structured VL Concept (SVLC) reasoning, such as the ability to\nrecognize object attributes, states, and inter-object relations. This leads to\nreasoning mistakes, which need to be corrected as they occur by teaching VL\nmodels the missing SVLC skills; often this must be done using private data\nwhere the issue was found, which naturally leads to a data-free continual (no\ntask-id) VL learning setting. In this work, we introduce the first Continual\nData-Free Structured VL Concepts Learning (ConStruct-VL) benchmark and show it\nis challenging for many existing data-free CL strategies. We, therefore,\npropose a data-free method comprised of a new approach of Adversarial\nPseudo-Replay (APR) which generates adversarial reminders of past tasks from\npast task models. To use this method efficiently, we also propose a continual\nparameter-efficient Layered-LoRA (LaLo) neural architecture allowing\nno-memory-cost access to all past models at train time. We show this approach\noutperforms all data-free methods by as much as ~7% while even matching some\nlevels of experience-replay (prohibitive for applications where data-privacy\nmust be preserved).",
    "descriptor": "",
    "authors": [
      "James Seale Smith",
      "Paola Cascante-Bonilla",
      "Assaf Arbelle",
      "Donghyun Kim",
      "Rameswar Panda",
      "David Cox",
      "Diyi Yang",
      "Zsolt Kira",
      "Rogerio Feris",
      "Leonid Karlinsky"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09790"
  },
  {
    "id": "arXiv:2211.09791",
    "title": "MOTRv2: Bootstrapping End-to-End Multi-Object Tracking by Pretrained  Object Detectors",
    "abstract": "In this paper, we propose MOTRv2, a simple yet effective pipeline to\nbootstrap end-to-end multi-object tracking with a pretrained object detector.\nExisting end-to-end methods, e.g. MOTR and TrackFormer, are inferior to their\ntracking-by-detection counterparts mainly due to their poor detection\nperformance. We aim to improve MOTR by elegantly incorporating an extra object\ndetector. We first adopt the anchor formulation of queries and then use an\nextra object detector to generate proposals as anchors, providing detection\nprior to MOTR. The simple modification greatly eases the conflict between joint\nlearning detection and association tasks in MOTR. MOTRv2 keeps the end-to-end\nfeature and scales well on large-scale benchmarks. MOTRv2 ranks the 1st place\n(73.4% HOTA on DanceTrack) in the 1st Multiple People Tracking in Group Dance\nChallenge. Moreover, MOTRv2 achieves state-of-the-art performance on BDD100K\ndataset. We hope this simple and effective pipeline can provide some new\ninsights to the end-to-end MOT community. Code is available at\n\\url{https://github.com/megvii-research/MOTRv2}.",
    "descriptor": "\nComments: Tech report\n",
    "authors": [
      "Yuang Zhang",
      "Tiancai Wang",
      "Xiangyu Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09791"
  },
  {
    "id": "arXiv:2211.09794",
    "title": "Null-text Inversion for Editing Real Images using Guided Diffusion  Models",
    "abstract": "Recent text-guided diffusion models provide powerful image generation\ncapabilities. Currently, a massive effort is given to enable the modification\nof these images using text only as means to offer intuitive and versatile\nediting. To edit a real image using these state-of-the-art tools, one must\nfirst invert the image with a meaningful text prompt into the pretrained\nmodel's domain. In this paper, we introduce an accurate inversion technique and\nthus facilitate an intuitive text-based modification of the image. Our proposed\ninversion consists of two novel key components: (i) Pivotal inversion for\ndiffusion models. While current methods aim at mapping random noise samples to\na single input image, we use a single pivotal noise vector for each timestamp\nand optimize around it. We demonstrate that a direct inversion is inadequate on\nits own, but does provide a good anchor for our optimization. (ii) NULL-text\noptimization, where we only modify the unconditional textual embedding that is\nused for classifier-free guidance, rather than the input text embedding. This\nallows for keeping both the model weights and the conditional embedding intact\nand hence enables applying prompt-based editing while avoiding the cumbersome\ntuning of the model's weights. Our Null-text inversion, based on the publicly\navailable Stable Diffusion model, is extensively evaluated on a variety of\nimages and prompt editing, showing high-fidelity editing of real images.",
    "descriptor": "",
    "authors": [
      "Ron Mokady",
      "Amir Hertz",
      "Kfir Aberman",
      "Yael Pritch",
      "Daniel Cohen-Or"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09794"
  },
  {
    "id": "arXiv:2211.09795",
    "title": "Conffusion: Confidence Intervals for Diffusion Models",
    "abstract": "Diffusion models have become the go-to method for many generative tasks,\nparticularly for image-to-image generation tasks such as super-resolution and\ninpainting. Current diffusion-based methods do not provide statistical\nguarantees regarding the generated results, often preventing their use in\nhigh-stakes situations. To bridge this gap, we construct a confidence interval\naround each generated pixel such that the true value of the pixel is guaranteed\nto fall within the interval with a probability set by the user. Since diffusion\nmodels parametrize the data distribution, a straightforward way of constructing\nsuch intervals is by drawing multiple samples and calculating their bounds.\nHowever, this method has several drawbacks: i) slow sampling speeds ii)\nsuboptimal bounds iii) requires training a diffusion model per task. To\nmitigate these shortcomings we propose Conffusion, wherein we fine-tune a\npre-trained diffusion model to predict interval bounds in a single forward\npass. We show that Conffusion outperforms the baseline method while being three\norders of magnitude faster.",
    "descriptor": "",
    "authors": [
      "Eliahu Horwitz",
      "Yedid Hoshen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09795"
  },
  {
    "id": "arXiv:2211.09799",
    "title": "CAE v2: Context Autoencoder with CLIP Target",
    "abstract": "Masked image modeling (MIM) learns visual representation by masking and\nreconstructing image patches. Applying the reconstruction supervision on the\nCLIP representation has been proven effective for MIM. However, it is still\nunder-explored how CLIP supervision in MIM influences performance. To\ninvestigate strategies for refining the CLIP-targeted MIM, we study two\ncritical elements in MIM, i.e., the supervision position and the mask ratio,\nand reveal two interesting perspectives, relying on our developed simple\npipeline, context autodecoder with CLIP target (CAE v2). Firstly, we observe\nthat the supervision on visible patches achieves remarkable performance, even\nbetter than that on masked patches, where the latter is the standard format in\nthe existing MIM methods. Secondly, the optimal mask ratio positively\ncorrelates to the model size. That is to say, the smaller the model, the lower\nthe mask ratio needs to be. Driven by these two discoveries, our simple and\nconcise approach CAE v2 achieves superior performance on a series of downstream\ntasks. For example, a vanilla ViT-Large model achieves 81.7% and 86.7% top-1\naccuracy on linear probing and fine-tuning on ImageNet-1K, and 55.9% mIoU on\nsemantic segmentation on ADE20K with the pre-training for 300 epochs. We hope\nour findings can be helpful guidelines for the pre-training in the MIM area,\nespecially for the small-scale models.",
    "descriptor": "",
    "authors": [
      "Xinyu Zhang",
      "Jiahui Chen",
      "Junkun Yuan",
      "Qiang Chen",
      "Jian Wang",
      "Xiaodi Wang",
      "Shumin Han",
      "Xiaokang Chen",
      "Jimin Pi",
      "Kun Yao",
      "Junyu Han",
      "Errui Ding",
      "Jingdong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09799"
  },
  {
    "id": "arXiv:2211.09800",
    "title": "InstructPix2Pix: Learning to Follow Image Editing Instructions",
    "abstract": "We propose a method for editing images from human instructions: given an\ninput image and a written instruction that tells the model what to do, our\nmodel follows these instructions to edit the image. To obtain training data for\nthis problem, we combine the knowledge of two large pretrained models -- a\nlanguage model (GPT-3) and a text-to-image model (Stable Diffusion) -- to\ngenerate a large dataset of image editing examples. Our conditional diffusion\nmodel, InstructPix2Pix, is trained on our generated data, and generalizes to\nreal images and user-written instructions at inference time. Since it performs\nedits in the forward pass and does not require per example fine-tuning or\ninversion, our model edits images quickly, in a matter of seconds. We show\ncompelling editing results for a diverse collection of input images and written\ninstructions.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Tim Brooks",
      "Aleksander Holynski",
      "Alexei A. Efros"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09800"
  },
  {
    "id": "arXiv:2211.09807",
    "title": "Towards All-in-one Pre-training via Maximizing Multi-modal Mutual  Information",
    "abstract": "To effectively exploit the potential of large-scale models, various\npre-training strategies supported by massive data from different sources are\nproposed, including supervised pre-training, weakly-supervised pre-training,\nand self-supervised pre-training. It has been proved that combining multiple\npre-training strategies and data from various modalities/sources can greatly\nboost the training of large-scale models. However, current works adopt a\nmulti-stage pre-training system, where the complex pipeline may increase the\nuncertainty and instability of the pre-training. It is thus desirable that\nthese strategies can be integrated in a single-stage manner. In this paper, we\nfirst propose a general multi-modal mutual information formula as a unified\noptimization target and demonstrate that all existing approaches are special\ncases of our framework. Under this unified perspective, we propose an\nall-in-one single-stage pre-training approach, named Maximizing Multi-modal\nMutual Information Pre-training (M3I Pre-training). Our approach achieves\nbetter performance than previous pre-training methods on various vision\nbenchmarks, including ImageNet classification, COCO object detection, LVIS\nlong-tailed object detection, and ADE20k semantic segmentation. Notably, we\nsuccessfully pre-train a billion-level parameter image backbone and achieve\nstate-of-the-art performance on various benchmarks. Code shall be released.",
    "descriptor": "",
    "authors": [
      "Weijie Su",
      "Xizhou Zhu",
      "Chenxin Tao",
      "Lewei Lu",
      "Bin Li",
      "Gao Huang",
      "Yu Qiao",
      "Xiaogang Wang",
      "Jie Zhou",
      "Jifeng Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09807"
  },
  {
    "id": "arXiv:2211.09808",
    "title": "Uni-Perceiver v2: A Generalist Model for Large-Scale Vision and  Vision-Language Tasks",
    "abstract": "Despite the remarkable success of foundation models, their task-specific\nfine-tuning paradigm makes them inconsistent with the goal of general\nperception modeling. The key to eliminating this inconsistency is to use\ngeneralist models for general task modeling. However, existing attempts at\ngeneralist models are inadequate in both versatility and performance. In this\npaper, we propose Uni-Perceiver v2, which is the first generalist model capable\nof handling major large-scale vision and vision-language tasks with competitive\nperformance. Specifically, images are encoded as general region proposals,\nwhile texts are encoded via a Transformer-based language model. The encoded\nrepresentations are transformed by a task-agnostic decoder. Different tasks are\nformulated as a unified maximum likelihood estimation problem. We further\npropose an improved optimizer to ensure stable multi-task learning with an\nunmixed sampling strategy, which is helpful for tasks requiring large\nbatch-size training. After being jointly trained on various tasks,\nUni-Perceiver v2 is capable of directly handling downstream tasks without any\ntask-specific adaptation. Results show that Uni-Perceiver v2 outperforms all\nexisting generalist models in both versatility and performance. Meanwhile,\ncompared with the commonly-recognized strong baselines that require\ntasks-specific fine-tuning, Uni-Perceiver v2 achieves competitive performance\non a broad range of vision and vision-language tasks.",
    "descriptor": "\nComments: Code shall be released at this https URL\n",
    "authors": [
      "Hao Li",
      "Jinguo Zhu",
      "Xiaohu Jiang",
      "Xizhou Zhu",
      "Hongsheng Li",
      "Chun Yuan",
      "Xiaohua Wang",
      "Yu Qiao",
      "Xiaogang Wang",
      "Wenhai Wang",
      "Jifeng Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09808"
  },
  {
    "id": "arXiv:2211.09809",
    "title": "SPACEx: Speech-driven Portrait Animation with Controllable Expression",
    "abstract": "Animating portraits using speech has received growing attention in recent\nyears, with various creative and practical use cases. An ideal generated video\nshould have good lip sync with the audio, natural facial expressions and head\nmotions, and high frame quality. In this work, we present SPACEx, which uses\nspeech and a single image to generate high-resolution, and expressive videos\nwith realistic head pose, without requiring a driving video. It uses a\nmulti-stage approach, combining the controllability of facial landmarks with\nthe high-quality synthesis power of a pretrained face generator. SPACEx also\nallows for the control of emotions and their intensities. Our method\noutperforms prior methods in objective metrics for image quality and facial\nmotions and is strongly preferred by users in pair-wise comparisons. The\nproject website is available at https://deepimagination.cc/SPACEx/",
    "descriptor": "",
    "authors": [
      "Siddharth Gururani",
      "Arun Mallya",
      "Ting-Chun Wang",
      "Rafael Valle",
      "Ming-Yu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09809"
  },
  {
    "id": "arXiv:2211.09129",
    "title": "Characterizing 4-string contact interaction using machine learning",
    "abstract": "The geometry of 4-string contact interaction of closed string field theory is\ncharacterized using machine learning. We obtain Strebel quadratic differentials\non 4-punctured spheres as a neural network by performing unsupervised learning\nwith a custom-built loss function. This allows us to solve for local\ncoordinates and compute their associated mapping radii numerically. We also\ntrain a neural network distinguishing vertex from Feynman region. As a check,\n4-tachyon contact term in the tachyon potential is computed and a good\nagreement with the results in the literature is observed. We argue that our\nalgorithm is manifestly independent of number of punctures and scaling it to\ncharacterize the geometry of $n$-string contact interaction is feasible.",
    "descriptor": "\nComments: 28+10 pages, 13 figures, 6 tables\n",
    "authors": [
      "Harold Erbin",
      "Atakan Hilmi F\u0131rat"
    ],
    "subjectives": [
      "High Energy Physics - Theory (hep-th)",
      "Machine Learning (cs.LG)",
      "Complex Variables (math.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09129"
  },
  {
    "id": "arXiv:2211.09133",
    "title": "On the complexity of implementing Trotter steps",
    "abstract": "Quantum dynamics can be simulated on a quantum computer by exponentiating\nelementary terms from the Hamiltonian in a sequential manner. However, such an\nimplementation of Trotter steps has gate complexity depending on the total\nHamiltonian term number, comparing unfavorably to algorithms using more\nadvanced techniques. We develop methods to perform faster Trotter steps with\ncomplexity sublinear in the number of terms. We achieve this for a class of\nHamiltonians whose interaction strength decays with distance according to power\nlaw. Our methods include one based on a recursive block encoding and one based\non an average-cost simulation, overcoming the normalization-factor barrier of\nthese advanced quantum simulation techniques. We also realize faster Trotter\nsteps when certain blocks of Hamiltonian coefficients have low rank. Combining\nwith a tighter error analysis, we show that it suffices to use\n$\\left(\\eta^{1/3}n^{1/3}+\\frac{n^{2/3}}{\\eta^{2/3}}\\right)n^{1+o(1)}$ gates to\nsimulate uniform electron gas with $n$ spin orbitals and $\\eta$ electrons in\nsecond quantization in real space, asymptotically improving over the best\nprevious work. We obtain an analogous result when the external potential of\nnuclei is introduced under the Born-Oppenheimer approximation. We prove a\ncircuit lower bound when the Hamiltonian coefficients take a continuum range of\nvalues, showing that generic $n$-qubit $2$-local Hamiltonians with commuting\nterms require at least $\\Omega(n^2)$ gates to evolve with accuracy\n$\\epsilon=\\Omega(1/poly(n))$ for time $t=\\Omega(\\epsilon)$. Our proof is based\non a gate-efficient reduction from the approximate synthesis of diagonal\nunitaries within the Hamming weight-$2$ subspace, which may be of independent\ninterest. Our result thus suggests the use of Hamiltonian structural properties\nas both necessary and sufficient to implement Trotter steps with lower gate\ncomplexity.",
    "descriptor": "\nComments: 65 pages, 6 figures\n",
    "authors": [
      "Guang Hao Low",
      "Yuan Su",
      "Yu Tong",
      "Minh C. Tran"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Data Structures and Algorithms (cs.DS)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.09133"
  },
  {
    "id": "arXiv:2211.09166",
    "title": "A Two-Stage Deep Representation Learning-Based Speech Enhancement Method  Using Variational Autoencoder and Adversarial Training",
    "abstract": "This paper focuses on leveraging deep representation learning (DRL) for\nspeech enhancement (SE). In general, the performance of the deep neural network\n(DNN) is heavily dependent on the learning of data representation. However, the\nDRL's importance is often ignored in many DNN-based SE algorithms. To obtain a\nhigher quality enhanced speech, we propose a two-stage DRL-based SE method\nthrough adversarial training. In the first stage, we disentangle different\nlatent variables because disentangled representations can help DNN generate a\nbetter enhanced speech. Specifically, we use the $\\beta$-variational\nautoencoder (VAE) algorithm to obtain the speech and noise posterior\nestimations and related representations from the observed signal. However,\nsince the posteriors and representations are intractable and we can only apply\na conditional assumption to estimate them, it is difficult to ensure that these\nestimations are always pretty accurate, which may potentially degrade the final\naccuracy of the signal estimation. To further improve the quality of enhanced\nspeech, in the second stage, we introduce adversarial training to reduce the\neffect of the inaccurate posterior towards signal reconstruction and improve\nthe signal estimation accuracy, making our algorithm more robust for the\npotentially inaccurate posterior estimations. As a result, better SE\nperformance can be achieved. The experimental results indicate that the\nproposed strategy can help similar DNN-based SE algorithms achieve higher\nshort-time objective intelligibility (STOI), perceptual evaluation of speech\nquality (PESQ), and scale-invariant signal-to-distortion ratio (SI-SDR) scores.\nMoreover, the proposed algorithm can also outperform recent competitive SE\nalgorithms.",
    "descriptor": "\nComments: Submitted to IEEE/ACM Transactions on Audio, Speech and Language Processing\n",
    "authors": [
      "Yang Xiang",
      "Jesper Lisby H\u00f8jvang",
      "Morten H\u00f8jfeldt Rasmussen",
      "Mads Gr\u00e6sb\u00f8ll Christensen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.09166"
  },
  {
    "id": "arXiv:2211.09184",
    "title": "An Empirical Analysis of the Advantages of Finite- v.s. Infinite-Width  Bayesian Neural Networks",
    "abstract": "Comparing Bayesian neural networks (BNNs) with different widths is\nchallenging because, as the width increases, multiple model properties change\nsimultaneously, and, inference in the finite-width case is intractable. In this\nwork, we empirically compare finite- and infinite-width BNNs, and provide\nquantitative and qualitative explanations for their performance difference. We\nfind that when the model is mis-specified, increasing width can hurt BNN\nperformance. In these cases, we provide evidence that finite-width BNNs\ngeneralize better partially due to the properties of their frequency spectrum\nthat allows them to adapt under model mismatch.",
    "descriptor": "\nComments: Accepted at ICBINB Workshop, NeurIPS 2022\n",
    "authors": [
      "Jiayu Yao",
      "Yaniv Yacoby",
      "Beau Coker",
      "Weiwei Pan",
      "Finale Doshi-Velez"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09184"
  },
  {
    "id": "arXiv:2211.09186",
    "title": "Oncology and mechanics: landmark studies and promising clinical  applications",
    "abstract": "Clinical management of cancer has continuously evolved for several decades.\nBiochemical, molecular and genomics approaches have brought and still bring\nnumerous insights into cancerous diseases. It is now accepted that some\nphenomena, allowed by favorable biological conditions, emerge via mechanical\nsignaling at the cellular scale and via mechanical forces at the macroscale.\nMechanical phenomena in cancer have been studied in-depth over the last\ndecades, and their clinical applications are starting to be understood. If\nnumerous models and experimental setups have been proposed, only a few have led\nto clinical applications. The objective of this contribution is to propose to\nreview a large scope of mechanical findings which have consequences on the\nclinical management of cancer. This review is mainly addressed to doctoral\ncandidates in mechanics and applied mathematics who are faced with the\nchallenge of the mechanics-based modeling of cancer with the aim of clinical\napplications. We show that the collaboration of the biological and mechanical\napproaches has led to promising advances in terms of modeling, experimental\ndesign and therapeutic targets. Additionally, a specific focus is brought on\nimaging-informed mechanics-based models, which we believe can further the\ndevelopment of new therapeutic targets and the advent of personalized medicine.\nWe study in detail several successful workflows on patient-specific targeted\ntherapies based on mechanistic modeling.",
    "descriptor": "",
    "authors": [
      "St\u00e9phane Urcun",
      "Guillermo Lorenzo",
      "Davide Baroli",
      "Pierre-Yves Rohan",
      "Giuseppe Scium\u00e8",
      "Wafa Skalli",
      "Vincent Lubrano",
      "St\u00e9phane P.A. Bordas"
    ],
    "subjectives": [
      "Tissues and Organs (q-bio.TO)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Cell Behavior (q-bio.CB)"
    ],
    "url": "https://arxiv.org/abs/2211.09186"
  },
  {
    "id": "arXiv:2211.09196",
    "title": "Sobolev Spaces, Kernels and Discrepancies over Hyperspheres",
    "abstract": "This work provides theoretical foundations for kernel methods in the\nhyperspherical context. Specifically, we characterise the native spaces\n(reproducing kernel Hilbert spaces) and the Sobolev spaces associated with\nkernels defined over hyperspheres. Our results have direct consequences for\nkernel cubature, determining the rate of convergence of the worst case error,\nand expanding the applicability of cubature algorithms based on Stein's method.\nWe first introduce a suitable characterisation on Sobolev spaces on the\n$d$-dimensional hypersphere embedded in $(d+1)$-dimensional Euclidean spaces.\nOur characterisation is based on the Fourier--Schoenberg sequences associated\nwith a given kernel. Such sequences are hard (if not impossible) to compute\nanalytically on $d$-dimensional spheres, but often feasible over Hilbert\nspheres. We circumvent this problem by finding a projection operator that\nallows to Fourier mapping from Hilbert into finite dimensional hyperspheres. We\nillustrate our findings through some parametric families of kernels.",
    "descriptor": "",
    "authors": [
      "Simon Hubbert",
      "Emilio Porcu",
      "Chris. J. Oates",
      "Mark Girolami"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09196"
  },
  {
    "id": "arXiv:2211.09221",
    "title": "The non-overlapping statistical approximation to overlapping group lasso",
    "abstract": "Group lasso is a commonly used regularization method in statistical learning\nin which parameters are eliminated from the model according to predefined\ngroups. However, when the groups overlap, optimizing the group lasso penalized\nobjective can be time-consuming on large-scale problems because of the\nnon-separability induced by the overlapping groups. This bottleneck has\nseriously limited the application of overlapping group lasso regularization in\nmany modern problems, such as gene pathway selection and graphical model\nestimation. In this paper, we propose a separable penalty as an approximation\nof the overlapping group lasso penalty. Thanks to the separability, the\ncomputation of regularization based on our penalty is substantially faster than\nthat of the overlapping group lasso, especially for large-scale and\nhigh-dimensional problems. We show that the penalty is the tightest separable\nrelaxation of the overlapping group lasso norm within the family of\n$\\ell_{q_1}/\\ell_{q_2}$ norms. Moreover, we show that the estimator based on\nthe proposed separable penalty is statistically equivalent to the one based on\nthe overlapping group lasso penalty with respect to their error bounds and the\nrate-optimal performance under the squared loss. We demonstrate the faster\ncomputational time and statistical equivalence of our method compared with the\noverlapping group lasso in simulation examples and a classification problem of\ncancer tumors based on gene expression and multiple gene pathways.",
    "descriptor": "",
    "authors": [
      "Mingyu Qi",
      "Tianxi Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09221"
  },
  {
    "id": "arXiv:2211.09240",
    "title": "Stimulation of soy seeds using environmentally friendly magnetic and  electric fields",
    "abstract": "The study analyzes the impact of constant and alternating magnetic fields and\nalternating electric fields on various growth parameters of soy plants: the\ngermination energy and capacity, plants emergence and number, the Yield(II) of\nthe fresh mass of seedlings, protein content, and photosynthetic parameters.\nFour cultivars were used: MAVKA, MERLIN, VIOLETTA, and ANUSZKA. Moreover, the\nadvanced Machine Learning processing pipeline was proposed to distinguish the\nimpact of physical factors on photosynthetic parameters. It is possible to\ndistinguish exposition on different physical factors for the first three\ncultivars; therefore, it indicates that the EM factors have some observable\neffect on soy plants. Moreover, some influence of physical factors on growth\nparameters was observed. The use of ELM (Electromagnetic) fields had a positive\nimpact on the germination rate in Merlin plants. The highest values were\nrecorded for the constant magnetic field (CMF) - Merlin, and the lowest for the\nalternating electric field (AEF) - Violetta. An increase in terms of emergence\nand number of plants after seed stimulation was observed for the Mavka\ncultivar, except for the AEF treatment (number of plants after 30 days) (...)",
    "descriptor": "",
    "authors": [
      "Agata Dziwulska-Hunek",
      "Agnieszka Niemczynowicz",
      "Rados\u0142aw A. Kycia",
      "Arkadiusz Matwijczuk",
      "Krzysztof Kornarzy\u0144ski",
      "Joanna Stadnik",
      "Mariusz Szymanek"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.09240"
  },
  {
    "id": "arXiv:2211.09272",
    "title": "A Generalized Latent Factor Model Approach to Mixed-data Matrix  Completion with Entrywise Consistency",
    "abstract": "Matrix completion is a class of machine learning methods that concerns the\nprediction of missing entries in a partially observed matrix. This paper\nstudies matrix completion for mixed data, i.e., data involving mixed types of\nvariables (e.g., continuous, binary, ordinal). We formulate it as a low-rank\nmatrix estimation problem under a general family of non-linear factor models\nand then propose entrywise consistent estimators for estimating the low-rank\nmatrix. Tight probabilistic error bounds are derived for the proposed\nestimators. The proposed methods are evaluated by simulation studies and\nreal-data applications for collaborative filtering and large-scale educational\nassessment.",
    "descriptor": "",
    "authors": [
      "Yunxiao Chen",
      "Xiaoou Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.09272"
  },
  {
    "id": "arXiv:2211.09284",
    "title": "Iterative execution of discrete and inverse discrete Fourier transforms  with applications for signal denoising via sparsification",
    "abstract": "We describe a family of iterative algorithms that involve the repeated\nexecution of discrete and inverse discrete Fourier transforms. One interesting\nmember of this family is motivated by the discrete Fourier transform\nuncertainty principle and involves the application of a sparsification\noperation to both the time domain and frequency domain data with convergence\nobtained when time domain sparsity hits a stable pattern. This sparsification\nvariant has practical utility for signal denoising, in particular the recovery\nof a periodic spike signal in the presence of Gaussian noise. General\nconvergence properties and denoising performance are demonstrated using\nsimulation studies. We are not aware of prior work on such iterative Fourier\ntransformation algorithms and are posting this short paper in part to solicit\nfeedback from others in the field who may be familiar with similar techniques.",
    "descriptor": "",
    "authors": [
      "H. Robert Frost"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Numerical Analysis (math.NA)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.09284"
  },
  {
    "id": "arXiv:2211.09287",
    "title": "Variable selection for nonlinear Cox regression model via deep learning",
    "abstract": "Variable selection problem for the nonlinear Cox regression model is\nconsidered. In survival analysis, one main objective is to identify the\ncovariates that are associated with the risk of experiencing the event of\ninterest. The Cox proportional hazard model is being used extensively in\nsurvival analysis in studying the relationship between survival times and\ncovariates, where the model assumes that the covariate has a log-linear effect\non the hazard function. However, this linearity assumption may not be satisfied\nin practice. In order to extract a representative subset of features, various\nvariable selection approaches have been proposed for survival data under the\nlinear Cox model. However, there exists little literature on variable selection\nfor the nonlinear Cox model. To break this gap, we extend the recently\ndeveloped deep learning-based variable selection model LassoNet to survival\ndata. Simulations are provided to demonstrate the validity and effectiveness of\nthe proposed method. Finally, we apply the proposed methodology to analyze a\nreal data set on diffuse large B-cell lymphoma.",
    "descriptor": "",
    "authors": [
      "Kexuan Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.09287"
  },
  {
    "id": "arXiv:2211.09295",
    "title": "Testing for context-dependent changes in neural encoding in naturalistic  experiments",
    "abstract": "We propose a decoding-based approach to detect context effects on neural\ncodes in longitudinal neural recording data. The approach is agnostic to how\ninformation is encoded in neural activity, and can control for a variety of\npossible confounding factors present in the data. We demonstrate our approach\nby determining whether it is possible to decode location encoding from\nprefrontal cortex in the mouse and, further, testing whether the encoding\nchanges due to task engagement.",
    "descriptor": "\nComments: 39 pages, 13 figures\n",
    "authors": [
      "Yenho Chen",
      "Carl W. Harris",
      "Xiaoyu Ma",
      "Zheng Li",
      "Francisco Pereira",
      "Charles Y.Zheng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09295"
  },
  {
    "id": "arXiv:2211.09313",
    "title": "Unsupervised Model-based speaker adaptation of end-to-end lattice-free  MMI model for speech recognition",
    "abstract": "Modeling the speaker variability is a key challenge for automatic speech\nrecognition (ASR) systems. In this paper, the learning hidden unit\ncontributions (LHUC) based adaptation techniques with compact speaker dependent\n(SD) parameters are used to facilitate both speaker adaptive training (SAT) and\nunsupervised test-time speaker adaptation for end-to-end (E2E) lattice-free MMI\n(LF-MMI) models. An unsupervised model-based adaptation framework is proposed\nto estimate the SD parameters in E2E paradigm using LF-MMI and cross entropy\n(CE) criterions. Various regularization methods of the standard LHUC\nadaptation, e.g., the Bayesian LHUC (BLHUC) adaptation, are systematically\ninvestigated to mitigate the risk of overfitting, on E2E LF-MMI CNN-TDNN and\nCNN-TDNN-BLSTM models. Lattice-based confidence score estimation is used for\nadaptation data selection to reduce the supervision label uncertainty.\nExperiments on the 300-hour Switchboard task suggest that applying BLHUC in the\nproposed unsupervised E2E adaptation framework to byte pair encoding (BPE)\nbased E2E LF-MMI systems consistently outperformed the baseline systems by\nrelative word error rate (WER) reductions up to 10.5% and 14.7% on the NIST\nHub5'00 and RT03 evaluation sets, and achieved the best performance in WERs of\n9.0% and 9.7%, respectively. These results are comparable to the results of\nstate-of-the-art adapted LF-MMI hybrid systems and adapted Conformer-based E2E\nsystems.",
    "descriptor": "\nComments: 6 pages, 2 figures, submitted to ICASSP 2022\n",
    "authors": [
      "Xurong Xie",
      "Xunying Liu",
      "Hui Chen",
      "Hongan Wang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.09313"
  },
  {
    "id": "arXiv:2211.09328",
    "title": "Covering and packing with homothets of limited capacity",
    "abstract": "This work revolves around the two following questions: Given a convex body\n$C\\subset\\mathbb{R}^d$, a positive integer $k$ and a finite set\n$S\\subset\\mathbb{R}^d$ (or a finite $\\mu$ Borel measure in $\\mathbb{R}^d$), how\nmany homothets of $C$ are required to cover $S$ if no homothet is allowed to\ncover more than $k$ points of $S$ (or have measure more than $k$)? how many\nhomothets of $C$ can be packed if each of them must cover at least $k$ points\nof $S$ (or have measure at least $k$)? We prove that, so long as $S$ is not too\ndegenerate, the answer to both questions is $\\Theta_d(\\frac{|S|}{k})$, where\nthe hidden constant is independent of $d$, this is clearly best possible up to\na multiplicative constant. Analogous results hold in the case of measures. Then\nwe introduce a generalization of the standard covering and packing densities of\na convex body $C$ to Borel measure spaces in $\\mathbb{R}^d$ and, using the\naforementioned bounds, we show that they are bounded from above and below,\nrespectively, by functions of $d$. As an intermediate result, we give a simple\nproof the existence of weak $\\epsilon$-nets of size $O(\\frac{1}{\\epsilon})$ for\nthe range space induced by all homothets of $C$. Following some recent work in\ndiscrete geometry, we investigate the case $d=k=2$ in greater detail. We also\nprovide polynomial time algorithms for constructing a packing/covering\nexhibiting the $\\Theta_d(\\frac{|S|}{k})$ bound mentioned above in the case that\n$C$ is an Euclidean ball. Finally, it is shown that if $C$ is a square then it\nis NP-hard to decide whether $S$ can be covered by $\\frac{|S|}{4}$ squares\ncontaining $4$ points each.",
    "descriptor": "\nComments: 30 pages, 10 figures\n",
    "authors": [
      "Oriol Sol\u00e9 Pi"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2211.09328"
  },
  {
    "id": "arXiv:2211.09352",
    "title": "SpectNet : End-to-End Audio Signal Classification Using Learnable  Spectrograms",
    "abstract": "Pattern recognition from audio signals is an active research topic\nencompassing audio tagging, acoustic scene classification, music\nclassification, and other areas. Spectrogram and mel-frequency cepstral\ncoefficients (MFCC) are among the most commonly used features for audio signal\nanalysis and classification. Recently, deep convolutional neural networks (CNN)\nhave been successfully used for audio classification problems using\nspectrogram-based 2D features. In this paper, we present SpectNet, an\nintegrated front-end layer that extracts spectrogram features within a CNN\narchitecture that can be used for audio pattern recognition tasks. The\nfront-end layer utilizes learnable gammatone filters that are initialized using\nmel-scale filters. The proposed layer outputs a 2D spectrogram image which can\nbe fed into a 2D CNN for classification. The parameters of the entire network,\nincluding the front-end filterbank, can be updated via back-propagation. This\ntraining scheme allows for fine-tuning the spectrogram-image features according\nto the target audio dataset. The proposed method is evaluated in two different\naudio signal classification tasks: heart sound anomaly detection and acoustic\nscene classification. The proposed method shows a significant 1.02\\%\nimprovement in MACC for the heart sound classification task and 2.11\\%\nimprovement in accuracy for the acoustic scene classification task compared to\nthe classical spectrogram image features. The source code of our experiments\ncan be found at \\url{https://github.com/mHealthBuet/SpectNet}",
    "descriptor": "",
    "authors": [
      "Md. Istiaq Ansari",
      "Taufiq Hasan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.09352"
  },
  {
    "id": "arXiv:2211.09372",
    "title": "Linear isometries on Weighted Coordinates Poset Block Space",
    "abstract": "Given $[n]=\\{1,2,\\ldots,n\\}$, a poset order $\\preceq$ on $[n]$, a label map\n$\\pi : [n] \\rightarrow \\mathbb{N}$ defined by $\\pi(i)=k_i$ with\n$\\sum_{i=1}^{n}\\pi (i) = N$, and a weight function $w$ on $\\mathbb{F}_{q}$, let\n$\\mathbb{F}_{q}^N$ be the vector space of $N$-tuples over the field\n$\\mathbb{F}_{q}$ equipped with $(P,w,\\pi)$-metric where $ \\mathbb{F}_q^N $ is\nthe direct sum of spaces $ \\mathbb{F}_{q}^{k_1}, \\mathbb{F}_{q}^{k_2}, \\ldots,\n\\mathbb{F}_{q}^{k_n} $. In this paper, we determine the groups of linear\nisometries of $(P,w,\\pi)$-metric spaces in terms of a semi-direct product,\nwhich turns out to be similar to the case of poset (block) metric spaces. In\nparticular, we re-obtain the group of linear isometries of the $(P,w)$-mertic\nspaces and $(P,\\pi)$-mertic spaces.",
    "descriptor": "\nComments: 13 Pages\n",
    "authors": [
      "Atul Kumar Shriwastva",
      "R. S. Selvaraj"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.09372"
  },
  {
    "id": "arXiv:2211.09383",
    "title": "Any-speaker Adaptive Text-To-Speech Synthesis with Diffusion Models",
    "abstract": "There has been a significant progress in Text-To-Speech (TTS) synthesis\ntechnology in recent years, thanks to the advancement in neural generative\nmodeling. However, existing methods on any-speaker adaptive TTS have achieved\nunsatisfactory performance, due to their suboptimal accuracy in mimicking the\ntarget speakers' styles. In this work, we present Grad-StyleSpeech, which is an\nany-speaker adaptive TTS framework that is based on a diffusion model that can\ngenerate highly natural speech with extremely high similarity to target\nspeakers' voice, given a few seconds of reference speech. Grad-StyleSpeech\nsignificantly outperforms recent speaker-adaptive TTS baselines on English\nbenchmarks. Audio samples are available at\nhttps://nardien.github.io/grad-stylespeech-demo.",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Minki Kang",
      "Dongchan Min",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.09383"
  },
  {
    "id": "arXiv:2211.09391",
    "title": "Transfer learning for tensor Gaussian graphical models",
    "abstract": "Tensor Gaussian graphical models (GGMs), interpreting conditional\nindependence structures within tensor data, have important applications in\nnumerous areas. Yet, the available tensor data in one single study is often\nlimited due to high acquisition costs. Although relevant studies can provide\nadditional data, it remains an open question how to pool such heterogeneous\ndata. In this paper, we propose a transfer learning framework for tensor GGMs,\nwhich takes full advantage of informative auxiliary domains even when\nnon-informative auxiliary domains are present, benefiting from the carefully\ndesigned data-adaptive weights. Our theoretical analysis shows substantial\nimprovement of estimation errors and variable selection consistency on the\ntarget domain under much relaxed conditions, by leveraging information from\nauxiliary domains. Extensive numerical experiments are conducted on both\nsynthetic tensor graphs and a brain functional connectivity network data, which\ndemonstrates the satisfactory performance of the proposed method.",
    "descriptor": "",
    "authors": [
      "Mingyang Ren",
      "Yaoming Zhen",
      "Junhui Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09391"
  },
  {
    "id": "arXiv:2211.09403",
    "title": "Learning Mixtures of Markov Chains and MDPs",
    "abstract": "We present an algorithm for use in learning mixtures of both Markov chains\n(MCs) and Markov decision processes (offline latent MDPs) from trajectories,\nwith roots dating back to the work of Vempala and Wang. This amounts to\nhandling Markov chains with optional control input. The method is modular in\nnature and amounts to (1) a subspace estimation step, (2) spectral clustering\nof trajectories, and (3) a few iterations of the EM algorithm. We provide\nend-to-end performance guarantees where we only explicitly require the number\nof trajectories to be linear in states and the trajectory length to be linear\nin mixing time. Experimental results suggest it outperforms both EM (95.4% on\naverage) and a previous method by Gupta et al. (54.1%), obtaining 100% permuted\naccuracy on an 8x8 gridworld.",
    "descriptor": "\nComments: 34 pages (13 page paper, 21 page appendix)\n",
    "authors": [
      "Chinmaya Kausik",
      "Kevin Tan",
      "Ambuj Tewari"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09403"
  },
  {
    "id": "arXiv:2211.09404",
    "title": "Hard Exudate Segmentation Supplemented by Super-Resolution with  Multi-scale Attention Fusion Module",
    "abstract": "Hard exudates (HE) is the most specific biomarker for retina edema. Precise\nHE segmentation is vital for disease diagnosis and treatment, but automatic\nsegmentation is challenged by its large variation of characteristics including\nsize, shape and position, which makes it difficult to detect tiny lesions and\nlesion boundaries. Considering the complementary features between segmentation\nand super-resolution tasks, this paper proposes a novel hard exudates\nsegmentation method named SS-MAF with an auxiliary super-resolution task, which\nbrings in helpful detailed features for tiny lesion and boundaries detection.\nSpecifically, we propose a fusion module named Multi-scale Attention Fusion\n(MAF) module for our dual-stream framework to effectively integrate features of\nthe two tasks. MAF first adopts split spatial convolutional (SSC) layer for\nmulti-scale features extraction and then utilize attention mechanism for\nfeatures fusion of the two tasks. Considering pixel dependency, we introduce\nregion mutual information (RMI) loss to optimize MAF module for tiny lesions\nand boundary detection. We evaluate our method on two public lesion datasets,\nIDRiD and E-Ophtha. Our method shows competitive performance with\nlow-resolution inputs, both quantitatively and qualitatively. On E-Ophtha\ndataset, the method can achieve $\\geq3\\%$ higher dice and recall compared with\nthe state-of-the-art methods.",
    "descriptor": "\nComments: Accepted by IEEE BIBM 2022\n",
    "authors": [
      "Jiayi Zhang",
      "Xiaoshan Chen",
      "Zhongxi Qiu",
      "Mingming Yang",
      "Yan Hu",
      "Jiang Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09404"
  },
  {
    "id": "arXiv:2211.09439",
    "title": "Algebraic optimization of sequential decision problems",
    "abstract": "We study the optimization of the expected long-term reward in finite\npartially observable Markov decision processes over the set of stationary\nstochastic policies. In the case of deterministic observations, also known as\nstate aggregation, the problem is equivalent to optimizing a linear objective\nsubject to quadratic constraints. We characterize the feasible set of this\nproblem as the intersection of a product of affine varieties of rank one\nmatrices and a polytope. Based on this description, we obtain bounds on the\nnumber of critical points of the optimization problem. Finally, we conduct\nexperiments in which we solve the KKT equations or the Lagrange equations over\ndifferent boundary components of the feasible set, and compare the result to\nthe theoretical bounds and to other constrained optimization methods.",
    "descriptor": "\nComments: 19 pages, 3 figures\n",
    "authors": [
      "Mareike Dressler",
      "Marina Garrote-L\u00f3pez",
      "Guido Mont\u00fafar",
      "Johannes M\u00fcller",
      "Kemal Rose"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2211.09439"
  },
  {
    "id": "arXiv:2211.09462",
    "title": "RDRN: Recursively Defined Residual Network for Image Super-Resolution",
    "abstract": "Deep convolutional neural networks (CNNs) have obtained remarkable\nperformance in single image super-resolution (SISR). However, very deep\nnetworks can suffer from training difficulty and hardly achieve further\nperformance gain. There are two main trends to solve that problem: improving\nthe network architecture for better propagation of features through large\nnumber of layers and designing an attention mechanism for selecting most\ninformative features. Recent SISR solutions propose advanced attention and\nself-attention mechanisms. However, constructing a network to use an attention\nblock in the most efficient way is a challenging problem. To address this\nissue, we propose a general recursively defined residual block (RDRB) for\nbetter feature extraction and propagation through network layers. Based on RDRB\nwe designed recursively defined residual network (RDRN), a novel network\narchitecture which utilizes attention blocks efficiently. Extensive experiments\nshow that the proposed model achieves state-of-the-art results on several\npopular super-resolution benchmarks and outperforms previous methods by up to\n0.43 dB.",
    "descriptor": "\nComments: Accepted to ACCV 2022\n",
    "authors": [
      "Alexander Panaetov",
      "Karim Elhadji Daou",
      "Igor Samenko",
      "Evgeny Tetin",
      "Ilya Ivanov"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09462"
  },
  {
    "id": "arXiv:2211.09463",
    "title": "Why are there six degrees of separation in a social network?",
    "abstract": "A wealth of evidence shows that real world networks are endowed with the\nsmall-world property i.e., that the maximal distance between any two of their\nnodes scales logarithmically rather than linearly with their size. In addition,\nmost social networks are organized so that no individual is more than six\nconnections apart from any other, an empirical regularity known as the six\ndegrees of separation. Why social networks have this ultra-small world\norganization, whereby the graph's diameter is independent of the network size\nover several orders of magnitude, is still unknown. Here we show that the 'six\ndegrees of separation' are the property featured by the equilibrium state of\nany network where individuals weigh between their aspiration to improve their\ncentrality and the costs incurred in forming and maintaining connections. Thus,\nour results show how simple evolutionary rules of the kind traditionally\nassociated with human cooperation and altruism can also account for the\nemergence of one of the most intriguing attributes of social networks.",
    "descriptor": "\nComments: 15 pages, 6 figures\n",
    "authors": [
      "Ivan Samoylenko",
      "David Aleja",
      "Eva Primo",
      "Karin Alfaro-Bittner",
      "Ekaterina Vasilyeva",
      "Kirill Kovalenko",
      "Daniil Musatov",
      "Andreii M. Raigorodskii",
      "Regino Criado",
      "Miguel Romance",
      "David Papo",
      "Matjaz Perc",
      "Baruch Barzel",
      "Stefano Boccaletti"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.09463"
  },
  {
    "id": "arXiv:2211.09478",
    "title": "Parameterization of state duration in Hidden semi-Markov Models: an  application in electrocardiography",
    "abstract": "This work aims at providing a new model for time series classification based\non learning from just one example. We assume that time series can be well\ncharacterized as a parametric random process, a sort of Hidden semi-Markov\nModel representing a sequence of regression models with variable duration. We\nintroduce a parametric stochastic model for time series pattern recognition and\nprovide a maximum-likelihood estimation of its parameters. Particularly, we are\ninterested in examining two different representations for state duration: i) a\ndiscrete density distribution requiring an estimate for each possible duration;\nand ii) a parametric family of continuous density functions, here the Gamma\ndistribution, with just two parameters to estimate. An application on heartbeat\nclassification reveals the main strengths and weaknesses of each alternative.",
    "descriptor": "\nComments: 9 pages, 3 figures\n",
    "authors": [
      "Adri\u00e1n P\u00e9rez Herrero",
      "Paulo F\u00e9lix Lamas",
      "Jes\u00fas Mar\u00eda Rodr\u00edguez Presedo"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.09478"
  },
  {
    "id": "arXiv:2211.09481",
    "title": "Optimization on the symplectic Stiefel manifold: SR decomposition-based  retraction and applications",
    "abstract": "Numerous problems in optics, quantum physics, stability analysis, and control\nof dynamical systems can be brought to an optimization problem with matrix\nvariable subjected to the symplecticity constraint. As this constraint nicely\nforms a so-called symplectic Stiefel manifold, Riemannian optimization is\npreferred, because one can borrow ideas from unconstrained optimization methods\nafter preparing necessary geometric tools. Retraction is arguably the most\nimportant one which decides the way iterates are updated given a search\ndirection. Two retractions have been constructed so far: one relies on the\nCayley transform and the other is designed using quasi-geodesic curves. In this\npaper, we propose a new retraction which is based on an SR matrix\ndecomposition. We prove that its domain contains the open unit ball which is\nessential in proving the global convergence of the associated gradient-based\noptimization algorithm. Moreover, we consider three applications--symplectic\ntarget matrix problem, symplectic eigenvalue computation, and symplectic model\nreduction of Hamiltonian systems--with various examples. The extensive\nnumerical comparisons reveal the strengths of the proposed optimization\nalgorithm.",
    "descriptor": "\nComments: 30 pages, 11 figures\n",
    "authors": [
      "Bin Gao",
      "Nguyen Thanh Son",
      "Tatjana Stykel"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.09481"
  },
  {
    "id": "arXiv:2211.09496",
    "title": "EmoDiff: Intensity Controllable Emotional Text-to-Speech with Soft-Label  Guidance",
    "abstract": "Although current neural text-to-speech (TTS) models are able to generate\nhigh-quality speech, intensity controllable emotional TTS is still a\nchallenging task. Most existing methods need external optimizations for\nintensity calculation, leading to suboptimal results or degraded quality. In\nthis paper, we propose EmoDiff, a diffusion-based TTS model where emotion\nintensity can be manipulated by a proposed soft-label guidance technique\nderived from classifier guidance. Specifically, instead of being guided with a\none-hot vector for the specified emotion, EmoDiff is guided with a soft label\nwhere the value of the specified emotion and \\textit{Neutral} is set to\n$\\alpha$ and $1-\\alpha$ respectively. The $\\alpha$ here represents the emotion\nintensity and can be chosen from 0 to 1. Our experiments show that EmoDiff can\nprecisely control the emotion intensity while maintaining high voice quality.\nMoreover, diverse speech with specified emotion intensity can be generated by\nsampling in the reverse denoising process.",
    "descriptor": "\nComments: Submitted to ICASSP2023\n",
    "authors": [
      "Yiwei Guo",
      "Chenpeng Du",
      "Xie Chen",
      "Kai Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.09496"
  },
  {
    "id": "arXiv:2211.09512",
    "title": "Holistic Adaptive Controller and Observer Design Using the Koopman  Operator",
    "abstract": "We present a method for designing a data-driven Koopman-operator-based model\nthat adapts itself during operation and can be straightforwardly used for the\ncontroller and observer design. The recursive model is able to accurately\ndescribe different regions of the state space and additionally consider the\noccurrence of unpredictable system changes during operation. Furthermore, we\nshow that this adaptive model is applicable to state-space control, which\nrequires complete knowledge of the state vector. For changing system dynamics,\nthe state observer therefore also needs to have the ability to adapt. To the\nbest of our knowledge, there have been no approaches presently available that\nholistically use an adaptive Koopman-based plant model for the design of a\nstate-space controller and observer. We demonstrate our method on a test rig:\nthe controller and the observer adequately adapt during operation so that\noutstanding control performance is achieved even in the presence of strong\nsystems changes that occur.",
    "descriptor": "\nComments: This work has been submitted to IFAC for possible publication\n",
    "authors": [
      "Annika Junker",
      "Keno Pape",
      "Julia Timmermann",
      "Ansgar Tr\u00e4chtler"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.09512"
  },
  {
    "id": "arXiv:2211.09531",
    "title": "Cross-inhibition leads to group consensus despite the presence of  strongly opinionated minorities and asocial behaviour",
    "abstract": "Strongly opinionated minorities can have a dramatic impact on the opinion\ndynamics of a large population. Two factions of inflexible minorities,\npolarised into two competing opinions, could lead the entire population to\npersistent indecision. Equivalently, populations can remain undecided when\nindividuals sporadically change their opinion based on individual information\nrather than social information. Our analysis compares the cross-inhibition\nmodel with the voter model for decisions between equally good alternatives, and\nwith the weighted voter model for decisions among alternatives characterised by\ndifferent qualities. Here we show that cross-inhibition, differently from the\nother two models, is a simple mechanism, ubiquitous in collective biological\nsystems, that allows the population to reach a stable majority for one\nalternative even in the presence of asocial behaviour. The results predicted by\nthe mean-field models are confirmed by experiments with swarms of 100 locally\ninteracting robots. This work suggests an answer to the longstanding question\nof why inhibitory signals are widespread in natural systems of collective\ndecision making, and, at the same time, it proposes an efficient mechanism for\ndesigning resilient swarms of minimalistic robots.",
    "descriptor": "",
    "authors": [
      "Andreagiovanni Reina",
      "Raina Zakir",
      "Giulia De Masi",
      "Eliseo Ferrante"
    ],
    "subjectives": [
      "Biological Physics (physics.bio-ph)",
      "Multiagent Systems (cs.MA)",
      "Analysis of PDEs (math.AP)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2211.09531"
  },
  {
    "id": "arXiv:2211.09533",
    "title": "Parameter-Efficient Transformer with Hybrid Axial-Attention for Medical  Image Segmentation",
    "abstract": "Transformers have achieved remarkable success in medical image analysis owing\nto their powerful capability to use flexible self-attention mechanism. However,\ndue to lacking intrinsic inductive bias in modeling visual structural\ninformation, they generally require a large-scale pre-training schedule,\nlimiting the clinical applications over expensive small-scale medical data. To\nthis end, we propose a parameter-efficient transformer to explore intrinsic\ninductive bias via position information for medical image segmentation.\nSpecifically, we empirically investigate how different position encoding\nstrategies affect the prediction quality of the region of interest (ROI), and\nobserve that ROIs are sensitive to the position encoding strategies. Motivated\nby this, we present a novel Hybrid Axial-Attention (HAA), a form of position\nself-attention that can be equipped with spatial pixel-wise information and\nrelative position information as inductive bias. Moreover, we introduce a\ngating mechanism to alleviate the burden of training schedule, resulting in\nefficient feature selection over small-scale datasets. Experiments on the BraTS\nand Covid19 datasets prove the superiority of our method over the baseline and\nprevious works. Internal workflow visualization with interpretability is\nconducted to better validate our success.",
    "descriptor": "",
    "authors": [
      "Yiyue Hu",
      "Lei Zhang",
      "Nan Mu",
      "Lei Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09533"
  },
  {
    "id": "arXiv:2211.09535",
    "title": "Proactively Predicting Dynamic 6G Link Blockages Using LiDAR and In-Band  Signatures",
    "abstract": "Line-of-sight link blockages represent a key challenge for the reliability\nand latency of millimeter wave (mmWave) and terahertz (THz) communication\nnetworks. To address this challenge, this paper leverages mmWave and LiDAR\nsensory data to provide awareness about the communication environment and\nproactively predict dynamic link blockages before they occur. This allows the\nnetwork to make proactive decisions for hand-off/beam switching, enhancing the\nnetwork reliability and latency. More specifically, this paper addresses the\nfollowing key questions: (i) Can we predict a line-of-sight link blockage,\nbefore it happens, using in-band mmWave/THz signal and LiDAR sensing data? (ii)\nCan we also predict when this blockage will occur? (iii) Can we predict the\nblockage duration? And (iv) can we predict the direction of the moving\nblockage? For that, we develop machine learning solutions that learn special\npatterns of the received signal and sensory data, which we call\n\\textit{pre-blockage signatures}, to infer future blockages. To evaluate the\nproposed approaches, we build a large-scale real-world dataset that comprises\nco-existing LiDAR and mmWave communication measurements in outdoor vehicular\nscenarios. Then, we develop an efficient LiDAR data denoising algorithm that\napplies some pre-processing to the LiDAR data. Based on the real-world dataset,\nthe developed approaches are shown to achieve above 95\\% accuracy in predicting\nblockages occurring within 100 ms and more than 80\\% prediction accuracy for\nblockages occurring within one second. Given this future blockage prediction\ncapability, the paper also shows that the developed solutions can achieve an\norder of magnitude saving in network latency, which further highlights the\npotential of the developed blockage prediction solutions for wireless networks.",
    "descriptor": "\nComments: Submitted to IEEE. The dataset is available on the DeepSense 6G website: this http URL arXiv admin note: text overlap with arXiv:2111.09581, arXiv:2111.08242\n",
    "authors": [
      "Shunyao Wu",
      "Chaitali Chakrabarti",
      "Ahmed Alkhateeb"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.09535"
  },
  {
    "id": "arXiv:2211.09541",
    "title": "Locating Hidden Exoplanets in ALMA Data Using Machine Learning",
    "abstract": "Exoplanets in protoplanetary disks cause localized deviations from Keplerian\nvelocity in channel maps of molecular line emission. Current methods of\ncharacterizing these deviations are time consuming, and there is no unified\nstandard approach. We demonstrate that machine learning can quickly and\naccurately detect the presence of planets. We train our model on synthetic\nimages generated from simulations and apply it to real observations to identify\nforming planets in real systems. Machine learning methods, based on computer\nvision, are not only capable of correctly identifying the presence of one or\nmore planets, but they can also correctly constrain the location of those\nplanets.",
    "descriptor": "\nComments: 12 pages, 9 figures, 3 tables. Accepted to ApJ\n",
    "authors": [
      "Jason Terry",
      "Cassandra Hall",
      "Sean Abreau",
      "Sergei Gleyzer"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09541"
  },
  {
    "id": "arXiv:2211.09559",
    "title": "Interpretable HER2 scoring by evaluating clinical Guidelines through a  weakly supervised, constrained Deep Learning Approach",
    "abstract": "The evaluation of the Human Epidermal growth factor Receptor-2 (HER2)\nexpression is an important prognostic biomarker for breast cancer treatment\nselection. However, HER2 scoring has notoriously high interobserver variability\ndue to stain variations between centers and the need to estimate visually the\nstaining intensity in specific percentages of tumor area. In this paper,\nfocusing on the interpretability of HER2 scoring by a pathologist, we propose a\nsemi-automatic, two-stage deep learning approach that directly evaluates the\nclinical HER2 guidelines defined by the American Society of Clinical Oncology/\nCollege of American Pathologists (ASCO/CAP). In the first stage, we segment the\ninvasive tumor over the user-indicated Region of Interest (ROI). Then, in the\nsecond stage, we classify the tumor tissue into four HER2 classes. For the\nclassification stage, we use weakly supervised, constrained optimization to\nfind a model that classifies cancerous patches such that the tumor surface\npercentage meets the guidelines specification of each HER2 class. We end the\nsecond stage by freezing the model and refining its output logits in a\nsupervised way to all slide labels in the training set. To ensure the quality\nof our dataset's labels, we conducted a multi-pathologist HER2 scoring\nconsensus. For the assessment of doubtful cases where no consensus was found,\nour model can help by interpreting its HER2 class percentages output. We\nachieve a performance of 0.78 in F1-score on the test set while keeping our\nmodel interpretable for the pathologist, hopefully contributing to\ninterpretable AI models in digital pathology.",
    "descriptor": "\nComments: Submitted to Elsevier\n",
    "authors": [
      "Manh Dan Pham",
      "Cyprien Tilmant",
      "St\u00e9phanie Petit",
      "Isabelle Salmon",
      "Saima Ben Hadj",
      "Rutger H.J. Fick"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09559"
  },
  {
    "id": "arXiv:2211.09566",
    "title": "Enabling Collagen Quantification on HE-stained Slides Through Stain  Deconvolution and Restained HE-HES",
    "abstract": "In histology, the presence of collagen in the extra-cellular matrix has both\ndiagnostic and prognostic value for cancer malignancy, and can be highlighted\nby adding Saffron (S) to a routine Hematoxylin and Eosin (HE) staining.\nHowever, Saffron is not usually added because of the additional cost and\nbecause pathologists are accustomed to HE, with the exception of France-based\nlaboratories. In this paper, we show that it is possible to quantify the\ncollagen content from the HE image alone and to digitally create an HES image.\nTo do so, we trained a UNet to predict the Saffron densities from HE images. We\ncreated a dataset of registered, restained HE-HES slides and we extracted the\nSaffron concentrations as ground truth using stain deconvolution on the HES\nimages. Our model reached a Mean Absolute Error of 0.0668 $\\pm$ 0.0002 (Saffron\nvalues between 0 and 1) on a 3-fold testing set. We hope our approach can aid\nin improving the clinical workflow while reducing reagent costs for\nlaboratories.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Guillaume Balezo",
      "Christof A. Bertram",
      "Cyprien Tilmant",
      "St\u00e9phanie Petit",
      "Saima Ben Hadj",
      "Rutger H.J. Fick"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09566"
  },
  {
    "id": "arXiv:2211.09580",
    "title": "Quadrupole Magnet Design based on Genetic Multi-Objective Optimization",
    "abstract": "This work suggests to optimize the geometry of a quadrupole magnet by means\nof a genetic algorithm adapted to solve multi-objective optimization problems.\nTo that end, a non-domination sorting genetic algorithm known as NSGA-III is\nused. The optimization objectives are chosen such that a high magnetic field\nquality in the aperture of the magnet is guaranteed, while simultaneously the\nmagnet design remains cost-efficient. The field quality is computed using a\nmagnetostatic finite element model of the quadrupole, the results of which are\npost-processed and integrated into the optimization algorithm. An extensive\nanalysis of the optimization results is performed, including Pareto front\nmovements and identification of best designs.",
    "descriptor": "\nComments: 19 pages, 5 figures\n",
    "authors": [
      "Eric Diehl",
      "Moritz von Tresckow",
      "Lou Scholtissek",
      "Dimitrios Loukrezis",
      "Nicolas Marsic",
      "Wolfgang F. O. M\u00fcller",
      "Herbert De Gersem"
    ],
    "subjectives": [
      "Accelerator Physics (physics.acc-ph)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.09580"
  },
  {
    "id": "arXiv:2211.09591",
    "title": "Personal Privacy Protection Problems in the Digital Age",
    "abstract": "With the development of Internet technology, the issue of privacy leakage has\nattracted more and more attention from the public. In our daily life, mobile\nphone applications and identity documents that we use may bring the risk of\nprivacy leakage, which had increasingly aroused public concern. The path of\nprivacy protection in the digital age remains to be explored. To explore the\nsource of this risk and how it can be reduced, we conducted this study by using\npersonal experience, collecting data and applying the theory.",
    "descriptor": "\nComments: 9 pages, 3 figures\n",
    "authors": [
      "Zhiheng Yi",
      "Xiaoli Chen"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.09591"
  },
  {
    "id": "arXiv:2211.09602",
    "title": "Validation Diagnostics for SBI algorithms based on Normalizing Flows",
    "abstract": "Building on the recent trend of new deep generative models known as\nNormalizing Flows (NF), simulation-based inference (SBI) algorithms can now\nefficiently accommodate arbitrary complex and high-dimensional data\ndistributions. The development of appropriate validation methods however has\nfallen behind. Indeed, most of the existing metrics either require access to\nthe true posterior distribution, or fail to provide theoretical guarantees on\nthe consistency of the inferred approximation beyond the one-dimensional\nsetting. This work proposes easy to interpret validation diagnostics for\nmulti-dimensional conditional (posterior) density estimators based on NF. It\nalso offers theoretical guarantees based on results of local consistency. The\nproposed workflow can be used to check, analyse and guarantee consistent\nbehavior of the estimator. The method is illustrated with a challenging example\nthat involves tightly coupled parameters in the context of computational\nneuroscience. This work should help the design of better specified models or\ndrive the development of novel SBI-algorithms, hence allowing to build up trust\non their ability to address important questions in experimental science.",
    "descriptor": "\nComments: 7 pages, 2 figures, 1 appendix, to be published at \"Machine Learning and the Physical Sciences\" workshop (NeurIPS 2022)\n",
    "authors": [
      "Julia Linhart",
      "Alexandre Gramfort",
      "Pedro L. C. Rodrigues"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.09602"
  },
  {
    "id": "arXiv:2211.09613",
    "title": "Learning to Communicate with Intent: An Introduction",
    "abstract": "We propose a novel framework to learn how to communicate with intent, i.e.,\nto transmit messages over a wireless communication channel based on the\nend-goal of the communication. This stays in stark contrast to classical\ncommunication systems where the objective is to reproduce at the receiver side\neither exactly or approximately the message sent by the transmitter, regardless\nof the end-goal. Our procedure is general enough that can be adapted to any\ntype of goal or task, so long as the said task is a (almost-everywhere)\ndifferentiable function over which gradients can be propagated. We focus on\nsupervised learning and reinforcement learning (RL) tasks, and propose\nalgorithms to learn the communication system and the task jointly in an\nend-to-end manner. We then delve deeper into the transmission of images and\npropose two systems, one for the classification of images and a second one to\nplay an Atari game based on RL. The performance is compared with a joint source\nand channel coding (JSCC) communication system designed to minimize the\nreconstruction error, and results show overall great improvement. Further, for\nthe RL task, we show that while a JSCC strategy is not better than a random\naction selection strategy, with our approach we get close to the upper bound\neven for low SNRs.",
    "descriptor": "\nComments: 7 pages, 4 figues, submitted to IEEE ICC 2023\n",
    "authors": [
      "Miguel Angel Gutierrez-Estevez",
      "Yiqun Wu",
      "Chan Zhou"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.09613"
  },
  {
    "id": "arXiv:2211.09686",
    "title": "An efficient combination of quantum error correction and authentication",
    "abstract": "When sending quantum information over a channel, we want to ensure that the\nmessage remains intact. Quantum error correction and quantum authentication\nboth aim to protect (quantum) information, but approach this task from two very\ndifferent directions: error-correcting codes protect against probabilistic\nchannel noise and are meant to be very robust against small errors, while\nauthentication codes prevent adversarial attacks and are designed to be very\nsensitive against any error, including small ones.\nIn practice, when sending an authenticated state over a noisy channel, one\nwould have to wrap it in an error-correcting code to counterbalance the\nsensitivity of the underlying authentication scheme. We study the question of\nwhether this can be done more efficiently by combining the two functionalities\nin a single code. To illustrate the potential of such a combination, we design\nthe threshold code, a modification of the trap authentication code which\npreserves that code's authentication properties, but which is naturally robust\nagainst depolarizing channel noise. We show that the threshold code needs\npolylogarithmically fewer qubits to achieve the same level of security and\nrobustness, compared to the naive composition of the trap code with any\nconcatenated CSS code. We believe our analysis opens the door to combining more\ngeneral error-correction and authentication codes, which could improve the\npracticality of the resulting scheme.",
    "descriptor": "\nComments: 30 pages, 10 figures\n",
    "authors": [
      "Yfke Dulek",
      "Garazi Muguruza",
      "Florian Speelman"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.09686"
  },
  {
    "id": "arXiv:2211.09694",
    "title": "Thermodynamics of bidirectional associative memories",
    "abstract": "In this paper we investigate the equilibrium properties of bidirectional\nassociative memories (BAMs). Introduced by Kosko in 1988 as a generalization of\nthe Hopfield model to a bipartite structure, the simplest architecture is\ndefined by two layers of neurons, with synaptic connections only between units\nof different layers: even without internal connections within each layer,\ninformation storage and retrieval are still possible through the reverberation\nof neural activities passing from one layer to another. We characterize the\ncomputational capabilities of a stochastic extension of this model in the\nthermodynamic limit, by applying rigorous techniques from statistical physics.\nA detailed picture of the phase diagram at the replica symmetric level is\nprovided, both at finite temperature and in the noiseless regime. An analytical\nand numerical inspection of the transition curves (namely critical lines\nsplitting the various modes of operation of the machine) is carried out as the\ncontrol parameters - noise, load and asymmetry between the two layer sizes -\nare tuned. In particular, with a finite asymmetry between the two layers, it is\nshown how the BAM can store information more efficiently than the Hopfield\nmodel by requiring less parameters to encode a fixed number of patterns.\nComparisons are made with numerical simulations of neural dynamics. Finally, a\nlow-load analysis is carried out to explain the retrieval mechanism in the BAM\nby analogy with two interacting Hopfield models. A potential equivalence with\ntwo coupled Restricted Boltmzann Machines is also discussed.",
    "descriptor": "\nComments: 22 pages, 10 figures\n",
    "authors": [
      "Adriano Barra",
      "Giovanni Catania",
      "Aur\u00e9lien Decelle",
      "Beatriz Seoane"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.09694"
  },
  {
    "id": "arXiv:2211.09705",
    "title": "A Review of Deep Learning Techniques for Protein Function Prediction",
    "abstract": "Deep Learning and big data have shown tremendous success in bioinformatics\nand computational biology in recent years; artificial intelligence methods have\nalso significantly contributed in the task of protein function classification.\nThis review paper analyzes the recent developments in approaches for the task\nof predicting protein function using deep learning. We explain the importance\nof determining the protein function and why automating the following task is\ncrucial. Then, after reviewing the widely used deep learning techniques for\nthis task, we continue our review and highlight the emergence of the modern\nState of The Art (SOTA) deep learning models which have achieved groundbreaking\nresults in the field of computer vision, natural language processing and\nmulti-modal learning in the last few years. We hope that this review will\nprovide a broad view of the current role and advances of deep learning in\nbiological sciences, especially in predicting protein function tasks and\nencourage new researchers to contribute to this area.",
    "descriptor": "",
    "authors": [
      "Divyanshu Aggarwal",
      "Yasha Hasija"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09705"
  },
  {
    "id": "arXiv:2211.09715",
    "title": "Physics-informed neural networks for gravity currents reconstruction  from limited data",
    "abstract": "The present work investigates the use of physics-informed neural networks\n(PINNs) for the 3D reconstruction of unsteady gravity currents from limited\ndata. In the PINN context, the flow fields are reconstructed by training a\nneural network whose objective function penalizes the mismatch between the\nnetwork predictions and the observed data and embeds the underlying equations\nusing automatic differentiation. This study relies on a high-fidelity numerical\nexperiment of the canonical lock-exchange configuration. This allows us to\nbenchmark quantitatively the PINNs reconstruction capabilities on several\ntraining databases that mimic state-of-the-art experimental measurement\ntechniques for density and velocity. Notably, spatially averaged density\nmeasurements by light attenuation technique (LAT) are employed for the training\nprocedure. An optimal experimental setup for flow reconstruction by PINNs is\nproposed according to two criteria : the implementation complexity and the\naccuracy of the inferred fields.",
    "descriptor": "",
    "authors": [
      "Micka\u00ebl Delcey",
      "Yoann Cheny",
      "S\u00e9bastien Kiesgen de Richter"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09715"
  },
  {
    "id": "arXiv:2211.09727",
    "title": "A Survey on Evaluation Metrics for Synthetic Material Micro-Structure  Images from Generative Models",
    "abstract": "The evaluation of synthetic micro-structure images is an emerging problem as\nmachine learning and materials science research have evolved together. Typical\nstate of the art methods in evaluating synthetic images from generative models\nhave relied on the Fr\\'echet Inception Distance. However, this and other\nsimilar methods, are limited in the materials domain due to both the unique\nfeatures that characterize physically accurate micro-structures and limited\ndataset sizes. In this study we evaluate a variety of methods on scanning\nelectron microscope (SEM) images of graphene-reinforced polyurethane foams. The\nprimary objective of this paper is to report our findings with regards to the\nshortcomings of existing methods so as to encourage the machine learning\ncommunity to consider enhancements in metrics for assessing quality of\nsynthetic images in the material science domain.",
    "descriptor": "\nComments: Accepted in Neural Information Processing Systems (NeurIPS) 2022 Workshop on AI for Accelerated Materials Design (AI4Mat). Selected as spotlight paper for workshop\n",
    "authors": [
      "Devesh Shah",
      "Anirudh Suresh",
      "Alemayehu Admasu",
      "Devesh Upadhyay",
      "Kalyanmoy Deb"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.09727"
  },
  {
    "id": "arXiv:2211.09735",
    "title": "Behavior Score-Embedded Brain Encoder Network for Improved  Classification of Alzheimer Disease Using Resting State fMRI",
    "abstract": "The ability to accurately detect onset of dementia is important in the\ntreatment of the disease. Clinically, the diagnosis of Alzheimer Disease (AD)\nand Mild Cognitive Impairment (MCI) patients are based on an integrated\nassessment of psychological tests and brain imaging such as positron emission\ntomography (PET) and anatomical magnetic resonance imaging (MRI). In this work\nusing two different datasets, we propose a behavior score-embedded encoder\nnetwork (BSEN) that integrates regularly adminstrated psychological tests\ninformation into the encoding procedure of representing subject's restingstate\nfMRI data for automatic classification tasks. BSEN is based on a 3D\nconvolutional autoencoder structure with contrastive loss jointly optimized\nusing behavior scores from MiniMental State Examination (MMSE) and Clinical\nDementia Rating (CDR). Our proposed classification framework of using BSEN\nachieved an overall recognition accuracy of 59.44% (3-class classification: AD,\nMCI and Healthy Control), and we further extracted the most discriminative\nregions between healthy control (HC) and AD patients.",
    "descriptor": "\nComments: 4 pages, 1 figure\n",
    "authors": [
      "Wan-Ting Hsieh",
      "Jeremy Lefort-Besnard",
      "Hao-Chun Yang",
      "Li-Wei Kuo",
      "Chi-Chun Lee"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09735"
  },
  {
    "id": "arXiv:2211.09756",
    "title": "An Advantage Using Feature Selection with a Quantum Annealer",
    "abstract": "Feature selection is a technique in statistical prediction modeling that\nidentifies features in a record with a strong statistical connection to the\ntarget variable. Excluding features with a weak statistical connection to the\ntarget variable in training not only drops the dimension of the data, which\ndecreases the time complexity of the algorithm, it also decreases noise within\nthe data which assists in avoiding overfitting. In all, feature selection\nassists in training a robust statistical model that performs well and is\nstable. Given the lack of scalability in classical computation, current\ntechniques only consider the predictive power of the feature and not redundancy\nbetween the features themselves. Recent advancements in feature selection that\nleverages quantum annealing (QA) gives a scalable technique that aims to\nmaximize the predictive power of the features while minimizing redundancy. As a\nconsequence, it is expected that this algorithm would assist in the\nbias/variance trade-off yielding better features for training a statistical\nmodel. This paper tests this intuition against classical methods by utilizing\nopen-source data sets and evaluate the efficacy of each trained statistical\nmodel well-known prediction algorithms. The numerical results display an\nadvantage utilizing the features selected from the algorithm that leveraged QA.",
    "descriptor": "",
    "authors": [
      "Andrew Vlasic",
      "Grant Hunter",
      "Salvatore Certo"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09756"
  },
  {
    "id": "arXiv:2211.09767",
    "title": "Understanding and eliminating spurious modes in variational Monte Carlo  using collective variables",
    "abstract": "The use of neural network parametrizations to represent the ground state in\nvariational Monte Carlo (VMC) calculations has generated intense interest in\nrecent years. However, as we demonstrate in the context of the periodic\nHeisenberg spin chain, this approach can produce unreliable wave function\napproximations. One of the most obvious signs of failure is the occurrence of\nrandom, persistent spikes in the energy estimate during training. These energy\nspikes are caused by regions of configuration space that are over-represented\nby the wave function density, which are called ``spurious modes'' in the\nmachine learning literature. After exploring these spurious modes in detail, we\ndemonstrate that a collective-variable-based penalization yields a\nsubstantially more robust training procedure, preventing the formation of\nspurious modes and improving the accuracy of energy estimates. Because the\npenalization scheme is cheap to implement and is not specific to the particular\nmodel studied here, it can be extended to other applications of VMC where a\nreasonable choice of collective variable is available.",
    "descriptor": "\nComments: 12 pages, 13 figures\n",
    "authors": [
      "Huan Zhang",
      "Robert J. Webber",
      "Michael Lindsey",
      "Timothy C. Berkelbach",
      "Jonathan Weare"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.09767"
  },
  {
    "id": "arXiv:2211.09769",
    "title": "DeepSense 6G: A Large-Scale Real-World Multi-Modal Sensing and  Communication Dataset",
    "abstract": "This article presents the DeepSense 6G dataset, which is a large-scale\ndataset based on real-world measurements of co-existing multi-modal sensing and\ncommunication data. The DeepSense 6G dataset is built to advance deep learning\nresearch in a wide range of applications in the intersection of multi-modal\nsensing, communication, and positioning. This article provides a detailed\noverview of the DeepSense dataset structure, adopted testbeds, data collection\nand processing methodology, deployment scenarios, and example applications,\nwith the objective of facilitating the adoption and reproducibility of\nmulti-modal sensing and communication datasets.",
    "descriptor": "\nComments: The dataset is available on the DeepSense 6G website this http URL\n",
    "authors": [
      "Ahmed Alkhateeb",
      "Gouranga Charan",
      "Tawfik Osman",
      "Andrew Hredzak",
      "Jo\u00e3o Morais",
      "Umut Demirhan",
      "Nikhil Srinivas"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09769"
  },
  {
    "id": "arXiv:2211.09781",
    "title": "Monitoring machine learning (ML)-based risk prediction algorithms in the  presence of confounding medical interventions",
    "abstract": "Monitoring the performance of machine learning (ML)-based risk prediction\nmodels in healthcare is complicated by the issue of confounding medical\ninterventions (CMI): when an algorithm predicts a patient to be at high risk\nfor an adverse event, clinicians are more likely to administer prophylactic\ntreatment and alter the very target that the algorithm aims to predict.\nIgnoring CMI by monitoring only the untreated patients--whose outcomes remain\nunaltered--can inflate false alarm rates, because the evolution of both the\nmodel and clinician-ML interactions can induce complex dependencies in the data\nthat violate standard assumptions. A more sophisticated approach is to\nexplicitly account for CMI by modeling treatment propensities, but its\ntime-varying nature makes accurate estimation difficult. Given the many sources\nof complexity in the data, it is important to determine situations in which a\nsimple procedure that ignores CMI provides valid inference. Here we describe\nthe special case of monitoring model calibration, under either the assumption\nof conditional exchangeability or time-constant selection bias. We introduce a\nnew score-based cumulative sum (CUSUM) chart for monitoring in a frequentist\nframework and review an alternative approach using Bayesian inference. Through\nsimulations, we investigate the benefits of combining model updating with\nmonitoring and study when over-trust in a prediction model does (or does not)\ndelay detection. Finally, we simulate monitoring an ML-based postoperative\nnausea and vomiting risk calculator during the COVID-19 pandemic.",
    "descriptor": "",
    "authors": [
      "Jean Feng",
      "Alexej Gossmann",
      "Gene Pennello",
      "Nicholas Petrick",
      "Berkman Sahiner",
      "Romain Pirracchio"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09781"
  },
  {
    "id": "arXiv:2211.09801",
    "title": "Machine Learned Calabi--Yau Metrics and Curvature",
    "abstract": "Finding Ricci-flat (Calabi--Yau) metrics is a long standing problem in\ngeometry with deep implications for string theory and phenomenology. A new\nattack on this problem uses neural networks to engineer approximations to the\nCalabi--Yau metric within a given K\\\"ahler class. In this paper we investigate\nnumerical Ricci-flat metrics over smooth and singular K3 surfaces and\nCalabi--Yau threefolds. Using these Ricci-flat metric approximations for the\nCefal\\'u and Dwork family of quartic twofolds and the Dwork family of quintic\nthreefolds, we study characteristic forms on these geometries. Using persistent\nhomology, we show that high curvature regions of the manifolds form clusters\nnear the singular points, but also elsewhere. For our neural network\napproximations, we observe a Bogomolov--Yau type inequality $3c_2 \\geq c_1^2$\nand observe an identity when our geometries have isolated $A_1$ type\nsingularities. We sketch a proof that\n$\\chi(X~\\smallsetminus~\\mathrm{Sing}\\,{X}) + 2~|\\mathrm{Sing}\\,{X}| = 24$ also\nholds for our numerical approximations.",
    "descriptor": "\nComments: 36 pages, 21 figures, 7 tables, 2 appendices\n",
    "authors": [
      "Per Berglund",
      "Giorgi Butbaia",
      "Tristan H\u00fcbsch",
      "Vishnu Jejjala",
      "Dami\u00e1n Mayorga Pe\u00f1a",
      "Challenger Mishra",
      "Justin Tan"
    ],
    "subjectives": [
      "High Energy Physics - Theory (hep-th)",
      "Machine Learning (cs.LG)",
      "Algebraic Geometry (math.AG)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2211.09801"
  },
  {
    "id": "arXiv:2211.09806",
    "title": "Mapping Tropical Forest Cover and Deforestation with Planet NICFI  Satellite Images and Deep Learning in Mato Grosso State (Brazil) from 2015 to  2021",
    "abstract": "Monitoring changes in tree cover for rapid assessment of deforestation is\nconsidered the critical component of any climate mitigation policy for reducing\ncarbon. Here, we map tropical tree cover and deforestation between 2015 and\n2022 using 5 m spatial resolution Planet NICFI satellite images over the state\nof Mato Grosso (MT) in Brazil and a U-net deep learning model. The tree cover\nfor the state was 556510.8 km$^2$ in 2015 (58.1 % of the MT State) and was\nreduced to 141598.5 km$^2$ (14.8 % of total area) at the end of 2021. After\nreaching a minimum deforested area in December 2016 with 6632.05 km$^2$, the\nbi-annual deforestation area only showed a slight increase between December\n2016 and December 2019. A year after, the areas of deforestation almost doubled\nfrom 9944.5 km$^2$ in December 2019 to 19817.8 km$^2$ in December 2021. The\nhigh-resolution data product showed relatively consistent agreement with the\nofficial deforestation map from Brazil (67.2%) but deviated significantly from\nyear of forest cover loss estimates from the Global Forest change (GFC)\nproduct, mainly due to large area of fire degradation observed in the GFC data.\nHigh-resolution imagery from Planet NICFI associated with deep learning\ntechnics can significantly improve mapping deforestation extent in tropics.",
    "descriptor": "\nComments: 18 pages, 10 figures, submitted to Remote Sensing MDPI, Special Issue \"Remote Sensing of the Amazon Region\"\n",
    "authors": [
      "Fabien H Wagner",
      "Ricardo Dalagnol",
      "Celso HL Silva-Junior",
      "Griffin Carter",
      "Alison L Ritz",
      "Mayumi CM Hirye",
      "Jean PHB Ometto",
      "Sassan Saatchi"
    ],
    "subjectives": [
      "Earth and Planetary Astrophysics (astro-ph.EP)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09806"
  },
  {
    "id": "arXiv:2003.02475",
    "title": "Optimal Discretization is Fixed-parameter Tractable",
    "abstract": "Comments: Accepted to ACM-SIAM Symposium on Discrete Algorithms (SODA 2021). 53 pages, 18 figures",
    "descriptor": "\nComments: Accepted to ACM-SIAM Symposium on Discrete Algorithms (SODA 2021). 53 pages, 18 figures\n",
    "authors": [
      "Stefan Kratsch",
      "Tom\u00e1\u0161 Masa\u0159\u00edk",
      "Irene Muzi",
      "Marcin Pilipczuk",
      "Manuel Sorge"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2003.02475"
  },
  {
    "id": "arXiv:2005.13335",
    "title": "Optimal control of nonlinear systems with unsymmetrical input  constraints and its applications to the UAV circumnavigation problem",
    "abstract": "Optimal control of nonlinear systems with unsymmetrical input  constraints and its applications to the UAV circumnavigation problem",
    "descriptor": "",
    "authors": [
      "Yangguang Yu",
      "Xiangke Wang",
      "Zhiyong Sun",
      "Lincheng Shen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2005.13335"
  },
  {
    "id": "arXiv:2007.03762",
    "title": "Transfer Learning for Electricity Price Forecasting",
    "abstract": "Transfer Learning for Electricity Price Forecasting",
    "descriptor": "",
    "authors": [
      "Salih Gunduz",
      "Umut Ugurlu",
      "Ilkay Oksuz"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.03762"
  },
  {
    "id": "arXiv:2007.08284",
    "title": "Area- Efficient VLSI Implementation of Serial-In Parallel-Out Multiplier  Using Polynomial Representation in Finite Field GF(2m)",
    "abstract": "Comments: 19 pages, 4 figures",
    "descriptor": "\nComments: 19 pages, 4 figures\n",
    "authors": [
      "Saeideh Nabipour",
      "Gholamreza Zare Fatin",
      "Javad Javidan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2007.08284"
  },
  {
    "id": "arXiv:2010.15315",
    "title": "Exploring Generative Adversarial Networks for Image-to-Image Translation  in STEM Simulation",
    "abstract": "Exploring Generative Adversarial Networks for Image-to-Image Translation  in STEM Simulation",
    "descriptor": "",
    "authors": [
      "Nick Lawrence",
      "Mingren Shen",
      "Ruiqi Yin",
      "Cloris Feng",
      "Dane Morgan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2010.15315"
  },
  {
    "id": "arXiv:2011.08790",
    "title": "P1AC: Revisiting Absolute Pose From a Single Affine Correspondence",
    "abstract": "P1AC: Revisiting Absolute Pose From a Single Affine Correspondence",
    "descriptor": "",
    "authors": [
      "Jonathan Ventura",
      "Zuzana Kukelova",
      "Torsten Sattler",
      "D\u00e1niel Bar\u00e1th"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.08790"
  },
  {
    "id": "arXiv:2101.02405",
    "title": "Adaptive Group Testing on Networks with Community Structure: The  Stochastic Block Model",
    "abstract": "Comments: 27 pages, 5 figures. Presented in part at the 2021 IEEE International Symposium on Information Theory (ISIT). Restructured the paper and added new results for the noisy setting",
    "descriptor": "\nComments: 27 pages, 5 figures. Presented in part at the 2021 IEEE International Symposium on Information Theory (ISIT). Restructured the paper and added new results for the noisy setting\n",
    "authors": [
      "Surin Ahn",
      "Wei-Ning Chen",
      "Ayfer Ozgur"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2101.02405"
  },
  {
    "id": "arXiv:2103.15938",
    "title": "Safe Model-based Control from Signal Temporal Logic Specifications Using  Recurrent Neural Networks",
    "abstract": "Comments: Submitted to ICRA 2023",
    "descriptor": "\nComments: Submitted to ICRA 2023\n",
    "authors": [
      "Wenliang Liu",
      "Mirai Nishioka",
      "Calin Belta"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.15938"
  },
  {
    "id": "arXiv:2104.00762",
    "title": "Flexible Instruction-Set Semantics via Type Classes",
    "abstract": "Flexible Instruction-Set Semantics via Type Classes",
    "descriptor": "",
    "authors": [
      "Thomas Bourgeat",
      "Ian Clester",
      "Andres Erbsen",
      "Samuel Gruetter",
      "Pratap Singh",
      "Andrew Wright",
      "Adam Chlipala"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2104.00762"
  },
  {
    "id": "arXiv:2105.00924",
    "title": "Bird-Area Water-Bodies Dataset (BAWD) and Predictive AI Model for Avian  Botulism Outbreak (AVI-BoT)",
    "abstract": "Bird-Area Water-Bodies Dataset (BAWD) and Predictive AI Model for Avian  Botulism Outbreak (AVI-BoT)",
    "descriptor": "",
    "authors": [
      "Narayani Bhatia",
      "Devang Mahesh",
      "Jashandeep Singh",
      "Manan Suri"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.00924"
  },
  {
    "id": "arXiv:2105.09837",
    "title": "Towards Quantized Model Parallelism for Graph-Augmented MLPs Based on  Gradient-Free ADMM Framework",
    "abstract": "Comments: Accepted by the IEEE Transactions on Neural Networks and Learning Systems (TNNLS). arXiv admin note: substantial text overlap with arXiv:2009.02868",
    "descriptor": "\nComments: Accepted by the IEEE Transactions on Neural Networks and Learning Systems (TNNLS). arXiv admin note: substantial text overlap with arXiv:2009.02868\n",
    "authors": [
      "Junxiang Wang",
      "Hongyi Li",
      "Zheng Chai",
      "Yongchao Wang",
      "Yue Cheng",
      "Liang Zhao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.09837"
  },
  {
    "id": "arXiv:2105.12758",
    "title": "Testing symmetry on quantum computers",
    "abstract": "Comments: v2: 48 pages, various enhancements, including several examples and simulations of algorithms",
    "descriptor": "\nComments: v2: 48 pages, various enhancements, including several examples and simulations of algorithms\n",
    "authors": [
      "Margarite L. LaBorde",
      "Soorya Rethinasamy",
      "Mark M. Wilde"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2105.12758"
  },
  {
    "id": "arXiv:2106.16091",
    "title": "Exploring the Latent Space of Autoencoders with Interventional Assays",
    "abstract": "Comments: Published in NeurIPS 2022 Conference Proceedings",
    "descriptor": "\nComments: Published in NeurIPS 2022 Conference Proceedings\n",
    "authors": [
      "Felix Leeb",
      "Stefan Bauer",
      "Michel Besserve",
      "Bernhard Sch\u00f6lkopf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.16091"
  },
  {
    "id": "arXiv:2107.01384",
    "title": "ATC: an Advanced Tucker Compression library for multidimensional data",
    "abstract": "Comments: The ATC software is publicly available at the following repository: this https URL",
    "descriptor": "\nComments: The ATC software is publicly available at the following repository: this https URL\n",
    "authors": [
      "Wouter Baert",
      "Nick Vannieuwenhoven"
    ],
    "subjectives": [
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2107.01384"
  },
  {
    "id": "arXiv:2107.02762",
    "title": "Area-Delay-Efficeint FPGA Design of 32-bit Euclid's GCD based on Sum of  Absolute Difference",
    "abstract": "Area-Delay-Efficeint FPGA Design of 32-bit Euclid's GCD based on Sum of  Absolute Difference",
    "descriptor": "",
    "authors": [
      "Saeideh Nabipour",
      "Masoume Gholizade",
      "Nima Nabipour"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.02762"
  },
  {
    "id": "arXiv:2107.06471",
    "title": "A priori subcell limiting based on compact nonuniform nonlinear weighted  schemes of high-order CPR method for hyperbolic conservation laws",
    "abstract": "Comments: 50 pages",
    "descriptor": "\nComments: 50 pages\n",
    "authors": [
      "Huajun Zhu",
      "Huayong Liu",
      "Zhen-Guo Yan",
      "Guoquan Shi",
      "Xiaogang Deng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2107.06471"
  },
  {
    "id": "arXiv:2108.01612",
    "title": "An Efficient Digital Watermarking Algorithm Based on DCT and BCH Error  Correcting Code",
    "abstract": "An Efficient Digital Watermarking Algorithm Based on DCT and BCH Error  Correcting Code",
    "descriptor": "",
    "authors": [
      "Saeideh Nabipour",
      "Javad Javidan",
      "Majid Khorrami",
      "Jila Azimzadeh"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2108.01612"
  },
  {
    "id": "arXiv:2108.05240",
    "title": "Signaling Games in Multiple Dimensions: Geometric Properties of  Equilibrium Solutions",
    "abstract": "Comments: 17 pages and 6 figures",
    "descriptor": "\nComments: 17 pages and 6 figures\n",
    "authors": [
      "Ertan Kaz\u0131kl\u0131",
      "Sinan Gezici",
      "Serdar Y\u00fcksel"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2108.05240"
  },
  {
    "id": "arXiv:2108.12722",
    "title": "Feature Extraction for Machine Learning-based Intrusion Detection in IoT  Networks",
    "abstract": "Feature Extraction for Machine Learning-based Intrusion Detection in IoT  Networks",
    "descriptor": "",
    "authors": [
      "Mohanad Sarhan",
      "Siamak Layeghy",
      "Nour Moustafa",
      "Marcus Gallagher",
      "Marius Portmann"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.12722"
  },
  {
    "id": "arXiv:2110.02605",
    "title": "Computational lower bounds of the Maxwell eigenvalues",
    "abstract": "Computational lower bounds of the Maxwell eigenvalues",
    "descriptor": "",
    "authors": [
      "Dietmar Gallistl",
      "Vladislav Olkhovskiy"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.02605"
  },
  {
    "id": "arXiv:2110.04598",
    "title": "Self-explaining Neural Network with Concept-based Explanations for ICU  Mortality Prediction",
    "abstract": "Comments: Workshop on Interpretable ML in Healthcare at International Conference on Machine Learning (ICML 2022)",
    "descriptor": "\nComments: Workshop on Interpretable ML in Healthcare at International Conference on Machine Learning (ICML 2022)\n",
    "authors": [
      "Sayantan Kumar",
      "Sean C. Yu",
      "Thomas Kannampallil",
      "Zachary Abrams",
      "Andrew Michelson",
      "Philip R.O. Payne"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04598"
  },
  {
    "id": "arXiv:2110.04903",
    "title": "Normative Modeling on Multimodal Neuroimaging Data using Variational  Autoencoders",
    "abstract": "Comments: Medical Imaging Meets NeurIPS workshop in NeurIPS 2022",
    "descriptor": "\nComments: Medical Imaging Meets NeurIPS workshop in NeurIPS 2022\n",
    "authors": [
      "Sayantan Kumar",
      "Philip Payne",
      "Aristeidis Sotiras"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04903"
  },
  {
    "id": "arXiv:2110.07210",
    "title": "Improve Cross-lingual Voice Cloning Using Low-quality Code-switched Data",
    "abstract": "Improve Cross-lingual Voice Cloning Using Low-quality Code-switched Data",
    "descriptor": "",
    "authors": [
      "Haitong Zhang",
      "Yue Lin"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.07210"
  },
  {
    "id": "arXiv:2110.12539",
    "title": "Discrete Acoustic Space for an Efficient Sampling in Neural  Text-To-Speech",
    "abstract": "Comments: 5 pages, 5 figures, accepted at IberSPEECH 2022",
    "descriptor": "\nComments: 5 pages, 5 figures, accepted at IberSPEECH 2022\n",
    "authors": [
      "Marek Strelec",
      "Jonas Rohnke",
      "Antonio Bonafonte",
      "Mateusz \u0141ajszczak",
      "Trevor Wood"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.12539"
  },
  {
    "id": "arXiv:2110.14003",
    "title": "Connected greedy colourings of perfect graphs and other classes: the  good, the bad and the ugly",
    "abstract": "Comments: 9 pages, 5 figures. Some errors fixed and more details added in this version",
    "descriptor": "\nComments: 9 pages, 5 figures. Some errors fixed and more details added in this version\n",
    "authors": [
      "Laurent Beaudou",
      "Caroline Brosse",
      "Oscar Defrain",
      "Florent Foucaud",
      "Aur\u00e9lie Lagoutte",
      "Vincent Limouzy",
      "Lucas Pastor"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2110.14003"
  },
  {
    "id": "arXiv:2111.08355",
    "title": "Hybrid Reflection Modulation",
    "abstract": "Comments: IEEE Transactions on Wireless Communications (to appear)",
    "descriptor": "\nComments: IEEE Transactions on Wireless Communications (to appear)\n",
    "authors": [
      "Zehra Yigit",
      "Ertugrul Basar",
      "Miaowen Wen",
      "Ibrahim Altunbas"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.08355"
  },
  {
    "id": "arXiv:2111.09159",
    "title": "Aggressive Q-Learning with Ensembles: Achieving Both High Sample  Efficiency and High Asymptotic Performance",
    "abstract": "Aggressive Q-Learning with Ensembles: Achieving Both High Sample  Efficiency and High Asymptotic Performance",
    "descriptor": "",
    "authors": [
      "Yanqiu Wu",
      "Xinyue Chen",
      "Che Wang",
      "Yiming Zhang",
      "Keith W. Ross"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.09159"
  },
  {
    "id": "arXiv:2112.03740",
    "title": "Dilated convolution with learnable spacings",
    "abstract": "Comments: 28 pages",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Ismail Khalfaoui-Hassani",
      "Thomas Pellegrini",
      "Timoth\u00e9e Masquelier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2112.03740"
  },
  {
    "id": "arXiv:2112.04855",
    "title": "An Australian DER Bill of Rights and Responsibilities",
    "abstract": "Comments: 21 pages, 1 figure, 1 table, 1 appendix",
    "descriptor": "\nComments: 21 pages, 1 figure, 1 table, 1 appendix\n",
    "authors": [
      "Niraj Lal",
      "Lee Brown"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.04855"
  },
  {
    "id": "arXiv:2112.13503",
    "title": "Under-Approximate Reachability Analysis for a Class of Linear Systems  with Inputs",
    "abstract": "Under-Approximate Reachability Analysis for a Class of Linear Systems  with Inputs",
    "descriptor": "",
    "authors": [
      "Mohamed Serry",
      "Jun Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Numerical Analysis (math.NA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2112.13503"
  },
  {
    "id": "arXiv:2112.13567",
    "title": "Cooperative Fair Throughput Maximization in a Multi-Cluster Wireless  Powered Network",
    "abstract": "Comments: 30 pages, 8 figures",
    "descriptor": "\nComments: 30 pages, 8 figures\n",
    "authors": [
      "Omid Rezaei",
      "Maryam Masjedi",
      "Mohammad Mahdi Naghsh",
      "Saeed Gazor",
      "Mohammad Mahdi Nayebi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2112.13567"
  },
  {
    "id": "arXiv:2112.15287",
    "title": "Distributed Random Reshuffling over Networks",
    "abstract": "Comments: 20 pages, 13 figures",
    "descriptor": "\nComments: 20 pages, 13 figures\n",
    "authors": [
      "Kun Huang",
      "Xiao Li",
      "Andre Milzarek",
      "Shi Pu",
      "Junwen Qiu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.15287"
  },
  {
    "id": "arXiv:2112.15458",
    "title": "Accurate and Real-time 3D Pedestrian Detection Using an Efficient  Attentive Pillar Network",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Duy-Tho Le",
      "Hengcan Shi",
      "Hamid Rezatofighi",
      "Jianfei Cai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.15458"
  },
  {
    "id": "arXiv:2201.04031",
    "title": "The extreme upper tail of Japan's citation distribution reveals its  research success",
    "abstract": "Comments: 19 pages, 1 figure and 5 tables in a single PDF file",
    "descriptor": "\nComments: 19 pages, 1 figure and 5 tables in a single PDF file\n",
    "authors": [
      "Alonso Rodriguez-Navarro",
      "Ricardo Brito"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2201.04031"
  },
  {
    "id": "arXiv:2201.07821",
    "title": "Building a Performance Model for Deep Learning Recommendation Model  Training on GPUs",
    "abstract": "Comments: 11 pages, 11 figures. Appears in the 29th IEEE International Conference on High-Performance Computing, Data, and Analytics (HiPC 2022)",
    "descriptor": "\nComments: 11 pages, 11 figures. Appears in the 29th IEEE International Conference on High-Performance Computing, Data, and Analytics (HiPC 2022)\n",
    "authors": [
      "Zhongyi Lin",
      "Louis Feng",
      "Ehsan K. Ardestani",
      "Jaewon Lee",
      "John Lundell",
      "Changkyu Kim",
      "Arun Kejariwal",
      "John D. Owens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2201.07821"
  },
  {
    "id": "arXiv:2201.11300",
    "title": "Geo-MOEA: A Multi-Objective Evolutionary Algorithm with Geo-obfuscation  for Mobile Crowdsourcing Workers",
    "abstract": "Comments: 14 pages, 13 figures",
    "descriptor": "\nComments: 14 pages, 13 figures\n",
    "authors": [
      "Shun Zhang",
      "Tao Zhang",
      "Zhili Chen",
      "N. Xiong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2201.11300"
  },
  {
    "id": "arXiv:2201.12944",
    "title": "Deep Learning Approaches on Image Captioning: A Review",
    "abstract": "Comments: 38 pages, 6 figures",
    "descriptor": "\nComments: 38 pages, 6 figures\n",
    "authors": [
      "Taraneh Ghandi",
      "Hamidreza Pourreza",
      "Hamidreza Mahyar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12944"
  },
  {
    "id": "arXiv:2202.08975",
    "title": "Probing Pretrained Models of Source Code",
    "abstract": "Probing Pretrained Models of Source Code",
    "descriptor": "",
    "authors": [
      "Sergey Troshin",
      "Nadezhda Chirkova"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08975"
  },
  {
    "id": "arXiv:2202.12967",
    "title": "Exploring with Sticky Mittens: Reinforcement Learning with Expert  Interventions via Option Templates",
    "abstract": "Comments: Conference on Robot Learning (CoRL) 2022",
    "descriptor": "\nComments: Conference on Robot Learning (CoRL) 2022\n",
    "authors": [
      "Souradeep Dutta",
      "Kaustubh Sridhar",
      "Osbert Bastani",
      "Edgar Dobriban",
      "James Weimer",
      "Insup Lee",
      "Julia Parish-Morris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.12967"
  },
  {
    "id": "arXiv:2203.00714",
    "title": "Subspace-Based Pilot Decontamination in User-Centric Scalable Cell-Free  Wireless Networks",
    "abstract": "Subspace-Based Pilot Decontamination in User-Centric Scalable Cell-Free  Wireless Networks",
    "descriptor": "",
    "authors": [
      "Fabian G\u00f6ttsch",
      "Noboru Osawa",
      "Takeo Ohseki",
      "Kosuke Yamazaki",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2203.00714"
  },
  {
    "id": "arXiv:2203.01310",
    "title": "Counterfactually Evaluating Explanations in Recommender Systems",
    "abstract": "Counterfactually Evaluating Explanations in Recommender Systems",
    "descriptor": "",
    "authors": [
      "Yuanshun Yao",
      "Chong Wang",
      "Hang Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.01310"
  },
  {
    "id": "arXiv:2203.02591",
    "title": "A Small Gain Analysis of Single Timescale Actor Critic",
    "abstract": "A Small Gain Analysis of Single Timescale Actor Critic",
    "descriptor": "",
    "authors": [
      "Alex Olshevsky",
      "Bahman Gharesifard"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2203.02591"
  },
  {
    "id": "arXiv:2203.04443",
    "title": "Estimating the Uncertainty in Emotion Class Labels with  Utterance-Specific Dirichlet Priors",
    "abstract": "Estimating the Uncertainty in Emotion Class Labels with  Utterance-Specific Dirichlet Priors",
    "descriptor": "",
    "authors": [
      "Wen Wu",
      "Chao Zhang",
      "Xixin Wu",
      "Philip C. Woodland"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.04443"
  },
  {
    "id": "arXiv:2203.07116",
    "title": "Deep Transformers Thirst for Comprehensive-Frequency Data",
    "abstract": "Comments: 7 pages, 10 figures",
    "descriptor": "\nComments: 7 pages, 10 figures\n",
    "authors": [
      "Rui Xia",
      "Chao Xue",
      "Boyu Deng",
      "Fang Wang",
      "Jingchao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.07116"
  },
  {
    "id": "arXiv:2203.11702",
    "title": "BERT-ASC: Implicit Aspect Representation Learning through  Auxiliary-Sentence Construction for Sentiment Analysis",
    "abstract": "Comments: under review",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Murtadha Ahmed",
      "Shengfeng Pan",
      "Jianlin Su",
      "Xinxin Cao",
      "Wenze Zhang",
      "Bo Wen",
      "Yunfeng Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.11702"
  },
  {
    "id": "arXiv:2203.14685",
    "title": "HetuMoE: An Efficient Trillion-scale Mixture-of-Expert Distributed  Training System",
    "abstract": "HetuMoE: An Efficient Trillion-scale Mixture-of-Expert Distributed  Training System",
    "descriptor": "",
    "authors": [
      "Xiaonan Nie",
      "Pinxue Zhao",
      "Xupeng Miao",
      "Tong Zhao",
      "Bin Cui"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2203.14685"
  },
  {
    "id": "arXiv:2204.01723",
    "title": "Signal Propagation: A Framework for Learning and Inference In a Forward  Pass",
    "abstract": "Signal Propagation: A Framework for Learning and Inference In a Forward  Pass",
    "descriptor": "",
    "authors": [
      "Adam Kohan",
      "Edward A. Rietman",
      "Hava T. Siegelmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2204.01723"
  },
  {
    "id": "arXiv:2204.03783",
    "title": "Does Simultaneous Speech Translation need Simultaneous Models?",
    "abstract": "Comments: Findings of EMNLP 2022",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Sara Papi",
      "Marco Gaido",
      "Matteo Negri",
      "Marco Turchi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.03783"
  },
  {
    "id": "arXiv:2204.05502",
    "title": "CoupleFace: Relation Matters for Face Recognition Distillation",
    "abstract": "Comments: Accepted by ECCV22",
    "descriptor": "\nComments: Accepted by ECCV22\n",
    "authors": [
      "Jiaheng Liu",
      "Haoyu Qin",
      "Yichao Wu",
      "Jinyang Guo",
      "Ding Liang",
      "Ke Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.05502"
  },
  {
    "id": "arXiv:2204.08110",
    "title": "Language Contamination Helps Explain the Cross-lingual Capabilities of  English Pretrained Models",
    "abstract": "Comments: EMNLP 2022; corrected typos in appendix tables",
    "descriptor": "\nComments: EMNLP 2022; corrected typos in appendix tables\n",
    "authors": [
      "Terra Blevins",
      "Luke Zettlemoyer"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2204.08110"
  },
  {
    "id": "arXiv:2204.12368",
    "title": "Fast Coalgebraic Bisimilarity Minimization",
    "abstract": "Fast Coalgebraic Bisimilarity Minimization",
    "descriptor": "",
    "authors": [
      "Jules Jacobs",
      "Thorsten Wi\u00dfmann"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2204.12368"
  },
  {
    "id": "arXiv:2204.14146",
    "title": "Training Language Models with Language Feedback",
    "abstract": "Comments: The First Workshop on Learning with Natural Language Supervision at ACL 2022",
    "descriptor": "\nComments: The First Workshop on Learning with Natural Language Supervision at ACL 2022\n",
    "authors": [
      "J\u00e9r\u00e9my Scheurer",
      "Jon Ander Campos",
      "Jun Shern Chan",
      "Angelica Chen",
      "Kyunghyun Cho",
      "Ethan Perez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.14146"
  },
  {
    "id": "arXiv:2204.14236",
    "title": "Combining Lipschitz and RBF Surrogate Models for High-dimensional  Computationally Expensive Problems",
    "abstract": "Combining Lipschitz and RBF Surrogate Models for High-dimensional  Computationally Expensive Problems",
    "descriptor": "",
    "authors": [
      "Jakub Kudela",
      "Radomil Matousek"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.14236"
  },
  {
    "id": "arXiv:2205.00742",
    "title": "FirmTruss Community Search in Multilayer Networks",
    "abstract": "Comments: Accepted to VLDB 2023 (PVLDB 2022)",
    "descriptor": "\nComments: Accepted to VLDB 2023 (PVLDB 2022)\n",
    "authors": [
      "Ali Behrouz",
      "Farnoosh Hashemi",
      "Laks V.S. Lakshmanan"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.00742"
  },
  {
    "id": "arXiv:2205.01563",
    "title": "Simulation of reversible molecular mechanical logic gates and circuits",
    "abstract": "Simulation of reversible molecular mechanical logic gates and circuits",
    "descriptor": "",
    "authors": [
      "Ian Seet",
      "Thomas E. Ouldridge",
      "Jonathan P.K. Doye"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2205.01563"
  },
  {
    "id": "arXiv:2205.01754",
    "title": "B\u00e9zier Curve Gaussian Processes",
    "abstract": "B\u00e9zier Curve Gaussian Processes",
    "descriptor": "",
    "authors": [
      "Ronny Hug",
      "Stefan Becker",
      "Wolfgang H\u00fcbner",
      "Michael Arens",
      "J\u00fcrgen Beyerer"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01754"
  },
  {
    "id": "arXiv:2205.04529",
    "title": "Foveated Rendering: Motivation, Taxonomy, and Research Directions",
    "abstract": "Comments: 16 pages, 12 figures",
    "descriptor": "\nComments: 16 pages, 12 figures\n",
    "authors": [
      "Susmija Jabbireddy",
      "Xuetong Sun",
      "Xiaoxu Meng",
      "Amitabh Varshney"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2205.04529"
  },
  {
    "id": "arXiv:2205.06157",
    "title": "Training Strategies for Own Voice Reconstruction in Hearing Protection  Devices using an In-ear Microphone",
    "abstract": "Comments: Accepted to IWAENC 2022",
    "descriptor": "\nComments: Accepted to IWAENC 2022\n",
    "authors": [
      "Mattes Ohlenbusch",
      "Christian Rollwage",
      "Simon Doclo"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2205.06157"
  },
  {
    "id": "arXiv:2205.06934",
    "title": "A Saliency-Guided Street View Image Inpainting Framework for Efficient  Last-Meters Wayfinding",
    "abstract": "A Saliency-Guided Street View Image Inpainting Framework for Efficient  Last-Meters Wayfinding",
    "descriptor": "",
    "authors": [
      "Chuanbo Hu",
      "Shan Jia",
      "Fan Zhang",
      "Xin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.06934"
  },
  {
    "id": "arXiv:2205.07362",
    "title": "What is an equivariant neural network?",
    "abstract": "Comments: 8 pages, 3 figure",
    "descriptor": "\nComments: 8 pages, 3 figure\n",
    "authors": [
      "Lek-Heng Lim",
      "Bradley J. Nelson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Representation Theory (math.RT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2205.07362"
  },
  {
    "id": "arXiv:2205.09786",
    "title": "Subset Node Anomaly Tracking over Large Dynamic Graphs",
    "abstract": "Comments: 9 pages + 2 pages supplement, accepted to 2022 ACM SIGKDD Research Track - fixed one notation typo",
    "descriptor": "\nComments: 9 pages + 2 pages supplement, accepted to 2022 ACM SIGKDD Research Track - fixed one notation typo\n",
    "authors": [
      "Xingzhi Guo",
      "Baojian Zhou",
      "Steven Skiena"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.09786"
  },
  {
    "id": "arXiv:2205.12244",
    "title": "Unsupervised Learning of Hierarchical Conversation Structure",
    "abstract": "Comments: In Findings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2022 Findings)",
    "descriptor": "\nComments: In Findings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2022 Findings)\n",
    "authors": [
      "Bo-Ru Lu",
      "Yushi Hu",
      "Hao Cheng",
      "Noah A. Smith",
      "Mari Ostendorf"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.12244"
  },
  {
    "id": "arXiv:2205.13618",
    "title": "Phantom Sponges: Exploiting Non-Maximum Suppression to Attack Deep  Object Detectors",
    "abstract": "Phantom Sponges: Exploiting Non-Maximum Suppression to Attack Deep  Object Detectors",
    "descriptor": "",
    "authors": [
      "Avishag Shapira",
      "Alon Zolfi",
      "Luca Demetrio",
      "Battista Biggio",
      "Asaf Shabtai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.13618"
  },
  {
    "id": "arXiv:2205.13636",
    "title": "Quark: Controllable Text Generation with Reinforced Unlearning",
    "abstract": "Quark: Controllable Text Generation with Reinforced Unlearning",
    "descriptor": "",
    "authors": [
      "Ximing Lu",
      "Sean Welleck",
      "Jack Hessel",
      "Liwei Jiang",
      "Lianhui Qin",
      "Peter West",
      "Prithviraj Ammanabrolu",
      "Yejin Choi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.13636"
  },
  {
    "id": "arXiv:2205.14485",
    "title": "Noise-Aware Statistical Inference with Differentially Private Synthetic  Data",
    "abstract": "Comments: 23 pages, 12 figures",
    "descriptor": "\nComments: 23 pages, 12 figures\n",
    "authors": [
      "Ossi R\u00e4is\u00e4",
      "Joonas J\u00e4lk\u00f6",
      "Samuel Kaski",
      "Antti Honkela"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14485"
  },
  {
    "id": "arXiv:2205.14550",
    "title": "Machine Learning for Microcontroller-Class Hardware: A Review",
    "abstract": "Comments: Published in IEEE Sensors Journal. Cite this as: S. S. Saha, S. S. Sandha and M. Srivastava, \"Machine Learning for Microcontroller-Class Hardware: A Review,\" in IEEE Sensors Journal, vol. 22, no. 22, pp. 21362-21390, 15 Nov., 2022",
    "descriptor": "\nComments: Published in IEEE Sensors Journal. Cite this as: S. S. Saha, S. S. Sandha and M. Srivastava, \"Machine Learning for Microcontroller-Class Hardware: A Review,\" in IEEE Sensors Journal, vol. 22, no. 22, pp. 21362-21390, 15 Nov., 2022\n",
    "authors": [
      "Swapnil Sayan Saha",
      "Sandeep Singh Sandha",
      "Mani Srivastava"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.14550"
  },
  {
    "id": "arXiv:2205.15412",
    "title": "Asynchronous Deterministic Leader Election in Three-Dimensional  Programmable Matter",
    "abstract": "Comments: 18 pages, 4 figures, 2 tables. Accepted at ICDCN 2023",
    "descriptor": "\nComments: 18 pages, 4 figures, 2 tables. Accepted at ICDCN 2023\n",
    "authors": [
      "Joseph L. Briones",
      "Tishya Chhabra",
      "Joshua J. Daymude",
      "Andr\u00e9a W. Richa"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2205.15412"
  },
  {
    "id": "arXiv:2206.02845",
    "title": "On Efficient Approximate Queries over Machine Learning Models",
    "abstract": "Comments: Accepted by PVLDB 2023, 16 pages, 15 figures",
    "descriptor": "\nComments: Accepted by PVLDB 2023, 16 pages, 15 figures\n",
    "authors": [
      "Dujian Ding",
      "Sihem Amer-Yahia",
      "Laks VS Lakshmanan"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.02845"
  },
  {
    "id": "arXiv:2206.07373",
    "title": "NatiQ: An End-to-end Text-to-Speech System for Arabic",
    "abstract": "NatiQ: An End-to-end Text-to-Speech System for Arabic",
    "descriptor": "",
    "authors": [
      "Ahmed Abdelali",
      "Nadir Durrani",
      "Cenk Demiroglu",
      "Fahim Dalvi",
      "Hamdy Mubarak",
      "Kareem Darwish"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2206.07373"
  },
  {
    "id": "arXiv:2206.08604",
    "title": "An F-shape Click Model for Information Retrieval on Multi-block Mobile  Pages",
    "abstract": "Comments: WSDM 2023. More readable and full version",
    "descriptor": "\nComments: WSDM 2023. More readable and full version\n",
    "authors": [
      "Lingyue Fu",
      "Jianghao Lin",
      "Weiwen Liu",
      "Ruiming Tang",
      "Weinan Zhang",
      "Rui Zhang",
      "Yong Yu"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.08604"
  },
  {
    "id": "arXiv:2206.09759",
    "title": "An Input-Queueing TSN Switching Architecture to Achieve Zero Packet Loss  for Timely Traffic",
    "abstract": "An Input-Queueing TSN Switching Architecture to Achieve Zero Packet Loss  for Timely Traffic",
    "descriptor": "",
    "authors": [
      "Ming Li",
      "Lei Deng",
      "Yunghsiang S. Han"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2206.09759"
  },
  {
    "id": "arXiv:2206.11973",
    "title": "Liquidity Risks in Lending Protocols: Evidence from Aave Protocol",
    "abstract": "Liquidity Risks in Lending Protocols: Evidence from Aave Protocol",
    "descriptor": "",
    "authors": [
      "Xiaotong Sun",
      "Charalampos Stasinakis",
      "Georgios Sermpinis"
    ],
    "subjectives": [
      "Risk Management (q-fin.RM)",
      "Cryptography and Security (cs.CR)",
      "Computational Finance (q-fin.CP)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2206.11973"
  },
  {
    "id": "arXiv:2206.14672",
    "title": "Not Cheating on the Turing Test: Towards Grounded Language Learning in  Artificial Intelligence",
    "abstract": "Comments: Philosophy master's thesis (2020) available on the SUNScholar research repository (this https URL)",
    "descriptor": "\nComments: Philosophy master's thesis (2020) available on the SUNScholar research repository (this https URL)\n",
    "authors": [
      "Lize Alberts"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.14672"
  },
  {
    "id": "arXiv:2207.03348",
    "title": "Human-Robot Commensality: Bite Timing Prediction for Robot-Assisted  Feeding in Groups",
    "abstract": "Comments: 6th Conference on Robot Learning (CoRL), 2022",
    "descriptor": "\nComments: 6th Conference on Robot Learning (CoRL), 2022\n",
    "authors": [
      "Jan Ondras",
      "Abrar Anwar",
      "Tong Wu",
      "Fanjun Bu",
      "Malte Jung",
      "Jorge Jose Ortiz",
      "Tapomayukh Bhattacharjee"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.03348"
  },
  {
    "id": "arXiv:2207.06190",
    "title": "Simulation-guided Beam Search for Neural Combinatorial Optimization",
    "abstract": "Comments: Accepted at NeurIPS 2022",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Jinho Choo",
      "Yeong-Dae Kwon",
      "Jihoon Kim",
      "Jeongwoo Jae",
      "Andr\u00e9 Hottung",
      "Kevin Tierney",
      "Youngjune Gwon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2207.06190"
  },
  {
    "id": "arXiv:2207.07307",
    "title": "MIMO-DoAnet: Multi-channel Input and Multiple Outputs DoA Network with  Unknown Number of Sound Sources",
    "abstract": "Comments: Accepted by Interspeech 2022",
    "descriptor": "\nComments: Accepted by Interspeech 2022\n",
    "authors": [
      "Haoran Yin",
      "Meng Ge",
      "Yanjie Fu",
      "Gaoyan Zhang",
      "Longbiao Wang",
      "Lei Zhang",
      "Lin Qiu",
      "Jianwu Dang"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2207.07307"
  },
  {
    "id": "arXiv:2207.11209",
    "title": "Divide and Conquer: 3D Point Cloud Instance Segmentation With Point-Wise  Binarization",
    "abstract": "Divide and Conquer: 3D Point Cloud Instance Segmentation With Point-Wise  Binarization",
    "descriptor": "",
    "authors": [
      "Weiguang Zhao",
      "Yuyao Yan",
      "Chaolong Yang",
      "Jianan Ye",
      "Xi Yang",
      "Kaizhu Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11209"
  },
  {
    "id": "arXiv:2207.13381",
    "title": "Look Closer to Your Enemy: Learning to Attack via Teacher-student  Mimicking",
    "abstract": "Comments: 13 pages, 8 figures, NDSS",
    "descriptor": "\nComments: 13 pages, 8 figures, NDSS\n",
    "authors": [
      "Mingjie Wang",
      "Zhiqing Tang",
      "Sirui Li",
      "Dingwen Xiao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.13381"
  },
  {
    "id": "arXiv:2207.13944",
    "title": "On the Multidimensional Random Subset Sum Problem",
    "abstract": "On the Multidimensional Random Subset Sum Problem",
    "descriptor": "",
    "authors": [
      "Luca Becchetti",
      "Arthur Carvalho Walraven da Cunha",
      "Andrea Clementi",
      "Francesco d'Amore",
      "Hicham Lesfari",
      "Emanuele Natale",
      "Luca Trevisan"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2207.13944"
  },
  {
    "id": "arXiv:2207.14687",
    "title": "A Data-driven Latent Semantic Analysis for Automatic Text Summarization  using LDA Topic Modelling",
    "abstract": "A Data-driven Latent Semantic Analysis for Automatic Text Summarization  using LDA Topic Modelling",
    "descriptor": "",
    "authors": [
      "Daniel F. O. Onah",
      "Elaine L. L. Pang",
      "Mahmoud El-Haj"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.14687"
  },
  {
    "id": "arXiv:2208.03058",
    "title": "Multi-Axis Control of a Qubit in the Presence of Unknown Non-Markovian  Quantum Noise",
    "abstract": "Multi-Axis Control of a Qubit in the Presence of Unknown Non-Markovian  Quantum Noise",
    "descriptor": "",
    "authors": [
      "Akram Youssry",
      "Hendra I. Nurdin"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.03058"
  },
  {
    "id": "arXiv:2208.03078",
    "title": "Cohort comfort models -- Using occupants' similarity to predict personal  thermal preference with less data",
    "abstract": "Cohort comfort models -- Using occupants' similarity to predict personal  thermal preference with less data",
    "descriptor": "",
    "authors": [
      "Matias Quintana",
      "Stefano Schiavon",
      "Federico Tartarini",
      "Joyce Kim",
      "Clayton Miller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.03078"
  },
  {
    "id": "arXiv:2208.05781",
    "title": "Path-aware Siamese Graph Neural Network for Link Prediction",
    "abstract": "Comments: 5 pages, 1 figure, 3 tables, 35 references, manuscript under review",
    "descriptor": "\nComments: 5 pages, 1 figure, 3 tables, 35 references, manuscript under review\n",
    "authors": [
      "Jingsong Lv",
      "Zhao Li",
      "Hongyang Chen",
      "Yao Qi",
      "Chunqi Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.05781"
  },
  {
    "id": "arXiv:2208.05898",
    "title": "Enabling Long-term Fairness in Dynamic Resource Allocation",
    "abstract": "Comments: Accepted to ACM SIGMETRICS 2023",
    "descriptor": "\nComments: Accepted to ACM SIGMETRICS 2023\n",
    "authors": [
      "T. Si-Salem",
      "G. Iosifidis",
      "G. Neglia"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2208.05898"
  },
  {
    "id": "arXiv:2208.06807",
    "title": "Semi-Supervised Video Inpainting with Cycle Consistency Constraints",
    "abstract": "Semi-Supervised Video Inpainting with Cycle Consistency Constraints",
    "descriptor": "",
    "authors": [
      "Zhiliang Wu",
      "Hanyu Xuan",
      "Changchang Sun",
      "Kang Zhang",
      "Yan Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.06807"
  },
  {
    "id": "arXiv:2208.08191",
    "title": "Transformer Vs. MLP-Mixer: Exponential Expressive Gap For NLP Problems",
    "abstract": "Transformer Vs. MLP-Mixer: Exponential Expressive Gap For NLP Problems",
    "descriptor": "",
    "authors": [
      "Dan Navon",
      "Alex M. Bronstein"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.08191"
  },
  {
    "id": "arXiv:2208.09333",
    "title": "Text to Image Generation: Leaving no Language Behind",
    "abstract": "Text to Image Generation: Leaving no Language Behind",
    "descriptor": "",
    "authors": [
      "Pedro Reviriego",
      "Elena Merino-G\u00f3mez"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.09333"
  },
  {
    "id": "arXiv:2208.14269",
    "title": "AuthROS: Secure Data Sharing Among Robot Operating Systems Based on  Ethereum",
    "abstract": "AuthROS: Secure Data Sharing Among Robot Operating Systems Based on  Ethereum",
    "descriptor": "",
    "authors": [
      "Shenhui Zhang",
      "Wenkai Li",
      "Xiaoqi Li",
      "Boyi Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2208.14269"
  },
  {
    "id": "arXiv:2209.00122",
    "title": "Tree-Based Adaptive Model Learning",
    "abstract": "Comments: 10 pages, 3 figures, A Journey from Process Algebra via Timed Automata to Model Learning. Ferreira, T., van Heerdt, G., Silva, A. (2022). Tree-Based Adaptive Model Learning. In: Jansen, N., Stoelinga, M., van den Bos, P. (eds) A Journey from Process Algebra via Timed Automata to Model Learning; Full implementation and experiment results available at this https URL",
    "descriptor": "\nComments: 10 pages, 3 figures, A Journey from Process Algebra via Timed Automata to Model Learning. Ferreira, T., van Heerdt, G., Silva, A. (2022). Tree-Based Adaptive Model Learning. In: Jansen, N., Stoelinga, M., van den Bos, P. (eds) A Journey from Process Algebra via Timed Automata to Model Learning; Full implementation and experiment results available at this https URL\n",
    "authors": [
      "Tiago Ferreira",
      "Gerco van Heerdt",
      "Alexandra Silva"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.00122"
  },
  {
    "id": "arXiv:2209.07180",
    "title": "Open Challenges in Synthetic Speech Detection",
    "abstract": "Comments: To appear in: IEEE International Workshop on Information Forensics and Security (WIFS), December 12-16, 2022, Shanghai, China",
    "descriptor": "\nComments: To appear in: IEEE International Workshop on Information Forensics and Security (WIFS), December 12-16, 2022, Shanghai, China\n",
    "authors": [
      "Luca Cuccovillo",
      "Christoforos Papastergiopoulos",
      "Anastasios Vafeiadis",
      "Artem Yaroshchuk",
      "Patrick Aichroth",
      "Konstantinos Votis",
      "Dimitrios Tzovaras"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2209.07180"
  },
  {
    "id": "arXiv:2209.07196",
    "title": "Environment Classification via Blind Roomprints Estimation",
    "abstract": "Comments: To appear in: IEEE International Workshop on Information Forensics and Security (WIFS), December 12-16, 2022, Shanghai, China",
    "descriptor": "\nComments: To appear in: IEEE International Workshop on Information Forensics and Security (WIFS), December 12-16, 2022, Shanghai, China\n",
    "authors": [
      "Malte Baum",
      "Luca Cuccovillo",
      "Artem Yaroshchuk",
      "Patrick Aichroth"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2209.07196"
  },
  {
    "id": "arXiv:2209.07420",
    "title": "Scalable Task-Driven Robotic Swarm Control via Collision Avoidance and  Learning Mean-Field Control",
    "abstract": "Comments: More precise proof for Corollary 1",
    "descriptor": "\nComments: More precise proof for Corollary 1\n",
    "authors": [
      "Kai Cui",
      "Mengguang Li",
      "Christian Fabian",
      "Heinz Koeppl"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.07420"
  },
  {
    "id": "arXiv:2209.07819",
    "title": "Self-Supervised Learning of Phenotypic Representations from Cell Images  with Weak Labels",
    "abstract": "Self-Supervised Learning of Phenotypic Representations from Cell Images  with Weak Labels",
    "descriptor": "",
    "authors": [
      "Jan Oscar Cross-Zamirski",
      "Guy Williams",
      "Elizabeth Mouchet",
      "Carola-Bibiane Sch\u00f6nlieb",
      "Riku Turkki",
      "Yinhai Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.07819"
  },
  {
    "id": "arXiv:2209.09720",
    "title": "Adaptive and Collaborative Bathymetric Channel-Finding Approach for  Multiple Autonomous Marine Vehicles",
    "abstract": "Comments: (v1) Submitted to IEEE International Conference on Robotics and Automation (ICRA) 2023, (v2) Updated figures, Submitted to IEEE Robotics and Automation Letters (RA-L)",
    "descriptor": "\nComments: (v1) Submitted to IEEE International Conference on Robotics and Automation (ICRA) 2023, (v2) Updated figures, Submitted to IEEE Robotics and Automation Letters (RA-L)\n",
    "authors": [
      "Nikolai Gershfeld",
      "Tyler M Paine",
      "Michael R. Benjamin"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.09720"
  },
  {
    "id": "arXiv:2209.10608",
    "title": "Dodging the Data Bottleneck: Automatic Subtitling with Automatically  Segmented ST Corpora",
    "abstract": "Dodging the Data Bottleneck: Automatic Subtitling with Automatically  Segmented ST Corpora",
    "descriptor": "",
    "authors": [
      "Sara Papi",
      "Alina Karakanta",
      "Matteo Negri",
      "Marco Turchi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.10608"
  },
  {
    "id": "arXiv:2209.10729",
    "title": "Fair Robust Active Learning by Joint Inconsistency",
    "abstract": "Comments: 11 pages, 2 figures, 8 tables",
    "descriptor": "\nComments: 11 pages, 2 figures, 8 tables\n",
    "authors": [
      "Tsung-Han Wu",
      "Hung-Ting Su",
      "Shang-Tse Chen",
      "Winston H. Hsu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.10729"
  },
  {
    "id": "arXiv:2209.11908",
    "title": "Fast Lifelong Adaptive Inverse Reinforcement Learning from  Demonstrations",
    "abstract": "Fast Lifelong Adaptive Inverse Reinforcement Learning from  Demonstrations",
    "descriptor": "",
    "authors": [
      "Letian Chen",
      "Sravan Jayanthi",
      "Rohan Paleja",
      "Daniel Martin",
      "Viacheslav Zakharov",
      "Matthew Gombolay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2209.11908"
  },
  {
    "id": "arXiv:2209.12152",
    "title": "All are Worth Words: A ViT Backbone for Diffusion Models",
    "abstract": "All are Worth Words: A ViT Backbone for Diffusion Models",
    "descriptor": "",
    "authors": [
      "Fan Bao",
      "Shen Nie",
      "Kaiwen Xue",
      "Yue Cao",
      "Chongxuan Li",
      "Hang Su",
      "Jun Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.12152"
  },
  {
    "id": "arXiv:2209.13388",
    "title": "Efficient Fault Detection Architecture of Bit-Parallel Multiplier in  Polynomial Basis of GF(2m) Using BCH Code",
    "abstract": "Comments: 8 pages, 4 Figures, 3 Tables",
    "descriptor": "\nComments: 8 pages, 4 Figures, 3 Tables\n",
    "authors": [
      "Saeideh Nabipour",
      "Javad Javidan",
      "Gholamreza Zare Fatin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2209.13388"
  },
  {
    "id": "arXiv:2210.00260",
    "title": "Localized RBF methods for modeling infiltration using the  Kirchhoff-transformed Richards equation",
    "abstract": "Localized RBF methods for modeling infiltration using the  Kirchhoff-transformed Richards equation",
    "descriptor": "",
    "authors": [
      "Mohamed Boujoudar",
      "Abdelaziz Beljadid",
      "Ahmed Taik"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.00260"
  },
  {
    "id": "arXiv:2210.01765",
    "title": "One Transformer Can Understand Both 2D & 3D Molecular Data",
    "abstract": "Comments: Preprint. Work in Progress. Code: this https URL",
    "descriptor": "\nComments: Preprint. Work in Progress. Code: this https URL\n",
    "authors": [
      "Shengjie Luo",
      "Tianlang Chen",
      "Yixian Xu",
      "Shuxin Zheng",
      "Tie-Yan Liu",
      "Liwei Wang",
      "Di He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Biomolecules (q-bio.BM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.01765"
  },
  {
    "id": "arXiv:2210.02067",
    "title": "Computing maximal generalized palindromes",
    "abstract": "Computing maximal generalized palindromes",
    "descriptor": "",
    "authors": [
      "Mitsuru Funakoshi",
      "Takuya Mieno",
      "Yuto Nakashima",
      "Shunsuke Inenaga",
      "Hideo Bannai",
      "Masayuki Takeda"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2210.02067"
  },
  {
    "id": "arXiv:2210.03016",
    "title": "\"A Special Operation\": A Quantitative Approach to Dissecting and  Comparing Different Media Ecosystems' Coverage of the Russo-Ukrainian War",
    "abstract": "Comments: Accepted to ICWSM 2023",
    "descriptor": "\nComments: Accepted to ICWSM 2023\n",
    "authors": [
      "Hans W. A. Hanley",
      "Deepak Kumar",
      "Zakir Durumeric"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.03016"
  },
  {
    "id": "arXiv:2210.04022",
    "title": "Speeding up the solution of the Site and Power Assignment Problem in  Wireless Networks",
    "abstract": "Speeding up the solution of the Site and Power Assignment Problem in  Wireless Networks",
    "descriptor": "",
    "authors": [
      "Pasquale Avella",
      "Alice Calamita",
      "Laura Palagi"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2210.04022"
  },
  {
    "id": "arXiv:2210.04971",
    "title": "Multi-step Planning for Automated Hyperparameter Optimization with  OptFormer",
    "abstract": "Comments: 8 pages, 7 figures",
    "descriptor": "\nComments: 8 pages, 7 figures\n",
    "authors": [
      "Lucio M. Dery",
      "Abram L. Friesen",
      "Nando De Freitas",
      "Marc'Aurelio Ranzato",
      "Yutian Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.04971"
  },
  {
    "id": "arXiv:2210.07468",
    "title": "Transparency Helps Reveal When Language Models Learn Meaning",
    "abstract": "Transparency Helps Reveal When Language Models Learn Meaning",
    "descriptor": "",
    "authors": [
      "Zhaofeng Wu",
      "William Merrill",
      "Hao Peng",
      "Iz Beltagy",
      "Noah A. Smith"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.07468"
  },
  {
    "id": "arXiv:2210.08207",
    "title": "Temporal Word Meaning Disambiguation using TimeLMs",
    "abstract": "Temporal Word Meaning Disambiguation using TimeLMs",
    "descriptor": "",
    "authors": [
      "Mihir Godbole",
      "Parth Dandavate",
      "Aditya Kane"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.08207"
  },
  {
    "id": "arXiv:2210.08836",
    "title": "MSDS: A Large-Scale Chinese Signature and Token Digit String Dataset for  Handwriting Verification",
    "abstract": "MSDS: A Large-Scale Chinese Signature and Token Digit String Dataset for  Handwriting Verification",
    "descriptor": "",
    "authors": [
      "Peirong Zhang",
      "Jiajia Jiang",
      "Yuliang Liu",
      "Lianwen Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.08836"
  },
  {
    "id": "arXiv:2210.09006",
    "title": "Fourier theoretic inequalities for inclusion of simple C*-algebras",
    "abstract": "Comments: 31 pages, 2 figures, major changes",
    "descriptor": "\nComments: 31 pages, 2 figures, major changes\n",
    "authors": [
      "Keshab Chandra Bakshi",
      "Satyajit Guin",
      "Sruthymurali"
    ],
    "subjectives": [
      "Operator Algebras (math.OA)",
      "Information Theory (cs.IT)",
      "Functional Analysis (math.FA)"
    ],
    "url": "https://arxiv.org/abs/2210.09006"
  },
  {
    "id": "arXiv:2210.11670",
    "title": "SIT at MixMT 2022: Fluent Translation Built on Giant Pre-trained Models",
    "abstract": "SIT at MixMT 2022: Fluent Translation Built on Giant Pre-trained Models",
    "descriptor": "",
    "authors": [
      "Abdul Rafae Khan",
      "Hrishikesh Kanade",
      "Girish Amar Budhrani",
      "Preet Jhanglani",
      "Jia Xu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11670"
  },
  {
    "id": "arXiv:2210.12464",
    "title": "Volatility forecasting using Deep Learning and sentiment analysis",
    "abstract": "Comments: 13 pages, 4 figures, accepted for publication at the SACAIR 2022 conference",
    "descriptor": "\nComments: 13 pages, 4 figures, accepted for publication at the SACAIR 2022 conference\n",
    "authors": [
      "V Ncume",
      "T. L van Zyl",
      "A Paskaramoorthy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.12464"
  },
  {
    "id": "arXiv:2210.13011",
    "title": "On All-Action Policy Gradients",
    "abstract": "Comments: NeurIPS 2022: Deep Reinforcement Learning Workshop",
    "descriptor": "\nComments: NeurIPS 2022: Deep Reinforcement Learning Workshop\n",
    "authors": [
      "Michal Nauman",
      "Marek Cygan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.13011"
  },
  {
    "id": "arXiv:2210.14019",
    "title": "The Curious Case of Benign Memorization",
    "abstract": "The Curious Case of Benign Memorization",
    "descriptor": "",
    "authors": [
      "Sotiris Anagnostidis",
      "Gregor Bachmann",
      "Lorenzo Noci",
      "Thomas Hofmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.14019"
  },
  {
    "id": "arXiv:2210.14142",
    "title": "From colouring-in to pointillism: revisiting semantic segmentation  supervision",
    "abstract": "Comments: Open Images V7 available at this https URL",
    "descriptor": "\nComments: Open Images V7 available at this https URL\n",
    "authors": [
      "Rodrigo Benenson",
      "Vittorio Ferrari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.14142"
  },
  {
    "id": "arXiv:2210.14404",
    "title": "Adaptive Test-Time Defense with the Manifold Hypothesis",
    "abstract": "Adaptive Test-Time Defense with the Manifold Hypothesis",
    "descriptor": "",
    "authors": [
      "Zhaoyuan Yang",
      "Zhiwei Xu",
      "Jing Zhang",
      "Richard Hartley",
      "Peter Tu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.14404"
  },
  {
    "id": "arXiv:2210.14698",
    "title": "Autoregressive Structured Prediction with Language Models",
    "abstract": "Comments: EMNLP 2022 (findings)",
    "descriptor": "\nComments: EMNLP 2022 (findings)\n",
    "authors": [
      "Tianyu Liu",
      "Yuchen Jiang",
      "Nicholas Monath",
      "Ryan Cotterell",
      "Mrinmaya Sachan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.14698"
  },
  {
    "id": "arXiv:2210.15906",
    "title": "Relative Behavioral Attributes: Filling the Gap between Symbolic Goal  Specification and Reward Learning from Human Preferences",
    "abstract": "Relative Behavioral Attributes: Filling the Gap between Symbolic Goal  Specification and Reward Learning from Human Preferences",
    "descriptor": "",
    "authors": [
      "Lin Guan",
      "Karthik Valmeekam",
      "Subbarao Kambhampati"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15906"
  },
  {
    "id": "arXiv:2210.16478",
    "title": "GPA-Net:No-Reference Point Cloud Quality Assessment with Multi-task  Graph Convolutional Network",
    "abstract": "GPA-Net:No-Reference Point Cloud Quality Assessment with Multi-task  Graph Convolutional Network",
    "descriptor": "",
    "authors": [
      "Ziyu Shan",
      "Qi Yang",
      "Rui Ye",
      "Yujie Zhang",
      "Yiling Xu",
      "Xiaozhong Xu",
      "Shan Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.16478"
  },
  {
    "id": "arXiv:2210.16622",
    "title": "Discriminative Speaker Representation via Contrastive Learning with  Class-Aware Attention in Angular Space",
    "abstract": "Comments: Submitted to ICASSP 2023, 5 pages, 2 figures",
    "descriptor": "\nComments: Submitted to ICASSP 2023, 5 pages, 2 figures\n",
    "authors": [
      "Zhe Li",
      "Man-Wai Mak",
      "Helen Mei-Ling Meng"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.16622"
  },
  {
    "id": "arXiv:2210.16636",
    "title": "Speaker Representation Learning via Contrastive Loss with Maximal  Speaker Separability",
    "abstract": "Comments: Accept by APSIPA ASC 2022, 6 pages, 2 figures",
    "descriptor": "\nComments: Accept by APSIPA ASC 2022, 6 pages, 2 figures\n",
    "authors": [
      "Zhe Li",
      "Man-Wai Mak"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.16636"
  },
  {
    "id": "arXiv:2210.17473",
    "title": "Chronic pain patient narratives allow for the estimation of current pain  intensity",
    "abstract": "Comments: 29 pages, 6 figures, 7 tables",
    "descriptor": "\nComments: 29 pages, 6 figures, 7 tables\n",
    "authors": [
      "Diogo A.P. Nunes",
      "Joana Ferreira-Gomes",
      "Daniela Oliveira",
      "Carlos Vaz",
      "Sofia Pimenta",
      "Fani Neto",
      "David Martins de Matos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.17473"
  },
  {
    "id": "arXiv:2211.00266",
    "title": "Two Low-complexity Efficient Beamformers for IRS-aided Directional  Modulation Networks",
    "abstract": "Two Low-complexity Efficient Beamformers for IRS-aided Directional  Modulation Networks",
    "descriptor": "",
    "authors": [
      "Yeqing Lin",
      "Jing Liu",
      "Rongen Dong",
      "Xun Chen",
      "Yue Wu",
      "Feng Shu",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.00266"
  },
  {
    "id": "arXiv:2211.00577",
    "title": "Fine-tuned Generative Adversarial Network-based Model for Medical Images  Super-Resolution",
    "abstract": "Fine-tuned Generative Adversarial Network-based Model for Medical Images  Super-Resolution",
    "descriptor": "",
    "authors": [
      "Alireza Aghelan",
      "Modjtaba Rouhani"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.00577"
  },
  {
    "id": "arXiv:2211.01324",
    "title": "eDiff-I: Text-to-Image Diffusion Models with an Ensemble of Expert  Denoisers",
    "abstract": "eDiff-I: Text-to-Image Diffusion Models with an Ensemble of Expert  Denoisers",
    "descriptor": "",
    "authors": [
      "Yogesh Balaji",
      "Seungjun Nah",
      "Xun Huang",
      "Arash Vahdat",
      "Jiaming Song",
      "Karsten Kreis",
      "Miika Aittala",
      "Timo Aila",
      "Samuli Laine",
      "Bryan Catanzaro",
      "Tero Karras",
      "Ming-Yu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01324"
  },
  {
    "id": "arXiv:2211.02052",
    "title": "Theta-Resonance: A Single-Step Reinforcement Learning Method for Design  Space Exploration",
    "abstract": "Theta-Resonance: A Single-Step Reinforcement Learning Method for Design  Space Exploration",
    "descriptor": "",
    "authors": [
      "Masood S. Mortazavi",
      "Tiancheng Qin",
      "Ning Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.02052"
  },
  {
    "id": "arXiv:2211.02692",
    "title": "High-Order Spline Upwind for Space-Time Isogeometric Analysis",
    "abstract": "High-Order Spline Upwind for Space-Time Isogeometric Analysis",
    "descriptor": "",
    "authors": [
      "Gabriele Loli",
      "Giancarlo Sangalli",
      "Paolo Tesini"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.02692"
  },
  {
    "id": "arXiv:2211.02888",
    "title": "Pitfalls of Climate Network Construction: A Statistical Perspective",
    "abstract": "Pitfalls of Climate Network Construction: A Statistical Perspective",
    "descriptor": "",
    "authors": [
      "Moritz Haas",
      "Bedartha Goswami",
      "Ulrike von Luxburg"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.02888"
  },
  {
    "id": "arXiv:2211.03160",
    "title": "Multi-GPU thermal lattice Boltzmann simulations using OpenACC and MPI",
    "abstract": "Comments: 31 pages, 12 figures",
    "descriptor": "\nComments: 31 pages, 12 figures\n",
    "authors": [
      "Ao Xu",
      "Bo-Tao Li"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.03160"
  },
  {
    "id": "arXiv:2211.03627",
    "title": "A Deep Double Ritz Method (D$^2$RM) for solving Partial Differential  Equations using Neural Networks",
    "abstract": "Comments: 26 pages",
    "descriptor": "\nComments: 26 pages\n",
    "authors": [
      "Carlos Uriarte",
      "David Pardo",
      "Ignacio Muga",
      "Judit Mu\u00f1oz-Matute"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.03627"
  },
  {
    "id": "arXiv:2211.05178",
    "title": "Fully-dynamic-to-incremental reductions with known deletion order (e.g.  sliding window)",
    "abstract": "Fully-dynamic-to-incremental reductions with known deletion order (e.g.  sliding window)",
    "descriptor": "",
    "authors": [
      "Binghui Peng",
      "Aviad Rubinstein"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.05178"
  },
  {
    "id": "arXiv:2211.05223",
    "title": "Aperiodic Sampled-Data Distributed Observer Design",
    "abstract": "Comments: 10 pages, 4 figures",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Shimin Wang",
      "Zhan Shu",
      "Tongwen Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.05223"
  },
  {
    "id": "arXiv:2211.05979",
    "title": "Semi-supervised Variational Autoencoder for Regression: Application on  Soft Sensors",
    "abstract": "Semi-supervised Variational Autoencoder for Regression: Application on  Soft Sensors",
    "descriptor": "",
    "authors": [
      "Yilin Zhuang",
      "Zhuobin Zhou",
      "Burak Alakent",
      "Mehmet Mercangoz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05979"
  },
  {
    "id": "arXiv:2211.05994",
    "title": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
    "abstract": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
    "descriptor": "",
    "authors": [
      "Linmei Hu",
      "Zeyi Liu",
      "Ziwang Zhao",
      "Lei Hou",
      "Liqiang Nie",
      "Juanzi Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05994"
  },
  {
    "id": "arXiv:2211.06119",
    "title": "SSGVS: Semantic Scene Graph-to-Video Synthesis",
    "abstract": "SSGVS: Semantic Scene Graph-to-Video Synthesis",
    "descriptor": "",
    "authors": [
      "Yuren Cong",
      "Jinhui Yi",
      "Bodo Rosenhahn",
      "Michael Ying Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.06119"
  },
  {
    "id": "arXiv:2211.06441",
    "title": "Metaphors We Learn By",
    "abstract": "Comments: Fixed citation formatting",
    "descriptor": "\nComments: Fixed citation formatting\n",
    "authors": [
      "Roland Memisevic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.06441"
  },
  {
    "id": "arXiv:2211.06490",
    "title": "A Non-Volatile All-Spin Non-Binary Matrix Multiplier: An Efficient  Hardware Accelerator for Machine Learning",
    "abstract": "Comments: A slightly shorter version of this article has been accepted for publication in IEEE Transactions on Electron Devices. The replacement corrects some errors in the previously uploaded version",
    "descriptor": "\nComments: A slightly shorter version of this article has been accepted for publication in IEEE Transactions on Electron Devices. The replacement corrects some errors in the previously uploaded version\n",
    "authors": [
      "Rahnuma Rahman",
      "Supriyo Bandyopadhyay"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Systems and Control (eess.SY)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.06490"
  },
  {
    "id": "arXiv:2211.06689",
    "title": "TINC: Tree-structured Implicit Neural Compression",
    "abstract": "TINC: Tree-structured Implicit Neural Compression",
    "descriptor": "",
    "authors": [
      "Runzhao Yang",
      "Tingxiong Xiao",
      "Yuxiao Cheng",
      "Jinli Suo",
      "Qionghai Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.06689"
  },
  {
    "id": "arXiv:2211.06816",
    "title": "Long-Range Zero-Shot Generative Deep Network Quantization",
    "abstract": "Long-Range Zero-Shot Generative Deep Network Quantization",
    "descriptor": "",
    "authors": [
      "Yan Luo",
      "Yangcheng Gao",
      "Zhao Zhang",
      "Haijun Zhang",
      "Mingliang Xu",
      "Meng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.06816"
  },
  {
    "id": "arXiv:2211.07022",
    "title": "AutoDRIVE Simulator -- Technical Report",
    "abstract": "Comments: This work was a part of India Connect @ NTU (IC@N) Research Internship Program 2020. arXiv admin note: substantial text overlap with arXiv:2103.10030",
    "descriptor": "\nComments: This work was a part of India Connect @ NTU (IC@N) Research Internship Program 2020. arXiv admin note: substantial text overlap with arXiv:2103.10030\n",
    "authors": [
      "Tanmay Vilas Samak",
      "Chinmay Vilas Samak"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.07022"
  },
  {
    "id": "arXiv:2211.07077",
    "title": "IFQA: Interpretable Face Quality Assessment",
    "abstract": "Comments: WACV 2023, Code: this https URL",
    "descriptor": "\nComments: WACV 2023, Code: this https URL\n",
    "authors": [
      "Byungho Jo",
      "Donghyeon Cho",
      "In Kyu Park",
      "Sungeun Hong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07077"
  },
  {
    "id": "arXiv:2211.07393",
    "title": "Temporal patterns in insulin needs for Type 1 diabetes",
    "abstract": "Comments: Submitted and accepted for presentation as a poster at the NeurIPS22 Time series for Health workshop, this https URL",
    "descriptor": "\nComments: Submitted and accepted for presentation as a poster at the NeurIPS22 Time series for Health workshop, this https URL\n",
    "authors": [
      "Isabella Degen",
      "Zahraa S. Abdallah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.07393"
  },
  {
    "id": "arXiv:2211.07443",
    "title": "Calibrated Interpretation: Confidence Estimation in Semantic Parsing",
    "abstract": "Comments: 10 pages",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Elias Stengel-Eskin",
      "Benjamin Van Durme"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.07443"
  },
  {
    "id": "arXiv:2211.07814",
    "title": "Extending the Neural Additive Model for Survival Analysis with EHR Data",
    "abstract": "Comments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 14 pages",
    "descriptor": "\nComments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 14 pages\n",
    "authors": [
      "Matthew Peroni",
      "Marharyta Kurban",
      "Sun Young Yang",
      "Young Sun Kim",
      "Hae Yeon Kang",
      "Ji Hyun Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07814"
  },
  {
    "id": "arXiv:2211.07881",
    "title": "ET-AL: Entropy-Targeted Active Learning for Bias Mitigation in Materials  Data",
    "abstract": "Comments: Working paper, 16 pages, 6 figures",
    "descriptor": "\nComments: Working paper, 16 pages, 6 figures\n",
    "authors": [
      "Hengrui Zhang",
      "Wei Wayne Chen",
      "James M. Rondinelli",
      "Wei Chen"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07881"
  },
  {
    "id": "arXiv:2211.07911",
    "title": "Operation-level Concurrent Transaction Execution for Blockchains",
    "abstract": "Operation-level Concurrent Transaction Execution for Blockchains",
    "descriptor": "",
    "authors": [
      "Haoran Lin",
      "Yajin Zhou",
      "Lei Wu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.07911"
  },
  {
    "id": "arXiv:2211.08029",
    "title": "Persian Emotion Detection using ParsBERT and Imbalanced Data Handling  Approaches",
    "abstract": "Comments: 14 pages, 5 figures, 9 tables",
    "descriptor": "\nComments: 14 pages, 5 figures, 9 tables\n",
    "authors": [
      "Amirhossein Abaskohi",
      "Nazanin Sabri",
      "Behnam Bahrak"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08029"
  },
  {
    "id": "arXiv:2211.08180",
    "title": "Divisible linear rank metric codes",
    "abstract": "Divisible linear rank metric codes",
    "descriptor": "",
    "authors": [
      "Olga Polverino",
      "Paolo Santonastaso",
      "John Sheekey",
      "Ferdinando Zullo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.08180"
  },
  {
    "id": "arXiv:2211.08295",
    "title": "An FNet based Auto Encoder for Long Sequence News Story Generation",
    "abstract": "Comments: 7 pages, 6 figures",
    "descriptor": "\nComments: 7 pages, 6 figures\n",
    "authors": [
      "Paul K. Mandal",
      "Rakeshkumar Mahto"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08295"
  },
  {
    "id": "arXiv:2211.08296",
    "title": "Deep-Learning-Empowered Inverse Design for Freeform Reconfigurable  Metasurfaces",
    "abstract": "Deep-Learning-Empowered Inverse Design for Freeform Reconfigurable  Metasurfaces",
    "descriptor": "",
    "authors": [
      "Changhao Liu",
      "Fan Yang",
      "Maokun Li",
      "Shenheng Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2211.08296"
  },
  {
    "id": "arXiv:2211.08406",
    "title": "Incorporating Pre-training Paradigm for Antibody Sequence-Structure  Co-design",
    "abstract": "Incorporating Pre-training Paradigm for Antibody Sequence-Structure  Co-design",
    "descriptor": "",
    "authors": [
      "Kaiyuan Gao",
      "Lijun Wu",
      "Jinhua Zhu",
      "Tianbo Peng",
      "Yingce Xia",
      "Liang He",
      "Shufang Xie",
      "Tao Qin",
      "Haiguang Liu",
      "Kun He",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08406"
  },
  {
    "id": "arXiv:2211.08407",
    "title": "Trust-Awareness to Secure Swarm Intelligence from Data Injection Attack",
    "abstract": "Comments: Submitted to ICC 2023",
    "descriptor": "\nComments: Submitted to ICC 2023\n",
    "authors": [
      "Bin Han",
      "Dennis Krummacker",
      "Qiuheng Zhou",
      "Hans D. Schotten"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.08407"
  },
  {
    "id": "arXiv:2211.08447",
    "title": "SexWEs: Domain-Aware Word Embeddings via Cross-lingual Semantic  Specialisation for Chinese Sexism Detection in Social Media",
    "abstract": "Comments: accepted at ICWSM 2023",
    "descriptor": "\nComments: accepted at ICWSM 2023\n",
    "authors": [
      "Aiqi Jiang",
      "Arkaitz Zubiaga"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.08447"
  },
  {
    "id": "arXiv:2211.08475",
    "title": "AutoDRIVE -- Technical Report",
    "abstract": "Comments: This work was a part of 2021 Undergraduate Final Year Project at the Department of Mechatronics Engineering, SRM Institute of Science and Technology",
    "descriptor": "\nComments: This work was a part of 2021 Undergraduate Final Year Project at the Department of Mechatronics Engineering, SRM Institute of Science and Technology\n",
    "authors": [
      "Tanmay Vilas Samak",
      "Chinmay Vilas Samak"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.08475"
  },
  {
    "id": "arXiv:2211.08513",
    "title": "Searching for Carriers of the Diffuse Interstellar Bands Across  Disciplines, using Natural Language Processing",
    "abstract": "Comments: Accepted for publication by Journal of Interdisciplinary Methodologies and Issues in Science (JIMIS)",
    "descriptor": "\nComments: Accepted for publication by Journal of Interdisciplinary Methodologies and Issues in Science (JIMIS)\n",
    "authors": [
      "Corentin van den Broek d'Obrenan",
      "Fr\u00e9d\u00e9ric Galliano",
      "Jeremy Minton",
      "Viktor Botev",
      "Ronin Wu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Astrophysics of Galaxies (astro-ph.GA)"
    ],
    "url": "https://arxiv.org/abs/2211.08513"
  },
  {
    "id": "arXiv:2211.08732",
    "title": "Lesion Guided Explainable Few Weak-shot Medical Report Generation",
    "abstract": "Lesion Guided Explainable Few Weak-shot Medical Report Generation",
    "descriptor": "",
    "authors": [
      "Jinghan Sun",
      "Dong Wei",
      "Liansheng Wang",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.08732"
  },
  {
    "id": "arXiv:2211.08737",
    "title": "Near-Term Quantum Computing Techniques: Variational Quantum Algorithms,  Error Mitigation, Circuit Compilation, Benchmarking and Classical Simulation",
    "abstract": "Comments: Please feel free to email He-Liang Huang with any comments, questions, suggestions or concerns",
    "descriptor": "\nComments: Please feel free to email He-Liang Huang with any comments, questions, suggestions or concerns\n",
    "authors": [
      "He-Liang Huang",
      "Xiao-Yue Xu",
      "Chu Guo",
      "Guojing Tian",
      "Shi-Jie Wei",
      "Xiaoming Sun",
      "Wan-Su Bao",
      "Gui-Lu Long"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08737"
  },
  {
    "id": "arXiv:2211.08792",
    "title": "Some Properties of the NE in $2 \\times 2$ Zero-Sum Games",
    "abstract": "Some Properties of the NE in $2 \\times 2$ Zero-Sum Games",
    "descriptor": "",
    "authors": [
      "Ke Sun"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.08792"
  },
  {
    "id": "arXiv:2211.08883",
    "title": "Identifying the Causes of Pyrocumulonimbus (PyroCb)",
    "abstract": "Comments: 14 pages 9 figures. To be published in the 2022 NeurIPS Workshop on Causal Machine Learning for Real-World Impact",
    "descriptor": "\nComments: 14 pages 9 figures. To be published in the 2022 NeurIPS Workshop on Causal Machine Learning for Real-World Impact\n",
    "authors": [
      "Emiliano D\u00edaz Salas-Porras",
      "Kenza Tazi",
      "Ashwin Braude",
      "Daniel Okoh",
      "Kara D. Lamb",
      "Duncan Watson-Parris",
      "Paula Harder",
      "Nis Meinert"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08883"
  },
  {
    "id": "arXiv:2211.08944",
    "title": "Reasons for the Superiority of Stochastic Estimators over Deterministic  Ones: Robustness, Consistency and Perceptual Quality",
    "abstract": "Reasons for the Superiority of Stochastic Estimators over Deterministic  Ones: Robustness, Consistency and Perceptual Quality",
    "descriptor": "",
    "authors": [
      "Guy Ohayon",
      "Theo Adrai",
      "Michael Elad",
      "Tomer Michaeli"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08944"
  },
  {
    "id": "arXiv:2211.08956",
    "title": "A Comprehensive Survey on Spectrum Sharing Techniques for 5G/B5G  Intelligent Wireless Networks: Opportunities, Challenges and Future Research  Directions",
    "abstract": "A Comprehensive Survey on Spectrum Sharing Techniques for 5G/B5G  Intelligent Wireless Networks: Opportunities, Challenges and Future Research  Directions",
    "descriptor": "",
    "authors": [
      "Anita Patil",
      "Sridhar Iyer",
      "Onel L.A. Lopez",
      "Rahul J Pandya",
      "Krishna Pai",
      "Anshuman Kalla",
      "Rakhee Kallimani"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.08956"
  },
  {
    "id": "arXiv:2211.09020",
    "title": "Optimal SMC for Transactional Programs",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:1906.12095 by other authors",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:1906.12095 by other authors\n",
    "authors": [
      "Parosh Aziz Abdulla",
      "Mohamed Faouzi Atig",
      "Ashutosh Gupta",
      "Shankaranarayanan Krishna",
      "Omkar Tuppe"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.09020"
  }
]
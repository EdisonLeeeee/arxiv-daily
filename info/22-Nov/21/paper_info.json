[
  {
    "id": "arXiv:2211.09810",
    "title": "Certifying Robustness of Convolutional Neural Networks with Tight Linear  Approximation",
    "abstract": "The robustness of neural network classifiers is becoming important in the\nsafety-critical domain and can be quantified by robustness verification.\nHowever, at present, efficient and scalable verification techniques are always\nsound but incomplete. Therefore, the improvement of certified robustness bounds\nis the key criterion to evaluate the superiority of robustness verification\napproaches. In this paper, we present a Tight Linear approximation approach for\nrobustness verification of Convolutional Neural Networks(Ti-Lin). For general\nCNNs, we first provide a new linear constraints for S-shaped activation\nfunctions, which is better than both existing Neuron-wise Tightest and\nNetwork-wise Tightest tools. We then propose Neuron-wise Tightest linear bounds\nfor Maxpool function. We implement Ti-Lin, the resulting verification method.\nWe evaluate it with 48 different CNNs trained on MNIST, CIFAR-10, and Tiny\nImageNet datasets. Experimental results show that Ti-Lin significantly\noutperforms other five state-of-the-art methods(CNN-Cert, DeepPoly, DeepCert,\nVeriNet, Newise). Concretely, Ti-Lin certifies much more precise robustness\nbounds on pure CNNs with Sigmoid/Tanh/Arctan functions and CNNs with Maxpooling\nfunction with at most 63.70% and 253.54% improvement, respectively.",
    "descriptor": "",
    "authors": [
      "Yuan Xiao",
      "Tongtong Bai",
      "Mingzheng Gu",
      "Chunrong Fang",
      "Zhenyu Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.09810"
  },
  {
    "id": "arXiv:2211.09812",
    "title": "GAMMT: Generative Ambiguity Modeling Using Multiple Transformers",
    "abstract": "We introduce a new model based on sets of probabilities for sequential data.\nWe name the model GAMMT, which stands for Generative Ambiguity Models using\nMultiple Transformers. We suppose that data generating process of a sequence is\nambiguous and determined by a set of probabilities rather than one as in the\nconventional model. We use multiple parallel transformers connected by a\nselection mechanism to approximate ambiguous probabilities. The GAMMT allows\nfor ambiguity modeling in a generative way and multiple representations of the\ninput tokens and the input sequence. This work explores the combination of\nattention mechanism and ambiguity by deep neural networks. We expect that this\nframework will facilitate new research into machine learning, improving our\nunderstanding of the attention-ambiguity mechanism.",
    "descriptor": "\nComments: 10 pages, 2 figures, 3 algorithms\n",
    "authors": [
      "Xingcheng Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.09812"
  },
  {
    "id": "arXiv:2211.09813",
    "title": "Hierarchical Estimation for Effective and Efficient Sampling Graph  Neural Network",
    "abstract": "Improving the scalability of GNNs is critical for large graphs. Existing\nmethods leverage three sampling paradigms including node-wise, layer-wise and\nsubgraph sampling, then design unbiased estimator for scalability. However, the\nhigh variance still severely hinders GNNs' performance. On account that\nprevious studies either lacks variance analysis or only focus on a particular\nsampling paradigm, we firstly propose an unified node sampling variance\nanalysis framework and analyze the core challenge \"circular dependency\" for\nderiving the minimum variance sampler, i. e., sampling probability depends on\nnode embeddings while node embeddings can not be calculated until sampling is\nfinished. Existing studies either ignore the node embeddings or introduce\nexternal parameters, resulting in the lack of a both efficient and effective\nvariance reduction methods. Therefore, we propose the \\textbf{H}ierarchical\n\\textbf{E}stimation based \\textbf{S}ampling GNN (HE-SGNN) with first level\nestimating the node embeddings in sampling probability to break circular\ndependency, and second level employing sampling GNN operator to estimate the\nnodes' representations on the entire graph. Considering the technical\ndifference, we propose different first level estimator, i.e., a time series\nsimulation for layer-wise sampling and a feature based simulation for subgraph\nsampling. The experimental results on seven representative datasets demonstrate\nthe effectiveness and efficiency of our method.",
    "descriptor": "",
    "authors": [
      "Yang Li",
      "Bingbing Xu",
      "Qi Cao",
      "Yige Yuan",
      "Huawei Shen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.09813"
  },
  {
    "id": "arXiv:2211.09814",
    "title": "Data-driven Real-time Short-term Prediction of Air Quality: Comparison  of ES, ARIMA, and LSTM",
    "abstract": "Air pollution is a worldwide issue that affects the lives of many people in\nurban areas. It is considered that the air pollution may lead to heart and lung\ndiseases. A careful and timely forecast of the air quality could help to reduce\nthe exposure risk for affected people. In this paper, we use a data-driven\napproach to predict air quality based on historical data. We compare three\npopular methods for time series prediction: Exponential Smoothing (ES),\nAuto-Regressive Integrated Moving Average (ARIMA) and Long short-term memory\n(LSTM). Considering prediction accuracy and time complexity, our experiments\nreveal that for short-term air pollution prediction ES performs better than\nARIMA and LSTM.",
    "descriptor": "",
    "authors": [
      "Iryna Talamanova",
      "Sabri Pllana"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09814"
  },
  {
    "id": "arXiv:2211.09817",
    "title": "On the Effect of Pre-training for Transformer in Different Modality on  Offline Reinforcement Learning",
    "abstract": "We empirically investigate how pre-training on data of different modalities,\nsuch as language and vision, affects fine-tuning of Transformer-based models to\nMujoco offline reinforcement learning tasks. Analysis of the internal\nrepresentation reveals that the pre-trained Transformers acquire largely\ndifferent representations before and after pre-training, but acquire less\ninformation of data in fine-tuning than the randomly initialized one. A closer\nlook at the parameter changes of the pre-trained Transformers reveals that\ntheir parameters do not change that much and that the bad performance of the\nmodel pre-trained with image data could partially come from large gradients and\ngradient clipping. To study what information the Transformer pre-trained with\nlanguage data utilizes, we fine-tune this model with no context provided,\nfinding that the model learns efficiently even without context information.\nSubsequent follow-up analysis supports the hypothesis that pre-training with\nlanguage data is likely to make the Transformer get context-like information\nand utilize it to solve the downstream task.",
    "descriptor": "\nComments: 48 pages. Published in NeurIPS 2022\n",
    "authors": [
      "Shiro Takagi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.09817"
  },
  {
    "id": "arXiv:2211.09818",
    "title": "Deep learning for Lagrangian drift simulation at the sea surface",
    "abstract": "We address Lagrangian drift simulation in geophysical dynamics and explore\ndeep learning approaches to overcome known limitations of state-of-the-art\nmodel-based and Markovian approaches in terms of computational complexity and\nerror propagation. We introduce a novel architecture, referred to as DriftNet,\ninspired from the Eulerian Fokker-Planck representation of Lagrangian dynamics.\nNumerical experiments for Lagrangian drift simulation at the sea surface\ndemonstrates the relevance of DriftNet w.r.t. state-of-the-art schemes.\nBenefiting from the fully-convolutional nature of Drift-Net, we explore through\na neural inversion how to diagnose modelderived velocities w.r.t. real drifter\ntrajectories.",
    "descriptor": "",
    "authors": [
      "Daria Botvynko",
      "Carlos Granero-Belinchon",
      "Simon Van Gennip",
      "Abdesslam Benzinou",
      "Ronan Fablet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.09818"
  },
  {
    "id": "arXiv:2211.09832",
    "title": "Latent User Intent Modeling for Sequential Recommenders",
    "abstract": "Sequential recommender models are essential components of modern industrial\nrecommender systems. These models learn to predict the next items a user is\nlikely to interact with based on his/her interaction history on the platform.\nMost sequential recommenders however lack a higher-level understanding of user\nintents, which often drive user behaviors online. Intent modeling is thus\ncritical for understanding users and optimizing long-term user experience. We\npropose a probabilistic modeling approach and formulate user intent as latent\nvariables, which are inferred based on user behavior signals using variational\nautoencoders (VAE). The recommendation policy is then adjusted accordingly\ngiven the inferred user intent. We demonstrate the effectiveness of the latent\nuser intent modeling via offline analyses as well as live experiments on a\nlarge-scale industrial recommendation platform.",
    "descriptor": "",
    "authors": [
      "Bo Chang",
      "Alexandros Karatzoglou",
      "Yuyan Wang",
      "Can Xu",
      "Ed H. Chi",
      "Minmin Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09832"
  },
  {
    "id": "arXiv:2211.09847",
    "title": "CoLI-Machine Learning Approaches for Code-mixed Language Identification  at the Word Level in Kannada-English Texts",
    "abstract": "The task of automatically identifying a language used in a given text is\ncalled Language Identification (LI). India is a multilingual country and many\nIndians especially youths are comfortable with Hindi and English, in addition\nto their local languages. Hence, they often use more than one language to post\ntheir comments on social media. Texts containing more than one language are\ncalled \"code-mixed texts\" and are a good source of input for LI. Languages in\nthese texts may be mixed at sentence level, word level or even at sub-word\nlevel. LI at word level is a sequence labeling problem where each and every\nword in a sentence is tagged with one of the languages in the predefined set of\nlanguages. In order to address word level LI in code-mixed Kannada-English\n(Kn-En) texts, this work presents i) the construction of code-mixed Kn-En\ndataset called CoLI-Kenglish dataset, ii) code-mixed Kn-En embedding and iii)\nlearning models using Machine Learning (ML), Deep Learning (DL) and Transfer\nLearning (TL) approaches. Code-mixed Kn-En texts are extracted from Kannada\nYouTube video comments to construct CoLI-Kenglish dataset and code-mixed Kn-En\nembedding. The words in CoLI-Kenglish dataset are grouped into six major\ncategories, namely, \"Kannada\", \"English\", \"Mixed-language\", \"Name\", \"Location\"\nand \"Other\". The learning models, namely, CoLI-vectors and CoLI-ngrams based on\nML, CoLI-BiLSTM based on DL and CoLI-ULMFiT based on TL approaches are built\nand evaluated using CoLI-Kenglish dataset. The performances of the learning\nmodels illustrated, the superiority of CoLI-ngrams model, compared to other\nmodels with a macro average F1-score of 0.64. However, the results of all the\nlearning models were quite competitive with each other.",
    "descriptor": "",
    "authors": [
      "H.L. Shashirekha",
      "F. Balouchzahi",
      "M.D. Anusha",
      "G. Sidorov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09847"
  },
  {
    "id": "arXiv:2211.09854",
    "title": "An Iterative Method to Learn a Linear Control Barrier Function",
    "abstract": "Control barrier function (CBF) has recently started to serve as a basis to\ndevelop approaches for enforcing safety requirements in control systems.\nHowever, constructing such function for a general system is a non-trivial task.\nThis paper proposes an iterative, optimization-based framework to obtain a CBF\nfrom a given user-specified set for a general control affine system. Without\nlosing generality, we parameterize the CBF as a set of linear functions of\nstates. By taking samples from the given user-specified set, we reformulate the\nproblem of learning a CBF into an optimization problem that solves for linear\nfunction coefficients. The resulting linear functions construct the CBF and\nyield a safe set which has forward invariance property. In addition, the\nproposed framework explicitly addresses control input constraints during the\nconstruction of CBFs. Effectiveness of the proposed method is demonstrated by\nlearning a CBF for an nonlinear Moore Greitzer jet engine, where the system\ntrajectory is prevented from entering unsafe set.",
    "descriptor": "",
    "authors": [
      "Zihao Liang",
      "Jason King Ching Lo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.09854"
  },
  {
    "id": "arXiv:2211.09855",
    "title": "ProtSi: Prototypical Siamese Network with Data Augmentation for Few-Shot  Subjective Answer Evaluation",
    "abstract": "Subjective answer evaluation is a time-consuming and tedious task, and the\nquality of the evaluation is heavily influenced by a variety of subjective\npersonal characteristics. Instead, machine evaluation can effectively assist\neducators in saving time while also ensuring that evaluations are fair and\nrealistic. However, most existing methods using regular machine learning and\nnatural language processing techniques are generally hampered by a lack of\nannotated answers and poor model interpretability, making them unsuitable for\nreal-world use. To solve these challenges, we propose ProtSi Network, a unique\nsemi-supervised architecture that for the first time uses few-shot learning to\nsubjective answer evaluation. To evaluate students' answers by similarity\nprototypes, ProtSi Network simulates the natural process of evaluator scoring\nanswers by combining Siamese Network which consists of BERT and encoder layers\nwith Prototypical Network. We employed an unsupervised diverse paraphrasing\nmodel ProtAugment, in order to prevent overfitting for effective few-shot text\nclassification. By integrating contrastive learning, the discriminative text\nissue can be mitigated. Experiments on the Kaggle Short Scoring Dataset\ndemonstrate that the ProtSi Network outperforms the most recent baseline models\nin terms of accuracy and quadratic weighted kappa.",
    "descriptor": "",
    "authors": [
      "Yining Lu",
      "Jingxi Qiu",
      "Gaurav Gupta"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.09855"
  },
  {
    "id": "arXiv:2211.09856",
    "title": "Machine Learning-Assisted Recurrence Prediction for Early-Stage  Non-Small-Cell Lung Cancer Patients",
    "abstract": "Background: Stratifying cancer patients according to risk of relapse can\npersonalize their care. In this work, we provide an answer to the following\nresearch question: How to utilize machine learning to estimate probability of\nrelapse in early-stage non-small-cell lung cancer patients?\nMethods: For predicting relapse in 1,387 early-stage (I-II), non-small-cell\nlung cancer (NSCLC) patients from the Spanish Lung Cancer Group data (65.7\naverage age, 24.8% females, 75.2% males) we train tabular and graph machine\nlearning models. We generate automatic explanations for the predictions of such\nmodels. For models trained on tabular data, we adopt SHAP local explanations to\ngauge how each patient feature contributes to the predicted outcome. We explain\ngraph machine learning predictions with an example-based method that highlights\ninfluential past patients. Results: Machine learning models trained on tabular\ndata exhibit a 76% accuracy for the Random Forest model at predicting relapse\nevaluated with a 10-fold cross-validation (model was trained 10 times with\ndifferent independent sets of patients in test, train and validation sets, the\nreported metrics are averaged over these 10 test sets). Graph machine learning\nreaches 68% accuracy over a 200-patient, held-out test set, calibrated on a\nheld-out set of 100 patients. Conclusions: Our results show that machine\nlearning models trained on tabular and graph data can enable objective,\npersonalised and reproducible prediction of relapse and therefore, disease\noutcome in patients with early-stage NSCLC. With further prospective and\nmultisite validation, and additional radiological and molecular data, this\nprognostic model could potentially serve as a predictive decision support tool\nfor deciding the use of adjuvant treatments in early-stage lung cancer.\nKeywords: Non-Small-Cell Lung Cancer, Tumor Recurrence Prediction, Machine\nLearning",
    "descriptor": "",
    "authors": [
      "Adrianna Janik",
      "Maria Torrente",
      "Luca Costabello",
      "Virginia Calvo",
      "Brian Walsh",
      "Carlos Camps",
      "Sameh K. Mohamed",
      "Ana L. Ortega",
      "V\u00edt Nov\u00e1\u010dek",
      "Bartomeu Massut\u00ed",
      "Pasquale Minervini",
      "M.Rosario Garcia Campelo",
      "Edel del Barco",
      "Joaquim Bosch-Barrera",
      "Ernestina Menasalvas",
      "Mohan Timilsina",
      "Mariano Provencio"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.09856"
  },
  {
    "id": "arXiv:2211.09858",
    "title": "Robust Vocal Quality Feature Embeddings for Dysphonic Voice Detection",
    "abstract": "Approximately 1.2% of the world's population has impaired voice production.\nAs a result, automatic dysphonic voice detection has attracted considerable\nacademic and clinical interest. However, existing methods for automated voice\nassessment often fail to generalize outside the training conditions or to other\nrelated applications. In this paper, we propose a deep learning framework for\ngenerating acoustic feature embeddings sensitive to vocal quality and robust\nacross different corpora. A contrastive loss is combined with a classification\nloss to train our deep learning model jointly. Data warping methods are used on\ninput voice samples to improve the robustness of our method. Empirical results\ndemonstrate that our method not only achieves high in-corpus and cross-corpus\nclassification accuracy but also generates good embeddings sensitive to voice\nquality and robust across different corpora. We also compare our results\nagainst three baseline methods on clean and three variations of deteriorated\nin-corpus and cross-corpus datasets and demonstrate that the proposed model\nconsistently outperforms the baseline methods.",
    "descriptor": "\nComments: This manuscript is submitted on July 06, 2022 to IEEE/ACM Transactions on Audio, Speech, and Language Processing for peer-review\n",
    "authors": [
      "Jianwei Zhang",
      "Julie Liss",
      "Suren Jayasuriya",
      "Visar Berisha"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.09858"
  },
  {
    "id": "arXiv:2211.09859",
    "title": "Data-Centric Debugging: mitigating model failures via targeted data  collection",
    "abstract": "Deep neural networks can be unreliable in the real world when the training\nset does not adequately cover all the settings where they are deployed.\nFocusing on image classification, we consider the setting where we have an\nerror distribution $\\mathcal{E}$ representing a deployment scenario where the\nmodel fails. We have access to a small set of samples $\\mathcal{E}_{sample}$\nfrom $\\mathcal{E}$ and it can be expensive to obtain additional samples. In the\ntraditional model development framework, mitigating failures of the model in\n$\\mathcal{E}$ can be challenging and is often done in an ad hoc manner. In this\npaper, we propose a general methodology for model debugging that can\nsystemically improve model performance on $\\mathcal{E}$ while maintaining its\nperformance on the original test set. Our key assumption is that we have access\nto a large pool of weakly (noisily) labeled data $\\mathcal{F}$. However,\nnaively adding $\\mathcal{F}$ to the training would hurt model performance due\nto the large extent of label noise. Our Data-Centric Debugging (DCD) framework\ncarefully creates a debug-train set by selecting images from $\\mathcal{F}$ that\nare perceptually similar to the images in $\\mathcal{E}_{sample}$. To do this,\nwe use the $\\ell_2$ distance in the feature space (penultimate layer\nactivations) of various models including ResNet, Robust ResNet and DINO where\nwe observe DINO ViTs are significantly better at discovering similar images\ncompared to Resnets. Compared to LPIPS, we find that our method reduces compute\nand storage requirements by 99.58\\%. Compared to the baselines that maintain\nmodel performance on the test set, we achieve significantly (+9.45\\%) improved\nresults on the debug-heldout sets.",
    "descriptor": "",
    "authors": [
      "Sahil Singla",
      "Atoosa Malemir Chegini",
      "Mazda Moayeri",
      "Soheil Feiz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09859"
  },
  {
    "id": "arXiv:2211.09861",
    "title": "Self-Supervised Visual Representation Learning via Residual Momentum",
    "abstract": "Self-supervised learning (SSL) approaches have shown promising capabilities\nin learning the representation from unlabeled data. Amongst them,\nmomentum-based frameworks have attracted significant attention. Despite being a\ngreat success, these momentum-based SSL frameworks suffer from a large gap in\nrepresentation between the online encoder (student) and the momentum encoder\n(teacher), which hinders performance on downstream tasks. This paper is the\nfirst to investigate and identify this invisible gap as a bottleneck that has\nbeen overlooked in the existing SSL frameworks, potentially preventing the\nmodels from learning good representation. To solve this problem, we propose\n\"residual momentum\" to directly reduce this gap to encourage the student to\nlearn the representation as close to that of the teacher as possible, narrow\nthe performance gap with the teacher, and significantly improve the existing\nSSL. Our method is straightforward, easy to implement, and can be easily\nplugged into other SSL frameworks. Extensive experimental results on numerous\nbenchmark datasets and diverse network architectures have demonstrated the\neffectiveness of our method over the state-of-the-art contrastive learning\nbaselines.",
    "descriptor": "\nComments: 18 pages, 16 figures\n",
    "authors": [
      "Trung X. Pham",
      "Axi Niu",
      "Zhang Kang",
      "Sultan Rizky Madjid",
      "Ji Woo Hong",
      "Daehyeok Kim",
      "Joshua Tian Jin Tee",
      "Chang D. Yoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09861"
  },
  {
    "id": "arXiv:2211.09864",
    "title": "SafeBound: A Practical System for Generating Cardinality Bounds",
    "abstract": "Recent work has reemphasized the importance of cardinality estimates for\nquery optimization. While new techniques have continuously improved in accuracy\nover time, they still generally allow for under-estimates which often lead\noptimizers to make overly optimistic decisions. This can be very costly for\nexpensive queries. An alternative approach to estimation is cardinality\nbounding, also called pessimistic cardinality estimation, where the cardinality\nestimator provides guaranteed upper bounds of the true cardinality. By never\nunderestimating, this approach allows the optimizer to avoid potentially\ninefficient plans. However, existing pessimistic cardinality estimators are not\nyet practical: they use very limited statistics on the data, and cannot handle\npredicates. In this paper, we introduce SafeBound, the first practical system\nfor generating cardinality bounds. SafeBound builds on a recent theoretical\nwork that uses degree sequences on join attributes to compute cardinality\nbounds, extends this framework with predicates, introduces a practical\ncompression method for the degree sequences, and implements an efficient\ninference algorithm. Across four workloads, SafeBound achieves up to 80% lower\nend-to-end runtimes than PostgreSQL, and is on par or better than state of the\nart ML-based estimators and pessimistic cardinality estimators, by improving\nthe runtime of the expensive queries. It also saves up to 500x in query\nplanning time, and uses up to 6.8x less space compared to state of the art\ncardinality estimation methods.",
    "descriptor": "",
    "authors": [
      "Kyle Deeds",
      "Dan Suciu",
      "Magda Balazinska"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.09864"
  },
  {
    "id": "arXiv:2211.09865",
    "title": "Gender Bias in Big Data Analysis",
    "abstract": "This article combines humanistic \"data critique\" with informed inspection of\nbig data analysis. It measures gender bias when gender prediction software\ntools (Gender API, Namsor, and Genderize.io) are used in historical big data\nresearch. Gender bias is measured by contrasting personally identified computer\nscience authors in the well-regarded DBLP dataset (1950-1980) with exactly\ncomparable results from the software tools. Implications for public\nunderstanding of gender bias in computing and the nature of the computing\nprofession are outlined. Preliminary assessment of the Semantic Scholar dataset\nis presented. The conclusion combines humanistic approaches with selective use\nof big data methods.",
    "descriptor": "\nComments: 27 pages, 1 figure, 3 tables\n",
    "authors": [
      "Thomas J. Misa"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.09865"
  },
  {
    "id": "arXiv:2211.09869",
    "title": "RenderDiffusion: Image Diffusion for 3D Reconstruction, Inpainting and  Generation",
    "abstract": "Diffusion models currently achieve state-of-the-art performance for both\nconditional and unconditional image generation. However, so far, image\ndiffusion models do not support tasks required for 3D understanding, such as\nview-consistent 3D generation or single-view object reconstruction. In this\npaper, we present RenderDiffusion as the first diffusion model for 3D\ngeneration and inference that can be trained using only monocular 2D\nsupervision. At the heart of our method is a novel image denoising architecture\nthat generates and renders an intermediate three-dimensional representation of\na scene in each denoising step. This enforces a strong inductive structure into\nthe diffusion process that gives us a 3D consistent representation while only\nrequiring 2D supervision. The resulting 3D representation can be rendered from\nany viewpoint. We evaluate RenderDiffusion on ShapeNet and Clevr datasets and\nshow competitive performance for generation of 3D scenes and inference of 3D\nscenes from 2D images. Additionally, our diffusion-based approach allows us to\nuse 2D inpainting to edit 3D scenes. We believe that our work promises to\nenable full 3D generation at scale when trained on massive image collections,\nthus circumventing the need to have large-scale 3D model collections for\nsupervision.",
    "descriptor": "\nComments: We will release our datasets, code, and checkpoints at this https URL\n",
    "authors": [
      "Titas Anciukevi\u010dius",
      "Zexiang Xu",
      "Matthew Fisher",
      "Paul Henderson",
      "Hakan Bilen",
      "Niloy J. Mitra",
      "Paul Guerrero"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09869"
  },
  {
    "id": "arXiv:2211.09878",
    "title": "Reducing Hallucinations in Neural Machine Translation with Feature  Attribution",
    "abstract": "Neural conditional language generation models achieve the state-of-the-art in\nNeural Machine Translation (NMT) but are highly dependent on the quality of\nparallel training dataset. When trained on low-quality datasets, these models\nare prone to various error types, including hallucinations, i.e. outputs that\nare fluent, but unrelated to the source sentences. These errors are\nparticularly dangerous, because on the surface the translation can be perceived\nas a correct output, especially if the reader does not understand the source\nlanguage. We present a case study focusing on model understanding and\nregularisation to reduce hallucinations in NMT. We first use feature\nattribution methods to study the behaviour of an NMT model that produces\nhallucinations. We then leverage these methods to propose a novel loss function\nthat substantially helps reduce hallucinations and does not require retraining\nthe model from scratch.",
    "descriptor": "",
    "authors": [
      "Jo\u00ebl Tang",
      "Marina Fomicheva",
      "Lucia Specia"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.09878"
  },
  {
    "id": "arXiv:2211.09892",
    "title": "Summarizing Community-based Question-Answer Pairs",
    "abstract": "Community-based Question Answering (CQA), which allows users to acquire their\ndesired information, has increasingly become an essential component of online\nservices in various domains such as E-commerce, travel, and dining. However, an\noverwhelming number of CQA pairs makes it difficult for users without\nparticular intent to find useful information spread over CQA pairs. To help\nusers quickly digest the key information, we propose the novel CQA\nsummarization task that aims to create a concise summary from CQA pairs. To\nthis end, we first design a multi-stage data annotation process and create a\nbenchmark dataset, CoQASUM, based on the Amazon QA corpus. We then compare a\ncollection of extractive and abstractive summarization methods and establish a\nstrong baseline approach DedupLED for the CQA summarization task. Our\nexperiment further confirms two key challenges, sentence-type transfer and\ndeduplication removal, towards the CQA summarization task. Our data and code\nare publicly available.",
    "descriptor": "\nComments: To appear in EMNLP 2022 main conference\n",
    "authors": [
      "Ting-Yao Hsu",
      "Yoshi Suhara",
      "Xiaolan Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.09892"
  },
  {
    "id": "arXiv:2211.09894",
    "title": "Features Compression based on Counterfactual Analysis",
    "abstract": "Counterfactual Explanations are becoming a de-facto standard in post-hoc\ninterpretable machine learning. For a given classifier and an instance\nclassified in an undesired class, its counterfactual explanation corresponds to\nsmall perturbations of that instance that allow changing the classification\noutcome. This work aims to leverage Counterfactual Explanations to detect the\nimportant decision boundaries of a pre-trained black-box model. This\ninformation is used to build a supervised discretization of the features in the\ndataset with a tunable granularity. A small and interpretable Decision Tree is\ntrained on the discretized dataset that is stable and robust. Numerical results\non real-world datasets show the effectiveness of the approach.",
    "descriptor": "\nComments: 29 pages, 12 figures\n",
    "authors": [
      "Veronica Piccialli",
      "Dolores Romero Morales",
      "Cecilia Salvatore"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.09894"
  },
  {
    "id": "arXiv:2211.09896",
    "title": "Activity Detection in Distributed Massive MIMO With Pilot-Hopping and  Activity Correlation",
    "abstract": "Many real-world scenarios for massive machine-type communication involve\nsensors monitoring a physical phenomenon. As a consequence, the activity\npattern of these sensors will be correlated. In this letter, we study how the\ncorrelation of user activities can be exploited to improve detection\nperformance in grant-free random access systems where the users transmit\npilot-hopping sequences and the detection is performed based on the received\nenergy. We show that we can expect considerable performance gains by adding\nregularizers, which take the activity correlation into account, to the\nnon-negative least squares, which has been shown to work well for independent\nuser activity.",
    "descriptor": "\nComments: 5 pages, 3 figures. This paper has been accepted for publication in IEEE Wireless Communications Letters\n",
    "authors": [
      "Ema Becirovic",
      "Emil Bj\u00f6rnson",
      "Erik G. Larsson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.09896"
  },
  {
    "id": "arXiv:2211.09898",
    "title": "Audio Anti-spoofing Using a Simple Attention Module and Joint  Optimization Based on Additive Angular Margin Loss and Meta-learning",
    "abstract": "Automatic speaker verification systems are vulnerable to a variety of access\nthreats, prompting research into the formulation of effective spoofing\ndetection systems to act as a gate to filter out such spoofing attacks. This\nstudy introduces a simple attention module to infer 3-dim attention weights for\nthe feature map in a convolutional layer, which then optimizes an energy\nfunction to determine each neuron's importance. With the advancement of both\nvoice conversion and speech synthesis technologies, unseen spoofing attacks are\nconstantly emerging to limit spoofing detection system performance. Here, we\npropose a joint optimization approach based on the weighted additive angular\nmargin loss for binary classification, with a meta-learning training framework\nto develop an efficient system that is robust to a wide range of spoofing\nattacks for model generalization enhancement. As a result, when compared to\ncurrent state-of-the-art systems, our proposed approach delivers a competitive\nresult with a pooled EER of 0.99% and min t-DCF of 0.0289.",
    "descriptor": "\nComments: Interspeech 2022\n",
    "authors": [
      "Zhenyu Wang",
      "John H.L. Hansen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.09898"
  },
  {
    "id": "arXiv:2211.09913",
    "title": "Multi-source Domain Adaptation for Text-independent Forensic Speaker  Recognition",
    "abstract": "Adapting speaker recognition systems to new environments is a widely-used\ntechnique to improve a well-performing model learned from large-scale data\ntowards a task-specific small-scale data scenarios. However, previous studies\nfocus on single domain adaptation, which neglects a more practical scenario\nwhere training data are collected from multiple acoustic domains needed in\nforensic scenarios. Audio analysis for forensic speaker recognition offers\nunique challenges in model training with multi-domain training data due to\nlocation/scenario uncertainty and diversity mismatch between reference and\nnaturalistic field recordings. It is also difficult to directly employ\nsmall-scale domain-specific data to train complex neural network architectures\ndue to domain mismatch and performance loss. Fine-tuning is a commonly-used\nmethod for adaptation in order to retrain the model with weights initialized\nfrom a well-trained model. Alternatively, in this study, three novel adaptation\nmethods based on domain adversarial training, discrepancy minimization, and\nmoment-matching approaches are proposed to further promote adaptation\nperformance across multiple acoustic domains. A comprehensive set of\nexperiments are conducted to demonstrate that: 1) diverse acoustic environments\ndo impact speaker recognition performance, which could advance research in\naudio forensics, 2) domain adversarial training learns the discriminative\nfeatures which are also invariant to shifts between domains, 3)\ndiscrepancy-minimizing adaptation achieves effective performance simultaneously\nacross multiple acoustic domains, and 4) moment-matching adaptation along with\ndynamic distribution alignment also significantly promotes speaker recognition\nperformance on each domain, especially for the LENA-field domain with noise\ncompared to all other systems.",
    "descriptor": "\nComments: IEEE/ACM TRANSACTIONS ON AUDIO, SPEECH, AND LANGUAGE PROCESSING\n",
    "authors": [
      "Zhenyu Wang",
      "John H. L. Hansen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.09913"
  },
  {
    "id": "arXiv:2211.09916",
    "title": "Online Distribution Shift Detection via Recency Prediction",
    "abstract": "When deploying modern machine learning-enabled robotic systems in high-stakes\napplications, detecting distribution shift is critical. However, most existing\nmethods for detecting distribution shift are not well-suited to robotics\nsettings, where data often arrives in a streaming fashion and may be very\nhigh-dimensional. In this work, we present an online method for detecting\ndistribution shift with guarantees on the false positive rate - i.e., when\nthere is no distribution shift, our system is very unlikely (with probability\n$< \\epsilon$) to falsely issue an alert; any alerts that are issued should\ntherefore be heeded. Our method is specifically designed for efficient\ndetection even with high dimensional data, and it empirically achieves up to\n11x faster detection on realistic robotics settings compared to prior work\nwhile maintaining a low false negative rate in practice (whenever there is a\ndistribution shift in our experiments, our method indeed emits an alert).",
    "descriptor": "",
    "authors": [
      "Rachel Luo",
      "Rohan Sinha",
      "Ali Hindy",
      "Shengjia Zhao",
      "Silvio Savarese",
      "Edward Schmerling",
      "Marco Pavone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09916"
  },
  {
    "id": "arXiv:2211.09919",
    "title": "Patch-Craft Self-Supervised Training for Correlated Image Denoising",
    "abstract": "Supervised neural networks are known to achieve excellent results in various\nimage restoration tasks. However, such training requires datasets composed of\npairs of corrupted images and their corresponding ground truth targets.\nUnfortunately, such data is not available in many applications. For the task of\nimage denoising in which the noise statistics is unknown, several\nself-supervised training methods have been proposed for overcoming this\ndifficulty. Some of these require knowledge of the noise model, while others\nassume that the contaminating noise is uncorrelated, both assumptions are too\nlimiting for many practical needs. This work proposes a novel self-supervised\ntraining technique suitable for the removal of unknown correlated noise. The\nproposed approach neither requires knowledge of the noise model nor access to\nground truth targets. The input to our algorithm consists of easily captured\nbursts of noisy shots. Our algorithm constructs artificial patch-craft images\nfrom these bursts by patch matching and stitching, and the obtained crafted\nimages are used as targets for the training. Our method does not require\nregistration of the images within the burst. We evaluate the proposed framework\nthrough extensive experiments with synthetic and real image noise.",
    "descriptor": "",
    "authors": [
      "Gregory Vaksman",
      "Michael Elad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09919"
  },
  {
    "id": "arXiv:2211.09923",
    "title": "Proceedings of the 2nd Workshop on Logic and Practice of Programming  (LPOP)",
    "abstract": "This proceedings contains abstracts and position papers for the work\npresented at the second Logic and Practice of Programming (LPOP) Workshop. The\nworkshop was held online, virtually in place of Chicago, USA, on November 15,\n2010, in conjunction with the ACM SIGPLAN Conference on Systems, Programming,\nLanguages, and Applications: Software for Humanity (SPLASH) 2020. The purpose\nof this workshop is to be a bridge between different areas of computer science\nthat use logic as a practical tool. We take advantage of the common language of\nformal logic to exchange ideas between these different areas.",
    "descriptor": "",
    "authors": [
      "David S. Warren",
      "Peter Van Roy",
      "Yanhong A. Liu"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.09923"
  },
  {
    "id": "arXiv:2211.09924",
    "title": "From LQR to Static Output Feedback: a New LMI Approach",
    "abstract": "This paper proposes a new Linear Matrix Inequality (LMI) for static output\nfeedback control assuming that a Linear Quadratic Regulator (LQR) has been\npreviously designed for the system. The main idea is to use a quadratic\ncandidate Lyapunov function for the closed-loop system parameterized by the\nunique positive definite matrix that solves the Riccati equation. A converse\nresult will also be proved guaranteeing the existence of matrices verifying the\nLMI if the system is static output feedback stabilizable. The proposed method\nwill then be extended to the design of static output feedback for the H1\ncontrol problem. Besides being a sufficient condition for which a converse\nresult is proved, there are another four main advantages of the proposed\nmethodology. First, it is computationally tractable. Second, one can use\nweighting matrices and obtain a solution in a similar way to LQR design. Third,\nthe proposed method has an extremely simple LMI structure when compared with\nother LMI methods proposed in the literature. Finally, for the cases where the\noutput is equal to the state it is shown that the LQR solution verifies the\nproposed LMI. Therefore, the static output feedback includes the LQR solution\nas a special case when the state is available, which is a desired property.\nSeveral examples show that the method is consistently successful and works well\nin practice.",
    "descriptor": "\nComments: published in IEEE Conference on Decision and Control 2022\n",
    "authors": [
      "Luis Rodrigues"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.09924"
  },
  {
    "id": "arXiv:2211.09925",
    "title": "FairMILE: A Multi-Level Framework for Fair and Scalable Graph  Representation Learning",
    "abstract": "Graph representation learning models have been deployed for making decisions\nin multiple high-stakes scenarios. It is therefore critical to ensure that\nthese models are fair. Prior research has shown that graph neural networks can\ninherit and reinforce the bias present in graph data. Researchers have begun to\nexamine ways to mitigate the bias in such models. However, existing efforts are\nrestricted by their inefficiency, limited applicability, and the constraints\nthey place on sensitive attributes. To address these issues, we present\nFairMILE a general framework for fair and scalable graph representation\nlearning. FairMILE is a multi-level framework that allows contemporary\nunsupervised graph embedding methods to scale to large graphs in an agnostic\nmanner. FairMILE learns both fair and high-quality node embeddings where the\nfairness constraints are incorporated in each phase of the framework. Our\nexperiments across two distinct tasks demonstrate that FairMILE can learn node\nrepresentations that often achieve superior fairness scores and high downstream\nperformance while significantly outperforming all the baselines in terms of\nefficiency.",
    "descriptor": "",
    "authors": [
      "Yuntian He",
      "Saket Gurukar",
      "Srinivasan Parthasarathy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.09925"
  },
  {
    "id": "arXiv:2211.09927",
    "title": "SAR-based landslide classification pretraining leads to better  segmentation",
    "abstract": "Rapid assessment after a natural disaster is key for prioritizing emergency\nresources. In the case of landslides, rapid assessment involves determining the\nextent of the area affected and measuring the size and location of individual\nlandslides. Synthetic Aperture Radar (SAR) is an active remote sensing\ntechnique that is unaffected by weather conditions. Deep Learning algorithms\ncan be applied to SAR data, but training them requires large labeled datasets.\nIn the case of landslides, these datasets are laborious to produce for\nsegmentation, and often they are not available for the specific region in which\nthe event occurred. Here, we study how deep learning algorithms for landslide\nsegmentation on SAR products can benefit from pretraining on a simpler task and\nfrom data from different regions. The method we explore consists of two\ntraining stages. First, we learn the task of identifying whether a SAR image\ncontains any landslides or not. Then, we learn to segment in a sparsely labeled\nscenario where half of the data do not contain landslides. We test whether the\ninclusion of feature embeddings derived from stage-1 helps with landslide\ndetection in stage-2. We find that it leads to minor improvements in the Area\nUnder the Precision-Recall Curve, but also to a significantly lower false\npositive rate in areas without landslides and an improved estimate of the\naverage number of landslide pixels in a chip. A more accurate pixel count\nallows to identify the most affected areas with higher confidence. This could\nbe valuable in rapid response scenarios where prioritization of resources at a\nglobal scale is important. We make our code publicly available at\nhttps://github.com/VMBoehm/SAR-landslide-detection-pretraining.",
    "descriptor": "\nComments: Accepted to the NeurIPS 2022 workshop Artificial Intelligence for Humanitarian Assistance and Disaster Response. This research was conducted as part of the Frontier Development Lab (FDL) 2022\n",
    "authors": [
      "Vanessa B\u00f6hm",
      "Wei Ji Leong",
      "Ragini Bal Mahesh",
      "Ioannis Prapas",
      "Edoardo Nemni",
      "Freddie Kalaitzis",
      "Siddha Ganju",
      "Raul Ramos-Pollan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.09927"
  },
  {
    "id": "arXiv:2211.09928",
    "title": "SMS: Spiking Marching Scheme for Efficient Long Time Integration of  Differential Equations",
    "abstract": "We propose a Spiking Neural Network (SNN)-based explicit numerical scheme for\nlong time integration of time-dependent Ordinary and Partial Differential\nEquations (ODEs, PDEs). The core element of the method is a SNN, trained to use\nspike-encoded information about the solution at previous timesteps to predict\nspike-encoded information at the next timestep. After the network has been\ntrained, it operates as an explicit numerical scheme that can be used to\ncompute the solution at future timesteps, given a spike-encoded initial\ncondition. A decoder is used to transform the evolved spiking-encoded solution\nback to function values. We present results from numerical experiments of using\nthe proposed method for ODEs and PDEs of varying complexity.",
    "descriptor": "\nComments: 14 pages, 7 figures\n",
    "authors": [
      "Qian Zhang",
      "Adar Kahana",
      "George Em Karniadakis",
      "Panos Stinis"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.09928"
  },
  {
    "id": "arXiv:2211.09929",
    "title": "Contrastive Credibility Propagation for Reliable Semi-Supervised  Learning",
    "abstract": "Inferencing unlabeled data from labeled data is an error-prone process.\nConventional neural network training is highly sensitive to supervision errors.\nThese two realities make semi-supervised learning (SSL) troublesome. Often, SSL\napproaches fail to outperform their fully supervised baseline. Proposed is a\nnovel framework for deep SSL, specifically pseudo-labeling, called contrastive\ncredibility propagation (CCP). Through an iterative process of generating and\nrefining soft pseudo-labels, CCP unifies a novel contrastive approach to\ngenerating pseudo-labels and a powerful technique to overcome instance-based\nlabel noise. The result is a semi-supervised classification framework\nexplicitly designed to overcome inevitable pseudo-label errors in an attempt to\nreliably boost performance over a supervised baseline. Our empirical evaluation\nacross five benchmark classification datasets suggests one must choose between\nreliability or effectiveness with prior approaches while CCP delivers both. We\nalso demonstrate an unsupervised signal to subsample pseudo-labels to eliminate\nerrors between iterations of CCP and after its conclusion.",
    "descriptor": "",
    "authors": [
      "Brody Kutt",
      "Pamela Toman",
      "Xavier Mignot",
      "Sujit Rokka Chhetri",
      "Shan Huang",
      "Nandini Ramanan",
      "Min Du",
      "William Hewlett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09929"
  },
  {
    "id": "arXiv:2211.09932",
    "title": "Simple Digital Controls from Approximate Plant Models",
    "abstract": "Two ways of designing low-order discrete-time (i.e. digital) controls for\nlow-order plant (i.e. process) models are considered in this tutorial. The\nfirst polynomial method finds the controller coefficients that place the poles\nof the closed-loop feedback system at specified positions for adroit controls,\ni.e. for a rapid and compressed transient response, when the plant model is\nknown precisely. The poles and zeros of the resulting controller are\nunconstrainted, although an integrator may be included in the controller\nstructure as a special case to drive steady-state errors towards zero. The\nsecond frequency method ensures that the feedback system has the desired\nphase-margin at a specified gain cross-over frequency (for the desired\nbandwidth) yielding robust stability with respect to plant model uncertainty.\nThe poles of the controller are at specified positions, e.g. for a standard\nProportional-Integral (PI), Proportional-Derivative (PD),\nProportional-Integral-Derivative (PID), structure or other more general\nconfigurations if necessary, and the problem is solved for the controller\nzeros. The poles and zeros of the resulting closed-loop feedback system are\nunconstrained. These complementary design procedures allow simple and effective\ncontrols to be derived analytically from a plant model, using a matrix inverse\noperation to solve a small set of linear simultaneous equations, as an\nalternative to more heuristic (e.g. trial-and-error) or empirical PID-tuning\napproaches. An azimuth controller for a pan-tilt-zoom camera mount is used as\nan illustrative example. The ways in which both procedures may be used to\ndesign controls with the desired balance between adroitness and robustness are\ndiscussed.",
    "descriptor": "",
    "authors": [
      "Hugh Lachlan Kennedy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.09932"
  },
  {
    "id": "arXiv:2211.09933",
    "title": "Fields: Towards Socially Intelligent Spatial Computing",
    "abstract": "In our everyday life, we intuitively use space to regulate our social\ninteractions. When we want to talk to someone, we approach them; if someone\njoins the conversation, we adjust our bodies to make space for them. In\ncontrast, devices are not as considerate: they interrupt us, require us to\ninput commands, and compete for our attention. In this paper, we introduce\nFields, a design framework for ubiquitous computing that informs the design of\nconnected products with social grace. Inspired by interactionist theories on\nsocial interaction, Fields builds on the idea that the physical space we share\nwith computers can be an interface to mediate interactions. It defines a\ngeneralized approach to spatial interactions, and a set of interaction patterns\nthat can be adapted to different ubiquitous computing systems. We investigated\nits value by implementing it in a set of prototypes and evaluating it in a lab\nsetting.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Leonardo Giusti",
      "Lauren Bedal",
      "Eiji Hayashi",
      "Jin Yamanaka",
      "Timi Oyedeji",
      "Colin Bay",
      "Ivan Poupyrev"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.09933"
  },
  {
    "id": "arXiv:2211.09935",
    "title": "Planning with Large Language Models via Corrective Re-prompting",
    "abstract": "Extracting the common sense knowledge present in Large Language Models (LLMs)\noffers a path to designing intelligent, embodied agents. Related works have\nqueried LLMs with a wide-range of contextual information, such as goals, sensor\nobservations and scene descriptions, to generate high-level action plans for\nspecific tasks; however these approaches often involve human intervention or\nadditional machinery to enable sensor-motor interactions. In this work, we\npropose a prompting-based strategy for extracting executable plans from an LLM,\nwhich leverages a novel and readily-accessible source of information:\nprecondition errors. Our approach assumes that actions are only afforded\nexecution in certain contexts, i.e., implicit preconditions must be met for an\naction to execute (e.g., a door must be unlocked to open it), and that the\nembodied agent has the ability to determine if the action is/is not executable\nin the current context (e.g., detect if a precondition error is present). When\nan agent is unable to execute an action, our approach re-prompts the LLM with\nprecondition error information to extract an executable corrective action to\nachieve the intended goal in the current context. We evaluate our approach in\nthe VirtualHome simulation environment on 88 different tasks and 7 scenes. We\nevaluate different prompt templates and compare to methods that naively\nre-sample actions from the LLM. Our approach, using precondition errors,\nimproves executability and semantic correctness of plans, while also reducing\nthe number of re-prompts required when querying actions.",
    "descriptor": "\nComments: 21 pages, 7 figures, Accepted to Foundation Models for Decision Making Workshop at Neural Information Processing Systems 2022\n",
    "authors": [
      "Shreyas Sundara Raman",
      "Vanya Cohen",
      "Eric Rosen",
      "Ifrah Idrees",
      "David Paulius",
      "Stefanie Tellex"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.09935"
  },
  {
    "id": "arXiv:2211.09937",
    "title": "Explainability Via Causal Self-Talk",
    "abstract": "Explaining the behavior of AI systems is an important problem that, in\npractice, is generally avoided. While the XAI community has been developing an\nabundance of techniques, most incur a set of costs that the wider deep learning\ncommunity has been unwilling to pay in most situations. We take a pragmatic\nview of the issue, and define a set of desiderata that capture both the\nambitions of XAI and the practical constraints of deep learning. We describe an\neffective way to satisfy all the desiderata: train the AI system to build a\ncausal model of itself. We develop an instance of this solution for Deep RL\nagents: Causal Self-Talk. CST operates by training the agent to communicate\nwith itself across time. We implement this method in a simulated 3D\nenvironment, and show how it enables agents to generate faithful and\nsemantically-meaningful explanations of their own behavior. Beyond\nexplanations, we also demonstrate that these learned models provide new ways of\nbuilding semantic control interfaces to AI systems.",
    "descriptor": "",
    "authors": [
      "Nicholas A. Roy",
      "Junkyung Kim",
      "Neil Rabinowitz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09937"
  },
  {
    "id": "arXiv:2211.09938",
    "title": "Progressive Hologram Generation Based on Object Saliency",
    "abstract": "Computer-generated hologram (CGH) is promised to realize the next generation\nof 3D visual media with life-changing applications. However, one of the\nessential obstacles to this technology is the time-consuming hologram\ncomputation. Thus, facilitating the computation of the generated hologram is of\nsignificant importance in this area. We propose a progressive hologram\ngeneration based on object saliency using discrete wavelet transform. In our\nmethod, the object is decomposed into 3 levels of resolution using wavelet\ntransform. Then, based on the saliency of the object, a progressive resolution\nhologram is generated. Our model generates a low resolution hologram for\nnon-salient areas of an object and a high-resolution hologram for salient\nareas, thus reducing CGH generation time. We applied our method to a number of\nobjects and show that salient parts are reconstructed with high quality while\nit helps the process to speed up. Finally, we compare the SSIM of the\nreconstructed objects.",
    "descriptor": "",
    "authors": [
      "Shima Rafiei",
      "Shahram Shirani"
    ],
    "subjectives": [
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.09938"
  },
  {
    "id": "arXiv:2211.09940",
    "title": "Expert Selection in Distributed Gaussian Processes: A Multi-label  Classification Approach",
    "abstract": "By distributing the training process, local approximation reduces the cost of\nthe standard Gaussian Process. An ensemble technique combines local predictions\nfrom Gaussian experts trained on different partitions of the data by assuming a\nperfect diversity of local predictors. Although it keeps the aggregation\ntractable, this assumption is often violated in practice. Taking dependencies\nbetween experts enables ensemble methods to provide consistent results.\nHowever, they have a high computational cost, which is cubic in the number of\nexperts involved. By implementing an expert selection strategy, the final\naggregation step uses fewer experts and is more efficient. Indeed, a static\nselection approach that assigns a fixed set of experts to each new data point\ncannot encode the specific properties of each unique data point. This paper\nproposes a flexible expert selection approach based on the characteristics of\nentry data points. To this end, we investigate the selection task as a\nmulti-label classification problem where the experts define labels, and each\nentry point is assigned to some experts. The proposed solution's prediction\nquality, efficiency, and asymptotic properties are discussed in detail. We\ndemonstrate the efficacy of our method through extensive numerical experiments\nusing synthetic and real-world data sets.",
    "descriptor": "",
    "authors": [
      "Hamed Jalali",
      "Gjergji Kasneci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.09940"
  },
  {
    "id": "arXiv:2211.09942",
    "title": "Professional Presentation and Projected Power: A Case Study of Implicit  Gender Information in English CVs",
    "abstract": "Gender discrimination in hiring is a pertinent and persistent bias in\nsociety, and a common motivating example for exploring bias in NLP. However,\nthe manifestation of gendered language in application materials has received\nlimited attention. This paper investigates the framing of skills and background\nin CVs of self-identified men and women. We introduce a data set of 1.8K\nauthentic, English-language, CVs from the US, covering 16 occupations, allowing\nus to partially control for the confound occupation-specific gender base rates.\nWe find that (1) women use more verbs evoking impressions of low power; and (2)\nclassifiers capture gender signal even after data balancing and removal of\npronouns and named entities, and this holds for both transformer-based and\nlinear classifiers.",
    "descriptor": "\nComments: Accepted at the NLP+CSS 2022 workshop (co-located with EMNLP)\n",
    "authors": [
      "Jinrui Yang",
      "Sheilla Njoto",
      "Marc Cheong",
      "Leah Ruppanner",
      "Lea Frermann"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.09942"
  },
  {
    "id": "arXiv:2211.09944",
    "title": "MelHuBERT: A simplified HuBERT on Mel spectrogram",
    "abstract": "Self-supervised models have had great success in learning speech\nrepresentations that can generalize to various downstream tasks. HuBERT, in\nparticular, achieves strong performance while being relatively simple in\ntraining compared to others. The original experimental setting is\ncomputationally extensive, hindering the reproducibility of the models. It is\nalso unclear why certain design decisions are made, such as the ad-hoc loss\nfunction, and whether these decisions have an impact on the learned\nrepresentations. We propose MelHuBERT, a simplified version of HuBERT that\ntakes Mel spectrograms as input, significantly reducing computation and memory\nconsumption. We study several aspects of training, including the loss function,\nmulti-stage training, and streaming options. Our result is a efficient yet\nperformant model that can be trained on a single GPU.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Tzu-Quan Lin",
      "Hung-yi Lee",
      "Hao Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.09944"
  },
  {
    "id": "arXiv:2211.09945",
    "title": "SparseVLR: A Novel Framework for Verified Locally Robust Sparse Neural  Networks Search",
    "abstract": "The compute-intensive nature of neural networks (NNs) limits their deployment\nin resource-constrained environments such as cell phones, drones, autonomous\nrobots, etc. Hence, developing robust sparse models fit for safety-critical\napplications has been an issue of longstanding interest. Though adversarial\ntraining with model sparsification has been combined to attain the goal,\nconventional adversarial training approaches provide no formal guarantee that\nthe models would be robust against any rogue samples in a restricted space\naround a benign sample. Recently proposed verified local robustness techniques\nprovide such a guarantee. This is the first paper that combines the ideas from\nverified local robustness and dynamic sparse training to develop `SparseVLR'--\na novel framework to search verified locally robust sparse networks. Obtained\nsparse models exhibit accuracy and robustness comparable to their dense\ncounterparts at sparsity as high as 99%. Furthermore, unlike most conventional\nsparsification techniques, SparseVLR does not require a pre-trained dense\nmodel, reducing the training time by 50%. We exhaustively investigated\nSparseVLR's efficacy and generalizability by evaluating various benchmark and\napplication-specific datasets across several models.",
    "descriptor": "\nComments: 16 pages, 9 tables, 7 figures\n",
    "authors": [
      "Sawinder Kaur",
      "Asif Salekin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09945"
  },
  {
    "id": "arXiv:2211.09949",
    "title": "Compressing Transformer-based self-supervised models for speech  processing",
    "abstract": "Despite the success of Transformers in self-supervised learning with\napplications to various downstream tasks, the computational cost of training\nand inference remains a major challenge for applying these models to a wide\nspectrum of devices. Several isolated attempts have been made to compress\nTransformers, prior to applying them to downstream tasks. In this work, we aim\nto provide context for the isolated results, studying several commonly used\ncompression techniques, including weight pruning, head pruning, low-rank\napproximation, and knowledge distillation. We report wall-clock time, the\nnumber of parameters, and the number of multiply-accumulate operations for\nthese techniques, charting the landscape of compressing Transformer-based\nself-supervised models.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Tzu-Quan Lin",
      "Tsung-Huan Yang",
      "Chun-Yao Chang",
      "Kuang-Ming Chen",
      "Tzu-hsun Feng",
      "Hung-yi Lee",
      "Hao Tang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.09949"
  },
  {
    "id": "arXiv:2211.09950",
    "title": "TempNet: Temporal Attention Towards the Detection of Animal Behaviour in  Videos",
    "abstract": "Recent advancements in cabled ocean observatories have increased the quality\nand prevalence of underwater videos; this data enables the extraction of\nhigh-level biologically relevant information such as species' behaviours.\nDespite this increase in capability, most modern methods for the automatic\ninterpretation of underwater videos focus only on the detection and counting\norganisms. We propose an efficient computer vision- and deep learning-based\nmethod for the detection of biological behaviours in videos. TempNet uses an\nencoder bridge and residual blocks to maintain model performance with a\ntwo-staged, spatial, then temporal, encoder. TempNet also presents temporal\nattention during spatial encoding as well as Wavelet Down-Sampling\npre-processing to improve model accuracy. Although our system is designed for\napplications to diverse fish behaviours (i.e, is generic), we demonstrate its\napplication to the detection of sablefish (Anoplopoma fimbria) startle events.\nWe compare the proposed approach with a state-of-the-art end-to-end video\ndetection method (ReMotENet) and a hybrid method previously offered exclusively\nfor the detection of sablefish's startle events in videos from an existing\ndataset. Results show that our novel method comfortably outperforms the\ncomparison baselines in multiple metrics, reaching a per-clip accuracy and\nprecision of 80% and 0.81, respectively. This represents a relative improvement\nof 31% in accuracy and 27% in precision over the compared methods using this\ndataset. Our computational pipeline is also highly efficient, as it can process\neach 4-second video clip in only 38ms. Furthermore, since it does not employ\nfeatures specific to sablefish startle events, our system can be easily\nextended to other behaviours in future works.",
    "descriptor": "\nComments: 6 pages, 5 figures, 2 tables, International Conference on Pattern Recognition, ICPR 2022, ICPR\n",
    "authors": [
      "Declan McIntosh",
      "Tunai Porto Marques",
      "Alexandra Branzan Albu",
      "Rodney Rountree",
      "Fabio De Leo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09950"
  },
  {
    "id": "arXiv:2211.09953",
    "title": "Towards Explaining Subjective Ground of Individuals on Social Media",
    "abstract": "Large-scale language models have been reducing the gap between machines and\nhumans in understanding the real world, yet understanding an individual's\ntheory of mind and behavior from text is far from being resolved.\nThis research proposes a neural model -- Subjective Ground Attention -- that\nlearns subjective grounds of individuals and accounts for their judgments on\nsituations of others posted on social media. Using simple attention modules as\nwell as taking one's previous activities into consideration, we empirically\nshow that our model provides human-readable explanations of an individual's\nsubjective preference in judging social situations. We further qualitatively\nevaluate the explanations generated by the model and claim that our model\nlearns an individual's subjective orientation towards abstract moral concepts",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Younghun Lee",
      "Dan Goldwasser"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.09953"
  },
  {
    "id": "arXiv:2211.09954",
    "title": "Robust DNN Surrogate Models with Uncertainty Quantification via  Adversarial Training",
    "abstract": "For computational efficiency, surrogate models have been used to emulate\nmathematical simulators for physical or biological processes. High-speed\nsimulation is crucial for conducting uncertainty quantification (UQ) when the\nsimulation is repeated over many randomly sampled input points (aka, the Monte\nCarlo method). In some cases, UQ is only feasible with a surrogate model.\nRecently, Deep Neural Network (DNN) surrogate models have gained popularity for\ntheir hard-to-match emulation accuracy. However, it is well-known that DNN is\nprone to errors when input data are perturbed in particular ways, the very\nmotivation for adversarial training. In the usage scenario of surrogate models,\nthe concern is less of a deliberate attack but more of the high sensitivity of\nthe DNN's accuracy to input directions, an issue largely ignored by researchers\nusing emulation models. In this paper, we show the severity of this issue\nthrough empirical studies and hypothesis testing. Furthermore, we adopt methods\nin adversarial training to enhance the robustness of DNN surrogate models.\nExperiments demonstrate that our approaches significantly improve the\nrobustness of the surrogate models without compromising emulation accuracy.",
    "descriptor": "",
    "authors": [
      "Lixiang Zhang",
      "Jia Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09954"
  },
  {
    "id": "arXiv:2211.09955",
    "title": "Emergence of a stochastic resonance in machine learning",
    "abstract": "Can noise be beneficial to machine-learning prediction of chaotic systems?\nUtilizing reservoir computers as a paradigm, we find that injecting noise to\nthe training data can induce a stochastic resonance with significant benefits\nto both short-term prediction of the state variables and long-term prediction\nof the attractor of the system. A key to inducing the stochastic resonance is\nto include the amplitude of the noise in the set of hyperparameters for\noptimization. By so doing, the prediction accuracy, stability and horizon can\nbe dramatically improved. The stochastic resonance phenomenon is demonstrated\nusing two prototypical high-dimensional chaotic systems.",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Zheng-Meng Zhai",
      "Ling-Wei Kong",
      "Ying-Cheng Lai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.09955"
  },
  {
    "id": "arXiv:2211.09959",
    "title": "Potential Auto-driving Threat: Universal Rain-removal Attack",
    "abstract": "The problem of robustness in adverse weather conditions is considered a\nsignificant challenge for computer vision algorithms in the applicants of\nautonomous driving. Image rain removal algorithms are a general solution to\nthis problem. They find a deep connection between raindrops/rain-streaks and\nimages by mining the hidden features and restoring information about the\nrain-free environment based on the powerful representation capabilities of\nneural networks. However, previous research has focused on architecture\ninnovations and has yet to consider the vulnerability issues that already exist\nin neural networks. This research gap hints at a potential security threat\ngeared toward the intelligent perception of autonomous driving in the rain. In\nthis paper, we propose a universal rain-removal attack (URA) on the\nvulnerability of image rain-removal algorithms by generating a non-additive\nspatial perturbation that significantly reduces the similarity and image\nquality of scene restoration. Notably, this perturbation is difficult to\nrecognise by humans and is also the same for different target images. Thus, URA\ncould be considered a critical tool for the vulnerability detection of image\nrain-removal algorithms. It also could be developed as a real-world artificial\nintelligence attack method. Experimental results show that URA can reduce the\nscene repair capability by 39.5% and the image generation quality by 26.4%,\ntargeting the state-of-the-art (SOTA) single-image rain-removal algorithms\ncurrently available.",
    "descriptor": "",
    "authors": [
      "Jinchegn Hu",
      "Jihao Li",
      "Zhuoran Hou",
      "Jingjing Jiang",
      "Cunjia Liu",
      "Yuanjian Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.09959"
  },
  {
    "id": "arXiv:2211.09960",
    "title": "Ask4Help: Learning to Leverage an Expert for Embodied Tasks",
    "abstract": "Embodied AI agents continue to become more capable every year with the advent\nof new models, environments, and benchmarks, but are still far away from being\nperformant and reliable enough to be deployed in real, user-facing,\napplications. In this paper, we ask: can we bridge this gap by enabling agents\nto ask for assistance from an expert such as a human being? To this end, we\npropose the Ask4Help policy that augments agents with the ability to request,\nand then use expert assistance. Ask4Help policies can be efficiently trained\nwithout modifying the original agent's parameters and learn a desirable\ntrade-off between task performance and the amount of requested help, thereby\nreducing the cost of querying the expert. We evaluate Ask4Help on two different\ntasks -- object goal navigation and room rearrangement and see substantial\nimprovements in performance using minimal help. On object navigation, an agent\nthat achieves a $52\\%$ success rate is raised to $86\\%$ with $13\\%$ help and\nfor rearrangement, the state-of-the-art model with a $7\\%$ success rate is\ndramatically improved to $90.4\\%$ using $39\\%$ help. Human trials with Ask4Help\ndemonstrate the efficacy of our approach in practical scenarios. We release the\ncode for Ask4Help here: https://github.com/allenai/ask4help.",
    "descriptor": "\nComments: Accepted at NeurIPS, 2022\n",
    "authors": [
      "Kunal Pratap Singh",
      "Luca Weihs",
      "Alvaro Herrasti",
      "Jonghyun Choi",
      "Aniruddha Kemhavi",
      "Roozbeh Mottaghi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.09960"
  },
  {
    "id": "arXiv:2211.09961",
    "title": "Path Independent Equilibrium Models Can Better Exploit Test-Time  Computation",
    "abstract": "Designing networks capable of attaining better performance with an increased\ninference budget is important to facilitate generalization to harder problem\ninstances. Recent efforts have shown promising results in this direction by\nmaking use of depth-wise recurrent networks. We show that a broad class of\narchitectures named equilibrium models display strong upwards generalization,\nand find that stronger performance on harder examples (which require more\niterations of inference to get correct) strongly correlates with the path\nindependence of the system -- its tendency to converge to the same steady-state\nbehaviour regardless of initialization, given enough computation. Experimental\ninterventions made to promote path independence result in improved\ngeneralization on harder problem instances, while those that penalize it\ndegrade this ability. Path independence analyses are also useful on a\nper-example basis: for equilibrium models that have good in-distribution\nperformance, path independence on out-of-distribution samples strongly\ncorrelates with accuracy. Our results help explain why equilibrium models are\ncapable of strong upwards generalization and motivates future work that\nharnesses path independence as a general modelling principle to facilitate\nscalable test-time usage.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Cem Anil",
      "Ashwini Pokle",
      "Kaiqu Liang",
      "Johannes Treutlein",
      "Yuhuai Wu",
      "Shaojie Bai",
      "Zico Kolter",
      "Roger Grosse"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.09961"
  },
  {
    "id": "arXiv:2211.09964",
    "title": "Optimal Algorithms for Linear Algebra in the Current Matrix  Multiplication Time",
    "abstract": "We study fundamental problems in linear algebra, such as finding a maximal\nlinearly independent subset of rows or columns (a basis), solving linear\nregression, or computing a subspace embedding. For these problems, we consider\ninput matrices $\\mathbf{A}\\in\\mathbb{R}^{n\\times d}$ with $n > d$. The input\ncan be read in $\\text{nnz}(\\mathbf{A})$ time, which denotes the number of\nnonzero entries of $\\mathbf{A}$. In this paper, we show that beyond the time\nrequired to read the input matrix, these fundamental linear algebra problems\ncan be solved in $d^{\\omega}$ time, i.e., where $\\omega \\approx 2.37$ is the\ncurrent matrix-multiplication exponent.\nTo do so, we introduce a constant-factor subspace embedding with the optimal\n$m=\\mathcal{O}(d)$ number of rows, and which can be applied in time\n$\\mathcal{O}\\left(\\frac{\\text{nnz}(\\mathbf{A})}{\\alpha}\\right) + d^{2 +\n\\alpha}\\text{poly}(\\log d)$ for any trade-off parameter $\\alpha>0$, tightening\na recent result by Chepurko et. al. [SODA 2022] that achieves an\n$\\exp(\\text{poly}(\\log\\log n))$ distortion with $m=d\\cdot\\text{poly}(\\log\\log\nd)$ rows in\n$\\mathcal{O}\\left(\\frac{\\text{nnz}(\\mathbf{A})}{\\alpha}+d^{2+\\alpha+o(1)}\\right)$\ntime. Our subspace embedding uses a recently shown property of stacked\nSubsampled Randomized Hadamard Transforms (SRHT), which actually increase the\ninput dimension, to \"spread\" the mass of an input vector among a large number\nof coordinates, followed by random sampling. To control the effects of random\nsampling, we use fast semidefinite programming to reweight the rows. We then\nuse our constant-factor subspace embedding to give the first optimal runtime\nalgorithms for finding a maximal linearly independent subset of columns,\nregression, and leverage score sampling. To do so, we also introduce a novel\nsubroutine that iteratively grows a set of independent rows, which may be of\nindependent interest.",
    "descriptor": "\nComments: SODA 2023\n",
    "authors": [
      "Yeshwanth Cherapanamjeri",
      "Sandeep Silwal",
      "David P. Woodruff",
      "Samson Zhou"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.09964"
  },
  {
    "id": "arXiv:2211.09966",
    "title": "AVATAR submission to the Ego4D AV Transcription Challenge",
    "abstract": "In this report, we describe our submission to the Ego4D AudioVisual (AV)\nSpeech Transcription Challenge 2022. Our pipeline is based on AVATAR, a state\nof the art encoder-decoder model for AV-ASR that performs early fusion of\nspectrograms and RGB images. We describe the datasets, experimental settings\nand ablations. Our final method achieves a WER of 68.40 on the challenge test\nset, outperforming the baseline by 43.7%, and winning the challenge.",
    "descriptor": "",
    "authors": [
      "Paul Hongsuck Seo",
      "Arsha Nagrani",
      "Cordelia Schmid"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.09966"
  },
  {
    "id": "arXiv:2211.09967",
    "title": "Learning on Health Fairness and Environmental Justice via Interactive  Visualization",
    "abstract": "This paper introduces an interactive visualization interface with a machine\nlearning consensus analysis that enables the researchers to explore the impact\nof atmospheric and socioeconomic factors on COVID-19 clinical severity by\nemploying multiple Recurrent Graph Neural Networks. We designed and implemented\na visualization interface that leverages coordinated multi-views to support\nexploratory and predictive analysis of hospitalizations and other\nsocio-geographic variables at multiple dimensions, simultaneously. By\nharnessing the strength of geometric deep learning, we build a consensus\nmachine learning model to include knowledge from county-level records and\ninvestigate the complex interrelationships between global infectious disease,\nenvironment, and social justice. Additionally, we make use of unique NASA\nsatellite-based observations which are not broadly used in the context of\nclimate justice applications. Our current interactive interface focus on three\nUS states (California, Pennsylvania, and Texas) to demonstrate its scientific\nvalue and presented three case studies to make qualitative evaluations.",
    "descriptor": "",
    "authors": [
      "Abdullah-Al-Raihan Nayeem",
      "Ignacio Segovia-Dominguez",
      "Huikyo Lee",
      "Dongyun Han",
      "Yuzhou Chen",
      "Zhiwei Zhen",
      "Yulia Gel",
      "Isaac Cho"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.09967"
  },
  {
    "id": "arXiv:2211.09970",
    "title": "Estimating defection in subscription-type markets: empirical analysis  from the scholarly publishing industry",
    "abstract": "We present the first empirical study on customer churn prediction in the\nscholarly publishing industry. The study examines our proposed method for\nprediction on a customer subscription data over a period of 6.5 years, which\nwas provided by a major academic publisher. We explore the subscription-type\nmarket within the context of customer defection and modelling, and provide\nanalysis of the business model of such markets, and how these characterise the\nacademic publishing business. The proposed method for prediction attempts to\nprovide inference of customer's likelihood of defection on the basis of their\nre-sampled use of provider resources -in this context, the volume and frequency\nof content downloads. We show that this approach can be both accurate as well\nas uniquely useful in the business-to-business context, with which the\nscholarly publishing business model shares similarities. The main findings of\nthis work suggest that whilst all predictive models examined, especially\nensemble methods of machine learning, achieve substantially accurate prediction\nof churn, nearly a year ahead, this can be furthermore achieved even when the\nspecific behavioural attributes that can be associated to each customer\nprobability to churn are overlooked. Allowing as such highly accurate inference\nof churn from minimal possible data. We show that modelling churn on the basis\nof re-sampling customers' use of resources over subscription time is a better\n(simplified) approach than when considering the high granularity that can often\ncharacterise consumption behaviour.",
    "descriptor": "",
    "authors": [
      "Michael Roberts",
      "J. Ignacio Deza",
      "Hisham Ihshaish",
      "Yanhui Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2211.09970"
  },
  {
    "id": "arXiv:2211.09973",
    "title": "The Runner-up Solution for YouTube-VIS Long Video Challenge 2022",
    "abstract": "This technical report describes our 2nd-place solution for the ECCV 2022\nYouTube-VIS Long Video Challenge. We adopt the previously proposed online video\ninstance segmentation method IDOL for this challenge. In addition, we use\npseudo labels to further help contrastive learning, so as to obtain more\ntemporally consistent instance embedding to improve tracking performance\nbetween frames. The proposed method obtains 40.2 AP on the YouTube-VIS 2022\nlong video dataset and was ranked second place in this challenge. We hope our\nsimple and effective method could benefit further research.",
    "descriptor": "\nComments: The Runner-up Solution for YouTube-VIS Long Video Challenge 2022, ECCV 2022 Workshop. arXiv admin note: text overlap with arXiv:2207.10661\n",
    "authors": [
      "Junfeng Wu",
      "Yi Jiang",
      "Qihao Liu",
      "Xiang Bai",
      "Song Bai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09973"
  },
  {
    "id": "arXiv:2211.09977",
    "title": "DCPViz: A Visual Analytics Approach for Downscaled Climate Projections",
    "abstract": "This paper introduces a novel visual analytics approach, DCPViz, to enable\nclimate scientists to explore massive climate data interactively without\nrequiring the upfront movement of massive data. Thus, climate scientists are\nafforded more effective approaches to support the identification of potential\ntrends and patterns in climate projections and their subsequent impacts. We\ndesigned the DCPViz pipeline to fetch and extract NEX-DCP30 data with minimal\ndata transfer from their public sources. We implemented DCPViz to demonstrate\nits scalability and scientific value and to evaluate its utility under three\nuse cases based on different models and through domain expert feedback.",
    "descriptor": "",
    "authors": [
      "Abdullah-Al-Raihan Nayeem",
      "Huikyo Lee",
      "Dongyun Han",
      "Mohammad Elshambakey",
      "William J. Tolone",
      "Todd Dobbs",
      "Daniel Crichton",
      "Isaac Cho"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.09977"
  },
  {
    "id": "arXiv:2211.09979",
    "title": "Comparison between EM and FCM algorithms in skin tone extraction",
    "abstract": "This study aims to investigate implementing EM and FCM algorithms for skin\ncolor extraction. The capabilities of three well-known color spaces, namely,\nRGB, HSV, and YCbCr for skin-tone extraction are assessed by using statistical\nmodeling of skin tones using EM and FCM algorithms. The results show that\nutilizing a Gaussian mixture model for parametric modeling of skin tones using\nEM algorithm works well in HSV color space when all three components of the\ncolor vector are used. In spite of discarding the luminance components in YCbCr\nand HSV color spaces, EM algorithm provides the best results. The results of\nthe detailed comparisons are explained in the conclusion.",
    "descriptor": "\nComments: 2016 1st International Conference on New Research Achievements in Electrical and Computer Engineering (ICNRAECE)\n",
    "authors": [
      "Elham Ravanbakhsh",
      "Mosab Rezaei",
      "Ehsan Namjoo",
      "Padideh Choobdar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.09979"
  },
  {
    "id": "arXiv:2211.09980",
    "title": "Contrastive Positive Sample Propagation along the Audio-Visual Event  Line",
    "abstract": "Visual and audio signals often coexist in natural environments, forming\naudio-visual events (AVEs). Given a video, we aim to localize video segments\ncontaining an AVE and identify its category. It is pivotal to learn the\ndiscriminative features for each video segment. Unlike existing work focusing\non audio-visual feature fusion, in this paper, we propose a new contrastive\npositive sample propagation (CPSP) method for better deep feature\nrepresentation learning. The contribution of CPSP is to introduce the available\nfull or weak label as a prior that constructs the exact positive-negative\nsamples for contrastive learning. Specifically, the CPSP involves comprehensive\ncontrastive constraints: pair-level positive sample propagation (PSP),\nsegment-level and video-level positive sample activation (PSA$_S$ and PSA$_V$).\nThree new contrastive objectives are proposed (\\emph{i.e.},\n$\\mathcal{L}_{\\text{avpsp}}$, $\\mathcal{L}_\\text{spsa}$, and\n$\\mathcal{L}_\\text{vpsa}$) and introduced into both the fully and weakly\nsupervised AVE localization. To draw a complete picture of the contrastive\nlearning in AVE localization, we also study the self-supervised positive sample\npropagation (SSPSP). As a result, CPSP is more helpful to obtain the refined\naudio-visual features that are distinguishable from the negatives, thus\nbenefiting the classifier prediction. Extensive experiments on the AVE and the\nnewly collected VGGSound-AVEL100k datasets verify the effectiveness and\ngeneralization ability of our method.",
    "descriptor": "\nComments: Accepted to TPAMI; Dataset and Code are available at this https URL arXiv admin note: substantial text overlap with arXiv:2104.00239\n",
    "authors": [
      "Jinxing Zhou",
      "Dan Guo",
      "Meng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.09980"
  },
  {
    "id": "arXiv:2211.09981",
    "title": "Weighted Ensemble Self-Supervised Learning",
    "abstract": "Ensembling has proven to be a powerful technique for boosting model\nperformance, uncertainty estimation, and robustness in supervised learning.\nAdvances in self-supervised learning (SSL) enable leveraging large unlabeled\ncorpora for state-of-the-art few-shot and supervised learning performance. In\nthis paper, we explore how ensemble methods can improve recent SSL techniques\nby developing a framework that permits data-dependent weighted cross-entropy\nlosses. We refrain from ensembling the representation backbone; this choice\nyields an efficient ensemble method that incurs a small training cost and\nrequires no architectural changes or computational overhead to downstream\nevaluation. The effectiveness of our method is demonstrated with two\nstate-of-the-art SSL methods, DINO (Caron et al., 2021) and MSN (Assran et al.,\n2022). Our method outperforms both in multiple evaluation metrics on\nImageNet-1K, particularly in the few-shot setting. We explore several weighting\nschemes and find that those which increase the diversity of ensemble heads lead\nto better downstream evaluation results. Thorough experiments yield improved\nprior art baselines which our method still surpasses; e.g., our overall\nimprovement with MSN ViT-B/16 is 3.9 p.p. for 1-shot learning.",
    "descriptor": "",
    "authors": [
      "Yangjun Ruan",
      "Saurabh Singh",
      "Warren Morningstar",
      "Alexander A. Alemi",
      "Sergey Ioffe",
      "Ian Fischer",
      "Joshua V. Dillon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.09981"
  },
  {
    "id": "arXiv:2211.09983",
    "title": "Universal Property of Convolutional Neural Networks",
    "abstract": "Universal approximation, whether a set of functions can approximate an\narbitrary function in a specific function space, has been actively studied in\nrecent years owing to the significant development of neural networks. However,\ndespite its extensive use, research on the universal properties of the\nconvolutional neural network has been limited due to its complex nature. In\nthis regard, we demonstrate the universal approximation theorem for\nconvolutional neural networks. A convolution with padding outputs the data of\nthe same shape as the input data; therefore, it is necessary to prove whether a\nconvolutional neural network composed of convolutions can approximate such a\nfunction. We have shown that convolutional neural networks can approximate\ncontinuous functions whose input and output values have the same shape. In\naddition, the minimum depth of the neural network required for approximation\nwas presented, and we proved that it is the optimal value. We also verified\nthat convolutional neural networks with sufficiently deep layers have\nuniversality when the number of channels is limited.",
    "descriptor": "",
    "authors": [
      "Geonho Hwang",
      "Myungjoo Kang"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.09983"
  },
  {
    "id": "arXiv:2211.09984",
    "title": "Multi-task Learning for Sparse Traffic Forecasting",
    "abstract": "Accurate traffic prediction is crucial to improve the performance of\nintelligent transportation systems. Previous traffic prediction tasks mainly\nfocus on small and non-isolated traffic subsystems, while the Traffic4cast 2022\ncompetition is dedicated to exploring the traffic state dynamics of entire\ncities. Given one hour of sparse loop count data only, the task is to predict\nthe congestion classes for all road segments and the expected times of arrival\nalong super-segments 15 minutes into the future. The sparsity of loop counter\ndata and highly uncertain real-time traffic conditions make the competition\nchallenging. For this reason, we propose a multi-task learning network that can\nsimultaneously predict the congestion classes and the speed of each road\nsegment. Specifically, we use clustering and neural network methods to learn\nthe dynamic features of loop counter data. Then, we construct a graph with road\nsegments as nodes and capture the spatial dependence between road segments\nbased on a Graph Neural Network. Finally, we learn three measures, namely the\ncongestion class, the speed value and the volume class, simultaneously through\na multi-task learning module. For the extended competition, we use the\npredicted speeds to calculate the expected times of arrival along\nsuper-segments. Our method achieved excellent results on the dataset provided\nby the Traffic4cast Competition 2022, source code is available at\nhttps://github.com/OctopusLi/NeurIPS2022-traffic4cast.",
    "descriptor": "",
    "authors": [
      "Jiezhang Li",
      "Junjun Li",
      "Yue-Jiao Gong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09984"
  },
  {
    "id": "arXiv:2211.09986",
    "title": "Pandering in a Flexible Representative Democracy",
    "abstract": "In representative democracies, the election of new representatives in regular\nelection cycles is meant to prevent corruption and other misbehavior by elected\nofficials and to keep them accountable in service of the ``will of the people.\"\nThis democratic ideal can be undermined when candidates are dishonest when\ncampaigning for election over these multiple cycles or rounds of voting. Much\nof the work on COMSOC to date has investigated strategic actions in only a\nsingle round. We introduce a novel formal model of \\emph{pandering}, or\nstrategic preference reporting by candidates seeking to be elected, and examine\nthe resilience of two democratic voting systems to pandering within a single\nround and across multiple rounds. The two voting systems we compare are\nRepresentative Democracy (RD) and Flexible Representative Democracy (FRD). For\neach voting system, our analysis centers on the types of strategies candidates\nemploy and how voters update their views of candidates based on how the\ncandidates have pandered in the past. We provide theoretical results on the\ncomplexity of pandering in our setting for a single cycle, formulate our\nproblem for multiple cycles as a Markov Decision Process, and use reinforcement\nlearning to study the effects of pandering by both single candidates and groups\nof candidates across a number of rounds.",
    "descriptor": "",
    "authors": [
      "Xiaolin Sun",
      "Jacob Masur",
      "Ben Abramowitz",
      "Nicholas Mattei",
      "Zizhan Zheng"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09986"
  },
  {
    "id": "arXiv:2211.09992",
    "title": "Look More but Care Less in Video Recognition",
    "abstract": "Existing action recognition methods typically sample a few frames to\nrepresent each video to avoid the enormous computation, which often limits the\nrecognition performance. To tackle this problem, we propose Ample and Focal\nNetwork (AFNet), which is composed of two branches to utilize more frames but\nwith less computation. Specifically, the Ample Branch takes all input frames to\nobtain abundant information with condensed computation and provides the\nguidance for Focal Branch by the proposed Navigation Module; the Focal Branch\nsqueezes the temporal size to only focus on the salient frames at each\nconvolution block; in the end, the results of two branches are adaptively fused\nto prevent the loss of information. With this design, we can introduce more\nframes to the network but cost less computation. Besides, we demonstrate AFNet\ncan utilize fewer frames while achieving higher accuracy as the dynamic\nselection in intermediate features enforces implicit temporal modeling.\nFurther, we show that our method can be extended to reduce spatial redundancy\nwith even less cost. Extensive experiments on five datasets demonstrate the\neffectiveness and efficiency of our method.",
    "descriptor": "\nComments: Accepted by NeurIPS 2022\n",
    "authors": [
      "Yitian Zhang",
      "Yue Bai",
      "Huan Wang",
      "Yi Xu",
      "Yun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09992"
  },
  {
    "id": "arXiv:2211.09997",
    "title": "Beyond ExaBricks: GPU Volume Path Tracing of AMR Data",
    "abstract": "Adaptive Mesh Refinement (AMR) is becoming a prevalent data representation\nfor scientific visualization. Resulting from large fluid mechanics simulations,\nthe data is usually cell centric, imposing a number of challenges for high\nquality reconstruction at sample positions. While recent work has concentrated\non real-time volume and isosurface rendering on GPUs, the rendering methods\nused still focus on simple lighting models without scattering events and global\nillumination. As in other areas of rendering, key to real-time performance are\nacceleration data structures; in this work we analyze the major bottlenecks of\ndata structures that were originally optimized for camera/primary ray traversal\nwhen used with the incoherent ray tracing workload of a volumetric path tracer,\nand propose strategies to overcome the challenges coming with this.",
    "descriptor": "",
    "authors": [
      "Stefan Zellmann",
      "Qi Wu",
      "Alper Sahistan",
      "Kwan-Liu Ma",
      "Ingo Wald"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.09997"
  },
  {
    "id": "arXiv:2211.10000",
    "title": "Protein language model rescue mutations highlight variant effects and  structure in clinically relevant genes",
    "abstract": "Despite being self-supervised, protein language models have shown remarkable\nperformance in fundamental biological tasks such as predicting impact of\ngenetic variation on protein structure and function. The effectiveness of these\nmodels on diverse set of tasks suggests that they learn meaningful\nrepresentations of fitness landscape that can be useful for downstream clinical\napplications. Here, we interrogate the use of these language models in\ncharacterizing known pathogenic mutations in curated, medically actionable\ngenes through an exhaustive search of putative compensatory mutations on each\nvariant's genetic background. Systematic analysis of the predicted effects of\nthese compensatory mutations reveal unappreciated structural features of\nproteins that are missed by other structure predictors like AlphaFold. While\ndeep mutational scan experiments provide an unbiased estimate of the mutational\nlandscape, we encourage the community to generate and curate rescue mutation\nexperiments to inform the design of more sophisticated co-masking strategies\nand leverage large language models more effectively for downstream clinical\nprediction tasks.",
    "descriptor": "\nComments: NeurIPS 2022, Workshop on Learning Meaningful Representations of Life\n",
    "authors": [
      "Onuralp Soylemez",
      "Pablo Cordero"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Genomics (q-bio.GN)"
    ],
    "url": "https://arxiv.org/abs/2211.10000"
  },
  {
    "id": "arXiv:2211.10001",
    "title": "BDTS: A Blockchain-based Data Trading System with Fair Exchange",
    "abstract": "Trading data through blockchain platforms is hard to achieve \\textit{fair\nexchange}. Reasons come from two folds: Firstly, guaranteeing fairness between\nsellers and consumers is a challenging task as the deception of any\nparticipating parties is risk-free. This leads to the second issue where\njudging the behavior of data executors (such as cloud service providers) among\ndistrustful parties is impractical in traditional trading protocols. To fill\nthe gaps, in this paper, we present a \\underline{b}lockchain-based\n\\underline{d}ata \\underline{t}rading \\underline{s}ystem, named BDTS. The\nproposed BDTS implements a fair-exchange protocol in which benign behaviors can\nobtain rewards while dishonest behaviors will be punished. Our scheme leverages\nthe smart contract technique to act as the agency, managing data distribution\nand payment execution. The solution requires the seller to provide consumers\nwith the correct decryption keys for proper execution and encourages a\n\\textit{rational} data executor to behave faithfully for \\textit{maximum}\nbenefits. We analyze the strategies of consumers, sellers, and dealers based on\nthe game theory and prove that our game can reach the subgame perfect Nash\nequilibrium when each party honestly behaves. Further, we implement our scheme\nbased on the Hyperledger Fabric platform with a full-functional design.\nEvaluations show that our scheme achieves satisfactory efficiency and\nfeasibility.",
    "descriptor": "",
    "authors": [
      "Bo Qin",
      "Qin Wang",
      "Qianhong Wu",
      "Sanxi Li",
      "Wenchang Shi",
      "Yingxin Bi",
      "Wenyi Tang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.10001"
  },
  {
    "id": "arXiv:2211.10002",
    "title": "Influential Recommender System",
    "abstract": "Traditional recommender systems are typically passive in that they try to\nadapt their recommendations to the user's historical interests. However, it is\nhighly desirable for commercial applications, such as e-commerce, advertisement\nplacement, and news portals, to be able to expand the users' interests so that\nthey would accept items that they were not originally aware of or interested in\nto increase customer interactions. In this paper, we present Influential\nRecommender System (IRS), a new recommendation paradigm that aims to\nproactively lead a user to like a given objective item by progressively\nrecommending to the user a sequence of carefully selected items (called an\ninfluence path). We propose the Influential Recommender Network (IRN), which is\na Transformer-based sequential model to encode the items' sequential\ndependencies. Since different people react to external influences differently,\nwe introduce the Personalized Impressionability Mask (PIM) to model how\nreceptive a user is to external influence to generate the most effective\ninfluence path for the user. To evaluate IRN, we design several performance\nmetrics to measure whether or not the influence path can smoothly expand the\nuser interest to include the objective item while maintaining the user's\nsatisfaction with the recommendation. Experimental results show that IRN\nsignificantly outperforms the baseline recommenders and demonstrates its\ncapability of influencing users' interests.",
    "descriptor": "",
    "authors": [
      "Haoren Zhu",
      "Hao Ge",
      "Xiaodong Gu",
      "Pengfei Zhao",
      "Dik Lun Lee"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10002"
  },
  {
    "id": "arXiv:2211.10003",
    "title": "3d human motion generation from the text via gesture action  classification and the autoregressive model",
    "abstract": "In this paper, a deep learning-based model for 3D human motion generation\nfrom the text is proposed via gesture action classification and an\nautoregressive model. The model focuses on generating special gestures that\nexpress human thinking, such as waving and nodding. To achieve the goal, the\nproposed method predicts expression from the sentences using a text\nclassification model based on a pretrained language model and generates\ngestures using the gate recurrent unit-based autoregressive model. Especially,\nwe proposed the loss for the embedding space for restoring raw motions and\ngenerating intermediate motions well. Moreover, the novel data augmentation\nmethod and stop token are proposed to generate variable length motions. To\nevaluate the text classification model and 3D human motion generation model, a\ngesture action classification dataset and action-based gesture dataset are\ncollected. With several experiments, the proposed method successfully generates\nperceptually natural and realistic 3D human motion from the text. Moreover, we\nverified the effectiveness of the proposed method using a public-available\naction recognition dataset to evaluate cross-dataset generalization\nperformance.",
    "descriptor": "\nComments: 5 pages, 3 figures, ICIP 2022\n",
    "authors": [
      "Gwantae Kim",
      "Youngsuk Ryu",
      "Junyeop Lee",
      "David K. Han",
      "Jeongmin Bae",
      "Hanseok Ko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.10003"
  },
  {
    "id": "arXiv:2211.10008",
    "title": "Confounder Balancing for Instrumental Variable Regression with Latent  Variable",
    "abstract": "This paper studies the confounding effects from the unmeasured confounders\nand the imbalance of observed confounders in IV regression and aims at unbiased\ncausal effect estimation. Recently, nonlinear IV estimators were proposed to\nallow for nonlinear model in both stages. However, the observed confounders may\nbe imbalanced in stage 2, which could still lead to biased treatment effect\nestimation in certain cases. To this end, we propose a Confounder Balanced IV\nRegression (CB-IV) algorithm to jointly remove the bias from the unmeasured\nconfounders and the imbalance of observed confounders. Theoretically, by\nredefining and solving an inverse problem for potential outcome function, we\nshow that our CB-IV algorithm can unbiasedly estimate treatment effects and\nachieve lower variance. The IV methods have a major disadvantage in that little\nprior or theory is currently available to pre-define a valid IV in real-world\nscenarios. Thus, we study two more challenging settings without pre-defined\nvalid IVs: (1) indistinguishable IVs implicitly present in observations, i.e.,\nmixed-variable challenge, and (2) latent IVs don't appear in observations,\ni.e., latent-variable challenge. To address these two challenges, we extend our\nCB-IV by a latent-variable module, namely CB-IV-L algorithm. Extensive\nexperiments demonstrate that our CB-IV(-L) outperforms the existing approaches.",
    "descriptor": "",
    "authors": [
      "Anpeng Wu",
      "Kun Kuang",
      "Ruoxuan Xiong",
      "Bo Li",
      "Fei Wu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.10008"
  },
  {
    "id": "arXiv:2211.10011",
    "title": "Structural Quality Metrics to Evaluate Knowledge Graphs",
    "abstract": "This work presents six structural quality metrics that can measure the\nquality of knowledge graphs and analyzes five cross-domain knowledge graphs on\nthe web (Wikidata, DBpedia, YAGO, Google Knowledge Graph, Freebase) as well as\n'Raftel', Naver's integrated knowledge graph. The 'Good Knowledge Graph' should\ndefine detailed classes and properties in its ontology so that knowledge in the\nreal world can be expressed abundantly. Also, instances and RDF triples should\nuse the classes and properties actively. Therefore, we tried to examine the\ninternal quality of knowledge graphs numerically by focusing on the structure\nof the ontology, which is the schema of knowledge graphs, and the degree of use\nthereof. As a result of the analysis, it was possible to find the\ncharacteristics of a knowledge graph that could not be known only by\nscale-related indicators such as the number of classes and properties.",
    "descriptor": "",
    "authors": [
      "Sumin Seo",
      "Heeseon Cheon",
      "Hyunho Kim",
      "Dongseok Hyun"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10011"
  },
  {
    "id": "arXiv:2211.10012",
    "title": "A Tale of Two Cities: Data and Configuration Variances in Robust Deep  Learning",
    "abstract": "Deep neural networks (DNNs), are widely used in many industries such as image\nrecognition, supply chain, medical diagnosis, and autonomous driving. However,\nprior work has shown the high accuracy of a DNN model does not imply high\nrobustness (i.e., consistent performances on new and future datasets) because\nthe input data and external environment (e.g., software and model\nconfigurations) for a deployed model are constantly changing. Hence, ensuring\nthe robustness of deep learning is not an option but a priority to enhance\nbusiness and consumer confidence. Previous studies mostly focus on the data\naspect of model variance. In this article, we systematically summarize DNN\nrobustness issues and formulate them in a holistic view through two important\naspects, i.e., data and software configuration variances in DNNs. We also\nprovide a predictive framework to generate representative variances\n(counterexamples) by considering both data and configurations for robust\nlearning through the lens of search-based optimization.",
    "descriptor": "",
    "authors": [
      "Guanqin Zhang",
      "Jiankun Sun",
      "Feng Xu",
      "H.M.N. Dilum Bandara",
      "Shiping Chen",
      "Yulei Sui",
      "Tim Menzies"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.10012"
  },
  {
    "id": "arXiv:2211.10014",
    "title": "Users are Closer than they Appear: Protecting User Location from WiFi  APs",
    "abstract": "WiFi-based indoor localization has now matured for over a decade. Most of the\ncurrent localization algorithms rely on the WiFi access points (APs) in the\nenterprise network to localize the WiFi user accurately. Thus, the WiFi user's\nlocation information could be easily snooped by an attacker listening through a\ncompromised WiFi AP. With indoor localization and navigation being the next\nstep towards automation, it is important to give users the capability to defend\nagainst such attacks. In this paper, we present MIRAGE, a system that can\nutilize the downlink physical layer information to create a defense against an\nattacker snooping on a WiFi user's location information. MIRAGE achieves this\nby utilizing the beamforming capability of the transmitter that is already part\nof the WiFi protocols. With this initial idea, we have demonstrated that the\nuser can obfuscate his/her location from the WiFi AP always with no compromise\nto the throughput of the existing WiFi communication system and reduce the user\nlocation accuracy of the attacker from 2.3m to more than 10m.",
    "descriptor": "\nComments: 6 pages, 6 figures, submitted to HotMobile 2023\n",
    "authors": [
      "Roshan Ayyalasomayajula",
      "Aditya Arun",
      "Wei Sun",
      "Dinesh Bharadia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.10014"
  },
  {
    "id": "arXiv:2211.10017",
    "title": "Who Says Elephants Can't Run: Bringing Large Scale MoE Models into Cloud  Scale Production",
    "abstract": "Mixture of Experts (MoE) models with conditional execution of sparsely\nactivated layers have enabled training models with a much larger number of\nparameters. As a result, these models have achieved significantly better\nquality on various natural language processing tasks including machine\ntranslation. However, it remains challenging to deploy such models in real-life\nscenarios due to the large memory requirements and inefficient inference. In\nthis work, we introduce a highly efficient inference framework with several\noptimization approaches to accelerate the computation of sparse models and cut\ndown the memory consumption significantly. While we achieve up to 26x speed-up\nin terms of throughput, we also reduce the model size almost to one eighth of\nthe original 32-bit float model by quantizing expert weights into 4-bit\nintegers. As a result, we are able to deploy 136x larger models with 27% less\ncost and significantly better quality compared to the existing solutions. This\nenables a paradigm shift in deploying large scale multilingual MoE transformers\nmodels replacing the traditional practice of distilling teacher models into\ndozens of smaller models per language or task.",
    "descriptor": "\nComments: Accepted to SustaiNLP 2022 (EMNLP 2022)\n",
    "authors": [
      "Young Jin Kim",
      "Rawn Henry",
      "Raffy Fahim",
      "Hany Hassan Awadalla"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10017"
  },
  {
    "id": "arXiv:2211.10018",
    "title": "A Dataset for Hyper-Relational Extraction and a Cube-Filling Approach",
    "abstract": "Relation extraction has the potential for large-scale knowledge graph\nconstruction, but current methods do not consider the qualifier attributes for\neach relation triplet, such as time, quantity or location. The qualifiers form\nhyper-relational facts which better capture the rich and complex knowledge\ngraph structure. For example, the relation triplet (Leonard Parker, Educated\nAt, Harvard University) can be factually enriched by including the qualifier\n(End Time, 1967). Hence, we propose the task of hyper-relational extraction to\nextract more specific and complete facts from text. To support the task, we\nconstruct HyperRED, a large-scale and general-purpose dataset. Existing models\ncannot perform hyper-relational extraction as it requires a model to consider\nthe interaction between three entities. Hence, we propose CubeRE, a\ncube-filling model inspired by table-filling approaches and explicitly\nconsiders the interaction between relation triplets and qualifiers. To improve\nmodel scalability and reduce negative class imbalance, we further propose a\ncube-pruning method. Our experiments show that CubeRE outperforms strong\nbaselines and reveal possible directions for future research. Our code and data\nare available at github.com/declare-lab/HyperRED.",
    "descriptor": "\nComments: 19 pages, 6 figures, accepted by EMNLP 2022\n",
    "authors": [
      "Yew Ken Chia",
      "Lidong Bing",
      "Sharifah Mahani Aljunied",
      "Luo Si",
      "Soujanya Poria"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.10018"
  },
  {
    "id": "arXiv:2211.10020",
    "title": "Perception-Based Sampled-Data Optimization of Dynamical Systems",
    "abstract": "Motivated by perception-based control problems in autonomous systems, this\npaper addresses the problem of developing feedback controllers to regulate the\ninputs and the states of a dynamical system to optimal solutions of an\noptimization problem when one has no access to exact measurements of the system\nstates. In particular, we consider the case where the states need to be\nestimated from high-dimensional sensory data received only at discrete time\nintervals. We develop a sampled-data feedback controller that is based on\nadaptations of a projected gradient descent method, and that includes neural\nnetworks as integral components to estimate the state of the system from\nperceptual information. We derive sufficient conditions to guarantee (local)\ninput-to-state stability of the control loop. Moreover, we show that the\ninterconnected system tracks the solution trajectory of the underlying\noptimization problem up to an error that depends on the approximation errors of\nthe neural network and on the time-variability of the optimization problem; the\nlatter originates from time-varying safety and performance objectives, input\nconstraints, and unknown disturbances. As a representative application, we\nillustrate our results with numerical simulations for vision-based autonomous\ndriving.",
    "descriptor": "\nComments: This work has been submitted to IFAC for possible publication\n",
    "authors": [
      "Liliaokeawawa Cothren",
      "Gianluca Bianchin",
      "Sarah Dean",
      "Emiliano Dall'Anese"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.10020"
  },
  {
    "id": "arXiv:2211.10022",
    "title": "Listing 4-Cycles",
    "abstract": "In this note we present an algorithm that lists all $4$-cycles in a graph in\ntime $\\tilde{O}(\\min(n^2,m^{4/3})+t)$ where $t$ is their number. Notably, this\nseparates $4$-cycle listing from triangle-listing, since the latter has a\n$(\\min(n^3,m^{3/2})+t)^{1-o(1)}$ lower bound under the $3$-SUM Conjecture.\nOur upper bound is conditionally tight because (1) $O(n^2,m^{4/3})$ is the\nbest known bound for detecting if the graph has any $4$-cycle, and (2) it\nmatches a recent $(\\min(n^3,m^{3/2})+t)^{1-o(1)}$ $3$-SUM lower bound for\nenumeration algorithms.\nThe latter lower bound was proved very recently by Abboud, Bringmann, and\nFischer [arXiv, 2022] and independently by Jin and Xu [arXiv, 2022].\nIn an independent work, Jin and Xu [arXiv, 2022] also present an algorithm\nwith the same time bound.",
    "descriptor": "",
    "authors": [
      "Amir Abboud",
      "Seri Khoury",
      "Oree Leibowitz",
      "Ron Safier"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.10022"
  },
  {
    "id": "arXiv:2211.10023",
    "title": "LiSnowNet: Real-time Snow Removal for LiDAR Point Cloud",
    "abstract": "LiDARs have been widely adopted to modern self-driving vehicles, providing 3D\ninformation of the scene and surrounding objects. However, adverser weather\nconditions still pose significant challenges to LiDARs since point clouds\ncaptured during snowfall can easily be corrupted. The resulting noisy point\nclouds degrade downstream tasks such as mapping. Existing works in de-noising\npoint clouds corrupted by snow are based on nearest-neighbor search, and thus\ndo not scale well with modern LiDARs which usually capture $100k$ or more\npoints at 10Hz. In this paper, we introduce an unsupervised de-noising\nalgorithm, LiSnowNet, running 52$\\times$ faster than the state-of-the-art\nmethods while achieving superior performance in de-noising. Unlike previous\nmethods, the proposed algorithm is based on a deep convolutional neural network\nand can be easily deployed to hardware accelerators such as GPUs. In addition,\nwe demonstrate how to use the proposed method for mapping even with corrupted\npoint clouds.",
    "descriptor": "\nComments: The paper has been accepted for the 2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2022)\n",
    "authors": [
      "Ming-Yuan Yu",
      "Ram Vasudevan",
      "Matthew Johnson-Roberson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.10023"
  },
  {
    "id": "arXiv:2211.10024",
    "title": "Diagnostics for Deep Neural Networks with Automated Copy/Paste Attacks",
    "abstract": "Deep neural networks (DNNs) are powerful, but they can make mistakes that\npose significant risks. A model performing well on a test set does not imply\nsafety in deployment, so it is important to have additional tools to understand\nits flaws. Adversarial examples can help reveal weaknesses, but they are often\ndifficult for a human to interpret or draw generalizable, actionable\nconclusions from. Some previous works have addressed this by studying\nhuman-interpretable attacks. We build on these with three contributions. First,\nwe introduce a method termed Search for Natural Adversarial Features Using\nEmbeddings (SNAFUE) which offers a fully-automated method for finding\n\"copy/paste\" attacks in which one natural image can be pasted into another in\norder to induce an unrelated misclassification. Second, we use this to red team\nan ImageNet classifier and identify hundreds of easily-describable sets of\nvulnerabilities. Third, we compare this approach with other interpretability\ntools by attempting to rediscover trojans. Our results suggest that SNAFUE can\nbe useful for interpreting DNNs and generating adversarial data for them. Code\nis available at https://github.com/thestephencasper/snafue",
    "descriptor": "",
    "authors": [
      "Stephen Casper",
      "Kaivalya Hariharan",
      "Dylan Hadfield-Menell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.10024"
  },
  {
    "id": "arXiv:2211.10027",
    "title": "Secure Quantum Computing for Healthcare Sector: A Short Analysis",
    "abstract": "Quantum computing research might lead to \"quantum leaps,\" and it could have\nunanticipated repercussions in the medical field. This technique has the\npotential to be used in a broad range of contexts, some of which include the\ndevelopment of novel drugs, the individualization of medical treatments, and\nthe speeding of DNA sequencing. This work has assembled a list of the numerous\nmethodologies presently employed in quantum medicine and other disciplines\npertaining to healthcare. This work has created a list of the most critical\nconcerns that need to be addressed before the broad use of quantum computing\ncan be realized. In addition, this work investigates in detail the ways in\nwhich potential future applications of quantum computing might compromise the\nsafety of healthcare delivery systems from the perspective of the medical\nindustry and the patient-centric healthcare system. The primary objective of\nthis investigation into quantum cryptography is to locate any potential flaws\nin the cryptographic protocols and strategies that have only very recently been\nthe focus of scrutiny from academic research community members.",
    "descriptor": "",
    "authors": [
      "P. Srikanth",
      "Adarsh Kumar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.10027"
  },
  {
    "id": "arXiv:2211.10028",
    "title": "Comparative evaluation of different methods of \"Homomorphic Encryption\"  and \"Traditional Encryption\" on a dataset with current problems and  developments",
    "abstract": "A database is a prime target for cyber-attacks as it contains confidential,\nsensitive, or protected information. With the increasing sophistication of the\ninternet and dependencies on internet data transmission, it has become vital to\nbe aware of various encryption technologies and trends. It can assist in\nsafeguarding private information and sensitive data, as well as improve the\nsecurity of client-server communication. Database encryption is a procedure\nthat employs an algorithm to convert data contained in a database into \"cipher\ntext,\" which is incomprehensible until decoded. Homomorphic encryption\ntechnology, which works with encrypted data, can be utilized in both symmetric\nand asymmetric systems. In this paper, we evaluated homomorphic encryption\ntechniques based on recent highly cited articles, as well as compared all\ndatabase encryption problems and developments since 2018. The benefits and\ndrawbacks of homomorphic approaches were examined over classic encryption\nmethods including Transparent Database Encryption, Column Level Encryption,\nField Level Encryption, File System Level Encryption, and Encrypting File\nSystem Encryption in this review. Additionally, popular databases that provide\nencryption services to their customers to protect their data are also examined.",
    "descriptor": "\nComments: 20 pages, 4 Figures\n",
    "authors": [
      "Tanvi S. Patel",
      "Srinivasakranthikiran Kolachina",
      "Daxesh P. Patel",
      "Pranav S. Shrivastav"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.10028"
  },
  {
    "id": "arXiv:2211.10030",
    "title": "Contrastive Knowledge Graph Error Detection",
    "abstract": "Knowledge Graph (KG) errors introduce non-negligible noise, severely\naffecting KG-related downstream tasks. Detecting errors in KGs is challenging\nsince the patterns of errors are unknown and diverse, while ground-truth labels\nare rare or even unavailable. A traditional solution is to construct logical\nrules to verify triples, but it is not generalizable since different KGs have\ndistinct rules with domain knowledge involved. Recent studies focus on\ndesigning tailored detectors or ranking triples based on KG embedding loss.\nHowever, they all rely on negative samples for training, which are generated by\nrandomly replacing the head or tail entity of existing triples. Such a negative\nsampling strategy is not enough for prototyping practical KG errors, e.g.,\n(Bruce_Lee, place_of_birth, China), in which the three elements are often\nrelevant, although mismatched. We desire a more effective unsupervised learning\nmechanism tailored for KG error detection. To this end, we propose a novel\nframework - ContrAstive knowledge Graph Error Detection (CAGED). It introduces\ncontrastive learning into KG learning and provides a novel way of modeling KG.\nInstead of following the traditional setting, i.e., considering entities as\nnodes and relations as semantic edges, CAGED augments a KG into different\nhyper-views, by regarding each relational triple as a node. After joint\ntraining with KG embedding and contrastive learning loss, CAGED assesses the\ntrustworthiness of each triple based on two learning signals, i.e., the\nconsistency of triple representations across multi-views and the\nself-consistency within the triple. Extensive experiments on three real-world\nKGs show that CAGED outperforms state-of-the-art methods in KG error detection.\nOur codes and datasets are available at https://github.com/Qing145/CAGED.git.",
    "descriptor": "",
    "authors": [
      "Qinggang Zhang",
      "Junnan Dong",
      "Keyu Duan",
      "Xiao Huang",
      "Yezi Liu",
      "Linchuan Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10030"
  },
  {
    "id": "arXiv:2211.10033",
    "title": "Adversarial Stimuli: Attacking Brain-Computer Interfaces via Perturbed  Sensory Events",
    "abstract": "Machine learning models are known to be vulnerable to adversarial\nperturbations in the input domain, causing incorrect predictions. Inspired by\nthis phenomenon, we explore the feasibility of manipulating EEG-based Motor\nImagery (MI) Brain Computer Interfaces (BCIs) via perturbations in sensory\nstimuli. Similar to adversarial examples, these \\emph{adversarial stimuli} aim\nto exploit the limitations of the integrated brain-sensor-processing components\nof the BCI system in handling shifts in participants' response to changes in\nsensory stimuli. This paper proposes adversarial stimuli as an attack vector\nagainst BCIs, and reports the findings of preliminary experiments on the impact\nof visual adversarial stimuli on the integrity of EEG-based MI BCIs. Our\nfindings suggest that minor adversarial stimuli can significantly deteriorate\nthe performance of MI BCIs across all participants (p=0.0003). Additionally,\nour results indicate that such attacks are more effective in conditions with\ninduced stress.",
    "descriptor": "",
    "authors": [
      "Bibek Upadhayay",
      "Vahid Behzadan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.10033"
  },
  {
    "id": "arXiv:2211.10039",
    "title": "Why pseudo label based algorithm is effective? --from the perspective of  pseudo labeled data",
    "abstract": "Recently, pseudo label based semi-supervised learning has achieved great\nsuccess in many fields. The core idea of the pseudo label based semi-supervised\nlearning algorithm is to use the model trained on the labeled data to generate\npseudo labels on the unlabeled data, and then train a model to fit the\npreviously generated pseudo labels. We give a theory analysis for why pseudo\nlabel based semi-supervised learning is effective in this paper. We mainly\ncompare the generalization error of the model trained under two settings: (1)\nThere are N labeled data. (2) There are N unlabeled data and a suitable initial\nmodel. Our analysis shows that, firstly, when the amount of unlabeled data\ntends to infinity, the pseudo label based semi-supervised learning algorithm\ncan obtain model which have the same generalization error upper bound as model\nobtained by normally training in the condition of the amount of labeled data\ntends to infinity. More importantly, we prove that when the amount of unlabeled\ndata is large enough, the generalization error upper bound of the model\nobtained by pseudo label based semi-supervised learning algorithm can converge\nto the optimal upper bound with linear convergence rate. We also give the lower\nbound on sampling complexity to achieve linear convergence rate. Our analysis\ncontributes to understanding the empirical successes of pseudo label-based\nsemi-supervised learning.",
    "descriptor": "",
    "authors": [
      "Zeping Min",
      "Cheng Tai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10039"
  },
  {
    "id": "arXiv:2211.10041",
    "title": "The communication cost of security and privacy in federated frequency  estimation",
    "abstract": "We consider the federated frequency estimation problem, where each user holds\na private item $X_i$ from a size-$d$ domain and a server aims to estimate the\nempirical frequency (i.e., histogram) of $n$ items with $n \\ll d$. Without any\nsecurity and privacy considerations, each user can communicate its item to the\nserver by using $\\log d$ bits. A naive application of secure aggregation\nprotocols would, however, require $d\\log n$ bits per user. Can we reduce the\ncommunication needed for secure aggregation, and does security come with a\nfundamental cost in communication?\nIn this paper, we develop an information-theoretic model for secure\naggregation that allows us to characterize the fundamental cost of security and\nprivacy in terms of communication. We show that with security (and without\nprivacy) $\\Omega\\left( n \\log d \\right)$ bits per user are necessary and\nsufficient to allow the server to compute the frequency distribution. This is\nsignificantly smaller than the $d\\log n$ bits per user needed by the naive\nscheme, but significantly higher than the $\\log d$ bits per user needed without\nsecurity. To achieve differential privacy, we construct a linear scheme based\non a noisy sketch which locally perturbs the data and does not require a\ntrusted server (a.k.a. distributed differential privacy). We analyze this\nscheme under $\\ell_2$ and $\\ell_\\infty$ loss. By using our\ninformation-theoretic framework, we show that the scheme achieves the optimal\naccuracy-privacy trade-off with optimal communication cost, while matching the\nperformance in the centralized case where data is stored in the central server.",
    "descriptor": "",
    "authors": [
      "Wei-Ning Chen",
      "Ayfer \u00d6zg\u00fcr",
      "Graham Cormode",
      "Akash Bharadwaj"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.10041"
  },
  {
    "id": "arXiv:2211.10043",
    "title": "Vision Transformers in Medical Imaging: A Review",
    "abstract": "Transformer, a model comprising attention-based encoder-decoder architecture,\nhave gained prevalence in the field of natural language processing (NLP) and\nrecently influenced the computer vision (CV) space. The similarities between\ncomputer vision and medical imaging, reviewed the question among researchers if\nthe impact of transformers on computer vision be translated to medical imaging?\nIn this paper, we attempt to provide a comprehensive and recent review on the\napplication of transformers in medical imaging by; describing the transformer\nmodel comparing it with a diversity of convolutional neural networks (CNNs),\ndetailing the transformer based approaches for medical image classification,\nsegmentation, registration and reconstruction with a focus on the image\nmodality, comparing the performance of state-of-the-art transformer\narchitectures to best performing CNNs on standard medical datasets.",
    "descriptor": "",
    "authors": [
      "Emerald U. Henry",
      "Onyeka Emebob",
      "Conrad Asotie Omonhinmin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10043"
  },
  {
    "id": "arXiv:2211.10045",
    "title": "What Makes An Apology More Effective? Exploring Anthropomorphism,  Individual Differences, And Emotion In Human-Automation Trust Repair",
    "abstract": "Recent advances in technology have allowed an automation system to recognize\nits errors and repair trust more actively than ever. While previous research\nhas called for further studies of different human factors and design features,\ntheir effect on human-automation trust repair scenarios remains unknown,\nespecially concerning emotions. This paper seeks to fill such gaps by\ninvestigating the impact of anthropomorphism, users' individual differences,\nand emotional responses on human-automation trust repair. Our experiment\nmanipulated various types of trust violations and apology messages with\ndifferent emotionally expressive anthropomorphic cues. While no significant\neffect from the different apology representations was found, our participants\ndisplayed polarizing attitudes toward the anthropomorphic cues. We also found\nthat (1). some personality traits, such as openness and conscientiousness,\nnegatively correlate with the effectiveness of the apology messages, and (2). a\nperson's emotional response toward a trust violation positively correlates with\nthe effectiveness of the apology messages.",
    "descriptor": "",
    "authors": [
      "Peggy Pei-Ying Lu",
      "Makoto Konishi",
      "Shin Sano",
      "Sho Hiruta",
      "Francis Ken Nakagawa"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.10045"
  },
  {
    "id": "arXiv:2211.10048",
    "title": "Clustering based opcode graph generation for malware variant detection",
    "abstract": "Malwares are the key means leveraged by threat actors in the cyber space for\ntheir attacks. There is a large array of commercial solutions in the market and\nsignificant scientific research to tackle the challenge of the detection and\ndefense against malwares. At the same time, attackers also advance their\ncapabilities in creating polymorphic and metamorphic malwares to make it\nincreasingly challenging for existing solutions. To tackle this issue, we\npropose a methodology to perform malware detection and family attribution. The\nproposed methodology first performs the extraction of opcodes from malwares in\neach family and constructs their respective opcode graphs. We explore the use\nof clustering algorithms on the opcode graphs to detect clusters of malwares\nwithin the same malware family. Such clusters can be seen as belonging to\ndifferent sub-family groups. Opcode graph signatures are built from each\ndetected cluster. Hence, for each malware family, a group of signatures is\ngenerated to represent the family. These signatures are used to classify an\nunknown sample as benign or belonging to one the malware families. We evaluate\nour methodology by performing experiments on a dataset consisting of both\nbenign files and malware samples belonging to a number of different malware\nfamilies and comparing the results to existing approach.",
    "descriptor": "\nComments: Keywords: malware detection and attribution, malware family, clustering, opcode graph, machine learning; this https URL\n",
    "authors": [
      "Kar Wai Fok",
      "Vrizlynn L. L. Thing"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10048"
  },
  {
    "id": "arXiv:2211.10052",
    "title": "Pedestrian Spatio-Temporal Information Fusion For Video Anomaly  Detection",
    "abstract": "Aiming at the problem that the current video anomaly detection cannot fully\nuse the temporal information and ignore the diversity of normal behavior, an\nanomaly detection method is proposed to integrate the spatiotemporal\ninformation of pedestrians. Based on the convolutional autoencoder, the input\nframe is compressed and restored through the encoder and decoder. Anomaly\ndetection is realized according to the difference between the output frame and\nthe true value. In order to strengthen the characteristic information\nconnection between continuous video frames, the residual temporal shift module\nand the residual channel attention module are introduced to improve the\nmodeling ability of the network on temporal information and channel\ninformation, respectively. Due to the excessive generalization of convolutional\nneural networks, in the memory enhancement modules, the hopping connections of\neach codec layer are added to limit autoencoders' ability to represent abnormal\nframes too vigorously and improve the anomaly detection accuracy of the\nnetwork. In addition, the objective function is modified by a feature\ndiscretization loss, which effectively distinguishes different normal behavior\npatterns. The experimental results on the CUHK Avenue and ShanghaiTech datasets\nshow that the proposed method is superior to the current mainstream video\nanomaly detection methods while meeting the real-time requirements.",
    "descriptor": "",
    "authors": [
      "Chao Hu",
      "Liqiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10052"
  },
  {
    "id": "arXiv:2211.10054",
    "title": "Decorr: Environment Partitioning for Invariant Learning and OOD  Generalization",
    "abstract": "Invariant learning methods try to find an invariant predictor across several\nenvironments and have become popular in OOD generalization. However, in\nsituations where environments do not naturally exist in the data, they have to\nbe decided by practitioners manually. Environment partitioning, which splits\nthe whole training dataset into environments by algorithms, will significantly\ninfluence the performance of invariant learning and has been left undiscussed.\nA good environment partitioning method can bring invariant learning to\napplications with more general settings and improve its performance. We propose\nto split the dataset into several environments by finding low-correlated data\nsubsets. Theoretical interpretations and algorithm details are both introduced\nin the paper. Through experiments on both synthetic and real data, we show that\nour Decorr method can achieve outstanding performance, while some other\npartitioning methods may lead to bad, even below-ERM results using the same\ntraining scheme of IRM.",
    "descriptor": "",
    "authors": [
      "Yufan Liao",
      "Qi Wu",
      "Xing Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10054"
  },
  {
    "id": "arXiv:2211.10056",
    "title": "Contrastive Losses Are Natural Criteria for Unsupervised Video  Summarization",
    "abstract": "Video summarization aims to select the most informative subset of frames in a\nvideo to facilitate efficient video browsing. Unsupervised methods usually rely\non heuristic training objectives such as diversity and representativeness.\nHowever, such methods need to bootstrap the online-generated summaries to\ncompute the objectives for importance score regression. We consider such a\npipeline inefficient and seek to directly quantify the frame-level importance\nwith the help of contrastive losses in the representation learning literature.\nLeveraging the contrastive losses, we propose three metrics featuring a\ndesirable key frame: local dissimilarity, global consistency, and uniqueness.\nWith features pre-trained on the image classification task, the metrics can\nalready yield high-quality importance scores, demonstrating competitive or\nbetter performance than past heavily-trained methods. We show that by refining\nthe pre-trained features with a lightweight contrastively learned projection\nmodule, the frame-level importance scores can be further improved, and the\nmodel can also leverage a large number of random videos and generalize to test\nvideos with decent performance. Code available at\nhttps://github.com/pangzss/pytorch-CTVSUM.",
    "descriptor": "\nComments: To appear in WACV2023\n",
    "authors": [
      "Zongshang Pang",
      "Yuta Nakashima",
      "Mayu Otani",
      "Hajime Nagahara"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10056"
  },
  {
    "id": "arXiv:2211.10057",
    "title": "Overview of the WANLP 2022 Shared Task on Propaganda Detection in Arabic",
    "abstract": "Propaganda is the expression of an opinion or an action by an individual or a\ngroup deliberately designed to influence the opinions or the actions of other\nindividuals or groups with reference to predetermined ends, which is achieved\nby means of well-defined rhetorical and psychological devices. Propaganda\ntechniques are commonly used in social media to manipulate or to mislead users.\nThus, there has been a lot of recent research on automatic detection of\npropaganda techniques in text as well as in memes. However, so far the focus\nhas been primarily on English. With the aim to bridge this language gap, we ran\na shared task on detecting propaganda techniques in Arabic tweets as part of\nthe WANLP 2022 workshop, which included two subtasks. Subtask~1 asks to\nidentify the set of propaganda techniques used in a tweet, which is a\nmultilabel classification problem, while Subtask~2 asks to detect the\npropaganda techniques used in a tweet together with the exact span(s) of text\nin which each propaganda technique appears. The task attracted 63 team\nregistrations, and eventually 14 and 3 teams made submissions for subtask 1 and\n2, respectively. Finally, 11 teams submitted system description papers.",
    "descriptor": "\nComments: Accepted at WANLP-22 (EMNLP-22), propaganda, disinformation, misinformation, fake news, memes, multimodality. arXiv admin note: text overlap with arXiv:2109.08013, arXiv:2105.09284\n",
    "authors": [
      "Firoj Alam",
      "Hamdy Mubarak",
      "Wajdi Zaghouani",
      "Giovanni Da San Martino",
      "Preslav Nakov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10057"
  },
  {
    "id": "arXiv:2211.10060",
    "title": "Reference-Based Autoencoder for Surface Defect Detection",
    "abstract": "Due to the extreme imbalance in the number of normal data and abnormal data,\nvisual anomaly detection is important for the development of industrial\nautomatic product quality inspection. Unsupervised methods based on\nreconstruction and embedding have been widely studied for anomaly detection, of\nwhich reconstruction-based methods are the most popular. However, establishing\na unified model for textured surface defect detection remains a challenge\nbecause these surfaces can vary in homogeneous and non regularly ways.\nFurthermore, existing reconstruction-based methods do not have a strong ability\nto convert the defect feature to the normal feature. To address these\nchallenges, we propose a novel unsupervised reference-based autoencoder (RB-AE)\nto accurately inspect a variety of textured defects. Unlike most\nreconstruction-based methods, artificial defects and a novel pixel-level\ndiscrimination loss function are utilized for training to enable the model to\nobtain pixel-level discrimination ability. First, the RB-AE employs an encoding\nmodule to extract multi-scale features of the textured surface. Subsequently, a\nnovel reference-based attention module (RBAM) is proposed to convert the defect\nfeatures to normal features to suppress the reconstruction of defects. In\naddition, RBAM can also effectively suppress the defective feature residual\ncaused by skip-connection. Next, a decoding module utilizes the repaired\nfeatures to reconstruct the normal texture background. Finally, a novel\nmultiscale feature discrimination module (MSFDM) is employed to defect\ndetection and segmentation.",
    "descriptor": "\nComments: 13pages\n",
    "authors": [
      "Wei Luo",
      "Haiming Yao",
      "Wenyong Yu",
      "Xue Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10060"
  },
  {
    "id": "arXiv:2211.10062",
    "title": "Intrusion Detection in Internet of Things using Convolutional Neural  Networks",
    "abstract": "Internet of Things (IoT) has become a popular paradigm to fulfil needs of the\nindustry such as asset tracking, resource monitoring and automation. As\nsecurity mechanisms are often neglected during the deployment of IoT devices,\nthey are more easily attacked by complicated and large volume intrusion attacks\nusing advanced techniques. Artificial Intelligence (AI) has been used by the\ncyber security community in the past decade to automatically identify such\nattacks. However, deep learning methods have yet to be extensively explored for\nIntrusion Detection Systems (IDS) specifically for IoT. Most recent works are\nbased on time sequential models like LSTM and there is short of research in\nCNNs as they are not naturally suited for this problem. In this article, we\npropose a novel solution to the intrusion attacks against IoT devices using\nCNNs. The data is encoded as the convolutional operations to capture the\npatterns from the sensors data along time that are useful for attacks detection\nby CNNs. The proposed method is integrated with two classical CNNs: ResNet and\nEfficientNet, where the detection performance is evaluated. The experimental\nresults show significant improvement in both true positive rate and false\npositive rate compared to the baseline using LSTM.",
    "descriptor": "\nComments: Keywords: Cybersecurity, Intrusion Detection, IoT, Deep Learning, Convolutional Neural Networks; this https URL\n",
    "authors": [
      "Martin Kodys",
      "Zhi Lu",
      "Kar Wai Fok",
      "Vrizlynn L. L. Thing"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10062"
  },
  {
    "id": "arXiv:2211.10065",
    "title": "How to train your draGAN: A task oriented solution to imbalanced  classification",
    "abstract": "The long-standing challenge of building effective classification models for\nsmall and imbalanced datasets has seen little improvement since the creation of\nthe Synthetic Minority Over-sampling Technique (SMOTE) over 20 years ago.\nThough GAN based models seem promising, there has been a lack of purpose built\narchitectures for solving the aforementioned problem, as most previous studies\nfocus on applying already existing models. This paper proposes a unique,\nperformance-oriented, data-generating strategy that utilizes a new\narchitecture, coined draGAN, to generate both minority and majority samples.\nThe samples are generated with the objective of optimizing the classification\nmodel's performance, rather than similarity to the real data. We benchmark our\napproach against state-of-the-art methods from the SMOTE family and competitive\nGAN based approaches on 94 tabular datasets with varying degrees of imbalance\nand linearity. Empirically we show the superiority of draGAN, but also\nhighlight some of its shortcomings. All code is available on:\nhttps://github.com/LeonGuertler/draGAN.",
    "descriptor": "\nComments: 94 Datasets; under review (Elsevier Neural Networks)\n",
    "authors": [
      "Leon O. Guertler",
      "Andri Ashfahani",
      "Anh Tuan Luu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10065"
  },
  {
    "id": "arXiv:2211.10066",
    "title": "Hyperbolic Sliced-Wasserstein via Geodesic and Horospherical Projections",
    "abstract": "It has been shown beneficial for many types of data which present an\nunderlying hierarchical structure to be embedded in hyperbolic spaces.\nConsequently, many tools of machine learning were extended to such spaces, but\nonly few discrepancies to compare probability distributions defined over those\nspaces exist. Among the possible candidates, optimal transport distances are\nwell defined on such Riemannian manifolds and enjoy strong theoretical\nproperties, but suffer from high computational cost. On Euclidean spaces,\nsliced-Wasserstein distances, which leverage a closed-form of the Wasserstein\ndistance in one dimension, are more computationally efficient, but are not\nreadily available on hyperbolic spaces. In this work, we propose to derive\nnovel hyperbolic sliced-Wasserstein discrepancies. These constructions use\nprojections on the underlying geodesics either along horospheres or geodesics.\nWe study and compare them on different tasks where hyperbolic representations\nare relevant, such as sampling or image classification.",
    "descriptor": "",
    "authors": [
      "Cl\u00e9ment Bonet",
      "Laetitia Chapel",
      "Lucas Drumetz",
      "Nicolas Courty"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.10066"
  },
  {
    "id": "arXiv:2211.10073",
    "title": "Point-Cloud-based Deep Learning Models for Finite Element Analysis",
    "abstract": "In this paper, we explore point-cloud based deep learning models to analyze\nnumerical simulations arising from finite element analysis. The objective is to\nclassify automatically the results of the simulations without tedious human\nintervention. Two models are here presented: the Point-Net classification model\nand the Dynamic Graph Convolutional Neural Net model. Both trained point-cloud\ndeep learning models performed well on experiments with finite element analysis\narising from automotive industry. The proposed models show promise in\nautomatizing the analysis process of finite element simulations. An accuracy of\n79.17% and 94.5% is obtained for the Point-Net and the Dynamic Graph\nConvolutional Neural Net model respectively.",
    "descriptor": "",
    "authors": [
      "Meduri Venkata Shivaditya",
      "Francesca Bugiotti",
      "Frederic Magoules"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.10073"
  },
  {
    "id": "arXiv:2211.10075",
    "title": "Policy Learning for Nonlinear Model Predictive Control with Application  to USVs",
    "abstract": "The unaffordable computation load of nonlinear model predictive control\n(NMPC) has prevented it for being used in robots with high sampling rates for\ndecades. This paper is concerned with the policy learning problem for nonlinear\nMPC with system constraints, and its applications to unmanned surface vehicles\n(USVs), where the nonlinear MPC policy is learned offline and deployed online\nto resolve the computational complexity issue. A deep neural networks (DNN)\nbased policy learning MPC (PL-MPC) method is proposed to avoid solving\nnonlinear optimal control problems online. The detailed policy learning method\nis developed and the PL-MPC algorithm is designed. The strategy to ensure the\npractical feasibility of policy implementation is proposed, and it is\ntheoretically proved that the closed-loop system under the proposed method is\nasymptotically stable in probability. In addition, we apply the PL-MPC\nalgorithm successfully to the motion control of USVs. It is shown that the\nproposed algorithm can be implemented at a sampling rate up to $5 Hz$ with\nhigh-precision motion control. The experiment video is available\nvia:\\url{https://v.youku.com/v_show/id_XNTkwMTM0NzM5Ng==.html",
    "descriptor": "",
    "authors": [
      "Rizhong Wang",
      "Huiping Li",
      "Bin Liang",
      "Yang Shi",
      "Demin Xu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.10075"
  },
  {
    "id": "arXiv:2211.10076",
    "title": "Applications of Quantum Annealing in Cryptography",
    "abstract": "This paper presents a new method to reduce the optimization of a\npseudo-Boolean function to QUBO problem which can be solved by quantum\nannealer. The new method has two aspects, one is coefficient optimization and\nthe other is variable optimization. The former is an improvement on the\nexisting algorithm in a special case. The latter is realized by means of the\nmaximal independent point set in graph theory. We apply this new method in\ninteger factorization on quantum annealers and achieve the largest integer\nfactorization (4137131) with 93 variables, the range of coefficients is\n[-1024,1024] which is much smaller than the previous results. We also focus on\nthe quantum attacks on block ciphers and present an efficient method with\nsmaller coefficients to transform Boolean equation systems into QUBO problems.",
    "descriptor": "",
    "authors": [
      "Anpeng Zhang",
      "Xiutao Feng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.10076"
  },
  {
    "id": "arXiv:2211.10080",
    "title": "Convergence of the PCTL algorithm for solving the discretized 3T energy  equations in RHD problems",
    "abstract": "For solving the three-temperature linear system arising from the radiation\nhydrodynamics (RHD) problem, Xu et. proposed a physical-variable based\ncoarsening algebraic two level (PCTL) iterative method and verified its\nefficiency by numerical experiments. However, there is still a lack of\nquantitative evaluation of the performance of PCTL algorithm, thus we aim to\nfill in this blank in this paper. By theoretical analysis, we give an\nestimation on the convergence factor of the PCTL algorithm and show it is\nindependent of the problem size, which provides a theoretical guarantee for\nsolving large-scale problems. Moreover, we also discuss the factors that affect\nthe efficiency of PCTL algorithm and provide a direction for the efficient\napplication of the PCTL algorithm.",
    "descriptor": "",
    "authors": [
      "Yue Hao",
      "Silu Huang",
      "Xiaowen Xu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.10080"
  },
  {
    "id": "arXiv:2211.10081",
    "title": "A fast and accurate numerical approach for electromagnetic inversion",
    "abstract": "This paper deals with the solution of Maxwell's equations to model the\nelectromagnetic fields in the case of a layered earth. The integrals involved\nin the solution are approximated by means of a novel approach based on the\nsplitting of the reflection term. The inverse problem, consisting in the\ncomputation of the unknown underground conductivity distribution from a set of\nmodeled magnetic field components, is also considered. Two optimization\nalgorithms are applied, based on line- and global-search methods, and a new\nminimization approach is presented. Several EM surveys from the ground surface\nare simulated, considering the horizontal coplanar (HCP) and perpendicular\n(PRP) magnetic dipolar configurations. The numerical experiments, carried out\nfor the study of river-levees integrity, allowed to estimate the errors\nassociated to these kind of investigations, and confirm the reliability of the\ntechnique.",
    "descriptor": "",
    "authors": [
      "Eleonora Denich",
      "Paolo Novati",
      "Stefano Picotti"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.10081"
  },
  {
    "id": "arXiv:2211.10082",
    "title": "Private Federated Statistics in an Interactive Setting",
    "abstract": "Privately learning statistics of events on devices can enable improved user\nexperience. Differentially private algorithms for such problems can benefit\nsignificantly from interactivity. We argue that an aggregation protocol can\nenable an interactive private federated statistics system where user's devices\nmaintain control of the privacy assurance. We describe the architecture of such\na system, and analyze its security properties.",
    "descriptor": "",
    "authors": [
      "Audra McMillan",
      "Omid Javidbakht",
      "Kunal Talwar",
      "Elliot Briggs",
      "Mike Chatzidakis",
      "Junye Chen",
      "John Duchi",
      "Vitaly Feldman",
      "Yusuf Goren",
      "Michael Hesse",
      "Vojta Jina",
      "Anil Katti",
      "Albert Liu",
      "Cheney Lyford",
      "Joey Meyer",
      "Alex Palmer",
      "David Park",
      "Wonhee Park",
      "Gianni Parsa",
      "Paul Pelzl",
      "Rehan Rishi",
      "Congzheng Song",
      "Shan Wang",
      "Shundong Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.10082"
  },
  {
    "id": "arXiv:2211.10085",
    "title": "Identifying Unique Causal Network from Nonstationary Time Series",
    "abstract": "Identifying causality is a challenging task in many data-intensive scenarios.\nMany algorithms have been proposed for this critical task. However, most of\nthem consider the learning algorithms for directed acyclic graph (DAG) of\nBayesian network (BN). These BN-based models only have limited causal\nexplainability because of the issue of Markov equivalence class. Moreover, they\nare dependent on the assumption of stationarity, whereas many sampling time\nseries from complex system are nonstationary. The nonstationary time series\nbring dataset shift problem, which leads to the unsatisfactory performances of\nthese algorithms. To fill these gaps, a novel causation model named Unique\nCausal Network (UCN) is proposed in this paper. Different from the previous\nBN-based models, UCN considers the influence of time delay, and proves the\nuniqueness of obtained network structure, which addresses the issue of Markov\nequivalence class. Furthermore, based on the decomposability property of UCN, a\nhigher-order causal entropy (HCE) algorithm is designed to identify the\nstructure of UCN in a distributed way. HCE algorithm measures the strength of\ncausality by using nearest-neighbors entropy estimator, which works well on\nnonstationary time series. Finally, lots of experiments validate that HCE\nalgorithm achieves state-of-the-art accuracy when time series are\nnonstationary, compared to the other baseline algorithms.",
    "descriptor": "\nComments: Submit to AAAI-23\n",
    "authors": [
      "Mingyu Kang",
      "Duxin Chen",
      "Ning Meng",
      "Gang Yan",
      "Wenwu Yu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10085"
  },
  {
    "id": "arXiv:2211.10086",
    "title": "Metadata Might Make Language Models Better",
    "abstract": "This paper discusses the benefits of including metadata when training\nlanguage models on historical collections. Using 19th-century newspapers as a\ncase study, we extend the time-masking approach proposed by Rosin et al., 2022\nand compare different strategies for inserting temporal, political and\ngeographical information into a Masked Language Model. After fine-tuning\nseveral DistilBERT on enhanced input data, we provide a systematic evaluation\nof these models on a set of evaluation tasks: pseudo-perplexity, metadata\nmask-filling and supervised classification. We find that showing relevant\nmetadata to a language model has a beneficial impact and may even produce more\nrobust and fairer models.",
    "descriptor": "",
    "authors": [
      "Kaspar Beelen",
      "Daniel van Strien"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2211.10086"
  },
  {
    "id": "arXiv:2211.10095",
    "title": "Improving Robustness of TCM-based Robust Steganography with Variable  Robustness",
    "abstract": "Recent study has found out that after multiple times of recompression, the\nDCT coefficients of JPEG image can form an embedding domain that is robust to\nrecompression, which is called transport channel matching (TCM) method. Because\nthe cost function of the adaptive steganography does not consider the impact of\nmodification on the robustness, the modified DCT coefficients of the stego\nimage after TCM will change after recompression. To reduce the number of\nchanged coefficients after recompression, this paper proposes a robust\nsteganography algorithm which dynamically updates the robustness cost of every\nDCT coefficient. The robustness cost proposed is calculated by testing whether\nthe modified DCT coefficient can resist recompression in every step of STC\nembedding process. By adding robustness cost to the distortion cost and using\nthe framework of STC embedding algorithm to embed the message, the stego images\nhave good performance both in robustness and security. The experimental results\nshow that the proposed algorithm can significantly enhance the robustness of\nstego images, and the embedded messages could be extracted correctly at almost\nall cases when recompressing with a lower quality factor and recompression\nprocess is known to the user of proposed algorithm.",
    "descriptor": "",
    "authors": [
      "Jimin Zhang",
      "Xianfeng Zhao",
      "Xiaolei He"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.10095"
  },
  {
    "id": "arXiv:2211.10097",
    "title": "Nonlinear Moving Horizon Estimation and Model Predictive Control for  Buildings with Unknown HVAC Dynamics",
    "abstract": "We present a solution for modeling and online identification for heating,\nventilation, and air conditioning (HVAC) control in buildings. Our approach\ncomprises: (a) a resistance-capacitance (RC) model based on first order energy\nbalance for deriving the zone temperature dynamics, and (b) a neural network\nfor modeling HVAC dynamics. State estimation and model identification are\nsimultaneously performed using nonlinear moving horizon estimation (MHE) with\nphysical constraints for system states. We leverage the identified model in\nmodel predictive control (MPC) for occupant comfort satisfaction and HVAC\nenergy savings and verify the approach using simulations. Our system relies\nonly on building management system data, does not require extensive data\nstorage, and does not require a detailed building model. This can significantly\naid the large scale adoption of MPC for future occupant-centric control of\ngrid-interactive buildings.",
    "descriptor": "\nComments: Accepted to 4th IFAC Workshop on Cyber-Physical and Human Systems (CPHS 2022)\n",
    "authors": [
      "Saman Mostafavi",
      "Harish Doddi",
      "Krishna Kalyanam",
      "David Schwartz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.10097"
  },
  {
    "id": "arXiv:2211.10098",
    "title": "UnconFuse: Avatar Reconstruction from Unconstrained Images",
    "abstract": "The report proposes an effective solution about 3D human body reconstruction\nfrom multiple unconstrained frames for ECCV 2022 WCPA Challenge: From Face,\nBody and Fashion to 3D Virtual avatars I (track1: Multi-View Based 3D Human\nBody Reconstruction). We reproduce the reconstruction method presented in\nMVP-Human as our baseline, and make some improvements for the particularity of\nthis challenge. We finally achieve the score 0.93 on the official testing set,\ngetting the 1st place on the leaderboard.",
    "descriptor": "\nComments: Accepted to ECCV 2022 Workshop\n",
    "authors": [
      "Han Huang",
      "Liliang Chen",
      "Xihao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10098"
  },
  {
    "id": "arXiv:2211.10099",
    "title": "Reconciling Shannon and Scott with a Lattice of Computable Information",
    "abstract": "This paper proposes a reconciliation of two different theories of\ninformation. The first, originally proposed in a lesser-known work by Claude\nShannon, describes how the information content of channels can be described\nqualitatively, but still abstractly, in terms of information elements, i.e.\nequivalence relations over the data source domain. Shannon showed that these\nelements form a complete lattice, with the order expressing when one element is\nmore informative than another. In the context of security and information flow\nthis structure has been independently rediscovered several times, and used as a\nfoundation for reasoning about information flow.\nThe second theory of information is Dana Scott's domain theory, a\nmathematical framework for giving meaning to programs as continuous functions\nover a particular topology. Scott's partial ordering also represents when one\nelement is more informative than another, but in the sense of computational\nprogress, i.e. when one element is a more defined or evolved version of\nanother.\nTo give a satisfactory account of information flow in programs it is\nnecessary to consider both theories together, to understand what information is\nconveyed by a program viewed as a channel (\\`a la Shannon) but also by the\ndefinedness of its encoding (\\`a la Scott). We combine these theories by\ndefining the Lattice of Computable Information (LoCI), a lattice of preorders\nrather than equivalence relations. LoCI retains the rich lattice structure of\nShannon's theory, filters out elements that do not make computational sense,\nand refines the remaining information elements to reflect how Scott's ordering\ncaptures the way that information is presented.\nWe show how the new theory facilitates the first general definition of\ntermination-insensitive information flow properties, a weakened form of\ninformation flow property commonly targeted by static program analyses.",
    "descriptor": "\nComments: 30 pages; to be presented at the 50th ACM SIGPLAN Symposium on Principles of Programming Languages (POPL 2023), 15-21 January 2023\n",
    "authors": [
      "Sebastian Hunt",
      "David Sands",
      "Sandro Stucki"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Cryptography and Security (cs.CR)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.10099"
  },
  {
    "id": "arXiv:2211.10100",
    "title": "Credit-cognisant reinforcement learning for multi-agent cooperation",
    "abstract": "Traditional multi-agent reinforcement learning (MARL) algorithms, such as\nindependent Q-learning, struggle when presented with partially observable\nscenarios, and where agents are required to develop delicate action sequences.\nThis is often the result of the reward for a good action only being available\nafter other agents have taken theirs, and these actions are not credited\naccordingly. Recurrent neural networks have proven to be a viable solution\nstrategy for solving these types of problems, resulting in significant\nperformance increase when compared to other methods. In this paper, we explore\na different approach and focus on the experiences used to update the\naction-value functions of each agent. We introduce the concept of\ncredit-cognisant rewards (CCRs), which allows an agent to perceive the effect\nits actions had on the environment as well as on its co-agents. We show that by\nmanipulating these experiences and constructing the reward contained within\nthem to include the rewards received by all the agents within the same action\nsequence, we are able to improve significantly on the performance of\nindependent deep Q-learning as well as deep recurrent Q-learning. We evaluate\nand test the performance of CCRs when applied to deep reinforcement learning\ntechniques at the hands of a simplified version of the popular card game\nHanabi.",
    "descriptor": "\nComments: 11 pages, 6 figures, 1 appendix, submitted to IEEE Transaction on Games\n",
    "authors": [
      "F. Bredell",
      "H. A. Engelbrecht",
      "J. C. Schoeman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.10100"
  },
  {
    "id": "arXiv:2211.10103",
    "title": "Let's Enhance: A Deep Learning Approach to Extreme Deblurring of Text  Images",
    "abstract": "This work presents a novel deep-learning-based pipeline for the inverse\nproblem of image deblurring, leveraging augmentation and pre-training with\nsynthetic data. Our results build on our winning submission to the recent\nHelsinki Deblur Challenge 2021, whose goal was to explore the limits of\nstate-of-the-art deblurring algorithms in a real-world data setting. The task\nof the challenge was to deblur out-of-focus images of random text, thereby in a\ndownstream task, maximizing an optical-character-recognition-based score\nfunction. A key step of our solution is the data-driven estimation of the\nphysical forward model describing the blur process. This enables a stream of\nsynthetic data, generating pairs of ground-truth and blurry images on-the-fly,\nwhich is used for an extensive augmentation of the small amount of challenge\ndata provided. The actual deblurring pipeline consists of an approximate\ninversion of the radial lens distortion (determined by the estimated forward\nmodel) and a U-Net architecture, which is trained end-to-end. Our algorithm was\nthe only one passing the hardest challenge level, achieving over 70% character\nrecognition accuracy. Our findings are well in line with the paradigm of\ndata-centric machine learning, and we demonstrate its effectiveness in the\ncontext of inverse problems. Apart from a detailed presentation of our\nmethodology, we also analyze the importance of several design choices in a\nseries of ablation studies. The code of our challenge submission is available\nunder https://github.com/theophil-trippe/HDC_TUBerlin_version_1.",
    "descriptor": "",
    "authors": [
      "Theophil Trippe",
      "Martin Genzel",
      "Jan Macdonald",
      "Maximilian M\u00e4rz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.10103"
  },
  {
    "id": "arXiv:2211.10104",
    "title": "Stereo Image Rain Removal via Dual-View Mutual Attention",
    "abstract": "Stereo images, containing left and right view images with disparity, are\nutilized in solving low-vision tasks recently, e.g., rain removal and\nsuper-resolution. Stereo image restoration methods usually obtain better\nperformance than monocular methods by learning the disparity between dual views\neither implicitly or explicitly. However, existing stereo rain removal methods\nstill cannot make full use of the complementary information between two views,\nand we find it is because: 1) the rain streaks have more complex distributions\nin directions and densities, which severely damage the complementary\ninformation and pose greater challenges; 2) the disparity estimation is not\naccurate enough due to the imperfect fusion mechanism for the features between\ntwo views. To overcome such limitations, we propose a new \\underline{Stereo}\n\\underline{I}mage \\underline{R}ain \\underline{R}emoval method (StereoIRR) via\nsufficient interaction between two views, which incorporates: 1) a new\nDual-view Mutual Attention (DMA) mechanism which generates mutual attention\nmaps by taking left and right views as key information for each other to\nfacilitate cross-view feature fusion; 2) a long-range and cross-view\ninteraction, which is constructed with basic blocks and dual-view mutual\nattention, can alleviate the adverse effect of rain on complementary\ninformation to help the features of stereo images to get long-range and\ncross-view interaction and fusion. Notably, StereoIRR outperforms other related\nmonocular and stereo image rain removal methods on several datasets. Our codes\nand datasets will be released.",
    "descriptor": "",
    "authors": [
      "Yanyan Wei",
      "Zhao Zhang",
      "Zhongqiu Zhao",
      "Yang Zhao",
      "Richang Hong",
      "Yi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10104"
  },
  {
    "id": "arXiv:2211.10105",
    "title": "$\u03b1$ DARTS Once More: Enhancing Differentiable Architecture Search  by Masked Image Modeling",
    "abstract": "Differentiable architecture search (DARTS) has been a mainstream direction in\nautomatic machine learning. Since the discovery that original DARTS will\ninevitably converge to poor architectures, recent works alleviate this by\neither designing rule-based architecture selection techniques or incorporating\ncomplex regularization techniques, abandoning the simplicity of the original\nDARTS that selects architectures based on the largest parametric value, namely\n$\\alpha$. Moreover, we find that all the previous attempts only rely on\nclassification labels, hence learning only single modal information and\nlimiting the representation power of the shared network. To this end, we\npropose to additionally inject semantic information by formulating a patch\nrecovery approach. Specifically, we exploit the recent trending masked image\nmodeling and do not abandon the guidance from the downstream tasks during the\nsearch phase. Our method surpasses all previous DARTS variants and achieves\nstate-of-the-art results on CIFAR-10, CIFAR-100, and ImageNet without complex\nmanual-designed strategies.",
    "descriptor": "",
    "authors": [
      "Bicheng Guo",
      "Shuxuan Guo",
      "Miaojing Shi",
      "Peng Chen",
      "Shibo He",
      "Jiming Chen",
      "Kaicheng Yu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10105"
  },
  {
    "id": "arXiv:2211.10117",
    "title": "Scaling Native Language Identification with Transformer Adapters",
    "abstract": "Native language identification (NLI) is the task of automatically identifying\nthe native language (L1) of an individual based on their language production in\na learned language. It is useful for a variety of purposes including marketing,\nsecurity and educational applications. NLI is usually framed as a multi-label\nclassification task, where numerous designed features are combined to achieve\nstate-of-the-art results. Recently deep generative approach based on\ntransformer decoders (GPT-2) outperformed its counterparts and achieved the\nbest results on the NLI benchmark datasets. We investigate this approach to\ndetermine the practical implications compared to traditional state-of-the-art\nNLI systems. We introduce transformer adapters to address memory limitations\nand improve training/inference speed to scale NLI applications for production.",
    "descriptor": "\nComments: Paper accepted to International Conference on Natural Language and Speech Processing 2022 (ICNLSP 2022)\n",
    "authors": [
      "Ahmet Yavuz Uluslu",
      "Gerold Schneider"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.10117"
  },
  {
    "id": "arXiv:2211.10119",
    "title": "Mixture Domain Adaptation to Improve Semantic Segmentation in Real-World  Surveillance",
    "abstract": "Various tasks encountered in real-world surveillance can be addressed by\ndetermining posteriors (e.g. by Bayesian inference or machine learning), based\non which critical decisions must be taken. However, the surveillance domain\n(acquisition device, operating conditions, etc.) is often unknown, which\nprevents any possibility of scene-specific optimization. In this paper, we\ndefine a probabilistic framework and present a formal proof of an algorithm for\nthe unsupervised many-to-infinity domain adaptation of posteriors. Our proposed\nalgorithm is applicable when the probability measure associated with the target\ndomain is a convex combination of the probability measures of the source\ndomains. It makes use of source models and a domain discriminator model trained\noff-line to compute posteriors adapted on the fly to the target domain.\nFinally, we show the effectiveness of our algorithm for the task of semantic\nsegmentation in real-world surveillance. The code is publicly available at\nhttps://github.com/rvandeghen/MDA.",
    "descriptor": "",
    "authors": [
      "S\u00e9bastien Pi\u00e9rard",
      "Anthony Cioppa",
      "Ana\u00efs Halin",
      "Renaud Vandeghen",
      "Maxime Zanella",
      "Beno\u00eet Macq",
      "Sa\u00efd Mahmoudi",
      "Marc Van Droogenbroeck"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10119"
  },
  {
    "id": "arXiv:2211.10128",
    "title": "Spatio-Temporal Feedback Control of Small Target Motion Detection Visual  System",
    "abstract": "Feedback is crucial to motion perception in animals' visual systems where its\nspatial and temporal dynamics are often shaped by movement patterns of\nsurrounding environments. However, such spatio-temporal feedback has not been\ndeeply explored in designing neural networks to detect small moving targets\nthat cover only one or a few pixels in image while presenting extremely limited\nvisual features. In this paper, we address small target motion detection\nproblem by developing a visual system with spatio-temporal feedback loop, and\nfurther reveal its important roles in suppressing false positive background\nmovement while enhancing network responses to small targets. Specifically, the\nproposed visual system is composed of two complementary subnetworks. The first\nsubnetwork is designed to extract spatial and temporal motion patterns of\ncluttered backgrounds by neuronal ensemble coding. The second subnetwork is\ndeveloped to capture small target motion information and integrate the\nspatio-temporal feedback signal from the first subnetwork to inhibit background\nfalse positives. Experimental results demonstrate that the proposed\nspatio-temporal feedback visual system is more competitive than existing\nmethods in discriminating small moving targets from complex dynamic\nenvironment.",
    "descriptor": "",
    "authors": [
      "Hongxin Wang",
      "Zhiyan Zhong",
      "Fang Lei",
      "Xiaohua Jing",
      "Jigen Peng",
      "Shigang Yue"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10128"
  },
  {
    "id": "arXiv:2211.10129",
    "title": "Rare Yet Popular: Evidence and Implications from Labeled Datasets for  Network Anomaly Detection",
    "abstract": "Anomaly detection research works generally propose algorithms or end-to-end\nsystems that are designed to automatically discover outliers in a dataset or a\nstream. While literature abounds concerning algorithms or the definition of\nmetrics for better evaluation, the quality of the ground truth against which\nthey are evaluated is seldom questioned. In this paper, we present a systematic\nanalysis of available public (and additionally our private) ground truth for\nanomaly detection in the context of network environments, where data is\nintrinsically temporal, multivariate and, in particular, exhibits spatial\nproperties, which, to the best of our knowledge, we are the first to explore.\nOur analysis reveals that, while anomalies are, by definition, temporally rare\nevents, their spatial characterization clearly shows some type of anomalies are\nsignificantly more popular than others. We find that simple clustering can\nreduce the need for human labeling by a factor of 2x-10x, that we are first to\nquantitatively analyze in the wild.",
    "descriptor": "\nComments: Published in the International Teletraffic Congress (ITC 34), 14-16 September 2022\n",
    "authors": [
      "Jose Manuel Navarro",
      "Alexis Huet",
      "Dario Rossi"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10129"
  },
  {
    "id": "arXiv:2211.10132",
    "title": "A Novel Approach to Climate Resilience of Infrastructure Networks",
    "abstract": "With a changing climate, the frequency and intensity of extreme weather\nevents are likely to increase, posing a threat to infrastructure systems'\nresilience. The response of infrastructure systems to localised failures\ndepends on whether assets are affected randomly, in a targeted strategic way,\nor any way in between. More than that, infrastructure decisions today,\nincluding new routes or improvements to existing assets, will underpin the\nbehaviour of the systems over the next century. It is important to separate and\nanalyse the case of climate-based disruptions and how they affect systems'\nresilience. This paper presents a probabilistic resilience assessment framework\nwhere failure scenarios and network disruptions are generated using weather\nprofile data from climate prediction models with component-level fragility\nfunctions. A case study is then carried out to quantify the resilience of Great\nBritain's railway passenger transport system to high-temperature-related track\nbuckling under the Representative Concentration Pathway 8.5 (RCP8.5) climate\nchange scenario. A 95-year horizon on the resilience of the railway system is\ndrawn. The results also reveal the non-linear responses of the railway system\nto the increasing temperature and show that models considering random asset\nfailures overestimate the system's resilience.",
    "descriptor": "",
    "authors": [
      "Qianqian Li",
      "Giuliano Punzo",
      "Craig Robson",
      "Hadi Arbabi",
      "Martin Mayfield"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.10132"
  },
  {
    "id": "arXiv:2211.10137",
    "title": "Identifying Correlation in Stream of Samples",
    "abstract": "Identifying independence between two random variables or correlated given\ntheir samples has been a fundamental problem in Statistics. However, how to do\nso in a space-efficient way if the number of states is large is not quite\nwell-studied.\nWe propose a new, simple counter matrix algorithm, which utilize hash\nfunctions and a compressed counter matrix to give an unbiased estimate of the\n$\\ell_2$ independence metric. With $\\mathcal{O}(\\epsilon^{-4}\\log\\delta^{-1})$\n(very loose bound) space, we can guarantee $1\\pm\\epsilon$ multiplicative error\nwith probability at least $1-\\delta$. We also provide a comparison of our\nalgorithm with the state-of-the-art sketching of sketches algorithm and show\nthat our algorithm is effective, and actually faster and at least 2 times more\nspace-efficient.",
    "descriptor": "",
    "authors": [
      "Zhenhao Gu",
      "Hao Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.10137"
  },
  {
    "id": "arXiv:2211.10144",
    "title": "Computational Short Cuts in Infinite Domain Constraint Satisfaction",
    "abstract": "A backdoor in a finite-domain CSP instance is a set of variables where each\npossible instantiation moves the instance into a polynomial-time solvable\nclass. Backdoors have found many applications in artificial intelligence and\nelsewhere, and the algorithmic problem of finding such backdoors has\nconsequently been intensively studied. Sioutis and Janhunen (Proc. 42nd German\nConference on AI (KI-2019)) have proposed a generalised backdoor concept\nsuitable for infinite-domain CSP instances over binary constraints. We\ngeneralise their concept into a large class of CSPs that allow for higher-arity\nconstraints. We show that this kind of infinite-domain backdoors have many of\nthe positive computational properties that finite-domain backdoors have: the\nassociated computational problems are fixed-parameter tractable whenever the\nunderlying constraint language is finite. On the other hand, we show that\ninfinite languages make the problems considerably harder: the general backdoor\ndetection problem is W[2]-hard and fixed-parameter tractability is ruled out\nunder standard complexity-theoretic assumptions. We demonstrate that backdoors\nmay have suboptimal behaviour on binary constraints -- this is detrimental from\nan AI perspective where binary constraints are predominant in, for instance,\nspatiotemporal applications. In response to this, we introduce sidedoors as an\nalternative to backdoors. The fundamental computational problems for sidedoors\nremain fixed-parameter tractable for finite constraint language (possibly also\ncontaining non-binary relations). Moreover, the sidedoor approach has appealing\ncomputational properties that sometimes leads to faster algorithms than the\nbackdoor approach.",
    "descriptor": "",
    "authors": [
      "Peter Jonsson",
      "Victor Lagerkvist",
      "Sebastian Ordyniak"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10144"
  },
  {
    "id": "arXiv:2211.10147",
    "title": "FiE: Building a Global Probability Space by Leveraging Early Fusion in  Encoder for Open-Domain Question Answering",
    "abstract": "Generative models have recently started to outperform extractive models in\nOpen Domain Question Answering, largely by leveraging their decoder to attend\nover multiple encoded passages and combining their information. However,\ngenerative models tend to be larger than extractive models due to the need for\na decoder, run slower during inference due to auto-regressive decoder beam\nsearch, and their generated output often suffers from hallucinations. We\npropose to extend transformer encoders with the ability to fuse information\nfrom multiple passages, using global representation to provide cross-sample\nattention over all tokens across samples. Furthermore, we propose an\nalternative answer span probability calculation to better aggregate answer\nscores in the global space of all samples. Using our proposed method, we\noutperform the current state-of-the-art method by $2.5$ Exact Match score on\nthe Natural Question dataset while using only $25\\%$ of parameters and $35\\%$\nof the latency during inference, and $4.4$ Exact Match on WebQuestions dataset.\nWhen coupled with synthetic data augmentation, we outperform larger models on\nthe TriviaQA dataset as well. The latency and parameter savings of our method\nmake it particularly attractive for open-domain question answering, as these\nmodels are often compute-intensive.",
    "descriptor": "\nComments: Accepted at EMNLP 2022 Main Conference\n",
    "authors": [
      "Akhil Kedia",
      "Mohd Abbas Zaidi",
      "Haejun Lee"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.10147"
  },
  {
    "id": "arXiv:2211.10151",
    "title": "Asymptotically Tight Bounds on the Time Complexity of Broadcast and its  Variants in Dynamic Networks",
    "abstract": "Data dissemination is a fundamental task in distributed computing. This paper\nstudies broadcast problems in various innovative models where the communication\nnetwork connecting $n$ processes is dynamic (e.g., due to mobility or failures)\nand controlled by an adversary.\nIn the first model, the processes transitively communicate their ids in\nsynchronous rounds along a rooted tree given in each round by the adversary\nwhose goal is to maximize the number of rounds until at least one id is known\nby all processes.\nPrevious research has shown a $\\lceil{\\frac{3n-1}{2}}\\rceil-2$ lower bound\nand an $O(n\\log\\log n)$ upper bound. We show the first linear upper bound for\nthis problem, namely $\\lceil{(1 + \\sqrt 2) n-1}\\rceil \\approx 2.4n$.\nWe extend these results to the setting where the adversary gives in each\nround $k$-disjoint forests and their goal is to maximize the number of rounds\nuntil there is a set of $k$ ids such that each process knows of at least one of\nthem. We give a $\\left\\lceil{\\frac{3(n-k)}{2}}\\right\\rceil-1$ lower bound and a\n$\\frac{\\pi^2+6}{6}n+1 \\approx 2.6n$ upper bound for this problem.\nFinally, we study the setting where the adversary gives in each round a\ndirected graph with $k$ roots and their goal is to maximize the number of\nrounds until there exist $k$ ids that are known by all processes. We give a\n$\\left\\lceil{\\frac{3(n-3k)}{2}}\\right\\rceil+2$ lower bound and a $\\lceil {\n(1+\\sqrt{2})n}\\rceil+k-1 \\approx 2.4n+k$ upper bound for this problem.\nFor the two latter problems no upper or lower bounds were previously known.",
    "descriptor": "\nComments: 25 pages, 8 figures, to be published in ITCS'23\n",
    "authors": [
      "Antoine El-Hayek",
      "Monika Henzinger",
      "Stefan Schmid"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.10151"
  },
  {
    "id": "arXiv:2211.10154",
    "title": "CRAFT: Concept Recursive Activation FacTorization for Explainability",
    "abstract": "Attribution methods are a popular class of explainability methods that use\nheatmaps to depict the most important areas of an image that drive a model\ndecision. Nevertheless, recent work has shown that these methods have limited\nutility in practice, presumably because they only highlight the most salient\nparts of an image (i.e., 'where' the model looked) and do not communicate any\ninformation about 'what' the model saw at those locations. In this work, we try\nto fill in this gap with CRAFT -- a novel approach to identify both 'what' and\n'where' by generating concept-based explanations. We introduce 3 new\ningredients to the automatic concept extraction literature: (i) a recursive\nstrategy to detect and decompose concepts across layers, (ii) a novel method\nfor a more faithful estimation of concept importance using Sobol indices, and\n(iii) the use of implicit differentiation to unlock Concept Attribution Maps.\nWe conduct both human and computer vision experiments to demonstrate the\nbenefits of the proposed approach. We show that our recursive decomposition\ngenerates meaningful and accurate concepts and that the proposed concept\nimportance estimation technique is more faithful to the model than previous\nmethods. When evaluating the usefulness of the method for human experimenters\non a human-defined utility benchmark, we find that our approach significantly\nimproves on two of the three test scenarios (while none of the current methods\nincluding ours help on the third). Overall, our study suggests that, while much\nwork remains toward the development of general explainability methods that are\nuseful in practical scenarios, the identification of meaningful concepts at the\nproper level of granularity yields useful and complementary information beyond\nthat afforded by attribution methods.",
    "descriptor": "",
    "authors": [
      "Thomas Fel",
      "Agustin Picard",
      "Louis Bethune",
      "Thibaut Boissin",
      "David Vigouroux",
      "Julien Colin",
      "R\u00e9mi Cad\u00e8ne",
      "Thomas Serre"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10154"
  },
  {
    "id": "arXiv:2211.10155",
    "title": "Structured Pruning Adapters",
    "abstract": "We propose Structured Pruning Adapters (SPAs), a family of compressing,\ntask-switching network adapters, that accelerate and specialize networks using\ntiny parameter sets. Specifically, we propose a channel- and a block-based SPA\nand evaluate them with a suite of pruning methods on both computer vision and\nnatural language processing benchmarks. Compared to regular structured pruning\nwith fine-tuning, our channel-SPA improves accuracy by 6.9% on average while\nusing half the parameters at 90% pruned weights. Alternatively, it can learn\nadaptations with 17x fewer parameters at 70% pruning with 1.6% lower accuracy.\nSimilarly, our block-SPA requires far fewer parameters than pruning with\nfine-tuning. Our experimental code and Python library of adapters are available\nat github.com/lukashedegaard/structured-pruning-adapters.",
    "descriptor": "\nComments: 12 pages, 9 figures, 4 tables\n",
    "authors": [
      "Lukas Hedegaard",
      "Aman Alok",
      "Juby Jose",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10155"
  },
  {
    "id": "arXiv:2211.10156",
    "title": "DETRDistill: A Universal Knowledge Distillation Framework for  DETR-families",
    "abstract": "Transformer-based detectors (DETRs) have attracted great attention due to\ntheir sparse training paradigm and the removal of post-processing operations,\nbut the huge model can be computationally time-consuming and difficult to be\ndeployed in real-world applications. To tackle this problem, knowledge\ndistillation (KD) can be employed to compress the huge model by constructing a\nuniversal teacher-student learning framework. Different from the traditional\nCNN detectors, where the distillation targets can be naturally aligned through\nthe feature map, DETR regards object detection as a set prediction problem,\nleading to an unclear relationship between teacher and student during\ndistillation. In this paper, we propose DETRDistill, a novel knowledge\ndistillation dedicated to DETR-families. We first explore a sparse matching\nparadigm with progressive stage-by-stage instance distillation. Considering the\ndiverse attention mechanisms adopted in different DETRs, we propose\nattention-agnostic feature distillation module to overcome the ineffectiveness\nof conventional feature imitation. Finally, to fully leverage the intermediate\nproducts from the teacher, we introduce teacher-assisted assignment\ndistillation, which uses the teacher's object queries and assignment results\nfor a group with additional guidance. Extensive experiments demonstrate that\nour distillation method achieves significant improvement on various competitive\nDETR approaches, without introducing extra consumption in the inference phase.\nTo the best of our knowledge, this is the first systematic study to explore a\ngeneral distillation method for DETR-style detectors.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Jiahao Chang",
      "Shuo Wang",
      "Guangkai Xu",
      "Zehui Chen",
      "Chenhongyi Yang",
      "Feng Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10156"
  },
  {
    "id": "arXiv:2211.10157",
    "title": "UMFuse: Unified Multi View Fusion for Human Editing applications",
    "abstract": "The vision community has explored numerous pose guided human editing methods\ndue to their extensive practical applications. Most of these methods still use\nan image-to-image formulation in which a single image is given as input to\nproduce an edited image as output. However, the problem is ill-defined in cases\nwhen the target pose is significantly different from the input pose. Existing\nmethods then resort to in-painting or style transfer to handle occlusions and\npreserve content. In this paper, we explore the utilization of multiple views\nto minimize the issue of missing information and generate an accurate\nrepresentation of the underlying human model. To fuse the knowledge from\nmultiple viewpoints, we design a selector network that takes the pose keypoints\nand texture from images and generates an interpretable per-pixel selection map.\nAfter that, the encodings from a separate network (trained on a single image\nhuman reposing task) are merged in the latent space. This enables us to\ngenerate accurate, precise, and visually coherent images for different editing\ntasks. We show the application of our network on 2 newly proposed tasks -\nMulti-view human reposing, and Mix-and-match human image generation.\nAdditionally, we study the limitations of single-view editing and scenarios in\nwhich multi-view provides a much better alternative.",
    "descriptor": "\nComments: 10 pages, 10 figures\n",
    "authors": [
      "Rishabh Jain",
      "Mayur Hemani",
      "Duygu Ceylan",
      "Krishna Kumar Singh",
      "Jingwan Lu",
      "Mausooom Sarkar",
      "Balaji Krishnamurthy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10157"
  },
  {
    "id": "arXiv:2211.10159",
    "title": "Optimal service station design for traffic mitigation via genetic  algorithm and neural network",
    "abstract": "This paper analyzes how the presence of service stations on highways affects\ntraffic congestion. We focus on the problem of optimally designing a service\nstation to achieve beneficial effects in terms of total traffic congestion and\npeak traffic reduction. Microsimulators cannot be used for this task due to\ntheir computational inefficiency. We propose a genetic algorithm based on the\nrecently proposed CTMs, that efficiently describes the dynamics of a service\nstation. Then, we leverage the algorithm to train a neural network capable of\nsolving the same problem, avoiding implementing the CTMs. Finally, we examine\ntwo case studies to validate the capabilities and performance of our\nalgorithms. In these simulations, we use real data extracted from Dutch\nhighways.",
    "descriptor": "\nComments: Submitted to IFAC Worlds conference 2023\n",
    "authors": [
      "Carlo Cenedese",
      "Michele Cucuzzella",
      "Adriano Cotta Ramusino",
      "Davide Spalenza",
      "John Lygeros",
      "Antonella Ferrara"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.10159"
  },
  {
    "id": "arXiv:2211.10163",
    "title": "Overview of the HASOC Subtrack at FIRE 2022: Offensive Language  Identification in Marathi",
    "abstract": "The widespread of offensive content online has become a reason for great\nconcern in recent years, motivating researchers to develop robust systems\ncapable of identifying such content automatically. With the goal of carrying\nout a fair evaluation of these systems, several international competitions have\nbeen organized, providing the community with important benchmark data and\nevaluation methods for various languages. Organized since 2019, the HASOC (Hate\nSpeech and Offensive Content Identification) shared task is one of these\ninitiatives. In its fourth iteration, HASOC 2022 included three subtracks for\nEnglish, Hindi, and Marathi. In this paper, we report the results of the HASOC\n2022 Marathi subtrack which provided participants with a dataset containing\ndata from Twitter manually annotated using the popular OLID taxonomy. The\nMarathi track featured three additional subtracks, each corresponding to one\nlevel of the taxonomy: Task A - offensive content identification (offensive vs.\nnon-offensive); Task B - categorization of offensive types (targeted vs.\nuntargeted), and Task C - offensive target identification (individual vs. group\nvs. others). Overall, 59 runs were submitted by 10 teams. The best systems\nobtained an F1 of 0.9745 for Subtrack 3A, an F1 of 0.9207 for Subtrack 3B, and\nF1 of 0.9607 for Subtrack 3C. The best performing algorithms were a mixture of\ntraditional and deep learning approaches.",
    "descriptor": "",
    "authors": [
      "Tharindu Ranasinghe",
      "Kai North",
      "Damith Premasiri",
      "Marcos Zampieri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.10163"
  },
  {
    "id": "arXiv:2211.10168",
    "title": "Language-Conditioned Reinforcement Learning to Solve Misunderstandings  with Action Corrections",
    "abstract": "Human-to-human conversation is not just talking and listening. It is an\nincremental process where participants continually establish a common\nunderstanding to rule out misunderstandings. Current language understanding\nmethods for intelligent robots do not consider this. There exist numerous\napproaches considering non-understandings, but they ignore the incremental\nprocess of resolving misunderstandings. In this article, we present a first\nformalization and experimental validation of incremental action-repair for\nrobotic instruction-following based on reinforcement learning. To evaluate our\napproach, we propose a collection of benchmark environments for action\ncorrection in language-conditioned reinforcement learning, utilizing a\nsynthetic instructor to generate language goals and their corresponding\ncorrections. We show that a reinforcement learning agent can successfully learn\nto understand incremental corrections of misunderstood instructions.",
    "descriptor": "\nComments: Accepted to the 2nd Workshop on Language in Reinforcement Learning, (NeurIPS 2022)\n",
    "authors": [
      "Frank R\u00f6der",
      "Manfred Eppe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.10168"
  },
  {
    "id": "arXiv:2211.10173",
    "title": "How Do Input Attributes Impact the Privacy Loss in Differential Privacy?",
    "abstract": "Differential privacy (DP) is typically formulated as a worst-case privacy\nguarantee over all individuals in a database. More recently, extensions to\nindividual subjects or their attributes, have been introduced. Under the\nindividual/per-instance DP interpretation, we study the connection between the\nper-subject gradient norm in DP neural networks and individual privacy loss and\nintroduce a novel metric termed the Privacy Loss-Input Susceptibility (PLIS),\nwhich allows one to apportion the subject's privacy loss to their input\nattributes. We experimentally show how this enables the identification of\nsensitive attributes and of subjects at high risk of data reconstruction.",
    "descriptor": "",
    "authors": [
      "Tamara T. Mueller",
      "Stefan Kolek",
      "Friederike Jungmann",
      "Alexander Ziller",
      "Dmitrii Usynin",
      "Moritz Knolle",
      "Daniel Rueckert",
      "Georgios Kaissis"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10173"
  },
  {
    "id": "arXiv:2211.10174",
    "title": "Deep Gaussian Processes for Air Quality Inference",
    "abstract": "Air pollution kills around 7 million people annually, and approximately 2.4\nbillion people are exposed to hazardous air pollution. Accurate, fine-grained\nair quality (AQ) monitoring is essential to control and reduce pollution.\nHowever, AQ station deployment is sparse, and thus air quality inference for\nunmonitored locations is crucial. Conventional interpolation methods fail to\nlearn the complex AQ phenomena. This work demonstrates that Deep Gaussian\nProcess models (DGPs) are a promising model for the task of AQ inference. We\nimplement Doubly Stochastic Variational Inference, a DGP algorithm, and show\nthat it performs comparably to the state-of-the-art models.",
    "descriptor": "\nComments: Accepted for publication at ACM India Joint International Conference on Data Science and Management of Data (CoDS-COMAD 2023)\n",
    "authors": [
      "Aadesh Desai",
      "Eshan Gujarathi",
      "Saagar Parikh",
      "Sachin Yadav",
      "Zeel Patel",
      "Nipun Batra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.10174"
  },
  {
    "id": "arXiv:2211.10177",
    "title": "Improving Pixel-Level Contrastive Learning by Leveraging Exogenous Depth  Information",
    "abstract": "Self-supervised representation learning based on Contrastive Learning (CL)\nhas been the subject of much attention in recent years. This is due to the\nexcellent results obtained on a variety of subsequent tasks (in particular\nclassification), without requiring a large amount of labeled samples. However,\nmost reference CL algorithms (such as SimCLR and MoCo, but also BYOL and Barlow\nTwins) are not adapted to pixel-level downstream tasks. One existing solution\nknown as PixPro proposes a pixel-level approach that is based on filtering of\npairs of positive/negative image crops of the same image using the distance\nbetween the crops in the whole image. We argue that this idea can be further\nenhanced by incorporating semantic information provided by exogenous data as an\nadditional selection filter, which can be used (at training time) to improve\nthe selection of the pixel-level positive/negative samples. In this paper we\nwill focus on the depth information, which can be obtained by using a depth\nestimation network or measured from available data (stereovision, parallax\nmotion, LiDAR, etc.). Scene depth can provide meaningful cues to distinguish\npixels belonging to different objects based on their depth. We show that using\nthis exogenous information in the contrastive loss leads to improved results\nand that the learned representations better follow the shapes of objects. In\naddition, we introduce a multi-scale loss that alleviates the issue of finding\nthe training parameters adapted to different object sizes. We demonstrate the\neffectiveness of our ideas on the Breakout Segmentation on Borehole Images\nwhere we achieve an improvement of 1.9\\% over PixPro and nearly 5\\% over the\nsupervised baseline. We further validate our technique on the indoor scene\nsegmentation tasks with ScanNet and outdoor scenes with CityScapes ( 1.6\\% and\n1.1\\% improvement over PixPro respectively).",
    "descriptor": "\nComments: Accepted for WACV 2023\n",
    "authors": [
      "Ahmed Ben Saad",
      "Kristina Prokopetc",
      "Josselin Kherroubi",
      "Axel Davy",
      "Adrien Courtois",
      "Gabriele Facciolo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10177"
  },
  {
    "id": "arXiv:2211.10181",
    "title": "LVOS: A Benchmark for Long-term Video Object Segmentation",
    "abstract": "Existing video object segmentation (VOS) benchmarks focus on short-term\nvideos which just last about 3-5 seconds and where objects are visible most of\nthe time. These videos are poorly representative of practical applications, and\nthe absence of long-term datasets restricts further investigation of VOS on the\napplication in realistic scenarios. So, in this paper, we present a new\nbenchmark dataset and evaluation methodology named LVOS, which consists of 220\nvideos with a total duration of 421 minutes. To the best of our knowledge, LVOS\nis the first densely annotated long-term VOS dataset. The videos in our LVOS\nlast 1.59 minutes on average, which is 20 times longer than videos in existing\nVOS datasets. Each video includes various attributes, especially challenges\nderiving from the wild, such as long-term reappearing and cross-temporal\nsimilar objeccts. Moreover, we provide additional language descriptions to\nencourage the exploration of integrating linguistic and visual features for\nvideo object segmentation. Based on LVOS, we assess existing video object\nsegmentation algorithms and propose a Diverse Dynamic Memory network (DDMemory)\nthat consists of three complementary memory banks to exploit temporal\ninformation adequately. The experiment results demonstrate the strength and\nweaknesses of prior methods, pointing promising directions for further study.\nOur objective is to provide the community with a large and varied benchmark to\nboost the advancement of long-term VOS. Data and code are available at\n\\url{https://lingyihongfd.github.io/lvos.github.io/}.",
    "descriptor": "",
    "authors": [
      "Lingyi Hong",
      "Wenchao Chen",
      "Zhongying Liu",
      "Wei Zhang",
      "Pinxue Guo",
      "Zhaoyu Chen",
      "Wenqiang Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10181"
  },
  {
    "id": "arXiv:2211.10188",
    "title": "Piecewise Affine Curvature model: a reduced-order model for soft  robot-environment interaction beyond PCC",
    "abstract": "Soft robot are celebrated for their propensity to enable compliant and\ncomplex robot-environment interactions. Soft robotic manipulators, or slender\ncontinuum structure robots have the potential to exploit these interactions to\nenable new exploration and manipulation capabilities and safe human-robot\ninteractions. However, the interactions, or perturbations by external forces\ncause the soft structure to deform in an infinite degree of freedom (DOF)\nspace. To control such system, reduced order models are needed; typically\nmodels consider piecewise sections of constant curvature although external\nforces often deform the structure out of the constant curvature hypothesis. In\nthis work we perform an analysis of the trade-off between computational\ntreatability and modelling accuracy. We then propose a new kinematic model, the\nPiecewise Affine Curvature (PAC) which we validate theoretically and\nexperimentally showing that this higher-order model better captures the\nconfiguration of a soft continuum body robot when perturbed by the external\nforces. In comparison to the current state of the art Piecewise Constant\nCurvature (PCC) model we demonstrate up to 30\\% reduction in error for the end\nposition of a soft continuum body robot.",
    "descriptor": "\nComments: Submitted to IEEE RoboSoft 2023\n",
    "authors": [
      "Francesco Stella",
      "Qinghua Guan",
      "Jinsong Leng",
      "Cosimo Della Santina",
      "Josie Hughes"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.10188"
  },
  {
    "id": "arXiv:2211.10192",
    "title": "Data-driven Basis for Reconstructing the Contrast in Born Inverse  Scattering: Picard Criterion, Regularity, Regularization and Stability",
    "abstract": "We consider the inverse medium scattering of reconstructing the medium\ncontrast using Born data, including the full aperture, limited-aperture, and\nmulti-frequency data. We propose a class of data-driven basis for these inverse\nproblems based on the generalized prolate spheroidal wave functions and related\neigenfunctions. Such data-driven eigenfunctions are eigenfunctions of a Fourier\nintegral operator; they remarkably extend analytically to the whole space, are\ndoubly orthogonal, and are complete in the class of band-limited functions. We\nfirst establish a Picard criterion for reconstructing the contrast using the\ndata-driven basis, where the reconstruction formula can also be understood in\nthe viewpoint of data processing and analytic extrapolation. Another salient\nfeature associated with the generalized prolate spheroidal wave functions is\nthat the data-driven basis for a disk is also a basis for a Sturm-Liouville\ndifferential operator. With the help of Sturm-Liouville theory, we estimate the\n$L^2$ approximation error for a spectral cutoff approximation of $H^s$\nfunctions, $0<s\\le1$. This yields a spectral cutoff regularization strategy for\nnoisy data and an explicit stability estimate for contrast in $H^s$ ($0<s\\le1$)\nin the full aperture case. In the limited-aperture and multi-frequency cases,\nwe also obtain spectral cutoff regularization strategies for noisy data and\nstability estimates for a class of contrast.",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Shixu Meng"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.10192"
  },
  {
    "id": "arXiv:2211.10193",
    "title": "Layer-Stack Temperature Scaling",
    "abstract": "Recent works demonstrate that early layers in a neural network contain useful\ninformation for prediction. Inspired by this, we show that extending\ntemperature scaling across all layers improves both calibration and accuracy.\nWe call this procedure \"layer-stack temperature scaling\" (LATES). Informally,\nLATES grants each layer a weighted vote during inference. We evaluate it on\nfive popular convolutional neural network architectures both in- and\nout-of-distribution and observe a consistent improvement over temperature\nscaling in terms of accuracy, calibration, and AUC. All conclusions are\nsupported by comprehensive statistical analyses. Since LATES neither retrains\nthe architecture nor introduces many more parameters, its advantages can be\nreaped without requiring additional data beyond what is used in temperature\nscaling. Finally, we show that combining LATES with Monte Carlo Dropout matches\nstate-of-the-art results on CIFAR10/100.",
    "descriptor": "\nComments: 10 pages, 7 figures, 3 tables\n",
    "authors": [
      "Amr Khalifa",
      "Michael C. Mozer",
      "Hanie Sedghi",
      "Behnam Neyshabur",
      "Ibrahim Alabdulmohsin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10193"
  },
  {
    "id": "arXiv:2211.10198",
    "title": "Promoting Social Behaviour in Reducing Peak Electricity Consumption  Using Multi-Agent Systems",
    "abstract": "As we move towards an energy system based on renewable energy sources, we\nneed to consider their inflexibility to meet sudden peaks in demand. It is\ntherefore important to reduce the peak load placed on our energy system. For\nindividual households this means spreading out the use of high-powered\nappliances, such as dishwashers and washing machines, throughout the day.\nTraditional approaches to this problem have relied on differential pricing set\nby a centralised utility company, but this mechanism has not been effective in\npromoting widespread shifting of appliance usage. Our previous research\ninvestigated a decentralised mechanism where agents receive an initial\nallocation of time-slots to use their appliances, which they can then exchange\nwith other agents. This was found to be an effective approach to reducing the\npeak load within a community energy system when we introduced social capital,\nthe tracking of favours given and received, in order to incentivise agents to\nact flexibly by accepting exchanges that do not immediately benefit them. This\nsystem encouraged self-interested agents to learn socially beneficial behaviour\nin order to earn social capital that they could later use to improve their own\nperformance. In this paper we expand this work by implementing real world\nhousehold appliance usage data in order to ensure that our mechanism could\nadapt to the challenging demand needs of real households. We also demonstrate\nhow smaller and more diverse populations can optimise more effectively than\nlarger community energy systems and better overcome the challenges of\nreal-world demand peaks.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2006.14526\n",
    "authors": [
      "Nathan A. Brooks",
      "Simon T. Powers",
      "James M. Borg"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.10198"
  },
  {
    "id": "arXiv:2211.10202",
    "title": "Some problems about co-consonance of topological spaces",
    "abstract": "In this paper, we first prove that the retract of a consonant space (or\nco-consonant space) is consonant (co-consonant). Using this result, some\nrelated results have obtained. Simultaneously, we proved that (1) the\nco-consonance of the Smyth powerspace implies the co-consonance of a\ntopological space under a necessary condition; (2) the co-consonance of a\ntopological implies the co-consonance of the smyth powerspace under some\nconditions; (3) if the lower powerspace is co-consonant, then the topological\nspace is co-consonant; (4) the co-consonance of implies the co-consonance of\nthe lower powerspace with some sufficient conditions.",
    "descriptor": "",
    "authors": [
      "Zhengmao He",
      "Bin Zhao"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "General Topology (math.GN)"
    ],
    "url": "https://arxiv.org/abs/2211.10202"
  },
  {
    "id": "arXiv:2211.10206",
    "title": "Multi-view Inverse Rendering for Large-scale Real-world Indoor Scenes",
    "abstract": "We present a multi-view inverse rendering method for large-scale real-world\nindoor scenes that reconstructs global illumination and physically-reasonable\nSVBRDFs. Unlike previous representations, where the global illumination of\nlarge scenes is simplified as multiple environment maps, we propose a compact\nrepresentation called Texture-based Lighting (TBL). It consists of 3D meshs and\nHDR textures, and efficiently models direct and infinite-bounce indirect\nlighting of the entire large scene. Based on TBL, we further propose a hybrid\nlighting representation with precomputed irradiance, which significantly\nimproves the efficiency and alleviate the rendering noise in the material\noptimization. To physically disentangle the ambiguity between materials, we\npropose a three-stage material optimization strategy based on the priors of\nsemantic segmentation and room segmentation. Extensive experiments show that\nthe proposed method outperforms the state-of-the-arts quantitatively and\nqualitatively, and enables physically-reasonable mixed-reality applications\nsuch as material editing, editable novel view synthesis and relighting. The\nproject page is at https://lzleejean.github.io/IRTex.",
    "descriptor": "",
    "authors": [
      "Zhen Li",
      "Lingli Wang",
      "Mofang Cheng",
      "Cihui Pan",
      "Jiaqi Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10206"
  },
  {
    "id": "arXiv:2211.10207",
    "title": "Virtual Service Embedding with Time-Varying Load and Provable Guarantees",
    "abstract": "Deploying services efficiently while satisfying their quality requirements is\na major challenge in network slicing. Effective solutions place instances of\nthe services' virtual network functions (VNFs) at different locations of the\ncellular infrastructure and manage such instances by scaling them as needed. In\nthis work, we address the above problem and the very relevant aspect of\nsub-slice reuse among different services. Further, unlike prior art, we account\nfor the services' finite lifetime and time-varying traffic load. We identify\ntwo major sources of inefficiency in service management: (i) the overspending\nof computing resources due to traffic of multiple services with different\nlatency requirements being processed by the same virtual machine (VM), and (ii)\nthe poor packing of traffic processing requests in the same VM, leading to\nopening more VMs than necessary. To cope with the above issues, we devise an\nalgorithm, called REShare, that can dynamically adapt to the system's\noperational conditions and find an optimal trade-off between the aforementioned\nopposite requirements. We prove that REShare has low algorithmic complexity and\nis asymptotic 2-competitive under a non-decreasing load. Numerical results,\nleveraging real-world scenarios, show that our solution outperforms\nalternatives, swiftly adapting to time-varying conditions and reducing service\ncost by over 25%.",
    "descriptor": "",
    "authors": [
      "Gil Einziger",
      "Gabriel Scalosub",
      "Carla Fabiana Chiasserini",
      "Francesco Malandrino"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.10207"
  },
  {
    "id": "arXiv:2211.10209",
    "title": "Leveraging Algorithmic Fairness to Mitigate Blackbox Attribute Inference  Attacks",
    "abstract": "Machine learning (ML) models have been deployed for high-stakes applications,\ne.g., healthcare and criminal justice. Prior work has shown that ML models are\nvulnerable to attribute inference attacks where an adversary, with some\nbackground knowledge, trains an ML attack model to infer sensitive attributes\nby exploiting distinguishable model predictions. However, some prior attribute\ninference attacks have strong assumptions about adversary's background\nknowledge (e.g., marginal distribution of sensitive attribute) and pose no more\nprivacy risk than statistical inference. Moreover, none of the prior attacks\naccount for class imbalance of sensitive attribute in datasets coming from\nreal-world applications (e.g., Race and Sex). In this paper, we propose an\npractical and effective attribute inference attack that accounts for this\nimbalance using an adaptive threshold over the attack model's predictions. We\nexhaustively evaluate our proposed attack on multiple datasets and show that\nthe adaptive threshold over the model's predictions drastically improves the\nattack accuracy over prior work. Finally, current literature lacks an effective\ndefence against attribute inference attacks. We investigate the impact of\nfairness constraints (i.e., designed to mitigate unfairness in model\npredictions) during model training on our attribute inference attack. We show\nthat constraint based fairness algorithms which enforces equalized odds acts as\nan effective defense against attribute inference attacks without impacting the\nmodel utility. Hence, the objective of algorithmic fairness and sensitive\nattribute privacy are aligned.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2202.02242\n",
    "authors": [
      "Jan Aalmoes",
      "Vasisht Duddu",
      "Antoine Boutet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.10209"
  },
  {
    "id": "arXiv:2211.10219",
    "title": "Local Search For Satisfiability Modulo Integer Arithmetic Theories",
    "abstract": "Satisfiability Modulo Theories (SMT) refers to the problem of deciding the\nsatisfiability of a formula with respect to certain background first order\ntheories. In this paper, we focus on Satisfiablity Modulo Integer Arithmetic,\nwhich is referred to as SMT(IA), including both linear and non-linear integer\narithmetic theories. Dominant approaches to SMT rely on calling a CDCL-based\nSAT solver, either in a lazy or eager favor. Local search, a competitive\napproach to solving combinatorial problems including SAT, however, has not been\nwell studied for SMT. We develop the first local search algorithm for SMT(IA)\nby directly operating on variables, breaking through the traditional framework.\nWe propose a local search framework by considering the distinctions between\nBoolean and integer variables. Moreover, we design a novel operator and scoring\nfunctions tailored for integer arithmetic, as well as a two-level operation\nselection heuristic. Putting these together, we develop a local search SMT(IA)\nsolver called LS-IA. Experiments are carried out to evaluate LS-IA on\nbenchmarks from SMTLIB. The results show that LS-IA is competitive and\ncomplementary with state-of-the-art SMT solvers, and performs particularly well\non those formulae with only integer variables. A simple sequential portfolio\nwith Z3 improves the state-of-the-art on satisfiable benchmark sets from\nSMT-LIB.",
    "descriptor": "",
    "authors": [
      "Shaowei Cai",
      "Bohan Li",
      "Xindi Zhang"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.10219"
  },
  {
    "id": "arXiv:2211.10226",
    "title": "Leveraging Multi-stream Information Fusion for Trajectory Prediction in  Low-illumination Scenarios: A Multi-channel Graph Convolutional Approach",
    "abstract": "Trajectory prediction is a fundamental problem and challenge for autonomous\nvehicles. Early works mainly focused on designing complicated architectures for\ndeep-learning-based prediction models in normal-illumination environments,\nwhich fail in dealing with low-light conditions. This paper proposes a novel\napproach for trajectory prediction in low-illumination scenarios by leveraging\nmulti-stream information fusion, which flexibly integrates image, optical flow,\nand object trajectory information. The image channel employs Convolutional\nNeural Network (CNN) and Long Short-term Memory (LSTM) networks to extract\ntemporal information from the camera. The optical flow channel is applied to\ncapture the pattern of relative motion between adjacent camera frames and\nmodelled by Spatial-Temporal Graph Convolutional Network (ST-GCN). The\ntrajectory channel is used to recognize high-level interactions between\nvehicles. Finally, information from all the three channels is effectively fused\nin the prediction module to generate future trajectories of surrounding\nvehicles in low-illumination conditions. The proposed multi-channel graph\nconvolutional approach is validated on HEV-I and newly generated Dark-HEV-I,\negocentric vision datasets that primarily focus on urban intersection\nscenarios. The results demonstrate that our method outperforms the baselines,\nin standard and low-illumination scenarios. Additionally, our approach is\ngeneric and applicable to scenarios with different types of perception data.\nThe source code of the proposed approach is available at\nhttps://github.com/TommyGong08/MSIF}{https://github.com/TommyGong08/MSIF.",
    "descriptor": "",
    "authors": [
      "Hailong Gong",
      "Zirui Li",
      "Chao Lu",
      "Guodong Du",
      "Jianwei Gong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10226"
  },
  {
    "id": "arXiv:2211.10227",
    "title": "Adversarial Detection by Approximation of Ensemble Boundary",
    "abstract": "A spectral approximation of a Boolean function is proposed for approximating\nthe decision boundary of an ensemble of Deep Neural Networks (DNNs) solving\ntwo-class pattern recognition problems. The Walsh combination of relatively\nweak DNN classifiers is shown experimentally to be capable of detecting\nadversarial attacks. By observing the difference in Walsh coefficient\napproximation between clean and adversarial images, it appears that\ntransferability of attack may be used for detection. Approximating the decision\nboundary may also aid in understanding the learning and transferability\nproperties of DNNs. While the experiments here use images, the proposed\napproach of modelling two-class ensemble decision boundaries could in principle\nbe applied to any application area.",
    "descriptor": "\nComments: 8 pages, 8 figures, 8 tables\n",
    "authors": [
      "T. Windeatt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10227"
  },
  {
    "id": "arXiv:2211.10228",
    "title": "GNS: A generalizable Graph Neural Network-based simulator for  particulate and fluid modeling",
    "abstract": "We develop a PyTorch-based Graph Network Simulator (GNS) that learns physics\nand predicts the flow behavior of particulate and fluid systems. GNS\ndiscretizes the domain with nodes representing a collection of material points\nand the links connecting the nodes representing the local interaction between\nparticles or clusters of particles. The GNS learns the interaction laws through\nmessage passing on the graph. GNS has three components: (a) Encoder, which\nembeds particle information to a latent graph, the edges are learned functions;\n(b) Processor, which allows data propagation and computes the nodal\ninteractions across steps; and (c) Decoder, which extracts the relevant\ndynamics (e.g., particle acceleration) from the graph. We introduce\nphysics-inspired simple inductive biases, such as an inertial frame that allows\nlearning algorithms to prioritize one solution (constant gravitational\nacceleration) over another, reducing learning time. The GNS implementation uses\nsemi-implicit Euler integration to update the next state based on the predicted\naccelerations. GNS trained on trajectory data is generalizable to predict\nparticle kinematics in complex boundary conditions not seen during training.\nThe trained model accurately predicts within a 5\\% error of its associated\nmaterial point method (MPM) simulation. The predictions are 5,000x faster than\ntraditional MPM simulations (2.5 hours for MPM simulations versus 20 s for GNS\nsimulation of granular flow). GNS surrogates are popular for solving\noptimization, control, critical-region prediction for in situ viz, and\ninverse-type problems. The GNS code is available under the open-source MIT\nlicense at https://github.com/geoelements/gns.",
    "descriptor": "",
    "authors": [
      "Krishna Kumar",
      "Joseph Vantassel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10228"
  },
  {
    "id": "arXiv:2211.10237",
    "title": "Rationale-aware Autonomous Driving Policy utilizing Safety Force Field  implemented on CARLA Simulator",
    "abstract": "Despite the rapid improvement of autonomous driving technology in recent\nyears, automotive manufacturers must resolve liability issues to commercialize\nautonomous passenger car of SAE J3016 Level 3 or higher. To cope with the\nproduct liability law, manufacturers develop autonomous driving systems in\ncompliance with international standards for safety such as ISO 26262 and ISO\n21448. Concerning the safety of the intended functionality (SOTIF) requirement\nin ISO 26262, the driving policy recommends providing an explicit rational\nbasis for maneuver decisions. In this case, mathematical models such as Safety\nForce Field (SFF) and Responsibility-Sensitive Safety (RSS) which have\ninterpretability on decision, may be suitable. In this work, we implement SFF\nfrom scratch to substitute the undisclosed NVIDIA's source code and integrate\nit with CARLA open-source simulator. Using SFF and CARLA, we present a\npredictor for claimed sets of vehicles, and based on the predictor, propose an\nintegrated driving policy that consistently operates regardless of safety\nconditions it encounters while passing through dynamic traffic. The policy does\nnot have a separate plan for each condition, but using safety potential, it\naims human-like driving blended in with traffic flow.",
    "descriptor": "\nComments: 9 pages including appendices, 4 figures, NeurIPS 2022 Workshop: Machine Learning for Autonomous Driving (ML4AD)\n",
    "authors": [
      "Ho Suk",
      "Taewoo Kim",
      "Hyungbin Park",
      "Pamul Yadav",
      "Junyong Lee",
      "Shiho Kim"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10237"
  },
  {
    "id": "arXiv:2211.10243",
    "title": "Speaker Overlap-aware Neural Diarization for Multi-party Meeting  Analysis",
    "abstract": "Recently, hybrid systems of clustering and neural diarization models have\nbeen successfully applied in multi-party meeting analysis. However, current\nmodels always treat overlapped speaker diarization as a multi-label\nclassification problem, where speaker dependency and overlaps are not well\nconsidered. To overcome the disadvantages, we reformulate overlapped speaker\ndiarization task as a single-label prediction problem via the proposed power\nset encoding (PSE). Through this formulation, speaker dependency and overlaps\ncan be explicitly modeled. To fully leverage this formulation, we further\npropose the speaker overlap-aware neural diarization (SOND) model, which\nconsists of a context-independent (CI) scorer to model global speaker\ndiscriminability, a context-dependent scorer (CD) to model local\ndiscriminability, and a speaker combining network (SCN) to combine and reassign\nspeaker activities. Experimental results show that using the proposed\nformulation can outperform the state-of-the-art methods based on target speaker\nvoice activity detection, and the performance can be further improved with\nSOND, resulting in a 6.30% relative diarization error reduction.",
    "descriptor": "\nComments: Accepted by EMNLP 2022\n",
    "authors": [
      "Zhihao Du",
      "Shiliang Zhang",
      "Siqi Zheng",
      "Zhijie Yan"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.10243"
  },
  {
    "id": "arXiv:2211.10244",
    "title": "Knowing What to Label for Few Shot Microscopy Image Cell Segmentation",
    "abstract": "In microscopy image cell segmentation, it is common to train a deep neural\nnetwork on source data, containing different types of microscopy images, and\nthen fine-tune it using a support set comprising a few randomly selected and\nannotated training target images. In this paper, we argue that the random\nselection of unlabelled training target images to be annotated and included in\nthe support set may not enable an effective fine-tuning process, so we propose\na new approach to optimise this image selection process. Our approach involves\na new scoring function to find informative unlabelled target images. In\nparticular, we propose to measure the consistency in the model predictions on\ntarget images against specific data augmentations. However, we observe that the\nmodel trained with source datasets does not reliably evaluate consistency on\ntarget images. To alleviate this problem, we propose novel self-supervised\npretext tasks to compute the scores of unlabelled target images. Finally, the\ntop few images with the least consistency scores are added to the support set\nfor oracle (i.e., expert) annotation and later used to fine-tune the model to\nthe target images. In our evaluations that involve the segmentation of five\ndifferent types of cell images, we demonstrate promising results on several\ntarget test sets compared to the random selection approach as well as other\nselection approaches, such as Shannon's entropy and Monte-Carlo dropout.",
    "descriptor": "\nComments: Accepted to WACV 2023\n",
    "authors": [
      "Youssef Dawoud",
      "Arij Bouazizi",
      "Katharina Ernst",
      "Gustavo Carneiro",
      "Vasileios Belagiannis"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10244"
  },
  {
    "id": "arXiv:2211.10247",
    "title": "GoSum: Extractive Summarization of Long Documents by Reinforcement  Learning and Graph Organized discourse state",
    "abstract": "Handling long texts with structural information and excluding redundancy\nbetween summary sentences are essential in extractive document summarization.\nIn this work, we propose GoSum, a novel reinforcement-learning-based extractive\nmodel for long-paper summarization. GoSum encodes states by building a\nheterogeneous graph from different discourse levels for each input document. We\nevaluate the model on two datasets of scientific articles summarization: PubMed\nand arXiv where it outperforms all extractive summarization models and most of\nthe strong abstractive baselines.",
    "descriptor": "",
    "authors": [
      "Junyi Bian",
      "Xiaodi Huang",
      "Hong Zhou",
      "Shanfeng Zhu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.10247"
  },
  {
    "id": "arXiv:2211.10248",
    "title": "Circuit Design for Predictive Maintenance",
    "abstract": "Industry 4.0 has become a driver for the entire manufacturing industry. Smart\nsystems have enabled 30% productivity increases and predictive maintenance has\nbeen demonstrated to provide a 50% reduction in machine downtime. So far, the\nsolution has been based on data analytics which has resulted in a proliferation\nof sensing technologies and infrastructure for data acquisition, transmission\nand processing. At the core of factory operation and automation are circuits\nthat control and power factory equipment, innovative circuit design has the\npotential to address many system integration challenges. We present a new\ncircuit design approach based on circuit level artificial intelligence\nsolutions, integrated within control and calibration functional blocks during\ncircuit design, improving the predictability and adaptability of each component\nfor predictive maintenance. This approach is envisioned to encourage the\ndevelopment of new EDA tools such as automatic digital shadow generation and\nproduct lifecycle models, that will help identification of circuit parameters\nthat adequately define the operating conditions for dynamic prediction and\nfault detection. Integration of a supplementary artificial intelligence block\nwithin the control loop is considered for capturing non-linearities and\ngain/bandwidth constraints of the main controller and identifying changes in\nthe operating conditions beyond the response of the controller. System\nintegration topics are discussed regarding integration within OPC Unified\nArchitecture and predictive maintenance interfaces, providing real-time updates\nto the digital shadow that help maintain an accurate, virtual replica model of\nthe physical system.",
    "descriptor": "\nComments: 4 pages, 4 figures, position paper\n",
    "authors": [
      "Taner Dosluoglu",
      "Martin MacDonald"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.10248"
  },
  {
    "id": "arXiv:2211.10250",
    "title": "HiveNAS: Neural Architecture Search using Artificial Bee Colony  Optimization",
    "abstract": "The traditional Neural Network-development process requires substantial\nexpert knowledge and relies heavily on intuition and trial-and-error. Neural\nArchitecture Search (NAS) frameworks were introduced to robustly search for\nnetwork topologies, as well as facilitate the automated development of Neural\nNetworks. While some optimization approaches -- such as Genetic Algorithms --\nhave been extensively explored in the NAS context, other Metaheuristic\nOptimization algorithms have not yet been evaluated. In this paper, we propose\nHiveNAS, the first Artificial Bee Colony-based NAS framework.",
    "descriptor": "",
    "authors": [
      "Mohamed Shahawy",
      "Elhadj Benkhelifa"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10250"
  },
  {
    "id": "arXiv:2211.10253",
    "title": "Delving into Transformer for Incremental Semantic Segmentation",
    "abstract": "Incremental semantic segmentation(ISS) is an emerging task where old model is\nupdated by incrementally adding new classes. At present, methods based on\nconvolutional neural networks are dominant in ISS. However, studies have shown\nthat such methods have difficulty in learning new tasks while maintaining good\nperformance on old ones (catastrophic forgetting). In contrast, a Transformer\nbased method has a natural advantage in curbing catastrophic forgetting due to\nits ability to model both long-term and short-term tasks. In this work, we\nexplore the reasons why Transformer based architecture are more suitable for\nISS, and accordingly propose propose TISS, a Transformer based method for\nIncremental Semantic Segmentation. In addition, to better alleviate\ncatastrophic forgetting while preserving transferability on ISS, we introduce\ntwo patch-wise contrastive losses to imitate similar features and enhance\nfeature diversity respectively, which can further improve the performance of\nTISS. Under extensive experimental settings with Pascal-VOC 2012 and ADE20K\ndatasets, our method significantly outperforms state-of-the-art incremental\nsemantic segmentation methods.",
    "descriptor": "",
    "authors": [
      "Zekai Xu",
      "Mingyi Zhang",
      "Jiayue Hou",
      "Xing Gong",
      "Chuan Wen",
      "Chengjie Wang",
      "Junge Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10253"
  },
  {
    "id": "arXiv:2211.10254",
    "title": "\"Being Simple on Complex Issues'' -- An Expert View on Visual Data  Communication of Climate Change",
    "abstract": "Despite overwhelming scientific consensus concerning the threatening impact\nof climate change, public understanding on the topic seems to lack depth. Data\nvisualizations play a critical role in both communicating scientific evidence\nabout climate change and in stimulating engagement and action. To investigate\nhow visualizations can be better utilized to communicate the complexities of\nclimate change to different audiences, we conducted interviews with 17 experts\nin the fields of climate change, data visualization, and science communication,\nas well as with 6 members of the broader citizenry. We use our findings to\nderive implications and recommendations for creating more effective\nvisualizations, particularly in news media sources geared toward lay audiences.\nImplications include the establishment of an iterative, user-centered co-design\nprocess, the adaption of contents according to the needs of the audience, and\nthe integration of information and formats which users can relate to. We\nfurther discuss the role of storytelling, aesthetics, uncertainty\nrepresentation, and interactive techniques in the visual communication of\nclimate change.",
    "descriptor": "\nComments: 12 pages, 3 figures, 3 tables\n",
    "authors": [
      "Regina Schuster",
      "Laura Koesten",
      "Kathleen Gregory",
      "Torsten M\u00f6ller"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.10254"
  },
  {
    "id": "arXiv:2211.10257",
    "title": "Model-based Causal Bayesian Optimization",
    "abstract": "How should we intervene on an unknown structural causal model to maximize a\ndownstream variable of interest? This optimization of the output of a system of\ninterconnected variables, also known as causal Bayesian optimization (CBO), has\nimportant applications in medicine, ecology, and manufacturing. Standard\nBayesian optimization algorithms fail to effectively leverage the underlying\ncausal structure. Existing CBO approaches assume noiseless measurements and do\nnot come with guarantees. We propose model-based causal Bayesian optimization\n(MCBO), an algorithm that learns a full system model instead of only modeling\nintervention-reward pairs. MCBO propagates epistemic uncertainty about the\ncausal mechanisms through the graph and trades off exploration and exploitation\nvia the optimism principle. We bound its cumulative regret, and obtain the\nfirst non-asymptotic bounds for CBO. Unlike in standard Bayesian optimization,\nour acquisition function cannot be evaluated in closed form, so we show how the\nreparameterization trick can be used to apply gradient-based optimizers.\nEmpirically we find that MCBO compares favorably with existing state-of-the-art\napproaches.",
    "descriptor": "\nComments: 24 pages, 8 figures\n",
    "authors": [
      "Scott Sussex",
      "Anastasiia Makarova",
      "Andreas Krause"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.10257"
  },
  {
    "id": "arXiv:2211.10260",
    "title": "Integrated Space Domain Awareness and Communication System",
    "abstract": "Space has been reforming and this evolution brings new threats that, together\nwith technological developments and malicious intent, can pose a major\nchallenge. Space domain awareness (SDA), a new conceptual idea, has come to the\nforefront. It aims sensing, detection, identification and countermeasures by\nproviding autonomy, intelligence and flexibility against potential threats in\nspace. In this study, we first present an insightful and clear view of the new\nspace. Secondly, we propose an integrated SDA and communication (ISDAC) system\nfor attacker detection. We assume that the attacker has beam-steering antennas\nand is capable to vary attack scenarios, such as random attacks on some\nreceiver antennas. To track random patterns and meet SDA requirements, a\nlightweight convolutional neural network architecture is developed. The\nproposed ISDAC system shows superior and robust performance under 12 different\nattacker configurations with a detection accuracy of over 97.8%.",
    "descriptor": "",
    "authors": [
      "Selen Gecgel Cetin",
      "Gunes Karabulut Kurt"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.10260"
  },
  {
    "id": "arXiv:2211.10265",
    "title": "Context Variance Evaluation of Pretrained Language Models for  Prompt-based Biomedical Knowledge Probing",
    "abstract": "Pretrained language models (PLMs) have motivated research on what kinds of\nknowledge these models learn. Fill-in-the-blanks problem (e.g., cloze tests) is\na natural approach for gauging such knowledge. BioLAMA generates prompts for\nbiomedical factual knowledge triples and uses the Top-k accuracy metric to\nevaluate different PLMs' knowledge. However, existing research has shown that\nsuch prompt-based knowledge probing methods can only probe a lower bound of\nknowledge. Many factors like prompt-based probing biases make the LAMA\nbenchmark unreliable and unstable. This problem is more prominent in BioLAMA.\nThe severe long-tailed distribution in vocabulary and large-N-M relation make\nthe performance gap between LAMA and BioLAMA remain notable. To address these,\nwe introduce context variance into the prompt generation and propose a new\nrank-change-based evaluation metric. Different from the previous known-unknown\nevaluation criteria, we propose the concept of \"Misunderstand\" in LAMA for the\nfirst time. Through experiments on 12 PLMs, our context variance prompts and\nUnderstand-Confuse-Misunderstand (UCM) metric makes BioLAMA more friendly to\nlarge-N-M relations and rare relations. We also conducted a set of control\nexperiments to disentangle \"understand\" from just \"read and copy\".",
    "descriptor": "\nComments: submitted to AMIA 2023 Informatics Summit\n",
    "authors": [
      "Zonghai Yao",
      "Yi Cao",
      "Zhichao Yang",
      "Hong Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10265"
  },
  {
    "id": "arXiv:2211.10270",
    "title": "Bayesian Multi-Task Learning MPC for Robotic Mobile Manipulation",
    "abstract": "Mobile manipulation in robotics is challenging due to the need of solving\nmany diverse tasks, such as opening a door or picking-and-placing an object.\nTypically, a basic first-principles system description of the robot is\navailable, thus motivating the use of model-based controllers. However, the\nrobot dynamics and its interaction with an object are affected by uncertainty,\nlimiting the controller's performance. To tackle this problem, we propose a\nBayesian multi-task learning model that uses trigonometric basis functions to\nidentify the error in the dynamics. In this way, data from different but\nrelated tasks can be leveraged to provide a descriptive error model that can be\nefficiently updated online for new, unseen tasks. We combine this learning\nscheme with a model predictive controller, and extensively test the\neffectiveness of the proposed approach, including comparisons with available\nbaseline controllers. We present simulation tests with a ball-balancing robot,\nand door-opening hardware experiments with a quadrupedal manipulator.",
    "descriptor": "",
    "authors": [
      "Elena Arcari",
      "Maria Vittoria Minniti",
      "Anna Scampicchio",
      "Andrea Carron",
      "Farbod Farshidian",
      "Marco Hutter",
      "Melanie N. Zeilinger"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.10270"
  },
  {
    "id": "arXiv:2211.10271",
    "title": "A Copy Mechanism for Handling Knowledge Base Elements in SPARQL Neural  Machine Translation",
    "abstract": "Neural Machine Translation (NMT) models from English to SPARQL are a\npromising development for SPARQL query generation. However, current\narchitectures are unable to integrate the knowledge base (KB) schema and handle\nquestions on knowledge resources, classes, and properties unseen during\ntraining, rendering them unusable outside the scope of topics covered in the\ntraining set. Inspired by the performance gains in natural language processing\ntasks, we propose to integrate a copy mechanism for neural SPARQL query\ngeneration as a way to tackle this issue. We illustrate our proposal by adding\na copy layer and a dynamic knowledge base vocabulary to two Seq2Seq\narchitectures (CNNs and Transformers). This layer makes the models copy KB\nelements directly from the questions, instead of generating them. We evaluate\nour approach on state-of-the-art datasets, including datasets referencing\nunknown KB elements and measure the accuracy of the copy-augmented\narchitectures. Our results show a considerable increase in performance on all\ndatasets compared to non-copy architectures.",
    "descriptor": "",
    "authors": [
      "Rose Hirigoyen",
      "Amal Zouaq",
      "Samuel Reyd"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10271"
  },
  {
    "id": "arXiv:2211.10274",
    "title": "SolderNet: Towards Trustworthy Visual Inspection of Solder Joints in  Electronics Manufacturing Using Explainable Artificial Intelligence",
    "abstract": "In electronics manufacturing, solder joint defects are a common problem\naffecting a variety of printed circuit board components. To identify and\ncorrect solder joint defects, the solder joints on a circuit board are\ntypically inspected manually by trained human inspectors, which is a very\ntime-consuming and error-prone process. To improve both inspection efficiency\nand accuracy, in this work we describe an explainable deep learning-based\nvisual quality inspection system tailored for visual inspection of solder\njoints in electronics manufacturing environments. At the core of this system is\nan explainable solder joint defect identification system called SolderNet which\nwe design and implement with trust and transparency in mind. While several\nchallenges remain before the full system can be developed and deployed, this\nstudy presents important progress towards trustworthy visual inspection of\nsolder joints in electronics manufacturing.",
    "descriptor": "\nComments: Accepted by IAAI-23, 7 pages\n",
    "authors": [
      "Hayden Gunraj",
      "Paul Guerrier",
      "Sheldon Fernandez",
      "Alexander Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10274"
  },
  {
    "id": "arXiv:2211.10275",
    "title": "An optimization-based registration approach to geometry reduction",
    "abstract": "We develop and assess an optimization-based approach to parametric geometry\nreduction. Given a family of parametric domains, we aim to determine a\nparametric diffeomorphism $\\Phi$ that maps a fixed reference domain $\\Omega$\ninto each element of the family, for different values of the parameter; the\nultimate goal of our study is to determine an effective tool for parametric\nprojection-based model order reduction of partial differential equations in\nparametric geometries. For practical problems in engineering, explicit\nparameterizations of the geometry are likely unavailable: for this reason, our\napproach takes as inputs a reference mesh of $\\Omega$ and a point cloud\n$\\{y_i^{\\rm raw}\\}_{i=1}^Q$ that belongs to the boundary of the target domain\n$V$ and returns a bijection $\\Phi$ that approximately maps $\\Omega$ in $V$. We\npropose a two-step procedure: given the point clouds $\\{x_j\\}_{j=1}^N\\subset\n\\partial \\Omega$ and $\\{y_i^{\\rm raw}\\}_{i=1}^Q \\subset \\partial V$, we first\nresort to a point-set registration algorithm to determine the displacements $\\{\nv_j \\}_{j=1}^N$ such that the deformed point cloud $\\{y_j:= x_j+v_j \\}_{j=1}^N$\napproximates $\\partial V$; then, we solve a nonlinear non-convex optimization\nproblem to build a mapping $\\Phi$ that is bijective from $\\Omega$ in\n$\\mathbb{R}^d$ and (approximately) satisfies $\\Phi(x_j) = y_j$ for\n$j=1,\\ldots,N$.We present a rigorous mathematical analysis to justify our\napproach; we further present thorough numerical experiments to show the\neffectiveness of the proposed method.",
    "descriptor": "",
    "authors": [
      "Tommaso Taddei"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.10275"
  },
  {
    "id": "arXiv:2211.10277",
    "title": "Task Residual for Tuning Vision-Language Models",
    "abstract": "Large-scale vision-language models (VLMs) pre-trained on billion-level data\nhave learned general visual representations and broad visual concepts. In\nprinciple, the well-learned knowledge structure of the VLMs should be inherited\nappropriately when being transferred to downstream tasks with limited data.\nHowever, most existing efficient transfer learning (ETL) approaches for VLMs\neither damage or are excessively biased towards the prior knowledge, e.g.,\nprompt tuning (PT) discards the pre-trained text-based classifier and builds a\nnew one while adapter-style tuning (AT) fully relies on the pre-trained\nfeatures. To address this, we propose a new efficient tuning approach for VLMs\nnamed Task Residual Tuning (TaskRes), which performs directly on the text-based\nclassifier and explicitly decouples the prior knowledge of the pre-trained\nmodels and new knowledge regarding a target task. Specifically, TaskRes keeps\nthe original classifier weights from the VLMs frozen and obtains a new\nclassifier for the target task by tuning a set of prior-independent parameters\nas a residual to the original one, which enables reliable prior knowledge\npreservation and flexible task-specific knowledge exploration. The proposed\nTaskRes is simple yet effective, which significantly outperforms previous ETL\nmethods (e.g., PT and AT) on 11 benchmark datasets while requiring minimal\neffort for the implementation. Our code will be available at\nhttps://github.com/geekyutao/TaskRes.",
    "descriptor": "\nComments: A new paradigm for tuning vision-language models\n",
    "authors": [
      "Tao Yu",
      "Zhihe Lu",
      "Xin Jin",
      "Zhibo Chen",
      "Xinchao Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10277"
  },
  {
    "id": "arXiv:2211.10278",
    "title": "Unsupervised 3D Pose Transfer with Cross Consistency and Dual  Reconstruction",
    "abstract": "The goal of 3D pose transfer is to transfer the pose from the source mesh to\nthe target mesh while preserving the identity information (e.g., face, body\nshape) of the target mesh. Deep learning-based methods improved the efficiency\nand performance of 3D pose transfer. However, most of them are trained under\nthe supervision of the ground truth, whose availability is limited in\nreal-world scenarios. In this work, we present X-DualNet, a simple yet\neffective approach that enables unsupervised 3D pose transfer. In X-DualNet, we\nintroduce a generator $G$ which contains correspondence learning and pose\ntransfer modules to achieve 3D pose transfer. We learn the shape correspondence\nby solving an optimal transport problem without any key point annotations and\ngenerate high-quality meshes with our elastic instance normalization (ElaIN) in\nthe pose transfer module. With $G$ as the basic component, we propose a cross\nconsistency learning scheme and a dual reconstruction objective to learn the\npose transfer without supervision. Besides that, we also adopt an\nas-rigid-as-possible deformer in the training process to fine-tune the body\nshape of the generated results. Extensive experiments on human and animal data\ndemonstrate that our framework can successfully achieve comparable performance\nas the state-of-the-art supervised approaches.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2109.15025\n",
    "authors": [
      "Chaoyue Song",
      "Jiacheng Wei",
      "Ruibo Li",
      "Fayao Liu",
      "Guosheng Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10278"
  },
  {
    "id": "arXiv:2211.10280",
    "title": "TensAIR: Online Learning from Data Streams via Asynchronous Iterative  Routing",
    "abstract": "Online learning (OL) from data streams is an emerging area of research that\nencompasses numerous challenges from stream processing, machine learning, and\nnetworking. Recent extensions of stream-processing platforms, such as Apache\nKafka and Flink, already provide basic extensions for the training of neural\nnetworks in a stream-processing pipeline. However, these extensions are not\nscalable and flexible enough for many real-world use-cases, since they do not\nintegrate the neural-network libraries as a first-class citizen into their\narchitectures. In this paper, we present TensAIR, which provides an end-to-end\ndataflow engine for OL from data streams via a protocol to which we refer as\nasynchronous iterative routing. TensAIR supports the common dataflow operators,\nsuch as Map, Reduce, Join, and has been augmented by the data-parallel OL\nfunctions train and predict. These belong to the new Model operator, in which\nan initial TensorFlow model (either freshly initialized or pre-trained) is\nreplicated among multiple decentralized worker nodes. Our decentralized\narchitecture allows TensAIR to efficiently shard incoming data batches across\nthe distributed model replicas, which in turn trigger the model updates via\nasynchronous stochastic gradient descent. We empirically demonstrate that\nTensAIR achieves a nearly linear scale-out in terms of (1) the number of worker\nnodes deployed in the network, and (2) the throughput at which the data batches\narrive at the dataflow operators. We exemplify the versatility of TensAIR by\ninvestigating both sparse (Word2Vec) and dense (CIFAR-10) use-cases, for which\nwe are able to demonstrate very significant performance improvements in\ncomparison to Kafka, Flink, and Horovod. We also demonstrate the magnitude of\nthese improvements by depicting the possibility of real-time concept drift\nadaptation of a sentiment analysis model trained over a Twitter stream.",
    "descriptor": "",
    "authors": [
      "Mauro Dalle Lucca Tosi",
      "Vinu E. Venugopal",
      "Martin Theobald"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.10280"
  },
  {
    "id": "arXiv:2211.10282",
    "title": "Exploring through Random Curiosity with General Value Functions",
    "abstract": "Efficient exploration in reinforcement learning is a challenging problem\ncommonly addressed through intrinsic rewards. Recent prominent approaches are\nbased on state novelty or variants of artificial curiosity. However, directly\napplying them to partially observable environments can be ineffective and lead\nto premature dissipation of intrinsic rewards. Here we propose random curiosity\nwith general value functions (RC-GVF), a novel intrinsic reward function that\ndraws upon connections between these distinct approaches. Instead of using only\nthe current observation's novelty or a curiosity bonus for failing to predict\nprecise environment dynamics, RC-GVF derives intrinsic rewards through\npredicting temporally extended general value functions. We demonstrate that\nthis improves exploration in a hard-exploration diabolical lock problem.\nFurthermore, RC-GVF significantly outperforms previous methods in the absence\nof ground-truth episodic counts in the partially observable MiniGrid\nenvironments. Panoramic observations on MiniGrid further boost RC-GVF's\nperformance such that it is competitive to baselines exploiting privileged\ninformation in form of episodic counts.",
    "descriptor": "\nComments: Accepted to NeurIPS 2022\n",
    "authors": [
      "Aditya Ramesh",
      "Louis Kirsch",
      "Sjoerd van Steenkiste",
      "J\u00fcrgen Schmidhuber"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10282"
  },
  {
    "id": "arXiv:2211.10284",
    "title": "Estimating more camera poses for ego-centric videos is essential for  VQ3D",
    "abstract": "Visual queries 3D localization (VQ3D) is a task in the Ego4D Episodic Memory\nBenchmark. Given an egocentric video, the goal is to answer queries of the form\n\"Where did I last see object X?\", where the query object X is specified as a\nstatic image, and the answer should be a 3D displacement vector pointing to\nobject X. However, current techniques use naive ways to estimate the camera\nposes of video frames, resulting in a low query with pose (QwP) ratio, thus a\npoor overall success rate. We design a new pipeline for the challenging\negocentric video camera pose estimation problem in our work. Moreover, we\nrevisit the current VQ3D framework and optimize it in terms of performance and\nefficiency. As a result, we get the top-1 overall success rate of 25.8% on VQ3D\nleaderboard, which is two times better than the 8.7% reported by the baseline.",
    "descriptor": "\nComments: Second International Ego4D Workshop at ECCV 2022\n",
    "authors": [
      "Jinjie Mai",
      "Chen Zhao",
      "Abdullah Hamdi",
      "Silvio Giancola",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10284"
  },
  {
    "id": "arXiv:2211.10285",
    "title": "A Fair Loss Function for Network Pruning",
    "abstract": "Model pruning can enable the deployment of neural networks in environments\nwith resource constraints. While pruning may have a small effect on the overall\nperformance of the model, it can exacerbate existing biases into the model such\nthat subsets of samples see significantly degraded performance. In this paper,\nwe introduce the performance weighted loss function, a simple modified\ncross-entropy loss function that can be used to limit the introduction of\nbiases during pruning. Experiments using biased classifiers for facial\nclassification and skin-lesion classification tasks demonstrate that the\nproposed method is a simple and effective tool that can enable existing pruning\nmethods to be used in fairness sensitive contexts.",
    "descriptor": "\nComments: Trustworthy and Socially Responsible Machine Learning (TSRML 2022) workshop co-located with NeurIPS 2022\n",
    "authors": [
      "Robbie Meyer",
      "Alexander Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.10285"
  },
  {
    "id": "arXiv:2211.10288",
    "title": "Just a Matter of Scale? Reevaluating Scale Equivariance in Convolutional  Neural Networks",
    "abstract": "The widespread success of convolutional neural networks may largely be\nattributed to their intrinsic property of translation equivariance. However,\nconvolutions are not equivariant to variations in scale and fail to generalize\nto objects of different sizes. Despite recent advances in this field, it\nremains unclear how well current methods generalize to unobserved scales on\nreal-world data and to what extent scale equivariance plays a role. To address\nthis, we propose the novel Scaled and Translated Image Recognition (STIR)\nbenchmark based on four different domains. Additionally, we introduce a new\nfamily of models that applies many re-scaled kernels with shared weights in\nparallel and then selects the most appropriate one. Our experimental results on\nSTIR show that both the existing and proposed approaches can improve\ngeneralization across scales compared to standard convolutions. We also\ndemonstrate that our family of models is able to generalize well towards larger\nscales and improve scale equivariance. Moreover, due to their unique design we\ncan validate that kernel selection is consistent with input scale. Even so,\nnone of the evaluated models maintain their performance for large differences\nin scale, demonstrating that a general understanding of how scale equivariance\ncan improve generalization and robustness is still lacking.",
    "descriptor": "",
    "authors": [
      "Thomas Altstidl",
      "An Nguyen",
      "Leo Schwinn",
      "Franz K\u00f6ferl",
      "Christopher Mutschler",
      "Bj\u00f6rn Eskofier",
      "Dario Zanca"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10288"
  },
  {
    "id": "arXiv:2211.10291",
    "title": "Evident: a Development Methodology and a Knowledge Base Topology for  Data Mining, Machine Learning and General Knowledge Management",
    "abstract": "Software has been developed for knowledge discovery, prediction and\nmanagement for over 30 years. However, there are still unresolved pain points\nwhen using existing project development and artifact management methodologies.\nHistorically, there has been a lack of applicable methodologies. Further,\nmethodologies that have been applied, such as Agile, have several limitations\nincluding scientific unfalsifiability that reduce their applicability. Evident,\na development methodology rooted in the philosophy of logical reasoning and\nEKB, a knowledge base topology, are proposed. Many pain points in data mining,\nmachine learning and general knowledge management are alleviated conceptually.\nEvident can be extended potentially to accelerate philosophical exploration,\nscience discovery, education as well as knowledge sharing & retention across\nthe globe. EKB offers one solution of storing information as knowledge, a\ngranular level above data. Related topics in computer history, software\nengineering, database, sensor, philosophy, and project & organization &\nmilitary managements are also discussed.",
    "descriptor": "",
    "authors": [
      "Mingwu",
      "Samer Haidar"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "Machine Learning (cs.LG)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.10291"
  },
  {
    "id": "arXiv:2211.10293",
    "title": "Dueling Bandits: From Two-dueling to Multi-dueling",
    "abstract": "We study a general multi-dueling bandit problem, where an agent compares\nmultiple options simultaneously and aims to minimize the regret due to\nselecting suboptimal arms. This setting generalizes the traditional two-dueling\nbandit problem and finds many real-world applications involving subjective\nfeedback on multiple options. We start with the two-dueling bandit setting and\npropose two efficient algorithms, DoublerBAI and MultiSBM-Feedback. DoublerBAI\nprovides a generic schema for translating known results on best arm\nidentification algorithms to the dueling bandit problem, and achieves a regret\nbound of $O(\\ln T)$. MultiSBM-Feedback not only has an optimal $O(\\ln T)$\nregret, but also reduces the constant factor by almost a half compared to\nbenchmark results. Then, we consider the general multi-dueling case and develop\nan efficient algorithm MultiRUCB. Using a novel finite-time regret analysis for\nthe general multi-dueling bandit problem, we show that MultiRUCB also achieves\nan $O(\\ln T)$ regret bound and the bound tightens as the capacity of the\ncomparison set increases. Based on both synthetic and real-world datasets, we\nempirically demonstrate that our algorithms outperform existing algorithms.",
    "descriptor": "",
    "authors": [
      "Yihan Du",
      "Siwei Wang",
      "Longbo Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10293"
  },
  {
    "id": "arXiv:2211.10298",
    "title": "Reinforcement Learning Methods for Wordle: A POMDP/Adaptive Control  Approach",
    "abstract": "In this paper we address the solution of the popular Wordle puzzle, using new\nreinforcement learning methods, which apply more generally to adaptive control\nof dynamic systems and to classes of Partially Observable Markov Decision\nProcess (POMDP) problems. These methods are based on approximation in value\nspace and the rollout approach, admit a straightforward implementation, and\nprovide improved performance over various heuristic approaches. For the Wordle\npuzzle, they yield on-line solution strategies that are very close to optimal\nat relatively modest computational cost. Our methods are viable for more\ncomplex versions of Wordle and related search problems, for which an optimal\nstrategy would be impossible to compute. They are also applicable to a wide\nrange of adaptive sequential decision problems that involve an unknown or\nfrequently changing environment whose parameters are estimated on-line.",
    "descriptor": "",
    "authors": [
      "Siddhant Bhambri",
      "Amrita Bhattacharjee",
      "Dimitri Bertsekas"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10298"
  },
  {
    "id": "arXiv:2211.10299",
    "title": "Trusted Hart for Mobile RISC-V Security",
    "abstract": "The majority of mobile devices today are based on Arm architecture that\nsupports the hosting of trusted applications in Trusted Execution Environment\n(TEE). RISC-V is a relatively new open-source instruction set architecture that\nwas engineered to fit many uses. In one potential RISC-V usage scenario, mobile\ndevices could be based on RISC-V hardware.\nWe consider the implications of porting the mobile security stack on top of a\nRISC-V system on a chip, identify the gaps in the open-source Keystone\nframework for building custom TEEs, and propose a security architecture that,\namong other things, supports the GlobalPlatform TEE API specification for\ntrusted applications. In addition to Keystone enclaves the architecture\nincludes a Trusted Hart -- a normal core that runs a trusted operating system\nand is dedicated for security functions, like control of the device's keystore\nand the management of secure peripherals.\nThe proposed security architecture for RISC-V platform is verified\nexperimentally using the HiFive Unleashed RISC-V development board.",
    "descriptor": "\nComments: Abbreviated version of this paper will be presented at the 14th International Workshop on Cyberspace Security and Artificial Intelligence (CAI-2022)\n",
    "authors": [
      "Vladimir Ushakov",
      "Sampo Sovio",
      "Qingchao Qi",
      "Vijayanand Nayani",
      "Valentin Manea",
      "Philip Ginzboorg",
      "Jan Erik Ekberg"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.10299"
  },
  {
    "id": "arXiv:2211.10307",
    "title": "SeaTurtleID: A novel long-span dataset highlighting the importance of  timestamps in wildlife re-identification",
    "abstract": "This paper introduces SeaTurtleID, the first public large-scale, long-span\ndataset with sea turtle photographs captured in the wild. The dataset is\nsuitable for benchmarking re-identification methods and evaluating several\nother computer vision tasks. The dataset consists of 7774 high-resolution\nphotographs of 400 unique individuals collected within 12 years in 1081\nencounters. Each photograph is accompanied by rich metadata, e.g., identity\nlabel, head segmentation mask, and encounter timestamp. The 12-year span of the\ndataset makes it the longest-spanned public wild animal dataset with\ntimestamps. By exploiting this unique property, we show that timestamps are\nnecessary for an unbiased evaluation of animal re-identification methods\nbecause they allow time-aware splits of the dataset into reference and query\nsets. We show that time-unaware splits can lead to performance overestimation\nof more than 100% compared to the time-aware splits for both feature- and\nCNN-based re-identification methods. We also argue that time-aware splits\ncorrespond to more realistic re-identification pipelines than the time-unaware\nones. We recommend that animal re-identification methods should only be tested\non datasets with timestamps using time-aware splits, and we encourage dataset\ncurators to include such information in the associated metadata.",
    "descriptor": "",
    "authors": [
      "Kostas Papafitsoros",
      "Luk\u00e1\u0161 Adam",
      "Vojt\u011bch \u010cerm\u00e1k",
      "Luk\u00e1\u0161 Picek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10307"
  },
  {
    "id": "arXiv:2211.10309",
    "title": "Constructions and bounds for codes with restricted overlaps",
    "abstract": "Non-overlapping codes have been studied for almost 60 years. In such a code,\nno proper, non-empty prefix of any codeword is a suffix of any codeword. In\nthis paper, we study codes in which overlaps of certain specified sizes are\nforbidden. We prove some general bounds and we give several constructions in\nthe case of binary codes. Our techniques also allow us to provide an\nalternative, elementary proof of a lower bound on non-overlapping codes due to\nLevenshtein in 1964.",
    "descriptor": "",
    "authors": [
      "Simon R. Blackburn",
      "Navid Nasr Esfahani",
      "Donald L. Kreher",
      "Douglas R. Stinson"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.10309"
  },
  {
    "id": "arXiv:2211.10317",
    "title": "$\u03b1$-Rank-Collections: Analyzing Expected Strategic Behavior with  Uncertain Utilities",
    "abstract": "Game theory largely rests on the availability of cardinal utility functions.\nIn contrast, only ordinal preferences are elicited in fields such as matching\nunder preferences. The literature focuses on mechanisms with simple dominant\nstrategies. However, many real-world applications do not have dominant\nstrategies, so intensities between preferences matter when participants\ndetermine their strategies. Even though precise information about cardinal\nutilities is unavailable, some data about the likelihood of utility functions\nis typically accessible. We propose to use Bayesian games to formalize\nuncertainty about decision-makers utilities by viewing them as a collection of\nnormal-form games where uncertainty about types persist in all game stages.\nInstead of searching for the Bayes-Nash equilibrium, we consider the question\nof how uncertainty in utilities is reflected in uncertainty of strategic play.\nWe introduce $\\alpha$-Rank-collections as a solution concept that extends\n$\\alpha$-Rank, a new solution concept for normal-form games, to Bayesian games.\nThis allows us to analyze the strategic play in, for example,\n(non-strategyproof) matching markets, for which we do not have appropriate\nsolution concepts so far. $\\alpha$-Rank-collections characterize a range of\nstrategy-profiles emerging from replicator dynamics of the game rather than\nequilibrium point. We prove that $\\alpha$-Rank-collections are invariant to\npositive affine transformations, and that they are efficient to approximate. An\ninstance of the Boston mechanism is used to illustrate the new solution\nconcept.",
    "descriptor": "\nComments: Submitted to INFORMS Journal on Computing\n",
    "authors": [
      "Fabian R. Pieroth",
      "Martin Bichler"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2211.10317"
  },
  {
    "id": "arXiv:2211.10320",
    "title": "A Fast Semi-Analytical Approach for Transient Electromigration Analysis  of Interconnect Trees using Matrix Exponential",
    "abstract": "As integrated circuit technologies are moving to smaller technology nodes,\nElectromigration (EM) has become one of the most challenging problems facing\nthe EDA industry. While numerical approaches have been widely deployed since\nthey can handle complicated interconnect structures, they tend to be much\nslower than analytical approaches. In this paper, we present a fast\nsemi-analytical approach, based on the matrix exponential, for the solution of\nKorhonen's stress equation at discrete spatial points of interconnect trees,\nwhich enables the analytical calculation of EM stress at any time and point\nindependently. The proposed approach is combined with the extended Krylov\nsubspace method to accurately simulate large EM models and accelerate the\ncalculation of the final solution. Experimental evaluation on OpenROAD\nbenchmarks demonstrates that our method achieves 0.5% average relative error\nover the COMSOL industrial tool while being up to three orders of magnitude\nfaster.",
    "descriptor": "",
    "authors": [
      "Pavlos Stoikos",
      "George Floros",
      "Dimitrios Garyfallou",
      "Nestor Evmorfopoulos",
      "George Stamoulis"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.10320"
  },
  {
    "id": "arXiv:2211.10321",
    "title": "Uncertainty-aware data-driven predictive control in a stochastic setting",
    "abstract": "Data-Driven Predictive Control (DDPC) has been recently proposed as an\neffective alternative to traditional Model Predictive Control (MPC), in that\nthe same constrained optimization problem can be addressed without the need to\nexplicitly identify a full model of the plant. However, DDPC is built upon\ninput/output trajectories. Therefore, the finite sample effect of stochastic\ndata, due to, e.g., measurement noise, may have a detrimental impact on\nclosed-loop performance. Exploiting a formal statistical analysis of the\nprediction error, in this paper we propose the first systematic approach to\ndeal with uncertainty due to finite sample effects. To this end, we introduce\ntwo regularization strategies for which, differently from existing\nregularization-based DDPC techniques, we propose a tuning rationale allowing us\nto select the regularization hyper-parameters before closing the loop and\nwithout additional experiments. Simulation results confirm the potential of the\nproposed strategy when closing the loop.",
    "descriptor": "\nComments: Preprint, 6 pages, 5 figures, \"This work has been submitted to IFAC for possible publication\"\n",
    "authors": [
      "Valentina Breschi",
      "Marco Fabris",
      "Simone Formentin",
      "Alessandro Chiuso"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.10321"
  },
  {
    "id": "arXiv:2211.10322",
    "title": "Understanding the double descent curve in Machine Learning",
    "abstract": "The theory of bias-variance used to serve as a guide for model selection when\napplying Machine Learning algorithms. However, modern practice has shown\nsuccess with over-parameterized models that were expected to overfit but did\nnot. This led to the proposal of the double descent curve of performance by\nBelkin et al. Although it seems to describe a real, representative phenomenon,\nthe field is lacking a fundamental theoretical understanding of what is\nhappening, what are the consequences for model selection and when is double\ndescent expected to occur. In this paper we develop a principled understanding\nof the phenomenon, and sketch answers to these important questions.\nFurthermore, we report real experimental results that are correctly predicted\nby our proposed hypothesis.",
    "descriptor": "",
    "authors": [
      "Luis Sa-Couto",
      "Jose Miguel Ramos",
      "Miguel Almeida",
      "Andreas Wichert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10322"
  },
  {
    "id": "arXiv:2211.10325",
    "title": "Numerical discretization of a Darcy-Forchheimer problem coupled with a  singular heat equation",
    "abstract": "In Lipschitz domains, we study a Darcy-Forchheimer problem coupled with a\nsingular heat equation by a nonlinear forcing term depending on the\ntemperature. By singular we mean that the heat source corresponds to a Dirac\nmeasure. We establish the existence of solutions for a model that allows a\ndiffusion coefficient in the heat equation depending on the temperature. For\nsuch a model, we also propose a finite element discretization scheme and\nprovide an a priori convergence analysis. In the case that the aforementioned\ndiffusion coefficient is constant, we devise an a posteriori error estimator\nand investigate reliability and efficiency properties. We conclude by devising\nan adaptive loop based on the proposed error estimator and presenting numerical\nexperiments.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2208.12887\n",
    "authors": [
      "Alejandro Allendes",
      "Gilberto Campa\u00f1a",
      "Enrique Otarola"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.10325"
  },
  {
    "id": "arXiv:2211.10330",
    "title": "GENIUS: Sketch-based Language Model Pre-training via Extreme and  Selective Masking for Text Generation and Augmentation",
    "abstract": "We introduce GENIUS: a conditional text generation model using sketches as\ninput, which can fill in the missing contexts for a given sketch (key\ninformation consisting of textual spans, phrases, or words, concatenated by\nmask tokens). GENIUS is pre-trained on a large-scale textual corpus with a\nnovel reconstruction from sketch objective using an extreme and selective\nmasking strategy, enabling it to generate diverse and high-quality texts given\nsketches. Comparison with other competitive conditional language models (CLMs)\nreveals the superiority of GENIUS's text generation quality. We further show\nthat GENIUS can be used as a strong and ready-to-use data augmentation tool for\nvarious natural language processing (NLP) tasks. Most existing textual data\naugmentation methods are either too conservative, by making small changes to\nthe original text, or too aggressive, by creating entirely new samples. With\nGENIUS, we propose GeniusAug, which first extracts the target-aware sketches\nfrom the original training set and then generates new samples based on the\nsketches. Empirical experiments on 6 text classification datasets show that\nGeniusAug significantly improves the models' performance in both\nin-distribution (ID) and out-of-distribution (OOD) settings. We also\ndemonstrate the effectiveness of GeniusAug on named entity recognition (NER)\nand machine reading comprehension (MRC) tasks. (Code and models are publicly\navailable at https://github.com/microsoft/SCGLab and\nhttps://github.com/beyondguo/genius)",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Biyang Guo",
      "Yeyun Gong",
      "Yelong Shen",
      "Songqiao Han",
      "Hailiang Huang",
      "Nan Duan",
      "Weizhu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.10330"
  },
  {
    "id": "arXiv:2211.10334",
    "title": "Distributed Average Consensus Over Noisy Communication Links in Directed  Graphs",
    "abstract": "Motivated by the needs of resiliency, scalability, and plug-and-play\noperation, distributed decision-making is becoming increasingly prevalent. The\nproblem of achieving consensus in a multi-agent system is at the core of\ndistributed decision-making. In this article, we study the problem of achieving\naverage consensus over a directed multi-agent network when the communication\nlinks are corrupted with noise. We propose an algorithm where each agent\nupdates its estimates based on the local mixing of information and adds its\nweighted noise-free initial information to its updates during every iteration.\nWe demonstrate that with appropriately designed weights the agents achieve\nconsensus under additive communication noise. We establish that when the\ncommunication links are noiseless the proposed algorithm moves towards\nconsensus at a geometric rate. Under communication noise, we prove that the\nagent estimates reach a consensus value almost surely. We present numerical\nexperiments to corroborate the efficacy of the proposed algorithm under\ndifferent noise realizations and various algorithm parameters.",
    "descriptor": "\nComments: 14 pages, 7 figures\n",
    "authors": [
      "Vivek Khatana",
      "Murti V. Salapaka"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.10334"
  },
  {
    "id": "arXiv:2211.10336",
    "title": "Tire-road friction estimation and uncertainty assessment to improve  electric aircraft braking system",
    "abstract": "The accurate online estimation of the road-friction coefficient is an\nessential feature for any advanced brake control system. In this study, a\ndata-driven scheme based on a MLP Neural Net is proposed to estimate the\noptimum friction coefficient as a function of windowed slip-friction\nmeasurements. A stochastic NN weights drop-out mechanism is used to online\nestimate the confidence interval of the estimated best friction coefficient\nthus providing a characterization of the epistemic uncertainty associated to\nthe NN block. Open loop and closed loop simulations of the landing phase of an\naircraft on an unknown surface are used to show the potentiality and efficacy\nof the proposed robust friction estimation approach.",
    "descriptor": "",
    "authors": [
      "Francesco Crocetti",
      "G. Costante",
      "M.L. Fravolini",
      "P. Valigi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10336"
  },
  {
    "id": "arXiv:2211.10338",
    "title": "Deep learning based landslide density estimation on SAR data for rapid  response",
    "abstract": "This work aims to produce landslide density estimates using Synthetic\nAperture Radar (SAR) satellite imageries to prioritise emergency resources for\nrapid response. We use the United States Geological Survey (USGS) Landslide\nInventory data annotated by experts after Hurricane Mar\\'ia in Puerto Rico on\nSept 20, 2017, and their subsequent susceptibility study which uses extensive\nadditional information such as precipitation, soil moisture, geological terrain\nfeatures, closeness to waterways and roads, etc. Since such data might not be\navailable during other events or regions, we aimed to produce a landslide\ndensity map using only elevation and SAR data to be useful to decision-makers\nin rapid response scenarios.\nThe USGS Landslide Inventory contains the coordinates of 71,431 landslide\nheads (not their full extent) and was obtained by manual inspection of aerial\nand satellite imagery. It is estimated that around 45\\% of the landslides are\nsmaller than a Sentinel-1 typical pixel which is 10m $\\times$ 10m, although\nmany are long and thin, probably leaving traces across several pixels. Our\nmethod obtains 0.814 AUC in predicting the correct density estimation class at\nthe chip level (128$\\times$128 pixels, at Sentinel-1 resolution) using only\nelevation data and up to three SAR acquisitions pre- and post-hurricane, thus\nenabling rapid assessment after a disaster. The USGS Susceptibility Study\nreports a 0.87 AUC, but it is measured at the landslide level and uses\nadditional information sources (such as proximity to fluvial channels, roads,\nprecipitation, etc.) which might not regularly be available in an rapid\nresponse emergency scenario.",
    "descriptor": "\nComments: 7 pages, 5 figures\n",
    "authors": [
      "Vanessa Boehm",
      "Wei Ji Leong",
      "Ragini Bal Mahesh",
      "Ioannis Prapas",
      "Edoardo Nemni",
      "Freddie Kalaitzis",
      "Siddha Ganju",
      "Raul Ramos-Pollan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10338"
  },
  {
    "id": "arXiv:2211.10340",
    "title": "Few-shot Learning for Multi-modal Social Media Event Filtering",
    "abstract": "Social media has become an important data source for event analysis. When\ncollecting this type of data, most contain no useful information to a target\nevent. Thus, it is essential to filter out those noisy data at the earliest\nopportunity for a human expert to perform further inspection. Most existing\nsolutions for event filtering rely on fully supervised methods for training.\nHowever, in many real-world scenarios, having access to large number of labeled\nsamples is not possible. To deal with a few labeled sample training problem for\nevent filtering, we propose a graph-based few-shot learning pipeline. We also\nrelease the Brazilian Protest Dataset to test our method. To the best of our\nknowledge, this dataset is the first of its kind in event filtering that\nfocuses on protests in multi-modal social media data, with most of the text in\nPortuguese. Our experimental results show that our proposed pipeline has\ncomparable performance with only a few labeled samples (60) compared with a\nfully labeled dataset (3100). To facilitate the research community, we make our\ndataset and code available at https://github.com/jdnascim/7Set-AL.",
    "descriptor": "\nComments: Accepted in IEEE International Workshop on Information Forensics and Security - WIFS 2022, Shanghai, China\n",
    "authors": [
      "Jos\u00e9 Nascimento",
      "Jo\u00e3o Phillipe Cardenuto",
      "Jing Yang",
      "Anderson Rocha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.10340"
  },
  {
    "id": "arXiv:2211.10344",
    "title": "Physics-informed neural networks for operator equations with stochastic  data",
    "abstract": "We consider the computation of statistical moments to operator equations with\nstochastic data. We remark that application of PINNs -- referred to as TPINNs\n-- allows to solve the induced tensor operator equations under minimal changes\nof existing PINNs code. This scheme can overcome the curse of dimensionality\nand covers non-linear and time-dependent operators. We propose two types of\narchitectures, referred to as vanilla and multi-output TPINNs, and investigate\ntheir benefits and limitations. Exhaustive numerical experiments are performed;\ndemonstrating applicability and performance; raising a variety of new promising\nresearch avenues.",
    "descriptor": "",
    "authors": [
      "Paul Escapil-Inchausp\u00e9",
      "Gonzalo A. Ruz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.10344"
  },
  {
    "id": "arXiv:2211.10346",
    "title": "Novelpy: A Python package to measure novelty and disruptiveness of  bibliometric and patent data",
    "abstract": "Novelpy (v1.2) is an open-source Python package designed to compute\nbibliometrics indicators. The package aims to provide a tool to the\nscientometrics community that centralizes different measures of novelty and\ndisruptiveness, enables their comparison and fosters reproducibility. This\npaper offers a comprehensive review of the different indicators available in\nNovelpy by formally describing these measures (both mathematically and\ngraphically) and presenting their benefits and limitations. We then compare the\ndifferent measures on a random sample of 1.5M articles drawn from Pubmed\nKnowledge Graph to demonstrate the module's capabilities. We encourage anyone\ninterested to participate in the development of future versions.",
    "descriptor": "",
    "authors": [
      "Pierre Pelletier",
      "Kevin Wirtz"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2211.10346"
  },
  {
    "id": "arXiv:2211.10360",
    "title": "Data efficient surrogate modeling for engineering design: Ensemble-free  batch mode deep active learning for regression",
    "abstract": "In a computer-aided engineering design optimization problem that involves\nnotoriously complex and time-consuming simulator, the prevalent approach is to\nreplace these simulations with a data-driven surrogate that approximates the\nsimulator's behavior at a much cheaper cost. The main challenge in creating an\ninexpensive data-driven surrogate is the generation of a sheer number of data\nusing these computationally expensive numerical simulations. In such cases,\nActive Learning (AL) methods have been used that attempt to learn an\ninput--output behavior while labeling the fewest samples possible. The current\ntrend in AL for a regression problem is dominated by the Bayesian framework\nthat needs training an ensemble of learning models that makes surrogate\ntraining computationally tedious if the underlying learning model is Deep\nNeural Networks (DNNs). However, DNNs have an excellent capability to learn\nhighly nonlinear and complex relationships even for a very high dimensional\nproblem. To leverage the excellent learning capability of deep networks along\nwith avoiding the computational complexity of the Bayesian paradigm, in this\nwork we propose a simple and scalable approach for active learning that works\nin a student-teacher manner to train a surrogate model. By using this proposed\napproach, we are able to achieve the same level of surrogate accuracy as the\nother baselines like DBAL and Monte Carlo sampling with up to 40 % fewer\nsamples. We empirically evaluated this method on multiple use cases including\nthree different engineering design domains:finite element analysis,\ncomputational fluid dynamics, and propeller design.",
    "descriptor": "\nComments: 23 pages, 12 figures\n",
    "authors": [
      "Harsh Vardhan",
      "Umesh Timalsina",
      "Peter Volgyesi",
      "Janos Sztipanovits"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.10360"
  },
  {
    "id": "arXiv:2211.10362",
    "title": "Damping analysis of Floating Offshore Wind Turbine (FOWT): a new control  strategy reducing the platform vibrations",
    "abstract": "In this paper, the coupled dynamics of the floating platform and the WTG\nrotor is analysed. In particular, the damping is explicitly derived from the\ncoupled equations of rotor and floating platform. The analysis of the damping\nleads to the study of the instability phenomena and it derives the explicit\nconditions that lead to the Non Minimum Phase Zero (NMPZ). Two NMPZs, one\nrelated to the rotor dynamics and the other one to the platform pitch dynamics,\nare analysed. The latter is a novelty and it is analysed in this work,\nproviding the community of an explicit condition for its verification. The\ndomain of the instability of the platform is explicitly derived from the\ncoupled system of equations. In the second part of the paper, from the analysis\nof the damping of the floating platform, a new strategy for the control of\nFOWTs is proposed. This strategy allows one to impose to the controller an\nexplicit level of damping in the platform pitch motion without changing the\nperiod of platform pitching. Finally the new strategy is compared to the one\nwithout compensation by performing aero-hydro-servo-elastic numerical\nsimulations of the UMaine IEA15MW FOWT. Generated power, movements, blade pitch\nand tower base fatigue are compared showing that the new control strategy can\nreduce fatigue in the structure without affecting the power production.",
    "descriptor": "\nComments: pre-print version to be submitted in Wind Energy Science\n",
    "authors": [
      "Matteo CapaldoO",
      "Paul Mella"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.10362"
  },
  {
    "id": "arXiv:2211.10369",
    "title": "Vehicular Safety Applications and Approaches: A Technical Survey",
    "abstract": "This paper proposes an extensive overview of safety applications and\napproaches as it relates to automated driving from the prospectives of sensor\nconfigurations, vehicle dynamics modelling, tyre modeling, and estimation\napproaches. First, different Advanced-Driver Assistance Systems (ADAS) are\nintroduced along with the main sensing components and technologies. Then,\ndifferent kinematics modelling of vehicles and tyres are discussed. Finally,\nvarious communicational technologies and architectures along with self-driving\nmodules are presented. Moreover, some interesting perspectives for future\nresearch are listed based on the extensive experience of the authors. The\nobjective of this study is to teach and guide the beginner and expert for\nchoosing the most suitable approach for autonomous driving applications in\nsafety and stability targeted issues.",
    "descriptor": "\nComments: 21 pages. arXiv admin note: text overlap with arXiv:1604.07446 by other authors\n",
    "authors": [
      "Hazem Fahmy",
      "Sabita Mahrajan"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.10369"
  },
  {
    "id": "arXiv:2211.10370",
    "title": "Invariant Learning via Diffusion Dreamed Distribution Shifts",
    "abstract": "Though the background is an important signal for image classification, over\nreliance on it can lead to incorrect predictions when spurious correlations\nbetween foreground and background are broken at test time. Training on a\ndataset where these correlations are unbiased would lead to more robust models.\nIn this paper, we propose such a dataset called Diffusion Dreamed Distribution\nShifts (D3S). D3S consists of synthetic images generated through\nStableDiffusion using text prompts and image guides obtained by pasting a\nsample foreground image onto a background template image. Using this scalable\napproach we generate 120K images of objects from all 1000 ImageNet classes in\n10 diverse backgrounds. Due to the incredible photorealism of the diffusion\nmodel, our images are much closer to natural images than previous synthetic\ndatasets. D3S contains a validation set of more than 17K images whose labels\nare human-verified in an MTurk study. Using the validation set, we evaluate\nseveral popular DNN image classifiers and find that the classification\nperformance of models generally suffers on our background diverse images. Next,\nwe leverage the foreground & background labels in D3S to learn a foreground\n(background) representation that is invariant to changes in background\n(foreground) by penalizing the mutual information between the foreground\n(background) features and the background (foreground) labels. Linear\nclassifiers trained on these features to predict foreground (background) from\nforeground (background) have high accuracies at 82.9% (93.8%), while\nclassifiers that predict these labels from background and foreground have a\nmuch lower accuracy of 2.4% and 45.6% respectively. This suggests that our\nforeground and background features are well disentangled. We further test the\nefficacy of these representations by training classifiers on a task with strong\nspurious correlations.",
    "descriptor": "\nComments: 18 pages, 13 figures, 5 tables\n",
    "authors": [
      "Priyatham Kattakinda",
      "Alexander Levine",
      "Soheil Feizi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10370"
  },
  {
    "id": "arXiv:2211.10378",
    "title": "Comparing Explanation Methods for Traditional Machine Learning Models  Part 2: Quantifying Model Explainability Faithfulness and Improvements with  Dimensionality Reduction",
    "abstract": "Machine learning (ML) models are becoming increasingly common in the\natmospheric science community with a wide range of applications. To enable\nusers to understand what an ML model has learned, ML explainability has become\na field of active research. In Part I of this two-part study, we described\nseveral explainability methods and demonstrated that feature rankings from\ndifferent methods can substantially disagree with each other. It is unclear,\nthough, whether the disagreement is overinflated due to some methods being less\nfaithful in assigning importance. Herein, \"faithfulness\" or \"fidelity\" refer to\nthe correspondence between the assigned feature importance and the contribution\nof the feature to model performance. In the present study, we evaluate the\nfaithfulness of feature ranking methods using multiple methods. Given the\nsensitivity of explanation methods to feature correlations, we also quantify\nhow much explainability faithfulness improves after correlated features are\nlimited. Before dimensionality reduction, the feature relevance methods [e.g.,\nSHAP, LIME, ALE variance, and logistic regression (LR) coefficients] were\ngenerally more faithful than the permutation importance methods due to the\nnegative impact of correlated features. Once correlated features were reduced,\ntraditional permutation importance became the most faithful method. In\naddition, the ranking uncertainty (i.e., the spread in rank assigned to a\nfeature by the different ranking methods) was reduced by a factor of 2-10, and\nexcluding less faithful feature ranking methods reduces it further. This study\nis one of the first to quantify the improvement in explainability from limiting\ncorrelated features and knowing the relative fidelity of different\nexplainability methods.",
    "descriptor": "\nComments: 18 pages; 12 figures ; part I (arXiv:2211.08943)\n",
    "authors": [
      "Montgomery Flora",
      "Corey Potvin",
      "Amy McGovern",
      "Shawn Handler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.10378"
  },
  {
    "id": "arXiv:2211.10382",
    "title": "Informative Sample-Aware Proxy for Deep Metric Learning",
    "abstract": "Among various supervised deep metric learning methods proxy-based approaches\nhave achieved high retrieval accuracies. Proxies, which are\nclass-representative points in an embedding space, receive updates based on\nproxy-sample similarities in a similar manner to sample representations. In\nexisting methods, a relatively small number of samples can produce large\ngradient magnitudes (ie, hard samples), and a relatively large number of\nsamples can produce small gradient magnitudes (ie, easy samples); these can\nplay a major part in updates. Assuming that acquiring too much sensitivity to\nsuch extreme sets of samples would deteriorate the generalizability of a\nmethod, we propose a novel proxy-based method called Informative Sample-Aware\nProxy (Proxy-ISA), which directly modifies a gradient weighting factor for each\nsample using a scheduled threshold function, so that the model is more\nsensitive to the informative samples. Extensive experiments on the\nCUB-200-2011, Cars-196, Stanford Online Products and In-shop Clothes Retrieval\ndatasets demonstrate the superiority of Proxy-ISA compared with the\nstate-of-the-art methods.",
    "descriptor": "\nComments: Accepted at ACM Multimedia Asia (MMAsia) 2022\n",
    "authors": [
      "Aoyu Li",
      "Ikuro Sato",
      "Kohta Ishikawa",
      "Rei Kawakami",
      "Rio Yokota"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.10382"
  },
  {
    "id": "arXiv:2211.10384",
    "title": "Indexing AI Risks with Incidents, Issues, and Variants",
    "abstract": "Two years after publicly launching the AI Incident Database (AIID) as a\ncollection of harms or near harms produced by AI in the world, a backlog of\n\"issues\" that do not meet its incident ingestion criteria have accumulated in\nits review queue. Despite not passing the database's current criteria for\nincidents, these issues advance human understanding of where AI presents the\npotential for harm. Similar to databases in aviation and computer security, the\nAIID proposes to adopt a two-tiered system for indexing AI incidents (i.e., a\nharm or near harm event) and issues (i.e., a risk of a harm event). Further, as\nsome machine learning-based systems will sometimes produce a large number of\nincidents, the notion of an incident \"variant\" is introduced. These proposed\nchanges mark the transition of the AIID to a new version in response to lessons\nlearned from editing 2,000+ incident reports and additional reports that fall\nunder the new category of \"issue.\"",
    "descriptor": "\nComments: To be published in Human-Centered AI Workshop at NeurIPS 2022\n",
    "authors": [
      "Sean McGregor",
      "Kevin Paeth",
      "Khoa Lam"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10384"
  },
  {
    "id": "arXiv:2211.10395",
    "title": "Hydraulic Parameter Estimation in District Heating Networks",
    "abstract": "Using hydraulic models in control design in district heating networks can\nincrease pumping efficiency and reduce sensitivity to hydraulic bottlenecks.\nThese models are usually white-box, as they are obtained based on full\nknowledge of the district heating network and its parameters. This type of\nmodel is time-consuming to obtain, and might differ from the actual behavior of\nthe system. In this paper, a method is proposed to obtain a grey-box hydraulic\nmodel for tree-shaped district heating systems: hydraulic parameters are\nestimated based on pressure measurements in only two locations. While previous\nworks only estimate parameters related to pressure losses in pipes, this work\nalso includes customers valves in the grey-box model structure, an important\ninclusion for control-oriented applications. Finally, a numerical example\nillustrates the proposed method on a small district heating network, showing\nits ability to obtain an accurate model on the basis of noisy measurements.",
    "descriptor": "",
    "authors": [
      "Felix Agner",
      "Pauline Kergus",
      "Richard Pates",
      "Anders Rantzer"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.10395"
  },
  {
    "id": "arXiv:2211.10398",
    "title": "Improved Approximations for Unrelated Machine Scheduling",
    "abstract": "We revisit two well-studied scheduling problems in the unrelated machines\nsetting where each job can have a different processing time on each machine.\nFor minimizing total weighted completion time we give a 1.45-approximation,\nwhich improves upon the previous 1.488-approximation [Im and Shadloo SODA\n2020]. The key technical ingredient in this improvement lies in a new rounding\nscheme that gives strong negative correlation with less restrictions. For\nminimizing $L_k$-norms of machine loads, inspired by [Kalaitzis et al. SODA\n2017], we give better approximation algorithms. In particular we give a $\\sqrt\n{4/3}$-approximation for the $L_2$-norm which improves upon the former $\\sqrt\n2$-approximations due to [Azar-Epstein STOC 2005] and [Kumar et al. JACM 2009].",
    "descriptor": "\nComments: To appear in SODA 2023\n",
    "authors": [
      "Sungjin Im",
      "Shi Li"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.10398"
  },
  {
    "id": "arXiv:2211.10405",
    "title": "Short Note on Generating Sets for Semiflows",
    "abstract": "In this short note, we are interested in discussing characteristics of finite\ngenerating sets for $\\mathcal{F}$, the set of all semiflows with non negative\ncoefficients of a Petri Net. By systematically positioning these results over\nsemi rings such as $\\mathbb{N}$ or $\\mathbb{Q^+}$ then over a field such as\n$\\mathbb{Q}$, we were able to discover a handful of new results",
    "descriptor": "",
    "authors": [
      "Gerard Memmi"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.10405"
  },
  {
    "id": "arXiv:2211.10407",
    "title": "Materials Science Ontology Design with an Analytico-Synthetic Facet  Analysis Framework",
    "abstract": "Researchers across nearly every discipline seek to leverage ontologies for\nknowledge discovery and computational tasks; yet, the number of machine\nreadable materials science ontologies is limited. The work presented in this\npaper explores the Processing, Structure, Properties and Performance (PSPP)\nframework for accelerating the development of materials science ontologies. We\npursue a case study framed by the creation of an Aerogel ontology and a Battery\nCathode ontology and demonstrate the Helping Interdisciplinary Vocabulary\nEngineer for Materials Science (HIVE4MAT) as a proof of concept showing PSPP\nrelationships. The paper includes background context covering materials\nscience, the PSPP framework, and faceted analysis for ontologies. We report our\nresearch objectives, methods, research procedures, and results. The findings\nindicate that the PSPP framework offers a rubric that may help guide and\npotentially accelerate ontology development.",
    "descriptor": "\nComments: Proceeding of 16th International Conference on Metadata and Semantics Research\n",
    "authors": [
      "Jane Greenberg",
      "Scott McClellan",
      "Xintong Zhao",
      "Elijah J Kellner",
      "David Venator",
      "Haoran Zhao",
      "Jiacheng Shen",
      "Xiaohua Hu",
      "Yuan An"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2211.10407"
  },
  {
    "id": "arXiv:2211.10408",
    "title": "Improved Cross-view Completion Pre-training for Stereo Matching",
    "abstract": "Despite impressive performance for high-level downstream tasks,\nself-supervised pre-training methods have not yet fully delivered on dense\ngeometric vision tasks such as stereo matching. The application of\nself-supervised learning concepts, such as instance discrimination or masked\nimage modeling, to geometric tasks is an active area of research. In this work\nwe build on the recent cross-view completion framework: this variation of\nmasked image modeling leverages a second view from the same scene, which is\nwell suited for binocular downstream tasks. However, the applicability of this\nconcept has so far been limited in at least two ways: (a) by the difficulty of\ncollecting real-world image pairs - in practice only synthetic data had been\nused - and (b) by the lack of generalization of vanilla transformers to dense\ndownstream tasks for which relative position is more meaningful than absolute\nposition. We explore three avenues of improvement: first, we introduce a method\nto collect suitable real-world image pairs at large scale. Second, we\nexperiment with relative positional embeddings and demonstrate that they enable\nvision transformers to perform substantially better. Third, we scale up vision\ntransformer based cross-completion architectures, which is made possible by the\nuse of large amounts of data. With these improvements, we show for the first\ntime that state-of-the-art results on deep stereo matching can be reached\nwithout using any standard task-specific techniques like correlation volume,\niterative estimation or multi-scale reasoning.",
    "descriptor": "",
    "authors": [
      "Philippe Weinzaepfel",
      "Vaibhav Arora",
      "Yohann Cabon",
      "Thomas Lucas",
      "Romain Br\u00e9gier",
      "Vincent Leroy",
      "Gabriela Csurka",
      "Leonid Antsfeld",
      "Boris Chidlovskii",
      "J\u00e9r\u00f4me Revaud"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10408"
  },
  {
    "id": "arXiv:2211.10409",
    "title": "AXI-Pack: Near-Memory Bus Packing for Bandwidth-Efficient Irregular  Workloads",
    "abstract": "Data-intensive applications involving irregular memory streams are\ninefficiently handled by modern processors and memory systems highly optimized\nfor regular, contiguous data. Recent work tackles these inefficiencies in\nhardware through core-side stream extensions or memory-side prefetchers and\naccelerators, but fails to provide end-to-end solutions which also achieve high\nefficiency in on-chip interconnects. We propose AXI-Pack, an extension to ARM's\nAXI4 protocol introducing bandwidth-efficient strided and indirect bursts to\nenable end-to-end irregular streams. AXI-Pack adds irregular stream semantics\nto memory requests and avoids inefficient narrow-bus transfers by packing\nmultiple narrow data elements onto a wide bus. It retains full compatibility\nwith AXI4 and does not require modifications to non-burst-reshaping\ninterconnect IPs. To demonstrate our approach end-to-end, we extend an\nopen-source RISC-V vector processor to leverage AXI-Pack at its memory\ninterface for strided and indexed accesses. On the memory side, we design a\nbanked memory controller efficiently handling AXI-Pack requests. On a system\nwith a 256-bit-wide interconnect running FP32 workloads, AXI-Pack achieves\nnear-ideal peak on-chip bus utilizations of 87% and 39%, speedups of 5.4x and\n2.4x, and energy efficiency improvements of 5.3x and 2.1x over a baseline using\nan AXI4 bus on strided and indirect benchmarks, respectively.",
    "descriptor": "\nComments: 6 pages, 5 figures. Submitted to DATE 2023\n",
    "authors": [
      "Chi Zhang",
      "Paul Scheffler",
      "Thomas Benz",
      "Matteo Perotti",
      "Luca Benini"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.10409"
  },
  {
    "id": "arXiv:2211.10411",
    "title": "CITADEL: Conditional Token Interaction via Dynamic Lexical Routing for  Efficient and Effective Multi-Vector Retrieval",
    "abstract": "Multi-vector retrieval methods combine the merits of sparse (e.g. BM25) and\ndense (e.g. DPR) retrievers and have achieved state-of-the-art performance on\nvarious retrieval tasks. These methods, however, are orders of magnitude slower\nand need much more space to store their indices compared to their single-vector\ncounterparts. In this paper, we unify different multi-vector retrieval models\nfrom a token routing viewpoint and propose conditional token interaction via\ndynamic lexical routing, namely CITADEL, for efficient and effective\nmulti-vector retrieval. CITADEL learns to route different token vectors to the\npredicted lexical ``keys'' such that a query token vector only interacts with\ndocument token vectors routed to the same key. This design significantly\nreduces the computation cost while maintaining high accuracy. Notably, CITADEL\nachieves the same or slightly better performance than the previous state of the\nart, ColBERT-v2, on both in-domain (MS MARCO) and out-of-domain (BEIR)\nevaluations, while being nearly 40 times faster. Code and data are available at\nhttps://github.com/facebookresearch/dpr-scale.",
    "descriptor": "",
    "authors": [
      "Minghan Li",
      "Sheng-Chieh Lin",
      "Barlas Oguz",
      "Asish Ghoshal",
      "Jimmy Lin",
      "Yashar Mehdad",
      "Wen-tau Yih",
      "Xilun Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.10411"
  },
  {
    "id": "arXiv:2211.10412",
    "title": "Video Unsupervised Domain Adaptation with Deep Learning: A Comprehensive  Survey",
    "abstract": "Video analysis tasks such as action recognition have received increasing\nresearch interest with growing applications in fields such as smart healthcare,\nthanks to the introduction of large-scale datasets and deep learning-based\nrepresentations. However, video models trained on existing datasets suffer from\nsignificant performance degradation when deployed directly to real-world\napplications due to domain shifts between the training public video datasets\n(source video domains) and real-world videos (target video domains). Further,\nwith the high cost of video annotation, it is more practical to use unlabeled\nvideos for training. To tackle performance degradation and address concerns in\nhigh video annotation cost uniformly, the video unsupervised domain adaptation\n(VUDA) is introduced to adapt video models from the labeled source domain to\nthe unlabeled target domain by alleviating video domain shift, improving the\ngeneralizability and portability of video models. This paper surveys recent\nprogress in VUDA with deep learning. We begin with the motivation of VUDA,\nfollowed by its definition, and recent progress of methods for both closed-set\nVUDA and VUDA under different scenarios, and current benchmark datasets for\nVUDA research. Eventually, future directions are provided to promote further\nVUDA research.",
    "descriptor": "\nComments: Survey on Video Unsupervised Domain Adaptation (VUDA), 16 pages, 1 figure, 8 tables\n",
    "authors": [
      "Yuecong Xu",
      "Haozhi Cao",
      "Zhenghua Chen",
      "Xiaoli Li",
      "Lihua Xie",
      "Jianfei Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10412"
  },
  {
    "id": "arXiv:2211.10413",
    "title": "TSN-FlexTest: Flexible TSN Measurement Testbed (Extended Version)",
    "abstract": "Robust, reliable, and deterministic networks are essential for a variety of\napplications. In order to provide guaranteed communication network services,\nTime-Sensitive Networking (TSN) unites a set of standards for\ntime-synchronization, flow control, enhanced reliability, and management. We\ndesign the TSN-FlexTest testbed with generic commodity hardware and open-source\nsoftware components to enable flexible TSN measurements. We have conducted\nextensive measurements to validate the TSN-FlexTest testbed and to examine TSN\ncharacteristics. The measurements provide insights into the effects of TSN\nconfigurations, such as increasing the number of synchronization messages for\nthe Precision Time Protocol, indicating that a measurement accuracy of 15 ns\ncan be achieved. The TSN measurements included extensive evaluations of the\nTime-aware Shaper (TAS) for sets of Tactile Internet (TI) packet traffic\nstreams. The measurements elucidate the effects of different scheduling and\nshaping approaches, while revealing the need for pervasive network control that\nsynchronizes the sending nodes with the network switches. We present the first\nmeasurements of distributed TAS with synchronized senders on a commodity\nhardware testbed, demonstrating the same Quality-of-Service as with dedicated\nwires for high-priority TI streams despite a 200% over-saturation cross traffic\nload. The testbed is provided as an open-source project to facilitate future\nTSN research.",
    "descriptor": "\nComments: 30 pages, 18 figures, 6 tables\n",
    "authors": [
      "Marian Ulbricht",
      "Stefan Senk",
      "Hosein K. Nazari",
      "How-Hang Liu",
      "Martin Reisslein",
      "Giang T. Nguyen",
      "Frank H. P. Fitzek"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.10413"
  },
  {
    "id": "arXiv:2211.10420",
    "title": "Mirror Sinkhorn: Fast Online Optimization on Transport Polytopes",
    "abstract": "Optimal transport has arisen as an important tool in machine learning,\nallowing to capture geometric properties of the data. It is formulated as a\nlinear program on transport polytopes. The problem of convex optimization on\nthis set includes both OT and multiple related ones, such as point cloud\nregistration.\nWe present in this work an optimization algorithm that utilizes Sinkhorn\nmatrix scaling and mirror descent to minimize convex objectives on this domain.\nThis algorithm can be run online and is both adaptive and robust to noise. A\nmathematical analysis of the convergence rate of the algorithm for minimising\nconvex functions is provided, as well as experiments that illustrate its\nperformance on synthetic data and real-world data.",
    "descriptor": "",
    "authors": [
      "Marin Ballu",
      "Quentin Berthet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.10420"
  },
  {
    "id": "arXiv:2211.10421",
    "title": "CNeRV: Content-adaptive Neural Representation for Visual Data",
    "abstract": "Compression and reconstruction of visual data have been widely studied in the\ncomputer vision community, even before the popularization of deep learning.\nMore recently, some have used deep learning to improve or refine existing\npipelines, while others have proposed end-to-end approaches, including\nautoencoders and implicit neural representations, such as SIREN and NeRV. In\nthis work, we propose Neural Visual Representation with Content-adaptive\nEmbedding (CNeRV), which combines the generalizability of autoencoders with the\nsimplicity and compactness of implicit representation. We introduce a novel\ncontent-adaptive embedding that is unified, concise, and internally\n(within-video) generalizable, that compliments a powerful decoder with a\nsingle-layer encoder. We match the performance of NeRV, a state-of-the-art\nimplicit neural representation, on the reconstruction task for frames seen\nduring training while far surpassing for frames that are skipped during\ntraining (unseen images). To achieve similar reconstruction quality on unseen\nimages, NeRV needs 120x more time to overfit per-frame due to its lack of\ninternal generalization. With the same latent code length and similar model\nsize, CNeRV outperforms autoencoders on reconstruction of both seen and unseen\nimages. We also show promising results for visual data compression. More\ndetails can be found in the project pagehttps://haochen-rye.github.io/CNeRV/",
    "descriptor": "\nComments: BMVC 2022 at this https URL\n",
    "authors": [
      "Hao Chen",
      "Matt Gwilliam",
      "Bo He",
      "Ser-Nam Lim",
      "Abhinav Shrivastava"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10421"
  },
  {
    "id": "arXiv:2211.10435",
    "title": "PAL: Program-aided Language Models",
    "abstract": "Large language models (LLMs) have recently demonstrated an impressive ability\nto perform arithmetic and symbolic reasoning tasks when provided with a few\nexamples at test time (few-shot prompting). Much of this success can be\nattributed to prompting methods for reasoning, such as chain-of-thought, that\nemploy LLMs for both understanding the problem description by decomposing it\ninto steps, as well as solving each step of the problem. While LLMs seem to be\nadept at this sort of step-by-step decomposition, LLMs often make logical and\narithmetic mistakes in the solution part, even when the problem is correctly\ndecomposed. We present Program-Aided Language models (PaL): a new method that\nuses the LLM to understand natural language problems and generate programs as\nthe intermediate reasoning steps, but offloads the solution step to a\nprogrammatic runtime such as a Python interpreter. With PaL, decomposing the\nnatural language problem into runnable steps remains the only learning task for\nthe LLM, while solving is delegated to the interpreter. We experiment with 12\nreasoning tasks from BIG-Bench Hard and other benchmarks, including\nmathematical reasoning, symbolic reasoning, and algorithmic problems. In all\nthese natural language reasoning tasks, generating code using an LLM and\nreasoning using a Python interpreter leads to more accurate results than much\nlarger models, and we set new state-of-the-art results in all 12 benchmarks.\nFor example, PaL using Codex achieves state-of-the-art few-shot accuracy on the\nGSM benchmark of math word problems when the model is allowed only a single\ndecoding, surpassing PaLM-540B with chain-of-thought prompting by an absolute\n8% .In three reasoning tasks from the BIG-Bench Hard benchmark, PaL outperforms\nCoT by 11%. On GSM-hard, a more challenging version of GSM that we create, PaL\noutperforms chain-of-thought by an absolute 40%.",
    "descriptor": "\nComments: The first three authors contributed equally. Our code and data are publicly available at this http URL\n",
    "authors": [
      "Luyu Gao",
      "Aman Madaan",
      "Shuyan Zhou",
      "Uri Alon",
      "Pengfei Liu",
      "Yiming Yang",
      "Jamie Callan",
      "Graham Neubig"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10435"
  },
  {
    "id": "arXiv:2211.10437",
    "title": "A Structure-Guided Diffusion Model for Large-Hole Diverse Image  Completion",
    "abstract": "Diverse image completion, a problem of generating various ways of filling\nincomplete regions (i.e. holes) of an image, has made remarkable success.\nHowever, managing input images with large holes is still a challenging problem\ndue to the corruption of semantically important structures. In this paper, we\ntackle this problem by incorporating explicit structural guidance. We propose a\nstructure-guided diffusion model (SGDM) for the large-hole diverse completion\nproblem. Our proposed SGDM consists of a structure generator and a texture\ngenerator, which are both diffusion probabilistic models (DMs). The structure\ngenerator generates an edge image representing a plausible structure within the\nholes, which is later used to guide the texture generation process. To jointly\ntrain these two generators, we design a strategy that combines optimal Bayesian\ndenoising and a momentum framework. In addition to the quality improvement,\nauxiliary edge images generated by the structure generator can be manually\nedited to allow user-guided image editing. Our experiments using datasets of\nfaces (CelebA-HQ) and natural scenes (Places) show that our method achieves a\ncomparable or superior trade-off between visual quality and diversity compared\nto other state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Daichi Horita",
      "Jiaolong Yang",
      "Dong Chen",
      "Yuki Koyama",
      "Kiyoharu Aizawa"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10437"
  },
  {
    "id": "arXiv:2211.10438",
    "title": "SmoothQuant: Accurate and Efficient Post-Training Quantization for Large  Language Models",
    "abstract": "Large language models (LLMs) show excellent performance but are compute- and\nmemory-intensive. Quantization can reduce memory and accelerate inference.\nHowever, for LLMs beyond 100 billion parameters, existing methods cannot\nmaintain accuracy or do not run efficiently on hardware. We propose\nSmoothQuant, a training-free, accuracy-preserving, and general-purpose\npost-training quantization (PTQ) solution to enable 8-bit weight, 8-bit\nactivation (W8A8) quantization for LLMs that can be implemented efficiently. We\nobserve that systematic outliers appear at fixed activation channels. Based on\nthe fact that weights are easy to quantize while activations are not,\nSmoothQuant smooths the activation outliers by migrating the quantization\ndifficulty from activations to weights with a mathematically equivalent\ntransformation. SmoothQuant enables an INT8 quantization of both weights and\nactivations for all the GEMMs in LLMs, including OPT-175B, BLOOM-176B and\nGLM-130B. SmoothQuant has better hardware efficiency than existing techniques\nusing mixed-precision activation quantization or weight-only quantization. We\ndemonstrate up to 1.56x speedup and 2x memory reduction for LLMs with\nnegligible loss in accuracy. Thanks to the hardware-friendly design, we\nintegrate SmoothQuant into FasterTransformer, a state-of-the-art LLM serving\nframework, and achieve faster inference speed with half the number of GPUs\ncompared to FP16. Our work offers a turn-key solution that reduces hardware\ncosts and democratizes LLMs. Code will be released at:\nhttps://github.com/mit-han-lab/smoothquant.",
    "descriptor": "\nComments: The first two authors contributed equally to this work\n",
    "authors": [
      "Guangxuan Xiao",
      "Ji Lin",
      "Mickael Seznec",
      "Julien Demouth",
      "Song Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10438"
  },
  {
    "id": "arXiv:2211.10439",
    "title": "BEVFormer v2: Adapting Modern Image Backbones to Bird's-Eye-View  Recognition via Perspective Supervision",
    "abstract": "We present a novel bird's-eye-view (BEV) detector with perspective\nsupervision, which converges faster and better suits modern image backbones.\nExisting state-of-the-art BEV detectors are often tied to certain depth\npre-trained backbones like VoVNet, hindering the synergy between booming image\nbackbones and BEV detectors. To address this limitation, we prioritize easing\nthe optimization of BEV detectors by introducing perspective space supervision.\nTo this end, we propose a two-stage BEV detector, where proposals from the\nperspective head are fed into the bird's-eye-view head for final predictions.\nTo evaluate the effectiveness of our model, we conduct extensive ablation\nstudies focusing on the form of supervision and the generality of the proposed\ndetector. The proposed method is verified with a wide spectrum of traditional\nand modern image backbones and achieves new SoTA results on the large-scale\nnuScenes dataset. The code shall be released soon.",
    "descriptor": "",
    "authors": [
      "Chenyu Yang",
      "Yuntao Chen",
      "Hao Tian",
      "Chenxin Tao",
      "Xizhou Zhu",
      "Zhaoxiang Zhang",
      "Gao Huang",
      "Hongyang Li",
      "Yu Qiao",
      "Lewei Lu",
      "Jie Zhou",
      "Jifeng Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10439"
  },
  {
    "id": "arXiv:2211.10440",
    "title": "Magic3D: High-Resolution Text-to-3D Content Creation",
    "abstract": "DreamFusion has recently demonstrated the utility of a pre-trained\ntext-to-image diffusion model to optimize Neural Radiance Fields (NeRF),\nachieving remarkable text-to-3D synthesis results. However, the method has two\ninherent limitations: (a) extremely slow optimization of NeRF and (b)\nlow-resolution image space supervision on NeRF, leading to low-quality 3D\nmodels with a long processing time. In this paper, we address these limitations\nby utilizing a two-stage optimization framework. First, we obtain a coarse\nmodel using a low-resolution diffusion prior and accelerate with a sparse 3D\nhash grid structure. Using the coarse representation as the initialization, we\nfurther optimize a textured 3D mesh model with an efficient differentiable\nrenderer interacting with a high-resolution latent diffusion model. Our method,\ndubbed Magic3D, can create high quality 3D mesh models in 40 minutes, which is\n2x faster than DreamFusion (reportedly taking 1.5 hours on average), while also\nachieving higher resolution. User studies show 61.7% raters to prefer our\napproach over DreamFusion. Together with the image-conditioned generation\ncapabilities, we provide users with new ways to control 3D synthesis, opening\nup new avenues to various creative applications.",
    "descriptor": "\nComments: Project website: this https URL\n",
    "authors": [
      "Chen-Hsuan Lin",
      "Jun Gao",
      "Luming Tang",
      "Towaki Takikawa",
      "Xiaohui Zeng",
      "Xun Huang",
      "Karsten Kreis",
      "Sanja Fidler",
      "Ming-Yu Liu",
      "Tsung-Yi Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10440"
  },
  {
    "id": "arXiv:2211.09848",
    "title": "Fully Digital Second-order Level-crossing Sampling ADC for Data Saving  in Sensing Sparse Signals",
    "abstract": "This paper presents a fully integrated second-order level-crossing sampling\ndata converter for real-time data compression and feature extraction. Compared\nwith level-sampling ADCs which sample at fixed voltage levels, the proposed\ncircuits updates tracking thresholds using linear extrapolation, which forms a\nsecond-order level-crossing sampling ADC that has sloped sampling levels. The\ncomputing is done digitally and is implemented by modifying the digital control\nlogic of a conventional SAR ADC. The system selects only the turning points in\nthe input waveform for quantization. The output of the proposed data converter\nconsists of both the digital value of the selected sampling points and the\ntimestamp between the selected sampling points. The main advantages are data\nsavings and power savings for the data converter and the following digital\nsignal processing or communication circuits, which are ideal for low-power\nsensors. The test chip was fabricated using a 180nm CMOS process. The proposed\nADC saves 30% compared to a conventional SAR ADC and achieves a compression\nfactor of 6.17 for tracking ECG signals.",
    "descriptor": "\nComments: 4 pages, 8 figures\n",
    "authors": [
      "Mario Renteria-Pinon",
      "Xiaochen Tang",
      "Jaime Ramirez-Angulo",
      "Wei Tang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.09848"
  },
  {
    "id": "arXiv:2211.09860",
    "title": "Automated Quantum Memory Compilation with Improved Dynamic Range",
    "abstract": "Emerging quantum algorithms that process data require that classical input\ndata be represented as a quantum state. These data-processing algorithms often\nfollow the gate model of quantum computing--which requires qubits to be\ninitialized to a basis state, typically $\\lvert 0 \\rangle$--and thus often\nemploy state generation circuits to transform the initialized basis state to a\ndata-representation state. There are many ways to encode classical data in a\nqubit, and the oft-applied approach of basis encoding does not allow\noptimization to the extent that other variants do. In this work, we thus\nconsider automatic synthesis of addressable, quantum read-only memory (QROM)\ncircuits, which act as data-encoding state-generation circuits. We investigate\nthree data encoding approaches, one of which we introduce to provide improved\ndynamic range and precision. We present experimental results that compare these\nencoding methods for QROM synthesis to better understand the implications of\nand applications for each.",
    "descriptor": "\nComments: 14 pages, 9 figures, and 13 tables\n",
    "authors": [
      "Aviraj Sinha",
      "Elena R. Henderson",
      "Jessie M. Henderson",
      "Mitchell A. Thornton"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2211.09860"
  },
  {
    "id": "arXiv:2211.09862",
    "title": "Knowledge distillation for fast and accurate DNA sequence correction",
    "abstract": "Accurate genome sequencing can improve our understanding of biology and the\ngenetic basis of disease. The standard approach for generating DNA sequences\nfrom PacBio instruments relies on HMM-based models. Here, we introduce\nDistilled DeepConsensus - a distilled transformer-encoder model for sequence\ncorrection, which improves upon the HMM-based methods with runtime constraints\nin mind. Distilled DeepConsensus is 1.3x faster and 1.5x smaller than its\nlarger counterpart while improving the yield of high quality reads (Q30) over\nthe HMM-based method by 1.69x (vs. 1.73x for larger model). With improved\naccuracy of genomic sequences, Distilled DeepConsensus improves downstream\napplications of genomic sequence analysis such as reducing variant calling\nerrors by 39% (34% for larger model) and improving genome assembly quality by\n3.8% (4.2% for larger model). We show that the representations learned by\nDistilled DeepConsensus are similar between faster and slower models.",
    "descriptor": "",
    "authors": [
      "Anastasiya Belyaeva",
      "Joel Shor",
      "Daniel E. Cook",
      "Kishwar Shafin",
      "Daniel Liu",
      "Armin T\u00f6pfer",
      "Aaron M. Wenger",
      "William J. Rowell",
      "Howard Yang",
      "Alexey Kolesnikov",
      "Cory Y. McLean",
      "Maria Nattestad",
      "Andrew Carroll",
      "Pi-Chuan Chang"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09862"
  },
  {
    "id": "arXiv:2211.09866",
    "title": "Fast Uncertainty Estimates in Deep Learning Interatomic Potentials",
    "abstract": "Deep learning has emerged as a promising paradigm to give access to highly\naccurate predictions of molecular and materials properties. A common\nshort-coming shared by current approaches, however, is that neural networks\nonly give point estimates of their predictions and do not come with predictive\nuncertainties associated with these estimates. Existing uncertainty\nquantification efforts have primarily leveraged the standard deviation of\npredictions across an ensemble of independently trained neural networks. This\nincurs a large computational overhead in both training and prediction that\noften results in order-of-magnitude more expensive predictions. Here, we\npropose a method to estimate the predictive uncertainty based on a single\nneural network without the need for an ensemble. This allows us to obtain\nuncertainty estimates with virtually no additional computational overhead over\nstandard training and inference. We demonstrate that the quality of the\nuncertainty estimates matches those obtained from deep ensembles. We further\nexamine the uncertainty estimates of our methods and deep ensembles across the\nconfiguration space of our test system and compare the uncertainties to the\npotential energy surface. Finally, we study the efficacy of the method in an\nactive learning setting and find the results to match an ensemble-based\nstrategy at order-of-magnitude reduced computational cost.",
    "descriptor": "",
    "authors": [
      "Albert Zhu",
      "Simon Batzner",
      "Albert Musaelian",
      "Boris Kozinsky"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.09866"
  },
  {
    "id": "arXiv:2211.09887",
    "title": "Microstructural neuroimaging using spherical convolutional neural  networks",
    "abstract": "Diffusion-weighted magnetic resonance imaging is sensitive to the\nmicrostructural properties of brain tissue. However, estimating clinically and\nscientifically relevant microstructural properties from the measured signals\nremains a highly challenging inverse problem. This paper presents a novel\nframework for estimating microstructural parameters using recently developed\norientationally invariant spherical convolutional neural networks and\nefficiently simulated training data with a known ground truth. The network was\ntrained to predict the ground-truth parameter values from simulated noisy data\nand applied to imaging data acquired in a clinical setting to generate\nmicrostructural parameter maps. Our model could estimate model parameters from\nspherical data more accurately than conventional non-linear least squares or a\nmulti-layer perceptron applied on powder-averaged data (i.e., the spherical\nmean technique, a popular method for orientationally invariant microstructural\nparameter estimation). Importantly, our method is generalizable and can be used\nto estimate the parameters of any Gaussian compartment model.",
    "descriptor": "",
    "authors": [
      "Leevi Kerkel\u00e4",
      "Kiran Seunarine",
      "Filip Szczepankiewicz",
      "Chris A. Clark"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.09887"
  },
  {
    "id": "arXiv:2211.09888",
    "title": "Bayesian Optimization of 2D Echocardiography Segmentation",
    "abstract": "Bayesian Optimization (BO) is a well-studied hyperparameter tuning technique\nthat is more efficient than grid search for high-cost, high-parameter machine\nlearning problems. Echocardiography is a ubiquitous modality for evaluating\nheart structure and function in cardiology. In this work, we use BO to optimize\nthe architectural and training-related hyperparameters of a previously\npublished deep fully convolutional neural network model for multi-structure\nsegmentation in echocardiography. In a fair comparison, the resulting model\noutperforms this recent state-of-the-art on the annotated CAMUS dataset in both\napical two- and four-chamber echo views. We report mean Dice overlaps of 0.95,\n0.96, and 0.93 on left ventricular (LV) endocardium, LV epicardium, and left\natrium respectively. We also observe significant improvement in derived\nclinical indices, including smaller median absolute errors for LV end-diastolic\nvolume (4.9mL vs. 6.7), end-systolic volume (3.1mL vs. 5.2), and ejection\nfraction (2.6% vs. 3.7); and much tighter limits of agreement, which were\nalready within inter-rater variability for non-contrast echo. These results\ndemonstrate the benefits of BO for echocardiography segmentation over a recent\nstate-of-the-art framework, although validation using large-scale independent\nclinical data is required.",
    "descriptor": "",
    "authors": [
      "Son-Tung Tran",
      "Joshua V. Stough",
      "Xiaoyan Zhang",
      "Christopher M. Haggerty"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.09888"
  },
  {
    "id": "arXiv:2211.09901",
    "title": "Dynamic Predictive Sampling Analog to Digital Converter for Sparse  Signal Sensing",
    "abstract": "This paper presents a dynamic predictive sampling (DPS) based\nanalog-to-digital converter (ADC) that provides a non-uniform sampling of input\nanalog continuous-time signals. The processing unit generates a dynamic\nprediction of the input signal using two prior-quantized samplings to compute\ndigital values of an upper threshold and a lower threshold. The digital\nthreshold values are converted to analog thresholds to form a tracking window.\nA comparator compares the input analog signal with the tracking window to\ndetermine if the prediction is successful. A counter records timestamps between\nthe unsuccessful predictions, which are the selected sampling points for\nquantization. No quantization is performed for successfully predicted sampling\npoints so that the data throughput and power can be saved. The proposed\ncircuits were designed as a 10-bit ADC using 0.18 micro CMOS process sampling\nat 1 kHz. The results show that the proposed system can achieve a data\ncompression factor of 6.17 and a power saving factor of 31% compared to a\nNyquist rate SAR ADC for ECG monitoring.",
    "descriptor": "\nComments: 5 pages, 8 figures\n",
    "authors": [
      "Xiaochen Tang",
      "Mario Renteria-Pinon",
      "Wei Tang"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.09901"
  },
  {
    "id": "arXiv:2211.09903",
    "title": "CHARTER: Identifying the Most-Critical Gate Operations in Quantum  Circuits via Amplified Gate Reversibility",
    "abstract": "When quantum programs are executed on noisy intermediate-scale quantum (NISQ)\ncomputers, they experience hardware noise; consequently, the program outputs\nare often erroneous. To mitigate the adverse effects of hardware noise, it is\nnecessary to understand the effect of hardware noise on the program output and\nmore fundamentally, understand the impact of hardware noise on specific regions\nwithin a quantum program. Identifying and optimizing regions that are more\nnoise-sensitive is the key to expanding the capabilities of NISQ computers.\nToward achieving that goal, we propose CHARTER, a novel technique to pinpoint\nspecific gates and regions within a quantum program that are the most affected\nby the hardware noise and that have the highest impact on the program output.\nUsing CHARTER's methodology, programmers can obtain a precise understanding of\nhow different components of their code affect the output and optimize those\ncomponents without the need for non-scalable quantum simulation on classical\ncomputers.",
    "descriptor": "\nComments: This worked was published in SC'22\n",
    "authors": [
      "Tirthak Patel",
      "Daniel Silver",
      "Devesh Tiwari"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2211.09903"
  },
  {
    "id": "arXiv:2211.09904",
    "title": "Crossing and intersecting families of geometric graphs on point sets",
    "abstract": "Let $S$ be a set of $n$ points in the plane in general position. Two line\nsegments connecting pairs of points of $S$ cross if they have an interior point\nin common. Two vertex disjoint geometric graphs with vertices in $S$ cross if\nthere are two edges, one from each graph, which cross. A set of vertex disjoint\ngeometric graphs with vertices in $S$ is called mutually crossing if any two of\nthem cross.\nWe show that there exists a constant $c$ such that from any family of $n$\nmutually crossing triangles, one can always obtain a family of at least $n^c$\nmutually crossing $2$-paths (each of which is the result of deleting an edge\nfrom one of the triangles) and then provide an example that implies that $c$\ncannot be taken to be larger than $2/3$. For every $n$ we determine the maximum\nnumber of crossings that a Hamiltonian cycle on a set of $n$ points might have.\nNext, we construct a point set whose longest perfect matching contains no\ncrossings. We also consider edges consisting of a horizontal and a vertical\nline segment joining pairs of points of $S$, which we call elbows, and prove\nthat in any point set $S$ there exists a family of $\\lfloor n/4 \\rfloor$ vertex\ndisjoint mutually crossing elbows. Additionally, we show a point set that\nadmits no more than $n/3$ mutually crossing elbows.\nFinally we study intersecting families of graphs, which are not necessarily\nvertex disjoint. A set of edge disjoint graphs with vertices in $S$ is called\nan intersecting family if for any two graphs in the set we can choose an edge\nin each of them such that they cross. We prove a conjecture by Lara and\nRubio-Montiel, namely, that any set $S$ of $n$ points in general position\nadmits a family of intersecting triangles with a quadratic number of elements.\nSome other results are obtained throughout this work.",
    "descriptor": "\nComments: 19 pages, 14 figures\n",
    "authors": [
      "Jos\u00e9 Luis \u00c1lvarez-Rebollar",
      "Jorge Cravioto-Lagos",
      "Nestaly Mar\u00edn",
      "Oriol Sol\u00e9-Pi",
      "Jorge Urrutia"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2211.09904"
  },
  {
    "id": "arXiv:2211.09908",
    "title": "Escaping From Saddle Points Using Asynchronous Coordinate Gradient  Descent",
    "abstract": "Large-scale non-convex optimization problems are expensive to solve due to\ncomputational and memory costs. To reduce the costs, first-order\n(computationally efficient) and asynchronous-parallel (memory efficient)\nalgorithms are necessary to minimize non-convex functions in machine learning.\nHowever, asynchronous-first-order methods applied within non-convex settings\nrun into two difficulties: (i) parallelization delays, which affect convergence\nby disrupting the monotonicity of first-order methods, and (ii) sub-optimal\nsaddle points where the gradient is zero. To solve these two difficulties, we\npropose an asynchronous-coordinate-gradient-descent algorithm shown to converge\nto local minima with a bounded delay. Our algorithm overcomes\nparallelization-delay issues by using a carefully constructed Hamiltonian\nfunction. We prove that our designed kinetic-energy term, incorporated within\nthe Hamiltonian, allows our algorithm to decrease monotonically per iteration.\nNext, our algorithm steers iterates clear of saddle points by utilizing a\nperturbation sub-routine. Similar to other state-of-the-art (SOTA) algorithms,\nwe achieve a poly-logarithmic convergence rate with respect to dimension.\nUnlike other SOTA algorithms, which are synchronous, our work is the first to\nstudy how parallelization delays affect the convergence rate of asynchronous\nfirst-order algorithms. We prove that our algorithm outperforms synchronous\ncounterparts under large parallelization delays, with convergence depending\nsublinearly with respect to delays. To our knowledge, this is the first local\noptima convergence result of a first-order asynchronous algorithm for\nnon-convex settings.",
    "descriptor": "\nComments: 26 pages, 5 figures\n",
    "authors": [
      "Marco Bornstein",
      "Jin-Peng Liu",
      "Jingling Li",
      "Furong Huang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.09908"
  },
  {
    "id": "arXiv:2211.09912",
    "title": "Do graph neural networks learn traditional jet substructure?",
    "abstract": "At the CERN LHC, the task of jet tagging, whose goal is to infer the origin\nof a jet given a set of final-state particles, is dominated by machine learning\nmethods. Graph neural networks have been used to address this task by treating\njets as point clouds with underlying, learnable, edge connections between the\nparticles inside. We explore the decision-making process for one such\nstate-of-the-art network, ParticleNet, by looking for relevant edge connections\nidentified using the layerwise-relevance propagation technique. As the model is\ntrained, we observe changes in the distribution of relevant edges connecting\ndifferent intermediate clusters of particles, known as subjets. The resulting\ndistribution of subjet connections is different for signal jets originating\nfrom top quarks, whose subjets typically correspond to its three decay\nproducts, and background jets originating from lighter quarks and gluons. This\nbehavior indicates that the model is using traditional jet substructure\nobservables, such as the number of prongs -- energetic particle clusters --\nwithin a jet, when identifying jets.",
    "descriptor": "\nComments: 5 pages, 4 figures. Accepted to Machine Learning for Physical Sciences NeurIPS 2022 workshop\n",
    "authors": [
      "Farouk Mokhtar",
      "Raghav Kansal",
      "Javier Duarte"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Phenomenology (hep-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.09912"
  },
  {
    "id": "arXiv:2211.09917",
    "title": "Inverse Optimal Control with Discount Factor for Continuous and  Discrete-Time Control-Affine Systems and Reinforcement Learning",
    "abstract": "This paper addresses the inverse optimal control problem of finding the state\nweighting function that leads to a quadratic value function when the cost on\nthe input is fixed to be quadratic. The paper focuses on a class of infinite\nhorizon discrete-time and continuous-time optimal control problems whose\ndynamics are control-affine and whose cost is quadratic in the input. The\noptimal control policy for this problem is the projection of minus the gradient\nof the value function onto the space formed by all feasible control directions.\nThis projection points along the control direction of steepest decrease of the\nvalue function. For discrete-time systems and a quadratic value function the\noptimal control law can be obtained as the solution of a regularized least\nsquares program, which corresponds to a receding horizon control with a single\nstep ahead. For the single input case and a quadratic value function the\nsolution for small weights in the control energy is interpreted as a control\npolicy that at each step brings the trajectories of the system as close as\npossible to the origin, as measured by an appropriate norm. Conditions under\nwhich the optimal control law is linear are also stated. Additionally, the\npaper offers a mapping of the optimal control formulation to an equivalent\nreinforcement learning formulation. Examples show the application of the\ntheoretical results.",
    "descriptor": "\nComments: published at IEEE Conference on Decision and Control 2022\n",
    "authors": [
      "Luis Rodrigues"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.09917"
  },
  {
    "id": "arXiv:2211.09920",
    "title": "Distributed Deep Joint Source-Channel Coding over a Multiple Access  Channel",
    "abstract": "We consider distributed image transmission over a noisy multiple access\nchannel (MAC) using deep joint source-channel coding (DeepJSCC). It is known\nthat Shannon's separation theorem holds when transmitting independent sources\nover a MAC in the asymptotic infinite block length regime. However, we are\ninterested in the practical finite block length regime, in which case separate\nsource and channel coding is known to be suboptimal. We introduce a novel joint\nimage compression and transmission scheme, where the devices send their\ncompressed image representations in a non-orthogonal manner. While\nnon-orthogonal multiple access (NOMA) is known to achieve the capacity region,\nto the best of our knowledge, non-orthogonal joint source channel coding (JSCC)\nscheme for practical systems has not been studied before. Through extensive\nexperiments, we show significant improvements in terms of the quality of the\nreconstructed images compared to orthogonal transmission employing current\nDeepJSCC approaches particularly for low bandwidth ratios. We publicly share\nsource code to facilitate further research and reproducibility.",
    "descriptor": "\nComments: 6 pages\n",
    "authors": [
      "Selim F. Yilmaz",
      "Can Karamanli",
      "Deniz Gunduz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.09920"
  },
  {
    "id": "arXiv:2211.09956",
    "title": "A Persian ASR-based SER: Modification of Sharif Emotional Speech  Database and Investigation of Persian Text Corpora",
    "abstract": "Speech Emotion Recognition (SER) is one of the essential perceptual methods\nof humans in understanding the situation and how to interact with others,\ntherefore, in recent years, it has been tried to add the ability to recognize\nemotions to human-machine communication systems. Since the SER process relies\non labeled data, databases are essential for it. Incomplete, low-quality or\ndefective data may lead to inaccurate predictions. In this paper, we fixed the\ninconsistencies in Sharif Emotional Speech Database (ShEMO), as a Persian\ndatabase, by using an Automatic Speech Recognition (ASR) system and\ninvestigating the effect of Farsi language models obtained from accessible\nPersian text corpora. We also introduced a Persian/Farsi ASR-based SER system\nthat uses linguistic features of the ASR outputs and Deep Learning-based\nmodels.",
    "descriptor": "\nComments: 7 pages, 4 figures, 8 tables\n",
    "authors": [
      "Ali Yazdani",
      "Yasser Shekofteh"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.09956"
  },
  {
    "id": "arXiv:2211.09988",
    "title": "Exploring WavLM on Speech Enhancement",
    "abstract": "There is a surge in interest in self-supervised learning approaches for\nend-to-end speech encoding in recent years as they have achieved great success.\nEspecially, WavLM showed state-of-the-art performance on various speech\nprocessing tasks. To better understand the efficacy of self-supervised learning\nmodels for speech enhancement, in this work, we design and conduct a series of\nexperiments with three resource conditions by combining WavLM and two\nhigh-quality speech enhancement systems. Also, we propose a regression-based\nWavLM training objective and a noise-mixing data configuration to further boost\nthe downstream enhancement performance. The experiments on the DNS challenge\ndataset and a simulation dataset show that the WavLM benefits the speech\nenhancement task in terms of both speech quality and speech recognition\naccuracy, especially for low fine-tuning resources. For the high fine-tuning\nresource condition, only the word error rate is substantially improved.",
    "descriptor": "\nComments: Accepted by IEEE SLT 2022\n",
    "authors": [
      "Hyungchan Song",
      "Sanyuan Chen",
      "Zhuo Chen",
      "Yu Wu",
      "Takuya Yoshioka",
      "Min Tang",
      "Jong Won Shin",
      "Shujie Liu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.09988"
  },
  {
    "id": "arXiv:2211.10013",
    "title": "Active Learning by Query by Committee with Robust Divergences",
    "abstract": "Active learning is a widely used methodology for various problems with high\nmeasurement costs. In active learning, the next object to be measured is\nselected by an acquisition function, and measurements are performed\nsequentially. The query by committee is a well-known acquisition function. In\nconventional methods, committee disagreement is quantified by the\nKullback--Leibler divergence. In this paper, the measure of disagreement is\ndefined by the Bregman divergence, which includes the Kullback--Leibler\ndivergence as an instance, and the dual $\\gamma$-power divergence. As a\nparticular class of the Bregman divergence, the $\\beta$-divergence is\nconsidered. By deriving the influence function, we show that the proposed\nmethod using $\\beta$-divergence and dual $\\gamma$-power divergence are more\nrobust than the conventional method in which the measure of disagreement is\ndefined by the Kullback--Leibler divergence. Experimental results show that the\nproposed method performs as well as or better than the conventional method.",
    "descriptor": "",
    "authors": [
      "Hideitsu Hino",
      "Shinto Eguchi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10013"
  },
  {
    "id": "arXiv:2211.10015",
    "title": "Asymptotics for The $k$-means",
    "abstract": "The $k$-means is one of the most important unsupervised learning techniques\nin statistics and computer science. The goal is to partition a data set into\nmany clusters, such that observations within clusters are the most homogeneous\nand observations between clusters are the most heterogeneous. Although it is\nwell known, the investigation of the asymptotic properties is far behind,\nleading to difficulties in developing more precise $k$-means methods in\npractice. To address this issue, a new concept called clustering consistency is\nproposed. Fundamentally, the proposed clustering consistency is more\nappropriate than the previous criterion consistency for the clustering methods.\nUsing this concept, a new $k$-means method is proposed. It is found that the\nproposed $k$-means method has lower clustering error rates and is more robust\nto small clusters and outliers than existing $k$-means methods. When $k$ is\nunknown, using the Gap statistics, the proposed method can also identify the\nnumber of clusters. This is rarely achieved by existing $k$-means methods\nadopted by many software packages.",
    "descriptor": "\nComments: Manuscript\n",
    "authors": [
      "Tonglin Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10015"
  },
  {
    "id": "arXiv:2211.10026",
    "title": "DGD-cGAN: A Dual Generator for Image Dewatering and Restoration",
    "abstract": "Underwater images are usually covered with a blue-greenish colour cast,\nmaking them distorted, blurry or low in contrast. This phenomenon occurs due to\nthe light attenuation given by the scattering and absorption in the water\ncolumn. In this paper, we present an image enhancement approach for dewatering\nwhich employs a conditional generative adversarial network (cGAN) with two\ngenerators. Our Dual Generator Dewatering cGAN (DGD-cGAN) removes the haze and\ncolour cast induced by the water column and restores the true colours of\nunderwater scenes whereby the effects of various attenuation and scattering\nphenomena that occur in underwater images are tackled by the two generators.\nThe first generator takes at input the underwater image and predicts the\ndewatered scene, while the second generator learns the underwater image\nformation process by implementing a custom loss function based upon the\ntransmission and the veiling light components of the image formation model. Our\nexperiments show that DGD-cGAN consistently delivers a margin of improvement as\ncompared with the state-of-the-art methods on several widely available\ndatasets.",
    "descriptor": "\nComments: 12 pages and 61 images\n",
    "authors": [
      "Salma Gonzalez-Sabbagh",
      "Antonio Robles-Kelly",
      "Shang Gao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10026"
  },
  {
    "id": "arXiv:2211.10049",
    "title": "Recent Advances in Algebraic Geometry and Bayesian Statistics",
    "abstract": "This article is a review of theoretical advances in the research field of\nalgebraic geometry and Bayesian statistics in the last two decades. Many\nstatistical models and learning machines which contain hierarchical structures\nor latent variables are called nonidentifiable, because the map from a\nparameter to a statistical model is not one-to-one. In nonidentifiable models,\nboth the likelihood function and the posterior distribution have singularities\nin general, hence it was difficult to analyze their statistical properties.\nHowever, from the end of the 20th century, new theory and methodology based on\nalgebraic geometry have been established which enables us to investigate such\nmodels and machines in the real world. In this article, the following results\nin recent advances are reported. First, we explain the framework of Bayesian\nstatistics and introduce a new perspective from the birational geometry.\nSecond, two mathematical solutions are derived based on algebraic geometry. An\nappropriate parameter space can be found by a resolution map, which makes the\nposterior distribution be normal crossing and the log likelihood ratio function\nbe well-defined. Third, three applications to statistics are introduced. The\nposterior distribution is represented by the renormalized form, the asymptotic\nfree energy is derived, and the universal formula among the generalization\nloss, the cross validation, and the information criterion is established. Two\nmathematical solutions and three applications to statistics based on algebraic\ngeometry reported in this article are now being used in many practical fields\nin data science and artificial intelligence.",
    "descriptor": "",
    "authors": [
      "Sumio Watanabe"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10049"
  },
  {
    "id": "arXiv:2211.10061",
    "title": "Data-Adaptive Discriminative Feature Localization with Statistically  Guaranteed Interpretation",
    "abstract": "In explainable artificial intelligence, discriminative feature localization\nis critical to reveal a blackbox model's decision-making process from raw data\nto prediction. In this article, we use two real datasets, the MNIST handwritten\ndigits and MIT-BIH Electrocardiogram (ECG) signals, to motivate key\ncharacteristics of discriminative features, namely adaptiveness, predictive\nimportance and effectiveness. Then, we develop a localization framework based\non adversarial attacks to effectively localize discriminative features. In\ncontrast to existing heuristic methods, we also provide a statistically\nguaranteed interpretability of the localized features by measuring a\ngeneralized partial $R^2$. We apply the proposed method to the MNIST dataset\nand the MIT-BIH dataset with a convolutional auto-encoder. In the first, the\ncompact image regions localized by the proposed method are visually appealing.\nSimilarly, in the second, the identified ECG features are biologically\nplausible and consistent with cardiac electrophysiological principles while\nlocating subtle anomalies in a QRS complex that may not be discernible by the\nnaked eye. Overall, the proposed method compares favorably with\nstate-of-the-art competitors. Accompanying this paper is a Python library\ndnn-locate (https://dnn-locate.readthedocs.io/en/latest/) that implements the\nproposed approach.",
    "descriptor": "\nComments: 27 pages, 11 figures\n",
    "authors": [
      "Ben Dai",
      "Xiaotong Shen",
      "Lin Yee Chen",
      "Chunlin Li",
      "Wei Pan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.10061"
  },
  {
    "id": "arXiv:2211.10070",
    "title": "An Energy-Conserving Fourier Particle-in-Cell Method with  Asymptotic-Preserving Preconditioner for Vlasov-Amp\u00e8re System with Exact  Curl-Free Constraint",
    "abstract": "We present an efficient and accurate energy-conserving implicit\nparticle-in-cell~(PIC) algorithm for the electrostatic Vlasov system, with\nparticular emphasis on its high robustness for simulating complex plasma\nsystems with multiple physical scales. This method consists of several\nindispensable elements: (\\romannumeral1) the reformulation of the original\nVlasov-Poisson system into an equivalent Vlasov-Amp\\`ere system with\ndivergence-/curl-free constraints; (\\romannumeral2) a novel\nstructure-preserving Fourier spatial discretization, which exactly preserves\nthese constraints at the discrete level; (\\romannumeral3) a preconditioned\nAnderson-acceleration algorithm for the solution of the highly nonlinear\nsystem; and (\\romannumeral4) a linearized and uniform approximation of the\nimplicit Crank-Nicolson scheme for various Debye lengths, based on the\ngeneralized Ohm's law, which serves as an asymptotic-preserving preconditioner\nfor the proposed method. Numerical experiments are conducted, and comparisons\nare made among the proposed energy-conserving scheme, the classical leapfrog\nscheme, and a Strang operator-splitting scheme to demonstrate the superiority\nof the proposed method, especially for plasma systems crossing physical scales.",
    "descriptor": "\nComments: 32 pages, 10 figures\n",
    "authors": [
      "Zhuoning Li",
      "Zhenli Xu",
      "Zhiguo Yang"
    ],
    "subjectives": [
      "Computational Physics (physics.comp-ph)",
      "Numerical Analysis (math.NA)",
      "Plasma Physics (physics.plasm-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.10070"
  },
  {
    "id": "arXiv:2211.10124",
    "title": "Global quantitative robustness of regression feed-forward neural  networks",
    "abstract": "Neural networks are an indispensable model class for many complex learning\ntasks. Despite the popularity and importance of neural networks and many\ndifferent established techniques from literature for stabilization and\nrobustification of the training, the classical concepts from robust statistics\nhave rarely been considered so far in the context of neural networks.\nTherefore, we adapt the notion of the regression breakdown point to regression\nneural networks and compute the breakdown point for different feed-forward\nnetwork configurations and contamination settings. In an extensive simulation\nstudy, we compare the performance, measured by the out-of-sample loss, by a\nproxy of the breakdown rate and by the training steps, of non-robust and robust\nregression feed-forward neural networks in a plethora of different\nconfigurations. The results indeed motivate to use robust loss functions for\nneural network training.",
    "descriptor": "",
    "authors": [
      "Tino Werner"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10124"
  },
  {
    "id": "arXiv:2211.10138",
    "title": "Joint nnU-Net and Radiomics Approaches for Segmentation and Prognosis of  Head and Neck Cancers with PET/CT images",
    "abstract": "Automatic segmentation of head and neck cancer (HNC) tumors and lymph nodes\nplays a crucial role in the optimization treatment strategy and prognosis\nanalysis. This study aims to employ nnU-Net for automatic segmentation and\nradiomics for recurrence-free survival (RFS) prediction using pretreatment\nPET/CT images in multi-center HNC cohort. A multi-center HNC dataset with 883\npatients (524 patients for training, 359 for testing) was provided in HECKTOR\n2022. A bounding box of the extended oropharyngeal region was retrieved for\neach patient with fixed size of 224 x 224 x 224 $mm^{3}$. Then 3D nnU-Net\narchitecture was adopted to automatic segmentation of primary tumor and lymph\nnodes synchronously.Based on predicted segmentation, ten conventional features\nand 346 standardized radiomics features were extracted for each patient. Three\nprognostic models were constructed containing conventional and radiomics\nfeatures alone, and their combinations by multivariate CoxPH modelling. The\nstatistical harmonization method, ComBat, was explored towards reducing\nmulticenter variations. Dice score and C-index were used as evaluation metrics\nfor segmentation and prognosis task, respectively. For segmentation task, we\nachieved mean dice score around 0.701 for primary tumor and lymph nodes by 3D\nnnU-Net. For prognostic task, conventional and radiomics models obtained the\nC-index of 0.658 and 0.645 in the test set, respectively, while the combined\nmodel did not improve the prognostic performance with the C-index of 0.648.",
    "descriptor": "",
    "authors": [
      "Hui Xu",
      "Yihao Li",
      "Wei Zhao",
      "Gwenol\u00e9 Quellec",
      "Lijun Lu",
      "Mathieu Hatt"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10138"
  },
  {
    "id": "arXiv:2211.10152",
    "title": "Self-Transriber: Few-shot Lyrics Transcription with Self-training",
    "abstract": "The current lyrics transcription approaches heavily rely on supervised\nlearning with labeled data, but such data are scarce and manual labeling of\nsinging is expensive. How to benefit from unlabeled data and alleviate limited\ndata problem have not been explored for lyrics transcription. We propose the\nfirst semi-supervised lyrics transcription paradigm, Self-Transcriber, by\nleveraging on unlabeled data using self-training with noisy student\naugmentation. We attempt to demonstrate the possibility of lyrics transcription\nwith a few amount of labeled data. Self-Transcriber generates pseudo labels of\nthe unlabeled singing using teacher model, and augments pseudo-labels to the\nlabeled data for student model update with both self-training and supervised\ntraining losses. This work closes the gap between supervised and\nsemi-supervised learning as well as opens doors for few-shot learning of lyrics\ntranscription. Our experiments show that our approach using only 12.7 hours of\nlabeled data achieves competitive performance compared with the supervised\napproaches trained on 149.1 hours of labeled data for lyrics transcription.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Xiaoxue Gao",
      "Xianghu Yue",
      "Haizhou Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.10152"
  },
  {
    "id": "arXiv:2211.10194",
    "title": "Self-Remixing: Unsupervised Speech Separation via Separation and  Remixing",
    "abstract": "We present Self-Remixing, a novel self-supervised speech separation method,\nwhich refines a pre-trained separation model in an unsupervised manner. The\nproposed method consists of a shuffler module and a solver module, and they\ngrow together through separation and remixing processes. Specifically, the\nshuffler first separates observed mixtures and makes pseudo-mixtures by\nshuffling and remixing the separated signals. The solver then separates the\npseudo-mixtures and remixes the separated signals back to the observed\nmixtures. The solver is trained using the observed mixtures as supervision,\nwhile the shuffler's weights are updated by taking the moving average with the\nsolver's, generating the pseudo-mixtures with fewer distortions. Our\nexperiments demonstrate that Self-Remixing gives better performance over\nexisting remixing-based self-supervised methods with the same or less training\ncosts under unsupervised setup. Self-Remixing also outperforms baselines in\nsemi-supervised domain adaptation, showing effectiveness in multiple setups.",
    "descriptor": "\nComments: Submitted to ICASSP2023, 5pages, 2figures, 2tables\n",
    "authors": [
      "Kohei Saijo",
      "Tetsuji Ogawa"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.10194"
  },
  {
    "id": "arXiv:2211.10211",
    "title": "Lagrangian stochastic model for the orientation of inertialess non  spherical particles in turbulent flows: an efficient numerical method for CFD  approach",
    "abstract": "In this work, we propose a model for the orientation of non-spherical\nparticles arising in multi-phase turbulence flow. This model addresses the\nmacroscopic scale in use in CFD codes enabling turbulence models for the fluid\nphase. It consists in a stochastic version of the Jeffery equation that can be\nincorporated in a statistical Lagrangian description of the particles suspended\nin the flow. For use in this context, we propose and analyse a numerical scheme\nbased on the well-known splitting scheme algorithm decoupling the orientation\ndynamics into their main contributions: stretching and rotation. We detail the\nimplementation in an open-source CFD software. We analyse the weak and strong\nconvergence both of the global scheme and of their sub-parts. Subsequently, the\nsplitting technique yields to a highly efficient hybrid algorithm coupling pure\nprobabilistic and deterministic numerical schemes. Various experiments were\nimplemented and compared with analytic predictions of the model to test the\nscheme for use in a CFD code.",
    "descriptor": "",
    "authors": [
      "Lorenzo Campana",
      "Mireille Bossy",
      "Christophe Henry"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.10211"
  },
  {
    "id": "arXiv:2211.10245",
    "title": "On the inadequacy of nominal assortativity for assessing homophily in  networks",
    "abstract": "Nominal assortativity (or discrete assortativity) is widely used to\ncharacterize group mixing patterns in networks, enabling researchers to analyze\nhow groups interact with one another. Here we demonstrate that the measure\npresents severe shortcomings when applied to networks with unequal group sizes\nand asymmetric mixing. We characterize these shortcomings analytically and use\nsynthetic and empirical networks to show that nominal assortativity fails to\naccount for group imbalance and asymmetric group interactions, thereby\nproducing an inaccurate characterization of mixing patterns. We propose the\nadjusted nominal assortativity and show that this adjustment recovers the\nexpected assortativity in networks with various level of mixing. Furthermore,\nwe propose an analytical method to assess asymmetric mixing by estimating the\ntendency of inter- and intra-group connectivities. Finally, we discuss how this\napproach enables uncovering hidden mixing patterns in real-world networks.",
    "descriptor": "\nComments: 17 pages, 3 figures\n",
    "authors": [
      "Fariba Karimi",
      "Marcos Oliveira"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Computers and Society (cs.CY)",
      "Social and Information Networks (cs.SI)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.10245"
  },
  {
    "id": "arXiv:2211.10295",
    "title": "On the Evaluation of Generative Models in High Energy Physics",
    "abstract": "There has been a recent explosion in research into machine-learning-based\ngenerative modeling to tackle computational challenges for simulations in high\nenergy physics (HEP). In order to use such alternative simulators in practice,\nwe need well defined metrics to compare different generative models and\nevaluate their discrepancy from the true distributions. We present the first\nsystematic review and investigation into evaluation metrics and their\nsensitivity to failure modes of generative models, using the framework of\ntwo-sample goodness-of-fit testing, and their relevance and viability for HEP.\nInspired by previous work in both physics and computer vision, we propose two\nnew metrics, the Fr\\'echet and kernel physics distances (FPD and KPD), and\nperform a variety of experiments measuring their performance on simple\nGaussian-distributed, and simulated high energy jet datasets. We find FPD, in\nparticular, to be the most sensitive metric to all alternative jet\ndistributions tested and recommend its adoption, along with the KPD and\nWasserstein distances between individual feature distributions, for evaluating\ngenerative models in HEP. We finally demonstrate the efficacy of these proposed\nmetrics in evaluating and comparing a novel attention-based generative\nadversarial particle transformer to the state-of-the-art message-passing\ngenerative adversarial network jet simulation model.",
    "descriptor": "\nComments: 11 pages, 5 figures, 3 tables, and a 3 page appenidx\n",
    "authors": [
      "Raghav Kansal",
      "Anni Li",
      "Javier Duarte",
      "Nadezda Chernyavskaya",
      "Maurizio Pierini",
      "Breno Orzari",
      "Thiago Tomei"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.10295"
  },
  {
    "id": "arXiv:2211.10305",
    "title": "Neural Inference of Gaussian Processes for Time Series Data of Quasars",
    "abstract": "The study of quasar light curves poses two problems: inference of the power\nspectrum and interpolation of an irregularly sampled time series. A baseline\napproach to these tasks is to interpolate a time series with a Damped Random\nWalk (DRW) model, in which the spectrum is inferred using Maximum Likelihood\nEstimation (MLE). However, the DRW model does not describe the smoothness of\nthe time series, and MLE faces many problems in terms of optimization and\nnumerical precision. In this work, we introduce a new stochastic model that we\ncall $\\textit{Convolved Damped Random Walk}$ (CDRW). This model introduces a\nconcept of smoothness to a DRW, which enables it to describe quasar spectra\ncompletely. We also introduce a new method of inference of Gaussian process\nparameters, which we call $\\textit{Neural Inference}$. This method uses the\npowers of state-of-the-art neural networks to improve the conventional MLE\ninference technique. In our experiments, the Neural Inference method results in\nsignificant improvement over the baseline MLE (RMSE: $0.318 \\rightarrow 0.205$,\n$0.464 \\rightarrow 0.444$). Moreover, the combination of both the CDRW model\nand Neural Inference significantly outperforms the baseline DRW and MLE in\ninterpolating a typical quasar light curve ($\\chi^2$: $0.333 \\rightarrow\n0.998$, $2.695 \\rightarrow 0.981$). The code is published on GitHub.",
    "descriptor": "\nComments: Machine Learning and the Physical Sciences workshop, NeurIPS 2022\n",
    "authors": [
      "Egor Danilov",
      "Aleksandra \u0106iprijanovi\u0107",
      "Brian Nord"
    ],
    "subjectives": [
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10305"
  },
  {
    "id": "arXiv:2211.10331",
    "title": "A greedy randomized average block projection method for linear  feasibility problems",
    "abstract": "The randomized projection (RP) method is a simple iterative scheme for\nsolving linear feasibility problems and has recently gained popularity due to\nits speed and low memory requirement. This paper develops an accelerated\nvariant of the standard RP method by using two ingredients: the greedy\nprobability criterion and the average block approach, and obtains a greedy\nrandomized average block projection (GRABP) method for solving large-scale\nsystems of linear inequalities. We prove that this method converges linearly in\nexpectation under different choices of extrapolated stepsizes. Numerical\nexperiments on both randomly generated and real-world data show the advantage\nof GRABP over several state-of-the-art solvers, such as the randomized\nprojection (RP) method, the sampling Kaczmarz Motzkin (SKM) method, the\ngeneralized SKM (GSKM) method, and the Nesterov acceleration of SKM method.",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Lin Zhu",
      "Yuan Lei",
      "Jiaxin Xie"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.10331"
  },
  {
    "id": "arXiv:2211.10335",
    "title": "Large Scale Radio Frequency Wideband Signal Detection & Recognition",
    "abstract": "Applications of deep learning to the radio frequency (RF) domain have largely\nconcentrated on the task of narrowband signal classification after the signals\nof interest have already been detected and extracted from a wideband capture.\nTo encourage broader research with wideband operations, we introduce the\nWidebandSig53 (WBSig53) dataset which consists of 550 thousand\nsynthetically-generated samples from 53 different signal classes containing\napproximately 2 million unique signals. We extend the TorchSig signal\nprocessing machine learning toolkit for open-source and customizable\ngeneration, augmentation, and processing of the WBSig53 dataset. We conduct\nexperiments using state of the art (SoTA) convolutional neural networks and\ntransformers with the WBSig53 dataset. We investigate the performance of signal\ndetection tasks, i.e. detect the presence, time, and frequency of all signals\npresent in the input data, as well as the performance of signal recognition\ntasks, where networks detect the presence, time, frequency, and modulation\nfamily of all signals present in the input data. Two main approaches to these\ntasks are evaluated with segmentation networks and object detection networks\noperating on complex input spectrograms. Finally, we conduct comparative\nanalysis of the various approaches in terms of the networks' mean average\nprecision, mean average recall, and the speed of inference.",
    "descriptor": "",
    "authors": [
      "Luke Boegner",
      "Garrett Vanhoy",
      "Phillip Vallance",
      "Manbir Gulati",
      "Dresden Feitzinger",
      "Bradley Comar",
      "Robert D. Miller"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10335"
  },
  {
    "id": "arXiv:2211.10351",
    "title": "Deep learning for structural health monitoring: An application to  heritage structures",
    "abstract": "Thanks to recent advancements in numerical methods, computer power, and\nmonitoring technology, seismic ambient noise provides precious information\nabout the structural behavior of old buildings. The measurement of the\nvibrations produced by anthropic and environmental sources and their use for\ndynamic identification and structural health monitoring of buildings initiated\nan emerging, cross-disciplinary field engaging seismologists, engineers,\nmathematicians, and computer scientists. In this work, we employ recent deep\nlearning techniques for time-series forecasting to inspect and detect anomalies\nin the large dataset recorded during a long-term monitoring campaign conducted\non the San Frediano bell tower in Lucca. We frame the problem as an\nunsupervised anomaly detection task and train a Temporal Fusion Transformer to\nlearn the normal dynamics of the structure. We then detect the anomalies by\nlooking at the differences between the predicted and observed frequencies.",
    "descriptor": "",
    "authors": [
      "Fabio Carrara",
      "Fabrizio Falchi",
      "Maria Girardi",
      "Nicola Messina",
      "Cristina Padovani",
      "Daniele Pellegrini"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10351"
  },
  {
    "id": "arXiv:2211.10352",
    "title": "Towards Fast Single-Trial Online ERP based Brain-Computer Interface  using dry EEG electrodes and neural networks: a pilot study",
    "abstract": "Speeding up the spelling in event-related potentials (ERP) based\nBrain-Computer Interfaces (BCI) requires eliciting strong brain responses in a\nshort span of time, as much as the accurate classification of such evoked\npotentials remains challenging and imposes hard constraints for signal\nprocessing and machine learning techniques. Recent advances in stimulus\npresentation and deep learning showcased a promising direction in significantly\nimproving the efficacy of those systems, in this study we propose the\ncombination of colored inverted face stimulation with classification using\nconvolutional neural networks in the hard settings of dry electrodes and fast\nflashing single-trial ERP-based BCI. The high online accuracy achieved, with\ntwo subjects passing the 90 percent correct symbol detection bar and a transfer\nrate above 60 bits per minute, demonstrates the approach potential in improving\nthe practicality of ERP based BCIs.",
    "descriptor": "\nComments: 24 pages, 9 figures\n",
    "authors": [
      "Okba Bekhelifi",
      "Nasr-Eddine Berrached"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10352"
  },
  {
    "id": "arXiv:2211.10354",
    "title": "CRONOS: Colorization and Contrastive Learning Enhanced NLoS Human  Presence Detection using Wi-Fi CSI Signals",
    "abstract": "In recent years, demands of pervasive smart services and applications\nincrease explosively. Device-free human detection through sensors or cameras\nhas been widely adopted but with privacy issues as well as misdetection for\nmotionless people. To resolve these defects, channel state information (CSI)\ncaptured from commercialized Wi-Fi devices is capable of providing plentiful\nsignal features for accurate detection. The existing systems has inaccurate\nclassification under a non-line-of-sight (NLoS) and stationery scenario of a\nperson standing still at corner in a room. In this work, we have proposed a\ncolorization and contrastive learning enhanced NLoS human presence detection\n(CRONOS) system. CRONOS is capable of generating dynamic recurrence plots (RPs)\nand coloring CSI ratios to distinguish mobile people and vacancy of a room,\nrespectively. Furthermore, supervised contrastive learning is conceived to\nretrieve substantial representations, where consultation loss is formulated to\ndifferentiate the representative distances between dynamic and stationery\ncases. Furthermore, a self-switched static feature enhanced classifier (S3FEC)\nis proposed to determine the utilization of either RPs or coloring CSI ratio.\nFinally, comprehensive experimental results have revealed that our proposed\nCRONOS outperforms the existing systems applying machine learning, non-learning\nbased methods as well as non-CSI based features in open literature, which\nachieves the highest presence detection accuracy and moderate computational\ncomplexity in vacancy, mobility, LoS and NLoS scenarios.",
    "descriptor": "",
    "authors": [
      "Li-Hsiang Shen",
      "Chia-Che Hsieh",
      "An-Hung Hsiao",
      "Kai-Ten Feng"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10354"
  },
  {
    "id": "arXiv:2211.10355",
    "title": "Discriminating sensor activation in activity recognition within  multi-occupancy environments based on nearby interaction",
    "abstract": "This work presents a computer model to discriminate sensor activation in\nmulti-occupancy environments based on proximity interaction. Current\nproximity-based and indoor location methods allow the estimation of the\npositions or areas where inhabitants carry out their daily human activities.\nThe spatial-temporal relation between location and sensor activations is\ndescribed in this work to generate a sensor interaction matrix for each\ninhabitant. This enables the use of classical HAR models to reduce the\ncomplexity of the multi-occupancy problem. A case study deployed with UWB and\nbinary sensors is presented.",
    "descriptor": "\nComments: 10 pages, 6 figures, 1 table\n",
    "authors": [
      "Aurora Polo-Rodriguez",
      "Javier Medina-Quero"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.10355"
  },
  {
    "id": "arXiv:2211.10363",
    "title": "Always Valid Risk Monitoring for Online Matrix Completion",
    "abstract": "Always-valid concentration inequalities are increasingly used as performance\nmeasures for online statistical learning, notably in the learning of generative\nmodels and supervised learning. Such inequality advances the online learning\nalgorithms design by allowing random, adaptively chosen sample sizes instead of\na fixed pre-specified size in offline statistical learning. However,\nestablishing such an always-valid type result for the task of matrix completion\nis challenging and far from understood in the literature. Due to the importance\nof such type of result, this work establishes and devises the always-valid risk\nbound process for online matrix completion problems. Such theoretical advances\nare made possible by a novel combination of non-asymptotic martingale\nconcentration and regularized low-rank matrix regression. Our result enables a\nmore sample-efficient online algorithm design and serves as a foundation to\nevaluate online experiment policies on the task of online matrix completion.",
    "descriptor": "",
    "authors": [
      "Chi-Hua Wang",
      "Wenjie Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2211.10363"
  },
  {
    "id": "arXiv:2211.10371",
    "title": "Heterogeneous Hidden Markov Models for Sleep Activity Recognition from  Multi-Source Passively Sensed Data",
    "abstract": "Psychiatric patients' passive activity monitoring is crucial to detect\nbehavioural shifts in real-time, comprising a tool that helps clinicians\nsupervise patients' evolution over time and enhance the associated treatments'\noutcomes. Frequently, sleep disturbances and mental health deterioration are\nclosely related, as mental health condition worsening regularly entails shifts\nin the patients' circadian rhythms. Therefore, Sleep Activity Recognition\nconstitutes a behavioural marker to portray patients' activity cycles and to\ndetect behavioural changes among them. Moreover, mobile passively sensed data\ncaptured from smartphones, thanks to these devices' ubiquity, constitute an\nexcellent alternative to profile patients' biorhythm.\nIn this work, we aim to identify major sleep episodes based on passively\nsensed data. To do so, a Heterogeneous Hidden Markov Model is proposed to model\na discrete latent variable process associated with the Sleep Activity\nRecognition task in a self-supervised way. We validate our results against\nsleep metrics reported by clinically tested wearables, proving the\neffectiveness of the proposed approach.",
    "descriptor": "\nComments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 10 pages (6 pages + 4 pages of references and appendices)\n",
    "authors": [
      "Fernando Moreno-Pino",
      "Mar\u00eda Mart\u00ednez-Garc\u00eda",
      "Pablo M. Olmos",
      "Antonio Art\u00e9s-Rodr\u00edguez"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10371"
  },
  {
    "id": "arXiv:2211.10379",
    "title": "Arbitrarily Accurate Classification Applied to Specific Emitter  Identification",
    "abstract": "This article introduces a method of evaluating subsamples until any\nprescribed level of classification accuracy is attained, thus obtaining\narbitrary accuracy. A logarithmic reduction in error rate is obtained with a\nlinear increase in sample count. The technique is applied to specific emitter\nidentification on a published dataset of physically recorded over-the-air\nsignals from 16 ostensibly identical high-performance radios. The technique\nuses a multi-channel deep learning convolutional neural network acting on the\nbispectra of I/Q signal subsamples each consisting of 56 parts per million\n(ppm) of the original signal duration. High levels of accuracy are obtained\nwith minimal computation time: in this application, each addition of eight\nsamples decreases error by one order of magnitude.",
    "descriptor": "",
    "authors": [
      "Michael C. Kleder"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10379"
  },
  {
    "id": "arXiv:2211.10381",
    "title": "Active Learning with Convolutional Gaussian Neural Processes for  Environmental Sensor Placement",
    "abstract": "Deploying environmental measurement stations can be a costly and time\nconsuming procedure, especially in regions which are remote or otherwise\ndifficult to access, such as Antarctica. Therefore, it is crucial that sensors\nare placed as efficiently as possible, maximising the informativeness of their\nmeasurements. Previous approaches for identifying salient placement locations\ntypically model the data with a Gaussian process (GP). However, designing a GP\ncovariance which captures the complex behaviour of non-stationary\nspatiotemporal data is a difficult task. Further, the computational cost of\nthese models make them challenging to scale to large environmental datasets. In\nthis work, we explore using convolutional Gaussian neural processes (ConvGNPs)\nto address these issues. A ConvGNP is a meta-learning model which uses a neural\nnetwork to parameterise a GP predictive. Our model is data-driven, flexible,\nefficient, and permits gridded or off-grid input data. Using simulated surface\ntemperature fields over Antarctica as ground truth, we show that a ConvGNP\nsubstantially outperforms a non-stationary GP baseline in terms of predictive\nperformance. We then use the ConvGNP in a temperature sensor placement toy\nexperiment, yielding promising results.",
    "descriptor": "\nComments: Accepted to the NeurIPS 2022 Workshop on Gaussian Processes, Spatiotemporal Modeling, and Decision-making Systems\n",
    "authors": [
      "Tom R. Andersson",
      "Wessel P. Bruinsma",
      "Stratis Markou",
      "Daniel C. Jones",
      "J. Scott Hosking",
      "James Requeima",
      "Alejandro Coca-Castro",
      "Anna Vaughan",
      "Anna-Louise Ellis",
      "Matthew Lazzara",
      "Richard E. Turner"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10381"
  },
  {
    "id": "arXiv:2211.10388",
    "title": "Patch-Based Denoising Diffusion Probabilistic Model for Sparse-View CT  Reconstruction",
    "abstract": "Sparse-view computed tomography (CT) can be used to reduce radiation dose\ngreatly but is suffers from severe image artifacts. Recently, the deep learning\nbased method for sparse-view CT reconstruction has attracted a major attention.\nHowever, neural networks often have a limited ability to remove the artifacts\nwhen they only work in the image domain. Deep learning-based sinogram\nprocessing can achieve a better anti-artifact performance, but it inevitably\nrequires feature maps of the whole image in a video memory, which makes\nhandling large-scale or three-dimensional (3D) images rather challenging. In\nthis paper, we propose a patch-based denoising diffusion probabilistic model\n(DDPM) for sparse-view CT reconstruction. A DDPM network based on patches\nextracted from fully sampled projection data is trained and then used to\ninpaint down-sampled projection data. The network does not require paired\nfull-sampled and down-sampled data, enabling unsupervised learning. Since the\ndata processing is patch-based, the deep learning workflow can be distributed\nin parallel, overcoming the memory problem of large-scale data. Our experiments\nshow that the proposed method can effectively suppress few-view artifacts while\nfaithfully preserving textural details.",
    "descriptor": "",
    "authors": [
      "Wenjun Xia",
      "Wenxiang Cong",
      "Ge Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.10388"
  },
  {
    "id": "arXiv:2211.10400",
    "title": "On Weakly Hausdorff Spaces and Locally Strongly Sober Spaces",
    "abstract": "We show that the locally strongly sober spaces are exactly the coherent sober\nspaces that are weakly Hausdorff in the sense of Keimel and Lawson. This allows\nus to describe their Stone duals explicitly. As another application, we show\nthat weak Hausdorffness is a sufficient condition for lenses and of\nquasi-lenses to form homeomorphic spaces, generalizing previously known\nresults.",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Jean Goubault-Larrecq"
    ],
    "subjectives": [
      "General Topology (math.GN)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.10400"
  },
  {
    "id": "arXiv:2211.10415",
    "title": "Intelligent Reflecting Surface assisted Integrated Sensing and  Communication System",
    "abstract": "High-speed communication and accurate sensing are of vital importance for\nfuture transportation system. Integrated sensing and communication (ISAC)\nsystem has the advantages of high spectrum efficiency and low hardware cost,\nsatisfying the requirements of sensing and communication. Therefore, ISAC is\nconsidered to be a promising technology in the future transportation system.\nHowever, due to the low transmit power of signal and the influence of harsh\ntransmission environment on radar sensing, the signal to noise ratio (SNR) at\nthe radar receiver is low, which affects the sensing performance. This paper\nintroduces the intelligent reflecting surface (IRS) into ISAC system. With IRS\ncomposed of M sub-surfaces implemented on the surface of the target. The SNR at\nthe radar receiver is 20lg(M) times larger than the scheme without IRS.\nCorrespondingly, radar detection probability is significantly improved, and\nCramer-Rao Lower Bound (CRLB) for ranging and velocity estimation is reduced.\nThis paper proves the efficiency of IRS enabled ISAC system, which motivates\nthe implementation of IRS to enhance the sensing capability in ISAC system.",
    "descriptor": "",
    "authors": [
      "Zhiqing Wei",
      "Xinyi Yang",
      "Chunwei Meng",
      "Xiaoyu Yang",
      "Kaifeng Han",
      "Chen Qiu",
      "Huici Wu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2211.10415"
  },
  {
    "id": "arXiv:2211.10418",
    "title": "Sample-efficient Quantum Born Machine through Coding Rate Reduction",
    "abstract": "The quantum circuit Born machine (QCBM) is a quantum physics inspired\nimplicit generative model naturally suitable for learning binary images, with a\npotential advantage of modeling discrete distributions that are hard to\nsimulate classically. As data samples are generated quantum-mechanically, QCBMs\nencompass a unique optimization landscape. However, pioneering works on QCBMs\ndo not consider the practical scenario where only small batch sizes are allowed\nduring training. QCBMs trained with a statistical two-sample test objective in\nthe image space require large amounts of projective measurements to approximate\nthe model distribution well, unpractical for large-scale quantum systems due to\nthe exponential scaling of the probability space. QCBMs trained adversarially\nagainst a deep neural network discriminator are proof-of-concept models that\nface mode collapse. In this work we investigate practical learning of QCBMs. We\nuse the information-theoretic \\textit{Maximal Coding Rate Reduction} (MCR$^2$)\nmetric as a second moment matching tool and study its effect on mode collapse\nin QCBMs. We compute the sampling based gradient of MCR$^2$ with respect to\nquantum circuit parameters with or without an explicit feature mapping. We\nexperimentally show that matching up to the second moment alone is not\nsufficient for training the quantum generator, but when combined with the class\nprobability estimation loss, MCR$^2$ is able to resist mode collapse. In\naddition, we show that adversarially trained neural network kernel for infinite\nmoment matching is also effective against mode collapse. On the Bars and\nStripes dataset, our proposed techniques alleviate mode collapse to a larger\ndegree than previous QCBM training schemes, moving one step closer towards\npracticality and scalability.",
    "descriptor": "",
    "authors": [
      "Pengyuan Zhai"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10418"
  },
  {
    "id": "arXiv:2211.10419",
    "title": "A Neural Active Inference Model of Perceptual-Motor Learning",
    "abstract": "The active inference framework (AIF) is a promising new computational\nframework grounded in contemporary neuroscience that can produce human-like\nbehavior through reward-based learning. In this study, we test the ability for\nthe AIF to capture the role of anticipation in the visual guidance of action in\nhumans through the systematic investigation of a visual-motor task that has\nbeen well-explored -- that of intercepting a target moving over a ground plane.\nPrevious research demonstrated that humans performing this task resorted to\nanticipatory changes in speed intended to compensate for semi-predictable\nchanges in target speed later in the approach. To capture this behavior, our\nproposed \"neural\" AIF agent uses artificial neural networks to select actions\non the basis of a very short term prediction of the information about the task\nenvironment that these actions would reveal along with a long-term estimate of\nthe resulting cumulative expected free energy. Systematic variation revealed\nthat anticipatory behavior emerged only when required by limitations on the\nagent's movement capabilities, and only when the agent was able to estimate\naccumulated free energy over sufficiently long durations into the future. In\naddition, we present a novel formulation of the prior function that maps a\nmulti-dimensional world-state to a uni-dimensional distribution of free-energy.\nTogether, these results demonstrate the use of AIF as a plausible model of\nanticipatory visually guided behavior in humans.",
    "descriptor": "\nComments: 16 pages including references, 6 figures. Submitted to Frontiers in Computational Neuroscience\n",
    "authors": [
      "Zhizhuo Yang",
      "Gabriel J. Diaz",
      "Brett R. Fajen",
      "Reynold Bailey",
      "Alexander Ororbia"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10419"
  },
  {
    "id": "arXiv:2211.10422",
    "title": "Forecasting labels under distribution-shift for machine-guided sequence  design",
    "abstract": "The ability to design and optimize biological sequences with specific\nfunctionalities would unlock enormous value in technology and healthcare. In\nrecent years, machine learning-guided sequence design has progressed this goal\nsignificantly, though validating designed sequences in the lab or clinic takes\nmany months and substantial labor. It is therefore valuable to assess the\nlikelihood that a designed set contains sequences of the desired quality (which\noften lies outside the label distribution in our training data) before\ncommitting resources to an experiment. Forecasting, a prominent concept in many\ndomains where feedback can be delayed (e.g. elections), has not been used or\nstudied in the context of sequence design. Here we propose a method to guide\ndecision-making that forecasts the performance of high-throughput libraries\n(e.g. containing $10^5$ unique variants) based on estimates provided by models,\nproviding a posterior for the distribution of labels in the library. We show\nthat our method outperforms baselines that naively use model scores to estimate\nlibrary performance, which are the only tool available today for this purpose.",
    "descriptor": "\nComments: 15 pages, 3 figures, to appear in MLCB-PMLR proceedings, oral presentation at MLCB 2022 and LMLR 2022\n",
    "authors": [
      "Lauren Berk Wheelock",
      "Stephen Malina",
      "Jeffrey Gerold",
      "Sam Sinai"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2211.10422"
  },
  {
    "id": "arXiv:2211.10431",
    "title": "Improving ECG-based COVID-19 diagnosis and mortality predictions using  pre-pandemic medical records at population-scale",
    "abstract": "Pandemic outbreaks such as COVID-19 occur unexpectedly, and need immediate\naction due to their potential devastating consequences on global health.\nPoint-of-care routine assessments such as electrocardiogram (ECG), can be used\nto develop prediction models for identifying individuals at risk. However,\nthere is often too little clinically-annotated medical data, especially in\nearly phases of a pandemic, to develop accurate prediction models. In such\nsituations, historical pre-pandemic health records can be utilized to estimate\na preliminary model, which can then be fine-tuned based on limited available\npandemic data. This study shows this approach -- pre-train deep learning models\nwith pre-pandemic data -- can work effectively, by demonstrating substantial\nperformance improvement over three different COVID-19 related diagnostic and\nprognostic prediction tasks. Similar transfer learning strategies can be useful\nfor developing timely artificial intelligence solutions in future pandemic\noutbreaks.",
    "descriptor": "\nComments: Accepted for NeurIPS 2022 TS4H workshop\n",
    "authors": [
      "Weijie Sun",
      "Sunil Vasu Kalmady",
      "Nariman Sepehrvan",
      "Luan Manh Chu",
      "Zihan Wang",
      "Amir Salimi",
      "Abram Hindle",
      "Russell Greiner",
      "Padma Kaul"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10431"
  },
  {
    "id": "arXiv:1910.07755",
    "title": "Reducing the Computational Complexity of Pseudoinverse for the  Incremental Broad Learning System on Added Inputs",
    "abstract": "Reducing the Computational Complexity of Pseudoinverse for the  Incremental Broad Learning System on Added Inputs",
    "descriptor": "",
    "authors": [
      "Hufei Zhu",
      "Zhulin Liu",
      "C. L. Philip Chen",
      "Yanyang Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1910.07755"
  },
  {
    "id": "arXiv:2001.03908",
    "title": "Self-Driving like a Human driver instead of a Robocar: Personalized  comfortable driving experience for autonomous vehicles",
    "abstract": "Comments: 8 pages, 9 figures, NeurIPS 2019 Workshop: Machine Learning for Autonomous Driving (ML4AD)",
    "descriptor": "\nComments: 8 pages, 9 figures, NeurIPS 2019 Workshop: Machine Learning for Autonomous Driving (ML4AD)\n",
    "authors": [
      "Il Bae",
      "Jaeyoung Moon",
      "Junekyo Jhung",
      "Ho Suk",
      "Taewoo Kim",
      "Hyungbin Park",
      "Jaekwang Cha",
      "Jinhyuk Kim",
      "Dohyun Kim",
      "Shiho Kim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2001.03908"
  },
  {
    "id": "arXiv:2009.05908",
    "title": "Understanding Boolean Function Learnability on Deep Neural Networks: PAC  Learning Meets Neurosymbolic Models",
    "abstract": "Understanding Boolean Function Learnability on Deep Neural Networks: PAC  Learning Meets Neurosymbolic Models",
    "descriptor": "",
    "authors": [
      "Marcio Nicolau",
      "Anderson R. Tavares",
      "Zhiwei Zhang",
      "Pedro Avelar",
      "Jo\u00e3o M. Flach",
      "Luis C. Lamb",
      "Moshe Y. Vardi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.05908"
  },
  {
    "id": "arXiv:2009.10262",
    "title": "Safety-Critical Control of Compartmental Epidemiological Models with  Measurement Delays",
    "abstract": "Comments: Accepted to the IEEE Control System Letters (L-CSS) and the 2021 American Control Conference (ACC). 6 pages, 3 figures",
    "descriptor": "\nComments: Accepted to the IEEE Control System Letters (L-CSS) and the 2021 American Control Conference (ACC). 6 pages, 3 figures\n",
    "authors": [
      "Tamas G. Molnar",
      "Andrew W. Singletary",
      "Gabor Orosz",
      "Aaron D. Ames"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2009.10262"
  },
  {
    "id": "arXiv:2010.02576",
    "title": "A Note on High-Probability versus In-Expectation Guarantees of  Generalization Bounds in Machine Learning",
    "abstract": "A Note on High-Probability versus In-Expectation Guarantees of  Generalization Bounds in Machine Learning",
    "descriptor": "",
    "authors": [
      "Alexander Mey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2010.02576"
  },
  {
    "id": "arXiv:2010.09567",
    "title": "Solving relaxations of MAP-MRF problems: Combinatorial in-face  Frank-Wolfe directions",
    "abstract": "Solving relaxations of MAP-MRF problems: Combinatorial in-face  Frank-Wolfe directions",
    "descriptor": "",
    "authors": [
      "Vladimir Kolmogorov"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.09567"
  },
  {
    "id": "arXiv:2012.12348",
    "title": "An overview on deep learning-based approximation methods for partial  differential equations",
    "abstract": "Comments: 49 pages. Compared to the first version, the manuscript has been significantly expanded. In particular, Python source code implementing several of the presented methods using PyTorch, as well as numerical simulations have been added",
    "descriptor": "\nComments: 49 pages. Compared to the first version, the manuscript has been significantly expanded. In particular, Python source code implementing several of the presented methods using PyTorch, as well as numerical simulations have been added\n",
    "authors": [
      "Christian Beck",
      "Martin Hutzenthaler",
      "Arnulf Jentzen",
      "Benno Kuckuck"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2012.12348"
  },
  {
    "id": "arXiv:2101.04230",
    "title": "Explaining the Black-box Smoothly- A Counterfactual Approach",
    "abstract": "Comments: Preprint Accepted in Medical image Analysis journal",
    "descriptor": "\nComments: Preprint Accepted in Medical image Analysis journal\n",
    "authors": [
      "Sumedha Singla",
      "Motahhare Eslami",
      "Brian Pollack",
      "Stephen Wallace",
      "Kayhan Batmanghelich"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2101.04230"
  },
  {
    "id": "arXiv:2103.16565",
    "title": "Learning Representational Invariances for Data-Efficient Action  Recognition",
    "abstract": "Comments: Accepted to CVIU. Project page: this https URL",
    "descriptor": "\nComments: Accepted to CVIU. Project page: this https URL\n",
    "authors": [
      "Yuliang Zou",
      "Jinwoo Choi",
      "Qitong Wang",
      "Jia-Bin Huang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.16565"
  },
  {
    "id": "arXiv:2104.03835",
    "title": "Eternal distance-k domination on graphs",
    "abstract": "Comments: 21 pages, 8 figures",
    "descriptor": "\nComments: 21 pages, 8 figures\n",
    "authors": [
      "Danielle Cox",
      "Erin Meger",
      "M.E. Messinger"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2104.03835"
  },
  {
    "id": "arXiv:2105.02743",
    "title": "Random density matrices: Analytical results for mean root fidelity and  mean square Bures distance",
    "abstract": "Comments: 13 pages, 10 figures ; Published Version",
    "descriptor": "\nComments: 13 pages, 10 figures ; Published Version\n",
    "authors": [
      "Aritra Laha",
      "Agrim Aggarwal",
      "Santosh Kumar"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.02743"
  },
  {
    "id": "arXiv:2105.08237",
    "title": "Towards Unsupervised Sketch-based Image Retrieval",
    "abstract": "Towards Unsupervised Sketch-based Image Retrieval",
    "descriptor": "",
    "authors": [
      "Conghui Hu",
      "Yongxin Yang",
      "Yunpeng Li",
      "Timothy M. Hospedales",
      "Yi-Zhe Song"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.08237"
  },
  {
    "id": "arXiv:2105.14574",
    "title": "Scalable Marked Point Processes for Exchangeable and Non-Exchangeable  Event Sequences",
    "abstract": "Scalable Marked Point Processes for Exchangeable and Non-Exchangeable  Event Sequences",
    "descriptor": "",
    "authors": [
      "Aristeidis Panos",
      "Ioannis Kosmidis",
      "Petros Dellaportas"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14574"
  },
  {
    "id": "arXiv:2106.11112",
    "title": "Multivariate Data Explanation by Jumping Emerging Patterns Visualization",
    "abstract": "Multivariate Data Explanation by Jumping Emerging Patterns Visualization",
    "descriptor": "",
    "authors": [
      "M\u00e1rio Popolin Neto",
      "Fernando V. Paulovich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.11112"
  },
  {
    "id": "arXiv:2107.11433",
    "title": "A general sample complexity analysis of vanilla policy gradient",
    "abstract": "Comments: Accepted at AISTATS 2022. This version updates references and adds acknowledgement to Matteo Papini who greatly improved our work before the submission",
    "descriptor": "\nComments: Accepted at AISTATS 2022. This version updates references and adds acknowledgement to Matteo Papini who greatly improved our work before the submission\n",
    "authors": [
      "Rui Yuan",
      "Robert M. Gower",
      "Alessandro Lazaric"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.11433"
  },
  {
    "id": "arXiv:2108.10218",
    "title": "Modeling chronic pain experiences from online reports using the Reddit  Reports of Chronic Pain dataset",
    "abstract": "Comments: 24 pages, 26 figures, 8 tables",
    "descriptor": "\nComments: 24 pages, 26 figures, 8 tables\n",
    "authors": [
      "Diogo A.P. Nunes",
      "Joana Ferreira-Gomes",
      "Fani Neto",
      "David Martins de Matos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Social and Information Networks (cs.SI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2108.10218"
  },
  {
    "id": "arXiv:2109.03393",
    "title": "Learning to Discriminate Information for Online Action Detection:  Analysis and Application",
    "abstract": "Comments: To appear in TPAMI. arXiv admin note: substantial text overlap with arXiv:1912.04461",
    "descriptor": "\nComments: To appear in TPAMI. arXiv admin note: substantial text overlap with arXiv:1912.04461\n",
    "authors": [
      "Sumin Lee",
      "Hyunjun Eun",
      "Jinyoung Moon",
      "Seokeon Choi",
      "Yoonhyung Kim",
      "Chanho Jung",
      "Changick Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.03393"
  },
  {
    "id": "arXiv:2111.03383",
    "title": "A Bayesian generative neural network framework for epidemic inference  problems",
    "abstract": "Comments: 30 pages, 6 figures, 1 table",
    "descriptor": "\nComments: 30 pages, 6 figures, 1 table\n",
    "authors": [
      "Indaco Biazzo",
      "Alfredo Braunstein",
      "Luca Dall'Asta",
      "Fabio Mazza"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.03383"
  },
  {
    "id": "arXiv:2111.10983",
    "title": "A Semi-Supervised Adaptive Discriminative Discretization Method  Improving Discrimination Power of Regularized Naive Bayes",
    "abstract": "A Semi-Supervised Adaptive Discriminative Discretization Method  Improving Discrimination Power of Regularized Naive Bayes",
    "descriptor": "",
    "authors": [
      "Shihe Wang",
      "Jianfeng Ren",
      "Ruibin Bai"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.10983"
  },
  {
    "id": "arXiv:2112.04475",
    "title": "Reliable Simulation of Quantum Channels",
    "abstract": "Comments: V2: presentation improved, details on proofs added, references added, minor corrections. V3: minor changes",
    "descriptor": "\nComments: V2: presentation improved, details on proofs added, references added, minor corrections. V3: minor changes\n",
    "authors": [
      "Ke Li",
      "Yongsheng Yao"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.04475"
  },
  {
    "id": "arXiv:2112.12641",
    "title": "Prolog-based agnostic explanation module for structured pattern  classification",
    "abstract": "Prolog-based agnostic explanation module for structured pattern  classification",
    "descriptor": "",
    "authors": [
      "Gonzalo N\u00e1poles",
      "Fabian Hoitsma",
      "Andreas Knoben",
      "Agnieszka Jastrzebska",
      "Maikel Leon Espinosa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12641"
  },
  {
    "id": "arXiv:2112.14927",
    "title": "An Empirical Study of Security Practices for Microservices Systems",
    "abstract": "Comments: Preprint accepted for publication in Journal of Systems and Software, 2022",
    "descriptor": "\nComments: Preprint accepted for publication in Journal of Systems and Software, 2022\n",
    "authors": [
      "Ali Rezaei Nasab",
      "Mojtaba Shahin",
      "Seyed Ali Hoseyni Raviz",
      "Peng Liang",
      "Amir Mashmool",
      "Valentina Lenarduzzi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.14927"
  },
  {
    "id": "arXiv:2201.08318",
    "title": "Cheating Automatic Short Answer Grading: On the Adversarial Usage of  Adjectives and Adverbs",
    "abstract": "Cheating Automatic Short Answer Grading: On the Adversarial Usage of  Adjectives and Adverbs",
    "descriptor": "",
    "authors": [
      "Anna Filighera",
      "Sebastian Ochs",
      "Tim Steuer",
      "Thomas Tregel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.08318"
  },
  {
    "id": "arXiv:2201.11924",
    "title": "Close the Optical Sensing Domain Gap by Physics-Grounded Active Stereo  Sensor Simulation",
    "abstract": "Comments: 20 pages, 14 figures, 10 tables",
    "descriptor": "\nComments: 20 pages, 14 figures, 10 tables\n",
    "authors": [
      "Xiaoshuai Zhang",
      "Rui Chen",
      "Ang Li",
      "Fanbo Xiang",
      "Yuzhe Qin",
      "Jiayuan Gu",
      "Zhan Ling",
      "Minghua Liu",
      "Peiyu Zeng",
      "Songfang Han",
      "Zhiao Huang",
      "Tongzhou Mu",
      "Jing Xu",
      "Hao Su"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.11924"
  },
  {
    "id": "arXiv:2202.00569",
    "title": "Arrhythmia Classification using CGAN-augmented ECG Signals",
    "abstract": "Arrhythmia Classification using CGAN-augmented ECG Signals",
    "descriptor": "",
    "authors": [
      "Edmond Adib",
      "Fatemeh Afghah",
      "John J. Prevost"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00569"
  },
  {
    "id": "arXiv:2202.01508",
    "title": "The Wiretap Channel for Capacitive PUF-Based Security Enclosures",
    "abstract": "The Wiretap Channel for Capacitive PUF-Based Security Enclosures",
    "descriptor": "",
    "authors": [
      "Kathrin Garb",
      "Marvin Xhemrishi",
      "Ludwig K\u00fcrzinger",
      "Christoph Frisch"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.01508"
  },
  {
    "id": "arXiv:2202.03390",
    "title": "Geometric Multimodal Contrastive Representation Learning",
    "abstract": "Comments: ICML 2022 Camera ready version (update)",
    "descriptor": "\nComments: ICML 2022 Camera ready version (update)\n",
    "authors": [
      "Petra Poklukar",
      "Miguel Vasco",
      "Hang Yin",
      "Francisco S. Melo",
      "Ana Paiva",
      "Danica Kragic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03390"
  },
  {
    "id": "arXiv:2202.04824",
    "title": "AdaPrompt: Adaptive Model Training for Prompt-based NLP",
    "abstract": "AdaPrompt: Adaptive Model Training for Prompt-based NLP",
    "descriptor": "",
    "authors": [
      "Yulong Chen",
      "Yang Liu",
      "Li Dong",
      "Shuohang Wang",
      "Chenguang Zhu",
      "Michael Zeng",
      "Yue Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.04824"
  },
  {
    "id": "arXiv:2202.07773",
    "title": "The efficacy and generalizability of conditional GANs for posterior  inference in physics-based inverse problems",
    "abstract": "The efficacy and generalizability of conditional GANs for posterior  inference in physics-based inverse problems",
    "descriptor": "",
    "authors": [
      "Deep Ray",
      "Harisankar Ramaswamy",
      "Dhruv V. Patel",
      "Assad A. Oberai"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07773"
  },
  {
    "id": "arXiv:2202.10996",
    "title": "Learning Dynamics and Structure of Complex Systems Using Graph Neural  Networks",
    "abstract": "Learning Dynamics and Structure of Complex Systems Using Graph Neural  Networks",
    "descriptor": "",
    "authors": [
      "Zhe Li",
      "Andreas S. Tolias",
      "Xaq Pitkow"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.10996"
  },
  {
    "id": "arXiv:2202.11735",
    "title": "Truncated LinUCB for Stochastic Linear Bandits",
    "abstract": "Comments: A typo corrected: in Lemma 34(ii), it should be \\|x\\| instead of \\|x\\|^2. Thus, in the proof of Lemma 3, exp(-r^2) should be exp(-r), which, however, does not affect other parts",
    "descriptor": "\nComments: A typo corrected: in Lemma 34(ii), it should be \\|x\\| instead of \\|x\\|^2. Thus, in the proof of Lemma 3, exp(-r^2) should be exp(-r), which, however, does not affect other parts\n",
    "authors": [
      "Yanglei Song",
      "Meng zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2202.11735"
  },
  {
    "id": "arXiv:2202.12035",
    "title": "Semidefinite games",
    "abstract": "Comments: Revised version, 27 pages",
    "descriptor": "\nComments: Revised version, 27 pages\n",
    "authors": [
      "Constantin Ickstadt",
      "Thorsten Theobald",
      "Elias Tsigaridas"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.12035"
  },
  {
    "id": "arXiv:2202.12788",
    "title": "Sensing accident-prone features in urban scenes for proactive driving  and accident prevention",
    "abstract": "Comments: (13 pages, 9 figures, 6 tables, under review in IEEE Transactions on Intelligent Transportation Systems)",
    "descriptor": "\nComments: (13 pages, 9 figures, 6 tables, under review in IEEE Transactions on Intelligent Transportation Systems)\n",
    "authors": [
      "Sumit Mishra",
      "Praveen Kumar Rajendran",
      "Luiz Felipe Vecchietti",
      "Dongsoo Har"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.12788"
  },
  {
    "id": "arXiv:2203.00141",
    "title": "GA+DDPG+HER: Genetic Algorithm-Based Function Optimizer in Deep  Reinforcement Learning for Robotic Manipulation Tasks",
    "abstract": "Comments: This submission is replacement of: 2203.00141",
    "descriptor": "\nComments: This submission is replacement of: 2203.00141\n",
    "authors": [
      "Adarsh Sehgal",
      "Nicholas Ward",
      "Hung Manh La",
      "Christos Papachristos",
      "Sushil Louis"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.00141"
  },
  {
    "id": "arXiv:2203.01629",
    "title": "Learning Group Importance using the Differentiable Hypergeometric  Distribution",
    "abstract": "Learning Group Importance using the Differentiable Hypergeometric  Distribution",
    "descriptor": "",
    "authors": [
      "Thomas M. Sutter",
      "Laura Manduchi",
      "Alain Ryser",
      "Julia E. Vogt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2203.01629"
  },
  {
    "id": "arXiv:2203.04275",
    "title": "Robust Multi-Task Learning and Online Refinement for Spacecraft Pose  Estimation across Domain Gap",
    "abstract": "Comments: Submitted to Advances in Space Research",
    "descriptor": "\nComments: Submitted to Advances in Space Research\n",
    "authors": [
      "Tae Ha Park",
      "Simone D'Amico"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.04275"
  },
  {
    "id": "arXiv:2203.12601",
    "title": "R3M: A Universal Visual Representation for Robot Manipulation",
    "abstract": "Comments: Conference on Robot Learning (CoRL) 2022",
    "descriptor": "\nComments: Conference on Robot Learning (CoRL) 2022\n",
    "authors": [
      "Suraj Nair",
      "Aravind Rajeswaran",
      "Vikash Kumar",
      "Chelsea Finn",
      "Abhinav Gupta"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.12601"
  },
  {
    "id": "arXiv:2203.13896",
    "title": "Using Multiple Instance Learning for Explainable Solar Flare Prediction",
    "abstract": "Using Multiple Instance Learning for Explainable Solar Flare Prediction",
    "descriptor": "",
    "authors": [
      "C\u00e9dric Huwyler",
      "Martin Melchior"
    ],
    "subjectives": [
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13896"
  },
  {
    "id": "arXiv:2203.14713",
    "title": "Image-text Retrieval: A Survey on Recent Research and Development",
    "abstract": "Comments: Accpted by IJCAI'2022 survey track",
    "descriptor": "\nComments: Accpted by IJCAI'2022 survey track\n",
    "authors": [
      "Min Cao",
      "Shiping Li",
      "Juntao Li",
      "Liqiang Nie",
      "Min Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.14713"
  },
  {
    "id": "arXiv:2203.15360",
    "title": "Time-optimal control of cranes subject to container height constraints",
    "abstract": "Time-optimal control of cranes subject to container height constraints",
    "descriptor": "",
    "authors": [
      "Filipe Marques Barbosa",
      "Johan L\u00f6fberg"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2203.15360"
  },
  {
    "id": "arXiv:2204.01986",
    "title": "On the Computational Consequences of Cost Function Design in Nonlinear  Optimal Control",
    "abstract": "On the Computational Consequences of Cost Function Design in Nonlinear  Optimal Control",
    "descriptor": "",
    "authors": [
      "Tyler Westenbroek",
      "Anand Siththaranjan",
      "Mohsin Sarwari",
      "Claire J. Tomlin",
      "Shankar S. Sastry"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2204.01986"
  },
  {
    "id": "arXiv:2204.02075",
    "title": "Complex-Valued Autoencoders for Object Discovery",
    "abstract": "Comments: Published in Transactions on Machine Learning Research (TMLR)",
    "descriptor": "\nComments: Published in Transactions on Machine Learning Research (TMLR)\n",
    "authors": [
      "Sindy L\u00f6we",
      "Phillip Lippe",
      "Maja Rudolph",
      "Max Welling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.02075"
  },
  {
    "id": "arXiv:2204.08508",
    "title": "Entropy of labeled versus unlabeled networks",
    "abstract": "Entropy of labeled versus unlabeled networks",
    "descriptor": "",
    "authors": [
      "Jeremy Paton",
      "Harrison Hartle",
      "Huck Stepanyants",
      "Pim van der Hoorn",
      "Dmitri Krioukov"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)",
      "Probability (math.PR)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2204.08508"
  },
  {
    "id": "arXiv:2204.11484",
    "title": "AQuaMoHo: Localized Low-Cost Outdoor Air Quality Sensing over a  Thermo-Hygrometer",
    "abstract": "Comments: 26 Pages, 17 Figures, Journal",
    "descriptor": "\nComments: 26 Pages, 17 Figures, Journal\n",
    "authors": [
      "Prithviraj Pramanik",
      "Prasenjit Karmakar",
      "Praveen Kumar Sharma",
      "Soumyajit Chatterjee",
      "Abhijit Roy",
      "Santanu Mandal",
      "Subrata Nandi",
      "Sandip Chakraborty",
      "Mousumi Saha",
      "Sujoy Saha"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.11484"
  },
  {
    "id": "arXiv:2204.11936",
    "title": "Discrete-Continuous Smoothing and Mapping",
    "abstract": "Comments: Extended technical report for publication in IEEE Robotics and Automation Letters (RA-L)",
    "descriptor": "\nComments: Extended technical report for publication in IEEE Robotics and Automation Letters (RA-L)\n",
    "authors": [
      "Kevin J. Doherty",
      "Ziqi Lu",
      "Kurran Singh",
      "John J. Leonard"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.11936"
  },
  {
    "id": "arXiv:2204.12115",
    "title": "Fast Successive-Cancellation Decoding of Polar Codes with Sequence Nodes",
    "abstract": "Comments: 30 pages, 6 figures, submitted for possible journal publication",
    "descriptor": "\nComments: 30 pages, 6 figures, submitted for possible journal publication\n",
    "authors": [
      "Yang Lu",
      "Ming-Min Zhao",
      "Ming Lei",
      "Min-Jian Zhao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2204.12115"
  },
  {
    "id": "arXiv:2205.01754",
    "title": "B\u00e9zier Curve Gaussian Processes",
    "abstract": "B\u00e9zier Curve Gaussian Processes",
    "descriptor": "",
    "authors": [
      "Ronny Hug",
      "Stefan Becker",
      "Wolfgang H\u00fcbner",
      "Michael Arens",
      "J\u00fcrgen Beyerer"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.01754"
  },
  {
    "id": "arXiv:2205.03860",
    "title": "Zero and R2D2: A Large-scale Chinese Cross-modal Benchmark and A  Vision-Language Framework",
    "abstract": "Zero and R2D2: A Large-scale Chinese Cross-modal Benchmark and A  Vision-Language Framework",
    "descriptor": "",
    "authors": [
      "Chunyu Xie",
      "Jincheng Li",
      "Heng Cai",
      "Fanjing Kong",
      "Xiaoyu Wu",
      "Jianfei Song",
      "Henrique Morimitsu",
      "Lin Yao",
      "Dexin Wang",
      "Dawei Leng",
      "Baochang Zhang",
      "Xiangyang Ji",
      "Yafeng Deng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.03860"
  },
  {
    "id": "arXiv:2205.13125",
    "title": "Prompt-based Learning for Unpaired Image Captioning",
    "abstract": "Prompt-based Learning for Unpaired Image Captioning",
    "descriptor": "",
    "authors": [
      "Peipei Zhu",
      "Xiao Wang",
      "Lin Zhu",
      "Zhenglong Sun",
      "Weishi Zheng",
      "Yaowei Wang",
      "Changwen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.13125"
  },
  {
    "id": "arXiv:2205.13643",
    "title": "Differentiable solver for time-dependent deformation problems with  contact",
    "abstract": "Differentiable solver for time-dependent deformation problems with  contact",
    "descriptor": "",
    "authors": [
      "Zizhou Huang",
      "Davi Colli Tozoni",
      "Arvi Gjoka",
      "Zachary Ferguson",
      "Teseo Schneider",
      "Daniele Panozzo",
      "Denis Zorin"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2205.13643"
  },
  {
    "id": "arXiv:2205.14567",
    "title": "Input-to-State Safety with Input Delay in Longitudinal Vehicle Control",
    "abstract": "Comments: Accepted to the 17th IFAC Workshop on Time Delay Systems. 6 pages, 3 figures",
    "descriptor": "\nComments: Accepted to the 17th IFAC Workshop on Time Delay Systems. 6 pages, 3 figures\n",
    "authors": [
      "Tamas G. Molnar",
      "Anil Alan",
      "Adam K. Kiss",
      "Aaron D. Ames",
      "Gabor Orosz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Robotics (cs.RO)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2205.14567"
  },
  {
    "id": "arXiv:2206.02060",
    "title": "A privacy preserving querying mechanism with high utility for electric  vehicles",
    "abstract": "A privacy preserving querying mechanism with high utility for electric  vehicles",
    "descriptor": "",
    "authors": [
      "Ugur Ilker Atmaca",
      "Sayan Biswas",
      "Carsten Maple",
      "Catuscia Palamidessi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2206.02060"
  },
  {
    "id": "arXiv:2206.03638",
    "title": "Graph Neural Networks as Multi-view Learning",
    "abstract": "Graph Neural Networks as Multi-view Learning",
    "descriptor": "",
    "authors": [
      "Haoyu Han",
      "Xiaorui Liu",
      "Haitao Mao",
      "Torkamani Ali",
      "Feng Shi",
      "Victor Lee",
      "Jiliang Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.03638"
  },
  {
    "id": "arXiv:2206.03796",
    "title": "Adaptive Neural Network-based Unscented Kalman Filter for Robust Pose  Tracking of Noncooperative Spacecraft",
    "abstract": "Comments: Submitted to AIAA Journal of Guidance, Control, and Dynamics",
    "descriptor": "\nComments: Submitted to AIAA Journal of Guidance, Control, and Dynamics\n",
    "authors": [
      "Tae Ha Park",
      "Simone D'Amico"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.03796"
  },
  {
    "id": "arXiv:2206.05060",
    "title": "Social Network Structure Shapes Innovation: Experience-sharing in RL  with SAPIENS",
    "abstract": "Social Network Structure Shapes Innovation: Experience-sharing in RL  with SAPIENS",
    "descriptor": "",
    "authors": [
      "Eleni Nisioti",
      "Mateo Mahaut",
      "Pierre-Yves Oudeyer",
      "Ida Momennejad",
      "Cl\u00e9ment Moulin-Frier"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2206.05060"
  },
  {
    "id": "arXiv:2206.05356",
    "title": "A Speedup Theorem for Asynchronous Computation with Applications to  Consensus and Approximate Agreement",
    "abstract": "A Speedup Theorem for Asynchronous Computation with Applications to  Consensus and Approximate Agreement",
    "descriptor": "",
    "authors": [
      "Pierre Fraigniaud",
      "Ami Paz",
      "Sergio Rajsbaum"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2206.05356"
  },
  {
    "id": "arXiv:2206.05597",
    "title": "Lower Bounds for Sorting 16, 17, and 18 Elements",
    "abstract": "Lower Bounds for Sorting 16, 17, and 18 Elements",
    "descriptor": "",
    "authors": [
      "Florian Stober",
      "Armin Wei\u00df"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2206.05597"
  },
  {
    "id": "arXiv:2206.06004",
    "title": "A Novel Multi-Layer Modular Approach for Real-Time Gravitational-Wave  Detection",
    "abstract": "A Novel Multi-Layer Modular Approach for Real-Time Gravitational-Wave  Detection",
    "descriptor": "",
    "authors": [
      "Francesco Pio Barone",
      "Daniele Dell'Aquila",
      "Marco Russo"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.06004"
  },
  {
    "id": "arXiv:2206.06089",
    "title": "Graph Neural Networks Intersect Probabilistic Graphical Models: A Survey",
    "abstract": "Graph Neural Networks Intersect Probabilistic Graphical Models: A Survey",
    "descriptor": "",
    "authors": [
      "Chenqing Hua",
      "Sitao Luan",
      "Qian Zhang",
      "Jie Fu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.06089"
  },
  {
    "id": "arXiv:2206.07536",
    "title": "Autonomous Platoon Control with Integrated Deep Reinforcement Learning  and Dynamic Programming",
    "abstract": "Autonomous Platoon Control with Integrated Deep Reinforcement Learning  and Dynamic Programming",
    "descriptor": "",
    "authors": [
      "Tong Liu",
      "Lei Lei",
      "Kan Zheng",
      "Kuan Zhang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.07536"
  },
  {
    "id": "arXiv:2206.07643",
    "title": "Coarse-to-Fine Vision-Language Pre-training with Fusion in the Backbone",
    "abstract": "Comments: NeurIPS 2022. Project Website: this https URL",
    "descriptor": "\nComments: NeurIPS 2022. Project Website: this https URL\n",
    "authors": [
      "Zi-Yi Dou",
      "Aishwarya Kamath",
      "Zhe Gan",
      "Pengchuan Zhang",
      "Jianfeng Wang",
      "Linjie Li",
      "Zicheng Liu",
      "Ce Liu",
      "Yann LeCun",
      "Nanyun Peng",
      "Jianfeng Gao",
      "Lijuan Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.07643"
  },
  {
    "id": "arXiv:2206.09209",
    "title": "The Frenet Frame as a Generalization of the Park Transform",
    "abstract": "Comments: 10 pages, 2 figures, submitted to the IEEE Transactions on Power Systems",
    "descriptor": "\nComments: 10 pages, 2 figures, submitted to the IEEE Transactions on Power Systems\n",
    "authors": [
      "Federico Milano"
    ],
    "subjectives": [
      "Differential Geometry (math.DG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2206.09209"
  },
  {
    "id": "arXiv:2206.11693",
    "title": "Learning Agile Skills via Adversarial Imitation of Rough Partial  Demonstrations",
    "abstract": "Learning Agile Skills via Adversarial Imitation of Rough Partial  Demonstrations",
    "descriptor": "",
    "authors": [
      "Chenhao Li",
      "Marin Vlastelica",
      "Sebastian Blaes",
      "Jonas Frey",
      "Felix Grimminger",
      "Georg Martius"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.11693"
  },
  {
    "id": "arXiv:2206.13727",
    "title": "Persistent homology-based descriptor for machine-learning potential",
    "abstract": "Comments: 26 pages, 8 figures",
    "descriptor": "\nComments: 26 pages, 8 figures\n",
    "authors": [
      "Emi Minamitani",
      "Ippei Obayashi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Materials Science (cond-mat.mtrl-sci)"
    ],
    "url": "https://arxiv.org/abs/2206.13727"
  },
  {
    "id": "arXiv:2207.11717",
    "title": "A Priority Map for Vision-and-Language Navigation with Trajectory Plans  and Feature-Location Cues",
    "abstract": "Comments: Accepted to WACV 2023",
    "descriptor": "\nComments: Accepted to WACV 2023\n",
    "authors": [
      "Jason Armitage",
      "Leonardo Impett",
      "Rico Sennrich"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.11717"
  },
  {
    "id": "arXiv:2207.13281",
    "title": "Cubic Goldreich-Levin",
    "abstract": "Comments: 51 pages",
    "descriptor": "\nComments: 51 pages\n",
    "authors": [
      "Dain Kim",
      "Anqi Li",
      "Jonathan Tidor"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.13281"
  },
  {
    "id": "arXiv:2207.13545",
    "title": "Learning Hyper Label Model for Programmatic Weak Supervision",
    "abstract": "Learning Hyper Label Model for Programmatic Weak Supervision",
    "descriptor": "",
    "authors": [
      "Renzhi Wu",
      "Shen-En Chen",
      "Jieyu Zhang",
      "Xu Chu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2207.13545"
  },
  {
    "id": "arXiv:2207.13987",
    "title": "ClaSP -- Parameter-free Time Series Segmentation",
    "abstract": "ClaSP -- Parameter-free Time Series Segmentation",
    "descriptor": "",
    "authors": [
      "Arik Ermshaus",
      "Patrick Sch\u00e4fer",
      "Ulf Leser"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2207.13987"
  },
  {
    "id": "arXiv:2207.14687",
    "title": "A Data-driven Latent Semantic Analysis for Automatic Text Summarization  using LDA Topic Modelling",
    "abstract": "A Data-driven Latent Semantic Analysis for Automatic Text Summarization  using LDA Topic Modelling",
    "descriptor": "",
    "authors": [
      "Daniel F. O. Onah",
      "Elaine L. L. Pang",
      "Mahmoud El-Haj"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.14687"
  },
  {
    "id": "arXiv:2208.02835",
    "title": "Safe and Human-Like Autonomous Driving: A Predictor-Corrector Potential  Game Approach",
    "abstract": "Safe and Human-Like Autonomous Driving: A Predictor-Corrector Potential  Game Approach",
    "descriptor": "",
    "authors": [
      "Mushuang Liu",
      "H. Eric Tseng",
      "Dimitar Filev",
      "Anouck Girard",
      "Ilya Kolmanovsky"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.02835"
  },
  {
    "id": "arXiv:2208.04676",
    "title": "DeepHider: A Covert NLP Watermarking Framework Based on Multi-task  Learning",
    "abstract": "Comments: 16 pages,10 figures",
    "descriptor": "\nComments: 16 pages,10 figures\n",
    "authors": [
      "Long Dai",
      "Jiarong Mao",
      "Xuefeng Fan",
      "Xiaoyi Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.04676"
  },
  {
    "id": "arXiv:2208.04931",
    "title": "Co-lexicographically ordering automata and regular languages. Part I",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2106.02309",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2106.02309\n",
    "authors": [
      "Nicola Cotumaccio",
      "Giovanna D'Agostino",
      "Alberto Policriti",
      "Nicola Prezza"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2208.04931"
  },
  {
    "id": "arXiv:2208.06687",
    "title": "Avoider-Enforcer Game is NP-hard",
    "abstract": "Comments: 8 pages, 3 figures",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Tillmann Miltzow",
      "Milo\u0161 Stojakovi\u0107"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Computer Science and Game Theory (cs.GT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2208.06687"
  },
  {
    "id": "arXiv:2208.06721",
    "title": "Lyapunov Design for Robust and Efficient Robotic Reinforcement Learning",
    "abstract": "Lyapunov Design for Robust and Efficient Robotic Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Tyler Westenbroek",
      "Fernando Castaneda",
      "Ayush Agrawal",
      "Shankar Sastry",
      "Koushil Sreenath"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.06721"
  },
  {
    "id": "arXiv:2208.06787",
    "title": "HDR-Plenoxels: Self-Calibrating High Dynamic Range Radiance Fields",
    "abstract": "Comments: Accepted at ECCV 2022. [Project page] this https URL [Code] this https URL",
    "descriptor": "\nComments: Accepted at ECCV 2022. [Project page] this https URL [Code] this https URL\n",
    "authors": [
      "Kim Jun-Seong",
      "Kim Yu-Ji",
      "Moon Ye-Bin",
      "Tae-Hyun Oh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2208.06787"
  },
  {
    "id": "arXiv:2208.07473",
    "title": "BoW3D: Bag of Words for Real-Time Loop Closing in 3D LiDAR SLAM",
    "abstract": "Comments: Accepted by IEEE Robotics and Automation Letters (RA-L)/ICRA 2023",
    "descriptor": "\nComments: Accepted by IEEE Robotics and Automation Letters (RA-L)/ICRA 2023\n",
    "authors": [
      "Yunge Cui",
      "Xieyuanli Chen",
      "Yinlong Zhang",
      "Jiahua Dong",
      "Qingxiao Wu",
      "Feng Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.07473"
  },
  {
    "id": "arXiv:2208.09727",
    "title": "Security Implications of Large Language Model Code Assistants: A User  Study",
    "abstract": "Comments: 18 pages, 12 figures. G. Sandoval and H. Pearce contributed equally to this work",
    "descriptor": "\nComments: 18 pages, 12 figures. G. Sandoval and H. Pearce contributed equally to this work\n",
    "authors": [
      "Gustavo Sandoval",
      "Hammond Pearce",
      "Teo Nys",
      "Ramesh Karri",
      "Brendan Dolan-Gavitt",
      "Siddharth Garg"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.09727"
  },
  {
    "id": "arXiv:2208.11223",
    "title": "POPDx: An Automated Framework for Patient Phenotyping across 392,246  Individuals in the UK Biobank Study",
    "abstract": "Comments: 45 pages, 6 main figures, 2 main tables",
    "descriptor": "\nComments: 45 pages, 6 main figures, 2 main tables\n",
    "authors": [
      "Lu Yang",
      "Sheng Wang",
      "Russ B. Altman"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.11223"
  },
  {
    "id": "arXiv:2209.00686",
    "title": "Nonlinear desirability theory",
    "abstract": "Nonlinear desirability theory",
    "descriptor": "",
    "authors": [
      "Enrique Miranda",
      "Marco Zaffalon"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.00686"
  },
  {
    "id": "arXiv:2209.06112",
    "title": "CU-Net: Real-Time High-Fidelity Color Upsampling for Point Clouds",
    "abstract": "CU-Net: Real-Time High-Fidelity Color Upsampling for Point Clouds",
    "descriptor": "",
    "authors": [
      "Lingdong Wang",
      "Mohammad Hajiesmaili",
      "Jacob Chakareski",
      "Ramesh K. Sitaraman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.06112"
  },
  {
    "id": "arXiv:2209.11287",
    "title": "Leveraging GPU Tensor Cores for Double Precision Euclidean Distance  Calculations",
    "abstract": "Comments: To be published in 2022 29th IEEE International Conference on High Performance Computing, Data, and Analytics",
    "descriptor": "\nComments: To be published in 2022 29th IEEE International Conference on High Performance Computing, Data, and Analytics\n",
    "authors": [
      "Benoit Gallet",
      "Michael Gowanlock"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2209.11287"
  },
  {
    "id": "arXiv:2209.11497",
    "title": "Time Series Causal Link Estimation under Hidden Confounding using  Knockoff Interventions",
    "abstract": "Comments: \"A causal view on dynamical systems\" Workshop at NeurIPS 2022",
    "descriptor": "\nComments: \"A causal view on dynamical systems\" Workshop at NeurIPS 2022\n",
    "authors": [
      "Violeta Teodora Trifunov",
      "Maha Shadaydeh",
      "Joachim Denzler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2209.11497"
  },
  {
    "id": "arXiv:2209.15148",
    "title": "Embedded System Performance Analysis for Implementing a Portable  Drowsiness Detection System for Drivers",
    "abstract": "Comments: 20 pages, 12 figures, 3 tables",
    "descriptor": "\nComments: 20 pages, 12 figures, 3 tables\n",
    "authors": [
      "Minjeong Kim",
      "Jimin Koo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2209.15148"
  },
  {
    "id": "arXiv:2210.00571",
    "title": "Beyond the Existential Theory of the Reals",
    "abstract": "Beyond the Existential Theory of the Reals",
    "descriptor": "",
    "authors": [
      "Marcus Schaefer",
      "Daniel Stefankovic"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2210.00571"
  },
  {
    "id": "arXiv:2210.01209",
    "title": "Automatic Assessment of Functional Movement Screening Exercises with  Deep Learning Architectures",
    "abstract": "Automatic Assessment of Functional Movement Screening Exercises with  Deep Learning Architectures",
    "descriptor": "",
    "authors": [
      "Andreas Spilz",
      "MIchael Munz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.01209"
  },
  {
    "id": "arXiv:2210.02042",
    "title": "FedMT: Federated Learning with Mixed-type Labels",
    "abstract": "Comments: 23 pages",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Qiong Zhang",
      "Aline Talhouk",
      "Gang Niu",
      "Xiaoxiao Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.02042"
  },
  {
    "id": "arXiv:2210.02653",
    "title": "Stabilization-free serendipity virtual element method for plane  elasticity",
    "abstract": "Comments: 24 pages, 17 figures. arXiv admin note: text overlap with arXiv:2202.10037",
    "descriptor": "\nComments: 24 pages, 17 figures. arXiv admin note: text overlap with arXiv:2202.10037\n",
    "authors": [
      "Alvin Chen",
      "N. Sukumar"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2210.02653"
  },
  {
    "id": "arXiv:2210.04081",
    "title": "SlenderGNN: Accurate, Robust, and Interpretable GNN, and the Reasons for  its Success",
    "abstract": "Comments: 20 pages",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Jaemin Yoo",
      "Meng-Chieh Lee",
      "Shubhranshu Shekhar",
      "Christos Faloutsos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2210.04081"
  },
  {
    "id": "arXiv:2210.05408",
    "title": "Private Randomness Agreement and its Application in Quantum Key  Distribution Networks",
    "abstract": "Comments: 5 pages",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Ren\u00e9 B\u00f8dker Christensen",
      "Petar Popovski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.05408"
  },
  {
    "id": "arXiv:2210.06871",
    "title": "Adv-Attribute: Inconspicuous and Transferable Adversarial Attack on Face  Recognition",
    "abstract": "Comments: Accepted by NeurIPS2022",
    "descriptor": "\nComments: Accepted by NeurIPS2022\n",
    "authors": [
      "Shuai Jia",
      "Bangjie Yin",
      "Taiping Yao",
      "Shouhong Ding",
      "Chunhua Shen",
      "Xiaokang Yang",
      "Chao Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.06871"
  },
  {
    "id": "arXiv:2210.06884",
    "title": "Algorithms for Weighted Pushdown Automata",
    "abstract": "Comments: 12 pages, 7 figures. Accepted at EMNLP 2022",
    "descriptor": "\nComments: 12 pages, 7 figures. Accepted at EMNLP 2022\n",
    "authors": [
      "Alexandra Butoi",
      "Brian DuSell",
      "Tim Vieira",
      "Ryan Cotterell",
      "David Chiang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.06884"
  },
  {
    "id": "arXiv:2210.10768",
    "title": "Anytime-valid off-policy inference for contextual bandits",
    "abstract": "Comments: 40 pages, 6 figures",
    "descriptor": "\nComments: 40 pages, 6 figures\n",
    "authors": [
      "Ian Waudby-Smith",
      "Lili Wu",
      "Aaditya Ramdas",
      "Nikos Karampatziakis",
      "Paul Mineiro"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.10768"
  },
  {
    "id": "arXiv:2210.10864",
    "title": "Cluster and Aggregate: Face Recognition with Large Probe Set",
    "abstract": "Comments: To appear in NeurIPS 2022",
    "descriptor": "\nComments: To appear in NeurIPS 2022\n",
    "authors": [
      "Minchul Kim",
      "Feng Liu",
      "Anil Jain",
      "Xiaoming Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.10864"
  },
  {
    "id": "arXiv:2210.11089",
    "title": "Speech Dereverberation with a Reverberation Time Shortening Target",
    "abstract": "Comments: \"Speech Dereverberation with a Reverberation Time Shortening Target (2210.11,089)\" is an updated version of the previous paper submitted at 19 Apr 2022 09:15:25 UTC-- \"Single-Channel Speech Dereverberation using Subband Network with A Reverberation Time Shortening Target (2204.08,765)\". Please visit arXiv:2204.08765",
    "descriptor": "\nComments: \"Speech Dereverberation with a Reverberation Time Shortening Target (2210.11,089)\" is an updated version of the previous paper submitted at 19 Apr 2022 09:15:25 UTC-- \"Single-Channel Speech Dereverberation using Subband Network with A Reverberation Time Shortening Target (2204.08,765)\". Please visit arXiv:2204.08765\n",
    "authors": [
      "Rui Zhou",
      "Wenye Zhu",
      "Xiaofei Li"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.11089"
  },
  {
    "id": "arXiv:2210.12218",
    "title": "SEIFER: Scalable Edge Inference for Deep Neural Networks",
    "abstract": "Comments: Accepted to the \"Challenges in Deploying and Monitoring ML Systems\" Workshop of NeurIPS 2022",
    "descriptor": "\nComments: Accepted to the \"Challenges in Deploying and Monitoring ML Systems\" Workshop of NeurIPS 2022\n",
    "authors": [
      "Arjun Parthasarathy",
      "Bhaskar Krishnamachari"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2210.12218"
  },
  {
    "id": "arXiv:2210.12686",
    "title": "Holistic Interaction Transformer Network for Action Detection",
    "abstract": "Comments: Accepted for WACV 2023. Code: this https URL",
    "descriptor": "\nComments: Accepted for WACV 2023. Code: this https URL\n",
    "authors": [
      "Gueter Josmy Faure",
      "Min-Hung Chen",
      "Shang-Hong Lai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.12686"
  },
  {
    "id": "arXiv:2210.13389",
    "title": "A Regularized Conditional GAN for Posterior Sampling in Inverse Problems",
    "abstract": "A Regularized Conditional GAN for Posterior Sampling in Inverse Problems",
    "descriptor": "",
    "authors": [
      "Matthew Bendel",
      "Rizwan Ahmad",
      "Philip Schniter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.13389"
  },
  {
    "id": "arXiv:2210.14476",
    "title": "Sinusoidal Frequency Estimation by Gradient Descent",
    "abstract": "Comments: Submitted to ICASSP 2023",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Ben Hayes",
      "Charalampos Saitis",
      "Gy\u00f6rgy Fazekas"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.14476"
  },
  {
    "id": "arXiv:2210.14648",
    "title": "Masked Modeling Duo: Learning Representations by Encouraging Both  Networks to Model the Input",
    "abstract": "Comments: 6 pages, 3 figures, and 6 tables. Under review",
    "descriptor": "\nComments: 6 pages, 3 figures, and 6 tables. Under review\n",
    "authors": [
      "Daisuke Niizumi",
      "Daiki Takeuchi",
      "Yasunori Ohishi",
      "Noboru Harada",
      "Kunio Kashino"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.14648"
  },
  {
    "id": "arXiv:2210.15058",
    "title": "Tangent Bundle Filters and Neural Networks: from Manifolds to Cellular  Sheaves and Back",
    "abstract": "Tangent Bundle Filters and Neural Networks: from Manifolds to Cellular  Sheaves and Back",
    "descriptor": "",
    "authors": [
      "Claudio Battiloro",
      "Zhiyang Wang",
      "Hans Riess",
      "Paolo Di Lorenzo",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15058"
  },
  {
    "id": "arXiv:2210.15669",
    "title": "On Catalan Constant Continued Fractions",
    "abstract": "On Catalan Constant Continued Fractions",
    "descriptor": "",
    "authors": [
      "David Naccache",
      "Ofer Yifrach-Stav"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Discrete Mathematics (cs.DM)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2210.15669"
  },
  {
    "id": "arXiv:2210.15707",
    "title": "FedAudio: A Federated Learning Benchmark for Audio Tasks",
    "abstract": "FedAudio: A Federated Learning Benchmark for Audio Tasks",
    "descriptor": "",
    "authors": [
      "Tuo Zhang",
      "Tiantian Feng",
      "Samiul Alam",
      "Sunwoo Lee",
      "Mi Zhang",
      "Shrikanth S. Narayanan",
      "Salman Avestimehr"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15707"
  },
  {
    "id": "arXiv:2210.15715",
    "title": "Simulating realistic speech overlaps improves multi-talker ASR",
    "abstract": "Comments: v2: fix minor typo",
    "descriptor": "\nComments: v2: fix minor typo\n",
    "authors": [
      "Muqiao Yang",
      "Naoyuki Kanda",
      "Xiaofei Wang",
      "Jian Wu",
      "Sunit Sivasankaran",
      "Zhuo Chen",
      "Jinyu Li",
      "Takuya Yoshioka"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15715"
  },
  {
    "id": "arXiv:2210.15934",
    "title": "Multiresolution Signal Processing of Financial Market Objects",
    "abstract": "Comments: 7 pages, 12 figures. Copy at this https URL may be updated more frequently than arXiv copy",
    "descriptor": "\nComments: 7 pages, 12 figures. Copy at this https URL may be updated more frequently than arXiv copy\n",
    "authors": [
      "Ioana Boier"
    ],
    "subjectives": [
      "Computational Finance (q-fin.CP)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2210.15934"
  },
  {
    "id": "arXiv:2211.00464",
    "title": "On the zeroes of hypergraph independence polynomials",
    "abstract": "On the zeroes of hypergraph independence polynomials",
    "descriptor": "",
    "authors": [
      "David Galvin",
      "Gwen McKinley",
      "Will Perkins",
      "Michail Sarantis",
      "Prasad Tetali"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Data Structures and Algorithms (cs.DS)",
      "Mathematical Physics (math-ph)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.00464"
  },
  {
    "id": "arXiv:2211.01292",
    "title": "Learning an Artificial Language for Knowledge-Sharing in Multilingual  Translation",
    "abstract": "Comments: WMT 2022",
    "descriptor": "\nComments: WMT 2022\n",
    "authors": [
      "Danni Liu",
      "Jan Niehues"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.01292"
  },
  {
    "id": "arXiv:2211.01840",
    "title": "LE3D: A Lightweight Ensemble Framework of Data Drift Detectors for  Resource-Constrained Devices",
    "abstract": "Comments: IEEE CCNC 2023, Las Vegas, USA",
    "descriptor": "\nComments: IEEE CCNC 2023, Las Vegas, USA\n",
    "authors": [
      "Ioannis Mavromatis",
      "Adrian Sanchez-Mompo",
      "Francesco Raimondo",
      "James Pope",
      "Marcello Bullo",
      "Ingram Weeks",
      "Vijay Kumar",
      "Pietro Carnelli",
      "George Oikonomou",
      "Theodoros Spyridopoulos",
      "Aftab Khan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.01840"
  },
  {
    "id": "arXiv:2211.04200",
    "title": "Intelligent Surface Enabled Sensing-Assisted Communication",
    "abstract": "Comments: 8 pages, Submitted to IEEE for possible publication",
    "descriptor": "\nComments: 8 pages, Submitted to IEEE for possible publication\n",
    "authors": [
      "Kaitao Meng",
      "Qingqing Wu",
      "Wen Chen",
      "Deshi Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.04200"
  },
  {
    "id": "arXiv:2211.04454",
    "title": "SLATE: A Sequence Labeling Approach for Task Extraction from Free-form  Inked Content",
    "abstract": "Comments: Accepted at EMNLP 2022 as an Industry Track paper",
    "descriptor": "\nComments: Accepted at EMNLP 2022 as an Industry Track paper\n",
    "authors": [
      "Apurva Gandhi",
      "Ryan Serrao",
      "Biyi Fang",
      "Gilbert Antonius",
      "Jenna Hong",
      "Tra My Nguyen",
      "Sheng Yi",
      "Ehi Nosakhare",
      "Irene Shaffer",
      "Soundararajan Srinivasan",
      "Vivek Gupta"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04454"
  },
  {
    "id": "arXiv:2211.05290",
    "title": "Equivariant Contrastive Learning for Sequential Recommendation",
    "abstract": "Comments: 12 pages, 6 figures",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Peilin Zhou",
      "Jingqi Gao",
      "Yueqi Xie",
      "Qichen Ye",
      "Yining Hua",
      "Sunghun Kim"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.05290"
  },
  {
    "id": "arXiv:2211.05567",
    "title": "Partial Differential Equations Meet Deep Neural Networks: A Survey",
    "abstract": "Partial Differential Equations Meet Deep Neural Networks: A Survey",
    "descriptor": "",
    "authors": [
      "Shudong Huang",
      "Wentao Feng",
      "Chenwei Tang",
      "Jiancheng Lv"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.05567"
  },
  {
    "id": "arXiv:2211.05955",
    "title": "MEE: A Novel Multilingual Event Extraction Dataset",
    "abstract": "Comments: Accepted at EMNLP 2022",
    "descriptor": "\nComments: Accepted at EMNLP 2022\n",
    "authors": [
      "Amir Pouran Ben Veyseh",
      "Javid Ebrahimi",
      "Franck Dernoncourt",
      "Thien Huu Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05955"
  },
  {
    "id": "arXiv:2211.05958",
    "title": "MINION: a Large-Scale and Diverse Dataset for Multilingual Event  Detection",
    "abstract": "Comments: Accepted at NAACL 2022",
    "descriptor": "\nComments: Accepted at NAACL 2022\n",
    "authors": [
      "Amir Pouran Ben Veyseh",
      "Minh Van Nguyen",
      "Franck Dernoncourt",
      "Thien Huu Nguyen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05958"
  },
  {
    "id": "arXiv:2211.05994",
    "title": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
    "abstract": "A Survey of Knowledge-Enhanced Pre-trained Language Models",
    "descriptor": "",
    "authors": [
      "Linmei Hu",
      "Zeyi Liu",
      "Ziwang Zhao",
      "Lei Hou",
      "Liqiang Nie",
      "Juanzi Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05994"
  },
  {
    "id": "arXiv:2211.06284",
    "title": "Accelerated Distributed Projected Gradient Descent for Convex  Optimization with Clique-wise Coupled Constraints",
    "abstract": "Comments: 8 pages, 5 figures",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Yuto Watanabe",
      "Kazunori Sakurama"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.06284"
  },
  {
    "id": "arXiv:2211.07004",
    "title": "Advancing Learned Video Compression with In-loop Frame Prediction",
    "abstract": "Advancing Learned Video Compression with In-loop Frame Prediction",
    "descriptor": "",
    "authors": [
      "Ren Yang",
      "Radu Timofte",
      "Luc Van Gool"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.07004"
  },
  {
    "id": "arXiv:2211.07441",
    "title": "Multi-VQG: Generating Engaging Questions for Multiple Images",
    "abstract": "Comments: In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP 2022)",
    "descriptor": "\nComments: In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP 2022)\n",
    "authors": [
      "Min-Hsuan Yeh",
      "Vicent Chen",
      "Ting-Hao 'Kenneth' Haung",
      "Lun-Wei Ku"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07441"
  },
  {
    "id": "arXiv:2211.07501",
    "title": "Discovering A Variety of Objects in Spatio-Temporal Human-Object  Interactions",
    "abstract": "Comments: Techniqual report. A part of the HAKE project. Project: this https URL",
    "descriptor": "\nComments: Techniqual report. A part of the HAKE project. Project: this https URL\n",
    "authors": [
      "Yong-Lu Li",
      "Hongwei Fan",
      "Zuoyu Qiu",
      "Yiming Dou",
      "Liang Xu",
      "Hao-Shu Fang",
      "Peiyang Guo",
      "Haisheng Su",
      "Dongliang Wang",
      "Wei Wu",
      "Cewu Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.07501"
  },
  {
    "id": "arXiv:2211.07627",
    "title": "Redeeming Intrinsic Rewards via Constrained Optimization",
    "abstract": "Comments: NeurIPS 2022",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Eric Chen",
      "Zhang-Wei Hong",
      "Joni Pajarinen",
      "Pulkit Agrawal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.07627"
  },
  {
    "id": "arXiv:2211.08615",
    "title": "GLFF: Global and Local Feature Fusion for Face Forgery Detection",
    "abstract": "GLFF: Global and Local Feature Fusion for Face Forgery Detection",
    "descriptor": "",
    "authors": [
      "Yan Ju",
      "Shan Jia",
      "Jialing Cai",
      "Haiying Guan",
      "Siwei Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08615"
  },
  {
    "id": "arXiv:2211.08655",
    "title": "Compositional Approximately Bisimilar Abstractions of Interconnected  Systems",
    "abstract": "Comments: 9,2",
    "descriptor": "\nComments: 9,2\n",
    "authors": [
      "Belamfedel Alaoui Sadek",
      "Saharsh",
      "Pushpak Jagtap",
      "Adnane Saoud"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.08655"
  },
  {
    "id": "arXiv:2211.08792",
    "title": "Some Properties of the Nash Equilibrium in $2 \\times 2$ Zero-Sum Games",
    "abstract": "Some Properties of the Nash Equilibrium in $2 \\times 2$ Zero-Sum Games",
    "descriptor": "",
    "authors": [
      "Ke Sun"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.08792"
  },
  {
    "id": "arXiv:2211.08800",
    "title": "Bounding the Response Time of DAG Tasks Using Long Paths",
    "abstract": "Bounding the Response Time of DAG Tasks Using Long Paths",
    "descriptor": "",
    "authors": [
      "Qingqiang He",
      "Nan Guan",
      "Mingsong Lv",
      "Xu Jiang",
      "Wanli Chang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.08800"
  },
  {
    "id": "arXiv:2211.08883",
    "title": "Identifying the Causes of Pyrocumulonimbus (PyroCb)",
    "abstract": "Comments: 14 pages 9 figures. To be published in the 2022 NeurIPS Workshop on Causal Machine Learning for Real-World Impact",
    "descriptor": "\nComments: 14 pages 9 figures. To be published in the 2022 NeurIPS Workshop on Causal Machine Learning for Real-World Impact\n",
    "authors": [
      "Emiliano D\u00edaz Salas-Porras",
      "Kenza Tazi",
      "Ashwin Braude",
      "Daniel Okoh",
      "Kara D. Lamb",
      "Duncan Watson-Parris",
      "Paula Harder",
      "Nis Meinert"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.08883"
  },
  {
    "id": "arXiv:2211.09421",
    "title": "FedSiam-DA: Dual-aggregated Federated Learning via Siamese Network under  Non-IID Data",
    "abstract": "Comments: 8 pages, 5 figures",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Ming Yang",
      "Yanhan Wang",
      "Xin Wang",
      "Zhenyong Zhang",
      "Xiaoming Wu",
      "Peng Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09421"
  },
  {
    "id": "arXiv:2211.09423",
    "title": "DexPoint: Generalizable Point Cloud Reinforcement Learning for  Sim-to-Real Dexterous Manipulation",
    "abstract": "Comments: Conference on Robot Learning (CoRL) 2022; project page: this https URL",
    "descriptor": "\nComments: Conference on Robot Learning (CoRL) 2022; project page: this https URL\n",
    "authors": [
      "Yuzhe Qin",
      "Binghao Huang",
      "Zhao-Heng Yin",
      "Hao Su",
      "Xiaolong Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.09423"
  },
  {
    "id": "arXiv:2211.09613",
    "title": "Learning to Communicate with Intent: An Introduction",
    "abstract": "Comments: 7 pages, 4 figues, submitted to IEEE ICC 2023",
    "descriptor": "\nComments: 7 pages, 4 figues, submitted to IEEE ICC 2023\n",
    "authors": [
      "Miguel Angel Gutierrez-Estevez",
      "Yiqun Wu",
      "Chan Zhou"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.09613"
  },
  {
    "id": "arXiv:2211.09721",
    "title": "A Finite-Particle Convergence Rate for Stein Variational Gradient  Descent",
    "abstract": "A Finite-Particle Convergence Rate for Stein Variational Gradient  Descent",
    "descriptor": "",
    "authors": [
      "Jiaxin Shi",
      "Lester Mackey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.09721"
  }
]
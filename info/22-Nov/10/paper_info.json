[
  {
    "id": "arXiv:2211.04470",
    "title": "Efficient Single-Image Depth Estimation on Mobile Devices, Mobile AI &  AIM 2022 Challenge: Report",
    "abstract": "Various depth estimation models are now widely used on many mobile and IoT\ndevices for image segmentation, bokeh effect rendering, object tracking and\nmany other mobile tasks. Thus, it is very crucial to have efficient and\naccurate depth estimation models that can run fast on low-power mobile\nchipsets. In this Mobile AI challenge, the target was to develop deep\nlearning-based single image depth estimation solutions that can show a\nreal-time performance on IoT platforms and smartphones. For this, the\nparticipants used a large-scale RGB-to-depth dataset that was collected with\nthe ZED stereo camera capable to generated depth maps for objects located at up\nto 50 meters. The runtime of all models was evaluated on the Raspberry Pi 4\nplatform, where the developed solutions were able to generate VGA resolution\ndepth maps at up to 27 FPS while achieving high fidelity results. All models\ndeveloped in the challenge are also compatible with any Android or Linux-based\nmobile devices, their detailed description is provided in this paper.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2105.08630, arXiv:2211.03885; text overlap with arXiv:2105.08819, arXiv:2105.08826, arXiv:2105.08629, arXiv:2105.07809, arXiv:2105.07825\n",
    "authors": [
      "Andrey Ignatov",
      "Grigory Malivenko",
      "Radu Timofte",
      "Lukasz Treszczotko",
      "Xin Chang",
      "Piotr Ksiazek",
      "Michal Lopuszynski",
      "Maciej Pioro",
      "Rafal Rudnicki",
      "Maciej Smyl",
      "Yujie Ma",
      "Zhenyu Li",
      "Zehui Chen",
      "Jialei Xu",
      "Xianming Liu",
      "Junjun Jiang",
      "XueChao Shi",
      "Difan Xu",
      "Yanan Li",
      "Xiaotao Wang",
      "Lei Lei",
      "Ziyu Zhang",
      "Yicheng Wang",
      "Zilong Huang",
      "Guozhong Luo",
      "Gang Yu",
      "Bin Fu",
      "Jiaqi Li",
      "Yiran Wang",
      "Zihao Huang",
      "Zhiguo Cao",
      "Marcos V. Conde",
      "Denis Sapozhnikov",
      "Byeong Hyun Lee",
      "Dongwon Park",
      "Seongmin Hong",
      "Joonhee Lee",
      "Seunggyu Lee",
      "Se Young Chun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04470"
  },
  {
    "id": "arXiv:2211.04473",
    "title": "Towards Improved Room Impulse Response Estimation for Speech Recognition",
    "abstract": "We propose to characterize and improve the performance of blind room impulse\nresponse (RIR) estimation systems in the context of a downstream application\nscenario, far-field automatic speech recognition (ASR). We first draw the\nconnection between improved RIR estimation and improved ASR performance, as a\nmeans of evaluating neural RIR estimators. We then propose a GAN-based\narchitecture that encodes RIR features from reverberant speech and constructs\nan RIR from the encoded features, and uses a novel energy decay relief loss to\noptimize for capturing energy-based properties of the input reverberant speech.\nWe show that our model outperforms the state-of-the-art baselines on acoustic\nbenchmarks (by 72% on the energy decay relief and 22% on an early-reflection\nenergy metric), as well as in an ASR evaluation task (by 6.9% in word error\nrate).",
    "descriptor": "",
    "authors": [
      "Anton Ratnarajah",
      "Ishwarya Ananthabhotla",
      "Vamsi Krishna Ithapu",
      "Pablo Hoffmann",
      "Dinesh Manocha",
      "Paul Calamia"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.04473"
  },
  {
    "id": "arXiv:2211.04476",
    "title": "Discover, Explanation, Improvement: Automatic Slice Detection Framework  for Natural Language Processing",
    "abstract": "Current natural language processing (NLP) models such as BERT and RoBERTa\nhave achieved high overall performance, but they often make systematic errors\ndue to bias or certain difficult features to learn. Thus research on slice\ndetection models (SDM) which automatically identifies underperforming groups of\ndatapoints has gradually caught more attention, which aims at both\nunderstanding model behaviors and providing insights for future model training\nand designing. However, there is little systematic research on SDM and\nquantitative evaluation of its assessment for NLP models. Our paper fills this\ngap by proposing \"Discover, Explanation, Improvement\" framework that discovers\ncoherent and underperforming groups of datapoints and unites datapoints of each\nslice under human-understandable concepts; it also provides comprehensive\nevaluation tasks and the corresponding quantitative metrics, which enable\nconvenient comparison for future works. Results show that our framework can\naccurately select error-prone datapoints with informative semantic features\nthat summarize error patterns, based on which it directly boosts model\nperformance by an average of 2.85 points based on trained models without tuning\nany parameters across multiple datasets.",
    "descriptor": "\nComments: 15 pages, 5 figures\n",
    "authors": [
      "Wenyue Hua",
      "Lifeng Jin",
      "Linfeng Song",
      "Haitao Mi",
      "Yongfeng Zhang",
      "Dong Yu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04476"
  },
  {
    "id": "arXiv:2211.04486",
    "title": "Active Example Selection for In-Context Learning",
    "abstract": "With a handful of demonstration examples, large-scale language models show\nstrong capability to perform various tasks by in-context learning from these\nexamples, without any fine-tuning. We demonstrate that in-context learning\nperformance can be highly unstable across samples of examples, indicating the\nidiosyncrasies of how language models acquire information. We formulate example\nselection for in-context learning as a sequential decision problem, and propose\na reinforcement learning algorithm for identifying generalizable policies to\nselect demonstration examples. For GPT-2, our learned policies demonstrate\nstrong abilities of generalizing to unseen tasks in training, with a $5.8\\%$\nimprovement on average. Examples selected from our learned policies can even\nachieve a small improvement on GPT-3 Ada. However, the improvement diminishes\non larger GPT-3 models, suggesting emerging capabilities of large language\nmodels.",
    "descriptor": "\nComments: EMNLP 2022, code is available at this https URL\n",
    "authors": [
      "Yiming Zhang",
      "Shi Feng",
      "Chenhao Tan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04486"
  },
  {
    "id": "arXiv:2211.04506",
    "title": "On the cut-query complexity of approximating max-cut",
    "abstract": "We consider the problem of query-efficient global max-cut on a weighted\nundirected graph in the value oracle model examined by [RSW18]. This model\narises as a natural special case of submodular function maximization: on query\n$S \\subseteq V$, the oracle returns the total weight of the cut between $S$ and\n$V \\backslash S$.\nFor most constants $c \\in (0,1]$, we nail down the query complexity of\nachieving a $c$-approximation, for both deterministic and randomized algorithms\n(up to logarithmic factors). Analogously to general submodular function\nmaximization in the same model, we observe a phase transition at $c = 1/2$: we\ndesign a deterministic algorithm for global $c$-approximate max-cut in $O(\\log\nn)$ queries for any $c < 1/2$, and show that any randomized algorithm requires\n$\\tilde{\\Omega}(n)$ queries to find a $c$-approximate max-cut for any $c >\n1/2$. Additionally, we show that any deterministic algorithm requires\n$\\Omega(n^2)$ queries to find an exact max-cut (enough to learn the entire\ngraph), and develop a $\\tilde{O}(n)$-query randomized $c$-approximation for any\n$c < 1$.\nOur approach provides two technical contributions that may be of independent\ninterest. One is a query-efficient sparsifier for undirected weighted graphs\n(prior work of [RSW18] holds only for unweighted graphs). Another is an\nextension of the cut dimension to rule out approximation (prior work of\n[GPRW20] introducing the cut dimension only rules out exact solutions).",
    "descriptor": "",
    "authors": [
      "Orestis Plevrakis",
      "Seyoon Ragavan",
      "S. Matthew Weinberg"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.04506"
  },
  {
    "id": "arXiv:2211.04508",
    "title": "SpeechMatrix: A Large-Scale Mined Corpus of Multilingual  Speech-to-Speech Translations",
    "abstract": "We present SpeechMatrix, a large-scale multilingual corpus of\nspeech-to-speech translations mined from real speech of European Parliament\nrecordings. It contains speech alignments in 136 language pairs with a total of\n418 thousand hours of speech. To evaluate the quality of this parallel speech,\nwe train bilingual speech-to-speech translation models on mined data only and\nestablish extensive baseline results on EuroParl-ST, VoxPopuli and FLEURS test\nsets. Enabled by the multilinguality of SpeechMatrix, we also explore\nmultilingual speech-to-speech translation, a topic which was addressed by few\nother works. We also demonstrate that model pre-training and sparse scaling\nusing Mixture-of-Experts bring large gains to translation performance. The\nmined data and models are freely available.",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Paul-Ambroise Duquenne",
      "Hongyu Gong",
      "Ning Dong",
      "Jingfei Du",
      "Ann Lee",
      "Vedanuj Goswani",
      "Changhan Wang",
      "Juan Pino",
      "Beno\u00eet Sagot",
      "Holger Schwenk"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.04508"
  },
  {
    "id": "arXiv:2211.04509",
    "title": "Care for the Mind Amid Chronic Diseases: An Interpretable AI Approach  Using IoT",
    "abstract": "Health sensing for chronic disease management creates immense benefits for\nsocial welfare. Existing health sensing studies primarily focus on the\nprediction of physical chronic diseases. Depression, a widespread complication\nof chronic diseases, is however understudied. We draw on the medical literature\nto support depression prediction using motion sensor data. To connect human\nexpertise in the decision-making, safeguard trust for this high-stake\nprediction, and ensure algorithm transparency, we develop an interpretable deep\nlearning model: Temporal Prototype Network (TempPNet). TempPNet is built upon\nthe emergent prototype learning models. To accommodate the temporal\ncharacteristic of sensor data and the progressive property of depression,\nTempPNet differs from existing prototype learning models in its capability of\ncapturing the temporal progression of depression. Extensive empirical analyses\nusing real-world motion sensor data show that TempPNet outperforms\nstate-of-the-art benchmarks in depression prediction. Moreover, TempPNet\ninterprets its predictions by visualizing the temporal progression of\ndepression and its corresponding symptoms detected from sensor data. We further\nconduct a user study to demonstrate its superiority over the benchmarks in\ninterpretability. This study offers an algorithmic solution for impactful\nsocial good - collaborative care of chronic diseases and depression in health\nsensing. Methodologically, it contributes to extant literature with a novel\ninterpretable deep learning model for depression prediction from sensor data.\nPatients, doctors, and caregivers can deploy our model on mobile devices to\nmonitor patients' depression risks in real-time. Our model's interpretability\nalso allows human experts to participate in the decision-making by reviewing\nthe interpretation of prediction outcomes and making informed interventions.",
    "descriptor": "\nComments: 39 pages, 12 figures\n",
    "authors": [
      "Jiaheng Xie",
      "Xiaohang Zhao",
      "Xiang Liu",
      "Xiao Fang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04509"
  },
  {
    "id": "arXiv:2211.04511",
    "title": "The $(+)$-extended twisted generalized Reed-Solomon code",
    "abstract": "In this paper, we give a parity check matrix for the $(+)$-extended twisted\ngeneralized Reed Solomon (in short, ETGRS) code, and then not only prove that\nit is MDS or NMDS, but also determine the weight distribution. Especially,\nbased on Schur method, we show that the $(+)$-ETGRS code is not GRS or EGRS.\nFurthermore, we present a sufficient and necessary condition for any punctured\ncode of the $(+)$-ETGRS code to be self-orthogonal, and then construct several\nclasses of self-dual $(+)$-TGRS codes and almost self-dual $(+)$-ETGRS codes.",
    "descriptor": "",
    "authors": [
      "Canze Zhu",
      "Qunying Liao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.04511"
  },
  {
    "id": "arXiv:2211.04515",
    "title": "QuantPipe: Applying Adaptive Post-Training Quantization for Distributed  Transformer Pipelines in Dynamic Edge Environments",
    "abstract": "Pipeline parallelism has achieved great success in deploying large-scale\ntransformer models in cloud environments, but has received less attention in\nedge environments. Unlike in cloud scenarios with high-speed and stable network\ninterconnects, dynamic bandwidth in edge systems can degrade distributed\npipeline performance. We address this issue with QuantPipe, a\ncommunication-efficient distributed edge system that introduces post-training\nquantization (PTQ) to compress the communicated tensors. QuantPipe uses\nadaptive PTQ to change bitwidths in response to bandwidth dynamics, maintaining\ntransformer pipeline performance while incurring limited inference accuracy\nloss. We further improve the accuracy with a directed-search analytical\nclipping for integer quantization method (DS-ACIQ), which bridges the gap\nbetween estimated and real data distributions. Experimental results show that\nQuantPipe adapts to dynamic bandwidth to maintain pipeline performance while\nachieving a practical model accuracy using a wide range of quantization\nbitwidths, e.g., improving accuracy under 2-bit quantization by 15.85\\% on\nImageNet compared to naive quantization.",
    "descriptor": "",
    "authors": [
      "Haonan Wang",
      "Connor Imes",
      "Souvik Kundu",
      "Peter A. Beerel",
      "Stephen P. Crago",
      "John Paul Walters"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.04515"
  },
  {
    "id": "arXiv:2211.04517",
    "title": "Deep IMU Bias Inference for Robust Visual-Inertial Odometry with Factor  Graphs",
    "abstract": "Visual Inertial Odometry (VIO) is one of the most established state\nestimation methods for mobile platforms. However, when visual tracking fails,\nVIO algorithms quickly diverge due to rapid error accumulation during inertial\ndata integration. This error is typically modeled as a combination of additive\nGaussian noise and a slowly changing bias which evolves as a random walk. In\nthis work, we propose to train a neural network to learn the true bias\nevolution. We implement and compare two common sequential deep learning\narchitectures: LSTMs and Transformers. Our approach follows from recent\nlearning-based inertial estimators, but, instead of learning a motion model, we\ntarget IMU bias explicitly, which allows us to generalize to locomotion\npatterns unseen in training. We show that our proposed method improves state\nestimation in visually challenging situations across a wide range of motions by\nquadrupedal robots, walking humans, and drones. Our experiments show an average\n15% reduction in drift rate, with much larger reductions when there is total\nvision failure. Importantly, we also demonstrate that models trained with one\nlocomotion pattern (human walking) can be applied to another (quadruped robot\ntrotting) without retraining.",
    "descriptor": "\nComments: Accepted to Robotics and Automation Letters\n",
    "authors": [
      "Russell Buchanan",
      "Varun Agrawal",
      "Marco Camurri",
      "Frank Dellaert",
      "Maurice Fallon"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.04517"
  },
  {
    "id": "arXiv:2211.04519",
    "title": "Several classes of projective few-weight linear codes and their  applications",
    "abstract": "It is well-known that few-weight linear codes have better applications in\nsecret sharing schemes \\cite{JY2006,CC2005}.In particular, projective\ntwo-weight codes are very precious as they are closely related to finite\nprojective spaces, strongly regular graphs and combinatorial designs\n\\cite{RC1986,CD2018,P1972}. Here, we present the following two applications.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2107.02446\n",
    "authors": [
      "Canze Zhu",
      "Qunying Liao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.04519"
  },
  {
    "id": "arXiv:2211.04524",
    "title": "Knowledge Retrieval for Robotic Cooking",
    "abstract": "Search algorithms are applied where data retrieval with specified\nspecifications is required. The motivation behind developing search algorithms\nin Functional Object-Oriented Networks is that most of the time, a certain\nrecipe needs to be retrieved or ingredients for a certain recipe needs to be\ndetermined. According to the introduction, there is a time when execution of an\nentire recipe is not available for a robot thus prompting the need to retrieve\na certain recipe or ingredients. With a quality FOON, robots can decipher a\ntask goal, find the correct objects at the required states on which to operate\nand output a sequence of proper manipulation motions. This paper shows several\nproposed weighted FOON and task planning algorithms that allow a robot and a\nhuman to successfully complete complicated tasks together with higher success\nrates than a human doing them alone.",
    "descriptor": "\nComments: 3 pages, 1 figure, and 2 tables\n",
    "authors": [
      "Kundana Mandapaka"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04524"
  },
  {
    "id": "arXiv:2211.04526",
    "title": "Disclosure of a Neuromorphic Starter Kit",
    "abstract": "This paper presents a Neuromorphic Starter Kit, which has been designed to\nhelp a variety of research groups perform research, exploration and real-world\ndemonstrations of brain-based, neuromorphic processors and hardware\nenvironments. A prototype kit has been built and tested. We explain the\nmotivation behind the kit, its design and composition, and a prototype physical\ndemonstration.",
    "descriptor": "\nComments: 4 pages, 3 figures\n",
    "authors": [
      "James S. Plank",
      "Bryson Gullett",
      "Adam Z. Foshie",
      "Garrett S. Rose",
      "Catherine D. Schuman"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.04526"
  },
  {
    "id": "arXiv:2211.04530",
    "title": "Creating a Safety Assurance Case for an ML Satellite-Based Wildfire  Detection and Alert System",
    "abstract": "Wildfires are a common problem in many areas of the world with often\ncatastrophic consequences. A number of systems have been created to provide\nearly warnings of wildfires, including those that use satellite data to detect\nfires. The increased availability of small satellites, such as CubeSats, allows\nthe wildfire detection response time to be reduced by deploying constellations\nof multiple satellites over regions of interest. By using machine learned\ncomponents on-board the satellites, constraints which limit the amount of data\nthat can be processed and sent back to ground stations can be overcome. There\nare hazards associated with wildfire alert systems, such as failing to detect\nthe presence of a wildfire, or detecting a wildfire in the incorrect location.\nIt is therefore necessary to be able to create a safety assurance case for the\nwildfire alert ML component that demonstrates it is sufficiently safe for use.\nThis paper describes in detail how a safety assurance case for an ML wildfire\nalert system is created. This represents the first fully developed safety case\nfor an ML component containing explicit argument and evidence as to the safety\nof the machine learning.",
    "descriptor": "",
    "authors": [
      "Richard Hawkins",
      "Chiara Picardi",
      "Lucy Donnell",
      "Murray Ireland"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.04530"
  },
  {
    "id": "arXiv:2211.04533",
    "title": "Harmonizing the object recognition strategies of deep neural networks  with humans",
    "abstract": "The many successes of deep neural networks (DNNs) over the past decade have\nlargely been driven by computational scale rather than insights from biological\nintelligence. Here, we explore if these trends have also carried concomitant\nimprovements in explaining the visual strategies humans rely on for object\nrecognition. We do this by comparing two related but distinct properties of\nvisual strategies in humans and DNNs: where they believe important visual\nfeatures are in images and how they use those features to categorize objects.\nAcross 84 different DNNs trained on ImageNet and three independent datasets\nmeasuring the where and the how of human visual strategies for object\nrecognition on those images, we find a systematic trade-off between DNN\ncategorization accuracy and alignment with human visual strategies for object\nrecognition. State-of-the-art DNNs are progressively becoming less aligned with\nhumans as their accuracy improves. We rectify this growing issue with our\nneural harmonizer: a general-purpose training routine that both aligns DNN and\nhuman visual strategies and improves categorization accuracy. Our work\nrepresents the first demonstration that the scaling laws that are guiding the\ndesign of DNNs today have also produced worse models of human vision. We\nrelease our code and data at https://serre-lab.github.io/Harmonization to help\nthe field build more human-like DNNs.",
    "descriptor": "\nComments: Published at NeurIPS 2022\n",
    "authors": [
      "Thomas Fel",
      "Ivan Felipe",
      "Drew Linsley",
      "Thomas Serre"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04533"
  },
  {
    "id": "arXiv:2211.04534",
    "title": "Going for GOAL: A Resource for Grounded Football Commentaries",
    "abstract": "Recent video+language datasets cover domains where the interaction is highly\nstructured, such as instructional videos, or where the interaction is scripted,\nsuch as TV shows. Both of these properties can lead to spurious cues to be\nexploited by models rather than learning to ground language. In this paper, we\npresent GrOunded footbAlL commentaries (GOAL), a novel dataset of football (or\n`soccer') highlights videos with transcribed live commentaries in English. As\nthe course of a game is unpredictable, so are commentaries, which makes them a\nunique resource to investigate dynamic language grounding. We also provide\nstate-of-the-art baselines for the following tasks: frame reordering, moment\nretrieval, live commentary retrieval and play-by-play live commentary\ngeneration. Results show that SOTA models perform reasonably well in most\ntasks. We discuss the implications of these results and suggest new tasks for\nwhich GOAL can be used. Our codebase is available at:\nhttps://gitlab.com/grounded-sport-convai/goal-baselines.",
    "descriptor": "\nComments: Preprint formatted using the ACM Multimedia template (8 pages + appendix)\n",
    "authors": [
      "Alessandro Suglia",
      "Jos\u00e9 Lopes",
      "Emanuele Bastianelli",
      "Andrea Vanzo",
      "Shubham Agarwal",
      "Malvina Nikandrou",
      "Lu Yu",
      "Ioannis Konstas",
      "Verena Rieser"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.04534"
  },
  {
    "id": "arXiv:2211.04535",
    "title": "Asymptotically Optimal Stochastic Lossy Coding of Markov Sources",
    "abstract": "An effective 'on-the-fly' mechanism for stochastic lossy coding of Markov\nsources using string matching techniques is proposed in this paper. Earlier\nwork has shown that the rate-distortion bound can be asymptotically achieved by\na 'natural type selection' (NTS) mechanism which iteratively encodes\nasymptotically long source strings (from an unknown source distribution P) and\nregenerates the codebook according to a maximum likelihood distribution\nframework, after observing a set of K codewords to 'd-match' (i.e., satisfy the\ndistortion constraint for) a respective set of K source words. This result was\nlater generalized for sources with memory under the assumption that the source\nwords must contain a sequence of asymptotic-length vectors (or super-symbols)\nover the source super-alphabet, i.e., the source is considered a vector source.\nHowever, the earlier result suffers from a significant practical flaw, more\nspecifically, it requires expanding the super-symbols (and correspondingly the\nsuper-alphabet) lengths to infinity in order to achieve the rate-distortion\nbound, even for finite memory sources, e.g., Markov sources. This implies that\nthe complexity of the NTS iteration will explode beyond any practical\ncapabilities, thus compromising the promise of the NTS algorithm in practical\nscenarios for sources with memory. This work describes a considerably more\nefficient and tractable mechanism to achieve asymptotically optimal performance\ngiven a prescribed memory constraint, within a practical framework tailored to\nMarkov sources. More specifically, the algorithm finds asymptotically the\noptimal codebook reproduction distribution, within a constrained set of\ndistributions having Markov property with a prescribed order, that achieves the\nminimum per letter coding rate while maintaining a specified distortion level.",
    "descriptor": "",
    "authors": [
      "Ahmed Elshafiy",
      "Kenneth Rose"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.04535"
  },
  {
    "id": "arXiv:2211.04538",
    "title": "ARMOR: A Model-based Framework for Improving Arbitrary Baseline Policies  with Offline Data",
    "abstract": "We propose a new model-based offline RL framework, called Adversarial Models\nfor Offline Reinforcement Learning (ARMOR), which can robustly learn policies\nto improve upon an arbitrary baseline policy regardless of data coverage. Based\non the concept of relative pessimism, ARMOR is designed to optimize for the\nworst-case relative performance when facing uncertainty. In theory, we prove\nthat the learned policy of ARMOR never degrades the performance of the baseline\npolicy with any admissible hyperparameter, and can learn to compete with the\nbest policy within data coverage when the hyperparameter is well tuned, and the\nbaseline policy is supported by the data. Such a robust policy improvement\nproperty makes ARMOR especially suitable for building real-world learning\nsystems, because in practice ensuring no performance degradation is imperative\nbefore considering any benefit learning can bring.",
    "descriptor": "",
    "authors": [
      "Tengyang Xie",
      "Mohak Bhardwaj",
      "Nan Jiang",
      "Ching-An Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04538"
  },
  {
    "id": "arXiv:2211.04539",
    "title": "Physics-informed inference of aerial animal movements from weather radar  data",
    "abstract": "Studying animal movements is essential for effective wildlife conservation\nand conflict mitigation. For aerial movements, operational weather radars have\nbecome an indispensable data source in this respect. However, partial\nmeasurements, incomplete spatial coverage, and poor understanding of animal\nbehaviours make it difficult to reconstruct complete spatio-temporal movement\npatterns from available radar data. We tackle this inverse problem by learning\na mapping from high-dimensional radar measurements to low-dimensional latent\nrepresentations using a convolutional encoder. Under the assumption that the\nlatent system dynamics are well approximated by a locally linear Gaussian\ntransition model, we perform efficient posterior estimation using the classical\nKalman smoother. A convolutional decoder maps the inferred latent system states\nback to the physical space in which the known radar observation model can be\napplied, enabling fully unsupervised training. To encourage physical\nconsistency, we additionally introduce a physics-informed loss term that\nleverages known mass conservation constraints. Our experiments on synthetic\nradar data show promising results in terms of reconstruction quality and\ndata-efficiency.",
    "descriptor": "\nComments: NeurIPS 2022, AI4Science workshop\n",
    "authors": [
      "Fiona Lippert",
      "Bart Kranstauber",
      "E. Emiel van Loon",
      "Patrick Forr\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04539"
  },
  {
    "id": "arXiv:2211.04542",
    "title": "Multiple-Valued Logic Circuit Design and Data Transmission Intended for  Embedded Systems",
    "abstract": "This thesis proposes novel ternary circuits aiming to reduce energy to\npreserve battery consumption. The proposed designs include eight ternary logic\ngates, three ternary combinational circuits, and six Ternary Arithmetic Logic\nUnits. This thesis applies the best tradeoff between reducing the number of\nused transistors, utilizing energy efficient transistor arrangements such as\ntransmission gates, and applying the dual supply voltages to achieve its\nobjective. The proposed designs are compared to the latest ternary circuits\nusing the HSPICE simulator for different supply voltages, different\ntemperatures, and different frequencies. Simulations are performed to prove the\nefficiency of the proposed designs. The results demonstrate the advantage of\nthe proposed designs with a reduction of over 73 percent in terms of transistor\ncount for the THA and over 88 percent in energy consumption for the STI, TNAND,\nTDecoder, TMUX, THA, and TMUL, respectively. Moreover, the noise immunity curve\nand Monte Carlo analysis for major process variations, TOX, CNT Diameter, CNT\nCount, and Channel length, were studied.",
    "descriptor": "\nComments: Ph.D. Dissertation\n",
    "authors": [
      "Ramzi A. Jaber",
      "Lina Nimri",
      "Ali M. Haidar"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Hardware Architecture (cs.AR)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.04542"
  },
  {
    "id": "arXiv:2211.04545",
    "title": "Voting on Cyclic Orders, Group Theory, and Ballots",
    "abstract": "A cyclic order may be thought of informally as a way to seat people around a\ntable, perhaps for a game of chance or for dinner. Given a set of agents such\nas $\\{A,B,C\\}$, we can formalize this by defining a cyclic order as a\npermutation or linear order on this finite set, under the equivalence relation\nwhere $A\\succ B\\succ C$ is identified with both $B\\succ C\\succ A$ and $C\\succ\nA\\succ B$. As with other collections of sets with some structure, we might want\nto aggregate preferences of a (possibly different) set of voters on the set of\npossible ways to choose a cyclic order.\nHowever, given the combinatorial explosion of the number of full rankings of\ncyclic orders, one may not wish to use the usual voting machinery. This raises\nthe question of what sort of ballots may be appropriate; a single cyclic order,\na set of them, or some other ballot type? Further, there is a natural action of\nthe group of permutations on the set of agents. A reasonable requirement for a\nchoice procedure would be to respect this symmetry (the equivalent of\nneutrality in normal voting theory).\nIn this paper we will exploit the representation theory of the symmetric\ngroup to analyze several natural types of ballots for voting on cyclic orders,\nand points-based procedures using such ballots. We provide a full\ncharacterization of such procedures for two quite different ballot types for\n$n=4$, along with the most important observations for $n=5$.",
    "descriptor": "\nComments: 29 pages, to be published in conference proceedings from AMS Special Session on The Mathematics of Decisions, Elections and Games, 2022\n",
    "authors": [
      "Karl-Dieter Crisman",
      "Abraham Holleran",
      "Micah Martin",
      "Josephine Noonan"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Representation Theory (math.RT)"
    ],
    "url": "https://arxiv.org/abs/2211.04545"
  },
  {
    "id": "arXiv:2211.04550",
    "title": "OutlierDetection.jl: A modular outlier detection ecosystem for the Julia  programming language",
    "abstract": "OutlierDetection.jl is an open-source ecosystem for outlier detection in\nJulia. It provides a range of high-performance outlier detection algorithms\nimplemented directly in Julia. In contrast to previous packages, our ecosystem\nenables the development highly-scalable outlier detection algorithms using a\nhigh-level programming language. Additionally, it provides a standardized, yet\nflexible, interface for future outlier detection algorithms and allows for\nmodel composition unseen in previous packages. Best practices such as unit\ntesting, continuous integration, and code coverage reporting are enforced\nacross the ecosystem. The most recent version of OutlierDetection.jl is\navailable at https://github.com/OutlierDetectionJL/OutlierDetection.jl.",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "David Muhr",
      "Michael Affenzeller",
      "Anthony D. Blaom"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04550"
  },
  {
    "id": "arXiv:2211.04555",
    "title": "Detecting and Accommodating Novel Types and Concepts in an Embodied  Simulation Environment",
    "abstract": "In this paper, we present methods for two types of metacognitive tasks in an\nAI system: rapidly expanding a neural classification model to accommodate a new\ncategory of object, and recognizing when a novel object type is observed\ninstead of misclassifying the observation as a known class. Our methods take\nnumerical data drawn from an embodied simulation environment, which describes\nthe motion and properties of objects when interacted with, and we demonstrate\nthat this type of representation is important for the success of novel type\ndetection. We present a suite of experiments in rapidly accommodating the\nintroduction of new categories and concepts and in novel type detection, and an\narchitecture to integrate the two in an interactive system.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2204.08107\n",
    "authors": [
      "Sadaf Ghaffari",
      "Nikhil Krishnaswamy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04555"
  },
  {
    "id": "arXiv:2211.04557",
    "title": "Estimation of Appearance and Occupancy Information in Birds Eye View  from Surround Monocular Images",
    "abstract": "Autonomous driving requires efficient reasoning about the location and\nappearance of the different agents in the scene, which aids in downstream tasks\nsuch as object detection, object tracking, and path planning. The past few\nyears have witnessed a surge in approaches that combine the different taskbased\nmodules of the classic self-driving stack into an End-toEnd(E2E) trainable\nlearning system. These approaches replace perception, prediction, and sensor\nfusion modules with a single contiguous module with shared latent space\nembedding, from which one extracts a human-interpretable representation of the\nscene. One of the most popular representations is the Birds-eye View (BEV),\nwhich expresses the location of different traffic participants in the ego\nvehicle frame from a top-down view. However, a BEV does not capture the\nchromatic appearance information of the participants. To overcome this\nlimitation, we propose a novel representation that captures various traffic\nparticipants appearance and occupancy information from an array of monocular\ncameras covering 360 deg field of view (FOV). We use a learned image embedding\nof all camera images to generate a BEV of the scene at any instant that\ncaptures both appearance and occupancy of the scene, which can aid in\ndownstream tasks such as object tracking and executing language-based commands.\nWe test the efficacy of our approach on synthetic dataset generated from CARLA.\nThe code, data set, and results can be found at https://rebrand.ly/APP\nOCC-results.",
    "descriptor": "",
    "authors": [
      "Sarthak Sharma",
      "Unnikrishnan R. Nair",
      "Udit Singh Parihar",
      "Midhun Menon S",
      "Srikanth Vidapanakal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.04557"
  },
  {
    "id": "arXiv:2211.04560",
    "title": "Focused Dynamic Slicing for Large Applications using an Abstract  Memory-Model",
    "abstract": "Dynamic slicing techniques compute program dependencies to find all\nstatements that affect the value of a variable at a program point for a\nspecific execution. Despite their many potential uses, applicability is limited\nby the fact that they typically cannot scale beyond small-sized applications.\nWe believe that at the heart of this limitation is the use of memory references\nto identify data-dependencies. Particularly, working with memory references\nhinders distinct treatment of the code-to-be-sliced (e.g., classes the user has\nan interest in) from the rest of the code (including libraries and frameworks).\nThe ability to perform a coarser-grained analysis for the code that is not\nunder focus may provide performance gains and could become one avenue toward\nscalability. In this paper, we propose a novel approach that completely\nreplaces memory reference registering and processing with a memory analysis\nmodel that works with program symbols (i.e., terms). In fact, this approach\nenables the alternative of not instrumenting -- thus, not generating any trace\n-- for code that is not part of the code-to-be-sliced. We report on an\nimplementation of an abstract dynamic slicer for C\\#, \\textit{DynAbs}, and an\nevaluation that shows how large and relevant parts of Roslyn and Powershell --\ntwo of the largest and modern C\\# applications that can be found in GitHub --\ncan be sliced for their test cases assertions in at most a few minutes. We also\nshow how reducing the code-to-be-sliced focus can bring important speedups with\nmarginal relative precision loss.",
    "descriptor": "",
    "authors": [
      "Alexis Soifer",
      "Diego Garbervetsky",
      "Victor Braberman",
      "Sebastian Uchitel"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.04560"
  },
  {
    "id": "arXiv:2211.04569",
    "title": "Toward a Neural Semantic Parsing System for EHR Question Answering",
    "abstract": "Clinical semantic parsing (SP) is an important step toward identifying the\nexact information need (as a machine-understandable logical form) from a\nnatural language query aimed at retrieving information from electronic health\nrecords (EHRs). Current approaches to clinical SP are largely based on\ntraditional machine learning and require hand-building a lexicon. The recent\nadvancements in neural SP show a promise for building a robust and flexible\nsemantic parser without much human effort. Thus, in this paper, we aim to\nsystematically assess the performance of two such neural SP models for EHR\nquestion answering (QA). We found that the performance of these advanced neural\nmodels on two clinical SP datasets is promising given their ease of application\nand generalizability. Our error analysis surfaces the common types of errors\nmade by these models and has the potential to inform future research into\nimproving the performance of neural SP models for EHR QA.",
    "descriptor": "\nComments: Accepted at the AMIA Annual Symposium 2022 (10 pages, 5 tables, 1 figure)\n",
    "authors": [
      "Sarvesh Soni",
      "Kirk Roberts"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.04569"
  },
  {
    "id": "arXiv:2211.04571",
    "title": "HySenSe: A Hyper-Sensitive and High-Fidelity Vision-Based Tactile Sensor",
    "abstract": "In this paper, to address the sensitivity and durability trade-off of\nVision-based Tactile Sensor (VTSs), we introduce a hyper-sensitive and\nhigh-fidelity VTS called HySenSe. We demonstrate that by solely changing one\nstep during the fabrication of the gel layer of the GelSight sensor (as the\nmost well-known VTS), we can substantially improve its sensitivity and\ndurability. Our experimental results clearly demonstrate the outperformance of\nthe HySenSe compared with a similar GelSight sensor in detecting textural\ndetails of various objects under identical experimental conditions and low\ninteraction forces (<= 1.5 N).",
    "descriptor": "\nComments: Accepted to IEEE Sensors 2022 Conference\n",
    "authors": [
      "Ozdemir Can Kara",
      "Naruhiko Ikoma",
      "Farshid Alambeigi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.04571"
  },
  {
    "id": "arXiv:2211.04576",
    "title": "Detecting Euphemisms with Literal Descriptions and Visual Imagery",
    "abstract": "This paper describes our two-stage system for the Euphemism Detection shared\ntask hosted by the 3rd Workshop on Figurative Language Processing in\nconjunction with EMNLP 2022. Euphemisms tone down expressions about sensitive\nor unpleasant issues like addiction and death. The ambiguous nature of\neuphemistic words or expressions makes it challenging to detect their actual\nmeaning within a context. In the first stage, we seek to mitigate this\nambiguity by incorporating literal descriptions into input text prompts to our\nbaseline model. It turns out that this kind of direct supervision yields\nremarkable performance improvement. In the second stage, we integrate visual\nsupervision into our system using visual imageries, two sets of images\ngenerated by a text-to-image model by taking terms and descriptions as input.\nOur experiments demonstrate that visual supervision also gives a statistically\nsignificant performance boost. Our system achieved the second place with an F1\nscore of 87.2%, only about 0.9% worse than the best submission.",
    "descriptor": "\nComments: 7 pages, 1 table, 1 figure. Accepted to the 3rd Workshop on Figurative Language Processing at EMNLP 2022. this https URL\n",
    "authors": [
      "\u0130lker Kesen",
      "Aykut Erdem",
      "Erkut Erdem",
      "Iacer Calixto"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04576"
  },
  {
    "id": "arXiv:2211.04577",
    "title": "Understanding Political Agreements and Disagreements: Evidence from the  2022 French Presidential Election",
    "abstract": "Since the seminal works of Condorcet and Borda, social choice theory has\nexplored how to aggregate individual preferences into collective decisions.\nYet, social choice theory has focused primarily on identifying winners in\nelections involving few candidates, leaving questions about direct\nparticipation on multiple issues relatively unexplored. Here we analyze data\ncollected in a direct participation experiment where people built their own\ngovernment programs using 120 proposals from the candidates of the 2022 French\npresidential. We find that in this setting it is useful to introduce a measure\nof \"divisiveness,\" which can be constructed for any voting rule, is orthogonal\nto them, and helps identify polarizing proposals. We show that divisiveness\ncaptures fragmentation across multiple dimensions (sex, age, political\norientation, and urban-rural divide) and explore some of its axiomatic\nproperties. These results suggest divisiveness is a relevant aggregate in\ndirect forms of participation.",
    "descriptor": "\nComments: 23 pages main manuscript with 8 figures. 25 pages of supplementary material\n",
    "authors": [
      "Carlos Navarrete",
      "Nicole Ferrada",
      "Mariana Macedo",
      "Rachael Colley",
      "Jingling Zhang",
      "Umberto Grandi",
      "Jerome Lang",
      "C\u00e9sar A. Hidalgo"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.04577"
  },
  {
    "id": "arXiv:2211.04582",
    "title": "Learning to Learn Domain-invariant Parameters for Domain Generalization",
    "abstract": "Due to domain shift, deep neural networks (DNNs) usually fail to generalize\nwell on unknown test data in practice. Domain generalization (DG) aims to\novercome this issue by capturing domain-invariant representations from source\ndomains. Motivated by the insight that only partial parameters of DNNs are\noptimized to extract domain-invariant representations, we expect a general\nmodel that is capable of well perceiving and emphatically updating such\ndomain-invariant parameters. In this paper, we propose two modules of Domain\nDecoupling and Combination (DDC) and Domain-invariance-guided Backpropagation\n(DIGB), which can encourage such general model to focus on the parameters that\nhave a unified optimization direction between pairs of contrastive samples. Our\nextensive experiments on two benchmarks have demonstrated that our proposed\nmethod has achieved state-of-the-art performance with strong generalization\ncapability.",
    "descriptor": "\nComments: Submitted to ICASSP'23\n",
    "authors": [
      "Feng Hou",
      "Yao Zhang",
      "Yang Liu",
      "Jin Yuan",
      "Cheng Zhong",
      "Yang Zhang",
      "Zhongchao Shi",
      "Jianping Fan",
      "Zhiqiang He"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04582"
  },
  {
    "id": "arXiv:2211.04583",
    "title": "Wall Street Tree Search: Risk-Aware Planning for Offline Reinforcement  Learning",
    "abstract": "Offline reinforcement-learning (RL) algorithms learn to make decisions using\na given, fixed training dataset without the possibility of additional online\ndata collection. This problem setting is captivating because it holds the\npromise of utilizing previously collected datasets without any costly or risky\ninteraction with the environment. However, this promise also bears the drawback\nof this setting. The restricted dataset induces subjective uncertainty because\nthe agent can encounter unfamiliar sequences of states and actions that the\ntraining data did not cover. Moreover, inherent system stochasticity further\nincreases uncertainty and aggravates the offline RL problem, preventing the\nagent from learning an optimal policy. To mitigate the destructive uncertainty\neffects, we need to balance the aspiration to take reward-maximizing actions\nwith the incurred risk due to incorrect ones. In financial economics, modern\nportfolio theory (MPT) is a method that risk-averse investors can use to\nconstruct diversified portfolios that maximize their returns without\nunacceptable levels of risk. We integrate MPT into the agent's decision-making\nprocess to present a simple-yet-highly-effective risk-aware planning algorithm\nfor offline RL. Our algorithm allows us to systematically account for the\n\\emph{estimated quality} of specific actions and their \\emph{estimated risk}\ndue to the uncertainty. We show that our approach can be coupled with the\nTransformer architecture to yield a state-of-the-art planner for offline RL\ntasks, maximizing the return while significantly reducing the variance.",
    "descriptor": "\nComments: Accepted to Foundation Models for Decision Making (FMDM) Workshop at 36th Conference on Neural Information Processing Systems (NeurIPS)\n",
    "authors": [
      "Dan Elbaz",
      "Gal Novik",
      "Oren Salzman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.04583"
  },
  {
    "id": "arXiv:2211.04584",
    "title": "Energy System Digitization in the Era of AI: A Three-Layered Approach  towards Carbon Neutrality",
    "abstract": "The transition towards carbon-neutral electricity is one of the biggest game\nchangers in addressing climate change since it addresses the dual challenges of\nremoving carbon emissions from the two largest sectors of emitters: electricity\nand transportation. The transition to a carbon-neutral electric grid poses\nsignificant challenges to conventional paradigms of modern grid planning and\noperation. Much of the challenge arises from the scale of the decision making\nand the uncertainty associated with the energy supply and demand. Artificial\nIntelligence (AI) could potentially have a transformative impact on\naccelerating the speed and scale of carbon-neutral transition, as many decision\nmaking processes in the power grid can be cast as classic, though challenging,\nmachine learning tasks. We point out that to amplify AI's impact on\ncarbon-neutral transition of the electric energy systems, the AI algorithms\noriginally developed for other applications should be tailored in three layers\nof technology, markets, and policy.",
    "descriptor": "\nComments: To be published in Patterns (Cell Press)\n",
    "authors": [
      "Le Xie",
      "Tong Huang",
      "Xiangtian Zheng",
      "Yan Liu",
      "Mengdi Wang",
      "Vijay Vittal",
      "P. R. Kumar",
      "Srinivas Shakkottai",
      "Yi Cui"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.04584"
  },
  {
    "id": "arXiv:2211.04586",
    "title": "Learning to Price Supply Chain Contracts against a Learning Retailer",
    "abstract": "The rise of big data analytics has automated the decision-making of companies\nand increased supply chain agility. In this paper, we study the supply chain\ncontract design problem faced by a data-driven supplier who needs to respond to\nthe inventory decisions of the downstream retailer. Both the supplier and the\nretailer are uncertain about the market demand and need to learn about it\nsequentially. The goal for the supplier is to develop data-driven pricing\npolicies with sublinear regret bounds under a wide range of possible retailer\ninventory policies for a fixed time horizon.\nTo capture the dynamics induced by the retailer's learning policy, we first\nmake a connection to non-stationary online learning by following the notion of\nvariation budget. The variation budget quantifies the impact of the retailer's\nlearning strategy on the supplier's decision-making. We then propose dynamic\npricing policies for the supplier for both discrete and continuous demand. We\nalso note that our proposed pricing policy only requires access to the support\nof the demand distribution, but critically, does not require the supplier to\nhave any prior knowledge about the retailer's learning policy or the demand\nrealizations. We examine several well-known data-driven policies for the\nretailer, including sample average approximation, distributionally robust\noptimization, and parametric approaches, and show that our pricing policies\nlead to sublinear regret bounds in all these cases.\nAt the managerial level, we answer affirmatively that there is a pricing\npolicy with a sublinear regret bound under a wide range of retailer's learning\npolicies, even though she faces a learning retailer and an unknown demand\ndistribution. Our work also provides a novel perspective in data-driven\noperations management where the principal has to learn to react to the learning\npolicies employed by other agents in the system.",
    "descriptor": "",
    "authors": [
      "Xuejun Zhao",
      "Ruihao Zhu",
      "William B. Haskell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Theoretical Economics (econ.TH)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.04586"
  },
  {
    "id": "arXiv:2211.04589",
    "title": "Finite Sample Identification of Wide Shallow Neural Networks with Biases",
    "abstract": "Artificial neural networks are functions depending on a finite number of\nparameters typically encoded as weights and biases. The identification of the\nparameters of the network from finite samples of input-output pairs is often\nreferred to as the \\emph{teacher-student model}, and this model has represented\na popular framework for understanding training and generalization. Even if the\nproblem is NP-complete in the worst case, a rapidly growing literature -- after\nadding suitable distributional assumptions -- has established finite sample\nidentification of two-layer networks with a number of neurons $m=\\mathcal\nO(D)$, $D$ being the input dimension. For the range $D<m<D^2$ the problem\nbecomes harder, and truly little is known for networks parametrized by biases\nas well. This paper fills the gap by providing constructive methods and\ntheoretical guarantees of finite sample identification for such wider shallow\nnetworks with biases. Our approach is based on a two-step pipeline: first, we\nrecover the direction of the weights, by exploiting second order information;\nnext, we identify the signs by suitable algebraic evaluations, and we recover\nthe biases by empirical risk minimization via gradient descent. Numerical\nresults demonstrate the effectiveness of our approach.",
    "descriptor": "",
    "authors": [
      "Massimo Fornasier",
      "Timo Klock",
      "Marco Mondelli",
      "Michael Rauchensteiner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.04589"
  },
  {
    "id": "arXiv:2211.04591",
    "title": "Learning to Follow Instructions in Text-Based Games",
    "abstract": "Text-based games present a unique class of sequential decision making problem\nin which agents interact with a partially observable, simulated environment via\nactions and observations conveyed through natural language. Such observations\ntypically include instructions that, in a reinforcement learning (RL) setting,\ncan directly or indirectly guide a player towards completing reward-worthy\ntasks. In this work, we study the ability of RL agents to follow such\ninstructions. We conduct experiments that show that the performance of\nstate-of-the-art text-based game agents is largely unaffected by the presence\nor absence of such instructions, and that these agents are typically unable to\nexecute tasks to completion. To further study and address the task of\ninstruction following, we equip RL agents with an internal structured\nrepresentation of natural language instructions in the form of Linear Temporal\nLogic (LTL), a formal language that is increasingly used for temporally\nextended reward specification in RL. Our framework both supports and highlights\nthe benefit of understanding the temporal semantics of instructions and in\nmeasuring progress towards achievement of such a temporally extended behaviour.\nExperiments with 500+ games in TextWorld demonstrate the superior performance\nof our approach.",
    "descriptor": "\nComments: NeurIPS 2022\n",
    "authors": [
      "Mathieu Tuli",
      "Andrew C. Li",
      "Pashootan Vaezipoor",
      "Toryn Q. Klassen",
      "Scott Sanner",
      "Sheila A. McIlraith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.04591"
  },
  {
    "id": "arXiv:2211.04598",
    "title": "Reducing Down(stream)time: Pretraining Molecular GNNs using  Heterogeneous AI Accelerators",
    "abstract": "The demonstrated success of transfer learning has popularized approaches that\ninvolve pretraining models from massive data sources and subsequent finetuning\ntowards a specific task. While such approaches have become the norm in fields\nsuch as natural language processing, implementation and evaluation of transfer\nlearning approaches for chemistry are in the early stages. In this work, we\ndemonstrate finetuning for downstream tasks on a graph neural network (GNN)\ntrained over a molecular database containing 2.7 million water clusters. The\nuse of Graphcore IPUs as an AI accelerator for training molecular GNNs reduces\ntraining time from a reported 2.7 days on 0.5M clusters to 1.2 hours on 2.7M\nclusters. Finetuning the pretrained model for downstream tasks of molecular\ndynamics and transfer to a different potential energy surface took only 8.3\nhours and 28 minutes, respectively, on a single GPU.",
    "descriptor": "\nComments: Machine Learning and the Physical Sciences Workshop at the 36th conference on Neural Information Processing Systems (NeurIPS)\n",
    "authors": [
      "Jenna A. Bilbrey",
      "Kristina M. Herman",
      "Henry Sprueill",
      "Soritis S. Xantheas",
      "Payel Das",
      "Manuel Lopez Roldan",
      "Mike Kraus",
      "Hatem Helal",
      "Sutanay Choudhury"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atomic and Molecular Clusters (physics.atm-clus)"
    ],
    "url": "https://arxiv.org/abs/2211.04598"
  },
  {
    "id": "arXiv:2211.04601",
    "title": "Universal Sorting: Finding a DAG using Priced Comparisons",
    "abstract": "We resolve two open problems in sorting with priced information, introduced\nby [Charikar, Fagin, Guruswami, Kleinberg, Raghavan, Sahai (CFGKRS), STOC\n2000]. In this setting, different comparisons have different (potentially\ninfinite) costs. The goal is to sort with small competitive ratio (algorithmic\ncost divided by cheapest proof).\n1) When all costs are in $\\{0,1,n,\\infty\\}$, we give an algorithm that has\n$\\widetilde{O}(n^{3/4})$ competitive ratio. Our algorithm generalizes the\nalgorithms for generalized sorting (all costs are either $1$ or $\\infty$), a\nversion initiated by [Huang, Kannan, Khanna, FOCS 2011] and addressed recently\nby [Kuszmaul, Narayanan, FOCS 2021].\n2) We answer the problem of bichromatic sorting posed by [CFGKRS]: The input\nis split into $A$ and $B$, and $A-A$ and $B-B$ comparisons are more expensive\nthan an $A-B$ comparisons. We give a randomized algorithm with a O(polylog n)\ncompetitive ratio.\nThese results are obtained by introducing the universal sorting problem,\nwhich generalizes the existing framework in two important ways. We remove the\npromise of a directed Hamiltonian path in the DAG of all comparisons. Instead,\nwe require that an algorithm outputs the transitive reduction of the DAG. For\nbichromatic sorting, when $A-A$ and $B-B$ comparisons cost $\\infty$, this\ngeneralizes the well-known nuts and bolts problem. We initiate an\ninstance-based study of the universal sorting problem. Our definition of\ninstance-optimality is inherently more algorithmic than that of the competitive\nratio in that we compare the cost of a candidate algorithm to the cost of the\noptimal instance-aware algorithm. This unifies existing lower bounds, and opens\nup the possibility of an $O(1)$-instance optimal algorithm for the bichromatic\nversion.",
    "descriptor": "\nComments: 40 pages, 5 figures\n",
    "authors": [
      "Mayank Goswami",
      "Riko Jacob"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.04601"
  },
  {
    "id": "arXiv:2211.04602",
    "title": "System Safety Engineering for Social and Ethical ML Risks: A Case Study",
    "abstract": "Governments, industry, and academia have undertaken efforts to identify and\nmitigate harms in ML-driven systems, with a particular focus on social and\nethical risks of ML components in complex sociotechnical systems. However,\nexisting approaches are largely disjointed, ad-hoc and of unknown\neffectiveness. Systems safety engineering is a well established discipline with\na track record of identifying and managing risks in many complex sociotechnical\ndomains. We adopt the natural hypothesis that tools from this domain could\nserve to enhance risk analyses of ML in its context of use. To test this\nhypothesis, we apply a \"best of breed\" systems safety analysis, Systems\nTheoretic Process Analysis (STPA), to a specific high-consequence system with\nan important ML-driven component, namely the Prescription Drug Monitoring\nPrograms (PDMPs) operated by many US States, several of which rely on an\nML-derived risk score. We focus in particular on how this analysis can extend\nto identifying social and ethical risks and developing concrete design-level\ncontrols to mitigate them.",
    "descriptor": "\nComments: 14 pages, 5 figures, 3 tables. Accepted to 36th Conference on Neural Information Processing Systems, Workshop on ML Safety (NeurIPS 2022)\n",
    "authors": [
      "Edgar W. Jatho III",
      "Logan O. Mailloux",
      "Shalaleh Rismani",
      "Eugene D. Williams",
      "Joshua A. Kroll"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.04602"
  },
  {
    "id": "arXiv:2211.04604",
    "title": "StructDiffusion: Object-Centric Diffusion for Semantic Rearrangement of  Novel Objects",
    "abstract": "Robots operating in human environments must be able to rearrange objects into\nsemantically-meaningful configurations, even if these objects are previously\nunseen. In this work, we focus on the problem of building physically-valid\nstructures without step-by-step instructions. We propose StructDiffusion, which\ncombines a diffusion model and an object-centric transformer to construct\nstructures out of a single RGB-D image based on high-level language goals, such\nas \"set the table.\" Our method shows how diffusion models can be used for\ncomplex multi-step 3D planning tasks. StructDiffusion improves success rate on\nassembling physically-valid structures out of unseen objects by on average 16%\nover an existing multi-modal transformer model, while allowing us to use one\nmulti-task model to produce a wider range of different structures. We show\nexperiments on held-out objects in both simulation and on real-world\nrearrangement tasks. For videos and additional results, check out our website:\nthis http URL",
    "descriptor": "",
    "authors": [
      "Weiyu Liu",
      "Tucker Hermans",
      "Sonia Chernova",
      "Chris Paxton"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04604"
  },
  {
    "id": "arXiv:2211.04607",
    "title": "First principles physics-informed neural network for quantum  wavefunctions and eigenvalue surfaces",
    "abstract": "Physics-informed neural networks have been widely applied to learn general\nparametric solutions of differential equations. Here, we propose a neural\nnetwork to discover parametric eigenvalue and eigenfunction surfaces of quantum\nsystems. We apply our method to solve the hydrogen molecular ion. This is an\nab-initio deep learning method that solves the Schrodinger equation with the\nCoulomb potential yielding realistic wavefunctions that include a cusp at the\nion positions. The neural solutions are continuous and differentiable functions\nof the interatomic distance and their derivatives are analytically calculated\nby applying automatic differentiation. Such a parametric and analytical form of\nthe solutions is useful for further calculations such as the determination of\nforce fields.",
    "descriptor": "",
    "authors": [
      "Marios Mattheakis",
      "Gabriel R. Schleder",
      "Daniel Larson",
      "Efthimios Kaxiras"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.04607"
  },
  {
    "id": "arXiv:2211.04617",
    "title": "Countering Misinformation on Social Networks Using Graph Alterations",
    "abstract": "We restrict the propagation of misinformation in a social-media-like\nenvironment while preserving the spread of correct information. We model the\nenvironment as a random network of users in which each news item propagates in\nthe network in consecutive cascades. Existing studies suggest that the cascade\nbehaviors of misinformation and correct information are affected differently by\nuser polarization and reflexivity. We show that this difference can be used to\nalter network dynamics in a way that selectively hinders the spread of\nmisinformation content. To implement these alterations, we introduce an\noptimization-based probabilistic dropout method that randomly removes\nconnections between users to achieve minimal propagation of misinformation. We\nuse disciplined convex programming to optimize these removal probabilities over\na reduced space of possible network alterations. We test the algorithm's\neffectiveness using simulated social networks. In our tests, we use both\nsynthetic network structures based on stochastic block models, and natural\nnetwork structures that are generated using random sampling of a dataset\ncollected from Twitter. The results show that on average the algorithm\ndecreases the cascade size of misinformation content by up to $70\\%$ in\nsynthetic network tests and up to $45\\%$ in natural network tests while\nmaintaining a branching ratio of at least $1.5$ for correct information.",
    "descriptor": "\nComments: 10 pages, 6 figures\n",
    "authors": [
      "Yigit E. Bayiz",
      "Ufuk Topcu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.04617"
  },
  {
    "id": "arXiv:2211.04618",
    "title": "Discovering the Hidden Facts of User-Dispatcher Interactions via  Text-based Reporting Systems for Community Safety",
    "abstract": "Recently, an increasing number of safety organizations in the U.S. have\nincorporated text-based risk reporting systems to respond to safety incident\nreports from their community members. To gain a better understanding of the\ninteraction between community members and dispatchers using text-based risk\nreporting systems, this study conducts a system log analysis of LiveSafe, a\ncommunity safety reporting system, to provide empirical evidence of the\nconversational patterns between users and dispatchers using both quantitative\nand qualitative methods. We created an ontology to capture information (e.g.,\nlocation, attacker, target, weapon, start-time, and end-time, etc.) that\ndispatchers often collected from users regarding their incident tips. Applying\nthe proposed ontology, we found that dispatchers often asked users for\ndifferent information across varied event types (e.g., Attacker for Abuse and\nAttack events, Target for Harassment events). Additionally, using emotion\ndetection and regression analysis, we found an inconsistency in dispatchers'\nemotional support and responsiveness to users' messages between different\norganizations and between incident categories. The results also showed that\nusers had a higher response rate and responded quicker when dispatchers\nprovided emotional support. These novel findings brought significant insights\nto both practitioners and system designers, e.g., AI-based solutions to augment\nhuman agents' skills for improved service quality.",
    "descriptor": "",
    "authors": [
      "Yiren Liu",
      "Ryan Mayfield",
      "Yun Huang"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.04618"
  },
  {
    "id": "arXiv:2211.04620",
    "title": "DeepE: a deep neural network for knowledge graph embedding",
    "abstract": "Recently, neural network based methods have shown their power in learning\nmore expressive features on the task of knowledge graph embedding (KGE).\nHowever, the performance of deep methods often falls behind the shallow ones on\nsimple graphs. One possible reason is that deep models are difficult to train,\nwhile shallow models might suffice for accurately representing the structure of\nthe simple KGs.\nIn this paper, we propose a neural network based model, named DeepE, to\naddress the problem, which stacks multiple building blocks to predict the tail\nentity based on the head entity and the relation. Each building block is an\naddition of a linear and a non-linear function. The stacked building blocks are\nequivalent to a group of learning functions with different non-linear depth.\nHence, DeepE allows deep functions to learn deep features, and shallow\nfunctions to learn shallow features. Through extensive experiments, we find\nDeepE outperforms other state-of-the-art baseline methods. A major advantage of\nDeepE is the robustness. DeepE achieves a Mean Rank (MR) score that is 6%, 30%,\n65% lower than the best baseline methods on FB15k-237, WN18RR and YAGO3-10. Our\ndesign makes it possible to train much deeper networks on KGE, e.g. 40 layers\non FB15k-237, and without scarifying precision on simple relations.",
    "descriptor": "\nComments: 10 pages, 5 figures, 7 tables\n",
    "authors": [
      "Zhu Danhao",
      "Shen Si",
      "Huang Shujian",
      "Yin Chang",
      "Ding Ziqi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04620"
  },
  {
    "id": "arXiv:2211.04623",
    "title": "Neural network concatenation for Polar Codes",
    "abstract": "When a neural network (NN) is used to decode a polar code, its training\ncomplexity scales exponentially as the code block size (or to be precise, as a\nnumber of message bits) increases. Therefore, existing solutions that use a\nneural network for polar decoders are stuck with short block sizes like 16 or\n32. Despite the fact that the NN training is very complex for long polar codes,\nthe NN decoding gives the better latency and its performance is potentially\nclose to the maximum likelihood (ML). In this paper, we describe an efficient\nalgorithm to create the NN decoding for a polar code of any size with the\ninitial performance that is equal or better than that of successive cancelation\n(SC). Therefore, it creates an opportunity to design the NN based decoding with\nthe performance that is as close to the ML, as the training time allows.",
    "descriptor": "",
    "authors": [
      "Evgeny Stupachenko"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.04623"
  },
  {
    "id": "arXiv:2211.04624",
    "title": "Cold Start Streaming Learning for Deep Networks",
    "abstract": "The ability to dynamically adapt neural networks to newly-available data\nwithout performance deterioration would revolutionize deep learning\napplications. Streaming learning (i.e., learning from one data example at a\ntime) has the potential to enable such real-time adaptation, but current\napproaches i) freeze a majority of network parameters during streaming and ii)\nare dependent upon offline, base initialization procedures over large subsets\nof data, which damages performance and limits applicability. To mitigate these\nshortcomings, we propose Cold Start Streaming Learning (CSSL), a simple,\nend-to-end approach for streaming learning with deep networks that uses a\ncombination of replay and data augmentation to avoid catastrophic forgetting.\nBecause CSSL updates all model parameters during streaming, the algorithm is\ncapable of beginning streaming from a random initialization, making base\ninitialization optional. Going further, the algorithm's simplicity allows\ntheoretical convergence guarantees to be derived using analysis of the Neural\nTangent Random Feature (NTRF). In experiments, we find that CSSL outperforms\nexisting baselines for streaming learning in experiments on CIFAR100, ImageNet,\nand Core50 datasets. Additionally, we propose a novel multi-task streaming\nlearning setting and show that CSSL performs favorably in this domain. Put\nsimply, CSSL performs well and demonstrates that the complicated, multi-step\ntraining pipelines adopted by most streaming methodologies can be replaced with\na simple, end-to-end learning approach without sacrificing performance.",
    "descriptor": "\nComments: 52 pages, 7 figures, pre-print\n",
    "authors": [
      "Cameron R. Wolfe",
      "Anastasios Kyrillidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.04624"
  },
  {
    "id": "arXiv:2211.04625",
    "title": "Soft Augmentation for Image Classification",
    "abstract": "Modern neural networks are over-parameterized and thus rely on strong\nregularization such as data augmentation and weight decay to reduce overfitting\nand improve generalization. The dominant form of data augmentation applies\ninvariant transforms, where the learning target of a sample is invariant to the\ntransform applied to that sample. We draw inspiration from human visual\nclassification studies and propose generalizing augmentation with invariant\ntransforms to soft augmentation where the learning target softens non-linearly\nas a function of the degree of the transform applied to the sample: e.g., more\naggressive image crop augmentations produce less confident learning targets. We\ndemonstrate that soft targets allow for more aggressive data augmentation,\noffer more robust performance boosts, work with other augmentation policies,\nand interestingly, produce better calibrated models (since they are trained to\nbe less confident on aggressively cropped/occluded examples). Combined with\nexisting aggressive augmentation strategies, soft target 1) doubles the top-1\naccuracy boost across Cifar-10, Cifar-100, ImageNet-1K, and ImageNet-V2, 2)\nimproves model occlusion performance by up to $4\\times$, and 3) halves the\nexpected calibration error (ECE). Finally, we show that soft augmentation\ngeneralizes to self-supervised classification tasks.",
    "descriptor": "",
    "authors": [
      "Yang Liu",
      "Shen Yan",
      "Laura Leal-Taix\u00e9",
      "James Hays",
      "Deva Ramanan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04625"
  },
  {
    "id": "arXiv:2211.04627",
    "title": "Computing (1+epsilon)-Approximate Degeneracy in Sublinear Time",
    "abstract": "The problem of finding the degeneracy of a graph is a subproblem of the\nk-core decomposition problem. In this paper, we present a (1 +\nepsilon)-approximate solution to the degeneracy problem which runs in O(n log\nn) time, sublinear in the input size for dense graphs, by sampling a small\nnumber of neighbors adjacent to high degree nodes. Our algorithm can also be\nextended to an O(n log n) time solution to the k-core decomposition problem.\nThis improves upon the method by Bhattacharya et al., which implies a (4 +\nepsilon)-approximate ~O(n) solution to the degeneracy problem, and our\ntechniques are similar to other sketching methods which use sublinear space for\nk-core and degeneracy. We prove theoretical guarantees of our algorithm and\nprovide optimizations, which improve the running time of our algorithm in\npractice. Experiments on massive real-world web graphs show that our algorithm\nperforms significantly faster than previous methods for computing degeneracy,\nincluding the 2022 exact degeneracy algorithm by Li et al.",
    "descriptor": "",
    "authors": [
      "Valerie King",
      "Alex Thomo",
      "Quinton Yong"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.04627"
  },
  {
    "id": "arXiv:2211.04630",
    "title": "Minimalist Data Wrangling with Python",
    "abstract": "Minimalist Data Wrangling with Python is envisaged as a student's first\nintroduction to data science, providing a high-level overview as well as\ndiscussing key concepts in detail. We explore methods for cleaning data\ngathered from different sources, transforming, selecting, and extracting\nfeatures, performing exploratory data analysis and dimensionality reduction,\nidentifying naturally occurring data clusters, modelling patterns in data,\ncomparing data between groups, and reporting the results. This textbook is a\nnon-profit project. Its online and PDF versions are freely available at\nhttps://datawranglingpy.gagolewski.com/.",
    "descriptor": "\nComments: Release: v1.0.2.9001 (2022-11-09T12:17:50+1100)\n",
    "authors": [
      "Marek Gagolewski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04630"
  },
  {
    "id": "arXiv:2211.04634",
    "title": "Optimal Graph Filters for Clustering Attributed Graphs",
    "abstract": "Many real-world systems can be represented as graphs where the different\nentities are presented by nodes and their interactions by edges. An important\ntask in studying large datasets is graph clustering. While there has been a lot\nof work on graph clustering using the connectivity between the nodes, many\nreal-world networks also have node attributes. Clustering attributed graphs\nrequires joint modeling of graph structure and node attributes. Recent work has\nfocused on graph convolutional networks and graph convolutional filters to\ncombine structural and content information. However, these methods are mostly\nlimited to lowpass filtering and do not explicitly optimize the filters for the\nclustering task. In this paper, we introduce a graph signal processing based\napproach, where we design polynomial graph filters optimized for clustering.\nThe proposed approach is formulated as a two-step iterative optimization\nproblem where graph filters that are interpretable and optimal for the given\ndata are learned while maximizing the separation between different clusters.\nThe proposed approach is evaluated on attributed networks and compared to the\nstate-of-the-art graph convolutional network approaches.",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Meiby Ortiz-Bouza",
      "Selin Aviyente"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.04634"
  },
  {
    "id": "arXiv:2211.04635",
    "title": "LiCo-Net: Linearized Convolution Network for Hardware-efficient Keyword  Spotting",
    "abstract": "This paper proposes a hardware-efficient architecture, Linearized Convolution\nNetwork (LiCo-Net) for keyword spotting. It is optimized specifically for\nlow-power processor units like microcontrollers. ML operators exhibit\nheterogeneous efficiency profiles on power-efficient hardware. Given the exact\ntheoretical computation cost, int8 operators are more computation-effective\nthan float operators, and linear layers are often more efficient than other\nlayers. The proposed LiCo-Net is a dual-phase system that uses the efficient\nint8 linear operators at the inference phase and applies streaming convolutions\nat the training phase to maintain a high model capacity. The experimental\nresults show that LiCo-Net outperforms single-value decomposition filter (SVDF)\non hardware efficiency with on-par detection performance. Compared to SVDF,\nLiCo-Net reduces cycles by 40% on HiFi4 DSP.",
    "descriptor": "",
    "authors": [
      "Haichuan Yang",
      "Zhaojun Yang",
      "Li Wan",
      "Biqiao Zhang",
      "Yangyang Shi",
      "Yiteng Huang",
      "Ivaylo Enchev",
      "Limin Tang",
      "Raziel Alvarez",
      "Ming Sun",
      "Xin Lei",
      "Raghuraman Krishnamoorthi",
      "Vikas Chandra"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.04635"
  },
  {
    "id": "arXiv:2211.04639",
    "title": "A 4/3-Approximation Algorithm for Half-Integral Cycle Cut Instances of  the TSP",
    "abstract": "A long-standing conjecture for the traveling salesman problem (TSP) states\nthat the integrality gap of the standard linear programming relaxation of the\nTSP is at most 4/3. Despite significant efforts, the conjecture remains open.\nWe consider the half-integral case, in which the LP has solution values in\n$\\{0, 1/2, 1\\}$. Such instances have been conjectured to be the most difficult\ninstances for the overall four-thirds conjecture. Karlin, Klein, and Oveis\nGharan, in a breakthrough result, were able to show that in the half-integral\ncase, the integrality gap is at most 1.49993. This result led to the first\nsignificant progress on the overall conjecture in decades; the same authors\nshowed the integrality gap is at most $1.5- 10^{-36}$ in the non-half-integral\ncase. For the half-integral case, the current best-known ratio is 1.4983, a\nresult by Gupta et al.\nWith the improvements on the 3/2 bound remaining very incremental even in the\nhalf-integral case, we turn the question around and look for a large class of\nhalf-integral instances for which we can prove that the 4/3 conjecture is\ncorrect.\nThe previous works on the half-integral case perform induction on a hierarchy\nof critical tight sets in the support graph of the LP solution, in which some\nof the sets correspond to \"cycle cuts\" and the others to \"degree cuts\". We show\nthat if all the sets in the hierarchy correspond to cycle cuts, then we can\nfind a distribution of tours whose expected cost is at most 4/3 times the value\nof the half-integral LP solution; sampling from the distribution gives us a\nrandomized 4/3-approximation algorithm. We note that the known bad cases for\nthe integrality gap have a gap of 4/3 and have a half-integral LP solution in\nwhich all the critical tight sets in the hierarchy are cycle cuts; thus our\nresult is tight.",
    "descriptor": "\nComments: Comments, questions, and suggestions are welcome!\n",
    "authors": [
      "Billy Jin",
      "Nathan Klein",
      "David P. Williamson"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.04639"
  },
  {
    "id": "arXiv:2211.04641",
    "title": "Sensitivity analysis of quasi-stationary-distributions (QSDs)",
    "abstract": "This paper studies the sensitivity analysis of mass-action systems against\ntheir diffusion approximations, particularly the dependence on population\nsizes. As a continuous time Markov chain, a mass-action system can be described\nby a equation driven by finite many Poisson processes, which has a diffusion\napproximation that can be pathwisely matched. The magnitude of noise in\nmass-action systems is proportional to the square root of the molecule\ncount/population, which makes a large class of mass-action systems have\nquasi-stationary distributions (QSDs) instead of invariant probability\nmeasures. In this paper we modify the coupling based technique developed in [8]\nto estimate an upper bound of the 1-Wasserstein distance between two QSDs. Some\nnumerical results for sensitivity with different population sizes are provided.",
    "descriptor": "",
    "authors": [
      "Yao Li",
      "Yaping Yuan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.04641"
  },
  {
    "id": "arXiv:2211.04643",
    "title": "Faster Walsh-Hadamard Transform and Matrix Multiplication over Finite  Fields using Lookup Tables",
    "abstract": "We use lookup tables to design faster algorithms for important algebraic\nproblems over finite fields. These faster algorithms, which only use arithmetic\noperations and lookup table operations, may help to explain the difficulty of\ndetermining the complexities of these important problems. Our results over a\nconstant-sized finite field are as follows.\nThe Walsh-Hadamard transform of a vector of length $N$ can be computed using\n$O(N \\log N / \\log \\log N)$ bit operations. This generalizes to any transform\ndefined as a Kronecker power of a fixed matrix. By comparison, the Fast\nWalsh-Hadamard transform (similar to the Fast Fourier transform) uses $O(N \\log\nN)$ arithmetic operations, which is believed to be optimal up to constant\nfactors.\nAny algebraic algorithm for multiplying two $N \\times N$ matrices using\n$O(N^\\omega)$ operations can be converted into an algorithm using $O(N^\\omega /\n(\\log N)^{\\omega/2 - 1})$ bit operations. For example, Strassen's algorithm can\nbe converted into an algorithm using $O(N^{2.81} / (\\log N)^{0.4})$ bit\noperations. It remains an open problem with practical implications to determine\nthe smallest constant $c$ such that Strassen's algorithm can be implemented to\nuse $c \\cdot N^{2.81} + o(N^{2.81})$ arithmetic operations; using a lookup\ntable allows one to save a super-constant factor in bit operations.",
    "descriptor": "\nComments: 10 pages, to appear in the 6th Symposium on Simplicity in Algorithms (SOSA 2023)\n",
    "authors": [
      "Josh Alman"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.04643"
  },
  {
    "id": "arXiv:2211.04644",
    "title": "Kalman Filter-based Sensing in Communication Systems with Clock  Asynchronism",
    "abstract": "In this paper, we propose a novel Kalman Filter (KF)-based uplink (UL) joint\ncommunication and sensing (JCAS) scheme, which can significantly reduce the\nrange and location estimation errors due to the clock asynchronism between the\nbase station (BS) and user equipment (UE). Clock asynchronism causes\ntime-varying time offset (TO) and carrier frequency offset (CFO), leading to\nmajor challenges in uplink sensing. Unlike existing technologies, our scheme\ndoes not require knowing the location of the UE in advance, and retains the\nlinearity of the sensing parameter estimation problem. We first estimate the\nangle-of-arrivals (AoAs) of multipaths and use them to spatially filter the\nCSI. Then, we propose a KF-based CSI enhancer that exploits the estimation of\nDoppler with CFO as the prior information to significantly suppress the\ntime-varying noise-like TO terms in spatially filtered CSIs. Subsequently, we\ncan estimate the accurate ranges of UE and the scatterers based on the\nKF-enhanced CSI. Finally, we identify the UE's AoA and range estimation and\nlocate UE, then locate the dumb scatterers using the bi-static system.\nSimulation results validate the proposed scheme. The localization root mean\nsquare error of the proposed method is about 20 dB lower than the benchmarking\nscheme.",
    "descriptor": "\nComments: 14 pages, 16 figures, submitted to IEEE JSAC Special issue: 5G/6G Precise Positioning on Cooperative Intelligent Transportation Systems (C-ITS) and Connected Automated Vehicles (CAV)\n",
    "authors": [
      "Xu Chen",
      "Zhiyong Feng",
      "J. Andrew Zhang",
      "Xin Yuan",
      "Ping Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.04644"
  },
  {
    "id": "arXiv:2211.04653",
    "title": "Approximate backwards differentiation of gradient flow",
    "abstract": "The gradient flow (GF) is an ODE for which its explicit Euler's\ndiscretization is the gradient descent method. In this work, we investigate a\nfamily of methods derived from \\emph{approximate implicit discretizations} of\n(\\GF), drawing the connection between larger stability regions and less\nsensitive hyperparameter tuning. We focus on the implicit $\\tau$-step backwards\ndifferentiation formulas (BDFs), approximated in an inner loop with a few\niterations of vanilla gradient descent, and give their convergence rate when\nthe objective function is convex, strongly convex, or nonconvex. Numerical\nexperiments show the wide range of effects of these different methods on\nextremely poorly conditioned problems, especially those brought about in\ntraining deep neural networks.",
    "descriptor": "",
    "authors": [
      "Yushen Huang",
      "Taehoon Lee",
      "Yifan Sun"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.04653"
  },
  {
    "id": "arXiv:2211.04656",
    "title": "MEVID: Multi-view Extended Videos with Identities for Video Person  Re-Identification",
    "abstract": "In this paper, we present the Multi-view Extended Videos with Identities\n(MEVID) dataset for large-scale, video person re-identification (ReID) in the\nwild. To our knowledge, MEVID represents the most-varied video person ReID\ndataset, spanning an extensive indoor and outdoor environment across nine\nunique dates in a 73-day window, various camera viewpoints, and entity clothing\nchanges. Specifically, we label the identities of 158 unique people wearing 598\noutfits taken from 8, 092 tracklets, average length of about 590 frames, seen\nin 33 camera views from the very large-scale MEVA person activities dataset.\nWhile other datasets have more unique identities, MEVID emphasizes a richer set\nof information about each individual, such as: 4 outfits/identity vs. 2\noutfits/identity in CCVID, 33 viewpoints across 17 locations vs. 6 in 5\nsimulated locations for MTA, and 10 million frames vs. 3 million for LS-VID.\nBeing based on the MEVA video dataset, we also inherit data that is\nintentionally demographically balanced to the continental United States. To\naccelerate the annotation process, we developed a semi-automatic annotation\nframework and GUI that combines state-of-the-art real-time models for object\ndetection, pose estimation, person ReID, and multi-object tracking. We evaluate\nseveral state-of-the-art methods on MEVID challenge problems and\ncomprehensively quantify their robustness in terms of changes of outfit, scale,\nand background location. Our quantitative analysis on the realistic, unique\naspects of MEVID shows that there are significant remaining challenges in video\nperson ReID and indicates important directions for future research.",
    "descriptor": "\nComments: This paper was accepted to WACV 20223\n",
    "authors": [
      "Daniel Davila",
      "Dawei Du",
      "Bryon Lewis",
      "Christopher Funk",
      "Joseph Van Pelt",
      "Roderick Collins",
      "Kellie Corona",
      "Matt Brown",
      "Scott McCloskey",
      "Anthony Hoogs",
      "Brian Clipp"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04656"
  },
  {
    "id": "arXiv:2211.04657",
    "title": "A Method to Judge the Style of Classical Poetry Based on Pre-trained  Model",
    "abstract": "One of the important topics in the research field of Chinese classical poetry\nis to analyze the poetic style. By examining the relevant works of previous\ndynasties, researchers judge a poetic style mostly by their subjective\nfeelings, and refer to the previous evaluations that have become a certain\nconclusion. Although this judgment method is often effective, there may be some\nerrors. This paper builds the most perfect data set of Chinese classical poetry\nat present, trains a BART-poem pre -trained model on this data set, and puts\nforward a generally applicable poetry style judgment method based on this\nBART-poem model, innovatively introduces in-depth learning into the field of\ncomputational stylistics, and provides a new research method for the study of\nclassical poetry. This paper attempts to use this method to solve the problem\nof poetry style identification in the Tang and Song Dynasties, and takes the\npoetry schools that are considered to have a relatively clear and consistent\npoetic style, such as the Hongzheng Qizi and Jiajing Qizi, Jiangxi poetic\nschool and Tongguang poetic school, as the research object, and takes the poems\nof their representative poets for testing. Experiments show that the judgment\nresults of the tested poetry work made by the model are basically consistent\nwith the conclusions given by critics of previous dynasties, verify some\navant-garde judgments of Mr. Qian Zhongshu, and better solve the task of poetry\nstyle recognition in the Tang and Song dynasties.",
    "descriptor": "\nComments: 4 pages, 2 figures\n",
    "authors": [
      "Ziyao Wang",
      "Jiandong Zhang",
      "Jun Ma"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04657"
  },
  {
    "id": "arXiv:2211.04658",
    "title": "SUPRA: Superpixel Guided Loss for Improved Multi-modal Segmentation in  Endoscopy",
    "abstract": "Domain shift is a well-known problem in the medical imaging community. In\nparticular, for endoscopic image analysis where the data can have different\nmodalities the performance of deep learning (DL) methods gets adversely\naffected. In other words, methods developed on one modality cannot be used for\na different modality. However, in real clinical settings, endoscopists switch\nbetween modalities for better mucosal visualisation. In this paper, we explore\nthe domain generalisation technique to enable DL methods to be used in such\nscenarios. To this extend, we propose to use super pixels generated with Simple\nLinear Iterative Clustering (SLIC) which we refer to as \"SUPRA\" for SUPeRpixel\nAugmented method. SUPRA first generates a preliminary segmentation mask making\nuse of our new loss \"SLICLoss\" that encourages both an accurate and\ncolor-consistent segmentation. We demonstrate that SLICLoss when combined with\nBinary Cross Entropy loss (BCE) can improve the model's generalisability with\ndata that presents significant domain shift. We validate this novel compound\nloss on a vanilla U-Net using the EndoUDA dataset, which contains images for\nBarret's Esophagus and polyps from two modalities. We show that our method\nyields an improvement of nearly 25% in the target domain set compared to the\nbaseline.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Rafael Martinez Garcia-Pe\u00f1a",
      "Mansoor Ali Teevno",
      "Gilberto Ochoa-Ruiz",
      "Sharib Ali"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.04658"
  },
  {
    "id": "arXiv:2211.04659",
    "title": "Extragradient with Positive Momentum is Optimal for Games with  Cross-Shaped Jacobian Spectrum",
    "abstract": "The extragradient method has recently gained increasing attention, due to its\nconvergence behavior on smooth games. In $n$-player differentiable games, the\neigenvalues of the Jacobian of the vector field are distributed on the complex\nplane, exhibiting more convoluted dynamics compared to classical (i.e., single\nplayer) minimization. In this work, we take a polynomial-based analysis of the\nextragradient with momentum for optimizing games with \\emph{cross-shaped}\nJacobian spectrum on the complex plane. We show two results. First, based on\nthe hyperparameter setup, the extragradient with momentum exhibits three\ndifferent modes of convergence: when the eigenvalues are distributed $i)$ on\nthe real line, $ii)$ both on the real line along with complex conjugates, and\n$iii)$ only as complex conjugates. Then, we focus on the case $ii)$, i.e., when\nthe eigenvalues of the Jacobian have \\emph{cross-shaped} structure, as observed\nin training generative adversarial networks. For this problem class, we derive\nthe optimal hyperparameters of the momentum extragradient method, and show that\nit achieves an accelerated convergence rate.",
    "descriptor": "",
    "authors": [
      "Junhyung Lyle Kim",
      "Gauthier Gidel",
      "Anastasios Kyrillidis",
      "Fabian Pedregosa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.04659"
  },
  {
    "id": "arXiv:2211.04661",
    "title": "Challenges and Barriers of Using Low Code Software for Machine Learning",
    "abstract": "As big data grows ubiquitous across many domains, more and more stakeholders\nseek to develop Machine Learning (ML) applications on their data. The success\nof an ML application usually depends on the close collaboration of ML experts\nand domain experts. However, the shortage of ML engineers remains a fundamental\nproblem. Low-code Machine learning tools/platforms (aka, AutoML) aim to\ndemocratize ML development to domain experts by automating many repetitive\ntasks in the ML pipeline. This research presents an empirical study of around\n14k posts (questions + accepted answers) from Stack Overflow (SO) that\ncontained AutoML-related discussions. We examine how these topics are spread\nacross the various Machine Learning Life Cycle (MLLC) phases and their\npopularity and difficulty. This study offers several interesting findings.\nFirst, we find 13 AutoML topics that we group into four categories. The MLOps\ntopic category (43% questions) is the largest, followed by Model (28%\nquestions), Data (27% questions), Documentation (2% questions). Second, Most\nquestions are asked during Model training (29%) (i.e., implementation phase)\nand Data preparation (25%) MLLC phase. Third, AutoML practitioners find the\nMLOps topic category most challenging, especially topics related to model\ndeployment & monitoring and Automated ML pipeline. These findings have\nimplications for all three AutoML stakeholders: AutoML researchers, AutoML\nservice vendors, and AutoML developers. Academia and Industry collaboration can\nimprove different aspects of AutoML, such as better DevOps/deployment support\nand tutorial-based documentation.",
    "descriptor": "",
    "authors": [
      "Md Abdullah Al Alamin",
      "Gias Uddin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.04661"
  },
  {
    "id": "arXiv:2211.04665",
    "title": "Gaussian Process Learning-Based Model Predictive Control for Safe  Interactions of a Platoon of Autonomous and Human-Driven Vehicles",
    "abstract": "With the continued integration of autonomous vehicles (AVs) into public\nroads, a mixed traffic environment with large-scale human-driven vehicles (HVs)\nand AVs interactions is imminent. In challenging traffic scenarios, such as\nemergency braking, it is crucial to account for the reactive and uncertain\nbehavior of HVs when developing control strategies for AVs. This paper studies\nthe safe control of a platoon of AVs interacting with a human-driven vehicle in\nlongitudinal car-following scenarios. We first propose the use of a model that\ncombines a first-principles model (nominal model) with a Gaussian process (GP)\nlearning-based component for predicting behaviors of the human-driven vehicle\nwhen it interacts with AVs. The modeling accuracy of the proposed method shows\na $9\\%$ reduction in root mean square error (RMSE) in predicting a HV's\nvelocity compared to the nominal model. Exploiting the properties of this\nmodel, we design a model predictive control (MPC) strategy for a platoon of AVs\nto ensure a safe distance between each vehicle, as well as a (probabilistic)\nsafety of the human-driven car following the platoon. Compared to a baseline\nMPC that uses only a nominal model for HVs, our method achieves better\nvelocity-tracking performance for the autonomous vehicle platoon and more\nrobust constraint satisfaction control for a platoon of mixed vehicles system.\nSimulation studies demonstrate a $4.2\\%$ decrease in the control cost and an\napproximate $1m$ increase in the minimum distance between autonomous and\nhuman-driven vehicles to better guarantee safety in challenging traffic\nscenarios.",
    "descriptor": "",
    "authors": [
      "Jie Wang",
      "Zhihao Jiang",
      "Yash Vardhan Pant"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.04665"
  },
  {
    "id": "arXiv:2211.04668",
    "title": "Zero-Label Prompt Selection",
    "abstract": "Natural language prompts have been shown to facilitate cross-task\ngeneralization for large language models. However, with no or limited labeled\nexamples, the cross-task performance is highly sensitive to the choice of\nprompts, while selecting a high-performing prompt is challenging given the\nscarcity of labels. To address the issue, we propose a Zero-Label Prompt\nSelection (ZPS) method that selects prompts without any labeled data or\ngradient update. Specifically, given the candidate human-written prompts for a\ntask, ZPS labels a set of unlabeled data with a prompt ensemble and uses the\npseudo-labels for prompt selection. Experiments show that ZPS improves over\nprior methods by a sizeable margin in zero-label performance. We also extend\nZPS to a few-shot setting and show its advantages over strong baselines such as\nprompt tuning and model tuning.",
    "descriptor": "",
    "authors": [
      "Chonghua Liao",
      "Yanan Zheng",
      "Zhilin Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.04668"
  },
  {
    "id": "arXiv:2211.04670",
    "title": "Distributional Shift Adaptation using Domain-Specific Features",
    "abstract": "Machine learning algorithms typically assume that the training and test\nsamples come from the same distributions, i.e., in-distribution. However, in\nopen-world scenarios, streaming big data can be Out-Of-Distribution (OOD),\nrendering these algorithms ineffective. Prior solutions to the OOD challenge\nseek to identify invariant features across different training domains. The\nunderlying assumption is that these invariant features should also work\nreasonably well in the unlabeled target domain. By contrast, this work is\ninterested in the domain-specific features that include both invariant features\nand features unique to the target domain. We propose a simple yet effective\napproach that relies on correlations in general regardless of whether the\nfeatures are invariant or not. Our approach uses the most confidently predicted\nsamples identified by an OOD base model (teacher model) to train a new model\n(student model) that effectively adapts to the target domain. Empirical\nevaluations on benchmark datasets show that the performance is improved over\nthe SOTA by ~10-20%",
    "descriptor": "",
    "authors": [
      "Anique Tahir",
      "Lu Cheng",
      "Ruocheng Guo",
      "Huan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04670"
  },
  {
    "id": "arXiv:2211.04673",
    "title": "Syntax-Aware On-the-Fly Code Completion",
    "abstract": "Code completion aims to help improve developers' productivity by suggesting\nthe next code tokens from a given context. Various approaches have been\nproposed to incorporate abstract syntax tree (AST) information for model\ntraining, ensuring that code completion is aware of the syntax of the\nprogramming languages. However, existing syntax-aware code completion\napproaches are not on-the-fly, as we found that for every two-thirds of\ncharacters that developers type, AST fails to be extracted because it requires\nthe syntactically correct source code, limiting its practicality in real-world\nscenarios. On the other hand, existing on-the-fly code completion does not\nconsider syntactic information yet. In this paper, we propose PyCoder to\nleverage token types, a kind of lightweight syntactic information, which is\nreadily available and aligns with the natural order of source code. Our PyCoder\nis trained in a multi-task training manner so that by learning the supporting\ntask of predicting token types during the training phase, the models achieve\nbetter performance on predicting tokens and lines of code without the need for\ntoken types in the inference phase. Comprehensive experiments show that PyCoder\nachieves the first rank on the CodeXGLUE leaderboard with an accuracy of 77.12%\nfor the token-level predictions, which is 0.43%-24.25% more accurate than\nbaselines. In addition, PyCoder achieves an exact match of 43.37% for the\nline-level predictions, which is 3.63%-84.73% more accurate than baselines.\nThese results lead us to conclude that token type information (an alternative\nto syntactic information) that is rarely used in the past can greatly improve\nthe performance of code completion approaches, without requiring the\nsyntactically correct source code like AST-based approaches do. Our PyCoder is\npublicly available on HuggingFace.",
    "descriptor": "\nComments: 14 pages, Under Review at IEEE Transactions on Software Engineering\n",
    "authors": [
      "Wannita Takerngsaksiri",
      "Chakkrit Tantithamthavorn",
      "Yuan-Fang Li"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04673"
  },
  {
    "id": "arXiv:2211.04674",
    "title": "Lipschitz Continuous Algorithms for Graph Problems",
    "abstract": "It has been widely observed in the machine learning community that a small\nperturbation to the input can cause a large change in the prediction of a\ntrained model, and such phenomena have been intensively studied in the machine\nlearning community under the name of adversarial attacks. Because graph\nalgorithms also are widely used for decision making and knowledge discovery, it\nis important to design graph algorithms that are robust against adversarial\nattacks. In this study, we consider the Lipschitz continuity of algorithms as a\nrobustness measure and initiate a systematic study of the Lipschitz continuity\nof algorithms for (weighted) graph problems.\nDepending on how we embed the output solution to a metric space, we can think\nof several Lipschitzness notions. We mainly consider the one that is invariant\nunder scaling of weights, and we provide Lipschitz continuous algorithms and\nlower bounds for the minimum spanning tree problem, the shortest path problem,\nand the maximum weight matching problem. In particular, our shortest path\nalgorithm is obtained by first designing an algorithm for unweighted graphs\nthat are robust against edge contractions and then applying it to the\nunweighted graph constructed from the original weighted graph.\nThen, we consider another Lipschitzness notion induced by a natural mapping\nthat maps the output solution to its characteristic vector. It turns out that\nno Lipschitz continuous algorithm exists for this Lipschitz notion, and we\ninstead design algorithms with bounded pointwise Lipschitz constants for the\nminimum spanning tree problem and the maximum weight bipartite matching\nproblem. Our algorithm for the latter problem is based on an LP relaxation with\nentropy regularization.",
    "descriptor": "",
    "authors": [
      "Soh Kumabe",
      "Yuichi Yoshida"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.04674"
  },
  {
    "id": "arXiv:2211.04676",
    "title": "Efficient Bounds and Estimates for Canonical Angles in Randomized  Subspace Approximations",
    "abstract": "Randomized subspace approximation with \"matrix sketching\" is an effective\napproach for constructing approximate partial singular value decompositions\n(SVDs) of large matrices. The performance of such techniques has been\nextensively analyzed, and very precise estimates on the distribution of the\nresidual errors have been derived. However, our understanding of the accuracy\nof the computed singular vectors (measured in terms of the canonical angles\nbetween the spaces spanned by the exact and the computed singular vectors,\nrespectively) remains relatively limited. In this work, we present bounds and\nestimates for canonical angles of randomized subspace approximation that can be\ncomputed efficiently either a priori or a posterior. Under moderate\noversampling in the randomized SVD, our prior probabilistic bounds are\nasymptotically tight and can be computed efficiently, while bringing a clear\ninsight into the balance between oversampling and power iterations given a\nfixed budget on the number of matrix-vector multiplications. The numerical\nexperiments demonstrate the empirical effectiveness of these canonical angle\nbounds and estimates on different matrices under various algorithmic choices\nfor the randomized SVD.",
    "descriptor": "",
    "authors": [
      "Yijun Dong",
      "Per-Gunnar Martinsson",
      "Yuji Nakatsukasa"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.04676"
  },
  {
    "id": "arXiv:2211.04677",
    "title": "A micro-macro decomposed reduced basis method for the time-dependent  radiative transfer equation",
    "abstract": "Kinetic transport equations are notoriously difficult to simulate because of\ntheir complex multiscale behaviors and the need to numerically resolve a high\ndimensional probability density function. Past literature has focused on\nbuilding reduced order models (ROM) by analytical methods. In recent years,\nthere is a surge of interest in developing ROM using data-driven or\ncomputational tools that offer more applicability and flexibility. This paper\nis a work towards that direction.\nMotivated by our previous work of designing ROM for the stationary radiative\ntransfer equation in [30] by leveraging the low-rank structure of the solution\nmanifold induced by the angular variable, we here further advance the\nmethodology to the time-dependent model. Particularly, we take the celebrated\nreduced basis method (RBM) approach and propose a novel micro-macro decomposed\nreduced basis method (MMD-RBM). The MMD-RBM is constructed by exploiting, in a\ngreedy fashion, the low-rank structures of both the micro- and macro-solution\nmanifolds with respect to the angular and temporal variables. Our reduced order\nsurrogate consists of: reduced bases for reduced order subspaces and a reduced\nquadrature rule in the angular space. The proposed MMD-RBM features several\nstructure-preserving components: 1) an equilibrium-respecting strategy to\nconstruct reduced order subspaces which better utilize the structure of the\ndecomposed system, and 2) a recipe for preserving positivity of the quadrature\nweights thus to maintain the stability of the underlying reduced solver. The\nresulting ROM can be used to achieve a fast online solve for the angular flux\nin angular directions outside the training set and for arbitrary order moment\nof the angular flux.",
    "descriptor": "",
    "authors": [
      "Zhichao Peng",
      "Yanlai Chen",
      "Yingda Cheng",
      "Fengyan Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.04677"
  },
  {
    "id": "arXiv:2211.04678",
    "title": "Two types of spectral volume methods for 1-D linear hyperbolic equations  with degenerate variable coefficients",
    "abstract": "In this paper, we analyze two classes of spectral volume (SV) methods for\none-dimensional hyperbolic equations with degenerate variable coefficients. The\ntwo classes of SV methods are constructed by letting a piecewise $k$-th order\n($k\\ge 1$ is an arbitrary integer) polynomial function satisfy the local\nconservation law in each {\\it control volume} obtained by dividing the interval\nelement of the underlying mesh with $k$ Gauss-Legendre points (LSV) or Radaus\npoints (RSV). The $L^2$-norm stability and optimal order convergence properties\nfor both methods are rigorously proved for general non-uniform meshes. The\nsuperconvergence behaviors of the two SV schemes have been also investigated:\nit is proved that under the $L^2$ norm, the SV flux function approximates the\nexact flux with $(k+2)$-th order and the SV solution approximates the exact\nsolution with $(k+\\frac32)$-th order; some superconvergence behaviors at\ncertain special points and for element averages have been also discovered and\nproved. Our theoretical findings are verified by several numerical experiments.",
    "descriptor": "",
    "authors": [
      "Minqiang Xu",
      "Yanting yuan",
      "Waixiang Cao",
      "Qingsong Zou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.04678"
  },
  {
    "id": "arXiv:2211.04683",
    "title": "Dynamic Slicing by On-demand Re-execution",
    "abstract": "In this paper, we propose a novel approach that aims to offer an alternative\nto the prevalent paradigm to dynamic slicing construction. Dynamic slicing\nrequires dynamic data and control dependencies that arise in an execution.\nDuring a single execution, memory reference information is recorded and then\ntraversed to extract dependencies. Execute-once approaches and tools are\nchallenged even by executions of moderate size of simple and short programs. We\npropose to shift practical time complexity from execution size to slice size.\nIn particular, our approach executes the program multiple times while tracking\ntargeted information at each execution. We present a concrete algorithm that\nfollows an on-demand re-execution paradigm that uses a novel concept of\nfrontier dependency to incrementally build a dynamic slice. To focus dependency\ntracking, the algorithm relies on static analysis. We show results of an\nevaluation on the SV-COMP benchmark and Antrl4 unit tests that provide evidence\nthat on-demand re-execution can provide performance gains particularly when\nslice size is small and execution size is large.",
    "descriptor": "",
    "authors": [
      "Ivan Postolski",
      "Victor Braberman",
      "Diego Garbervetsky",
      "Sebastian Uchitel"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.04683"
  },
  {
    "id": "arXiv:2211.04684",
    "title": "Few-Shot Character Understanding in Movies as an Assessment to  Meta-Learning of Theory-of-Mind",
    "abstract": "When reading a story, humans can rapidly understand new fictional characters\nwith a few observations, mainly by drawing analogy to fictional and real people\nthey met before in their lives. This reflects the few-shot and meta-learning\nessence of humans' inference of characters' mental states, i.e., humans'\ntheory-of-mind (ToM), which is largely ignored in existing research. We fill\nthis gap with a novel NLP benchmark, TOM-IN-AMC, the first assessment of\nmodels' ability of meta-learning of ToM in a realistic narrative understanding\nscenario. Our benchmark consists of $\\sim$1,000 parsed movie scripts for this\npurpose, each corresponding to a few-shot character understanding task; and\nrequires models to mimic humans' ability of fast digesting characters with a\nfew starting scenes in a new movie. Our human study verified that humans can\nsolve our problem by inferring characters' mental states based on their\npreviously seen movies; while the state-of-the-art metric-learning and\nmeta-learning approaches adapted to our task lags 30% behind.",
    "descriptor": "",
    "authors": [
      "Mo Yu",
      "Yisi Sang",
      "Kangsheng Pu",
      "Zekai Wei",
      "Han Wang",
      "Jing Li",
      "Yue Yu",
      "Jie Zhou"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04684"
  },
  {
    "id": "arXiv:2211.04685",
    "title": "Tight Bounds for Vertex Connectivity in Dynamic Streams",
    "abstract": "We present a streaming algorithm for the vertex connectivity problem in\ndynamic streams with a (nearly) optimal space bound: for any $n$-vertex graph\n$G$ and any integer $k \\geq 1$, our algorithm with high probability outputs\nwhether or not $G$ is $k$-vertex-connected in a single pass using\n$\\widetilde{O}(k n)$ space.\nOur upper bound matches the known $\\Omega(k n)$ lower bound for this problem\neven in insertion-only streams -- which we extend to multi-pass algorithms in\nthis paper -- and closes one of the last remaining gaps in our understanding of\ndynamic versus insertion-only streams. Our result is obtained via a novel\nanalysis of the previous best dynamic streaming algorithm of Guha, McGregor,\nand Tench [PODS 2015] who obtained an $\\widetilde{O}(k^2 n)$ space algorithm\nfor this problem. This also gives a model-independent algorithm for computing a\n\"certificate\" of $k$-vertex-connectivity as a union of $O(k^2\\log{n})$ spanning\nforests, each on a random subset of $O(n/k)$ vertices, which may be of\nindependent interest.",
    "descriptor": "\nComments: Full version of the paper accepted to SOSA 2023. 15 pages, 3 Figures\n",
    "authors": [
      "Sepehr Assadi",
      "Vihan Shah"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.04685"
  },
  {
    "id": "arXiv:2211.04686",
    "title": "Directional Privacy for Deep Learning",
    "abstract": "Differentially Private Stochastic Gradient Descent (DP-SGD) is a key method\nfor applying privacy in the training of deep learning models. This applies\nisotropic Gaussian noise to gradients during training, which can perturb these\ngradients in any direction, damaging utility. Metric DP, however, can provide\nalternative mechanisms based on arbitrary metrics that might be more suitable.\nIn this paper we apply \\textit{directional privacy}, via a mechanism based on\nthe von Mises-Fisher (VMF) distribution, to perturb gradients in terms of\n\\textit{angular distance} so that gradient direction is broadly preserved. We\nshow that this provides $\\epsilon d$-privacy for deep learning training, rather\nthan the $(\\epsilon, \\delta)$-privacy of the Gaussian mechanism; and that\nexperimentally, on key datasets, the VMF mechanism can outperform the Gaussian\nin the utility-privacy trade-off.",
    "descriptor": "",
    "authors": [
      "Pedro Faustini",
      "Natasha Fernandes",
      "Annabelle McIver",
      "Mark Dras"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.04686"
  },
  {
    "id": "arXiv:2211.04687",
    "title": "MFDNet: Towards Real-time Image Denoising On Mobile Devices",
    "abstract": "Deep convolutional neural networks have achieved great progress in image\ndenoising tasks. However, their complicated architectures and heavy\ncomputational cost hinder their deployments on a mobile device. Some recent\nefforts in designing lightweight denoising networks focus on reducing either\nFLOPs (floating-point operations) or the number of parameters. However, these\nmetrics are not directly correlated with the on-device latency. By performing\nextensive analysis and experiments, we identify the network architectures that\ncan fully utilize powerful neural processing units (NPUs) and thus enjoy both\nlow latency and excellent denoising performance. To this end, we propose a\nmobile-friendly denoising network, namely MFDNet. The experiments show that\nMFDNet achieves state-of-the-art performance on real-world denoising benchmarks\nSIDD and DND under real-time latency on mobile devices. The code and\npre-trained models will be released.",
    "descriptor": "\nComments: Under review at the 2023 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2023)\n",
    "authors": [
      "Zhuoqun Liu",
      "Meiguang Jin",
      "Ying Chen",
      "Huaida Liu",
      "Canqian Yang",
      "Hongkai Xiong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.04687"
  },
  {
    "id": "arXiv:2211.04690",
    "title": "Analysis and Hermite spectral approximation of diffusive-viscous wave  equations in unbounded domains arising in geophysics",
    "abstract": "The diffusive-viscous wave equation (DVWE) is widely used in seismic\nexploration since it can explain frequency-dependent seismic reflections in a\nreservoir with hydrocarbons. Most of the existing numerical approximations for\nthe DVWE are based on domain truncation with ad hoc boundary conditions.\nHowever, this would generate artificial reflections as well as truncation\nerrors. To this end, we directly consider the DVWE in unbounded domains. We\nfirst show the existence, uniqueness, and regularity of the solution of the\nDVWE. We then develop a Hermite spectral Galerkin scheme and derive the\ncorresponding error estimate showing that the Hermite spectral Galerkin\napproximation delivers a spectral rate of convergence provided sufficiently\nsmooth solutions. Several numerical experiments with constant and discontinuous\ncoefficients are provided to verify the theoretical result and to demonstrate\nthe effectiveness of the proposed method. In particular, We verify the error\nestimate for both smooth and non-smooth source terms and initial conditions. In\nview of the error estimate and the regularity result, we show the sharpness of\nthe convergence rate in terms of the regularity of the source term. We also\nshow that the artificial reflection does not occur by using the present method.",
    "descriptor": "\nComments: 32 pages, 27 figures\n",
    "authors": [
      "Dan Ling",
      "Zhiping Mao"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.04690"
  },
  {
    "id": "arXiv:2211.04691",
    "title": "A Solution for a Fundamental Problem of 3D Inference based on 2D  Representations",
    "abstract": "3D inference from monocular vision using neural networks is an important\nresearch area of computer vision. Applications of the research area are various\nwith many proposed solutions and have shown remarkable performance. Although\nmany efforts have been invested, there are still unanswered questions, some of\nwhich are fundamental. In this paper, I discuss a problem that I hope will come\nto be known as a generalization of the Blind Perspective-n-Point (Blind PnP)\nproblem for object-driven 3D inference based on 2D representations. The vital\ndifference between the fundamental problem and the Blind PnP problem is that 3D\ninference parameters in the fundamental problem are attached directly to 3D\npoints and the camera concept will be represented through the sharing of the\nparameters of these points. By providing an explainable and robust\ngradient-decent solution based on 2D representations for an important special\ncase of the problem, the paper opens up a new approach for using available\ninformation-based learning methods to solve problems related to 3D object pose\nestimation from 2D images.",
    "descriptor": "",
    "authors": [
      "Thien An L. Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04691"
  },
  {
    "id": "arXiv:2211.04693",
    "title": "Deep Explainable Learning with Graph Based Data Assessing and Rule  Reasoning",
    "abstract": "Learning an explainable classifier often results in low accuracy model or\nends up with a huge rule set, while learning a deep model is usually more\ncapable of handling noisy data at scale, but with the cost of hard to explain\nthe result and weak at generalization. To mitigate this gap, we propose an\nend-to-end deep explainable learning approach that combines the advantage of\ndeep model in noise handling and expert rule-based interpretability.\nSpecifically, we propose to learn a deep data assessing model which models the\ndata as a graph to represent the correlations among different observations,\nwhose output will be used to extract key data features. The key features are\nthen fed into a rule network constructed following predefined noisy expert\nrules with trainable parameters. As these models are correlated, we propose an\nend-to-end training framework, utilizing the rule classification loss to\noptimize the rule learning model and data assessing model at the same time. As\nthe rule-based computation is none-differentiable, we propose a gradient\nlinking search module to carry the gradient information from the rule learning\nmodel to the data assessing model. The proposed method is tested in an industry\nproduction system, showing comparable prediction accuracy, much higher\ngeneralization stability and better interpretability when compared with a\ndecent deep ensemble baseline, and shows much better fitting power than pure\nrule-based approach.",
    "descriptor": "",
    "authors": [
      "Yuanlong Li",
      "Gaopan Huang",
      "Min Zhou",
      "Chuan Fu",
      "Honglin Qiao",
      "Yan He"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04693"
  },
  {
    "id": "arXiv:2211.04696",
    "title": "Robust Point Cloud Registration Framework Based on Deep Graph  Matching(TPAMI Version)",
    "abstract": "3D point cloud registration is a fundamental problem in computer vision and\nrobotics. Recently, learning-based point cloud registration methods have made\ngreat progress. However, these methods are sensitive to outliers, which lead to\nmore incorrect correspondences. In this paper, we propose a novel deep graph\nmatching-based framework for point cloud registration. Specifically, we first\ntransform point clouds into graphs and extract deep features for each point.\nThen, we develop a module based on deep graph matching to calculate a soft\ncorrespondence matrix. By using graph matching, not only the local geometry of\neach point but also its structure and topology in a larger range are considered\nin establishing correspondences, so that more correct correspondences are\nfound. We train the network with a loss directly defined on the\ncorrespondences, and in the test stage the soft correspondences are transformed\ninto hard one-to-one correspondences so that registration can be performed by a\ncorrespondence-based solver. Furthermore, we introduce a transformer-based\nmethod to generate edges for graph construction, which further improves the\nquality of the correspondences. Extensive experiments on object-level and\nscene-level benchmark datasets show that the proposed method achieves\nstate-of-the-art performance. The code is available at:\n\\href{https://github.com/fukexue/RGM}{https://github.com/fukexue/RGM}.",
    "descriptor": "\nComments: accepted by TPAMI 2022. arXiv admin note: substantial text overlap with arXiv:2103.04256\n",
    "authors": [
      "Kexue Fu",
      "Jiazheng Luo",
      "Xiaoyuan Luo",
      "Shaolei Liu",
      "Chenxi Zhang",
      "Manning Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04696"
  },
  {
    "id": "arXiv:2211.04698",
    "title": "Unsupervised Extractive Summarization with Heterogeneous Graph  Embeddings for Chinese Document",
    "abstract": "In the scenario of unsupervised extractive summarization, learning\nhigh-quality sentence representations is essential to select salient sentences\nfrom the input document. Previous studies focus more on employing statistical\napproaches or pre-trained language models (PLMs) to extract sentence\nembeddings, while ignoring the rich information inherent in the heterogeneous\ntypes of interaction between words and sentences. In this paper, we are the\nfirst to propose an unsupervised extractive summarizaiton method with\nheterogeneous graph embeddings (HGEs) for Chinese document. A heterogeneous\ntext graph is constructed to capture different granularities of interactions by\nincorporating graph structural information. Moreover, our proposed graph is\ngeneral and flexible where additional nodes such as keywords can be easily\nintegrated. Experimental results demonstrate that our method consistently\noutperforms the strong baseline in three summarization datasets.",
    "descriptor": "",
    "authors": [
      "Chen Lin",
      "Ye Liu",
      "Siyu An",
      "Di Yin"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.04698"
  },
  {
    "id": "arXiv:2211.04699",
    "title": "FF2: A Feature Fusion Two-Stream Framework for Punctuation Restoration",
    "abstract": "To accomplish punctuation restoration, most existing methods focus on\nintroducing extra information (e.g., part-of-speech) or addressing the class\nimbalance problem. Recently, large-scale transformer-based pre-trained language\nmodels (PLMS) have been utilized widely and obtained remarkable success.\nHowever, the PLMS are trained on the large dataset with marks, which may not\nfit well with the small dataset without marks, causing the convergence to be\nnot ideal. In this study, we propose a Feature Fusion two-stream framework\n(FF2) to bridge the gap. Specifically, one stream leverages a pre-trained\nlanguage model to capture the semantic feature, while another auxiliary module\ncaptures the feature at hand. We also modify the computation of multi-head\nattention to encourage communication among heads. Then, two features with\ndifferent perspectives are aggregated to fuse information and enhance context\nawareness. Without additional data, the experimental results on the popular\nbenchmark IWSLT demonstrate that FF2 achieves new SOTA performance, which\nverifies that our approach is effective.",
    "descriptor": "\nComments: 5pages. arXiv admin note: substantial text overlap with arXiv:2203.12487\n",
    "authors": [
      "Yangjun Wu",
      "Kebin Fang",
      "Yao Zhao",
      "Hao Zhang",
      "Lifeng Shi",
      "Mengqi Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.04699"
  },
  {
    "id": "arXiv:2211.04700",
    "title": "NoiSER: Noise is All You Need for Enhancing Low-Light Images Without  Task-Related Data",
    "abstract": "This paper is about an extraordinary phenomenon. Suppose we don't use any\nlow-light images as training data, can we enhance a low-light image by deep\nlearning? Obviously, current methods cannot do this, since deep neural networks\nrequire to train their scads of parameters using copious amounts of training\ndata, especially task-related data. In this paper, we show that in the context\nof fundamental deep learning, it is possible to enhance a low-light image\nwithout any task-related training data. Technically, we propose a new, magical,\neffective and efficient method, termed \\underline{Noi}se\n\\underline{SE}lf-\\underline{R}egression (NoiSER), which learns a gray-world\nmapping from Gaussian distribution for low-light image enhancement (LLIE).\nSpecifically, a self-regression model is built as a carrier to learn a\ngray-world mapping during training, which is performed by simply iteratively\nfeeding random noise. During inference, a low-light image is directly fed into\nthe learned mapping to yield a normal-light one. Extensive experiments show\nthat our NoiSER is highly competitive to current task-related data based LLIE\nmodels in terms of quantitative and visual results, while outperforming them in\nterms of the number of parameters, training time and inference speed. With only\nabout 1K parameters, NoiSER realizes about 1 minute for training and 1.2 ms for\ninference with 600$\\times$400 resolution on RTX 2080 Ti. Besides, NoiSER has an\ninborn automated exposure suppression capability and can automatically adjust\ntoo bright or too dark, without additional manipulations.",
    "descriptor": "",
    "authors": [
      "Zhao Zhang",
      "Suiyi Zhao",
      "Xiaojie Jin",
      "Mingliang Xu",
      "Yi Yang",
      "Shuicheng Yan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04700"
  },
  {
    "id": "arXiv:2211.04704",
    "title": "A Linear Time Algorithm for the Optimal Discrete IRS Beamforming",
    "abstract": "It remains an open problem to find the optimal configuration of phase shifts\nunder the discrete constraint for intelligent reflecting surface (IRS) in\npolynomial time. The above problem is widely believed to be difficult because\nit is not linked to any known combinatorial problems that can be solved\nefficiently. The branch-and-bound algorithms and the approximation algorithms\nconstitute the best results in this area. Nevertheless, this work shows that\nthe global optimum can actually be reached in linear time in terms of the\nnumber of reflective elements (REs) of IRS. The main idea is to geometrically\ninterpret the discrete beamforming problem as choosing the optimal point on the\nunit circle. Although the number of possible combinations of phase shifts grows\nexponentially with the number of REs, it turns out that there are merely a\nlinear number of points on the unit circle to consider. Furthermore, the\nproposed algorithm can be viewed as a novel approach to a special case of the\ndiscrete quadratic program (QP).",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Dmitry Rybin",
      "Shuyi Ren",
      "Kaiming Shen",
      "Xin Li",
      "Xin Chen",
      "Zhi-Quan Luo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.04704"
  },
  {
    "id": "arXiv:2211.04712",
    "title": "Improve Model Testing by Integrating Bounded Model Checking and Coverage  Guided Fuzzing",
    "abstract": "The control logic models built by Simulink or Ptolemy have been widely used\nin industry scenes. It is an urgent need to ensure the safety and security of\nthe control logic models. Test case generation technologies are widely used to\nensure the safety and security. State-of-the-art model testing tools employ\nmodel checking techniques or search-based methods to generate test cases.\nTraditional search based techniques based on Simulink simulation are plagued by\nproblems such as low speed and high overhead. Traditional model checking\ntechniques such as symbolic execution have limited performance when dealing\nwith nonlinear elements and complex loops. Recently, coverage guided fuzzing\ntechnologies are known to be effective for test case generation, due to their\nhigh efficiency and impressive effects over complex branches of loops.\nIn this paper, we apply fuzzing methods to improve model testing and\ndemonstrate the effectiveness. The fuzzing methods aim to cover more program\nbranches by mutating valuable seeds. Inspired by this feature, we propose a\nnovel integration technology SPsCGF, which leverages bounded model checking for\nsymbolic execution to generate test cases as initial seeds and then conduct\nfuzzing based upon these worthy seeds. In this manner, our work combines the\nadvantages of the model checking methods and fuzzing techniques in a novel way.\nSince the control logic models always receive signal inputs, we specifically\ndesign novel mutation operators for signals to improve the existing fuzzing\nmethod in model testing. Over the evaluated benchmarks which consist of\nindustrial cases, SPsCGF could achieve 8% to 38% higher model coverage and\n3x-10x time efficiency compared with the state-of-the-art works.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Yixiao Yang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.04712"
  },
  {
    "id": "arXiv:2211.04715",
    "title": "Robosourcing Educational Resources -- Leveraging Large Language Models  for Learnersourcing",
    "abstract": "In this article, we introduce and evaluate the concept of robosourcing for\ncreating educational content. Robosourcing lies in the intersection of\ncrowdsourcing and large language models, where instead of a crowd of humans,\nrequests to large language models replace some of the work traditionally\nperformed by the crowd. Robosourcing includes a human-in-the-loop to provide\npriming (input) as well as to evaluate and potentially adjust the generated\nartefacts; these evaluations could also be used to improve the large language\nmodels. We propose a system to outline the robosourcing process. We further\nstudy the feasibility of robosourcing in the context of education by conducting\nan evaluation of robosourced and programming exercises, generated using OpenAI\nCodex. Our results suggest that robosourcing could significantly reduce human\neffort in creating diverse educational content while maintaining quality\nsimilar to human-created content.",
    "descriptor": "",
    "authors": [
      "Paul Denny",
      "Sami Sarsa",
      "Arto Hellas",
      "Juho Leinonen"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.04715"
  },
  {
    "id": "arXiv:2211.04717",
    "title": "Improving Noisy Student Training on Non-target Domain Data for Automatic  Speech Recognition",
    "abstract": "Noisy Student Training (NST) has recently demonstrated extremely strong\nperformance in Automatic Speech Recognition (ASR). In this paper, we propose a\ndata selection strategy named LM Filter to improve the performances of NST on\nnon-target domain data in ASR tasks. Hypothesis with and without Language Model\nare generated and CER differences between them are utilized as a filter\nthreshold. Results reveal that significant improvements of 10.4% compared with\nno data filtering baselines. We can achieve 3.31% CER in AISHELL-1 test set,\nwhich is best result from our knowledge without any other supervised data. We\nalso perform evaluations on supervised 1000 hour AISHELL-2 dataset and\ncompetitive results of 4.72% CER can be achieved.",
    "descriptor": "",
    "authors": [
      "Yu Chen",
      "Wen Ding",
      "Junjie Lai"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.04717"
  },
  {
    "id": "arXiv:2211.04718",
    "title": "Efficient Neural Mapping for Localisation of Unmanned Ground Vehicles",
    "abstract": "Global localisation from visual data is a challenging problem applicable to\nmany robotics domains. Prior works have shown that neural networks can be\ntrained to map images of an environment to absolute camera pose within that\nenvironment, learning an implicit neural mapping in the process. In this work\nwe evaluate the applicability of such an approach to real-world robotics\nscenarios, demonstrating that by constraining the problem to 2-dimensions and\nsignificantly increasing the quantity of training data, a compact model capable\nof real-time inference on embedded platforms can be used to achieve\nlocalisation accuracy of several centimetres. We deploy our trained model\nonboard a UGV platform, demonstrating its effectiveness in a waypoint\nnavigation task. Along with this work we will release a novel localisation\ndataset comprising simulated and real environments, each with training samples\nnumbering in the tens of thousands.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Christopher J. Holder",
      "Muhammad Shafique"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04718"
  },
  {
    "id": "arXiv:2211.04719",
    "title": "A Framework for Automated Correctness Checking of Biochemical Protocol  Realizations on Digital Microfluidic Biochips",
    "abstract": "Recent advances in digital microfluidic (DMF) technologies offer a promising\nplatform for a wide variety of biochemical applications, such as DNA analysis,\nautomated drug discovery, and toxicity monitoring. For on-chip implementation\nof complex bioassays, automated synthesis tools have been developed to meet the\ndesign challenges. Currently, the synthesis tools pass through a number of\ncomplex design steps to realize a given biochemical protocol on a target DMF\narchitecture. Thus, design errors can arise during the synthesis steps. Before\ndeploying a DMF biochip on a safety critical system, it is necessary to ensure\nthat the desired biochemical protocol has been correctly implemented, i.e., the\nsynthesized output (actuation sequences for the biochip) is free from any\ndesign or realization errors. We propose a symbolic constraint-based analysis\nframework for checking the correctness of a synthesized biochemical protocol\nwith respect to the original design specification. The verification scheme\nbased on this framework can detect several post-synthesis fluidic violations\nand realization errors in 2D-array based or pin-constrained biochips as well as\nin cyberphysical systems. It further generates diagnostic feedback for error\nlocalization. We present experimental results on the polymerase chain reaction\n(PCR) and in-vitro multiplexed bioassays to demonstrate the proposed\nverification approach.",
    "descriptor": "",
    "authors": [
      "Sukanta Bhattacharjee",
      "Ansuman Banerjee",
      "Krishnendu Chakrabarty",
      "Bhargab B. Bhattacharya"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2211.04719"
  },
  {
    "id": "arXiv:2211.04734",
    "title": "Framework Construction of an Adversarial Federated Transfer Learning  Classifier",
    "abstract": "As the Internet grows in popularity, more and more classification jobs, such\nas IoT, finance industry and healthcare field, rely on mobile edge computing to\nadvance machine learning. In the medical industry, however, good diagnostic\naccuracy necessitates the combination of large amounts of labeled data to train\nthe model, which is difficult and expensive to collect and risks jeopardizing\npatients' privacy. In this paper, we offer a novel medical diagnostic framework\nthat employs a federated learning platform to ensure patient data privacy by\ntransferring classification algorithms acquired in a labeled domain to a domain\nwith sparse or missing labeled data. Rather than using a generative adversarial\nnetwork, our framework uses a discriminative model to build multiple\nclassification loss functions with the goal of improving diagnostic accuracy.\nIt also avoids the difficulty of collecting large amounts of labeled data or\nthe high cost of generating large amount of sample data. Experiments on\nreal-world image datasets demonstrates that the suggested adversarial federated\ntransfer learning method is promising for real-world medical diagnosis\napplications that use image classification.",
    "descriptor": "",
    "authors": [
      "Hang Yi",
      "Tongxuan Bie",
      "Tongjiang Yan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.04734"
  },
  {
    "id": "arXiv:2211.04735",
    "title": "Uncertainty quantification in timber-like beams using sparse grids:  theory and examples with off-the-shelf software utilization",
    "abstract": "When dealing with timber structures, the characteristic strength and\nstiffness of the material are made highly variable and uncertain by the\nunavoidable, yet hardly predictable, presence of knots and other defects. In\nthis work we apply the sparse grids stochastic collocation method to perform\nuncertainty quantification for structural engineering in the scenario described\nabove. Sparse grids have been developed by the mathematical community in the\nlast decades and their theoretical background has been rigorously and\nextensively studied. The document proposes a brief practice-oriented\nintroduction with minimal theoretical background, provides detailed\ninstructions for the use of the already implemented Sparse Grid Matlab kit\n(freely available on-line) and discusses two numerical examples inspired from\ntimber engineering problems that highlight how sparse grids exhibit superior\nperformances compared to the plain Monte Carlo method. The Sparse Grid Matlab\nkit requires only a few lines of code to be interfaced with any numerical\nsolver for mechanical problems (in this work we used an isogeometric\ncollocation method) and provides outputs that can be easily interpreted and\nused in the engineering practice.",
    "descriptor": "",
    "authors": [
      "Balduzzi Giuseppe",
      "Bonizzoni Francesca",
      "Tamellini Lorenzo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.04735"
  },
  {
    "id": "arXiv:2211.04738",
    "title": "Asymptotic preserving and uniformly unconditionally stable finite  difference schemes for kinetic transport equations",
    "abstract": "In this paper, uniformly unconditionally stable first and second order finite\ndifference schemes are developed for kinetic transport equations in the\ndiffusive scaling. We first derive an approximate evolution equation for the\nmacroscopic density, from the formal solution of the distribution function,\nwhich is then discretized by following characteristics for the transport part\nwith a backward finite difference semi-Lagrangian approach, while the diffusive\npart is discretized implicitly. After the macroscopic density is available, the\ndistribution function can be efficiently solved even with a fully implicit time\ndiscretization, since all discrete velocities are decoupled, resulting in a\nlow-dimensional linear system from spatial discretizations at each discrete\nvelocity. Both first and second order discretizations in space and in time are\nconsidered. The resulting schemes can be shown to be asymptotic preserving (AP)\nin the diffusive limit. Uniformly unconditional stabilities are verified from a\nFourier analysis based on eigenvalues of corresponding amplification matrices.\nNumerical experiments, including high dimensional problems, have demonstrated\nthe corresponding orders of accuracy both in space and in time, uniform\nstability, AP property, and good performances of our proposed approach.",
    "descriptor": "",
    "authors": [
      "Guoliang Zhang",
      "Hongqiang Zhu",
      "Tao Xiong"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.04738"
  },
  {
    "id": "arXiv:2211.04741",
    "title": "Harpocrates: Privacy-Preserving and Immutable Audit Log for Sensitive  Data Operations",
    "abstract": "The audit log is a crucial component to monitor fine-grained operations over\nsensitive data (e.g., personal, health) for security inspection and assurance.\nSince such data operations can be highly sensitive, it is vital to ensure that\nthe audit log achieves not only validity and immutability, but also\nconfidentiality against active threats to standard data regulations (e.g.,\nHIPAA) compliance. Despite its critical needs, state-of-the-art\nprivacy-preserving audit log schemes (e.g., Ghostor (NSDI '20), Calypso (VLDB\n'19)) do not fully obtain a high level of privacy, integrity, and immutability\nsimultaneously, in which certain information (e.g., user identities) is still\nleaked in the log.\nIn this paper, we propose Harpocrates, a new privacy-preserving and immutable\naudit log scheme. Harpocrates permits data store, share, and access operations\nto be recorded in the audit log without leaking sensitive information (e.g.,\ndata identifier, user identity), while permitting the validity of data\noperations to be publicly verifiable. Harpocrates makes use of blockchain\ntechniques to achieve immutability and avoid a single point of failure, while\ncryptographic zero-knowledge proofs are harnessed for confidentiality and\npublic verifiability. We analyze the security of our proposed technique and\nprove that it achieves non-malleability and indistinguishability. We fully\nimplemented Harpocrates and evaluated its performance on a real blockchain\nsystem (i.e., Hyperledger Fabric) deployed on a commodity platform (i.e.,\nAmazon EC2). Experimental results demonstrated that Harpocrates is highly\nscalable and achieves practical performance.",
    "descriptor": "\nComments: To appear at IEEE 4th International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications (TPS-ISA) 2022\n",
    "authors": [
      "Mohit Bhasi Thazhath",
      "Jan Michalak",
      "Thang Hoang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.04741"
  },
  {
    "id": "arXiv:2211.04742",
    "title": "Knowledge Distillation for Federated Learning: a Practical Guide",
    "abstract": "Federated Learning (FL) enables the training of Deep Learning models without\ncentrally collecting possibly sensitive raw data. This paves the way for\nstronger privacy guarantees when building predictive models. The most used\nalgorithms for FL are parameter-averaging based schemes (e.g., Federated\nAveraging) that, however, have well known limits: (i) Clients must implement\nthe same model architecture; (ii) Transmitting model weights and model updates\nimplies high communication cost, which scales up with the number of model\nparameters; (iii) In presence of non-IID data distributions,\nparameter-averaging aggregation schemes perform poorly due to client model\ndrifts. Federated adaptations of regular Knowledge Distillation (KD) can solve\nand/or mitigate the weaknesses of parameter-averaging FL algorithms while\npossibly introducing other trade-offs. In this article, we provide a review of\nKD-based algorithms tailored for specific FL issues.",
    "descriptor": "\nComments: 9 pages, 1 figure\n",
    "authors": [
      "Alessio Mora",
      "Irene Tenison",
      "Paolo Bellavista",
      "Irina Rish"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04742"
  },
  {
    "id": "arXiv:2211.04746",
    "title": "Novelty in news search: a longitudinal study of the 2020 US elections",
    "abstract": "The 2020 US elections news coverage was extensive, with new pieces of\ninformation generated rapidly. This evolving scenario presented an opportunity\nto study the performance of search engines in a context in which they had to\nquickly process information as it was published. We analyze novelty, a\nmeasurement of new items that emerge in the top news search results, to compare\nthe coverage and visibility of different topics. We conduct a longitudinal\nstudy of news results of five search engines collected in short-bursts (every\n21 minutes) from two regions (Oregon, US and Frankfurt, Germany), starting on\nelection day and lasting until one day after the announcement of Biden as the\nwinner. We find more new items emerging for election related queries (\"joe\nbiden\", \"donald trump\" and \"us elections\") compared to topical (e.g.,\n\"coronavirus\") or stable (e.g., \"holocaust\") queries. We demonstrate\ndifferences across search engines and regions over time, and we highlight\nimbalances between candidate queries. When it comes to news search, search\nengines are responsible for such imbalances, either due to their algorithms or\nthe set of news sources they rely on. We argue that such imbalances affect the\nvisibility of political candidates in news searches during electoral periods.",
    "descriptor": "",
    "authors": [
      "Roberto Ulloa",
      "Mykola Makhortykh",
      "Aleksandra Urman",
      "Juhi Kulshrestha"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.04746"
  },
  {
    "id": "arXiv:2211.04750",
    "title": "Errorless Robust JPEG Steganography using Outputs of JPEG Coders",
    "abstract": "Robust steganography is a technique of hiding secret messages in images so\nthat the message can be recovered after additional image processing. One of the\nmost popular processing operations is JPEG recompression. Unfortunately, most\nof today's steganographic methods addressing this issue only provide a\nprobabilistic guarantee of recovering the secret and are consequently not\nerrorless. That is unacceptable since even a single unexpected change can make\nthe whole message unreadable if it is encrypted. We propose to create a robust\nset of DCT coefficients by inspecting their behavior during recompression,\nwhich requires access to the targeted JPEG compressor. This is done by dividing\nthe DCT coefficients into 64 non-overlapping lattices because one embedding\nchange can potentially affect many other coefficients from the same DCT block\nduring recompression. The robustness is then combined with standard\nsteganographic costs creating a lattice embedding scheme robust against JPEG\nrecompression. Through experiments, we show that the size of the robust set and\nthe scheme's security depends on the ordering of lattices during embedding. We\nverify the validity of the proposed method with three typical JPEG compressors\nand benchmark its security for various embedding payloads, three different ways\nof ordering the lattices, and a range of Quality Factors. Finally, this method\nis errorless by construction, meaning the embedded message will always be\nreadable.",
    "descriptor": "\nComments: 10 pages, 11 figures, 1 table, submitted to IEEE Transactions on Dependable and Secure Computing\n",
    "authors": [
      "Jan Butora",
      "Pauline Puteaux",
      "Patrick Bas"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Cryptography and Security (cs.CR)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.04750"
  },
  {
    "id": "arXiv:2211.04753",
    "title": "ReFu: Refine and Fuse the Unobserved View for Detail-Preserving  Single-Image 3D Human Reconstruction",
    "abstract": "Single-image 3D human reconstruction aims to reconstruct the 3D textured\nsurface of the human body given a single image. While implicit function-based\nmethods recently achieved reasonable reconstruction performance, they still\nbear limitations showing degraded quality in both surface geometry and texture\nfrom an unobserved view. In response, to generate a realistic textured surface,\nwe propose ReFu, a coarse-to-fine approach that refines the projected backside\nview image and fuses the refined image to predict the final human body. To\nsuppress the diffused occupancy that causes noise in projection images and\nreconstructed meshes, we propose to train occupancy probability by\nsimultaneously utilizing 2D and 3D supervisions with occupancy-based volume\nrendering. We also introduce a refinement architecture that generates\ndetail-preserving backside-view images with front-to-back warping. Extensive\nexperiments demonstrate that our method achieves state-of-the-art performance\nin 3D human reconstruction from a single image, showing enhanced geometry and\ntexture quality from an unobserved view.",
    "descriptor": "\nComments: Accepted at ACM MM 2022\n",
    "authors": [
      "Gyumin Shim",
      "Minsoo Lee",
      "Jaegul Choo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04753"
  },
  {
    "id": "arXiv:2211.04754",
    "title": "Semi-Equivariant Continuous Normalizing Flows for Target-Aware Molecule  Generation",
    "abstract": "We propose an algorithm for learning a conditional generative model of a\nmolecule given a target. Specifically, given a receptor molecule that one\nwishes to bind to, the conditional model generates candidate ligand molecules\nthat may bind to it. The distribution should be invariant to rigid body\ntransformations that act $\\textit{jointly}$ on the ligand and the receptor; it\nshould also be invariant to permutations of either the ligand or receptor\natoms. Our learning algorithm is based on a continuous normalizing flow. We\nestablish semi-equivariance conditions on the flow which guarantee the\naforementioned invariance conditions on the conditional distribution. We\npropose a graph neural network architecture which implements this flow, and\nwhich is designed to learn effectively despite the vast differences in size\nbetween the ligand and receptor. We evaluate our method on the CrossDocked2020\ndataset, attaining a significant improvement in binding affinity over competing\nmethods.",
    "descriptor": "",
    "authors": [
      "Eyal Rozenberg",
      "Daniel Freedman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2211.04754"
  },
  {
    "id": "arXiv:2211.04755",
    "title": "Towards Global Crop Maps with Transfer Learning",
    "abstract": "The continuous increase in global population and the impact of climate change\non crop production are expected to affect the food sector significantly. In\nthis context, there is need for timely, large-scale and precise mapping of\ncrops for evidence-based decision making. A key enabler towards this direction\nare new satellite missions that freely offer big remote sensing data of high\nspatio-temporal resolution and global coverage. During the previous decade and\nbecause of this surge of big Earth observations, deep learning methods have\ndominated the remote sensing and crop mapping literature. Nevertheless, deep\nlearning models require large amounts of annotated data that are scarce and\nhard-to-acquire. To address this problem, transfer learning methods can be used\nto exploit available annotations and enable crop mapping for other regions,\ncrop types and years of inspection. In this work, we have developed and trained\na deep learning model for paddy rice detection in South Korea using Sentinel-1\nVH time-series. We then fine-tune the model for i) paddy rice detection in\nFrance and Spain and ii) barley detection in the Netherlands. Additionally, we\npropose a modification in the pre-trained weights in order to incorporate extra\ninput features (Sentinel-1 VV). Our approach shows excellent performance when\ntransferring in different areas for the same crop type and rather promising\nresults when transferring in a different area and crop type.",
    "descriptor": "\nComments: Accepted for publication at Tackling Climate Change with Machine Learning: workshop at NeurIPS 2022\n",
    "authors": [
      "Hyun-Woo Jo",
      "Alkiviadis Koukos",
      "Vasileios Sitokonstantinou",
      "Woo-Kyun Lee",
      "Charalampos Kontoes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04755"
  },
  {
    "id": "arXiv:2211.04757",
    "title": "Lower bounds for piecewise polynomial approximations of oscillatory  functions",
    "abstract": "We prove sharp lower bounds on the error incurred when approximating\noscillating functions using piecewise polynomial spaces.",
    "descriptor": "",
    "authors": [
      "Jeffrey Galkowski"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.04757"
  },
  {
    "id": "arXiv:2211.04759",
    "title": "Nested Named Entity Recognition from Medical Texts: An Adaptive Shared  Network Architecture with Attentive CRF",
    "abstract": "Recognizing useful named entities plays a vital role in medical information\nprocessing, which helps drive the development of medical area research. Deep\nlearning methods have achieved good results in medical named entity recognition\n(NER). However, we find that existing methods face great challenges when\ndealing with the nested named entities. In this work, we propose a novel\nmethod, referred to as ASAC, to solve the dilemma caused by the nested\nphenomenon, in which the core idea is to model the dependency between different\ncategories of entity recognition. The proposed method contains two key modules:\nthe adaptive shared (AS) part and the attentive conditional random field (ACRF)\nmodule. The former part automatically assigns adaptive weights across each task\nto achieve optimal recognition accuracy in the multi-layer network. The latter\nmodule employs the attention operation to model the dependency between\ndifferent entities. In this way, our model could learn better entity\nrepresentations by capturing the implicit distinctions and relationships\nbetween different categories of entities. Extensive experiments on public\ndatasets verify the effectiveness of our method. Besides, we also perform\nablation analyses to deeply understand our methods.",
    "descriptor": "",
    "authors": [
      "Junzhe Jiang",
      "Mingyue Cheng",
      "Qi Liu",
      "Zhi Li",
      "Enhong Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04759"
  },
  {
    "id": "arXiv:2211.04762",
    "title": "Building Resilience in Cybersecurity -- An Artificial Lab Approach",
    "abstract": "Based on classical contagion models we introduce an artificial cyber lab: the\ndigital twin of a complex cyber system in which possible cyber resilience\nmeasures may be implemented and tested. Using the lab, in numerical case\nstudies, we identify two classes of measures to control systemic cyber risks:\nsecurity- and topology-based interventions. We discuss the implications of our\nfindings on selected real-world cybersecurity measures currently applied in the\ninsurance and regulation practice or under discussion for future cyber risk\ncontrol. To this end, we provide a brief overview of the current cybersecurity\nregulation and emphasize the role of insurance companies as private regulators.\nMoreover, from an insurance point of view, we provide first attempts to design\nsystemic cyber risk obligations and to measure the systemic risk contribution\nof individual policyholders.",
    "descriptor": "",
    "authors": [
      "Kerstin Awiszus",
      "Yannick Bell",
      "Jan L\u00fcttringhaus",
      "Gregor Svindland",
      "Alexander Vo\u00df",
      "Stefan Weber"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)",
      "Systems and Control (eess.SY)",
      "Probability (math.PR)",
      "Risk Management (q-fin.RM)"
    ],
    "url": "https://arxiv.org/abs/2211.04762"
  },
  {
    "id": "arXiv:2211.04769",
    "title": "Interpretable Explainability in Facial Emotion Recognition and  Gamification for Data Collection",
    "abstract": "Training facial emotion recognition models requires large sets of data and\ncostly annotation processes. To alleviate this problem, we developed a gamified\nmethod of acquiring annotated facial emotion data without an explicit labeling\neffort by humans. The game, which we named Facegame, challenges the players to\nimitate a displayed image of a face that portrays a particular basic emotion.\nEvery round played by the player creates new data that consists of a set of\nfacial features and landmarks, already annotated with the emotion label of the\ntarget facial expression. Such an approach effectively creates a robust,\nsustainable, and continuous machine learning training process. We evaluated\nFacegame with an experiment that revealed several contributions to the field of\naffective computing. First, the gamified data collection approach allowed us to\naccess a rich variation of facial expressions of each basic emotion due to the\nnatural variations in the players' facial expressions and their expressive\nabilities. We report improved accuracy when the collected data were used to\nenrich well-known in-the-wild facial emotion datasets and consecutively used\nfor training facial emotion recognition models. Second, the natural language\nprescription method used by the Facegame constitutes a novel approach for\ninterpretable explainability that can be applied to any facial emotion\nrecognition model. Finally, we observed significant improvements in the facial\nemotion perception and expression skills of the players through repeated game\nplay.",
    "descriptor": "\nComments: 8 pages, 8 figures, 2022 10th International Conference on Affective Computing and Intelligent Interaction (ACII)\n",
    "authors": [
      "Krist Shingjergji",
      "Deniz Iren",
      "Felix Bottger",
      "Corrie Urlings",
      "Roland Klemke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.04769"
  },
  {
    "id": "arXiv:2211.04770",
    "title": "Continual learning autoencoder training for a particle-in-cell  simulation via streaming",
    "abstract": "The upcoming exascale era will provide a new generation of physics\nsimulations. These simulations will have a high spatiotemporal resolution,\nwhich will impact the training of machine learning models since storing a high\namount of simulation data on disk is nearly impossible. Therefore, we need to\nrethink the training of machine learning models for simulations for the\nupcoming exascale era. This work presents an approach that trains a neural\nnetwork concurrently to a running simulation without storing data on a disk.\nThe training pipeline accesses the training data by in-memory streaming.\nFurthermore, we apply methods from the domain of continual learning to enhance\nthe generalization of the model. We tested our pipeline on the training of a 3d\nautoencoder trained concurrently to laser wakefield acceleration\nparticle-in-cell simulation. Furthermore, we experimented with various\ncontinual learning methods and their effect on the generalization.",
    "descriptor": "",
    "authors": [
      "Patrick Stiller",
      "Varun Makdani",
      "Franz P\u00f6schel",
      "Richard Pausch",
      "Alexander Debus",
      "Michael Bussmann",
      "Nico Hoffmann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "High Energy Physics - Theory (hep-th)"
    ],
    "url": "https://arxiv.org/abs/2211.04770"
  },
  {
    "id": "arXiv:2211.04772",
    "title": "Efficient Large-scale Audio Tagging via Transformer-to-CNN Knowledge  Distillation",
    "abstract": "Audio Spectrogram Transformer models rule the field of Audio Tagging,\noutrunning previously dominating Convolutional Neural Networks (CNNs). Their\nsuperiority is based on the ability to scale up and exploit large-scale\ndatasets such as AudioSet. However, Transformers are demanding in terms of\nmodel size and computational requirements compared to CNNs. We propose a\ntraining procedure for efficient CNNs based on offline Knowledge Distillation\n(KD) from high-performing yet complex transformers. The proposed training\nschema and the efficient CNN design based on MobileNetV3 results in models\noutperforming previous solutions in terms of parameter and computational\nefficiency and prediction performance. We provide models of different\ncomplexity levels, scaling from low-complexity models up to a new\nstate-of-the-art performance of .483 mAP on AudioSet. Source Code available at:\nhttps://github.com/fschmid56/EfficientAT",
    "descriptor": "\nComments: Submitted to ICASSP 2023. Source Code available at: this https URL\n",
    "authors": [
      "Florian Schmid",
      "Khaled Koutini",
      "Gerhard Widmer"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.04772"
  },
  {
    "id": "arXiv:2211.04773",
    "title": "SG-Shuffle: Multi-aspect Shuffle Transformer for Scene Graph Generation",
    "abstract": "Scene Graph Generation (SGG) serves a comprehensive representation of the\nimages for human understanding as well as visual understanding tasks. Due to\nthe long tail bias problem of the object and predicate labels in the available\nannotated data, the scene graph generated from current methodologies can be\nbiased toward common, non-informative relationship labels. Relationship can\nsometimes be non-mutually exclusive, which can be described from multiple\nperspectives like geometrical relationships or semantic relationships, making\nit even more challenging to predict the most suitable relationship label. In\nthis work, we proposed the SG-Shuffle pipeline for scene graph generation with\n3 components: 1) Parallel Transformer Encoder, which learns to predict object\nrelationships in a more exclusive manner by grouping relationship labels into\ngroups of similar purpose; 2) Shuffle Transformer, which learns to select the\nfinal relationship labels from the category-specific feature generated in the\nprevious step; and 3) Weighted CE loss, used to alleviate the training bias\ncaused by the imbalanced dataset.",
    "descriptor": "",
    "authors": [
      "Anh Duc Bui",
      "Soyeon Caren Han",
      "Josiah Poon"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04773"
  },
  {
    "id": "arXiv:2211.04774",
    "title": "ARNet: Automatic Refinement Network for Noisy Partial Label Learning",
    "abstract": "Partial label learning (PLL) is a typical weakly supervised learning, where\neach sample is associated with a set of candidate labels. The basic assumption\nof PLL is that the ground-truth label must reside in the candidate set.\nHowever, this assumption may not be satisfied due to the unprofessional\njudgment of the annotators, thus limiting the practical application of PLL. In\nthis paper, we relax this assumption and focus on a more general problem, noisy\nPLL, where the ground-truth label may not exist in the candidate set. To\naddress this challenging problem, we further propose a novel framework called\n\"Automatic Refinement Network (ARNet)\". Our method consists of multiple rounds.\nIn each round, we purify the noisy samples through two key modules, i.e., noisy\nsample detection and label correction. To guarantee the performance of these\nmodules, we start with warm-up training and automatically select the\nappropriate correction epoch. Meanwhile, we exploit data augmentation to\nfurther reduce prediction errors in ARNet. Through theoretical analysis, we\nprove that our method is able to reduce the noise level of the dataset and\neventually approximate the Bayes optimal classifier. To verify the\neffectiveness of ARNet, we conduct experiments on multiple benchmark datasets.\nExperimental results demonstrate that our ARNet is superior to existing\nstate-of-the-art approaches in noisy PLL. Our code will be made public soon.",
    "descriptor": "",
    "authors": [
      "Zheng Lian",
      "Mingyu Xu",
      "Lan Chen",
      "Licai Sun",
      "Bin Liu",
      "Jianhua Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04774"
  },
  {
    "id": "arXiv:2211.04775",
    "title": "ZK-IMG: Attested Images via Zero-Knowledge Proofs to Fight  Disinformation",
    "abstract": "Over the past few years, AI methods of generating images have been increasing\nin capabilities, with recent breakthroughs enabling high-resolution,\nphotorealistic \"deepfakes\" (artificially generated images with the purpose of\nmisinformation or harm). The rise of deepfakes has potential for social\ndisruption. Recent work has proposed using ZK-SNARKs (zero-knowledge succinct\nnon-interactive argument of knowledge) and attested cameras to verify that\nimages were taken by a camera. ZK-SNARKs allow verification of image\ntransformations non-interactively (i.e., post-hoc) with only standard\ncryptographic hardness assumptions. Unfortunately, this work does not preserve\ninput privacy, is impractically slow (working only on 128$\\times$128 images),\nand/or requires custom cryptographic arguments.\nTo address these issues, we present zk-img, a library for attesting to image\ntransformations while hiding the pre-transformed image. zk-img allows\napplication developers to specify high level image transformations. Then,\nzk-img will transparently compile these specifications to ZK-SNARKs. To hide\nthe input or output images, zk-img will compute the hash of the images inside\nthe ZK-SNARK. We further propose methods of chaining image transformations\nsecurely and privately, which allows for arbitrarily many transformations. By\ncombining these optimizations, zk-img is the first system to be able to\ntransform HD images on commodity hardware, securely and privately.",
    "descriptor": "",
    "authors": [
      "Daniel Kang",
      "Tatsunori Hashimoto",
      "Ion Stoica",
      "Yi Sun"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.04775"
  },
  {
    "id": "arXiv:2211.04780",
    "title": "On the Robustness of Explanations of Deep Neural Network Models: A  Survey",
    "abstract": "Explainability has been widely stated as a cornerstone of the responsible and\ntrustworthy use of machine learning models. With the ubiquitous use of Deep\nNeural Network (DNN) models expanding to risk-sensitive and safety-critical\ndomains, many methods have been proposed to explain the decisions of these\nmodels. Recent years have also seen concerted efforts that have shown how such\nexplanations can be distorted (attacked) by minor input perturbations. While\nthere have been many surveys that review explainability methods themselves,\nthere has been no effort hitherto to assimilate the different methods and\nmetrics proposed to study the robustness of explanations of DNN models. In this\nwork, we present a comprehensive survey of methods that study, understand,\nattack, and defend explanations of DNN models. We also present a detailed\nreview of different metrics used to evaluate explanation methods, as well as\ndescribe attributional attack and defense methods. We conclude with lessons and\ntake-aways for the community towards ensuring robust explanations of DNN model\npredictions.",
    "descriptor": "\nComments: Under Review ACM Computing Surveys \"Special Issue on Trustworthy AI\"\n",
    "authors": [
      "Amlan Jyoti",
      "Karthik Balaji Ganesh",
      "Manoj Gayala",
      "Nandita Lakshmi Tunuguntla",
      "Sandesh Kamath",
      "Vineeth N Balasubramanian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04780"
  },
  {
    "id": "arXiv:2211.04781",
    "title": "Profiling Obese Subgroups in National Health and Nutritional Status  Survey Data using Machine Learning Techniques: A Case Study from Brunei  Darussalam",
    "abstract": "National Health and Nutritional Status Survey (NHANSS) is conducted annually\nby the Ministry of Health in Negara Brunei Darussalam to assess the population\nhealth and nutritional patterns and characteristics. The main aim of this study\nwas to discover meaningful patterns (groups) from the obese sample of NHANSS\ndata by applying data reduction and interpretation techniques. The mixed nature\nof the variables (qualitative and quantitative) in the data set added novelty\nto the study. Accordingly, the Categorical Principal Component (CATPCA)\ntechnique was chosen to interpret the meaningful results. The relationships\nbetween obesity and the lifestyle factors like demography, socioeconomic\nstatus, physical activity, dietary behavior, history of blood pressure,\ndiabetes, etc., were determined based on the principal components generated by\nCATPCA. The results were validated with the help of the split method technique\nto counter verify the authenticity of the generated groups. Based on the\nanalysis and results, two subgroups were found in the data set, and the salient\nfeatures of these subgroups have been reported. These results can be proposed\nfor the betterment of the healthcare industry.",
    "descriptor": "\nComments: A Case study of Obese Subgroups from Brunei Darussalam: 15 Pages, 4 figures, journal\n",
    "authors": [
      "Usman Khalil",
      "Owais Ahmed Malik",
      "Daphne Teck Ching Lai",
      "Ong Sok King"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04781"
  },
  {
    "id": "arXiv:2211.04785",
    "title": "Masked Vision-Language Transformers for Scene Text Recognition",
    "abstract": "Scene text recognition (STR) enables computers to recognize and read the text\nin various real-world scenes. Recent STR models benefit from taking linguistic\ninformation in addition to visual cues into consideration. We propose a novel\nMasked Vision-Language Transformers (MVLT) to capture both the explicit and the\nimplicit linguistic information. Our encoder is a Vision Transformer, and our\ndecoder is a multi-modal Transformer. MVLT is trained in two stages: in the\nfirst stage, we design a STR-tailored pretraining method based on a masking\nstrategy; in the second stage, we fine-tune our model and adopt an iterative\ncorrection method to improve the performance. MVLT attains superior results\ncompared to state-of-the-art STR models on several benchmarks. Our code and\nmodel are available at https://github.com/onealwj/MVLT.",
    "descriptor": "\nComments: The paper is accepted by the 33rd British Machine Vision Conference (BMVC 2022)\n",
    "authors": [
      "Jie Wu",
      "Ying Peng",
      "Shengming Zhang",
      "Weigang Qi",
      "Jian Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04785"
  },
  {
    "id": "arXiv:2211.04786",
    "title": "Leveraging Sequentiality in Reinforcement Learning from a Single  Demonstration",
    "abstract": "Deep Reinforcement Learning has been successfully applied to learn robotic\ncontrol. However, the corresponding algorithms struggle when applied to\nproblems where the agent is only rewarded after achieving a complex task. In\nthis context, using demonstrations can significantly speed up the learning\nprocess, but demonstrations can be costly to acquire. In this paper, we propose\nto leverage a sequential bias to learn control policies for complex robotic\ntasks using a single demonstration. To do so, our method learns a\ngoal-conditioned policy to control a system between successive low-dimensional\ngoals. This sequential goal-reaching approach raises a problem of compatibility\nbetween successive goals: we need to ensure that the state resulting from\nreaching a goal is compatible with the achievement of the following goals. To\ntackle this problem, we present a new algorithm called DCIL-II. We show that\nDCIL-II can solve with unprecedented sample efficiency some challenging\nsimulated tasks such as humanoid locomotion and stand-up as well as fast\nrunning with a simulated Cassie robot. Our method leveraging sequentiality is a\nstep towards the resolution of complex robotic tasks under minimal\nspecification effort, a key feature for the next generation of autonomous\nrobots.",
    "descriptor": "",
    "authors": [
      "Alexandre Chenu",
      "Olivier Serris",
      "Olivier Sigaud",
      "Nicolas Perrin-Gilbert"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04786"
  },
  {
    "id": "arXiv:2211.04793",
    "title": "RadFormer: Transformers with Global-Local Attention for Interpretable  and Accurate Gallbladder Cancer Detection",
    "abstract": "We propose a novel deep neural network architecture to learn interpretable\nrepresentation for medical image analysis. Our architecture generates a global\nattention for region of interest, and then learns bag of words style deep\nfeature embeddings with local attention. The global, and local feature maps are\ncombined using a contemporary transformer architecture for highly accurate\nGallbladder Cancer (GBC) detection from Ultrasound (USG) images. Our\nexperiments indicate that the detection accuracy of our model beats even human\nradiologists, and advocates its use as the second reader for GBC diagnosis. Bag\nof words embeddings allow our model to be probed for generating interpretable\nexplanations for GBC detection consistent with the ones reported in medical\nliterature. We show that the proposed model not only helps understand decisions\nof neural network models but also aids in discovery of new visual features\nrelevant to the diagnosis of GBC. Source-code and model will be available at\nhttps://github.com/sbasu276/RadFormer",
    "descriptor": "\nComments: To Appear in Elsevier Medical Image Analysis\n",
    "authors": [
      "Soumen Basu",
      "Mayank Gupta",
      "Pratyaksha Rana",
      "Pankaj Gupta",
      "Chetan Arora"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04793"
  },
  {
    "id": "arXiv:2211.04797",
    "title": "Shortest Cycles With Monotone Submodular Costs",
    "abstract": "We introduce the following submodular generalization of the Shortest Cycle\nproblem. For a nonnegative monotone submodular cost function $f$ defined on the\nedges (or the vertices) of an undirected graph $G$, we seek for a cycle $C$ in\n$G$ of minimum cost $\\textsf{OPT}=f(C)$. We give an algorithm that given an\n$n$-vertex graph $G$, parameter $\\varepsilon > 0$, and the function $f$\nrepresented by an oracle, in time $n^{\\mathcal{O}(\\log 1/\\varepsilon)}$ finds a\ncycle $C$ in $G$ with $f(C)\\leq (1+\\varepsilon)\\cdot \\textsf{OPT}$. This is in\nsharp contrast with the non-approximability of the closely related Monotone\nSubmodular Shortest $(s,t)$-Path problem, which requires exponentially many\nqueries to the oracle for finding an $n^{2/3-\\varepsilon}$-approximation [Goel\net al., FOCS 2009]. We complement our algorithm with a matching lower bound. We\nshow that for every $\\varepsilon > 0$, obtaining a\n$(1+\\varepsilon)$-approximation requires at least $n^{\\Omega(\\log 1/\n\\varepsilon)}$ queries to the oracle. When the function $f$ is integer-valued,\nour algorithm yields that a cycle of cost $\\textsf{OPT}$ can be found in time\n$n^{\\mathcal{O}(\\log \\textsf{OPT})}$. In particular, for\n$\\textsf{OPT}=n^{\\mathcal{O}(1)}$ this gives a quasipolynomial-time algorithm\ncomputing a cycle of minimum submodular cost. Interestingly, while a\nquasipolynomial-time algorithm often serves as a good indication that a\npolynomial time complexity could be achieved, we show a lower bound that\n$n^{\\mathcal{O}(\\log n)}$ queries are required even when $\\textsf{OPT} =\n\\mathcal{O}(n)$.",
    "descriptor": "\nComments: 17 pages, 1 figure. Accepted to SODA 2023\n",
    "authors": [
      "Fedor V. Fomin",
      "Petr A. Golovach",
      "Tuukka Korhonen",
      "Daniel Lokshtanov",
      "Giannos Stamoulis"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.04797"
  },
  {
    "id": "arXiv:2211.04798",
    "title": "On the use of learning-based forecasting methods for ameliorating  fashion business processes: A position paper",
    "abstract": "The fashion industry is one of the most active and competitive markets in the\nworld, manufacturing millions of products and reaching large audiences every\nyear. A plethora of business processes are involved in this large-scale\nindustry, but due to the generally short life-cycle of clothing items,\nsupply-chain management and retailing strategies are crucial for good market\nperformance. Correctly understanding the wants and needs of clients, managing\nlogistic issues and marketing the correct products are high-level problems with\na lot of uncertainty associated to them given the number of influencing\nfactors, but most importantly due to the unpredictability often associated with\nthe future. It is therefore straightforward that forecasting methods, which\ngenerate predictions of the future, are indispensable in order to ameliorate\nall the various business processes that deal with the true purpose and meaning\nof fashion: having a lot of people wear a particular product or style,\nrendering these items, people and consequently brands fashionable. In this\npaper, we provide an overview of three concrete forecasting tasks that any\nfashion company can apply in order to improve their industrial and market\nimpact. We underline advances and issues in all three tasks and argue about\ntheir importance and the impact they can have at an industrial level. Finally,\nwe highlight issues and directions of future work, reflecting on how\nlearning-based forecasting methods can further aid the fashion industry.",
    "descriptor": "\nComments: 2nd International Workshop on Industrial Machine Learning @ ICPR 2022\n",
    "authors": [
      "Geri Skenderi",
      "Christian Joppi",
      "Matteo Denitto",
      "Marco Cristani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04798"
  },
  {
    "id": "arXiv:2211.04799",
    "title": "Bit-depth enhancement detection for compressed video",
    "abstract": "In recent years, display intensity and contrast have increased considerably.\nMany displays support high dynamic range (HDR) and 10-bit color depth. Since\nhigh bit-depth is an emerging technology, video content is still largely shot\nand transmitted with a bit depth of 8 bits or less per color component.\nInsufficient bit-depths produce distortions called false contours or banding,\nand they are visible on high contrast screens. To deal with such distortions,\nresearchers have proposed algorithms for bit-depth enhancement\n(dequantization). Such techniques convert videos with low bit-depth (LBD) to\nvideos with high bit-depth (HBD). The quality of converted LBD video, however,\nis usually lower than that of the original HBD video, and many consumers prefer\nto keep the original HBD versions. In this paper, we propose an algorithm to\ndetermine whether a video has undergone conversion before compression. This\nproblem is complex; it involves detecting outcomes of different dequantization\nalgorithms in the presence of compression that strongly affects the\nleast-significant bits (LSBs) in the video frames. Our algorithm can detect\nbit-depth enhancement and demonstrates good generalization capability, as it is\nable to determine whether a video has undergone processing by dequantization\nalgorithms absent from the training dataset.",
    "descriptor": "",
    "authors": [
      "Nickolay Safonov",
      "Dmitriy Vatolin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.04799"
  },
  {
    "id": "arXiv:2211.04800",
    "title": "Designing Network Design Strategies Through Gradient Path Analysis",
    "abstract": "Designing a high-efficiency and high-quality expressive network architecture\nhas always been the most important research topic in the field of deep\nlearning. Most of today's network design strategies focus on how to integrate\nfeatures extracted from different layers, and how to design computing units to\neffectively extract these features, thereby enhancing the expressiveness of the\nnetwork. This paper proposes a new network design strategy, i.e., to design the\nnetwork architecture based on gradient path analysis. On the whole, most of\ntoday's mainstream network design strategies are based on feed forward path,\nthat is, the network architecture is designed based on the data path. In this\npaper, we hope to enhance the expressive ability of the trained model by\nimproving the network learning ability. Due to the mechanism driving the\nnetwork parameter learning is the backward propagation algorithm, we design\nnetwork design strategies based on back propagation path. We propose the\ngradient path design strategies for the layer-level, the stage-level, and the\nnetwork-level, and the design strategies are proved to be superior and feasible\nfrom theoretical analysis and experiments.",
    "descriptor": "\nComments: 12 pages, 9 figures\n",
    "authors": [
      "Chien-Yao Wang",
      "Hong-Yuan Mark Liao",
      "I-Hau Yeh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04800"
  },
  {
    "id": "arXiv:2211.04803",
    "title": "DSCOT: An NFT-Based Blockchain Architecture for the Authentication of  IoT-Enabled Smart Devices in Smart Cities",
    "abstract": "Smart city architecture brings all the underlying architectures, i.e.,\nInternet of Things (IoT), Cyber-Physical Systems (CPSs), Internet of\nCyber-Physical Things (IoCPT), and Internet of Everything (IoE), together to\nwork as a system under its umbrella. The goal of smart city architecture is to\ncome up with a solution that may integrate all the real-time response\napplications. However, the cyber-physical space poses threats that can\njeopardize the working of a smart city where all the data belonging to people,\nsystems, and processes will be at risk. Various architectures based on\ncentralized and distributed mechanisms support smart cities; however, the\nsecurity concerns regarding traceability, scalability, security services,\nplatform assistance, and resource management persist. In this paper, private\nblockchain-based architecture Decentralized Smart City of Things (DSCoT) is\nproposed. It actively utilizes fog computing for all the users and smart\ndevices connected to a fog node in a particular management system in a smart\ncity, i.e., a smart house or hospital, etc. Non-fungible tokens (NFTs) have\nbeen utilized for representation to define smart device attributes. NFTs in the\nproposed DSCoT architecture provide devices and user authentication (IoT)\nfunctionality. DSCoT has been designed to provide a smart city solution that\nensures robust security features such as Confidentiality, Integrity,\nAvailability (CIA), and authorization by defining new attributes and functions\nfor Owner, User, Fog, and IoT devices authentication. The evaluation of the\nproposed functions and components in terms of Gas consumption and time\ncomplexity has shown promising results. Comparatively, the Gas consumption for\nminting DSCoT NFT showed approximately 27%, and a DSCoT approve() was\napproximately 11% more efficient than the PUF-based NFT solution.",
    "descriptor": "\nComments: 18 pages, 15 figures, 5 tables, journal\n",
    "authors": [
      "Usman Khalil",
      "Owais Ahmed Malik",
      "Ong Wee Hong",
      "Mueen Uddin"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.04803"
  },
  {
    "id": "arXiv:2211.04811",
    "title": "BGRA: A Reference Architecture for Blockchain Governance",
    "abstract": "Blockchain technology has been integrated into diverse software applications\nby enabling a decentralised architecture design. However, the defects of\non-chain algorithmic mechanisms, and tedious disputes and debates in off-chain\ncommunities may affect the operation of blockchain systems. Accordingly,\nblockchain governance has received great interest for supporting the design,\nuse, and maintenance of blockchain systems, hence improving the overall\ntrustworthiness. Although much effort has been put into this research topic,\nthere is a distinct lack of consideration for blockchain governance from the\nperspective of software architecture design. In this study, we propose a\npattern-oriented reference architecture for governance-driven blockchain\nsystems, which can provide guidance for future blockchain architecture design.\nWe design the reference architecture based on an extensive review of\narchitecture patterns for blockchain governance in academic literature and\nindustry implementation. The reference architecture consists of four layers. We\ndemonstrate the components in each layer, annotating with the identified\npatterns. A qualitative analysis of mapping two concrete blockchain\narchitectures, Polkadot and Quorum, on the reference architecture is conducted,\nto evaluate the correctness and utility of proposed reference architecture.",
    "descriptor": "",
    "authors": [
      "Yue Liu",
      "Qinghua Lu",
      "Guangsheng Yu",
      "Hye-Young Paik",
      "Liming Zhu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.04811"
  },
  {
    "id": "arXiv:2211.04812",
    "title": "Discrimination and Class Imbalance Aware Online Naive Bayes",
    "abstract": "Fairness-aware mining of massive data streams is a growing and challenging\nconcern in the contemporary domain of machine learning. Many stream learning\nalgorithms are used to replace humans at critical decision-making points e.g.,\nhiring staff, assessing credit risk, etc. This calls for handling massive\nincoming information with minimum response delay while ensuring fair and high\nquality decisions. Recent discrimination-aware learning methods are optimized\nbased on overall accuracy. However, the overall accuracy is biased in favor of\nthe majority class; therefore, state-of-the-art methods mainly diminish\ndiscrimination by partially or completely ignoring the minority class. In this\ncontext, we propose a novel adaptation of Na\\\"ive Bayes to mitigate\ndiscrimination embedded in the streams while maintaining high predictive\nperformance for both the majority and minority classes. Our proposed algorithm\nis simple, fast, and attains multi-objective optimization goals. To handle\nclass imbalance and concept drifts, a dynamic instance weighting module is\nproposed, which gives more importance to recent instances and less importance\nto obsolete instances based on their membership in minority or majority class.\nWe conducted experiments on a range of streaming and static datasets and\ndeduced that our proposed methodology outperforms existing state-of-the-art\nfairness-aware methods in terms of both discrimination score and balanced\naccuracy.",
    "descriptor": "",
    "authors": [
      "Maryam Badar",
      "Marco Fisichella",
      "Vasileios Iosifidis",
      "Wolfgang Nejdl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.04812"
  },
  {
    "id": "arXiv:2211.04813",
    "title": "Deep W-Networks: Solving Multi-Objective Optimisation Problems With Deep  Reinforcement Learning",
    "abstract": "In this paper, we build on advances introduced by the Deep Q-Networks (DQN)\napproach to extend the multi-objective tabular Reinforcement Learning (RL)\nalgorithm W-learning to large state spaces. W-learning algorithm can naturally\nsolve the competition between multiple single policies in multi-objective\nenvironments. However, the tabular version does not scale well to environments\nwith large state spaces. To address this issue, we replace underlying Q-tables\nwith DQN, and propose an addition of W-Networks, as a replacement for tabular\nweights (W) representations. We evaluate the resulting Deep W-Networks (DWN)\napproach in two widely-accepted multi-objective RL benchmarks: deep sea\ntreasure and multi-objective mountain car. We show that DWN solves the\ncompetition between multiple policies while outperforming the baseline in the\nform of a DQN solution. Additionally, we demonstrate that the proposed\nalgorithm can find the Pareto front in both tested environments.",
    "descriptor": "",
    "authors": [
      "Jernej Hribar",
      "Luke Hackett",
      "Ivana Dusparic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.04813"
  },
  {
    "id": "arXiv:2211.04815",
    "title": "The hull of two classical propagation rules and their applications",
    "abstract": "Propagation rules are of great help in constructing good linear codes. Both\nEuclidean and Hermitian hulls of linear codes perform an important part in\ncoding theory. In this paper, we consider these two aspects together and\ndetermine the dimensions of Euclidean and Hermitian hulls of two classical\npropagation rules, namely, the direct sum construction and the\n$(\\mathbf{u},\\mathbf{u+v})$-construction. Some new criteria for resulting codes\nderived from these two propagation rules being self-dual, self-orthogonal or\nlinear complement dual (LCD) codes are given. As applications, we construct\nsome linear codes with prescribed hull dimensions and many new binary, ternary\nEuclidean formally self-dual (FSD) LCD codes, quaternary Hermitian FSD LCD\ncodes and good quaternary Hermitian LCD codes which are optimal or have best or\nalmost best known parameters according to Datebase at\n$this http URL Moreover, our methods contributes positively to\nimprove the lower bounds on the minimum distance of known LCD codes.",
    "descriptor": "\nComments: 16 pages, 5 tables\n",
    "authors": [
      "Yang Li",
      "Shixin Zhu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.04815"
  },
  {
    "id": "arXiv:2211.04829",
    "title": "Frozen Gaussian Sampling for Scalar Wave Equations",
    "abstract": "In this article, we introduce the frozen Gaussian sampling (FGS) algorithm to\nsolve the scalar wave equation in the high-frequency regime. The FGS algorithm\nis a Monte Carlo sampling strategy based on the frozen Gaussian approximation,\nwhich greatly reduces the computation workload in the wave propagation and\nreconstruction. In this work, we propose feasible and detailed procedures to\nimplement the FGS algorithm to approximate scalar wave equations with Gaussian\ninitial conditions and WKB initial conditions respectively. For both initial\ndata cases, we rigorously analyze the error of applying this algorithm to wave\nequations of dimensionality $d \\geq 3$. In Gaussian initial data cases, we\nprove that the sampling error due to the Monte Carlo method is independent of\nthe typical wave number. We also derive a quantitative bound of the sampling\nerror in WKB initial data cases. Finally, we validate the performance of the\nFGS and the theoretical estimates about the sampling error through various\nnumerical examples, which include using the FGS to solve wave equations with\nboth Gaussian and WKB initial data of dimensionality $d = 1, 2$, and $3$.",
    "descriptor": "",
    "authors": [
      "Lihui Chai",
      "Ye Feng",
      "Zhennan Zhou"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.04829"
  },
  {
    "id": "arXiv:2211.04831",
    "title": "3DFill:Reference-guided Image Inpainting by Self-supervised 3D Image  Alignment",
    "abstract": "Most existing image inpainting algorithms are based on a single view,\nstruggling with large holes or the holes containing complicated scenes. Some\nreference-guided algorithms fill the hole by referring to another viewpoint\nimage and use 2D image alignment. Due to the camera imaging process, simple 2D\ntransformation is difficult to achieve a satisfactory result. In this paper, we\npropose 3DFill, a simple and efficient method for reference-guided image\ninpainting. Given a target image with arbitrary hole regions and a reference\nimage from another viewpoint, the 3DFill first aligns the two images by a\ntwo-stage method: 3D projection + 2D transformation, which has better results\nthan 2D image alignment. The 3D projection is an overall alignment between\nimages and the 2D transformation is a local alignment focused on the hole\nregion. The entire process of image alignment is self-supervised. We then fill\nthe hole in the target image with the contents of the aligned image. Finally,\nwe use a conditional generation network to refine the filled image to obtain\nthe inpainting result. 3DFill achieves state-of-the-art performance on image\ninpainting across a variety of wide view shifts and has a faster inference\nspeed than other inpainting models.",
    "descriptor": "",
    "authors": [
      "Liang Zhao",
      "Xinyuan Zhao",
      "Hailong Ma",
      "Xinyu Zhang",
      "Long Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04831"
  },
  {
    "id": "arXiv:2211.04834",
    "title": "Distribution-based Emotion Recognition in Conversation",
    "abstract": "Automatic emotion recognition in conversation (ERC) is crucial for\nemotion-aware conversational artificial intelligence. This paper proposes a\ndistribution-based framework that formulates ERC as a sequence-to-sequence\nproblem for emotion distribution estimation. The inherent ambiguity of emotions\nand the subjectivity of human perception lead to disagreements in emotion\nlabels, which is handled naturally in our framework from the perspective of\nuncertainty estimation in emotion distributions. A Bayesian training loss is\nintroduced to improve the uncertainty estimation by conditioning each emotional\nstate on an utterance-specific Dirichlet prior distribution. Experimental\nresults on the IEMOCAP dataset show that ERC outperformed the\nsingle-utterance-based system, and the proposed distribution-based ERC methods\nhave not only better classification accuracy, but also show improved\nuncertainty estimation.",
    "descriptor": "\nComments: To appear in SLT 2022\n",
    "authors": [
      "Wen Wu",
      "Chao Zhang",
      "Philip C. Woodland"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.04834"
  },
  {
    "id": "arXiv:2211.04854",
    "title": "6G Mobile-Edge Empowered Metaverse: Requirements, Technologies,  Challenges and Research Directions",
    "abstract": "The Metaverse has emerged as the successor of the conventional mobile\ninternet to change people's lifestyles. It has strict visual and physical\nrequirements to ensure an immersive experience (i.e., high visual quality, low\nmotion-to-photon latency, and real-time tactile and control experience).\nHowever, the current communication systems fall short to satisfy these\nrequirements. Mobile edge computing (MEC) has been indispensable to enable low\nlatency and powerful computing. Moreover, the sixth generation (6G) networks\npromise to provide end users with high-capacity communications to MEC servers.\nIn this paper, we bring together the primary components into a 6G mobile-edge\nframework to empower the Metaverse. This includes the usage of heterogeneous\nradios, intelligent reflecting surfaces (IRS), non-orthogonal multiple access\n(NOMA), and digital twins (DTs). We also discuss novel communication paradigms\n(i.e., semantic communication, holographic-type communication, and haptic\ncommunication) to further satisfy the demand for human-type communications and\nfulfil user preferences and immersive experiences in the Metaverse.",
    "descriptor": "",
    "authors": [
      "Jiadong Yu",
      "Ahmad Alhilal",
      "Pan Hui",
      "Danny H.K. Tsang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.04854"
  },
  {
    "id": "arXiv:2211.04861",
    "title": "ERNIE-UniX2: A Unified Cross-lingual Cross-modal Framework for  Understanding and Generation",
    "abstract": "Recent cross-lingual cross-modal works attempt to extend Vision-Language\nPre-training (VLP) models to non-English inputs and achieve impressive\nperformance. However, these models focus only on understanding tasks utilizing\nencoder-only architecture. In this paper, we propose ERNIE-UniX2, a unified\ncross-lingual cross-modal pre-training framework for both generation and\nunderstanding tasks. ERNIE-UniX2 integrates multiple pre-training paradigms\n(e.g., contrastive learning and language modeling) based on encoder-decoder\narchitecture and attempts to learn a better joint representation across\nlanguages and modalities. Furthermore, ERNIE-UniX2 can be seamlessly fine-tuned\nfor varieties of generation and understanding downstream tasks. Pre-trained on\nboth multilingual text-only and image-text datasets, ERNIE-UniX2 achieves SOTA\nresults on various cross-lingual cross-modal generation and understanding tasks\nsuch as multimodal machine translation and multilingual visual question\nanswering.",
    "descriptor": "\nComments: 13 pages, 2 figures\n",
    "authors": [
      "Bin Shan",
      "Yaqian Han",
      "Weichong Yin",
      "Shuohuan Wang",
      "Yu Sun",
      "Hao Tian",
      "Hua Wu",
      "Haifeng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04861"
  },
  {
    "id": "arXiv:2211.04862",
    "title": "Domain-incremental Cardiac Image Segmentation with Style-oriented Replay  and Domain-sensitive Feature Whitening",
    "abstract": "Contemporary methods have shown promising results on cardiac image\nsegmentation, but merely in static learning, i.e., optimizing the network once\nfor all, ignoring potential needs for model updating. In real-world scenarios,\nnew data continues to be gathered from multiple institutions over time and new\ndemands keep growing to pursue more satisfying performance. The desired model\nshould incrementally learn from each incoming dataset and progressively update\nwith improved functionality as time goes by. As the datasets sequentially\ndelivered from multiple sites are normally heterogenous with domain\ndiscrepancy, each updated model should not catastrophically forget previously\nlearned domains while well generalizing to currently arrived domains or even\nunseen domains. In medical scenarios, this is particularly challenging as\naccessing or storing past data is commonly not allowed due to data privacy. To\nthis end, we propose a novel domain-incremental learning framework to recover\npast domain inputs first and then regularly replay them during model\noptimization. Particularly, we first present a style-oriented replay module to\nenable structure-realistic and memory-efficient reproduction of past data, and\nthen incorporate the replayed past data to jointly optimize the model with\ncurrent data to alleviate catastrophic forgetting. During optimization, we\nadditionally perform domain-sensitive feature whitening to suppress model's\ndependency on features that are sensitive to domain changes (e.g.,\ndomain-distinctive style features) to assist domain-invariant feature\nexploration and gradually improve the generalization performance of the\nnetwork. We have extensively evaluated our approach with the M&Ms Dataset in\nsingle-domain and compound-domain incremental learning settings with improved\nperformance over other comparison approaches.",
    "descriptor": "\nComments: Accepted to IEEE Transactions on Medical Imaging\n",
    "authors": [
      "Kang Li",
      "Lequan Yu",
      "Pheng-Ann Heng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04862"
  },
  {
    "id": "arXiv:2211.04871",
    "title": "Graph classes equivalent to 12-representable graphs",
    "abstract": "Jones et al. (2015) introduced the notion of $u$-representable graphs, where\n$u$ is a word over $\\{1, 2\\}$ different from $22\\cdots2$, as a generalization\nof word-representable graphs. Kitaev (2016) showed that if $u$ is of length at\nleast 3, then every graph is $u$-representable. This indicates that there are\nonly two nontrivial classes in the theory of $u$-representable graphs:\n11-representable graphs, which correspond to word-representable graphs, and\n12-representable graphs. This study deals with 12-representable graphs.\nJones et al. (2015) provided a characterization of 12-representable trees in\nterms of forbidden induced subgraphs. Chen and Kitaev (2022) presented a\nforbidden induced subgraph characterization of a subclass of 12-representable\ngrid graphs.\nThis paper shows that a bipartite graph is 12-representable if and only if it\nis an interval containment bigraph. The equivalence gives us a forbidden\ninduced subgraph characterization of 12-representable bipartite graphs since\nthe list of minimal forbidden induced subgraphs is known for interval\ncontainment bigraphs. We then have a forbidden induced subgraph\ncharacterization for grid graphs, which solves an open problem of Chen and\nKitaev (2022). The study also shows that a graph is 12-representable if and\nonly if it is the complement of a simple-triangle graph. This equivalence\nindicates that a necessary condition for 12-representability presented by Jones\net al. (2015) is also sufficient. Finally, we show from these equivalences that\n12-representability can be determined in $O(n^2)$ time for bipartite graphs and\nin $O(n(\\bar{m}+n))$ time for arbitrary graphs, where $n$ and $\\bar{m}$ are the\nnumber of vertices and edges of the complement of the given graph.",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Asahi Takaoka"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.04871"
  },
  {
    "id": "arXiv:2211.04872",
    "title": "Visual Named Entity Linking: A New Dataset and A Baseline",
    "abstract": "Visual Entity Linking (VEL) is a task to link regions of images with their\ncorresponding entities in Knowledge Bases (KBs), which is beneficial for many\ncomputer vision tasks such as image retrieval, image caption, and visual\nquestion answering. While existing tasks in VEL either rely on textual data to\ncomplement a multi-modal linking or only link objects with general entities,\nwhich fails to perform named entity linking on large amounts of image data. In\nthis paper, we consider a purely Visual-based Named Entity Linking (VNEL) task,\nwhere the input only consists of an image. The task is to identify objects of\ninterest (i.e., visual entity mentions) in images and link them to\ncorresponding named entities in KBs. Since each entity often contains rich\nvisual and textual information in KBs, we thus propose three different\nsub-tasks, i.e., visual to visual entity linking (V2VEL), visual to textual\nentity linking (V2TEL), and visual to visual-textual entity linking (V2VTEL).\nIn addition, we present a high-quality human-annotated visual person linking\ndataset, named WIKIPerson. Based on WIKIPerson, we establish a series of\nbaseline algorithms for the solution of each sub-task, and conduct experiments\nto verify the quality of proposed datasets and the effectiveness of baseline\nmethods. We envision this work to be helpful for soliciting more works\nregarding VNEL in the future. The codes and datasets are publicly available at\nhttps://github.com/ict-bigdatalab/VNEL.",
    "descriptor": "\nComments: 13 pages, 11 figures, published to EMNLP 2022(findings)\n",
    "authors": [
      "Wenxiang Sun",
      "Yixing Fan",
      "Jiafeng Guo",
      "Ruqing Zhang",
      "Xueqi Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04872"
  },
  {
    "id": "arXiv:2211.04877",
    "title": "Interactive Feature Embedding for Infrared and Visible Image Fusion",
    "abstract": "General deep learning-based methods for infrared and visible image fusion\nrely on the unsupervised mechanism for vital information retention by utilizing\nelaborately designed loss functions. However, the unsupervised mechanism\ndepends on a well designed loss function, which cannot guarantee that all vital\ninformation of source images is sufficiently extracted. In this work, we\npropose a novel interactive feature embedding in self-supervised learning\nframework for infrared and visible image fusion, attempting to overcome the\nissue of vital information degradation. With the help of self-supervised\nlearning framework, hierarchical representations of source images can be\nefficiently extracted. In particular, interactive feature embedding models are\ntactfully designed to build a bridge between the self-supervised learning and\ninfrared and visible image fusion learning, achieving vital information\nretention. Qualitative and quantitative evaluations exhibit that the proposed\nmethod performs favorably against state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Fan Zhao",
      "Wenda Zhao",
      "Huchuan Lu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04877"
  },
  {
    "id": "arXiv:2211.04878",
    "title": "Foundation Models for Semantic Novelty in Reinforcement Learning",
    "abstract": "Effectively exploring the environment is a key challenge in reinforcement\nlearning (RL). We address this challenge by defining a novel intrinsic reward\nbased on a foundation model, such as contrastive language image pretraining\n(CLIP), which can encode a wealth of domain-independent semantic\nvisual-language knowledge about the world. Specifically, our intrinsic reward\nis defined based on pre-trained CLIP embeddings without any fine-tuning or\nlearning on the target RL task. We demonstrate that CLIP-based intrinsic\nrewards can drive exploration towards semantically meaningful states and\noutperform state-of-the-art methods in challenging sparse-reward\nprocedurally-generated environments.",
    "descriptor": "\nComments: Foundation Models for Decision Making Workshop at Neural Information Processing Systems, 2022\n",
    "authors": [
      "Tarun Gupta",
      "Peter Karkus",
      "Tong Che",
      "Danfei Xu",
      "Marco Pavone"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04878"
  },
  {
    "id": "arXiv:2211.04880",
    "title": "Outcome-Oriented Prescriptive Process Monitoring Based on Temporal Logic  Patterns",
    "abstract": "Prescriptive Process Monitoring systems recommend, during the execution of a\nbusiness process, interventions that, if followed, prevent a negative outcome\nof the process. Such interventions have to be reliable, that is, they have to\nguarantee the achievement of the desired outcome or performance, and they have\nto be flexible, that is, they have to avoid overturning the normal process\nexecution or forcing the execution of a given activity. Most of the existing\nPrescriptive Process Monitoring solutions, however, while performing well in\nterms of recommendation reliability, provide the users with very specific\n(sequences of) activities that have to be executed without caring about the\nfeasibility of these recommendations. In order to face this issue, we propose a\nnew Outcome-Oriented Prescriptive Process Monitoring system recommending\ntemporal relations between activities that have to be guaranteed during the\nprocess execution in order to achieve a desired outcome. This softens the\nmandatory execution of an activity at a given point in time, thus leaving more\nfreedom to the user in deciding the interventions to put in place. Our approach\ndefines these temporal relations with Linear Temporal Logic over finite traces\npatterns that are used as features to describe the historical process data\nrecorded in an event log by the information systems supporting the execution of\nthe process. Such encoded log is used to train a Machine Learning classifier to\nlearn a mapping between the temporal patterns and the outcome of a process\nexecution. The classifier is then queried at runtime to return as\nrecommendations the most salient temporal patterns to be satisfied to maximize\nthe likelihood of a certain outcome for an input ongoing process execution. The\nproposed system is assessed using a pool of 22 real-life event logs that have\nalready been used as a benchmark in the Process Mining community.",
    "descriptor": "\nComments: 38 pages, 6 figures, 8 tables\n",
    "authors": [
      "Ivan Donadello",
      "Chiara Di Francescomarino",
      "Fabrizio Maria Maggi",
      "Francesco Ricci",
      "Aladdin Shikhizada"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.04880"
  },
  {
    "id": "arXiv:2211.04884",
    "title": "Composite Fixed-Length Ordered Features for Palmprint Template  Protection with Diminished Performance Loss",
    "abstract": "Palmprint recognition has become more and more popular due to its advantages\nover other biometric modalities such as fingerprint, in that it is larger in\narea, richer in information and able to work at a distance. However, the issue\nof palmprint privacy and security (especially palmprint template protection)\nremains under-studied. Among the very few research works, most of them only use\nthe directional and orientation features of the palmprint with transformation\nprocessing, yielding unsatisfactory protection and identification performance.\nThus, this paper proposes a palmprint template protection-oriented operator\nthat has a fixed length and is ordered in nature, by fusing point features and\norientation features. Firstly, double orientations are extracted with more\naccuracy based on MFRAT. Then key points of SURF are extracted and converted to\nbe fixed-length and ordered features. Finally, composite features that fuse up\nthe double orientations and SURF points are transformed using the irreversible\ntransformation of IOM to generate the revocable palmprint template. Experiments\nshow that the EER after irreversible transformation on the PolyU and CASIA\ndatabases are 0.17% and 0.19% respectively, and the absolute precision loss is\n0.08% and 0.07%, respectively, which proves the advantage of our method.",
    "descriptor": "",
    "authors": [
      "Weiqiang Zhao",
      "Heng Zhao",
      "Zhicheng Cao",
      "Liaojun Pang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04884"
  },
  {
    "id": "arXiv:2211.04886",
    "title": "ART/ATK: A research platform for assessing and mitigating the  sim-to-real gap in robotics and autonomous vehicle engineering",
    "abstract": "We discuss a platform that has both software and hardware components, and\nwhose purpose is to support research into characterizing and mitigating the\nsim-to-real gap in robotics and vehicle autonomy engineering. The software is\noperating-system independent and has three main components: a simulation engine\ncalled Chrono, which supports high-fidelity vehicle and sensor simulation; an\nautonomy stack for algorithm design and testing; and a development environment\nthat supports visualization and hardware-in-the-loop experimentation. The\naccompanying hardware platform is a 1/6th scale vehicle augmented with\nreconfigurable mountings for computing, sensing, and tracking. Since this\nvehicle platform has a digital twin within the simulation environment, one can\ntest the same autonomy perception, state estimation, or controls algorithms, as\nwell as the processors they run on, in both simulation and reality. A\ndemonstration is provided to show the utilization of this platform for autonomy\nresearch. Future work will concentrate on augmenting ART/ATK with support for a\nfull-sized Chevy Bolt EUV, which will be made available to this group in the\nimmediate future.",
    "descriptor": "\nComments: 4 pages, Presented at IROS 2022 Workshop on Miniature Robot Platforms for Full Scale Autonomous Vehicle Research. arXiv admin note: substantial text overlap with arXiv:2206.06537\n",
    "authors": [
      "Asher Elmquist",
      "Aaron Young",
      "Thomas Hansen",
      "Sriram Ashokkumar",
      "Stefan Caldararu",
      "Abhiraj Dashora",
      "Ishaan Mahajan",
      "Harry Zhang",
      "Luning Fang",
      "He Shen",
      "Xiangru Xu",
      "Radu Serban",
      "Dan Negrut"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.04886"
  },
  {
    "id": "arXiv:2211.04888",
    "title": "Extending Temporal Data Augmentation for Video Action Recognition",
    "abstract": "Pixel space augmentation has grown in popularity in many Deep Learning areas,\ndue to its effectiveness, simplicity, and low computational cost. Data\naugmentation for videos, however, still remains an under-explored research\ntopic, as most works have been treating inputs as stacks of static images\nrather than temporally linked series of data. Recently, it has been shown that\ninvolving the time dimension when designing augmentations can be superior to\nits spatial-only variants for video action recognition. In this paper, we\npropose several novel enhancements to these techniques to strengthen the\nrelationship between the spatial and temporal domains and achieve a deeper\nlevel of perturbations. The video action recognition results of our techniques\noutperform their respective variants in Top-1 and Top-5 settings on the UCF-101\nand the HMDB-51 datasets.",
    "descriptor": "",
    "authors": [
      "Artjoms Gorpincenko",
      "Michal Mackiewicz"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04888"
  },
  {
    "id": "arXiv:2211.04894",
    "title": "Disentangling Aesthetic and Technical Effects for Video Quality  Assessment of User Generated Content",
    "abstract": "User-generated-content (UGC) videos have dominated the Internet during recent\nyears. While many methods attempt to objectively assess the quality of these\nUGC videos, the mechanisms of human quality perception in the UGC-VQA problem\nis still yet to be explored. To better explain the quality perception\nmechanisms and learn more robust representations, we aim to disentangle the\neffects of aesthetic quality issues and technical quality issues risen by the\ncomplicated video generation processes in the UGC-VQA problem. To overcome the\nabsence of respective supervisions during disentanglement, we propose the\nLimited View Biased Supervisions (LVBS) scheme where two separate evaluators\nare trained with decomposed views specifically designed for each issue.\nComposed of an Aesthetic Quality Evaluator (AQE) and a Technical Quality\nEvaluator (TQE) under the LVBS scheme, the proposed Disentangled Objective\nVideo Quality Evaluator (DOVER) reach excellent performance (0.91 SRCC for\nKoNViD-1k, 0.89 SRCC for LSVQ, 0.88 SRCC for YouTube-UGC) in the UGC-VQA\nproblem. More importantly, our blind subjective studies prove that the separate\nevaluators in DOVER can effectively match human perception on respective\ndisentangled quality issues. Codes and demos are released in\nhttps://github.com/teowu/dover.",
    "descriptor": "\nComments: 12 pages, 7 figures\n",
    "authors": [
      "Haoning Wu",
      "Liang Liao",
      "Chaofeng Chen",
      "Jingwen Hou",
      "Annan Wang",
      "Wenxiu Sun",
      "Qiong Yan",
      "Weisi Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.04894"
  },
  {
    "id": "arXiv:2211.04895",
    "title": "Grasp Learning: Models, Methods, and Performance",
    "abstract": "Grasp learning has become an exciting and important topic in robotics. Just a\nfew years ago, the problem of grasping novel objects from unstructured piles of\nclutter was considered a serious research challenge. Now, it is a capability\nthat is quickly becoming incorporated into industrial supply chain automation.\nHow did that happen? What is the current state of the art in robotic grasp\nlearning, what are the different methodological approaches, and what machine\nlearning models are used? This review attempts to give an overview of the\ncurrent state of the art of grasp learning research.",
    "descriptor": "",
    "authors": [
      "Robert Platt"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.04895"
  },
  {
    "id": "arXiv:2211.04898",
    "title": "Mask More and Mask Later: Efficient Pre-training of Masked Language  Models by Disentangling the [MASK] Token",
    "abstract": "The pre-training of masked language models (MLMs) consumes massive\ncomputation to achieve good results on downstream NLP tasks, resulting in a\nlarge carbon footprint. In the vanilla MLM, the virtual tokens, [MASK]s, act as\nplaceholders and gather the contextualized information from unmasked tokens to\nrestore the corrupted information. It raises the question of whether we can\nappend [MASK]s at a later layer, to reduce the sequence length for earlier\nlayers and make the pre-training more efficient. We show: (1) [MASK]s can\nindeed be appended at a later layer, being disentangled from the word\nembedding; (2) The gathering of contextualized information from unmasked tokens\ncan be conducted with a few layers. By further increasing the masking rate from\n15% to 50%, we can pre-train RoBERTa-base and RoBERTa-large from scratch with\nonly 78% and 68% of the original computational budget without any degradation\non the GLUE benchmark. When pre-training with the original budget, our method\noutperforms RoBERTa for 6 out of 8 GLUE tasks, on average by 0.4%.",
    "descriptor": "\nComments: Code available at: this https URL\n",
    "authors": [
      "Baohao Liao",
      "David Thulke",
      "Sanjika Hewavitharana",
      "Hermann Ney",
      "Christof Monz"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04898"
  },
  {
    "id": "arXiv:2211.04900",
    "title": "Numerical investigations on the resonance errors of multiscale  discontinuous Galerkin methods for one-dimensional stationary Schr\u00f6dinger  equation",
    "abstract": "In this paper, numerical experiments are carried out to investigate the\nimpact of penalty parameters in the numerical traces on the resonance errors of\nhigh order multiscale discontinuous Galerkin (DG) methods [6, 7] for\none-dimensional stationary Schr\\\"{o}dinger equation. Previous work showed that\npenalty parameters were required to be positive in error analysis, but the\nmethods with zero penalty parameters worked fine in numerical simulations on\ncoarse meshes. In this work, by performing extensive numerical experiments, we\ndiscover that zero penalty parameters lead to resonance errors in the\nmultiscale DG methods, and taking positive penalty parameters can effectively\nreduce resonance errors and make the matrix in the global linear system have\nbetter condition numbers.",
    "descriptor": "",
    "authors": [
      "Bo Dong",
      "Wei Wang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.04900"
  },
  {
    "id": "arXiv:2211.04903",
    "title": "Novel Chapter Abstractive Summarization using Spinal Tree Aware  Sub-Sentential Content Selection",
    "abstract": "Summarizing novel chapters is a difficult task due to the input length and\nthe fact that sentences that appear in the desired summaries draw content from\nmultiple places throughout the chapter. We present a pipelined\nextractive-abstractive approach where the extractive step filters the content\nthat is passed to the abstractive component. Extremely lengthy input also\nresults in a highly skewed dataset towards negative instances for extractive\nsummarization; we thus adopt a margin ranking loss for extraction to encourage\nseparation between positive and negative examples. Our extraction component\noperates at the constituent level; our approach to this problem enriches the\ntext with spinal tree information which provides syntactic context (in the form\nof constituents) to the extraction model. We show an improvement of 3.71\nRouge-1 points over best results reported in prior work on an existing novel\nchapter dataset.",
    "descriptor": "",
    "authors": [
      "Hardy Hardy",
      "Miguel Ballesteros",
      "Faisal Ladhak",
      "Muhammad Khalifa",
      "Vittorio Castelli",
      "Kathleen McKeown"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.04903"
  },
  {
    "id": "arXiv:2211.04905",
    "title": "SimOn: A Simple Framework for Online Temporal Action Localization",
    "abstract": "Online Temporal Action Localization (On-TAL) aims to immediately provide\naction instances from untrimmed streaming videos. The model is not allowed to\nutilize future frames and any processing techniques to modify past predictions,\nmaking On-TAL much more challenging. In this paper, we propose a simple yet\neffective framework, termed SimOn, that learns to predict action instances\nusing the popular Transformer architecture in an end-to-end manner.\nSpecifically, the model takes the current frame feature as a query and a set of\npast context information as keys and values of the Transformer. Different from\nthe prior work that uses a set of outputs of the model as past contexts, we\nleverage the past visual context and the learnable context embedding for the\ncurrent query. Experimental results on the THUMOS14 and ActivityNet1.3 datasets\nshow that our model remarkably outperforms the previous methods, achieving a\nnew state-of-the-art On-TAL performance. In addition, the evaluation for Online\nDetection of Action Start (ODAS) demonstrates the effectiveness and robustness\nof our method in the online setting. The code is available at\nhttps://github.com/TuanTNG/SimOn",
    "descriptor": "",
    "authors": [
      "Tuan N. Tang",
      "Jungin Park",
      "Kwonyoung Kim",
      "Kwanghoon Sohn"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04905"
  },
  {
    "id": "arXiv:2211.04906",
    "title": "Cross-view Graph Contrastive Representation Learning on Partially  Aligned Multi-view Data",
    "abstract": "Multi-view representation learning has developed rapidly over the past\ndecades and has been applied in many fields. However, most previous works\nassumed that each view is complete and aligned. This leads to an inevitable\ndeterioration in their performance when encountering practical problems such as\nmissing or unaligned views. To address the challenge of representation learning\non partially aligned multi-view data, we propose a new cross-view graph\ncontrastive learning framework, which integrates multi-view information to\nalign data and learn latent representations. Compared with current approaches,\nthe proposed method has the following merits: (1) our model is an end-to-end\nframework that simultaneously performs view-specific representation learning\nvia view-specific autoencoders and cluster-level data aligning by combining\nmulti-view information with the cross-view graph contrastive learning; (2) it\nis easy to apply our model to explore information from three or more\nmodalities/sources as the cross-view graph contrastive learning is devised.\nExtensive experiments conducted on several real datasets demonstrate the\neffectiveness of the proposed method on the clustering and classification\ntasks.",
    "descriptor": "",
    "authors": [
      "Yiming Wang",
      "Dongxia Chang",
      "Zhiqiang Fu",
      "Jie Wen",
      "Yao Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04906"
  },
  {
    "id": "arXiv:2211.04908",
    "title": "Profiling and Improving the PyTorch Dataloader for high-latency Storage:  A Technical Report",
    "abstract": "A growing number of Machine Learning Frameworks recently made Deep Learning\naccessible to a wider audience of engineers, scientists, and practitioners, by\nallowing straightforward use of complex neural network architectures and\nalgorithms. However, since deep learning is rapidly evolving, not only through\ntheoretical advancements but also with respect to hardware and software\nengineering, ML frameworks often lose backward compatibility and introduce\ntechnical debt that can lead to bottlenecks and sub-optimal resource\nutilization. Moreover, the focus is in most cases not on deep learning\nengineering, but rather on new models and theoretical advancements. In this\nwork, however, we focus on engineering, more specifically on the data loading\npipeline in the PyTorch Framework. We designed a series of benchmarks that\noutline performance issues of certain steps in the data loading process. Our\nfindings show that for classification tasks that involve loading many files,\nlike images, the training wall-time can be significantly improved. With our\nnew, modified ConcurrentDataloader we can reach improvements in GPU utilization\nand significantly reduce batch loading time, up to 12X. This allows for the use\nof the cloud-based, S3-like object storage for datasets, and have comparable\ntraining time as if datasets are stored on local drives.",
    "descriptor": "",
    "authors": [
      "Ivan Svogor",
      "Christian Eichenberger",
      "Markus Spanring",
      "Moritz Neun",
      "Michael Kopp"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2211.04908"
  },
  {
    "id": "arXiv:2211.04912",
    "title": "Solution of time-harmonic Maxwell's equations by a domain decomposition  method based on PML transmission conditions",
    "abstract": "Numerical discretization of the large-scale Maxwell's equations leads to an\nill-conditioned linear system that is challenging to solve. The key requirement\nfor successive solutions of this linear system is to choose an efficient\nsolver. In this work we use Perfectly Matched Layers (PML) to increase this\nefficiency. PML have been widely used to truncate numerical simulations of wave\nequations due to improving the accuracy of the solution instead of using\nabsorbing boundary conditions (ABCs). Here, we will develop an efficient solver\nby providing an alternative use of PML as transmission conditions at the\ninterfaces between subdomains in our domain decomposition method. We solve\nMaxwell's equations and assess the convergence rate of our solutions compared\nto the situation where absorbing boundary conditions are chosen as transmission\nconditions.",
    "descriptor": "",
    "authors": [
      "Sahar Borzooei",
      "Victorita Dolean",
      "Pierre-Henri Tournier",
      "Claire Migliaccio"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.04912"
  },
  {
    "id": "arXiv:2211.04918",
    "title": "Detection of Sparse Anomalies in High-Dimensional Network Telescope  Signals",
    "abstract": "Network operators and system administrators are increasingly overwhelmed with\nincessant cyber-security threats ranging from malicious network reconnaissance\nto attacks such as distributed denial of service and data breaches. A large\nnumber of these attacks could be prevented if the network operators were better\nequipped with threat intelligence information that would allow them to block or\nthrottle nefarious scanning activities. Network telescopes or \"darknets\" offer\na unique window into observing Internet-wide scanners and other malicious\nentities, and they could offer early warning signals to operators that would be\ncritical for infrastructure protection and/or attack mitigation. A network\ntelescope consists of unused or \"dark\" IP spaces that serve no users, and\nsolely passively observes any Internet traffic destined to the \"telescope\nsensor\" in an attempt to record ubiquitous network scanners, malware that\nforage for vulnerable devices, and other dubious activities. Hence, monitoring\nnetwork telescopes for timely detection of coordinated and heavy scanning\nactivities is an important, albeit challenging, task. The challenges mainly\narise due to the non-stationarity and the dynamic nature of Internet traffic\nand, more importantly, the fact that one needs to monitor high-dimensional\nsignals (e.g., all TCP/UDP ports) to search for \"sparse\" anomalies. We propose\nstatistical methods to address both challenges in an efficient and \"online\"\nmanner; our work is validated both with synthetic data as well as real-world\ndata from a large network telescope.",
    "descriptor": "",
    "authors": [
      "Rafail Kartsioukas",
      "Rajat Tandon",
      "Zheng Gao",
      "Jelena Mirkovic",
      "Michalis Kallitsis",
      "Stilian Stoev"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.04918"
  },
  {
    "id": "arXiv:2211.04921",
    "title": "Global, and Local Optimization Beamforming for Acoustic Broadband  Sources",
    "abstract": "This paper presents an extension to global optimization beamforming for\nacoustic broadband sources. Given, that properties such as the source location,\nspatial shape, multipole rotation, or flow properties can be parameterized over\nthe frequency, a CSM-fitting can be performed for all frequencies at the same\ntime. A numerical analysis shows that the non-linear error function for the\nstandard global optimization problem is similar to a Point Spread Function and\ncontains local minima, but can be improved with the proposed broadband\noptimization. Not only increases the broadband optimization process the ratio\nof equations to unknown variables, but it also smooths out the cost function.\nIt also simplifies the process of identifying sources and reconstructing their\nspectra from the results. The paper shows that the method is superior on\nsynthetic monopoles compared to standard global optimization and CLEAN-SC. For\nreal-world data the results of broadband global optimization, standard global\noptimization, and CLEAN-SC are similar. However, the proposed method does not\nrequire the identification and integration of Regions Of Interest. It is shown,\nthat by using reasonable initial values the global optimization problem reduces\nto a local optimization problem with similar results. Further, it is shown that\nthe proposed method is able to identify multipoles with different pole\namplitudes and unknown pole rotations.",
    "descriptor": "\nComments: Submitted to Journal of Sound and Vibration\n",
    "authors": [
      "Armin Goudarzi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.04921"
  },
  {
    "id": "arXiv:2211.04922",
    "title": "Decomposition of Probability Marginals for Security Games in Abstract  Networks",
    "abstract": "Given a set system $(E, \\mathcal{P})$, let $\\pi \\in [0,1]^{\\mathcal{P}}$ be a\nvector of requirement values on the sets and let $\\rho \\in [0, 1]^E$ be a\nvector of probability marginals with $\\sum_{e \\in P} \\rho_e \\geq \\pi_P$ for all\n$P \\in \\mathcal{P}$. We study the question under which conditions the marginals\n$\\rho$ can be decomposed into a probability distribution on the subsets of $E$\nsuch that the resulting random set intersects each $P \\in \\mathcal{P}$ with\nprobability at least $\\pi_P$.\nExtending a result by Dahan, Amin, and Jaillet (MOR 2022) motivated by a\nnetwork security game in directed acyclic graphs, we show that such a\ndistribution exists if $\\mathcal{P}$ is an abstract network and the\nrequirements are of the form $\\pi_P = 1 - \\sum_{e \\in P} \\mu_e$ for some $\\mu\n\\in [0, 1]^E$. Our proof yields an explicit description of a feasible\ndistribution that can be computed efficiently. As a consequence, equilibria for\nthe security game studied by Dahan et al. can be efficiently computed even when\nthe underlying digraph contains cycles. As a subroutine of our algorithm, we\nprovide a combinatorial algorithm for computing shortest paths in abstract\nnetworks, answering an open question by McCormick (SODA 1996). We further show\nthat a conservation law proposed by Dahan et al. for requirement functions in\npartially ordered sets can be reduced to the setting of affine requirements\ndescribed above.",
    "descriptor": "",
    "authors": [
      "Jannik Matuschke"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computer Science and Game Theory (cs.GT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.04922"
  },
  {
    "id": "arXiv:2211.04924",
    "title": "Utilising Bayesian Networks to combine multimodal data and expert  opinion for the robust prediction of depression and its symptoms",
    "abstract": "Predicting the presence of major depressive disorder (MDD) using behavioural\nand cognitive signals is a highly non-trivial task. The heterogeneous clinical\nprofile of MDD means that any given speech, facial expression and/or observed\ncognitive pattern may be associated with a unique combination of depressive\nsymptoms. Conventional discriminative machine learning models potentially lack\nthe complexity to robustly model this heterogeneity. Bayesian networks,\nhowever, may instead be well-suited to such a scenario. These networks are\nprobabilistic graphical models that efficiently describe the joint probability\ndistribution over a set of random variables by explicitly capturing their\nconditional dependencies. This framework provides further advantages over\nstandard discriminative modelling by offering the possibility to incorporate\nexpert opinion in the graphical structure of the models, generating explainable\nmodel predictions, informing about the uncertainty of predictions, and\nnaturally handling missing data. In this study, we apply a Bayesian framework\nto capture the relationships between depression, depression symptoms, and\nfeatures derived from speech, facial expression and cognitive game data\ncollected at thymia.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Salvatore Fara",
      "Orlaith Hickey",
      "Alexandra Georgescu",
      "Stefano Goria",
      "Emilia Molimpakis",
      "Nicholas Cummins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04924"
  },
  {
    "id": "arXiv:2211.04927",
    "title": "From Distance to Dependency: A Paradigm Shift of Full-reference Image  Quality Assessment",
    "abstract": "Deep learning-based full-reference image quality assessment (FR-IQA) models\ntypically rely on the feature distance between the reference and distorted\nimages. However, the underlying assumption of these models that the distance in\nthe deep feature domain could quantify the quality degradation does not\nscientifically align with the invariant texture perception, especially when the\nimages are generated artificially by neural networks. In this paper, we bring a\nradical shift in inferring the quality with learned features and propose the\nDeep Image Dependency (DID) based FR-IQA model. The feature dependency\nfacilitates the comparisons of deep learning features in a high-order manner\nwith Brownian distance covariance, which is characterized by the joint\ndistribution of the features from reference and test images, as well as their\nmarginal distributions. This enables the quantification of the feature\ndependency against nonlinear transformation, which is far beyond the\ncomputation of the numerical errors in the feature space. Experiments on image\nquality prediction, texture image similarity, and geometric invariance validate\nthe superior performance of our proposed measure.",
    "descriptor": "",
    "authors": [
      "Hanwei Zhu",
      "Baoliang Chen",
      "Lingyu Zhu",
      "Shiqi Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.04927"
  },
  {
    "id": "arXiv:2211.04928",
    "title": "miCSE: Mutual Information Contrastive Learning for Low-shot Sentence  Embeddings",
    "abstract": "This paper presents miCSE, a mutual information-based Contrastive learning\nframework that significantly advances the state-of-the-art in few-shot sentence\nembedding. The proposed approach imposes alignment between the attention\npattern of different views during contrastive learning. Learning sentence\nembeddings with miCSE entails enforcing the syntactic consistency across\naugmented views for every single sentence, making contrastive self-supervised\nlearning more sample efficient. As a result, the proposed approach shows strong\nperformance in the few-shot learning domain. While it achieves superior results\ncompared to state-of-the-art methods on multiple benchmarks in few-shot\nlearning, it is comparable in the full-shot scenario. The proposed approach is\nconceptually simple, easy to implement and optimize, yet empirically powerful.\nThis study opens up avenues for efficient self-supervised learning methods that\nare more robust than current contrastive methods for sentence embedding.",
    "descriptor": "",
    "authors": [
      "Tassilo Klein",
      "Moin Nabi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04928"
  },
  {
    "id": "arXiv:2211.04934",
    "title": "DoSA : A System to Accelerate Annotations on Business Documents with  Human-in-the-Loop",
    "abstract": "Business documents come in a variety of structures, formats and information\nneeds which makes information extraction a challenging task. Due to these\nvariations, having a document generic model which can work well across all\ntypes of documents and for all the use cases seems far-fetched. For\ndocument-specific models, we would need customized document-specific labels. We\nintroduce DoSA (Document Specific Automated Annotations), which helps\nannotators in generating initial annotations automatically using our novel\nbootstrap approach by leveraging document generic datasets and models. These\ninitial annotations can further be reviewed by a human for correctness. An\ninitial document-specific model can be trained and its inference can be used as\nfeedback for generating more automated annotations. These automated annotations\ncan be reviewed by human-in-the-loop for the correctness and a new improved\nmodel can be trained using the current model as pre-trained model before going\nfor the next iteration. In this paper, our scope is limited to Form like\ndocuments due to limited availability of generic annotated datasets, but this\nidea can be extended to a variety of other documents as more datasets are\nbuilt. An open-source ready-to-use implementation is made available on GitHub\nhttps://github.com/neeleshkshukla/DoSA.",
    "descriptor": "\nComments: Accepted at DaSH@EMNLP2022, 5 pages, 4 figures\n",
    "authors": [
      "Neelesh K Shukla",
      "Msp Raja",
      "Raghu Katikeri",
      "Amit Vaid"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.04934"
  },
  {
    "id": "arXiv:2211.04938",
    "title": "Combinatorics of Reduced Ordered Binary Decision Diagrams: Application  to uniform random sampling",
    "abstract": "Since three decades binary decision diagrams, representing efficiently\nBoolean functions, are widely used, in many distinct contexts like model\nverification, machine learning. The most famous variant, called reduced ordered\nbinary decision diagram (ROBDD for short), can be viewed as the result of a\ncompaction procedure on the full decision tree. In this paper we aim at\ncomputing the exact distribution of the Boolean functions in $k$~variables\naccording to the ROBDD size, where the ROBDD size is equal to the size of the\nunderlying directed acyclic graph (DAG) structure. Recall the number of Boolean\nfunctions is equal to $2^{2^k}$, which is of double exponential growth; hence a\ncombinatorial explosion is to be expected. The maximal size of a ROBDD with $k$\nvariables is $M_k \\sim 2^k / k$ and thus, the support of the ROBDD size\ndistribution is also of length $M_k$, making $M_k$ a natural complexity unit\nfor our problem. In this paper, we develop the first polynomial algorithm to\nderive the distribution of the Boolean functions with respect to their ROBDD\nsizes. The algorithm is essentially quartic in $M_k$ for the time complexity\nand quadratic for the space complexity. The main obstacle is to take into\naccount dependencies inside the DAG structure, and we propose a new\ncombinatorial counting procedure reminiscent of the inclusion-exclusion\nprinciple. As a by-product, we present an efficient polynomial unranking\nalgorithm for ROBDDs, which in turn yields a uniform random sampler over the\nset of ROBDDs of a given size or of a given profile. This is a great\nimprovement to the uniform sampler over the set of all Boolean functions in $k$\nvariables. Indeed, due to the Shannon effect, the uniform distribution over\nBoolean functions is heavily biased to extremely complex functions, with near\nmaximal ROBDD size, thus preventing to sample small ROBDDs",
    "descriptor": "",
    "authors": [
      "Julien Cl\u00e9ment",
      "Antoine Genitrini"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.04938"
  },
  {
    "id": "arXiv:2211.04939",
    "title": "Efficient Speech Translation with Pre-trained Models",
    "abstract": "When building state-of-the-art speech translation models, the need for large\ncomputational resources is a significant obstacle due to the large training\ndata size and complex models. The availability of pre-trained models is a\npromising opportunity to build strong speech translation systems efficiently.\nIn a first step, we investigate efficient strategies to build cascaded and\nend-to-end speech translation systems based on pre-trained models. Using this\nstrategy, we can train and apply the models on a single GPU. While the\nend-to-end models show superior translation performance to cascaded ones, the\napplication of this technology has a limitation on the need for additional\nend-to-end training data. In a second step, we proposed an additional\nsimilarity loss to encourage the model to generate similar hidden\nrepresentations for speech and transcript. Using this technique, we can\nincrease the data efficiency and improve the translation quality by 6 BLEU\npoints in scenarios with limited end-to-end training data.",
    "descriptor": "",
    "authors": [
      "Zhaolin Li",
      "Jan Niehues"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.04939"
  },
  {
    "id": "arXiv:2211.04942",
    "title": "Distribution-Aligned Fine-Tuning for Efficient Neural Retrieval",
    "abstract": "Dual-encoder-based neural retrieval models achieve appreciable performance\nand complement traditional lexical retrievers well due to their semantic\nmatching capabilities, which makes them a common choice for hybrid IR systems.\nHowever, these models exhibit a performance bottleneck in the online query\nencoding step, as the corresponding query encoders are usually large and\ncomplex Transformer models.\nIn this paper we investigate heterogeneous dual-encoder models, where the two\nencoders are separate models that do not share parameters or initializations.\nWe empirically show that heterogeneous dual-encoders are susceptible to\ncollapsing representations, causing them to output constant trivial\nrepresentations when they are fine-tuned using a standard contrastive loss due\nto a distribution mismatch. We propose DAFT, a simple two-stage fine-tuning\napproach that aligns the two encoders in order to prevent them from collapsing.\nWe further demonstrate how DAFT can be used to train efficient heterogeneous\ndual-encoder models using lightweight query encoders.",
    "descriptor": "",
    "authors": [
      "Jurek Leonhardt",
      "Marcel Jahnke",
      "Avishek Anand"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.04942"
  },
  {
    "id": "arXiv:2211.04943",
    "title": "Evaluating and Improving Context Attention Distribution on Multi-Turn  Response Generation using Self-Contained Distractions",
    "abstract": "Despite the rapid progress of open-domain generation-based conversational\nagents, most deployed systems treat dialogue contexts as single-turns, while\nsystems dealing with multi-turn contexts are less studied. There is a lack of a\nreliable metric for evaluating multi-turn modelling, as well as an effective\nsolution for improving it. In this paper, we focus on an essential component of\nmulti-turn generation-based conversational agents: context attention\ndistribution, i.e. how systems distribute their attention on dialogue's\ncontext. For evaluation of this component, We introduce a novel\nattention-mechanism-based metric: DAS ratio. To improve performance on this\ncomponent, we propose an optimization strategy that employs self-contained\ndistractions. Our experiments on the Ubuntu chatlogs dataset show that models\nwith comparable perplexity can be distinguished by their ability on context\nattention distribution. Our proposed optimization strategy improves both\nnon-hierarchical and hierarchical models on the proposed metric by about 10%\nfrom baselines.",
    "descriptor": "",
    "authors": [
      "Yujie Xing",
      "Jon Atle Gulla"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.04943"
  },
  {
    "id": "arXiv:2211.04944",
    "title": "Safety-Critical Optimal Control for Robotic Manipulators in A Cluttered  Environment",
    "abstract": "Designing safety-critical control for robotic manipulators is challenging,\nespecially in a cluttered environment. First, the actual trajectory of a\nmanipulator might deviate from the planned one due to the complex collision\nenvironments and non-trivial dynamics, leading to collision; Second, the\nfeasible space for the manipulator is hard to obtain since the explicit\ndistance functions between collision meshes are unknown. By analyzing the\nrelationship between the safe set and the controlled invariant set, this paper\nproposes a data-driven control barrier function (CBF) construction method,\nwhich extracts CBF from distance samples. Specifically, the CBF guarantees the\ncontrolled invariant property for considering the system dynamics. The\ndata-driven method samples the distance function and determines the safe set.\nThen, the CBF is synthesized based on the safe set by a scenario-based sum of\nsquare (SOS) program. Unlike most existing linearization based approaches, our\nmethod reserves the volume of the feasible space for planning without\napproximation, which helps find a solution in a cluttered environment. The\ncontrol law is obtained by solving a CBF-based quadratic program in real time,\nwhich works as a safe filter for the desired planning-based controller.\nMoreover, our method guarantees safety with the proven probabilistic result.\nOur method is validated on a 7-DOF manipulator in both real and virtual\ncluttered environments. The experiments show that the manipulator is able to\nexecute tasks where the clearance between obstacles is in millimeters.",
    "descriptor": "",
    "authors": [
      "Xuda Ding",
      "Han Wang",
      "Yi Ren",
      "Yu Zheng",
      "Cailian Chen",
      "Jianping He"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.04944"
  },
  {
    "id": "arXiv:2211.04946",
    "title": "Accountable and Explainable Methods for Complex Reasoning over Text",
    "abstract": "A major concern of Machine Learning (ML) models is their opacity. They are\ndeployed in an increasing number of applications where they often operate as\nblack boxes that do not provide explanations for their predictions. Among\nothers, the potential harms associated with the lack of understanding of the\nmodels' rationales include privacy violations, adversarial manipulations, and\nunfair discrimination. As a result, the accountability and transparency of ML\nmodels have been posed as critical desiderata by works in policy and law,\nphilosophy, and computer science.\nIn computer science, the decision-making process of ML models has been\nstudied by developing accountability and transparency methods. Accountability\nmethods, such as adversarial attacks and diagnostic datasets, expose\nvulnerabilities of ML models that could lead to malicious manipulations or\nsystematic faults in their predictions. Transparency methods explain the\nrationales behind models' predictions gaining the trust of relevant\nstakeholders and potentially uncovering mistakes and unfairness in models'\ndecisions. To this end, transparency methods have to meet accountability\nrequirements as well, e.g., being robust and faithful to the underlying\nrationales of a model.\nThis thesis presents my research that expands our collective knowledge in the\nareas of accountability and transparency of ML models developed for complex\nreasoning tasks over text.",
    "descriptor": "\nComments: PhD Thesis\n",
    "authors": [
      "Pepa Atanasova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.04946"
  },
  {
    "id": "arXiv:2211.04952",
    "title": "Graph Neural Networks with Adaptive Readouts",
    "abstract": "An effective aggregation of node features into a graph-level representation\nvia readout functions is an essential step in numerous learning tasks involving\ngraph neural networks. Typically, readouts are simple and non-adaptive\nfunctions designed such that the resulting hypothesis space is permutation\ninvariant. Prior work on deep sets indicates that such readouts might require\ncomplex node embeddings that can be difficult to learn via standard\nneighborhood aggregation schemes. Motivated by this, we investigate the\npotential of adaptive readouts given by neural networks that do not necessarily\ngive rise to permutation invariant hypothesis spaces. We argue that in some\nproblems such as binding affinity prediction where molecules are typically\npresented in a canonical form it might be possible to relax the constraints on\npermutation invariance of the hypothesis space and learn a more effective model\nof the affinity by employing an adaptive readout function. Our empirical\nresults demonstrate the effectiveness of neural readouts on more than 40\ndatasets spanning different domains and graph characteristics. Moreover, we\nobserve a consistent improvement over standard readouts (i.e., sum, max, and\nmean) relative to the number of neighborhood aggregation iterations and\ndifferent convolutional operators.",
    "descriptor": "\nComments: Published at NeurIPS 2022. 10 pages, 5 figures, 1 table\n",
    "authors": [
      "David Buterez",
      "Jon Paul Janet",
      "Steven J. Kiddle",
      "Dino Oglic",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04952"
  },
  {
    "id": "arXiv:2211.04961",
    "title": "Parallel-Connected Battery Current Imbalance Dynamics",
    "abstract": "In this work, we derive analytical expressions governing state-of-charge and\ncurrent imbalance dynamics for two parallel-connected batteries. The model,\nbased on equivalent circuits and an affine open circuit voltage relation,\ndescribes the evolution of state-of-charge and current imbalance over the\ncourse of a complete charge and discharge cycle. Using this framework, we\nidentify the conditions under which an aged battery will experience a higher\ncurrent magnitude and state-of-charge deviation towards the end of a charge or\ndischarge cycle. This work enables a quantitative understanding of how\nmismatches in battery capacities and resistances influence imbalance dynamics\nin parallel-connected battery systems, helping to pave a path forward for\nbattery degradation modeling in heterogeneous battery systems.",
    "descriptor": "\nComments: 7 pages, 4 figures, conference paper (MECC 2022)\n",
    "authors": [
      "Andrew Weng",
      "Sravan Pannala",
      "Jason B. Siegel",
      "Anna G. Stefanopoulou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.04961"
  },
  {
    "id": "arXiv:2211.04963",
    "title": "Pure Transformer with Integrated Experts for Scene Text Recognition",
    "abstract": "Scene text recognition (STR) involves the task of reading text in cropped\nimages of natural scenes. Conventional models in STR employ convolutional\nneural network (CNN) followed by recurrent neural network in an encoder-decoder\nframework. In recent times, the transformer architecture is being widely\nadopted in STR as it shows strong capability in capturing long-term dependency\nwhich appears to be prominent in scene text images. Many researchers utilized\ntransformer as part of a hybrid CNN-transformer encoder, often followed by a\ntransformer decoder. However, such methods only make use of the long-term\ndependency mid-way through the encoding process. Although the vision\ntransformer (ViT) is able to capture such dependency at an early stage, its\nutilization remains largely unexploited in STR. This work proposes the use of a\ntransformer-only model as a simple baseline which outperforms hybrid\nCNN-transformer models. Furthermore, two key areas for improvement were\nidentified. Firstly, the first decoded character has the lowest prediction\naccuracy. Secondly, images of different original aspect ratios react\ndifferently to the patch resolutions while ViT only employ one fixed patch\nresolution. To explore these areas, Pure Transformer with Integrated Experts\n(PTIE) is proposed. PTIE is a transformer model that can process multiple patch\nresolutions and decode in both the original and reverse character orders. It is\nexamined on 7 commonly used benchmarks and compared with over 20\nstate-of-the-art methods. The experimental results show that the proposed\nmethod outperforms them and obtains state-of-the-art results in most\nbenchmarks.",
    "descriptor": "\nComments: Accepted in ECCV2022\n",
    "authors": [
      "Yew Lee Tan",
      "Adams Wai-kin Kong",
      "Jung-Jae Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04963"
  },
  {
    "id": "arXiv:2211.04971",
    "title": "Understanding Cross-modal Interactions in V&L Models that Generate Scene  Descriptions",
    "abstract": "Image captioning models tend to describe images in an object-centric way,\nemphasising visible objects. But image descriptions can also abstract away from\nobjects and describe the type of scene depicted. In this paper, we explore the\npotential of a state-of-the-art Vision and Language model, VinVL, to caption\nimages at the scene level using (1) a novel dataset which pairs images with\nboth object-centric and scene descriptions. Through (2) an in-depth analysis of\nthe effect of the fine-tuning, we show (3) that a small amount of curated data\nsuffices to generate scene descriptions without losing the capability to\nidentify object-level concepts in the scene; the model acquires a more holistic\nview of the image compared to when object-centric descriptions are generated.\nWe discuss the parallels between these results and insights from computational\nand cognitive science research on scene perception.",
    "descriptor": "",
    "authors": [
      "Michele Cafagna",
      "Albert Gatt",
      "Kees van Deemter"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04971"
  },
  {
    "id": "arXiv:2211.04972",
    "title": "Hibikino-Musashi@Home 2018 Team Description Paper",
    "abstract": "Our team, Hibikino-Musashi@Home (the shortened name is HMA), was founded in\n2010. It is based in the Kitakyushu Science and Research Park, Japan. We have\nparticipated in the RoboCup@Home Japan open competition open platform league\nevery year since 2010. Moreover, we participated in the RoboCup 2017 Nagoya as\nopen platform league and domestic standard platform league teams. Currently,\nthe Hibikino-Musashi@Home team has 20 members from seven different laboratories\nbased in the Kyushu Institute of Technology. In this paper, we introduce the\nactivities of our team and the technologies.",
    "descriptor": "\nComments: 8 pages, 5 figures, RoboCup@Home\n",
    "authors": [
      "Yutaro Ishida",
      "Sansei Hori",
      "Yuichiro Tanaka",
      "Yuma Yoshimoto",
      "Kouhei Hashimoto",
      "Gouki Iwamoto",
      "Yoshiya Aratani",
      "Kenya Yamashita",
      "Shinya Ishimoto",
      "Kyosuke Hitaka",
      "Fumiaki Yamaguchi",
      "Ryuhei Miyoshi",
      "Kentaro Honda",
      "Yushi Abe",
      "Yoshitaka Kato",
      "Takashi Morie",
      "Hakaru Tamukoh"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.04972"
  },
  {
    "id": "arXiv:2211.04973",
    "title": "Accelerating Adversarial Perturbation by 50% with Semi-backward  Propagation",
    "abstract": "Adversarial perturbation plays a significant role in the field of adversarial\nrobustness, which solves a maximization problem over the input data. We show\nthat the backward propagation of such optimization can accelerate $2\\times$\n(and thus the overall optimization including the forward propagation can\naccelerate $1.5\\times$), without any utility drop, if we only compute the\noutput gradient but not the parameter gradient during the backward propagation.",
    "descriptor": "",
    "authors": [
      "Zhiqi Bu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.04973"
  },
  {
    "id": "arXiv:2211.04974",
    "title": "Leveraging Offline Data in Online Reinforcement Learning",
    "abstract": "Two central paradigms have emerged in the reinforcement learning (RL)\ncommunity: online RL and offline RL. In the online RL setting, the agent has no\nprior knowledge of the environment, and must interact with it in order to find\nan $\\epsilon$-optimal policy. In the offline RL setting, the learner instead\nhas access to a fixed dataset to learn from, but is unable to otherwise\ninteract with the environment, and must obtain the best policy it can from this\noffline data. Practical scenarios often motivate an intermediate setting: if we\nhave some set of offline data and, in addition, may also interact with the\nenvironment, how can we best use the offline data to minimize the number of\nonline interactions necessary to learn an $\\epsilon$-optimal policy?\nIn this work, we consider this setting, which we call the \\textsf{FineTuneRL}\nsetting, for MDPs with linear structure. We characterize the necessary number\nof online samples needed in this setting given access to some offline dataset,\nand develop an algorithm, \\textsc{FTPedel}, which is provably optimal. We show\nthrough an explicit example that combining offline data with online\ninteractions can lead to a provable improvement over either purely offline or\npurely online RL. Finally, our results illustrate the distinction between\n\\emph{verifiable} learning, the typical setting considered in online RL, and\n\\emph{unverifiable} learning, the setting often considered in offline RL, and\nshow that there is a formal separation between these regimes.",
    "descriptor": "",
    "authors": [
      "Andrew Wagenmaker",
      "Aldo Pacchiano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.04974"
  },
  {
    "id": "arXiv:2211.04976",
    "title": "Workload Forecasting of a Logistic Node Using Bayesian Neural Networks",
    "abstract": "Purpose: Traffic volume in empty container depots has been highly volatile\ndue to external factors. Forecasting the expected container truck traffic along\nwith having a dynamic module to foresee the future workload plays a critical\nrole in improving the work efficiency. This paper studies the relevant\nliterature and designs a forecasting model addressing the aforementioned\nissues. Methodology: The paper develops a forecasting model to predict hourly\nwork and traffic volume of container trucks in an empty container depot using a\nBayesian Neural Network based model. Furthermore, the paper experiments with\ndatasets with different characteristics to assess the model's forecasting range\nfor various data sources. Findings: The real data of an empty container depot\nis utilized to develop a forecasting model and to later verify the capabilities\nof the model. The findings show the performance validity of the model and\nprovide the groundwork to build an effective traffic and workload planning\nsystem for the empty container depot in question. Originality: This paper\nproposes a Bayesian deep learning-based forecasting model for traffic and\nworkload of an empty container depot using real-world data. This designed and\nimplemented forecasting model offers a solution with which every actor in the\ncontainer truck transportation benefits from the optimized workload.",
    "descriptor": "",
    "authors": [
      "Emin Nakilcioglu",
      "Anisa Rizvanolli und Olaf Rendel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04976"
  },
  {
    "id": "arXiv:2211.04979",
    "title": "Perceived personality state estimation in dyadic and small group  interaction with deep learning methods",
    "abstract": "Dyadic and small group collaboration is an evolutionary advantageous\nbehaviour and the need for such collaboration is a regular occurrence in day to\nday life. In this paper we estimate the perceived personality traits of\nindividuals in dyadic and small groups over thin-slices of interaction on four\nmultimodal datasets. We find that our transformer based predictive model\nperforms similarly to human annotators tasked with predicting the perceived\nbig-five personality traits of participants. Using this model we analyse the\nestimated perceived personality traits of individuals performing tasks in small\ngroups and dyads. Permutation analysis shows that in the case of small groups\nundergoing collaborative tasks, the perceived personality of group members\nclusters, this is also observed for dyads in a collaborative problem solving\ntask, but not in dyads under non-collaborative task settings. Additionally, we\nfind that the group level average perceived personality traits provide a better\npredictor of group performance than the group level average self-reported\npersonality traits.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Kristian Fenech",
      "\u00c1d\u00e1m Fodor",
      "Sean P. Bergeron",
      "Rachid R. Saboundji",
      "Catharine Oertel",
      "Andr\u00e1s L\u0151rincz"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04979"
  },
  {
    "id": "arXiv:2211.04980",
    "title": "A Capability-based Distributed Authorization System to Enforce  Context-aware Permission Sequences",
    "abstract": "Controlled sharing is fundamental to distributed systems. We consider a\ncapability-based distributed authorization system where a client receives\ncapabilities (access tokens) from an authorization server to access the\nresources of resource servers. Capability-based authorization systems have been\nwidely used on the Web, in mobile applications and other distributed systems.\nA common requirement of such systems is that the user uses tokens of multiple\nservers in a particular order. A related requirement is the token may be used\nif certain environmental conditions hold. We introduce a secure\ncapability-based system that supports \"permission sequence\" and \"context\". This\nallows a finite sequence of permissions to be enforced, each with their own\nspecific context. We prove the safety property of this system for these\nconditions and integrate the system into OAuth 2.0 with proof-of-possession\ntokens. We evaluate our implementation and compare it with plain OAuth with\nrespect to the average time for obtaining an authorization token and acquiring\naccess to the resource.",
    "descriptor": "",
    "authors": [
      "Adrian Shuai Li",
      "Reihaneh Safavi-Naini",
      "Philip W. L. Fong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.04980"
  },
  {
    "id": "arXiv:2211.04981",
    "title": "Sampling an Edge in $O(n/\\sqrt{m} + \\log \\varepsilon^{-1})$ Time via  Bernoulli Trial Simulation",
    "abstract": "Sampling edges from a graph in sublinear time is a fundamental problem and a\npowerful subroutine for designing sublinear-time algorithms. Suppose we have\naccess to the vertices of the graph and know a constant-factor approximation to\nthe number of edges. An algorithm for pointwise $\\varepsilon$-approximate edge\nsampling with complexity $O(n/\\sqrt{\\varepsilon m})$ has been given by Eden and\nRosenbaum [SOSA 2018]. This has been later improved by T\\v{e}tek and Thorup\n[STOC 2022] to $O(n \\log(\\varepsilon^{-1})/\\sqrt{m})$. At the same time,\n$\\Omega(n/\\sqrt{m})$ time is necessary. We close the problem, under the\nassumption of knowing $m$ up to a constant factor, for all but very dense\ngraphs by giving an algorithm with complexity $O(n/\\sqrt{m} + \\log\n\\varepsilon^{-1})$.\nOur algorithm is based on a new technique that we call \\emph{Bernoulli trial\nsimulation}. We believe this technique could also be useful for other problems.\nGiven access to trials of the form $Bern(p)$, this technique allows us to\nsimulate a Bernoulli trial $Bern(f(p) \\pm \\varepsilon)$ (without knowing $p$),\nin time complexity $O(\\log \\varepsilon^{-1})$ for some functions $f$. We\nspecifically use this for $f(p) = 1/(2p)$ for $p \\geq 2/3$. Therefore, we can\nperform rejection sampling, without the algorithm having to know the desired\nrejection probability. We conjecture Bernoulli trial simulation for $f(p) =\n1/(2p)$ can be done exactly in expected $O(1)$ samples. This would lead to an\nexact algorithm for sampling an edge with complexity $O(n/\\sqrt{m})$,\ncompletely resolving the problem of sampling an edge, again assuming rough\nknowledge of $m$. We consider the problem of removing this assumption to be an\ninteresting open problem.",
    "descriptor": "",
    "authors": [
      "Talya Eden",
      "Shyam Narayanan",
      "Jakub T\u011btek"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.04981"
  },
  {
    "id": "arXiv:2211.04986",
    "title": "Fast and Scalable Channels in Kotlin Coroutines",
    "abstract": "Asynchronous programming has gained significant popularity over the last\ndecade: support for this programming pattern is available in many popular\nlanguages via libraries and native language implementations, typically in the\nform of coroutines or the async/await construct. Instead of programming via\nshared memory, this concept assumes implicit synchronization through message\npassing. The key data structure enabling such communication is the rendezvous\nchannel. Roughly, a rendezvous channel is a blocking queue of size zero, so\nboth send(e) and receive() operations wait for each other, performing a\nrendezvous when they meet. To optimize the message passing pattern, channels\nare usually equipped with a fixed-size buffer, so send(e)-s do not suspend and\nput elements into the buffer until its capacity is exceeded. This primitive is\nknown as a buffered channel.\nThis paper presents a fast and scalable algorithm for both rendezvous and\nbuffered channels. Similarly to modern queues, our solution is based on an\ninfinite array with two positional counters for send(e) and receive()\noperations, leveraging the unconditional Fetch-And-Add instruction to update\nthem. Yet, the algorithm requires non-trivial modifications of this classic\npattern, in order to support the full channel semantics, such as buffering and\ncancellation of waiting requests. We compare the performance of our solution to\nthat of the Kotlin implementation, as well as against other academic proposals,\nshowing up to 9.8x speedup. To showcase its expressiveness and performance, we\nalso integrated the proposed algorithm into the standard Kotlin Coroutines\nlibrary, replacing the previous channel implementations.",
    "descriptor": "",
    "authors": [
      "Nikita Koval",
      "Dan Alistarh",
      "Roman Elizarov"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.04986"
  },
  {
    "id": "arXiv:2211.04987",
    "title": "Interpretable Deep Reinforcement Learning for Green Security Games with  Real-Time Information",
    "abstract": "Green Security Games with real-time information (GSG-I) add the real-time\ninformation about the agents' movement to the typical GSG formulation. Prior\nworks on GSG-I have used deep reinforcement learning (DRL) to learn the best\npolicy for the agent in such an environment without any need to store the huge\nnumber of state representations for GSG-I. However, the decision-making process\nof DRL methods is largely opaque, which results in a lack of trust in their\npredictions. To tackle this issue, we present an interpretable DRL method for\nGSG-I that generates visualization to explain the decisions taken by the DRL\nalgorithm. We also show that this approach performs better and works well with\na simpler training regimen compared to the existing method.",
    "descriptor": "",
    "authors": [
      "Vishnu Dutt Sharma",
      "John P. Dickerson",
      "Pratap Tokekar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04987"
  },
  {
    "id": "arXiv:2211.04988",
    "title": "Hyper-GST: Predict Metro Passenger Flow Incorporating GraphSAGE,  Hypergraph, Social-meaningful Edge Weights and Temporal Exploitation",
    "abstract": "Predicting metro passenger flow precisely is of great importance for dynamic\ntraffic planning. Deep learning algorithms have been widely applied due to\ntheir robust performance in modelling non-linear systems. However, traditional\ndeep learning algorithms completely discard the inherent graph structure within\nthe metro system. Graph-based deep learning algorithms could utilise the graph\nstructure but raise a few challenges, such as how to determine the weights of\nthe edges and the shallow receptive field caused by the over-smoothing issue.\nTo further improve these challenges, this study proposes a model based on\nGraphSAGE with an edge weights learner applied. The edge weights learner\nutilises socially meaningful features to generate edge weights. Hypergraph and\ntemporal exploitation modules are also constructed as add-ons for better\nperformance. A comparison study is conducted on the proposed algorithm and\nother state-of-art graph neural networks, where the proposed algorithm could\nimprove the performance.",
    "descriptor": "",
    "authors": [
      "Yuyang Miao",
      "Yao Xu",
      "Danilo Mandic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.04988"
  },
  {
    "id": "arXiv:2211.04989",
    "title": "Piano Learning and Improvisation Through Adaptive Visualisation and  Digital Augmentation",
    "abstract": "The task of learning the piano has been a centuries-old challenge for\nnovices, experts and technologists. Several innovations have been introduced to\nsupport proper posture, movement, and motivation, while sight-reading and\nimprovisation remain the least-explored areas. In this PhD, we address this gap\nby redesigning the piano augmentation as an interactive and adaptive space.\nSpecifically, we will explore how to support learners with adaptive\nvisualisations through a two-pronged approach: (1) by designing adaptive\nvisualisations based on the proficiency of the learner to support regular piano\nplaying and (2) by assisting them with expert annotations projected on the\npiano to encourage improvisation. To this end, we will build a model to\nunderstand the complexities of learners' spatiotemporal data and use these to\nsupport learning. We will then evaluate our approach through user studies\nenabling practice and improvisation. Our work contributes to how adaptive\nvisualisations can push music instrument learning and support multi-target\nselection tasks in immersive spaces.",
    "descriptor": "\nComments: 8 pages, 1 figure, doctoral symposium paper\n",
    "authors": [
      "Jordan Aiko Deja"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.04989"
  },
  {
    "id": "arXiv:2211.04993",
    "title": "RL-DWA Omnidirectional Motion Planning for Person Following in Domestic  Assistance and Monitoring",
    "abstract": "Robot assistants are emerging as high-tech solutions to support people in\neveryday life. Following and assisting the user in the domestic environment\nrequires flexible mobility to safely move in cluttered spaces. We introduce a\nnew approach to person following for assistance and monitoring. Our methodology\nexploits an omnidirectional robotic platform to detach the computation of\nlinear and angular velocities and navigate within the domestic environment\nwithout losing track of the assisted person. While linear velocities are\nmanaged by a conventional Dynamic Window Approach (DWA) local planner, we\ntrained a Deep Reinforcement Learning (DRL) agent to predict optimized angular\nvelocities commands and maintain the orientation of the robot towards the user.\nWe evaluate our navigation system on a real omnidirectional platform in various\nindoor scenarios, demonstrating the competitive advantage of our solution\ncompared to a standard differential steering following.",
    "descriptor": "",
    "authors": [
      "Andrea Eirale",
      "Mauro Martini",
      "Marcello Chiaberge"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04993"
  },
  {
    "id": "arXiv:2211.04994",
    "title": "A Nearly Time-Optimal Distributed Approximation of Minimum Cost  $k$-Edge-Connected Spanning Subgraph",
    "abstract": "The minimum-cost $k$-edge-connected spanning subgraph ($k$-ECSS) problem is a\ngeneralization and strengthening of the well-studied minimum-cost spanning tree\n(MST) problem. While the round complexity of distributedly computing the latter\nhas been well-understood, the former remains mostly open, especially as soon as\n$k\\geq 3$.\nIn this paper, we present the first distributed algorithm that computes an\napproximation of $k$-ECSS in sublinear time for general $k$. Concretely, we\ndescribe a randomized distributed algorithm that, in\n$\\tilde{O}(k(D+k\\sqrt{n}))$ rounds, computes a $k$-edge-connected spanning\nsubgraph whose cost is within an $O(\\log n\\log k)$ factor of optimal. Here, $n$\nand $D$ denote the number of vertices and diameter of the graph, respectively.\nThis time complexity is nearly optimal for any $k=poly(\\log n)$, almost\nmatching an $\\tilde{\\Omega}(D+\\sqrt{n/k})$ lower bound. Our algorithm is the\nfirst to achieve a sublinear round complexity for $k\\geq 3$. We note that this\ncase is considerably more challenging than the well-studied and well-understood\n$k=1$ case -- better known as MST -- and the closely related $k=2$ case.\nOur algorithm is based on reducing the $k$-ECSS problem to $k$ set cover\ninstances, in which we gradually augment the connectivity of the spanning\nsubgraph. To solve each set cover instance, we combine new structural\nobservations on minimum cuts with graph sketching ideas. One key ingredient in\nour algorithm is a novel structural lemma that allows us to compress the\ninformation about all minimum cuts in a graph into a succinct representation,\nwhich is computed in a decentralized fashion. We hope that this succinct\nrepresentation may find applications in other computational settings or for\nother problems.",
    "descriptor": "\nComments: SODA 2023\n",
    "authors": [
      "Michal Dory",
      "Mohsen Ghaffari"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.04994"
  },
  {
    "id": "arXiv:2211.04996",
    "title": "ParGAN: Learning Real Parametrizable Transformations",
    "abstract": "Current methods for image-to-image translation produce compelling results,\nhowever, the applied transformation is difficult to control, since existing\nmechanisms are often limited and non-intuitive. We propose ParGAN, a\ngeneralization of the cycle-consistent GAN framework to learn image\ntransformations with simple and intuitive controls. The proposed generator\ntakes as input both an image and a parametrization of the transformation. We\ntrain this network to preserve the content of the input image while ensuring\nthat the result is consistent with the given parametrization. Our approach does\nnot require paired data and can learn transformations across several tasks and\ndatasets. We show how, with disjoint image domains with no annotated\nparametrization, our framework can create smooth interpolations as well as\nlearn multiple transformations simultaneously.",
    "descriptor": "",
    "authors": [
      "Diego Martin Arroyo",
      "Alessio Tonioni",
      "Federico Tombari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04996"
  },
  {
    "id": "arXiv:2211.04998",
    "title": "Similarity among the 2D-shapes and the analysis of dissimilarity scores",
    "abstract": "We present a conceptually simple and intuitive method to calculate and to\nmeasure the dissimilarities among 2D shapes. Several methods to interpret and\nto visualize the resulting dissimilarity matrix are presented and compared.",
    "descriptor": "",
    "authors": [
      "Karel Zimmermann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04998"
  },
  {
    "id": "arXiv:2211.05006",
    "title": "Almost Tight Error Bounds on Differentially Private Continual Counting",
    "abstract": "The first large-scale deployment of private federated learning uses\ndifferentially private counting in the continual release model as a subroutine\n(Google AI blog titled \"Federated Learning with Formal Differential Privacy\nGuarantees\"). In this case, a concrete bound on the error is very relevant to\nreduce the privacy parameter. The standard mechanism for continual counting is\nthe binary mechanism. We present a novel mechanism and show that its mean\nsquared error is both asymptotically optimal and a factor 10 smaller than the\nerror of the binary mechanism. We also show that the constants in our analysis\nare almost tight by giving non-asymptotic lower and upper bounds that differ\nonly in the constants of lower-order terms. Our algorithm is a matrix mechanism\nfor the counting matrix and takes constant time per release. We also use our\nexplicit factorization of the counting matrix to give an upper bound on the\nexcess risk of the private learning algorithm of Denisov et al. (NeurIPS 2022).\nOur lower bound for any continual counting mechanism is the first tight lower\nbound on continual counting under approximate differential privacy. It is\nachieved using a new lower bound on a certain factorization norm, denoted by\n$\\gamma_F(\\cdot)$, in terms of the singular values of the matrix. In\nparticular, we show that for any complex matrix, $A \\in \\mathbb{C}^{m \\times\nn}$, \\[ \\gamma_F(A) \\geq \\frac{1}{\\sqrt{m}}\\|A\\|_1, \\] where $\\|\\cdot \\|$\ndenotes the Schatten-1 norm.\nWe believe this technique will be useful in proving lower bounds for a larger\nclass of linear queries. To illustrate the power of this technique, we show the\nfirst lower bound on the mean squared error for answering parity queries.",
    "descriptor": "\nComments: To appear in SODA 2023\n",
    "authors": [
      "Monika Henzinger",
      "Jalaj Upadhyay",
      "Sarvagya Upadhyay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.05006"
  },
  {
    "id": "arXiv:2211.05007",
    "title": "Discord Questions: A Computational Approach To Diversity Analysis in  News Coverage",
    "abstract": "There are many potential benefits to news readers accessing diverse sources.\nModern news aggregators do the hard work of organizing the news, offering\nreaders a plethora of source options, but choosing which source to read remains\nchallenging. We propose a new framework to assist readers in identifying source\ndifferences and gaining an understanding of news coverage diversity. The\nframework is based on the generation of Discord Questions: questions with a\ndiverse answer pool, explicitly illustrating source differences. To assemble a\nprototype of the framework, we focus on two components: (1) discord question\ngeneration, the task of generating questions answered differently by sources,\nfor which we propose an automatic scoring method, and create a model that\nimproves performance from current question generation (QG) methods by 5%, (2)\nanswer consolidation, the task of grouping answers to a question that are\nsemantically similar, for which we collect data and repurpose a method that\nachieves 81% balanced accuracy on our realistic test set. We illustrate the\nframework's feasibility through a prototype interface. Even though model\nperformance at discord QG still lags human performance by more than 15%,\ngenerated questions are judged to be more interesting than factoid questions\nand can reveal differences in the level of detail, sentiment, and reasoning of\nsources in news coverage.",
    "descriptor": "\nComments: EMNLP 2022 Findings - Long Paper\n",
    "authors": [
      "Philippe Laban",
      "Chien-Sheng Wu",
      "Lidiya Murakhovs'ka",
      "Xiang 'Anthony' Chen",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05007"
  },
  {
    "id": "arXiv:2211.05012",
    "title": "Active queue management: First steps toward a new control-theoretic  viewpoint",
    "abstract": "Active Queue Management (AQM) for mitigating Internet congestion has been\naddressed via various feedback control syntheses, among which P, PI, and PID\nregulators are quite popular and often associated to a Smith predictor. Here,\nto better account for the many uncertainties, like the round trip time or the\nnumber of TCP sessions, the above controllers are replaced by an intelligent\nproportional controller associated to Model-Free Control (MFC) and by\nforecasting techniques derived from a new approach to time series. Several\ncomputer simulations via a well accepted linear modeling, where the delay is\nassumed to be constant, are presented and discussed.",
    "descriptor": "\nComments: 10th International Conference on Systems and Control (ICSC'2022), Marseille, France, 23-25 November 2022\n",
    "authors": [
      "C\u00e9fric Join",
      "Hugues Mounier",
      "Emmanuel Delaleau",
      "Michel Fliess"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Networking and Internet Architecture (cs.NI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.05012"
  },
  {
    "id": "arXiv:2211.05013",
    "title": "Effects of Stratigraphy on Response of Energy Piles",
    "abstract": "Energy piles are gaining increased popularity due to a growing demand for\nclean energy. To further advance the understanding of soil-structure\ninteraction in energy piles, recently-derived analytical solutions have been\nimplemented to investigate the impact of stratigraphy on the soil-structure\ninteraction. This was accomplished by comparing the measured and predicted head\ndisplacements, axial strains and stresses in an energy pile embedded in the\nactual homogeneous and layered soil profiles, as well as into synthetic\nhomogeneous soil profiles. The analytical solutions for homogeneous soil\nprofile captured the smooth experimentally observed response versus depth very\nwell. In the case of a layered soil profile, the corresponding analytical model\nwas capable of capturing nuances in trends of axial stress and strain versus\ndepth at the interface of different layers. The analytical predictions for the\nlayered profile appear to be slightly less accurate than for the homogenous\nprofile. The experimental data obtained from the layered profile appear to be a\nbit more scattered than those from the homogeneous profile. In the former case,\nthe interplay of the individual soil layers with the pile occurs while\nmaintaining the continuity of the pile stress and displacement at the interface\nof different layers. The response throughout each layer of the layered profile\nis quantitatively different than the corresponding homogeneous response.\nNevertheless, qualitatively the response throughout each layer of the layered\nprofile is similar to the response of the pile embedded in the corresponding\nhomogeneous layer.",
    "descriptor": "\nComments: 10 pages, 8 figures\n",
    "authors": [
      "Arash Saeidi Rashk Olia",
      "Dunja Peric"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.05013"
  },
  {
    "id": "arXiv:2211.05015",
    "title": "Detecting Languages Unintelligible to Multilingual Models through Local  Structure Probes",
    "abstract": "Providing better language tools for low-resource and endangered languages is\nimperative for equitable growth. Recent progress with massively multilingual\npretrained models has proven surprisingly effective at performing zero-shot\ntransfer to a wide variety of languages. However, this transfer is not\nuniversal, with many languages not currently understood by multilingual\napproaches. It is estimated that only 72 languages possess a \"small set of\nlabeled datasets\" on which we could test a model's performance, the vast\nmajority of languages not having the resources available to simply evaluate\nperformances on. In this work, we attempt to clarify which languages do and do\nnot currently benefit from such transfer. To that end, we develop a general\napproach that requires only unlabelled text to detect which languages are not\nwell understood by a cross-lingual model. Our approach is derived from the\nhypothesis that if a model's understanding is insensitive to perturbations to\ntext in a language, it is likely to have a limited understanding of that\nlanguage. We construct a cross-lingual sentence similarity task to evaluate our\napproach empirically on 350, primarily low-resource, languages.",
    "descriptor": "",
    "authors": [
      "Louis Clou\u00e2tre",
      "Prasanna Parthasarathi",
      "Amal Zouaq",
      "Sarath Chandar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05015"
  },
  {
    "id": "arXiv:2211.05018",
    "title": "The Best of Both Worlds: a Framework for Combining Degradation  Prediction with High Performance Super-Resolution Networks",
    "abstract": "To date, the best-performing blind super-resolution (SR) techniques follow\none of two paradigms: A) generate and train a standard SR network on synthetic\nlow-resolution - high-resolution (LR - HR) pairs or B) attempt to predict the\ndegradations an LR image has suffered and use these to inform a customised SR\nnetwork. Despite significant progress, subscribers to the former miss out on\nuseful degradation information that could be used to improve the SR process. On\nthe other hand, followers of the latter rely on weaker SR networks, which are\nsignificantly outperformed by the latest architectural advancements. In this\nwork, we present a framework for combining any blind SR prediction mechanism\nwith any deep SR network, using a metadata insertion block to insert prediction\nvectors into SR network feature maps. Through comprehensive testing, we prove\nthat state-of-the-art contrastive and iterative prediction schemes can be\nsuccessfully combined with high-performance SR networks such as RCAN and HAN\nwithin our framework. We show that our hybrid models consistently achieve\nstronger SR performance than both their non-blind and blind counterparts.\nFurthermore, we demonstrate our framework's robustness by predicting\ndegradations and super-resolving images from a complex pipeline of blurring,\nnoise and compression.",
    "descriptor": "",
    "authors": [
      "Matthew Aquilina",
      "Keith George Ciantar",
      "Christian Galea",
      "Kenneth P. Camilleri",
      "Reuben A. Farrugia",
      "John Abela"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05018"
  },
  {
    "id": "arXiv:2211.05025",
    "title": "Local Structure Matters Most in Most Languages",
    "abstract": "Many recent perturbation studies have found unintuitive results on what does\nand does not matter when performing Natural Language Understanding (NLU) tasks\nin English. Coding properties, such as the order of words, can often be removed\nthrough shuffling without impacting downstream performances. Such insight may\nbe used to direct future research into English NLP models. As many improvements\nin multilingual settings consist of wholesale adaptation of English approaches,\nit is important to verify whether those studies replicate or not in\nmultilingual settings. In this work, we replicate a study on the importance of\nlocal structure, and the relative unimportance of global structure, in a\nmultilingual setting. We find that the phenomenon observed on the English\nlanguage broadly translates to over 120 languages, with a few caveats.",
    "descriptor": "",
    "authors": [
      "Louis Clou\u00e2tre",
      "Prasanna Parthasarathi",
      "Amal Zouaq",
      "Sarath Chandar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05025"
  },
  {
    "id": "arXiv:2211.05030",
    "title": "Creative Writing with an AI-Powered Writing Assistant: Perspectives from  Professional Writers",
    "abstract": "Recent developments in natural language generation (NLG) using neural\nlanguage models have brought us closer than ever to the goal of building\nAI-powered creative writing tools. However, most prior work on human-AI\ncollaboration in the creative writing domain has evaluated new systems with\namateur writers, typically in contrived user studies of limited scope. In this\nwork, we commissioned 13 professional, published writers from a diverse set of\ncreative writing backgrounds to craft stories using Wordcraft, a text editor\nwith built-in AI-powered writing assistance tools. Using interviews and\nparticipant journals, we discuss the potential of NLG to have significant\nimpact in the creative writing domain--especially with respect to\nbrainstorming, generation of story details, world-building, and research\nassistance. Experienced writers, more so than amateurs, typically have\nwell-developed systems and methodologies for writing, as well as distinctive\nvoices and target audiences. Our work highlights the challenges in building for\nthese writers; NLG technologies struggle to preserve style and authorial voice,\nand they lack deep understanding of story contents. In order for AI-powered\nwriting assistants to realize their full potential, it is essential that they\ntake into account the diverse goals and expertise of human writers.",
    "descriptor": "",
    "authors": [
      "Daphne Ippolito",
      "Ann Yuan",
      "Andy Coenen",
      "Sehmon Burnam"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05030"
  },
  {
    "id": "arXiv:2211.05031",
    "title": "Improving Performance of Automatic Keyword Extraction (AKE) Methods  Using PoS-Tagging and Enhanced Semantic-Awareness",
    "abstract": "Automatic keyword extraction (AKE) has gained more importance with the\nincreasing amount of digital textual data that modern computing systems\nprocess. It has various applications in information retrieval (IR) and natural\nlanguage processing (NLP), including text summarisation, topic analysis and\ndocument indexing. This paper proposes a simple but effective\npost-processing-based universal approach to improve the performance of any AKE\nmethods, via an enhanced level of semantic-awareness supported by PoS-tagging.\nTo demonstrate the performance of the proposed approach, we considered word\ntypes retrieved from a PoS-tagging step and two representative sources of\nsemantic information -- specialised terms defined in one or more\ncontext-dependent thesauri, and named entities in Wikipedia. The above three\nsteps can be simply added to the end of any AKE methods as part of a\npost-processor, which simply re-evaluate all candidate keywords following some\ncontext-specific and semantic-aware criteria. For five state-of-the-art (SOTA)\nAKE methods, our experimental results with 17 selected datasets showed that the\nproposed approach improved their performances both consistently (up to 100\\% in\nterms of improved cases) and significantly (between 10.2\\% and 53.8\\%, with an\naverage of 25.8\\%, in terms of F1-score and across all five methods),\nespecially when all the three enhancement steps are used. Our results have\nprofound implications considering the ease to apply our proposed approach to\nany AKE methods and to further extend it.",
    "descriptor": "",
    "authors": [
      "Enes Altuncu",
      "Jason R.C. Nurse",
      "Yang Xu",
      "Jie Guo",
      "Shujun Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.05031"
  },
  {
    "id": "arXiv:2211.05035",
    "title": "Combining Contrastive Learning and Knowledge Graph Embeddings to develop  medical word embeddings for the Italian language",
    "abstract": "Word embeddings play a significant role in today's Natural Language\nProcessing tasks and applications. While pre-trained models may be directly\nemployed and integrated into existing pipelines, they are often fine-tuned to\nbetter fit with specific languages or domains. In this paper, we attempt to\nimprove available embeddings in the uncovered niche of the Italian medical\ndomain through the combination of Contrastive Learning (CL) and Knowledge Graph\nEmbedding (KGE). The main objective is to improve the accuracy of semantic\nsimilarity between medical terms, which is also used as an evaluation task.\nSince the Italian language lacks medical texts and controlled vocabularies, we\nhave developed a specific solution by combining preexisting CL methods\n(multi-similarity loss, contextualization, dynamic sampling) and the\nintegration of KGEs, creating a new variant of the loss. Although without\nhaving outperformed the state-of-the-art, represented by multilingual models,\nthe obtained results are encouraging, providing a significant leap in\nperformance compared to the starting model, while using a significantly lower\namount of data.",
    "descriptor": "",
    "authors": [
      "Denys Amore Bondarenko",
      "Roger Ferrod",
      "Luigi Di Caro"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05035"
  },
  {
    "id": "arXiv:2211.05036",
    "title": "Portmanteauing Features for Scene Text Recognition",
    "abstract": "Scene text images have different shapes and are subjected to various\ndistortions, e.g. perspective distortions. To handle these challenges, the\nstate-of-the-art methods rely on a rectification network, which is connected to\nthe text recognition network. They form a linear pipeline which uses text\nrectification on all input images, even for images that can be recognized\nwithout it. Undoubtedly, the rectification network improves the overall text\nrecognition performance. However, in some cases, the rectification network\ngenerates unnecessary distortions on images, resulting in incorrect predictions\nin images that would have otherwise been correct without it. In order to\nalleviate the unnecessary distortions, the portmanteauing of features is\nproposed. The portmanteau feature, inspired by the portmanteau word, is a\nfeature containing information from both the original text image and the\nrectified image. To generate the portmanteau feature, a non-linear input\npipeline with a block matrix initialization is presented. In this work, the\ntransformer is chosen as the recognition network due to its utilization of\nattention and inherent parallelism, which can effectively handle the\nportmanteau feature. The proposed method is examined on 6 benchmarks and\ncompared with 13 state-of-the-art methods. The experimental results show that\nthe proposed method outperforms the state-of-the-art methods on various of the\nbenchmarks.",
    "descriptor": "\nComments: Accepted in ICPR 2022\n",
    "authors": [
      "Yew Lee Tan",
      "Ernest Yu Kai Chew",
      "Adams Wai-Kin Kong",
      "Jung-Jae Kim",
      "Joo Hwee Lim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05036"
  },
  {
    "id": "arXiv:2211.05039",
    "title": "Active Acquisition for Multimodal Temporal Data: A Challenging  Decision-Making Task",
    "abstract": "We introduce a challenging decision-making task that we call active\nacquisition for multimodal temporal data (A2MT). In many real-world scenarios,\ninput features are not readily available at test time and must instead be\nacquired at significant cost. With A2MT, we aim to learn agents that actively\nselect which modalities of an input to acquire, trading off acquisition cost\nand predictive performance. A2MT extends a previous task called active feature\nacquisition to temporal decision making about high-dimensional inputs. Further,\nwe propose a method based on the Perceiver IO architecture to address A2MT in\npractice. Our agents are able to solve a novel synthetic scenario requiring\npractically relevant cross-modal reasoning skills. On two large-scale,\nreal-world datasets, Kinetics-700 and AudioSet, our agents successfully learn\ncost-reactive acquisition behavior. However, an ablation reveals they are\nunable to learn to learn adaptive acquisition strategies, emphasizing the\ndifficulty of the task even for state-of-the-art models. Applications of A2MT\nmay be impactful in domains like medicine, robotics, or finance, where\nmodalities differ in acquisition cost and informativeness.",
    "descriptor": "\nComments: Foundation Models for Decision Making Workshop at Neural Information Processing Systems 2022\n",
    "authors": [
      "Jannik Kossen",
      "C\u0103t\u0103lina Cangea",
      "Eszter V\u00e9rtes",
      "Andrew Jaegle",
      "Viorica Patraucean",
      "Ira Ktena",
      "Nenad Tomasev",
      "Danielle Belgrave"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.05039"
  },
  {
    "id": "arXiv:2211.05041",
    "title": "MACSum: Controllable Summarization with Mixed Attributes",
    "abstract": "Controllable summarization allows users to generate customized summaries with\nspecified attributes. However, due to the lack of designated annotations of\ncontrolled summaries, existing works have to craft pseudo datasets by adapting\ngeneric summarization benchmarks. Furthermore, most research focuses on\ncontrolling single attributes individually (e.g., a short summary or a highly\nabstractive summary) rather than controlling a mix of attributes together\n(e.g., a short and highly abstractive summary). In this paper, we propose\nMACSum, the first human-annotated summarization dataset for controlling mixed\nattributes. It contains source texts from two domains, news articles and\ndialogues, with human-annotated summaries controlled by five designed\nattributes (Length, Extractiveness, Specificity, Topic, and Speaker). We\npropose two simple and effective parameter-efficient approaches for the new\ntask of mixed controllable summarization based on hard prompt tuning and soft\nprefix tuning. Results and analysis demonstrate that hard prompt models yield\nthe best performance on all metrics and human evaluations. However,\nmixed-attribute control is still challenging for summarization tasks. Our\ndataset and code are available at https://github.com/psunlpgroup/MACSum.",
    "descriptor": "\nComments: 14 pages, 7 figures\n",
    "authors": [
      "Yusen Zhang",
      "Yang Liu",
      "Ziyi Yang",
      "Yuwei Fang",
      "Yulong Chen",
      "Dragomir Radev",
      "Chenguang Zhu",
      "Michael Zeng",
      "Rui Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05041"
  },
  {
    "id": "arXiv:2211.05044",
    "title": "What is Wrong with Language Models that Can Not Tell a Story?",
    "abstract": "This paper argues that a deeper understanding of narrative and the successful\ngeneration of longer subjectively interesting texts is a vital bottleneck that\nhinders the progress in modern Natural Language Processing (NLP) and may even\nbe in the whole field of Artificial Intelligence. We demonstrate that there are\nno adequate datasets, evaluation methods, and even operational concepts that\ncould be used to start working on narrative processing.",
    "descriptor": "",
    "authors": [
      "Ivan P. Yamshchikov",
      "Alexey Tikhonov"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.05044"
  },
  {
    "id": "arXiv:2211.05052",
    "title": "In-memory factorization of holographic perceptual representations",
    "abstract": "Disentanglement of constituent factors of a sensory signal is central to\nperception and cognition and hence is a critical task for future artificial\nintelligence systems. In this paper, we present a compute engine capable of\nefficiently factorizing holographic perceptual representations by exploiting\nthe computation-in-superposition capability of brain-inspired hyperdimensional\ncomputing and the intrinsic stochasticity associated with analog in-memory\ncomputing based on nanoscale memristive devices. Such an iterative in-memory\nfactorizer is shown to solve at least five orders of magnitude larger problems\nthat cannot be solved otherwise, while also significantly lowering the\ncomputational time and space complexity. We present a large-scale experimental\ndemonstration of the factorizer by employing two in-memory compute chips based\non phase-change memristive devices. The dominant matrix-vector multiply\noperations are executed at O(1) thus reducing the computational time complexity\nto merely the number of iterations. Moreover, we experimentally demonstrate the\nability to factorize visual perceptual representations reliably and\nefficiently.",
    "descriptor": "\nComments: 23 pages, 4 figures, 1 extended data figure, 3 supplementary notes, 2 supplementary figures and 3 supplementary tables\n",
    "authors": [
      "Jovin Langenegger",
      "Geethan Karunaratne",
      "Michael Hersche",
      "Luca Benini",
      "Abu Sebastian",
      "Abbas Rahimi"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.05052"
  },
  {
    "id": "arXiv:2211.05053",
    "title": "On Minimizing Tardy Processing Time, Max-Min Skewed Convolution, and  Triangular Structured ILPs",
    "abstract": "The starting point of this paper is the problem of scheduling $n$ jobs with\nprocessing times and due dates on a single machine so as to minimize the total\nprocessing time of tardy jobs, i.e., $1||\\sum p_j U_j$. This problem was\nidentified by Bringmann et al.~(Algorithmica 2022) as a natural\nsubquadratic-time special case of the classic $1||\\sum w_j U_j$ problem, which\nlikely requires time quadratic in the total processing time $P$, because of a\nfine-grained lower bound. Bringmann et al.~obtain their $\\tilde{O}(P^{7/4})$\ntime scheduling algorithm through a new variant of convolution, dubbed Max-Min\nSkewed Convolution, which they solve in $\\tilde{O}(n^{7/4})$ time. Our main\ntechnical contribution is a faster and simpler convolution algorithm running in\n$\\tilde{O}(n^{5/3})$ time. It implies an $\\tilde{O}(P^{5/3})$ time algorithm\nfor \\problem, but may also be of independent interest.\nInspired by recent developments for the Subset Sum and Knapsack problems, we\nstudy $1||\\sum p_j U_j$ parameterized by the maximum job processing time\n$p_{\\max}$. With proximity techniques borrowed from integer linear programming\n(ILP), we show structural properties of the problem that, coupled with a new\ndynamic programming formulation, lead to an $\\tilde{O}(n+p_{\\max}^3)$ time\nalgorithm. Moreover, in the setting with multiple machines, we use similar\ntechniques to get an $n \\cdot p_{\\max}^{O(m)}$ time algorithm for $Pm||\\sum p_j\nU_j$.\nFinally, we point out that the considered problems exhibit a particular\ntriangular block structure in the constraint matrices of their ILP\nformulations. In light of recent ILP research, a question that arises is\nwhether one can devise a generic algorithm for such a class of ILPs. We give a\nnegative answer to this question: we show that already a slight generalization\nof the structure of the scheduling ILP leads to a strongly NP-hard problem.",
    "descriptor": "\nComments: SODA 2023\n",
    "authors": [
      "Kim-Manuel Klein",
      "Adam Polak",
      "Lars Rohwedder"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.05053"
  },
  {
    "id": "arXiv:2211.05054",
    "title": "Message passing methods on complex networks",
    "abstract": "Networks and network computations have become a primary mathematical tool for\nanalyzing the structure of many kinds of complex systems, ranging from the\nInternet and transportation networks to biochemical interactions and social\nnetworks. A common task in network analysis is the calculation of quantities\nthat reside on the nodes of a network, such as centrality measures,\nprobabilities, or model states. In this review article we discuss message\npassing methods, a family of techniques for performing such calculations, based\non the propagation of information between the nodes of a network. We introduce\nthe message passing approach with a series of examples, give some illustrative\napplications and results, and discuss the deep connections between message\npassing and phase transitions in networks. We also point out some limitations\nof the message passing approach and describe some recently-introduced methods\nthat address these limitations.",
    "descriptor": "\nComments: 16 pages and 16 figures\n",
    "authors": [
      "M. E. J. Newman"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.05054"
  },
  {
    "id": "arXiv:2211.05057",
    "title": "A Note on the Compatibility of Different Robust Program Equilibria of  the Prisoner's Dilemma",
    "abstract": "We study a program game version of the Prisoner's Dilemma, i.e., a two-player\ngame in which each player submits a computer program, the programs are given\nread access to each other's source code and then choose whether to cooperate or\ndefect. Prior work has introduced various programs that form cooperative\nequilibria against themselves in this game. For example, the\n$\\epsilon$-grounded Fair Bot cooperates with probability $\\epsilon$ and with\nthe remaining probability runs its opponent's program and copies its action. If\nboth players submit this program, then this is a Nash equilibrium in which both\nplayers cooperate. Others have proposed cooperative equilibria based on\nproof-based Fair Bots, which cooperate if they can prove that the opponent\ncooperates (and defect otherwise). We here show that these different programs\nare compatible with each other. For example, if one player submits\n$\\epsilon$-grounded Fair Bot and the other submits a proof-based Fair Bot, then\nthis is also a cooperative equilibrium of the program game version of the\nPrisoner's Dilemma.",
    "descriptor": "\nComments: 8 pages, 1 table\n",
    "authors": [
      "Caspar Oesterheld"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.05057"
  },
  {
    "id": "arXiv:2211.05062",
    "title": "Land Use Trade-offs in Decarbonization of Electricity Generation in the  American West",
    "abstract": "Land-use conflicts may constrain the unprecedented rates of renewable energy\ndeployment required to meet the decarbonization goals of the Inflation\nReduction Act (IRA). This paper employs geospatially resolved data and a\ndetailed electricity system capacity expansion model to generate 160\naffordable, zero-carbon electricity supply portfolios for the American west and\nevaluates the land use impacts of each portfolio. Less than 4% of all sites\nsuitable for solar development and 17% of all wind sites appear in this set of\nportfolios. Of these sites, 53% of solar and 85% of wind sites exhibit higher\ndevelopment risk and potential for land use conflict. We thus find that clean\nelectricity goals cannot be achieved in an affordable manner without\nsubstantial renewable development on sites with potential for land use\nconflict. However, this paper identifies significant flexibility across western\nU.S. states to site renewable energy or alter the composition of the\nelectricity supply portfolio to ameliorate potential conflicts.",
    "descriptor": "\nComments: 30 pages, 5 figures, 1 table in the main text\n",
    "authors": [
      "Neha Patankar",
      "Xiili Sarkela-Basset",
      "Greg Schivley",
      "Emily Leslie",
      "Jesse Jenkins"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.05062"
  },
  {
    "id": "arXiv:2211.05066",
    "title": "Entropy-stable flux-differencing formulation with Gauss nodes for the  DGSEM",
    "abstract": "In this work, we propose an extension of telescopic derivative operators for\nthe DGSEM with Gauss nodes, and we prove that this formulation is equivalent to\nits usual matrix counterpart. Among other possible applications, this allows\nextending the stabilization methods already developed for Gauss-Lobatto nodes\nto Gauss nodes, also ensuring properties such as entropy stability while\nretaining their improved accuracy.",
    "descriptor": "\nComments: Short note\n",
    "authors": [
      "Andr\u00e9s Mateo-Gab\u00edn",
      "Andr\u00e9s M. Rueda-Ram\u00edrez",
      "Eusebio Valero",
      "Gonzalo Rubio"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2211.05066"
  },
  {
    "id": "arXiv:2211.05068",
    "title": "Galois Hull Dimensions of Gabidulin Codes",
    "abstract": "For a prime power $q$, an integer $m$ and $0\\leq e\\leq m-1$ we study the\n$e$-Galois hull dimension of Gabidulin codes $G_k(\\boldsymbol{\\alpha})$ of\nlength $m$ and dimension $k$ over $\\mathbb{F}_{q^m}$. Using a self-dual basis\n$\\boldsymbol{\\alpha}$ of $\\mathbb{F}_{q^m}$ over $\\mathbb{F}_q$, we first\nexplicitly compute the hull dimension of $G_k(\\boldsymbol{\\alpha})$. Then a\nnecessary and sufficient condition of $G_k(\\boldsymbol{\\alpha})$ to be linear\ncomplementary dual (LCD), self-orthogonal and self-dual will be provided. We\nprove the existence of $e$-Galois (where $e=\\frac{m}{2}$) self-dual Gabidulin\ncodes of length $m$ for even $q$, which is in contrast to the known fact that\nEuclidean self-dual Gabidulin codes do not exist for even $q$. As an\napplication, we construct two classes of entangled-assisted quantum\nerror-correcting codes (EAQECCs) whose parameters have more flexibility\ncompared to known codes in this context.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Habibul Islam",
      "Anna-Lena Horlemann"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.05068"
  },
  {
    "id": "arXiv:2211.05069",
    "title": "Basis for a vector space generated by Hamiltonian time paths in a  complete time graph",
    "abstract": "In this paper we introduce the notion of a complete time graph of order n. We\ndefine time paths and Hamiltonian time paths in a complete time graph. Each\nHamiltonian time path (htp) is associated with some permutation p of the\nintegers 1 to n. The characteristic function of this path forms a vector in the\nvector space of rational-valued functions on the set of edges of the compete\ntime graph. We will consider the vector space generated by these functions. The\nmain result in this paper is to determine the dimension of this vector space\nfor n greater than or equal to 5. We also give an algorithm with its complexity\nfor the construction of a basis in this vector space.",
    "descriptor": "\nComments: 16 pages 3 figures\n",
    "authors": [
      "Malay Dutta",
      "Anjana K. Mahanta"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.05069"
  },
  {
    "id": "arXiv:2211.05075",
    "title": "Supporting AI/ML Security Workers through an Adversarial Techniques,  Tools, and Common Knowledge (AI/ML ATT&CK) Framework",
    "abstract": "This paper focuses on supporting AI/ML Security Workers -- professionals\ninvolved in the development and deployment of secure AI-enabled software\nsystems. It presents AI/ML Adversarial Techniques, Tools, and Common Knowledge\n(AI/ML ATT&CK) framework to enable AI/ML Security Workers intuitively to\nexplore offensive and defensive tactics.",
    "descriptor": "\nComments: AI/ML ATT&CK\n",
    "authors": [
      "Mohamad Fazelnia",
      "Ahmet Okutan",
      "Mehdi Mirakhorli"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.05075"
  },
  {
    "id": "arXiv:2211.05077",
    "title": "Prompting Large Pre-trained Vision-Language Models For Compositional  Concept Learning",
    "abstract": "This work explores the zero-shot compositional learning ability of large\npre-trained vision-language models(VLMs) within the prompt-based learning\nframework and propose a model (\\textit{PromptCompVL}) to solve the compositonal\nzero-shot learning (CZSL) problem. \\textit{PromptCompVL} makes two design\nchoices: first, it uses a soft-prompting instead of hard-prompting to inject\nlearnable parameters to reprogram VLMs for compositional learning. Second, to\naddress the compositional challenge, it uses the soft-embedding layer to learn\nprimitive concepts in different combinations. By combining both soft-embedding\nand soft-prompting, \\textit{PromptCompVL} achieves state-of-the-art performance\non the MIT-States dataset. Furthermore, our proposed model achieves consistent\nimprovement compared to other CLIP-based methods which shows the effectiveness\nof the proposed prompting strategies for CZSL.",
    "descriptor": "",
    "authors": [
      "Guangyue Xu",
      "Parisa Kordjamshidi",
      "Joyce Chai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.05077"
  },
  {
    "id": "arXiv:2211.05087",
    "title": "Cross-lingual Transfer Learning for Check-worthy Claim Identification  over Twitter",
    "abstract": "Misinformation spread over social media has become an undeniable infodemic.\nHowever, not all spreading claims are made equal. If propagated, some claims\ncan be destructive, not only on the individual level, but to organizations and\neven countries. Detecting claims that should be prioritized for fact-checking\nis considered the first step to fight against spread of fake news. With\ntraining data limited to a handful of languages, developing supervised models\nto tackle the problem over lower-resource languages is currently infeasible.\nTherefore, our work aims to investigate whether we can use existing datasets to\ntrain models for predicting worthiness of verification of claims in tweets in\nother languages. We present a systematic comparative study of six approaches\nfor cross-lingual check-worthiness estimation across pairs of five diverse\nlanguages with the help of Multilingual BERT (mBERT) model. We run our\nexperiments using a state-of-the-art multilingual Twitter dataset. Our results\nshow that for some language pairs, zero-shot cross-lingual transfer is possible\nand can perform as good as monolingual models that are trained on the target\nlanguage. We also show that in some languages, this approach outperforms (or at\nleast is comparable to) state-of-the-art models.",
    "descriptor": "",
    "authors": [
      "Maram Hasanain",
      "Tamer Elsayed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.05087"
  },
  {
    "id": "arXiv:2211.05092",
    "title": "Clinical Contrastive Learning for Biomarker Detection",
    "abstract": "This paper presents a novel positive and negative set selection strategy for\ncontrastive learning of medical images based on labels that can be extracted\nfrom clinical data. In the medical field, there exists a variety of labels for\ndata that serve different purposes at different stages of a diagnostic and\ntreatment process. Clinical labels and biomarker labels are two examples. In\ngeneral, clinical labels are easier to obtain in larger quantities because they\nare regularly collected during routine clinical care, while biomarker labels\nrequire expert analysis and interpretation to obtain. Within the field of\nophthalmology, previous work has shown that clinical values exhibit\ncorrelations with biomarker structures that manifest within optical coherence\ntomography (OCT) scans. We exploit this relationship between clinical and\nbiomarker data to improve performance for biomarker classification. This is\naccomplished by leveraging the larger amount of clinical data as pseudo-labels\nfor our data without biomarker labels in order to choose positive and negative\ninstances for training a backbone network with a supervised contrastive loss.\nIn this way, a backbone network learns a representation space that aligns with\nthe clinical data distribution available. Afterwards, we fine-tune the network\ntrained in this manner with the smaller amount of biomarker labeled data with a\ncross-entropy loss in order to classify these key indicators of disease\ndirectly from OCT scans. Our method is shown to outperform state of the art\nself-supervised methods by as much as 5% in terms of accuracy on individual\nbiomarker detection.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2209.11195\n",
    "authors": [
      "Kiran Kokilepersaud",
      "Mohit Prabhushankar",
      "Ghassan AlRegib"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.05092"
  },
  {
    "id": "arXiv:2211.05094",
    "title": "3D Scene Inference from Transient Histograms",
    "abstract": "Time-resolved image sensors that capture light at pico-to-nanosecond\ntimescales were once limited to niche applications but are now rapidly becoming\nmainstream in consumer devices. We propose low-cost and low-power imaging\nmodalities that capture scene information from minimal time-resolved image\nsensors with as few as one pixel. The key idea is to flood illuminate large\nscene patches (or the entire scene) with a pulsed light source and measure the\ntime-resolved reflected light by integrating over the entire illuminated area.\nThe one-dimensional measured temporal waveform, called \\emph{transient},\nencodes both distances and albedoes at all visible scene points and as such is\nan aggregate proxy for the scene's 3D geometry. We explore the viability and\nlimitations of the transient waveforms by themselves for recovering scene\ninformation, and also when combined with traditional RGB cameras. We show that\nplane estimation can be performed from a single transient and that using only a\nfew more it is possible to recover a depth map of the whole scene. We also show\ntwo proof-of-concept hardware prototypes that demonstrate the feasibility of\nour approach for compact, mobile, and budget-limited applications.",
    "descriptor": "",
    "authors": [
      "Sacha Jungerman",
      "Atul Ingle",
      "Yin Li",
      "Mohit Gupta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.05094"
  },
  {
    "id": "arXiv:2211.05100",
    "title": "BLOOM: A 176B-Parameter Open-Access Multilingual Language Model",
    "abstract": "Large language models (LLMs) have been shown to be able to perform new tasks\nbased on a few demonstrations or natural language instructions. While these\ncapabilities have led to widespread adoption, most LLMs are developed by\nresource-rich organizations and are frequently kept from the public. As a step\ntowards democratizing this powerful technology, we present BLOOM, a\n176B-parameter open-access language model designed and built thanks to a\ncollaboration of hundreds of researchers. BLOOM is a decoder-only Transformer\nlanguage model that was trained on the ROOTS corpus, a dataset comprising\nhundreds of sources in 46 natural and 13 programming languages (59 in total).\nWe find that BLOOM achieves competitive performance on a wide variety of\nbenchmarks, with stronger results after undergoing multitask prompted\nfinetuning. To facilitate future research and applications using LLMs, we\npublicly release our models and code under the Responsible AI License.",
    "descriptor": "",
    "authors": [
      "Teven Le Scao",
      "Angela Fan",
      "Christopher Akiki",
      "Ellie Pavlick",
      "Suzana Ili\u0107",
      "Daniel Hesslow",
      "Roman Castagn\u00e9",
      "Alexandra Sasha Luccioni",
      "Fran\u00e7ois Yvon",
      "Matthias Gall\u00e9",
      "Jonathan Tow",
      "Alexander M. Rush",
      "Stella Biderman",
      "Albert Webson",
      "Pawan Sasanka Ammanamanchi",
      "Thomas Wang",
      "Beno\u00eet Sagot",
      "Niklas Muennighoff",
      "Albert Villanova del Moral",
      "Olatunji Ruwase",
      "Rachel Bawden",
      "Stas Bekman",
      "Angelina McMillan-Major",
      "Iz Beltagy",
      "Huu Nguyen",
      "Lucile Saulnier",
      "Samson Tan",
      "Pedro Ortiz Suarez",
      "Victor Sanh",
      "Hugo Lauren\u00e7on",
      "Yacine Jernite",
      "Julien Launay",
      "Margaret Mitchell",
      "Colin Raffel",
      "Aaron Gokaslan",
      "Adi Simhi",
      "Aitor Soroa",
      "Alham Fikri Aji",
      "Amit Alfassy",
      "Anna Rogers",
      "Ariel Kreisberg Nitzav",
      "Canwen Xu",
      "Chenghao Mou",
      "Chris Emezue",
      "Christopher Klamm",
      "Colin Leong",
      "Daniel van Strien",
      "David Ifeoluwa Adelani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05100"
  },
  {
    "id": "arXiv:2211.05102",
    "title": "Efficiently Scaling Transformer Inference",
    "abstract": "We study the problem of efficient generative inference for Transformer\nmodels, in one of its most challenging settings: large deep models, with tight\nlatency targets and long sequence lengths. Better understanding of the\nengineering tradeoffs for inference for large Transformer-based models is\nimportant as use cases of these models are growing rapidly throughout\napplication areas. We develop a simple analytical model for inference\nefficiency to select the best multi-dimensional partitioning techniques\noptimized for TPU v4 slices based on the application requirements. We combine\nthese with a suite of low-level optimizations to achieve a new Pareto frontier\non the latency and model FLOPS utilization (MFU) tradeoffs on 500B+ parameter\nmodels that outperforms the FasterTransformer suite of benchmarks. We further\nshow that with appropriate partitioning, the lower memory requirements of\nmultiquery attention (i.e. multiple query heads share single key/value head)\nenables scaling up to 32x larger context lengths. Finally, we achieve a\nlow-batch-size latency of 29ms per token during generation (using int8 weight\nquantization) and a 76% MFU during large-batch-size processing of input tokens,\nwhile supporting a long 2048-token context length on the PaLM 540B parameter\nmodel.",
    "descriptor": "",
    "authors": [
      "Reiner Pope",
      "Sholto Douglas",
      "Aakanksha Chowdhery",
      "Jacob Devlin",
      "James Bradbury",
      "Anselm Levskaya",
      "Jonathan Heek",
      "Kefan Xiao",
      "Shivani Agrawal",
      "Jeff Dean"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.05102"
  },
  {
    "id": "arXiv:2211.05105",
    "title": "Safe Latent Diffusion: Mitigating Inappropriate Degeneration in  Diffusion Models",
    "abstract": "Text-conditioned image generation models have recently achieved astonishing\nresults in image quality and text alignment and are consequently employed in a\nfast-growing number of applications. Since they are highly data-driven, relying\non billion-sized datasets randomly scraped from the internet, they also suffer,\nas we demonstrate, from degenerated and biased human behavior. In turn, they\nmay even reinforce such biases. To help combat these undesired side effects, we\npresent safe latent diffusion (SLD). Specifically, to measure the inappropriate\ndegeneration due to unfiltered and imbalanced training sets, we establish a\nnovel image generation test bed-inappropriate image prompts (I2P)-containing\ndedicated, real-world image-to-text prompts covering concepts such as nudity\nand violence. As our exhaustive empirical evaluation demonstrates, the\nintroduced SLD removes and suppresses inappropriate image parts during the\ndiffusion process, with no additional training required and no adverse effect\non overall image quality or text alignment.",
    "descriptor": "",
    "authors": [
      "Patrick Schramowski",
      "Manuel Brack",
      "Bj\u00f6rn Deiseroth",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05105"
  },
  {
    "id": "arXiv:2211.05109",
    "title": "ViTALiTy: Unifying Low-rank and Sparse Approximation for Vision  Transformer Acceleration with a Linear Taylor Attention",
    "abstract": "Vision Transformer (ViT) has emerged as a competitive alternative to\nconvolutional neural networks for various computer vision applications.\nSpecifically, ViT multi-head attention layers make it possible to embed\ninformation globally across the overall image. Nevertheless, computing and\nstoring such attention matrices incurs a quadratic cost dependency on the\nnumber of patches, limiting its achievable efficiency and scalability and\nprohibiting more extensive real-world ViT applications on resource-constrained\ndevices. Sparse attention has been shown to be a promising direction for\nimproving hardware acceleration efficiency for NLP models. However, a\nsystematic counterpart approach is still missing for accelerating ViT models.\nTo close the above gap, we propose a first-of-its-kind algorithm-hardware\ncodesigned framework, dubbed ViTALiTy, for boosting the inference efficiency of\nViTs. Unlike sparsity-based Transformer accelerators for NLP, ViTALiTy unifies\nboth low-rank and sparse components of the attention in ViTs. At the algorithm\nlevel, we approximate the dot-product softmax operation via first-order Taylor\nattention with row-mean centering as the low-rank component to linearize the\ncost of attention blocks and further boost the accuracy by incorporating a\nsparsity-based regularization. At the hardware level, we develop a dedicated\naccelerator to better leverage the resulting workload and pipeline from\nViTALiTy's linear Taylor attention which requires the execution of only the\nlow-rank component, to further boost the hardware efficiency. Extensive\nexperiments and ablation studies validate that ViTALiTy offers boosted\nend-to-end efficiency (e.g., $3\\times$ faster and $3\\times$ energy-efficient)\nunder comparable accuracy, with respect to the state-of-the-art solution.",
    "descriptor": "\nComments: 14 pages, 15 figures, Accepted to IEEE HPCA 2023\n",
    "authors": [
      "Jyotikrishna Dass",
      "Shang Wu",
      "Huihong Shi",
      "Chaojian Li",
      "Zhifan Ye",
      "Zhongfeng Wang",
      "Yingyan Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05109"
  },
  {
    "id": "arXiv:2211.05110",
    "title": "Large Language Models with Controllable Working Memory",
    "abstract": "Large language models (LLMs) have led to a series of breakthroughs in natural\nlanguage processing (NLP), owing to their excellent understanding and\ngeneration abilities. Remarkably, what further sets these models apart is the\nmassive amounts of world knowledge they internalize during pretraining. While\nmany downstream applications provide the model with an informational context to\naid its performance on the underlying task, how the model's world knowledge\ninteracts with the factual information presented in the context remains under\nexplored. As a desirable behavior, an LLM should give precedence to the context\nwhenever it contains task-relevant information that conflicts with the model's\nmemorized knowledge. This enables model predictions to be grounded in the\ncontext, which can then be used to update or correct specific model predictions\nwithout frequent retraining. By contrast, when the context is irrelevant to the\ntask, the model should ignore it and fall back on its internal knowledge. In\nthis paper, we undertake a first joint study of the aforementioned two\nproperties, namely controllability and robustness, in the context of LLMs. We\ndemonstrate that state-of-the-art T5 and PaLM (both pretrained and finetuned)\ncould exhibit poor controllability and robustness, which do not scale with\nincreasing model size. As a solution, we propose a novel method - Knowledge\nAware FineTuning (KAFT) - to strengthen both controllability and robustness by\nincorporating counterfactual and irrelevant contexts to standard supervised\ndatasets. Our comprehensive evaluation showcases the utility of KAFT across\nmodel architectures and sizes.",
    "descriptor": "",
    "authors": [
      "Daliang Li",
      "Ankit Singh Rawat",
      "Manzil Zaheer",
      "Xin Wang",
      "Michal Lukasik",
      "Andreas Veit",
      "Felix Yu",
      "Sanjiv Kumar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05110"
  },
  {
    "id": "arXiv:2211.05116",
    "title": "A Note on Task-Aware Loss via Reweighing Prediction Loss by  Decision-Regret",
    "abstract": "In this short technical note we propose a baseline for decision-aware\nlearning for contextual linear optimization, which solves stochastic linear\noptimization when cost coefficients can be predicted based on context\ninformation. We propose a decision-aware version of predict-then-optimize. We\nreweigh the prediction error by the decision regret incurred by an (unweighted)\npilot estimator of costs to obtain a decision-aware predictor, then optimize\nwith cost predictions from the decision-aware predictor. This method can be\nmotivated as a finite-difference, iterate-independent approximation of the\ngradients of previously proposed end-to-end learning algorithms; it is also\nconsistent with previously suggested intuition for end-to-end learning. This\nbaseline is computationally easy to implement with readily available reweighted\nprediction oracles and linear optimization, and can be implemented with convex\noptimization so long as the prediction error minimization is convex.\nEmpirically, we demonstrate that this approach can lead to improvements over a\n\"predict-then-optimize\" framework for settings with misspecified models, and is\ncompetitive with other end-to-end approaches. Therefore, due to its simplicity\nand ease of use, we suggest it as a simple baseline for end-to-end and\ndecision-aware learning.",
    "descriptor": "\nComments: Technical note\n",
    "authors": [
      "Connor Lawless",
      "Angela Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.05116"
  },
  {
    "id": "arXiv:2105.03668",
    "title": "Real-Time Prediction of Probabilistic Crack Growth with a Helicopter  Component Digital Twin",
    "abstract": "To deploy the airframe digital twin or to conduct probabilistic evaluations\nof the remaining life of a structural component, a (near) real-time\ncrack-growth simulation method is critical. In this paper, a reduced-order\nsimulation approach is developed to achieve this goal by leveraging two\nmethods. On the one hand, the symmetric Galerkin boundary element method -\nfinite element method (SGBEM-FEM) coupling method is combined with parametric\nmodeling to generate the database of computed stress intensity factors for\ncracks with various sizes/shapes in a complex structural component, by which\nhundreds of samples are automatically simulated within a day. On the other\nhand, machine learning methods are applied to establish the relation between\ncrack sizes/shapes and crack-front stress intensity factors. By combining the\nreduced-order computational model with load inputs and fatigue growth laws, a\nreal-time prediction of probabilistic crack growth in complex structures with\nminimum computational burden is realized. In an example of a round-robin\nhelicopter component, even though the fatigue crack growth is simulated cycle\nby cycle, the simulation is faster than real-time (as compared with the\nphysical test). The proposed approach is a key simulation technology toward\nrealizing the digital twin of complex structures, which further requires fusion\nof model predictions with flight/inspection/monitoring data.",
    "descriptor": "\nComments: 29 pages, 15 figures\n",
    "authors": [
      "Xuan Zhou",
      "Shuangxin He",
      "Leiting Dong",
      "Satya N. Atluri"
    ],
    "subjectives": [
      "Applied Physics (physics.app-ph)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2105.03668"
  },
  {
    "id": "arXiv:2211.04468",
    "title": "An efficient graph generative model for navigating ultra-large  combinatorial synthesis libraries",
    "abstract": "Virtual, make-on-demand chemical libraries have transformed early-stage drug\ndiscovery by unlocking vast, synthetically accessible regions of chemical\nspace. Recent years have witnessed rapid growth in these libraries from\nmillions to trillions of compounds, hiding undiscovered, potent hits for a\nvariety of therapeutic targets. However, they are quickly approaching a size\nbeyond that which permits explicit enumeration, presenting new challenges for\nvirtual screening. To overcome these challenges, we propose the Combinatorial\nSynthesis Library Variational Auto-Encoder (CSLVAE). The proposed generative\nmodel represents such libraries as a differentiable, hierarchically-organized\ndatabase. Given a compound from the library, the molecular encoder constructs a\nquery for retrieval, which is utilized by the molecular decoder to reconstruct\nthe compound by first decoding its chemical reaction and subsequently decoding\nits reactants. Our design minimizes autoregression in the decoder, facilitating\nthe generation of large, valid molecular graphs. Our method performs fast and\nparallel batch inference for ultra-large synthesis libraries, enabling a number\nof important applications in early-stage drug discovery. Compounds proposed by\nour method are guaranteed to be in the library, and thus synthetically and\ncost-effectively accessible. Importantly, CSLVAE can encode out-of-library\ncompounds and search for in-library analogues. In experiments, we demonstrate\nthe capabilities of the proposed method in the navigation of massive\ncombinatorial synthesis libraries.",
    "descriptor": "\nComments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Aryan Pedawi",
      "Pawel Gniewek",
      "Chaoyi Chang",
      "Brandon M. Anderson",
      "Henry van den Bedem"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.04468"
  },
  {
    "id": "arXiv:2211.04507",
    "title": "Differentiable Quantum Programming with Unbounded Loops",
    "abstract": "The emergence of variational quantum applications has led to the development\nof automatic differentiation techniques in quantum computing. Recently, Zhu et\nal. (PLDI 2020) have formulated differentiable quantum programming with bounded\nloops, providing a framework for scalable gradient calculation by quantum means\nfor training quantum variational applications. However, promising parameterized\nquantum applications, e.g., quantum walk and unitary implementation, cannot be\ntrained in the existing framework due to the natural involvement of unbounded\nloops. To fill in the gap, we provide the first differentiable quantum\nprogramming framework with unbounded loops, including a newly designed\ndifferentiation rule, code transformation, and their correctness proof.\nTechnically, we introduce a randomized estimator for derivatives to deal with\nthe infinite sum in the differentiation of unbounded loops, whose applicability\nin classical and probabilistic programming is also discussed. We implement our\nframework with Python and Q#, and demonstrate a reasonable sample efficiency.\nThrough extensive case studies, we showcase an exciting application of our\nframework in automatically identifying close-to-optimal parameters for several\nparameterized quantum applications.",
    "descriptor": "\nComments: Codes are available at this https URL\n",
    "authors": [
      "Wang Fang",
      "Mingsheng Ying",
      "Xiaodi Wu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.04507"
  },
  {
    "id": "arXiv:2211.04527",
    "title": "Bounds on the differential uniformity of the Wan-Lidl polynomials",
    "abstract": "We study the differential uniformity of the Wan-Lidl polynomials over finite\nfields. A general upper bound, independent of the order of the field, is\nestablished. Additional bounds are established in settings where one of the\nparameters is restricted. In particular, we establish a class of permutation\npolynomials which have differential uniformity at most 5 over fields of order\n$3\\bmod 4$, irrespective of the field size. Computational results are also\ngiven.",
    "descriptor": "",
    "authors": [
      "Li-An Chen",
      "Robert S. Coulter"
    ],
    "subjectives": [
      "Number Theory (math.NT)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.04527"
  },
  {
    "id": "arXiv:2211.04540",
    "title": "Millimeter-Wave Radar Beamforming with Spatial Path Index Modulation  Communications",
    "abstract": "To efficiently utilize the wireless spectrum and save hardware costs, the\nfifth generation and beyond (B5G) wireless networks envisage integrated sensing\nand communications (ISAC) paradigms to jointly access the spectrum. In B5G\nsystems, the expensive hardware is usually avoided by employing hybrid\nbeamformers that employ fewer radio-frequency chains but at the cost of the\nmultiplexing gain. Recently, it has been proposed to overcome this shortcoming\nof millimeter wave (mmWave) hybrid beamformers through spatial path index\nmodulation (SPIM), which modulates the spatial paths between the base station\nand users and improves spectral efficiency. In this paper, we propose an\nSPIM-ISAC approach for hybrid beamforming to simultaneously generate beams\ntoward both radar targets and communications users. We introduce a low\ncomplexity approach for the design of hybrid beamformers, which include\nradar-only and communications-only beamformers. Numerical experiments\ndemonstrate that our SPIM-ISAC approach exhibits a significant performance\nimprovement over the conventional mmWave-ISAC design in terms of spectral\nefficiency and the generated beampattern.",
    "descriptor": "\nComments: 6pages4figures, Submitted to IEEE\n",
    "authors": [
      "Ahmet M. Elbir",
      "Kumar Vijay Mishra",
      "Abdulkadir \u00c7elik",
      "Ahmed M. Eltawil"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.04540"
  },
  {
    "id": "arXiv:2211.04561",
    "title": "A physics-aware deep learning model for energy localization in  multiscale shock-to-detonation simulations of heterogeneous energetic  materials",
    "abstract": "Predictive simulations of the shock-to-detonation transition (SDT) in\nheterogeneous energetic materials (EM) are vital to the design and control of\ntheir energy release and sensitivity. Due to the complexity of the\nthermo-mechanics of EM during the SDT, both macro-scale response and sub-grid\nmesoscale energy localization must be captured accurately. This work proposes\nan efficient and accurate multiscale framework for SDT simulations of EM. We\nemploy deep learning to model the mesoscale energy localization of\nshock-initiated EM microstructures upon which prediction results are used to\nsupply reaction progress rate information to the macroscale SDT simulation. The\nproposed multiscale modeling framework is divided into two stages. First, a\nphysics-aware recurrent convolutional neural network (PARC) is used to model\nthe mesoscale energy localization of shock-initiated heterogeneous EM\nmicrostructures. PARC is trained using direct numerical simulations (DNS) of\nhotspot ignition and growth within microstructures of pressed HMX material\nsubjected to different input shock strengths. After training, PARC is employed\nto supply hotspot ignition and growth rates for macroscale SDT simulations. We\nshow that PARC can play the role of a surrogate model in a multiscale\nsimulation framework, while drastically reducing the computation cost and\nproviding improved representations of the sub-grid physics. The proposed\nmultiscale modeling approach will provide a new tool for material scientists in\ndesigning high-performance and safer energetic materials.",
    "descriptor": "",
    "authors": [
      "Phong C.H. Nguyen",
      "Yen-Thi Nguyen",
      "Pradeep K. Seshadri",
      "Joseph B. Choi",
      "H.S. Udaykumar",
      "Stephen Baek"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04561"
  },
  {
    "id": "arXiv:2211.04568",
    "title": "Towards Algorithmic Fairness in Space-Time: Filling in Black Holes",
    "abstract": "New technologies and the availability of geospatial data have drawn attention\nto spatio-temporal biases present in society. For example: the COVID-19\npandemic highlighted disparities in the availability of broadband service and\nits role in the digital divide; the environmental justice movement in the\nUnited States has raised awareness to health implications for minority\npopulations stemming from historical redlining practices; and studies have\nfound varying quality and coverage in the collection and sharing of open-source\ngeospatial data. Despite the extensive literature on machine learning (ML)\nfairness, few algorithmic strategies have been proposed to mitigate such\nbiases. In this paper we highlight the unique challenges for quantifying and\naddressing spatio-temporal biases, through the lens of use cases presented in\nthe scientific literature and media. We envision a roadmap of ML strategies\nthat need to be developed or adapted to quantify and overcome these challenges\n-- including transfer learning, active learning, and reinforcement learning\ntechniques. Further, we discuss the potential role of ML in providing guidance\nto policy makers on issues related to spatial fairness.",
    "descriptor": "",
    "authors": [
      "Cheryl Flynn",
      "Aritra Guha",
      "Subhabrata Majumdar",
      "Divesh Srivastava",
      "Zhengyi Zhou"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04568"
  },
  {
    "id": "arXiv:2211.04573",
    "title": "Classification of Colorectal Cancer Polyps via Transfer Learning and  Vision-Based Tactile Sensing",
    "abstract": "In this study, to address the current high earlydetection miss rate of\ncolorectal cancer (CRC) polyps, we explore the potentials of utilizing transfer\nlearning and machine learning (ML) classifiers to precisely and sensitively\nclassify the type of CRC polyps. Instead of using the common colonoscopic\nimages, we applied three different ML algorithms on the 3D textural image\noutputs of a unique vision-based surface tactile sensor (VS-TS). To collect\nrealistic textural images of CRC polyps for training the utilized ML\nclassifiers and evaluating their performance, we first designed and additively\nmanufactured 48 types of realistic polyp phantoms with different hardness,\ntype, and textures. Next, the performance of the used three ML algorithms in\nclassifying the type of fabricated polyps was quantitatively evaluated using\nvarious statistical metrics.",
    "descriptor": "\nComments: Accepted to IEEE Sensors 2022 Conference\n",
    "authors": [
      "Nethra Venkatayogi",
      "Ozdemir Can Kara",
      "Jeff Bonyun",
      "Naruhiko Ikoma",
      "Farshid Alambeigi"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.04573"
  },
  {
    "id": "arXiv:2211.04594",
    "title": "A Framework for Decentralised Resolvent Splitting",
    "abstract": "Decentralised optimisation is typically concerned with problems having\nobjective functions with finite-sum structure that are distributed over a\nnetwork. Although there are several decentralised algorithms in the literature\nfor solving minimisations problems with the aforementioned form, relatively few\nof these generalise to the abstraction of monotone inclusions. In this work, we\naddress this by developing a new framework for decentralised resolvent\nsplitting for finding a zero in the sum of finitely many set-valued monotone\noperators over regular networks. Our framework also simplifies and extends\nnon-decentralised splitting algorithms in the literature.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Matthew K. Tam"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.04594"
  },
  {
    "id": "arXiv:2211.04610",
    "title": "PhaseAug: A Differentiable Augmentation for Speech Synthesis to Simulate  One-to-Many Mapping",
    "abstract": "Previous generative adversarial network (GAN)-based neural vocoders are\ntrained to reconstruct the exact ground truth waveform from the paired\nmel-spectrogram and do not consider the one-to-many relationship of speech\nsynthesis. This conventional training causes overfitting for both the\ndiscriminators and the generator, leading to the periodicity artifacts in the\ngenerated audio signal. In this work, we present PhaseAug, the first\ndifferentiable augmentation for speech synthesis that rotates the phase of each\nfrequency bin to simulate one-to-many mapping. With our proposed method, we\noutperform baselines without any architecture modification. Code and audio\nsamples will be available at https://github.com/mindslab-ai/phaseaug.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Junhyeok Lee",
      "Seungu Han",
      "Hyunjae Cho",
      "Wonbin Jung"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.04610"
  },
  {
    "id": "arXiv:2211.04628",
    "title": "MP-SeizNet: A Multi-Path CNN Bi-LSTM Network for Seizure-Type  Classification Using EEG",
    "abstract": "Seizure type identification is essential for the treatment and management of\nepileptic patients. However, it is a difficult process known to be time\nconsuming and labor intensive. Automated diagnosis systems, with the\nadvancement of machine learning algorithms, have the potential to accelerate\nthe classification process, alert patients, and support physicians in making\nquick and accurate decisions. In this paper, we present a novel multi-path\nseizure-type classification deep learning network (MP-SeizNet), consisting of a\nconvolutional neural network (CNN) and a bidirectional long short-term memory\nneural network (Bi-LSTM) with an attention mechanism. The objective of this\nstudy was to classify specific types of seizures, including complex partial,\nsimple partial, absence, tonic, and tonic-clonic seizures, using only\nelectroencephalogram (EEG) data. The EEG data is fed to our proposed model in\ntwo different representations. The CNN was fed with wavelet-based features\nextracted from the EEG signals, while the Bi-LSTM was fed with raw EEG signals\nto let our MP-SeizNet jointly learns from different representations of seizure\ndata for more accurate information learning. The proposed MP-SeizNet was\nevaluated using the largest available EEG epilepsy database, the Temple\nUniversity Hospital EEG Seizure Corpus, TUSZ v1.5.2. We evaluated our proposed\nmodel across different patient data using three-fold cross-validation and\nacross seizure data using five-fold cross-validation, achieving F1 scores of\n87.6% and 98.1%, respectively.",
    "descriptor": "",
    "authors": [
      "Hezam Albaqami",
      "Ghulam Mubashar Hassan",
      "Amitava Datta"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04628"
  },
  {
    "id": "arXiv:2211.04631",
    "title": "Maximum likelihood recursive state estimation in state-space models: A  new approach based on statistical analysis of incomplete data",
    "abstract": "This paper revisits the work of Rauch et al. (1965) and develops a novel\nmethod for recursive maximum likelihood particle filtering for general\nstate-space models. The new method is based on statistical analysis of\nincomplete observations of the systems. Score function and conditional observed\ninformation of the incomplete observations/data are introduced and their\ndistributional properties are discussed. Some identities concerning the score\nfunction and information matrices of the incomplete data are derived. Maximum\nlikelihood estimation of state-vector is presented in terms of the score\nfunction and observed information matrices. In particular, to deal with\nnonlinear state-space, a sequential Monte Carlo method is developed. It is\ngiven recursively by an EM-gradient-particle filtering which extends the work\nof Lange (1995) for state estimation. To derive covariance matrix of\nstate-estimation errors, an explicit form of observed information matrix is\nproposed. It extends Louis (1982) general formula for the same matrix to\nstate-vector estimation. Under (Neumann) boundary conditions of state\ntransition probability distribution, the inverse of this matrix coincides with\nthe Cramer-Rao lower bound on the covariance matrix of estimation errors of\nunbiased state-estimator. In the case of linear models, the method shows that\nthe Kalman filter is a fully efficient state estimator whose covariance matrix\nof estimation error coincides with the Cramer-Rao lower bound. Some numerical\nexamples are discussed to exemplify the main results.",
    "descriptor": "\nComments: 24 pages, 4 Figures\n",
    "authors": [
      "Budhi Arta Surya"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Information Theory (cs.IT)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.04631"
  },
  {
    "id": "arXiv:2211.04637",
    "title": "Quantum Search Algorithm for Binary Constant Weight Codes",
    "abstract": "A binary constant weight code is a type of error-correcting code with a wide\nrange of applications. The problem of finding a binary constant weight code has\nlong been studied as a combinatorial optimization problem in coding theory. In\nthis paper, we propose a quantum search algorithm for binary constant weight\ncodes. Specifically, the search problem is newly formulated as a quadratic\nunconstrained binary optimization (QUBO) and Grover adaptive search (GAS) is\nused for providing the quadratic speedup. Focusing on the inherent structure of\nthe problem, we derive an upper bound on the minimum of the objective function\nvalue and a lower bound on the exact number of solutions. In our algebraic\nanalysis, it was found that this proposed algorithm is capable of reducing the\nnumber of required qubits, thus enhancing the feasibility. Additionally, our\nsimulations demonstrated that it reduces the query complexities by 63% in the\nclassical domain and 31% in the quantum domain. The proposed approach may be\nuseful for other quantum search algorithms and optimization problems.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Kein Yukiyoshi",
      "Naoki Ishikawa"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.04637"
  },
  {
    "id": "arXiv:2211.04649",
    "title": "Gold-standard of HER2 breast cancer biopsies using supervised learning  based on multiple pathologist annotations",
    "abstract": "Breast cancer is one of the most common cancer in women around the world. For\ndiagnosis, pathologists evaluate biomarkers such as HER2 protein using\nimmunohistochemistry over tissue extracted by a biopsy. Through microscopic\ninspection, this assessment estimates the intensity and integrity of the\nmembrane cells' staining and scores the sample as 0, 1+, 2+, or 3+: a\nsubjective decision that depends on the interpretation of the pathologist. This\npaper presents the preliminary data analysis of the annotations of three\npathologists over the same set of samples obtained using 20x magnification and\nincluding $1,252$ non-overlapping biopsy patches. We evaluate the intra- and\ninter-expert variability achieving substantial and moderate agreement,\nrespectively, according to Fleiss' Kappa coefficient, as a previous stage\ntowards a generation of a HER2 breast cancer biopsy gold-standard using\nsupervised learning from multiple pathologist annotations.",
    "descriptor": "",
    "authors": [
      "Benjam\u00edn Hern\u00e1ndez",
      "Violeta Chang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04649"
  },
  {
    "id": "arXiv:2211.04655",
    "title": "Variants of SGD for Lipschitz Continuous Loss Functions in Low-Precision  Environments",
    "abstract": "Motivated by neural network training in low-bit floating and fixed-point\nenvironments, this work studies the convergence of variants of SGD with\ncomputational error. Considering a general stochastic Lipschitz continuous loss\nfunction, a novel convergence result to a Clarke stationary point is presented\nassuming that only an approximation of its stochastic gradient can be computed\nas well as error in computing the SGD step itself. Different variants of SGD\nare then tested empirically in a variety of low-precision arithmetic\nenvironments, with improved test set accuracy achieved compared to SGD for two\nimage recognition tasks.",
    "descriptor": "",
    "authors": [
      "Michael R. Metel"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04655"
  },
  {
    "id": "arXiv:2211.04675",
    "title": "Combination of multiple neural networks using transfer learning and  extensive geometric data augmentation for assessing cellularity scores in  histopathology images",
    "abstract": "Classification of cancer cellularity within tissue samples is currently a\nmanual process performed by pathologists. This process of correctly determining\ncancer cellularity can be time intensive. Deep Learning (DL) techniques in\nparticular have become increasingly more popular for this purpose, due to the\naccuracy and performance they exhibit, which can be comparable to the\npathologists. This work investigates the capabilities of two DL approaches to\nassess cancer cellularity in whole slide images (WSI) in the SPIE-AAPM-NCI\nBreastPathQ challenge dataset. The effects of training on augmented data via\nrotations, and combinations of multiple architectures into a single network\nwere analyzed using a modified Kendall Tau-b prediction probability metric\nknown as the average prediction probability PK. A deep, transfer learned,\nConvolutional Neural Network (CNN) InceptionV3 was used as a baseline,\nachieving an average PK value of 0.884, showing improvement from the average PK\nvalue of 0.83 achieved by pathologists. The network was then trained on\nadditional training datasets which were rotated between 1 and 360 degrees,\nwhich saw a peak increase of PK up to 4.2%. An additional architecture\nconsisting of the InceptionV3 network and VGG16, a shallow, transfer learned\nCNN, was combined in a parallel architecture. This parallel architecture\nachieved a baseline average PK value of 0.907, a statistically significantly\nimprovement over either of the architectures' performances separately (p<0.0001\nby unpaired t-test).",
    "descriptor": "\nComments: 7 pages (includes a cover page), 5 figures, 1 table, work addresses the BreastPathQ challenge\n",
    "authors": [
      "Jacob D. Beckmann",
      "Kosta Popovic"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.04675"
  },
  {
    "id": "arXiv:2211.04702",
    "title": "A survey of some recent developments in measures of association",
    "abstract": "This paper surveys some recent developments in measures of association\nrelated to a new coefficient of correlation introduced by the author. A\nstraightforward extension of this coefficient to standard Borel spaces (which\nincludes all Polish spaces), overlooked in the literature so far, is proposed\nat the end of the survey.",
    "descriptor": "\nComments: 22 pages\n",
    "authors": [
      "Sourav Chatterjee"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.04702"
  },
  {
    "id": "arXiv:2211.04703",
    "title": "Automated MRI Field of View Prescription from Region of Interest  Prediction by Intra-stack Attention Neural Network",
    "abstract": "Manual prescription of the field of view (FOV) by MRI technologists is\nvariable and prolongs the scanning process. Often, the FOV is too large or\ncrops critical anatomy. We propose a deep-learning framework, trained by\nradiologists' supervision, for automating FOV prescription. An intra-stack\nshared feature extraction network and an attention network are used to process\na stack of 2D image inputs to generate output scalars defining the location of\na rectangular region of interest (ROI). The attention mechanism is used to make\nthe model focus on the small number of informative slices in a stack. Then the\nsmallest FOV that makes the neural network predicted ROI free of aliasing is\ncalculated by an algebraic operation derived from MR sampling theory. We\nretrospectively collected 595 cases between February 2018 and February 2022.\nThe framework's performance is examined quantitatively with intersection over\nunion (IoU) and pixel error on position, and qualitatively with a reader study.\nWe use the t-test for comparing quantitative results from all models and a\nradiologist. The proposed model achieves an average IoU of 0.867 and average\nROI position error of 9.06 out of 512 pixels on 80 test cases, significantly\nbetter (P<0.05) than two baseline models and not significantly different from a\nradiologist (P>0.12). Finally, the FOV given by the proposed framework achieves\nan acceptance rate of 92% from an experienced radiologist.",
    "descriptor": "",
    "authors": [
      "Ke Lei",
      "Ali B. Syed",
      "Xucheng Zhu",
      "John M. Pauly",
      "Shreyas S. Vasanawala"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04703"
  },
  {
    "id": "arXiv:2211.04710",
    "title": "Expressive-VC: Highly Expressive Voice Conversion with Attention Fusion  of Bottleneck and Perturbation Features",
    "abstract": "Voice conversion for highly expressive speech is challenging. Current\napproaches struggle with the balancing between speaker similarity,\nintelligibility and expressiveness. To address this problem, we propose\nExpressive-VC, a novel end-to-end voice conversion framework that leverages\nadvantages from both neural bottleneck feature (BNF) approach and information\nperturbation approach. Specifically, we use a BNF encoder and a Perturbed-Wav\nencoder to form a content extractor to learn linguistic and para-linguistic\nfeatures respectively, where BNFs come from a robust pre-trained ASR model and\nthe perturbed wave becomes speaker-irrelevant after signal perturbation. We\nfurther fuse the linguistic and para-linguistic features through an attention\nmechanism, where speaker-dependent prosody features are adopted as the\nattention query, which result from a prosody encoder with target speaker\nembedding and normalized pitch and energy of source speech as input. Finally\nthe decoder consumes the integrated features and the speaker-dependent prosody\nfeature to generate the converted speech. Experiments demonstrate that\nExpressive-VC is superior to several state-of-the-art systems, achieving both\nhigh expressiveness captured from the source speech and high speaker similarity\nwith the target speaker; meanwhile intelligibility is well maintained.",
    "descriptor": "",
    "authors": [
      "Ziqian Ning",
      "Qicong Xie",
      "Pengcheng Zhu",
      "Zhichao Wang",
      "Liumeng Xue",
      "Jixun Yao",
      "Lei Xie",
      "Mengxiao Bi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.04710"
  },
  {
    "id": "arXiv:2211.04732",
    "title": "Directed Acyclic Outerplanar Graphs Have Constant Stack Number",
    "abstract": "The stack number of a directed acyclic graph $G$ is the minimum $k$ for which\nthere is a topological ordering of $G$ and a $k$-coloring of the edges such\nthat no two edges of the same color cross, i.e., have alternating endpoints\nalong the topological ordering. We prove that the stack number of directed\nacyclic outerplanar graphs is bounded by a constant, which gives a positive\nanswer to a conjecture by Heath, Pemmaraju and Trenk [SIAM J. Computing, 1999].\nAs an immediate consequence, this shows that all upward outerplanar graphs have\nconstant stack number, answering a question by Bhore et al. [GD 2021] and\nthereby making significant progress towards the problem for general upward\nplanar graphs originating from Nowakowski and Parker [Order, 1989]. As our main\ntool we develop the novel technique of directed $H$-partitions, which might be\nof independent interest. We complement the bounded stack number for directed\nacyclic outerplanar graphs by constructing a family of directed acyclic 2-trees\nthat have unbounded stack number, thereby refuting a conjecture by N\\\"ollenburg\nand Pupyrev [arXiv:2107.13658, 2021].",
    "descriptor": "",
    "authors": [
      "Paul Jungeblut",
      "Laura Merker",
      "Torsten Ueckerdt"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.04732"
  },
  {
    "id": "arXiv:2211.04756",
    "title": "Spiking Neural Network Decision Feedback Equalization",
    "abstract": "In the past years, artificial neural networks (ANNs) have become the de-facto\nstandard to solve tasks in communications engineering that are difficult to\nsolve with traditional methods. In parallel, the artificial intelligence\ncommunity drives its research to biology-inspired, brain-like spiking neural\nnetworks (SNNs), which promise extremely energy-efficient computing. In this\npaper, we investigate the use of SNNs in the context of channel equalization\nfor ultra-low complexity receivers. We propose an SNN-based equalizer with a\nfeedback structure akin to the decision feedback equalizer (DFE). For\nconversion of real-world data into spike signals we introduce a novel ternary\nencoding and compare it with traditional log-scale encoding. We show that our\napproach clearly outperforms conventional linear equalizers for three different\nexemplary channels. We highlight that mainly the conversion of the channel\noutput to spikes introduces a small performance penalty. The proposed SNN with\na decision feedback structure enables the path to competitive energy-efficient\ntransceivers.",
    "descriptor": "\nComments: Submitted to SCC 2023\n",
    "authors": [
      "Eike-Manuel Bansbach",
      "Alexander von Bank",
      "Laurent Schmalen"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.04756"
  },
  {
    "id": "arXiv:2211.04764",
    "title": "Quantitative Susceptibility Mapping in Cognitive Decline: A Review of  Technical Aspects and Applications",
    "abstract": "In the human brain, essential iron molecules for proper neurological\nfunctioning exist in transferrin (tf) and ferritin (Fe3) forms. However, its\nunusual increment manifests iron overload, which reacts with hydrogen peroxide.\nThis reaction will generate hydroxyl radicals, and irons higher oxidation\nstates. Further, this reaction causes tissue damage or cognitive decline in the\nbrain and also leads to neurodegenerative diseases. The susceptibility\ndifference due to iron overload within the volume of interest (VOI) responsible\nfor field perturbation of MRI and can benefit in estimating the neural\ndisorder. The quantitative susceptibility mapping (QSM) technique can estimate\nsusceptibility alteration and assist in quantifying the local tissue\nsusceptibility differences. It has attracted many researchers and clinicians to\ndiagnose and detect neural disorders such as Parkinsons, Alzheimers, Multiple\nSclerosis, and aging. The paper presents a systematic review illustrating QSM\nfundamentals and its processing steps, including phase unwrapping, background\nfield removal, and susceptibility inversion. Using QSM, the present work\ndelivers novel predictive biomarkers for various neural disorders. It can\nstrengthen new researchers fundamental knowledge and provides insight into its\napplicability for cognitive decline disclosure. The paper discusses the future\nscope of QSM processing stages and their applications in identifying new\nbiomarkers for neural disorders.",
    "descriptor": "",
    "authors": [
      "Shradha Verma",
      "Tripti Goel",
      "M Tanveer"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04764"
  },
  {
    "id": "arXiv:2211.04768",
    "title": "Absolute decision corrupts absolutely: conservative online speaker  diarisation",
    "abstract": "Our focus lies in developing an online speaker diarisation framework which\ndemonstrates robust performance across diverse domains. In online speaker\ndiarisation, outputs generated in real-time are irreversible, and a few\nmisjudgements in the early phase of an input session can lead to catastrophic\nresults. We hypothesise that cautiously increasing the number of estimated\nspeakers is of paramount importance among many other factors. Thus, our\nproposed framework includes decreasing the number of speakers by one when the\nsystem judges that an increase in the past was faulty. We also adopt dual\nbuffers, checkpoints and centroids, where checkpoints are combined with\nsilhouette coefficients to estimate the number of speakers and centroids\nrepresent speakers. Again, we believe that more than one centroid can be\ngenerated from one speaker. Thus we design a clustering-based label matching\ntechnique to assign labels in real-time. The resulting system is lightweight\nyet surprisingly effective. The system demonstrates state-of-the-art\nperformance on DIHARD 2 and 3 datasets, where it is also competitive in AMI and\nVoxConverse test sets.",
    "descriptor": "\nComments: 5pages, 2 figure, 4 tables, submitted to ICASSP\n",
    "authors": [
      "Youngki Kwon",
      "Hee-Soo Heo",
      "Bong-Jin Lee",
      "You Jin Kim",
      "Jee-weon Jung"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.04768"
  },
  {
    "id": "arXiv:2211.04782",
    "title": "Graph and distributed extensions of the Douglas-Rachford method",
    "abstract": "In this paper, we propose several graph-based extensions of the\nDouglas-Rachford splitting (DRS) method to solve monotone inclusion problems\ninvolving the sum of $N$ maximal monotone operators. Our construction is based\non a two-layer architecture that we refer to as bilevel graphs, to which we\nassociate a generalization of the DRS algorithm that presents the prescribed\nstructure. The resulting schemes can be understood as unconditionally stable\nfrugal resolvent splitting methods with a minimal lifting in the sense of Ryu\n[Math Program 182(1):233-273, 2020], as well as instances of the (degenerate)\nPreconditioned Proximal Point method, which provides robust convergence\nguarantees. We further describe how the graph-based extensions of the DRS\nmethod can be leveraged to design new fully distributed protocols. Applications\nto a congested optimal transport problem and to distributed Support Vector\nMachines show interesting connections with the underlying graph topology and\nhighly competitive performances with state-of-the-art distributed optimization\napproaches.",
    "descriptor": "\nComments: 23 pages, 4 figures\n",
    "authors": [
      "Kristian Bredies",
      "Enis Chenchene",
      "Emanuele Naldi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.04782"
  },
  {
    "id": "arXiv:2211.04806",
    "title": "Machine-Learned Exclusion Limits without Binning",
    "abstract": "Machine-Learned Likelihoods (MLL) is a method that, by combining modern\nmachine-learning classification techniques with likelihood-based inference\ntests, allows to estimate the experimental sensitivity of high-dimensional data\nsets. We extend the MLL method by including the exclusion hypothesis tests and\nshow that the addition of Kernel Density Estimators avoids the need to bin the\nclassifier output in order to extract the resulting one-dimensional signal and\nbackground probability density functions. We first test our method on toy\nmodels generated with multivariate Gaussian distributions, where the true\nprobability distribution functions are known. We then apply it to a case of\ninterest in the search for new physics at the HL-LHC, in which a $Z^\\prime$\nboson decays into lepton pairs, comparing the performance of our method for\nestimating 95\\% CL exclusion limits to the results obtained applying a binned\nlikelihood to the machine-learning classifier output.",
    "descriptor": "\nComments: 14 pages, 3 figures. MLL+KDE code will be available from this https URL\n",
    "authors": [
      "Ernesto Arganda",
      "Andres D. Perez",
      "Martin de los Rios",
      "Rosa Mar\u00eda Sand\u00e1 Seoane"
    ],
    "subjectives": [
      "High Energy Physics - Phenomenology (hep-ph)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.04806"
  },
  {
    "id": "arXiv:2211.04807",
    "title": "A nonsmooth primal-dual method with simultaneous adaptive PDE constraint  solver",
    "abstract": "We introduce an efficient first-order primal-dual method for the solution of\nnonsmooth PDE-constrained optimization problems. We achieve this efficiency\nthrough not solving the PDE or its linearisation on each iteration of the\noptimization method. Instead, we run the method in parallel with a simple\nconventional linear system solver (Jacobi, Gauss-Seidel, conjugate gradients),\nalways taking only one step of the linear system solver for each step of the\noptimization method. The control parameter is updated on each iteration as\ndetermined by the optimization method. We prove linear convergence under a\nsecond-order growth condition, and numerically demonstrate the performance on a\nvariety of PDEs related to inverse problems involving boundary measurements.",
    "descriptor": "",
    "authors": [
      "Bj\u00f8rn Jensen",
      "Tuomo Valkonen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.04807"
  },
  {
    "id": "arXiv:2211.04825",
    "title": "Novel structural-scale uncertainty measures and error retention curves:  application to multiple sclerosis",
    "abstract": "This paper focuses on the uncertainty estimation of white matter lesions\n(WML) segmentation in magnetic resonance imaging (MRI). On one side,\nvoxel-scale segmentation errors cause the erroneous delineation of the lesions;\non the other side, lesion-scale detection errors lead to wrong lesion counts.\nBoth of these factors are clinically relevant for the assessment of multiple\nsclerosis patients. This work aims to compare the ability of different voxel-\nand lesion- scale uncertainty measures to capture errors related to\nsegmentation and lesion detection respectively. Our main contributions are (i)\nproposing new measures of lesion-scale uncertainty that do not utilise\nvoxel-scale uncertainties; (ii) extending an error retention curves analysis\nframework for evaluation of lesion-scale uncertainty measures. Our results\nobtained on the multi-center testing set of 58 patients demonstrate that the\nproposed lesion-scale measures achieves the best performance among the analysed\nmeasures. All code implementations are provided at\nhttps://github.com/NataliiaMolch/MS_WML_uncs",
    "descriptor": "\nComments: 4 pages, 2 figures, 3 tables, ISBI preprint\n",
    "authors": [
      "Nataliia Molchanova",
      "Vatsal Raina",
      "Andrey Malinin",
      "Francesco La Rosa",
      "Henning Muller",
      "Mark Gales",
      "Cristina Granziera",
      "Mara Graziani",
      "Meritxell Bach Cuadra"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04825"
  },
  {
    "id": "arXiv:2211.04847",
    "title": "Hyper-Parameter Auto-Tuning for Sparse Bayesian Learning",
    "abstract": "Choosing the values of hyper-parameters in sparse Bayesian learning (SBL) can\nsignificantly impact performance. However, the hyper-parameters are normally\ntuned manually, which is often a difficult task. Most recently, effective\nautomatic hyper-parameter tuning was achieved by using an empirical auto-tuner.\nIn this work, we address the issue of hyper-parameter auto-tuning using neural\nnetwork (NN)-based learning. Inspired by the empirical auto-tuner, we design\nand learn a NN-based auto-tuner, and show that considerable improvement in\nconvergence rate and recovery performance can be achieved.",
    "descriptor": "",
    "authors": [
      "Dawei Gao",
      "Qinghua Guo",
      "Ming Jin",
      "Guisheng Liao",
      "Yonina C. Eldar"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04847"
  },
  {
    "id": "arXiv:2211.04850",
    "title": "Final infarct prediction in acute ischemic stroke",
    "abstract": "This article focuses on the control center of each human body: the brain. We\nwill point out the pivotal role of the cerebral vasculature and how its complex\nmechanisms may vary between subjects. We then emphasize a specific acute\npathological state, i.e., acute ischemic stroke, and show how medical imaging\nand its analysis can be used to define the treatment. We show how the\ncore-penumbra concept is used in practice using mismatch criteria and how\nmachine learning can be used to make predictions of the final infarct, either\nvia deconvolution or convolutional neural networks.",
    "descriptor": "\nComments: 17 pages, 5 figures, part of PhD thesis KU Leuven 2022 \"Understanding Final Infarct Prediction in Acute Ischemic Stroke Using Convolutional Neural Networks\"\n",
    "authors": [
      "Jeroen Bertels",
      "David Robben",
      "Dirk Vandermeulen",
      "Robin Lemmens"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04850"
  },
  {
    "id": "arXiv:2211.04867",
    "title": "Trackerless freehand ultrasound with sequence modelling and auxiliary  transformation over past and future frames",
    "abstract": "Three-dimensional (3D) freehand ultrasound (US) reconstruction without a\ntracker can be advantageous over its two-dimensional or tracked counterparts in\nmany clinical applications. In this paper, we propose to estimate 3D spatial\ntransformation between US frames from both past and future 2D images, using\nfeed-forward and recurrent neural networks (RNNs). With the temporally\navailable frames, a further multi-task learning algorithm is proposed to\nutilise a large number of auxiliary transformation-predicting tasks between\nthem. Using more than 40,000 US frames acquired from 228 scans on 38 forearms\nof 19 volunteers in a volunteer study, the hold-out test performance is\nquantified by frame prediction accuracy, volume reconstruction overlap,\naccumulated tracking error and final drift, based on ground-truth from an\noptical tracker. The results show the importance of modelling the\ntemporal-spatially correlated input frames as well as output transformations,\nwith further improvement owing to additional past and/or future frames. The\nbest performing model was associated with predicting transformation between\nmoderately-spaced frames, with an interval of less than ten frames at 20 frames\nper second (fps). Little benefit was observed by adding frames more than one\nsecond away from the predicted transformation, with or without LSTM-based RNNs.\nInterestingly, with the proposed approach, explicit within-sequence loss that\nencourages consistency in composing transformations or minimises accumulated\nerror may no longer be required. The implementation code and volunteer data\nwill be made publicly available ensuring reproducibility and further research.",
    "descriptor": "\nComments: 10 pages, 4 figures, Paper submitted to IEEE International Symposium on Biomedical Imaging (ISBI)\n",
    "authors": [
      "Qi Li",
      "Ziyi Shen",
      "Qian Li",
      "Dean C Barratt",
      "Thomas Dowrick",
      "Matthew J Clarkson",
      "Tom Vercauteren",
      "Yipeng Hu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04867"
  },
  {
    "id": "arXiv:2211.04890",
    "title": "Artificial intelligence for improved fitting of trajectories of  elementary particles in inhomogeneous dense materials immersed in a magnetic  field",
    "abstract": "In this article, we use artificial intelligence algorithms to show how to\nenhance the resolution of the elementary particle track fitting in\ninhomogeneous dense detectors, such as plastic scintillators. We use deep\nlearning to replace more traditional Bayesian filtering methods, drastically\nimproving the reconstruction of the interacting particle kinematics. We show\nthat a specific form of neural network, inherited from the field of natural\nlanguage processing, is very close to the concept of a Bayesian filter that\nadopts a hyper-informative prior. Such a paradigm change can influence the\ndesign of future particle physics experiments and their data exploitation.",
    "descriptor": "",
    "authors": [
      "Sa\u00fal Alonso-Monsalve",
      "Davide Sgalaberna",
      "Xingyu Zhao",
      "Clark McGrew",
      "Andr\u00e9 Rubbia"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Experiment (hep-ex)"
    ],
    "url": "https://arxiv.org/abs/2211.04890"
  },
  {
    "id": "arXiv:2211.04914",
    "title": "Grand Dyck paths with air pockets",
    "abstract": "Grand Dyck paths with air pockets (GDAP) are a generalization of Dyck paths\nwith air pockets by allowing them to go below the $x$-axis. We present\nenumerative results on GDAP (or their prefixes) subject to various restrictions\nsuch as maximal/minimal height, ordinate of the last point and particular first\nreturn decomposition. In some special cases we give bijections with other known\ncombinatorial classes.",
    "descriptor": "\nComments: 20 pages, 4 figures\n",
    "authors": [
      "Jean-Luc Baril",
      "Sergey Kirgizov",
      "R\u00e9mi Mar\u00e9chal",
      "Vincent Vajnovszki"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.04914"
  },
  {
    "id": "arXiv:2211.04920",
    "title": "On the distance-edge-monitoring numbers of graphs",
    "abstract": "Foucaud et al. [Discrete Appl. Math. 319 (2022), 424-438] recently introduced\nand initiated the study of a new graph-theoretic concept in the area of network\nmonitoring. For a set $M$ of vertices and an edge $e$ of a graph $G$, let $P(M,\ne)$ be the set of pairs $(x, y)$ with a vertex $x$ of $M$ and a vertex $y$ of\n$V(G)$ such that $d_G(x, y)\\neq d_{G-e}(x, y)$. For a vertex $x$, let $EM(x)$\nbe the set of edges $e$ such that there exists a vertex $v$ in $G$ with $(x, v)\n\\in P(\\{x\\}, e)$. A set $M$ of vertices of a graph $G$ is\ndistance-edge-monitoring set if every edge $e$ of $G$ is monitored by some\nvertex of $M$, that is, the set $P(M, e)$ is nonempty. The\ndistance-edge-monitoring number of a graph $G$, denoted by $dem(G)$, is defined\nas the smallest size of distance-edge-monitoring sets of $G$. The vertices of\n$M$ represent distance probes in a network modeled by $G$; when the edge $e$\nfails, the distance from $x$ to $y$ increases, and thus we are able to detect\nthe failure. It turns out that not only we can detect it, but we can even\ncorrectly locate the failing edge. In this paper, we continue the study of\n\\emph{distance-edge-monitoring sets}. In particular, we give upper and lower\nbounds of $P(M,e)$, $EM(x)$, $dem(G)$, respectively, and extremal graphs\nattaining the bounds are characterized. We also characterize the graphs with\n$dem(G)=3$.",
    "descriptor": "",
    "authors": [
      "Chengxu Yang",
      "Ralf Klasing",
      "Yaping Mao",
      "Xingchao Deng"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.04920"
  },
  {
    "id": "arXiv:2211.04926",
    "title": "Optimized Global Perturbation Attacks For Brain Tumour ROI Extraction  From Binary Classification Models",
    "abstract": "Deep learning techniques have greatly benefited computer-aided diagnostic\nsystems. However, unlike other fields, in medical imaging, acquiring large\nfine-grained annotated datasets such as 3D tumour segmentation is challenging\ndue to the high cost of manual annotation and privacy regulations. This has\ngiven interest to weakly-supervise methods to utilize the weakly labelled data\nfor tumour segmentation. In this work, we propose a weakly supervised approach\nto obtain regions of interest using binary class labels. Furthermore, we\npropose a novel objective function to train the generator model based on a\npretrained binary classification model. Finally, we apply our method to the\nbrain tumour segmentation problem in MRI.",
    "descriptor": "\nComments: Accepted in Medical Imaging meets NeurIPS Workshop NeurIPS 2022\n",
    "authors": [
      "Sajith Rajapaksa",
      "Farzad Khalvati"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04926"
  },
  {
    "id": "arXiv:2211.04956",
    "title": "A Characterization of List Learnability",
    "abstract": "A classical result in learning theory shows the equivalence of PAC\nlearnability of binary hypothesis classes and the finiteness of VC dimension.\nExtending this to the multiclass setting was an open problem, which was settled\nin a recent breakthrough result characterizing multiclass PAC learnability via\nthe DS dimension introduced earlier by Daniely and Shalev-Shwartz. In this work\nwe consider list PAC learning where the goal is to output a list of $k$\npredictions. List learning algorithms have been developed in several settings\nbefore and indeed, list learning played an important role in the recent\ncharacterization of multiclass learnability. In this work we ask: when is it\npossible to $k$-list learn a hypothesis class? We completely characterize\n$k$-list learnability in terms of a generalization of DS dimension that we call\nthe $k$-DS dimension. Generalizing the recent characterization of multiclass\nlearnability, we show that a hypothesis class is $k$-list learnable if and only\nif the $k$-DS dimension is finite.",
    "descriptor": "",
    "authors": [
      "Moses Charikar",
      "Chirag Pabbaraju"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.04956"
  },
  {
    "id": "arXiv:2211.04965",
    "title": "Resource frugal optimizer for quantum machine learning",
    "abstract": "Quantum-enhanced data science, also known as quantum machine learning (QML),\nis of growing interest as an application of near-term quantum computers.\nVariational QML algorithms have the potential to solve practical problems on\nreal hardware, particularly when involving quantum data. However, training\nthese algorithms can be challenging and calls for tailored optimization\nprocedures. Specifically, QML applications can require a large shot-count\noverhead due to the large datasets involved. In this work, we advocate for\nsimultaneous random sampling over both the dataset as well as the measurement\noperators that define the loss function. We consider a highly general loss\nfunction that encompasses many QML applications, and we show how to construct\nan unbiased estimator of its gradient. This allows us to propose a shot-frugal\ngradient descent optimizer called Refoqus (REsource Frugal Optimizer for\nQUantum Stochastic gradient descent). Our numerics indicate that Refoqus can\nsave several orders of magnitude in shot cost, even relative to optimizers that\nsample over measurement operators alone.",
    "descriptor": "\nComments: 20 pages, 5 figures\n",
    "authors": [
      "Charles Moussa",
      "Max Hunter Gordon",
      "Michal Baczyk",
      "M. Cerezo",
      "Lukasz Cincio",
      "Patrick J. Coles"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.04965"
  },
  {
    "id": "arXiv:2211.04984",
    "title": "Graph representation learning for street networks",
    "abstract": "Streets networks provide an invaluable source of information about the\ndifferent temporal and spatial patterns emerging in our cities. These streets\nare often represented as graphs where intersections are modelled as nodes and\nstreets as links between them. Previous work has shown that raster\nrepresentations of the original data can be created through a learning\nalgorithm on low-dimensional representations of the street networks. In\ncontrast, models that capture high-level urban network metrics can be trained\nthrough convolutional neural networks. However, the detailed topological data\nis lost through the rasterisation of the street network. The models cannot\nrecover this information from the image alone, failing to capture complex\nstreet network features. This paper proposes a model capable of inferring good\nrepresentations directly from the street network. Specifically, we use a\nvariational autoencoder with graph convolutional layers and a decoder that\noutputs a probabilistic fully-connected graph to learn latent representations\nthat encode both local network structure and the spatial distribution of nodes.\nWe train the model on thousands of street network segments and use the learnt\nrepresentations to generate synthetic street configurations. Finally, we\nproposed a possible application to classify the urban morphology of different\nnetwork segments by investigating their common characteristics in the learnt\nspace.",
    "descriptor": "\nComments: 12 pages, 8 figures\n",
    "authors": [
      "Mateo Neira",
      "Roberto Murcio"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.04984"
  },
  {
    "id": "arXiv:2211.05020",
    "title": "Duality for Neural Networks through Reproducing Kernel Banach Spaces",
    "abstract": "Reproducing Kernel Hilbert spaces (RKHS) have been a very successful tool in\nvarious areas of machine learning. Recently, Barron spaces have been used to\nproof bounds on the generalisation error for neural networks. Unfortunately,\nBarron spaces cannot be understood in terms of RKHS due to the strong nonlinear\ncoupling of the weights. We show that this can be solved by using the more\ngeneral Reproducing Kernel Banach spaces (RKBS). This class of integral RKBS\ncan be understood as an infinite union of RKHS spaces. As the RKBS is not a\nHilbert space, it is not its own dual space. However, we show that its dual\nspace is again an RKBS where the roles of the data and parameters are\ninterchanged, forming an adjoint pair of RKBSs including a reproducing property\nin the dual space. This allows us to construct the saddle point problem for\nneural networks, which can be used in whole field of primal-dual optimisation\ntechniques.",
    "descriptor": "",
    "authors": [
      "Len Spek",
      "Tjeerd Jan Heeringa",
      "Christoph Brune"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05020"
  },
  {
    "id": "arXiv:2211.05047",
    "title": "A Comparative Study of Data Augmentation Techniques for Deep Learning  Based Emotion Recognition",
    "abstract": "Automated emotion recognition in speech is a long-standing problem. While\nearly work on emotion recognition relied on hand-crafted features and simple\nclassifiers, the field has now embraced end-to-end feature learning and\nclassification using deep neural networks. In parallel to these models,\nresearchers have proposed several data augmentation techniques to increase the\nsize and variability of existing labeled datasets. Despite many seminal\ncontributions in the field, we still have a poor understanding of the interplay\nbetween the network architecture and the choice of data augmentation. Moreover,\nonly a handful of studies demonstrate the generalizability of a particular\nmodel across multiple datasets, which is a prerequisite for robust real-world\nperformance. In this paper, we conduct a comprehensive evaluation of popular\ndeep learning approaches for emotion recognition. To eliminate bias, we fix the\nmodel architectures and optimization hyperparameters using the VESUS dataset\nand then use repeated 5-fold cross validation to evaluate the performance on\nthe IEMOCAP and CREMA-D datasets. Our results demonstrate that long-range\ndependencies in the speech signal are critical for emotion recognition and that\nspeed/rate augmentation offers the most robust performance gain across models.",
    "descriptor": "\nComments: Under Submission\n",
    "authors": [
      "Ravi Shankar",
      "Abdouh Harouna Kenfack",
      "Arjun Somayazulu",
      "Archana Venkataraman"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.05047"
  },
  {
    "id": "arXiv:2211.05071",
    "title": "A Diffeomorphic Flow-based Variational Framework for Multi-speaker  Emotion Conversion",
    "abstract": "This paper introduces a new framework for non-parallel emotion conversion in\nspeech. Our framework is based on two key contributions. First, we propose a\nstochastic version of the popular CycleGAN model. Our modified loss function\nintroduces a Kullback Leibler (KL) divergence term that aligns the source and\ntarget data distributions learned by the generators, thus overcoming the\nlimitations of sample wise generation. By using a variational approximation to\nthis stochastic loss function, we show that our KL divergence term can be\nimplemented via a paired density discriminator. We term this new architecture a\nvariational CycleGAN (VCGAN). Second, we model the prosodic features of target\nemotion as a smooth and learnable deformation of the source prosodic features.\nThis approach provides implicit regularization that offers key advantages in\nterms of better range alignment to unseen and out of distribution speakers. We\nconduct rigorous experiments and comparative studies to demonstrate that our\nproposed framework is fairly robust with high performance against several\nstate-of-the-art baselines.",
    "descriptor": "\nComments: Accepted in IEEE Transactions on Audio, Speech and Language Processing\n",
    "authors": [
      "Ravi Shankar",
      "Hsi-Wei Hsieh",
      "Nicolas Charon",
      "Archana Venkataraman"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.05071"
  },
  {
    "id": "arXiv:2211.05085",
    "title": "Automated Learning: An Implementation of The A* Search Algorithm over  The Random Base Functions",
    "abstract": "This letter explains an algorithm for finding a set of base functions. The\nmethod aims to capture the leading behavior of the dataset in terms of a few\nbase functions. Implementation of the A-star search will help find these\nfunctions, while the gradient descent optimizes the parameters of the functions\nat each search step. We will show the resulting plots to compare the\nextrapolation with the unseen data.",
    "descriptor": "\nComments: 4 pages, 12 figures\n",
    "authors": [
      "Nima Tatari"
    ],
    "subjectives": [
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05085"
  },
  {
    "id": "arXiv:2211.05103",
    "title": "Accidental Learners: Spoken Language Identification in Multilingual  Self-Supervised Models",
    "abstract": "In this paper, we extend previous self-supervised approaches for language\nidentification by experimenting with Conformer based architecture in a\nmultilingual pre-training paradigm. We find that pre-trained speech models\noptimally encode language discriminatory information in lower layers. Further,\nwe demonstrate that the embeddings obtained from these layers are significantly\nrobust to classify unseen languages and different acoustic environments without\nadditional training. After fine-tuning a pre-trained Conformer model on the\nVoxLingua107 dataset, we achieve results similar to current state-of-the-art\nsystems for language identification. More, our model accomplishes this with 5x\nless parameters. We open-source the model through the NVIDIA NeMo toolkit.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Travis M. Bartley",
      "Fei Jia",
      "Krishna C. Puvvada",
      "Samuel Kriman",
      "Boris Ginsburg"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.05103"
  },
  {
    "id": "arXiv:1805.10833",
    "title": "Bayesian Learning with Wasserstein Barycenters",
    "abstract": "Comments: This is the final version, accepted for publication in ESAIM-P&S. Results on Bayesian consistency in Wasserstein topology and on convergence of the BWB estimator have been extended and improved. A series of new examples have been added",
    "descriptor": "\nComments: This is the final version, accepted for publication in ESAIM-P&S. Results on Bayesian consistency in Wasserstein topology and on convergence of the BWB estimator have been extended and improved. A series of new examples have been added\n",
    "authors": [
      "Julio Backhoff-Veraguas",
      "Joaquin Fontbona",
      "Gonzalo Rios",
      "Felipe Tobar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1805.10833"
  },
  {
    "id": "arXiv:2009.11789",
    "title": "A Case for Partitioned Bloom Filters",
    "abstract": "Comments: 11 pages; accepted for publication in IEEE Transactions on Computers",
    "descriptor": "\nComments: 11 pages; accepted for publication in IEEE Transactions on Computers\n",
    "authors": [
      "Paulo S\u00e9rgio Almeida"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2009.11789"
  },
  {
    "id": "arXiv:2011.10268",
    "title": "Hyperparameter Optimization for AST Differencing",
    "abstract": "Hyperparameter Optimization for AST Differencing",
    "descriptor": "",
    "authors": [
      "Matias Martinez",
      "Jean-R\u00e9my Falleri",
      "Martin Monperrus"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2011.10268"
  },
  {
    "id": "arXiv:2012.07678",
    "title": "Classifying CELESTE as NP Complete",
    "abstract": "Comments: Keywords: complexity analysis, NP completeness, algorithmic analysis, game analysis",
    "descriptor": "\nComments: Keywords: complexity analysis, NP completeness, algorithmic analysis, game analysis\n",
    "authors": [
      "Zeeshan Ahmed",
      "Alapan Chaudhuri",
      "Kunwar Shaanjeet Singh Grover"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2012.07678"
  },
  {
    "id": "arXiv:2012.10593",
    "title": "Wheel-INS2: Multiple MEMS IMU-based Dead Reckoning System for Wheeled  Robots with Evaluation of Different IMU Configurations",
    "abstract": "Comments: Accepted to IEEE Transactions on Intelligent Transportation Systems",
    "descriptor": "\nComments: Accepted to IEEE Transactions on Intelligent Transportation Systems\n",
    "authors": [
      "Yibin Wu",
      "Jian Kuang",
      "Xiaoji Niu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2012.10593"
  },
  {
    "id": "arXiv:2101.10443",
    "title": "Towards glass-box CNNs",
    "abstract": "Towards glass-box CNNs",
    "descriptor": "",
    "authors": [
      "Piduguralla Manaswini",
      "Jignesh S. Bhatt"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.10443"
  },
  {
    "id": "arXiv:2102.12842",
    "title": "Coalgebra Encoding for Efficient Minimization",
    "abstract": "Coalgebra Encoding for Efficient Minimization",
    "descriptor": "",
    "authors": [
      "Hans-Peter Deifel",
      "Stefan Milius",
      "Thorsten Wi\u00dfmann"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2102.12842"
  },
  {
    "id": "arXiv:2104.08535",
    "title": "The challenges of temporal alignment on Twitter during crises",
    "abstract": "Comments: Accepted to Findings of EMNLP, 2022",
    "descriptor": "\nComments: Accepted to Findings of EMNLP, 2022\n",
    "authors": [
      "Aniket Pramanick",
      "Tilman Beck",
      "Kevin Stowe",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2104.08535"
  },
  {
    "id": "arXiv:2105.02095",
    "title": "Two-layer neural networks with values in a Banach space",
    "abstract": "Two-layer neural networks with values in a Banach space",
    "descriptor": "",
    "authors": [
      "Yury Korolev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Functional Analysis (math.FA)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2105.02095"
  },
  {
    "id": "arXiv:2105.05716",
    "title": "Acting upon Imagination: when to trust imagined trajectories in model  based reinforcement learning",
    "abstract": "Acting upon Imagination: when to trust imagined trajectories in model  based reinforcement learning",
    "descriptor": "",
    "authors": [
      "Adrian Remonda",
      "Eduardo Veas",
      "Granit Luzhnica"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.05716"
  },
  {
    "id": "arXiv:2106.01275",
    "title": "Probing for the Trace Estimation of a Permuted Matrix Inverse  Corresponding to a Lattice Displacement",
    "abstract": "Probing for the Trace Estimation of a Permuted Matrix Inverse  Corresponding to a Lattice Displacement",
    "descriptor": "",
    "authors": [
      "Heather Switzer",
      "Andreas Stathopoulos",
      "Eloy Romero",
      "Jesse Laeuchli",
      "Kostas Orginos"
    ],
    "subjectives": [
      "High Energy Physics - Lattice (hep-lat)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.01275"
  },
  {
    "id": "arXiv:2106.03134",
    "title": "Pseudo-Riemannian Graph Convolutional Networks",
    "abstract": "Comments: 20 pages",
    "descriptor": "\nComments: 20 pages\n",
    "authors": [
      "Bo Xiong",
      "Shichao Zhu",
      "Nico Potyka",
      "Shirui Pan",
      "Chuan Zhou",
      "Steffen Staab"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.03134"
  },
  {
    "id": "arXiv:2106.08569",
    "title": "Curriculum generation using Autoencoder based continuous optimization",
    "abstract": "Comments: 9 pages, along with all experiment details",
    "descriptor": "\nComments: 9 pages, along with all experiment details\n",
    "authors": [
      "Dipankar Sarkar",
      "Mukur Gupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.08569"
  },
  {
    "id": "arXiv:2107.01594",
    "title": "A Rewriting Coherence Theorem with Applications in Homotopy Type Theory",
    "abstract": "Comments: 34 pages; expands on and reuses material of our previous conference paper \"Coherence via Well-Foundedness\", arXiv:2001.07655",
    "descriptor": "\nComments: 34 pages; expands on and reuses material of our previous conference paper \"Coherence via Well-Foundedness\", arXiv:2001.07655\n",
    "authors": [
      "Nicolai Kraus",
      "Jakob von Raumer"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2107.01594"
  },
  {
    "id": "arXiv:2107.01602",
    "title": "Graphical State Space Model",
    "abstract": "Graphical State Space Model",
    "descriptor": "",
    "authors": [
      "Shaolin L\u00fc"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.01602"
  },
  {
    "id": "arXiv:2107.02780",
    "title": "Causal Inference with Corrupted Data: Measurement Error, Missing Values,  Discretization, and Differential Privacy",
    "abstract": "Causal Inference with Corrupted Data: Measurement Error, Missing Values,  Discretization, and Differential Privacy",
    "descriptor": "",
    "authors": [
      "Anish Agarwal",
      "Rahul Singh"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.02780"
  },
  {
    "id": "arXiv:2107.05161",
    "title": "Bounds for Multiple Packing and List-Decoding Error Exponents",
    "abstract": "Comments: This paper has been split into three parts (arXiv:2211.04406, arXiv:2211.04407, arXiv:2211.04408) with new results added and significant revision. The current version is therefore dated",
    "descriptor": "\nComments: This paper has been split into three parts (arXiv:2211.04406, arXiv:2211.04407, arXiv:2211.04408) with new results added and significant revision. The current version is therefore dated\n",
    "authors": [
      "Yihan Zhang",
      "Shashank Vatedka"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Computational Complexity (cs.CC)",
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2107.05161"
  },
  {
    "id": "arXiv:2108.02336",
    "title": "A Fracture Multiscale Model for Peridynamic enrichment within the  Partition of Unity Method",
    "abstract": "A Fracture Multiscale Model for Peridynamic enrichment within the  Partition of Unity Method",
    "descriptor": "",
    "authors": [
      "Matthias Birner",
      "Patrick Diehl",
      "Robert Lipton",
      "Marc Alexander Schweitzer"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2108.02336"
  },
  {
    "id": "arXiv:2108.10293",
    "title": "A Simplicial Model for $KB4_n$: Epistemic Logic with Agents that May Die",
    "abstract": "A Simplicial Model for $KB4_n$: Epistemic Logic with Agents that May Die",
    "descriptor": "",
    "authors": [
      "\u00c9ric Goubault",
      "J\u00e9r\u00e9my Ledent",
      "Sergio Rajsbaum"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Multiagent Systems (cs.MA)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2108.10293"
  },
  {
    "id": "arXiv:2109.04398",
    "title": "Neural-IMLS: Self-supervised Implicit Moving Least-Squares Network for  Surface Reconstruction",
    "abstract": "Neural-IMLS: Self-supervised Implicit Moving Least-Squares Network for  Surface Reconstruction",
    "descriptor": "",
    "authors": [
      "Zixiong Wang",
      "Pengfei Wang",
      "Pengshuai Wang",
      "Qiujie Dong",
      "Junjie Gao",
      "Shuangmin Chen",
      "Shiqing Xin",
      "Changhe Tu",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2109.04398"
  },
  {
    "id": "arXiv:2109.06122",
    "title": "Discovering the Unknown Knowns: Turning Implicit Knowledge in the  Dataset into Explicit Training Examples for Visual Question Answering",
    "abstract": "Comments: Accepted to EMNLP 2021",
    "descriptor": "\nComments: Accepted to EMNLP 2021\n",
    "authors": [
      "Jihyung Kil",
      "Cheng Zhang",
      "Dong Xuan",
      "Wei-Lun Chao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.06122"
  },
  {
    "id": "arXiv:2110.00943",
    "title": "CDRNet: Accurate Cup-to-Disc Ratio Measurement with Tight Bounding Box  Supervision in Fundus Photography Using Deep Learning",
    "abstract": "Comments: 18 pages, 7 figures, 8 tables, Multimedia Tools and Applications",
    "descriptor": "\nComments: 18 pages, 7 figures, 8 tables, Multimedia Tools and Applications\n",
    "authors": [
      "Juan Wang",
      "Bin Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.00943"
  },
  {
    "id": "arXiv:2110.04814",
    "title": "Finding Second-Order Stationary Points in Nonconvex-Strongly-Concave  Minimax Optimization",
    "abstract": "Finding Second-Order Stationary Points in Nonconvex-Strongly-Concave  Minimax Optimization",
    "descriptor": "",
    "authors": [
      "Luo Luo",
      "Yujun Li",
      "Cheng Chen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04814"
  },
  {
    "id": "arXiv:2111.07367",
    "title": "\"Will You Find These Shortcuts?\" A Protocol for Evaluating the  Faithfulness of Input Salience Methods for Text Classification",
    "abstract": "\"Will You Find These Shortcuts?\" A Protocol for Evaluating the  Faithfulness of Input Salience Methods for Text Classification",
    "descriptor": "",
    "authors": [
      "Jasmijn Bastings",
      "Sebastian Ebert",
      "Polina Zablotskaia",
      "Anders Sandholm",
      "Katja Filippova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.07367"
  },
  {
    "id": "arXiv:2111.10290",
    "title": "A Risk-Managed Steady-State Analysis to Assess the Impact of Power Grid  Uncertainties",
    "abstract": "Comments: Submitted for publication to IEEE Transactions in Power Systems and pending review",
    "descriptor": "\nComments: Submitted for publication to IEEE Transactions in Power Systems and pending review\n",
    "authors": [
      "Naeem Turner-Bandele",
      "Amritanshu Pandey",
      "Larry Pileggi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.10290"
  },
  {
    "id": "arXiv:2111.12312",
    "title": "Lossy Compression of General Random Variables",
    "abstract": "Lossy Compression of General Random Variables",
    "descriptor": "",
    "authors": [
      "Erwin Riegler",
      "Helmut B\u00f6lcskei",
      "G\u00fcnther Koliander"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.12312"
  },
  {
    "id": "arXiv:2111.13207",
    "title": "Characteristic Neural Ordinary Differential Equations",
    "abstract": "Characteristic Neural Ordinary Differential Equations",
    "descriptor": "",
    "authors": [
      "Xingzi Xu",
      "Ali Hasan",
      "Khalil Elkhalil",
      "Jie Ding",
      "Vahid Tarokh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.13207"
  },
  {
    "id": "arXiv:2112.03626",
    "title": "Optimal degree of smoothness to exploit in nonparametric regressions",
    "abstract": "Comments: 4 Tables",
    "descriptor": "\nComments: 4 Tables\n",
    "authors": [
      "Ying Zhu"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2112.03626"
  },
  {
    "id": "arXiv:2112.05478",
    "title": "Critical configurations for three projective views",
    "abstract": "Comments: 32 pages, 8 figures. This is a companion paper to arXiv:2112.05074. The paper has seen a major revision after the initial referee report, submitted to Mathematica Scandinavica",
    "descriptor": "\nComments: 32 pages, 8 figures. This is a companion paper to arXiv:2112.05074. The paper has seen a major revision after the initial referee report, submitted to Mathematica Scandinavica\n",
    "authors": [
      "Martin Br\u00e5telund"
    ],
    "subjectives": [
      "Algebraic Geometry (math.AG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.05478"
  },
  {
    "id": "arXiv:2112.05480",
    "title": "Modular-proximal gradient algorithms in variable exponent Lebesgue  spaces",
    "abstract": "Modular-proximal gradient algorithms in variable exponent Lebesgue  spaces",
    "descriptor": "",
    "authors": [
      "Marta Lazzaretti",
      "Luca Calatroni",
      "Claudio Estatico"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.05480"
  },
  {
    "id": "arXiv:2112.08866",
    "title": "Detecting Model Misspecification in Amortized Bayesian Inference with  Neural Networks",
    "abstract": "Detecting Model Misspecification in Amortized Bayesian Inference with  Neural Networks",
    "descriptor": "",
    "authors": [
      "Marvin Schmitt",
      "Paul-Christian B\u00fcrkner",
      "Ullrich K\u00f6the",
      "Stefan T. Radev"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.08866"
  },
  {
    "id": "arXiv:2112.09182",
    "title": "Predicting Shallow Water Dynamics using Echo-State Networks with  Transfer Learning",
    "abstract": "Predicting Shallow Water Dynamics using Echo-State Networks with  Transfer Learning",
    "descriptor": "",
    "authors": [
      "Xiaoqian Chen",
      "Balasubramanya T. Nadiga",
      "Ilya Timofeyev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Analysis, Statistics and Probability (physics.data-an)",
      "Geophysics (physics.geo-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.09182"
  },
  {
    "id": "arXiv:2112.09985",
    "title": "Scalable Bicriteria Algorithms for Non-Monotone Submodular Cover",
    "abstract": "Scalable Bicriteria Algorithms for Non-Monotone Submodular Cover",
    "descriptor": "",
    "authors": [
      "Victoria G. Crawford"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.09985"
  },
  {
    "id": "arXiv:2112.13168",
    "title": "AI-Bind: Improving Binding Predictions for Novel Protein Targets and  Ligands",
    "abstract": "Comments: 83 pages, 26 figures, all references moved to a single section, new results added on AI interpretability, added comparison with MolTrans, added validation using gold standard experimental data",
    "descriptor": "\nComments: 83 pages, 26 figures, all references moved to a single section, new results added on AI interpretability, added comparison with MolTrans, added validation using gold standard experimental data\n",
    "authors": [
      "Ayan Chatterjee",
      "Robin Walters",
      "Zohair Shafi",
      "Omair Shafi Ahmed",
      "Michael Sebek",
      "Deisy Gysi",
      "Rose Yu",
      "Tina Eliassi-Rad",
      "Albert-L\u00e1szl\u00f3 Barab\u00e1si",
      "Giulia Menichetti"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.13168"
  },
  {
    "id": "arXiv:2201.01871",
    "title": "Direct multi-modal inversion of geophysical logs using deep learning",
    "abstract": "Comments: Submitted to Earth and Space Science",
    "descriptor": "\nComments: Submitted to Earth and Space Science\n",
    "authors": [
      "Sergey Alyaev",
      "Ahmed H. Elsheikh"
    ],
    "subjectives": [
      "Geophysics (physics.geo-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.01871"
  },
  {
    "id": "arXiv:2202.05658",
    "title": "Stable approximation of Helmholtz solutions by evanescent plane waves",
    "abstract": "Stable approximation of Helmholtz solutions by evanescent plane waves",
    "descriptor": "",
    "authors": [
      "Emile Parolin",
      "Daan Huybrechs",
      "Andrea Moiola"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.05658"
  },
  {
    "id": "arXiv:2202.06411",
    "title": "How Likely A Coalition of Voters Can Influence A Large Election?",
    "abstract": "How Likely A Coalition of Voters Can Influence A Large Election?",
    "descriptor": "",
    "authors": [
      "Lirong Xia"
    ],
    "subjectives": [
      "Theoretical Economics (econ.TH)",
      "Artificial Intelligence (cs.AI)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.06411"
  },
  {
    "id": "arXiv:2202.07069",
    "title": "Kantorovich Functors and Characteristic Logics for Behavioural Distances",
    "abstract": "Kantorovich Functors and Characteristic Logics for Behavioural Distances",
    "descriptor": "",
    "authors": [
      "Sergey Goncharov",
      "Dirk Hofmann",
      "Pedro Nora",
      "Lutz Schr\u00f6der",
      "Paul Wild"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.07069"
  },
  {
    "id": "arXiv:2202.07136",
    "title": "Debiased Self-Training for Semi-Supervised Learning",
    "abstract": "Comments: NIPS 2022 Oral",
    "descriptor": "\nComments: NIPS 2022 Oral\n",
    "authors": [
      "Baixu Chen",
      "Junguang Jiang",
      "Ximei Wang",
      "Pengfei Wan",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07136"
  },
  {
    "id": "arXiv:2202.08522",
    "title": "Recovering Unbalanced Communities in the Stochastic Block Model With  Application to Clustering with a Faulty Oracle",
    "abstract": "Recovering Unbalanced Communities in the Stochastic Block Model With  Application to Clustering with a Faulty Oracle",
    "descriptor": "",
    "authors": [
      "Chandra Sekhar Mukherjee",
      "Pan Peng",
      "Jiapeng Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08522"
  },
  {
    "id": "arXiv:2202.11664",
    "title": "Comparative analysis of machine learning methods for active flow control",
    "abstract": "Comments: submitted to Journal of Fluid Mechanics",
    "descriptor": "\nComments: submitted to Journal of Fluid Mechanics\n",
    "authors": [
      "Fabio Pino",
      "Lorenzo Schena",
      "Jean Rabault",
      "Miguel A. Mendez"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.11664"
  },
  {
    "id": "arXiv:2203.07915",
    "title": "Topology Optimization of Fluid-Structure Interaction Problems with Total  Stress Equilibrium",
    "abstract": "Topology Optimization of Fluid-Structure Interaction Problems with Total  Stress Equilibrium",
    "descriptor": "",
    "authors": [
      "Mohamed Abdelhamid",
      "Aleksander Czekanski"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2203.07915"
  },
  {
    "id": "arXiv:2203.09303",
    "title": "MSPred: Video Prediction at Multiple Spatio-Temporal Scales with  Hierarchical Recurrent Networks",
    "abstract": "MSPred: Video Prediction at Multiple Spatio-Temporal Scales with  Hierarchical Recurrent Networks",
    "descriptor": "",
    "authors": [
      "Angel Villar-Corrales",
      "Ani Karapetyan",
      "Andreas Boltres",
      "Sven Behnke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.09303"
  },
  {
    "id": "arXiv:2203.13558",
    "title": "Neural Networks with Divisive normalization for image segmentation with  application in cityscapes dataset",
    "abstract": "Neural Networks with Divisive normalization for image segmentation with  application in cityscapes dataset",
    "descriptor": "",
    "authors": [
      "Pablo Hern\u00e1ndez-C\u00e1mara",
      "Valero Laparra",
      "Jes\u00fas Malo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2203.13558"
  },
  {
    "id": "arXiv:2203.16067",
    "title": "Decision-Focused Learning without Differentiable Optimization: Learning  Locally Optimized Decision Losses",
    "abstract": "Comments: 16 pages, 5 figures, 3 tables",
    "descriptor": "\nComments: 16 pages, 5 figures, 3 tables\n",
    "authors": [
      "Sanket Shah",
      "Kai Wang",
      "Bryan Wilder",
      "Andrew Perrault",
      "Milind Tambe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.16067"
  },
  {
    "id": "arXiv:2203.16799",
    "title": "M-MELD: A Multilingual Multi-Party Dataset for Emotion Recognition in  Conversations",
    "abstract": "Comments: Submitted to ICASSP 2023",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Sreyan Ghosh",
      "S Ramaneswaran",
      "Utkarsh Tyagi",
      "Harshvardhan Srivastava",
      "Samden Lepcha",
      "S Sakshi",
      "Dinesh Manocha"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2203.16799"
  },
  {
    "id": "arXiv:2204.00057",
    "title": "ElectAnon: A Blockchain-Based, Anonymous, Robust and Scalable  Ranked-Choice Voting Protocol",
    "abstract": "ElectAnon: A Blockchain-Based, Anonymous, Robust and Scalable  Ranked-Choice Voting Protocol",
    "descriptor": "",
    "authors": [
      "Ceyhun Onur",
      "Arda Yurdakul"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2204.00057"
  },
  {
    "id": "arXiv:2204.00065",
    "title": "Importance of Different Temporal Modulations of Speech: A Tale of Two  Perspectives",
    "abstract": "Comments: Submitted to ICASSP 2023",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Samik Sadhu",
      "Hynek Hermansky"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2204.00065"
  },
  {
    "id": "arXiv:2204.04162",
    "title": "Stable Matching: Choosing Which Proposals to Make",
    "abstract": "Comments: 52 pages",
    "descriptor": "\nComments: 52 pages\n",
    "authors": [
      "Ishan Agarwal",
      "Richard Cole"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2204.04162"
  },
  {
    "id": "arXiv:2204.04602",
    "title": "How much can one learn a partial differential equation from its  solution?",
    "abstract": "Comments: 44 pages",
    "descriptor": "\nComments: 44 pages\n",
    "authors": [
      "Yuchen He",
      "Hongkai Zhao",
      "Yimin Zhong"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)"
    ],
    "url": "https://arxiv.org/abs/2204.04602"
  },
  {
    "id": "arXiv:2204.08730",
    "title": "A Stackelberg game for incentive-based demand response in energy markets",
    "abstract": "Comments: Accepted to 61st IEEE Conference on Decision and Control (CDC), 2022",
    "descriptor": "\nComments: Accepted to 61st IEEE Conference on Decision and Control (CDC), 2022\n",
    "authors": [
      "Marta Fochesato",
      "Carlo Cenedese",
      "John Lygeros"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.08730"
  },
  {
    "id": "arXiv:2204.10779",
    "title": "CgAT: Center-Guided Adversarial Training for Deep Hashing-Based  Retrieval",
    "abstract": "Comments: has no contributions",
    "descriptor": "\nComments: has no contributions\n",
    "authors": [
      "Xunguang Wang",
      "Yinqun Lin",
      "Xiaomeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.10779"
  },
  {
    "id": "arXiv:2204.10897",
    "title": "Welfare effects of strategic voting under scoring rules",
    "abstract": "Welfare effects of strategic voting under scoring rules",
    "descriptor": "",
    "authors": [
      "Egor Ianovski",
      "Daria Teplova",
      "Valeriia Kuka"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2204.10897"
  },
  {
    "id": "arXiv:2204.12404",
    "title": "Hierarchical Bayesian Modelling for Knowledge Transfer Across  Engineering Fleets via Multitask Learning",
    "abstract": "Hierarchical Bayesian Modelling for Knowledge Transfer Across  Engineering Fleets via Multitask Learning",
    "descriptor": "",
    "authors": [
      "L.A. Bull",
      "D. Di Francesco",
      "M. Dhada",
      "O. Steinert",
      "T. Lindgren",
      "A.K. Parlikad",
      "A.B. Duncan",
      "M. Girolami"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2204.12404"
  },
  {
    "id": "arXiv:2204.12831",
    "title": "The Revisiting Problem in Simultaneous Localization and Mapping: A  Survey on Visual Loop Closure Detection",
    "abstract": "Comments: 25 pages, 15 figures",
    "descriptor": "\nComments: 25 pages, 15 figures\n",
    "authors": [
      "Konstantinos A. Tsintotas",
      "Loukas Bampis",
      "Antonios Gasteratos"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.12831"
  },
  {
    "id": "arXiv:2204.13041",
    "title": "Proto-Quipper with dynamic lifting",
    "abstract": "Proto-Quipper with dynamic lifting",
    "descriptor": "",
    "authors": [
      "Peng Fu",
      "Kohei Kishida",
      "Neil J. Ross",
      "Peter Selinger"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Category Theory (math.CT)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2204.13041"
  },
  {
    "id": "arXiv:2204.13380",
    "title": "Safety-Aware Optimal Control for Motion Planning with Low Computing  Complexity",
    "abstract": "Safety-Aware Optimal Control for Motion Planning with Low Computing  Complexity",
    "descriptor": "",
    "authors": [
      "Xuda Ding",
      "Han Wang",
      "Jianping He",
      "Cailian Chen",
      "Kostas Margellos",
      "Antonis Papachristodoulou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.13380"
  },
  {
    "id": "arXiv:2204.13499",
    "title": "FieldFuzz: Stateful Fuzzing of Proprietary Industrial Controllers using  Injected Ghosts",
    "abstract": "FieldFuzz: Stateful Fuzzing of Proprietary Industrial Controllers using  Injected Ghosts",
    "descriptor": "",
    "authors": [
      "Andrei Bytes",
      "Prashant Hari Narayan Rajput",
      "Constantine Doumanidis",
      "Michail Maniatakos",
      "Jianying Zhou"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2204.13499"
  },
  {
    "id": "arXiv:2204.14145",
    "title": "Efficient solution of robust optimal control problems using local  reduction",
    "abstract": "Efficient solution of robust optimal control problems using local  reduction",
    "descriptor": "",
    "authors": [
      "Marta Zagorowska",
      "Paola Falugi",
      "Edward O'Dwyer",
      "Eric C. Kerrigan"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.14145"
  },
  {
    "id": "arXiv:2205.02717",
    "title": "BasicTAD: an Astounding RGB-Only Baseline for Temporal Action Detection",
    "abstract": "Comments: 22 pages,3 figure",
    "descriptor": "\nComments: 22 pages,3 figure\n",
    "authors": [
      "Min Yang",
      "Guo Chen",
      "Yin-Dong Zheng",
      "Tong Lu",
      "Limin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.02717"
  },
  {
    "id": "arXiv:2205.03205",
    "title": "Unlimited Lives: Secure In-Process Rollback with Isolated Domains",
    "abstract": "Unlimited Lives: Secure In-Process Rollback with Isolated Domains",
    "descriptor": "",
    "authors": [
      "Merve Turhan",
      "Thomas Nyman",
      "Christoph Baumann",
      "Jan Tobias M\u00fchlberg"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.03205"
  },
  {
    "id": "arXiv:2205.05068",
    "title": "Secure and Private Source Coding with Private Key and Decoder Side  Information",
    "abstract": "Comments: Shorter version to appear in the 2022 IEEE Information Theory Workshop",
    "descriptor": "\nComments: Shorter version to appear in the 2022 IEEE Information Theory Workshop\n",
    "authors": [
      "Onur G\u00fcnl\u00fc",
      "Rafael F. Schaefer",
      "Holger Boche",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2205.05068"
  },
  {
    "id": "arXiv:2205.05413",
    "title": "Compact and Efficient KEMs over NTRU Lattices",
    "abstract": "Compact and Efficient KEMs over NTRU Lattices",
    "descriptor": "",
    "authors": [
      "Zhichuang Liang",
      "Boyue Fang",
      "Jieyu Zheng",
      "Yunlei Zhao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2205.05413"
  },
  {
    "id": "arXiv:2205.05878",
    "title": "Training Uncertainty-Aware Classifiers with Conformalized Deep Learning",
    "abstract": "Comments: 46 pages, 48 figures, 5 tables",
    "descriptor": "\nComments: 46 pages, 48 figures, 5 tables\n",
    "authors": [
      "Bat-Sheva Einbinder",
      "Yaniv Romano",
      "Matteo Sesia",
      "Yanfei Zhou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2205.05878"
  },
  {
    "id": "arXiv:2205.06373",
    "title": "Continuous Interior Penalty stabilization for divergence-free finite  element methods",
    "abstract": "Comments: 3 figures, 23 pages",
    "descriptor": "\nComments: 3 figures, 23 pages\n",
    "authors": [
      "Gabriel R. Barrenechea",
      "Erik Burman",
      "Ernesto C\u00e1ceres",
      "Johnny Guzm\u00e1n"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.06373"
  },
  {
    "id": "arXiv:2205.06871",
    "title": "Near-Negative Distinction: Giving a Second Life to Human Evaluation  Datasets",
    "abstract": "Comments: EMNLP 2022 - Long Paper",
    "descriptor": "\nComments: EMNLP 2022 - Long Paper\n",
    "authors": [
      "Philippe Laban",
      "Chien-Sheng Wu",
      "Wenhao Liu",
      "Caiming Xiong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.06871"
  },
  {
    "id": "arXiv:2205.08062",
    "title": "Strong Revenue (Non-)Monotonicity of Single-parameter Auctions",
    "abstract": "Strong Revenue (Non-)Monotonicity of Single-parameter Auctions",
    "descriptor": "",
    "authors": [
      "Ziyun Chen",
      "Zhiyi Huang",
      "Dorsa Majdi",
      "Zipeng Yan"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2205.08062"
  },
  {
    "id": "arXiv:2205.13635",
    "title": "RIGID: Robust Linear Regression with Missing Data",
    "abstract": "RIGID: Robust Linear Regression with Missing Data",
    "descriptor": "",
    "authors": [
      "Alireza Aghasi",
      "MohammadJavad Feizollahi",
      "Saeed Ghadimi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2205.13635"
  },
  {
    "id": "arXiv:2206.01092",
    "title": "Innovations in Integrating Machine Learning and Agent-Based Modeling of  Biomedical Systems",
    "abstract": "Comments: 32 pages, 1 table, 8 figures",
    "descriptor": "\nComments: 32 pages, 1 table, 8 figures\n",
    "authors": [
      "Nikita Sivakumar",
      "Cameron Mura",
      "Shayn M. Peirce"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Cell Behavior (q-bio.CB)"
    ],
    "url": "https://arxiv.org/abs/2206.01092"
  },
  {
    "id": "arXiv:2206.03077",
    "title": "An Exploratory Analysis of Feedback Types Used in Online Coding  Exercises",
    "abstract": "Comments: 15 pages, 3 figures",
    "descriptor": "\nComments: 15 pages, 3 figures\n",
    "authors": [
      "Natalie Kiesler"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2206.03077"
  },
  {
    "id": "arXiv:2206.04827",
    "title": "A Quasi-Optimal Spectral Solver for the Heat and Poisson Equations in a  Closed Cylinder",
    "abstract": "Comments: 18 pages, 3 figures. Submitted to SIURO. Edited based on reviewer comments",
    "descriptor": "\nComments: 18 pages, 3 figures. Submitted to SIURO. Edited based on reviewer comments\n",
    "authors": [
      "David Darrow"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2206.04827"
  },
  {
    "id": "arXiv:2206.05017",
    "title": "Empathetic Conversational Systems: A Review of Current Advances, Gaps,  and Opportunities",
    "abstract": "Comments: 20 pages, 3 figures, 4 tables",
    "descriptor": "\nComments: 20 pages, 3 figures, 4 tables\n",
    "authors": [
      "Aravind Sesagiri Raamkumar",
      "Yinping Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.05017"
  },
  {
    "id": "arXiv:2206.05604",
    "title": "A Theoretical Understanding of Neural Network Compression from Sparse  Linear Approximation",
    "abstract": "A Theoretical Understanding of Neural Network Compression from Sparse  Linear Approximation",
    "descriptor": "",
    "authors": [
      "Wenjing Yang",
      "Ganghua Wang",
      "Jie Ding",
      "Yuhong Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.05604"
  },
  {
    "id": "arXiv:2206.10098",
    "title": "Reconstruct from BEV: A 3D Lane Detection Approach based on Geometry  Structure Prior",
    "abstract": "Comments: Proceedings of the CVPR 2022 Workshop of Autonomous Driving",
    "descriptor": "\nComments: Proceedings of the CVPR 2022 Workshop of Autonomous Driving\n",
    "authors": [
      "Chenguang Li",
      "Jia Shi",
      "Ya Wang",
      "Guangliang Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10098"
  },
  {
    "id": "arXiv:2206.10692",
    "title": "Multi-level Domain Adaptation for Lane Detection",
    "abstract": "Comments: Proceedings of the CVPR 2022 Workshop of Autonomous Driving",
    "descriptor": "\nComments: Proceedings of the CVPR 2022 Workshop of Autonomous Driving\n",
    "authors": [
      "Chenguang Li",
      "Boheng Zhang",
      "Jia Shi",
      "Guangliang Cheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.10692"
  },
  {
    "id": "arXiv:2206.11346",
    "title": "Constrained Stochastic Nonconvex Optimization with State-dependent  Markov Data",
    "abstract": "Comments: 2 figures",
    "descriptor": "\nComments: 2 figures\n",
    "authors": [
      "Abhishek Roy",
      "Krishnakumar Balasubramanian",
      "Saeed Ghadimi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.11346"
  },
  {
    "id": "arXiv:2206.11812",
    "title": "Formalizing the Problem of Side Effect Regularization",
    "abstract": "Comments: 14 pages, accepted to ML Safety Workshop at NeurIPS 2022. Alexander Turner and Aseem Saxena contributed equally",
    "descriptor": "\nComments: 14 pages, accepted to ML Safety Workshop at NeurIPS 2022. Alexander Turner and Aseem Saxena contributed equally\n",
    "authors": [
      "Alexander Matt Turner",
      "Aseem Saxena",
      "Prasad Tadepalli"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.11812"
  },
  {
    "id": "arXiv:2206.12150",
    "title": "Decoding Short LDPC Codes via BP-RNN Diversity and Reliability-Based  Post-Processing",
    "abstract": "Decoding Short LDPC Codes via BP-RNN Diversity and Reliability-Based  Post-Processing",
    "descriptor": "",
    "authors": [
      "Joachim Rosseel",
      "Val\u00e9rian Mannoni",
      "Inbar Fijalkow",
      "Valentin Savin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2206.12150"
  },
  {
    "id": "arXiv:2206.13482",
    "title": "Understanding Benign Overfitting in Gradient-Based Meta Learning",
    "abstract": "Understanding Benign Overfitting in Gradient-Based Meta Learning",
    "descriptor": "",
    "authors": [
      "Lisha Chen",
      "Songtao Lu",
      "Tianyi Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.13482"
  },
  {
    "id": "arXiv:2206.14332",
    "title": "Active Exploration via Experiment Design in Markov Chains",
    "abstract": "Active Exploration via Experiment Design in Markov Chains",
    "descriptor": "",
    "authors": [
      "Mojm\u00edr Mutn\u00fd",
      "Tadeusz Janik",
      "Andreas Krause"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2206.14332"
  },
  {
    "id": "arXiv:2207.07862",
    "title": "MAC-DO: Charge Based Multi-Bit Analog In-Memory Accelerator Compatible  with DRAM Using Output Stationary Mapping",
    "abstract": "Comments: 14 pages, 22 figures",
    "descriptor": "\nComments: 14 pages, 22 figures\n",
    "authors": [
      "Minki Jeong",
      "Wanyeong Jung"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2207.07862"
  },
  {
    "id": "arXiv:2207.08015",
    "title": "Collaborative Best Arm Identification with Limited Communication on  Non-IID Data",
    "abstract": "Comments: 36 pages",
    "descriptor": "\nComments: 36 pages\n",
    "authors": [
      "Nikolai Karpov",
      "Qin Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2207.08015"
  },
  {
    "id": "arXiv:2207.09340",
    "title": "A coherence parameter characterizing generative compressed sensing with  Fourier measurements",
    "abstract": "A coherence parameter characterizing generative compressed sensing with  Fourier measurements",
    "descriptor": "",
    "authors": [
      "Aaron Berk",
      "Simone Brugiapaglia",
      "Babhru Joshi",
      "Yaniv Plan",
      "Matthew Scott",
      "\u00d6zg\u00fcr Yilmaz"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.09340"
  },
  {
    "id": "arXiv:2207.09521",
    "title": "The Dice loss in the context of missing or empty labels: Introducing  $\u03a6$ and $\u03b5$",
    "abstract": "Comments: 8 pages, 3 figures, 1 table, International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI) 2022",
    "descriptor": "\nComments: 8 pages, 3 figures, 1 table, International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI) 2022\n",
    "authors": [
      "Sofie Tilborghs",
      "Jeroen Bertels",
      "David Robben",
      "Dirk Vandermeulen",
      "Frederik Maes"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09521"
  },
  {
    "id": "arXiv:2207.09684",
    "title": "On the Versatile Uses of Partial Distance Correlation in Deep Learning",
    "abstract": "Comments: This paper has been selected as best paper award for ECCV 2022!",
    "descriptor": "\nComments: This paper has been selected as best paper award for ECCV 2022!\n",
    "authors": [
      "Xingjian Zhen",
      "Zihang Meng",
      "Rudrasis Chakraborty",
      "Vikas Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.09684"
  },
  {
    "id": "arXiv:2207.11554",
    "title": "3DOS: Towards 3D Open Set Learning -- Benchmarking and Understanding  Semantic Novelty Detection on Point Clouds",
    "abstract": "Comments: Accepted by NeurIPS 2022 Datasets and Benchmarks Track. Code: this https URL",
    "descriptor": "\nComments: Accepted by NeurIPS 2022 Datasets and Benchmarks Track. Code: this https URL\n",
    "authors": [
      "Antonio Alliegro",
      "Francesco Cappio Borlino",
      "Tatiana Tommasi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.11554"
  },
  {
    "id": "arXiv:2207.12369",
    "title": "Toward reliable signals decoding for electroencephalogram: A benchmark  study to EEGNeX",
    "abstract": "Comments: 17 pages, 5 figures",
    "descriptor": "\nComments: 17 pages, 5 figures\n",
    "authors": [
      "Xia Chen",
      "Xiangbin Teng",
      "Han Chen",
      "Yafeng Pan",
      "Philipp Geyer"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Human-Computer Interaction (cs.HC)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2207.12369"
  },
  {
    "id": "arXiv:2207.14529",
    "title": "The Effects of Data Quality on Machine Learning Performance",
    "abstract": "The Effects of Data Quality on Machine Learning Performance",
    "descriptor": "",
    "authors": [
      "Lukas Budach",
      "Moritz Feuerpfeil",
      "Nina Ihde",
      "Andrea Nathansen",
      "Nele Noack",
      "Hendrik Patzlaff",
      "Felix Naumann",
      "Hazar Harmouch"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2207.14529"
  },
  {
    "id": "arXiv:2208.02971",
    "title": "CROLoss: Towards a Customizable Loss for Retrieval Models in Recommender  Systems",
    "abstract": "Comments: 9 pages, 5 figures. Accepted by by CIKM 2022",
    "descriptor": "\nComments: 9 pages, 5 figures. Accepted by by CIKM 2022\n",
    "authors": [
      "Yongxiang Tang",
      "Wentao Bai",
      "Guilin Li",
      "Xialong Liu",
      "Yu Zhang"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2208.02971"
  },
  {
    "id": "arXiv:2208.05187",
    "title": "Leveraging Endo- and Exo-Temporal Regularization for Black-box Video  Domain Adaptation",
    "abstract": "Comments: 9 pages, 4 figures, and 4 tables",
    "descriptor": "\nComments: 9 pages, 4 figures, and 4 tables\n",
    "authors": [
      "Yuecong Xu",
      "Jianfei Yang",
      "Haozhi Cao",
      "Min Wu",
      "Xiaoli Li",
      "Lihua Xie",
      "Zhenghua Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.05187"
  },
  {
    "id": "arXiv:2208.06414",
    "title": "Optimistic No-regret Algorithms for Discrete Caching",
    "abstract": "Comments: Accepted to ACM SIGMETRICS 2023",
    "descriptor": "\nComments: Accepted to ACM SIGMETRICS 2023\n",
    "authors": [
      "Naram Mhaisen",
      "Abhishek Sinha",
      "Georgios Paschos",
      "Georgios Iosifidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2208.06414"
  },
  {
    "id": "arXiv:2208.07736",
    "title": "Introducing Intermediate Domains for Effective Self-Training during  Test-Time",
    "abstract": "Introducing Intermediate Domains for Effective Self-Training during  Test-Time",
    "descriptor": "",
    "authors": [
      "Robert A. Marsden",
      "Mario D\u00f6bler",
      "Bin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.07736"
  },
  {
    "id": "arXiv:2208.08607",
    "title": "Event-triggered Finite-time Control Using Inverse-optimal Implicit  Lyapunov Function",
    "abstract": "Comments: To be revised and corrected",
    "descriptor": "\nComments: To be revised and corrected\n",
    "authors": [
      "Peng Wang",
      "Shuzhi Sam Ge",
      "Xiaobing Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.08607"
  },
  {
    "id": "arXiv:2208.10530",
    "title": "Smoothness Analysis for Probabilistic Programs with Application to  Optimised Variational Inference",
    "abstract": "Comments: To appear at POPL 2023",
    "descriptor": "\nComments: To appear at POPL 2023\n",
    "authors": [
      "Wonyeol Lee",
      "Xavier Rival",
      "Hongseok Yang"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.10530"
  },
  {
    "id": "arXiv:2208.11035",
    "title": "Not All GPUs Are Created Equal: Characterizing Variability in  Large-Scale, Accelerator-Rich Systems",
    "abstract": "Comments: 14 pages, 18 figures, to appear at The 34th International Conference for High Performance Computing, Networking, Storage, and Analysis (SC '22)",
    "descriptor": "\nComments: 14 pages, 18 figures, to appear at The 34th International Conference for High Performance Computing, Networking, Storage, and Analysis (SC '22)\n",
    "authors": [
      "Prasoon Sinha",
      "Akhil Guliani",
      "Rutwik Jain",
      "Brandon Tran",
      "Matthew D. Sinclair",
      "Shivaram Venkataraman"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2208.11035"
  },
  {
    "id": "arXiv:2208.12923",
    "title": "Global RTK Positioning in Graphical State Space",
    "abstract": "Global RTK Positioning in Graphical State Space",
    "descriptor": "",
    "authors": [
      "Yihong Ge",
      "Sudan Yan",
      "Shaolin L\u00fc",
      "Cong Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2208.12923"
  },
  {
    "id": "arXiv:2209.00552",
    "title": "Systems Theoretic Process Analysis of a Run Time Assured Neural Network  Control System",
    "abstract": "Systems Theoretic Process Analysis of a Run Time Assured Neural Network  Control System",
    "descriptor": "",
    "authors": [
      "Kerianne L. Hobbs",
      "Benjamin K. Heiner",
      "Lillian Busse",
      "Kyle Dunlap",
      "Jonathan Rowanhill",
      "Ashlie B. Hocking",
      "Aditya Zutshi"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.00552"
  },
  {
    "id": "arXiv:2209.05559",
    "title": "Deep Reinforcement Learning for Cryptocurrency Trading: Practical  Approach to Address Backtest Overfitting",
    "abstract": "Deep Reinforcement Learning for Cryptocurrency Trading: Practical  Approach to Address Backtest Overfitting",
    "descriptor": "",
    "authors": [
      "Berend Jelmer Dirk Gort",
      "Xiao-Yang Liu",
      "Xinghang Sun",
      "Jiechao Gao",
      "Shuaiyu Chen",
      "Christina Dan Wang"
    ],
    "subjectives": [
      "Statistical Finance (q-fin.ST)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2209.05559"
  },
  {
    "id": "arXiv:2209.07089",
    "title": "Constrained Update Projection Approach to Safe Policy Optimization",
    "abstract": "Comments: Accepted by NeurIPS2022. arXiv admin note: substantial text overlap with arXiv:2202.07565",
    "descriptor": "\nComments: Accepted by NeurIPS2022. arXiv admin note: substantial text overlap with arXiv:2202.07565\n",
    "authors": [
      "Long Yang",
      "Jiaming Ji",
      "Juntao Dai",
      "Linrui Zhang",
      "Binbin Zhou",
      "Pengfei Li",
      "Yaodong Yang",
      "Gang Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.07089"
  },
  {
    "id": "arXiv:2209.12188",
    "title": "Milner's Proof System for Regular Expressions Modulo Bisimilarity is  Complete (Crystallization: Near-Collapsing Process Graph Interpretations of  Regular Expressions)",
    "abstract": "Comments: Version article submitted to LICS 2022 (with some corrections performed already during the review process, a few afterwards, 14 pages, 2 pages of the appendix)",
    "descriptor": "\nComments: Version article submitted to LICS 2022 (with some corrections performed already during the review process, a few afterwards, 14 pages, 2 pages of the appendix)\n",
    "authors": [
      "Clemens Grabmayer"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2209.12188"
  },
  {
    "id": "arXiv:2209.14172",
    "title": "An Automatic Evaluation of the WMT22 General Machine Translation Task",
    "abstract": "Comments: Update: correction, fr-&gt;de and de-&gt; tables were switched",
    "descriptor": "\nComments: Update: correction, fr-&gt;de and de-&gt; tables were switched\n",
    "authors": [
      "Benjamin Marie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2209.14172"
  },
  {
    "id": "arXiv:2210.00379",
    "title": "NeRF: Neural Radiance Field in 3D Vision, A Comprehensive Review",
    "abstract": "NeRF: Neural Radiance Field in 3D Vision, A Comprehensive Review",
    "descriptor": "",
    "authors": [
      "Kyle Gao",
      "Yina Gao",
      "Hongjie He",
      "Denning Lu",
      "Linlin Xu",
      "Jonathan Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00379"
  },
  {
    "id": "arXiv:2210.00422",
    "title": "Stochastic optimization on matrices and a graphon McKean-Vlasov limit",
    "abstract": "Comments: 34 pages, references added, introduction modified",
    "descriptor": "\nComments: 34 pages, references added, introduction modified\n",
    "authors": [
      "Zaid Harchaoui",
      "Sewoong Oh",
      "Soumik Pal",
      "Raghav Somani",
      "Raghavendra Tripathi"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.00422"
  },
  {
    "id": "arXiv:2210.00640",
    "title": "Wide Attention Is The Way Forward For Transformers?",
    "abstract": "Wide Attention Is The Way Forward For Transformers?",
    "descriptor": "",
    "authors": [
      "Jason Ross Brown",
      "Yiren Zhao",
      "Ilia Shumailov",
      "Robert D Mullins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.00640"
  },
  {
    "id": "arXiv:2210.00918",
    "title": "Fill in Fabrics: Body-Aware Self-Supervised Inpainting for Image-Based  Virtual Try-On",
    "abstract": "Fill in Fabrics: Body-Aware Self-Supervised Inpainting for Image-Based  Virtual Try-On",
    "descriptor": "",
    "authors": [
      "H. Zunair",
      "Y. Gobeil",
      "S. Mercier",
      "A. Ben Hamza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00918"
  },
  {
    "id": "arXiv:2210.00923",
    "title": "Masked Supervised Learning for Semantic Segmentation",
    "abstract": "Masked Supervised Learning for Semantic Segmentation",
    "descriptor": "",
    "authors": [
      "Hasib Zunair",
      "A. Ben Hamza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.00923"
  },
  {
    "id": "arXiv:2210.01120",
    "title": "Predicting CO$_2$ Absorption in Ionic Liquids with Molecular Descriptors  and Explainable Graph Neural Networks",
    "abstract": "Predicting CO$_2$ Absorption in Ionic Liquids with Molecular Descriptors  and Explainable Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Yue Jian",
      "Yuyang Wang",
      "Amir Barati Farimani"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01120"
  },
  {
    "id": "arXiv:2210.01512",
    "title": "Code-Switching without Switching: Language Agnostic End-to-End Speech  Translation",
    "abstract": "Code-Switching without Switching: Language Agnostic End-to-End Speech  Translation",
    "descriptor": "",
    "authors": [
      "Christian Huber",
      "Enes Yavuz Ugan",
      "Alexander Waibel"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.01512"
  },
  {
    "id": "arXiv:2210.02097",
    "title": "Teaching Yourself: Graph Self-Distillation on Neighborhood for Node  Classification",
    "abstract": "Teaching Yourself: Graph Self-Distillation on Neighborhood for Node  Classification",
    "descriptor": "",
    "authors": [
      "Lirong Wu",
      "Jun Xia",
      "Haitao Lin",
      "Zhangyang Gao",
      "Zicheng Liu",
      "Guojiang Zhao",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.02097"
  },
  {
    "id": "arXiv:2210.02963",
    "title": "Valuing Uncertainties in Wind Generation: An Agent-Based Optimization  Approach",
    "abstract": "Comments: 6 pages, 3 figures. Submitted to the 2023 American Control Conference (ACC)",
    "descriptor": "\nComments: 6 pages, 3 figures. Submitted to the 2023 American Control Conference (ACC)\n",
    "authors": [
      "Daniel Shen",
      "Marija Ilic"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.02963"
  },
  {
    "id": "arXiv:2210.04052",
    "title": "FedDef: Defense Against Gradient Leakage in Federated Learning-based  Network Intrusion Detection Systems",
    "abstract": "Comments: 14 pages, 9 figures, submitted to TIFS",
    "descriptor": "\nComments: 14 pages, 9 figures, submitted to TIFS\n",
    "authors": [
      "Jiahui Chen",
      "Yi Zhao",
      "Qi Li",
      "Xuewei Feng",
      "Ke Xu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04052"
  },
  {
    "id": "arXiv:2210.05152",
    "title": "TriangleNet: Edge Prior Augmented Network for Semantic Segmentation  through Cross-Task Consistency",
    "abstract": "TriangleNet: Edge Prior Augmented Network for Semantic Segmentation  through Cross-Task Consistency",
    "descriptor": "",
    "authors": [
      "Dan Zhang",
      "Rui Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.05152"
  },
  {
    "id": "arXiv:2210.05523",
    "title": "An efficient neural-network and finite-difference hybrid method for  elliptic interface problems with applications",
    "abstract": "An efficient neural-network and finite-difference hybrid method for  elliptic interface problems with applications",
    "descriptor": "",
    "authors": [
      "Wei-Fan Hu",
      "Te-Sheng Lin",
      "Yu-Hau Tseng",
      "Ming-Chih Lai"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.05523"
  },
  {
    "id": "arXiv:2210.07347",
    "title": "Disentanglement of Correlated Factors via Hausdorff Factorized Support",
    "abstract": "Disentanglement of Correlated Factors via Hausdorff Factorized Support",
    "descriptor": "",
    "authors": [
      "Karsten Roth",
      "Mark Ibrahim",
      "Zeynep Akata",
      "Pascal Vincent",
      "Diane Bouchacourt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.07347"
  },
  {
    "id": "arXiv:2210.08008",
    "title": "Inductive Logical Query Answering in Knowledge Graphs",
    "abstract": "Comments: Accepted at NeurIPS 2022",
    "descriptor": "\nComments: Accepted at NeurIPS 2022\n",
    "authors": [
      "Mikhail Galkin",
      "Zhaocheng Zhu",
      "Hongyu Ren",
      "Jian Tang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08008"
  },
  {
    "id": "arXiv:2210.08121",
    "title": "Inferring Versatile Behavior from Demonstrations by Matching Geometric  Descriptors",
    "abstract": "Comments: Accepted as a poster at the 6th Conference on Robot Learning (CoRL), 2022",
    "descriptor": "\nComments: Accepted as a poster at the 6th Conference on Robot Learning (CoRL), 2022\n",
    "authors": [
      "Niklas Freymuth",
      "Nicolas Schreiber",
      "Philipp Becker",
      "Aleksandar Taranovic",
      "Gerhard Neumann"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.08121"
  },
  {
    "id": "arXiv:2210.08430",
    "title": "Explainable Causal Analysis of Mental Health on Social Media Data",
    "abstract": "Explainable Causal Analysis of Mental Health on Social Media Data",
    "descriptor": "",
    "authors": [
      "Chandni Saxena",
      "Muskan Garg",
      "Gunjan Ansari"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2210.08430"
  },
  {
    "id": "arXiv:2210.12347",
    "title": "Quantifying Complexity: An Object-Relations Approach to Complex Systems",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2210.07202",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2210.07202\n",
    "authors": [
      "Stephen Casey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Data Analysis, Statistics and Probability (physics.data-an)"
    ],
    "url": "https://arxiv.org/abs/2210.12347"
  },
  {
    "id": "arXiv:2210.12772",
    "title": "Electroanatomic Mapping to determine Scar Regions in patients with  Atrial Fibrillation",
    "abstract": "Electroanatomic Mapping to determine Scar Regions in patients with  Atrial Fibrillation",
    "descriptor": "",
    "authors": [
      "Jiyue He",
      "Kuk Jin Jang",
      "Katie Walsh",
      "Jackson Liang",
      "Sanjay Dixit",
      "Rahul Mangharam"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Image and Video Processing (eess.IV)",
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2210.12772"
  },
  {
    "id": "arXiv:2210.15184",
    "title": "Too Brittle To Touch: Comparing the Stability of Quantization and  Distillation Towards Developing Lightweight Low-Resource MT Models",
    "abstract": "Comments: 16 Pages, 7 Figures, Accepted to WMT 2022 (Research Track)",
    "descriptor": "\nComments: 16 Pages, 7 Figures, Accepted to WMT 2022 (Research Track)\n",
    "authors": [
      "Harshita Diddee",
      "Sandipan Dandapat",
      "Monojit Choudhury",
      "Tanuja Ganu",
      "Kalika Bali"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.15184"
  },
  {
    "id": "arXiv:2210.15228",
    "title": "Solving Audio Inverse Problems with a Diffusion Model",
    "abstract": "Comments: Submitted to ICASSP 2023",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Eloi Moliner",
      "Jaakko Lehtinen",
      "Vesa V\u00e4lim\u00e4ki"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.15228"
  },
  {
    "id": "arXiv:2210.15655",
    "title": "GILP: An Interactive Tool for Visualizing the Simplex Algorithm",
    "abstract": "Comments: ACM SIGCSE 2023 Manuscript, 13 pages, 5 figures",
    "descriptor": "\nComments: ACM SIGCSE 2023 Manuscript, 13 pages, 5 figures\n",
    "authors": [
      "Henry W. Robbins",
      "Samuel C. Gutekunst",
      "David B. Shmoys",
      "David P. Williamson"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2210.15655"
  },
  {
    "id": "arXiv:2210.16064",
    "title": "DORE: Document Ordered Relation Extraction based on Generative Framework",
    "abstract": "Comments: Findings of EMNLP 2022",
    "descriptor": "\nComments: Findings of EMNLP 2022\n",
    "authors": [
      "Qipeng Guo",
      "Yuqing Yang",
      "Hang Yan",
      "Xipeng Qiu",
      "Zheng Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.16064"
  },
  {
    "id": "arXiv:2210.16412",
    "title": "A State-Augmented Approach for Learning Optimal Resource Management  Decisions in Wireless Networks",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2207.02242",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2207.02242\n",
    "authors": [
      "Yi\u011fit Berkay Uslu",
      "Navid NaderiAlizadeh",
      "Mark Eisen",
      "Alejandro Ribeiro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2210.16412"
  },
  {
    "id": "arXiv:2210.16791",
    "title": "Adaptive Speech Quality Aware Complex Neural Network for Acoustic Echo  Cancellation with Supervised Contrastive Learning",
    "abstract": "Comments: Submitted to International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2023. Under review",
    "descriptor": "\nComments: Submitted to International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2023. Under review\n",
    "authors": [
      "Bozhong Liu",
      "Xiaoxi Yu",
      "Hantao Huang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.16791"
  },
  {
    "id": "arXiv:2210.17274",
    "title": "Imbalanced Data Classification via Generative Adversarial Network with  Application to Anomaly Detection in Additive Manufacturing Process",
    "abstract": "Imbalanced Data Classification via Generative Adversarial Network with  Application to Anomaly Detection in Additive Manufacturing Process",
    "descriptor": "",
    "authors": [
      "Jihoon Chung",
      "Bo Shen",
      "Zhenyu",
      "Kong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2210.17274"
  },
  {
    "id": "arXiv:2210.17326",
    "title": "Model Compression for DNN-Based Text-Independent Speaker Verification  Using Weight Quantization",
    "abstract": "Comments: Correct EER in Table 2",
    "descriptor": "\nComments: Correct EER in Table 2\n",
    "authors": [
      "Jingyu Li",
      "Zhaoyang Zhang",
      "Jiong Wang",
      "Tan Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2210.17326"
  },
  {
    "id": "arXiv:2211.00483",
    "title": "From Information to Affirmation: An Investigation on the Echo Chamber  Effect from YouTube Comments under Technology Product Reviews",
    "abstract": "Comments: 13 pages, 3 figures and 3 tables",
    "descriptor": "\nComments: 13 pages, 3 figures and 3 tables\n",
    "authors": [
      "Hongrui Jin"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.00483"
  },
  {
    "id": "arXiv:2211.00711",
    "title": "Alternative polynomial-time algorithm for Bipartite Matching",
    "abstract": "Alternative polynomial-time algorithm for Bipartite Matching",
    "descriptor": "",
    "authors": [
      "Sylvain Guillemot"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.00711"
  },
  {
    "id": "arXiv:2211.00889",
    "title": "Accelerating Parallel Stochastic Gradient Descent via Non-blocking  Mini-batches",
    "abstract": "Comments: 12 pages, 4 figures",
    "descriptor": "\nComments: 12 pages, 4 figures\n",
    "authors": [
      "Haoze He",
      "Parijat Dube"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.00889"
  },
  {
    "id": "arXiv:2211.01141",
    "title": "User-Entity Differential Privacy in Learning Natural Language Models",
    "abstract": "Comments: Accepted at IEEE BigData 2022",
    "descriptor": "\nComments: Accepted at IEEE BigData 2022\n",
    "authors": [
      "Phung Lai",
      "NhatHai Phan",
      "Tong Sun",
      "Rajiv Jain",
      "Franck Dernoncourt",
      "Jiuxiang Gu",
      "Nikolaos Barmpalios"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.01141"
  },
  {
    "id": "arXiv:2211.01458",
    "title": "Towards Zero-Shot Code-Switched Speech Recognition",
    "abstract": "Comments: 5 pages",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Brian Yan",
      "Matthew Wiesner",
      "Ondrej Klejch",
      "Preethi Jyothi",
      "Shinji Watanabe"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.01458"
  },
  {
    "id": "arXiv:2211.01700",
    "title": "Semantic 3D Grid Maps for Autonomous Driving",
    "abstract": "Comments: Submitted, accepted and presented at the 25th IEEE International Conference on Intelligent Transportation Systems (IEEE ITSC 2022)",
    "descriptor": "\nComments: Submitted, accepted and presented at the 25th IEEE International Conference on Intelligent Transportation Systems (IEEE ITSC 2022)\n",
    "authors": [
      "Ajinkya Khoche",
      "Maciej K Wozniak",
      "Daniel Duberg",
      "Patric Jensfelt"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.01700"
  },
  {
    "id": "arXiv:2211.01722",
    "title": "Hybrid-SD (H_SD): A new hybrid evaluation metric for automatic speech  recognition tasks",
    "abstract": "Hybrid-SD (H_SD): A new hybrid evaluation metric for automatic speech  recognition tasks",
    "descriptor": "",
    "authors": [
      "Zitha Sasindran",
      "Harsha Yelchuri",
      "Supreeth Rao",
      "T. V. Prabhakar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.01722"
  },
  {
    "id": "arXiv:2211.02516",
    "title": "Singlularity Avoidance with Application to Online Trajectory  Optimization for Serial Manipulators",
    "abstract": "Comments: 8 pages, 2 figures",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "Florian Beck",
      "Minh Nhat Vu",
      "Christian Hartl-Nesic",
      "Andreas Kugi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.02516"
  },
  {
    "id": "arXiv:2211.02545",
    "title": "GoRela: Go Relative for Viewpoint-Invariant Motion Forecasting",
    "abstract": "GoRela: Go Relative for Viewpoint-Invariant Motion Forecasting",
    "descriptor": "",
    "authors": [
      "Alexander Cui",
      "Sergio Casas",
      "Kelvin Wong",
      "Simon Suo",
      "Raquel Urtasun"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.02545"
  },
  {
    "id": "arXiv:2211.02700",
    "title": "Achieving mouse-level strategic evasion performance using real-time  computational planning",
    "abstract": "Comments: 6 pages, 4 figures, ICRA 2023",
    "descriptor": "\nComments: 6 pages, 4 figures, ICRA 2023\n",
    "authors": [
      "German Espinosa",
      "Gabrielle E. Wink",
      "Alexander T. Lai",
      "Daniel A. Dombeck",
      "Malcolm A. MacIver"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2211.02700"
  },
  {
    "id": "arXiv:2211.02767",
    "title": "Fuzzy Substring Matching: On-device Fuzzy Friend Search at Snapchat",
    "abstract": "Fuzzy Substring Matching: On-device Fuzzy Friend Search at Snapchat",
    "descriptor": "",
    "authors": [
      "Vasyl Pihur",
      "Scott Thompson"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.02767"
  },
  {
    "id": "arXiv:2211.02927",
    "title": "Unsupervised Machine Learning for Explainable Medicare Fraud Detection",
    "abstract": "Comments: Working paper",
    "descriptor": "\nComments: Working paper\n",
    "authors": [
      "Shubhranshu Shekhar",
      "Jetson Leder-Luis",
      "Leman Akoglu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02927"
  },
  {
    "id": "arXiv:2211.02937",
    "title": "Quantization Adaptor for Bit-Level Deep Learning-Based Massive MIMO CSI  Feedback",
    "abstract": "Comments: 9 pages, 8 figures, 5 tables. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice",
    "descriptor": "\nComments: 9 pages, 8 figures, 5 tables. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice\n",
    "authors": [
      "Xudong Zhang",
      "Zhilin Lu",
      "Rui Zeng",
      "Jintao Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.02937"
  },
  {
    "id": "arXiv:2211.02947",
    "title": "Prototypical quadruplet for few-shot class incremental learning",
    "abstract": "Prototypical quadruplet for few-shot class incremental learning",
    "descriptor": "",
    "authors": [
      "Sanchar Palit",
      "Biplab Banerjee",
      "Subhasis Chaudhuri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02947"
  },
  {
    "id": "arXiv:2211.03329",
    "title": "Implicit Graphon Neural Representation",
    "abstract": "Comments: 3 figures",
    "descriptor": "\nComments: 3 figures\n",
    "authors": [
      "Xinyue Xia",
      "Gal Mishne",
      "Yusu Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.03329"
  },
  {
    "id": "arXiv:2211.03365",
    "title": "Polynomial Kernels for Generalized Domination Problems",
    "abstract": "Comments: 19 pages, 6 figures",
    "descriptor": "\nComments: 19 pages, 6 figures\n",
    "authors": [
      "Pradeesha Ashok",
      "Rajath Rao",
      "Avi Tomar"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.03365"
  },
  {
    "id": "arXiv:2211.03877",
    "title": "The Need for Seed (in the abstract Tile Assembly Model)",
    "abstract": "Comments: To appear in the SODA 2023 proceedings",
    "descriptor": "\nComments: To appear in the SODA 2023 proceedings\n",
    "authors": [
      "Andrew Alseth",
      "Matthew J. Patitz"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2211.03877"
  },
  {
    "id": "arXiv:2211.03900",
    "title": "SLICT: Multi-input Multi-scale Surfel-Based Lidar-Inertial  Continuous-Time Odometry and Mapping",
    "abstract": "SLICT: Multi-input Multi-scale Surfel-Based Lidar-Inertial  Continuous-Time Odometry and Mapping",
    "descriptor": "",
    "authors": [
      "Thien-Minh Nguyen",
      "Daniel Duberg",
      "Patric Jensfelt",
      "Shenghai Yuan",
      "Lihua Xie"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.03900"
  },
  {
    "id": "arXiv:2211.03946",
    "title": "Understanding the Role of Mixup in Knowledge Distillation: An Empirical  Study",
    "abstract": "Comments: To be presented at WACV 2023",
    "descriptor": "\nComments: To be presented at WACV 2023\n",
    "authors": [
      "Hongjun Choi",
      "Eun Som Jeon",
      "Ankita Shukla",
      "Pavan Turaga"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.03946"
  },
  {
    "id": "arXiv:2211.03985",
    "title": "Adaptive Data Depth via Multi-Armed Bandits",
    "abstract": "Comments: Keywords: multi-armed bandits, data depth, adaptivity, large-scale computation, simplicial depth",
    "descriptor": "\nComments: Keywords: multi-armed bandits, data depth, adaptivity, large-scale computation, simplicial depth\n",
    "authors": [
      "Tavor Z. Baharav",
      "Tze Leung Lai"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.03985"
  },
  {
    "id": "arXiv:2211.04022",
    "title": "Integrated Sensing, Computation, and Communication: System Framework and  Performance Optimization",
    "abstract": "Integrated Sensing, Computation, and Communication: System Framework and  Performance Optimization",
    "descriptor": "",
    "authors": [
      "Yinghui He",
      "Guanding Yu",
      "Yunlong Cai",
      "Haiyan Luo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.04022"
  },
  {
    "id": "arXiv:2211.04049",
    "title": "Caching and Reproducibility: Making Data Science experiments faster and  FAIRer",
    "abstract": "Comments: 8 pages, 1 table",
    "descriptor": "\nComments: 8 pages, 1 table\n",
    "authors": [
      "Moritz Schubotz",
      "Ankit Satpute",
      "Andre Greiner-Petter",
      "Akiko Aizawa",
      "Bela Gipp"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.04049"
  },
  {
    "id": "arXiv:2211.04071",
    "title": "Improving performance of real-time full-band blind packet-loss  concealment with predictive network",
    "abstract": "Comments: Submitted to ICASSP 2023, 5 pages, 1 figure, 4 tables",
    "descriptor": "\nComments: Submitted to ICASSP 2023, 5 pages, 1 figure, 4 tables\n",
    "authors": [
      "Viet-Anh Nguyen",
      "Anh H. T. Nguyen",
      "Andy W. H. Khong"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.04071"
  },
  {
    "id": "arXiv:2211.04185",
    "title": "Coupled Modeling and Fusion Control for a Multi-modal Deformable  Land-air Robot",
    "abstract": "Coupled Modeling and Fusion Control for a Multi-modal Deformable  Land-air Robot",
    "descriptor": "",
    "authors": [
      "Xinyu Zhang",
      "Yuanhao Huang",
      "Kangyao Huang",
      "Ziqi Zhao",
      "Jingwei Li",
      "Huaping Liu",
      "Jun Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.04185"
  },
  {
    "id": "arXiv:2211.04279",
    "title": "Detecting Shortcuts in Medical Images -- A Case Study in Chest X-rays",
    "abstract": "Comments: Submitted to ISBI 2023",
    "descriptor": "\nComments: Submitted to ISBI 2023\n",
    "authors": [
      "Amelia Jim\u00e9nez-S\u00e1nchez",
      "Dovile Juodelyte",
      "Bethany Chamberlain",
      "Veronika Cheplygina"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04279"
  },
  {
    "id": "arXiv:2211.04352",
    "title": "Optimal shepherding and transport of a flock",
    "abstract": "Comments: A couple paragraphs removed for brevity",
    "descriptor": "\nComments: A couple paragraphs removed for brevity\n",
    "authors": [
      "Aditya Ranganathan",
      "Alexander Heyde",
      "Anupam Gupta",
      "L.Mahadevan"
    ],
    "subjectives": [
      "Soft Condensed Matter (cond-mat.soft)",
      "Robotics (cs.RO)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.04352"
  },
  {
    "id": "arXiv:2211.04393",
    "title": "Normalization Perturbation: A Simple Domain Generalization Method for  Real-World Domain Shifts",
    "abstract": "Normalization Perturbation: A Simple Domain Generalization Method for  Real-World Domain Shifts",
    "descriptor": "",
    "authors": [
      "Qi Fan",
      "Mattia Segu",
      "Yu-Wing Tai",
      "Fisher Yu",
      "Chi-Keung Tang",
      "Bernt Schiele",
      "Dengxin Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.04393"
  },
  {
    "id": "arXiv:2211.04406",
    "title": "Multiple Packing: Lower and Upper Bounds",
    "abstract": "Comments: The paper arXiv:2107.05161 has been split into three parts with new results added and significant revision. This paper is one of the three parts. The other two are arXiv:2211.04408 and arXiv:2211.04407",
    "descriptor": "\nComments: The paper arXiv:2107.05161 has been split into three parts with new results added and significant revision. This paper is one of the three parts. The other two are arXiv:2211.04408 and arXiv:2211.04407\n",
    "authors": [
      "Yihan Zhang",
      "Shashank Vatedka"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.04406"
  },
  {
    "id": "arXiv:2211.04407",
    "title": "Multiple Packing: Lower Bounds via Infinite Constellations",
    "abstract": "Comments: The paper arXiv:2107.05161 has been split into three parts with new results added and significant revision. This paper is one of the three parts. The other two are arXiv:2211.04408 and arXiv:2211.04406",
    "descriptor": "\nComments: The paper arXiv:2107.05161 has been split into three parts with new results added and significant revision. This paper is one of the three parts. The other two are arXiv:2211.04408 and arXiv:2211.04406\n",
    "authors": [
      "Yihan Zhang",
      "Shashank Vatedka"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.04407"
  },
  {
    "id": "arXiv:2211.04408",
    "title": "Multiple Packing: Lower Bounds via Error Exponents",
    "abstract": "Comments: The paper arXiv:2107.05161 has been split into three parts with new results added and significant revision. This paper is one of the three parts. The other two are arXiv:2211.04407 and arXiv:2211.04406",
    "descriptor": "\nComments: The paper arXiv:2107.05161 has been split into three parts with new results added and significant revision. This paper is one of the three parts. The other two are arXiv:2211.04407 and arXiv:2211.04406\n",
    "authors": [
      "Yihan Zhang",
      "Shashank Vatedka"
    ],
    "subjectives": [
      "Metric Geometry (math.MG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.04408"
  }
]
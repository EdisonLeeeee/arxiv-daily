[
  {
    "id": "arXiv:2211.12503",
    "title": "Is the Elephant Flying? Resolving Ambiguities in Text-to-Image  Generative Models",
    "abstract": "Natural language often contains ambiguities that can lead to\nmisinterpretation and miscommunication. While humans can handle ambiguities\neffectively by asking clarifying questions and/or relying on contextual cues\nand common-sense knowledge, resolving ambiguities can be notoriously hard for\nmachines. In this work, we study ambiguities that arise in text-to-image\ngenerative models. We curate a benchmark dataset covering different types of\nambiguities that occur in these systems. We then propose a framework to\nmitigate ambiguities in the prompts given to the systems by soliciting\nclarifications from the user. Through automatic and human evaluations, we show\nthe effectiveness of our framework in generating more faithful images aligned\nwith human intention in the presence of ambiguities.",
    "descriptor": "",
    "authors": [
      "Ninareh Mehrabi",
      "Palash Goyal",
      "Apurv Verma",
      "Jwala Dhamala",
      "Varun Kumar",
      "Qian Hu",
      "Kai-Wei Chang",
      "Richard Zemel",
      "Aram Galstyan",
      "Rahul Gupta"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.12503"
  },
  {
    "id": "arXiv:2211.12504",
    "title": "Identifying gender bias in blockbuster movies through the lens of  machine learning",
    "abstract": "The problem of gender bias is highly prevalent and well known. In this paper,\nwe have analysed the portrayal of gender roles in English movies, a medium that\neffectively influences society in shaping people's beliefs and opinions. First,\nwe gathered scripts of films from different genres and derived sentiments and\nemotions using natural language processing techniques. Afterwards, we converted\nthe scripts into embeddings, i.e. a way of representing text in the form of\nvectors. With a thorough investigation, we found specific patterns in male and\nfemale characters' personality traits in movies that align with societal\nstereotypes. Furthermore, we used mathematical and machine learning techniques\nand found some biases wherein men are shown to be more dominant and envious\nthan women, whereas women have more joyful roles in movies. In our work, we\nintroduce, to the best of our knowledge, a novel technique to convert dialogues\ninto an array of emotions by combining it with Plutchik's wheel of emotions.\nOur study aims to encourage reflections on gender equality in the domain of\nfilm and facilitate other researchers in analysing movies automatically instead\nof using manual approaches.",
    "descriptor": "",
    "authors": [
      "Muhammad Junaid Haris",
      "Aanchal Upreti",
      "Melih Kurtaran",
      "Filip Ginter",
      "Sebastien Lafond",
      "Sepinoud Azimi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12504"
  },
  {
    "id": "arXiv:2211.12506",
    "title": "Dynamic Loss For Robust Learning",
    "abstract": "Label noise and class imbalance commonly coexist in real-world data. Previous\nworks for robust learning, however, usually address either one type of the data\nbiases and underperform when facing them both. To mitigate this gap, this work\npresents a novel meta-learning based dynamic loss that automatically adjusts\nthe objective functions with the training process to robustly learn a\nclassifier from long-tailed noisy data. Concretely, our dynamic loss comprises\na label corrector and a margin generator, which respectively correct noisy\nlabels and generate additive per-class classification margins by perceiving the\nunderlying data distribution as well as the learning state of the classifier.\nEquipped with a new hierarchical sampling strategy that enriches a small amount\nof unbiased metadata with diverse and hard samples, the two components in the\ndynamic loss are optimized jointly through meta-learning and cultivate the\nclassifier to well adapt to clean and balanced test data. Extensive experiments\nshow our method achieves state-of-the-art accuracy on multiple real-world and\nsynthetic datasets with various types of data biases, including CIFAR-10/100,\nAnimal-10N, ImageNet-LT, and Webvision. Code will soon be publicly available.",
    "descriptor": "",
    "authors": [
      "Shenwang Jiang",
      "Jianan Li",
      "Jizhou Zhang",
      "Ying Wang",
      "Tingfa Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12506"
  },
  {
    "id": "arXiv:2211.12507",
    "title": "OpenFE: Automated Feature Generation beyond Expert-level Performance",
    "abstract": "The goal of automated feature generation is to liberate machine learning\nexperts from the laborious task of manual feature generation, which is crucial\nfor improving the learning performance of tabular data. The major challenge in\nautomated feature generation is to efficiently and accurately identify useful\nfeatures from a vast pool of candidate features. In this paper, we present\nOpenFE, an automated feature generation tool that provides competitive results\nagainst machine learning experts. OpenFE achieves efficiency and accuracy with\ntwo components: 1) a novel feature boosting method for accurately estimating\nthe incremental performance of candidate features. 2) a feature-scoring\nframework for retrieving effective features from a large number of candidates\nthrough successive featurewise halving and feature importance attribution.\nExtensive experiments on seven benchmark datasets show that OpenFE outperforms\nexisting baseline methods. We further evaluate OpenFE in two famous Kaggle\ncompetitions with thousands of data science teams participating. In one of the\ncompetitions, features generated by OpenFE with a simple baseline model can\nbeat 99.3\\% data science teams. In addition to the empirical results, we\nprovide a theoretical perspective to show that feature generation is beneficial\nin a simple yet representative setting. The code is available at\nhttps://github.com/ZhangTP1996/OpenFE.",
    "descriptor": "\nComments: 23 pages, 3 figures\n",
    "authors": [
      "Tianping Zhang",
      "Zheyu Zhang",
      "Zhiyuan Fan",
      "Haoyan Luo",
      "Fengyuan Liu",
      "Wei Cao",
      "Jian Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12507"
  },
  {
    "id": "arXiv:2211.12508",
    "title": "Time-Aware Datasets are Adaptive Knowledgebases for the New Normal",
    "abstract": "Recent advances in text classification and knowledge capture in language\nmodels have relied on availability of large-scale text datasets. However,\nlanguage models are trained on static snapshots of knowledge and are limited\nwhen that knowledge evolves. This is especially critical for misinformation\ndetection, where new types of misinformation continuously appear, replacing old\ncampaigns. We propose time-aware misinformation datasets to capture\ntime-critical phenomena. In this paper, we first present evidence of evolving\nmisinformation and show that incorporating even simple time-awareness\nsignificantly improves classifier accuracy. Second, we present COVID-TAD, a\nlarge-scale COVID-19 misinformation da-taset spanning 25 months. It is the\nfirst large-scale misinformation dataset that contains multiple snapshots of a\ndatastream and is orders of magnitude bigger than related misinformation\ndatasets. We describe the collection and labeling pro-cess, as well as\npreliminary experiments.",
    "descriptor": "",
    "authors": [
      "Abhijit Suprem",
      "Sanjyot Vaidya",
      "Joao Eduardo Ferreira",
      "Calton Pu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.12508"
  },
  {
    "id": "arXiv:2211.12509",
    "title": "SimVP: Towards Simple yet Powerful Spatiotemporal Predictive Learning",
    "abstract": "Recent years have witnessed remarkable advances in spatiotemporal predictive\nlearning, incorporating auxiliary inputs, elaborate neural architectures, and\nsophisticated training strategies. Although impressive, the system complexity\nof mainstream methods is increasing as well, which may hinder the convenient\napplications. This paper proposes SimVP, a simple spatiotemporal predictive\nbaseline model that is completely built upon convolutional networks without\nrecurrent architectures and trained by common mean squared error loss in an\nend-to-end fashion. Without introducing any extra tricks and strategies, SimVP\ncan achieve superior performance on various benchmark datasets. To further\nimprove the performance, we derive variants with the gated spatiotemporal\nattention translator from SimVP that can achieve better performance. We\ndemonstrate that SimVP has strong generalization and extensibility on\nreal-world datasets through extensive experiments. The significant reduction in\ntraining cost makes it easier to scale to complex scenarios. We believe SimVP\ncan serve as a solid baseline to benefit the spatiotemporal predictive learning\ncommunity.",
    "descriptor": "",
    "authors": [
      "Cheng Tan",
      "Zhangyang Gao",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12509"
  },
  {
    "id": "arXiv:2211.12511",
    "title": "Scalable and Effective Conductance-based Graph Clustering",
    "abstract": "Conductance-based graph clustering has been recognized as a fundamental\noperator in numerous graph analysis applications. Despite the significant\nsuccess of conductance-based graph clustering, existing algorithms are either\nhard to obtain satisfactory clustering qualities, or have high time and space\ncomplexity to achieve provable clustering qualities. To overcome these\nlimitations, we devise a powerful \\textit{peeling}-based graph clustering\nframework \\textit{PCon}. We show that many existing solutions can be reduced to\nour framework. Namely, they first define a score function for each vertex, then\niteratively remove the vertex with the smallest score. Finally, they output the\nresult with the smallest conductance during the peeling process. Based on our\nframework, we propose two novel algorithms \\textit{PCon\\_core} and\n\\emph{PCon\\_de} with linear time and space complexity, which can efficiently\nand effectively identify clusters from massive graphs with more than a few\nbillion edges. Surprisingly, we prove that \\emph{PCon\\_de} can identify\nclusters with near-constant approximation ratio, resulting in an important\ntheoretical improvement over the well-known quadratic Cheeger bound. Empirical\nresults on real-life and synthetic datasets show that our algorithms can\nachieve 5$\\sim$42 times speedup with a high clustering accuracy, while using\n1.4$\\sim$7.8 times less memory than the baseline algorithms.",
    "descriptor": "",
    "authors": [
      "Longlong Lin",
      "Rong-Hua Li",
      "Tao Jia"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12511"
  },
  {
    "id": "arXiv:2211.12512",
    "title": "NLP meets psychotherapy: Using predicted client emotions and  self-reported client emotions to measure emotional coherence",
    "abstract": "Emotions are experienced and expressed through various response systems.\nCoherence between emotional experience and emotional expression is considered\nimportant to clients' well being. To date, emotional coherence (EC) has been\nstudied at a single time point using lab-based tasks with relatively small\ndatasets. No study has examined EC between the subjective experience of\nemotions and emotion expression in therapy or whether this coherence is\nassociated with clients' well being. Natural language Processing (NLP)\napproaches have been applied to identify emotions from psychotherapy dialogue,\nwhich can be implemented to study emotional processes on a larger scale.\nHowever, these methods have yet to be used to study coherence between emotional\nexperience and emotional expression over the course of therapy and whether it\nrelates to clients' well-being. This work presents an end-to-end approach where\nwe use emotion predictions from our transformer based emotion recognition model\nto study emotional coherence and its diagnostic potential in psychotherapy\nresearch. We first employ our transformer based approach on a Hebrew\npsychotherapy dataset to automatically label clients' emotions at utterance\nlevel in psychotherapy dialogues. We subsequently investigate the emotional\ncoherence between clients' self-reported emotional states and our model-based\nemotion predictions. We also examine the association between emotional\ncoherence and clients' well being. Our findings indicate a significant\ncorrelation between clients' self-reported emotions and positive and negative\nemotions expressed verbally during psychotherapy sessions. Coherence in\npositive emotions was also highly correlated with clients well-being. These\nresults illustrate how NLP can be applied to identify important emotional\nprocesses in psychotherapy to improve diagnosis and treatment for clients\nsuffering from mental-health problems.",
    "descriptor": "\nComments: Accepted at Empowering Communities: A Participatory Approach to AI for Mental Health, NeurIPS 2022 VIRTUAL Workshop\n",
    "authors": [
      "Neha Warikoo",
      "Tobias Mayer",
      "Dana Atzil-Slonim",
      "Amir Eliassaf",
      "Shira Haimovitz",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.12512"
  },
  {
    "id": "arXiv:2211.12513",
    "title": "Real-time response estimation of structural vibration with inverse force  identification",
    "abstract": "This study aimed to develop a virtual sensing algorithm of structural\nvibration for the real-time identification of unmeasured information. First,\ncertain local point vibration responses (such as displacement and acceleration)\nare measured using physical sensors, and the data sets are extended using a\nnumerical model to cover the unmeasured quantities through the entire spatial\ndomain in the real-time computation process. A modified time integrator is then\nproposed to synchronize the physical sensors and the numerical model using\ninverse dynamics. In particular, an efficient inverse force identification\nmethod is derived using implicit time integration. The second-order ordinary\ndifferential formulation and its projection-based reduced-order modeling is\nused to avoid two times larger degrees of freedom within the state space form.\nThen, the Tikhonov regularization noise-filtering algorithm is employed instead\nof Kalman filtering. The performance of the proposed method is investigated on\nboth numerical and experimental testbeds under sinusoidal and random excitation\nloading conditions. In the experimental test, the algorithm is implemented on a\nsingle-board computer, including inverse force identification and unmeasured\nresponse prediction. The results show that the virtual sensing algorithm can\naccurately identify unmeasured information, forces, and displacements\nthroughout the vibration model in real time in a very limited computing\nenvironment.",
    "descriptor": "\nComments: 24 Pages, 15 Figures, 10 Tables\n",
    "authors": [
      "Seungin Oh",
      "Hanmin Lee",
      "Jai-Kyung Lee",
      "Hyungchul Yoon",
      "Jin-Gyun Kim"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.12513"
  },
  {
    "id": "arXiv:2211.12514",
    "title": "AugOp: Inject Transformation into Neural Operator",
    "abstract": "In this paper, we propose a simple and general approach to augment regular\nconvolution operator by injecting extra group-wise transformation during\ntraining and recover it during inference. Extra transformation is carefully\nselected to ensure it can be merged with regular convolution in each group and\nwill not change the topological structure of regular convolution during\ninference. Compared with regular convolution operator, our approach (AugConv)\ncan introduce larger learning capacity to improve model performance during\ntraining but will not increase extra computational overhead for model\ndeployment. Based on ResNet, we utilize AugConv to build convolutional neural\nnetworks named AugResNet. Result on image classification dataset Cifar-10 shows\nthat AugResNet outperforms its baseline in terms of model performance.",
    "descriptor": "",
    "authors": [
      "Longqing Ye"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12514"
  },
  {
    "id": "arXiv:2211.12515",
    "title": "Smart Agriculture : A Novel Multilevel Approach for Agricultural Risk  Assessment over Unstructured Data",
    "abstract": "Detecting opportunities and threats from massive text data is a challenging\ntask for most. Traditionally, companies would rely mainly on structured data to\ndetect and predict risks, losing a huge amount of information that could be\nextracted from unstructured text data. Fortunately, artificial intelligence\ncame to remedy this issue by innovating in data extraction and processing\ntechniques, allowing us to understand and make use of Natural Language data and\nturning it into structures that a machine can process and extract insight from.\nUncertainty refers to a state of not knowing what will happen in the future.\nThis paper aims to leverage natural language processing and machine learning\ntechniques to model uncertainties and evaluate the risk level in each\nuncertainty cluster using massive text data.",
    "descriptor": "",
    "authors": [
      "Hasna Najmi",
      "Mounia Mikram",
      "Maryem Rhanoui",
      "Siham Yousfi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12515"
  },
  {
    "id": "arXiv:2211.12528",
    "title": "Rate-Splitting Enabled Multi-Connectivity in Mixed-Criticality Systems",
    "abstract": "The enormous quality of service (QoS) demands posed by mission-critical\nuse-cases of future 5G/6G wireless communication raise the need for\nresource-efficient highly reliable and low latency connectivity solutions.\nMulti-connectivity is considered a promising yet resource demanding approach to\nenhance reliability. In this work, we study the potential of the rate-splitting\nmultiple access (RSMA) framework as an efficient way to enable uplink\nmulti-connectivity for data transmissions with particularly high reliability\nrequirements. Mapping high-criticality data onto the common stream allows it to\nbe decoded at multiple access points (APs), which enhances reliability, while\nthe private stream is utilized to serve applications with less stringent\nrequirements. We propose a criticality-aware RSMA-based transmission scheme\nwith short blocklength coding and derive an iterative power allocation\nalgorithm by means of successive convex approximation (SCA). The proposed\nscheme is shown to achieve an expanded stability rate region compared to two\nbaseline schemes. Moreover, it turns out to be less impacted by short\nblocklength while leading to substantial rate gains, particularly in the high\nSNR regime.",
    "descriptor": "\nComments: 6 pages, 4 figures, submitted to IEEE ICC 2023\n",
    "authors": [
      "Yasemin Karacora",
      "Aydin Sezgin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.12528"
  },
  {
    "id": "arXiv:2211.12539",
    "title": "Universal Variable-to-Fixed Length Lossy Compression at Finite  Blocklengths",
    "abstract": "We consider universal variable-to-fixed length compression of memoryless\nsources with a fidelity criterion. We design a dictionary codebook over the\nreproduction alphabet which is used to parse the source stream. Once a source\nsubsequence is within a specified distortion of a dictionary codeword, the\nindex of the codeword is emitted as the reproduced string. Our proposed\ndictionary consists of coverings of type classes in the boundary of transition\nfrom low to high empirical lossy rate. We derive the asymptotics of the\n\\epsilon-coding rate (up to the third-order term) of our coding scheme for\nlarge enough dictionaries.",
    "descriptor": "",
    "authors": [
      "Nematollah Iri"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.12539"
  },
  {
    "id": "arXiv:2211.12541",
    "title": "Deterministic Approximation Algorithms for Volumes of Spectrahedra",
    "abstract": "We give a method for computing asymptotic formulas and approximations for the\nvolumes of spectrahedra, based on the maximum-entropy principle from\nstatistical physics. The method gives an approximate volume formula based on a\nsingle convex optimization problem of minimizing $-\\log \\det P$ over the\nspectrahedron. Spectrahedra can be described as affine slices of the convex\ncone of positive semi-definite (PSD) matrices, and the method yields efficient\ndeterministic approximation algorithms and asymptotic formulas whenever the\nnumber of affine constraints is sufficiently dominated by the dimension of the\nPSD cone.\nOur approach is inspired by the work of Barvinok and Hartigan who used an\nanalogous framework for approximately computing volumes of polytopes.\nSpectrahedra, however, possess a remarkable feature not shared by polytopes, a\nnew fact that we also prove: central sections of the set of density matrices\n(the quantum version of the simplex) all have asymptotically the same volume.\nThis allows for very general approximation algorithms, which apply to large\nclasses of naturally occurring spectrahedra.\nWe give two main applications of this method. First, we apply this method to\nwhat we call the \"multi-way Birkhoff spectrahedron\" and obtain an explicit\nasymptotic formula for its volume. This spectrahedron is the set of quantum\nstates with maximal entanglement (i.e., the quantum states having univariant\nquantum marginals equal to the identity matrix) and is the quantum analog of\nthe multi-way Birkhoff polytope. Second, we apply this method to explicitly\ncompute the asymptotic volume of central sections of the set of density\nmatrices.",
    "descriptor": "",
    "authors": [
      "Mahmut Levent Do\u011fan",
      "Jonathan Leake",
      "Mohan Ravichandran"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Mathematical Physics (math-ph)",
      "Combinatorics (math.CO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.12541"
  },
  {
    "id": "arXiv:2211.12542",
    "title": "PVT3D: Point Voxel Transformers for Place Recognition from Sparse Lidar  Scans",
    "abstract": "Place recognition based on point cloud (LiDAR) scans is an important module\nfor achieving robust autonomy in robots or self-driving vehicles. Training deep\nnetworks to match such scans presents a difficult trade-off: a higher spatial\nresolution of the network's intermediate representations is needed to perform\nfine-grained matching of subtle geometric features, but growing it too large\nmakes the memory requirements infeasible. In this work, we propose a\nPoint-Voxel Transformer network (PVT3D) that achieves robust fine-grained\nmatching with low memory requirements. It leverages a sparse voxel branch to\nextract and aggregate information at a lower resolution and a point-wise branch\nto obtain fine-grained local information. A novel hierarchical cross-attention\ntransformer (HCAT) uses queries from one branch to try to match structures in\nthe other branch, ensuring that both extract self-contained descriptors of the\npoint cloud (rather than one branch dominating), but using both to inform the\noutput global descriptor of the point cloud. Extensive experiments show that\nthe proposed PVT3D method surpasses the state-of-the-art by a large amount on\nseveral datasets (Oxford RobotCar, TUM, USyd). For instance, we achieve AR@1 of\n85.6% on the TUM dataset, which surpasses the strongest prior model by ~15%.",
    "descriptor": "\nComments: 11 pages, 7 figures, 5 tables\n",
    "authors": [
      "Yan Xia",
      "Mariia Gladkova",
      "Rui Wang",
      "Jo\u00e3o F. Henriques",
      "Daniel Cremers",
      "Uwe Stilla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12542"
  },
  {
    "id": "arXiv:2211.12544",
    "title": "Zero NeRF: Registration with Zero Overlap",
    "abstract": "We present Zero-NeRF, a projective surface registration method that, to the\nbest of our knowledge, offers the first general solution capable of alignment\nbetween scene representations with minimal or zero visual correspondence. To do\nthis, we enforce consistency between visible surfaces of partial and complete\nreconstructions, which allows us to constrain occluded geometry. We use a NeRF\nas our surface representation and the NeRF rendering pipeline to perform this\nalignment. To demonstrate the efficacy of our method, we register real-world\nscenes from opposite sides with infinitesimal overlaps that cannot be\naccurately registered using prior methods, and we compare these results against\nwidely used registration methods.",
    "descriptor": "",
    "authors": [
      "Casey Peat",
      "Oliver Batchelor",
      "Richard Green",
      "James Atlas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12544"
  },
  {
    "id": "arXiv:2211.12551",
    "title": "Sparse Probabilistic Circuits via Pruning and Growing",
    "abstract": "Probabilistic circuits (PCs) are a tractable representation of probability\ndistributions allowing for exact and efficient computation of likelihoods and\nmarginals. There has been significant recent progress on improving the scale\nand expressiveness of PCs. However, PC training performance plateaus as model\nsize increases. We discover that most capacity in existing large PC structures\nis wasted: fully-connected parameter layers are only sparsely used. We propose\ntwo operations: pruning and growing, that exploit the sparsity of PC\nstructures. Specifically, the pruning operation removes unimportant\nsub-networks of the PC for model compression and comes with theoretical\nguarantees. The growing operation increases model capacity by increasing the\nsize of the latent space. By alternatingly applying pruning and growing, we\nincrease the capacity that is meaningfully used, allowing us to significantly\nscale up PC learning. Empirically, our learner achieves state-of-the-art\nlikelihoods on MNIST-family image datasets and on Penn Tree Bank language data\ncompared to other PC learners and less tractable deep generative models such as\nflow-based models and variational autoencoders (VAEs).",
    "descriptor": "\nComments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022)\n",
    "authors": [
      "Meihua Dang",
      "Anji Liu",
      "Guy Van den Broeck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12551"
  },
  {
    "id": "arXiv:2211.12560",
    "title": "Contextually Aware Intelligent Control Agents for Heterogeneous Swarms",
    "abstract": "An emerging challenge in swarm shepherding research is to design effective\nand efficient artificial intelligence algorithms that maintain a\nlow-computational ceiling while increasing the swarm's abilities to operate in\ndiverse contexts. We propose a methodology to design a context-aware\nswarm-control intelligent agent. The intelligent control agent (shepherd) first\nuses swarm metrics to recognise the type of swarm it interacts with to then\nselect a suitable parameterisation from its behavioural library for that\nparticular swarm type. The design principle of our methodology is to increase\nthe situation awareness (i.e. information contents) of the control agent\nwithout sacrificing the low-computational cost necessary for efficient swarm\ncontrol. We demonstrate successful shepherding in both homogeneous and\nheterogeneous swarms.",
    "descriptor": "\nComments: 37 pages, 3 figures, 11 tables\n",
    "authors": [
      "Adam Hepworth",
      "Aya Hussein",
      "Darryn Reid",
      "Hussein Abbass"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12560"
  },
  {
    "id": "arXiv:2211.12561",
    "title": "Retrieval-Augmented Multimodal Language Modeling",
    "abstract": "Recent multimodal models such as DALL-E and CM3 have achieved remarkable\nprogress in text-to-image and image-to-text generation. However, these models\nstore all learned knowledge (e.g., the appearance of the Eiffel Tower) in the\nmodel parameters, requiring increasingly larger models and training data to\ncapture more knowledge. To integrate knowledge in a more scalable and modular\nway, we propose a retrieval-augmented multimodal model, which enables a base\nmultimodal model (generator) to refer to relevant knowledge fetched by a\nretriever from external memory (e.g., multimodal documents on the web).\nSpecifically, we implement a retriever using the pretrained CLIP model and a\ngenerator using the CM3 Transformer architecture, and train this model using\nthe LAION dataset. Our resulting model, named Retrieval-Augmented CM3 (RA-CM3),\nis the first multimodal model that can retrieve and generate mixtures of text\nand images. We show that RA-CM3 significantly outperforms baseline multimodal\nmodels such as DALL-E and CM3 on both image and caption generation tasks (12\nFID and 17 CIDEr improvements on MS-COCO), while requiring much less compute\nfor training (<30% of DALL-E). Moreover, we show that RA-CM3 exhibits novel\ncapabilities such as knowledge-intensive image generation and multimodal\nin-context learning.",
    "descriptor": "",
    "authors": [
      "Michihiro Yasunaga",
      "Armen Aghajanyan",
      "Weijia Shi",
      "Rich James",
      "Jure Leskovec",
      "Percy Liang",
      "Mike Lewis",
      "Luke Zettlemoyer",
      "Wen-tau Yih"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12561"
  },
  {
    "id": "arXiv:2211.12562",
    "title": "HashSDF: Accurate Implicit Surfaces with Fast Local Features on  Permutohedral Lattices",
    "abstract": "Neural radiance-density field methods have become increasingly popular for\nthe task of novel-view rendering. Their recent extension to hash-based\npositional encoding ensures fast training and inference with state-of-the-art\nresults. However, density-based methods struggle with recovering accurate\nsurface geometry. Hybrid methods alleviate this issue by optimizing the density\nbased on an underlying SDF. However, current SDF methods are overly smooth and\nmiss fine geometric details. In this work, we combine the strengths of these\ntwo lines of work in a novel hash-based implicit surface representation. We\npropose improvements to the two areas by replacing the voxel hash encoding with\na permutohedral lattice which optimizes faster in three and higher dimensions.\nWe additionally propose a regularization scheme which is crucial for recovering\nhigh-frequency geometric detail. We evaluate our method on multiple datasets\nand show that we can recover geometric detail at the level of pores and\nwrinkles while using only RGB images for supervision. Furthermore, using sphere\ntracing we can render novel views at 30 fps on an RTX 3090.",
    "descriptor": "",
    "authors": [
      "Radu Alexandru Rosu",
      "Sven Behnke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12562"
  },
  {
    "id": "arXiv:2211.12565",
    "title": "A Novel Center-based Deep Contrastive Metric Learning Method for the  Detection of Polymicrogyria in Pediatric Brain MRI",
    "abstract": "Polymicrogyria (PMG) is a disorder of cortical organization mainly seen in\nchildren, which can be associated with seizures, developmental delay and motor\nweakness. PMG is typically diagnosed on magnetic resonance imaging (MRI) but\nsome cases can be challenging to detect even for experienced radiologists. In\nthis study, we create an open pediatric MRI dataset (PPMR) with PMG and\ncontrols from the Children's Hospital of Eastern Ontario (CHEO), Ottawa,\nCanada. The differences between PMG MRIs and control MRIs are subtle and the\ntrue distribution of the features of the disease is unknown. This makes\nautomatic detection of cases of potential PMG in MRI difficult. We propose an\nanomaly detection method based on a novel center-based deep contrastive metric\nlearning loss function (cDCM) which enables the automatic detection of cases of\npotential PMG. Additionally, based on our proposed loss function, we customize\na deep learning model structure that integrates dilated convolution,\nsqueeze-and-excitation blocks and feature fusion for our PPMR dataset. Despite\nworking with a small and imbalanced dataset our method achieves 92.01% recall\nat 55.04% precision. This will facilitate a computer aided tool for\nradiologists to select potential PMG MRIs. To the best of our knowledge, this\nresearch is the first to apply machine learning techniques to identify PMG from\nMRI only.",
    "descriptor": "\nComments: 24 pages, 13 figures\n",
    "authors": [
      "Lingfeng Zhang",
      "Nishard Abdeen",
      "Jochen Lang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12565"
  },
  {
    "id": "arXiv:2211.12570",
    "title": "Predicting the Type and Target of Offensive Social Media Posts in  Marathi",
    "abstract": "The presence of offensive language on social media is very common motivating\nplatforms to invest in strategies to make communities safer. This includes\ndeveloping robust machine learning systems capable of recognizing offensive\ncontent online. Apart from a few notable exceptions, most research on automatic\noffensive language identification has dealt with English and a few other high\nresource languages such as French, German, and Spanish. In this paper we\naddress this gap by tackling offensive language identification in Marathi, a\nlow-resource Indo-Aryan language spoken in India. We introduce the Marathi\nOffensive Language Dataset v.2.0 or MOLD 2.0 and present multiple experiments\non this dataset. MOLD 2.0 is a much larger version of MOLD with expanded\nannotation to the levels B (type) and C (target) of the popular OLID taxonomy.\nMOLD 2.0 is the first hierarchical offensive language dataset compiled for\nMarathi, thus opening new avenues for research in low-resource Indo-Aryan\nlanguages. Finally, we also introduce SeMOLD, a larger dataset annotated\nfollowing the semi-supervised methods presented in SOLID.",
    "descriptor": "\nComments: This is a preprint of an article published in the Journal of Intelligent Information Systems, Springer. The final authenticated version is available online at this https URL\n",
    "authors": [
      "Marcos Zampieri",
      "Tharindu Ranasinghe",
      "Mrinal Chaudhari",
      "Saurabh Gaikwad",
      "Prajwal Krishna",
      "Mayuresh Nene",
      "Shrunali Paygude"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.12570"
  },
  {
    "id": "arXiv:2211.12571",
    "title": "\"Coherent Mode\" for the World's Public Square",
    "abstract": "Systems for large scale deliberation have resolved polarized issues and\nshifted agenda setting into the public's hands. These systems integrate\nbridging-based ranking algorithms - including group informed consensus\nimplemented in Polis and the continuous matrix factorization approach\nimplemented by Twitter Birdwatch - making it possible to highlight statements\nwhich enjoy broad support from a diversity of opinion groups.\nPolis has been productively employed to foster more constructive political\ndeliberation at nation scale in law making exercises. Twitter Birdwatch is\nimplemented with the intention of addressing misinformation in the global\npublic square. From one perspective, Twitter Birdwatch can be viewed as an\nanti-misinformation system which has deliberative aspects. But it can also be\nviewed as a first step towards a generalized deliberative system, using\nTwitter's misinformation problem as a proving ground.\nIn this paper, we propose that Twitter could adapt Birdwatch to produce maps\nof public opinion. We describe a system in five parts for generalizing\nBirdwatch: activation of a deliberative system and topic selection, population\nsampling and the role of expert networks, deliberation, reporting interpretable\nresults and finally distribution of the results to the public and those in\npower.",
    "descriptor": "",
    "authors": [
      "Colin Megill",
      "Elizabeth Barry",
      "Christopher Small"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Human-Computer Interaction (cs.HC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.12571"
  },
  {
    "id": "arXiv:2211.12572",
    "title": "Plug-and-Play Diffusion Features for Text-Driven Image-to-Image  Translation",
    "abstract": "Large-scale text-to-image generative models have been a revolutionary\nbreakthrough in the evolution of generative AI, allowing us to synthesize\ndiverse images that convey highly complex visual concepts. However, a pivotal\nchallenge in leveraging such models for real-world content creation tasks is\nproviding users with control over the generated content. In this paper, we\npresent a new framework that takes text-to-image synthesis to the realm of\nimage-to-image translation -- given a guidance image and a target text prompt,\nour method harnesses the power of a pre-trained text-to-image diffusion model\nto generate a new image that complies with the target text, while preserving\nthe semantic layout of the source image. Specifically, we observe and\nempirically demonstrate that fine-grained control over the generated structure\ncan be achieved by manipulating spatial features and their self-attention\ninside the model. This results in a simple and effective approach, where\nfeatures extracted from the guidance image are directly injected into the\ngeneration process of the target image, requiring no training or fine-tuning\nand applicable for both real or generated guidance images. We demonstrate\nhigh-quality results on versatile text-guided image translation tasks,\nincluding translating sketches, rough drawings and animations into realistic\nimages, changing of the class and appearance of objects in a given image, and\nmodifications of global qualities such as lighting and color.",
    "descriptor": "",
    "authors": [
      "Narek Tumanyan",
      "Michal Geyer",
      "Shai Bagon",
      "Tali Dekel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12572"
  },
  {
    "id": "arXiv:2211.12578",
    "title": "Online Federated Learning via Non-Stationary Detection and Adaptation  amidst Concept Drift",
    "abstract": "Federated Learning (FL) is an emerging domain in the broader context of\nartificial intelligence research. Methodologies pertaining to FL assume\ndistributed model training, consisting of a collection of clients and a server,\nwith the main goal of achieving optimal global model with restrictions on data\nsharing due to privacy concerns. It is worth highlighting that the diverse\nexisting literature in FL mostly assume stationary data generation processes;\nsuch an assumption is unrealistic in real-world conditions where concept drift\noccurs due to, for instance, seasonal or period observations, faults in sensor\nmeasurements. In this paper, we introduce a multiscale algorithmic framework\nwhich combines theoretical guarantees of \\textit{FedAvg} and \\textit{FedOMD}\nalgorithms in near stationary settings with a non-stationary detection and\nadaptation technique to ameliorate FL generalization performance in the\npresence of model/concept drifts. We present a multi-scale algorithmic\nframework leading to $\\Tilde{\\mathcal{O}} ( \\min \\{ \\sqrt{LT} ,\n\\Delta^{\\frac{1}{3}}T^{\\frac{2}{3}} + \\sqrt{T} \\})$ \\textit{dynamic regret} for\n$T$ rounds with an underlying general convex loss function, where $L$ is the\nnumber of times non-stationary drifts occured and $\\Delta$ is the cumulative\nmagnitude of drift experienced within $T$ rounds.",
    "descriptor": "",
    "authors": [
      "Bhargav Ganguly",
      "Vaneet Aggarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.12578"
  },
  {
    "id": "arXiv:2211.12581",
    "title": "Monte Carlo Forest Search: UNSAT Solver Synthesis via Reinforcement  learning",
    "abstract": "We introduce Monte Carlo Forest Search (MCFS), an offline algorithm for\nautomatically synthesizing strong tree-search solvers for proving\n\\emph{unsatisfiability} on given distributions, leveraging ideas from the Monte\nCarlo Tree Search (MCTS) algorithm that led to breakthroughs in AlphaGo. The\ncrucial difference between proving unsatisfiability and existing applications\nof MCTS, is that policies produce trees rather than paths. Rather than finding\na good path (solution) within a tree, the search problem becomes searching for\na small proof tree within a forest of candidate proof trees. We introduce two\nkey ideas to adapt to this setting. First, we estimate tree size with paths,\nvia the unbiased approximation from Knuth (1975). Second, we query a strong\nsolver at a user-defined depth rather than learning a policy across the whole\ntree, in order to focus our policy search on early decisions, which offer the\ngreatest potential for reducing tree size. We then present MCFS-SAT, an\nimplementation of MCFS for learning branching policies for solving the Boolean\nsatisfiability (SAT) problem that required many modifications from AlphaGo. We\nmatched or improved performance over a strong baseline on two well-known SAT\ndistributions (\\texttt{sgen}, \\texttt{random}). Notably, we improved running\ntime by 9\\% on \\texttt{sgen} over the \\texttt{kcnfs} solver and even further\nover the strongest UNSAT solver from the 2021 SAT competition.",
    "descriptor": "",
    "authors": [
      "Chris Cameron",
      "Jason Hartford",
      "Taylor Lundy",
      "Tuan Truong",
      "Alan Milligan",
      "Rex Chen",
      "Kevin Leyton-Brown"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12581"
  },
  {
    "id": "arXiv:2211.12584",
    "title": "Big Earth Data and Machine Learning for Sustainable and Resilient  Agriculture",
    "abstract": "Big streams of Earth images from satellites or other platforms (e.g., drones\nand mobile phones) are becoming increasingly available at low or no cost and\nwith enhanced spatial and temporal resolution. This thesis recognizes the\nunprecedented opportunities offered by the high quality and open access Earth\nobservation data of our times and introduces novel machine learning and big\ndata methods to properly exploit them towards developing applications for\nsustainable and resilient agriculture. The thesis addresses three distinct\nthematic areas, i.e., the monitoring of the Common Agricultural Policy (CAP),\nthe monitoring of food security and applications for smart and resilient\nagriculture. The methodological innovations of the developments related to the\nthree thematic areas address the following issues: i) the processing of big\nEarth Observation (EO) data, ii) the scarcity of annotated data for machine\nlearning model training and iii) the gap between machine learning outputs and\nactionable advice.\nThis thesis demonstrated how big data technologies such as data cubes,\ndistributed learning, linked open data and semantic enrichment can be used to\nexploit the data deluge and extract knowledge to address real user needs.\nFurthermore, this thesis argues for the importance of semi-supervised and\nunsupervised machine learning models that circumvent the ever-present challenge\nof scarce annotations and thus allow for model generalization in space and\ntime. Specifically, it is shown how merely few ground truth data are needed to\ngenerate high quality crop type maps and crop phenology estimations. Finally,\nthis thesis argues there is considerable distance in value between model\ninferences and decision making in real-world scenarios and thereby showcases\nthe power of causal and interpretable machine learning in bridging this gap.",
    "descriptor": "\nComments: Phd thesis\n",
    "authors": [
      "Vasileios Sitokonstantinou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12584"
  },
  {
    "id": "arXiv:2211.12586",
    "title": "Modeling System Events and Negative Events Using Thinging Machines Based  on Lupascian Logic",
    "abstract": "This paper is an exploration of the ontological foundations of conceptual\nmodeling that addresses the concept of events and related notions. Development\nmodels that convey how things change over space and time demand continued\nattention in systems and software engineering. In this context, foundational\nmatters in modeling systems include the definition of an event, the types of\nevents, and the kinds of relationships that can be recognized among events.\nAlthough a broad spectrum of research of such issues exists in various fields\nof study, events have extensive applicability in computing (e.g., event-driven\nprogramming, architecture, data modeling, automation, and surveillance). While\nthese computing notions are diverse, their event-based nature lets us apply\nmany of the same software engineering techniques to all of them. In this paper,\nthe focus is on addressing the dynamic concepts of system events and negative\nevents. Specifically, we concentrate on what computer scientists would refer to\nas an event grammar and event calculus. Analyzing the concept of event would\nfurther the understanding of the event notion and provide a sound foundation\nfor improving the theory and practice of conceptual modeling. An event in\ncomputer science has many definitions (e.g., anything that happens, changes in\nthe properties of objects, and the occurrence of and transition between\nstates). This paper is based upon a different conceptualization using thinging\nmachines and Lupascian logic to define negative events. An event is defined as\na time penetrated domain s region, which is described in terms of things and\nfive-action machines. Accordingly, samples from event grammar and event\ncalculus are remodeled and analyzed in terms of this definition. The results\npoint to an enriched modeling technique with an enhanced conceptualization of\nevents that can benefit behavior modeling in systems.",
    "descriptor": "\nComments: 12 pages, 29 figures\n",
    "authors": [
      "Sabah Al-Fedaghi"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.12586"
  },
  {
    "id": "arXiv:2211.12588",
    "title": "Program of Thoughts Prompting: Disentangling Computation from Reasoning  for Numerical Reasoning Tasks",
    "abstract": "Recently, there has been significant progress in teaching language models to\nperform step-by-step reasoning to solve complex numerical reasoning tasks.\nChain-of-thoughts prompting (CoT) is by far the state-of-art method for these\ntasks. CoT uses language models to perform both reasoning and computation in\nthe multi-step `thought' process. To disentangle computation from reasoning, we\npropose `Program of Thoughts' (PoT), which uses language models (mainly Codex)\nto express the reasoning process as a program. The computation is relegated to\nan external computer, which executes the generated programs to derive the\nanswer. We evaluate PoT on five math word problem datasets (GSM, AQuA, SVAMP,\nTabMWP, MultiArith) and three financial-QA datasets (FinQA, ConvFinQA, TATQA)\nfor both few-shot and zero-shot setups. Under both few-shot and zero-shot\nsettings, PoT can show an average performance gain over CoT by around 12\\%\nacross all the evaluated datasets. By combining PoT with self-consistency\ndecoding, we can achieve SoTA performance on all math problem datasets and\nnear-SoTA performance on financial datasets. All of our data and code are\nreleased in\nGithub\\footnote{\\url{https://github.com/wenhuchen/Program-of-Thoughts}}.",
    "descriptor": "",
    "authors": [
      "Wenhu Chen",
      "Xueguang Ma",
      "Xinyi Wang",
      "William W. Cohen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12588"
  },
  {
    "id": "arXiv:2211.12589",
    "title": "Building Squares with Optimal State Complexity in Restricted Active  Self-Assembly",
    "abstract": "Tile Automata is a recently defined model of self-assembly that borrows many\nconcepts from cellular automata to create active self-assembling systems where\nchanges may be occurring within an assembly without requiring attachment. This\nmodel has been shown to be powerful, but many fundamental questions have yet to\nbe explored. Here, we study the state complexity of assembling $n \\times n$\nsquares in seeded Tile Automata systems where growth starts from a seed and\ntiles may attach one at a time, similar to the abstract Tile Assembly Model. We\nprovide optimal bounds for three classes of seeded Tile Automata systems (all\nwithout detachment), which vary in the amount of complexity allowed in the\ntransition rules. We show that, in general, seeded Tile Automata systems\nrequire $\\Theta{(\\log^{\\frac{1}{4}} n)}$ states. For single-transition systems,\nwhere only one state may change in a transition rule, we show a bound of\n$\\Theta{(\\log^{\\frac{1}{3}} n)}$, and for deterministic systems, where each\npair of states may only have one associated transition rule, a bound of\n$\\Theta( (\\frac{\\log n}{\\log \\log n})^\\frac{1}{2} )$.",
    "descriptor": "\nComments: An earlier version was published in the 2022 Symposium on Algorithmic Foundations of Dynamic Networks (SAND)\n",
    "authors": [
      "Robert M. Alaniz",
      "David Caballero",
      "Sonya C. Cirlos",
      "Timothy Gomez",
      "Elise Grizzell",
      "Andrew Rodriguez",
      "Robert Schweller",
      "Armando Tenorio",
      "Tim Wylie"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2211.12589"
  },
  {
    "id": "arXiv:2211.12598",
    "title": "Stable and accurate least squares radial basis function approximations  on bounded domains",
    "abstract": "The computation of global radial basis function (RBF) approximations requires\nthe solution of a linear system which, depending on the choice of RBF\nparameters, may be ill-conditioned. We study the stability and accuracy of\napproximation methods using the Gaussian RBF in all scaling regimes of the\nassociated shape parameter. The approximation is based on discrete least\nsquares with function samples on a bounded domain, using RBF centers both\ninside and outside the domain. This results in a rectangular linear system. We\nshow for one-dimensional approximations that linear scaling of the shape\nparameter with the degrees of freedom is optimal, resulting in constant overlap\nbetween neighbouring RBF's regardless of their number, and we propose an\nexplicit suitable choice of the proportionality constant. We show numerically\nthat highly accurate approximations to smooth functions can also be obtained on\nbounded domains in several dimensions, using a linear scaling with the degrees\nof freedom per dimension. We extend the least squares approach to a\ncollocation-based method for the solution of elliptic boundary value problems\nand illustrate that the combination of centers outside the domain, oversampling\nand optimal scaling can result in accuracy close to machine precision in spite\nof having to solve very ill-conditioned linear systems.",
    "descriptor": "",
    "authors": [
      "Ben Adcock",
      "Daan Huybrechs",
      "C\u00e9cile Piret"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.12598"
  },
  {
    "id": "arXiv:2211.12600",
    "title": "ArrayFlex: A Systolic Array Architecture with Configurable Transparent  Pipelining",
    "abstract": "Convolutional Neural Networks (CNNs) are the state-of-the-art solution for\nmany deep learning applications. For maximum scalability, their computation\nshould combine high performance and energy efficiency. In practice, the\nconvolutions of each CNN layer are mapped to a matrix multiplication that\nincludes all input features and kernels of each layer and is computed using a\nsystolic array. In this work, we focus on the design of a systolic array with\nconfigurable pipeline with the goal to select an optimal pipeline configuration\nfor each CNN layer. The proposed systolic array, called ArrayFlex, can operate\nin normal, or in shallow pipeline mode, thus balancing the execution time in\ncycles and the operating clock frequency. By selecting the appropriate pipeline\nconfiguration per CNN layer, ArrayFlex reduces the inference latency of\nstate-of-the-art CNNs by 11%, on average, as compared to a traditional\nfixed-pipeline systolic array. Most importantly, this result is achieved while\nusing 13%-23% less power, for the same applications, thus offering a combined\nenergy-delay-product efficiency between 1.4x and 1.8x.",
    "descriptor": "\nComments: DATE 2023\n",
    "authors": [
      "C. Peltekis",
      "D. Filippas",
      "G. Dimitrakopoulos",
      "C. Nicopoulos",
      "D. Pnevmatikatos"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12600"
  },
  {
    "id": "arXiv:2211.12603",
    "title": "Reachability in Restricted Chemical Reaction Networks",
    "abstract": "The popularity of molecular computation has given rise to several models of\nabstraction, one of the more recent ones being Chemical Reaction Networks\n(CRNs). These are equivalent to other popular computational models, such as\nVector Addition Systems and Petri-Nets, and restricted versions are equivalent\nto Population Protocols. This paper continues the work on core reachability\nquestions related to Chemical Reaction Networks; given two configurations, can\none reach the other according to the system's rules? With no restrictions,\nreachability was recently shown to be Ackermann-complete, this resolving a\ndecades-old problem.\nHere, we fully characterize monotone reachability problems based on various\nrestrictions such as the rule size, the number of rules that may create a\nspecies (k-source) or consume a species (k-consuming), the volume, and whether\nthe rules have an acyclic production order (feed-forward). We show\nPSPACE-completeness of reachability with only bimolecular reactions with\ntwo-source and two-consuming rules. This proves hardness of reachability in\nPopulation Protocols, which was unknown. Further, this shows reachability in\nCRNs is PSPACE-complete with size-2 rules, which was previously only known with\nsize-5 rules. This is achieved using techniques within the motion planning\nframework.\nWe provide many important results for feed-forward CRNs where rules are\nsingle-source or single-consuming. We show that reachability is solvable in\npolynomial time if the system does not contain special void or autogenesis\nrules. We then fully characterize all systems of this type and show that if you\nallow void/autogenesis rules, or have more than one source and one consuming,\nthe problems become NP-complete. Finally, we show several interesting special\ncases of CRNs based on these restrictions or slight relaxations and note future\nsignificant open questions related to this taxonomy.",
    "descriptor": "\nComments: This research was supported in part by National Science Foundation Grant CCF-1817602\n",
    "authors": [
      "Robert M. Alaniz",
      "Bin Fu",
      "Timothy Gomez",
      "Elise Grizzell",
      "Andrew Rodriguez",
      "Robert Schweller",
      "Tim Wylie"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2211.12603"
  },
  {
    "id": "arXiv:2211.12604",
    "title": "SuperTran: Reference Based Video Transformer for Enhancing Low Bitrate  Streams in Real Time",
    "abstract": "This work focuses on low bitrate video streaming scenarios (e.g. 50 -\n200Kbps) where the video quality is severely compromised. We present a family\nof novel deep generative models for enhancing perceptual video quality of such\nstreams by performing super-resolution while also removing compression\nartifacts. Our model, which we call SuperTran, consumes as input a single\nhigh-quality, high-resolution reference images in addition to the low-quality,\nlow-resolution video stream. The model thus learns how to borrow or copy visual\nelements like textures from the reference image and fill in the remaining\ndetails from the low resolution stream in order to produce perceptually\nenhanced output video. The reference frame can be sent once at the start of the\nvideo session or be retrieved from a gallery. Importantly, the resulting output\nhas substantially better detail than what has been otherwise possible with\nmethods that only use a low resolution input such as the SuperVEGAN method.\nSuperTran works in real-time (up to 30 frames/sec) on the cloud alongside\nstandard pipelines.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Tejas Khot",
      "Nataliya Shapovalova",
      "Silviu Andrei",
      "Walterio Mayol-Cuevas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.12604"
  },
  {
    "id": "arXiv:2211.12607",
    "title": "CMOS-compatible Ising and Potts Annealing Using Single Photon Avalanche  Diodes",
    "abstract": "Massively parallel annealing processors may offer superior performance for a\nwide range of sampling and optimization problems. A key component dictating the\nsize of these processors is the neuron update circuit, ideally implemented\nusing special stochastic nanodevices. We leverage photon statistics using\nsingle photon avalanche diodes (SPADs) and temporal filtering to generate\nstochastic states. This method is a powerful alternative offering unique\nfeatures not currently seen in annealing processors: the ability to\ncontinuously control the computational temperature and the seamless extension\nto the Potts model, a $n$-state generalization of the two-state Ising model.\nSPADs also offer a considerable practical advantage since they are readily\nmanufacturable in current standard CMOS processes. As a first step towards\nrealizing a CMOS SPAD-based annealer, we have designed Ising and Potts models\ndriven by an array of discrete SPADs and show they accurately sample from their\ntheoretical distributions.",
    "descriptor": "",
    "authors": [
      "William Whitehead",
      "Zachary Nelson",
      "Kerem Y. Camsari",
      "Luke Theogarajan"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Applied Physics (physics.app-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.12607"
  },
  {
    "id": "arXiv:2211.12610",
    "title": "Efficient Exploration using Model-Based Quality-Diversity with Gradients",
    "abstract": "Exploration is a key challenge in Reinforcement Learning, especially in\nlong-horizon, deceptive and sparse-reward environments. For such applications,\npopulation-based approaches have proven effective. Methods such as\nQuality-Diversity deals with this by encouraging novel solutions and producing\na diversity of behaviours. However, these methods are driven by either\nundirected sampling (i.e. mutations) or use approximated gradients (i.e.\nEvolution Strategies) in the parameter space, which makes them highly\nsample-inefficient. In this paper, we propose a model-based Quality-Diversity\napproach. It extends existing QD methods to use gradients for efficient\nexploitation and leverage perturbations in imagination for efficient\nexploration. Our approach optimizes all members of a population simultaneously\nto maintain both performance and diversity efficiently by leveraging the\neffectiveness of QD algorithms as good data generators to train deep models. We\ndemonstrate that it maintains the divergent search capabilities of\npopulation-based approaches on tasks with deceptive rewards while significantly\nimproving their sample efficiency and quality of solutions.",
    "descriptor": "",
    "authors": [
      "Bryan Lim",
      "Manon Flageat",
      "Antoine Cully"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12610"
  },
  {
    "id": "arXiv:2211.12615",
    "title": "AutoReply: Detecting Nonsense in Dialogue Introspectively with  Discriminative Replies",
    "abstract": "Existing approaches built separate classifiers to detect nonsense in\ndialogues. In this paper, we show that without external classifiers, dialogue\nmodels can detect errors in their own messages introspectively, by calculating\nthe likelihood of replies that are indicative of poor messages. For example, if\nan agent believes its partner is likely to respond \"I don't understand\" to a\ncandidate message, that message may not make sense, so an alternative message\nshould be chosen. We evaluate our approach on a dataset from the game\nDiplomacy, which contains long dialogues richly grounded in the game state, on\nwhich existing models make many errors. We first show that hand-crafted replies\ncan be effective for the task of detecting nonsense in applications as complex\nas Diplomacy. We then design AutoReply, an algorithm to search for such\ndiscriminative replies automatically, given a small number of annotated\ndialogue examples. We find that AutoReply-generated replies outperform\nhandcrafted replies and perform on par with carefully fine-tuned large\nsupervised models. Results also show that one single reply without much\ncomputation overheads can also detect dialogue nonsense reasonably well.",
    "descriptor": "",
    "authors": [
      "Weiyan Shi",
      "Emily Dinan",
      "Adi Renduchintala",
      "Daniel Fried",
      "Athul Paul Jacob",
      "Zhou Yu",
      "Mike Lewis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12615"
  },
  {
    "id": "arXiv:2211.12616",
    "title": "Improved Multi-GPU parallelization of a Lagrangian Transport Model",
    "abstract": "This report highlights our work on improving GPU parallelization by\nsupporting compute nodes with multiple GPUs. However, since the default support\nfor multi-GPUs in OpenACC is limited[6], the current implementation allows each\nMPI process to access only a single GPU. Thus, the only way to take full\nadvantage of multi-GPU nodes in the current version is to launch multiple\nprocesses, which increases resource contention. We investigated the benefits of\nhaving only one process offload to all available GPU devices.",
    "descriptor": "\nComments: Technical Report\n",
    "authors": [
      "Saheed Bolarinwa"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.12616"
  },
  {
    "id": "arXiv:2211.12620",
    "title": "Good Data from Bad Models : Foundations of Threshold-based Auto-labeling",
    "abstract": "Creating large-scale high-quality labeled datasets is a major bottleneck in\nsupervised machine learning workflows. Auto-labeling systems are a promising\nway to reduce reliance on manual labeling for dataset construction.\nThreshold-based auto-labeling, where validation data obtained from humans is\nused to find a threshold for confidence above which the data is\nmachine-labeled, is emerging as a popular solution used widely in practice.\nGiven the long shelf-life and diverse usage of the resulting datasets,\nunderstanding when the data obtained by such auto-labeling systems can be\nrelied on is crucial. In this work, we analyze threshold-based auto-labeling\nsystems and derive sample complexity bounds on the amount of human-labeled\nvalidation data required for guaranteeing the quality of machine-labeled data.\nOur results provide two insights. First, reasonable chunks of the unlabeled\ndata can be automatically and accurately labeled by seemingly bad models.\nSecond, a hidden downside of threshold-based auto-labeling systems is\npotentially prohibitive validation data usage. Together, these insights\ndescribe the promise and pitfalls of using such systems. We validate our\ntheoretical guarantees with simulations and study the efficacy of\nthreshold-based auto-labeling on real datasets.",
    "descriptor": "",
    "authors": [
      "Harit Vishwakarma",
      "Heguang Lin",
      "Frederic Sala",
      "Ramya Korlakai Vinayak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.12620"
  },
  {
    "id": "arXiv:2211.12624",
    "title": "Improving Robust Generalization by Direct PAC-Bayesian Bound  Minimization",
    "abstract": "Recent research in robust optimization has shown an overfitting-like\nphenomenon in which models trained against adversarial attacks exhibit higher\nrobustness on the training set compared to the test set. Although previous work\nprovided theoretical explanations for this phenomenon using a robust\nPAC-Bayesian bound over the adversarial test error, related algorithmic\nderivations are at best only loosely connected to this bound, which implies\nthat there is still a gap between their empirical success and our understanding\nof adversarial robustness theory. To close this gap, in this paper we consider\na different form of the robust PAC-Bayesian bound and directly minimize it with\nrespect to the model posterior. The derivation of the optimal solution connects\nPAC-Bayesian learning to the geometry of the robust loss surface through a\nTrace of Hessian (TrH) regularizer that measures the surface flatness. In\npractice, we restrict the TrH regularizer to the top layer only, which results\nin an analytical solution to the bound whose computational cost does not depend\non the network depth. Finally, we evaluate our TrH regularization approach over\nCIFAR-10/100 and ImageNet using Vision Transformers (ViT) and compare against\nbaseline adversarial robustness algorithms. Experimental results show that TrH\nregularization leads to improved ViT robustness that either matches or\nsurpasses previous state-of-the-art approaches while at the same time requires\nless memory and computational cost.",
    "descriptor": "",
    "authors": [
      "Zifan Wang",
      "Nan Ding",
      "Tomer Levinboim",
      "Xi Chen",
      "Radu Soricut"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12624"
  },
  {
    "id": "arXiv:2211.12627",
    "title": "$\u03b2$-Multivariational Autoencoder for Entangled Representation  Learning in Video Frames",
    "abstract": "It is crucial to choose actions from an appropriate distribution while\nlearning a sequential decision-making process in which a set of actions is\nexpected given the states and previous reward. Yet, if there are more than two\nlatent variables and every two variables have a covariance value, learning a\nknown prior from data becomes challenging. Because when the data are big and\ndiverse, many posterior estimate methods experience posterior collapse. In this\npaper, we propose the $\\beta$-Multivariational Autoencoder ($\\beta$MVAE) to\nlearn a Multivariate Gaussian prior from video frames for use as part of a\nsingle object-tracking in form of a decision-making process. We present a novel\nformulation for object motion in videos with a set of dependent parameters to\naddress a single object-tracking task. The true values of the motion parameters\nare obtained through data analysis on the training set. The parameters\npopulation is then assumed to have a Multivariate Gaussian distribution. The\n$\\beta$MVAE is developed to learn this entangled prior $p = N(\\mu, \\Sigma)$\ndirectly from frame patches where the output is the object masks of the frame\npatches. We devise a bottleneck to estimate the posterior's parameters, i.e.\n$\\mu', \\Sigma'$. Via a new reparameterization trick, we learn the likelihood\n$p(\\hat{x}|z)$ as the object mask of the input. Furthermore, we alter the\nneural network of $\\beta$MVAE with the U-Net architecture and name the new\nnetwork $\\beta$Multivariational U-Net ($\\beta$MVUnet). Our networks are trained\nfrom scratch via over 85k video frames for 24 ($\\beta$MVUnet) and 78\n($\\beta$MVAE) million steps. We show that $\\beta$MVUnet enhances both posterior\nestimation and segmentation functioning over the test set. Our code and the\ntrained networks are publicly released.",
    "descriptor": "",
    "authors": [
      "Fatemeh Nouri",
      "Robert Bergevin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12627"
  },
  {
    "id": "arXiv:2211.12628",
    "title": "Safe Control and Learning Using Generalized Action Governor",
    "abstract": "This paper introduces the Generalized Action Governor, which is a supervisory\nscheme for augmenting a nominal closed-loop system with the capability of\nstrictly handling constraints. After presenting its theory for general systems\nand introducing tailored design approaches for linear and discrete systems, we\ndiscuss its application to safe online learning, which aims to safely evolve\ncontrol parameters using real-time data to improve performance for uncertain\nsystems. In particular, we propose two safe learning algorithms based on\nintegration of reinforcement learning/data-driven Koopman operator-based\ncontrol with the generalized action governor. The developments are illustrated\nwith a numerical example.",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Nan Li",
      "Yutong Li",
      "Ilya Kolmanovsky",
      "Anouck Girard",
      "H. Eric Tseng",
      "Dimitar Filev"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.12628"
  },
  {
    "id": "arXiv:2211.12629",
    "title": "A Complete Diagrammatic Calculus for Boolean Satisfiability",
    "abstract": "We propose a calculus of string diagrams to reason about satisfiability of\nBoolean formulas, and prove it to be sound and complete. We then showcase our\ncalculus in a few case studies. First, we consider SAT-solving. Second, we\nconsider Horn clauses, which leads us to a new decision method for\npropositional logic programs equivalence under Herbrand model semantics.",
    "descriptor": "",
    "authors": [
      "Tao Gu",
      "Robin Piedeleu",
      "Fabio Zanasi"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.12629"
  },
  {
    "id": "arXiv:2211.12633",
    "title": "Near-optimal learning of Banach-valued, high-dimensional functions via  deep neural networks",
    "abstract": "The past decade has seen increasing interest in applying Deep Learning (DL)\nto Computational Science and Engineering (CSE). Driven by impressive results in\napplications such as computer vision, Uncertainty Quantification (UQ),\ngenetics, simulations and image processing, DL is increasingly supplanting\nclassical algorithms, and seems poised to revolutionize scientific computing.\nHowever, DL is not yet well-understood from the standpoint of numerical\nanalysis. Little is known about the efficiency and reliability of DL from the\nperspectives of stability, robustness, accuracy, and sample complexity. In\nparticular, approximating solutions to parametric PDEs is an objective of UQ\nfor CSE. Training data for such problems is often scarce and corrupted by\nerrors. Moreover, the target function is a possibly infinite-dimensional smooth\nfunction taking values in the PDE solution space, generally an\ninfinite-dimensional Banach space. This paper provides arguments for Deep\nNeural Network (DNN) approximation of such functions, with both known and\nunknown parametric dependence, that overcome the curse of dimensionality. We\nestablish practical existence theorems that describe classes of DNNs with\ndimension-independent architecture size and training procedures based on\nminimizing the (regularized) $\\ell^2$-loss which achieve near-optimal algebraic\nrates of convergence. These results involve key extensions of compressed\nsensing for Banach-valued recovery and polynomial emulation with DNNs. When\napproximating solutions of parametric PDEs, our results account for all sources\nof error, i.e., sampling, optimization, approximation and physical\ndiscretization, and allow for training high-fidelity DNN approximations from\ncoarse-grained sample data. Our theoretical results fall into the category of\nnon-intrusive methods, providing a theoretical alternative to classical methods\nfor high-dimensional approximation.",
    "descriptor": "\nComments: 49 pages\n",
    "authors": [
      "Ben Adcock",
      "Simone Brugiapaglia",
      "Nick Dexter",
      "Sebastian Moraga"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.12633"
  },
  {
    "id": "arXiv:2211.12634",
    "title": "Image Anomaly Detection and Localization with Position and Neighborhood  Information",
    "abstract": "Anomaly detection and localization are essential in many areas, where\ncollecting enough anomalous samples for training is almost impossible. To\novercome this difficulty, many existing methods use a pre-trained network to\nencode input images and non-parametric modeling to estimate the encoded feature\ndistribution. In the modeling process, however, they overlook that position and\nneighborhood information affect the distribution of normal features. To use the\ninformation, in this paper, the normal distribution is estimated with\nconditional probability given neighborhood features, which is modeled with a\nmulti-layer perceptron network. At the same time, positional information can be\nused by building a histogram of representative features at each position. While\nexisting methods simply resize the anomaly map into the resolution of an input\nimage, the proposed method uses an additional refine network that is trained\nfrom synthetic anomaly images to perform better interpolation considering the\nshape and edge of the input image. For the popular industrial dataset, MVTec AD\nbenchmark, the experimental results show \\textbf{99.52\\%} and \\textbf{98.91\\%}\nAUROC scores in anomaly detection and localization, which is state-of-the-art\nperformance.",
    "descriptor": "",
    "authors": [
      "Jaehyeok Bae",
      "Jae-Han Lee",
      "Seyun Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12634"
  },
  {
    "id": "arXiv:2211.12636",
    "title": "Dehazed Image Quality Evaluation: From Partial Discrepancy to Blind  Perception",
    "abstract": "Image dehazing aims to restore spatial details from hazy images. There have\nemerged a number of image dehazing algorithms, designed to increase the\nvisibility of those hazy images. However, much less work has been focused on\nevaluating the visual quality of dehazed images. In this paper, we propose a\nReduced-Reference dehazed image quality evaluation approach based on Partial\nDiscrepancy (RRPD) and then extend it to a No-Reference quality assessment\nmetric with Blind Perception (NRBP). Specifically, inspired by the hierarchical\ncharacteristics of the human perceiving dehazed images, we introduce three\ngroups of features: luminance discrimination, color appearance, and overall\nnaturalness. In the proposed RRPD, the combined distance between a set of\nsender and receiver features is adopted to quantify the perceptually dehazed\nimage quality. By integrating global and local channels from dehazed images,\nthe RRPD is converted to NRBP which does not rely on any information from the\nreferences. Extensive experiment results on several dehazed image quality\ndatabases demonstrate that our proposed methods outperform state-of-the-art\nfull-reference, reduced-reference, and no-reference quality assessment models.\nFurthermore, we show that the proposed dehazed image quality evaluation methods\ncan be effectively applied to tune parameters for potential image dehazing\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Wei Zhou",
      "Ruizeng Zhang",
      "Leida Li",
      "Hantao Liu",
      "Huiyan Chen"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12636"
  },
  {
    "id": "arXiv:2211.12638",
    "title": "Projection-free Adaptive Regret with Membership Oracles",
    "abstract": "In the framework of online convex optimization, most iterative algorithms\nrequire the computation of projections onto convex sets, which can be\ncomputationally expensive. To tackle this problem HK12 proposed the study of\nprojection-free methods that replace projections with less expensive\ncomputations. The most common approach is based on the Frank-Wolfe method, that\nuses linear optimization computation in lieu of projections. Recent work by\nGK22 gave sublinear adaptive regret guarantees with projection free algorithms\nbased on the Frank Wolfe approach.\nIn this work we give projection-free algorithms that are based on a different\ntechnique, inspired by Mhammedi22, that replaces projections by set-membership\ncomputations. We propose a simple lazy gradient-based algorithm with a\nMinkowski regularization that attains near-optimal adaptive regret bounds. For\ngeneral convex loss functions we improve previous adaptive regret bounds from\n$O(T^{3/4})$ to $O(\\sqrt{T})$, and further to tight interval dependent bound\n$\\tilde{O}(\\sqrt{I})$ where $I$ denotes the interval length. For strongly\nconvex functions we obtain the first poly-logarithmic adaptive regret bounds\nusing a projection-free algorithm.",
    "descriptor": "",
    "authors": [
      "Zhou Lu",
      "Nataly Brukhim",
      "Paula Gradu",
      "Elad Hazan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.12638"
  },
  {
    "id": "arXiv:2211.12640",
    "title": "Event-Triggered Decentralized Federated Learning over  Resource-Constrained Edge Devices",
    "abstract": "Federated learning (FL) is a technique for distributed machine learning (ML),\nin which edge devices carry out local model training on their individual\ndatasets. In traditional FL algorithms, trained models at the edge are\nperiodically sent to a central server for aggregation, utilizing a star\ntopology as the underlying communication graph. However, assuming access to a\ncentral coordinator is not always practical, e.g., in ad hoc wireless network\nsettings. In this paper, we develop a novel methodology for fully decentralized\nFL, where in addition to local training, devices conduct model aggregation via\ncooperative consensus formation with their one-hop neighbors over the\ndecentralized underlying physical network. We further eliminate the need for a\ntiming coordinator by introducing asynchronous, event-triggered communications\namong the devices. In doing so, to account for the inherent resource\nheterogeneity challenges in FL, we define personalized communication triggering\nconditions at each device that weigh the change in local model parameters\nagainst the available local resources. We theoretically demonstrate that our\nmethodology converges to the globally optimal learning model at a\n$O{(\\frac{\\ln{k}}{\\sqrt{k}})}$ rate under standard assumptions in distributed\nlearning and consensus literature. Our subsequent numerical evaluations\ndemonstrate that our methodology obtains substantial improvements in\nconvergence speed and/or communication savings compared with existing\ndecentralized FL baselines.",
    "descriptor": "\nComments: 23 pages. arXiv admin note: text overlap with arXiv:2204.03726\n",
    "authors": [
      "Shahryar Zehtabi",
      "Seyyedali Hosseinalipour",
      "Christopher G. Brinton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.12640"
  },
  {
    "id": "arXiv:2211.12641",
    "title": "Leveraging Data Recasting to Enhance Tabular Reasoning",
    "abstract": "Creating challenging tabular inference data is essential for learning complex\nreasoning. Prior work has mostly relied on two data generation strategies. The\nfirst is human annotation, which yields linguistically diverse data but is\ndifficult to scale. The second category for creation is synthetic generation,\nwhich is scalable and cost effective but lacks inventiveness. In this research,\nwe present a framework for semi-automatically recasting existing tabular data\nto make use of the benefits of both approaches. We utilize our framework to\nbuild tabular NLI instances from five datasets that were initially intended for\ntasks like table2text creation, tabular Q/A, and semantic parsing. We\ndemonstrate that recasted data could be used as evaluation benchmarks as well\nas augmentation data to enhance performance on tabular NLI tasks. Furthermore,\nwe investigate the effectiveness of models trained on recasted data in the\nzero-shot scenario, and analyse trends in performance across different recasted\ndatasets types.",
    "descriptor": "\nComments: 14 pages, 10 tables, 3 figues, EMNLP 2022 (Findings)\n",
    "authors": [
      "Aashna Jena",
      "Vivek Gupta",
      "Manish Shrivastava",
      "Julian Martin Eisenschlos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12641"
  },
  {
    "id": "arXiv:2211.12647",
    "title": "Approval-Based Voting with Mixed Goods",
    "abstract": "We consider a voting scenario in which the resource to be voted upon may\nconsist of both indivisible and divisible goods. This setting generalizes both\nthe well-studied model of multiwinner voting and the recently introduced model\nof cake sharing. Under approval votes, we propose two variants of the extended\njustified representation (EJR) notion from multiwinner voting, a stronger one\ncalled EJR for mixed goods (EJR-M) and a weaker one called EJR up to 1 (EJR-1).\nWe extend three multiwinner voting rules to our setting -- GreedyEJR, the\nmethod of equal shares (MES), and proportional approval voting (PAV) -- and\nshow that while all three generalizations satisfy EJR-1, only the first one\nprovides EJR-M. In addition, we derive tight bounds on the proportionality\ndegree implied by EJR-M and EJR-1, and investigate the proportionality degree\nof our proposed rules.",
    "descriptor": "\nComments: Appears in the 37th AAAI Conference on Artificial Intelligence (AAAI), 2023\n",
    "authors": [
      "Xinhang Lu",
      "Jannik Peters",
      "Haris Aziz",
      "Xiaohui Bei",
      "Warut Suksompong"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.12647"
  },
  {
    "id": "arXiv:2211.12649",
    "title": "Predicting Topological Maps for Visual Navigation in Unexplored  Environments",
    "abstract": "We propose a robotic learning system for autonomous exploration and\nnavigation in unexplored environments. We are motivated by the idea that even\nan unseen environment may be familiar from previous experiences in similar\nenvironments. The core of our method, therefore, is a process for building,\npredicting, and using probabilistic layout graphs for assisting goal-based\nvisual navigation. We describe a navigation system that uses the layout\npredictions to satisfy high-level goals (e.g. \"go to the kitchen\") more rapidly\nand accurately than the prior art. Our proposed navigation framework comprises\nthree stages: (1) Perception and Mapping: building a multi-level 3D scene\ngraph; (2) Prediction: predicting probabilistic 3D scene graph for the\nunexplored environment; (3) Navigation: assisting navigation with the graphs.\nWe test our framework in Matterport3D and show more success and efficient\nnavigation in unseen environments.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Huangying Zhan",
      "Hamid Rezatofighi",
      "Ian Reid"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12649"
  },
  {
    "id": "arXiv:2211.12650",
    "title": "FRE: A Fast Method For Anomaly Detection And Segmentation",
    "abstract": "This paper presents a fast and principled approach for solving the visual\nanomaly detection and segmentation problem. In this setup, we have access to\nonly anomaly-free training data and want to detect and identify anomalies of an\narbitrary nature on test data. We propose the application of linear statistical\ndimensionality reduction techniques on the intermediate features produced by a\npretrained DNN on the training data, in order to capture the low-dimensional\nsubspace truly spanned by said features. We show that the \\emph{feature\nreconstruction error} (FRE), which is the $\\ell_2$-norm of the difference\nbetween the original feature in the high-dimensional space and the pre-image of\nits low-dimensional reduced embedding, is extremely effective for anomaly\ndetection. Further, using the same feature reconstruction error concept on\nintermediate convolutional layers, we derive FRE maps that provide pixel-level\nspatial localization of the anomalies in the image (i.e. segmentation).\nExperiments using standard anomaly detection datasets and DNN architectures\ndemonstrate that our method matches or exceeds best-in-class quality\nperformance, but at a fraction of the computational and memory cost required by\nthe state of the art. It can be trained and run very efficiently, even on a\ntraditional CPU.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2203.10422\n",
    "authors": [
      "Ibrahima Ndiour",
      "Nilesh Ahuja",
      "Utku Genc",
      "Omesh Tickoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12650"
  },
  {
    "id": "arXiv:2211.12655",
    "title": "Bit-Interleaved Coded Energy-Based Modulation with Iterative Decoding",
    "abstract": "This paper develops a low-complexity near-optimal non-coherent receiver for a\nmulti-level energy-based coded modulation system. Inspired by the turbo\nprocessing principle, we incorporate the fundamentals of bit-interleaved coded\nmodulation with iterative decoding (BICM-ID) into the proposed receiver design.\nThe resulting system is called bit-interleaved coded energy-based modulation\nwith iterative decoding (BICEM-ID) and its error performance is analytically\nstudied. Specifically, we derive upper bounds on the average pairwise error\nprobability (PEP) of the non-coherent BICEM-ID system in the feedback-free (FF)\nand error-free feedback (EFF) scenarios. It is revealed that the definition of\nthe nearest neighbors, which is important in the performance analysis in the FF\nscenario, is very different from that in the coherent BICM-ID counterpart. The\nanalysis also reveals how the mapping from coded bits to energy levels\ninfluences the diversity order and coding gain of the BICEM-ID systems. A\ndesign criterion for good mappings is then formulated and an algorithm is\nproposed to find a set of best mappings for BICEM-ID. Finally, simulation\nresults corroborate the main analytical findings.",
    "descriptor": "",
    "authors": [
      "Ali Fazeli",
      "Ha H. Nguyen",
      "Halim Yanikomeroglu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.12655"
  },
  {
    "id": "arXiv:2211.12656",
    "title": "ActiveRMAP: Radiance Field for Active Mapping And Planning",
    "abstract": "A high-quality 3D reconstruction of a scene from a collection of 2D images\ncan be achieved through offline/online mapping methods. In this paper, we\nexplore active mapping from the perspective of implicit representations, which\nhave recently produced compelling results in a variety of applications. One of\nthe most popular implicit representations - Neural Radiance Field (NeRF), first\ndemonstrated photorealistic rendering results using multi-layer perceptrons,\nwith promising offline 3D reconstruction as a by-product of the radiance field.\nMore recently, researchers also applied this implicit representation for online\nreconstruction and localization (i.e. implicit SLAM systems). However, the\nstudy on using implicit representation for active vision tasks is still very\nlimited. In this paper, we are particularly interested in applying the neural\nradiance field for active mapping and planning problems, which are closely\ncoupled tasks in an active system. We, for the first time, present an RGB-only\nactive vision framework using radiance field representation for active 3D\nreconstruction and planning in an online manner. Specifically, we formulate\nthis joint task as an iterative dual-stage optimization problem, where we\nalternatively optimize for the radiance field representation and path planning.\nExperimental results suggest that the proposed method achieves competitive\nresults compared to other offline methods and outperforms active reconstruction\nmethods using NeRFs.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Huangying Zhan",
      "Jiyang Zheng",
      "Yi Xu",
      "Ian Reid",
      "Hamid Rezatofighi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.12656"
  },
  {
    "id": "arXiv:2211.12657",
    "title": "One Class One Click: Quasi Scene-level Weakly Supervised Point Cloud  Semantic Segmentation with Active Learning",
    "abstract": "Reliance on vast annotations to achieve leading performance severely\nrestricts the practicality of large-scale point cloud semantic segmentation.\nFor the purpose of reducing data annotation costs, effective labeling schemes\nare developed and contribute to attaining competitive results under weak\nsupervision strategy. Revisiting current weak label forms, we introduce One\nClass One Click (OCOC), a low cost yet informative quasi scene-level label,\nwhich encapsulates point-level and scene-level annotations. An active weakly\nsupervised framework is proposed to leverage scarce labels by involving weak\nsupervision from global and local perspectives. Contextual constraints are\nimposed by an auxiliary scene classification task, respectively based on global\nfeature embedding and point-wise prediction aggregation, which restricts the\nmodel prediction merely to OCOC labels. Furthermore, we design a context-aware\npseudo labeling strategy, which effectively supplement point-level supervisory\nsignals. Finally, an active learning scheme with a uncertainty measure -\ntemporal output discrepancy is integrated to examine informative samples and\nprovides guidance on sub-clouds query, which is conducive to quickly attaining\ndesirable OCOC annotations and reduces the labeling cost to an extremely low\nextent. Extensive experimental analysis using three LiDAR benchmarks collected\nfrom airborne, mobile and ground platforms demonstrates that our proposed\nmethod achieves very promising results though subject to scarce labels. It\nconsiderably outperforms genuine scene-level weakly supervised methods by up to\n25\\% in terms of average F1 score and achieves competitive results against full\nsupervision schemes. On terrestrial LiDAR dataset - Semantics3D, using\napproximately 2\\textpertenthousand{} of labels, our method achieves an average\nF1 score of 85.2\\%, which increases by 11.58\\% compared to the baseline model.",
    "descriptor": "",
    "authors": [
      "Puzuo Wang",
      "Wei Yao",
      "Jie Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12657"
  },
  {
    "id": "arXiv:2211.12660",
    "title": "The Impact of Generative AI on the Future of Visual Content Marketing",
    "abstract": "In today's world of marketing, it is necessary to have visually appealing\ncontent. Visual material has become an essential area of focus for every\ncompany as a result of the widespread availability of gadgets for mass\ncommunication and extended visual advancements. Similarly, artificial\nintelligence is also gaining ground and it is proving to be the most\nrevolutionary technological advancement thus far. The integration of visual\ncontent with artificial intelligence is the key to acquiring and retaining\nloyal customers; its absence from the overarching marketing strategy of any\nproduction raises a red flag that could ultimately result in a smaller market\nshare for that company.",
    "descriptor": "\nComments: 15 pages, 5 figures\n",
    "authors": [
      "Shiva Mayahi",
      "Marko Vidrih"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.12660"
  },
  {
    "id": "arXiv:2211.12668",
    "title": "DyRRen: A Dynamic Retriever-Reranker-Generator Model for Numerical  Reasoning over Tabular and Textual Data",
    "abstract": "Numerical reasoning over hybrid data containing tables and long texts has\nrecently received research attention from the AI community. To generate an\nexecutable reasoning program consisting of math and table operations to answer\na question, state-of-the-art methods use a retriever-generator pipeline.\nHowever, their retrieval results are static, while different generation steps\nmay rely on different sentences. To attend to the retrieved information that is\nrelevant to each generation step, in this paper, we propose DyRRen, an extended\nretriever-reranker-generator framework where each generation step is enhanced\nby a dynamic reranking of retrieved sentences. It outperforms existing\nbaselines on the FinQA dataset.",
    "descriptor": "\nComments: 9 pages, accepted by AAAI 2023\n",
    "authors": [
      "Xiao Li",
      "Yin Zhu",
      "Sichen Liu",
      "Jiangzhou Ju",
      "Yuzhong Qu",
      "Gong Cheng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.12668"
  },
  {
    "id": "arXiv:2211.12674",
    "title": "Semantic-aware One-shot Face Re-enactment with Dense Correspondence  Estimation",
    "abstract": "One-shot face re-enactment is a challenging task due to the identity mismatch\nbetween source and driving faces. Specifically, the suboptimally disentangled\nidentity information of driving subjects would inevitably interfere with the\nre-enactment results and lead to face shape distortion. To solve this problem,\nthis paper proposes to use 3D Morphable Model (3DMM) for explicit facial\nsemantic decomposition and identity disentanglement. Instead of using 3D\ncoefficients alone for re-enactment control, we take the advantage of the\ngenerative ability of 3DMM to render textured face proxies. These proxies\ncontain abundant yet compact geometric and semantic information of human faces,\nwhich enable us to compute the face motion field between source and driving\nimages by estimating the dense correspondence. In this way, we could\napproximate re-enactment results by warping source images according to the\nmotion field, and a Generative Adversarial Network (GAN) is adopted to further\nimprove the visual quality of warping results. Extensive experiments on various\ndatasets demonstrate the advantages of the proposed method over existing\nstart-of-the-art benchmarks in both identity preservation and re-enactment\nfulfillment.",
    "descriptor": "",
    "authors": [
      "Yunfan Liu",
      "Qi Li",
      "Zhenan Sun",
      "Tieniu Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12674"
  },
  {
    "id": "arXiv:2211.12677",
    "title": "Word-Level Representation From Bytes For Language Modeling",
    "abstract": "Modern language models mostly take sub-words as input, a design that balances\nthe trade-off between vocabulary size, number of parameters, and performance.\nHowever, sub-word tokenization still has disadvantages like not being robust to\nnoise and difficult to generalize to new languages. Also, the current trend of\nscaling up models reveals that larger models require larger embeddings but that\nmakes parallelization hard. Previous work on image classification proves\nsplitting raw input into a sequence of chucks is a strong, model-agnostic\ninductive bias. Based on this observation, we rethink the existing\ncharacter-aware method that takes character-level inputs but makes word-level\nsequence modeling and prediction. We overhaul this method by introducing a\ncross-attention network that builds word-level representation directly from\nbytes, and a sub-word level prediction based on word-level hidden states to\navoid the time and space requirement of word-level prediction. With these two\nimprovements combined, we have a token free model with slim input embeddings\nfor downstream tasks. We name our method Byte2Word and perform evaluations on\nlanguage modeling and text classification. Experiments show that Byte2Word is\non par with the strong sub-word baseline BERT but only takes up 10\\% of\nembedding size. We further test our method on synthetic noise and cross-lingual\ntransfer and find it competitive to baseline methods on both settings.",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Chu-Tak Lee",
      "Qipeng Guo",
      "Xipeng Qiu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.12677"
  },
  {
    "id": "arXiv:2211.12686",
    "title": "Batching of Tasks by Users of Pseudonymous Forums: Anonymity Compromise  and Protection",
    "abstract": "There are a number of forums where people participate under pseudonyms. One\nexample is peer review, where the identity of reviewers for any paper is\nconfidential. When participating in these forums, people frequently engage in\n\"batching\": executing multiple related tasks (e.g., commenting on multiple\npapers) at nearly the same time. Our empirical analysis shows that batching is\ncommon in two applications we consider $\\unicode{x2013}$ peer review and\nWikipedia edits. In this paper, we identify and address the risk of\ndeanonymization arising from linking batched tasks. To protect against linkage\nattacks, we take the approach of adding delay to the posting time of batched\ntasks. We first show that under some natural assumptions, no delay mechanism\ncan provide a meaningful differential privacy guarantee. We therefore propose a\n\"one-sided\" formulation of differential privacy for protecting against linkage\nattacks. We design a mechanism that adds zero-inflated uniform delay to events\nand show it can preserve privacy. We prove that this noise distribution is in\nfact optimal in minimizing expected delay among mechanisms adding independent\nnoise to each event, thereby establishing the Pareto frontier of the trade-off\nbetween the expected delay for batched and unbatched events. Finally, we\nconduct a series of experiments on Wikipedia and Bitcoin data that corroborate\nthe practical utility of our algorithm in obfuscating batching without\nintroducing onerous delay to a system.",
    "descriptor": "",
    "authors": [
      "Alexander Goldberg",
      "Giulia Fanti",
      "Nihar B. Shah"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.12686"
  },
  {
    "id": "arXiv:2211.12698",
    "title": "Rega-Net:Retina Gabor Attention for Deep Convolutional Neural Networks",
    "abstract": "Extensive research works demonstrate that the attention mechanism in\nconvolutional neural networks (CNNs) effectively improves accuracy. But little\nworks design attention mechanisms using large receptive fields. In this work,\nwe propose a novel attention method named Rega-net to increase CNN accuracy by\nenlarging the receptive field. Inspired by the mechanism of the human retina,\nwe design convolutional kernels to resemble the non-uniformly distributed\nstructure of the human retina. Then, we sample variable-resolution values in\nthe Gabor function distribution and fill these values in retina-like kernels.\nThis distribution allows important features to be more visible in the center\nposition of the receptive field. We further design an attention module\nincluding these retina-like kernels. Experiments demonstrate that our Rega-Net\nachieves 79.963\\% top-1 accuracy on ImageNet-1K classification and 43.1\\% mAP\non COCO2017 object detection. The mAP of the Rega-Net increased by up to 3.5\\%\ncompared to baseline networks.",
    "descriptor": "",
    "authors": [
      "Chun Bao",
      "Jie Cao",
      "Yaqian Ning",
      "Yang Cheng",
      "Qun Hao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12698"
  },
  {
    "id": "arXiv:2211.12701",
    "title": "Continual Learning of Natural Language Processing Tasks: A Survey",
    "abstract": "Continual learning (CL) is an emerging learning paradigm that aims to emulate\nthe human capability of learning and accumulating knowledge continually without\nforgetting the previously learned knowledge and also transferring the knowledge\nto new tasks to learn them better. This survey presents a comprehensive review\nof the recent progress of CL in the NLP field. It covers (1) all CL settings\nwith a taxonomy of existing techniques. Besides dealing with forgetting, it\nalso focuses on (2) knowledge transfer, which is of particular importance to\nNLP. Both (1) and (2) are not mentioned in the existing survey. Finally, a list\nof future directions is also discussed.",
    "descriptor": "",
    "authors": [
      "Zixuan Ke",
      "Bing Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.12701"
  },
  {
    "id": "arXiv:2211.12703",
    "title": "Subgroup Robustness Grows On Trees: An Empirical Baseline Investigation",
    "abstract": "Researchers have proposed many methods for fair and robust machine learning,\nbut comprehensive empirical evaluation of their subgroup robustness is lacking.\nIn this work, we address this gap in the context of tabular data, where\nsensitive subgroups are clearly-defined, real-world fairness problems abound,\nand prior works often do not compare to state-of-the-art tree-based models as\nbaselines. We conduct an empirical comparison of several previously-proposed\nmethods for fair and robust learning alongside state-of-the-art tree-based\nmethods and other baselines. Via experiments with more than $340{,}000$ model\nconfigurations on eight datasets, we show that tree-based methods have strong\nsubgroup robustness, even when compared to robustness- and fairness-enhancing\nmethods. Moreover, the best tree-based models tend to show good performance\nover a range of metrics, while robust or group-fair models can show\nbrittleness, with significant performance differences across different metrics\nfor a fixed model. We also demonstrate that tree-based models show less\nsensitivity to hyperparameter configurations, and are less costly to train. Our\nwork suggests that tree-based ensemble models make an effective baseline for\ntabular data, and are a sensible default when subgroup robustness is desired.\nFor associated code and detailed results, see\nhttps://github.com/jpgard/subgroup-robustness-grows-on-trees .",
    "descriptor": "\nComments: To appear at Neural Information Processing Systems (NeurIPS) 2022. Code at this https URL\n",
    "authors": [
      "Josh Gardner",
      "Zoran Popovi\u0107",
      "Ludwig Schmidt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.12703"
  },
  {
    "id": "arXiv:2211.12705",
    "title": "In-Mouth Robotic Bite Transfer with Visual and Haptic Sensing",
    "abstract": "Assistance during eating is essential for those with severe mobility issues\nor eating risks. However, dependence on traditional human caregivers is linked\nto malnutrition, weight loss, and low self-esteem. For those who require eating\nassistance, a semi-autonomous robotic platform can provide independence and a\nhealthier lifestyle. We demonstrate an essential capability of this platform:\nsafe, comfortable, and effective transfer of a bite-sized food item from a\nutensil directly to the inside of a person's mouth. Our system uses a\nforce-reactive controller to safely accommodate the user's motions throughout\nthe transfer, allowing full reactivity until bite detection then reducing\nreactivity in the direction of exit. Additionally, we introduce a novel\ndexterous wrist-like end effector capable of small, unimposing movements to\nreduce user discomfort. We conduct a user study with 11 participants covering 8\ndiverse food categories to evaluate our system end-to-end, and we find that\nusers strongly prefer our method to a wide range of baselines. Appendices and\nvideos are available at our website: https://tinyurl.com/btICRA.",
    "descriptor": "\nComments: Submitted to ICRA 2023\n",
    "authors": [
      "Lorenzo Shaikewitz",
      "Yilin Wu",
      "Suneel Belkhale",
      "Jennifer Grannen",
      "Priya Sundaresan",
      "Dorsa Sadigh"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.12705"
  },
  {
    "id": "arXiv:2211.12706",
    "title": "Quality Assurance in MLOps Setting: An Industrial Perspective",
    "abstract": "Today, machine learning (ML) is widely used in industry to provide the core\nfunctionality of production systems. However, it is practically always used in\nproduction systems as part of a larger end-to-end software system that is made\nup of several other components in addition to the ML model. Due to production\ndemand and time constraints, automated software engineering practices are\nhighly applicable. The increased use of automated ML software engineering\npractices in industries such as manufacturing and utilities requires an\nautomated Quality Assurance (QA) approach as an integral part of ML software.\nHere, QA helps reduce risk by offering an objective perspective on the software\ntask. Although conventional software engineering has automated tools for QA\ndata analysis for data-driven ML, the use of QA practices for ML in operation\n(MLOps) is lacking. This paper examines the QA challenges that arise in\nindustrial MLOps and conceptualizes modular strategies to deal with data\nintegrity and Data Quality (DQ). The paper is accompanied by real industrial\nuse-cases from industrial partners. The paper also presents several challenges\nthat may serve as a basis for future studies.",
    "descriptor": "",
    "authors": [
      "Ayan Chatterjee",
      "Bestoun S. Ahmed",
      "Erik Hallin",
      "Anton Engman"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12706"
  },
  {
    "id": "arXiv:2211.12707",
    "title": "Can Open-Domain QA Reader Utilize External Knowledge Efficiently like  Humans?",
    "abstract": "Recent state-of-the-art open-domain QA models are typically based on a two\nstage retriever-reader approach in which the retriever first finds the relevant\nknowledge/passages and the reader then leverages that to predict the answer.\nPrior work has shown that the performance of the reader usually tends to\nimprove with the increase in the number of these passages. Thus,\nstate-of-the-art models use a large number of passages (e.g. 100) for\ninference. While the reader in this approach achieves high prediction\nperformance, its inference is computationally very expensive. We humans, on the\nother hand, use a more efficient strategy while answering: firstly, if we can\nconfidently answer the question using our already acquired knowledge then we do\nnot even use the external knowledge, and in the case when we do require\nexternal knowledge, we don't read the entire knowledge at once, instead, we\nonly read that much knowledge that is sufficient to find the answer. Motivated\nby this procedure, we ask a research question \"Can the open-domain QA reader\nutilize external knowledge efficiently like humans without sacrificing the\nprediction performance?\"\nDriven by this question, we explore an approach that utilizes both\n'closed-book' (leveraging knowledge already present in the model parameters)\nand 'open-book' inference (leveraging external knowledge). Furthermore, instead\nof using a large fixed number of passages for open-book inference, we\ndynamically read the external knowledge in multiple 'knowledge iterations'.\nThrough comprehensive experiments on NQ and TriviaQA datasets, we demonstrate\nthat this dynamic reading approach improves both the 'inference efficiency' and\nthe 'prediction accuracy' of the reader. Comparing with the FiD reader, this\napproach matches its accuracy by utilizing just 18.32% of its reader inference\ncost and also outperforms it by achieving up to 55.10% accuracy on NQ Open.",
    "descriptor": "\nComments: AAAI-23 Workshop on Knowledge Augmented Methods for NLP\n",
    "authors": [
      "Neeraj Varshney",
      "Man Luo",
      "Chitta Baral"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.12707"
  },
  {
    "id": "arXiv:2211.12709",
    "title": "SciAI4Industry -- Solving PDEs for industry-scale problems with deep  learning",
    "abstract": "Solving partial differential equations with deep learning makes it possible\nto reduce simulation times by multiple orders of magnitude and unlock\nscientific methods that typically rely on large numbers of sequential\nsimulations, such as optimization and uncertainty quantification. Two of the\nlargest challenges of adopting scientific AI for industrial problem settings is\nthat training datasets must be simulated in advance and that neural networks\nfor solving large-scale PDEs exceed the memory capabilities of current GPUs. We\nintroduce a distributed programming API in the Julia language for simulating\ntraining data in parallel on the cloud and without requiring users to manage\nthe underlying HPC infrastructure. In addition, we show that model-parallel\ndeep learning based on domain decomposition allows us to scale neural networks\nfor solving PDEs to commercial-scale problem settings and achieve above 90%\nparallel efficiency. Combining our cloud API for training data generation and\nmodel-parallel deep learning, we train large-scale neural networks for solving\nthe 3D Navier-Stokes equation and simulating 3D CO2 flow in porous media. For\nthe CO2 example, we simulate a training dataset based on a commercial carbon\ncapture and storage (CCS) project and train a neural network for CO2 flow\nsimulation on a 3D grid with over 2 million cells that is 5 orders of\nmagnitudes faster than a conventional numerical simulator and 3,200 times\ncheaper.",
    "descriptor": "\nComments: Submitted to International Parallel and Distributed Processing Symposium (IPDPS) on October 5, 2022\n",
    "authors": [
      "Philipp A. Witte",
      "Russell J. Hewett",
      "Kumar Saurabh",
      "AmirHossein Sojoodi",
      "Ranveer Chandra"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.12709"
  },
  {
    "id": "arXiv:2211.12712",
    "title": "Contrastive Identity-Aware Learning for Multi-Agent Value Decomposition",
    "abstract": "Value Decomposition (VD) aims to deduce the contributions of agents for\ndecentralized policies in the presence of only global rewards, and has recently\nemerged as a powerful credit assignment paradigm for tackling cooperative\nMulti-Agent Reinforcement Learning (MARL) problems. One of the main challenges\nin VD is to promote diverse behaviors among agents, while existing methods\ndirectly encourage the diversity of learned agent networks with various\nstrategies. However, we argue that these dedicated designs for agent networks\nare still limited by the indistinguishable VD network, leading to homogeneous\nagent behaviors and thus downgrading the cooperation capability. In this paper,\nwe propose a novel Contrastive Identity-Aware learning (CIA) method, explicitly\nboosting the credit-level distinguishability of the VD network to break the\nbottleneck of multi-agent diversity. Specifically, our approach leverages\ncontrastive learning to maximize the mutual information between the temporal\ncredits and identity representations of different agents, encouraging the full\nexpressiveness of credit assignment and further the emergence of\nindividualities. The algorithm implementation of the proposed CIA module is\nsimple yet effective that can be readily incorporated into various VD\narchitectures. Experiments on the SMAC benchmarks and across different VD\nbackbones demonstrate that the proposed method yields results superior to the\nstate-of-the-art counterparts. Our code is available at\nhttps://github.com/liushunyu/CIA.",
    "descriptor": "",
    "authors": [
      "Shunyu Liu",
      "Yihe Zhou",
      "Jie Song",
      "Tongya Zheng",
      "Kaixuan Chen",
      "Tongtian Zhu",
      "Zunlei Feng",
      "Mingli Song"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.12712"
  },
  {
    "id": "arXiv:2211.12713",
    "title": "Reliable Robustness Evaluation via Automatically Constructed Attack  Ensembles",
    "abstract": "Attack Ensemble (AE), which combines multiple attacks together, provides a\nreliable way to evaluate adversarial robustness. In practice, AEs are often\nconstructed and tuned by human experts, which however tends to be sub-optimal\nand time-consuming. In this work, we present AutoAE, a conceptually simple\napproach for automatically constructing AEs. In brief, AutoAE repeatedly adds\nthe attack and its iteration steps to the ensemble that maximizes ensemble\nimprovement per additional iteration consumed. We show theoretically that\nAutoAE yields AEs provably within a constant factor of the optimal for a given\ndefense. We then use AutoAE to construct two AEs for $l_{\\infty}$ and $l_2$\nattacks, and apply them without any tuning or adaptation to 45 top adversarial\ndefenses on the RobustBench leaderboard. In all except one cases we achieve\nequal or better (often the latter) robustness evaluation than existing AEs, and\nnotably, in 29 cases we achieve better robustness evaluation than the best\nknown one. Such performance of AutoAE shows itself as a reliable evaluation\nprotocol for adversarial robustness, which further indicates the huge potential\nof automatic AE construction. Code is available at\n\\url{https://github.com/LeegerPENG/AutoAE}.",
    "descriptor": "",
    "authors": [
      "Shengcai Liu",
      "Fu Peng",
      "Ke Tang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.12713"
  },
  {
    "id": "arXiv:2211.12714",
    "title": "Developmental Plasticity-inspired Adaptive Pruning for Deep Spiking and  Artificial Neural Networks",
    "abstract": "Developmental plasticity plays a vital role in shaping the brain's structure\nduring ongoing learning in response to the dynamically changing environments.\nHowever, the existing network compression methods for deep artificial neural\nnetworks (ANNs) and spiking neural networks (SNNs) draw little inspiration from\nthe brain's developmental plasticity mechanisms, thus limiting their ability to\nlearn efficiently, rapidly, and accurately. This paper proposed a developmental\nplasticity-inspired adaptive pruning (DPAP) method, with inspiration from the\nadaptive developmental pruning of dendritic spines, synapses, and neurons\naccording to the \"use it or lose it, gradually decay\" principle. The proposed\nDPAP model considers multiple biologically realistic mechanisms (such as\ndendritic spine dynamic plasticity, activity-dependent neural spiking trace,\nlocal synaptic plasticity), with the addition of an adaptive pruning strategy,\nso that the network structure can be dynamically optimized during learning\nwithout any pre-training and retraining. We demonstrated that the proposed DPAP\nmethod applied to deep ANNs and SNNs could learn efficient network\narchitectures that retain only relevant important connections and neurons.\nExtensive comparative experiments show consistent and remarkable performance\nand speed boost with the extremely compressed networks on a diverse set of\nbenchmark tasks, especially neuromorphic datasets for SNNs. This work explores\nhow developmental plasticity enables the complex deep networks to gradually\nevolve into brain-like efficient and compact structures, eventually achieving\nstate-of-the-art (SOTA) performance for biologically realistic SNNs.",
    "descriptor": "",
    "authors": [
      "Bing Han",
      "Feifei Zhao",
      "Yi Zeng",
      "Guobin Shen"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12714"
  },
  {
    "id": "arXiv:2211.12715",
    "title": "Embedding Compression for Text Classification Using Dictionary Screening",
    "abstract": "In this paper, we propose a dictionary screening method for embedding\ncompression in text classification tasks. The key purpose of this method is to\nevaluate the importance of each keyword in the dictionary. To this end, we\nfirst train a pre-specified recurrent neural network-based model using a full\ndictionary. This leads to a benchmark model, which we then use to obtain the\npredicted class probabilities for each sample in a dataset. Next, to evaluate\nthe impact of each keyword in affecting the predicted class probabilities, we\ndevelop a novel method for assessing the importance of each keyword in a\ndictionary. Consequently, each keyword can be screened, and only the most\nimportant keywords are reserved. With these screened keywords, a new dictionary\nwith a considerably reduced size can be constructed. Accordingly, the original\ntext sequence can be substantially compressed. The proposed method leads to\nsignificant reductions in terms of parameters, average text sequence, and\ndictionary size. Meanwhile, the prediction power remains very competitive\ncompared to the benchmark model. Extensive numerical studies are presented to\ndemonstrate the empirical performance of the proposed method.",
    "descriptor": "",
    "authors": [
      "Jing Zhou",
      "Xinru Jing",
      "Muyu Liu",
      "Hansheng Wang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.12715"
  },
  {
    "id": "arXiv:2211.12716",
    "title": "Global Meets Local: Effective Multi-Label Image Classification via  Category-Aware Weak Supervision",
    "abstract": "Multi-label image classification, which can be categorized into\nlabel-dependency and region-based methods, is a challenging problem due to the\ncomplex underlying object layouts. Although region-based methods are less\nlikely to encounter issues with model generalizability than label-dependency\nmethods, they often generate hundreds of meaningless or noisy proposals with\nnon-discriminative information, and the contextual dependency among the\nlocalized regions is often ignored or over-simplified. This paper builds a\nunified framework to perform effective noisy-proposal suppression and to\ninteract between global and local features for robust feature learning.\nSpecifically, we propose category-aware weak supervision to concentrate on\nnon-existent categories so as to provide deterministic information for local\nfeature learning, restricting the local branch to focus on more high-quality\nregions of interest. Moreover, we develop a cross-granularity attention module\nto explore the complementary information between global and local features,\nwhich can build the high-order feature correlation containing not only\nglobal-to-local, but also local-to-local relations. Both advantages guarantee a\nboost in the performance of the whole network. Extensive experiments on two\nlarge-scale datasets (MS-COCO and VOC 2007) demonstrate that our framework\nachieves superior performance over state-of-the-art methods.",
    "descriptor": "\nComments: 12 pages, 10 figures, published in ACMMM 2022\n",
    "authors": [
      "Jiawei Zhan",
      "Jun Liu",
      "Wei Tang",
      "Guannan Jiang",
      "Xi Wang",
      "Bin-Bin Gao",
      "Tianliang Zhang",
      "Wenlong Wu",
      "Wei Zhang",
      "Chengjie Wang",
      "Yuan Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12716"
  },
  {
    "id": "arXiv:2211.12728",
    "title": "Stochastic Capacitated Arc Routing Problem",
    "abstract": "This paper deals with the Stochastic Capacitated Arc Routing Problem (SCARP),\nobtained by randomizing quantities on the arcs in the CARP. Optimization\nproblems for the SCARP are characterized by decisions that are made without\nknowing their full consequences. For real-life problems, it is important to\ncreate solutions insensitive to variations of the quantities to collect because\nof the randomness of these quantities. Efficient robust solutions are required\nto avoid unprofitable costly moves of vehicles to the depot node. Different\ncriteria are proposed to model the SCARP and advanced concepts of a genetic\nalgorithm optimizing both cost and robustness are provided. The method is\nbenchmarked on the well-known instances proposed by DeArmon, Eglese and\nBelenguer. The results prove it is possible to obtain robust solutions without\nany significant enlargement of the solution cost. This allows treating more\nrealistic problems including industrial goals and constraints linked to\nvariations in the quantities to be collected.",
    "descriptor": "",
    "authors": [
      "Fleury G\u00e9rard",
      "Lacomme Philippe",
      "Christian Prins"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.12728"
  },
  {
    "id": "arXiv:2211.12732",
    "title": "Wild-Places: A Large-Scale Dataset for Lidar Place Recognition in  Unstructured Natural Environments",
    "abstract": "Many existing datasets for lidar place recognition are solely representative\nof structured urban environments, and have recently been saturated in\nperformance by deep learning based approaches. Natural and unstructured\nenvironments present many additional challenges for the tasks of long-term\nlocalisation but these environments are not represented in currently available\ndatasets. To address this we introduce Wild-Places, a challenging large-scale\ndataset for lidar place recognition in unstructured, natural environments.\nWild-Places contains eight lidar sequences collected with a handheld sensor\npayload over the course of fourteen months, containing a total of 67K\nundistorted lidar submaps along with accurate 6DoF ground truth. Our dataset\ncontains multiple revisits both within and between sequences, allowing for both\nintra-sequence (i.e. loop closure detection) and inter-sequence (i.e.\nre-localisation) place recognition. We also benchmark several state-of-the-art\napproaches to demonstrate the challenges that this dataset introduces,\nparticularly the case of long-term place recognition due to natural\nenvironments changing over time. Our dataset and code will be available at\nhttps://csiro-robotics.github.io/Wild-Places.",
    "descriptor": "\nComments: Submitted to ICRA2023\n",
    "authors": [
      "Joshua Knights",
      "Kavisha Vidanapathirana",
      "Milad Ramezani",
      "Sridha Sridharan",
      "Clinton Fookes",
      "Peyman Moghadam"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.12732"
  },
  {
    "id": "arXiv:2211.12733",
    "title": "Safety Analysis of Autonomous Driving Systems Based on Model Learning",
    "abstract": "We present a practical verification method for safety analysis of the\nautonomous driving system (ADS). The main idea is to build a surrogate model\nthat quantitatively depicts the behaviour of an ADS in the specified traffic\nscenario. The safety properties proved in the resulting surrogate model apply\nto the original ADS with a probabilistic guarantee. Furthermore, we explore the\nsafe and the unsafe parameter space of the traffic scenario for driving\nhazards. We demonstrate the utility of the proposed approach by evaluating\nsafety properties on the state-of-the-art ADS in literature, with a variety of\nsimulated traffic scenarios.",
    "descriptor": "",
    "authors": [
      "Renjue Li",
      "Tianhang Qin",
      "Pengfei Yang",
      "Cheng-Chao Huang",
      "Youcheng Sun",
      "Lijun Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.12733"
  },
  {
    "id": "arXiv:2211.12734",
    "title": "A note on the category of c-spaces",
    "abstract": "We prove that the category of c-spaces with continuous maps is not cartesian\nclosed. As a corollary the category of locally finitary compact spaces with\ncontinuous maps is also not cartesian closed.",
    "descriptor": "\nComments: 5 pages\n",
    "authors": [
      "Z. Lyu",
      "X. Xie",
      "H. Kou"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Category Theory (math.CT)"
    ],
    "url": "https://arxiv.org/abs/2211.12734"
  },
  {
    "id": "arXiv:2211.12735",
    "title": "Integrally Pre-Trained Transformer Pyramid Networks",
    "abstract": "In this paper, we present an integral pre-training framework based on masked\nimage modeling (MIM). We advocate for pre-training the backbone and neck\njointly so that the transfer gap between MIM and downstream recognition tasks\nis minimal. We make two technical contributions. First, we unify the\nreconstruction and recognition necks by inserting a feature pyramid into the\npre-training stage. Second, we complement mask image modeling (MIM) with masked\nfeature modeling (MFM) that offers multi-stage supervision to the feature\npyramid. The pre-trained models, termed integrally pre-trained transformer\npyramid networks (iTPNs), serve as powerful foundation models for visual\nrecognition. In particular, the base/large-level iTPN achieves an 86.2%/87.8%\ntop-1 accuracy on ImageNet-1K, a 53.2%/55.6% box AP on COCO object detection\nwith 1x training schedule using Mask-RCNN, and a 54.7%/57.7% mIoU on ADE20K\nsemantic segmentation using UPerHead -- all these results set new records. Our\nwork inspires the community to work on unifying upstream pre-training and\ndownstream fine-tuning tasks. Code and the pre-trained models will be released\nat https://github.com/sunsmarterjie/iTPN.",
    "descriptor": "\nComments: 13 pages, 5 figures, 13 tables\n",
    "authors": [
      "Yunjie Tian",
      "Lingxi Xie",
      "Zhaozhi Wang",
      "Longhui Wei",
      "Xiaopeng Zhang",
      "Jianbin Jiao",
      "Yaowei Wang",
      "Qi Tian",
      "Qixiang Ye"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12735"
  },
  {
    "id": "arXiv:2211.12737",
    "title": "RoentGen: Vision-Language Foundation Model for Chest X-ray Generation",
    "abstract": "Multimodal models trained on large natural image-text pair datasets have\nexhibited astounding abilities in generating high-quality images. Medical\nimaging data is fundamentally different to natural images, and the language\nused to succinctly capture relevant details in medical data uses a different,\nnarrow but semantically rich, domain-specific vocabulary. Not surprisingly,\nmulti-modal models trained on natural image-text pairs do not tend to\ngeneralize well to the medical domain. Developing generative imaging models\nfaithfully representing medical concepts while providing compositional\ndiversity could mitigate the existing paucity of high-quality, annotated\nmedical imaging datasets. In this work, we develop a strategy to overcome the\nlarge natural-medical distributional shift by adapting a pre-trained latent\ndiffusion model on a corpus of publicly available chest x-rays (CXR) and their\ncorresponding radiology (text) reports. We investigate the model's ability to\ngenerate high-fidelity, diverse synthetic CXR conditioned on text prompts. We\nassess the model outputs quantitatively using image quality metrics, and\nevaluate image quality and text-image alignment by human domain experts. We\npresent evidence that the resulting model (RoentGen) is able to create visually\nconvincing, diverse synthetic CXR images, and that the output can be controlled\nto a new extent by using free-form text prompts including radiology-specific\nlanguage. Fine-tuning this model on a fixed training set and using it as a data\naugmentation method, we measure a 5% improvement of a classifier trained\njointly on synthetic and real images, and a 3% improvement when trained on a\nlarger but purely synthetic training set. Finally, we observe that this\nfine-tuning distills in-domain knowledge in the text-encoder and can improve\nits representation capabilities of certain diseases like pneumothorax by 25%.",
    "descriptor": "\nComments: 19 pages\n",
    "authors": [
      "Pierre Chambon",
      "Christian Bluethgen",
      "Jean-Benoit Delbrouck",
      "Rogier Van der Sluijs",
      "Ma\u0142gorzata Po\u0142acin",
      "Juan Manuel Zambrano Chaves",
      "Tanishq Mathew Abraham",
      "Shivanshu Purohit",
      "Curtis P. Langlotz",
      "Akshay Chaudhari"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12737"
  },
  {
    "id": "arXiv:2211.12738",
    "title": "Differentially Private Fair Division",
    "abstract": "Fairness and privacy are two important concerns in social decision-making\nprocesses such as resource allocation. We study privacy in the fair allocation\nof indivisible resources using the well-established framework of differential\nprivacy. We present algorithms for approximate envy-freeness and\nproportionality when two instances are considered to be adjacent if they differ\nonly on the utility of a single agent for a single item. On the other hand, we\nprovide strong negative results for both fairness criteria when the adjacency\nnotion allows the entire utility function of a single agent to change.",
    "descriptor": "\nComments: Appears in the 37th AAAI Conference on Artificial Intelligence (AAAI), 2023\n",
    "authors": [
      "Pasin Manurangsi",
      "Warut Suksompong"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.12738"
  },
  {
    "id": "arXiv:2211.12739",
    "title": "Texts as Images in Prompt Tuning for Multi-Label Image Recognition",
    "abstract": "Prompt tuning has been employed as an efficient way to adapt large\nvision-language pre-trained models (e.g. CLIP) to various downstream tasks in\ndata-limited or label-limited settings. Nonetheless, visual data (e.g., images)\nis by default prerequisite for learning prompts in existing methods. In this\nwork, we advocate that the effectiveness of image-text contrastive learning in\naligning the two modalities (for training CLIP) further makes it feasible to\ntreat texts as images for prompt tuning and introduce TaI prompting. In\ncontrast to the visual data, text descriptions are easy to collect, and their\nclass labels can be directly derived. Particularly, we apply TaI prompting to\nmulti-label image recognition, where sentences in the wild serve as\nalternatives to images for prompt tuning. Moreover, with TaI, double-grained\nprompt tuning (TaI-DPT) is further presented to extract both coarse-grained and\nfine-grained embeddings for enhancing the multi-label recognition performance.\nExperimental results show that our proposed TaI-DPT outperforms zero-shot CLIP\nby a large margin on multiple benchmarks, e.g., MS-COCO, VOC2007, and NUS-WIDE,\nwhile it can be combined with existing methods of prompting from images to\nimprove recognition performance further. Code is released at\nhttps://github.com/guozix/TaI-DPT.",
    "descriptor": "",
    "authors": [
      "Zixian Guo",
      "Bowen Dong",
      "Zhilong Ji",
      "Jinfeng Bai",
      "Yiwen Guo",
      "Wangmeng Zuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12739"
  },
  {
    "id": "arXiv:2211.12740",
    "title": "Masked Autoencoding for Scalable and Generalizable Decision Making",
    "abstract": "We are interested in learning scalable agents for reinforcement learning that\ncan learn from large-scale, diverse sequential data similar to current large\nvision and language models. To this end, this paper presents masked decision\nprediction (MaskDP), a simple and scalable self-supervised pretraining method\nfor reinforcement learning (RL) and behavioral cloning (BC). In our MaskDP\napproach, we employ a masked autoencoder (MAE) to state-action trajectories,\nwherein we randomly mask state and action tokens and reconstruct the missing\ndata. By doing so, the model is required to infer masked-out states and actions\nand extract information about dynamics. We find that masking different\nproportions of the input sequence significantly helps with learning a better\nmodel that generalizes well to multiple downstream tasks. In our empirical\nstudy, we find that a MaskDP model gains the capability of zero-shot transfer\nto new BC tasks, such as single and multiple goal reaching, and it can\nzero-shot infer skills from a few example transitions. In addition, MaskDP\ntransfers well to offline RL and shows promising scaling behavior w.r.t. to\nmodel size. It is amenable to data-efficient finetuning, achieving competitive\nresults with prior methods based on autoregressive pretraining.",
    "descriptor": "",
    "authors": [
      "Fangchen Liu",
      "Hao Liu",
      "Aditya Grover",
      "Pieter Abbeel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12740"
  },
  {
    "id": "arXiv:2211.12743",
    "title": "Efficient List-Decodable Regression using Batches",
    "abstract": "We begin the study of list-decodable linear regression using batches. In this\nsetting only an $\\alpha \\in (0,1]$ fraction of the batches are genuine. Each\ngenuine batch contains $\\ge n$ i.i.d. samples from a common unknown\ndistribution and the remaining batches may contain arbitrary or even\nadversarial samples. We derive a polynomial time algorithm that for any $n\\ge\n\\tilde \\Omega(1/\\alpha)$ returns a list of size $\\mathcal O(1/\\alpha^2)$ such\nthat one of the items in the list is close to the true regression parameter.\nThe algorithm requires only $\\tilde{\\mathcal{O}}(d/\\alpha^2)$ genuine batches\nand works under fairly general assumptions on the distribution.\nThe results demonstrate the utility of batch structure, which allows for the\nfirst polynomial time algorithm for list-decodable regression, which may be\nimpossible for the non-batch setting, as suggested by a recent SQ lower bound\n\\cite{diakonikolas2021statistical} for the non-batch setting.",
    "descriptor": "\nComments: First draft\n",
    "authors": [
      "Abhimanyu Das",
      "Ayush Jain",
      "Weihao Kong",
      "Rajat Sen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.12743"
  },
  {
    "id": "arXiv:2211.12744",
    "title": "Towards Advanced Monitoring for Scientific Workflows",
    "abstract": "Scientific workflows consist of thousands of highly parallelized tasks\nexecuted in a distributed environment involving many components. Automatic\ntracing and investigation of the components' and tasks' performance metrics,\ntraces, and behavior are necessary to support the end user with a level of\nabstraction since the large amount of data cannot be analyzed manually. The\nexecution and monitoring of scientific workflows involves many components, the\ncluster infrastructure, its resource manager, the workflow, and the workflow\ntasks. All components in such an execution environment access different\nmonitoring metrics and provide metrics on different abstraction levels. The\ncombination and analysis of observed metrics from different components and\ntheir interdependencies are still widely unregarded.\nWe specify four different monitoring layers that can serve as an\narchitectural blueprint for the monitoring responsibilities and the\ninteractions of components in the scientific workflow execution context. We\ndescribe the different monitoring metrics subject to the four layers and how\nthe layers interact. Finally, we examine five state-of-the-art scientific\nworkflow management systems (SWMS) in order to assess which steps are needed to\nenable our four-layer-based approach.",
    "descriptor": "\nComments: Paper accepted in 2022 IEEE International Conference on Big Data Workshop SCDM 2022\n",
    "authors": [
      "Jonathan Bader",
      "Joel Witzke",
      "Soeren Becker",
      "Ansgar L\u00f6\u00dfer",
      "Fabian Lehmann",
      "Leon Doehler",
      "Anh Duc Vu",
      "Odej Kao"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.12744"
  },
  {
    "id": "arXiv:2211.12746",
    "title": "Completing point cloud from few points by Wasserstein GAN and  Transformers",
    "abstract": "In many vision and robotics applications, it is common that the captured\nobjects are represented by very few points. Most of the existing completion\nmethods are designed for partial point clouds with many points, and they\nperform poorly or even fail completely in the case of few points. However, due\nto the lack of detail information, completing objects from few points faces a\nhuge challenge. Inspired by the successful applications of GAN and Transformers\nin the image-based vision task, we introduce GAN and Transformer techniques to\naddress the above problem. Firstly, the end-to-end encoder-decoder network with\nTransformers and the Wasserstein GAN with Transformer are pre-trained, and then\nthe overall network is fine-tuned. Experimental results on the ShapeNet dataset\nshow that our method can not only improve the completion performance for many\ninput points, but also keep stable for few input points. Our source code is\navailable at https://github.com/WxfQjh/Stability-point-recovery.git.",
    "descriptor": "",
    "authors": [
      "Xianfeng Wu",
      "Jinhui Qian",
      "Qing Wei",
      "Xianzu Wu",
      "Xinyi Liu",
      "Luxin Hu",
      "Yanli Gong",
      "Zhongyuan Lai",
      "Libing Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12746"
  },
  {
    "id": "arXiv:2211.12748",
    "title": "Dynamic Appearance: A Video Representation for Action Recognition with  Joint Training",
    "abstract": "Static appearance of video may impede the ability of a deep neural network to\nlearn motion-relevant features in video action recognition. In this paper, we\nintroduce a new concept, Dynamic Appearance (DA), summarizing the appearance\ninformation relating to movement in a video while filtering out the static\ninformation considered unrelated to motion. We consider distilling the dynamic\nappearance from raw video data as a means of efficient video understanding. To\nthis end, we propose the Pixel-Wise Temporal Projection (PWTP), which projects\nthe static appearance of a video into a subspace within its original vector\nspace, while the dynamic appearance is encoded in the projection residual\ndescribing a special motion pattern. Moreover, we integrate the PWTP module\nwith a CNN or Transformer into an end-to-end training framework, which is\noptimized by utilizing multi-objective optimization algorithms. We provide\nextensive experimental results on four action recognition benchmarks:\nKinetics400, Something-Something V1, UCF101 and HMDB51.",
    "descriptor": "",
    "authors": [
      "Guoxi Huang",
      "Adrian G. Bors"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12748"
  },
  {
    "id": "arXiv:2211.12751",
    "title": "SAH: Shifting-aware Asymmetric Hashing for Reverse $k$-Maximum Inner  Product Search",
    "abstract": "This paper investigates a new yet challenging problem called Reverse\n$k$-Maximum Inner Product Search (R$k$MIPS). Given a query (item) vector, a set\nof item vectors, and a set of user vectors, the problem of R$k$MIPS aims to\nfind a set of user vectors whose inner products with the query vector are one\nof the $k$ largest among the query and item vectors. We propose the first\nsubquadratic-time algorithm, i.e., Shifting-aware Asymmetric Hashing (SAH), to\ntackle the R$k$MIPS problem. To speed up the Maximum Inner Product Search\n(MIPS) on item vectors, we design a shifting-invariant asymmetric\ntransformation and develop a novel sublinear-time Shifting-Aware Asymmetric\nLocality Sensitive Hashing (SA-ALSH) scheme. Furthermore, we devise a new\nblocking strategy based on the Cone-Tree to effectively prune user vectors (in\na batch). We prove that SAH achieves a theoretical guarantee for solving the\nRMIPS problem. Experimental results on five real-world datasets show that SAH\nruns 4$\\sim$8$\\times$ faster than the state-of-the-art methods for R$k$MIPS\nwhile achieving F1-scores of over 90\\%. The code is available at\n\\url{https://github.com/HuangQiang/SAH}.",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Qiang Huang",
      "Yanhao Wang",
      "Anthony K. H. Tung"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Databases (cs.DB)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12751"
  },
  {
    "id": "arXiv:2211.12752",
    "title": "Agent-Specific Deontic Modality Detection in Legal Language",
    "abstract": "Legal documents are typically long and written in legalese, which makes it\nparticularly difficult for laypeople to understand their rights and duties.\nWhile natural language understanding technologies can be valuable in supporting\nsuch understanding in the legal domain, the limited availability of datasets\nannotated for deontic modalities in the legal domain, due to the cost of hiring\nexperts and privacy issues, is a bottleneck. To this end, we introduce,\nLEXDEMOD, a corpus of English contracts annotated with deontic modality\nexpressed with respect to a contracting party or agent along with the modal\ntriggers. We benchmark this dataset on two tasks: (i) agent-specific\nmulti-label deontic modality classification, and (ii) agent-specific deontic\nmodality and trigger span detection using Transformer-based (Vaswani et al.,\n2017) language models. Transfer learning experiments show that the linguistic\ndiversity of modal expressions in LEXDEMOD generalizes reasonably from lease to\nemployment and rental agreements. A small case study indicates that a model\ntrained on LEXDEMOD can detect red flags with high recall. We believe our work\noffers a new research direction for deontic modality detection in the legal\ndomain.",
    "descriptor": "\nComments: Accepted at EMNLP 2022\n",
    "authors": [
      "Abhilasha Sancheti",
      "Aparna Garimella",
      "Balaji Vasan Srinivasan",
      "Rachel Rudinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.12752"
  },
  {
    "id": "arXiv:2211.12757",
    "title": "FAIRification of MLC data",
    "abstract": "The multi-label classification (MLC) task has increasingly been receiving\ninterest from the machine learning (ML) community, as evidenced by the growing\nnumber of papers and methods that appear in the literature. Hence, ensuring\nproper, correct, robust, and trustworthy benchmarking is of utmost importance\nfor the further development of the field. We believe that this can be achieved\nby adhering to the recently emerged data management standards, such as the FAIR\n(Findable, Accessible, Interoperable, and Reusable) and TRUST (Transparency,\nResponsibility, User focus, Sustainability, and Technology) principles. To\nFAIRify the MLC datasets, we introduce an ontology-based online catalogue of\nMLC datasets that follow these principles. The catalogue extensively describes\nmany MLC datasets with comprehensible meta-features, MLC-specific semantic\ndescriptions, and different data provenance information. The MLC data catalogue\nis extensively described in our recent publication in Nature Scientific\nReports, Kostovska & Bogatinovski et al., and available at:\nthis http URL In addition, we provide an\nontology-based system for easy access and querying of performance/benchmark\ndata obtained from a comprehensive MLC benchmark study. The system is available\nat: this http URL",
    "descriptor": "\nComments: This paper was accepted ECML PKDD 2022\n",
    "authors": [
      "Ana Kostovska",
      "Jasmin Bogatinovski",
      "Andrej Treven",
      "Sa\u0161o D\u017eeroski",
      "Dragi Kocev",
      "Pan\u010de Panov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.12757"
  },
  {
    "id": "arXiv:2211.12758",
    "title": "PANeRF: Pseudo-view Augmentation for Improved Neural Radiance Fields  Based on Few-shot Inputs",
    "abstract": "The method of neural radiance fields (NeRF) has been developed in recent\nyears, and this technology has promising applications for synthesizing novel\nviews of complex scenes. However, NeRF requires dense input views, typically\nnumbering in the hundreds, for generating high-quality images. With a decrease\nin the number of input views, the rendering quality of NeRF for unseen\nviewpoints tends to degenerate drastically. To overcome this challenge, we\npropose pseudo-view augmentation of NeRF, a scheme that expands a sufficient\namount of data by considering the geometry of few-shot inputs. We first\ninitialized the NeRF network by leveraging the expanded pseudo-views, which\nefficiently minimizes uncertainty when rendering unseen views. Subsequently, we\nfine-tuned the network by utilizing sparse-view inputs containing precise\ngeometry and color information. Through experiments under various settings, we\nverified that our model faithfully synthesizes novel-view images of superior\nquality and outperforms existing methods for multi-view datasets.",
    "descriptor": "",
    "authors": [
      "Young Chun Ahn",
      "Seokhwan Jang",
      "Sungheon Park",
      "Ji-Yeon Kim",
      "Nahyup Kang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12758"
  },
  {
    "id": "arXiv:2211.12759",
    "title": "NAS-LID: Efficient Neural Architecture Search with Local Intrinsic  Dimension",
    "abstract": "One-shot neural architecture search (NAS) substantially improves the search\nefficiency by training one supernet to estimate the performance of every\npossible child architecture (i.e., subnet). However, the inconsistency of\ncharacteristics among subnets incurs serious interference in the optimization,\nresulting in poor performance ranking correlation of subnets. Subsequent\nexplorations decompose supernet weights via a particular criterion, e.g.,\ngradient matching, to reduce the interference; yet they suffer from huge\ncomputational cost and low space separability. In this work, we propose a\nlightweight and effective local intrinsic dimension (LID)-based method NAS-LID.\nNAS-LID evaluates the geometrical properties of architectures by calculating\nthe low-cost LID features layer-by-layer, and the similarity characterized by\nLID enjoys better separability compared with gradients, which thus effectively\nreduces the interference among subnets. Extensive experiments on NASBench-201\nindicate that NAS-LID achieves superior performance with better efficiency.\nSpecifically, compared to the gradient-driven method, NAS-LID can save up to\n86% of GPU memory overhead when searching on NASBench-201. We also demonstrate\nthe effectiveness of NAS-LID on ProxylessNAS and OFA spaces. Source\ncode:https://github.com/marsggbo/NAS-LID.",
    "descriptor": "\nComments: Accepted by AAAI2023\n",
    "authors": [
      "Xin He",
      "Jiangchao Yao",
      "Yuxin Wang",
      "Zhenheng Tang",
      "Ka Chu Cheung",
      "Simon See",
      "Bo Han",
      "Xiaowen Chu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12759"
  },
  {
    "id": "arXiv:2211.12760",
    "title": "InDiReCT: Language-Guided Zero-Shot Deep Metric Learning for Images",
    "abstract": "Common Deep Metric Learning (DML) datasets specify only one notion of\nsimilarity, e.g., two images in the Cars196 dataset are deemed similar if they\nshow the same car model. We argue that depending on the application, users of\nimage retrieval systems have different and changing similarity notions that\nshould be incorporated as easily as possible. Therefore, we present\nLanguage-Guided Zero-Shot Deep Metric Learning (LanZ-DML) as a new DML setting\nin which users control the properties that should be important for image\nrepresentations without training data by only using natural language. To this\nend, we propose InDiReCT (Image representations using Dimensionality Reduction\non CLIP embedded Texts), a model for LanZ-DML on images that exclusively uses a\nfew text prompts for training. InDiReCT utilizes CLIP as a fixed feature\nextractor for images and texts and transfers the variation in text prompt\nembeddings to the image embedding space. Extensive experiments on five datasets\nand overall thirteen similarity notions show that, despite not seeing any\nimages during training, InDiReCT performs better than strong baselines and\napproaches the performance of fully-supervised models. An analysis reveals that\nInDiReCT learns to focus on regions of the image that correlate with the\ndesired similarity notion, which makes it a fast to train and easy to use\nmethod to create custom embedding spaces only using natural language.",
    "descriptor": "\nComments: Accepted to WACV 2023\n",
    "authors": [
      "Konstantin Kobs",
      "Michael Steininger",
      "Andreas Hotho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.12760"
  },
  {
    "id": "arXiv:2211.12761",
    "title": "MPMICE: A hybrid MPM-CFD model for simulating coupled problems in porous  media. Application to earthquake-induced submarine landslides",
    "abstract": "In this paper, we describe a soil-fluid-structure interaction model that\ncombines soil mechanics (saturated sediments), fluid mechanics (seawater or\nair), and solid mechanics (structures). The formulation combines the Material\nPoint Method, which models large deformation of the porous media and the\nstructure, with the Implicit Continuous-fluid Eulerian, which models complex\nfluid flows. We validate the model and simulate the whole process of\nearthquake-induced submarine landslides. We show that this model captures\ncomplex interactions between saturated sediment, seawater, and structure, so we\ncan use the model to estimate the impact of potential submarine landslides on\noffshore structures.",
    "descriptor": "",
    "authors": [
      "Quoc Anh Tran",
      "Gustav Grimstad",
      "Seyed Ali Ghoreishian Amiri"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.12761"
  },
  {
    "id": "arXiv:2211.12764",
    "title": "VoP: Text-Video Co-operative Prompt Tuning for Cross-Modal Retrieval",
    "abstract": "Many recent studies leverage the pre-trained CLIP for text-video cross-modal\nretrieval by tuning the backbone with additional heavy modules, which not only\nbrings huge computational burdens with much more parameters, but also leads to\nthe knowledge forgetting from upstream models.In this work, we propose the VoP:\nText-Video Co-operative Prompt Tuning for efficient tuning on the text-video\nretrieval task. The proposed VoP is an end-to-end framework with both video &\ntext prompts introducing, which can be regarded as a powerful baseline with\nonly 0.1% trainable parameters. Further, based on the spatio-temporal\ncharacteristics of videos, we develop three novel video prompt mechanisms to\nimprove the performance with different scales of trainable parameters. The\nbasic idea of the VoP enhancement is to model the frame position, frame\ncontext, and layer function with specific trainable prompts, respectively.\nExtensive experiments show that compared to full fine-tuning, the enhanced VoP\nachieves a 1.4% average R@1 gain across five text-video retrieval benchmarks\nwith 6x less parameter overhead. The code will be available at\nhttps://github.com/bighuang624/VoP.",
    "descriptor": "",
    "authors": [
      "Siteng Huang",
      "Biao Gong",
      "Yulin Pan",
      "Jianwen Jiang",
      "Yiliang Lv",
      "Yuyuan Li",
      "Donglin Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.12764"
  },
  {
    "id": "arXiv:2211.12765",
    "title": "Analysis of Discrete-Time Switched Linear Systems under Logic Dynamic  Switchings",
    "abstract": "The control properties of discrete-time switched linear systems (SLSs) with\nswitching signals generated by logical dynamic systems are studied using the\nsemi-tensor product approach. With the algebraic state-space representation,\nThe linear modes and logical generators are aggregated as a hybrid system,\nleading to the criteria for reachability, controllability, observability, and\nreconstructibility of the SLSs. Algorithms are given to check these properties.\nThen two kinds of realization problems concerning whether the logical dynamic\nsystems can generate the desired switching signals are investigated, and\nnecessary and sufficient conditions for realizability are given with respect to\nthe cases of fixed operating time switchings and finite reference signal\nswitchings.",
    "descriptor": "\nComments: 12 pages, 2 figures\n",
    "authors": [
      "Xiao Zhang",
      "Zhengping Ji",
      "Daizhan Cheng"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.12765"
  },
  {
    "id": "arXiv:2211.12767",
    "title": "Cambrian Explosion Algorithm for Multi-Objective Association Rules  Mining",
    "abstract": "Association rule mining is one of the most studied research fields of data\nmining, with applications ranging from grocery basket problems to highly\nexplainable classification systems. Classical association rule mining\nalgorithms have several flaws especially with regards to their execution times,\nmemory usage and number of rules produced. An alternative is the use of\nmeta-heuristics, which have been used on several optimisation problems. This\npaper has two objectives. First, we provide a comparison of the performances of\nstate-of-the-art meta-heuristics on the association rule mining problem. We use\nthe multi-objective versions of those algorithms using support, confidence and\ncosine. Second, we propose a new algorithm designed to mine rules efficiently\nfrom massive datasets by exploring a large variety of solutions, akin to the\nexplosion of species diversity of the Cambrian Explosion. We compare our\nalgorithm to 20 benchmark algorithms on 22 real-world data-sets, and show that\nour algorithm present good results and outperform several state-of-the-art\nalgorithms.",
    "descriptor": "",
    "authors": [
      "Th\u00e9ophile Berteloot",
      "Richard Khoury",
      "Audrey Durand"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.12767"
  },
  {
    "id": "arXiv:2211.12769",
    "title": "Byzantine Multiple Access Channels -- Part I: Reliable Communication",
    "abstract": "We study communication over a Multiple Access Channel (MAC) where users can\npossibly be adversarial. When all users are non-adversarial, we want their\nmessages to be decoded reliably. When a user behaves adversarially, we require\nthat the honest users' messages be decoded reliably. An adversarial user can\nmount an attack by sending any input into the channel rather than following the\nprotocol. It turns out that the $2$-user MAC capacity region follows from the\npoint-to-point Arbitrarily Varying Channel (AVC) capacity. For the $3$-user MAC\nin which at most one user may be malicious, we characterize the capacity region\nfor deterministic codes and randomized codes (where each user shares an\nindependent random secret key with the receiver). These results are then\ngeneralized for the $k$-user MAC where the adversary may control all users in\none out of a collection of given subsets.",
    "descriptor": "\nComments: This supercedes Part I of arxiv:1904.11925\n",
    "authors": [
      "Neha Sangwan",
      "Mayank Bakshi",
      "Bikash Kumar Dey",
      "Vinod M. Prabhakaran"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.12769"
  },
  {
    "id": "arXiv:2211.12771",
    "title": "Reconnoitering the class distinguishing abilities of the features, to  know them better",
    "abstract": "The relevance of machine learning (ML) in our daily lives is closely\nintertwined with its explainability. Explainability can allow end-users to have\na transparent and humane reckoning of a ML scheme's capability and utility. It\nwill also foster the user's confidence in the automated decisions of a system.\nExplaining the variables or features to explain a model's decision is a need of\nthe present times. We could not really find any work, which explains the\nfeatures on the basis of their class-distinguishing abilities (specially when\nthe real world data are mostly of multi-class nature). In any given dataset, a\nfeature is not equally good at making distinctions between the different\npossible categorizations (or classes) of the data points. In this work, we\nexplain the features on the basis of their class or category-distinguishing\ncapabilities. We particularly estimate the class-distinguishing capabilities\n(scores) of the variables for pair-wise class combinations. We validate the\nexplainability given by our scheme empirically on several real-world,\nmulti-class datasets. We further utilize the class-distinguishing scores in a\nlatent feature context and propose a novel decision making protocol. Another\nnovelty of this work lies with a \\emph{refuse to render decision} option when\nthe latent variable (of the test point) has a high class-distinguishing\npotential for the likely classes.",
    "descriptor": "",
    "authors": [
      "Payel Sadhukhan",
      "Sarbani palit",
      "Kausik Sengupta"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12771"
  },
  {
    "id": "arXiv:2211.12773",
    "title": "Learning Regularized Positional Encoding for Molecular Prediction",
    "abstract": "Machine learning has become a promising approach for molecular modeling.\nPositional quantities, such as interatomic distances and bond angles, play a\ncrucial role in molecule physics. The existing works rely on careful manual\ndesign of their representation. To model the complex nonlinearity in predicting\nmolecular properties in an more end-to-end approach, we propose to encode the\npositional quantities with a learnable embedding that is continuous and\ndifferentiable. A regularization technique is employed to encourage embedding\nsmoothness along the physical dimension. We experiment with a variety of\nmolecular property and force field prediction tasks. Improved performance is\nobserved for three different model architectures after plugging in the proposed\npositional encoding method. In addition, the learned positional encoding allows\neasier physics-based interpretation. We observe that tasks of similar physics\nhave the similar learned positional encoding.",
    "descriptor": "\nComments: AI4Science Workshop at NeurIPS 2022\n",
    "authors": [
      "Xiang Gao",
      "Weihao Gao",
      "Wenzhi Xiao",
      "Zhirui Wang",
      "Chong Wang",
      "Liang Xiang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2211.12773"
  },
  {
    "id": "arXiv:2211.12774",
    "title": "Prototypical context-aware dynamics generalization for high-dimensional  model-based reinforcement learning",
    "abstract": "The latent world model provides a promising way to learn policies in a\ncompact latent space for tasks with high-dimensional observations, however, its\ngeneralization across diverse environments with unseen dynamics remains\nchallenging. Although the recurrent structure utilized in current advances\nhelps to capture local dynamics, modeling only state transitions without an\nexplicit understanding of environmental context limits the generalization\nability of the dynamics model. To address this issue, we propose a Prototypical\nContext-Aware Dynamics (ProtoCAD) model, which captures the local dynamics by\ntime consistent latent context and enables dynamics generalization in\nhigh-dimensional control tasks. ProtoCAD extracts useful contextual information\nwith the help of the prototypes clustered over batch and benefits model-based\nRL in two folds: 1) It utilizes a temporally consistent prototypical\nregularizer that encourages the prototype assignments produced for different\ntime parts of the same latent trajectory to be temporally consistent instead of\ncomparing the features; 2) A context representation is designed which combines\nboth the projection embedding of latent states and aggregated prototypes and\ncan significantly improve the dynamics generalization ability. Extensive\nexperiments show that ProtoCAD surpasses existing methods in terms of dynamics\ngeneralization. Compared with the recurrent-based model RSSM, ProtoCAD delivers\n13.2% and 26.7% better mean and median performance across all dynamics\ngeneralization tasks.",
    "descriptor": "",
    "authors": [
      "Junjie Wang",
      "Yao Mu",
      "Dong Li",
      "Qichao Zhang",
      "Dongbin Zhao",
      "Yuzheng Zhuang",
      "Ping Luo",
      "Bin Wang",
      "Jianye Hao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12774"
  },
  {
    "id": "arXiv:2211.12776",
    "title": "Research on Data Fusion Algorithm Based on Deep Learning in Target  Tracking",
    "abstract": "Aiming at the limitation that deep long and short-term memory network(DLSTM)\nalgorithm cannot perform parallel computing and cannot obtain global\ninformation, in this paper, feature extraction and feature processing are\nfirstly carried out according to the characteristics of eye movement data and\ntracking data, then by introducing a convolutional neural network (CNN) into a\ndeep long and short-term memory network, developed a new network structure and\ndesigned a fusion strategy, an eye tracking data fusion algorithm based on long\nand short-term memory network is proposed. The experimental results show that\ncompared with the two fusion algorithms based on deep learning, the algorithm\nproposed in this paper performs well in terms of fusion quality.",
    "descriptor": "",
    "authors": [
      "Huihui Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12776"
  },
  {
    "id": "arXiv:2211.12777",
    "title": "A Dual-scale Lead-seperated Transformer With Lead-orthogonal Attention  And Meta-information For Ecg Classification",
    "abstract": "Auxiliary diagnosis of cardiac electrophysiological status can be obtained\nthrough the analysis of 12-lead electrocardiograms (ECGs). This work proposes a\ndual-scale lead-separated transformer with lead-orthogonal attention and\nmeta-information (DLTM-ECG) as a novel approach to address this challenge. ECG\nsegments of each lead are interpreted as independent patches, and together with\nthe reduced dimension signal, they form a dual-scale representation. As a\nmethod to reduce interference from segments with low correlation, two group\nattention mechanisms perform both lead-internal and cross-lead attention. Our\nmethod allows for the addition of previously discarded meta-information,\nfurther improving the utilization of clinical information. Experimental results\nshow that our DLTM-ECG yields significantly better classification scores than\nother transformer-based models,matching or performing better than\nstate-of-the-art (SOTA) deep learning methods on two benchmark datasets. Our\nwork has the potential for similar multichannel bioelectrical signal processing\nand physiological multimodal tasks.",
    "descriptor": "",
    "authors": [
      "Yang Li",
      "Guijin Wang",
      "Zhourui Xia",
      "Wenming Yang",
      "Li Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12777"
  },
  {
    "id": "arXiv:2211.12778",
    "title": "Monitoring and Improving Personalized Sleep Quality from Long-Term  Lifelogs",
    "abstract": "Sleep plays a vital role in our physical, cognitive, and psychological\nwell-being. Despite its importance, long-term monitoring of personalized sleep\nquality (SQ) in real-world contexts is still challenging. Many sleep researches\nare still developing clinically and far from accessible to the general public.\nFortunately, wearables and IoT devices provide the potential to explore the\nsleep insights from multimodal data, and have been used in some SQ researches.\nHowever, most of these studies analyze the sleep related data and present the\nresults in a delayed manner (i.e., today's SQ obtained from last night's data),\nit is sill difficult for individuals to know how their sleep will be before\nthey go to bed and how they can proactively improve it. To this end, this paper\nproposes a computational framework to monitor the individual SQ based on both\nthe objective and subjective data from multiple sources, and moves a step\nfurther towards providing the personalized feedback to improve the SQ in a\ndata-driven manner. The feedback is implemented by referring the insights from\nthe PMData dataset based on the discovered patterns between life events and\ndifferent levels of SQ. The deep learning based personal SQ model (PerSQ),\nusing the long-term heterogeneous data and considering the carry-over effect,\nachieves higher prediction performance compared with baseline models. A case\nstudy also shows reasonable results for an individual to monitor and improve\nthe SQ in the future.",
    "descriptor": "\nComments: 9 pages,9 figures, 4 tables\n",
    "authors": [
      "Wenbin Gan",
      "Minh-Son Dao",
      "Koji Zettsu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12778"
  },
  {
    "id": "arXiv:2211.12781",
    "title": "Breaking the Representation Bottleneck of Chinese Characters: Neural  Machine Translation with Stroke Sequence Modeling",
    "abstract": "Existing research generally treats Chinese character as a minimum unit for\nrepresentation. However, such Chinese character representation will suffer two\nbottlenecks: 1) Learning bottleneck, the learning cannot benefit from its rich\ninternal features (e.g., radicals and strokes); and 2) Parameter bottleneck,\neach individual character has to be represented by a unique vector. In this\npaper, we introduce a novel representation method for Chinese characters to\nbreak the bottlenecks, namely StrokeNet, which represents a Chinese character\nby a Latinized stroke sequence (e.g., \"ao1 (concave)\" to \"ajaie\" and \"tu1\n(convex)\" to \"aeaqe\"). Specifically, StrokeNet maps each stroke to a specific\nLatin character, thus allowing similar Chinese characters to have similar Latin\nrepresentations. With the introduction of StrokeNet to neural machine\ntranslation (NMT), many powerful but not applicable techniques to non-Latin\nlanguages (e.g., shared subword vocabulary learning and ciphertext-based data\naugmentation) can now be perfectly implemented. Experiments on the widely-used\nNIST Chinese-English, WMT17 Chinese-English and IWSLT17 Japanese-English NMT\ntasks show that StrokeNet can provide a significant performance boost over the\nstrong baselines with fewer model parameters, achieving 26.5 BLEU on the WMT17\nChinese-English task which is better than any previously reported results\nwithout using monolingual data. Code and scripts are freely available at\nhttps://github.com/zjwang21/StrokeNet.",
    "descriptor": "\nComments: Accepted to EMNLP 2022\n",
    "authors": [
      "Zhijun Wang",
      "Xuebo Liu",
      "Min Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12781"
  },
  {
    "id": "arXiv:2211.12782",
    "title": "Hand Avatar: Free-Pose Hand Animation and Rendering from Monocular Video",
    "abstract": "We present HandAvatar, a novel representation for hand animation and\nrendering, which can generate smoothly compositional geometry and\nself-occlusion-aware texture. Specifically, we first develop a MANO-HD model as\na high-resolution mesh topology to fit personalized hand shapes. Sequentially,\nwe decompose hand geometry into per-bone rigid parts, and then re-compose\npaired geometry encodings to derive an across-part consistent occupancy field.\nAs for texture modeling, we propose a self-occlusion-aware shading field\n(SelF). In SelF, drivable anchors are paved on the MANO-HD surface to record\nalbedo information under a wide variety of hand poses. Moreover, directed soft\noccupancy is designed to describe the ray-to-surface relation, which is\nleveraged to generate an illumination field for the disentanglement of\npose-independent albedo and pose-dependent illumination. Trained from monocular\nvideo data, our HandAvatar can perform free-pose hand animation and rendering\nwhile at the same time achieving superior appearance fidelity. We also\ndemonstrate that HandAvatar provides a route for hand appearance editing.\nProject website: https://seanchenxy.github.io/HandAvatarWeb.",
    "descriptor": "",
    "authors": [
      "Xingyu Chen",
      "Baoyuan Wang",
      "Heung-Yeung Shum"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.12782"
  },
  {
    "id": "arXiv:2211.12785",
    "title": "Smoothing splines for discontinuous signals",
    "abstract": "Smoothing splines are standard methods of nonparametric regression for\nobtaining smooth functions from noisy observations. But as splines are twice\ndifferentiable by construction, they cannot capture potential discontinuities\nin the underlying signal. The smoothing spline model can be augmented such that\ndiscontinuities at a priori unknown locations are incorporated. The augmented\nmodel results in a minimization problem with respect to discontinuity\nlocations. The minimizing solution is a cubic smoothing spline with\ndiscontinuities (CSSD) which may serve as function estimator for discontinuous\nsignals, as a changepoint detector, and as a tool for exploratory data\nanalysis. However, these applications are hardly accessible at the moment\nbecause there is no efficient algorithm for computing a CSSD. In this paper, we\npropose an efficient algorithm that computes a global minimizer of the\nunderlying problem. Its worst case complexity is quadratic in the number of\ndata points. If the number of detected discontinuities scales linearly with the\nsignal length, we observe linear growth of the runtime. By the proposed\nalgorithm, a CSSD can be computed in reasonable time on standard hardware.\nFurthermore, we implement a strategy for automatic selection of the\nhyperparameters. Numerical examples demonstrate the applicability of a CSSD for\nthe tasks mentioned above.",
    "descriptor": "",
    "authors": [
      "Martin Storath",
      "Andreas Weinmann"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2211.12785"
  },
  {
    "id": "arXiv:2211.12787",
    "title": "Program Repair",
    "abstract": "Automated program repair is an emerging technology which consists of a suite\nof techniques to automatically fix bugs or vulnerabilities in programs. In this\npaper, we present a comprehensive survey of the state of the art in program\nrepair. We first study the different suite of techniques used including search\nbased repair, constraint based repair and learning based repair. We then\ndiscuss one of the main challenges in program repair namely patch overfitting,\nby distilling a class of techniques which can alleviate patch overfitting. We\nthen discuss classes of program repair tools, applications of program repair as\nwell as uses of program repair in industry. We conclude the survey with a\nforward looking outlook on future usages of program repair, as well as research\nopportunities arising from work on code from large language models.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2012.06824 by other authors\n",
    "authors": [
      "Xiang Gao",
      "Yannic Noller",
      "Abhik Roychoudhury"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.12787"
  },
  {
    "id": "arXiv:2211.12791",
    "title": "An ensemble of VisNet, Transformer-M, and pretraining models for  molecular property prediction in OGB Large-Scale Challenge @ NeurIPS 2022",
    "abstract": "In the technical report, we provide our solution for OGB-LSC 2022 Graph\nRegression Task. The target of this task is to predict the quantum chemical\nproperty, HOMO-LUMO gap for a given molecule on PCQM4Mv2 dataset. In the\ncompetition, we designed two kinds of models: Transformer-M-ViSNet which is an\ngeometry-enhanced graph neural network for fully connected molecular graphs and\nPretrained-3D-ViSNet which is a pretrained ViSNet by distilling geomeotric\ninformation from optimized structures. With an ensemble of 22 models, ViSNet\nTeam achieved the MAE of 0.0723 eV on the test-challenge set, dramatically\nreducing the error by 39.75% compared with the best method in the last year\ncompetition.",
    "descriptor": "",
    "authors": [
      "Yusong Wang",
      "Shaoning Li",
      "Tong Wang",
      "Zun Wang",
      "Xinheng He",
      "Bin Shao",
      "Tie-Yan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.12791"
  },
  {
    "id": "arXiv:2211.12792",
    "title": "MECCH: Metapath Context Convolution-based Heterogeneous Graph Neural  Networks",
    "abstract": "Heterogeneous graph neural networks (HGNNs) were proposed for representation\nlearning on structural data with multiple types of nodes and edges. Researchers\nhave developed metapath-based HGNNs to deal with the over-smoothing problem of\nrelation-based HGNNs. However, existing metapath-based models suffer from\neither information loss or high computation costs. To address these problems,\nwe design a new Metapath Context Convolution-based Heterogeneous Graph Neural\nNetwork (MECCH). Specifically, MECCH applies three novel components after\nfeature preprocessing to extract comprehensive information from the input graph\nefficiently: (1) metapath context construction, (2) metapath context encoder,\nand (3) convolutional metapath fusion. Experiments on five real-world\nheterogeneous graph datasets for node classification and link prediction show\nthat MECCH achieves superior prediction accuracy compared with state-of-the-art\nbaselines with improved computational efficiency.",
    "descriptor": "\nComments: 11 pages, 5 figures, 9 tables; code available at this https URL\n",
    "authors": [
      "Xinyu Fu",
      "Irwin King"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12792"
  },
  {
    "id": "arXiv:2211.12794",
    "title": "Zero Forcing Uplink Detection through Large-Scale RIS: System  Performance and Phase Shift Design",
    "abstract": "A multiple-input multiple-output wireless communication system is\nanalytically studied, which operates with the aid of a large-scale\nreconfigurable intelligent surface (LRIS). LRIS is equipped with multiple\npassive elements with discrete phase adjustment capabilities, and independent\nRician fading conditions are assumed for both the transmitter-to-LRIS and\nLRIS-to-receiver links. A direct transceiver link is also considered which is\nmodeled by Rayleigh fading distribution. The system performance is analytically\nstudied when the linear yet efficient zero-forcing detection is implemented at\nthe receiver. In particular, the outage performance is derived in closed-form\nexpression for different system configuration setups with regards to the\navailable channel state information (CSI) at the receiver. In fact, the case of\nboth perfect and imperfect CSI is analyzed. Also, an efficient phase shift\ndesign approach at LRIS is introduced, which is linear on the number of passive\nelements and receive antennas. The proposed phase shift design can be applied\non two different modes of operation; namely, when the system strives to adapt\neither on the instantaneous or statistical CSI. Finally, some impactful\nengineering insights are provided, such as how the channel fading conditions,\nCSI, discrete phase shift resolution, and volume of antenna/LRIS element arrays\nimpact on the overall system performance.",
    "descriptor": "\nComments: Accepted for publication to IEEE Transactions on Communications\n",
    "authors": [
      "Nikolaos I. Miridakis",
      "Theodoros A. Tsiftsis",
      "Rugui Yao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.12794"
  },
  {
    "id": "arXiv:2211.12796",
    "title": "IMaSC -- ICFOSS Malayalam Speech Corpus",
    "abstract": "Modern text-to-speech (TTS) systems use deep learning to synthesize speech\nincreasingly approaching human quality, but they require a database of high\nquality audio-text sentence pairs for training. Malayalam, the official\nlanguage of the Indian state of Kerala and spoken by 35+ million people, is a\nlow resource language in terms of available corpora for TTS systems. In this\npaper, we present IMaSC, a Malayalam text and speech corpora containing\napproximately 50 hours of recorded speech. With 8 speakers and a total of\n34,473 text-audio pairs, IMaSC is larger than every other publicly available\nalternative. We evaluated the database by using it to train TTS models for each\nspeaker based on a modern deep learning architecture. Via subjective\nevaluation, we show that our models perform significantly better in terms of\nnaturalness compared to previous studies and publicly available models, with an\naverage mean opinion score of 4.50, indicating that the synthesized speech is\nclose to human quality.",
    "descriptor": "\nComments: 18 pages, 8 figures\n",
    "authors": [
      "Deepa P Gopinath",
      "Thennal D K",
      "Vrinda V Nair",
      "Swaraj K S",
      "Sachin G"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.12796"
  },
  {
    "id": "arXiv:2211.12798",
    "title": "An Open Case-based Reasoning Framework for Personalized On-board Driving  Assistance in Risk Scenarios",
    "abstract": "Driver reaction is of vital importance in risk scenarios. Drivers can take\ncorrect evasive maneuver at proper cushion time to avoid the potential traffic\ncrashes, but this reaction process is highly experience-dependent and requires\nvarious levels of driving skills. To improve driving safety and avoid the\ntraffic accidents, it is necessary to provide all road drivers with on-board\ndriving assistance. This study explores the plausibility of case-based\nreasoning (CBR) as the inference paradigm underlying the choice of personalized\ncrash evasive maneuvers and the cushion time, by leveraging the wealthy of\nhuman driving experience from the steady stream of traffic cases, which have\nbeen rarely explored in previous studies. To this end, in this paper, we\npropose an open evolving framework for generating personalized on-board driving\nassistance. In particular, we present the FFMTE model with high performance to\nmodel the traffic events and build the case database; A tailored CBR-based\nmethod is then proposed to retrieve, reuse and revise the existing cases to\ngenerate the assistance. We take the 100-Car Naturalistic Driving Study dataset\nas an example to build and test our framework; the experiments show reasonable\nresults, providing the drivers with valuable evasive information to avoid the\npotential crashes in different scenarios.",
    "descriptor": "\nComments: 10 pahes, 8 figures, 4 tables, accepted by IEEE BigData 2022\n",
    "authors": [
      "Wenbin Gan",
      "Minh-Son Dao",
      "Koji Zettsu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.12798"
  },
  {
    "id": "arXiv:2211.12799",
    "title": "Benchmarking JSON BinPack",
    "abstract": "In this paper, we present benchmark results for a pre-production\nimplementation of a novel serialization specification: JSON BinPack. JSON\nBinPack is a schema-driven and schema-less sequential binary serialization\nspecification based on JSON Schema. It is rich in diverse encodings, and is\ndeveloped to improve network performance and reduce the operational costs of\nInternet-based software systems. We present benchmark results for 27 JSON\ndocuments and for each plot, we show the schema-driven and schema-less\nserialization specifications that produce the smallest bit-strings. Through\nextensive plots and statistical comparisons, we show that JSON BinPack in\nschema-driven mode is as space-efficient or more space-efficient than every\nother serialization specification for the 27 documents under consideration. In\ncomparison to JSON, JSON BinPack in schema-driven mode provides a median and\naverage size reductions of 86.7% and 78.7%, respectively. We also show that the\nschema-less mode of the JSON BinPack binary serialization specification is as\nspace-efficient or more space-efficient than every other schema-less\nserialization specification for the 27 documents under consideration. In\ncomparison to JSON, JSON BinPack in schema-less mode provides a median and\naverage size reductions of 30.6% and 30.5%, respectively. Unlike other\nconsidered schema-driven binary serialization specifications, JSON BinPack in\nschema-driven mode is space-efficient in comparison to best-case compressed\nJSON in terms of the median and average with size reductions of 76.1% and\n66.8%, respectively. We have made our benchmark results available at\njviotti/binary-json-size-benchmark on GitHub.",
    "descriptor": "\nComments: 41 Pages. arXiv admin note: substantial text overlap with arXiv:2201.03051\n",
    "authors": [
      "Juan Cruz Viotti",
      "Mital Kinderkhedia"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.12799"
  },
  {
    "id": "arXiv:2211.12803",
    "title": "You Don't Know When I Will Arrive: Unpredictable Controller Synthesis  for Temporal Logic Tasks",
    "abstract": "In this paper, we investigate the problem of synthesizing controllers for\ntemporal logic specifications under security constraint. We assume that there\nexists a passive intruder (eavesdropper) that can partially observe the\nbehavior of the system. For the purpose of security, we require that the\nsystem's behaviors are unpredictable in the sense that the intruder cannot\ndetermine for sure that the system will exactly accomplish the task in $K$\nsteps ahead. This problem is particularly challenging since future information\nis involved in the synthesis process. We propose a novel information structure\nthat predicts the effect of control in the future. A sound and complete\nalgorithm is developed to synthesize a controller which ensures both task\ncompletion and security guarantee. The proposed approach is illustrated by a\ncase study of robot task planning.",
    "descriptor": "",
    "authors": [
      "Yu Chen",
      "Shuo Yang",
      "Rahul Mangharam",
      "Xiang Yin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.12803"
  },
  {
    "id": "arXiv:2211.12805",
    "title": "Markov decision processes with maximum entropy rate for Surveillance  Tasks",
    "abstract": "We consider the problem of synthesizing optimal policies for Markov decision\nprocesses (MDP) for both utility objective and security constraint.\nSpecifically, our goal is to maximize the \\emph{entropy rate} of the MDP while\nachieving a surveillance task in the sense that a given region of interest is\nvisited infinitely often with probability one. Such a policy is of our interest\nsince it guarantees both the completion of tasks and maximizes the\n\\emph{unpredictability} of limit behavior of the system. Existing works either\nfocus on the total entropy or do not consider the surveillance tasks which are\nnot suitable for surveillance tasks with infinite horizon. We provide a\ncomplete solution to this problem. Specifically, we present an algorithm for\nsynthesizing entropy rate maximizing policies for communicating MDPs. Then\nbased on a new state classification method, we show the entropy rate\nmaximization problem under surveillance task can be effectively solved in\npolynomial-time. We illustrate the proposed algorithm based on a case study of\nrobot planning scenario.",
    "descriptor": "",
    "authors": [
      "Yu Chen",
      "Shaoyuan Li",
      "Xiang Yin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.12805"
  },
  {
    "id": "arXiv:2211.12814",
    "title": "Vertical Federated Learning",
    "abstract": "Vertical Federated Learning (VFL) is a federated learning setting where\nmultiple parties with different features about the same set of users jointly\ntrain machine learning models without exposing their raw data or model\nparameters. Motivated by the rapid growth in VFL research and real-world\napplications, we provide a comprehensive review of the concept and algorithms\nof VFL, as well as current advances and challenges in various aspects,\nincluding effectiveness, efficiency, and privacy. We provide an exhaustive\ncategorization for VFL settings and privacy-preserving protocols and\ncomprehensively analyze the privacy attacks and defense strategies for each\nprotocol. In the end, we propose a unified framework, termed VFLow, which\nconsiders the VFL problem under communication, computation, privacy, and\neffectiveness constraints. Finally, we review the most recent advances in\nindustrial applications, highlighting open challenges and future directions for\nVFL.",
    "descriptor": "",
    "authors": [
      "Yang Liu",
      "Yan Kang",
      "Tianyuan Zou",
      "Yanhong Pu",
      "Yuanqin He",
      "Xiaozhou Ye",
      "Ye Ouyang",
      "Ya-Qin Zhang",
      "Qiang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.12814"
  },
  {
    "id": "arXiv:2211.12817",
    "title": "Reason from Context with Self-supervised Learning",
    "abstract": "A tiny object in the sky cannot be an elephant. Context reasoning is critical\nin visual recognition, where current inputs need to be interpreted in the light\nof previous experience and knowledge. To date, research into contextual\nreasoning in visual recognition has largely proceeded with supervised learning\nmethods. The question of whether contextual knowledge can be captured with\nself-supervised learning regimes remains under-explored. Here, we established a\nmethodology for context-aware self-supervised learning. We proposed a novel\nSelf-supervised Learning Method for Context Reasoning (SeCo), where the only\ninputs to SeCo are unlabeled images with multiple objects present in natural\nscenes. Similar to the distinction between fovea and periphery in human vision,\nSeCo processes self-proposed target object regions and their contexts\nseparately, and then employs a learnable external memory for retrieving and\nupdating context-relevant target information. To evaluate the contextual\nassociations learned by the computational models, we introduced two evaluation\nprotocols, lift-the-flap and object priming, addressing the problems of \"what\"\nand \"where\" in context reasoning. In both tasks, SeCo outperformed all\nstate-of-the-art (SOTA) self-supervised learning methods by a significant\nmargin. Our network analysis revealed that the external memory in SeCo learns\nto store prior contextual knowledge, facilitating target identity inference in\nlift-the-flap task. Moreover, we conducted psychophysics experiments and\nintroduced a Human benchmark in Object Priming dataset (HOP). Our quantitative\nand qualitative results demonstrate that SeCo approximates human-level\nperformance and exhibits human-like behavior. All our source code and data are\npublicly available here.",
    "descriptor": "",
    "authors": [
      "Xiao Liu",
      "Ankur Sikarwar",
      "Joo Hwee Lim",
      "Gabriel Kreiman",
      "Zenglin Shi",
      "Mengmi Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12817"
  },
  {
    "id": "arXiv:2211.12819",
    "title": "Tracking biomedical articles along the translational continuum: a  measure based on biomedical knowledge representation",
    "abstract": "Keeping track of translational research is essential to evaluating the\nperformance of programs on translational medicine. Despite several indicators\nin previous studies, a consensus measure is still needed to represent the\ntranslational features of biomedical research at the article level. In this\nstudy, we first trained semantic representations of biomedical entities and\ndocuments (i.e., bio entity2vec and bio doc2vec) based on over 30 million\nPubMed articles. With these vectors, we then developed a new measure called\nTranslational Progression (TP) for tracking biomedical articles along the\ntranslational continuum. We validated the effectiveness of TP from two\nperspectives (Clinical trial phase identification and ACH classification),\nwhich showed excellent consistency between TP and other indicators. Meanwhile,\nTP has several advantages. First, it can track the degree of translation of\nbiomedical research dynamically and in real time. Second, it is straightforward\nto interpret and operationalize. Third, it doesn%u2019t require labor-intensive\nMeSH labeling and it is suitable for big scholarly data as well as papers that\nare not indexed in PubMed. In addition, we examined the translational\nprogressions of biomedical research from three dimensions (including overall\ndistribution, time, and research topic), which revealed three significant\nfindings. The proposed measure in this study could be used by policymakers to\nmonitor biomedical research with high translational potential in real time and\nmake better decisions. It can also be adopted and improved for other domains,\nsuch as physics or computer science, to assess the application value of\nscientific discoveries.",
    "descriptor": "\nComments: 26 pages, 11 figures\n",
    "authors": [
      "Xin Li",
      "Xuli Tang",
      "Wei Lu"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2211.12819"
  },
  {
    "id": "arXiv:2211.12820",
    "title": "Fairly Allocating Utility in Constrained Multiwinner Elections",
    "abstract": "Fairness in multiwinner elections is studied in varying contexts. For\ninstance, diversity of candidates and representation of voters are both\nseparately termed as being fair. A common denominator to ensure fairness across\nall such contexts is the use of constraints. However, across these contexts,\nthe candidates selected to satisfy the given constraints may systematically\nlead to unfair outcomes for historically disadvantaged voter populations as the\ncost of fairness may be borne unequally. Hence, we develop a model to select\ncandidates that satisfy the constraints fairly across voter populations. To do\nso, the model maps the constrained multiwinner election problem to a problem of\nfairly allocating indivisible goods. We propose three variants of the model,\nnamely, global, localized, and inter-sectional. Next, we analyze the model's\ncomputational complexity, and we present an empirical analysis of the utility\ntraded-off across various settings of our model across the three variants and\ndiscuss the impact of Simpson's paradox using synthetic datasets and a dataset\nof voting at the United Nations. Finally, we discuss the implications of our\nwork for AI and machine learning, especially for studies that use constraints\nto guarantee fairness.",
    "descriptor": "\nComments: 13 pages (2-column), 3 figures\n",
    "authors": [
      "Kunal Relia"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.12820"
  },
  {
    "id": "arXiv:2211.12821",
    "title": "Explainable AI for Pre-Trained Code Models: What Do They Learn? When  They Do Not Work?",
    "abstract": "In recent years, there has been a wide interest in designing deep neural\nnetwork-based models that automate downstream software engineering tasks, such\nas program document generation, code search, and program repair. Although the\nmain objective of these studies is to improve the effectiveness of the\ndownstream task, many studies only attempt to employ the next best neural\nnetwork model, without a proper in-depth analysis of why a particular solution\nworks or does not, on particular tasks or scenarios. In this paper, using an\neXplainable AI (XAI) method (attention mechanism), we study state-of-the-art\nTransformer-based models (CodeBERT and GraphCodeBERT) on a set of software\nengineering downstream tasks: code document generation (CDG), code refinement\n(CR), and code translation (CT). We first evaluate the validity of the\nattention mechanism on each particular task. Then, through quantitative and\nqualitative studies, we identify what CodeBERT and GraphCodeBERT learn (put the\nhighest attention on, in terms of source code token types), on these tasks.\nFinally, we show some of the common patterns when the model does not work as\nexpected (perform poorly while the problem in hand is easy) and suggest\nrecommendations that may alleviate the observed challenges.",
    "descriptor": "\nComments: 46 pages, 20 figures, Sumbitted to Empirical Software Engineering\n",
    "authors": [
      "Ahmad Haji Mohammadkhani",
      "Chakkrit Tantithamthavorn",
      "Hadi Hemmati"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.12821"
  },
  {
    "id": "arXiv:2211.12824",
    "title": "Tell Me What Happened: Unifying Text-guided Video Completion via  Multimodal Masked Video Generation",
    "abstract": "Generating a video given the first several static frames is challenging as it\nanticipates reasonable future frames with temporal coherence. Besides video\nprediction, the ability to rewind from the last frame or infilling between the\nhead and tail is also crucial, but they have rarely been explored for video\ncompletion. Since there could be different outcomes from the hints of just a\nfew frames, a system that can follow natural language to perform video\ncompletion may significantly improve controllability. Inspired by this, we\nintroduce a novel task, text-guided video completion (TVC), which requests the\nmodel to generate a video from partial frames guided by an instruction. We then\npropose Multimodal Masked Video Generation (MMVG) to address this TVC task.\nDuring training, MMVG discretizes the video frames into visual tokens and masks\nmost of them to perform video completion from any time point. At inference\ntime, a single MMVG model can address all 3 cases of TVC, including video\nprediction, rewind, and infilling, by applying corresponding masking\nconditions. We evaluate MMVG in various video scenarios, including egocentric,\nanimation, and gaming. Extensive experimental results indicate that MMVG is\neffective in generating high-quality visual appearances with text guidance for\nTVC.",
    "descriptor": "",
    "authors": [
      "Tsu-Jui Fu",
      "Licheng Yu",
      "Ning Zhang",
      "Cheng-Yang Fu",
      "Jong-Chyi Su",
      "William Yang Wang",
      "Sean Bell"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.12824"
  },
  {
    "id": "arXiv:2211.12826",
    "title": "Data-driven Feature Tracking for Event Cameras",
    "abstract": "Because of their high temporal resolution, increased resilience to motion\nblur, and very sparse output, event cameras have been shown to be ideal for\nlow-latency and low-bandwidth feature tracking, even in challenging scenarios.\nExisting feature tracking methods for event cameras are either handcrafted or\nderived from first principles but require extensive parameter tuning, are\nsensitive to noise, and do not generalize to different scenarios due to\nunmodeled effects. To tackle these deficiencies, we introduce the first\ndata-driven feature tracker for event cameras, which leverages low-latency\nevents to track features detected in a grayscale frame. We achieve robust\nperformance via a novel frame attention module, which shares information across\nfeature tracks. By directly transferring zero-shot from synthetic to real data,\nour data-driven tracker outperforms existing approaches in relative feature age\nby up to 120 % while also achieving the lowest latency. This performance gap is\nfurther increased to 130 % by adapting our tracker to real data with a novel\nself-supervision strategy.",
    "descriptor": "",
    "authors": [
      "Nico Messikommer",
      "Carter Fang",
      "Mathias Gehrig",
      "Davide Scaramuzza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12826"
  },
  {
    "id": "arXiv:2211.12827",
    "title": "Video Instance Shadow Detection",
    "abstract": "Video instance shadow detection aims to simultaneously detect, segment,\nassociate, and track paired shadow-object associations in videos. This work has\nthree key contributions to the task. First, we design SSIS-Track, a new\nframework to extract shadow-object associations in videos with paired tracking\nand without category specification; especially, we strive to maintain paired\ntracking even the objects/shadows are temporarily occluded for several frames.\nSecond, we leverage both labeled images and unlabeled videos, and explore\ntemporal coherence by augmenting the tracking ability via an association cycle\nconsistency loss to optimize SSIS-Track's performance. Last, we build\n$\\textit{SOBA-VID}$, a new dataset with 232 unlabeled videos of ${5,863}$\nframes for training and 60 labeled videos of ${1,182}$ frames for testing.\nExperimental results show that SSIS-Track surpasses baselines built from SOTA\nvideo tracking and instance-shadow-detection methods by a large margin. In the\nend, we showcase several video-level applications.",
    "descriptor": "",
    "authors": [
      "Zhenghao Xing",
      "Tianyu Wang",
      "Xiaowei Hu",
      "Haoran Wu",
      "Chi-Wing Fu",
      "Pheng-Ann Heng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12827"
  },
  {
    "id": "arXiv:2211.12829",
    "title": "Unsupervised 3D Keypoint Estimation with Multi-View Geometry",
    "abstract": "Given enough annotated training data, 3D human pose estimation models can\nachieve high accuracy. However, annotations are not always available,\nespecially for people performing unusual activities. In this paper, we propose\nan algorithm that learns to detect 3D keypoints on human bodies from\nmultiple-views without any supervision other than the constraints multiple-view\ngeometry provides. To ensure that the estimated 3D keypoints are meaningful,\nthey are re-projected to each view to estimate the person's mask that the model\nitself has initially estimated. Our approach outperforms other state-of-the-art\nunsupervised 3D human pose estimation methods on the Human3.6M and MPI-INF-3DHP\nbenchmark datasets.",
    "descriptor": "",
    "authors": [
      "Sina Honari",
      "Pascal Fua"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12829"
  },
  {
    "id": "arXiv:2211.12833",
    "title": "Worst-Case to Expander-Case Reductions",
    "abstract": "In recent years, the expander decomposition method was used to develop many\ngraph algorithms, resulting in major improvements to longstanding complexity\nbarriers. This powerful hammer has led the community to (1) believe that most\nproblems are as easy on worst-case graphs as they are on expanders, and (2)\nsuspect that expander decompositions are the key to breaking the remaining\nlongstanding barriers in fine-grained complexity.\nWe set out to investigate the extent to which these two things are true (and\nfor which problems). Towards this end, we put forth the concept of worst-case\nto expander-case self-reductions. We design a collection of such reductions for\nfundamental graph problems, verifying belief (1) for them. The list includes\n$k$-Clique, $4$-Cycle, Maximum Cardinality Matching, Vertex-Cover, and Minimum\nDominating Set. Interestingly, for most (but not all) of these problems the\nproof is via a simple gadget reduction, not via expander decompositions,\nshowing that this hammer is effectively useless against the problem and\ncontradicting (2).",
    "descriptor": "\nComments: The full version of a paper accepted to ITCS 2023\n",
    "authors": [
      "Amir Abboud",
      "Nathan Wallheimer"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.12833"
  },
  {
    "id": "arXiv:2211.12835",
    "title": "Automatic Generation of Socratic Subquestions for Teaching Math Word  Problems",
    "abstract": "Socratic questioning is an educational method that allows students to\ndiscover answers to complex problems by asking them a series of thoughtful\nquestions. Generation of didactically sound questions is challenging, requiring\nunderstanding of the reasoning process involved in the problem. We hypothesize\nthat such questioning strategy can not only enhance the human performance, but\nalso assist the math word problem (MWP) solvers. In this work, we explore the\nability of large language models (LMs) in generating sequential questions for\nguiding math word problem-solving. We propose various guided question\ngeneration schemes based on input conditioning and reinforcement learning. On\nboth automatic and human quality evaluations, we find that LMs constrained with\ndesirable question properties generate superior questions and improve the\noverall performance of a math word problem solver. We conduct a preliminary\nuser study to examine the potential value of such question generation models in\nthe education domain. Results suggest that the difficulty level of problems\nplays an important role in determining whether questioning improves or hinders\nhuman performance. We discuss the future of using such questioning strategies\nin education.",
    "descriptor": "\nComments: Kumar Shridhar and Jakub Macina contributed equally to this work. Accepted at the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP 2022). Code available: this https URL\n",
    "authors": [
      "Kumar Shridhar",
      "Jakub Macina",
      "Mennatallah El-Assady",
      "Tanmay Sinha",
      "Manu Kapur",
      "Mrinmaya Sachan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12835"
  },
  {
    "id": "arXiv:2211.12846",
    "title": "Assessment of Human Behavior in Virtual Reality by Eye Tracking",
    "abstract": "Virtual reality (VR) is not a new technology but has been in development for\ndecades, driven by advances in computer technology. Currently, VR technology is\nincreasingly being used in applications to enable immersive, yet controlled\nresearch settings. Education and entertainment are two important application\nareas, where VR has been considered a key enabler of immersive experiences and\ntheir further advancement. At the same time, the study of human behavior in\nsuch innovative environments is expected to contribute to a better design of VR\napplications. Therefore, modern VR devices are consistently equipped with\neye-tracking technology, enabling thus further studies of human behavior\nthrough the collection of process data. In particular, eye-tracking technology\nin combination with machine learning techniques and explainable models can\nprovide new insights for a deeper understanding of human behavior during\nimmersion in virtual environments.\nIn this work, a systematic computational framework based on eye-tracking and\nbehavioral user data and state-of-the-art machine learning approaches is\nproposed to understand human behavior and individual differences in VR\ncontexts. This computational framework is then employed in three user studies\nacross two different domains. In the educational domain, two different\nimmersive VR classrooms were created where students can learn and teachers can\ntrain. In terms of VR entertainment, eye movements open a new avenue to\nevaluate VR locomotion techniques from the perspective of user cognitive load\nand user experience. This work paves the way for assessing human behavior in VR\nscenarios and provides profound insights into the way of designing, evaluating,\nand improving interactive VR systems. In particular, more effective and\ncustomizable virtual environments can be created to provide users with tailored\nexperiences.",
    "descriptor": "\nComments: dissertation\n",
    "authors": [
      "Hong Gao"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.12846"
  },
  {
    "id": "arXiv:2211.12849",
    "title": "Whole-Body Trajectory Optimization for Robot Multimodal Locomotion",
    "abstract": "The general problem of planning feasible trajectories for multimodal robots\nis still an open challenge. This paper presents a whole-body trajectory\noptimisation approach that addresses this challenge by combining methods and\ntools developed for aerial and legged robots. First, robot models that enable\nthe presented whole-body trajectory optimisation framework are presented. The\nkey model is the so-called robot centroidal momentum, the dynamics of which is\ndirectly related to the models of the robot actuation for aerial and\nterrestrial locomotion. Then, the paper presents how these models can be\nemployed in an optimal control problem to generate either terrestrial or aerial\nlocomotion trajectories with a unified approach. The optimisation problem\nconsiders robot kinematics, momentum, thrust forces and their bounds. The\noverall approach is validated using the multimodal robot iRonCub, a flying\nhumanoid robot that expresses a degree of terrestrial and aerial locomotion. To\nsolve the associated optimal trajectory generation problem, we employ ADAM, a\ncustom-made open-source library that implements a collection of algorithms for\ncalculating rigid-body dynamics using CasADi.",
    "descriptor": "\nComments: Paper accepted in Humanoids 2022\n",
    "authors": [
      "Giuseppe L'Erario",
      "Gabriele Nava",
      "Giulio Romualdi",
      "Fabio Bergonti",
      "Valentino Razza",
      "Stefano Dafarra",
      "Daniele Pucci"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.12849"
  },
  {
    "id": "arXiv:2211.12850",
    "title": "OOD-DiskANN: Efficient and Scalable Graph ANNS for Out-of-Distribution  Queries",
    "abstract": "State-of-the-art algorithms for Approximate Nearest Neighbor Search (ANNS)\nsuch as DiskANN, FAISS-IVF, and HNSW build data dependent indices that offer\nsubstantially better accuracy and search efficiency over data-agnostic indices\nby overfitting to the index data distribution. When the query data is drawn\nfrom a different distribution - e.g., when index represents image embeddings\nand query represents textual embeddings - such algorithms lose much of this\nperformance advantage. On a variety of datasets, for a fixed recall target,\nlatency is worse by an order of magnitude or more for Out-Of-Distribution (OOD)\nqueries as compared to In-Distribution (ID) queries. The question we address in\nthis work is whether ANNS algorithms can be made efficient for OOD queries if\nthe index construction is given access to a small sample set of these queries.\nWe answer positively by presenting OOD-DiskANN, which uses a sparing sample (1%\nof index set size) of OOD queries, and provides up to 40% improvement in mean\nquery latency over SoTA algorithms of a similar memory footprint. OOD-DiskANN\nis scalable and has the efficiency of graph-based ANNS indices. Some of our\ncontributions can improve query efficiency for ID queries as well.",
    "descriptor": "",
    "authors": [
      "Shikhar Jaiswal",
      "Ravishankar Krishnaswamy",
      "Ankit Garg",
      "Harsha Vardhan Simhadri",
      "Sheshansh Agrawal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.12850"
  },
  {
    "id": "arXiv:2211.12851",
    "title": "A Streamlit-based Artificial Intelligence Trust Platform for  Next-Generation Wireless Networks",
    "abstract": "With the rapid development and integration of artificial intelligence (AI)\nmethods in next-generation networks (NextG), AI algorithms have provided\nsignificant advantages for NextG in terms of frequency spectrum usage,\nbandwidth, latency, and security. A key feature of NextG is the integration of\nAI, i.e., self-learning architecture based on self-supervised algorithms, to\nimprove the performance of the network. A secure AI-powered structure is also\nexpected to protect NextG networks against cyber-attacks. However, AI itself\nmay be attacked, i.e., model poisoning targeted by attackers, and it results in\ncybersecurity violations. This paper proposes an AI trust platform using\nStreamlit for NextG networks that allows researchers to evaluate, defend,\ncertify, and verify their AI models and applications against adversarial\nthreats of evasion, poisoning, extraction, and interference.",
    "descriptor": "\nComments: 4 pages, 2 figures\n",
    "authors": [
      "M. Kuzlu",
      "F. O. Catak",
      "S. Sarp",
      "U. Cali",
      "O Gueler"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.12851"
  },
  {
    "id": "arXiv:2211.12852",
    "title": "GraphWOZ: Dialogue Management with Conversational Knowledge Graphs",
    "abstract": "We present a new approach to dialogue management using conversational\nknowledge graphs as core representation of the dialogue state. To this end, we\nintroduce a new dataset, GraphWOZ, which comprises Wizard-of-Oz dialogues in\nwhich human participants interact with a robot acting as a receptionist. In\ncontrast to most existing work on dialogue management, GraphWOZ relies on a\ndialogue state explicitly represented as a dynamic knowledge graph instead of a\nfixed set of slots. This graph is composed of a varying number of entities\n(such as individuals, places, events, utterances and mentions) and relations\nbetween them (such as persons being part of a group or attending an event). The\ngraph is then regularly updated on the basis of new observations and system\nactions. GraphWOZ is released along with detailed manual annotations related to\nthe user intents, system responses, and reference relations occurring in both\nuser and system turns. Based on GraphWOZ, we present experimental results for\ntwo dialogue management tasks, namely conversational entity linking and\nresponse ranking. For conversational entity linking, we show how to connect\nutterance mentions to their corresponding entity in the knowledge graph with a\nneural model relying on a combination of both string and graph-based features.\nResponse ranking is then performed by summarizing the relevant content of the\ngraph into a text, which is concatenated with the dialogue history and employed\nas input to score possible responses to a given dialogue state.",
    "descriptor": "",
    "authors": [
      "Nicholas Thomas Walker",
      "Stefan Ultes",
      "Pierre Lison"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12852"
  },
  {
    "id": "arXiv:2211.12853",
    "title": "BAD-NeRF: Bundle Adjusted Deblur Neural Radiance Fields",
    "abstract": "Neural Radiance Fields (NeRF) have received considerable attention recently,\ndue to its impressive capability in photo-realistic 3D reconstruction and novel\nview synthesis, given a set of posed camera images. Earlier work usually\nassumes the input images are in good quality. However, image degradation (e.g.\nimage motion blur in low-light conditions) can easily happen in real-world\nscenarios, which would further affect the rendering quality of NeRF. In this\npaper, we present a novel bundle adjusted deblur Neural Radiance Fields\n(BAD-NeRF), which can be robust to severe motion blurred images and inaccurate\ncamera poses. Our approach models the physical image formation process of a\nmotion blurred image, and jointly learns the parameters of NeRF and recovers\nthe camera motion trajectories during exposure time. In experiments, we show\nthat by directly modeling the real physical image formation process, BAD-NeRF\nachieves superior performance over prior works on both synthetic and real\ndatasets.",
    "descriptor": "",
    "authors": [
      "Peng Wang",
      "Lingzhe Zhao",
      "Ruijie Ma",
      "Peidong Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12853"
  },
  {
    "id": "arXiv:2211.12857",
    "title": "Explaining Image Classifiers with Multiscale Directional Image  Representation",
    "abstract": "Image classifiers are known to be difficult to interpret and therefore\nrequire explanation methods to understand their decisions. We present\nShearletX, a novel mask explanation method for image classifiers based on the\nshearlet transform -- a multiscale directional image representation. Current\nmask explanation methods are regularized by smoothness constraints that protect\nagainst undesirable fine-grained explanation artifacts. However, the smoothness\nof a mask limits its ability to separate fine-detail patterns, that are\nrelevant for the classifier, from nearby nuisance patterns, that do not affect\nthe classifier. ShearletX solves this problem by avoiding smoothness\nregularization all together, replacing it by shearlet sparsity constraints. The\nresulting explanations consist of a few edges, textures, and smooth parts of\nthe original image, that are the most relevant for the decision of the\nclassifier. To support our method, we propose a mathematical definition for\nexplanation artifacts and an information theoretic score to evaluate the\nquality of mask explanations. We demonstrate the superiority of ShearletX over\nprevious mask based explanation methods using these new metrics, and present\nexemplary situations where separating fine-detail patterns allows explaining\nphenomena that were not explainable before.",
    "descriptor": "",
    "authors": [
      "Stefan Kolek",
      "Robert Windesheim",
      "Hector Andrade Loarca",
      "Gitta Kutyniok",
      "Ron Levie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12857"
  },
  {
    "id": "arXiv:2211.12858",
    "title": "SketchBoost: Fast Gradient Boosted Decision Tree for Multioutput  Problems",
    "abstract": "Gradient Boosted Decision Tree (GBDT) is a widely-used machine learning\nalgorithm that has been shown to achieve state-of-the-art results on many\nstandard data science problems. We are interested in its application to\nmultioutput problems when the output is highly multidimensional. Although there\nare highly effective GBDT implementations, their scalability to such problems\nis still unsatisfactory. In this paper, we propose novel methods aiming to\naccelerate the training process of GBDT in the multioutput scenario. The idea\nbehind these methods lies in the approximate computation of a scoring function\nused to find the best split of decision trees. These methods are implemented in\nSketchBoost, which itself is integrated into our easily customizable\nPython-based GPU implementation of GBDT called Py-Boost. Our numerical study\ndemonstrates that SketchBoost speeds up the training process of GBDT by up to\nover 40 times while achieving comparable or even better performance.",
    "descriptor": "\nComments: 25 pages, 6 figures. Advances in Neural Information Processing Systems (NeurIPS) 2022\n",
    "authors": [
      "Leonid Iosipoi",
      "Anton Vakhrushev"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.12858"
  },
  {
    "id": "arXiv:2211.12860",
    "title": "DETRs with Collaborative Hybrid Assignments Training",
    "abstract": "In this paper, we provide the observation that too few queries assigned as\npositive samples in DETR with one-to-one set matching leads to sparse\nsupervisions on the encoder's output which considerably hurt the discriminative\nfeature learning of the encoder and vice visa for attention learning in the\ndecoder. To alleviate this, we present a novel collaborative hybrid assignments\ntraining scheme, namely Co-DETR, to learn more efficient and effective\nDETR-based detectors from versatile label assignment manners. This new training\nscheme can easily enhance the encoder's learning ability in end-to-end\ndetectors by training the multiple parallel auxiliary heads supervised by\none-to-many label assignments such as ATSS, FCOS, and Faster RCNN. In addition,\nwe conduct extra customized positive queries by extracting the positive\ncoordinates from these auxiliary heads to improve the training efficiency of\npositive samples in the decoder. In inference, these auxiliary heads are\ndiscarded and thus our method introduces no additional parameters and\ncomputational cost to the original detector while requiring no hand-crafted\nnon-maximum suppression (NMS). We conduct extensive experiments to evaluate the\neffectiveness of the proposed approach on DETR variants, including DAB-DETR,\nDeformable-DETR, and H-Deformable-DETR. Specifically, we improve the basic\nDeformable-DETR by 5.8% in 12-epoch training and 3.2% in 36-epoch training. The\nstate-of-the-art H-Deformable-DETR can still be improved from 57.9% to 58.7% on\nthe MS COCO val. Surprisingly, incorporated with the large-scale backbone\nMixMIM-g with 1-Billion parameters, we achieve the 64.5% mAP on MS COCO\ntest-dev, achieving superior performance with much fewer extra data sizes.\nCodes will be available at https://github.com/Sense-X/Co-DETR.",
    "descriptor": "\nComments: Tech report. Codes will be available at this https URL\n",
    "authors": [
      "Zhuofan Zong",
      "Guanglu Song",
      "Yu Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12860"
  },
  {
    "id": "arXiv:2211.12862",
    "title": "Shortest Odd Paths in Conservative Graphs: Connections and Complexity",
    "abstract": "We present some reductions between optimization problems for undirected\nconservative graphs, that is, edge-weighted graphs without negative cycles. We\nsettle the complexity of some of them, and exhibit some remaining challenges.\nOur key result is that the shortest odd path problem between two given\nvertices, and its variants, such as the shortest odd cycle problem through a\ngiven vertex, turn out to be NP-hard, deciding a long-standing question by\nLov\\'asz (Open Problem 27 in Schrijver's book, 2003), in the negative. The\ncomplexity of finding a shortest odd cycle for conservative weights or of\nfinding an odd $T$-join of minimum cardinality remains open. We finally relate\nthese problems to relevant, solved or hopeful variants.",
    "descriptor": "\nComments: 9 pages, 2 figures\n",
    "authors": [
      "Ildik\u00f3 Schlotter",
      "Andr\u00e1s Seb\u0151"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.12862"
  },
  {
    "id": "arXiv:2211.12864",
    "title": "Privacy-Enhancing Optical Embeddings for Lensless Classification",
    "abstract": "Lensless imaging can provide visual privacy due to the highly multiplexed\ncharacteristic of its measurements. However, this alone is a weak form of\nsecurity, as various adversarial attacks can be designed to invert the\none-to-many scene mapping of such cameras. In this work, we enhance the privacy\nprovided by lensless imaging by (1) downsampling at the sensor and (2) using a\nprogrammable mask with variable patterns as our optical encoder. We build a\nprototype from a low-cost LCD and Raspberry Pi components, for a total cost of\naround 100 USD. This very low price point allows our system to be deployed and\nleveraged in a broad range of applications. In our experiments, we first\ndemonstrate the viability and reconfigurability of our system by applying it to\nvarious classification tasks: MNIST, CelebA (face attributes), and CIFAR10. By\njointly optimizing the mask pattern and a digital classifier in an end-to-end\nfashion, low-dimensional, privacy-enhancing embeddings are learned directly at\nthe sensor. Secondly, we show how the proposed system, through variable mask\npatterns, can thwart adversaries that attempt to invert the system (1) via\nplaintext attacks or (2) in the event of camera parameters leaks. We\ndemonstrate the defense of our system to both risks, with 55% and 26% drops in\nimage quality metrics for attacks based on model-based convex optimization and\ngenerative neural networks respectively. We open-source a wave propagation and\ncamera simulator needed for end-to-end optimization, the training software, and\na library for interfacing with the camera.",
    "descriptor": "\nComments: 30 pages, 27 figures, under review, for code, see this https URL arXiv admin note: substantial text overlap with arXiv:2206.01429\n",
    "authors": [
      "Eric Bezzam",
      "Martin Vetterli",
      "Matthieu Simeoni"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.12864"
  },
  {
    "id": "arXiv:2211.12868",
    "title": "Perfect Sampling from Pairwise Comparisons",
    "abstract": "In this work, we study how to efficiently obtain perfect samples from a\ndiscrete distribution $\\mathcal{D}$ given access only to pairwise comparisons\nof elements of its support. Specifically, we assume access to samples $(x, S)$,\nwhere $S$ is drawn from a distribution over sets $\\mathcal{Q}$ (indicating the\nelements being compared), and $x$ is drawn from the conditional distribution\n$\\mathcal{D}_S$ (indicating the winner of the comparison) and aim to output a\nclean sample $y$ distributed according to $\\mathcal{D}$. We mainly focus on the\ncase of pairwise comparisons where all sets $S$ have size 2. We design a Markov\nchain whose stationary distribution coincides with $\\mathcal{D}$ and give an\nalgorithm to obtain exact samples using the technique of Coupling from the\nPast. However, the sample complexity of this algorithm depends on the structure\nof the distribution $\\mathcal{D}$ and can be even exponential in the support of\n$\\mathcal{D}$ in many natural scenarios. Our main contribution is to provide an\nefficient exact sampling algorithm whose complexity does not depend on the\nstructure of $\\mathcal{D}$. To this end, we give a parametric Markov chain that\nmixes significantly faster given a good approximation to the stationary\ndistribution. We can obtain such an approximation using an efficient learning\nfrom pairwise comparisons algorithm (Shah et al., JMLR 17, 2016). Our technique\nfor speeding up sampling from a Markov chain whose stationary distribution is\napproximately known is simple, general and possibly of independent interest.",
    "descriptor": "",
    "authors": [
      "Dimitris Fotakis",
      "Alkis Kalavasis",
      "Christos Tzamos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.12868"
  },
  {
    "id": "arXiv:2211.12870",
    "title": "ActMAD: Activation Matching to Align Distributions for  Test-Time-Training",
    "abstract": "Test-Time-Training (TTT) is an approach to cope with out-of-distribution\n(OOD) data by adapting a trained model to distribution shifts occurring at\ntest-time. We propose to perform this adaptation via Activation Matching\n(ActMAD): We analyze activations of the model and align activation statistics\nof the OOD test data to those of the training data. In contrast to existing\nmethods, which model the distribution of entire channels in the ultimate layer\nof the feature extractor, we model the distribution of each feature in multiple\nlayers across the network. This results in a more fine-grained supervision and\nmakes ActMAD attain state of the art performance on CIFAR-100C and Imagenet-C.\nActMAD is also architecture- and task-agnostic, which lets us go beyond image\nclassification, and score 15.4% improvement over previous approaches when\nevaluating a KITTI-trained object detector on KITTI-Fog. Our experiments\nhighlight that ActMAD can be applied to online adaptation in realistic\nscenarios, requiring little data to attain its full performance.",
    "descriptor": "",
    "authors": [
      "Muhammad Jehanzeb Mirza",
      "Pol Jan\u00e9 Soneira",
      "Wei Lin",
      "Mateusz Kozinski",
      "Horst Possegger",
      "Horst Bischof"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12870"
  },
  {
    "id": "arXiv:2211.12872",
    "title": "\u03bcSplit: efficient image decomposition for microscopy data",
    "abstract": "Light microscopy is routinely used to look at living cells and biological\ntissues at sub-cellular resolution. Components of the imaged cells can be\nhighlighted using fluorescent labels, allowing biologists to investigate\nindividual structures of interest. Given the complexity of biological\nprocesses, it is typically necessary to look at multiple structures\nsimultaneously, typically via a temporal multiplexing scheme. Still, imaging\nmore than 3 or 4 structures in this way is difficult for technical reasons and\nlimits the rate of scientific progress in the life sciences. Hence, a\ncomputational method to split apart (decompose) superimposed biological\nstructures acquired in a single image channel, i.e. without temporal\nmultiplexing, would have tremendous impact. Here we present {\\mu}Split, a\ndedicated approach for trained image decomposition. We find that best results\nusing regular deep architectures is achieved when large image patches are used\nduring training, making memory consumption the limiting factor to further\nimproving performance. We therefore introduce lateral contextualization (LC), a\nmemory efficient way to train deep networks that operate well on small input\npatches. In later layers, additional image context is fed at adequately lowered\nresolution. We integrate LC with Hierarchical Autoencoders and Hierarchical\nVAEs.For the latter, we also present a modified ELBO loss and show that it\nenables sound VAE training. We apply {\\mu}Split to five decomposition tasks,\none on a synthetic dataset, four others derived from two real microscopy\ndatasets. LC consistently achieves SOTA results, while simultaneously requiring\nconsiderably less GPU memory than competing architectures not using LC. When\nintroducing LC, results obtained with the above-mentioned vanilla architectures\ndo on average improve by 2.36 dB (PSNR decibel), with individual improvements\nranging from 0.9 to 3.4 dB.",
    "descriptor": "\nComments: 10 pages, 7 figures, 9 pages supplement, 8 supplementary figures\n",
    "authors": [
      "Ashesh",
      "Alexander Krull",
      "Moises Di Sante",
      "Francesco Silvio Pasqualini",
      "Florian Jug"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12872"
  },
  {
    "id": "arXiv:2211.12873",
    "title": "Effects of Sim2Real Image Translation on Lane Keeping Assist System in  CARLA Simulator",
    "abstract": "Autonomous vehicle simulation has the advantage of testing algorithms in\nvarious environment variables and scenarios without wasting time and resources,\nhowever, there is a visual gap with the real-world. In this paper, we trained\nDCLGAN to realistically convert the image of the CARLA simulator and evaluated\nthe effect of the Sim2Real conversion focusing on the LKAS (Lane Keeping Assist\nSystem) algorithm. In order to avoid the case where the lane is translated\ndistortedly by DCLGAN, we found the optimal training hyperparameter using FSIM\n(feature-similarity). After training, we built a system that connected the\nDCLGAN model with CARLA and AV in real-time. Then, we collected data (e.g.\nimages, GPS) and analyzed them using the following four methods. First, image\nreality was measured with FID, which we verified quantitatively reflects the\nlane characteristics. CARLA images that passed through DCLGAN had smaller FID\nvalues than the original images. Second, lane segmentation accuracy through\nENet-SAD was improved by DCLGAN. Third, in the curved route, the case of using\nDCLGAN drove closer to the center of the lane and had a high success rate.\nLastly, in the straight route, DCLGAN improved lane restoring ability after\ndeviating from the center of the lane as much as in reality.",
    "descriptor": "",
    "authors": [
      "Jinu Pahk",
      "Jungseok Shim",
      "MinHyeok Baek",
      "Yongseob Lim",
      "Gyeungho Choi"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.12873"
  },
  {
    "id": "arXiv:2211.12874",
    "title": "A Dynamic Weighted Federated Learning for Android Malware Classification",
    "abstract": "Android malware attacks are increasing daily at a tremendous volume, making\nAndroid users more vulnerable to cyber-attacks. Researchers have developed many\nmachine learning (ML)/ deep learning (DL) techniques to detect and mitigate\nandroid malware attacks. However, due to technological advancement, there is a\nrise in android mobile devices. Furthermore, the devices are geographically\ndispersed, resulting in distributed data. In such scenario, traditional ML/DL\ntechniques are infeasible since all of these approaches require the data to be\nkept in a central system; this may provide a problem for user privacy because\nof the massive proliferation of Android mobile devices; putting the data in a\ncentral system creates an overhead. Also, the traditional ML/DL-based android\nmalware classification techniques are not scalable. Researchers have proposed\nfederated learning (FL) based android malware classification system to solve\nthe privacy preservation and scalability with high classification performance.\nIn traditional FL, Federated Averaging (FedAvg) is utilized to construct the\nglobal model at each round by merging all of the local models obtained from all\nof the customers that participated in the FL. However, the conventional FedAvg\nhas a disadvantage: if one poor-performing local model is included in global\nmodel development for each round, it may result in an under-performing global\nmodel. Because FedAvg favors all local models equally when averaging. To\naddress this issue, our main objective in this work is to design a dynamic\nweighted federated averaging (DW-FedAvg) strategy in which the weights for each\nlocal model are automatically updated based on their performance at the client.\nThe DW-FedAvg is evaluated using four popular benchmark datasets, Melgenome,\nDrebin, Kronodroid and Tuandromd used in android malware classification\nresearch.",
    "descriptor": "\nComments: Accepted in SoCTA 2022\n",
    "authors": [
      "Ayushi Chaudhuri",
      "Arijit Nandi",
      "Buddhadeb Pradhan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12874"
  },
  {
    "id": "arXiv:2211.12875",
    "title": "A Survey of Deep Graph Clustering: Taxonomy, Challenge, and Application",
    "abstract": "Graph clustering, which aims to divide the nodes in the graph into several\ndistinct clusters, is a fundamental and challenging task. In recent years, deep\ngraph clustering methods have been increasingly proposed and achieved promising\nperformance. However, the corresponding survey paper is scarce and it is\nimminent to make a summary in this field. From this motivation, this paper\nmakes the first comprehensive survey of deep graph clustering. Firstly, the\ndetailed definition of deep graph clustering and the important baseline methods\nare introduced. Besides, the taxonomy of deep graph clustering methods is\nproposed based on four different criteria including graph type, network\narchitecture, learning paradigm, and clustering method. In addition, through\nthe careful analysis of the existing works, the challenges and opportunities\nfrom five perspectives are summarized. At last, the applications of deep graph\nclustering in four domains are presented. It is worth mentioning that a\ncollection of state-of-the-art deep graph clustering methods including papers,\ncodes, and datasets is available on GitHub. We hope this work will serve as a\nquick guide and help researchers to overcome challenges in this vibrant field.",
    "descriptor": "\nComments: 13 pages, 13 figures\n",
    "authors": [
      "Liu Yue",
      "Xia Jun",
      "Zhou Sihang",
      "Wang Siwei",
      "Guo Xifeng",
      "Yang Xihong",
      "Liang Ke",
      "Tu Wenxuan",
      "Li Stan Z.",
      "Liu Xin Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12875"
  },
  {
    "id": "arXiv:2211.12877",
    "title": "End-to-End DNN Inference on a Massively Parallel Analog In Memory  Computing Architecture",
    "abstract": "The demand for computation resources and energy efficiency of Convolutional\nNeural Networks (CNN) applications requires a new paradigm to overcome the\n\"Memory Wall\". Analog In-Memory Computing (AIMC) is a promising paradigm since\nit performs matrix-vector multiplications, the critical kernel of many ML\napplications, in-place in the analog domain within memory arrays structured as\ncrossbars of memory cells. However, several factors limit the full exploitation\nof this technology, including the physical fabrication of the crossbar devices,\nwhich constrain the memory capacity of a single array. Multi-AIMC architectures\nhave been proposed to overcome this limitation, but they have been demonstrated\nonly for tiny and custom CNNs or performing some layers off-chip. In this work,\nwe present the full inference of an end-to-end ResNet-18 DNN on a 512-cluster\nheterogeneous architecture coupling a mix of AIMC cores and digital RISC-V\ncores, achieving up to 20.2 TOPS. Moreover, we analyze the mapping of the\nnetwork on the available non-volatile cells, compare it with state-of-the-art\nmodels, and derive guidelines for next-generation many-core architectures based\non AIMC devices.",
    "descriptor": "",
    "authors": [
      "Nazareno Bruschi",
      "Giuseppe Tagliavini",
      "Angelo Garofalo",
      "Francesco Conti",
      "Irem Boybat",
      "Luca Benini",
      "Davide Rossi"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.12877"
  },
  {
    "id": "arXiv:2211.12878",
    "title": "Mitigating Data Sparsity for Short Text Topic Modeling by Topic-Semantic  Contrastive Learning",
    "abstract": "To overcome the data sparsity issue in short text topic modeling, existing\nmethods commonly rely on data augmentation or the data characteristic of short\ntexts to introduce more word co-occurrence information. However, most of them\ndo not make full use of the augmented data or the data characteristic: they\ninsufficiently learn the relations among samples in data, leading to dissimilar\ntopic distributions of semantically similar text pairs. To better address data\nsparsity, in this paper we propose a novel short text topic modeling framework,\nTopic-Semantic Contrastive Topic Model (TSCTM). To sufficiently model the\nrelations among samples, we employ a new contrastive learning method with\nefficient positive and negative sampling strategies based on topic semantics.\nThis contrastive learning method refines the representations, enriches the\nlearning signals, and thus mitigates the sparsity issue. Extensive experimental\nresults show that our TSCTM outperforms state-of-the-art baselines regardless\nof the data augmentation availability, producing high-quality topics and topic\ndistributions.",
    "descriptor": "\nComments: Accepted to EMNLP2022 main conference\n",
    "authors": [
      "Xiaobao Wu",
      "Anh Tuan Luu",
      "Xinshuai Dong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.12878"
  },
  {
    "id": "arXiv:2211.12879",
    "title": "Data Augmentation Vision Transformer for Fine-grained Image  Classification",
    "abstract": "Recently, the vision transformer (ViT) has made breakthroughs in image\nrecognition. Its self-attention mechanism (MSA) can extract discriminative\nlabeling information of different pixel blocks to improve image classification\naccuracy. However, the classification marks in their deep layers tend to ignore\nlocal features between layers. In addition, the embedding layer will be\nfixed-size pixel blocks. Input network Inevitably introduces additional image\nnoise. To this end, this paper studies a data augmentation vision transformer\n(DAVT) based on data augmentation and proposes a data augmentation method for\nattention cropping, which uses attention weights as the guide to crop images\nand improve the ability of the network to learn critical features. Secondly,\nthis paper also proposes a hierarchical attention selection (HAS) method, which\nimproves the ability of discriminative markers between levels of learning by\nfiltering and fusing labels between levels. Experimental results show that the\naccuracy of this method on the two general datasets, CUB-200-2011, and Stanford\nDogs, is better than the existing mainstream methods, and its accuracy is 1.4\\%\nand 1.6\\% higher than the original ViT, respectively.",
    "descriptor": "",
    "authors": [
      "Chao Hu",
      "Liqiang Zhu",
      "Weibin Qiu",
      "Weijie Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12879"
  },
  {
    "id": "arXiv:2211.12881",
    "title": "DGEKT: A Dual Graph Ensemble Learning Method for Knowledge Tracing",
    "abstract": "Knowledge tracing aims to trace students' evolving knowledge states by\npredicting their future performance on concept-related exercises. Recently,\nsome graph-based models have been developed to incorporate the relationships\nbetween exercises to improve knowledge tracing, but only a single type of\nrelationship information is generally explored. In this paper, we present a\nnovel Dual Graph Ensemble learning method for Knowledge Tracing (DGEKT), which\nestablishes a dual graph structure of students' learning interactions to\ncapture the heterogeneous exercise-concept associations and interaction\ntransitions by hypergraph modeling and directed graph modeling, respectively.\nTo ensemble the dual graph models, we introduce the technique of online\nknowledge distillation, due to the fact that although the knowledge tracing\nmodel is expected to predict students' responses to the exercises related to\ndifferent concepts, it is optimized merely with respect to the prediction\naccuracy on a single exercise at each step. With online knowledge distillation,\nthe dual graph models are adaptively combined to form a stronger teacher model,\nwhich in turn provides its predictions on all exercises as extra supervision\nfor better modeling ability. In the experiments, we compare DGEKT against eight\nknowledge tracing baselines on three benchmark datasets, and the results\ndemonstrate that DGEKT achieves state-of-the-art performance.",
    "descriptor": "",
    "authors": [
      "Chaoran Cui",
      "Yumo Yao",
      "Chunyun Zhang",
      "Hebo Ma",
      "Yuling Ma",
      "Zhaochun Ren",
      "Chen Zhang",
      "James Ko"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.12881"
  },
  {
    "id": "arXiv:2211.12883",
    "title": "Evaluating and Mitigating Static Bias of Action Representations in the  Background and the Foreground",
    "abstract": "Deep neural networks for video action recognition easily learn to utilize\nshortcut static features, such as background and objects instead of motion\nfeatures. This results in poor generalization to atypical videos such as soccer\nplaying on concrete surfaces (instead of soccer fields). However, due to the\nrarity of out-of-distribution (OOD) data, quantitative evaluation of static\nbias remains a difficult task. In this paper, we synthesize new sets of\nbenchmarks to evaluate static bias of action representations, including SCUB\nfor static cues in the background, and SCUF for static cues in the foreground.\nFurther, we propose a simple yet effective video data augmentation technique,\nStillMix, that automatically identifies bias-inducing video frames; unlike\nsimilar augmentation techniques, StillMix does not need to enumerate or\nprecisely segment biased content. With extensive experiments, we quantitatively\ncompare and analyze existing action recognition models on the created\nbenchmarks to reveal their characteristics. We validate the effectiveness of\nStillMix and show that it improves TSM (Lin, Gan, and Han 2021) and Video Swin\nTransformer (Liu et al. 2021) by more than 10% of accuracy on SCUB for OOD\naction recognition.",
    "descriptor": "",
    "authors": [
      "Haoxin Li",
      "Yue Wu",
      "Yuan Liu",
      "Hanwang Zhang",
      "Boyang Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12883"
  },
  {
    "id": "arXiv:2211.12885",
    "title": "Cost Splitting for Multi-Objective Conflict-Based Search",
    "abstract": "The Multi-Objective Multi-Agent Path Finding (MO-MAPF) problem is the problem\nof finding the Pareto-optimal frontier of collision-free paths for a team of\nagents while minimizing multiple cost metrics. Examples of such cost metrics\ninclude arrival times, travel distances, and energy consumption.In this paper,\nwe focus on the Multi-Objective Conflict-Based Search (MO-CBS) algorithm, a\nstate-of-the-art MO-MAPF algorithm. We show that the standard splitting\nstrategy used by MO-CBS can lead to duplicate search nodes and hence can\nduplicate the search effort that MO-CBS needs to make. To address this issue,\nwe propose two new splitting strategies for MO-CBS, namely cost splitting and\ndisjoint cost splitting. Our theoretical results show that, when combined with\neither of these two new splitting strategies, MO-CBS maintains its completeness\nand optimality guarantees. Our experimental results show that disjoint cost\nsplitting, our best splitting strategy, speeds up MO-CBS by up to two orders of\nmagnitude and substantially improves its success rates in various settings.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Cheng Ge",
      "Han Zhang",
      "Jiaoyang Li",
      "Sven Koenig"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.12885"
  },
  {
    "id": "arXiv:2211.12886",
    "title": "OReX: Object Reconstruction from Planner Cross-sections Using Neural  Fields",
    "abstract": "Reconstructing 3D shapes from planar cross-sections is a challenge inspired\nby downstream applications like medical imaging and geographic informatics. The\ninput is an in/out indicator function fully defined on a sparse collection of\nplanes in space, and the output is an interpolation of the indicator function\nto the entire volume. Previous works addressing this sparse and ill-posed\nproblem either produce low quality results, or rely on additional priors such\nas target topology, appearance information, or input normal directions. In this\npaper, we present OReX, a method for 3D shape reconstruction from slices alone,\nfeaturing a Neural Field as the interpolation prior. A simple neural network is\ntrained on the input planes to receive a 3D coordinate and return an\ninside/outside estimate for the query point. This prior is powerful in inducing\nsmoothness and self-similarities. The main challenge for this approach is\nhigh-frequency details, as the neural prior is overly smoothing. To alleviate\nthis, we offer an iterative estimation architecture and a hierarchical input\nsampling scheme that encourage coarse-to-fine training, allowing focusing on\nhigh frequencies at later stages. In addition, we identify and analyze a common\nripple-like effect stemming from the mesh extraction step. We mitigate it by\nregularizing the spatial gradients of the indicator function around input\nin/out boundaries, cutting the problem at the root.\nThrough extensive qualitative and quantitative experimentation, we\ndemonstrate our method is robust, accurate, and scales well with the size of\nthe input. We report state-of-the-art results compared to previous approaches\nand recent potential solutions, and demonstrate the benefit of our individual\ncontributions through analysis and ablation studies.",
    "descriptor": "",
    "authors": [
      "Haim Sawdayee",
      "Amir Vaxman",
      "Amit H. Bermano"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12886"
  },
  {
    "id": "arXiv:2211.12891",
    "title": "Integrated Sensing and Communication: Joint Pilot and Transmission  Design",
    "abstract": "This paper studies a communication-centric integrated sensing and\ncommunication (ISAC) system, where a multi-antenna base station (BS)\nsimultaneously performs downlink communication and target detection. A novel\ntarget detection and information transmission protocol is proposed, where the\nBS executes the channel estimation and beamforming successively and meanwhile\njointly exploits the pilot sequences in the channel estimation stage and user\ninformation in the transmission stage to assist target detection. We\ninvestigate the joint design of pilot matrix, training duration, and transmit\nbeamforming to maximize the probability of target detection, subject to the\nminimum achievable rate required by the user. However, designing the optimal\npilot matrix is rather challenging since there is no closed-form expression of\nthe detection probability with respect to the pilot matrix. To tackle this\ndifficulty, we resort to designing the pilot matrix based on the\ninformation-theoretic criterion to maximize the mutual information (MI) between\nthe received observations and BS-target channel coefficients for target\ndetection. We first derive the optimal pilot matrix for both channel estimation\nand target detection, and then propose an unified pilot matrix structure to\nbalance minimizing the channel estimation error (MSE) and maximizing MI. Based\non the proposed structure, a low-complexity successive refinement algorithm is\nproposed. Simulation results demonstrate that the proposed pilot matrix\nstructure can well balance the MSE-MI and the Rate-MI tradeoffs, and show the\nsignificant region improvement of our proposed design as compared to other\nbenchmark schemes. Furthermore, it is unveiled that as the communication\nchannel is more correlated, the Rate-MI region can be further enlarged.",
    "descriptor": "\nComments: This papar answers the optimal space code-time design for supporting ISAC\n",
    "authors": [
      "Meng Hua",
      "Qingqing Wu",
      "Wen Chen",
      "Abbas Jamalipour"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.12891"
  },
  {
    "id": "arXiv:2211.12893",
    "title": "Prototypical Contrastive Learning and Adaptive Interest Selection for  Candidate Generation in Recommendations",
    "abstract": "Deep Candidate Generation plays an important role in large-scale recommender\nsystems. It takes user history behaviors as inputs and learns user and item\nlatent embeddings for candidate generation. In the literature, conventional\nmethods suffer from two problems. First, a user has multiple embeddings to\nreflect various interests, and such number is fixed. However, taking into\naccount different levels of user activeness, a fixed number of interest\nembeddings is sub-optimal. For example, for less active users, they may need\nfewer embeddings to represent their interests compared to active users. Second,\nthe negative samples are often generated by strategies with unobserved\nsupervision, and similar items could have different labels. Such a problem is\ntermed as class collision. In this paper, we aim to advance the typical\ntwo-tower DNN candidate generation model. Specifically, an Adaptive Interest\nSelection Layer is designed to learn the number of user embeddings adaptively\nin an end-to-end way, according to the level of their activeness. Furthermore,\nwe propose a Prototypical Contrastive Learning Module to tackle the class\ncollision problem introduced by negative sampling. Extensive experimental\nevaluations show that the proposed scheme remarkably outperforms competitive\nbaselines on multiple benchmarks.",
    "descriptor": "",
    "authors": [
      "Ningning Li",
      "Qunwei Li",
      "Xichen Ding",
      "Shaohu Chen",
      "Wenliang Zhong"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.12893"
  },
  {
    "id": "arXiv:2211.12899",
    "title": "Emerging Biometric Modalities and their Use: Loopholes in the  Terminology of the GDPR and Resulting Privacy Risks",
    "abstract": "Technological advancements allow biometric applications to be more\nomnipresent than in any other time before. This paper argues that in the\ncurrent EU data protection regulation, classification applications using\nbiometric data receive less protection compared to biometric recognition. We\nanalyse preconditions in the regulatory language and explore how this has the\npotential to be the source of unique privacy risks for processing operations\nclassifying individuals based on soft traits like emotions. This can have high\nimpact on personal freedoms and human rights and therefore, should be subject\nto data protection impact assessment.",
    "descriptor": "",
    "authors": [
      "Tamas Bisztray",
      "Nils Gruschka",
      "Thirimachos Bourlai",
      "Lothar Fritsch"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.12899"
  },
  {
    "id": "arXiv:2211.12900",
    "title": "Ignorance is Bliss? The Effect of Explanations on Perceptions of Voice  Assistants",
    "abstract": "Voice assistants offer a convenient and hands-free way of accessing computing\nin the home, but a key problem with speech as an interaction modality is how to\nscaffold accurate mental models of voice assistants, a task complicated by\nprivacy and security concerns. We present the results of a survey of voice\nassistant users (n=1314) measuring trust, security, and privacy perceptions of\nvoice assistants with varying levels of online functionality explained in\ndifferent ways. We then asked participants to re-explain how these voice\nassistants worked, showing that while privacy explanations relieved privacy\nconcerns, trust concerns were exacerbated by trust explanations. Participants'\ntrust, privacy, and security perceptions also distinguished between first party\nonline functionality from the voice assistant vendor and third party online\nfunctionality from other developers, and trust in vendors appeared to operate\nindependently from device explanations. Our findings point to the use of\nanalogies to guide users, targeting trust and privacy concerns, key\nimprovements required from manufacturers, and implications for competition in\nthe sector.",
    "descriptor": "\nComments: To appear in the Proceedings of the ACM on Human-Computer Interaction, CSCW1, April 2023 issue. To be presented at CSCW 2023\n",
    "authors": [
      "William Seymour",
      "Jose Such"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.12900"
  },
  {
    "id": "arXiv:2211.12904",
    "title": "Implementation and Evaluation of a System for Assessment of The Quality  of Long-Term Management of Patients at a Geriatric Hospital",
    "abstract": "Background\nThe use of a clinical decision support system for assessing the quality of\ncare, based on computerized clinical guidelines (GLs), is likely to improve\ncare, reduce costs, save time, and enhance the staff's capabilities.\nObjectives\nImplement and evaluate a system for assessment of the quality of the care, in\nthe domain of management of pressure ulcers, by investigating the level of\ncompliance of the staff to the GLs.\nMethods\nUsing data for 100 random patients from the local EMR system we performed a\ntechnical evaluation, checking the applicability and usability, followed by a\nfunctional evaluation of the system investigating the quality metrics given to\nthe compliance of the medical's staff to the protocol. We compared the scores\ngiven by the nurse when supported by the system, to the scores given by the\nnurse without the system's support, and to the scores given by the system. We\nalso measured the time taken to perform the assessment with and without the\nsystem's support.\nResults\nThere were no significant differences in the scores of most measures given by\nthe nurse using the system, compared to the scores given by the system. There\nwere also no significant differences across the values of most quality measures\ngiven by the nurse without support compared to the values given by the nurse\nwith support. Using the system, however, significantly reduced the nurse's\naverage assessment time.\nConclusions\nUsing an automated quality-assessment system, may enable a senior nurse, to\nquickly and accurately assess the quality of care. In addition to its accuracy,\nthe system considerably reduces the time taken to assess the various quality\nmeasures.",
    "descriptor": "",
    "authors": [
      "Erez Shalom",
      "Ayelet Goldstein",
      "Roni Wais",
      "Maya Slivanova",
      "Nogah Melamed Cohen",
      "Yuval Shahar"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.12904"
  },
  {
    "id": "arXiv:2211.12905",
    "title": "GhostNetV2: Enhance Cheap Operation with Long-Range Attention",
    "abstract": "Light-weight convolutional neural networks (CNNs) are specially designed for\napplications on mobile devices with faster inference speed. The convolutional\noperation can only capture local information in a window region, which prevents\nperformance from being further improved. Introducing self-attention into\nconvolution can capture global information well, but it will largely encumber\nthe actual speed. In this paper, we propose a hardware-friendly attention\nmechanism (dubbed DFC attention) and then present a new GhostNetV2 architecture\nfor mobile applications. The proposed DFC attention is constructed based on\nfully-connected layers, which can not only execute fast on common hardware but\nalso capture the dependence between long-range pixels. We further revisit the\nexpressiveness bottleneck in previous GhostNet and propose to enhance expanded\nfeatures produced by cheap operations with DFC attention, so that a GhostNetV2\nblock can aggregate local and long-range information simultaneously. Extensive\nexperiments demonstrate the superiority of GhostNetV2 over existing\narchitectures. For example, it achieves 75.3% top-1 accuracy on ImageNet with\n167M FLOPs, significantly suppressing GhostNetV1 (74.5%) with a similar\ncomputational cost. The source code will be available at\nhttps://github.com/huawei-noah/Efficient-AI-Backbones/tree/master/ghostnetv2_pytorch\nand https://gitee.com/mindspore/models/tree/master/research/cv/ghostnetv2.",
    "descriptor": "\nComments: This paper is accepted by NeurIPS 2022 (Spotlight)\n",
    "authors": [
      "Yehui Tang",
      "Kai Han",
      "Jianyuan Guo",
      "Chang Xu",
      "Chao Xu",
      "Yunhe Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12905"
  },
  {
    "id": "arXiv:2211.12914",
    "title": "Open-vocabulary Attribute Detection",
    "abstract": "Vision-language modeling has enabled open-vocabulary tasks where predictions\ncan be queried using any text prompt in a zero-shot manner. Existing\nopen-vocabulary tasks focus on object classes, whereas research on object\nattributes is limited due to the lack of a reliable attribute-focused\nevaluation benchmark. This paper introduces the Open-Vocabulary Attribute\nDetection (OVAD) task and the corresponding OVAD benchmark. The objective of\nthe novel task and benchmark is to probe object-level attribute information\nlearned by vision-language models. To this end, we created a clean and densely\nannotated test set covering 117 attribute classes on the 80 object classes of\nMS COCO. It includes positive and negative annotations, which enables\nopen-vocabulary evaluation. Overall, the benchmark consists of 1.4 million\nannotations. For reference, we provide a first baseline method for\nopen-vocabulary attribute detection. Moreover, we demonstrate the benchmark's\nvalue by studying the attribute detection performance of several foundation\nmodels. Project page https://ovad-benchmark.github.io/",
    "descriptor": "",
    "authors": [
      "Mar\u00eda A. Bravo",
      "Sudhanshu Mittal",
      "Simon Ging",
      "Thomas Brox"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12914"
  },
  {
    "id": "arXiv:2211.12916",
    "title": "An information security monitoring and management system for 5G and 6G  Networks based on SDN/NFV",
    "abstract": "An approach to using the concept of Software-Defined Networking and Network\nFunctions Virtualization (SDN/NFV) for the implementation of an information\nsecurity monitoring and management system in 5G and 6G networks is proposed.\nSDN switches based on the OpenFlow protocol are offered as network sensors. In\norder to reduce the time for finding a subset of the right rules in the vast\narray of all rules on traffic filtering systems that are logically located on\nsensors, a method of processing and filtering traffic in 5G and 6G transport\nnetworks is proposed. This method is based on DPDK with the LPM algorithm and\nis capable of processing up to 8 megapackets per second on 1 CPU core; the\npacket processing takes O(1), which is significantly lower than with similar\nalgorithms. The managing subsystem consists of regional monitoring centres and\na main one. The main Monitoring Centre includes a main cluster of SDN\ncontrollers along with Active/Active redundancy scheme. The regional centres\nrepresent SDN software controllers that manage locally subordinate sensors. All\nthe managing centres are interconnected via the Transport subsystem and form a\nnetwork. An algorithm for network sensor load balancing between SDN controllers\nhas been developed in order to provide fault tolerance, load balancing and\nnetwork connectivity. The algorithm results in a set of optimal sensor groups\nwith total load not exceeding the maximum capacity of the SDN controllers.",
    "descriptor": "",
    "authors": [
      "Igor Buzhin",
      "Veronica Antonova",
      "Yury Mironov",
      "Vladislav Gnezdilov",
      "Eldar Gaifutdinov",
      "Mikhail Gorodnichev"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.12916"
  },
  {
    "id": "arXiv:2211.12921",
    "title": "Hybrid Learning of Time-Series Inverse Dynamics Models for Locally  Isotropic Robot Motion",
    "abstract": "Applications of force control and motion planning often rely on an inverse\ndynamics model to represent the high-dimensional dynamic behavior of robots\nduring motion. The widespread occurrence of low-velocity, small-scale, locally\nisotropic motion (LIMO) typically complicates the identification of appropriate\nmodels due to the exaggeration of dynamic effects and sensory perturbation\ncaused by complex friction and phenomena of hysteresis, e.g., pertaining to\njoint elasticity. We propose a hybrid model learning base architectures\ncombining a rigid body dynamics model identified by parametric regression and\ntime-series neural network architectures based on multilayer-perceptron, LSTM,\nand Transformer topologies. Further, we introduce novel joint-wise rotational\nhistory encoding, reinforcing temporal information to effectively model dynamic\nhysteresis. The models are evaluated on a KUKA iiwa 14 during algorithmically\ngenerated locally isotropic movements. Together with the rotational encoding,\nthe proposed architectures outperform state-of-the-art baselines by a magnitude\nof 10$^3$ yielding an RMSE of 0.14 Nm. Leveraging the hybrid structure and\ntime-series encoding capabilities, our approach allows for accurate torque\nestimation, indicating its applicability in critically force-sensitive\napplications during motion sequences exceeding the capacity of conventional\ninverse dynamics models while retaining trainability in face of scarce data and\nexplainability due to the employed physics model prior.",
    "descriptor": "\nComments: Accepted for publication in IEEE Robotics and Automation Letters ( see this https URL ). 8 pages, 8 figures\n",
    "authors": [
      "Tolga-Can \u00c7allar",
      "Sven B\u00f6ttger"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.12921"
  },
  {
    "id": "arXiv:2211.12923",
    "title": "A Calculus for Amortized Expected Runtimes",
    "abstract": "We develop a weakest-precondition-style calculus \\`a la Dijkstra for\nreasoning about amortized expected runtimes of randomized algorithms with\naccess to dynamic memory - the $\\textsf{aert}$ calculus. Our calculus is truly\nquantitative, i.e. instead of Boolean valued predicates, it manipulates\nreal-valued functions.\nEn route to the $\\textsf{aert}$ calculus, we study the $\\textsf{ert}$\ncalculus for reasoning about expected runtimes of Kaminski et al. [2018]\nextended by capabilities for handling dynamic memory, thus enabling\ncompositional and local reasoning about randomized data structures. This\nextension employs runtime separation logic, which has been foreshadowed by\nMatheja [2020] and then implemented in Isabelle/HOL by Haslbeck [2021]. In\naddition to Haslbeck's results, we further prove soundness of the so-extended\n$\\textsf{ert}$ calculus with respect to an operational Markov decision process\nmodel featuring countably-branching nondeterminism, provide intuitive\nexplanations, and provide proof rules enabling separation logic-style\nverification for upper bounds on expected runtimes. Finally, we build the\nso-called potential method for amortized analysis into the $\\textsf{ert}$\ncalculus, thus obtaining the $\\textsf{aert}$ calculus.\nSince one needs to be able to handle changes in potential which can be\nnegative, the $\\textsf{aert}$ calculus needs to be capable of handling signed\nrandom variables. A particularly pleasing feature of our solution is that,\nunlike e.g. Kozen [1985], we obtain a loop rule for our signed random\nvariables, and furthermore, unlike e.g. Kaminski and Katoen [2017], the\n$\\textsf{aert}$ calculus makes do without the need for involved technical\nmachinery keeping track of the integrability of the random variables.\nFinally, we present case studies, including a formal analysis of a randomized\ndelete-insert-find-any set data structure [Brodal et al. 1996].",
    "descriptor": "",
    "authors": [
      "Kevin Batz",
      "Benjamin Lucien Kaminski",
      "Joost-Pieter Katoen",
      "Christoph Matheja",
      "Lena Verscht"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.12923"
  },
  {
    "id": "arXiv:2211.12926",
    "title": "Contrastive Multi-View Textual-Visual Encoding: Towards One Hundred  Thousand-Scale One-Shot Logo Identification",
    "abstract": "In this paper, we study the problem of identifying logos of business brands\nin natural scenes in an open-set one-shot setting. This problem setup is\nsignificantly more challenging than traditionally-studied 'closed-set' and\n'large-scale training samples per category' logo recognition settings. We\npropose a novel multi-view textual-visual encoding framework that encodes text\nappearing in the logos as well as the graphical design of the logos to learn\nrobust contrastive representations. These representations are jointly learned\nfor multiple views of logos over a batch and thereby they generalize well to\nunseen logos. We evaluate our proposed framework for cropped logo verification,\ncropped logo identification, and end-to-end logo identification in natural\nscene tasks; and compare it against state-of-the-art methods. Further, the\nliterature lacks a 'very-large-scale' collection of reference logo images that\ncan facilitate the study of one-hundred thousand-scale logo identification. To\nfill this gap in the literature, we introduce Wikidata Reference Logo Dataset\n(WiRLD), containing logos for 100K business brands harvested from Wikidata. Our\nproposed framework that achieves an area under the ROC curve of 91.3% on the\nQMUL-OpenLogo dataset for the verification task, outperforms state-of-the-art\nmethods by 9.1% and 2.6% on the one-shot logo identification task on the\nToplogos-10 and the FlickrLogos32 datasets, respectively. Further, we show that\nour method is more stable compared to other baselines even when the number of\ncandidate logos is on a 100K scale.",
    "descriptor": "\nComments: Accepted to ICVGIP 2022\n",
    "authors": [
      "Nakul Sharma",
      "Abhirama S. Penamakuri",
      "Anand Mishra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12926"
  },
  {
    "id": "arXiv:2211.12930",
    "title": "Introspection-based Explainable Reinforcement Learning in Episodic and  Non-episodic Scenarios",
    "abstract": "With the increasing presence of robotic systems and human-robot environments\nin today's society, understanding the reasoning behind actions taken by a robot\nis becoming more important. To increase this understanding, users are provided\nwith explanations as to why a specific action was taken. Among other effects,\nthese explanations improve the trust of users in their robotic partners. One\noption for creating these explanations is an introspection-based approach which\ncan be used in conjunction with reinforcement learning agents to provide\nprobabilities of success. These can in turn be used to reason about the actions\ntaken by the agent in a human-understandable fashion. In this work, this\nintrospection-based approach is developed and evaluated further on the basis of\nan episodic and a non-episodic robotics simulation task. Furthermore, an\nadditional normalization step to the Q-values is proposed, which enables the\nusage of the introspection-based approach on negative and comparatively small\nQ-values. Results obtained show the viability of introspection for episodic\nrobotics tasks and, additionally, that the introspection-based approach can be\nused to generate explanations for the actions taken in a non-episodic robotics\nenvironment as well.",
    "descriptor": "",
    "authors": [
      "Niclas Schroeter",
      "Francisco Cruz",
      "Stefan Wermter"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12930"
  },
  {
    "id": "arXiv:2211.12931",
    "title": "Can we Adopt Self-supervised Pretraining for Chest X-Rays?",
    "abstract": "Chest radiograph (or Chest X-Ray, CXR) is a popular medical imaging modality\nthat is used by radiologists across the world to diagnose heart or lung\nconditions. Over the last decade, Convolutional Neural Networks (CNN), have\nseen success in identifying pathologies in CXR images. Typically, these CNNs\nare pretrained on the standard ImageNet classification task, but this assumes\navailability of large-scale annotated datasets. In this work, we analyze the\nutility of pretraining on unlabeled ImageNet or Chest X-Ray (CXR) datasets\nusing various algorithms and in multiple settings. Some findings of our work\ninclude: (i) supervised training with labeled ImageNet learns strong\nrepresentations that are hard to beat; (ii) self-supervised pretraining on\nImageNet (~1M images) shows performance similar to self-supervised pretraining\non a CXR dataset (~100K images); and (iii) the CNN trained on supervised\nImageNet can be trained further with self-supervised CXR images leading to\nimprovements, especially when the downstream dataset is on the order of a few\nthousand images.",
    "descriptor": "\nComments: Extended Abstract presented at Machine Learning for Health (ML4H) symposium 2022, November 28th, 2022, New Orleans, United States & Virtual, this http URL, 10 pages\n",
    "authors": [
      "Arsh Verma",
      "Makarand Tapaswi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12931"
  },
  {
    "id": "arXiv:2211.12933",
    "title": "Join the High Accuracy Club on ImageNet with A Binary Neural Network  Ticket",
    "abstract": "Binary neural networks are the extreme case of network quantization, which\nhas long been thought of as a potential edge machine learning solution.\nHowever, the significant accuracy gap to the full-precision counterparts\nrestricts their creative potential for mobile applications. In this work, we\nrevisit the potential of binary neural networks and focus on a compelling but\nunanswered problem: how can a binary neural network achieve the crucial\naccuracy level (e.g., 80%) on ILSVRC-2012 ImageNet? We achieve this goal by\nenhancing the optimization process from three complementary perspectives: (1)\nWe design a novel binary architecture BNext based on a comprehensive study of\nbinary architectures and their optimization process. (2) We propose a novel\nknowledge-distillation technique to alleviate the counter-intuitive overfitting\nproblem observed when attempting to train extremely accurate binary models. (3)\nWe analyze the data augmentation pipeline for binary networks and modernize it\nwith up-to-date techniques from full-precision models. The evaluation results\non ImageNet show that BNext, for the first time, pushes the binary model\naccuracy boundary to 80.57% and significantly outperforms all the existing\nbinary networks. Code and trained models are available at: (blind URL, see\nappendix).",
    "descriptor": "",
    "authors": [
      "Nianhui Guo",
      "Joseph Bethge",
      "Christoph Meinel",
      "Haojin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12933"
  },
  {
    "id": "arXiv:2211.12934",
    "title": "Applying the Web of Things Abstraction to Bluetooth Low Energy  Communication",
    "abstract": "We apply the Web of Things (WoT) communication pattern, i.e., the semantic\ndescription of metadata and interaction affordances, to Internet of Things\n(IoT) devices that rely on non-IP-based protocols, using Bluetooth Low Energy\n(LE) as an example. The reference implementation of the WoT Scripting API,\nnode-wot, currently supports only IP-based application layer protocols such as\nHTTP and MQTT. However, a significant number of IoT devices do not communicate\nover IP, but via other network layer protocols, e.g. L2CAP used by Bluetooth\nLE. To leverage the WoT abstraction in Bluetooth Low Energy communication, we\nspecified two ontologies to describe the capabilities of Bluetooth LE devices\nand transmitted binary data, considered the different interaction possibilities\nwith the Linux Bluetooth stack BlueZ, and due to better documentation, used the\nD-Bus API to implement Bluetooth LE bindings in JavaScript. Finally, we\nevaluated the latencies of the bindings in comparison to the BlueZ tool\nbluetoothctl, showing that the Bluetooth LE bindings are on average about 16\npercent slower than the comparison program during connection establishment and\nabout 6 percent slower when disconnecting, but have almost the same performance\nduring reading (about 3 percent slower).",
    "descriptor": "\nComments: Connected World Semantic Interoperability Workshop 2022, 8 pages\n",
    "authors": [
      "Michael Freund",
      "Rene Dorsch",
      "Andreas Harth"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.12934"
  },
  {
    "id": "arXiv:2211.12941",
    "title": "EurNet: Efficient Multi-Range Relational Modeling of Spatial  Multi-Relational Data",
    "abstract": "Modeling spatial relationship in the data remains critical across many\ndifferent tasks, such as image classification, semantic segmentation and\nprotein structure understanding. Previous works often use a unified solution\nlike relative positional encoding. However, there exists different kinds of\nspatial relations, including short-range, medium-range and long-range\nrelations, and modeling them separately can better capture the focus of\ndifferent tasks on the multi-range relations (e.g., short-range relations can\nbe important in instance segmentation, while long-range relations should be\nupweighted for semantic segmentation). In this work, we introduce the EurNet\nfor Efficient multi-range relational modeling. EurNet constructs the\nmulti-relational graph, where each type of edge corresponds to short-, medium-\nor long-range spatial interactions. In the constructed graph, EurNet adopts a\nnovel modeling layer, called gated relational message passing (GRMP), to\npropagate multi-relational information across the data. GRMP captures multiple\nrelations within the data with little extra computational cost. We study\nEurNets in two important domains for image and protein structure modeling.\nExtensive experiments on ImageNet classification, COCO object detection and\nADE20K semantic segmentation verify the gains of EurNet over the previous SoTA\nFocalNet. On the EC and GO protein function prediction benchmarks, EurNet\nconsistently surpasses the previous SoTA GearNet. Our results demonstrate the\nstrength of EurNets on modeling spatial multi-relational data from various\ndomains. The implementations of EurNet for image modeling are available at\nhttps://github.com/hirl-team/EurNet-Image . The implementations for other\napplied domains/tasks will be released soon.",
    "descriptor": "\nComments: Research project paper. arXiv v1: codes and model weights of EurNet for image modeling released\n",
    "authors": [
      "Minghao Xu",
      "Yuanfan Guo",
      "Yi Xu",
      "Jian Tang",
      "Xinlei Chen",
      "Yuandong Tian"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12941"
  },
  {
    "id": "arXiv:2211.12942",
    "title": "Double criterion-based estimator for signal number estimation for the  colored noise with unknown covariance matrix",
    "abstract": "The subspace-based techniques are widely utilized to estimate the parameters\nof sums of complex sinusoids corrupted by noise, and the zoom ESPRIT algorithm\nutilizes the zoom technique to apply the ESPRIT to a narrow frequency band to\nimprove the accuracy of frequency estimation. However, the Gaussian noise\nbecomes non-Gaussian in the zoomed baseband after being filtered by a low-pass\nfilter, and thus has an unknown covariance matrix. However, most exiting\nalgorithms for model order estimation performs poorly for the case of colored\nnoise with unknown covariance matrix. In order to accurately estimate the\ndimension of the signal subspace for the zoom ESPRIT algorithm, this paper\nproposes a novel strategy to estimate the number of signals for the case of\ncolored noise with unknown covariance matrix. The proposed strategy is based on\nthe analysis of the behavior of information theoretic criteria utilized in\nmodel order selection. Firstly, a first criterion is defined as the ratio of\nthe current eigenvalue and the mean of the next ones, and its properties is\nanalyzed with respect to the over-modeling and under-modeling. Secondly, a\nnovel second criterion is designed as the ratio of the current value and the\nnext value of the first criterion, and its properties is also analyzed with\nrespect to the over-modeling and under-modeling. Then, a novel signal number\nestimation method is proposed by combining the second criterion with the first\ncriterion to check whether the eigenvalue being tested is arising from a signal\nor from noise. The resulted signal number estimation method is called as the\ndouble criterion-based estimator as it utilizes two criteria to separate the\nsignal eigenvalues from the noise eigenvalues. Finally, simulation results are\npresented to illustrate the performance of the proposed double criterion-based\nestimator and compare it with the existing methods.",
    "descriptor": "\nComments: 23 pages, 5 figures\n",
    "authors": [
      "Huiyue Yi",
      "Wuxiong Zhang",
      "Hui Xu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.12942"
  },
  {
    "id": "arXiv:2211.12950",
    "title": "Look, Read and Ask: Learning to Ask Questions by Reading Text in Images",
    "abstract": "We present a novel problem of text-based visual question generation or\nTextVQG in short. Given the recent growing interest of the document image\nanalysis community in combining text understanding with conversational\nartificial intelligence, e.g., text-based visual question answering, TextVQG\nbecomes an important task. TextVQG aims to generate a natural language question\nfor a given input image and an automatically extracted text also known as OCR\ntoken from it such that the OCR token is an answer to the generated question.\nTextVQG is an essential ability for a conversational agent. However, it is\nchallenging as it requires an in-depth understanding of the scene and the\nability to semantically bridge the visual content with the text present in the\nimage. To address TextVQG, we present an OCR consistent visual question\ngeneration model that Looks into the visual content, Reads the scene text, and\nAsks a relevant and meaningful natural language question. We refer to our\nproposed model as OLRA. We perform an extensive evaluation of OLRA on two\npublic benchmarks and compare them against baselines. Our model OLRA\nautomatically generates questions similar to the public text-based visual\nquestion answering datasets that were curated manually. Moreover, we\nsignificantly outperform baseline approaches on the performance measures\npopularly used in text generation literature.",
    "descriptor": "",
    "authors": [
      "Soumya Jahagirdar",
      "Shankar Gangisetty",
      "Anand Mishra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12950"
  },
  {
    "id": "arXiv:2211.12953",
    "title": "Filtering for Anderson acceleration",
    "abstract": "This work introduces, analyzes and demonstrates an efficient and\ntheoretically sound filtering strategy to ensure the condition of the\nleast-squares problem solved at each iteration of Anderson acceleration. The\nfiltering strategy consists of two steps: the first controls the length\ndisparity between columns of the least-squares matrix, and the second enforces\na lower bound on the angles between subspaces spanned by the columns of that\nmatrix. The combined strategy is shown to control the condition number of the\nleast-squares matrix at each iteration. The method is shown to be effective on\na range of problems based on discretizations of partial differential equations.\nIt is shown particularly effective for problems where the initial iterate may\nlie far from the solution, and which progress through distinct preasymptotic\nand asymptotic phases.",
    "descriptor": "\nComments: 21 pages, 10 figures, 2 tables\n",
    "authors": [
      "Sara Pollock",
      "Leo G. Rebholz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.12953"
  },
  {
    "id": "arXiv:2211.12955",
    "title": "A Survey on Orthogonal Time Frequency Space: New Delay Doppler  Communications Paradigm in 6G era",
    "abstract": "In 6G era, the space-air-ground integrated networks (SAGIN) are expected to\nprovide global coverage and thus are required to support a wide range of\nemerging applications in hostile environments with high-mobility. In such\nscenarios, conventional orthogonal frequency division multiplexing (OFDM)\nmodulation, which has been widely deployed in the cellular and Wi-Fi\ncommunications systems, will suffer from performance degradation due to high\nDoppler shift. To address this challenge, a new two-dimensional (2D) modulation\nscheme referred to as orthogonal time frequency space (OTFS) was proposed and\nhas been recognized as an enabling technology for future high-mobility\nscenarios. In particular, OTFS modulates information in the delay-Doppler (DD)\ndomain rather than the time-frequency (TF) domain for OFDM, providing the\nbenefits of Doppler-resilience and delay-resilience, low signaling latency, low\npeak-to-average ratio (PAPR), and low-complexity implementation. Recent\nresearches also show that the direct interaction of information and physical\nworld in the DD domain makes OTFS an promising waveform for realizing\nintegrated sensing and communications (ISAC). In this article, we will present\na comprehensive survey of OTFS technology in 6G era, including the\nfundamentals, recent advances, and future works. Our aim is that this article\ncould provide valuable references for all researchers working in the area of\nOTFS.",
    "descriptor": "\nComments: Survey paper on OTFS, submitted to China Communications\n",
    "authors": [
      "Weijie Yuan",
      "Shuangyang Li",
      "Zhiqiang Wei",
      "Jiamo Jiang",
      "Haijun Zhang",
      "Pingzhi Fan"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.12955"
  },
  {
    "id": "arXiv:2211.12956",
    "title": "Reinforcement learning for traffic signal control in hybrid action space",
    "abstract": "The prevailing reinforcement-learning-based traffic signal control methods\nare typically staging-optimizable or duration-optimizable, depending on the\naction spaces. In this paper, we propose a novel control architecture, TBO,\nwhich is based on hybrid proximal policy optimization. To the best of our\nknowledge, TBO is the first RL-based algorithm to implement synchronous\noptimization of the staging and duration. Compared to discrete and continuous\naction spaces, hybrid action space is a merged search space, in which TBO\nbetter implements the trade-off between frequent switching and unsaturated\nrelease. Experiments are given to demonstrate that TBO reduces the queue length\nand delay by 13.78% and 14.08% on average, respectively, compared to the\nexisting baselines. Furthermore, we calculate the Gini coefficients of the\nright-of-way to indicate TBO does not harm fairness while improving efficiency.",
    "descriptor": "\nComments: 27 pages\n",
    "authors": [
      "Haoqing Luo",
      "sheng jin"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12956"
  },
  {
    "id": "arXiv:2211.12964",
    "title": "Petroleum prices prediction using data mining techniques -- A Review",
    "abstract": "Over the past 20 years, Kenya's demand for petroleum products has\nproliferated. This is mainly because this particular commodity is used in many\nsectors of the country's economy. Exchange rates are impacted by constantly\nshifting prices, which also impact Kenya's industrial output of commodities.\nThe cost of other items produced and even the expansion of the economy is\nsignificantly impacted by any change in the price of petroleum products.\nTherefore, accurate petroleum price forecasting is critical for devising\npolicies that are suitable to curb fuel-related shocks. Data mining techniques\nare the tools used to find valuable patterns in data. Data mining techniques\nused in petroleum price prediction, including artificial neural networks\n(ANNs), support vector machines (SVMs), and intelligent optimization techniques\nlike the genetic algorithm (GA), have grown increasingly popular. This study\nprovides a comprehensive review of the existing data mining techniques for\nmaking predictions on petroleum prices. The data mining techniques are\nclassified into regression models, deep neural network models, fuzzy sets and\nlogic, and hybrid models. A detailed discussion of how these models are\ndeveloped and the accuracy of the models is provided.",
    "descriptor": "",
    "authors": [
      "Kiplang'at Weldon",
      "John Ngechu",
      "Ngatho Everlyne",
      "Nancy Njambi",
      "Kinyua Gikunda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12964"
  },
  {
    "id": "arXiv:2211.12966",
    "title": "How do Authors' Perceptions of their Papers Compare with Co-authors'  Perceptions and Peer-review Decisions?",
    "abstract": "How do author perceptions match up to the outcomes of the peer-review process\nand perceptions of others? In a top-tier computer science conference (NeurIPS\n2021) with more than 23,000 submitting authors and 9,000 submitted papers, we\nsurvey the authors on three questions: (i) their predicted probability of\nacceptance for each of their papers, (ii) their perceived ranking of their own\npapers based on scientific contribution, and (iii) the change in their\nperception about their own papers after seeing the reviews. The salient results\nare: (1) Authors have roughly a three-fold overestimate of the acceptance\nprobability of their papers: The median prediction is 70% for an approximately\n25% acceptance rate. (2) Female authors exhibit a marginally higher\n(statistically significant) miscalibration than male authors; predictions of\nauthors invited to serve as meta-reviewers or reviewers are similarly\ncalibrated, but better than authors who were not invited to review. (3)\nAuthors' relative ranking of scientific contribution of two submissions they\nmade generally agree (93%) with their predicted acceptance probabilities, but\nthere is a notable 7% responses where authors think their better paper will\nface a worse outcome. (4) The author-provided rankings disagreed with the\npeer-review decisions about a third of the time; when co-authors ranked their\njointly authored papers, co-authors disagreed at a similar rate -- about a\nthird of the time. (5) At least 30% of respondents of both accepted and\nrejected papers said that their perception of their own paper improved after\nthe review process. The stakeholders in peer review should take these findings\ninto account in setting their expectations from peer review.",
    "descriptor": "",
    "authors": [
      "Charvi Rastogi",
      "Ivan Stelmakh",
      "Alina Beygelzimer",
      "Yann N. Dauphin",
      "Percy Liang",
      "Jennifer Wortman Vaughan",
      "Zhenyu Xue",
      "Hal Daum\u00e9 III",
      "Emma Pierson",
      "Nihar B. Shah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Databases (cs.DB)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2211.12966"
  },
  {
    "id": "arXiv:2211.12968",
    "title": "A Two-Level Galerkin Reduced Order Model for the Steady Navier-Stokes  Equations",
    "abstract": "We propose, analyze, and investigate numerically a novel two-level Galerkin\nreduced order model (2L-ROM) for the efficient and accurate numerical\nsimulation of the steady Navier-Stokes equations. In the first step of the\n2L-ROM, a relatively low-dimensional nonlinear system is solved. In the second\nstep, the Navier-Stokes equations are linearized around the solution found in\nthe first step, and a higher-dimensional system for the linearized problem is\nsolved. We prove an error bound for the new 2L-ROM and compare it to the\nstandard one level ROM (1L-ROM) in the numerical simulation of the steady\nBurgers equation. The 2L-ROM significantly decreases (by a factor of $2$ and\neven $3$) the 1L-ROM computational cost, without compromising its numerical\naccuracy.",
    "descriptor": "",
    "authors": [
      "Dylan Park",
      "Changhong Mou",
      "Honghu Liu",
      "Adrian Sandu",
      "Traian Iliescu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.12968"
  },
  {
    "id": "arXiv:2211.12969",
    "title": "A Dynamic Equivalent Method for PMSG-WTG Based Wind Farms Considering  wind Speeds and Fault Severities",
    "abstract": "The dynamic security assessment of power systems needs to scan contingencies\nin a preselected set through time-domain simulations. With more and more\ninverter-based-generation, such as wind and solar power generation, integrated\ninto power systems, electro-magnetic transient simulation is adopted. However,\nthe complexity of simulation will increase greatly if inverter-based-generation\nunits are modeled in detail. In order to reduce the complexity of simulation of\npower systems including large-scale wind farms, it is critical to develop\ndynamic equivalent methods for wind farms which are applicable to the expected\ncontingency analysis. The dynamic response characteristics of permanent magnet\nsynchronous generator-wind turbine generators (PMSG-WTGs) are not only\ninfluenced by their control strategies, but also by the operating wind speeds\nand the fault severities. Thus, this paper proposes a dynamic equivalent method\nfor PMSG-WTG based wind farms considering the wind speeds and the fault\nseverities. Firstly, this paper analyzes all possible response characteristics\nof a PMSG-WTG and proposes a clustering method based on the operating wind\nspeed and the terminal voltage of each PMSG-WTG at the end of the fault. Then,\na single-machine equivalent method is introduced for each group of PMSG-WTGs.\nFor the group of PMSG-WTGs with active power ramp recovery process, an\nequivalent model with segmented ramp rate limitation for active current is\ndesigned. In order to obtain the clustering indicators, a simulation-based\niterative method is put forward to calculate the voltage at point of common\nconnection (PCC) of the wind farm, and a PMSG-WTG terminal voltage calculation\nmethod is further presented. Eventually, the efficiency and accuracy of the\nproposed method are verified by the simulation results.",
    "descriptor": "",
    "authors": [
      "Dongsheng Li",
      "Chen Shen",
      "Ye Liu",
      "Ying Chen",
      "Shaowei Huang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.12969"
  },
  {
    "id": "arXiv:2211.12971",
    "title": "Cooperative data-driven modeling",
    "abstract": "Data-driven modeling in mechanics is evolving rapidly based on recent machine\nlearning advances, especially on artificial neural networks. As the field\nmatures, new data and models created by different groups become available,\nopening possibilities for cooperative modeling. However, artificial neural\nnetworks suffer from catastrophic forgetting, i.e. they forget how to perform\nan old task when trained on a new one. This hinders cooperation because\nadapting an existing model for a new task affects the performance on a previous\ntask trained by someone else. The authors developed a continual learning method\nthat addresses this issue, applying it here for the first time to solid\nmechanics. In particular, the method is applied to recurrent neural networks to\npredict history-dependent plasticity behavior, although it can be used on any\nother architecture (feedforward, convolutional, etc.) and to predict other\nphenomena. This work intends to spawn future developments on continual learning\nthat will foster cooperative strategies among the mechanics community to solve\nincreasingly challenging problems. We show that the chosen continual learning\nstrategy can sequentially learn several constitutive laws without forgetting\nthem, using less data to achieve the same error as standard training of one law\nper model.",
    "descriptor": "",
    "authors": [
      "Aleksandr Dekhovich",
      "O. Taylan Turan",
      "Jiaxiang Yi",
      "Miguel A. Bessa"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12971"
  },
  {
    "id": "arXiv:2211.12972",
    "title": "Uniform Passive Fault-Tolerant Control of a Quadcopter with One, Two, or  Three Rotor Failure",
    "abstract": "This study proposes a uniform passive fault-tolerant control (FTC) method for\na quadcopter that does not rely on fault information subject to one, two\nadjacent, two opposite, or three rotors failure. The uniform control implies\nthat the passive FTC is able to cover the condition from quadcopter fault-free\nto rotor failure without controller switching. To achieve the purpose of the\npassive FTC, the rotors' fault is modeled as a disturbance acting on the\nvirtual control of the quadcopter system. The disturbance estimate is used\ndirectly for the passive FTC with rotor failure. To avoid controller switching\nbetween normal control and FTC, a dynamic control allocation is used. In\naddition, the closed-loop stability has been analyzed and a virtual control\nfeedback is adopted to achieve the passive FTC for the quadcopter with two and\nthree rotor failure. To validate the proposed uniform passive FTC method,\noutdoor experiments are performed for the first time, which have demonstrated\nthat the hovering quadcopter is able to recover from one rotor failure by the\nproposed controller and continue to fly even if two adjacent, two opposite, or\nthree rotors fail, without any rotor fault information and controller\nswitching.",
    "descriptor": "",
    "authors": [
      "Chenxu Ke",
      "Kai-Yuan Cai",
      "Quan Quan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.12972"
  },
  {
    "id": "arXiv:2211.12977",
    "title": "Linear Programming Hierarchies in Coding Theory: Dual Solutions",
    "abstract": "The rate vs. distance problem is a long-standing open problem in coding\ntheory. Recent papers have suggested a new way to tackle this problem by\nappealing to a new hierarchy of linear programs. If one can find good dual\nsolutions to these LPs, this would result in improved upper bounds for the rate\nvs. distance problem of linear codes. In this work, we develop the first dual\nfeasible solutions to the LPs in this hierarchy. These match the best-known\nbound for a wide range of parameters. Our hope is that this is a first step\ntowards better solutions, and improved upper bounds for the rate vs. distance\nproblem of linear codes.",
    "descriptor": "",
    "authors": [
      "Elyassaf Loyfer",
      "Nati Linial"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.12977"
  },
  {
    "id": "arXiv:2211.12979",
    "title": "FLAIR #1: semantic segmentation and domain adaptation dataset",
    "abstract": "The French National Institute of Geographical and Forest Information (IGN)\nhas the mission to document and measure land-cover on French territory and\nprovides referential geographical datasets, including high-resolution aerial\nimages and topographic maps. The monitoring of land-cover plays a crucial role\nin land management and planning initiatives, which can have significant\nsocio-economic and environmental impact. Together with remote sensing\ntechnologies, artificial intelligence (IA) promises to become a powerful tool\nin determining land-cover and its evolution. IGN is currently exploring the\npotential of IA in the production of high-resolution land cover maps. Notably,\ndeep learning methods are employed to obtain a semantic segmentation of aerial\nimages. However, territories as large as France imply heterogeneous contexts:\nvariations in landscapes and image acquisition make it challenging to provide\nuniform, reliable and accurate results across all of France. The FLAIR-one\ndataset presented is part of the dataset currently used at IGN to establish the\nFrench national reference land cover map \"Occupation du sol \\`a grande\n\\'echelle\" (OCS- GE).",
    "descriptor": "",
    "authors": [
      "Anatol Garioud",
      "St\u00e9phane Peillet",
      "Eva Bookjans",
      "S\u00e9bastien Giordano",
      "Boris Wattrelos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.12979"
  },
  {
    "id": "arXiv:2211.12981",
    "title": "Improving Visual-textual Sentiment Analysis by Fusing Expert Features",
    "abstract": "Visual-textual sentiment analysis aims to predict sentiment with the input of\na pair of image and text. The main challenge of visual-textual sentiment\nanalysis is how to learn effective visual features for sentiment prediction\nsince input images are often very diverse. To address this challenge, we\npropose a new method that improves visual-textual sentiment analysis by\nintroducing powerful expert visual features. The proposed method consists of\nfour parts: (1) a visual-textual branch to learn features directly from data\nfor sentiment analysis, (2) a visual expert branch with a set of pre-trained\n\"expert\" encoders to extract effective visual features, (3) a CLIP branch to\nimplicitly model visual-textual correspondence, and (4) a multimodal feature\nfusion network based on either BERT or MLP to fuse multimodal features and make\nsentiment prediction. Extensive experiments on three datasets show that our\nmethod produces better visual-textual sentiment analysis performance than\nexisting methods.",
    "descriptor": "",
    "authors": [
      "Junyu Chen",
      "Jie An",
      "Hanjia Lyu",
      "Jiebo Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2211.12981"
  },
  {
    "id": "arXiv:2211.12982",
    "title": "The Stochastic Arrival Problem",
    "abstract": "We study a new modification of the Arrival problem, which allows for nodes\nthat exhibit random as well as controlled behaviour, in addition to switching\nnodes. We study the computational complexity of these extensions, building on\nexisting work on Reachability Switching Games. In particular, we show for\nversions of the arrival problem involving just switching and random nodes it is\n\\PP{}-hard to decide if their value is greater than a half and we give a PSPACE\ndecision algorithm.",
    "descriptor": "\nComments: 37 pages, 16 figures, included in the proceedings of the 16th International Conference on Reachability Problems,\n",
    "authors": [
      "Thomas Webster"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.12982"
  },
  {
    "id": "arXiv:2211.12987",
    "title": "Reinforcement Learning Agent Design and Optimization with Bandwidth  Allocation Model",
    "abstract": "Reinforcement learning (RL) is currently used in various real-life\napplications. RL-based solutions have the potential to generically address\nproblems, including the ones that are difficult to solve with heuristics and\nmeta-heuristics and, in addition, the set of problems and issues where some\nintelligent or cognitive approach is required. However, reinforcement learning\nagents require a not straightforward design and have important design issues.\nRL agent design issues include the target problem modeling, state-space\nexplosion, the training process, and agent efficiency. Research currently\naddresses these issues aiming to foster RL dissemination. A BAM model, in\nsummary, allocates and shares resources with users. There are three basic BAM\nmodels and several hybrids that differ in how they allocate and share resources\namong users. This paper addresses the issue of an RL agent design and\nefficiency. The RL agent's objective is to allocate and share resources among\nusers. The paper investigates how a BAM model can contribute to the RL agent\ndesign and efficiency. The AllocTC-Sharing (ATCS) model is analytically\ndescribed and simulated to evaluate how it mimics the RL agent operation and\nhow the ATCS can offload computational tasks from the RL agent. The essential\nargument researched is whether algorithms integrated with the RL agent design\nand operation have the potential to facilitate agent design and optimize its\nexecution. The ATCS analytical model and simulation presented demonstrate that\na BAM model offloads agent tasks and assists the agent's design and\noptimization.",
    "descriptor": "\nComments: 2022 International Conference on Computational Science and Computational Intelligence (CSCI), 7 pages, 4 figures\n",
    "authors": [
      "Rafael F. Reale",
      "Joberto S. B. Martins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2211.12987"
  },
  {
    "id": "arXiv:2211.12988",
    "title": "A Secure and Intelligent Data Sharing Scheme for UAV-Assisted Disaster  Rescue",
    "abstract": "Unmanned aerial vehicles (UAVs) have the potential to establish flexible and\nreliable emergency networks in disaster sites when terrestrial communication\ninfrastructures go down. Nevertheless, potential security threats may occur on\nUAVs during data transmissions due to the untrusted environment and open-access\nUAV networks. Moreover, UAVs typically have limited battery and computation\ncapacity, making them unaffordable for heavy security provisioning operations\nwhen performing complicated rescue tasks. In this paper, we develop\nRescueChain, a secure and efficient information sharing scheme for UAV-assisted\ndisaster rescue. Specifically, we first implement a lightweight\nblockchain-based framework to safeguard data sharing under disasters and\nimmutably trace misbehaving entities. A reputation-based consensus protocol is\ndevised to adapt the weakly connected environment with improved consensus\nefficiency and promoted UAVs' honest behaviors. Furthermore, we introduce a\nnovel vehicular fog computing (VFC)-based off-chain mechanism by leveraging\nground vehicles as moving fog nodes to offload UAVs' heavy data processing and\nstorage tasks. To offload computational tasks from the UAVs to ground vehicles\nhaving idle computing resources, an optimal allocation strategy is developed by\nchoosing payoffs that achieve equilibrium in a Stackelberg game formulation of\nthe allocation problem. For lack of sufficient knowledge on network model\nparameters and users' private cost parameters in practical environment, we also\ndesign a two-tier deep reinforcement learning-based algorithm to seek the\noptimal payment and resource strategies of UAVs and vehicles with improved\nlearning efficiency. Simulation results show that RescueChain can effectively\naccelerate consensus process, improve offloading efficiency, reduce energy\nconsumption, and enhance user payoffs.",
    "descriptor": "\nComments: Accepted by IEEE/ACM Transactions on Networking (ToN)\n",
    "authors": [
      "Yuntao Wang",
      "Zhou Su",
      "Qichao Xu",
      "Ruidong Li",
      "Tom H. Luan",
      "Pinghui Wang"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2211.12988"
  },
  {
    "id": "arXiv:2211.12989",
    "title": "Unsupervised Unlearning of Concept Drift with Autoencoders",
    "abstract": "The phenomena of concept drift refers to a change of the data distribution\naffecting the data stream of future samples -- such non-stationary environments\nare often encountered in the real world. Consequently, learning models\noperating on the data stream might become obsolete, and need costly and\ndifficult adjustments such as retraining or adaptation. Existing methods to\naddress concept drift are, typically, categorised as active or passive. The\nformer continually adapt a model using incremental learning, while the latter\nperform a complete model retraining when a drift detection mechanism triggers\nan alarm. We depart from the traditional avenues and propose for the first time\nan alternative approach which \"unlearns\" the effects of the concept drift.\nSpecifically, we propose an autoencoder-based method for \"unlearning\" the\nconcept drift in an unsupervised manner, without having to retrain or adapt any\nof the learning models operating on the data.",
    "descriptor": "",
    "authors": [
      "Andr\u00e9 Artelt",
      "Kleanthis Malialis",
      "Christos Panayiotou",
      "Marios Polycarpou",
      "Barbara Hammer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.12989"
  },
  {
    "id": "arXiv:2211.12990",
    "title": "Adversarial Attacks are a Surprisingly Strong Baseline for Poisoning  Few-Shot Meta-Learners",
    "abstract": "This paper examines the robustness of deployed few-shot meta-learning systems\nwhen they are fed an imperceptibly perturbed few-shot dataset. We attack\namortized meta-learners, which allows us to craft colluding sets of inputs that\nare tailored to fool the system's learning algorithm when used as training\ndata. Jointly crafted adversarial inputs might be expected to synergistically\nmanipulate a classifier, allowing for very strong data-poisoning attacks that\nwould be hard to detect. We show that in a white box setting, these attacks are\nvery successful and can cause the target model's predictions to become worse\nthan chance. However, in opposition to the well-known transferability of\nadversarial examples in general, the colluding sets do not transfer well to\ndifferent classifiers. We explore two hypotheses to explain this: 'overfitting'\nby the attack, and mismatch between the model on which the attack is generated\nand that to which the attack is transferred. Regardless of the mitigation\nstrategies suggested by these hypotheses, the colluding inputs transfer no\nbetter than adversarial inputs that are generated independently in the usual\nway.",
    "descriptor": "\nComments: Accepted at I Can't Believe It's Not Better Workshop, Neurips 2022\n",
    "authors": [
      "Elre T. Oldewage",
      "John Bronskill",
      "Richard E. Turner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.12990"
  },
  {
    "id": "arXiv:2211.12996",
    "title": "Converting OpenStreetMap (OSM) Data to Functional Road Networks for  Downstream Applications",
    "abstract": "In this work, we study the OpenStreetMap (OSM) data that contains Extensible\nMarkup Language (XML) formatted data. OpenStreetMap data has many different\nformats. OSM XML format is one of them. OSM data has information in the form of\nnodes (points), ways (lines and boundaries), and relations (relationships\nbetween two or more nodes or ways). Here, we preprocess OSM XML data to extract\nthe ways and nodes information using python to get the whole map of the streets\nfor the Memphis area. We parse the OSM data in such a way that gives us the\nwhole map of the Memphis area. We can further use this map for different Neural\nNetworks (NN) and Machine learning (ML) applications. The steps that are\nincluded in this work downloading the Memphis area OSM data, understanding and\nparsing the OSM XML file, converting the nodes and ways information into the\nPandas DataFrame, and visualizing these data into the whole map by using\npython's available data visualization libraries.",
    "descriptor": "",
    "authors": [
      "Md Kaisar Ahmed"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12996"
  },
  {
    "id": "arXiv:2211.12999",
    "title": "Mitigating Negative Transfer in Multi-Task Learning with Exponential  Moving Average Loss Weighting Strategies",
    "abstract": "Multi-Task Learning (MTL) is a growing subject of interest in deep learning,\ndue to its ability to train models more efficiently on multiple tasks compared\nto using a group of conventional single-task models. However, MTL can be\nimpractical as certain tasks can dominate training and hurt performance in\nothers, thus making some tasks perform better in a single-task model compared\nto a multi-task one. Such problems are broadly classified as negative transfer,\nand many prior approaches in the literature have been made to mitigate these\nissues. One such current approach to alleviate negative transfer is to weight\neach of the losses so that they are on the same scale. Whereas current loss\nbalancing approaches rely on either optimization or complex numerical analysis,\nnone directly scale the losses based on their observed magnitudes. We propose\nmultiple techniques for loss balancing based on scaling by the exponential\nmoving average and benchmark them against current best-performing methods on\nthree established datasets. On these datasets, they achieve comparable, if not\nhigher, performance compared to current best-performing methods.",
    "descriptor": "\nComments: AAAI 2023 Student Abstract, Contains Abstract + Appendix / Supplementary Material\n",
    "authors": [
      "Anish Lakkapragada",
      "Essam Sleiman",
      "Saimourya Surabhi",
      "Dennis P. Wall"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12999"
  },
  {
    "id": "arXiv:2211.13000",
    "title": "A Network Classification Method based on Density Time Evolution Patterns  Extracted from Network Automata",
    "abstract": "Network modeling has proven to be an efficient tool for many\ninterdisciplinary areas, including social, biological, transport, and many\nother real world complex systems. In addition, cellular automata (CA) are a\nformalism that has been studied in the last decades as a model for exploring\npatterns in the dynamic spatio-temporal behavior of these systems based on\nlocal rules. Some studies explore the use of cellular automata to analyze the\ndynamic behavior of networks, denominating them as network automata (NA).\nRecently, NA proved to be efficient for network classification, since it uses a\ntime-evolution pattern (TEP) for the feature extraction. However, the TEPs\nexplored by previous studies are composed of binary values, which does not\nrepresent detailed information on the network analyzed. Therefore, in this\npaper, we propose alternate sources of information to use as descriptor for the\nclassification task, which we denominate as density time-evolution pattern\n(D-TEP) and state density time-evolution pattern (SD-TEP). We explore the\ndensity of alive neighbors of each node, which is a continuous value, and\ncompute feature vectors based on histograms of the TEPs. Our results show a\nsignificant improvement compared to previous studies at five synthetic network\ndatabases and also seven real world databases. Our proposed method demonstrates\nnot only a good approach for pattern recognition in networks, but also shows\ngreat potential for other kinds of data, such as images.",
    "descriptor": "",
    "authors": [
      "Kallil M. C. Zielinski",
      "Lucas C. Ribas",
      "Jeaneth Machicao",
      "Odemir M. Bruno"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13000"
  },
  {
    "id": "arXiv:2211.13003",
    "title": "Detecting Conspiracy Theory Against COVID-19 Vaccines",
    "abstract": "Since the beginning of the vaccination trial, social media has been flooded\nwith anti-vaccination comments and conspiracy beliefs. As the day passes, the\nnumber of COVID- 19 cases increases, and online platforms and a few news\nportals entertain sharing different conspiracy theories. The most popular\nconspiracy belief was the link between the 5G network spreading COVID-19 and\nthe Chinese government spreading the virus as a bioweapon, which initially\ncreated racial hatred. Although some disbelief has less impact on society,\nothers create massive destruction. For example, the 5G conspiracy led to the\nburn of the 5G Tower, and belief in the Chinese bioweapon story promoted an\nattack on the Asian-Americans. Another popular conspiracy belief was that Bill\nGates spread this Coronavirus disease (COVID-19) by launching a mass\nvaccination program to track everyone. This Conspiracy belief creates distrust\nissues among laypeople and creates vaccine hesitancy. This study aims to\ndiscover the conspiracy theory against the vaccine on social platforms. We\nperformed a sentiment analysis on the 598 unique sample comments related to\nCOVID-19 vaccines. We used two different models, BERT and Perspective API, to\nfind out the sentiment and toxicity of the sentence toward the COVID-19\nvaccine.",
    "descriptor": "\nComments: 6 pages, 5 figures\n",
    "authors": [
      "Md Hasibul Amin",
      "Harika Madanu",
      "Sahithi Lavu",
      "Hadi Mansourifar",
      "Dana Alsagheer",
      "Weidong Shi"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.13003"
  },
  {
    "id": "arXiv:2211.13004",
    "title": "Data-Codata Symmetry and its Interaction with Evaluation Order",
    "abstract": "Data types and codata types are, as the names suggest, often seen as duals of\neach other. However, most programming languages do not support both of them in\ntheir full generality, or if they do, they are still seen as distinct\nconstructs with separately defined type-checking, compilation, etc. Rendel et\nal. were the first to propose variants of two standard program transformations,\nde- and refunctionalization, as a test to gauge and improve the symmetry\nbetween data and codata types. However, in previous works, codata and data were\nstill seen as separately defined language constructs, with de- and\nrefunctionalization being defined as similar but separate algorithms. These\nworks also glossed over interactions between the aforementioned transformations\nand evaluation order, which leads to a loss of desirable $\\eta$ expansion\nequalities. We argue that the failure of complete symmetry is due to the\ninherent asymmetry of natural deduction as the logical foundation of the\nlanguage design. Natural deduction is asymmetric in that its focus is on\nproducers (proofs) of types, whereas consumers (contexts, continuations,\nrefutations) have a second-class status. Inspired by existing\nsequent-calculus-based language designs, we present the first language design\nthat is fully symmetric in that the issues of polarity (data type vs codata\ntypes) and evaluation order (call-by-value vs call-by-name) are untangled and\nbecome independent attributes of a single form of type declaration. Both\nattributes, polarity and evaluation order, can be changed independently by one\nalgorithm each. In particular, defunctionalization and refunctionalization are\nnow one algorithm. Evaluation order can be defined and changed individually for\neach type, independently from polarity. By allowing only certain combinations\nof evaluation order and polarity, the aforementioned $\\eta$ laws can be\nrestored.",
    "descriptor": "\nComments: 23 pages, 11 figures\n",
    "authors": [
      "David Binder",
      "Julian Jabs",
      "Ingo Skupin",
      "Klaus Ostermann"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.13004"
  },
  {
    "id": "arXiv:2211.13009",
    "title": "Federated Learning on Non-IID Graphs via Structural Knowledge Sharing",
    "abstract": "Graph neural networks (GNNs) have shown their superiority in modeling graph\ndata. Owing to the advantages of federated learning, federated graph learning\n(FGL) enables clients to train strong GNN models in a distributed manner\nwithout sharing their private data. A core challenge in federated systems is\nthe non-IID problem, which also widely exists in real-world graph data. For\nexample, local data of clients may come from diverse datasets or even domains,\ne.g., social networks and molecules, increasing the difficulty for FGL methods\nto capture commonly shared knowledge and learn a generalized encoder. From\nreal-world graph datasets, we observe that some structural properties are\nshared by various domains, presenting great potential for sharing structural\nknowledge in FGL. Inspired by this, we propose FedStar, an FGL framework that\nextracts and shares the common underlying structure information for inter-graph\nfederated learning tasks. To explicitly extract the structure information\nrather than encoding them along with the node features, we define structure\nembeddings and encode them with an independent structure encoder. Then, the\nstructure encoder is shared across clients while the feature-based knowledge is\nlearned in a personalized way, making FedStar capable of capturing more\nstructure-based domain-invariant information and avoiding feature misalignment\nissues. We perform extensive experiments over both cross-dataset and\ncross-domain non-IID FGL settings, demonstrating the superiority of FedStar.",
    "descriptor": "",
    "authors": [
      "Yue Tan",
      "Yixin Liu",
      "Guodong Long",
      "Jing Jiang",
      "Qinghua Lu",
      "Chengqi Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2211.13009"
  },
  {
    "id": "arXiv:2211.13010",
    "title": "Are micro-architectural features able to explain faulty executions in  the presence of soft errors? A preliminary study",
    "abstract": "Soft errors induced by radiations are one of the most challenging issues\nimpacting the electronic systems' reliability. In the embedded domain, system\ndesigners often rely on Double Modular Redundancy (DMR) to reach the desired\nlevel of reliability. This solution has increasing overhead, given the\ncomplexity achieved by modern microprocessors in all domains. This paper\naddresses the promising field of using efficient machine-learning powered cores\nfor the detection of soft errors. To create such cores and make them general\nenough to work with different software applications, microarchitectural\nattributes are a fascinating option as candidate fault detection features.\nSeveral processors already track these features through dedicated Performance\nMonitoring Units. However, there is an open question to understand to what\nextent they are enough to detect faulty executions. This paper moves a step\nforward in this direction. Exploiting the capability of \\textit{gem5} to\nsimulate real computing systems, perform fault injection experiments and\nprofile microarchitectural attributes (i.e., \\textit{gem5} Stats), this paper\npresents the results of a comprehensive analysis regarding the potential\nattributes to be used for soft error detection and associated models that can\nbe trained with these features. Particular emphasis was devoted to\nunderstanding whether event timing could bring additional information to the\ndetection task. This information is crucial to identify the best machine\nlearning models to employ in this challenging task.",
    "descriptor": "",
    "authors": [
      "Deniz Kasap",
      "Alessio Carpegna",
      "Alessandro Savino",
      "Stefano Di Carlo"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.13010"
  },
  {
    "id": "arXiv:2211.13012",
    "title": "Model-agnostic stochastic model predictive control",
    "abstract": "We propose a model-agnostic stochastic predictive control (MASMPC) algorithm\nfor dynamical systems. The proposed approach first discovers\n\\textit{interpretable} governing differential equations from data using a novel\nalgorithm and blends it with a model predictive control algorithm. One salient\nfeature of the proposed approach resides in the fact that it requires no input\nmeasurement (external excitation); the unknown excitation is instead treated as\nwhite noise, and a stochastic differential equation corresponding to the\nunderlying system is identified. With the novel stochastic differential\nequation discovery framework, the proposed approach is able to generalize; this\neliminates the repeated retraining phase -- a major bottleneck with other\nmachine learning-based model agnostic control algorithms. Overall, the proposed\nMASMPC (a) is robust against measurement noise, (b) works with sparse\nmeasurements, (c) can tackle set-point changes, (d) works with multiple control\nvariables, and (e) can incorporate dead time. We have obtained state-of-the-art\nresults on several benchmark examples. Finally, we use the proposed approach\nfor vibration mitigation of a 76-storey building under seismic loading.",
    "descriptor": "",
    "authors": [
      "Tapas Tripura",
      "Souvik Chakraborty"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.13012"
  },
  {
    "id": "arXiv:2211.13014",
    "title": "Sarcasm Detection Framework Using Emotion and Sentiment Features",
    "abstract": "Sarcasm detection is an essential task that can help identify the actual\nsentiment in user-generated data, such as discussion forums or tweets. Sarcasm\nis a sophisticated form of linguistic expression because its surface meaning\nusually contradicts its inner, deeper meaning. Such incongruity is the\nessential component of sarcasm, however, it makes sarcasm detection quite a\nchallenging task. In this paper, we propose a model which incorporates emotion\nand sentiment features to capture the incongruity intrinsic to sarcasm.\nMoreover, we use CNN and pre-trained Transformer to capture context features.\nOur approach achieved state-of-the-art results on four datasets from social\nnetworking platforms and online media.",
    "descriptor": "",
    "authors": [
      "Oxana Vitman",
      "Yevhen Kostiuk",
      "Grigori Sidorov",
      "Alexander Gelbukh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13014"
  },
  {
    "id": "arXiv:2211.13015",
    "title": "Semantics-Preserving Sketch Embedding for Face Generation",
    "abstract": "With recent advances in image-to-image translation tasks, remarkable progress\nhas been witnessed in generating face images from sketches. However, existing\nmethods frequently fail to generate images with details that are semantically\nand geometrically consistent with the input sketch, especially when various\ndecoration strokes are drawn. To address this issue, we introduce a novel W-W+\nencoder architecture to take advantage of the high expressive power of W+ space\nand semantic controllability of W space. We introduce an explicit intermediate\nrepresentation for sketch semantic embedding. With a semantic feature matching\nloss for effective semantic supervision, our sketch embedding precisely conveys\nthe semantics in the input sketches to the synthesized images. Moreover, a\nnovel sketch semantic interpretation approach is designed to automatically\nextract semantics from vectorized sketches. We conduct extensive experiments on\nboth synthesized sketches and hand-drawn sketches, and the results demonstrate\nthe superiority of our method over existing approaches on both\nsemantics-preserving and generalization ability.",
    "descriptor": "",
    "authors": [
      "Binxin Yang",
      "Xuejin Chen",
      "Chaoqun Wang",
      "Chi Zhang",
      "Zihan Chen",
      "Xiaoyan Sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13015"
  },
  {
    "id": "arXiv:2211.13016",
    "title": "On the Typicality of Musical Sequences",
    "abstract": "It has been shown in a recent publication that words in human-produced\nEnglish language tend to have an information content close to the conditional\nentropy. In this paper, we show that the same is true for events in\nhuman-produced monophonic musical sequences. We also show how \"typical\nsampling\" influences the distribution of information around the entropy for\nsingle events and sequences.",
    "descriptor": "\nComments: 2 pages, 1 figure, Accepted at the Extended Abstracts for the Late-Breaking Demo Session of the 23rd Int. Society for Music Information Retrieval Conf., Bengaluru, India, 2022\n",
    "authors": [
      "Mathias Rose Bjare",
      "Stefan Lattner"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.13016"
  },
  {
    "id": "arXiv:2211.13024",
    "title": "Comparison of Motion Encoding Frameworks on Human Manipulation Actions",
    "abstract": "Movement generation, and especially generalisation to unseen situations,\nplays an important role in robotics. Different types of movement generation\nmethods exist such as spline based methods, dynamical system based methods, and\nmethods based on Gaussian mixture models (GMMs). Using a large, new dataset on\nhuman manipulations, in this paper we provide a highly detailed comparison of\nthree most widely used movement encoding and generation frameworks: dynamic\nmovement primitives (DMPs), time based Gaussian mixture regression (tbGMR) and\nstable estimator of dynamical systems (SEDS). We compare these frameworks with\nrespect to their movement encoding efficiency, reconstruction accuracy, and\nmovement generalisation capabilities. The new dataset consists of nine object\nmanipulation actions performed by 12 humans: pick and place, put on top/take\ndown, put inside/take out, hide/uncover, and push/pull with a total of 7,652\nmovement examples. Our analysis shows that for movement encoding and\nreconstruction DMPs are the most efficient framework with respect to the number\nof parameters and reconstruction accuracy if a sufficient number of kernels is\nused. In case of movement generalisation to new start- and end-point\nsituations, DMPs and task parameterized GMM (TP-GMM, movement generalisation\nframework based on tbGMR) lead to similar performance and outperform SEDS.\nFurthermore we observe that TP-GMM and SEDS suffer from inaccurate convergence\nto the end-point as compared to DMPs. These different quantitative results will\nhelp designing trajectory representations in an improved task-dependent way in\nfuture robotic applications.",
    "descriptor": "",
    "authors": [
      "Lennart Jahn",
      "Florentin W\u00f6rg\u00f6tter",
      "Tomas Kulvicius"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.13024"
  },
  {
    "id": "arXiv:2211.13028",
    "title": "Parallel Randomized Tucker Decomposition Algorithms",
    "abstract": "The Tucker tensor decomposition is a natural extension of the singular value\ndecomposition (SVD) to multiway data. We propose to accelerate Tucker tensor\ndecomposition algorithms by using randomization and parallelization. We present\ntwo algorithms that scale to large data and many processors, significantly\nreduce both computation and communication cost compared to previous\ndeterministic and randomized approaches, and obtain nearly the same\napproximation errors. The key idea in our algorithms is to perform randomized\nsketches with Kronecker-structured random matrices, which reduces computation\ncompared to unstructured matrices and can be implemented using a fundamental\ntensor computational kernel. We provide probabilistic error analysis of our\nalgorithms and implement a new parallel algorithm for the structured randomized\nsketch. Our experimental results demonstrate that our combination of\nrandomization and parallelization achieves accurate Tucker decompositions much\nfaster than alternative approaches. We observe up to a 16X speedup over the\nfastest deterministic parallel implementation on 3D simulation data.",
    "descriptor": "",
    "authors": [
      "Rachel Minster",
      "Zitong Li",
      "Grey Ballard"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.13028"
  },
  {
    "id": "arXiv:2211.13032",
    "title": "Monte Carlo Tree Search Algorithms for Risk-Aware and Multi-Objective  Reinforcement Learning",
    "abstract": "In many risk-aware and multi-objective reinforcement learning settings, the\nutility of the user is derived from a single execution of a policy. In these\nsettings, making decisions based on the average future returns is not suitable.\nFor example, in a medical setting a patient may only have one opportunity to\ntreat their illness. Making decisions using just the expected future returns --\nknown in reinforcement learning as the value -- cannot account for the\npotential range of adverse or positive outcomes a decision may have. Therefore,\nwe should use the distribution over expected future returns differently to\nrepresent the critical information that the agent requires at decision time by\ntaking both the future and accrued returns into consideration. In this paper,\nwe propose two novel Monte Carlo tree search algorithms. Firstly, we present a\nMonte Carlo tree search algorithm that can compute policies for nonlinear\nutility functions (NLU-MCTS) by optimising the utility of the different\npossible returns attainable from individual policy executions, resulting in\ngood policies for both risk-aware and multi-objective settings. Secondly, we\npropose a distributional Monte Carlo tree search algorithm (DMCTS) which\nextends NLU-MCTS. DMCTS computes an approximate posterior distribution over the\nutility of the returns, and utilises Thompson sampling during planning to\ncompute policies in risk-aware and multi-objective settings. Both algorithms\noutperform the state-of-the-art in multi-objective reinforcement learning for\nthe expected utility of the returns.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2102.00966\n",
    "authors": [
      "Conor F. Hayes",
      "Mathieu Reymond",
      "Diederik M. Roijers",
      "Enda Howley",
      "Patrick Mannion"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13032"
  },
  {
    "id": "arXiv:2211.13035",
    "title": "Can lies be faked? Comparing low-stakes and high-stakes deception video  datasets from a Machine Learning perspective",
    "abstract": "Despite the great impact of lies in human societies and a meager 54% human\naccuracy for Deception Detection (DD), Machine Learning systems that perform\nautomated DD are still not viable for proper application in real-life settings\ndue to data scarcity. Few publicly available DD datasets exist and the creation\nof new datasets is hindered by the conceptual distinction between low-stakes\nand high-stakes lies. Theoretically, the two kinds of lies are so distinct that\na dataset of one kind could not be used for applications for the other kind.\nEven though it is easier to acquire data on low-stakes deception since it can\nbe simulated (faked) in controlled settings, these lies do not hold the same\nsignificance or depth as genuine high-stakes lies, which are much harder to\nobtain and hold the practical interest of automated DD systems. To investigate\nwhether this distinction holds true from a practical perspective, we design\nseveral experiments comparing a high-stakes DD dataset and a low-stakes DD\ndataset evaluating their results on a Deep Learning classifier working\nexclusively from video data. In our experiments, a network trained in\nlow-stakes lies had better accuracy classifying high-stakes deception than\nlow-stakes, although using low-stakes lies as an augmentation strategy for the\nhigh-stakes dataset decreased its accuracy.",
    "descriptor": "\nComments: 11 pages, 3 figures\n",
    "authors": [
      "Mateus Karvat Camara",
      "Adriana Postal",
      "Tomas Henrique Maul",
      "Gustavo Paetzold"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13035"
  },
  {
    "id": "arXiv:2211.13041",
    "title": "A new Privacy Preserving and Scalable Revocation Method for Self  Sovereign Identity -- The Perfect Revocation Method does not exist yet",
    "abstract": "Digital Identities are playing an essential role in our digital lives. Today,\nused Digital Identities are based on central architectures. Central Digital\nIdentity providers control and know our data and, thereby, our Identity. Self\nSovereign Identities (SSI) are based on a decentralized data storage and data\nexchange architecture, where the user is in sole control of his data and\nidentity. Most of the issued credentials need the possibility of revocation.\nFor a Central Digital Identity, revocation is easy. In decentral architectures,\nrevocation is more challenging. Revocation can be done with different methods\ne.g. lists, compressed lists and cryptographic accumulators. A revocation\nmethod must be privacy preserving and must scale. This paper gives an overview\nabout the available revocation methods, include a survey to define\nrequirements, assess different revocation groups against the requirements,\nhighlights shortcomings of the methods and introduce a new revocation method\ncalled Linked Validity Verifiable Credentials.",
    "descriptor": "",
    "authors": [
      "Andreas Freitag"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.13041"
  },
  {
    "id": "arXiv:2211.13042",
    "title": "Usability Study of Tactile and Voice Interaction Modes by People with  Disabilities for Home Automation Controls",
    "abstract": "This paper presents a comparative usability study on tactile and vocal\ninteraction modes for home automation control of equipment at home for\ndifferent profiles of disabled people. The study is related to the HIP HOPE\nproject concerning the construction of 19 inclusive housing in the Toulouse\nmetropolitan area in France. The experimentation took place in a living lab\nwith 7 different disabled people who realize realistic use cases. The USE and\nUEQ questionnaires were selected as usability tools. The first results show\nthat both interfaces are easy to learn but that usefulness and ease of use\ndimensions need to be improved. This study shows that there is real need for\nmultimodality between touch and voice interaction to control the smart home.\nThis study also shows that there is need to adapt the interface and the\nenvironment to the person's disability.",
    "descriptor": "",
    "authors": [
      "Nadine Vigouroux",
      "Fr\u00e9d\u00e9ric Vella",
      "Ga\u00eblle Lepage",
      "Eric Campo"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.13042"
  },
  {
    "id": "arXiv:2211.13050",
    "title": "Semi-Supervised Lifelong Language Learning",
    "abstract": "Lifelong learning aims to accumulate knowledge and alleviate catastrophic\nforgetting when learning tasks sequentially. However, existing lifelong\nlanguage learning methods only focus on the supervised learning setting.\nUnlabeled data, which can be easily accessed in real-world scenarios, are\nunderexplored. In this paper, we explore a novel setting, semi-supervised\nlifelong language learning (SSLL), where a model learns sequentially arriving\nlanguage tasks with both labeled and unlabeled data. We propose an unlabeled\ndata enhanced lifelong learner to explore SSLL. Specially, we dedicate\ntask-specific modules to alleviate catastrophic forgetting and design two\nmodules to exploit unlabeled data: (1) a virtual supervision enhanced task\nsolver is constructed on a teacher-student framework to mine the underlying\nknowledge from unlabeled data; and (2) a backward augmented learner is built to\nencourage knowledge transfer from newly arrived unlabeled data to previous\ntasks. Experimental results on various language tasks demonstrate our model's\neffectiveness and superiority over competitive baselines under the new setting\nSSLL.",
    "descriptor": "\nComments: EMNLP Findings 2022 Long Paper\n",
    "authors": [
      "Yingxiu Zhao",
      "Yinhe Zheng",
      "Bowen Yu",
      "Zhiliang Tian",
      "Dongkyu Lee",
      "Jian Sun",
      "Haiyang Yu",
      "Yongbin Li",
      "Nevin L. Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.13050"
  },
  {
    "id": "arXiv:2211.13051",
    "title": "Powderworld: A Platform for Understanding Generalization via Rich Task  Distributions",
    "abstract": "One of the grand challenges of reinforcement learning is the ability to\ngeneralize to new tasks. However, general agents require a set of rich, diverse\ntasks to train on. Designing a `foundation environment' for such tasks is\ntricky -- the ideal environment would support a range of emergent phenomena, an\nexpressive task space, and fast runtime. To take a step towards addressing this\nresearch bottleneck, this work presents Powderworld, a lightweight yet\nexpressive simulation environment running directly on the GPU. Within\nPowderworld, two motivating challenges distributions are presented, one for\nworld-modelling and one for reinforcement learning. Each contains hand-designed\ntest tasks to examine generalization. Experiments indicate that increasing the\nenvironment's complexity improves generalization for world models and certain\nreinforcement learning agents, yet may inhibit learning in high-variance\nenvironments. Powderworld aims to support the study of generalization by\nproviding a source of diverse tasks arising from the same core rules.",
    "descriptor": "",
    "authors": [
      "Kevin Frans",
      "Phillip Isola"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13051"
  },
  {
    "id": "arXiv:2211.13058",
    "title": "IDEALI: intuitively localising connected devices in order to support  autonomy",
    "abstract": "The ability to localise a smart device is very useful to visually or\ncognitively impaired people. Localisation-capable technologies are becoming\nmore readily available as off-the-shelf components. In this paper, we highlight\nthe need for such a service in the field of health and autonomy, especially for\ndisabled people. We introduce a model for Semantic Position Description (SPD)\n(e.g. \"The pill organiser in on the kitchen table\") as well as various\nalgorithms that transform raw distance estimations to SPD related to proximity,\nalignment and room identification. Two of these algorithms are evaluated using\nthe LocURa4IoT testbed. The results are compared to the output of a\npre-experiment involving ten human participants in the Maison Intelligente de\nBlagnac. The two studies indicate that both approaches converge up to 90% of\nthe time. .",
    "descriptor": "",
    "authors": [
      "Fr\u00e9d\u00e9ric Vella",
      "R\u00e9jane Dalc\u00e9",
      "Antonio Serpa",
      "Thierry Val",
      "Adrien van Den Bossche",
      "Fr\u00e9d\u00e9ric Vella",
      "Nadine Vigouroux"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.13058"
  },
  {
    "id": "arXiv:2211.13061",
    "title": "A Masked Face Classification Benchmark",
    "abstract": "We propose a novel image dataset focused on tiny faces wearing face masks for\nmask classification purposes, dubbed Small Face MASK (SF-MASK), composed of a\ncollection made from 20k low-resolution images exported from diverse and\nheterogeneous datasets, ranging from 7 x 7 to 64 x 64 pixel resolution. An\naccurate visualization of this collection, through counting grids, made it\npossible to highlight gaps in the variety of poses assumed by the heads of the\npedestrians. In particular, faces filmed by very high cameras, in which the\nfacial features appear strongly skewed, are absent. To address this structural\ndeficiency, we produced a set of synthetic images which resulted in a\nsatisfactory covering of the intra-class variance. Furthermore, a small\nsubsample of 1701 images contains badly worn face masks, opening to multi-class\nclassification challenges. Experiments on SF-MASK focus on face mask\nclassification using several classifiers. Results show that the richness of\nSF-MASK (real + synthetic images) leads all of the tested classifiers to\nperform better than exploiting comparative face mask datasets, on a fixed 1077\nimages testing set. Dataset and evaluation code are publicly available here:\nhttps://github.com/HumaticsLAB/sf-mask",
    "descriptor": "\nComments: 15 pages, 7 figures. Accepted at T-CAP workshop @ ICPR 2022\n",
    "authors": [
      "Federico Cunico",
      "Andrea Toaiari",
      "Marco Cristani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13061"
  },
  {
    "id": "arXiv:2211.13063",
    "title": "Guidelines for Developing Bots for GitHub",
    "abstract": "Projects on GitHub rely on the automation provided by software development\nbots to uphold quality and alleviate developers' workload. Nevertheless, the\npresence of bots can be annoying and disruptive to the community. Backed by\nmultiple studies with practitioners, this paper provides guidelines for\ndeveloping and maintaining software bots. These guidelines aim to support the\ndevelopment of future and current bots and social coding platforms.",
    "descriptor": "",
    "authors": [
      "Mairieli Wessel",
      "Andy Zaidman",
      "Marco Gerosa",
      "Igor Steinmacher"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.13063"
  },
  {
    "id": "arXiv:2211.13067",
    "title": "Sparse2Dense: Learning to Densify 3D Features for 3D Object Detection",
    "abstract": "LiDAR-produced point clouds are the major source for most state-of-the-art 3D\nobject detectors. Yet, small, distant, and incomplete objects with sparse or\nfew points are often hard to detect. We present Sparse2Dense, a new framework\nto efficiently boost 3D detection performance by learning to densify point\nclouds in latent space. Specifically, we first train a dense point 3D detector\n(DDet) with a dense point cloud as input and design a sparse point 3D detector\n(SDet) with a regular point cloud as input. Importantly, we formulate the\nlightweight plug-in S2D module and the point cloud reconstruction module in\nSDet to densify 3D features and train SDet to produce 3D features, following\nthe dense 3D features in DDet. So, in inference, SDet can simulate dense 3D\nfeatures from regular (sparse) point cloud inputs without requiring dense\ninputs. We evaluate our method on the large-scale Waymo Open Dataset and the\nWaymo Domain Adaptation Dataset, showing its high performance and efficiency\nover the state of the arts.",
    "descriptor": "\nComments: Accepted to 36th Conference on Neural Information Processing Systems (NeurIPS 2022). Code will be released on this https URL\n",
    "authors": [
      "Tianyu Wang",
      "Xiaowei Hu",
      "Zhengzhe Liu",
      "Chi-Wing Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13067"
  },
  {
    "id": "arXiv:2211.13069",
    "title": "Cultural Incongruencies in Artificial Intelligence",
    "abstract": "Artificial intelligence (AI) systems attempt to imitate human behavior. How\nwell they do this imitation is often used to assess their utility and to\nattribute human-like (or artificial) intelligence to them. However, most work\non AI refers to and relies on human intelligence without accounting for the\nfact that human behavior is inherently shaped by the cultural contexts they are\nembedded in, the values and beliefs they hold, and the social practices they\nfollow. Additionally, since AI technologies are mostly conceived and developed\nin just a handful of countries, they embed the cultural values and practices of\nthese countries. Similarly, the data that is used to train the models also\nfails to equitably represent global cultural diversity. Problems therefore\narise when these technologies interact with globally diverse societies and\ncultures, with different values and interpretive practices. In this position\npaper, we describe a set of cultural dependencies and incongruencies in the\ncontext of AI-based language and vision technologies, and reflect on the\npossibilities of and potential strategies towards addressing these\nincongruencies.",
    "descriptor": "\nComments: 3 page position paper, presented at the NeurIPS 2022 Workshop on Cultures in AI/AI in Culture\n",
    "authors": [
      "Vinodkumar Prabhakaran",
      "Rida Qadri",
      "Ben Hutchinson"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13069"
  },
  {
    "id": "arXiv:2211.13070",
    "title": "Enhancing team performance with transfer-learning during real-world  human-robot collaboration",
    "abstract": "Socially aware robots should be able, among others, to support fluent\nhuman-robot collaboration in tasks that require interdependent actions in order\nto be solved. Towards enhancing mutual performance, collaborative robots should\nbe equipped with adaptation and learning capabilities. However, co-learning can\nbe a time consuming procedure. For this reason, transferring knowledge from an\nexpert could potentially boost the overall team performance. In the present\nstudy, transfer learning was integrated in a deep Reinforcement Learning (dRL)\nagent. In a real-time and real-world set-up, two groups of participants had to\ncollaborate with a cobot under two different conditions of dRL agents; one that\nwas transferring knowledge and one that did not. A probabilistic policy reuse\nmethod was used for the transfer learning (TL). The results showed that there\nwas a significant difference between the performance of the two groups; TL\nhalved the time needed for the training of new participants to the task.\nMoreover, TL also affected the subjective performance of the teams and enhanced\nthe perceived fluency. Finally, in many cases the objective performance metrics\ndid not correlate with the subjective ones providing interesting insights about\nthe design of transparent and explainable cobot behaviour.",
    "descriptor": "",
    "authors": [
      "Athanasios C. Tsitos",
      "Maria Dagioglou"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.13070"
  },
  {
    "id": "arXiv:2211.13073",
    "title": "Asynchronous global-local non-invasive coupling for linear elliptic  problems",
    "abstract": "This paper presents the first asynchronous version of the Global/Local\nnon-invasive coupling, capable of dealing efficiently with multiple, possibly\nadjacent, patches. We give a new interpretation of the coupling in terms of\nprimal domain decomposition method, and we prove the convergence of the relaxed\nasynchronous iteration. The asynchronous paradigm lifts many bottlenecks of the\nGlobal/Local coupling performance. We illustrate the method on several linear\nelliptic problems as encountered in thermal and elasticity studies.",
    "descriptor": "",
    "authors": [
      "Ahmed El Kerim",
      "Pierre Gosselet",
      "Fr\u00e9d\u00e9ric Magoul\u00e8s"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.13073"
  },
  {
    "id": "arXiv:2211.13078",
    "title": "Participation of Stakeholder in the Design of a Conception Application  of Augmentative and Alternative Communication",
    "abstract": "The objective of this paper is to describe the implication of an\ninterdisciplinary team involved during a user-centered design methodology to\ndesign the platform (WebSoKeyTo) that meets the needs of therapists to design\naugmentative and alternative communication (AAC) aids for disabled users. We\ndescribe the processes of the design process and the role of the various actors\n(therapists and human computer researchers) in the various phases of the\nprocess. Finally, we analyze a satisfaction scale of the therapists on their\nparticipation in the codesign process. This study demonstrates the interest in\nextending the design actors to other therapists and caregivers (professional\nand family) in the daily life of people with disabilities.",
    "descriptor": "",
    "authors": [
      "Fr\u00e9d\u00e9ric Vella",
      "Flavien Clastres-Babou",
      "Fr\u00e9d\u00e9ric Vella",
      "Nadine Vigouroux",
      "Philippe Truillet",
      "Nadine Vigouroux",
      "Charline Calmels",
      "Caroline Mercadier",
      "Karine Gigaud",
      "Margot Issanchou",
      "Kristina Gourinovitch",
      "Anne Garaix"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.13078"
  },
  {
    "id": "arXiv:2211.13079",
    "title": "User Centred Method to Design a Platform to Design Augmentative and  Alternative Communication Assistive Technologies",
    "abstract": "We describe a co-design approach to design the online WebSoKeyTo used to\ndesign AAC. This co-design was carried out between a team of therapists and a\nteam of human-computer interaction researchers. Our approach begins with the\nuse and evaluation of an existing SoKeyTo AAC design application. This step was\nessential in the awareness and definition of the needs by the therapists and in\nthe understanding of the poor usability scores of SoKeyTo by the researchers.\nWe then describe the various phases (focus group, brainstorming, prototyping)\nwith the co-design choices retained. An evaluation of WebSoKeyTo is in\nprogress.",
    "descriptor": "",
    "authors": [
      "Fr\u00e9d\u00e9ric Vella",
      "Flavien Clastres-Babou",
      "Nadine Vigouroux",
      "Philippe Truillet",
      "Charline Calmels",
      "Caroline Mercadier",
      "Karine Gigaud",
      "Margot Issanchou",
      "Kristina Gourinovitch",
      "Anne Garaix"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2211.13079"
  },
  {
    "id": "arXiv:2211.13081",
    "title": "Robust Mean Teacher for Continual and Gradual Test-Time Adaptation",
    "abstract": "Since experiencing domain shifts during test-time is inevitable in practice,\ntest-time adaption (TTA) continues to adapt the model during deployment.\nRecently, the area of continual and gradual test-time adaptation (TTA) emerged.\nIn contrast to standard TTA, continual TTA considers not only a single domain\nshift, but a sequence of shifts. Gradual TTA further exploits the property that\nsome shifts evolve gradually over time. Since in both settings long test\nsequences are present, error accumulation needs to be addressed for methods\nrelying on self-training. In this work, we propose and show that in the setting\nof TTA, the symmetric cross-entropy is better suited as a consistency loss for\nmean teachers compared to the commonly used cross-entropy. This is justified by\nour analysis with respect to the (symmetric) cross-entropy's gradient\nproperties. To pull the test feature space closer to the source domain, where\nthe pre-trained model is well posed, contrastive learning is leveraged. Since\napplications differ in their requirements, we address different settings,\nnamely having source data available and the more challenging source-free\nsetting. We demonstrate the effectiveness of our proposed method 'robust mean\nteacher' (RMT) on the continual and gradual corruption benchmarks CIFAR10C,\nCIFAR100C, and Imagenet-C. We further consider ImageNet-R and propose a new\ncontinual DomainNet-126 benchmark. State-of-the-art results are achieved on all\nbenchmarks.",
    "descriptor": "",
    "authors": [
      "Mario D\u00f6bler",
      "Robert A. Marsden",
      "Bin Yang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13081"
  },
  {
    "id": "arXiv:2211.13084",
    "title": "Runtime Analysis for the NSGA-II: Proving, Quantifying, and Explaining  the Inefficiency For Three or More Objectives",
    "abstract": "The NSGA-II is one of the most prominent algorithms to solve multi-objective\noptimization problems. Despite numerous successful applications and, very\nrecently, also competitive mathematical performance guarantees, several studies\nhave shown that the NSGA-II is less effective for larger numbers of objectives.\nIn this work, we use mathematical runtime analyses to rigorously prove and\nquantify this phenomenon. We show that even on the simple OneMinMax benchmark,\nwhere every solution is Pareto optimal, the NSGA-II also with large population\nsizes cannot compute the full Pareto front (objective vectors of all Pareto\noptima) in sub-exponential time. Our proofs suggest that the reason for this\nunexpected behavior lies in the fact that in the computation of the crowding\ndistance, the different objectives are regarded independently. This is not a\nproblem for two objectives, where any sorting of a pair-wise incomparable set\nof solutions according to one objective is also such a sorting according to the\nother objective (in the inverse order).",
    "descriptor": "",
    "authors": [
      "Weijie Zheng",
      "Benjamin Doerr"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13084"
  },
  {
    "id": "arXiv:2211.13087",
    "title": "Human or Machine? Turing Tests for Vision and Language",
    "abstract": "As AI algorithms increasingly participate in daily activities that used to be\nthe sole province of humans, we are inevitably called upon to consider how much\nmachines are really like us. To address this question, we turn to the Turing\ntest and systematically benchmark current AIs in their abilities to imitate\nhumans. We establish a methodology to evaluate humans versus machines in\nTuring-like tests and systematically evaluate a representative set of selected\ndomains, parameters, and variables. The experiments involved testing 769 human\nagents, 24 state-of-the-art AI agents, 896 human judges, and 8 AI judges, in\n21,570 Turing tests across 6 tasks encompassing vision and language modalities.\nSurprisingly, the results reveal that current AIs are not far from being able\nto impersonate human judges across different ages, genders, and educational\nlevels in complex visual and language challenges. In contrast, simple AI judges\noutperform human judges in distinguishing human answers versus machine answers.\nThe curated large-scale Turing test datasets introduced here and their\nevaluation metrics provide valuable insights to assess whether an agent is\nhuman or not. The proposed formulation to benchmark human imitation ability in\ncurrent AIs paves a way for the research community to expand Turing tests to\nother research areas and conditions. All of source code and data are publicly\navailable at https://tinyurl.com/8x8nha7p",
    "descriptor": "\nComments: 134 pages\n",
    "authors": [
      "Mengmi Zhang",
      "Giorgia Dellaferrera",
      "Ankur Sikarwar",
      "Marcelo Armendariz",
      "Noga Mudrik",
      "Prachi Agrawal",
      "Spandan Madan",
      "Andrei Barbu",
      "Haochen Yang",
      "Tanishq Kumar",
      "Meghna Sadwani",
      "Stella Dellaferrera",
      "Michele Pizzochero",
      "Hanspeter Pfister",
      "Gabriel Kreiman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13087"
  },
  {
    "id": "arXiv:2211.13090",
    "title": "TransVCL: Attention-enhanced Video Copy Localization Network with  Flexible Supervision",
    "abstract": "Video copy localization aims to precisely localize all the copied segments\nwithin a pair of untrimmed videos in video retrieval applications. Previous\nmethods typically start from frame-to-frame similarity matrix generated by\ncosine similarity between frame-level features of the input video pair, and\nthen detect and refine the boundaries of copied segments on similarity matrix\nunder temporal constraints. In this paper, we propose TransVCL: an\nattention-enhanced video copy localization network, which is optimized directly\nfrom initial frame-level features and trained end-to-end with three main\ncomponents: a customized Transformer for feature enhancement, a correlation and\nsoftmax layer for similarity matrix generation, and a temporal alignment module\nfor copied segments localization. In contrast to previous methods demanding the\nhandcrafted similarity matrix, TransVCL incorporates long-range temporal\ninformation between feature sequence pair using self- and cross- attention\nlayers. With the joint design and optimization of three components, the\nsimilarity matrix can be learned to present more discriminative copied\npatterns, leading to significant improvements over previous methods on\nsegment-level labeled datasets (VCSL and VCDB). Besides the state-of-the-art\nperformance in fully supervised setting, the attention architecture facilitates\nTransVCL to further exploit unlabeled or simply video-level labeled data.\nAdditional experiments of supplementing video-level labeled datasets including\nSVD and FIVR reveal the high flexibility of TransVCL from full supervision to\nsemi-supervision (with or without video-level annotation). Code is publicly\navailable at https://github.com/transvcl/TransVCL.",
    "descriptor": "\nComments: Accepted by the Thirty-Seventh AAAI Conference on Artificial Intelligence(AAAI2023)\n",
    "authors": [
      "Sifeng He",
      "Yue He",
      "Minlong Lu",
      "Chen Jiang",
      "Xudong Yang",
      "Feng Qian",
      "Xiaobo Zhang",
      "Lei Yang",
      "Jiandong Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13090"
  },
  {
    "id": "arXiv:2211.13091",
    "title": "Navigation with Tactile Sensor for Natural Human-Robot Interaction",
    "abstract": "Tactile sensors have been introduced to a wide range of robotic tasks such as\nrobot manipulation to mimic the sense of human touch. However, there has only\nbeen a few works that integrate tactile sensing into robot navigation. This\npaper describes a navigation system which allows robots to operate in crowded\nhuman-dense environments and behave with socially acceptable reactions by\nutilizing semantic and force information collected by embedded tactile sensors,\nRGB-D camera and LiDAR. Compliance control is implemented based on artificial\npotential fields considering not only laser scan but also force reading from\ntactile sensors which promises a fast and reliable response to any possible\ncollision. In contrast to cameras, LiDAR and other non-contact sensors, tactile\nsensors can directly interact with humans and can be used to accept social cues\nakin to natural human behavior under the same situation. Furthermore,\nleveraging semantic segmentation from vision module, the robot is able to\nidentify and, therefore assign varying social cost to different groups of\nhumans enabling for socially conscious path planning. At the end of this paper,\nthe proposed control strategy was validated successfully by testing several\nscenarios on an omni-directional robot in real world.",
    "descriptor": "",
    "authors": [
      "Zhen Hao Gan",
      "Yangwei You",
      "Meng Yee",
      "Chuah"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.13091"
  },
  {
    "id": "arXiv:2211.13093",
    "title": "Autonomous Vision-based Rapid Aerial Grasping",
    "abstract": "In a future with autonomous robots, visual and spatial perception is of\nutmost importance for robotic systems. Particularly for aerial robotics, there\nare many applications where utilizing visual perception is necessary for any\nreal-world scenarios. Robotic aerial grasping using drones promises fast\npick-and-place solutions with a large increase in mobility over other robotic\nsolutions. Utilizing Mask R-CNN scene segmentation (detectron2), we propose a\nvision-based system for autonomous rapid aerial grasping which does not rely on\nmarkers for object localization and does not require the size of the object to\nbe previously known. With spatial information from a depth camera, we generate\na point cloud of the detected objects and perform geometry-based grasp planning\nto determine grasping points on the objects. In real-world experiments, we show\nthat our system can localize objects with a mean error of 3 cm compared to a\nmotion capture ground truth for distances from the object ranging from 0.5 m to\n2.5 m. Similar grasping efficacy is maintained compared to a system using\nmotion capture for object localization in experiments. With our results, we\nshow the first use of geometry-based grasping techniques with a flying platform\nand aim to increase the autonomy of existing aerial manipulation platforms,\nbringing them further towards real-world applications in warehouses and similar\nenvironments.",
    "descriptor": "\nComments: 7 pages, 10 figures, preprint of submission to IEEE International Conference on Robotics and Automation (ICRA) 2023\n",
    "authors": [
      "Erik Bauer",
      "Barnabas Gavin Cangan",
      "Robert K. Katzschmann"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13093"
  },
  {
    "id": "arXiv:2211.13094",
    "title": "Characterizing a Neutron-Induced Fault Model for Deep Neural Networks",
    "abstract": "The reliability evaluation of Deep Neural Networks (DNNs) executed on Graphic\nProcessing Units (GPUs) is a challenging problem since the hardware\narchitecture is highly complex and the software frameworks are composed of many\nlayers of abstraction. While software-level fault injection is a common and\nfast way to evaluate the reliability of complex applications, it may produce\nunrealistic results since it has limited access to the hardware resources and\nthe adopted fault models may be too naive (i.e., single and double bit flip).\nContrarily, physical fault injection with neutron beam provides realistic error\nrates but lacks fault propagation visibility. This paper proposes a\ncharacterization of the DNN fault model combining both neutron beam experiments\nand fault injection at software level. We exposed GPUs running General Matrix\nMultiplication (GEMM) and DNNs to beam neutrons to measure their error rate. On\nDNNs, we observe that the percentage of critical errors can be up to 61%, and\nshow that ECC is ineffective in reducing critical errors. We then performed a\ncomplementary software-level fault injection, using fault models derived from\nRTL simulations. Our results show that by injecting complex fault models, the\nYOLOv3 misdetection rate is validated to be very close to the rate measured\nwith beam experiments, which is 8.66x higher than the one measured with fault\ninjection using only single-bit flips.",
    "descriptor": "",
    "authors": [
      "Fernando Fernandes dos Santos",
      "Angeliki Kritikakou",
      "Josie Esteban Rodriguez Condia",
      "Juan David Guerrero Balaguera",
      "Matteo Sonza Reorda",
      "Olivier Sentieys",
      "Paolo Rech"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.13094"
  },
  {
    "id": "arXiv:2211.13095",
    "title": "Schr\u00f6dinger's Bat: Diffusion Models Sometimes Generate Polysemous  Words in Superposition",
    "abstract": "Recent work has shown that despite their impressive capabilities,\ntext-to-image diffusion models such as DALL-E 2 (Ramesh et al., 2022) can\ndisplay strange behaviours when a prompt contains a word with multiple possible\nmeanings, often generating images containing both senses of the word (Rassin et\nal., 2022). In this work we seek to put forward a possible explanation of this\nphenomenon. Using the similar Stable Diffusion model (Rombach et al., 2022), we\nfirst show that when given an input that is the sum of encodings of two\ndistinct words, the model can produce an image containing both concepts\nrepresented in the sum. We then demonstrate that the CLIP encoder used to\nencode prompts (Radford et al., 2021) encodes polysemous words as a\nsuperposition of meanings, and that using linear algebraic techniques we can\nedit these representations to influence the senses represented in the generated\nimages. Combining these two findings, we suggest that the homonym duplication\nphenomenon described by Rassin et al. (2022) is caused by diffusion models\nproducing images representing both of the meanings that are present in\nsuperposition in the encoding of a polysemous word.",
    "descriptor": "",
    "authors": [
      "Jennifer C. White",
      "Ryan Cotterell"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.13095"
  },
  {
    "id": "arXiv:2211.13097",
    "title": "DeepVulSeeker: A Novel Vulnerability Identification Framework via Code  Graph Structure and Pre-training Mechanism",
    "abstract": "Software vulnerabilities can pose severe harms to a computing system. They\ncan lead to system crash, privacy leakage, or even physical damage. Correctly\nidentifying vulnerabilities among enormous software codes in a timely manner is\nso far the essential prerequisite to patch them. Unfortantely, the current\nvulnerability identification methods, either the classic ones or the\ndeep-learning-based ones, have several critical drawbacks, making them unable\nto meet the present-day demands put forward by the software industry. To\novercome the drawbacks, in this paper, we propose DeepVulSeeker, a novel fully\nautomated vulnerability identification framework, which leverages both code\ngraph structures and the semantic features with the help of the recently\nadvanced Graph Representation Self-Attention and pre-training mechanisms. Our\nexperiments show that DeepVulSeeker not only reaches an accuracy as high as\n0.99 on traditional CWE datasets, but also outperforms all other exisiting\nmethods on two highly-complicated datasets. We also testified DeepVulSeeker\nbased on three case studies, and found that DeepVulSeeker is able to understand\nthe implications of the vulnerbilities. We have fully implemented DeepVulSeeker\nand open-sourced it for future follow-up research.",
    "descriptor": "",
    "authors": [
      "Jin Wang",
      "Hui Xiao",
      "Shuwen Zhong",
      "Yinhao Xiao"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.13097"
  },
  {
    "id": "arXiv:2211.13098",
    "title": "Are Concept Drift Detectors Reliable Alarming Systems? -- A Comparative  Study",
    "abstract": "As machine learning models increasingly replace traditional business logic in\nthe production system, their lifecycle management is becoming a significant\nconcern. Once deployed into production, the machine learning models are\nconstantly evaluated on new streaming data. Given the continuous data flow,\nshifting data, also known as concept drift, is ubiquitous in such settings.\nConcept drift usually impacts the performance of machine learning models, thus,\nidentifying the moment when concept drift occurs is required. Concept drift is\nidentified through concept drift detectors. In this work, we assess the\nreliability of concept drift detectors to identify drift in time by exploring\nhow late are they reporting drifts and how many false alarms are they\nsignaling. We compare the performance of the most popular drift detectors\nbelonging to two different concept drift detector groups, error rate-based\ndetectors and data distribution-based detectors. We assess their performance on\nboth synthetic and real-world data. In the case of synthetic data, we\ninvestigate the performance of detectors to identify two types of concept\ndrift, abrupt and gradual. Our findings aim to help practitioners understand\nwhich drift detector should be employed in different situations and, to achieve\nthis, we share a list of the most important observations made throughout this\nstudy, which can serve as guidelines for practical usage. Furthermore, based on\nour empirical results, we analyze the suitability of each concept drift\ndetection group to be used as alarming system.",
    "descriptor": "",
    "authors": [
      "Lorena Poenaru-Olaru",
      "Luis Cruz",
      "Arie van Deursen",
      "Jan S. Rellermeyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13098"
  },
  {
    "id": "arXiv:2211.13101",
    "title": "High-Quality Fault Resiliency in Fat Trees",
    "abstract": "Coupling regular topologies with optimised routing algorithms is key in\npushing the performance of interconnection networks of supercomputers.In this\npaper we present Dmodc, a fast deterministic routing algorithm for Parallel\nGeneralised Fat-Trees (PGFTs) which minimises congestion risk even under\nmassive network degradation caused by equipment failure.Dmodc computes\nforwarding tables with a closed-form arithmetic formula by relying on a fast\npreprocessing phase.This allows complete re-routing of networks with tens of\nthousands of nodes in less than a second.In turn, this greatly helps\ncentralised fabric management react to faults with high-quality routing tables\nand no impact to running applications in current and future very large-scale\nHPC clusters.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2211.11817\n",
    "authors": [
      "John Gliksberg",
      "Antoine Capra",
      "Alexandre Louvet",
      "Pedro Javier Garcia",
      "Devan Sohier"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.13101"
  },
  {
    "id": "arXiv:2211.13104",
    "title": "Mixed Signals: Analyzing Software Attribution Challenges in the Android  Ecosystem",
    "abstract": "The ability to identify the author responsible for a given software object is\ncritical for many research studies and for enhancing software transparency and\naccountability. However, as opposed to other application markets like iOS,\nattribution in the Android ecosystem is known to be hard. Prior research has\nleveraged market metadata and signing certificates to identify software authors\nwithout questioning the validity and accuracy of these attribution signals.\nHowever, Android app authors can, either intentionally or by mistake, hide\ntheir true identity due to: (1) the lack of policy enforcement by markets to\nensure the accuracy and correctness of the information disclosed by developers\nin their market profiles during the app release process, and (2) the use of\nself-signed certificates for signing apps instead of certificates issued by\ntrusted CAs.\nIn this paper, we perform the first empirical analysis of the availability,\nvolatility and overall aptness of publicly available metadata for author\nattribution in Android app markets. To that end, we analyze a dataset of over\n2.5 million market entries and apps extracted from five Android markets for\nover two years. Our results show that widely used attribution signals are often\nmissing from market profiles and that they change over time. We also invalidate\nthe general belief about the validity of signing certificates for author\nattribution. For instance, we find that apps from different authors share\nsigning certificates due to the proliferation of app building frameworks and\nsoftware factories. Finally, we introduce the concept of attribution graph and\nwe apply it to evaluate the validity of existing attribution signals on the\nGoogle Play Store. Our results confirm that the lack of control over publicly\navailable signals can confuse the attribution process.",
    "descriptor": "",
    "authors": [
      "Kaspar Hageman",
      "\u00c1lvaro Feal",
      "Julien Gamba",
      "Aniketh Girish",
      "Jakob Bleier",
      "Martina Lindorfer",
      "Juan Tapiador",
      "Narseo Vallina-Rodriguez"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.13104"
  },
  {
    "id": "arXiv:2211.13108",
    "title": "Integral Continual Learning Along the Tangent Vector Field of Tasks",
    "abstract": "We propose a continual learning method which incorporates information from\nspecialized datasets incrementally, by integrating it along the vector field of\n\"generalist\" models. The tangent plane to the specialist model acts as a\ngeneralist guide and avoids the kind of over-fitting that leads to catastrophic\nforgetting, while exploiting the convexity of the optimization landscape in the\ntangent plane. It maintains a small fixed-size memory buffer, as low as 0.4% of\nthe source datasets, which is updated by simple resampling. Our method achieves\nstate-of-the-art across various buffer sizes for different datasets.\nSpecifically, in the class-incremental setting we outperform the existing\nmethods by an average of 26.24% and 28.48%, for Seq-CIFAR-10 and\nSeq-TinyImageNet respectively. Our method can easily be combined with existing\nreplay-based continual learning methods. When memory buffer constraints are\nrelaxed to allow storage of other metadata such as logits, we attain\nstate-of-the-art accuracy with an error reduction of 36% towards the paragon\nperformance on Seq-CIFAR-10.",
    "descriptor": "",
    "authors": [
      "Tian Yu Liu",
      "Aditya Golatkar",
      "Stefano Soatto",
      "Alessandro Achille"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13108"
  },
  {
    "id": "arXiv:2211.13110",
    "title": "Compiler Provenance Recovery for Multi-CPU Architectures Using a  Centrifuge Mechanism",
    "abstract": "Bit-stream recognition (BSR) has many applications, such as forensic\ninvestigations, detection of copyright infringement, and malware analysis. We\npropose the first BSR that takes a bare input bit-stream and outputs a class\nlabel without any preprocessing. To achieve our goal, we propose a centrifuge\nmechanism, where the upstream layers (sub-net) capture global features and tell\nthe downstream layers (main-net) to switch the focus, even if a part of the\ninput bit-stream has the same value. We applied the centrifuge mechanism to\ncompiler provenance recovery, a type of BSR, and achieved excellent\nclassification. Additionally, downstream transfer learning (DTL), one of the\nlearning methods we propose for the centrifuge mechanism, pre-trains the\nmain-net using the sub-net's ground truth instead of the sub-net's output. We\nfound that sub-predictions made by DTL tend to be highly accurate when the\nsub-label classification contributes to the essence of the main prediction.",
    "descriptor": "\nComments: 8 pages, 4 figures, 5 tables\n",
    "authors": [
      "Yuhei Otsubo",
      "Akira Otsuka",
      "Mamoru Mimura"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.13110"
  },
  {
    "id": "arXiv:2211.13112",
    "title": "This is the way: designing and compiling LEPISZCZE, a comprehensive NLP  benchmark for Polish",
    "abstract": "The availability of compute and data to train larger and larger language\nmodels increases the demand for robust methods of benchmarking the true\nprogress of LM training. Recent years witnessed significant progress in\nstandardized benchmarking for English. Benchmarks such as GLUE, SuperGLUE, or\nKILT have become de facto standard tools to compare large language models.\nFollowing the trend to replicate GLUE for other languages, the KLEJ benchmark\nhas been released for Polish. In this paper, we evaluate the progress in\nbenchmarking for low-resourced languages. We note that only a handful of\nlanguages have such comprehensive benchmarks. We also note the gap in the\nnumber of tasks being evaluated by benchmarks for resource-rich English/Chinese\nand the rest of the world. In this paper, we introduce LEPISZCZE (the Polish\nword for glew, the Middle English predecessor of glue), a new, comprehensive\nbenchmark for Polish NLP with a large variety of tasks and high-quality\noperationalization of the benchmark. We design LEPISZCZE with flexibility in\nmind. Including new models, datasets, and tasks is as simple as possible while\nstill offering data versioning and model tracking. In the first run of the\nbenchmark, we test 13 experiments (task and dataset pairs) based on the five\nmost recent LMs for Polish. We use five datasets from the Polish benchmark and\nadd eight novel datasets. As the paper's main contribution, apart from\nLEPISZCZE, we provide insights and experiences learned while creating the\nbenchmark for Polish as the blueprint to design similar benchmarks for other\nlow-resourced languages.",
    "descriptor": "\nComments: 10 pages, 8 pages appendix\n",
    "authors": [
      "\u0141ukasz Augustyniak",
      "Kamil Tagowski",
      "Albert Sawczyn",
      "Denis Janiak",
      "Roman Bartusiak",
      "Adrian Szymczak",
      "Marcin W\u0105troba",
      "Arkadiusz Janz",
      "Piotr Szyma\u0144ski",
      "Miko\u0142aj Morzy",
      "Tomasz Kajdanowicz",
      "Maciej Piasecki"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13112"
  },
  {
    "id": "arXiv:2211.13114",
    "title": "Step Counting with Attention-based LSTM",
    "abstract": "Physical activity is recognized as an essential component of overall health.\nOne measure of physical activity, the step count, is well known as a predictor\nof long-term morbidity and mortality. Step Counting (SC) is the automated\ncounting of the number of steps an individual takes over a specified period of\ntime and space. Due to the ubiquity of smartphones and smartwatches, most\ncurrent SC approaches rely on the built-in accelerometer sensors on these\ndevices. The sensor signals are analyzed as multivariate time series, and the\nnumber of steps is calculated through a variety of approaches, such as\ntime-domain, frequency-domain, machine-learning, and deep-learning approaches.\nMost of the existing approaches rely on dividing the input signal into windows,\ndetecting steps in each window, and summing the detected steps. However, these\napproaches require the determination of multiple parameters, including the\nwindow size. Furthermore, most of the existing deep-learning SC approaches\nrequire ground-truth labels for every single step, which can be arduous and\ntime-consuming to annotate. To circumvent these requirements, we present a\nnovel SC approach utilizing many-to-one attention-based LSTM. With the proposed\nLSTM network, SC is solved as a regression problem, taking the entire sensor\nsignal as input and the step count as the output. The analysis shows that the\nattention-based LSTM automatically learned the pattern of steps even in the\nabsence of ground-truth labels. The experimental results on three publicly\navailable SC datasets demonstrate that the proposed method successfully counts\nthe number of steps with low values of mean absolute error and high values of\nSC accuracy.",
    "descriptor": "",
    "authors": [
      "Shehroz S. Khan",
      "Ali Abedi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.13114"
  },
  {
    "id": "arXiv:2211.13116",
    "title": "Fed-TDA: Federated Tabular Data Augmentation on Non-IID Data",
    "abstract": "Non-independent and identically distributed (non-IID) data is a key challenge\nin federated learning (FL), which usually hampers the optimization convergence\nand the performance of FL. Existing data augmentation methods based on\nfederated generative models or raw data sharing strategies for solving the\nnon-IID problem still suffer from low performance, privacy protection concerns,\nand high communication overhead in decentralized tabular data. To tackle these\nchallenges, we propose a federated tabular data augmentation method, named\nFed-TDA. The core idea of Fed-TDA is to synthesize tabular data for data\naugmentation using some simple statistics (e.g., distributions of each column\nand global covariance). Specifically, we propose the multimodal distribution\ntransformation and inverse cumulative distribution mapping respectively\nsynthesize continuous and discrete columns in tabular data from a noise\naccording to the pre-learned statistics. Furthermore, we theoretically analyze\nthat our Fed-TDA not only preserves data privacy but also maintains the\ndistribution of the original data and the correlation between columns. Through\nextensive experiments on five real-world tabular datasets, we demonstrate the\nsuperiority of Fed-TDA over the state-of-the-art in test performance and\ncommunication efficiency.",
    "descriptor": "",
    "authors": [
      "Shaoming Duan",
      "Chuanyi Liu",
      "Peiyi Han",
      "Tianyu He",
      "Yifeng Xu",
      "Qiyuan Deng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.13116"
  },
  {
    "id": "arXiv:2211.13118",
    "title": "Branch-and-Bound with Barrier: Dominance and Suboptimality Detection for  DD-Based Branch-and-Bound",
    "abstract": "The branch-and-bound algorithm based on decision diagrams introduced by\nBergman et al. in 2016 is a framework for solving discrete optimization\nproblems with a dynamic programming formulation. It works by compiling a series\nof bounded-width decision diagrams that can provide lower and upper bounds for\nany given subproblem. Eventually, every part of the search space will be either\nexplored or pruned by the algorithm, thus proving optimality. This paper\npresents new ingredients to speed up the search by exploiting the structure of\ndynamic programming models. The key idea is to prevent the repeated exploration\nof nodes corresponding to the same dynamic programming states by storing and\nquerying thresholds in a data structure called the Barrier. These thresholds\nare based on dominance relations between partial solutions previously found.\nThey can be further strengthened by integrating the filtering techniques\nintroduced by Gillard et al. in 2021. Computational experiments show that the\npruning brought by the Barrier allows to significantly reduce the number of\nnodes expanded by the algorithm. This results in more benchmark instances of\ndifficult optimization problems being solved in less time while using narrower\ndecision diagrams.",
    "descriptor": "\nComments: Submitted to INFORMS Journal on Computing\n",
    "authors": [
      "Vianney Copp\u00e9",
      "Xavier Gillard",
      "Pierre Schaus"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.13118"
  },
  {
    "id": "arXiv:2211.13121",
    "title": "#Secim2023: First Public Dataset for Studying Turkish General Election",
    "abstract": "In the context of Turkey's upcoming parliamentary and presidential elections\n(\"se\\c{c}im\" in Turkish), social media is playing an important role in shaping\npublic debate. The increasing engagement of citizens on social media platforms\nhas led to the growing use of social media by political actors. It is of utmost\nimportance to capture the upcoming Turkish elections, as social media is\nbecoming an essential component of election propaganda, political debates,\nsmear campaigns, and election manipulation by domestic and international\nactors. We provide a comprehensive dataset for social media researchers to\nstudy the upcoming election, develop tools to prevent online manipulation, and\ngather novel information to inform the public. We are committed to continually\nimproving the data collection and updating it regularly leading up to the\nelection. Using the Secim2023 dataset, researchers can examine the social and\ncommunication networks between political actors, track current trends, and\ninvestigate emerging threats to election integrity. Our dataset is available\nat: https://github.com/ViralLab/Secim2023_Dataset",
    "descriptor": "\nComments: 22 pages, 9 figures\n",
    "authors": [
      "Ali Najafi",
      "Nihat Mugurtay",
      "Ege Demirci",
      "Serhat Demirkiran",
      "Huseyin Alper Karadeniz",
      "Onur Varol"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.13121"
  },
  {
    "id": "arXiv:2211.13123",
    "title": "Motif-aware temporal GCN for fraud detection in signed cryptocurrency  trust networks",
    "abstract": "Graph convolutional networks (GCNs) is a class of artificial neural networks\nfor processing data that can be represented as graphs. Since financial\ntransactions can naturally be constructed as graphs, GCNs are widely applied in\nthe financial industry, especially for financial fraud detection. In this\npaper, we focus on fraud detection on cryptocurrency truct networks. In the\nliterature, most works focus on static networks. Whereas in this study, we\nconsider the evolving nature of cryptocurrency networks, and use local\nstructural as well as the balance theory to guide the training process. More\nspecifically, we compute motif matrices to capture the local topological\ninformation, then use them in the GCN aggregation process. The generated\nembedding at each snapshot is a weighted average of embeddings within a time\nwindow, where the weights are learnable parameters. Since the trust networks is\nsigned on each edge, balance theory is used to guide the training process.\nExperimental results on bitcoin-alpha and bitcoin-otc datasets show that the\nproposed model outperforms those in the literature.",
    "descriptor": "",
    "authors": [
      "Chong Mo",
      "Song Li",
      "Geoffrey K. F. Tso",
      "Jiandong Zhou",
      "Yiyan Qi",
      "Mingjie Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Trading and Market Microstructure (q-fin.TR)"
    ],
    "url": "https://arxiv.org/abs/2211.13123"
  },
  {
    "id": "arXiv:2211.13124",
    "title": "Number Theory Meets Linguistics: Modelling Noun Pluralisation Across  1497 Languages Using 2-adic Metrics",
    "abstract": "A simple machine learning model of pluralisation as a linear regression\nproblem minimising a p-adic metric substantially outperforms even the most\nrobust of Euclidean-space regressors on languages in the Indo-European,\nAustronesian, Trans New-Guinea, Sino-Tibetan, Nilo-Saharan, Oto-Meanguean and\nAtlantic-Congo language families. There is insufficient evidence to support\nmodelling distinct noun declensions as a p-adic neighbourhood even in\nIndo-European languages.",
    "descriptor": "\nComments: Accepted into AACL-IJCNLP 2022\n",
    "authors": [
      "Gregory Baker",
      "Diego Molla-Aliod"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2211.13124"
  },
  {
    "id": "arXiv:2211.13126",
    "title": "Crown-CAM: Reliable Visual Explanations for Tree Crown Detection in  Aerial Images",
    "abstract": "Visual explanation of \"black-box\" models has enabled researchers and experts\nin artificial intelligence (AI) to exploit the localization abilities of such\nmethods to a much greater extent. Despite most of the developed visual\nexplanation methods applied to single object classification problems, they are\nnot well-explored in the detection task, where the challenges may go beyond\nsimple coarse area-based discrimination. This is of particular importance when\na detector should face several objects with different scales from various\nviewpoints or if the objects of interest are absent. In this paper, we propose\nCrownCAM to generate reliable visual explanations for the challenging and\ndynamic problem of tree crown detection in aerial images. It efficiently\nprovides fine-grain localization of tree crowns and non-contextual background\nsuppression for scenarios with highly dense forest trees in the presence of\npotential distractors or scenes without tree crowns. Additionally, two\nIntersection over Union (IoU)-based metrics are introduced that can effectively\nquantify both the accuracy and inaccuracy of generated visual explanations with\nrespect to regions with or without tree crowns in the image. Empirical\nevaluations demonstrate that the proposed Crown-CAM outperforms the Score-CAM,\nAugmented ScoreCAM, and Eigen-CAM methods by an average IoU margin of 8.7, 5.3,\nand 21.7 (and 3.3, 9.8, and 16.5) respectively in improving the accuracy (and\ndecreasing inaccuracy) of visual explanations on the challenging NEON tree\ncrown dataset.",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Seyed Mojtaba Marvasti-Zadeh",
      "Devin Goodsman",
      "Nilanjan Ray",
      "Nadir Erbilgin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13126"
  },
  {
    "id": "arXiv:2211.13130",
    "title": "A Brief Overview of AI Governance for Responsible Machine Learning  Systems",
    "abstract": "Organizations of all sizes, across all industries and domains are leveraging\nartificial intelligence (AI) technologies to solve some of their biggest\nchallenges around operations, customer experience, and much more. However, due\nto the probabilistic nature of AI, the risks associated with it are far greater\nthan traditional technologies. Research has shown that these risks can range\nanywhere from regulatory, compliance, reputational, and user trust, to\nfinancial and even societal risks. Depending on the nature and size of the\norganization, AI technologies can pose a significant risk, if not used in a\nresponsible way. This position paper seeks to present a brief introduction to\nAI governance, which is a framework designed to oversee the responsible use of\nAI with the goal of preventing and mitigating risks. Having such a framework\nwill not only manage risks but also gain maximum value out of AI projects and\ndevelop consistency for organization-wide adoption of AI.",
    "descriptor": "\nComments: NeurIPS 2022 Trustworthy and Socially Responsible Machine Learning (TSRML) Workshop\n",
    "authors": [
      "Navdeep Gill",
      "Abhishek Mathur",
      "Marcos V. Conde"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13130"
  },
  {
    "id": "arXiv:2211.13131",
    "title": "FeTrIL: Feature Translation for Exemplar-Free Class-Incremental Learning",
    "abstract": "Exemplar-free class-incremental learning is very challenging due to the\nnegative effect of catastrophic forgetting. A balance between stability and\nplasticity of the incremental process is needed in order to obtain good\naccuracy for past as well as new classes. Existing exemplar-free\nclass-incremental methods focus either on successive fine tuning of the model,\nthus favoring plasticity, or on using a feature extractor fixed after the\ninitial incremental state, thus favoring stability. We introduce a method which\ncombines a fixed feature extractor and a pseudo-features generator to improve\nthe stability-plasticity balance. The generator uses a simple yet effective\ngeometric translation of new class features to create representations of past\nclasses, made of pseudo-features. The translation of features only requires the\nstorage of the centroid representations of past classes to produce their\npseudo-features. Actual features of new classes and pseudo-features of past\nclasses are fed into a linear classifier which is trained incrementally to\ndiscriminate between all classes. The incremental process is much faster with\nthe proposed method compared to mainstream ones which update the entire deep\nmodel. Experiments are performed with three challenging datasets, and different\nincremental settings. A comparison with ten existing methods shows that our\nmethod outperforms the others in most cases.",
    "descriptor": "",
    "authors": [
      "Gr\u00e9goire Petit",
      "Adrian Popescu",
      "Hugo Schindler",
      "David Picard",
      "Bertrand Delezoide"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13131"
  },
  {
    "id": "arXiv:2211.13133",
    "title": "Structural Knowledge Distillation for Object Detection",
    "abstract": "Knowledge Distillation (KD) is a well-known training paradigm in deep neural\nnetworks where knowledge acquired by a large teacher model is transferred to a\nsmall student. KD has proven to be an effective technique to significantly\nimprove the student's performance for various tasks including object detection.\nAs such, KD techniques mostly rely on guidance at the intermediate feature\nlevel, which is typically implemented by minimizing an lp-norm distance between\nteacher and student activations during training. In this paper, we propose a\nreplacement for the pixel-wise independent lp-norm based on the structural\nsimilarity (SSIM). By taking into account additional contrast and structural\ncues, feature importance, correlation and spatial dependence in the feature\nspace are considered in the loss formulation. Extensive experiments on MSCOCO\ndemonstrate the effectiveness of our method across different training schemes\nand architectures. Our method adds only little computational overhead, is\nstraightforward to implement and at the same time it significantly outperforms\nthe standard lp-norms. Moreover, more complex state-of-the-art KD methods using\nattention-based sampling mechanisms are outperformed, including a +3.5 AP gain\nusing a Faster R-CNN R-50 compared to a vanilla model.",
    "descriptor": "",
    "authors": [
      "Philip de Rijk",
      "Lukas Schneider",
      "Marius Cordts",
      "Dariu M. Gavrila"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13133"
  },
  {
    "id": "arXiv:2211.13137",
    "title": "Pruned Lightweight Encoders for Computer Vision",
    "abstract": "Latency-critical computer vision systems, such as autonomous driving or drone\ncontrol, require fast image or video compression when offloading neural network\ninference to a remote computer. To ensure low latency on a near-sensor edge\ndevice, we propose the use of lightweight encoders with constant bitrate and\npruned encoding configurations, namely, ASTC and JPEG XS. Pruning introduces\nsignificant distortion which we show can be recovered by retraining the neural\nnetwork with compressed data after decompression. Such an approach does not\nmodify the network architecture or require coding format modifications. By\nretraining with compressed datasets, we reduced the classification accuracy and\nsegmentation mean intersection over union (mIoU) degradation due to ASTC\ncompression to 4.9-5.0 percentage points (pp) and 4.4-4.0 pp, respectively.\nWith the same method, the mIoU lost due to JPEG XS compression at the main\nprofile was restored to 2.7-2.3 pp. In terms of encoding speed, our ASTC\nencoder implementation is 2.3x faster than JPEG. Even though the JPEG XS\nreference encoder requires optimizations to reach low latency, we showed that\ndisabling significance flag coding saves 22-23% of encoding time at the cost of\n0.4-0.3 mIoU after retraining.",
    "descriptor": "",
    "authors": [
      "Jakub \u017d\u00e1dn\u00edk",
      "Markku M\u00e4kitalo",
      "Pekka J\u00e4\u00e4skel\u00e4inen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13137"
  },
  {
    "id": "arXiv:2211.13140",
    "title": "The Functional Machine Calculus II: Semantics",
    "abstract": "The Functional Machine Calculus (FMC), recently introduced by the authors, is\na generalization of the lambda-calculus which may faithfully encode the effects\nof higher-order mutable store, I/O and probabilistic/non-deterministic input.\nSignificantly, it remains confluent and can be simply typed in the presence of\nthese effects. In this paper, we explore the denotational semantics of the FMC.\nWe have three main contributions: first, we argue that its syntax -- in which\nboth effects and lambda-calculus are realised using the same syntactic\nconstructs -- is semantically natural, corresponding closely to the structure\nof a Scott-style domain theoretic semantics. Second, we show that simple types\nconfer strong normalization by extending Gandy's proof for the lambda-calculus,\nincluding a small simplification of the technique. Finally, we show that the\ntyped FMC (without considering the specifics of encoded effects), modulo an\nappropriate equational theory, is a complete language for Cartesian closed\ncategories.",
    "descriptor": "\nComments: 40 pages, to be published in Computer Science Logic 2023\n",
    "authors": [
      "Chris Barrett",
      "Willem Heijltjes",
      "Guy McCusker"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2211.13140"
  },
  {
    "id": "arXiv:2211.13152",
    "title": "Introducing topography in convolutional neural networks",
    "abstract": "Parts of the brain that carry sensory tasks are organized topographically:\nnearby neurons are responsive to the same properties of input signals. Thus, in\nthis work, inspired by the neuroscience literature, we proposed a new\ntopographic inductive bias in Convolutional Neural Networks (CNNs). To achieve\nthis, we introduced a new topographic loss and an efficient implementation to\ntopographically organize each convolutional layer of any CNN. We benchmarked\nour new method on 4 datasets and 3 models in vision and audio tasks and showed\nequivalent performance to all benchmarks. Besides, we also showcased the\ngeneralizability of our topographic loss with how it can be used with different\ntopographic organizations in CNNs. Finally, we demonstrated that adding the\ntopographic inductive bias made CNNs more resistant to pruning. Our approach\nprovides a new avenue to obtain models that are more memory efficient while\nmaintaining better accuracy.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Maxime Poli",
      "Emmanuel Dupoux",
      "Rachid Riad"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.13152"
  },
  {
    "id": "arXiv:2211.13170",
    "title": "The World of Graph Databases from An Industry Perspective",
    "abstract": "Rapidly growing social networks and other graph data have created a high\ndemand for graph technologies in the market. A plethora of graph databases,\nsystems, and solutions have emerged, as a result. On the other hand, graph has\nlong been a well studied area in the database research community. Despite the\nnumerous surveys on various graph research topics, there is a lack of survey on\ngraph technologies from an industry perspective. The purpose of this paper is\nto provide the research community with an industrial perspective on the graph\ndatabase landscape, so that graph researcher can better understand the industry\ntrend and the challenges that the industry is facing, and work on solutions to\nhelp address these problems.",
    "descriptor": "\nComments: 8 papers, 3 figures, to appear in SIGMOD Record\n",
    "authors": [
      "Yuanyuan Tian"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.13170"
  },
  {
    "id": "arXiv:2211.13171",
    "title": "Query Efficient Cross-Dataset Transferable Black-Box Attack on Action  Recognition",
    "abstract": "Black-box adversarial attacks present a realistic threat to action\nrecognition systems. Existing black-box attacks follow either a query-based\napproach where an attack is optimized by querying the target model, or a\ntransfer-based approach where attacks are generated using a substitute model.\nWhile these methods can achieve decent fooling rates, the former tends to be\nhighly query-inefficient while the latter assumes extensive knowledge of the\nblack-box model's training data. In this paper, we propose a new attack on\naction recognition that addresses these shortcomings by generating\nperturbations to disrupt the features learned by a pre-trained substitute model\nto reduce the number of queries. By using a nearly disjoint dataset to train\nthe substitute model, our method removes the requirement that the substitute\nmodel be trained using the same dataset as the target model, and leverages\nqueries to the target model to retain the fooling rate benefits provided by\nquery-based methods. This ultimately results in attacks which are more\ntransferable than conventional black-box attacks. Through extensive\nexperiments, we demonstrate highly query-efficient black-box attacks with the\nproposed framework. Our method achieves 8% and 12% higher deception rates\ncompared to state-of-the-art query-based and transfer-based attacks,\nrespectively.",
    "descriptor": "",
    "authors": [
      "Rohit Gupta",
      "Naveed Akhtar",
      "Gaurav Kumar Nayak",
      "Ajmal Mian",
      "Mubarak Shah"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.13171"
  },
  {
    "id": "arXiv:2211.13173",
    "title": "Average Token Delay: A Latency Metric for Simultaneous Translation",
    "abstract": "Simultaneous translation is a task in which translation begins before the\nspeaker has finished speaking. In its evaluation, we have to consider the\nlatency of the translation in addition to the quality. The latency is\npreferably as small as possible for users to comprehend what the speaker says\nwith a small delay. Existing latency metrics focus on when the translation\nstarts but do not consider adequately when the translation ends. This means\nsuch metrics do not penalize the latency caused by a long translation output,\nwhich actually delays users' comprehension. In this work, we propose a novel\nlatency evaluation metric called Average Token Delay (ATD) that focuses on the\nend timings of partial translations in simultaneous translation. We discuss the\nadvantage of ATD using simulated examples and also investigate the differences\nbetween ATD and Average Lagging with simultaneous translation experiments.",
    "descriptor": "",
    "authors": [
      "Yasumasa Kano",
      "Katsuhito Sudoh",
      "Satoshi Nakamura"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.13173"
  },
  {
    "id": "arXiv:2211.13174",
    "title": "Evolutionary Generalized Zero-Shot Learning",
    "abstract": "An open problem on the path to artificial intelligence is generalization from\nthe known to the unknown, which is instantiated as Generalized Zero-Shot\nLearning (GZSL) task. In this work, we propose a novel Evolutionary Generalized\nZero-Shot Learning setting, which (i) avoids the domain shift problem in\ninductive GZSL, and (ii) is more in line with the needs of real-world\ndeployments than transductive GZSL. In the proposed setting, a zero-shot model\nwith poor initial performance is able to achieve online evolution during\napplication. We elaborate on three challenges of this special task, i.e.,\ncatastrophic forgetting, initial prediction bias, and evolutionary data class\nbias. Moreover, we propose targeted solutions for each challenge, resulting in\na generic method capable of continuing to evolve on a given initial IGZSL\nmodel. Experiments on three popular GZSL benchmark datasets show that our model\ncan learn from the test data stream while other baselines fail.",
    "descriptor": "",
    "authors": [
      "Dubing Chen",
      "Haofeng Zhang",
      "Yuming Shen",
      "Yang Long",
      "Ling Shao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.13174"
  },
  {
    "id": "arXiv:2211.13175",
    "title": "Ordered sorting of cluttered objects using multiple mobile manipulators",
    "abstract": "We present a search-based planning algorithm to sort objects in clutter using\na multi-robot team. We consider the object rearrangement problem in which the\nobjects must be sorted into different groups in a particular order. In clutter,\nthe order constraints could not be easily satisfied since some objects occlude\nother objects. Those objects occluding others need to be moved more than once\nto make the occluded objects accessible. This nonmonotone class of the\nrearrangement prob- lem with order constraints becomes harder if multiple\nrobots are involved, which practically mandates proper computations of robot\nallocations. The proposed method first finds a sequence of objects to be sorted\nusing a search such that the order constraint in each group is satisfied. The\nsearch can solve nonmonotone instances that require temporal relocation of some\nobjects to access the next object to be sorted. Once a complete sorting\nsequence is found, the objects in the sequence are assigned to multiple mobile\nmanipulators using a greedy allocation method. We develop four versions of the\nmethod with different search strategies. In the experiments, we show that our\nmethod can find a sorting sequence quickly (e.g., 4.6 sec with 20 objects\nsorted into five groups) even though the solved instances include hard\nnonmonotone ones. The extensive tests and the experiments in simulation show\nthe ability of the method to solve the real-world sorting problem using\nmultiple mobile manipulators.",
    "descriptor": "",
    "authors": [
      "Jeeho Ahn",
      "Sebin Lee",
      "Changjoo Nam"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.13175"
  },
  {
    "id": "arXiv:2211.13182",
    "title": "Cascade: An Application Pipelining Toolkit for Coarse-Grained  Reconfigurable Arrays",
    "abstract": "While coarse-grained reconfigurable arrays (CGRAs) have emerged as promising\nprogrammable accelerator architectures, pipelining applications running on\nCGRAs is required to ensure high maximum clock frequencies. Current CGRA\ncompilers either lack pipelining techniques resulting in low performance or\nperform exhaustive pipelining resulting in high energy and resource\nconsumption. We introduce Cascade, an application pipelining toolkit for CGRAs,\nincluding a CGRA application frequency model, automated pipelining techniques\nfor CGRA application compilers that work with both dense and sparse\napplications, and hardware optimizations for improving application frequency.\nCascade enables 7 - 34x lower critical path delays and 7 - 190x lower EDP\nacross a variety of dense image processing and machine learning workloads, and\n2 - 4.4x lower critical path delays and 1.5 - 4.2x lower EDP on sparse\nworkloads, compared to a compiler without pipelining.",
    "descriptor": "\nComments: Preprint version\n",
    "authors": [
      "Jackson Melchert",
      "Yuchen Mei",
      "Kalhan Koul",
      "Qiaoyi Liu",
      "Mark Horowitz",
      "Priyanka Raina"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2211.13182"
  },
  {
    "id": "arXiv:2211.13183",
    "title": "Precision Medicine for the Population-The Hope and Hype of Public Health  Genomics",
    "abstract": "Public health is the most recent of the biomedical sciences to be seduced by\nthe trendy moniker \"precision.\" Advocates for \"precision public health\" (PPH)\ncall for a data-driven, computational approach to public health, leveraging\nswaths of genomic \"big data\" to inform public health decision-making. Yet, like\nprecision medicine, PPH oversells the value of genomic data to determine health\noutcomes, but on a population-level. A large historical literature has shown\nthat over-emphasizing heredity tends to disproportionately harm underserved\nminorities and disadvantaged communities. By comparing and contrasting PPH with\nan earlier attempt at using big data and genetics, in the Progressive era\n(1890-1920), we highlight some potential risks of a genotype-driven preventive\npublic health. We conclude by suggesting that such risks may be avoided by\nprioritizing data integration across many levels of analysis, from the\nmolecular to the social.",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "JunBo Wu",
      "Nathaniel Comfort"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2211.13183"
  },
  {
    "id": "arXiv:2211.13184",
    "title": "TorchScale: Transformers at Scale",
    "abstract": "Large Transformers have achieved state-of-the-art performance across many\ntasks. Most open-source libraries on scaling Transformers focus on improving\ntraining or inference with better parallelization. In this work, we present\nTorchScale, an open-source toolkit that allows researchers and developers to\nscale up Transformers efficiently and effectively. TorchScale has the\nimplementation of several modeling techniques, which can improve modeling\ngenerality and capability, as well as training stability and efficiency.\nExperimental results on language modeling and neural machine translation\ndemonstrate that TorchScale can successfully scale Transformers to different\nsizes without tears. The library is available at https://aka.ms/torchscale.",
    "descriptor": "\nComments: Work in progress\n",
    "authors": [
      "Shuming Ma",
      "Hongyu Wang",
      "Shaohan Huang",
      "Wenhui Wang",
      "Zewen Chi",
      "Li Dong",
      "Alon Benhaim",
      "Barun Patra",
      "Vishrav Chaudhary",
      "Xia Song",
      "Furu Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.13184"
  },
  {
    "id": "arXiv:2211.13185",
    "title": "BaRe-ESA: A Riemannian Framework for Unregistered Human Body Shapes",
    "abstract": "We present BaRe-ESA, a novel Riemannian framework for human body scan\nrepresentation, interpolation and extrapolation. BaRe-ESA operates directly on\nunregistered meshes, i.e., without the need to establish prior point to point\ncorrespondences or to assume a consistent mesh structure. Our method relies on\na latent space representation, which is equipped with a Riemannian\n(non-Euclidean) metric associated to an invariant higher-order metric on the\nspace of surfaces. Experimental results on the FAUST and DFAUST datasets show\nthat BaRe-ESA brings significant improvements with respect to previous\nsolutions in terms of shape registration, interpolation and extrapolation. The\nefficiency and strength of our model is further demonstrated in applications\nsuch as motion transfer and random generation of body shape and pose.",
    "descriptor": "\nComments: 12 pages, 7 figures, 2 tables\n",
    "authors": [
      "Emmanuel Hartman",
      "Emery Pierson",
      "Martin Bauer",
      "Nicolas Charon",
      "Mohamed Daoudi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13185"
  },
  {
    "id": "arXiv:2211.13189",
    "title": "ASiT: Audio Spectrogram vIsion Transformer for General Audio  Representation",
    "abstract": "Vision transformers, which were originally developed for natural language\nprocessing, have recently generated significant interest in the computer vision\nand audio communities due to their flexibility in learning long-range\nrelationships. Constrained by data hungry nature of transformers and limited\nlabelled data most transformer-based models for audio tasks are finetuned from\nImageNet pretrained models, despite the huge gap between the natural images\ndomain and audio domain. This has motivated the research in self-supervised\npretraining of audio transformers, which reduces the dependency on large\namounts of labeled data and focuses on extracting concise representation of the\naudio spectrograms. In this paper, we propose ASiT, a novel self-supervised\ntransformer for general audio representations that captures local and global\ncontextual information employing group masked model learning and\nself-distillation. We evaluate our pretrained models on both audio and speech\nclassification tasks including audio event classification, keyword spotting,\nand speaker identification. We further conduct comprehensive ablation studies,\nincluding evaluations of different pretraining strategies. The proposed ASiT\nframework significantly boosts the performance on all tasks and sets a new\nstate-of-the-art performance on five audio and speech classification tasks,\noutperforming recent methods, including the approaches that use additional\ndatasets for pretraining. The code and pretrained weights will be made publicly\navailable for the scientific community.",
    "descriptor": "",
    "authors": [
      "Sara Atito",
      "Muhammad Awais",
      "Wenwu Wang",
      "Mark D Plumbley",
      "Josef Kittler"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.13189"
  },
  {
    "id": "arXiv:2211.13190",
    "title": "BiasBed -- Rigorous Texture Bias Evaluation",
    "abstract": "The well-documented presence of texture bias in modern convolutional neural\nnetworks has led to a plethora of algorithms that promote an emphasis on shape\ncues, often to support generalization to new domains. Yet, common datasets,\nbenchmarks and general model selection strategies are missing, and there is no\nagreed, rigorous evaluation protocol. In this paper, we investigate\ndifficulties and limitations when training networks with reduced texture bias.\nIn particular, we also show that proper evaluation and meaningful comparisons\nbetween methods are not trivial. We introduce BiasBed, a testbed for texture-\nand style-biased training, including multiple datasets and a range of existing\nalgorithms. It comes with an extensive evaluation protocol that includes\nrigorous hypothesis testing to gauge the significance of the results, despite\nthe considerable training instability of some style bias methods. Our extensive\nexperiments, shed new light on the need for careful, statistically founded\nevaluation protocols for style bias (and beyond). E.g., we find that some\nalgorithms proposed in the literature do not significantly mitigate the impact\nof style bias at all. With the release of BiasBed, we hope to foster a common\nunderstanding of consistent and meaningful comparisons, and consequently faster\nprogress towards learning methods free of texture bias. Code is available at\nhttps://github.com/D1noFuzi/BiasBed",
    "descriptor": "",
    "authors": [
      "Nikolai Kalischek",
      "Rodrigo C. Daudt",
      "Torben Peters",
      "Jan D. Wegner",
      "Konrad Schindler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13190"
  },
  {
    "id": "arXiv:2211.13194",
    "title": "Indian Commercial Truck License Plate Detection and Recognition for  Weighbridge Automation",
    "abstract": "Detection and recognition of a licence plate is important when automating\nweighbridge services. While many large databases are available for Latin and\nChinese alphanumeric license plates, data for Indian License Plates is\ninadequate. In particular, databases of Indian commercial truck license plates\nare inadequate, despite the fact that commercial vehicle license plate\nrecognition plays a profound role in terms of logistics management and\nweighbridge automation. Moreover, models to recognise license plates are not\neffectively able to generalise to such data due to its challenging nature, and\ndue to the abundant frequency of handwritten license plates, leading to the\nusage of diverse font styles. Thus, a database and effective models to\nrecognise and detect such license plates are crucial. This paper provides a\ndatabase on commercial truck license plates, and using state-of-the-art models\nin real-time object Detection: You Only Look Once Version 7, and SceneText\nRecognition: Permuted Autoregressive Sequence Models, our method outperforms\nthe other cited references where the maximum accuracy obtained was less than\n90%, while we have achieved 95.82% accuracy in our algorithm implementation on\nthe presented challenging license plate dataset. Index Terms- Automatic License\nPlate Recognition, character recognition, license plate detection, vision\ntransformer.",
    "descriptor": "",
    "authors": [
      "Siddharth Agrawal",
      "Keyur D. Joshi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13194"
  },
  {
    "id": "arXiv:2211.13195",
    "title": "Privacy-Preserving Application-to-Application Authentication Using  Dynamic Runtime Behaviors",
    "abstract": "Application authentication is typically performed using some form of secret\ncredentials such as cryptographic keys, passwords, or API keys. Since clients\nare responsible for securely storing and managing the keys, this approach is\nvulnerable to attacks on clients. Similarly a centrally managed key store is\nalso susceptible to various attacks and if compromised, can leak credentials.\nTo resolve such issues, we propose an application authentication, where we rely\non unique and distinguishable application's behavior to lock the key during a\nsetup phase and unlock it for authentication. Our system add a fuzzy-extractor\nlayer on top of current credential authentication systems. During a key\nenrollment process, the application's behavioral data collected from various\nsensors in the network are used to hide the credential key. The fuzzy extractor\nreleases the key to the server if the application's behavior during the\nauthentication matches the one collected during the enrollment, with some noise\ntolerance. We designed the system, analyzed its security, and implemented and\nevaluated it using 10 real-life applications deployed in our network. Our\nsecurity analysis shows that the system is secure against client compromise,\nvault compromise, and feature observation. The evaluation shows the scheme can\nachieve 0 percent False Accept Rate with an average False Rejection Rate 14\npercent and takes about 51 ms to successfully authenticate a client. In light\nof these promising results, we expect our system to be of practical use, since\nits deployment requires zero to minimal changes on the server.",
    "descriptor": "",
    "authors": [
      "Mihai Christodorescu",
      "Maliheh Shirvanian",
      "Shams Zawoad"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.13195"
  },
  {
    "id": "arXiv:2211.13196",
    "title": "SeedBERT: Recovering Annotator Rating Distributions from an Aggregated  Label",
    "abstract": "Many machine learning tasks -- particularly those in affective computing --\nare inherently subjective. When asked to classify facial expressions or to rate\nan individual's attractiveness, humans may disagree with one another, and no\nsingle answer may be objectively correct. However, machine learning datasets\ncommonly have just one \"ground truth\" label for each sample, so models trained\non these labels may not perform well on tasks that are subjective in nature.\nThough allowing models to learn from the individual annotators' ratings may\nhelp, most datasets do not provide annotator-specific labels for each sample.\nTo address this issue, we propose SeedBERT, a method for recovering annotator\nrating distributions from a single label by inducing pre-trained models to\nattend to different portions of the input. Our human evaluations indicate that\nSeedBERT's attention mechanism is consistent with human sources of annotator\ndisagreement. Moreover, in our empirical evaluations using large language\nmodels, SeedBERT demonstrates substantial gains in performance on downstream\nsubjective tasks compared both to standard deep learning models and to other\ncurrent models that account explicitly for annotator disagreement.",
    "descriptor": "\nComments: To be published in AAAI-23 Workshop on Uncertainty Reasoning and Quantification in Decision Making\n",
    "authors": [
      "Aneesha Sampath",
      "Victoria Lin",
      "Louis-Philippe Morency"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2211.13196"
  },
  {
    "id": "arXiv:2211.13202",
    "title": "Lite-Mono: A Lightweight CNN and Transformer Architecture for  Self-Supervised Monocular Depth Estimation",
    "abstract": "Self-supervised monocular depth estimation that does not require ground-truth\nfor training has attracted attention in recent years. It is of high interest to\ndesign lightweight but effective models, so that they can be deployed on edge\ndevices. Many existing architectures benefit from using heavier backbones at\nthe expense of model sizes. In this paper we achieve comparable results with a\nlightweight architecture. Specifically, we investigate the efficient\ncombination of CNNs and Transformers, and design a hybrid architecture\nLite-Mono. A Consecutive Dilated Convolutions (CDC) module and a Local-Global\nFeatures Interaction (LGFI) module are proposed. The former is used to extract\nrich multi-scale local features, and the latter takes advantage of the\nself-attention mechanism to encode long-range global information into the\nfeatures. Experiments demonstrate that our full model outperforms Monodepth2 by\na large margin in accuracy, with about 80% fewer trainable parameters.",
    "descriptor": "",
    "authors": [
      "Ning Zhang",
      "Francesco Nex",
      "George Vosselman",
      "Norman Kerle"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13202"
  },
  {
    "id": "arXiv:2211.13203",
    "title": "Inversion-Based Creativity Transfer with Diffusion Models",
    "abstract": "In this paper, we introduce the task of \"Creativity Transfer\". The artistic\ncreativity within a painting is the means of expression, which includes not\nonly the painting material, colors, and brushstrokes, but also the high-level\nattributes including semantic elements, object shape, etc. Previous arbitrary\nexample-guided artistic image generation methods (e.g., style transfer) often\nfail to control shape changes or convey semantic elements. The pre-trained\ntext-to-image synthesis diffusion probabilistic models have achieved remarkable\nquality, but they often require extensive textual descriptions to accurately\nportray attributes of a particular painting. We believe that the uniqueness of\nan artwork lies precisely in the fact that it cannot be adequately explained\nwith normal language. Our key idea is to learn artistic creativity directly\nfrom a single painting and then guide the synthesis without providing complex\ntextual descriptions. Specifically, we assume creativity as a learnable textual\ndescription of a painting. We propose an attention-based inversion method,\nwhich can efficiently and accurately learn the holistic and detailed\ninformation of an image, thus capturing the complete artistic creativity of a\npainting. We demonstrate the quality and efficiency of our method on numerous\npaintings of various artists and styles. Code and models are available at\nhttps://github.com/zyxElsa/creativity-transfer.",
    "descriptor": "",
    "authors": [
      "Yuxin Zhang",
      "Nisha Huang",
      "Fan Tang",
      "Haibin Huang",
      "Chongyang Ma",
      "Weiming Dong",
      "Changsheng Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.13203"
  },
  {
    "id": "arXiv:2211.13206",
    "title": "ManVatar : Fast 3D Head Avatar Reconstruction Using Motion-Aware Neural  Voxels",
    "abstract": "With NeRF widely used for facial reenactment, recent methods can recover\nphoto-realistic 3D head avatar from just a monocular video. Unfortunately, the\ntraining process of the NeRF-based methods is quite time-consuming, as MLP used\nin the NeRF-based methods is inefficient and requires too many iterations to\nconverge. To overcome this problem, we propose ManVatar, a fast 3D head avatar\nreconstruction method using Motion-Aware Neural Voxels. ManVatar is the first\nto decouple expression motion from canonical appearance for head avatar, and\nmodel the expression motion by neural voxels. In particular, the motion-aware\nneural voxels is generated from the weighted concatenation of multiple 4D\ntensors. The 4D tensors semantically correspond one-to-one with 3DMM expression\nbases and share the same weights as 3DMM expression coefficients. Benefiting\nfrom our novel representation, the proposed ManVatar can recover\nphoto-realistic head avatars in just 5 minutes (implemented with pure PyTorch),\nwhich is significantly faster than the state-of-the-art facial reenactment\nmethods.",
    "descriptor": "\nComments: Project Page: this https URL\n",
    "authors": [
      "Yuelang Xu",
      "Lizhen Wang",
      "Xiaochen Zhao",
      "Hongwen Zhang",
      "Yebin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13206"
  },
  {
    "id": "arXiv:2211.13208",
    "title": "On Instance-Dependent Bounds for Offline Reinforcement Learning with  Linear Function Approximation",
    "abstract": "Sample-efficient offline reinforcement learning (RL) with linear function\napproximation has recently been studied extensively. Much of prior work has\nyielded the minimax-optimal bound of $\\tilde{\\mathcal{O}}(\\frac{1}{\\sqrt{K}})$,\nwith $K$ being the number of episodes in the offline data. In this work, we\nseek to understand instance-dependent bounds for offline RL with function\napproximation. We present an algorithm called Bootstrapped and Constrained\nPessimistic Value Iteration (BCP-VI), which leverages data bootstrapping and\nconstrained optimization on top of pessimism. We show that under a partial data\ncoverage assumption, that of \\emph{concentrability} with respect to an optimal\npolicy, the proposed algorithm yields a fast rate of\n$\\tilde{\\mathcal{O}}(\\frac{1}{K})$ for offline RL when there is a positive gap\nin the optimal Q-value functions, even when the offline data were adaptively\ncollected. Moreover, when the linear features of the optimal actions in the\nstates reachable by an optimal policy span those reachable by the behavior\npolicy and the optimal actions are unique, offline RL achieves absolute zero\nsub-optimality error when $K$ exceeds a (finite) instance-dependent threshold.\nTo the best of our knowledge, these are the first\n$\\tilde{\\mathcal{O}}(\\frac{1}{K})$ bound and absolute zero sub-optimality bound\nrespectively for offline RL with linear function approximation from adaptive\ndata with partial coverage. We also provide instance-agnostic and\ninstance-dependent information-theoretical lower bounds to complement our upper\nbounds.",
    "descriptor": "\nComments: AAAI'23\n",
    "authors": [
      "Thanh Nguyen-Tang",
      "Ming Yin",
      "Sunil Gupta",
      "Svetha Venkatesh",
      "Raman Arora"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13208"
  },
  {
    "id": "arXiv:2211.13217",
    "title": "On the Complexity of Finding a Diverse and Representative Committee  using a Monotone, Separable Positional Multiwinner Voting Rule",
    "abstract": "Fairness in multiwinner elections, a growing line of research in\ncomputational social choice, primarily concerns the use of constraints to\nensure fairness. Recent work proposed a model to find a diverse \\emph{and}\nrepresentative committee and studied the model's computational aspects.\nHowever, the work gave complexity results under major assumptions on how the\ncandidates and the voters are grouped. Here, we close this gap and classify the\ncomplexity of finding a diverse and representative committee using a monotone,\nseparable positional multiwinner voting rule, conditioned \\emph{only} on the\nassumption that P $\\neq$ NP.",
    "descriptor": "\nComments: 2-column format, 8 pages. arXiv admin note: substantial text overlap with arXiv:2107.07356\n",
    "authors": [
      "Kunal Relia"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Artificial Intelligence (cs.AI)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2211.13217"
  },
  {
    "id": "arXiv:2211.13218",
    "title": "CODA-Prompt: COntinual Decomposed Attention-based Prompting for  Rehearsal-Free Continual Learning",
    "abstract": "Computer vision models suffer from a phenomenon known as catastrophic\nforgetting when learning novel concepts from continuously shifting training\ndata. Typical solutions for this continual learning problem require extensive\nrehearsal of previously seen data, which increases memory costs and may violate\ndata privacy. Recently, the emergence of large-scale pre-trained vision\ntransformer models has enabled prompting approaches as an alternative to\ndata-rehearsal. These approaches rely on a key-query mechanism to generate\nprompts and have been found to be highly resistant to catastrophic forgetting\nin the well-established rehearsal-free continual learning setting. However, the\nkey mechanism of these methods is not trained end-to-end with the task\nsequence. Our experiments show that this leads to a reduction in their\nplasticity, hence sacrificing new task accuracy, and inability to benefit from\nexpanded parameter capacity. We instead propose to learn a set of prompt\ncomponents which are assembled with input-conditioned weights to produce\ninput-conditioned prompts, resulting in a novel attention-based end-to-end\nkey-query scheme. Our experiments show that we outperform the current SOTA\nmethod DualPrompt on established benchmarks by as much as 5.4% in average\naccuracy. We also outperform the state of art by as much as 6.6% accuracy on a\ncontinual learning benchmark which contains both class-incremental and\ndomain-incremental task shifts, corresponding to many practical settings.",
    "descriptor": "",
    "authors": [
      "James Seale Smith",
      "Leonid Karlinsky",
      "Vyshnavi Gutta",
      "Paola Cascante-Bonilla",
      "Donghyun Kim",
      "Assaf Arbelle",
      "Rameswar Panda",
      "Rogerio Feris",
      "Zsolt Kira"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13218"
  },
  {
    "id": "arXiv:2211.13219",
    "title": "Automating Rigid Origami Design",
    "abstract": "While rigid origami has shown potential in a large diversity of engineering\napplications, current rigid origami crease pattern designs mostly rely on known\ntessellations. This leaves a potential gap in performance as the space of\nrigidly foldable crease patterns is far larger than these tessellations would\nsuggest. In this work, we build upon the recently developed principle of three\nunits method to formulate rigid origami design as a discrete optimization\nproblem. Our implementation allows for a simple definition of diverse\nobjectives and thereby expands the potential of rigid origami further to\noptimized, application-specific crease patterns. We benchmark a diverse set of\nsearch methods in several shape approximation tasks to validate our model and\nshowcase the flexibility of our formulation through four illustrative case\nstudies. Results show that using our proposed problem formulation one can\nsuccessfully approximate a variety of target shapes. Moreover, by specifying\ncustom reward functions, we can find patterns, which result in novel, foldable\ndesigns for everyday objects.",
    "descriptor": "",
    "authors": [
      "Jeremia Geiger",
      "Karolis Martinkus",
      "Oliver Richter",
      "Roger Wattenhofer"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.13219"
  },
  {
    "id": "arXiv:2211.13220",
    "title": "Tetrahedral Diffusion Models for 3D Shape Generation",
    "abstract": "Recently, probabilistic denoising diffusion models (DDMs) have greatly\nadvanced the generative power of neural networks. DDMs, inspired by\nnon-equilibrium thermodynamics, have not only been used for 2D image\ngeneration, but can also readily be applied to 3D point clouds. However,\nrepresenting 3D shapes as point clouds has a number of drawbacks, most obvious\nperhaps that they have no notion of topology or connectivity. Here, we explore\nan alternative route and introduce tetrahedral diffusion models, an extension\nof DDMs to tetrahedral partitions of 3D space. The much more structured 3D\nrepresentation with space-filling tetrahedra makes it possible to guide and\nregularize the diffusion process and to apply it to colorized assets. To\nmanipulate the proposed representation, we develop tetrahedral convolutions,\ndown- and up-sampling kernels. With those operators, 3D shape generation\namounts to learning displacement vectors and signed distance values on the\ntetrahedral grid. Our experiments confirm that Tetrahedral Diffusion yields\nplausible, visually pleasing and diverse 3D shapes, is able to handle surface\nattributes like color, and can be guided at test time to manipulate the\nresulting shapes.",
    "descriptor": "",
    "authors": [
      "Nikolai Kalischek",
      "Torben Peters",
      "Jan D. Wegner",
      "Konrad Schindler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13220"
  },
  {
    "id": "arXiv:2211.13221",
    "title": "Latent Video Diffusion Models for High-Fidelity Video Generation with  Arbitrary Lengths",
    "abstract": "AI-generated content has attracted lots of attention recently, but\nphoto-realistic video synthesis is still challenging. Although many attempts\nusing GANs and autoregressive models have been made in this area, the visual\nquality and length of generated videos are far from satisfactory. Diffusion\nmodels (DMs) are another class of deep generative models and have recently\nachieved remarkable performance on various image synthesis tasks. However,\ntraining image diffusion models usually requires substantial computational\nresources to achieve a high performance, which makes expanding diffusion models\nto high-dimensional video synthesis tasks more computationally expensive. To\nease this problem while leveraging its advantages, we introduce lightweight\nvideo diffusion models that synthesize high-fidelity and arbitrary-long videos\nfrom pure noise. Specifically, we propose to perform diffusion and denoising in\na low-dimensional 3D latent space, which significantly outperforms previous\nmethods on 3D pixel space when under a limited computational budget. In\naddition, though trained on tens of frames, our models can generate videos with\narbitrary lengths, i.e., thousands of frames, in an autoregressive way.\nFinally, conditional latent perturbation is further introduced to reduce\nperformance degradation during synthesizing long-duration videos. Extensive\nexperiments on various datasets and generated lengths suggest that our\nframework is able to sample much more realistic and longer videos than previous\napproaches, including GAN-based, autoregressive-based, and diffusion-based\nmethods.",
    "descriptor": "\nComments: Project Page: this https URL Github: this https URL\n",
    "authors": [
      "Yingqing He",
      "Tianyu Yang",
      "Yong Zhang",
      "Ying Shan",
      "Qifeng Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.13221"
  },
  {
    "id": "arXiv:2211.13222",
    "title": "SVFormer: Semi-supervised Video Transformer for Action Recognition",
    "abstract": "Semi-supervised action recognition is a challenging but critical task due to\nthe high cost of video annotations. Existing approaches mainly use\nconvolutional neural networks, yet current revolutionary vision transformer\nmodels have been less explored. In this paper, we investigate the use of\ntransformer models under the SSL setting for action recognition. To this end,\nwe introduce SVFormer, which adopts a steady pseudo-labeling framework (ie,\nEMA-Teacher) to cope with unlabeled video samples. While a wide range of data\naugmentations have been shown effective for semi-supervised image\nclassification, they generally produce limited results for video recognition.\nWe therefore introduce a novel augmentation strategy, Tube TokenMix, tailored\nfor video data where video clips are mixed via a mask with consistent masked\ntokens over the temporal axis. In addition, we propose a temporal warping\naugmentation to cover the complex temporal variation in videos, which stretches\nselected frames to various temporal durations in the clip. Extensive\nexperiments on three datasets Kinetics-400, UCF-101, and HMDB-51 verify the\nadvantage of SVFormer. In particular, SVFormer outperforms the state-of-the-art\nby 31.5% with fewer training epochs under the 1% labeling rate of Kinetics-400.\nOur method can hopefully serve as a strong benchmark and encourage future\nsearch on semi-supervised action recognition with Transformer networks.",
    "descriptor": "",
    "authors": [
      "Zhen Xing",
      "Qi Dai",
      "Han Hu",
      "Jingjing Chen",
      "Zuxuan Wu",
      "Yu-Gang Jiang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13222"
  },
  {
    "id": "arXiv:2211.13223",
    "title": "Generalizable Implicit Neural Representations via Instance Pattern  Composers",
    "abstract": "Despite recent advances in implicit neural representations (INRs), it remains\nchallenging for a coordinate-based multi-layer perceptron (MLP) of INRs to\nlearn a common representation across data instances and generalize it for\nunseen instances. In this work, we introduce a simple yet effective framework\nfor generalizable INRs that enables a coordinate-based MLP to represent complex\ndata instances by modulating only a small set of weights in an early MLP layer\nas an instance pattern composer; the remaining MLP weights learn pattern\ncomposition rules for common representations across instances. Our\ngeneralizable INR framework is fully compatible with existing meta-learning and\nhypernetworks in learning to predict the modulated weight for unseen instances.\nExtensive experiments demonstrate that our method achieves high performance on\na wide range of domains such as an audio, image, and 3D object, while the\nablation study validates our weight modulation.",
    "descriptor": "\nComments: 14 pages, 11 figures\n",
    "authors": [
      "Chiheon Kim",
      "Doyup Lee",
      "Saehoon Kim",
      "Minsu Cho",
      "Wook-Shin Han"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13223"
  },
  {
    "id": "arXiv:2211.13224",
    "title": "Peekaboo: Text to Image Diffusion Models are Zero-Shot Segmentors",
    "abstract": "Recent diffusion-based generative models combined with vision-language models\nare capable of creating realistic images from natural language prompts. While\nthese models are trained on large internet-scale datasets, such pre-trained\nmodels are not directly introduced to any semantic localization or grounding.\nMost current approaches for localization or grounding rely on human-annotated\nlocalization information in the form of bounding boxes or segmentation masks.\nThe exceptions are a few unsupervised methods that utilize architectures or\nloss functions geared towards localization, but they need to be trained\nseparately. In this work, we explore how off-the-shelf diffusion models,\ntrained with no exposure to such localization information, are capable of\ngrounding various semantic phrases with no segmentation-specific re-training.\nAn inference time optimization process is introduced, that is capable of\ngenerating segmentation masks conditioned on natural language. We evaluate our\nproposal Peekaboo for unsupervised semantic segmentation on the Pascal VOC\ndataset. In addition, we evaluate for referring segmentation on the RefCOCO\ndataset. In summary, we present a first zero-shot, open-vocabulary,\nunsupervised (no localization information), semantic grounding technique\nleveraging diffusion-based generative models with no re-training. Our code will\nbe released publicly.",
    "descriptor": "\nComments: 19 pages; contains appendix\n",
    "authors": [
      "Ryan Burgert",
      "Kanchana Ranasinghe",
      "Xiang Li",
      "Michael S. Ryoo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13224"
  },
  {
    "id": "arXiv:2211.13225",
    "title": "Learning to Imitate Object Interactions from Internet Videos",
    "abstract": "We study the problem of imitating object interactions from Internet videos.\nThis requires understanding the hand-object interactions in 4D, spatially in 3D\nand over time, which is challenging due to mutual hand-object occlusions. In\nthis paper we make two main contributions: (1) a novel reconstruction technique\nRHOV (Reconstructing Hands and Objects from Videos), which reconstructs 4D\ntrajectories of both the hand and the object using 2D image cues and temporal\nsmoothness constraints; (2) a system for imitating object interactions in a\nphysics simulator with reinforcement learning. We apply our reconstruction\ntechnique to 100 challenging Internet videos. We further show that we can\nsuccessfully imitate a range of different object interactions in a physics\nsimulator. Our object-centric approach is not limited to human-like\nend-effectors and can learn to imitate object interactions using different\nembodiments, like a robotic arm with a parallel jaw gripper.",
    "descriptor": "\nComments: Project page: this https URL\n",
    "authors": [
      "Austin Patel",
      "Andrew Wang",
      "Ilija Radosavovic",
      "Jitendra Malik"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.13225"
  },
  {
    "id": "arXiv:2211.13226",
    "title": "ClimateNeRF: Physically-based Neural Rendering for Extreme Climate  Synthesis",
    "abstract": "Physical simulations produce excellent predictions of weather effects. Neural\nradiance fields produce SOTA scene models. We describe a novel NeRF-editing\nprocedure that can fuse physical simulations with NeRF models of scenes,\nproducing realistic movies of physical phenomena inthose scenes. Our\napplication -- Climate NeRF -- allows people to visualize what climate change\noutcomes will do to them. ClimateNeRF allows us to render realistic weather\neffects, including smog, snow, and flood. Results can be controlled with\nphysically meaningful variables like water level. Qualitative and quantitative\nstudies show that our simulated results are significantly more realistic than\nthose from state-of-the-art 2D image editing and 3D NeRF stylization.",
    "descriptor": "\nComments: project page: this https URL\n",
    "authors": [
      "Yuan Li",
      "Zhi-Hao Lin",
      "David Forsyth",
      "Jia-Bin Huang",
      "Shenlong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.13226"
  },
  {
    "id": "arXiv:2211.13227",
    "title": "Paint by Example: Exemplar-based Image Editing with Diffusion Models",
    "abstract": "Language-guided image editing has achieved great success recently. In this\npaper, for the first time, we investigate exemplar-guided image editing for\nmore precise control. We achieve this goal by leveraging self-supervised\ntraining to disentangle and re-organize the source image and the exemplar.\nHowever, the naive approach will cause obvious fusing artifacts. We carefully\nanalyze it and propose an information bottleneck and strong augmentations to\navoid the trivial solution of directly copying and pasting the exemplar image.\nMeanwhile, to ensure the controllability of the editing process, we design an\narbitrary shape mask for the exemplar image and leverage the classifier-free\nguidance to increase the similarity to the exemplar image. The whole framework\ninvolves a single forward of the diffusion model without any iterative\noptimization. We demonstrate that our method achieves an impressive performance\nand enables controllable editing on in-the-wild images with high fidelity.",
    "descriptor": "\nComments: Code: this https URL\n",
    "authors": [
      "Binxin Yang",
      "Shuyang Gu",
      "Bo Zhang",
      "Ting Zhang",
      "Xuejin Chen",
      "Xiaoyan Sun",
      "Dong Chen",
      "Fang Wen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.13227"
  },
  {
    "id": "arXiv:2211.13228",
    "title": "Self-Supervised Learning based on Heat Equation",
    "abstract": "This paper presents a new perspective of self-supervised learning based on\nextending heat equation into high dimensional feature space. In particular, we\nremove time dependence by steady-state condition, and extend the remaining 2D\nLaplacian from x--y isotropic to linear correlated. Furthermore, we simplify it\nby splitting x and y axes as two first-order linear differential equations.\nSuch simplification explicitly models the spatial invariance along horizontal\nand vertical directions separately, supporting prediction across image blocks.\nThis introduces a very simple masked image modeling (MIM) method, named\nQB-Heat.\nQB-Heat leaves a single block with size of quarter image unmasked and\nextrapolates other three masked quarters linearly. It brings MIM to CNNs\nwithout bells and whistles, and even works well for pre-training light-weight\nnetworks that are suitable for both image classification and object detection\nwithout fine-tuning. Compared with MoCo-v2 on pre-training a Mobile-Former with\n5.8M parameters and 285M FLOPs, QB-Heat is on par in linear probing on\nImageNet, but clearly outperforms in non-linear probing that adds a transformer\nblock before linear classifier (65.6% vs. 52.9%). When transferring to object\ndetection with frozen backbone, QB-Heat outperforms MoCo-v2 and supervised\npre-training on ImageNet by 7.9 and 4.5 AP respectively.\nThis work provides an insightful hypothesis on the invariance within visual\nrepresentation over different shapes and textures: the linear relationship\nbetween horizontal and vertical derivatives. The code will be publicly\nreleased.",
    "descriptor": "",
    "authors": [
      "Yinpeng Chen",
      "Xiyang Dai",
      "Dongdong Chen",
      "Mengchen Liu",
      "Lu Yuan",
      "Zicheng Liu",
      "Youzuo Lin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13228"
  },
  {
    "id": "arXiv:2211.12158",
    "title": "Post's correspondence problem for hyperbolic and virtually nilpotent  groups",
    "abstract": "Post's Correspondence Problem (the PCP) is a classical decision problem in\ntheoretical computer science that asks whether for pairs of free monoid\nmorphisms $g, h\\colon\\Sigma^*\\to\\Delta^*$ there exists any non-trivial\n$x\\in\\Sigma^*$ such that $g(x)=h(x)$.\nPost's Correspondence Problem for a group $\\Gamma$ takes pairs of group\nhomomorphisms $g, h\\colon F(\\Sigma)\\to \\Gamma$ instead, and similarly asks\nwhether there exists an $x$ such that $g(x)=h(x)$ holds for non-elementary\nreasons. The restrictions imposed on $x$ in order to get non-elementary\nsolutions lead to several interpretations of the problem; we consider the\nnatural restriction asking that $x \\notin \\ker(g) \\cap \\ker(h)$ and prove that\nthe resulting interpretation of the PCP is undecidable for arbitrary hyperbolic\n$\\Gamma$, but decidable when $\\Gamma$ is virtually nilpotent. We also study\nthis problem for group constructions such as subgroups, direct products and\nfinite extensions. This problem is equivalent to an interpretation due to\nMyasnikov, Nikolev and Ushakov when one map is injective.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Laura Ciobanu",
      "Alex Levine",
      "Alan D. Logan"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.12158"
  },
  {
    "id": "arXiv:2211.12549",
    "title": "WarpPINN: Cine-MR image registration with physics-informed neural  networks",
    "abstract": "Heart failure is typically diagnosed with a global function assessment, such\nas ejection fraction. However, these metrics have low discriminate power,\nfailing to distinguish different types of this disease. Quantifying local\ndeformations in the form of cardiac strain can provide helpful information, but\nit remains a challenge. In this work, we introduce WarpPINN, a physics-informed\nneural network to perform image registration to obtain local metrics of the\nheart deformation. We apply this method to cine magnetic resonance images to\nestimate the motion during the cardiac cycle. We inform our neural network of\nnear-incompressibility of cardiac tissue by penalizing the jacobian of the\ndeformation field. The loss function has two components: an intensity-based\nsimilarity term between the reference and the warped template images, and a\nregularizer that represents the hyperelastic behavior of the tissue. The\narchitecture of the neural network allows us to easily compute the strain via\nautomatic differentiation to assess cardiac activity. We use Fourier feature\nmappings to overcome the spectral bias of neural networks, allowing us to\ncapture discontinuities in the strain field. We test our algorithm on a\nsynthetic example and on a cine-MRI benchmark of 15 healthy volunteers. We\noutperform current methodologies both landmark tracking and strain estimation.\nWe expect that WarpPINN will enable more precise diagnostics of heart failure\nbased on local deformation information. Source code is available at\nhttps://github.com/fsahli/WarpPINN.",
    "descriptor": "\nComments: 18 pages, 10 figures\n",
    "authors": [
      "Pablo Arratia L\u00f3pez",
      "Hern\u00e1n Mella",
      "Sergio Uribe",
      "Daniel E. Hurtado",
      "Francisco Sahli Costabal"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12549"
  },
  {
    "id": "arXiv:2211.12553",
    "title": "Using conditional variational autoencoders to generate images from  atmospheric Cherenkov telescopes",
    "abstract": "High-energy particles hitting the upper atmosphere of the Earth produce\nextensive air showers that can be detected from the ground level using imaging\natmospheric Cherenkov telescopes. The images recorded by Cherenkov telescopes\ncan be analyzed to separate gamma-ray events from the background hadron events.\nMany of the methods of analysis require simulation of massive amounts of events\nand the corresponding images by the Monte Carlo method. However, Monte Carlo\nsimulation is computationally expensive. The data simulated by the Monte Carlo\nmethod can be augmented by images generated using faster machine learning\nmethods such as generative adversarial networks or conditional variational\nautoencoders. We use a conditional variational autoencoder to generate images\nof gamma events from a Cherenkov telescope of the TAIGA experiment. The\nvariational autoencoder is trained on a set of Monte Carlo events with the\nimage size, or the sum of the amplitudes of the pixels, used as the conditional\nparameter. We used the trained variational autoencoder to generate new images\nwith the same distribution of the conditional parameter as the size\ndistribution of the Monte Carlo-simulated images of gamma events. The generated\nimages are similar to the Monte Carlo images: a classifier neural network\ntrained on gamma and proton events assigns them the average gamma score 0.984,\nwith less than 3% of the events being assigned the gamma score below 0.999. At\nthe same time, the sizes of the generated images do not match the conditional\nparameter used in their generation, with the average error 0.33.",
    "descriptor": "",
    "authors": [
      "Stanislav Polyakov",
      "Alexander Kryukov",
      "Andrey Demichev",
      "Julia Dubenskaya",
      "Elizaveta Gres",
      "Anna Vlaskina"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12553"
  },
  {
    "id": "arXiv:2211.12590",
    "title": "Deep Neural Mel-Subband Beamformer for In-car Speech Separation",
    "abstract": "While current deep learning (DL)-based beamforming techniques have been\nproved effective in speech separation, they are often designed to process\nnarrow-band (NB) frequencies independently which results in higher\ncomputational costs and inference times, making them unsuitable for real-world\nuse. In this paper, we propose DL-based mel-subband spatio-temporal beamformer\nto perform speech separation in a car environment with reduced computation cost\nand inference time. As opposed to conventional subband (SB) approaches, our\nframework uses a mel-scale based subband selection strategy which ensures a\nfine-grained processing for lower frequencies where most speech formant\nstructure is present, and coarse-grained processing for higher frequencies. In\na recursive way, robust frame-level beamforming weights are determined for each\nspeaker location/zone in a car from the estimated subband speech and noise\ncovariance matrices. Furthermore, proposed framework also estimates and\nsuppresses any echoes from the loudspeaker(s) by using the echo reference\nsignals. We compare the performance of our proposed framework to several NB,\nSB, and full-band (FB) processing techniques in terms of speech quality and\nrecognition metrics. Based on experimental evaluations on simulated and\nreal-world recordings, we find that our proposed framework achieves better\nseparation performance over all SB and FB approaches and achieves performance\ncloser to NB processing techniques while requiring lower computing cost.",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Vinay Kothapally",
      "Yong Xu",
      "Meng Yu",
      "Shi-Xiong Zhang",
      "Dong Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.12590"
  },
  {
    "id": "arXiv:2211.12592",
    "title": "Representations of the symmetric group are decomposable in polynomial  time",
    "abstract": "We introduce an algorithm to decompose orthogonal matrix representations of\nthe symmetric group over the reals into irreducible representations, which as a\nby-product also computes the multiplicities of the irreducible representations.\nThe algorithm applied to a $d$-dimensional representation of $S_n$ is shown to\nhave a complexity of $O(n^2 d^3)$ operations for determining multiplicities of\nirreducible representations and a further $O(n d^4)$ operations to fully\ndecompose representations with non-trivial multiplicities. These complexity\nbounds are pessimistic and in a practical implementation using floating point\narithmetic and exploiting sparsity we observe better complexity. We demonstrate\nthis algorithm on the problem of computing multiplicities of two tensor\nproducts of irreducible representations (the Kronecker coefficients problem) as\nwell as higher order tensor products. For hook and hook-like irreducible\nrepresentations the algorithm has polynomial complexity as $n$ increases.",
    "descriptor": "",
    "authors": [
      "Sheehan Olver"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.12592"
  },
  {
    "id": "arXiv:2211.12612",
    "title": "Transfer Learning for Contextual Multi-armed Bandits",
    "abstract": "Motivated by a range of applications, we study in this paper the problem of\ntransfer learning for nonparametric contextual multi-armed bandits under the\ncovariate shift model, where we have data collected on source bandits before\nthe start of the target bandit learning. The minimax rate of convergence for\nthe cumulative regret is established and a novel transfer learning algorithm\nthat attains the minimax regret is proposed. The results quantify the\ncontribution of the data from the source domains for learning in the target\ndomain in the context of nonparametric contextual multi-armed bandits.\nIn view of the general impossibility of adaptation to unknown smoothness, we\ndevelop a data-driven algorithm that achieves near-optimal statistical\nguarantees (up to a logarithmic factor) while automatically adapting to the\nunknown parameters over a large collection of parameter spaces under an\nadditional self-similarity assumption. A simulation study is carried out to\nillustrate the benefits of utilizing the data from the auxiliary source domains\nfor learning in the target domain.",
    "descriptor": "",
    "authors": [
      "Changxiao Cai",
      "T. Tony Cai",
      "Hongzhe Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2211.12612"
  },
  {
    "id": "arXiv:2211.12623",
    "title": "SkipConvGAN: Monaural Speech Dereverberation using Generative  Adversarial Networks via Complex Time-Frequency Masking",
    "abstract": "With the advancements in deep learning approaches, the performance of speech\nenhancing systems in the presence of background noise have shown significant\nimprovements. However, improving the system's robustness against reverberation\nis still a work in progress, as reverberation tends to cause loss of formant\nstructure due to smearing effects in time and frequency. A wide range of deep\nlearning-based systems either enhance the magnitude response and reuse the\ndistorted phase or enhance complex spectrogram using a complex time-frequency\nmask. Though these approaches have demonstrated satisfactory performance, they\ndo not directly address the lost formant structure caused by reverberation. We\nbelieve that retrieving the formant structure can help improve the efficiency\nof existing systems. In this study, we propose SkipConvGAN - an extension of\nour prior work SkipConvNet. The proposed system's generator network tries to\nestimate an efficient complex time-frequency mask, while the discriminator\nnetwork aids in driving the generator to restore the lost formant structure. We\nevaluate the performance of our proposed system on simulated and real\nrecordings of reverberant speech from the single-channel task of the REVERB\nchallenge corpus. The proposed system shows a consistent improvement across\nmultiple room configurations over other deep learning-based generative\nadversarial frameworks.",
    "descriptor": "\nComments: Published in: IEEE/ACM Transactions on Audio, Speech, and Language Processing ( Volume: 30)\n",
    "authors": [
      "Vinay Kothapally",
      "J. H. L. Hansen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2211.12623"
  },
  {
    "id": "arXiv:2211.12631",
    "title": "A Generic Approach for Statistical Stability in Model Distillation",
    "abstract": "Model distillation has been a popular method for producing interpretable\nmachine learning. It uses an interpretable \"student\" model to mimic the\npredictions made by the black box \"teacher\" model. However, when the student\nmodel is sensitive to the variability of the data sets used for training, the\ncorresponded interpretation is not reliable. Existing strategies stabilize\nmodel distillation by checking whether a large enough corpus of pseudo-data is\ngenerated to reliably reproduce student models, but methods to do so have so\nfar been developed for a specific student model. In this paper, we develop a\ngeneric approach for stable model distillation based on central limit theorem\nfor the average loss. We start with a collection of candidate student models\nand search for candidates that reasonably agree with the teacher. Then we\nconstruct a multiple testing framework to select a corpus size such that the\nconsistent student model would be selected under different pseudo sample. We\ndemonstrate the application of our proposed approach on three commonly used\nintelligible models: decision trees, falling rule lists and symbolic\nregression. Finally, we conduct simulation experiments on Mammographic Mass and\nBreast Cancer datasets and illustrate the testing procedure throughout a\ntheoretical analysis with Markov process.",
    "descriptor": "\nComments: 31 pages, 8 figures\n",
    "authors": [
      "Yunzhe Zhou",
      "Peiru Xu",
      "Giles Hooker"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12631"
  },
  {
    "id": "arXiv:2211.12632",
    "title": "Complex-Valued Time-Frequency Self-Attention for Speech Dereverberation",
    "abstract": "Several speech processing systems have demonstrated considerable performance\nimprovements when deep complex neural networks (DCNN) are coupled with\nself-attention (SA) networks. However, the majority of DCNN-based studies on\nspeech dereverberation that employ self-attention do not explicitly account for\nthe inter-dependencies between real and imaginary features when computing\nattention. In this study, we propose a complex-valued T-F attention (TFA)\nmodule that models spectral and temporal dependencies by computing\ntwo-dimensional attention maps across time and frequency dimensions. We\nvalidate the effectiveness of our proposed complex-valued TFA module with the\ndeep complex convolutional recurrent network (DCCRN) using the REVERB challenge\ncorpus. Experimental findings indicate that integrating our complex-TFA module\nwith DCCRN improves overall speech quality and performance of back-end speech\napplications, such as automatic speech recognition, compared to earlier\napproaches for self-attention.",
    "descriptor": "\nComments: Interspeech 2022: ISCA Best Student Paper Award Finalist\n",
    "authors": [
      "Vinay Kothapally",
      "John H.L. Hansen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.12632"
  },
  {
    "id": "arXiv:2211.12635",
    "title": "High-Order Methods for Hypersonic Flows with Strong Shocks and Real  Chemistry",
    "abstract": "We compare high-order methods including spectral difference (SD), flux\nreconstruction (FR), the entropy-stable discontinuous Galerkin spectral element\nmethod (ES-DGSEM), modal discontinuous Galerkin methods, and WENO to select the\nbest candidate to simulate strong shock waves characteristic of hypersonic\nflows. We consider several benchmarks, including the Leblanc and modified\nshock-density wave interaction problems that require robust stabilization and\npositivity-preserving properties for a successful flow realization. We also\nperform simulations of the three-species Sod problem with simplified chemistry\nwith the chemical reaction source terms introduced in the Euler equations. The\nES-DGSEM scheme exhibits the highest stability, negligible numerical\noscillations, and requires the least computational effort in resolving reactive\nflow regimes with strong shock waves. Therefore, we extend the ES-DGSEM to\nhypersonic Euler equations by deriving a new set of two-point entropy\nconservative fluxes for a five-species gas model. Stabilization for capturing\nstrong shock waves occurs by blending high-order entropy conservative fluxes\nwith low-order finite volume fluxes constructed using the HLLC Riemann solver.\nThe hypersonic Euler solver is verified using the non-equilibrium chemistry Sod\nproblem. To this end, we adopt the Mutation++ library to compute the reaction\nsource terms, thermodynamic properties, and transport coefficients. We also\ninvestigate the effect of real chemistry versus ideal chemistry, and the\nresults demonstrate that the ideal chemistry assumption fails at high\ntemperatures, hence real chemistry must be employed for accurate predictions.\nFinally, we consider a viscous hypersonic flow problem to verify the transport\ncoefficients and reaction source terms determined by the Mutation++ library.",
    "descriptor": "",
    "authors": [
      "Ahmad Peyvan",
      "Khemraj Shukla",
      "Jesse Chan",
      "George Karniadakis"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.12635"
  },
  {
    "id": "arXiv:2211.12644",
    "title": "Scalable Predictive Beamforming for IRS-Assisted Multi-User  Communications: A Deep Learning Approach",
    "abstract": "Beamforming design for intelligent reflecting surface (IRS)-assisted\nmulti-user communication (IRS-MUC) systems critically depends on the\nacquisition of accurate channel state information (CSI). However, channel\nestimation (CE) in IRS-MUC systems causes a large signaling overhead for\ntraining due to the large number of IRS elements. In this paper, taking into\naccount user mobility, we adopt a deep learning (DL) approach to implicitly\nlearn the historical line-of-sight (LoS) channel features and predict the IRS\nphase shifts to be adopted for the next time slot for maximization of the\nweighted sum-rate (WSR) of the IRS-MUC system. With the proposed predictive\napproach, we can avoid full-scale CSI estimation and facilitate low-dimensional\nCE for transmit beamforming design such that the signaling overhead is reduced\nby a scale of $\\frac{1}{N}$, where $N$ is the number of IRS elements. To this\nend, we first develop a universal DL-based predictive beamforming (DLPB)\nframework featuring a two-stage predictive-instantaneous beamforming mechanism.\nAs a realization of the developed framework, a location-aware convolutional\nlong short-term memory (CLSTM) graph neural network (GNN) is developed to\nfacilitate effective predictive beamforming at the IRS, where a CLSTM module is\nfirst adopted to exploit the spatial and temporal features of the considered\nchannels and a GNN is then applied to empower the designed neural network with\nhigh scalability and generalizability. Furthermore, in the second stage, based\non the predicted IRS phase shifts, an instantaneous CSI-aware fully-connected\nneural network is designed to optimize the transmit beamforming at the access\npoint. Simulation results demonstrate that the proposed framework not only\nachieves a better WSR performance and requires a lower CE overhead compared\nwith state-of-the-art benchmarks, but also is highly scalable in the numbers of\nusers.",
    "descriptor": "\nComments: 30 pages, 14 figures, journal paper\n",
    "authors": [
      "Chang Liu",
      "Xuemeng Liu",
      "Zhiqiang Wei",
      "Derrick Wing Kwan Ng",
      "Robert Schober"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.12644"
  },
  {
    "id": "arXiv:2211.12670",
    "title": "Expressibility-Enhancing Strategies for Quantum Neural Networks",
    "abstract": "Quantum neural networks (QNNs), represented by parameterized quantum\ncircuits, can be trained in the paradigm of supervised learning to map input\ndata to predictions. Much work has focused on theoretically analyzing the\nexpressive power of QNNs. However, in almost all literature, QNNs' expressive\npower is numerically validated using only simple univariate functions. We\nsurprisingly discover that state-of-the-art QNNs with strong expressive power\ncan have poor performance in approximating even just a simple sinusoidal\nfunction. To fill the gap, we propose four expressibility-enhancing strategies\nfor QNNs: Sinusoidal-friendly embedding, redundant measurement,\npost-measurement function, and random training data. We analyze the\neffectiveness of these strategies via mathematical analysis and/or numerical\nstudies including learning complex sinusoidal-based functions. Our results from\ncomparative experiments validate that the four strategies can significantly\nincrease the QNNs' performance in approximating complex multivariable functions\nand reduce the quantum circuit depth and qubits required.",
    "descriptor": "\nComments: 16 pages, 11 figures\n",
    "authors": [
      "Yalin Liao",
      "Junpeng Zhan"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12670"
  },
  {
    "id": "arXiv:2211.12681",
    "title": "Benchmarking Adversarially Robust Quantum Machine Learning at Scale",
    "abstract": "Machine learning (ML) methods such as artificial neural networks are rapidly\nbecoming ubiquitous in modern science, technology and industry. Despite their\naccuracy and sophistication, neural networks can be easily fooled by carefully\ndesigned malicious inputs known as adversarial attacks. While such\nvulnerabilities remain a serious challenge for classical neural networks, the\nextent of their existence is not fully understood in the quantum ML setting. In\nthis work, we benchmark the robustness of quantum ML networks, such as quantum\nvariational classifiers (QVC), at scale by performing rigorous training for\nboth simple and complex image datasets and through a variety of high-end\nadversarial attacks. Our results show that QVCs offer a notably enhanced\nrobustness against classical adversarial attacks by learning features which are\nnot detected by the classical neural networks, indicating a possible quantum\nadvantage for ML tasks. Contrarily, and remarkably, the converse is not true,\nwith attacks on quantum networks also capable of deceiving classical neural\nnetworks. By combining quantum and classical network outcomes, we propose a\nnovel adversarial attack detection technology. Traditionally quantum advantage\nin ML systems has been sought through increased accuracy or algorithmic\nspeed-up, but our work has revealed the potential for a new kind of quantum\nadvantage through superior robustness of ML models, whose practical realisation\nwill address serious security concerns and reliability issues of ML algorithms\nemployed in a myriad of applications including autonomous vehicles,\ncybersecurity, and surveillance robotic systems.",
    "descriptor": "\nComments: 10 pages, 5 Figures\n",
    "authors": [
      "Maxwell T. West",
      "Sarah M. Erfani",
      "Christopher Leckie",
      "Martin Sevior",
      "Lloyd C.L. Hollenberg",
      "Muhammad Usman"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.12681"
  },
  {
    "id": "arXiv:2211.12685",
    "title": "Mutual Information Learned Regressor: an Information-theoretic Viewpoint  of Training Regression Systems",
    "abstract": "As one of the central tasks in machine learning, regression finds lots of\napplications in different fields. An existing common practice for solving\nregression problems is the mean square error (MSE) minimization approach or its\nregularized variants which require prior knowledge about the models. Recently,\nYi et al., proposed a mutual information based supervised learning framework\nwhere they introduced a label entropy regularization which does not require any\nprior knowledge. When applied to classification tasks and solved via a\nstochastic gradient descent (SGD) optimization algorithm, their approach\nachieved significant improvement over the commonly used cross entropy loss and\nits variants. However, they did not provide a theoretical convergence analysis\nof the SGD algorithm for the proposed formulation. Besides, applying the\nframework to regression tasks is nontrivial due to the potentially infinite\nsupport set of the label. In this paper, we investigate the regression under\nthe mutual information based supervised learning framework. We first argue that\nthe MSE minimization approach is equivalent to a conditional entropy learning\nproblem, and then propose a mutual information learning formulation for solving\nregression problems by using a reparameterization technique. For the proposed\nformulation, we give the convergence analysis of the SGD algorithm for solving\nit in practice. Finally, we consider a multi-output regression data model where\nwe derive the generalization performance lower bound in terms of the mutual\ninformation associated with the underlying data distribution. The result shows\nthat the high dimensionality can be a bless instead of a curse, which is\ncontrolled by a threshold. We hope our work will serve as a good starting point\nfor further research on the mutual information based regression.",
    "descriptor": "\nComments: 28 pages, 2 figures, presubmitted to AISTATS2023 for reviewing\n",
    "authors": [
      "Jirong Yi",
      "Qiaosheng Zhang",
      "Zhen Chen",
      "Qiao Liu",
      "Wei Shao",
      "Yusen He",
      "Yaohua Wang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2211.12685"
  },
  {
    "id": "arXiv:2211.12691",
    "title": "Optimal Safety for Constrained Differential Inclusions using Nonsmooth  Control Barrier Functions",
    "abstract": "For a broad class of nonlinear systems, we formulate the problem of\nguaranteeing safety with optimality under constraints. Specifically, we define\ncontrolled safety for differential inclusions with constraints on the states\nand the inputs. Through the use of nonsmooth analysis tools, we show that a\ncontinuous optimal control law can be selected from a set-valued constraint\ncapturing the system constraints and conditions guaranteeing safety using\ncontrol barrier functions. Our results guarantee optimality and safety via a\ncontinuous state-feedback law designed using nonsmooth control barrier\nfunctions. An example pertaining to obstacle avoidance with a target\nillustrates our results and the associated benefits of using nonsmooth control\nbarrier functions.",
    "descriptor": "\nComments: Submitted to LCSS\n",
    "authors": [
      "Masoumeh Ghanbarpour",
      "Axton Isaly",
      "Ricardo G. Sanfelice",
      "Warren E. Dixon"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.12691"
  },
  {
    "id": "arXiv:2211.12700",
    "title": "Tailored Presolve Techniques in Branch-and-Bound Method for Fast  Mixed-Integer Optimal Control Applications",
    "abstract": "Mixed-integer model predictive control (MI-MPC) can be a powerful tool for\nmodeling hybrid control systems. In case of a linear-quadratic objective in\ncombination with linear or piecewise-linear system dynamics and inequality\nconstraints, MI-MPC needs to solve a mixed-integer quadratic program (MIQP) at\neach sampling time step. This paper presents a collection of block-sparse\npresolve techniques to efficiently remove decision variables, and to remove or\ntighten inequality constraints, tailored to mixed-integer optimal control\nproblems (MIOCP). In addition, we describe a novel heuristic approach based on\nan iterative presolve algorithm to compute a feasible but possibly suboptimal\nMIQP solution. We present benchmarking results for a C code implementation of\nthe proposed BB-ASIPM solver, including a branch-and-bound (B&B) method with\nthe proposed tailored presolve techniques and an active-set based interior\npoint method (ASIPM), compared against multiple state-of-the-art MIQP solvers\non a case study of motion planning with obstacle avoidance constraints.\nFinally, we demonstrate the computational performance of the BB-ASIPM solver on\nthe dSPACE Scalexio real-time embedded hardware using a second case study of\nstabilization for an underactuated cart-pole with soft contacts.",
    "descriptor": "\nComments: 27 pages, 7 figures, 2 tables, submitted to journal of Optimal Control Applications and Methods\n",
    "authors": [
      "Rien Quirynen",
      "Stefano Di Cairano"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.12700"
  },
  {
    "id": "arXiv:2211.12702",
    "title": "Evaluating Feature Attribution Methods for Electrocardiogram",
    "abstract": "The performance of cardiac arrhythmia detection with electrocardiograms(ECGs)\nhas been considerably improved since the introduction of deep learning models.\nIn practice, the high performance alone is not sufficient and a proper\nexplanation is also required. Recently, researchers have started adopting\nfeature attribution methods to address this requirement, but it has been\nunclear which of the methods are appropriate for ECG. In this work, we identify\nand customize three evaluation metrics for feature attribution methods based on\nthe characteristics of ECG: localization score, pointing game, and degradation\nscore. Using the three evaluation metrics, we evaluate and analyze eleven\nwidely-used feature attribution methods. We find that some of the feature\nattribution methods are much more adequate for explaining ECG, where Grad-CAM\noutperforms the second-best method by a large margin.",
    "descriptor": "\nComments: 5 pages, 3 figures. Code is available at this https URL\n",
    "authors": [
      "Jangwon Suh",
      "Jimyeong Kim",
      "Euna Jung",
      "Wonjong Rhee"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12702"
  },
  {
    "id": "arXiv:2211.12711",
    "title": "Benchmarking variational quantum circuits with permutation symmetry",
    "abstract": "We propose SnCQA, a set of hardware-efficient variational circuits of\nequivariant quantum convolutional circuits respective to permutation symmetries\nand spatial lattice symmetries with the number of qubits $n$. By exploiting\npermutation symmetries of the system, such as lattice Hamiltonians common to\nmany quantum many-body and quantum chemistry problems, Our quantum neural\nnetworks are suitable for solving machine learning problems where permutation\nsymmetries are present, which could lead to significant savings of\ncomputational costs. Aside from its theoretical novelty, we find our\nsimulations perform well in practical instances of learning ground states in\nquantum computational chemistry, where we could achieve comparable performances\nto traditional methods with few tens of parameters. Compared to other\ntraditional variational quantum circuits, such as the pure hardware-efficient\nansatz (pHEA), we show that SnCQA is more scalable, accurate, and noise\nresilient (with $20\\times$ better performance on $3 \\times 4$ square lattice\nand $200\\% - 1000\\%$ resource savings in various lattice sizes and key\ncriterions such as the number of layers, parameters, and times to converge in\nour cases), suggesting a potentially favorable experiment on near-time quantum\ndevices.",
    "descriptor": "\nComments: 10 pages, many figures\n",
    "authors": [
      "Han Zheng",
      "Gokul Subramanian Ravi",
      "Hanrui Wang",
      "Kanav Setia",
      "Frederic T. Chong",
      "Junyu Liu"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.12711"
  },
  {
    "id": "arXiv:2211.12717",
    "title": "Benchmarking Bayesian Deep Learning on Diabetic Retinopathy Detection  Tasks",
    "abstract": "Bayesian deep learning seeks to equip deep neural networks with the ability\nto precisely quantify their predictive uncertainty, and has promised to make\ndeep learning more reliable for safety-critical real-world applications. Yet,\nexisting Bayesian deep learning methods fall short of this promise; new methods\ncontinue to be evaluated on unrealistic test beds that do not reflect the\ncomplexities of downstream real-world tasks that would benefit most from\nreliable uncertainty quantification. We propose the RETINA Benchmark, a set of\nreal-world tasks that accurately reflect such complexities and are designed to\nassess the reliability of predictive models in safety-critical scenarios.\nSpecifically, we curate two publicly available datasets of high-resolution\nhuman retina images exhibiting varying degrees of diabetic retinopathy, a\nmedical condition that can lead to blindness, and use them to design a suite of\nautomated diagnosis tasks that require reliable predictive uncertainty\nquantification. We use these tasks to benchmark well-established and\nstate-of-the-art Bayesian deep learning methods on task-specific evaluation\nmetrics. We provide an easy-to-use codebase for fast and easy benchmarking\nfollowing reproducibility and software design principles. We provide\nimplementations of all methods included in the benchmark as well as results\ncomputed over 100 TPU days, 20 GPU days, 400 hyperparameter configurations, and\nevaluation on at least 6 random seeds each.",
    "descriptor": "\nComments: Published in Neural Information Processing Systems (NeurIPS) 2021 Datasets and Benchmarks Track Proceedings. First two authors contributed equally. Code available at this https URL\n",
    "authors": [
      "Neil Band",
      "Tim G. J. Rudner",
      "Qixuan Feng",
      "Angelos Filos",
      "Zachary Nado",
      "Michael W. Dusenberry",
      "Ghassen Jerfel",
      "Dustin Tran",
      "Yarin Gal"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12717"
  },
  {
    "id": "arXiv:2211.12750",
    "title": "Weighted exchange distance of basis pairs",
    "abstract": "Two pairs of disjoint bases $\\mathbf{P}_1=(R_1,B_1)$ and\n$\\mathbf{P}_2=(R_2,B_2)$ of a matroid $M$ are called equivalent if\n$\\mathbf{P}_1$ can be transformed into $\\mathbf{P}_2$ by a series of symmetric\nexchanges. In 1980, White conjectured that such a sequence always exists\nwhenever $R_1\\cup B_1=R_2\\cup B_2$. A strengthening of the conjecture was\nproposed by Hamidoune, stating that minimum length of an exchange is at most\nthe rank of the matroid.\nWe propose a weighted variant of Hamidoune's conjecture, where the weight of\nan exchange depends on the weights of the exchanged elements. We prove the\nconjecture for several matroid classes: strongly base orderable matroids, split\nmatroids, graphic matroids of wheels, and spikes.",
    "descriptor": "\nComments: 20 pages, 5 figures\n",
    "authors": [
      "Krist\u00f3f B\u00e9rczi",
      "Bence M\u00e1trav\u00f6lgyi",
      "Tam\u00e1s Schwarcz"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.12750"
  },
  {
    "id": "arXiv:2211.12786",
    "title": "Nonlinear Equivariant Imaging: Learning Multi-Parametric Tissue Mapping  without Ground Truth for Compressive Quantitative MRI",
    "abstract": "Current state-of-the-art reconstruction for quantitative tissue maps from\nfast, compressive, Magnetic Resonance Fingerprinting (MRF), use supervised deep\nlearning, with the drawback of requiring high-fidelity ground truth tissue map\ntraining data which is limited. This paper proposes NonLinear Equivariant\nImaging (NLEI), a self-supervised learning approach to eliminate the need for\nground truth for deep MRF image reconstruction. NLEI extends the recent\nEquivariant Imaging framework to nonlinear inverse problems such as MRF. Only\nfast, compressed-sampled MRF scans are used for training. NLEI learns tissue\nmapping using spatiotemporal priors: spatial priors are obtained from the\ninvariance of MRF data to a group of geometric image transformations, while\ntemporal priors are obtained from a nonlinear Bloch response model approximated\nby a pre-trained neural network. Tested retrospectively on two acquisition\nsettings, we observe that NLEI (self-supervised learning) closely approaches\nthe performance of supervised learning, despite not using ground truth during\ntraining.",
    "descriptor": "",
    "authors": [
      "Ketan Fatania",
      "Kwai Y. Chau",
      "Carolin M. Pirkl",
      "Marion I. Menzel",
      "Peter Hall",
      "Mohammad Golbabaee"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12786"
  },
  {
    "id": "arXiv:2211.12789",
    "title": "Hidden Factor estimation in Dynamic Generalized Factor Analysis Models",
    "abstract": "This paper deals with the estimation of the hidden factor in Dynamic\nGeneralized Factor Analysis via a generalization of Kalman filtering.\nAsymptotic consistency is discussed and it is shown that the Kalman one-step\npredictor is not the right tool while the pure filter yields a consistent\nestimate.",
    "descriptor": "",
    "authors": [
      "Giorgio Picci",
      "Lucia Falconi",
      "Augusto Ferrante",
      "Mattia Zorzi"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.12789"
  },
  {
    "id": "arXiv:2211.12809",
    "title": "A comparative study of source-finding techniques in HI emission line  cubes using SoFiA, MTObjects, and supervised deep learning",
    "abstract": "The 21 cm spectral line emission of atomic neutral hydrogen (HI) is one of\nthe primary wavelengths observed in radio astronomy. However, the signal is\nintrinsically faint and the HI content of galaxies depends on the cosmic\nenvironment, requiring large survey volumes and survey depth to investigate the\nHI Universe. As the amount of data coming from these surveys continues to\nincrease with technological improvements, so does the need for automatic\ntechniques for identifying and characterising HI sources while considering the\ntradeoff between completeness and purity. This study aimed to find the optimal\npipeline for finding and masking the most sources with the best mask quality\nand the fewest artefacts in 3D neutral hydrogen cubes. Various existing methods\nwere explored in an attempt to create a pipeline to optimally identify and mask\nthe sources in 3D neutral hydrogen 21 cm spectral line data cubes. Two\ntraditional source-finding methods were tested, SoFiA and MTObjects, as well as\na new supervised deep learning approach, in which a 3D convolutional neural\nnetwork architecture, known as V-Net was used. These three source-finding\nmethods were further improved by adding a classical machine learning classifier\nas a post-processing step to remove false positive detections. The pipelines\nwere tested on HI data cubes from the Westerbork Synthesis Radio Telescope with\nadditional inserted mock galaxies. SoFiA combined with a random forest\nclassifier provided the best results, with the V-Net-random forest combination\na close second. We suspect this is due to the fact that there are many more\nmock sources in the training set than real sources. There is, therefore, room\nto improve the quality of the V-Net network with better-labelled data such that\nit can potentially outperform SoFiA.",
    "descriptor": "",
    "authors": [
      "J.A. Barkai",
      "M.A.W. Verheijen",
      "E.T. Mart\u00ednez",
      "M.H.F. Wilkinson"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12809"
  },
  {
    "id": "arXiv:2211.12839",
    "title": "Newly Developed Flexible Grid Trading Model Combined ANN and SSO  algorithm",
    "abstract": "In modern society, the trading methods and strategies used in financial\nmarket have gradually changed from traditional on-site trading to electronic\nremote trading, and even online automatic trading performed by a pre-programmed\ncomputer programs because the continuous development of network and computer\ncomputing technology. The quantitative trading, which the main purpose is to\nautomatically formulate people's investment decisions into a fixed and\nquantifiable operation logic that eliminates all emotional interference and the\ninfluence of subjective thoughts and applies this logic to financial market\nactivities in order to obtain excess profits above average returns, has led a\nlot of attentions in financial market. The development of self-adjustment\nprogramming algorithms for automatically trading in financial market has\ntransformed a top priority for academic research and financial practice. Thus,\na new flexible grid trading model combined with the Simplified Swarm\nOptimization (SSO) algorithm for optimizing parameters for various market\nsituations as input values and the fully connected neural network (FNN) and\nLong Short-Term Memory (LSTM) model for training a quantitative trading model\nto automatically calculate and adjust the optimal trading parameters for\ntrading after inputting the existing market situation is developed and studied\nin this work. The proposed model provides a self-adjust model to reduce\ninvestors' effort in the trading market, obtains outperformed investment return\nrate and model robustness, and can properly control the balance between risk\nand return.",
    "descriptor": "",
    "authors": [
      "Wei-Chang Yeh",
      "Yu-Hsin Hsieh",
      "Chia-Ling Huang"
    ],
    "subjectives": [
      "Trading and Market Microstructure (q-fin.TR)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2211.12839"
  },
  {
    "id": "arXiv:2211.12845",
    "title": "Superresolution Reconstruction of Single Image for Latent features",
    "abstract": "In recent years, Deep Learning has shown good results in the Single Image\nSuperresolution Reconstruction (SISR) task, thus becoming the most widely used\nmethods in this field. The SISR task is a typical task to solve an uncertainty\nproblem. Therefore, it is often challenging to meet the requirements of\nHigh-quality sampling, fast Sampling, and diversity of details and texture\nafter Sampling simultaneously in a SISR task.It leads to model collapse, lack\nof details and texture features after Sampling, and too long Sampling time in\nHigh Resolution (HR) image reconstruction methods. This paper proposes a\nDiffusion Probability model for Latent features (LDDPM) to solve these\nproblems. Firstly, a Conditional Encoder is designed to effectively encode\nLow-Resolution (LR) images, thereby reducing the solution space of\nreconstructed images to improve the performance of reconstructed images. Then,\nthe Normalized Flow and Multi-modal adversarial training are used to model the\ndenoising distribution with complex Multi-modal distribution so that the\nGenerative Modeling ability of the model can be improved with a small number of\nSampling steps. Experimental results on mainstream datasets demonstrate that\nour proposed model reconstructs more realistic HR images and obtains better\nPSNR and SSIM performance compared to existing SISR tasks, thus providing a new\nidea for SISR tasks.",
    "descriptor": "",
    "authors": [
      "Xin Wang",
      "Jing-Ke Yan",
      "Jing-Ye Cai",
      "Jian-Hua Deng",
      "Qin Qin",
      "Qin Wang",
      "Heng Xiao",
      "Yao Cheng",
      "Peng-Fei Ye"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12845"
  },
  {
    "id": "arXiv:2211.12880",
    "title": "Faster Stochastic First-Order Method for Maximum-Likelihood Quantum  State Tomography",
    "abstract": "In maximum-likelihood quantum state tomography, both the sample size and\ndimension grow exponentially with the number of qubits. It is therefore\ndesirable to develop a stochastic first-order method, just like stochastic\ngradient descent for modern machine learning, to compute the maximum-likelihood\nestimate. To this end, we propose an algorithm called stochastic mirror descent\nwith the Burg entropy. Its expected optimization error vanishes at a $O (\n\\sqrt{ ( 1 / t ) d \\log t } )$ rate, where $d$ and $t$ denote the dimension and\nnumber of iterations, respectively. Its per-iteration time complexity is $O (\nd^3 )$, independent of the sample size. To the best of our knowledge, this is\ncurrently the computationally fastest stochastic first-order method for\nmaximum-likelihood quantum state tomography.",
    "descriptor": "\nComments: 11 pages, 1 figure\n",
    "authors": [
      "Chung-En Tsai",
      "Hao-Chung Cheng",
      "Yen-Huan Li"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.12880"
  },
  {
    "id": "arXiv:2211.12887",
    "title": "Complexity Framework For Forbidden Subgraphs",
    "abstract": "For any finite set $\\mathcal{H} = \\{H_1,\\ldots,H_p\\}$ of graphs, a graph is\n$\\mathcal{H}$-subgraph-free if it does not contain any of $H_1,\\ldots,H_p$ as a\nsubgraph. We propose a meta-theorem to classify if problems are \"efficiently\nsolvable\" or \"computationally hard\" on $\\mathcal{H}$-subgraph-free graphs. The\nconditions are that the problem should be efficiently solvable on graphs of\nbounded treewidth, computationally hard on subcubic graphs, and computational\nhardness is preserved under edge subdivision. We show that all problems\nsatisfying these conditions are efficiently solvable if $\\mathcal{H}$ contains\na disjoint union of one or more paths and subdivided claws, and are\ncomputationally hard otherwise. To illustrate the broad applicability of our\nframework, we study covering or packing problems, network design problems and\nwidth parameter problems. We apply the framework to obtain a dichotomy between\npolynomial-time solvability and NP-completeness. For other problems we obtain a\ndichotomy between almost-linear-time solvability and having no\nsubquadratic-time algorithm (conditioned on some hardness hypotheses). In this\nway we strengthen results in the literature.",
    "descriptor": "",
    "authors": [
      "Matthew Johnson",
      "Barnaby Martin",
      "Jelle J. Oostveen",
      "Sukanya Pandey",
      "Dani\u00ebl Paulusma",
      "Siani Smith",
      "Erik Jan van Leeuwen"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.12887"
  },
  {
    "id": "arXiv:2211.12908",
    "title": "Exact solution approaches for the discrete $\u03b1$-neighbor $p$-center  problem",
    "abstract": "The discrete $\\alpha$-neighbor $p$-center problem (d-$\\alpha$-$p$CP) is an\nemerging variant of the classical $p$-center problem which recently got\nattention in literature. In this problem, we are given a discrete set of points\nand we need to locate $p$ facilities on these points in such a way that the\nmaximum distance between each point where no facility is located and its\n$\\alpha$-closest facility is minimized. The only existing algorithms in\nliterature for solving the d-$\\alpha$-$p$CP are approximation algorithms and\ntwo recently proposed heuristics.\nIn this work, we present two integer programming formulations for the\nd-$\\alpha$-$p$CP, together with lifting of inequalities, valid inequalities,\ninequalities that do not change the optimal objective function value and\nvariable fixing procedures. We provide theoretical results on the strength of\nthe formulations and convergence results for the lower bounds obtained after\napplying the lifting procedures or the variable fixing procedures in an\niterative fashion. Based on our formulations and theoretical results, we\ndevelop branch-and-cut (B&C) algorithms, which are further enhanced with a\nstarting heuristic and a primal heuristic.\nWe evaluate the effectiveness of our B&C algorithms using instances from\nliterature. Our algorithms are able to solve 116 out of 194 instances from\nliterature to proven optimality, with a runtime of under a minute for most of\nthem. By doing so, we also provide improved solution values for 116 instances.",
    "descriptor": "",
    "authors": [
      "Elisabeth Gaar",
      "Markus Sinnl"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.12908"
  },
  {
    "id": "arXiv:2211.12911",
    "title": "Data-driven approximation of control invariant set for linear system  based on convex piecewise linear fitting",
    "abstract": "Control invariant set is critical for guaranteeing safe control and the\nproblem of computing control invariant set for linear discrete-time system is\nrevisited in this paper by using a data-driven approach. Specifically, sample\npoints on convergent trajectories of linear MPC are recorded, of which the\nconvex hull formulates a control invariant set for the linear system. To\napproximate the convex hull of multiple sample points, a convex piecewise\nlinear (PWL) fitting framework has been proposed, which yields a polyhedral\napproximation with predefined complexity. A descent algorithm for the convex\nPWL fitting problem is also developed, which is guaranteed to converge to a\nlocal optimum. The proposed strategy is flexible in computing the control\ninvariant set in high dimension with a predefined complexity. Simulation\nresults show that the proposed data-driven approximation can compute the\napproximated control invariant set with high accuracy and relatively low\ncomputational cost.",
    "descriptor": "",
    "authors": [
      "Jun Xu",
      "Fanglin Chen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.12911"
  },
  {
    "id": "arXiv:2211.12929",
    "title": "Parametric control of PageRank centrality rankings: a geometrical  approach",
    "abstract": "The PageRank algorithm is a landmark in the development of the Internet as we\nknow it, and its network-theoretic properties are still being studied. Here we\npresent a series of results regarding the parametric controllability of its\ncentralities, and develop a geometric method to crack the problem of assessing\nthe control of its rankings. We apply these methods to the biplex PageRank\ncase, comparing both centrality measures by means of numerical computations on\nreal and synthetic network datasets.",
    "descriptor": "\nComments: 18 pages, 6 figures\n",
    "authors": [
      "Gonzalo Contreras-Aso",
      "Regino Criado",
      "Miguel Romance"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2211.12929"
  },
  {
    "id": "arXiv:2211.12935",
    "title": "Functional Connectome: Approximating Brain Networks with Artificial  Neural Networks",
    "abstract": "We aimed to explore the capability of deep learning to approximate the\nfunction instantiated by biological neural circuits-the functional connectome.\nUsing deep neural networks, we performed supervised learning with firing rate\nobservations drawn from synthetically constructed neural circuits, as well as\nfrom an empirically supported Boundary Vector Cell-Place Cell network. The\nperformance of trained networks was quantified using a range of criteria and\ntasks. Our results show that deep neural networks were able to capture the\ncomputations performed by synthetic biological networks with high accuracy, and\nwere highly data efficient and robust to biological plasticity. We show that\ntrained deep neural networks are able to perform zero-shot generalisation in\nnovel environments, and allows for a wealth of tasks such as decoding the\nanimal's location in space with high accuracy. Our study reveals a novel and\npromising direction in systems neuroscience, and can be expanded upon with a\nmultitude of downstream applications, for example, goal-directed reinforcement\nlearning.",
    "descriptor": "\nComments: 13 pages, 10 figures\n",
    "authors": [
      "Sihao Liu",
      "Augustine N Mavor-Parker",
      "Caswell Barry"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2211.12935"
  },
  {
    "id": "arXiv:2211.12944",
    "title": "SS-CXR: Multitask Representation Learning using Self Supervised  Pre-training from Chest X-Rays",
    "abstract": "Chest X-rays (CXRs) are a widely used imaging modality for the diagnosis and\nprognosis of lung disease. The image analysis tasks vary. Examples include\npathology detection and lung segmentation. There is a large body of work where\nmachine learning algorithms are developed for specific tasks. A significant\nrecent example is Coronavirus disease (covid-19) detection using CXR data.\nHowever, the traditional diagnostic tool design methods based on supervised\nlearning are burdened by the need to provide training data annotation, which\nshould be of good quality for better clinical outcomes. Here, we propose an\nalternative solution, a new self-supervised paradigm, where a general\nrepresentation from CXRs is learned using a group-masked self-supervised\nframework. The pre-trained model is then fine-tuned for domain-specific tasks\nsuch as covid-19, pneumonia detection, and general health screening. We show\nthat the same pre-training can be used for the lung segmentation task. Our\nproposed paradigm shows robust performance in multiple downstream tasks which\ndemonstrates the success of the pre-training. Moreover, the performance of the\npre-trained models on data with significant drift during test time proves the\nlearning of a better generic representation. The methods are further validated\nby covid-19 detection in a unique small-scale pediatric data set. The\nperformance gain in accuracy (~25\\%) is significant when compared to a\nsupervised transformer-based method. This adds credence to the strength and\nreliability of our proposed framework and pre-training strategy.",
    "descriptor": "",
    "authors": [
      "Syed Muhammad Anwar",
      "Abhijeet Parida",
      "Sara Atito",
      "Muhammad Awais",
      "Gustavo Nino",
      "Josef Kitler",
      "Marius George Linguraru"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12944"
  },
  {
    "id": "arXiv:2211.12954",
    "title": "Quantum-Classical Tradeoffs in the Random Oracle Model",
    "abstract": "We study tradeoffs between quantum and classical queries for hybrid\nalgorithms that have black-box access to a random oracle. Although there are\nseveral established techniques for proving query lower bounds for both quantum\nand classical algorithms, there is no such widely applicable technique for\nhybrid algorithms and the optimal tradeoffs for many fundamental problems are\nstill unknown $\\unicode{x2013}$ an optimal tradeoff for the search problem was\nonly shown recently by Rosmanis, although not in the random oracle model. For\nanother fundamental problem, collision finding, the optimal tradeoff was not\nknown.\nIn this work, we develop a framework for recording a query transcript for\nquantum-classical algorithms that represents the knowledge gained by the\nalgorithm. The main feature of this framework is to allow us to record queries\nin two incompatible bases $\\unicode{x2013}$ classical queries in the standard\nbasis and quantum queries in the Fourier basis $\\unicode{x2013}$ in a\nconsistent way. We call the framework the hybrid compressed oracle as it\nnaturally interpolates between the classical way of recording queries and the\ncompressed oracle framework of Zhandry for recording quantum queries. We\ndemonstrate its applicability by giving a simpler proof of the optimal\nquantum-classical tradeoff for search and by showing an optimal tradeoff for\ncollision finding.",
    "descriptor": "\nComments: 36 pages\n",
    "authors": [
      "Yassine Hamoudi",
      "Qipeng Liu",
      "Makrand Sinha"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2211.12954"
  },
  {
    "id": "arXiv:2211.12959",
    "title": "Automatic, high-order, and adaptive algorithms for Brillouin zone  integration",
    "abstract": "We present efficient methods for Brillouin zone integration with a non-zero\nbut possibly very small broadening factor $\\eta$, focusing on cases in which\ndownfolded Hamiltonians can be evaluated efficiently using Wannier\ninterpolation. We describe robust, high-order accurate algorithms automating\nconvergence to a user-specified error tolerance $\\varepsilon$, emphasizing an\nefficient computational scaling with respect to $\\eta$. After analyzing the\nstandard equispaced integration method, applicable in the case of large\nbroadening, we describe a simple iterated adaptive integration algorithm\neffective in the small $\\eta$ regime. Its computational cost scales as\n$\\mathcal{O}(\\log^3(\\eta^{-1}))$ as $\\eta \\to 0^+$ in three dimensions, as\nopposed to $\\mathcal{O}(\\eta^{-3})$ for equispaced integration. We argue that,\nby contrast, tree-based adaptive integration methods scale only as\n$\\mathcal{O}(\\log(\\eta^{-1})/\\eta^{2})$ for typical Brillouin zone integrals.\nIn addition to its favorable scaling, the iterated adaptive algorithm is\nstraightforward to implement, particularly for integration on the irreducible\nBrillouin zone, for which it avoids the tetrahedral meshes required for\ntree-based schemes. We illustrate the algorithms by calculating the spectral\nfunction of SrVO$_3$ with broadening on the meV scale.",
    "descriptor": "",
    "authors": [
      "Jason Kaye",
      "Sophie Beck",
      "Alex Barnett",
      "Lorenzo Van Mu\u00f1oz",
      "Olivier Parcollet"
    ],
    "subjectives": [
      "Strongly Correlated Electrons (cond-mat.str-el)",
      "Materials Science (cond-mat.mtrl-sci)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.12959"
  },
  {
    "id": "arXiv:2211.12983",
    "title": "Causal Analysis of the TOPCAT Trial: Spironolactone for Preserved  Cardiac Function Heart Failure",
    "abstract": "We describe the results of applying causal discovery methods on the data from\na multi-site clinical trial, on the Treatment of Preserved Cardiac Function\nHeart Failure with an Aldosterone Antagonist (TOPCAT). The trial was\ninconclusive, with no clear benefits consistently shown for the whole cohort.\nHowever, there were questions regarding the reliability of the diagnosis and\ntreatment protocol for a geographic subgroup of the cohort. With the inclusion\nof medical context in the form of domain knowledge, causal discovery is used to\ndemonstrate regional discrepancies and to frame the regional transportability\nof the results. Furthermore, we show that, globally and especially for some\nsubgroups, the treatment has significant causal effects, thus offering a more\nrefined view of the trial results.",
    "descriptor": "",
    "authors": [
      "Francesca E. D. Raimondi",
      "Tadhg O'Keeffe",
      "Hana Chockler",
      "Andrew R. Lawrence",
      "Tamara Stemberga",
      "Andre Franca",
      "Maksim Sipos",
      "Javed Butler",
      "Shlomo Ben-Haim"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2211.12983"
  },
  {
    "id": "arXiv:2211.12986",
    "title": "Physics-informed neural networks for pathloss prediction",
    "abstract": "This paper introduces a physics-informed machine learning approach for\npathloss prediction. This is achieved by including in the training phase\nsimultaneously (i) physical dependencies between spatial loss field and (ii)\nmeasured pathloss values in the field. It is shown that the solution to a\nproposed learning problem improves generalization and prediction quality with a\nsmall number of neural network layers and parameters. The latter leads to fast\ninference times which are favorable for downstream tasks such as localization.\nMoreover, the physics-informed formulation allows training and prediction with\nsmall amount of training data which makes it appealing for a wide range of\npractical pathloss prediction scenarios.",
    "descriptor": "\nComments: 4 pages, 4 figures\n",
    "authors": [
      "Steffen Limmer",
      "Alberto Martinez Alba",
      "Nicola Michailow"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.12986"
  },
  {
    "id": "arXiv:2211.13001",
    "title": "Higher-order interaction model from geometric measurements",
    "abstract": "We introduce a higher simplicial generalization of the linear consensus model\nwhich shares several common features. The well-known linear consensus model is\na gradient flow with a sum of squares of distances between each pair of points.\nOur newly suggested model is also represented as a gradient flow equipped with\ntotal $n$-dimensional volume functional consisting of $n+1$ points as a\npotential. In this manner, the linear consensus model coincides with the case\nof $n=1$ where distance is understood as the 1-dimensional volume. From a\nsimple mathematical analysis, one can easily show that the linear consensus\nmodel (a gradient flow with 1-dimensional volume functional) collapses to one\nsingle point, which can be considered as a 0-complex. By extending this result,\nwe show that a solution to our model converges to an $(n-1)$-dimensional affine\nsubspace. We also perform several numerical simulations with an efficient\nalgorithm that reduces the computational cost.",
    "descriptor": "",
    "authors": [
      "Dohyun Kim",
      "Hansol Park",
      "Woojoo Shim"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2211.13001"
  },
  {
    "id": "arXiv:2211.13005",
    "title": "A CNN-Transformer Deep Learning Model for Real-time Sleep Stage  Classification in an Energy-Constrained Wireless Device",
    "abstract": "This paper proposes a deep learning (DL) model for automatic sleep stage\nclassification based on single-channel EEG data. The DL model features a\nconvolutional neural network (CNN) and transformers. The model was designed to\nrun on energy and memory-constrained devices for real-time operation with local\nprocessing. The Fpz-Cz EEG signals from a publicly available Sleep-EDF dataset\nare used to train and test the model. Four convolutional filter layers were\nused to extract features and reduce the data dimension. Then, transformers were\nutilized to learn the time-variant features of the data. To improve\nperformance, we also implemented a subject specific training before the\ninference (i.e., prediction) stage. With the subject specific training, the F1\nscore was 0.91, 0.37, 0.84, 0.877, and 0.73 for wake, N1-N3, and rapid eye\nmovement (REM) stages, respectively. The performance of the model was\ncomparable to the state-of-the-art works with significantly greater\ncomputational costs. We tested a reduced-sized version of the proposed model on\na low-cost Arduino Nano 33 BLE board and it was fully functional and accurate.\nIn the future, a fully integrated wireless EEG sensor with edge DL will be\ndeveloped for sleep research in pre-clinical and clinical experiments, such as\nreal-time sleep modulation.",
    "descriptor": "",
    "authors": [
      "Zongyan Yao",
      "Xilin Liu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13005"
  },
  {
    "id": "arXiv:2211.13006",
    "title": "Quantized Compressed Sensing with Score-Based Generative Models",
    "abstract": "We consider the general problem of recovering a high-dimensional signal from\nnoisy quantized measurements. Quantization, especially coarse quantization such\nas one-bit sign measurements, leads to severe information loss and thus a good\nprior knowledge of the unknown signal is helpful for accurate recovery.\nMotivated by the power of score-based generative models (SGM, also known as\ndiffusion models) in capturing the rich structure of natural signals beyond\nsimple sparsity, we propose an unsupervised data-driven approach called\nquantized compressed sensing with SGM (QCS-SGM), where the prior distribution\nis modeled by a pre-trained SGM. To perform posterior sampling, an annealed\npseudo-likelihood score called noise perturbed pseudo-likelihood score is\nintroduced and combined with the prior score of SGM. The proposed QCS-SGM\napplies to arbitrary number of quantization bits. Experiments on a variety of\nbaseline datasets demonstrate that the proposed QCS-SGM significantly\noutperforms existing state-of-the-art algorithms by a large margin for both\nin-distribution and out-of-distribution samples. Moreover, as a posterior\nsampling method, QCS-SGM can be easily used to obtain confidence intervals or\nuncertainty estimates of the reconstructed results. The code for the\nexperiments will be open-sourced at https://github.com/mengxiangming/QCS-SGM\nupon future publication.",
    "descriptor": "\nComments: 21 pages, 14 figures\n",
    "authors": [
      "Xiangming Meng",
      "Yoshiyuki Kabashima"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13006"
  },
  {
    "id": "arXiv:2211.13018",
    "title": "Challenges in Gaussian Processes for Non Intrusive Load Monitoring",
    "abstract": "Non-intrusive load monitoring (NILM) or energy disaggregation aims to break\ndown total household energy consumption into constituent appliances. Prior work\nhas shown that providing an energy breakdown can help people save up to 15\\% of\nenergy. In recent years, deep neural networks (deep NNs) have made remarkable\nprogress in the domain of NILM. In this paper, we demonstrate the performance\nof Gaussian Processes (GPs) for NILM. We choose GPs due to three main reasons:\ni) GPs inherently model uncertainty; ii) equivalence between infinite NNs and\nGPs; iii) by appropriately designing the kernel we can incorporate domain\nexpertise. We explore and present the challenges of applying our GP approaches\nto NILM.",
    "descriptor": "\nComments: Accepted at NeurIPS Workshop on Gaussian Processes, Spatiotemporal Modeling, and Decision-making Systems, 2023\n",
    "authors": [
      "Aadesh Desai",
      "Gautam Vashishtha",
      "Zeel B Patel",
      "Nipun Batra"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13018"
  },
  {
    "id": "arXiv:2211.13019",
    "title": "Safe Optimization of an Industrial Refrigeration Process Using an  Adaptive and Explorative Framework",
    "abstract": "Many industrial applications rely on real-time optimization to improve key\nperformance indicators. In the case of unknown process characteristics,\nreal-time optimization becomes challenging, particularly for the satisfaction\nof safety constraints. In this paper, we demonstrate the application of an\nadaptive and explorative real-time optimization framework to an industrial\nrefrigeration process, where we learn the process characteristics through\nchanges in process control targets and through exploration to satisfy safety\nconstraints. We quantify the uncertainty in unknown compressor characteristics\nof the refrigeration plant by using Gaussian processes and incorporate this\nuncertainty into the objective function of the real-time optimization problem\nas a weighted cost term. We adaptively control the weight of this term to drive\nexploration. The results of our simulation experiments indicate the proposed\napproach can help to increase the energy efficiency of the considered\nrefrigeration process, closely approximating the performance of a solution that\nhas complete information about the compressor performance characteristics.",
    "descriptor": "\nComments: Under review for IFAC WC 2023. arXiv admin note: substantial text overlap with arXiv:2211.05495\n",
    "authors": [
      "Buse Sibel Korkmaz",
      "Marta Zag\u00f3rowska",
      "Mehmet Mercang\u00f6z"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.13019"
  },
  {
    "id": "arXiv:2211.13045",
    "title": "Analysis of IRS-Assisted NOMA for 6G Wireless Communications",
    "abstract": "Non-orthogonal multiple access (NOMA) scheme enables serving users with the\nsame resource block i.e. frequency or time by multiplexing the signal of the\nusers. Intelligent reflecting surfaces (IRS) or reconfigurable intelligent\nsurfaces (RIS) is a potential approach for increasing transmission efficiency\nby modifying signal propagation by tweaking typically passive reflective\ncomponents. IRS reconfigures the wireless network in this manner to improve\nsystem performance. The research considered an IRS-assisted downlink NOMA\nsystem. This work modified the reference model by adopting an IRS-specific\nfrequency-distance-dependent path loss model for IRS-NOMA downlink received\npower and signal-to-interference plus noise ratio (SINR) measurement instead of\na typical or conventional distance-dependant path loss model. The incorporation\nof an IRS-specific path loss model provides a more convenient and better\nmeasurement compared to the conventional path loss model. Furthermore, this\nwork figures out an improvement scope in the reference model.",
    "descriptor": "",
    "authors": [
      "Mobasshir Mahbub",
      "Raed M. Shubair"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.13045"
  },
  {
    "id": "arXiv:2211.13052",
    "title": "Pyrocast: a Machine Learning Pipeline to Forecast Pyrocumulonimbus  (PyroCb) Clouds",
    "abstract": "Pyrocumulonimbus (pyroCb) clouds are storm clouds generated by extreme\nwildfires. PyroCbs are associated with unpredictable, and therefore dangerous,\nwildfire spread. They can also inject smoke particles and trace gases into the\nupper troposphere and lower stratosphere, affecting the Earth's climate. As\nglobal temperatures increase, these previously rare events are becoming more\ncommon. Being able to predict which fires are likely to generate pyroCb is\ntherefore key to climate adaptation in wildfire-prone areas. This paper\nintroduces Pyrocast, a pipeline for pyroCb analysis and forecasting. The\npipeline's first two components, a pyroCb database and a pyroCb forecast model,\nare presented. The database brings together geostationary imagery and\nenvironmental data for over 148 pyroCb events across North America, Australia,\nand Russia between 2018 and 2022. Random Forests, Convolutional Neural Networks\n(CNNs), and CNNs pretrained with Auto-Encoders were tested to predict the\ngeneration of pyroCb for a given fire six hours in advance. The best model\npredicted pyroCb with an AUC of $0.90 \\pm 0.04$.",
    "descriptor": "\nComments: 5 pages, 2 figures, Tackling Climate Change with Machine Learning: workshop at NeurIPS 2022\n",
    "authors": [
      "Kenza Tazi",
      "Emiliano D\u00edaz Salas-Porras",
      "Ashwin Braude",
      "Daniel Okoh",
      "Kara D. Lamb",
      "Duncan Watson-Parris",
      "Paula Harder",
      "Nis Meinert"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.13052"
  },
  {
    "id": "arXiv:2211.13053",
    "title": "Blue Communications for Edge Computing: the Reconfigurable Intelligent  Surfaces Opportunity",
    "abstract": "Wireless traffic is exploding, due to the myriad of new connections and the\nexchange of capillary data at the edge of the networks to operate real-time\nprocessing and decision making. The latter especially affects the uplink\ntraffic, which will grow in 6G and beyond networks, calling for new\noptimization metrics that include energy, service delay, and electromagnetic\nfield (EMF) exposure (EMFE). To this end, reconfigurable intelligent surfaces\n(RISs) represent a promising solution to mitigate the EMFE, thanks to their\nability of shaping and manipulating the impinging electromagnetic waves. In\nline with this vision, this paper proposes an online adaptive method to\nmitigate the EMFE under end-to-end delay constraints of a computation\noffloading service, in the context of RIS and multi-access edge computing\n(MEC)-aided wireless networks. The goal is to minimize the long-term average of\nthe EMF human exposure under such constraints, investigating the advantages of\nRISs towards blue (i.e. low EMFE) communications. A multiple-input\nmultiple-output (MIMO) system is investigated as part of the visions towards\n6G. Focusing on a typical scenario of computation offloading, the method\njointly and adaptively optimizes user precoding, transmit power, RIS\nreflectivity parameters, and receiver combiner, with theoretical guarantees on\nthe desired long-term performance. Besides the theoretical results, numerical\nsimulations assess the performance of the proposed algorithm, when exploiting\naccurate antenna patterns, thus showing the advantage of the RIS and that of\nour method, compared to benchmark solutions.",
    "descriptor": "\nComments: Accepted at IEEE Globecom 2022\n",
    "authors": [
      "Fatima Ezzahra Airod",
      "Mattia Merluzzi",
      "Antonio Clemente",
      "Emilio Calvanese Strinati"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Emerging Technologies (cs.ET)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2211.13053"
  },
  {
    "id": "arXiv:2211.13059",
    "title": "Inversion of sea surface currents from satellite-derived SST-SSH  synergies with 4DVarNets",
    "abstract": "Satellite altimetry is a unique way for direct observations of sea surface\ndynamics. This is however limited to the surface-constrained geostrophic\ncomponent of sea surface velocities. Ageostrophic dynamics are however expected\nto be significant for horizontal scales below 100~km and time scale below\n10~days. The assimilation of ocean general circulation models likely reveals\nonly a fraction of this ageostrophic component. Here, we explore a\nlearning-based scheme to better exploit the synergies between the observed sea\nsurface tracers, especially sea surface height (SSH) and sea surface\ntemperature (SST), to better inform sea surface currents. More specifically, we\ndevelop a 4DVarNet scheme which exploits a variational data assimilation\nformulation with trainable observations and {\\em a priori} terms. An Observing\nSystem Simulation Experiment (OSSE) in a region of the Gulf Stream suggests\nthat SST-SSH synergies could reveal sea surface velocities for time scales of\n2.5-3.0 days and horizontal scales of 0.5$^\\circ$-0.7$^\\circ$, including a\nsignificant fraction of the ageostrophic dynamics ($\\approx$ 47\\%). The\nanalysis of the contribution of different observation data, namely nadir\nalong-track altimetry, wide-swath SWOT altimetry and SST data, emphasizes the\nrole of SST features for the reconstruction at horizontal spatial scales\nranging from \\nicefrac{1}{20}$^\\circ$ to \\nicefrac{1}{4}$^\\circ$.",
    "descriptor": "",
    "authors": [
      "Ronan Fablet",
      "Bertrand Chapron",
      "Julien Le Sommer",
      "Florian S\u00e9vellec"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13059"
  },
  {
    "id": "arXiv:2211.13072",
    "title": "A note on graphs with purely imaginary per-spectrum",
    "abstract": "In 1983, Borowiecki and J\\'o\\'zwiak posed an open problem of characterizing\ngraphs with purely imaginary per-spectrum. The most general result, although a\npartial solution, was given in 2004 by Yan and Zhang, who show that if a graph\ncontains no subgraph which is an even subdivision of $K_{2,3}$, then it has\npurely imaginary per-spectrum. Zhang and Li in 2012 proved that such graphs are\nplanar and admit a pfaffian orientation. In this article, we describe how to\nconstruct graphs with purely imaginary per-spectrum having a subgraph which is\nan even subdivision of $K_{2,3}$ (planar and nonplanar) using coalescence of\nrooted graphs.",
    "descriptor": "",
    "authors": [
      "Hitesh Wankhede",
      "Ranveer Singh"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2211.13072"
  },
  {
    "id": "arXiv:2211.13115",
    "title": "A situated agent-based model to reveal irrigators' options behind their  actions under institutional arrangements in Southern France",
    "abstract": "There has been little exploration of the explicit simulation of the set of\noptions of actors in agent-based models and its evolution over time. This study\nproposes to use affordances as intermediate entities between agents'\nenvironment and agent actions. We illustrated the approach on a typical\ngravity-fed network in the South-East of France to explore how the abandonment\nof traditional sharing of water changes the irrigators' options to irrigate. We\nsimulated a typical dry year irrigation season under two institutional\narrangements (i.e. traditional coordination through daily slots and its\nabandonment). Simulation results are consistent with field surveys, and reveal\nan increase in the number of internal conflicts among irrigators as the\ncounterpart of the abandonment of traditional sharing of water. They also\nhighlight the consequences of the heterogeneity of the irrigators' interests\nwithin the collective institution. The sensitivity analysis of the model\nallowed identification of optimal modalities of coordination, and a potential\ncompromise between past and current institutional arrangements. The key\nbenefits of using affordances in ABM lie in the study of their population\ndynamics for characterizing the interaction situations between actors and their\nenvironment and for better understanding the model dynamics.",
    "descriptor": "",
    "authors": [
      "Bastien Richard",
      "Bruno Bont\u00e9",
      "Olivier Barreteau",
      "Isabelle Braud"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2211.13115"
  },
  {
    "id": "arXiv:2211.13117",
    "title": "On the Empirical Association between Trade Network Complexity and Global  Gross Domestic Product",
    "abstract": "In recent decades, trade between nations has constituted an important\ncomponent of global Gross Domestic Product (GDP), with official estimates\nshowing that it likely accounted for a quarter of total global production.\nWhile evidence of association already exists in macro-economic data between\ntrade volume and GDP growth, there is considerably less work on whether, at the\nlevel of individual granular sectors (such as vehicles or minerals),\nassociations exist between the complexity of trading networks and global GDP.\nIn this paper, we explore this question by using publicly available data from\nthe Atlas of Economic Complexity project to rigorously construct global trade\nnetworks between nations across multiple sectors, and studying the correlation\nbetween network-theoretic measures computed on these networks (such as average\nclustering coefficient and density) and global GDP. We find that there is\nindeed significant association between trade networks' complexity and global\nGDP across almost every sector, and that network metrics also correlate with\nbusiness cycle phenomena such as the Great Recession of 2007-2008. Our results\nshow that trade volume alone cannot explain global GDP growth, and that network\nscience may prove to be a valuable empirical avenue for studying complexity in\nmacro-economic phenomena such as trade.",
    "descriptor": "\nComments: Peer-reviewed and presented at The 11th International Conference on Complex Networks and their Applications (2022)\n",
    "authors": [
      "Mayank Kejriwal",
      "Yuesheng Luo"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.13117"
  },
  {
    "id": "arXiv:2211.13119",
    "title": "Performance of Cooperative Detection in Joint Communication-Sensing  Vehicular Network: A Data Analytic and Stochastic Geometry Approach",
    "abstract": "The increasing complexity of urban environments introduces additional\nuncertainty to the deployment of the autonomous vehicular network. A novel road\ninfrastructure cooperative detection model using Joint Communication and\nSensing (JCS) technology is proposed in this article to simultaneously achieve\nhigh-efficient communication and obstacle detection for urban autonomous\nvehicles. To suppress the performance fluctuation caused by shadowing and\nobstruction to the JCS signals, we first derive the statistic of road obstacles\nfrom the Geographic Information System (GIS). Then, the analysis of JCS channel\ncharacteristics and shadowing factors are presented using Line-of-Sight and\nNon-Line-of-Sight (LoS and NLoS) channel models under the complex urban\nscenario. A stochastic geometry approach is applied to analyze the interference\nfactors and the probability distribution of successful JCS detection and\ncommunication. Simulations have been made to verify the cooperative detection\nmodel by probability analysis based on LoS and NLoS channels, and the numerical\nresults demonstrate several different optimization methods for the deployment\nof JCS road infrastructures. Finally, we simulated and analyzed a deployment\noptimization method for JCS road infrastructures that complied with the\nstandard of urban traffic-spot structure placement.",
    "descriptor": "",
    "authors": [
      "Hao Ma",
      "Zhiqing Wei",
      "Zening Li",
      "Fan Ning",
      "Xu Chen",
      "Zhiyong Feng"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2211.13119"
  },
  {
    "id": "arXiv:2211.13122",
    "title": "Impact of Channel Models on Performance Characterization of RIS-Assisted  Wireless Systems",
    "abstract": "The performance characterization of communication systems assisted by large\nreconfigurable intelligent surfaces (RISs) significantly depends on the adopted\nmodels for the underlying channels. Under unrealistic channel models, the\nsystem performance may be over- or under-estimated which yields inaccurate\nconclusions for the system design. In this paper, we review five channel models\nthat are chosen to progressively improve the modeling accuracy for large RISs.\nFor each channel model, we highlight the underlying assumptions, its\nadvantages, and its limitations. We compare the system performance under the\naforementioned channel models using RIS configuration algorithms from the\nliterature and a new scalable algorithm proposed in this paper specifically for\nthe configuration of extremely large RISs.",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Vahid Jamali",
      "Walid Ghanem",
      "Robert Schober",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Emerging Technologies (cs.ET)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.13122"
  },
  {
    "id": "arXiv:2211.13125",
    "title": "EEG aided boosting of single-lead ECG based sleep staging with Deep  Knowledge Distillation",
    "abstract": "An electroencephalogram (EEG) signal is currently accepted as a standard for\nautomatic sleep staging. Lately, Near-human accuracy in automated sleep staging\nhas been achievable by Deep Learning (DL) based approaches, enabling multi-fold\nprogress in this area. However, An extensive and expensive clinical setup is\nrequired for EEG based sleep staging. Additionally, the EEG setup being\nobtrusive in nature and requiring an expert for setup adds to the inconvenience\nof the subject under study, making it adverse in the point of care setting. An\nunobtrusive and more suitable alternative to EEG is Electrocardiogram (ECG).\nUnsurprisingly, compared to EEG in sleep staging, its performance remains\nsub-par. In order to take advantage of both the modalities, transferring\nknowledge from EEG to ECG is a reasonable approach, ultimately boosting the\nperformance of ECG based sleep staging. Knowledge Distillation (KD) is a\npromising notion in DL that shares knowledge from a superior performing but\nusually more complex teacher model to an inferior but compact student model.\nBuilding upon this concept, a cross-modality KD framework assisting features\nlearned through models trained on EEG to improve ECG-based sleep staging\nperformance is proposed. Additionally, to better understand the distillation\napproach, extensive experimentation on the independent modules of the proposed\nmodel was conducted. Montreal Archive of Sleep Studies (MASS) dataset\nconsisting of 200 subjects was utilized for this study. The results from the\nproposed model for weighted-F1-score in 3-class and 4-class sleep staging\nshowed a 13.40 \\% and 14.30 \\% improvement, respectively. This study\ndemonstrates the feasibility of KD for single-channel ECG based sleep staging's\nperformance enhancement in 3-class (W-R-N) and 4-class (W-R-L-D)\nclassification.",
    "descriptor": "\nComments: Medical Measurements and Apllications (MeMeA-2022)\n",
    "authors": [
      "Vaibhav Joshi",
      "Sricharan V",
      "Preejith SP",
      "Mohanasankar Sivaprakasam"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13125"
  },
  {
    "id": "arXiv:2211.13128",
    "title": "A Closed-loop Sleep Modulation System with FPGA-Accelerated Deep  Learning",
    "abstract": "Closed-loop sleep modulation is an emerging research paradigm to treat sleep\ndisorders and enhance sleep benefits. However, two major barriers hinder the\nwidespread application of this research paradigm. First, subjects often need to\nbe wire-connected to rack-mount instrumentation for data acquisition, which\nnegatively affects sleep quality. Second, conventional real-time sleep stage\nclassification algorithms give limited performance. In this work, we conquer\nthese two limitations by developing a sleep modulation system that supports\nclosed-loop operations on the device. Sleep stage classification is performed\nusing a lightweight deep learning (DL) model accelerated by a low-power\nfield-programmable gate array (FPGA) device. The DL model uses a single channel\nelectroencephalogram (EEG) as input. Two convolutional neural networks (CNNs)\nare used to capture general and detailed features, and a bidirectional\nlong-short-term memory (LSTM) network is used to capture time-variant sequence\nfeatures. An 8-bit quantization is used to reduce the computational cost\nwithout compromising performance. The DL model has been validated using a\npublic sleep database containing 81 subjects, achieving a state-of-the-art\nclassification accuracy of 85.8% and a F1-score of 79%. The developed model has\nalso shown the potential to be generalized to different channels and input data\nlengths. Closed-loop in-phase auditory stimulation has been demonstrated on the\ntest bench.",
    "descriptor": "",
    "authors": [
      "Mingzhe Sun",
      "Aaron Zhou",
      "Naize Yang",
      "Yaqian Xu",
      "Yuhan Hou",
      "Xilin Liu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.13128"
  },
  {
    "id": "arXiv:2211.13157",
    "title": "Physics-Informed Multi-Stage Deep Learning Framework Development for  Digital Twin-Centred State-Based Reactor Power Prediction",
    "abstract": "Computationally efficient and trustworthy machine learning algorithms are\nnecessary for Digital Twin (DT) framework development. Generally speaking,\nDT-enabling technologies consist of five major components: (i) Machine learning\n(ML)-driven prediction algorithm, (ii) Temporal synchronization between physics\nand digital assets utilizing advanced sensors/instrumentation, (iii)\nuncertainty propagation, and (iv) DT operational framework. Unfortunately,\nthere is still a significant gap in developing those components for nuclear\nplant operation. In order to address this gap, this study specifically focuses\non the \"ML-driven prediction algorithms\" as a viable component for the nuclear\nreactor operation while assessing the reliability and efficacy of the proposed\nmodel. Therefore, as a DT prediction component, this study develops a\nmulti-stage predictive model consisting of two feedforward Deep Learning using\nNeural Networks (DNNs) to determine the final steady-state power of a reactor\ntransient for a nuclear reactor/plant. The goal of the multi-stage model\narchitecture is to convert probabilistic classification to continuous output\nvariables to improve reliability and ease of analysis. Four regression models\nare developed and tested with input from the first stage model to predict a\nsingle value representing the reactor power output. The combined model yields\n96% classification accuracy for the first stage and 92% absolute prediction\naccuracy for the second stage. The development procedure is discussed so that\nthe method can be applied generally to similar systems. An analysis of the role\nsimilar models would fill in DTs is performed.",
    "descriptor": "",
    "authors": [
      "James Daniell",
      "Kazuma Kobayashi",
      "Dinesh Kumar",
      "Souvik Chakraborty",
      "Ayodeji Alajo",
      "Ethan Taber",
      "Joseph Graham",
      "Syed Alam"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.13157"
  },
  {
    "id": "arXiv:2211.13172",
    "title": "Kernel PCA for multivariate extremes",
    "abstract": "We propose kernel PCA as a method for analyzing the dependence structure of\nmultivariate extremes and demonstrate that it can be a powerful tool for\nclustering and dimension reduction. Our work provides some theoretical insight\ninto the preimages obtained by kernel PCA, demonstrating that under certain\nconditions they can effectively identify clusters in the data. We build on\nthese new insights to characterize rigorously the performance of kernel PCA\nbased on an extremal sample, i.e., the angular part of random vectors for which\nthe radius exceeds a large threshold. More specifically, we focus on the\nasymptotic dependence of multivariate extremes characterized by the angular or\nspectral measure in extreme value theory and provide a careful analysis in the\ncase where the extremes are generated from a linear factor model. We give\ntheoretical guarantees on the performance of kernel PCA preimages of such\nextremes by leveraging their asymptotic distribution together with Davis-Kahan\nperturbation bounds. Our theoretical findings are complemented with numerical\nexperiments illustrating the finite sample performance of our methods.",
    "descriptor": "",
    "authors": [
      "Marco Avella-Medina",
      "Richard A. Davis",
      "Gennady Samorodnitsky"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2211.13172"
  },
  {
    "id": "arXiv:1910.03655",
    "title": "Executing Instructions in Situated Collaborative Interactions",
    "abstract": "Comments: EMNLP 2019 long paper",
    "descriptor": "\nComments: EMNLP 2019 long paper\n",
    "authors": [
      "Alane Suhr",
      "Claudia Yan",
      "Charlotte Schluger",
      "Stanley Yu",
      "Hadi Khader",
      "Marwa Mouallem",
      "Iris Zhang",
      "Yoav Artzi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1910.03655"
  },
  {
    "id": "arXiv:2002.10213",
    "title": "Superoptimization of WebAssembly Bytecode",
    "abstract": "Comments: 4 pages, 3 figures. Proceedings of MoreVMs: Workshop on Modern Language Runtimes, Ecosystems, and VMs (2020)",
    "descriptor": "\nComments: 4 pages, 3 figures. Proceedings of MoreVMs: Workshop on Modern Language Runtimes, Ecosystems, and VMs (2020)\n",
    "authors": [
      "Javier Cabrera-Arteaga",
      "Shrinish Donde",
      "Jian Gu",
      "Orestis Floros",
      "Lucas Satabin",
      "Benoit Baudry",
      "Martin Monperrus"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2002.10213"
  },
  {
    "id": "arXiv:2006.08690",
    "title": "Generalized and Scalable Optimal Sparse Decision Trees",
    "abstract": "Comments: This paper was published in ICML 2020",
    "descriptor": "\nComments: This paper was published in ICML 2020\n",
    "authors": [
      "Jimmy Lin",
      "Chudi Zhong",
      "Diane Hu",
      "Cynthia Rudin",
      "Margo Seltzer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.08690"
  },
  {
    "id": "arXiv:2012.00086",
    "title": "Bridging the Gap Between Tree and Connectivity Augmentation: Unified and  Stronger Approaches",
    "abstract": "Bridging the Gap Between Tree and Connectivity Augmentation: Unified and  Stronger Approaches",
    "descriptor": "",
    "authors": [
      "Federica Cecchetto",
      "Vera Traub",
      "Rico Zenklusen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2012.00086"
  },
  {
    "id": "arXiv:2012.10713",
    "title": "Fundamental Limits and Tradeoffs in Invariant Representation Learning",
    "abstract": "Comments: JMLR camera-ready version",
    "descriptor": "\nComments: JMLR camera-ready version\n",
    "authors": [
      "Han Zhao",
      "Chen Dan",
      "Bryon Aragam",
      "Tommi S. Jaakkola",
      "Geoffrey J. Gordon",
      "Pradeep Ravikumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2012.10713"
  },
  {
    "id": "arXiv:2101.12271",
    "title": "Fixpoints and relative precompleteness",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Anton Golov",
      "Sebastiaan A. Terwijn"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2101.12271"
  },
  {
    "id": "arXiv:2102.02465",
    "title": "LEAP: TrustZone Based Developer-Friendly TEE for Intelligent Mobile Apps",
    "abstract": "Comments: Accepted by IEEE Transactions on Mobile Computing",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Mobile Computing\n",
    "authors": [
      "Lizhi Sun",
      "Shuocheng Wang",
      "Hao Wu",
      "Yuhang Gong",
      "Fengyuan Xu",
      "Yunxin Liu",
      "Hao Han",
      "Sheng Zhong"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2102.02465"
  },
  {
    "id": "arXiv:2103.00065",
    "title": "Gradient Descent on Neural Networks Typically Occurs at the Edge of  Stability",
    "abstract": "Comments: ICLR 2021. v3 moves several figures from the appendix into the main text, and adds more discussion regarding Jastrz\\k{e}bski et al (2020): this https URL",
    "descriptor": "\nComments: ICLR 2021. v3 moves several figures from the appendix into the main text, and adds more discussion regarding Jastrz\\k{e}bski et al (2020): this https URL\n",
    "authors": [
      "Jeremy M. Cohen",
      "Simran Kaur",
      "Yuanzhi Li",
      "J. Zico Kolter",
      "Ameet Talwalkar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2103.00065"
  },
  {
    "id": "arXiv:2104.07128",
    "title": "Audio feature ranking for sound-based COVID-19 patient detection",
    "abstract": "Comments: 12 pages, 3 figures, 6 tables",
    "descriptor": "\nComments: 12 pages, 3 figures, 6 tables\n",
    "authors": [
      "Julia A. Meister",
      "Khuong An Nguyen",
      "Zhiyuan Luo"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2104.07128"
  },
  {
    "id": "arXiv:2104.11190",
    "title": "Multi-resolution Localized Orthogonal Decomposition for Helmholtz  problems",
    "abstract": "Comments: 27 pages, 9 figures",
    "descriptor": "\nComments: 27 pages, 9 figures\n",
    "authors": [
      "Moritz Hauck",
      "Daniel Peterseim"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2104.11190"
  },
  {
    "id": "arXiv:2105.10148",
    "title": "On Instrumental Variable Regression for Deep Offline Policy Evaluation",
    "abstract": "Comments: Accepted by Journal of Machine Learning Research in 11/2022",
    "descriptor": "\nComments: Accepted by Journal of Machine Learning Research in 11/2022\n",
    "authors": [
      "Yutian Chen",
      "Liyuan Xu",
      "Caglar Gulcehre",
      "Tom Le Paine",
      "Arthur Gretton",
      "Nando de Freitas",
      "Arnaud Doucet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2105.10148"
  },
  {
    "id": "arXiv:2107.02905",
    "title": "An in silico drug repurposing pipeline to identify drugs with the  potential to inhibit SARS-CoV-2 replication",
    "abstract": "Comments: 23 pages, 4 figures",
    "descriptor": "\nComments: 23 pages, 4 figures\n",
    "authors": [
      "M\u00e9abh MacMahon",
      "Woochang Hwang",
      "Soorin Yim",
      "Eoghan MacMahon",
      "Alexandre Abraham",
      "Justin Barton",
      "Mukunthan Tharmakulasingam",
      "Paul Bilokon",
      "Vasanthi Priyadarshini Gaddi",
      "Namshik Han"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Molecular Networks (q-bio.MN)"
    ],
    "url": "https://arxiv.org/abs/2107.02905"
  },
  {
    "id": "arXiv:2107.03884",
    "title": "CANDLE: Decomposing Conditional and Conjunctive Queries for  Task-Oriented Dialogue Systems",
    "abstract": "CANDLE: Decomposing Conditional and Conjunctive Queries for  Task-Oriented Dialogue Systems",
    "descriptor": "",
    "authors": [
      "Aadesh Gupta",
      "Kaustubh D.Dhole",
      "Rahul Tarway",
      "Swetha Prabhakar",
      "Ashish Shrivastava"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.03884"
  },
  {
    "id": "arXiv:2107.13211",
    "title": "Super-localization of elliptic multiscale problems",
    "abstract": "Comments: 22 pages, 7 figures",
    "descriptor": "\nComments: 22 pages, 7 figures\n",
    "authors": [
      "Moritz Hauck",
      "Daniel Peterseim"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2107.13211"
  },
  {
    "id": "arXiv:2108.00721",
    "title": "Quantitatively Nonblocking Supervisory Control of Discrete-Event Systems",
    "abstract": "Quantitatively Nonblocking Supervisory Control of Discrete-Event Systems",
    "descriptor": "",
    "authors": [
      "Renyuan Zhang",
      "Jiahao Wang",
      "Zenghui Wang",
      "Kai Cai"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.00721"
  },
  {
    "id": "arXiv:2108.12732",
    "title": "Feature Analysis for Machine Learning-based IoT Intrusion Detection",
    "abstract": "Comments: 22 pages, 6 figures. arXiv admin note: substantial text overlap with arXiv:2108.12722",
    "descriptor": "\nComments: 22 pages, 6 figures. arXiv admin note: substantial text overlap with arXiv:2108.12722\n",
    "authors": [
      "Mohanad Sarhan",
      "Siamak Layeghy",
      "Marius Portmann"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2108.12732"
  },
  {
    "id": "arXiv:2109.05084",
    "title": "Winding Through: Crowd Navigation via Topological Invariance",
    "abstract": "Comments: Final version to appear at IEEE RA-L - minor acknowledgments fix",
    "descriptor": "\nComments: Final version to appear at IEEE RA-L - minor acknowledgments fix\n",
    "authors": [
      "Christoforos Mavrogiannis",
      "Krishna Balasubramanian",
      "Sriyash Poddar",
      "Anush Gandra",
      "Siddhartha S. Srinivasa"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2109.05084"
  },
  {
    "id": "arXiv:2109.07744",
    "title": "Optimizing Hardware-Based Network Computation DAGs for Multiple Tenants  with SuperNIC",
    "abstract": "Comments: 17 pages",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Yizhou Shan",
      "Will Lin",
      "Ryan Kosta",
      "Arvind Krishnamurthy",
      "Yiying Zhang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.07744"
  },
  {
    "id": "arXiv:2109.07865",
    "title": "OMPQ: Orthogonal Mixed Precision Quantization",
    "abstract": "OMPQ: Orthogonal Mixed Precision Quantization",
    "descriptor": "",
    "authors": [
      "Yuexiao Ma",
      "Taisong Jin",
      "Xiawu Zheng",
      "Yan Wang",
      "Huixia Li",
      "Yongjian Wu",
      "Guannan Jiang",
      "Wei Zhang",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.07865"
  },
  {
    "id": "arXiv:2109.09943",
    "title": "Identifiability of Chemical Reaction Networks with Intrinsic and  Extrinsic Noise from Stationary Distributions",
    "abstract": "Comments: 27 pages, 1 figure, 1 table. The extrinsic noise section is revised, and minor edits have been made throughout",
    "descriptor": "\nComments: 27 pages, 1 figure, 1 table. The extrinsic noise section is revised, and minor edits have been made throughout\n",
    "authors": [
      "Theodore W. Grunberg",
      "Domitilla Del Vecchio"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.09943"
  },
  {
    "id": "arXiv:2109.10902",
    "title": "Mixed-supervised segmentation: Confidence maximization helps knowledge  distillation",
    "abstract": "Comments: To be published at Medical Image Analysis (Volume 83, January 2023). Code: this https URL Note: this article is a journal extension of our paper in IPMI 2021 arXiv:2012.08051",
    "descriptor": "\nComments: To be published at Medical Image Analysis (Volume 83, January 2023). Code: this https URL Note: this article is a journal extension of our paper in IPMI 2021 arXiv:2012.08051\n",
    "authors": [
      "Bingyuan Liu",
      "Christian Desrosiers",
      "Ismail Ben Ayed",
      "Jose Dolz"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.10902"
  },
  {
    "id": "arXiv:2109.13532",
    "title": "Template-free Prompt Tuning for Few-shot NER",
    "abstract": "Comments: Accepted by NAACL 2022 (Oral)",
    "descriptor": "\nComments: Accepted by NAACL 2022 (Oral)\n",
    "authors": [
      "Ruotian Ma",
      "Xin Zhou",
      "Tao Gui",
      "Yiding Tan",
      "Linyang Li",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.13532"
  },
  {
    "id": "arXiv:2110.00990",
    "title": "Hierarchical Kinematic Probability Distributions for 3D Human Shape and  Pose Estimation from Images in the Wild",
    "abstract": "Comments: ICCV 2021 (Edited to reduce file size)",
    "descriptor": "\nComments: ICCV 2021 (Edited to reduce file size)\n",
    "authors": [
      "Akash Sengupta",
      "Ignas Budvytis",
      "Roberto Cipolla"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.00990"
  },
  {
    "id": "arXiv:2110.05983",
    "title": "Network-Aware Flexibility Requests for Distribution-Level Flexibility  Markets",
    "abstract": "Network-Aware Flexibility Requests for Distribution-Level Flexibility  Markets",
    "descriptor": "",
    "authors": [
      "El\u00e9a Prat",
      "Irena Dukovska",
      "Lars Herre",
      "Rahul Nellikkath",
      "Malte Thoma",
      "Spyros Chatzivasileiadis"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2110.05983"
  },
  {
    "id": "arXiv:2111.10722",
    "title": "A Deterministic Sampling Method via Maximum Mean Discrepancy Flow with  Adaptive Kernel",
    "abstract": "Comments: 25 pages, 9 figures",
    "descriptor": "\nComments: 25 pages, 9 figures\n",
    "authors": [
      "Yindong Chen",
      "Yiwei Wang",
      "Lulu Kang",
      "Chun Liu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.10722"
  },
  {
    "id": "arXiv:2111.12545",
    "title": "Data2Model: Predicting Models from Training Data",
    "abstract": "Data2Model: Predicting Models from Training Data",
    "descriptor": "",
    "authors": [
      "Yingyan Zeng",
      "Tianhao Wang",
      "Si Chen",
      "Hoang Anh Just",
      "Ran Jin",
      "Ruoxi Jia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2111.12545"
  },
  {
    "id": "arXiv:2111.12791",
    "title": "Handling Inter-class and Intra-class Imbalance in Class-imbalanced  Learning",
    "abstract": "Comments: 15 pages, 4 tables, 12 figures",
    "descriptor": "\nComments: 15 pages, 4 tables, 12 figures\n",
    "authors": [
      "Zhining Liu",
      "Pengfei Wei",
      "Zhepei Wei",
      "Boyang Yu",
      "Jing Jiang",
      "Wei Cao",
      "Jiang Bian",
      "Yi Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.12791"
  },
  {
    "id": "arXiv:2111.13208",
    "title": "Evaluation of Interpretability for Deep Learning algorithms in EEG  Emotion Recognition: A case study in Autism",
    "abstract": "Evaluation of Interpretability for Deep Learning algorithms in EEG  Emotion Recognition: A case study in Autism",
    "descriptor": "",
    "authors": [
      "Juan Manuel Mayor-Torres",
      "Sara Medina-DeVilliers",
      "Tessa Clarkson",
      "Matthew D. Lerner",
      "Giuseppe Riccardi"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.13208"
  },
  {
    "id": "arXiv:2112.00845",
    "title": "Improving Differentially Private SGD via Randomly Sparsified Gradients",
    "abstract": "Improving Differentially Private SGD via Randomly Sparsified Gradients",
    "descriptor": "",
    "authors": [
      "Junyi Zhu",
      "Matthew B. Blaschko"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.00845"
  },
  {
    "id": "arXiv:2112.05539",
    "title": "Spaces of Besov-Sobolev type and a problem on nonlinear approximation",
    "abstract": "Comments: 45 pages",
    "descriptor": "\nComments: 45 pages\n",
    "authors": [
      "\u00d3scar Dom\u00ednguez",
      "Andreas Seeger",
      "Brian Street",
      "Jean Van Schaftingen",
      "Po-Lam Yung"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Classical Analysis and ODEs (math.CA)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.05539"
  },
  {
    "id": "arXiv:2112.05851",
    "title": "Short and Long Range Relation Based Spatio-Temporal Transformer for  Micro-Expression Recognition",
    "abstract": "Comments: 13 pages, 9 figures",
    "descriptor": "\nComments: 13 pages, 9 figures\n",
    "authors": [
      "Liangfei Zhang",
      "Xiaopeng Hong",
      "Ognjen Arandjelovic",
      "Guoying Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.05851"
  },
  {
    "id": "arXiv:2112.06320",
    "title": "Anomaly Crossing: New Horizons for Video Anomaly Detection as  Cross-domain Few-shot Learning",
    "abstract": "Anomaly Crossing: New Horizons for Video Anomaly Detection as  Cross-domain Few-shot Learning",
    "descriptor": "",
    "authors": [
      "Guangyu Sun",
      "Zhang Liu",
      "Lianggong Wen",
      "Jing Shi",
      "Chenliang Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.06320"
  },
  {
    "id": "arXiv:2112.08507",
    "title": "Algorithms for Adaptive Experiments that Trade-off Statistical Analysis  with Reward: Combining Uniform Random Assignment and Reward Maximization",
    "abstract": "Algorithms for Adaptive Experiments that Trade-off Statistical Analysis  with Reward: Combining Uniform Random Assignment and Reward Maximization",
    "descriptor": "",
    "authors": [
      "Tong Li",
      "Jacob Nogas",
      "Haochen Song",
      "Harsh Kumar",
      "Audrey Durand",
      "Anna Rafferty",
      "Nina Deliu",
      "Sofia S. Villar",
      "Joseph J. Williams"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.08507"
  },
  {
    "id": "arXiv:2112.08534",
    "title": "Trading with the Momentum Transformer: An Intelligent and Interpretable  Architecture",
    "abstract": "Comments: included motivation for attention mechanism and additional architecture details",
    "descriptor": "\nComments: included motivation for attention mechanism and additional architecture details\n",
    "authors": [
      "Kieran Wood",
      "Sven Giegerich",
      "Stephen Roberts",
      "Stefan Zohren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Trading and Market Microstructure (q-fin.TR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.08534"
  },
  {
    "id": "arXiv:2112.08676",
    "title": "Machine Learning-Accelerated Computational Solid Mechanics: Application  to Linear Elasticity",
    "abstract": "Comments: 3 figures, 9 pages, Accepted in AAAI 2022: Workshop on AI to Accelerate Science and Engineering (AI2ASE)",
    "descriptor": "\nComments: 3 figures, 9 pages, Accepted in AAAI 2022: Workshop on AI to Accelerate Science and Engineering (AI2ASE)\n",
    "authors": [
      "Rajat Arora"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Materials Science (cond-mat.mtrl-sci)"
    ],
    "url": "https://arxiv.org/abs/2112.08676"
  },
  {
    "id": "arXiv:2112.10608",
    "title": "Model order reduction strategies for weakly dispersive waves",
    "abstract": "Model order reduction strategies for weakly dispersive waves",
    "descriptor": "",
    "authors": [
      "Davide Torlo",
      "Mario Ricchiuto"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.10608"
  },
  {
    "id": "arXiv:2112.15454",
    "title": "Advanced Drone Swarm Security by Using Blockchain Governance Game",
    "abstract": "Comments: Song-Kyoo Kim, Advanced Drone Swarm Security by Using Blockchain Governance Game, Mathematics 10:18 (2022), 3338",
    "descriptor": "\nComments: Song-Kyoo Kim, Advanced Drone Swarm Security by Using Blockchain Governance Game, Mathematics 10:18 (2022), 3338\n",
    "authors": [
      "Song-Kyoo Kim"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2112.15454"
  },
  {
    "id": "arXiv:2201.07532",
    "title": "Consensus of Homogeneous Agents with General Linear Dynamics under  Switching Communication Networks",
    "abstract": "Consensus of Homogeneous Agents with General Linear Dynamics under  Switching Communication Networks",
    "descriptor": "",
    "authors": [
      "Chong Jin Ong",
      "Ilayda Canyakmaz"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.07532"
  },
  {
    "id": "arXiv:2201.08363",
    "title": "Physics-informed neural networks for modeling rate- and  temperature-dependent plasticity",
    "abstract": "Comments: 11 pages, 7 figures; Accepted in NeurIPS 2022, Machine Learning and the Physical Sciences workshop",
    "descriptor": "\nComments: 11 pages, 7 figures; Accepted in NeurIPS 2022, Machine Learning and the Physical Sciences workshop\n",
    "authors": [
      "Rajat Arora",
      "Pratik Kakkar",
      "Biswadip Dey",
      "Amit Chakraborty"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.08363"
  },
  {
    "id": "arXiv:2202.04414",
    "title": "Agree to Disagree: Diversity through Disagreement for Better  Transferability",
    "abstract": "Comments: 23 pages, 17 figures",
    "descriptor": "\nComments: 23 pages, 17 figures\n",
    "authors": [
      "Matteo Pagliardini",
      "Martin Jaggi",
      "Fran\u00e7ois Fleuret",
      "Sai Praneeth Karimireddy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04414"
  },
  {
    "id": "arXiv:2202.04629",
    "title": "Reducing Redundancy in the Bottleneck Representation of the Autoencoders",
    "abstract": "Comments: 6 pages,4 figures. The paper is under consideration at Pattern Recognition Letters",
    "descriptor": "\nComments: 6 pages,4 figures. The paper is under consideration at Pattern Recognition Letters\n",
    "authors": [
      "Firas Laakom",
      "Jenni Raitoharju",
      "Alexandros Iosifidis",
      "Moncef Gabbouj"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.04629"
  },
  {
    "id": "arXiv:2202.08408",
    "title": "Multivariate Time Series Forecasting with Dynamic Graph Neural ODEs",
    "abstract": "Comments: 14 pages, 6 figures, 5 tables",
    "descriptor": "\nComments: 14 pages, 6 figures, 5 tables\n",
    "authors": [
      "Ming Jin",
      "Yu Zheng",
      "Yuan-Fang Li",
      "Siheng Chen",
      "Bin Yang",
      "Shirui Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08408"
  },
  {
    "id": "arXiv:2202.09834",
    "title": "Real-time Model Predictive Control and System Identification Using  Differentiable Physics Simulation",
    "abstract": "Real-time Model Predictive Control and System Identification Using  Differentiable Physics Simulation",
    "descriptor": "",
    "authors": [
      "Sirui Chen",
      "Keenon Werling",
      "Albert Wu",
      "C. Karen Liu"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2202.09834"
  },
  {
    "id": "arXiv:2203.07706",
    "title": "ActFormer: A GAN-based Transformer towards General Action-Conditioned 3D  Human Motion Generation",
    "abstract": "ActFormer: A GAN-based Transformer towards General Action-Conditioned 3D  Human Motion Generation",
    "descriptor": "",
    "authors": [
      "Liang Xu",
      "Ziyang Song",
      "Dongliang Wang",
      "Jing Su",
      "Zhicheng Fang",
      "Chenjing Ding",
      "Weihao Gan",
      "Yichao Yan",
      "Xin Jin",
      "Xiaokang Yang",
      "Wenjun Zeng",
      "Wei Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2203.07706"
  },
  {
    "id": "arXiv:2203.09230",
    "title": "Surgical Workflow Recognition: from Analysis of Challenges to  Architectural Study",
    "abstract": "Comments: 11 pages, 2 figures",
    "descriptor": "\nComments: 11 pages, 2 figures\n",
    "authors": [
      "Tobias Czempiel",
      "Aidean Sharghi",
      "Magdalini Paschali",
      "Nassir Navab",
      "Omid Mohareri"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.09230"
  },
  {
    "id": "arXiv:2203.09634",
    "title": "Predicate Invention for Bilevel Planning",
    "abstract": "Comments: AAAI 2023. Short version appeared at RLDM 2022",
    "descriptor": "\nComments: AAAI 2023. Short version appeared at RLDM 2022\n",
    "authors": [
      "Tom Silver",
      "Rohan Chitnis",
      "Nishanth Kumar",
      "Willie McClinton",
      "Tomas Lozano-Perez",
      "Leslie Pack Kaelbling",
      "Joshua Tenenbaum"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2203.09634"
  },
  {
    "id": "arXiv:2203.13533",
    "title": "High-Performance Transformer Tracking",
    "abstract": "Comments: arXiv admin note: substantial text overlap with arXiv:2103.15436",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2103.15436\n",
    "authors": [
      "Xin Chen",
      "Bin Yan",
      "Jiawen Zhu",
      "Huchuan Lu",
      "Xiang Ruan",
      "Dong Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13533"
  },
  {
    "id": "arXiv:2203.13696",
    "title": "Speech-enhanced and Noise-aware Networks for Robust Speech Recognition",
    "abstract": "Comments: Published in ISCSLP 2022",
    "descriptor": "\nComments: Published in ISCSLP 2022\n",
    "authors": [
      "Hung-Shin Lee",
      "Pin-Yuan Chen",
      "Yao-Fei Cheng",
      "Yu Tsao",
      "Hsin-Min Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.13696"
  },
  {
    "id": "arXiv:2203.13964",
    "title": "Fusing Global and Local Features for Generalized AI-Synthesized Image  Detection",
    "abstract": "Comments: 5 pages, 3 figures, 2 tables",
    "descriptor": "\nComments: 5 pages, 3 figures, 2 tables\n",
    "authors": [
      "Yan Ju",
      "Shan Jia",
      "Lipeng Ke",
      "Hongfei Xue",
      "Koki Nagano",
      "Siwei Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2203.13964"
  },
  {
    "id": "arXiv:2203.16369",
    "title": "Incorporating Dynamic Semantics into Pre-Trained Language Model for  Aspect-based Sentiment Analysis",
    "abstract": "Comments: 12 pages, 5 figures",
    "descriptor": "\nComments: 12 pages, 5 figures\n",
    "authors": [
      "Kai Zhang",
      "Kun Zhang",
      "Mengdi Zhang",
      "Hongke Zhao",
      "Qi Liu",
      "Wei Wu",
      "Enhong Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2203.16369"
  },
  {
    "id": "arXiv:2203.16502",
    "title": "Generative Spoken Dialogue Language Modeling",
    "abstract": "Generative Spoken Dialogue Language Modeling",
    "descriptor": "",
    "authors": [
      "Tu Anh Nguyen",
      "Eugene Kharitonov",
      "Jade Copet",
      "Yossi Adi",
      "Wei-Ning Hsu",
      "Ali Elkahky",
      "Paden Tomasello",
      "Robin Algayres",
      "Benoit Sagot",
      "Abdelrahman Mohamed",
      "Emmanuel Dupoux"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2203.16502"
  },
  {
    "id": "arXiv:2204.03726",
    "title": "Decentralized Event-Triggered Federated Learning with Heterogeneous  Communication Thresholds",
    "abstract": "Decentralized Event-Triggered Federated Learning with Heterogeneous  Communication Thresholds",
    "descriptor": "",
    "authors": [
      "Shahryar Zehtabi",
      "Seyyedali Hosseinalipour",
      "Christopher G. Brinton"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2204.03726"
  },
  {
    "id": "arXiv:2204.03747",
    "title": "Implementation and Experimental Validation of Data-Driven Predictive  Control for Dissipating Stop-and-Go Waves in Mixed Traffic",
    "abstract": "Comments: 14 pages, 11 figures",
    "descriptor": "\nComments: 14 pages, 11 figures\n",
    "authors": [
      "Jiawei Wang",
      "Yang Zheng",
      "Jianghong Dong",
      "Chaoyi Chen",
      "Mengchi Cai",
      "Keqiang Li",
      "Qing Xu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2204.03747"
  },
  {
    "id": "arXiv:2204.03974",
    "title": "A General Framework for Hierarchical Redundancy Resolution Under  Arbitrary Constraints",
    "abstract": "Comments: Submitted to Transactions on Robotics (T-RO). Currently under the second round of review. 20 pages, 19 figures",
    "descriptor": "\nComments: Submitted to Transactions on Robotics (T-RO). Currently under the second round of review. 20 pages, 19 figures\n",
    "authors": [
      "Mario D. Fiore",
      "Gaetano Meli",
      "Anton Ziese",
      "Bruno Siciliano",
      "Ciro Natale"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2204.03974"
  },
  {
    "id": "arXiv:2204.11515",
    "title": "Multimodal Dual Emotion with Fusion of Visual Sentiment for Rumor  Detection",
    "abstract": "Comments: There is an error in the experimental recording process, and the results reported in the article need to be re-checked",
    "descriptor": "\nComments: There is an error in the experimental recording process, and the results reported in the article need to be re-checked\n",
    "authors": [
      "Ge Wang",
      "Li Tan",
      "Ziliang Shang",
      "He Liu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2204.11515"
  },
  {
    "id": "arXiv:2204.12436",
    "title": "Incentives in Social Decision Schemes with Pairwise Comparison  Preferences",
    "abstract": "Comments: A preliminary version appeared in the 31st International Joint Conference on Artificial Intelligence (IJCAI), 2022. The current version is significantly extended",
    "descriptor": "\nComments: A preliminary version appeared in the 31st International Joint Conference on Artificial Intelligence (IJCAI), 2022. The current version is significantly extended\n",
    "authors": [
      "Felix Brandt",
      "Patrick Lederer",
      "Warut Suksompong"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Theoretical Economics (econ.TH)"
    ],
    "url": "https://arxiv.org/abs/2204.12436"
  },
  {
    "id": "arXiv:2205.01491",
    "title": "A Comprehensive Survey of Image Augmentation Techniques for Deep  Learning",
    "abstract": "Comments: Revision",
    "descriptor": "\nComments: Revision\n",
    "authors": [
      "Mingle Xu",
      "Sook Yoon",
      "Alvaro Fuentes",
      "Dong Sun Park"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2205.01491"
  },
  {
    "id": "arXiv:2205.02003",
    "title": "Multi-subgoal Robot Navigation in Crowds with History Information and  Interactions",
    "abstract": "Multi-subgoal Robot Navigation in Crowds with History Information and  Interactions",
    "descriptor": "",
    "authors": [
      "Xinyi Yu",
      "Jianan Hu",
      "Yuehai Fan",
      "Wancai Zheng",
      "Linlin Ou"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2205.02003"
  },
  {
    "id": "arXiv:2205.02304",
    "title": "Operator inference for non-intrusive model reduction with quadratic  manifolds",
    "abstract": "Operator inference for non-intrusive model reduction with quadratic  manifolds",
    "descriptor": "",
    "authors": [
      "Rudy Geelen",
      "Stephen Wright",
      "Karen Willcox"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2205.02304"
  },
  {
    "id": "arXiv:2205.03597",
    "title": "Evolving Collaboration, Dependencies, and Use in the Rust Open Source  Software Ecosystem",
    "abstract": "Evolving Collaboration, Dependencies, and Use in the Rust Open Source  Software Ecosystem",
    "descriptor": "",
    "authors": [
      "William Schueller",
      "Johannes Wachs",
      "Vito D.P. Servedio",
      "Stefan Thurner",
      "Vittorio Loreto"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2205.03597"
  },
  {
    "id": "arXiv:2205.05052",
    "title": "On learning agent-based models from data",
    "abstract": "On learning agent-based models from data",
    "descriptor": "",
    "authors": [
      "Corrado Monti",
      "Marco Pangallo",
      "Gianmarco De Francisci Morales",
      "Francesco Bonchi"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Machine Learning (cs.LG)",
      "Econometrics (econ.EM)"
    ],
    "url": "https://arxiv.org/abs/2205.05052"
  },
  {
    "id": "arXiv:2205.09634",
    "title": "Phylogeny-Inspired Adaptation of Multilingual Models to New Languages",
    "abstract": "Comments: accepted in AACL 2022 Main Conference",
    "descriptor": "\nComments: accepted in AACL 2022 Main Conference\n",
    "authors": [
      "Fahim Faisal",
      "Antonios Anastasopoulos"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2205.09634"
  },
  {
    "id": "arXiv:2205.15032",
    "title": "Structure of non-negative posets of Dynkin type $\\mathbb{A}_n$",
    "abstract": "Comments: 17 pages; Example 2.4 corrected, typos corrected, references added",
    "descriptor": "\nComments: 17 pages; Example 2.4 corrected, typos corrected, references added\n",
    "authors": [
      "Marcin G\u0105siorek"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2205.15032"
  },
  {
    "id": "arXiv:2205.15448",
    "title": "FeatER: An Efficient Network for Human Reconstruction via Feature  Map-Based TransformER",
    "abstract": "FeatER: An Efficient Network for Human Reconstruction via Feature  Map-Based TransformER",
    "descriptor": "",
    "authors": [
      "Ce Zheng",
      "Matias Mendieta",
      "Taojiannan Yang",
      "Guo-Jun Qi",
      "Chen Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2205.15448"
  },
  {
    "id": "arXiv:2206.01178",
    "title": "Discretization Invariant Learning on Neural Fields",
    "abstract": "Comments: Presented at NeurIPS 2022 Symmetry and Geometry in Neural Representations (NeurReps) Workshop",
    "descriptor": "\nComments: Presented at NeurIPS 2022 Symmetry and Geometry in Neural Representations (NeurReps) Workshop\n",
    "authors": [
      "Clinton J. Wang",
      "Polina Golland"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2206.01178"
  },
  {
    "id": "arXiv:2206.04030",
    "title": "High-dimensional limit theorems for SGD: Effective dynamics and critical  scaling",
    "abstract": "Comments: Minor edits and new analysis of overparametrization in the XOR Gaussian mixture model. 38 pages, 11 figures",
    "descriptor": "\nComments: Minor edits and new analysis of overparametrization in the XOR Gaussian mixture model. 38 pages, 11 figures\n",
    "authors": [
      "Gerard Ben Arous",
      "Reza Gheissari",
      "Aukosh Jagannath"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2206.04030"
  },
  {
    "id": "arXiv:2206.07665",
    "title": "Region-enhanced Deep Graph Convolutional Networks for Rumor Detection",
    "abstract": "Comments: Due to the error in the hyperparameter record during the repeated experiment, there are problems in reproducing the results",
    "descriptor": "\nComments: Due to the error in the hyperparameter record during the repeated experiment, there are problems in reproducing the results\n",
    "authors": [
      "Ge Wang",
      "Li Tan",
      "Tianbao Song",
      "Wei Wang",
      "Ziliang Shang"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.07665"
  },
  {
    "id": "arXiv:2206.08182",
    "title": "Nucleus Segmentation and Analysis in Breast Cancer with the MIScnn  Framework",
    "abstract": "Comments: Error in Table 3.4 (moved row)",
    "descriptor": "\nComments: Error in Table 3.4 (moved row)\n",
    "authors": [
      "Adrian Pfleiderer",
      "Dominik M\u00fcller",
      "Frank Kramer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.08182"
  },
  {
    "id": "arXiv:2206.08287",
    "title": "Definition drives design: Disability models and mechanisms of bias in AI  technologies",
    "abstract": "Comments: 38 pages, 1 figure, 2 tables. Keywords: artificial intelligence; critical disability studies; information and communication technologies; data analytics; data science; fairness, accountability, transparency, and ethics",
    "descriptor": "\nComments: 38 pages, 1 figure, 2 tables. Keywords: artificial intelligence; critical disability studies; information and communication technologies; data analytics; data science; fairness, accountability, transparency, and ethics\n",
    "authors": [
      "Denis Newman-Griffis",
      "Jessica Sage Rauchberg",
      "Rahaf Alharbi",
      "Louise Hickman",
      "Harry Hochheiser"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2206.08287"
  },
  {
    "id": "arXiv:2206.08903",
    "title": "Colonoscopy 3D Video Dataset with Paired Depth from 2D-3D Registration",
    "abstract": "Colonoscopy 3D Video Dataset with Paired Depth from 2D-3D Registration",
    "descriptor": "",
    "authors": [
      "Taylor L. Bobrow",
      "Mayank Golhar",
      "Rohan Vijayan",
      "Venkata S. Akshintala",
      "Juan R. Garcia",
      "Nicholas J. Durr"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.08903"
  },
  {
    "id": "arXiv:2206.09900",
    "title": "Voxel-MAE: Masked Autoencoders for Self-supervised Pre-training  Large-scale Point Clouds",
    "abstract": "Comments: 10 pages, 4 figures",
    "descriptor": "\nComments: 10 pages, 4 figures\n",
    "authors": [
      "Chen Min",
      "Xinli Xu",
      "Dawei Zhao",
      "Liang Xiao",
      "Yiming Nie",
      "Bin Dai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.09900"
  },
  {
    "id": "arXiv:2206.10897",
    "title": "How to Combine Variational Bayesian Networks in Federated Learning",
    "abstract": "How to Combine Variational Bayesian Networks in Federated Learning",
    "descriptor": "",
    "authors": [
      "Atahan Ozer",
      "Kadir Burak Buldu",
      "Abdullah Akg\u00fcl",
      "Gozde Unal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.10897"
  },
  {
    "id": "arXiv:2206.11104",
    "title": "OpenXAI: Towards a Transparent Evaluation of Model Explanations",
    "abstract": "Comments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022) Track on Datasets and Benchmarks",
    "descriptor": "\nComments: 36th Conference on Neural Information Processing Systems (NeurIPS 2022) Track on Datasets and Benchmarks\n",
    "authors": [
      "Chirag Agarwal",
      "Satyapriya Krishna",
      "Eshika Saxena",
      "Martin Pawelczyk",
      "Nari Johnson",
      "Isha Puri",
      "Marinka Zitnik",
      "Himabindu Lakkaraju"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2206.11104"
  },
  {
    "id": "arXiv:2206.11134",
    "title": "Open Vocabulary Object Detection with Proposal Mining and Prediction  Equalization",
    "abstract": "Open Vocabulary Object Detection with Proposal Mining and Prediction  Equalization",
    "descriptor": "",
    "authors": [
      "Peixian Chen",
      "Kekai Sheng",
      "Mengdan Zhang",
      "Mingbao Lin",
      "Yunhang Shen",
      "Ke Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2206.11134"
  },
  {
    "id": "arXiv:2206.12822",
    "title": "Design and Performance Analysis of AFDM with Multiple Antennas in Doubly  Selective Channels",
    "abstract": "Design and Performance Analysis of AFDM with Multiple Antennas in Doubly  Selective Channels",
    "descriptor": "",
    "authors": [
      "Haoran Yin",
      "Xizhang Wei",
      "Yanqun Tang",
      "Kai Yang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2206.12822"
  },
  {
    "id": "arXiv:2206.15457",
    "title": "PhySRNet: Physics informed super-resolution network for application in  computational solid mechanics",
    "abstract": "Comments: 14 pages, 3 figures, arXiv admin note: text overlap with arXiv:2112.08676",
    "descriptor": "\nComments: 14 pages, 3 figures, arXiv admin note: text overlap with arXiv:2112.08676\n",
    "authors": [
      "Rajat Arora"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2206.15457"
  },
  {
    "id": "arXiv:2207.03809",
    "title": "UDRN: Unified Dimensional Reduction Neural Network for Feature Selection  and Feature Projection",
    "abstract": "Comments: 14 pages, 7 figures",
    "descriptor": "\nComments: 14 pages, 7 figures\n",
    "authors": [
      "Zelin Zang",
      "Yongjie Xu",
      "Linyan Lu",
      "Yulan Geng",
      "Senqiao Yang",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.03809"
  },
  {
    "id": "arXiv:2207.05616",
    "title": "Set input-to-state stability under input delays for nonlinear systems  with disturbances",
    "abstract": "Comments: 11 pages",
    "descriptor": "\nComments: 11 pages\n",
    "authors": [
      "Pallavi Sinha",
      "Irinel-Constantin Mor\u0103rescu",
      "Sukumar Srikant"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2207.05616"
  },
  {
    "id": "arXiv:2207.08467",
    "title": "Segmenting white matter hyperintensities on isotropic three-dimensional  Fluid Attenuated Inversion Recovery magnetic resonance images: A comparison  of Deep learning tools on a Norwegian national imaging database",
    "abstract": "Comments: 20 Pages, 9 Figures, 2 Tables",
    "descriptor": "\nComments: 20 Pages, 9 Figures, 2 Tables\n",
    "authors": [
      "Martin Soria R\u00f8vang",
      "Per Selnes",
      "Bradley John MacIntosh",
      "Inge Rasmus Groote",
      "Lene Paalhaugen",
      "Tormod Fladby",
      "Atle Bjoernerud"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.08467"
  },
  {
    "id": "arXiv:2207.09640",
    "title": "Test-Time Adaptation via Conjugate Pseudo-labels",
    "abstract": "Comments: Published in Neural Information Processing Systems (NeurIPS) 2022",
    "descriptor": "\nComments: Published in Neural Information Processing Systems (NeurIPS) 2022\n",
    "authors": [
      "Sachin Goyal",
      "Mingjie Sun",
      "Aditi Raghunathan",
      "Zico Kolter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2207.09640"
  },
  {
    "id": "arXiv:2207.10397",
    "title": "CodeT: Code Generation with Generated Tests",
    "abstract": "CodeT: Code Generation with Generated Tests",
    "descriptor": "",
    "authors": [
      "Bei Chen",
      "Fengji Zhang",
      "Anh Nguyen",
      "Daoguang Zan",
      "Zeqi Lin",
      "Jian-Guang Lou",
      "Weizhu Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2207.10397"
  },
  {
    "id": "arXiv:2207.12396",
    "title": "Exploring CLIP for Assessing the Look and Feel of Images",
    "abstract": "Comments: Accepted by AAAI2023. Code: this https URL",
    "descriptor": "\nComments: Accepted by AAAI2023. Code: this https URL\n",
    "authors": [
      "Jianyi Wang",
      "Kelvin C.K. Chan",
      "Chen Change Loy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2207.12396"
  },
  {
    "id": "arXiv:2207.13572",
    "title": "Membership Inference Attacks via Adversarial Examples",
    "abstract": "Comments: Trustworthy and Socially Responsible Machine Learning (TSRML 2022) co-located with NeurIPS 2022",
    "descriptor": "\nComments: Trustworthy and Socially Responsible Machine Learning (TSRML 2022) co-located with NeurIPS 2022\n",
    "authors": [
      "Hamid Jalalzai",
      "Elie Kadoche",
      "R\u00e9mi Leluc",
      "Vincent Plassier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2207.13572"
  },
  {
    "id": "arXiv:2208.01711",
    "title": "Optimal Rates for Regularized Conditional Mean Embedding Learning",
    "abstract": "Optimal Rates for Regularized Conditional Mean Embedding Learning",
    "descriptor": "",
    "authors": [
      "Zhu Li",
      "Dimitri Meunier",
      "Mattes Mollenhauer",
      "Arthur Gretton"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.01711"
  },
  {
    "id": "arXiv:2208.03288",
    "title": "Convolutional Ensembling based Few-Shot Defect Detection Technique",
    "abstract": "Comments: 7 pages, 7 images",
    "descriptor": "\nComments: 7 pages, 7 images\n",
    "authors": [
      "Soumyajit Karmakar",
      "Abeer Banerjee",
      "Prashant Sadashiv Gidde",
      "Sumeet Saurav",
      "Sanjay Singh"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.03288"
  },
  {
    "id": "arXiv:2208.03571",
    "title": "Transformer-based assignment decision network for multiple object  tracking",
    "abstract": "Comments: Preprint version. Under consideration at Computer Vision and Image Understanding",
    "descriptor": "\nComments: Preprint version. Under consideration at Computer Vision and Image Understanding\n",
    "authors": [
      "Athena Psalta",
      "Vasileios Tsironis",
      "Konstantinos Karantzalos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.03571"
  },
  {
    "id": "arXiv:2208.03683",
    "title": "Terahertz-Band Channel and Beam Split Estimation via Array Perturbation  Model",
    "abstract": "Comments: This work has been submitted to the IEEE for publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Ahmet M. Elbir",
      "Wei Shi",
      "Anastasios K. Papazafeiropoulos",
      "Pandelis Kourtessis",
      "Symeon Chatzinotas"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2208.03683"
  },
  {
    "id": "arXiv:2208.03792",
    "title": "Domain Randomization-Enhanced Depth Simulation and Restoration for  Perceiving and Grasping Specular and Transparent Objects",
    "abstract": "Comments: ECCV 2022",
    "descriptor": "\nComments: ECCV 2022\n",
    "authors": [
      "Qiyu Dai",
      "Jiyao Zhang",
      "Qiwei Li",
      "Tianhao Wu",
      "Hao Dong",
      "Ziyuan Liu",
      "Ping Tan",
      "He Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.03792"
  },
  {
    "id": "arXiv:2208.03985",
    "title": "Generating Coherent Narratives by Learning Dynamic and Discrete Entity  States with a Contrastive Framework",
    "abstract": "Comments: Accepted in AAAI 2023; 7 pages",
    "descriptor": "\nComments: Accepted in AAAI 2023; 7 pages\n",
    "authors": [
      "Jian Guan",
      "Zhenyu Yang",
      "Rongsheng Zhang",
      "Zhipeng Hu",
      "Minlie Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2208.03985"
  },
  {
    "id": "arXiv:2208.04405",
    "title": "Recovering the Graph Underlying Networked Dynamical Systems under  Partial Observability: A Deep Learning Approach",
    "abstract": "Comments: Accepted at The 37th AAAI Conference on Artificial Intelligence (main track)",
    "descriptor": "\nComments: Accepted at The 37th AAAI Conference on Artificial Intelligence (main track)\n",
    "authors": [
      "S\u00e9rgio Machado",
      "Anirudh Sridhar",
      "Paulo Gil",
      "Jorge Henriques",
      "Jos\u00e9 M. F. Moura",
      "Augusto Santos"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2208.04405"
  },
  {
    "id": "arXiv:2208.05192",
    "title": "Real-Time Oil Leakage Detection on Aftermarket Motorcycle Damping System  with Convolutional Neural Networks",
    "abstract": "Comments: analysis of literature reviewed, n.2 figures added, minor corrections",
    "descriptor": "\nComments: analysis of literature reviewed, n.2 figures added, minor corrections\n",
    "authors": [
      "Federico Bianchi",
      "Stefano Speziali",
      "Andrea Marini",
      "Massimiliano Proietti",
      "Lorenzo Menculini",
      "Alberto Garinei",
      "Gabriele Bellani",
      "Marcello Marconi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.05192"
  },
  {
    "id": "arXiv:2208.06081",
    "title": "Slicing4Meta: An Intelligent Integration Framework with  Multi-dimensional Network Resources for Metaverse-as-a-Service in Web 3.0",
    "abstract": "Slicing4Meta: An Intelligent Integration Framework with  Multi-dimensional Network Resources for Metaverse-as-a-Service in Web 3.0",
    "descriptor": "",
    "authors": [
      "Yi-Jing Liu",
      "Hongyang Du",
      "Dusit Niyato",
      "Gang Feng",
      "Jiawen Kang",
      "Zehui Xiong"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2208.06081"
  },
  {
    "id": "arXiv:2208.06163",
    "title": "Dropout is NOT All You Need to Prevent Gradient Leakage",
    "abstract": "Comments: 25 pages, 17 figures, 9 tables (supplementary material included)",
    "descriptor": "\nComments: 25 pages, 17 figures, 9 tables (supplementary material included)\n",
    "authors": [
      "Daniel Scheliga",
      "Patrick M\u00e4der",
      "Marco Seeland"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.06163"
  },
  {
    "id": "arXiv:2208.08846",
    "title": "Oh SSH-it, what's my fingerprint? A Large-Scale Analysis of SSH Host Key  Fingerprint Verification Records in the DNS",
    "abstract": "Comments: Preprint; submitted to CANS 2022; accepted at CANS 2022 and published in Springer LNCS vol 13641",
    "descriptor": "\nComments: Preprint; submitted to CANS 2022; accepted at CANS 2022 and published in Springer LNCS vol 13641\n",
    "authors": [
      "Sebastian Neef",
      "Nils Wisiol"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2208.08846"
  },
  {
    "id": "arXiv:2208.09046",
    "title": "Self-Supervised Primal-Dual Learning for Constrained Optimization",
    "abstract": "Comments: Accepted at AAAI23",
    "descriptor": "\nComments: Accepted at AAAI23\n",
    "authors": [
      "Seonho Park",
      "Pascal Van Hentenryck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2208.09046"
  },
  {
    "id": "arXiv:2208.11266",
    "title": "SCALE: Online Self-Supervised Lifelong Learning without Prior Knowledge",
    "abstract": "Comments: Submitted for review",
    "descriptor": "\nComments: Submitted for review\n",
    "authors": [
      "Xiaofan Yu",
      "Yunhui Guo",
      "Sicun Gao",
      "Tajana Rosing"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.11266"
  },
  {
    "id": "arXiv:2208.11290",
    "title": "ADMoE: Anomaly Detection with Mixture-of-Experts from Noisy Labels",
    "abstract": "Comments: AAAI 2023",
    "descriptor": "\nComments: AAAI 2023\n",
    "authors": [
      "Yue Zhao",
      "Guoqing Zheng",
      "Subhabrata Mukherjee",
      "Robert McCann",
      "Ahmed Awadallah"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2208.11290"
  },
  {
    "id": "arXiv:2208.11510",
    "title": "Quantum Multi-Agent Meta Reinforcement Learning",
    "abstract": "Comments: (To be) presented at AAAI 2023",
    "descriptor": "\nComments: (To be) presented at AAAI 2023\n",
    "authors": [
      "Won Joon Yun",
      "Jihong Park",
      "Joongheon Kim"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2208.11510"
  },
  {
    "id": "arXiv:2208.11975",
    "title": "Bottom-Up 2D Pose Estimation via Dual Anatomical Centers for Small-Scale  Persons",
    "abstract": "Comments: 28 pages, 10 figures, and 6 tables",
    "descriptor": "\nComments: 28 pages, 10 figures, and 6 tables\n",
    "authors": [
      "Yu Cheng",
      "Yihao Ai",
      "Bo Wang",
      "Xinchao Wang",
      "Robby T. Tan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.11975"
  },
  {
    "id": "arXiv:2208.12055",
    "title": "Combating Mode Collapse in GANs via Manifold Entropy Estimation",
    "abstract": "Combating Mode Collapse in GANs via Manifold Entropy Estimation",
    "descriptor": "",
    "authors": [
      "Haozhe Liu",
      "Bing Li",
      "Haoqian Wu",
      "Hanbang Liang",
      "Yawen Huang",
      "Yuexiang Li",
      "Bernard Ghanem",
      "Yefeng Zheng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2208.12055"
  },
  {
    "id": "arXiv:2208.12259",
    "title": "Improving Standard Transformer Models for 3D Point Cloud Understanding  with Image Pretraining",
    "abstract": "Improving Standard Transformer Models for 3D Point Cloud Understanding  with Image Pretraining",
    "descriptor": "",
    "authors": [
      "Guocheng Qian",
      "Xingdi Zhang",
      "Abdullah Hamdi",
      "Bernard Ghanem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2208.12259"
  },
  {
    "id": "arXiv:2208.13504",
    "title": "Unsupervised Semantic Analysis of a Region from Satellite Image Time  Series",
    "abstract": "Unsupervised Semantic Analysis of a Region from Satellite Image Time  Series",
    "descriptor": "",
    "authors": [
      "Carlos Echegoyen",
      "Aritz P\u00e9rez",
      "Guzm\u00e1n Santaf\u00e9",
      "Unai P\u00e9rez-Goya",
      "Mar\u00eda Dolores Ugarte"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2208.13504"
  },
  {
    "id": "arXiv:2209.00602",
    "title": "Python Implementation of the Dynamic Distributed Dimensional Data Model",
    "abstract": "Comments: 8 pages, 7 figures, accepted to HPEC 2022",
    "descriptor": "\nComments: 8 pages, 7 figures, accepted to HPEC 2022\n",
    "authors": [
      "Hayden Jananthan",
      "Lauren Milechin",
      "Michael Jones",
      "William Arcand",
      "William Bergeron",
      "David Bestor",
      "Chansup Byun",
      "Michael Houle",
      "Matthew Hubbell",
      "Vijay Gadepally",
      "Anna Klein",
      "Peter Michaleas",
      "Guillermo Morales",
      "Julie Mullen",
      "Andrew Prout",
      "Albert Reuther",
      "Antonio Rosa",
      "Siddharth Samsi",
      "Charles Yee",
      "Jeremy Kepner"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2209.00602"
  },
  {
    "id": "arXiv:2209.01540",
    "title": "An Empirical Study of End-to-End Video-Language Transformers with Masked  Visual Modeling",
    "abstract": "Comments: The first two authors contributed equally",
    "descriptor": "\nComments: The first two authors contributed equally\n",
    "authors": [
      "Tsu-Jui Fu",
      "Linjie Li",
      "Zhe Gan",
      "Kevin Lin",
      "William Yang Wang",
      "Lijuan Wang",
      "Zicheng Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.01540"
  },
  {
    "id": "arXiv:2209.02466",
    "title": "Circumventing volumetric locking in explicit material point methods: A  simple, efficient, and general approach",
    "abstract": "Circumventing volumetric locking in explicit material point methods: A  simple, efficient, and general approach",
    "descriptor": "",
    "authors": [
      "Yidong Zhao",
      "Chenfanfu Jiang",
      "Jinhyun Choo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2209.02466"
  },
  {
    "id": "arXiv:2209.02633",
    "title": "Energy Management of Multi-mode Hybrid Electric Vehicles based on  Hand-shaking Multi-agent Learning",
    "abstract": "Energy Management of Multi-mode Hybrid Electric Vehicles based on  Hand-shaking Multi-agent Learning",
    "descriptor": "",
    "authors": [
      "Min Hua",
      "Zhi Li",
      "Quan Zhou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2209.02633"
  },
  {
    "id": "arXiv:2209.03258",
    "title": "A Test for FLOPs as a Discriminant for Linear Algebra Algorithms",
    "abstract": "A Test for FLOPs as a Discriminant for Linear Algebra Algorithms",
    "descriptor": "",
    "authors": [
      "Aravind Sankaran",
      "Paolo Bientinesi"
    ],
    "subjectives": [
      "Performance (cs.PF)",
      "Mathematical Software (cs.MS)"
    ],
    "url": "https://arxiv.org/abs/2209.03258"
  },
  {
    "id": "arXiv:2209.06860",
    "title": "Reconstruction of Three-dimensional Scroll Waves in Excitable Media from  Two-Dimensional Observations using Deep Neural Networks",
    "abstract": "Reconstruction of Three-dimensional Scroll Waves in Excitable Media from  Two-Dimensional Observations using Deep Neural Networks",
    "descriptor": "",
    "authors": [
      "Jan Lebert",
      "Meenakshi Mittal",
      "Jan Christoph"
    ],
    "subjectives": [
      "Tissues and Organs (q-bio.TO)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Medical Physics (physics.med-ph)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2209.06860"
  },
  {
    "id": "arXiv:2209.07858",
    "title": "Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors,  and Lessons Learned",
    "abstract": "Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors,  and Lessons Learned",
    "descriptor": "",
    "authors": [
      "Deep Ganguli",
      "Liane Lovitt",
      "Jackson Kernion",
      "Amanda Askell",
      "Yuntao Bai",
      "Saurav Kadavath",
      "Ben Mann",
      "Ethan Perez",
      "Nicholas Schiefer",
      "Kamal Ndousse",
      "Andy Jones",
      "Sam Bowman",
      "Anna Chen",
      "Tom Conerly",
      "Nova DasSarma",
      "Dawn Drain",
      "Nelson Elhage",
      "Sheer El-Showk",
      "Stanislav Fort",
      "Zac Hatfield-Dodds",
      "Tom Henighan",
      "Danny Hernandez",
      "Tristan Hume",
      "Josh Jacobson",
      "Scott Johnston",
      "Shauna Kravec",
      "Catherine Olsson",
      "Sam Ringer",
      "Eli Tran-Johnson",
      "Dario Amodei",
      "Tom Brown",
      "Nicholas Joseph",
      "Sam McCandlish",
      "Chris Olah",
      "Jared Kaplan",
      "Jack Clark"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2209.07858"
  },
  {
    "id": "arXiv:2209.10897",
    "title": "Process Modeling and Conformance Checking in Healthcare: A COVID-19 Case  Study",
    "abstract": "Comments: 12 pages, 2 figures, 3 tables, 15 references",
    "descriptor": "\nComments: 12 pages, 2 figures, 3 tables, 15 references\n",
    "authors": [
      "Elisabetta Benevento",
      "Marco Pegoraro",
      "Mattia Antoniazzi",
      "Harry H. Beyel",
      "Viki Peeva",
      "Paul Balfanz",
      "Wil M.P. van der Aalst",
      "Lukas Martin",
      "Gernot Marx"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.10897"
  },
  {
    "id": "arXiv:2209.11324",
    "title": "Outdoor and indoor path loss modeling at the sub-THz band",
    "abstract": "Outdoor and indoor path loss modeling at the sub-THz band",
    "descriptor": "",
    "authors": [
      "Dimitrios G. Selimis",
      "Mar Francis De Guzman",
      "Fotis I. Lazarakis",
      "Kostas P. Peppas",
      "Katsuyuki Haneda"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2209.11324"
  },
  {
    "id": "arXiv:2209.13129",
    "title": "Deep Generative Multimedia Children's Literature",
    "abstract": "Comments: Under review at AAAI 2023 Workshop on Creative AI Across Modalities",
    "descriptor": "\nComments: Under review at AAAI 2023 Workshop on Creative AI Across Modalities\n",
    "authors": [
      "Matthew L. Olson"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2209.13129"
  },
  {
    "id": "arXiv:2209.14997",
    "title": "Optimistic MLE -- A Generic Model-based Algorithm for Partially  Observable Sequential Decision Making",
    "abstract": "Optimistic MLE -- A Generic Model-based Algorithm for Partially  Observable Sequential Decision Making",
    "descriptor": "",
    "authors": [
      "Qinghua Liu",
      "Praneeth Netrapalli",
      "Csaba Szepesv\u00e1ri",
      "Chi Jin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2209.14997"
  },
  {
    "id": "arXiv:2209.15180",
    "title": "SCI: A Spectrum Concentrated Implicit Neural Compression for Biomedical  Data",
    "abstract": "Comments: accepted to AAAI2023",
    "descriptor": "\nComments: accepted to AAAI2023\n",
    "authors": [
      "Runzhao Yang",
      "Tingxiong Xiao",
      "Yuxiao Cheng",
      "Qianni Cao",
      "Jinyuan Qu",
      "Jinli Suo",
      "Qionghai Dai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.15180"
  },
  {
    "id": "arXiv:2209.15304",
    "title": "Visual Information Hiding Based on Obfuscating Adversarial Perturbations",
    "abstract": "Visual Information Hiding Based on Obfuscating Adversarial Perturbations",
    "descriptor": "",
    "authors": [
      "Zhigang Su",
      "Dawei Zhou",
      "Decheng Liu",
      "Nannan Wang",
      "Zhen Wang",
      "Xinbo Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2209.15304"
  },
  {
    "id": "arXiv:2210.00053",
    "title": "Kernel Normalized Convolutional Networks for Privacy-Preserving Machine  Learning",
    "abstract": "Comments: To appear in the IEEE Conference on Secure and Trustworthy Machine Learning (SaTML), February 2023",
    "descriptor": "\nComments: To appear in the IEEE Conference on Secure and Trustworthy Machine Learning (SaTML), February 2023\n",
    "authors": [
      "Reza Nasirigerdeh",
      "Javad Torkzadehmahani",
      "Daniel Rueckert",
      "Georgios Kaissis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2210.00053"
  },
  {
    "id": "arXiv:2210.01320",
    "title": "Wi-Closure: Reliable and Efficient Search of Inter-robot Loop Closures  Using Wireless Sensing",
    "abstract": "Comments: 6 pages without references",
    "descriptor": "\nComments: 6 pages without references\n",
    "authors": [
      "Weiying Wang",
      "Anne Kemmeren",
      "Daniel Son",
      "Javier Alonso-Mora",
      "Stephanie Gil"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2210.01320"
  },
  {
    "id": "arXiv:2210.01506",
    "title": "How deep convolutional neural networks lose spatial information with  training",
    "abstract": "How deep convolutional neural networks lose spatial information with  training",
    "descriptor": "",
    "authors": [
      "Umberto M. Tomasini",
      "Leonardo Petrini",
      "Francesco Cagnetta",
      "Matthieu Wyart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.01506"
  },
  {
    "id": "arXiv:2210.01708",
    "title": "Conquering the Communication Constraints to Enable Large Pre-Trained  Models in Federated Learning",
    "abstract": "Conquering the Communication Constraints to Enable Large Pre-Trained  Models in Federated Learning",
    "descriptor": "",
    "authors": [
      "Guangyu Sun",
      "Matias Mendieta",
      "Taojiannan Yang",
      "Chen Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.01708"
  },
  {
    "id": "arXiv:2210.01932",
    "title": "Regression-Based Elastic Metric Learning on Shape Spaces of Elastic  Curves",
    "abstract": "Comments: 4 pages, 2 figures, derivations in appendix",
    "descriptor": "\nComments: 4 pages, 2 figures, derivations in appendix\n",
    "authors": [
      "Adele Myers",
      "Nina Miolane"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.01932"
  },
  {
    "id": "arXiv:2210.03103",
    "title": "Env-Aware Anomaly Detection: Ignore Style Changes, Stay True to Content!",
    "abstract": "Env-Aware Anomaly Detection: Ignore Style Changes, Stay True to Content!",
    "descriptor": "",
    "authors": [
      "Stefan Smeu",
      "Elena Burceanu",
      "Andrei Liviu Nicolicioiu",
      "Emanuela Haller"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.03103"
  },
  {
    "id": "arXiv:2210.03274",
    "title": "TCNL: Transparent and Controllable Network Learning Via Embedding  Human-Guided Concepts",
    "abstract": "TCNL: Transparent and Controllable Network Learning Via Embedding  Human-Guided Concepts",
    "descriptor": "",
    "authors": [
      "Zhihao Wang",
      "Chuang Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2210.03274"
  },
  {
    "id": "arXiv:2210.04269",
    "title": "Data-driven framework for input/output lookup tables reduction -- with  application to hypersonic flows in chemical non-equilibrium",
    "abstract": "Comments: 24 pages, 16 figures, 2 tables",
    "descriptor": "\nComments: 24 pages, 16 figures, 2 tables\n",
    "authors": [
      "Cl\u00e9ment Scherding",
      "Georgios Rigas",
      "Denis Sipp",
      "Peter J. Schmid",
      "Taraneh Sayadi"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.04269"
  },
  {
    "id": "arXiv:2210.05006",
    "title": "Energy-Efficient Deployment of Machine Learning Workloads on  Neuromorphic Hardware",
    "abstract": "Energy-Efficient Deployment of Machine Learning Workloads on  Neuromorphic Hardware",
    "descriptor": "",
    "authors": [
      "Peyton Chandarana",
      "Mohammadreza Mohammadi",
      "James Seekings",
      "Ramtin Zand"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Emerging Technologies (cs.ET)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.05006"
  },
  {
    "id": "arXiv:2210.07236",
    "title": "Improved Bounds on Neural Complexity for Representing Piecewise Linear  Functions",
    "abstract": "Comments: 31 pages. Accepted at NeurIPS 2022",
    "descriptor": "\nComments: 31 pages. Accepted at NeurIPS 2022\n",
    "authors": [
      "Kuan-Lin Chen",
      "Harinath Garudadri",
      "Bhaskar D. Rao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Complexity (cs.CC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2210.07236"
  },
  {
    "id": "arXiv:2210.07489",
    "title": "The Surprisingly Straightforward Scene Text Removal Method With Gated  Attention and Region of Interest Generation: A Comprehensive Prominent Model  Analysis",
    "abstract": "Comments: Accepted by ECCV 2022",
    "descriptor": "\nComments: Accepted by ECCV 2022\n",
    "authors": [
      "Hyeonsu Lee",
      "Chankyu Choi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.07489"
  },
  {
    "id": "arXiv:2210.07675",
    "title": "Learning image representations for anomaly detection: application to  discovery of histological alterations in drug development",
    "abstract": "Comments: 14 pages, 5 figures, 5 tables",
    "descriptor": "\nComments: 14 pages, 5 figures, 5 tables\n",
    "authors": [
      "Igor Zingman",
      "Birgit Stierstorfer",
      "Charlotte Lempp",
      "Fabian Heinemann"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.07675"
  },
  {
    "id": "arXiv:2210.11416",
    "title": "Scaling Instruction-Finetuned Language Models",
    "abstract": "Comments: Public checkpoints: this https URL",
    "descriptor": "\nComments: Public checkpoints: this https URL\n",
    "authors": [
      "Hyung Won Chung",
      "Le Hou",
      "Shayne Longpre",
      "Barret Zoph",
      "Yi Tay",
      "William Fedus",
      "Yunxuan Li",
      "Xuezhi Wang",
      "Mostafa Dehghani",
      "Siddhartha Brahma",
      "Albert Webson",
      "Shixiang Shane Gu",
      "Zhuyun Dai",
      "Mirac Suzgun",
      "Xinyun Chen",
      "Aakanksha Chowdhery",
      "Alex Castro-Ros",
      "Marie Pellat",
      "Kevin Robinson",
      "Dasha Valter",
      "Sharan Narang",
      "Gaurav Mishra",
      "Adams Yu",
      "Vincent Zhao",
      "Yanping Huang",
      "Andrew Dai",
      "Hongkun Yu",
      "Slav Petrov",
      "Ed H. Chi",
      "Jeff Dean",
      "Jacob Devlin",
      "Adam Roberts",
      "Denny Zhou",
      "Quoc V. Le",
      "Jason Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.11416"
  },
  {
    "id": "arXiv:2210.12254",
    "title": "Score-based Denoising Diffusion with Non-Isotropic Gaussian Noise Models",
    "abstract": "Comments: NeurIPS 2022 Workshop ; 4 pages, 1 page of references, 18 pages of appendix, 2 figures",
    "descriptor": "\nComments: NeurIPS 2022 Workshop ; 4 pages, 1 page of references, 18 pages of appendix, 2 figures\n",
    "authors": [
      "Vikram Voleti",
      "Christopher Pal",
      "Adam Oberman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.12254"
  },
  {
    "id": "arXiv:2210.12409",
    "title": "Recurrence Boosts Diversity! Revisiting Recurrent Latent Variable in  Transformer-Based Variational AutoEncoder for Diverse Text Generation",
    "abstract": "Comments: EMNLP 2022 Findings",
    "descriptor": "\nComments: EMNLP 2022 Findings\n",
    "authors": [
      "Jinyi Hu",
      "Xiaoyuan Yi",
      "Wenhao Li",
      "Maosong Sun",
      "Xing Xie"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2210.12409"
  },
  {
    "id": "arXiv:2210.13757",
    "title": "Workload Similarity Analysis using Machine Learning Techniques",
    "abstract": "Workload Similarity Analysis using Machine Learning Techniques",
    "descriptor": "",
    "authors": [
      "Ashish Ledalla",
      "Vineet Singh",
      "Deepak Mishra"
    ],
    "subjectives": [
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2210.13757"
  },
  {
    "id": "arXiv:2210.15368",
    "title": "A Teacher-student Framework for Unsupervised Speech Enhancement Using  Noise Remixing Training and Two-stage Inference",
    "abstract": "Comments: Submitted to ICASSP 2023",
    "descriptor": "\nComments: Submitted to ICASSP 2023\n",
    "authors": [
      "Li-Wei Chen",
      "Yao-Fei Cheng",
      "Hung-Shin Lee",
      "Yu Tsao",
      "Hsin-Min Wang"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2210.15368"
  },
  {
    "id": "arXiv:2210.15518",
    "title": "LongShortNet: Exploring Temporal and Semantic Features Fusion in  Streaming Perception",
    "abstract": "Comments: The source code is at this https URL",
    "descriptor": "\nComments: The source code is at this https URL\n",
    "authors": [
      "Chenyang Li",
      "Zhi-Qi Cheng",
      "Jun-Yan He",
      "Pengyu Li",
      "Bin Luo",
      "Han-Yuan Chen",
      "Yifeng Geng",
      "Jin-Peng Lan",
      "Xuansong Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2210.15518"
  },
  {
    "id": "arXiv:2210.15600",
    "title": "Automatic extraction of materials and properties from superconductors  scientific literature",
    "abstract": "Comments: 20 pages, 11 figures, 8 tables",
    "descriptor": "\nComments: 20 pages, 11 figures, 8 tables\n",
    "authors": [
      "Luca Foppiano",
      "Pedro Baptista de Castro",
      "Pedro Ortiz Suarez",
      "Kensei Terashima",
      "Yoshihiko Takano",
      "Masashi Ishii"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Superconductivity (cond-mat.supr-con)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.15600"
  },
  {
    "id": "arXiv:2210.15787",
    "title": "Convolutional Codes with Optimum Bidirectional Distance Profile",
    "abstract": "Convolutional Codes with Optimum Bidirectional Distance Profile",
    "descriptor": "",
    "authors": [
      "Ivan Stanojevi\u0107",
      "Vojin \u0160enk"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2210.15787"
  },
  {
    "id": "arXiv:2210.16118",
    "title": "Imitation Learning-based Implicit Semantic-aware Communication Networks:  Multi-layer Representation and Collaborative Reasoning",
    "abstract": "Comments: Accepted at IEEE Journal on Selected Areas in Communications",
    "descriptor": "\nComments: Accepted at IEEE Journal on Selected Areas in Communications\n",
    "authors": [
      "Yong Xiao",
      "Zijian Sun",
      "Guangming Shi",
      "Dusit Niyato"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2210.16118"
  },
  {
    "id": "arXiv:2210.16637",
    "title": "Beyond Prompting: Making Pre-trained Language Models Better Zero-shot  Learners by Clustering Representations",
    "abstract": "Comments: Accepted to EMNLP 2022",
    "descriptor": "\nComments: Accepted to EMNLP 2022\n",
    "authors": [
      "Yu Fei",
      "Ping Nie",
      "Zhao Meng",
      "Roger Wattenhofer",
      "Mrinmaya Sachan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2210.16637"
  },
  {
    "id": "arXiv:2210.16993",
    "title": "STN: a new tensor network method to identify stimulus category from  brain activity pattern",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Chunyu Liu",
      "Jiacai Zhang"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2210.16993"
  },
  {
    "id": "arXiv:2211.01207",
    "title": "Bias-Aware Face Mask Detection Dataset",
    "abstract": "Comments: submitted to IEEE Transactions on Computational Social Systems, 7 pages, 3 figures",
    "descriptor": "\nComments: submitted to IEEE Transactions on Computational Social Systems, 7 pages, 3 figures\n",
    "authors": [
      "Alperen Kantarc\u0131",
      "Ferda Ofli",
      "Muhammad Imran",
      "Haz\u0131m Kemal Ekenel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.01207"
  },
  {
    "id": "arXiv:2211.02147",
    "title": "A Survey on Reinforcement Learning in Aviation Applications",
    "abstract": "A Survey on Reinforcement Learning in Aviation Applications",
    "descriptor": "",
    "authors": [
      "Pouria Razzaghi",
      "Amin Tabrizian",
      "Wei Guo",
      "Shulu Chen",
      "Abenezer Taye",
      "Ellis Thompson",
      "Alexis Bregeon",
      "Ali Baheri",
      "Peng Wei"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.02147"
  },
  {
    "id": "arXiv:2211.03017",
    "title": "Learning-based Inverse Rendering of Complex Indoor Scenes with  Differentiable Monte Carlo Raytracing",
    "abstract": "Learning-based Inverse Rendering of Complex Indoor Scenes with  Differentiable Monte Carlo Raytracing",
    "descriptor": "",
    "authors": [
      "Jingsen Zhu",
      "Fujun Luan",
      "Yuchi Huo",
      "Zihao Lin",
      "Zhihua Zhong",
      "Dianbing Xi",
      "Jiaxiang Zheng",
      "Rui Tang",
      "Hujun Bao",
      "Rui Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.03017"
  },
  {
    "id": "arXiv:2211.05697",
    "title": "Bayesian hierarchical modelling for battery lifetime early prediction",
    "abstract": "Comments: 7 pages, 8 figures",
    "descriptor": "\nComments: 7 pages, 8 figures\n",
    "authors": [
      "Zihao Zhou",
      "David A. Howey"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.05697"
  },
  {
    "id": "arXiv:2211.07220",
    "title": "Constant Function Market Making, Social Welfare and Maximal Extractable  Value",
    "abstract": "Constant Function Market Making, Social Welfare and Maximal Extractable  Value",
    "descriptor": "",
    "authors": [
      "Bruno Mazorra",
      "Nicol\u00e1s Della Penna"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.07220"
  },
  {
    "id": "arXiv:2211.08321",
    "title": "Simulated Mental Imagery for Robotic Task Planning",
    "abstract": "Simulated Mental Imagery for Robotic Task Planning",
    "descriptor": "",
    "authors": [
      "Shijia Li",
      "Tomas Kulvicius",
      "Minija Tamosiunaite",
      "Florentin W\u00f6rg\u00f6tter"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.08321"
  },
  {
    "id": "arXiv:2211.08615",
    "title": "GLFF: Global and Local Feature Fusion for Face Forgery Detection",
    "abstract": "GLFF: Global and Local Feature Fusion for Face Forgery Detection",
    "descriptor": "",
    "authors": [
      "Yan Ju",
      "Shan Jia",
      "Jialing Cai",
      "Haiying Guan",
      "Siwei Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.08615"
  },
  {
    "id": "arXiv:2211.08939",
    "title": "Augmented Physics-Informed Neural Networks (APINNs): A gating  network-based soft domain decomposition methodology",
    "abstract": "Comments: Under review",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Zheyuan Hu",
      "Ameya D. Jagtap",
      "George Em Karniadakis",
      "Kenji Kawaguchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.08939"
  },
  {
    "id": "arXiv:2211.09124",
    "title": "A Review of Intelligent Music Generation Systems",
    "abstract": "Comments: Overall 24 Pages, 11 Figures, 2 Tables, 96 References items",
    "descriptor": "\nComments: Overall 24 Pages, 11 Figures, 2 Tables, 96 References items\n",
    "authors": [
      "Ziyi Zhao",
      "Hanwei Liu",
      "Song Li",
      "Junwei Pang",
      "Maoqing Zhang",
      "Yi Qin",
      "Lei Wang",
      "Qidi Wu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Multimedia (cs.MM)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2211.09124"
  },
  {
    "id": "arXiv:2211.09613",
    "title": "Learning to Communicate with Intent: An Introduction",
    "abstract": "Comments: 7 pages, 4 figues, submitted to IEEE ICC 2023",
    "descriptor": "\nComments: 7 pages, 4 figues, submitted to IEEE ICC 2023\n",
    "authors": [
      "Miguel Angel Gutierrez-Estevez",
      "Yiqun Wu",
      "Chan Zhou"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.09613"
  },
  {
    "id": "arXiv:2211.09676",
    "title": "Verified Reversible Programming for Verified Lossless Compression",
    "abstract": "Verified Reversible Programming for Verified Lossless Compression",
    "descriptor": "",
    "authors": [
      "James Townsend",
      "Jan-Willem van de Meent"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2211.09676"
  },
  {
    "id": "arXiv:2211.10002",
    "title": "Influential Recommender System",
    "abstract": "Comments: Accepted by ICDE 2023 (The 39th IEEE International Conference on Data Engineering)",
    "descriptor": "\nComments: Accepted by ICDE 2023 (The 39th IEEE International Conference on Data Engineering)\n",
    "authors": [
      "Haoren Zhu",
      "Hao Ge",
      "Xiaodong Gu",
      "Pengfei Zhao",
      "Dik Lun Lee"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10002"
  },
  {
    "id": "arXiv:2211.10400",
    "title": "On Weakly Hausdorff Spaces and Locally Strongly Sober Spaces",
    "abstract": "Comments: 15 pages; removed Proposition 5.4, whose proof was wrong; added new Lemma 5.5 and Remark 5.6, solving a previously open question",
    "descriptor": "\nComments: 15 pages; removed Proposition 5.4, whose proof was wrong; added new Lemma 5.5 and Remark 5.6, solving a previously open question\n",
    "authors": [
      "Jean Goubault-Larrecq"
    ],
    "subjectives": [
      "General Topology (math.GN)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2211.10400"
  },
  {
    "id": "arXiv:2211.10705",
    "title": "TORE: Token Reduction for Efficient Human Mesh Recovery with Transformer",
    "abstract": "TORE: Token Reduction for Efficient Human Mesh Recovery with Transformer",
    "descriptor": "",
    "authors": [
      "Zhiyang Dou",
      "Qingxuan Wu",
      "Cheng Lin",
      "Zeyu Cao",
      "Qiangqiang Wu",
      "Weilin Wan",
      "Taku Komura",
      "Wenping Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10705"
  },
  {
    "id": "arXiv:2211.10754",
    "title": "HALSIE -- Hybrid Approach to Learning Segmentation by Simultaneously  Exploiting Image and Event Modalities",
    "abstract": "HALSIE -- Hybrid Approach to Learning Segmentation by Simultaneously  Exploiting Image and Event Modalities",
    "descriptor": "",
    "authors": [
      "Shristi Das Biswas",
      "Adarsh Kosta",
      "Chamika Liyanagedera",
      "Marco Apolinario",
      "Kaushik Roy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10754"
  },
  {
    "id": "arXiv:2211.10772",
    "title": "DeepSolo: Let Transformer Decoder with Explicit Points Solo for Text  Spotting",
    "abstract": "Comments: The code will be available at this https URL",
    "descriptor": "\nComments: The code will be available at this https URL\n",
    "authors": [
      "Maoyuan Ye",
      "Jing Zhang",
      "Shanshan Zhao",
      "Juhua Liu",
      "Tongliang Liu",
      "Bo Du",
      "Dacheng Tao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.10772"
  },
  {
    "id": "arXiv:2211.10851",
    "title": "Reward is not Necessary: How to Create a Compositional Self-Preserving  Agent for Life-Long Learning",
    "abstract": "Comments: 54 pages",
    "descriptor": "\nComments: 54 pages\n",
    "authors": [
      "Thomas J. Ringstrom"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.10851"
  },
  {
    "id": "arXiv:2211.10902",
    "title": "Noisy Symbolic Abstractions for Deep RL: A case study with Reward  Machines",
    "abstract": "Comments: NeurIPS Deep Reinforcement Learning Workshop 2022",
    "descriptor": "\nComments: NeurIPS Deep Reinforcement Learning Workshop 2022\n",
    "authors": [
      "Andrew C. Li",
      "Zizhao Chen",
      "Pashootan Vaezipoor",
      "Toryn Q. Klassen",
      "Rodrigo Toro Icarte",
      "Sheila A. McIlraith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2211.10902"
  },
  {
    "id": "arXiv:2211.11004",
    "title": "Minimizing the Accumulated Trajectory Error to Improve Dataset  Distillation",
    "abstract": "Minimizing the Accumulated Trajectory Error to Improve Dataset  Distillation",
    "descriptor": "",
    "authors": [
      "Jiawei Du",
      "Yidi Jiang",
      "Vincent Y. F. Tan",
      "Joey Tianyi Zhou",
      "Haizhou Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11004"
  },
  {
    "id": "arXiv:2211.11100",
    "title": "Data-driven Tracking of the Bounce-back Path after Disasters: Critical  Milestones of Population Activity Recovery and Their Spatial Inequality",
    "abstract": "Data-driven Tracking of the Bounce-back Path after Disasters: Critical  Milestones of Population Activity Recovery and Their Spatial Inequality",
    "descriptor": "",
    "authors": [
      "Yuqin Jiang",
      "Faxi Yuan",
      "Hamed Farahmand",
      "Kushal Acharya",
      "Jingdi Zhang",
      "Ali Mostafavi"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2211.11100"
  },
  {
    "id": "arXiv:2211.11106",
    "title": "Efficient shallow learning as an alternative to deep learning",
    "abstract": "Comments: 26 pages, 4 figures (improved figures resolution)",
    "descriptor": "\nComments: 26 pages, 4 figures (improved figures resolution)\n",
    "authors": [
      "Yuval Meir",
      "Ofek Tevet",
      "Yarden Tzach",
      "Shiri Hodassman",
      "Ronit D. Gross",
      "Ido Kanter"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11106"
  },
  {
    "id": "arXiv:2211.11188",
    "title": "Simultaneous Multiple Object Detection and Pose Estimation using 3D  Model Infusion with Monocular Vision",
    "abstract": "Simultaneous Multiple Object Detection and Pose Estimation using 3D  Model Infusion with Monocular Vision",
    "descriptor": "",
    "authors": [
      "Congliang Li",
      "Shijie Sun",
      "Xiangyu Song",
      "Huansheng Song",
      "Naveed Akhtar",
      "Ajmal Saeed Mian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11188"
  },
  {
    "id": "arXiv:2211.11197",
    "title": "An Empirical Study of Package Management Issues via Stack Overflow",
    "abstract": "An Empirical Study of Package Management Issues via Stack Overflow",
    "descriptor": "",
    "authors": [
      "Syful Islam",
      "Raula Gaikovina Kula",
      "Christoph Treude",
      "Bodin Chinthanet",
      "Takashi Ishio",
      "Kenichi Matsumoto"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2211.11197"
  },
  {
    "id": "arXiv:2211.11202",
    "title": "FLNeRF: 3D Facial Landmarks Estimation in Neural Radiance Fields",
    "abstract": "Comments: Hao Zhang and Tianyuan Dai contributed equally. Project website: this https URL",
    "descriptor": "\nComments: Hao Zhang and Tianyuan Dai contributed equally. Project website: this https URL\n",
    "authors": [
      "Hao Zhang",
      "Tianyuan Dai",
      "Yu-Wing Tai",
      "Chi-Keung Tang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2211.11202"
  },
  {
    "id": "arXiv:2211.11210",
    "title": "Contrastive Masked Autoencoders for Self-Supervised Video Hashing",
    "abstract": "Comments: This work is accepted by the AAAI 2023. 9 pages, 6 figures, 6 tables",
    "descriptor": "\nComments: This work is accepted by the AAAI 2023. 9 pages, 6 figures, 6 tables\n",
    "authors": [
      "Yuting Wang",
      "Jinpeng Wang",
      "Bin Chen",
      "Ziyun Zeng",
      "Shutao Xia"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2211.11210"
  },
  {
    "id": "arXiv:2211.11238",
    "title": "RobustLoc: Robust Camera Pose Regression in Challenging Driving  Environments",
    "abstract": "RobustLoc: Robust Camera Pose Regression in Challenging Driving  Environments",
    "descriptor": "",
    "authors": [
      "Sijie Wang",
      "Qiyu Kang",
      "Rui She",
      "Wee Peng Tay",
      "Andreas Hartmannsgruber",
      "Diego Navarro Navarro"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11238"
  },
  {
    "id": "arXiv:2211.11294",
    "title": "TSDF: A simple yet comprehensive, unified data storage and exchange  format standard for digital biosensor data in health applications",
    "abstract": "TSDF: A simple yet comprehensive, unified data storage and exchange  format standard for digital biosensor data in health applications",
    "descriptor": "",
    "authors": [
      "Kasper Claes",
      "Valentina Ticcinelli",
      "Reham Badawy",
      "Yordan P. Raykov",
      "Luc J.W. Evers",
      "Max A. Little"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2211.11294"
  },
  {
    "id": "arXiv:2211.11378",
    "title": "Learning on tree architectures outperforms a convolutional feedforward  network",
    "abstract": "Comments: 20 pages, 4 figures, 1 table (improved figures resolution)",
    "descriptor": "\nComments: 20 pages, 4 figures, 1 table (improved figures resolution)\n",
    "authors": [
      "Yuval Meir",
      "Itamar Ben-Noam",
      "Yarden Tzach",
      "Shiri Hodassman",
      "Ido Kanter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11378"
  },
  {
    "id": "arXiv:2211.11592",
    "title": "Guided Depth Super-Resolution by Deep Anisotropic Diffusion",
    "abstract": "Guided Depth Super-Resolution by Deep Anisotropic Diffusion",
    "descriptor": "",
    "authors": [
      "Nando Metzger",
      "Rodrigo Caye Daudt",
      "Konrad Schindler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11592"
  },
  {
    "id": "arXiv:2211.11754",
    "title": "An Algorithm for Routing Vectors in Sequences",
    "abstract": "Comments: Source code and instructions for replicating our results are online at this https URL",
    "descriptor": "\nComments: Source code and instructions for replicating our results are online at this https URL\n",
    "authors": [
      "Franz A. Heinsen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2211.11754"
  },
  {
    "id": "arXiv:2211.11835",
    "title": "Fairness Increases Adversarial Vulnerability",
    "abstract": "Fairness Increases Adversarial Vulnerability",
    "descriptor": "",
    "authors": [
      "Cuong Tran",
      "Keyu Zhu",
      "Ferdinando Fioretto",
      "Pascal Van Hentenryck"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.11835"
  },
  {
    "id": "arXiv:2211.11865",
    "title": "Bayesian Learning for Neural Networks: an algorithmic survey",
    "abstract": "Bayesian Learning for Neural Networks: an algorithmic survey",
    "descriptor": "",
    "authors": [
      "Martin Magris",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2211.11865"
  },
  {
    "id": "arXiv:2211.11953",
    "title": "Teach-DETR: Better Training DETR with Teachers",
    "abstract": "Teach-DETR: Better Training DETR with Teachers",
    "descriptor": "",
    "authors": [
      "Linjiang Huang",
      "Kaixin Lu",
      "Guanglu Song",
      "Liang Wang",
      "Si Liu",
      "Yu Liu",
      "Hongsheng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11953"
  },
  {
    "id": "arXiv:2211.11959",
    "title": "Robust High-dimensional Tuning Free Multiple Testing",
    "abstract": "Comments: In this paper, we develop tuning-free and moment-free high dimensional inference procedures;",
    "descriptor": "\nComments: In this paper, we develop tuning-free and moment-free high dimensional inference procedures;\n",
    "authors": [
      "Jianqing Fan",
      "Zhipeng Lou",
      "Mengxin Yu"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2211.11959"
  },
  {
    "id": "arXiv:2211.11962",
    "title": "Transformation-Equivariant 3D Object Detection for Autonomous Driving",
    "abstract": "Comments: Accepted by AAAI 2023",
    "descriptor": "\nComments: Accepted by AAAI 2023\n",
    "authors": [
      "Hai Wu",
      "Chenglu Wen",
      "Wei Li",
      "Xin Li",
      "Ruigang Yang",
      "Cheng Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.11962"
  },
  {
    "id": "arXiv:2211.12032",
    "title": "PointCMC: Cross-Modal Multi-Scale Correspondences Learning for Point  Cloud Understanding",
    "abstract": "Comments: In order to revise the paper",
    "descriptor": "\nComments: In order to revise the paper\n",
    "authors": [
      "Honggu Zhou",
      "Xiaogang Peng",
      "Jiawei Mao",
      "Zizhao Wu",
      "Ming Zeng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12032"
  },
  {
    "id": "arXiv:2211.12040",
    "title": "Rethinking Implicit Neural Representations for Vision Learners",
    "abstract": "Rethinking Implicit Neural Representations for Vision Learners",
    "descriptor": "",
    "authors": [
      "Yiran Song",
      "Qianyu Zhou",
      "Lizhuang Ma"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12040"
  },
  {
    "id": "arXiv:2211.12044",
    "title": "Backdoor Cleansing with Unlabeled Data",
    "abstract": "Backdoor Cleansing with Unlabeled Data",
    "descriptor": "",
    "authors": [
      "Lu Pang",
      "Tao Sun",
      "Haibin Ling",
      "Chao Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2211.12044"
  },
  {
    "id": "arXiv:2211.12084",
    "title": "Accelerated Solutions of Coupled Phase-Field Problems using Generative  Adversarial Networks",
    "abstract": "Comments: 18 pages, 21 figures (including subfigures). Will be submitted to the journal: \"Computational Materials Science\" soon",
    "descriptor": "\nComments: 18 pages, 21 figures (including subfigures). Will be submitted to the journal: \"Computational Materials Science\" soon\n",
    "authors": [
      "Vir Karan",
      "A. Maruthi Indresh",
      "Saswata Bhattacharyya"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2211.12084"
  },
  {
    "id": "arXiv:2211.12150",
    "title": "The transport problem for non-additive measures",
    "abstract": "The transport problem for non-additive measures",
    "descriptor": "",
    "authors": [
      "Vicen\u00e7 Torra"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2211.12150"
  },
  {
    "id": "arXiv:2211.12224",
    "title": "Sustainable Wireless Services with UAV Swarms Tailored to Renewable  Energy Sources",
    "abstract": "Comments: To be published in Transactions on Smart Grid",
    "descriptor": "\nComments: To be published in Transactions on Smart Grid\n",
    "authors": [
      "Igor Donevski",
      "Marco Virgili",
      "Nithin Babu",
      "Jimmy Jessen Nielsen",
      "Andrew J. Forsyth",
      "Constantinos B. Papadias",
      "Petar Popovski"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2211.12224"
  },
  {
    "id": "arXiv:2211.12244",
    "title": "FE-Fusion-VPR: Attention-based Multi-Scale Network Architecture for  Visual Place Recognition by Fusing Frames and Events",
    "abstract": "FE-Fusion-VPR: Attention-based Multi-Scale Network Architecture for  Visual Place Recognition by Fusing Frames and Events",
    "descriptor": "",
    "authors": [
      "Kuanxu Hou",
      "Delei Kong",
      "Junjie Jiang",
      "Hao Zhuang",
      "Xinjie Huang",
      "Zheng Fang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2211.12244"
  },
  {
    "id": "arXiv:2211.12352",
    "title": "GlowGAN: Unsupervised Learning of HDR Images from LDR Images in the Wild",
    "abstract": "GlowGAN: Unsupervised Learning of HDR Images from LDR Images in the Wild",
    "descriptor": "",
    "authors": [
      "Chao Wang",
      "Ana Serrano",
      "Xingang Pan",
      "Bin Chen",
      "Hans-Peter Seidel",
      "Christian Theobalt",
      "Karol Myszkowski",
      "Thomas Leimkuehler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.12352"
  },
  {
    "id": "arXiv:2211.12421",
    "title": "Data-Driven Network Neuroscience: On Data Collection and Benchmark",
    "abstract": "Data-Driven Network Neuroscience: On Data Collection and Benchmark",
    "descriptor": "",
    "authors": [
      "David Tse Jung Huang",
      "Sophi Shilpa Gururajapathy",
      "Yiping Ke",
      "Miao Qiao",
      "Alan Wang",
      "Haribalan Kumar",
      "Yunhan Yang"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2211.12421"
  },
  {
    "id": "arXiv:2211.12455",
    "title": "ISIM: Iterative Self-Improved Model for Weakly Supervised Segmentation",
    "abstract": "Comments: This paper was submitted to IJCV on 15 Nov 2021. The reviewers decided to reject it. After getting the reviews, we wanted to study more. Unfortunately, one of the authors had severe issues (COVID-19 vaccination). After one year, the study was outdated and similar studies had been published. So, we leave the study by putting it in an archive in case it might have some effect on the literature",
    "descriptor": "\nComments: This paper was submitted to IJCV on 15 Nov 2021. The reviewers decided to reject it. After getting the reviews, we wanted to study more. Unfortunately, one of the authors had severe issues (COVID-19 vaccination). After one year, the study was outdated and similar studies had been published. So, we leave the study by putting it in an archive in case it might have some effect on the literature\n",
    "authors": [
      "Cenk Bircanoglu",
      "Nafiz Arica"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2211.12455"
  }
]
[
  {
    "id": "arXiv:2202.00673",
    "title": "Visualizing Automatic Speech Recognition -- Means for a Better  Understanding?",
    "abstract": "Automatic speech recognition (ASR) is improving ever more at mimicking human\nspeech processing. The functioning of ASR, however, remains to a large extent\nobfuscated by the complex structure of the deep neural networks (DNNs) they are\nbased on. In this paper, we show how so-called attribution methods, that we\nimport from image recognition and suitably adapt to handle audio data, can help\nto clarify the working of ASR. Taking DeepSpeech, an end-to-end model for ASR,\nas a case study, we show how these techniques help to visualize which features\nof the input are the most influential in determining the output. We focus on\nthree visualization techniques: Layer-wise Relevance Propagation (LRP),\nSaliency Maps, and Shapley Additive Explanations (SHAP). We compare these\nmethods and discuss potential further applications, such as in the detection of\nadversarial examples.",
    "descriptor": "\nComments: Proc. 2021 ISCA Symposium on Security and Privacy in Speech Communication\n",
    "authors": [
      "Karla Markert",
      "Romain Parracone",
      "Mykhailo Kulakov",
      "Philip Sperl",
      "Ching-Yu Kao",
      "Konstantin B\u00f6ttinger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Human-Computer Interaction (cs.HC)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.00673"
  },
  {
    "id": "arXiv:2202.00674",
    "title": "Just Another Method to Compute MTTF from Continuous Time Markov Chain",
    "abstract": "The Meantime to Failure is a statistic used to determine how much time a\nsystem spends to enter one of its absorption states. This statistic can be used\nin most areas of knowledge. In engineering, for example, can be used as a\nmeasure of equipment reliability, and in business, as a measure of processes\nperformance. This work presents a method to obtain the Meantime to Failure from\na Continuous Time Markov Chain models. The method is intuitive and is simpler\nto be implemented, since, it consists of solving a system of linear equations.",
    "descriptor": "\nComments: 3 pages, 1 figure\n",
    "authors": [
      "Eduardo M. Vasconcelos"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00674"
  },
  {
    "id": "arXiv:2202.00710",
    "title": "Improving Sample Efficiency of Value Based Models Using Attention and  Vision Transformers",
    "abstract": "Much of recent Deep Reinforcement Learning success is owed to the neural\narchitecture's potential to learn and use effective internal representations of\nthe world. While many current algorithms access a simulator to train with a\nlarge amount of data, in realistic settings, including while playing games that\nmay be played against people, collecting experience can be quite costly. In\nthis paper, we introduce a deep reinforcement learning architecture whose\npurpose is to increase sample efficiency without sacrificing performance. We\ndesign this architecture by incorporating advances achieved in recent years in\nthe field of Natural Language Processing and Computer Vision. Specifically, we\npropose a visually attentive model that uses transformers to learn a\nself-attention mechanism on the feature maps of the state representation, while\nsimultaneously optimizing return. We demonstrate empirically that this\narchitecture improves sample complexity for several Atari environments, while\nalso achieving better performance in some of the games.",
    "descriptor": "",
    "authors": [
      "Amir Ardalan Kalantari",
      "Mohammad Amini",
      "Sarath Chandar",
      "Doina Precup"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00710"
  },
  {
    "id": "arXiv:2202.00712",
    "title": "Should I take a walk? Estimating Energy Expenditure from Video Data",
    "abstract": "We explore the problem of automatically inferring the amount of kilocalories\nused by human during physical activity from his/her video observation. To study\nthis underresearched task, we introduce Vid2Burn -- an omni-source benchmark\nfor estimating caloric expenditure from video data featuring both, high- and\nlow-intensity activities for which we derive energy expenditure annotations\nbased on models established in medical literature. In practice, a training set\nwould only cover a certain amount of activity types, and it is important to\nvalidate, if the model indeed captures the essence of energy expenditure,\n(e.g., how many and which muscles are involved and how intense they work)\ninstead of memorizing fixed values of specific activity categories seen during\ntraining. Ideally, the models should look beyond such category-specific biases\nand regress the caloric cost in videos depicting activity categories not\nexplicitly present during training. With this property in mind, Vid2Burn is\naccompanied with a cross-category benchmark, where the task is to regress\ncaloric expenditure for types of physical activities not present during\ntraining. An extensive evaluation of state-of-the-art approaches for video\nrecognition modified for the energy expenditure estimation task demonstrates\nthe difficulty of this problem, especially for new activity types at test-time,\nmarking a new research direction. Dataset and code are available at\nhttps://github.com/KPeng9510/Vid2Burn.",
    "descriptor": "\nComments: Dataset and code are available at this https URL\n",
    "authors": [
      "Kunyu Peng",
      "Alina Roitberg",
      "Kailun Yang",
      "Jiaming Zhang",
      "Rainer Stiefelhagen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00712"
  },
  {
    "id": "arXiv:2202.00717",
    "title": "Pipeflow: An Efficient Task-Parallel Pipeline Programming Framework  using Modern C++",
    "abstract": "Pipeline is a fundamental parallel programming pattern. Mainstream pipeline\nprogramming frameworks count on data abstractions to perform pipeline\nscheduling. This design is convenient for data-centric pipeline applications\nbut inefficient for algorithms that only exploit task parallelism in pipeline.\nAs a result, we introduce a new task-parallel pipeline programming framework\ncalled Pipeflow. Pipeflow does not design yet another data abstraction but\nfocuses on the pipeline scheduling itself, enabling more efficient\nimplementation of task-parallel pipeline algorithms than existing frameworks.\nWe have evaluated Pipeflow on both micro-benchmarks and real-world\napplications. As an example, Pipeflow outperforms oneTBB 24% and 10% faster in\na VLSI placement and a timing analysis workloads that adopt pipeline\nparallelism to speed up runtimes, respectively.",
    "descriptor": "",
    "authors": [
      "Cheng-Hsiang Chiu",
      "Tsung-Wei Huang",
      "Zizheng Guo",
      "Yibo Lin"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.00717"
  },
  {
    "id": "arXiv:2202.00718",
    "title": "Personalized Federated Learning via Convex Clustering",
    "abstract": "We propose a parametric family of algorithms for personalized federated\nlearning with locally convex user costs. The proposed framework is based on a\ngeneralization of convex clustering in which the differences between different\nusers' models are penalized via a sum-of-norms penalty, weighted by a penalty\nparameter $\\lambda$. The proposed approach enables \"automatic\" model\nclustering, without prior knowledge of the hidden cluster structure, nor the\nnumber of clusters. Analytical bounds on the weight parameter, that lead to\nsimultaneous personalization, generalization and automatic model clustering are\nprovided. The solution to the formulated problem enables personalization, by\nproviding different models across different clusters, and generalization, by\nproviding models different than the per-user models computed in isolation. We\nthen provide an efficient algorithm based on the Parallel Direction Method of\nMultipliers (PDMM) to solve the proposed formulation in a federated\nserver-users setting. Numerical experiments corroborate our findings. As an\ninteresting byproduct, our results provide several generalizations to convex\nclustering.",
    "descriptor": "",
    "authors": [
      "Aleksandar Armacki",
      "Dragana Bajovic",
      "Dusan Jakovetic",
      "Soummya Kar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00718"
  },
  {
    "id": "arXiv:2202.00720",
    "title": "Gradient Based Clustering",
    "abstract": "We propose a general approach for distance based clustering, using the\ngradient of the cost function that measures clustering quality with respect to\ncluster assignments and cluster center positions. The approach is an iterative\ntwo step procedure (alternating between cluster assignment and cluster center\nupdates) and is applicable to a wide range of functions, satisfying some mild\nassumptions. The main advantage of the proposed approach is a simple and\ncomputationally cheap update rule. Unlike previous methods that specialize to a\nspecific formulation of the clustering problem, our approach is applicable to a\nwide range of costs, including non-Bregman clustering methods based on the\nHuber loss. We analyze the convergence of the proposed algorithm, and show that\nit converges to the set of appropriately defined fixed points, under arbitrary\ncenter initialization. In the special case of Bregman cost functions, the\nalgorithm converges to the set of centroidal Voronoi partitions, which is\nconsistent with prior works. Numerical experiments on real data demonstrate the\neffectiveness of the proposed method.",
    "descriptor": "",
    "authors": [
      "Aleksandar Armacki",
      "Dragana Bajovic",
      "Dusan Jakovetic",
      "Soummya Kar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00720"
  },
  {
    "id": "arXiv:2202.00728",
    "title": "Physical Design using Differentiable Learned Simulators",
    "abstract": "Designing physical artifacts that serve a purpose - such as tools and other\nfunctional structures - is central to engineering as well as everyday human\nbehavior. Though automating design has tremendous promise, general-purpose\nmethods do not yet exist. Here we explore a simple, fast, and robust approach\nto inverse design which combines learned forward simulators based on graph\nneural networks with gradient-based design optimization. Our approach solves\nhigh-dimensional problems with complex physical dynamics, including designing\nsurfaces and tools to manipulate fluid flows and optimizing the shape of an\nairfoil to minimize drag. This framework produces high-quality designs by\npropagating gradients through trajectories of hundreds of steps, even when\nusing models that were pre-trained for single-step predictions on data\nsubstantially different from the design tasks. In our fluid manipulation tasks,\nthe resulting designs outperformed those found by sampling-based optimization\ntechniques. In airfoil design, they matched the quality of those obtained with\na specialized solver. Our results suggest that despite some remaining\nchallenges, machine learning-based simulators are maturing to the point where\nthey can support general-purpose design optimization across a variety of\ndomains.",
    "descriptor": "\nComments: First three authors contributed equally\n",
    "authors": [
      "Kelsey R. Allen",
      "Tatiana Lopez-Guevara",
      "Kimberly Stachenfeld",
      "Alvaro Sanchez-Gonzalez",
      "Peter Battaglia",
      "Jessica Hamrick",
      "Tobias Pfaff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00728"
  },
  {
    "id": "arXiv:2202.00732",
    "title": "IFOR: Iterative Flow Minimization for Robotic Object Rearrangement",
    "abstract": "Accurate object rearrangement from vision is a crucial problem for a wide\nvariety of real-world robotics applications in unstructured environments. We\npropose IFOR, Iterative Flow Minimization for Robotic Object Rearrangement, an\nend-to-end method for the challenging problem of object rearrangement for\nunknown objects given an RGBD image of the original and final scenes. First, we\nlearn an optical flow model based on RAFT to estimate the relative\ntransformation of the objects purely from synthetic data. This flow is then\nused in an iterative minimization algorithm to achieve accurate positioning of\npreviously unseen objects. Crucially, we show that our method applies to\ncluttered scenes, and in the real world, while training only on synthetic data.\nVideos are available at https://imankgoyal.github.io/ifor.html.",
    "descriptor": "",
    "authors": [
      "Ankit Goyal",
      "Arsalan Mousavian",
      "Chris Paxton",
      "Yu-Wei Chao",
      "Brian Okorn",
      "Jia Deng",
      "Dieter Fox"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00732"
  },
  {
    "id": "arXiv:2202.00734",
    "title": "Framework for Evaluating Faithfulness of Local Explanations",
    "abstract": "We study the faithfulness of an explanation system to the underlying\nprediction model. We show that this can be captured by two properties,\nconsistency and sufficiency, and introduce quantitative measures of the extent\nto which these hold. Interestingly, these measures depend on the test-time data\ndistribution. For a variety of existing explanation systems, such as anchors,\nwe analytically study these quantities. We also provide estimators and sample\ncomplexity bounds for empirically determining the faithfulness of black-box\nexplanation systems. Finally, we experimentally validate the new properties and\nestimators.",
    "descriptor": "",
    "authors": [
      "Sanjoy Dasgupta",
      "Nave Frost",
      "Michal Moshkovitz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00734"
  },
  {
    "id": "arXiv:2202.00738",
    "title": "LocUNet: Fast Urban Positioning Using Radio Maps and Deep Learning",
    "abstract": "This paper deals with the problem of localization in a cellular network in a\ndense urban scenario. Global Navigation Satellite Systems (GNSS) typically\nperform poorly in urban environments, where the likelihood of line-of-sight\nconditions is low, and thus alternative localization methods are required for\ngood accuracy. We present LocUNet: A deep learning method for localization,\nbased merely on Received Signal Strength (RSS) from Base Stations (BSs), which\ndoes not require any increase in computation complexity at the user devices\nwith respect to the device standard operations, unlike methods that rely on\ntime of arrival or angle of arrival information. In the proposed method, the\nuser to be localized reports the RSS from BSs to a Central Processing Unit\n(CPU), which may be located in the cloud. Alternatively, the localization can\nbe performed locally at the user. Using estimated pathloss radio maps of the\nBSs, LocUNet can localize users with state-of-the-art accuracy and enjoys high\nrobustness to inaccuracies in the radio maps. The proposed method does not\nrequire pre-sampling of the environment; and is suitable for real-time\napplications, thanks to the RadioUNet, a neural network-based radio map\nestimator. We also introduce two datasets that allow numerical comparisons of\nRSS and Time of Arrival (ToA) methods in realistic urban environments.",
    "descriptor": "\nComments: To appear in ICASSP 2022. arXiv admin note: substantial text overlap with arXiv:2106.12556\n",
    "authors": [
      "\u00c7a\u011fkan Yapar",
      "Ron Levie",
      "Gitta Kutyniok",
      "Giuseppe Caire"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.00738"
  },
  {
    "id": "arXiv:2202.00739",
    "title": "Compiler-Driven Simulation of Reconfigurable Hardware Accelerators",
    "abstract": "As customized accelerator design has become increasingly popular to keep up\nwith the demand for high performance computing, it poses challenges for modern\nsimulator design to adapt to such a large variety of accelerators. Existing\nsimulators tend to two extremes: low-level and general approaches, such as RTL\nsimulation, that can model any hardware but require substantial effort and long\nexecution times; and higher-level application-specific models that can be much\nfaster and easier to use but require one-off engineering effort.\nThis work proposes a compiler-driven simulation workflow that can model\nconfigurable hardware accelerator. The key idea is to separate structure\nrepresentation from simulation by developing an intermediate language that can\nflexibly represent a wide variety of hardware constructs. We design the Event\nQueue (EQueue) dialect of MLIR, a dialect that can model arbitrary hardware\naccelerators with explicit data movement and distributed event-based control;\nwe also implement a generic simulation engine to model EQueue programs with\nhybrid MLIR dialects representing different abstraction levels. We demonstrate\ntwo case studies of EQueue-implemented accelerators: the systolic array of\nconvolution and SIMD processors in a modern FPGA. In the former we show EQueue\nsimulation is as accurate as a state-of-the-art simulator, while offering\nhigher extensibility and lower iteration cost via compiler passes. In the\nlatter we demonstrate our simulation flow can guide designer efficiently\nimprove their design using visualizable simulation outputs.",
    "descriptor": "",
    "authors": [
      "Zhijing Li",
      "Yuwei Ye",
      "Stephen Neuendorffer",
      "Adrian Sampso"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00739"
  },
  {
    "id": "arXiv:2202.00740",
    "title": "Investigating Transfer Learning in Graph Neural Networks",
    "abstract": "Graph neural networks (GNNs) build on the success of deep learning models by\nextending them for use in graph spaces. Transfer learning has proven extremely\nsuccessful for traditional deep learning problems: resulting in faster training\nand improved performance. Despite the increasing interest in GNNs and their use\ncases, there is little research on their transferability. This research\ndemonstrates that transfer learning is effective with GNNs, and describes how\nsource tasks and the choice of GNN impact the ability to learn generalisable\nknowledge. We perform experiments using real-world and synthetic data within\nthe contexts of node classification and graph classification. To this end, we\nalso provide a general methodology for transfer learning experimentation and\npresent a novel algorithm for generating synthetic graph classification tasks.\nWe compare the performance of GCN, GraphSAGE and GIN across both the synthetic\nand real-world datasets. Our results demonstrate empirically that GNNs with\ninductive operations yield statistically significantly improved transfer.\nFurther we show that similarity in community structure between source and\ntarget tasks support statistically significant improvements in transfer over\nand above the use of only the node attributes.",
    "descriptor": "",
    "authors": [
      "Nishai Kooverjee",
      "Steven James",
      "Terence van Zyl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00740"
  },
  {
    "id": "arXiv:2202.00743",
    "title": "Exploring the consequences of cyber attacks on Powertrain Cyber Physical  Systems",
    "abstract": "This paper proposes a novel approach for the study of cyber-attacks against\nthe powertrain of a generic vehicle. The proposed model is composed by a a\ngeneric Internal Combustion engine and a speed controller, that communicate\nthrough a Controller Area Network (CAN) bus. We consider a threat model\ncomposed by three representative attack scenarios designed to modify the output\nof the model, thus affecting the rotational speed of the engine. Two attack\nscenarios target both vehicle sensor systems and CAN communication, while one\nattack scenario only requires injection of CAN messages. To the best of our\nknowledge, this is the first attempt of modeling the consequences of realistic\ncyber attacks against a modern vehicle.",
    "descriptor": "",
    "authors": [
      "Dario Stabili",
      "Raffaele Romagnoli",
      "Mirco Marchetti",
      "Bruno Sinopoli",
      "Michele Colajanni"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.00743"
  },
  {
    "id": "arXiv:2202.00747",
    "title": "Thematic Domain Analysis for Ocean Modeling",
    "abstract": "Ocean science is a discipline that employs ocean models as an essential\nresearch asset. Such scientific modeling provides mathematical abstractions of\nreal-world systems, e.g., the oceans. These models are then coded as\nimplementations of the mathematical abstractions. The developed software\nsystems are called models of the real-world system.\nTo advance the state in engineering such ocean models, we intend to better\nunderstand how ocean models are developed and maintained in ocean science. In\nthis paper, we present the results of semi-structured interviews and the\nThematic Analysis~(TA) of the interview results to analyze the domain of ocean\nmodeling. Thereby, we identified developer requirements and impediments to\nmodel development and evolution, and related themes. This analysis can help to\nunderstand where methods from software engineering should be introduced and\nwhich challenges need to be addressed.\nWe suggest that other researchers extend and repeat our TA with model\ndevelopers and research software engineers working in related domains to\nfurther advance our knowledge and skills in scientific modeling.",
    "descriptor": "\nComments: 14 pages. arXiv admin note: substantial text overlap with arXiv:2108.08589\n",
    "authors": [
      "Reiner Jung",
      "Sven Gundlach",
      "Wilhelm Hasselbring"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.00747"
  },
  {
    "id": "arXiv:2202.00751",
    "title": "An Empirical Study of Modular Bias Mitigators and Ensembles",
    "abstract": "There are several bias mitigators that can reduce algorithmic bias in machine\nlearning models but, unfortunately, the effect of mitigators on fairness is\noften not stable when measured across different data splits. A popular approach\nto train more stable models is ensemble learning. Ensembles, such as bagging,\nboosting, voting, or stacking, have been successful at making predictive\nperformance more stable. One might therefore ask whether we can combine the\nadvantages of bias mitigators and ensembles? To explore this question, we first\nneed bias mitigators and ensembles to work together. We built an open-source\nlibrary enabling the modular composition of 10 mitigators, 4 ensembles, and\ntheir corresponding hyperparameters. Based on this library, we empirically\nexplored the space of combinations on 13 datasets, including datasets commonly\nused in fairness literature plus datasets newly curated by our library.\nFurthermore, we distilled the results into a guidance diagram for\npractitioners. We hope this paper will contribute towards improving stability\nin bias mitigation.",
    "descriptor": "",
    "authors": [
      "Michael Feffer",
      "Martin Hirzel",
      "Samuel C. Hoffman",
      "Kiran Kate",
      "Parikshit Ram",
      "Avraham Shinnar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.00751"
  },
  {
    "id": "arXiv:2202.00753",
    "title": "ADG-Pose: Automated Dataset Generation for Real-World Human Pose  Estimation",
    "abstract": "Recent advancements in computer vision have seen a rise in the prominence of\napplications using neural networks to understand human poses. However, while\naccuracy has been steadily increasing on State-of-the-Art datasets, these\ndatasets often do not address the challenges seen in real-world applications.\nThese challenges are dealing with people distant from the camera, people in\ncrowds, and heavily occluded people. As a result, many real-world applications\nhave trained on data that does not reflect the data present in deployment,\nleading to significant underperformance. This article presents ADG-Pose, a\nmethod for automatically generating datasets for real-world human pose\nestimation. These datasets can be customized to determine person distances,\ncrowdedness, and occlusion distributions. Models trained with our method are\nable to perform in the presence of these challenges where those trained on\nother datasets fail. Using ADG-Pose, end-to-end accuracy for real-world\nskeleton-based action recognition sees a 20% increase on scenes with moderate\ndistance and occlusion levels, and a 4X increase on distant scenes where other\nmodels failed to perform better than random.",
    "descriptor": "\nComments: The first two authors have equal contribution. 12 Pages\n",
    "authors": [
      "Ghazal Alinezhad Noghre",
      "Armin Danesh Pazho",
      "Justin Sanchez",
      "Nathan Hewitt",
      "Christopher Neff",
      "Hamed Tabkhi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.00753"
  },
  {
    "id": "arXiv:2202.00756",
    "title": "Ranging-Based Localizability-Constrained Deployment of Mobile Robotic  Networks",
    "abstract": "In cooperative localization schemes for robotic networks relying on noisy\nrange measurements between agents, the achievable positioning accuracy strongly\ndepends on the network geometry. This motivates the problem of planning robot\ntrajectories in such multi-robot systems in a way that maintains high\nlocalization accuracy. We present potential-based planning methods, where\nlocalizability potentials are introduced to characterize the quality of the\nnetwork geometry for cooperative position estimation. These potentials are\nbased on Cram\\'er Rao Lower Bounds (CRLB) and provide a theoretical lower bound\non the error covariance achievable by any unbiased position estimator. In the\nprocess, we establish connections between CRLBs and the theory of graph\nrigidity, which has been previously used to plan the motion of robotic\nnetworks. We develop decentralized deployment algorithms appropriate for large\nnetworks, and we use equality-constrained CRLBs to extend the concept of\nlocalizability to scenarios where additional information about the relative\npositions of the ranging sensors is known. We illustrate the resulting robot\ndeployment methodology through simulated examples.",
    "descriptor": "\nComments: 15 pages, 8 figures, submitted to IEEE Transactions on Robotics\n",
    "authors": [
      "Justin Cano",
      "Jerome Le Ny"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.00756"
  },
  {
    "id": "arXiv:2202.00758",
    "title": "ColloSSL: Collaborative Self-Supervised Learning for Human Activity  Recognition",
    "abstract": "A major bottleneck in training robust Human-Activity Recognition models (HAR)\nis the need for large-scale labeled sensor datasets. Because labeling large\namounts of sensor data is an expensive task, unsupervised and semi-supervised\nlearning techniques have emerged that can learn good features from the data\nwithout requiring any labels. In this paper, we extend this line of research\nand present a novel technique called Collaborative Self-Supervised Learning\n(ColloSSL) which leverages unlabeled data collected from multiple devices worn\nby a user to learn high-quality features of the data. A key insight that\nunderpins the design of ColloSSL is that unlabeled sensor datasets\nsimultaneously captured by multiple devices can be viewed as natural\ntransformations of each other, and leveraged to generate a supervisory signal\nfor representation learning. We present three technical innovations to extend\nconventional self-supervised learning algorithms to a multi-device setting: a\nDevice Selection approach which selects positive and negative devices to enable\ncontrastive learning, a Contrastive Sampling algorithm which samples positive\nand negative examples in a multi-device setting, and a loss function called\nMulti-view Contrastive Loss which extends standard contrastive loss to a\nmulti-device setting. Our experimental results on three multi-device datasets\nshow that ColloSSL outperforms both fully-supervised and semi-supervised\nlearning techniques in majority of the experiment settings, resulting in an\nabsolute increase of upto 7.9% in F_1 score compared to the best performing\nbaselines. We also show that ColloSSL outperforms the fully-supervised methods\nin a low-data regime, by just using one-tenth of the available labeled data in\nthe best case.",
    "descriptor": "\nComments: Accepted to ACM IMWUT 2022\n",
    "authors": [
      "Yash Jain",
      "Chi Ian Tang",
      "Chulhong Min",
      "Fahim Kawsar",
      "Akhil Mathur"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.00758"
  },
  {
    "id": "arXiv:2202.00762",
    "title": "Extending FEniCS to Work in Higher Dimensions Using Tensor Product  Finite Elements",
    "abstract": "We present a method to extend the finite element library FEniCS to solve\nproblems with domains in dimensions above three by constructing tensor product\nfinite elements. This methodology only requires that the high dimensional\ndomain is structured as a Cartesian product of two lower dimensional\nsubdomains. In this study we consider linear partial differential equations,\nthough the methodology can be extended to non-linear problems. The utilization\nof tensor product finite elements allows us to construct a global system of\nlinear algebraic equations that only relies on the finite element\ninfrastructure of the lower dimensional subdomains contained in FEniCS. We\ndemonstrate the effectiveness of our methodology in three distinctive test\ncases. The first test case is a Poisson equation posed in a four dimensional\ndomain which is a Cartesian product of two unit squares solved using the\nclassical Galerkin finite element method. The second test case is the wave\nequation in space-time, where the computational domain is a Cartesian product\nof a two dimensional space grid and a one dimensional time interval. In this\nsecond case we also employ the Galerkin method. Finally, the third test case is\nan advection dominated advection-diffusion equation where the global domain is\na Cartesian product of two one dimensional intervals. The streamline upwind\nPetrov-Galerkin method is applied to ensure discrete stability. In all three\ncases, optimal convergence rates are achieved with respect to h refinement.",
    "descriptor": "",
    "authors": [
      "Mark Loveland",
      "Eirik Valseth",
      "Matt Lukac",
      "Clint Dawson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.00762"
  },
  {
    "id": "arXiv:2202.00765",
    "title": "A Model for Multi-View Residual Covariances based on Perspective  Deformation",
    "abstract": "In this work, we derive a model for the covariance of the visual residuals in\nmulti-view SfM, odometry and SLAM setups. The core of our approach is the\nformulation of the residual covariances as a combination of geometric and\nphotometric noise sources. And our key novel contribution is the derivation of\na term modelling how local 2D patches suffer from perspective deformation when\nimaging 3D surfaces around a point. Together, these add up to an efficient and\ngeneral formulation which not only improves the accuracy of both feature-based\nand direct methods, but can also be used to estimate more accurate measures of\nthe state entropy and hence better founded point visibility thresholds. We\nvalidate our model with synthetic and real data and integrate it into\nphotometric and feature-based Bundle Adjustment, improving their accuracy with\na negligible overhead.",
    "descriptor": "",
    "authors": [
      "Alejandro Fontan",
      "Laura Oliva",
      "Javier Civera",
      "Rudolph Triebel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00765"
  },
  {
    "id": "arXiv:2202.00769",
    "title": "Distributional Reinforcement Learning via Sinkhorn Iterations",
    "abstract": "Distributional reinforcement learning~(RL) is a class of state-of-the-art\nalgorithms that estimate the whole distribution of the total return rather than\nonly its expectation. The representation manner of each return distribution and\nthe choice of distribution divergence are pivotal for the empirical success of\ndistributional RL. In this paper, we propose a new class of \\textit{Sinkhorn\ndistributional RL} algorithm that learns a finite set of statistics, i.e.,\ndeterministic samples, from each return distribution and then leverages\nSinkhorn iterations to evaluate the Sinkhorn distance between the current and\ntarget Bellmen distributions. Remarkably, as Sinkhorn divergence interpolates\nbetween the Wasserstein distance and Maximum Mean Discrepancy~(MMD). This\nallows our proposed Sinkhorn distributional RL algorithms to find a sweet spot\nleveraging the geometry of optimal transport-based distance, and the unbiased\ngradient estimates of MMD. Finally, experiments on a suite of Atari games\nreveal the competitive performance of Sinkhorn distributional RL algorithm as\nopposed to existing state-of-the-art algorithms.",
    "descriptor": "\nComments: Under review. arXiv admin note: text overlap with arXiv:2110.03155\n",
    "authors": [
      "Ke Sun",
      "Yingnan Zhao",
      "Yi Liu",
      "Bei Jiang",
      "Linglong Kong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00769"
  },
  {
    "id": "arXiv:2202.00770",
    "title": "Local Feature Matching with Transformers for low-end devices",
    "abstract": "LoFTR arXiv:2104.00680 is an efficient deep learning method for finding\nappropriate local feature matches on image pairs. This paper reports on the\noptimization of this method to work on devices with low computational\nperformance and limited memory. The original LoFTR approach is based on a\nResNet arXiv:1512.03385 head and two modules based on Linear Transformer\narXiv:2006.04768 architecture. In the presented work, only the coarse-matching\nblock was left, the number of parameters was significantly reduced, and the\nnetwork was trained using a knowledge distillation technique. The comparison\nshowed that this approach allows to obtain an appropriate feature detection\naccuracy for the student model compared to the teacher model in the coarse\nmatching block, despite the significant reduction of model size. Also, the\npaper shows additional steps required to make model compatible with NVIDIA\nTensorRT runtime, and shows an approach to optimize training method for low-end\nGPUs.",
    "descriptor": "\nComments: Project GitHub page this https URL\n",
    "authors": [
      "Kyrylo Kolodiazhnyi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00770"
  },
  {
    "id": "arXiv:2202.00772",
    "title": "PiP-X: Online feedback motion planning/replanning in dynamic  environments using invariant funnels",
    "abstract": "Computing kinodynamically feasible motion plans and repairing them on-the-fly\nas the environment changes is a challenging, yet relevant problem in\nrobot-navigation. We propose a novel online single-query sampling-based motion\nre-planning algorithm - PiP-X, using finite-time invariant sets - funnels. We\ncombine concepts from sampling-based methods, nonlinear systems analysis and\ncontrol theory to create a single framework that enables feedback motion\nre-planning for any general nonlinear dynamical system in dynamic workspaces.\nA volumetric funnel-graph is constructed using sampling-based methods, and an\noptimal funnel-path from robot configuration to a desired goal region is then\ndetermined by computing the shortest-path subtree in it. Analysing and formally\nquantifying the stability of trajectories using Lyapunov level-set theory\nensures kinodynamic feasibility and guaranteed set-invariance of the\nsolution-paths. The use of incremental search techniques and a pre-computed\nlibrary of motion-primitives ensure that our method can be used for quick\nonline rewiring of controllable motion plans in densely cluttered and dynamic\nenvironments.\nWe represent traversability and sequencibility of trajectories together in\nthe form of an augmented directed-graph, helping us leverage discrete\ngraph-based replanning algorithms to efficiently recompute feasible and\ncontrollable motion plans that are volumetric in nature. We validate our\napproach on a simulated 6DOF quadrotor platform in a variety of scenarios\nwithin a maze and random forest environment. From repeated experiments, we\nanalyse the performance in terms of algorithm-success and length of\ntraversed-trajectory.",
    "descriptor": "\nComments: An abridged version of this paper is in submission to WAFR 2022 conference\n",
    "authors": [
      "Mohamed Khalid M Jaffar",
      "Michael Otte"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.00772"
  },
  {
    "id": "arXiv:2202.00774",
    "title": "Accelerating DNN Training with Structured Data Gradient Pruning",
    "abstract": "Weight pruning is a technique to make Deep Neural Network (DNN) inference\nmore computationally efficient by reducing the number of model parameters over\nthe course of training. However, most weight pruning techniques generally does\nnot speed up DNN training and can even require more iterations to reach model\nconvergence. In this work, we propose a novel Structured Data Gradient Pruning\n(SDGP) method that can speed up training without impacting model convergence.\nThis approach enforces a specific sparsity structure, where only N out of every\nM elements in a matrix can be nonzero, making it amenable to hardware\nacceleration. Modern accelerators such as the Nvidia A100 GPU support this type\nof structured sparsity for 2 nonzeros per 4 elements in a reduction. Assuming\nhardware support for 2:4 sparsity, our approach can achieve a 15-25\\% reduction\nin total training time without significant impact to performance. Source code\nand pre-trained models are available at\n\\url{https://github.com/BradMcDanel/sdgp}.",
    "descriptor": "",
    "authors": [
      "Bradley McDanel",
      "Helia Dinh",
      "John Magallanes"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00774"
  },
  {
    "id": "arXiv:2202.00777",
    "title": "Web accessibility trends and implementation in dynamic web applications",
    "abstract": "The NASA Astrophysics Data System (ADS), a critical research service for the\nastrophysics community, strives to provide the most accessible and inclusive\nenvironment for the discovery and exploration of the astronomical literature.\nPart of this goal involves creating a digital platform that can accommodate\neverybody, including those with disabilities that would benefit from\nalternative ways to present the information provided by the website. NASA ADS\nfollows the official Web Content Accessibility Guidelines (WCAG) standard for\nensuring accessibility of all its applications, striving to exceed this\nstandard where possible. Through the use of both internal audits and external\nexpert review based on these guidelines, we have identified many areas for\nimproving accessibility in our current web application, and have implemented a\nnumber of updates to the UI as a result of this. We present an overview of some\ncurrent web accessibility trends, discuss our experience incorporating these\ntrends in our web application, and discuss the lessons learned and\nrecommendations for future projects.",
    "descriptor": "\nComments: Submitted to ADASS XXXI (2021)\n",
    "authors": [
      "Timothy W. Hostetler",
      "Shinyi Chen",
      "Sergi Blanco-Cuaresma",
      "Alberto Accomazzi",
      "Michael J. Kurtz",
      "Carolyn S. Grant",
      "Edwin Henneken",
      "Donna M. Thompson",
      "Roman Chyla",
      "Golnaz Shapurian",
      "Matthew R. Templeton",
      "Kelly E. Lockhart",
      "Nemanja Martinovic",
      "Stephen McDonald",
      "Felix Grezes"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)"
    ],
    "url": "https://arxiv.org/abs/2202.00777"
  },
  {
    "id": "arXiv:2202.00781",
    "title": "A discussion of measuring the top-1 percent most-highly cited  publications: Quality and impact of Chinese papers",
    "abstract": "The top 1 percent most highly cited articles are watched closely as the\nvanguards of the sciences. Using Web of Science data, one can find that China\nhad overtaken the USA in the relative participation in the top 1 percent in\n2019, after outcompeting the EU on this indicator in 2015. However, this\nfinding contrasts with repeated reports of Western agencies that the quality of\nChinese output in science is lagging other advanced nations, even as it has\ncaught up in numbers of articles. The difference between the results presented\nhere and the previous results depends mainly upon field normalizations, which\nclassify source journals by discipline. Average citation rates of these subsets\nare commonly used as a baseline so that one can compare among disciplines.\nHowever, the expected value of the top 1 percent of a sample of N papers is N\n100, ceteris paribus. Using the average citation rates as expected values,\nerrors are introduced by using the mean of highly skewed distributions and a\nspecious precision in the delineations of the subsets. Classifications can be\nused for the decomposition, but not for the normalization. When the data is\nthus decomposed, the USA ranks ahead of China in biomedical fields such as\nvirology. Although the number of papers is smaller, China outperforms the US in\nthe field of Business and Finance in the Social Sciences Citation Index when p\nis less than .05. Using percentile ranks, subsets other than indexing based\nclassifications can be tested for the statistical significance of differences\namong them.",
    "descriptor": "\nComments: 26 pages, 8 figures accepted for publication in Scientometrics\n",
    "authors": [
      "Caroline S. Wagner",
      "Lin Zhang",
      "Loet Leydesdorff"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.00781"
  },
  {
    "id": "arXiv:2202.00783",
    "title": "Modeling ventilation in a low-income house in Dhaka, Bangladesh",
    "abstract": "According to UNICEF, pneumonia is the leading cause of death in children\nunder 5. 70% of worldwide pneumonia deaths occur in only 15 countries,\nincluding Bangladesh. Previous research has indicated a potential association\nbetween the incidence of pneumonia and the presence of cross-ventilation in\nslum housing in Dhaka, Bangladesh. The objective of this research is to\nestablish a validated computational framework that can predict ventilation\nrates in slum homes to support further studies investigating this correlation.\nTo achieve this objective we employ a building thermal model (BTM) in\ncombination with uncertainty quantification (UQ). The BTM solves for the\ntime-evolution of volume-averaged temperatures in a typical home, considering\ndifferent ventilation configurations. The UQ method propagates uncertainty in\nmodel parameters, weather inputs, and physics models to predict mean values and\n95% confidence intervals for the quantities of interest, namely temperatures\nand ventilation rates in terms of air changes per hour (ACH). The model\npredictions are compared to on-site field measurements of air and thermal mass\ntemperatures, and of ACH. The results indicate that the use of standard cross-\nor single-sided ventilation models limits the accuracy of the ACH predictions;\nin contrast, a model based on a similarity relationship informed by the\navailable ACH measurements can produce more accurate predictions with\nconfidence intervals that encompass the measurements for 12 of the 17 available\ndata points.",
    "descriptor": "",
    "authors": [
      "Yunjae Hwang",
      "Laura",
      "Kwong",
      "Mohammad Saeed Munim",
      "Fosiul Alam Nizame",
      "Stephen Luby",
      "Catherine Gorl\u00e9"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2202.00783"
  },
  {
    "id": "arXiv:2202.00787",
    "title": "Achieving Fairness at No Utility Cost via Data Reweighing",
    "abstract": "With the fast development of algorithmic governance, fairness has become a\ncompulsory property for machine learning models to suppress unintentional\ndiscrimination. In this paper, we focus on the pre-processing aspect for\nachieving fairness, and propose a data reweighing approach that only adjusts\nthe weight for samples in the training phase. Different from most previous\nreweighing methods which assign a uniform weight for each (sub)group, we\ngranularly model the influence from each training sample with regard to\nfairness and predictive utility, and compute individual weights based on the\ninfluence with constraints of both fairness and utility. Experimental results\nreveal that previous methods achieve fairness at a non-negligible cost of\nutility, while as a significant advantage, our approach can empirically release\nthe tradeoff and obtain cost-free fairness. We demonstrate the cost-free\nfairness through vanilla classifiers and standard training processes on\ndifferent fairness notions, compared to baseline methods on multiple tabular\ndatasets.",
    "descriptor": "",
    "authors": [
      "Peizhao Li",
      "Hongfu Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.00787"
  },
  {
    "id": "arXiv:2202.00788",
    "title": "Modular Multi-Rotors: From Quadrotors to Fully-Actuated Aerial Vehicles",
    "abstract": "Traditional aerial vehicles have specific characteristics to perform specific\ntasks. For instance, in aerial transportation, the vehicles are limited with a\nmaximum payload that cannot be extended to transport heavier objects. We\npropose a versatile modular robotic system that can increase its payload and\ncontrollable degrees of freedom by reconfiguring heterogeneous modules; we call\nit H-ModQuad. The system consists of cuboid modules, propelled by quadrotors\nwith tilted propellers that can generate forces in different directions. We\npresent two module designs with different actuation properties that enhance the\ncapabilities of the assembled robot. By assembling different types of modules,\nH-ModQuad can increase its controllable degrees of freedom from 4 to 5 and 6\ndepending on its configuration. We model the modular vehicle and propose a\ngeneral control strategy for all possible numbers of controllable degrees of\nfreedom. We extend the concept of the actuation ellipsoid to find the best\nreference orientation that can maximize the performance of the structure. Our\napproach is validated with experiments using actual robots, showing that the\nstructure can perform independent actuation for rotation and translation.",
    "descriptor": "",
    "authors": [
      "Jiawei Xu",
      "Diego S. D'Antonio",
      "David Salda\u00f1a"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.00788"
  },
  {
    "id": "arXiv:2202.00789",
    "title": "Team Belief DAG Form: A Concise Representation for Team-Correlated  Game-Theoretic Decision Making",
    "abstract": "In this paper, we introduce a new representation for team-coordinated\ngame-theoretic decision making, which we coin team belief DAG form. In our\nrepresentation, at every timestep, a team coordinator observes the information\nthat is public to all its members, and then decides on a prescription for all\nthe possible states consistent with its observations. Our representation\nunifies and extends recent approaches to team coordination. Similar to the\napproach of Carminati et al (2021), our team belief DAG form can be used to\ncapture adversarial team games, and enables standard, out-of-the-box\ngame-theoretic techniques including no-regret learning (e.g., CFR and its\nstate-of-the-art modern variants such as DCFR and PCFR+) and first-order\nmethods. However, our representation can be exponentially smaller, and can be\nviewed as a lossless abstraction of theirs into a directed acyclic graph. In\nparticular, like the LP-based algorithm of Zhang & Sandholm (2022), the size of\nour representation scales with the amount of information uncommon to the team;\nin fact, using linear programming on top of our team belief DAG form to solve\nfor a team correlated equilibrium in an adversarial team games recovers almost\nexactly their algorithm. Unlike that paper, however, our representation\nexplicitly exposes the structure of the decision space, which is what enables\nthe aforementioned game-theoretic techniques.",
    "descriptor": "",
    "authors": [
      "Brian Hu Zhang",
      "Gabriele Farina",
      "Tuomas Sandholm"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.00789"
  },
  {
    "id": "arXiv:2202.00790",
    "title": "On Regularizing Coordinate-MLPs",
    "abstract": "We show that typical implicit regularization assumptions for deep neural\nnetworks (for regression) do not hold for coordinate-MLPs, a family of MLPs\nthat are now ubiquitous in computer vision for representing high-frequency\nsignals. Lack of such implicit bias disrupts smooth interpolations between\ntraining samples, and hampers generalizing across signal regions with different\nspectra. We investigate this behavior through a Fourier lens and uncover that\nas the bandwidth of a coordinate-MLP is enhanced, lower frequencies tend to get\nsuppressed unless a suitable prior is provided explicitly. Based on these\ninsights, we propose a simple regularization technique that can mitigate the\nabove problem, which can be incorporated into existing networks without any\narchitectural modifications.",
    "descriptor": "",
    "authors": [
      "Sameera Ramasinghe",
      "Lachlan MacDonald",
      "Simon Lucey"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00790"
  },
  {
    "id": "arXiv:2202.00791",
    "title": "Mars Terrain Segmentation with Less Labels",
    "abstract": "Planetary rover systems need to perform terrain segmentation to identify\ndrivable areas as well as identify specific types of soil for sample\ncollection. The latest Martian terrain segmentation methods rely on supervised\nlearning which is very data hungry and difficult to train where only a small\nnumber of labeled samples are available. Moreover, the semantic classes are\ndefined differently for different applications (e.g., rover traversal vs.\ngeological) and as a result the network has to be trained from scratch each\ntime, which is an inefficient use of resources. This research proposes a\nsemi-supervised learning framework for Mars terrain segmentation where a deep\nsegmentation network trained in an unsupervised manner on unlabeled images is\ntransferred to the task of terrain segmentation trained on few labeled images.\nThe network incorporates a backbone module which is trained using a contrastive\nloss function and an output atrous convolution module which is trained using a\npixel-wise cross-entropy loss function. Evaluation results using the metric of\nsegmentation accuracy show that the proposed method with contrastive\npretraining outperforms plain supervised learning by 2%-10%. Moreover, the\nproposed model is able to achieve a segmentation accuracy of 91.1% using only\n161 training images (1% of the original dataset) compared to 81.9% with plain\nsupervised learning.",
    "descriptor": "\nComments: IEEE Aerospace Conference 2022\n",
    "authors": [
      "Edwin Goh",
      "Jingdao Chen",
      "Brian Wilson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.00791"
  },
  {
    "id": "arXiv:2202.00794",
    "title": "Learning to pronounce as measuring cross lingual joint  orthography-phonology complexity",
    "abstract": "Recent work has demonstrated that machine learning models allow us to compare\nlanguages by showing how hard each language might be to learn under specific\ntasks. Following this line of investigation, we investigate what makes a\nlanguage \"hard to pronounce\" by modelling the task of grapheme-to-phoneme (g2p)\ntransliteration. By training a character-level transformer model on this task\nacross 22 languages and measuring the model's proficiency against its grapheme\nand phoneme inventories, we show that certain characteristics emerge that\nseparate easier and harder languages with respect to learning to pronounce.\nNamely that the complexity of a languages pronunciation from its orthography is\ndue to how expressive or simple its grapheme-to-phoneme mapping is. Further\ndiscussion illustrates how future studies should consider relative data\nsparsity per language in order to design more fair cross lingual comparison\ntasks.",
    "descriptor": "\nComments: Submitted to NLPML 2022\n",
    "authors": [
      "Domenic Rosati"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.00794"
  },
  {
    "id": "arXiv:2202.00795",
    "title": "Disaster Tweets Classification using BERT-Based Language Model",
    "abstract": "Social networking services have became an important communication channel in\ntime of emergency. The aim of this study is to create a machine learning\nlanguage model that is able to investigate if a person or area was in danger or\nnot. The ubiquitousness of smartphones enables people to announce an emergency\nthey are observing in real-time. Because of this, more agencies are interested\nin programmatically monitoring Twitter (i.e. disaster relief organizations and\nnews agencies). Design a language model that is able to understand and\nacknowledge when a disaster is happening based on the social network posts will\nbecome more and more necessary over time.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2102.12162 by other authors\n",
    "authors": [
      "Anh Duc Le"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00795"
  },
  {
    "id": "arXiv:2202.00796",
    "title": "On the Benefits of Selectivity in Pseudo-Labeling for Unsupervised  Multi-Source-Free Domain Adaptation",
    "abstract": "Due to privacy, storage, and other constraints, there is a growing need for\nunsupervised domain adaptation techniques in machine learning that do not\nrequire access to the data used to train a collection of source models.\nExisting methods for such multi-source-free domain adaptation typically train a\ntarget model using supervised techniques in conjunction with pseudo-labels for\nthe target data, which are produced by the available source models. However, we\nshow that assigning pseudo-labels to only a subset of the target data leads to\nimproved performance. In particular, we develop an information-theoretic bound\non the generalization error of the resulting target model that demonstrates an\ninherent bias-variance trade-off controlled by the subset choice. Guided by\nthis analysis, we develop a method that partitions the target data into\npseudo-labeled and unlabeled subsets to balance the trade-off. In addition to\nexploiting the pseudo-labeled subset, our algorithm further leverages the\ninformation in the unlabeled subset via a traditional unsupervised domain\nadaptation feature alignment procedure. Experiments on multiple benchmark\ndatasets demonstrate the superior performance of the proposed method.",
    "descriptor": "",
    "authors": [
      "Maohao Shen",
      "Yuheng Bu",
      "Gregory Wornell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00796"
  },
  {
    "id": "arXiv:2202.00798",
    "title": "Hierarchical Entity Alignment for Attribute-Rich Event-Driven Graphs",
    "abstract": "This paper addresses the problem of entity alignment in attribute-rich\nevent-driven graphs. Unlike many other entity alignment problems, we are\ninterested in aligning entities based on the similarity of their actions, i.e.,\nentities that participate in similar events are more likely to be the same. We\nmodel the generative process of this problem as a Bayesian model and derive our\nproposed algorithm from the posterior predictive distribution. We apply our\nHierarchical Entity AlignmenT (HEAT) algorithm to two datasets, one on\npublications and the other on financial transactions, derived from real data\nand provided to us by an external collaborator.",
    "descriptor": "",
    "authors": [
      "Elizabeth Hou",
      "Joanna Brown",
      "John Fisher"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.00798"
  },
  {
    "id": "arXiv:2202.00799",
    "title": "What is the Will of the People? Moderation Preferences for  Misinformation",
    "abstract": "To reduce the spread of misinformation, social media platforms may take\nenforcement actions against offending content, such as adding informational\nwarning labels, reducing distribution, or removing content entirely. However,\nboth their actions and their inactions have been controversial and plagued by\nallegations of partisan bias. The controversy in part can be explained by a\nlack of clarity around what actions should be taken, as they may not neatly\nreduce to questions of factual accuracy. When decisions are contested, the\nlegitimacy of decision-making processes becomes crucial to public acceptance.\nPlatforms have tried to legitimize their decisions by following well-defined\nprocedures through rules and codebooks. In this paper, we consider an alternate\nsource of legitimacy -- the will of the people. Surprisingly little is known\nabout what ordinary people want the platforms to do about specific content. We\nprovide empirical evidence about lay raters' preferences for platform actions\non 368 news articles. Our results confirm that on many items there is no clear\nconsensus on which actions to take. There is no partisan difference in terms of\nhow many items deserve platform actions but liberals do prefer somewhat more\naction on content from conservative sources, and vice versa. We find a clear\nhierarchy of perceived severity, with inform being the least severe action,\nfollowed by reduce, and then remove. We also find that judgments about two\nholistic properties, misleadingness and harm, could serve as an effective proxy\nto determine what actions would be approved by a majority of raters. We\nconclude with the promise of the will of the people while acknowledging the\npractical details that would have to be worked out.",
    "descriptor": "\nComments: currently under review\n",
    "authors": [
      "Shubham Atreja",
      "Libby Hemphill",
      "Paul Resnick"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.00799"
  },
  {
    "id": "arXiv:2202.00802",
    "title": "A Semi-Supervised Deep Clustering Pipeline for Mining Intentions From  Texts",
    "abstract": "Mining the latent intentions from large volumes of natural language inputs is\na key step to help data analysts design and refine Intelligent Virtual\nAssistants (IVAs) for customer service. To aid data analysts in this task we\npresent Verint Intent Manager (VIM), an analysis platform that combines\nunsupervised and semi-supervised approaches to help analysts quickly surface\nand organize relevant user intentions from conversational texts. For the\ninitial exploration of data we make use of a novel unsupervised and\nsemi-supervised pipeline that integrates the fine-tuning of high performing\nlanguage models, a distributed k-NN graph building method and community\ndetection techniques for mining the intentions and topics from texts. The\nfine-tuning step is necessary because pre-trained language models cannot encode\ntexts to efficiently surface particular clustering structures when the target\ntexts are from an unseen domain or the clustering task is not topic detection.\nFor flexibility we deploy two clustering approaches: where the number of\nclusters must be specified and where the number of clusters is detected\nautomatically with comparable clustering quality but at the expense of\nadditional computation time. We describe the application and deployment and\ndemonstrate its performance using BERT on three text mining tasks. Our\nexperiments show that BERT begins to produce better task-aware representations\nusing a labeled subset as small as 0.5% of the task data. The clustering\nquality exceeds the state-of-the-art results when BERT is fine-tuned with\nlabeled subsets of only 2.5% of the task data. As deployed in the VIM\napplication, this flexible clustering pipeline produces high quality results,\nimproving the performance of data analysts and reducing the time it takes to\nsurface intentions from customer service data, thereby reducing the time it\ntakes to build and deploy IVAs in new domains.",
    "descriptor": "\nComments: Submitted to The Thirty-Fourth Annual Conference on Innovative Applications of Artificial Intelligence (IAAI-22)\n",
    "authors": [
      "Xinyu Chen",
      "Ian Beaver"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00802"
  },
  {
    "id": "arXiv:2202.00804",
    "title": "Automatic event detection in football using tracking data",
    "abstract": "One of the main shortcomings of event data in football, which has been\nextensively used for analytics in the recent years, is that it still requires\nmanual collection, thus limiting its availability to a reduced number of\ntournaments. In this work, we propose a computational framework to\nautomatically extract football events using tracking data, namely the\ncoordinates of all players and the ball. Our approach consists of two models:\n(1) the possession model evaluates which player was in possession of the ball\nat each time, as well as the distinct player configurations in the time\nintervals where the ball is not in play; (2) the event detection model relies\non the changes in ball possession to determine in-game events, namely passes,\nshots, crosses, saves, receptions and interceptions, as well as set pieces.\nFirst, analyze the accuracy of tracking data for determining ball possession,\nas well as the accuracy of the time annotations for the manually collected\nevents. Then, we benchmark the auto-detected events with a dataset of manually\nannotated events to show that in most categories the proposed method achieves\n$+90\\%$ detection rate. Lastly, we demonstrate how the contextual information\noffered by tracking data can be leveraged to increase the granularity of\nauto-detected events, and exhibit how the proposed framework may be used to\nconduct a myriad of data analyses in football.",
    "descriptor": "\nComments: 31 pages, 17 figures\n",
    "authors": [
      "Ferran Vidal-Codina",
      "Nicolas Evans",
      "Bahaeddine El Fakir",
      "Johsan Billingham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00804"
  },
  {
    "id": "arXiv:2202.00805",
    "title": "Context Uncertainty in Contextual Bandits with Applications to  Recommender Systems",
    "abstract": "Recurrent neural networks have proven effective in modeling sequential user\nfeedbacks for recommender systems. However, they usually focus solely on item\nrelevance and fail to effectively explore diverse items for users, therefore\nharming the system performance in the long run. To address this problem, we\npropose a new type of recurrent neural networks, dubbed recurrent exploration\nnetworks (REN), to jointly perform representation learning and effective\nexploration in the latent space. REN tries to balance relevance and exploration\nwhile taking into account the uncertainty in the representations. Our\ntheoretical analysis shows that REN can preserve the rate-optimal sublinear\nregret even when there exists uncertainty in the learned representations. Our\nempirical study demonstrates that REN can achieve satisfactory long-term\nrewards on both synthetic and real-world recommendation datasets, outperforming\nstate-of-the-art models.",
    "descriptor": "\nComments: To appear at AAAI 2022\n",
    "authors": [
      "Hao Wang",
      "Yifei Ma",
      "Hao Ding",
      "Yuyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00805"
  },
  {
    "id": "arXiv:2202.00806",
    "title": "Security Evaluation of Block-based Image Encryption for Vision  Transformer against Jigsaw Puzzle Solver Attack",
    "abstract": "The aim of this paper is to evaluate the security of a block-based image\nencryption for the vision transformer against jigsaw puzzle solver attacks. The\nvision transformer, a model for image classification based on the transformer\narchitecture, is carried out by dividing an image into a grid of square\npatches. Some encryption schemes for the vision transformer have been proposed\nby applying block-based image encryption such as block scrambling and rotating\nto patches of the image. On the other hand, the security of encryption scheme\nfor the vision transformer has never evaluated. In this paper, jigsaw puzzle\nsolver attacks are utilized to evaluate the security of encrypted images by\nregarding the divided patches as pieces of a jigsaw puzzle. In experiments, an\nimage is resized and divided into patches to apply block scrambling-based image\nencryption, and then the security of encrypted images for the vision\ntransformer against jigsaw puzzle solver attacks is evaluated.",
    "descriptor": "\nComments: To be appeared in IEEE 4th Global Conference on Life Sciences and Technologies (LifeTech 2022)\n",
    "authors": [
      "Tatsuya Chuman",
      "Hitoshi Kiya"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.00806"
  },
  {
    "id": "arXiv:2202.00807",
    "title": "Federated Learning Challenges and Opportunities: An Outlook",
    "abstract": "Federated learning (FL) has been developed as a promising framework to\nleverage the resources of edge devices, enhance customers' privacy, comply with\nregulations, and reduce development costs. Although many methods and\napplications have been developed for FL, several critical challenges for\npractical FL systems remain unaddressed. This paper provides an outlook on FL\ndevelopment, categorized into five emerging directions of FL, namely algorithm\nfoundation, personalization, hardware and security constraints, lifelong\nlearning, and nonstandard data. Our unique perspectives are backed by practical\nobservations from large-scale federated systems for edge devices.",
    "descriptor": "\nComments: This paper provides an outlook on FL development as part of the ICASSP 2022 special session entitled \"Frontiers of Federated Learning: Applications, Challenges, and Opportunities\"\n",
    "authors": [
      "Jie Ding",
      "Eric Tramel",
      "Anit Kumar Sahu",
      "Shuang Wu",
      "Salman Avestimehr",
      "Tao Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.00807"
  },
  {
    "id": "arXiv:2202.00808",
    "title": "Gromov-Wasserstein Discrepancy with Local Differential Privacy for  Distributed Structural Graphs",
    "abstract": "Learning the similarity between structured data, especially the graphs, is\none of the essential problems. Besides the approach like graph kernels,\nGromov-Wasserstein (GW) distance recently draws big attention due to its\nflexibility to capture both topological and feature characteristics, as well as\nhandling the permutation invariance. However, structured data are widely\ndistributed for different data mining and machine learning applications. With\nprivacy concerns, accessing the decentralized data is limited to either\nindividual clients or different silos. To tackle these issues, we propose a\nprivacy-preserving framework to analyze the GW discrepancy of node embedding\nlearned locally from graph neural networks in a federated flavor, and then\nexplicitly place local differential privacy (LDP) based on Multi-bit Encoder to\nprotect sensitive information. Our experiments show that, with strong privacy\nprotections guaranteed by the $\\varepsilon$-LDP algorithm, the proposed\nframework not only preserves privacy in graph learning but also presents a\nnoised structural metric under GW distance, resulting in comparable and even\nbetter performance in classification and clustering tasks. Moreover, we reason\nthe rationale behind the LDP-based GW distance analytically and empirically.",
    "descriptor": "",
    "authors": [
      "Hongwei Jin",
      "Xun Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.00808"
  },
  {
    "id": "arXiv:2202.00810",
    "title": "Imaging based on Compton scattering: model-uncertainty and data-driven  reconstruction methods",
    "abstract": "The recent development of scintillation crystals combined with $\\gamma$-rays\nsources opens the way to an imaging concept based on Compton scattering, namely\nCompton scattering tomography (CST). The associated inverse problem rises many\nchallenges: non-linearity, multiple order-scattering and high level of noise.\nAlready studied in the literature, these challenges lead unavoidably to\nuncertainty of the forward model. This work proposes to study exact and\napproximated forward models and develops two data-driven reconstruction\nalgorithms able to tackle the inexactness of the forward model. The first one\nis based on the projective method called regularized sequential subspace\noptimization (RESESOP). We consider here a finite dimensional restriction of\nthe semi-discrete forward model and show its well-posedness and regularisation\nproperties. The second one considers the unsupervised learning method, deep\nimage prior (DIP), inspired by the construction of the model uncertainty in\nRESESOP. The methods are validated on Monte-Carlo data.",
    "descriptor": "",
    "authors": [
      "Janek G\u00f6deke",
      "Ga\u00ebl Rigaud"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.00810"
  },
  {
    "id": "arXiv:2202.00813",
    "title": "A Graph Based Neural Network Approach to Immune Profiling of Multiplexed  Tissue Samples",
    "abstract": "Multiplexed immunofluorescence provides an unprecedented opportunity for\nstudying specific cell-to-cell and cell microenvironment interactions. We\nemploy graph neural networks to combine features obtained from tissue\nmorphology with measurements of protein expression to profile the tumour\nmicroenvironment associated with different tumour stages. Our framework\npresents a new approach to analysing and processing these complex\nmulti-dimensional datasets that overcomes some of the key challenges in\nanalysing these data and opens up the opportunity to abstract biologically\nmeaningful interactions.",
    "descriptor": "",
    "authors": [
      "Natalia Garcia Martin",
      "Stefano Malacrino",
      "Marta Wojciechowska",
      "Leticia Campo",
      "Helen Jones",
      "David C. Wedge",
      "Chris Holmes",
      "Korsuk Sirinukunwattana",
      "Heba Sailem",
      "Clare Verrill",
      "Jens Rittscher"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)",
      "Cell Behavior (q-bio.CB)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2202.00813"
  },
  {
    "id": "arXiv:2202.00817",
    "title": "Do Differentiable Simulators Give Better Policy Gradients?",
    "abstract": "Differentiable simulators promise faster computation time for reinforcement\nlearning by replacing zeroth-order gradient estimates of a stochastic objective\nwith an estimate based on first-order gradients. However, it is yet unclear\nwhat factors decide the performance of the two estimators on complex landscapes\nthat involve long-horizon planning and control on physical systems, despite the\ncrucial relevance of this question for the utility of differentiable\nsimulators. We show that characteristics of certain physical systems, such as\nstiffness or discontinuities, may compromise the efficacy of the first-order\nestimator, and analyze this phenomenon through the lens of bias and variance.\nWe additionally propose an $\\alpha$-order gradient estimator, with $\\alpha \\in\n[0,1]$, which correctly utilizes exact gradients to combine the efficiency of\nfirst-order estimates with the robustness of zero-order methods. We demonstrate\nthe pitfalls of traditional estimators and the advantages of the $\\alpha$-order\nestimator on some numerical examples.",
    "descriptor": "",
    "authors": [
      "H.J. Terry Suh",
      "Max Simchowitz",
      "Kaiqing Zhang",
      "Russ Tedrake"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.00817"
  },
  {
    "id": "arXiv:2202.00821",
    "title": "Optimizing Sequential Experimental Design with Deep Reinforcement  Learning",
    "abstract": "Bayesian approaches developed to solve the optimal design of sequential\nexperiments are mathematically elegant but computationally challenging.\nRecently, techniques using amortization have been proposed to make these\nBayesian approaches practical, by training a parameterized policy that proposes\ndesigns efficiently at deployment time. However, these methods may not\nsufficiently explore the design space, require access to a differentiable\nprobabilistic model and can only optimize over continuous design spaces. Here,\nwe address these limitations by showing that the problem of optimizing policies\ncan be reduced to solving a Markov decision process (MDP). We solve the\nequivalent MDP with modern deep reinforcement learning techniques. Our\nexperiments show that our approach is also computationally efficient at\ndeployment time and exhibits state-of-the-art performance on both continuous\nand discrete design spaces, even when the probabilistic model is a black box.",
    "descriptor": "",
    "authors": [
      "Tom Blau",
      "Edwin Bonilla",
      "Amir Dezfouli",
      "Iadine Chades"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00821"
  },
  {
    "id": "arXiv:2202.00828",
    "title": "Co-training Improves Prompt-based Learning for Large Language Models",
    "abstract": "We demonstrate that co-training (Blum & Mitchell, 1998) can improve the\nperformance of prompt-based learning by using unlabeled data. While prompting\nhas emerged as a promising paradigm for few-shot and zero-shot learning, it is\noften brittle and requires much larger models compared to the standard\nsupervised setup. We find that co-training makes it possible to improve the\noriginal prompt model and at the same time learn a smaller, downstream\ntask-specific model. In the case where we only have partial access to a prompt\nmodel (e.g., output probabilities from GPT-3 (Brown et al., 2020)) we learn a\ncalibration model over the prompt outputs. When we have full access to the\nprompt model's gradients but full finetuning remains prohibitively expensive\n(e.g., T0 (Sanh et al., 2021)), we learn a set of soft prompt continuous\nvectors to iteratively update the prompt model. We find that models trained in\nthis manner can significantly improve performance on challenging datasets where\nthere is currently a large gap between prompt-based learning and\nfully-supervised models.",
    "descriptor": "\nComments: 17 pages, 8 figures\n",
    "authors": [
      "Hunter Lang",
      "Monica Agrawal",
      "Yoon Kim",
      "David Sontag"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00828"
  },
  {
    "id": "arXiv:2202.00830",
    "title": "Quantum Remote Entanglement for Medium-Free Secure Communication?",
    "abstract": "Present-day quantum communication predominantly depends on trusted relays\n(e.g., quantum repeaters, low-Earth-orbit satellite) connected by optical fiber\ncables to transmit information. However, recent evidence supports a decades-old\nconcept that quantum entanglement, harnessed by current quantum communication\nsystems, does not necessarily rely on a physical relay medium. In modern\nquantum communication networks, this trusted relay infrastructure is (1)\nsusceptible to security attacks, (2) limited by the channel capacity, (3)\nsubject to decoherence loss, and (4) expensive to set up. The instantaneous and\nfaster-than-light activities of quantum entanglement occurring in quantum\ncommunication have suggested guidance by some non-locality nature. On the\ncontrary, neither ground nor space-relays have shown or been demonstrated to\nembody it. It is proposed in this paper that the non-locality nature of quantum\ntheory governs quantum entanglement; elementary particles, components of a\nuniversal quantum body, can achieve remote entanglement regardless of a\nphysical medium or spatial proximity. Evidence and theory supporting remote\nentanglement in superconducting quantum systems (entanglement fidelities for\ncommunication in particular) are presented. One such particle, the photon,\nrepresenting a basic unit of quantum information, qubit $|\\psi\\rangle = \\alpha\n|0\\rangle + \\beta |1\\rangle$, consists of real continuous values in complex\nnumbers $(\\alpha, \\beta)$ with infinite precision. These values $(\\alpha,\n\\beta)$ can account for the distinctiveness of qubits and result in an identity\n$QuID$ that possibly supports remote entanglement. New approaches to\nmedium-free secure quantum communication are suggested by running simulations\nand actual quantum computations on a quantum circuit.",
    "descriptor": "",
    "authors": [
      "Wesley Joon-Wie Tann"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.00830"
  },
  {
    "id": "arXiv:2202.00834",
    "title": "Algorithms for Efficiently Learning Low-Rank Neural Networks",
    "abstract": "We study algorithms for learning low-rank neural networks -- networks where\nthe weight parameters are re-parameterized by products of two low-rank\nmatrices. First, we present a provably efficient algorithm which learns an\noptimal low-rank approximation to a single-hidden-layer ReLU network up to\nadditive error $\\epsilon$ with probability $\\ge 1 - \\delta$, given access to\nnoiseless samples with Gaussian marginals in polynomial time and samples. Thus,\nwe provide the first example of an algorithm which can efficiently learn a\nneural network up to additive error without assuming the ground truth is\nrealizable. To solve this problem, we introduce an efficient SVD-based\n\\textit{Nonlinear Kernel Projection} algorithm for solving a nonlinear low-rank\napproximation problem over Gaussian space. Inspired by the efficiency of our\nalgorithm, we propose a novel low-rank initialization framework for training\nlow-rank \\textit{deep} networks, and prove that for ReLU networks, the gap\nbetween our method and existing schemes widens as the desired rank of the\napproximating weights decreases, or as the dimension of the inputs increases\n(the latter point holds when network width is superlinear in dimension).\nFinally, we validate our theory by training ResNets and EfficientNets\n\\citep{he2016deepresidual, tan2019efficientnet} models on ImageNet\n\\citep{ILSVRC15}.",
    "descriptor": "\nComments: 52 pages, 4 figures, in submission\n",
    "authors": [
      "Kiran Vodrahalli",
      "Rakesh Shivanna",
      "Mahesh Sathiamoorthy",
      "Sagar Jain",
      "Ed Chi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00834"
  },
  {
    "id": "arXiv:2202.00836",
    "title": "On-Sensor Binarized Fully Convolutional Neural Network with A Pixel  Processor Array",
    "abstract": "This work presents a method to implement fully convolutional neural networks\n(FCNs) on Pixel Processor Array (PPA) sensors, and demonstrates coarse\nsegmentation and object localisation tasks. We design and train binarized FCN\nfor both binary weights and activations using batchnorm, group convolution, and\nlearnable threshold for binarization, producing networks small enough to be\nembedded on the focal plane of the PPA, with limited local memory resources,\nand using parallel elementary add/subtract, shifting, and bit operations only.\nWe demonstrate the first implementation of an FCN on a PPA device, performing\nthree convolution layers entirely in the pixel-level processors. We use this\narchitecture to demonstrate inference generating heat maps for object\nsegmentation and localisation at over 280 FPS using the SCAMP-5 PPA vision\nchip.",
    "descriptor": "",
    "authors": [
      "Yanan Liu",
      "Laurie Bose",
      "Yao Lu",
      "Piotr Dudek",
      "Walterio Mayol-Cuevas"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Emerging Technologies (cs.ET)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.00836"
  },
  {
    "id": "arXiv:2202.00838",
    "title": "Finding Biological Plausibility for Adversarially Robust Features via  Metameric Tasks",
    "abstract": "Recent work suggests that representations learned by adversarially robust\nnetworks are more human perceptually-aligned than non-robust networks via image\nmanipulations. Despite appearing closer to human visual perception, it is\nunclear if the constraints in robust DNN representations match biological\nconstraints found in human vision. Human vision seems to rely on\ntexture-based/summary statistic representations in the periphery, which have\nbeen shown to explain phenomena such as crowding and performance on visual\nsearch tasks. To understand how adversarially robust\noptimizations/representations compare to human vision, we performed a\npsychophysics experiment using a set of metameric discrimination tasks where we\nevaluated how well human observers could distinguish between images synthesized\nto match adversarially robust representations compared to non-robust\nrepresentations and a texture synthesis model of peripheral vision (Texforms).\nWe found that the discriminability of robust representation and texture model\nimages decreased to near chance performance as stimuli were presented farther\nin the periphery. Moreover, performance on robust and texture-model images\nshowed similar trends within participants, while performance on non-robust\nrepresentations changed minimally across the visual field. These results\ntogether suggest that (1) adversarially robust representations capture\nperipheral computation better than non-robust representations and (2) robust\nrepresentations capture peripheral computation similar to current\nstate-of-the-art texture peripheral vision models. More broadly, our findings\nsupport the idea that localized texture summary statistic representations may\ndrive human invariance to adversarial perturbations and that the incorporation\nof such representations in DNNs could give rise to useful properties like\nadversarial robustness.",
    "descriptor": "\nComments: Accepted to ICLR 2022 as a Spotlight\n",
    "authors": [
      "Anne Harrington",
      "Arturo Deza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2202.00838"
  },
  {
    "id": "arXiv:2202.00843",
    "title": "Pose Guided Image Generation from Misaligned Sources via Residual Flow  Based Correction",
    "abstract": "Generating new images with desired properties (e.g. new view/poses) from\nsource images has been enthusiastically pursued recently, due to its wide range\nof potential applications. One way to ensure high-quality generation is to use\nmultiple sources with complementary information such as different views of the\nsame object. However, as source images are often misaligned due to the large\ndisparities among the camera settings, strong assumptions have been made in the\npast with respect to the camera(s) or/and the object in interest, limiting the\napplication of such techniques. Therefore, we propose a new general approach\nwhich models multiple types of variations among sources, such as view angles,\nposes, facial expressions, in a unified framework, so that it can be employed\non datasets of vastly different nature. We verify our approach on a variety of\ndata including humans bodies, faces, city scenes and 3D objects. Both the\nqualitative and quantitative results demonstrate the better performance of our\nmethod than the state of the art.",
    "descriptor": "",
    "authors": [
      "Jiawei Lu",
      "He Wang",
      "Tianjia Shao",
      "Yin Yang",
      "Kun Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00843"
  },
  {
    "id": "arXiv:2202.00845",
    "title": "Random Processes with High Variance Produce Scale Free Networks",
    "abstract": "Real-world networks tend to be scale free, having heavy-tailed degree\ndistributions with more hubs than predicted by classical random graph\ngeneration methods. Preferential attachment and growth are the most commonly\naccepted mechanisms leading to these networks and are incorporated in the\nBarab\\'asi-Albert (BA) model. We provide an alternative model using a randomly\nstopped linking process inspired by a generalized Central Limit Theorem (CLT)\nfor geometric distributions with widely varying parameters. The common\ncharacteristic of both the BA model and our randomly stopped linking model is\nthe mixture of widely varying geometric distributions, suggesting the critical\ncharacteristic of scale free networks is high variance, not growth or\npreferential attachment. The limitation of classical random graph models is low\nvariance in parameters, while scale free networks are the natural, expected\nresult of real-world variance.",
    "descriptor": "\nComments: Submitted to Physica A. 13 pages, 1 figure\n",
    "authors": [
      "Josh Johnston",
      "Tim Andersen"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.00845"
  },
  {
    "id": "arXiv:2202.00846",
    "title": "Adaptive Experimentation with Delayed Binary Feedback",
    "abstract": "Conducting experiments with objectives that take significant delays to\nmaterialize (e.g. conversions, add-to-cart events, etc.) is challenging.\nAlthough the classical \"split sample testing\" is still valid for the delayed\nfeedback, the experiment will take longer to complete, which also means\nspending more resources on worse-performing strategies due to their fixed\nallocation schedules. Alternatively, adaptive approaches such as \"multi-armed\nbandits\" are able to effectively reduce the cost of experimentation. But these\nmethods generally cannot handle delayed objectives directly out of the box.\nThis paper presents an adaptive experimentation solution tailored for delayed\nbinary feedback objectives by estimating the real underlying objectives before\nthey materialize and dynamically allocating variants based on the estimates.\nExperiments show that the proposed method is more efficient for delayed\nfeedback compared to various other approaches and is robust in different\nsettings. In addition, we describe an experimentation product powered by this\nalgorithm. This product is currently deployed in the online experimentation\nplatform of JD.com, a large e-commerce company and a publisher of digital ads.",
    "descriptor": "\nComments: to be published in Proceedings of the ACM Web Conference 2022 (WWW '22)\n",
    "authors": [
      "Zenan Wang",
      "Carlos Carrion",
      "Xiliang Lin",
      "Fuhua Ji",
      "Yongjun Bao",
      "Weipeng Yan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00846"
  },
  {
    "id": "arXiv:2202.00848",
    "title": "Some Reflections on Drawing Causal Inference using Textual Data:  Parallels Between Human Subjects and Organized Texts",
    "abstract": "We examine the role of textual data as study units when conducting causal\ninference by drawing parallels between human subjects and organized texts. %in\nhuman population research. We elaborate on key causal concepts and principles,\nand expose some ambiguity and sometimes fallacies. To facilitate better framing\na causal query, we discuss two strategies: (i) shifting from immutable traits\nto perceptions of them, and (ii) shifting from some abstract concept/property\nto its constituent parts, i.e., adopting a constructivist perspective of an\nabstract concept. We hope this article would raise the awareness of the\nimportance of articulating and clarifying fundamental concepts before delving\ninto developing methodologies when drawing causal inference using textual data.",
    "descriptor": "\nComments: Accepted to CLeaR 2022\n",
    "authors": [
      "Bo Zhang",
      "Jiayao Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00848"
  },
  {
    "id": "arXiv:2202.00850",
    "title": "Active Audio-Visual Separation of Dynamic Sound Sources",
    "abstract": "We explore active audio-visual separation for dynamic sound sources, where an\nembodied agent moves intelligently in a 3D environment to continuously isolate\nthe time-varying audio stream being emitted by an object of interest. The agent\nhears a mixed stream of multiple time-varying audio sources (e.g., multiple\npeople conversing and a band playing music at a noisy party). Given a limited\ntime budget, it needs to extract the target sound using egocentric audio-visual\nobservations. We propose a reinforcement learning agent equipped with a novel\ntransformer memory that learns motion policies to control its camera and\nmicrophone to recover the dynamic target audio, improving its own estimates for\npast timesteps via self-attention. Using highly realistic acoustic SoundSpaces\nsimulations in real-world scanned Matterport3D environments, we show that our\nmodel is able to learn efficient behavior to carry out continuous separation of\na time-varying audio target. Project:\nhttps://vision.cs.utexas.edu/projects/active-av-dynamic-separation/.",
    "descriptor": "",
    "authors": [
      "Sagnik Majumder",
      "Ziad Al-Halah",
      "Kristen Grauman"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.00850"
  },
  {
    "id": "arXiv:2202.00854",
    "title": "Modification Problems toward Proper (Helly) Circular-arc Graphs",
    "abstract": "We present a $9^k\\cdot n^{O(1)}$-time algorithm for the proper circular-arc\nvertex deletion problem, resolving an open problem of van 't Hof and Villanger\n[Algorithmica 2013] and Crespelle et al. [arXiv:2001.06867]. Our structural\nstudy also implies parameterized algorithms for modification problems toward\nproper Helly circular-arc graphs.",
    "descriptor": "",
    "authors": [
      "Yixin Cao",
      "Jianxin Wang",
      "Hanchun Yuan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.00854"
  },
  {
    "id": "arXiv:2202.00855",
    "title": "Extension -- Adaptive Sampling with Implicit Radiance Field",
    "abstract": "This paper aims to explore and summarize the state-of-the-art progress in\nMonte Carlo adaptive light field sampling and reconstruction using deep\nreinforcement learning, with possible extension to it.",
    "descriptor": "",
    "authors": [
      "Yuchi Huo"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00855"
  },
  {
    "id": "arXiv:2202.00856",
    "title": "The Role of Linear Layers in Nonlinear Interpolating Networks",
    "abstract": "This paper explores the implicit bias of overparameterized neural networks of\ndepth greater than two layers. Our framework considers a family of networks of\nvarying depth that all have the same capacity but different implicitly defined\nrepresentation costs. The representation cost of a function induced by a neural\nnetwork architecture is the minimum sum of squared weights needed for the\nnetwork to represent the function; it reflects the function space bias\nassociated with the architecture. Our results show that adding linear layers to\na ReLU network yields a representation cost that reflects a complex interplay\nbetween the alignment and sparsity of ReLU units. Specifically, using a neural\nnetwork to fit training data with minimum representation cost yields an\ninterpolating function that is constant in directions perpendicular to a\nlow-dimensional subspace on which a parsimonious interpolant exists.",
    "descriptor": "",
    "authors": [
      "Greg Ongie",
      "Rebecca Willett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00856"
  },
  {
    "id": "arXiv:2202.00858",
    "title": "Hierarchical Shrinkage: improving the accuracy and interpretability of  tree-based methods",
    "abstract": "Tree-based models such as decision trees and random forests (RF) are a\ncornerstone of modern machine-learning practice. To mitigate overfitting, trees\nare typically regularized by a variety of techniques that modify their\nstructure (e.g. pruning). We introduce Hierarchical Shrinkage (HS), a post-hoc\nalgorithm that does not modify the tree structure, and instead regularizes the\ntree by shrinking the prediction over each node towards the sample means of its\nancestors. The amount of shrinkage is controlled by a single regularization\nparameter and the number of data points in each ancestor. Since HS is a\npost-hoc method, it is extremely fast, compatible with any tree growing\nalgorithm, and can be used synergistically with other regularization\ntechniques. Extensive experiments over a wide variety of real-world datasets\nshow that HS substantially increases the predictive performance of decision\ntrees, even when used in conjunction with other regularization techniques.\nMoreover, we find that applying HS to each tree in an RF often improves\naccuracy, as well as its interpretability by simplifying and stabilizing its\ndecision boundaries and SHAP values. We further explain the success of HS in\nimproving prediction performance by showing its equivalence to ridge regression\non a (supervised) basis constructed of decision stumps associated with the\ninternal nodes of a tree. All code and models are released in a full-fledged\npackage available on Github (github.com/csinva/imodels)",
    "descriptor": "",
    "authors": [
      "Abhineet Agarwal",
      "Yan Shuo Tan",
      "Omer Ronen",
      "Chandan Singh",
      "Bin Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Applications (stat.AP)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00858"
  },
  {
    "id": "arXiv:2202.00866",
    "title": "Decoupled IoU Regression for Object Detection",
    "abstract": "Non-maximum suppression (NMS) is widely used in object detection pipelines\nfor removing duplicated bounding boxes. The inconsistency between the\nconfidence for NMS and the real localization confidence seriously affects\ndetection performance. Prior works propose to predict Intersection-over-Union\n(IoU) between bounding boxes and corresponding ground-truths to improve NMS,\nwhile accurately predicting IoU is still a challenging problem. We argue that\nthe complex definition of IoU and feature misalignment make it difficult to\npredict IoU accurately. In this paper, we propose a novel Decoupled IoU\nRegression (DIR) model to handle these problems. The proposed DIR decouples the\ntraditional localization confidence metric IoU into two new metrics, Purity and\nIntegrity. Purity reflects the proportion of the object area in the detected\nbounding box, and Integrity refers to the completeness of the detected object\narea. Separately predicting Purity and Integrity can divide the complex mapping\nbetween the bounding box and its IoU into two clearer mappings and model them\nindependently. In addition, a simple but effective feature realignment approach\nis also introduced to make the IoU regressor work in a hindsight manner, which\ncan make the target mapping more stable. The proposed DIR can be conveniently\nintegrated with existing two-stage detectors and significantly improve their\nperformance. Through a simple implementation of DIR with HTC, we obtain 51.3%\nAP on MS COCO benchmark, which outperforms previous methods and achieves\nstate-of-the-art.",
    "descriptor": "\nComments: ACMMM 2021 Poster\n",
    "authors": [
      "Yan Gao",
      "Qimeng Wang",
      "Xu Tang",
      "Haochen Wang",
      "Fei Ding",
      "Jing Li",
      "Yao Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00866"
  },
  {
    "id": "arXiv:2202.00868",
    "title": "VIRDO: Visio-tactile Implicit Representations of Deformable Objects",
    "abstract": "Deformable object manipulation requires computationally efficient\nrepresentations that are compatible with robotic sensing modalities. In this\npaper, we present VIRDO:an implicit, multi-modal, and continuous representation\nfor deformable-elastic objects. VIRDO operates directly on visual (point cloud)\nand tactile (reaction forces) modalities and learns rich latent embeddings of\ncontact locations and forces to predict object deformations subject to external\ncontacts.Here, we demonstrate VIRDOs ability to: i) produce high-fidelity\ncross-modal reconstructions with dense unsupervised correspondences, ii)\ngeneralize to unseen contact formations,and iii) state-estimation with partial\nvisio-tactile feedback",
    "descriptor": "\nComments: This work has been accepted to ICRA 2022\n",
    "authors": [
      "Youngsun Wi",
      "Pete Florence",
      "Andy Zeng",
      "Nima Fazeli"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.00868"
  },
  {
    "id": "arXiv:2202.00870",
    "title": "Service Scheduling for Random Requests with Quadratic Waiting Costs",
    "abstract": "We study service scheduling problems in a slotted system in which agents\narrive with service requests according to a Bernoulli process and have to leave\nwithin two slots after arrival, service costs are quadratic in service rates,\nand there are also waiting costs. We consider quadratic waiting costs. We frame\nthe problems as average cost Markov decision processes. While the studied\nsystem is a linear system with quadratic costs, it has state dependent control.\nMoreover, it also possesses a non-standard cost function structure in the case\nof fixed waiting costs, rendering the optimization problem complex. We\ncharacterize optimal policy. We provide an explicit expression showing that the\noptimal policy is linear in the system state. We also consider systems in which\nthe agents make scheduling decisions for their respective service requests\nkeeping their own cost in view. We consider quadratic waiting costs and frame\nthese scheduling problems as stochastic games. We provide Nash equilibria of\nthis game. To address the issue of unknown system parameters, we propose an\nalgorithm to estimate them. We also bound the cost difference of the actual\ncost incurred and the cost incurred using estimated parameters.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2110.05148\n",
    "authors": [
      "Ramya Burra",
      "Chandramani Singh",
      "Joy Kuri"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.00870"
  },
  {
    "id": "arXiv:2202.00874",
    "title": "HTS-AT: A Hierarchical Token-Semantic Audio Transformer for Sound  Classification and Detection",
    "abstract": "Audio classification is an important task of mapping audio samples into their\ncorresponding labels. Recently, the transformer model with self-attention\nmechanisms has been adopted in this field. However, existing audio transformers\nrequire large GPU memories and long training time, meanwhile relying on\npretrained vision models to achieve high performance, which limits the model's\nscalability in audio tasks. To combat these problems, we introduce HTS-AT: an\naudio transformer with a hierarchical structure to reduce the model size and\ntraining time. It is further combined with a token-semantic module to map final\noutputs into class featuremaps, thus enabling the model for the audio event\ndetection (i.e. localization in time). We evaluate HTS-AT on three datasets of\naudio classification where it achieves new state-of-the-art (SOTA) results on\nAudioSet and ESC-50, and equals the SOTA on Speech Command V2. It also achieves\nbetter performance in event localization than the previous CNN-based models.\nMoreover, HTS-AT requires only 35% model parameters and 15% training time of\nthe previous audio transformer. These results demonstrate the high performance\nand high efficiency of HTS-AT.",
    "descriptor": "\nComments: Preprint version for ICASSP 2022, Singapore\n",
    "authors": [
      "Ke Chen",
      "Xingjian Du",
      "Bilei Zhu",
      "Zejun Ma",
      "Taylor Berg-Kirkpatrick",
      "Shlomo Dubnov"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.00874"
  },
  {
    "id": "arXiv:2202.00878",
    "title": "A Longitudinal Dataset of Twitter ISIS Users",
    "abstract": "We present a large longitudinal dataset of tweets from two sets of users that\nare suspected to be affiliated with ISIS. These sets of users are identified\nbased on a prior study and a campaign aimed at shutting down ISIS Twitter\naccounts. These users have engaged with known ISIS accounts at least once\nduring 2014-2015 and are still active as of 2021. Some of them have directly\nsupported the ISIS users and their tweets by retweeting them, and some of the\nusers that have quoted tweets of ISIS, have uncertain connections to ISIS seed\naccounts. This study and the dataset represent a unique approach to analyzing\nISIS data. Although much research exists on ISIS online activities, few studies\nhave focused on individual accounts. Our approach to validating accounts as\nwell as developing a framework for differentiating accounts' functionality\n(e.g., propaganda versus operational planning) offers a foundation for future\nresearch. We perform some descriptive statistics and preliminary analyses on\nour collected data to provide deeper insight and highlight the significance and\npracticality of such analyses. We further discuss several cross-disciplinary\npotential use cases and research directions.",
    "descriptor": "\nComments: 10 pages, 7 figures; Submitted to the 16th International Conference on Web and Social Media (AAAI ICWSM-2022)\n",
    "authors": [
      "Younes Karimi",
      "Anna Squicciarini",
      "Peter K. Forster",
      "Kira M. Leavitt"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00878"
  },
  {
    "id": "arXiv:2202.00879",
    "title": "Automated Detection of Doxing on Twitter",
    "abstract": "Doxing refers to the practice of disclosing sensitive personal information\nabout a person without their consent. This form of cyberbullying is an\nunpleasant and sometimes dangerous phenomenon for online social networks.\nAlthough prior work exists on automated identification of other types of\ncyberbullying, a need exists for methods capable of detecting doxing on Twitter\nspecifically. We propose and evaluate a set of approaches for automatically\ndetecting second- and third-party disclosures on Twitter of sensitive private\ninformation, a subset of which constitutes doxing. We summarize our findings of\ncommon intentions behind doxing episodes and compare nine different approaches\nfor automated detection based on string-matching and one-hot encoded\nheuristics, as well as word and contextualized string embedding representations\nof tweets. We identify an approach providing 96.86% accuracy and 97.37% recall\nusing contextualized string embeddings and conclude by discussing the\npracticality of our proposed methods.",
    "descriptor": "\nComments: 24 pages, 1 figure. Accepted in the 25th ACM Conference on Computer-Supported Cooperative Work and Social Computing (ACM CSCW 2022)\n",
    "authors": [
      "Younes Karimi",
      "Anna Squicciarini",
      "Shomir Wilson"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.00879"
  },
  {
    "id": "arXiv:2202.00881",
    "title": "Robustness and Adaptability of Reinforcement Learning based Cooperative  Autonomous Driving in Mixed-autonomy Traffic",
    "abstract": "Building autonomous vehicles (AVs) is a complex problem, but enabling them to\noperate in the real world where they will be surrounded by human-driven\nvehicles (HVs) is extremely challenging. Prior works have shown the\npossibilities of creating inter-agent cooperation between a group of AVs that\nfollow a social utility. Such altruistic AVs can form alliances and affect the\nbehavior of HVs to achieve socially desirable outcomes. We identify two major\nchallenges in the co-existence of AVs and HVs. First, social preferences and\nindividual traits of a given human driver, e.g., selflessness and\naggressiveness are unknown to an AV, and it is almost impossible to infer them\nin real-time during a short AV-HV interaction. Second, contrary to AVs that are\nexpected to follow a policy, HVs do not necessarily follow a stationary policy\nand therefore are extremely hard to predict. To alleviate the above-mentioned\nchallenges, we formulate the mixed-autonomy problem as a multi-agent\nreinforcement learning (MARL) problem and propose a decentralized framework and\nreward function for training cooperative AVs. Our approach enables AVs to learn\nthe decision-making of HVs implicitly from experience, optimizes for a social\nutility while prioritizing safety and allowing adaptability; robustifying\naltruistic AVs to different human behaviors and constraining them to a safe\naction space. Finally, we investigate the robustness, safety and sensitivity of\nAVs to various HVs behavioral traits and present the settings in which the AVs\ncan learn cooperative policies that are adaptable to different situations.",
    "descriptor": "",
    "authors": [
      "Rodolfo Valiente",
      "Behrad Toghi",
      "Ramtin Pedarsani",
      "Yaser P. Fallah"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.00881"
  },
  {
    "id": "arXiv:2202.00884",
    "title": "Automotive Parts Assessment: Applying Real-time Instance-Segmentation  Models to Identify Vehicle Parts",
    "abstract": "The problem of automated car damage assessment presents a major challenge in\nthe auto repair and damage assessment industry. The domain has several\napplication areas ranging from car assessment companies such as car rentals and\nbody shops to accidental damage assessment for car insurance companies. In\nvehicle assessment, the damage can take any form including scratches, minor and\nmajor dents to missing parts. More often, the assessment area has a significant\nlevel of noise such as dirt, grease, oil or rush that makes an accurate\nidentification challenging. Moreover, the identification of a particular part\nis the first step in the repair industry to have an accurate labour and part\nassessment where the presence of different car models, shapes and sizes makes\nthe task even more challenging for a machine-learning model to perform well. To\naddress these challenges, this research explores and applies various instance\nsegmentation methodologies to evaluate the best performing models.\nThe scope of this work focusses on two genres of real-time instance\nsegmentation models due to their industrial significance, namely SipMask and\nYolact. These methodologies are evaluated against a previously reported car\nparts dataset (DSMLR) and an internally curated dataset extracted from local\ncar repair workshops. The Yolact-based part localization and segmentation\nmethod performed well when compared to other real-time instance mechanisms with\na mAP of 66.5. For the workshop repair dataset, SipMask++ reported better\naccuracies for object detection with a mAP of 57.0 with outcomes for\nAP_IoU=.50and AP_IoU=.75 reporting 72.0 and 67.0 respectively while Yolact was\nfound to be a better performer for AP_s with 44.0 and 2.6 for object detection\nand segmentation categories respectively.",
    "descriptor": "",
    "authors": [
      "Syed Adnan Yusuf",
      "Abdulmalik Ali Aldawsari",
      "Riad Souissi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.00884"
  },
  {
    "id": "arXiv:2202.00885",
    "title": "Opted Out, Yet Tracked: Are Regulations Enough to Protect Your Privacy?",
    "abstract": "Data protection regulations, such as GDPR and CCPA, require websites and\nembedded third-parties, especially advertisers, to seek user consent before\nthey can collect and process user data. Only when the users opt in, can these\nentities collect, process, and share user data. Websites typically incorporate\nConsent Management Platforms (CMPs), such as OneTrust and CookieBot, to solicit\nand convey user consent to the embedded advertisers, with the expectation that\nthe consent will be respected. However, neither the websites nor the regulators\ncurrently have any mechanism to audit advertisers' compliance with the user\nconsent, i.e., to determine if advertisers indeed do not collect, process, and\nshare user data when the user opts out.\nIn this paper, we propose an auditing framework that leverages advertisers'\nbidding behavior to empirically assess the violations of data protection\nregulations. Using our framework, we conduct a measurement study to evaluate\ntwo of the most widely deployed CMPs, i.e., OneTrust and CookieBot, as well as\nadvertiser-offered opt-out controls, i.e., National Advertising Initiative's\nopt-out, under GDPR and CCPA -- arguably two of the most mature data protection\nregulations. Our results indicate that user data is unfortunately still being\ncollected, processed, and shared even when users opt-out. Our findings suggest\nthat several prominent advertisers (e.g., AppNexus, PubMatic) might be in\npotential violation of GDPR and CCPA. Overall, our work casts a doubt if\nregulations are effective at protecting users' online privacy.",
    "descriptor": "",
    "authors": [
      "Zengrui Liu",
      "Umar Iqbal",
      "Nitesh Saxena"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.00885"
  },
  {
    "id": "arXiv:2202.00886",
    "title": "Accurate calibration of surround view camera systems from a  generalization of the hand eye constraint",
    "abstract": "Multi-perspective cameras are quickly gaining importance in many applications\nsuch as smart vehicles and virtual or augmented reality. However, a large\nsystem size or absence of overlap in neighbouring fields-of-view often\ncomplicate their calibration. We present a novel solution which relies on the\navailability of an external motion capture system. Our core contribution\nconsists of an extension to the hand-eye calibration problem which jointly\nsolves multi-eye-to-base problems in closed form. We furthermore demonstrate\nits equivalence to the multi-eye-in-hand problem. The practical validity of our\napproach is supported by our experiments, indicating that the method is highly\nefficient and accurate, and outperforms existing closed-form alternatives.",
    "descriptor": "\nComments: accepted in the 2022 IEEE International Conference on Robotics and Automation (ICRA), Philadelphia (PA), USA\n",
    "authors": [
      "Yifu Wang",
      "Wenqing Jiang",
      "Kun Huang",
      "Soren Schwertfeger",
      "Laurent Kneip"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00886"
  },
  {
    "id": "arXiv:2202.00889",
    "title": "Choice of technology and evaluation of the production capabilities of a  3d printer robot for creating elements of experimental equipment for the  production of biofuel components",
    "abstract": "Elements of experimental equipment for the production of biofuel components\nmust meet high reliability and safety requirements. At the same time, in the\ncourse of research on the subject of creating equipment for the production of\nbiofuels, a variable range of equipment is regularly proposed and should be\nchecked. The manufacture of elements of such equipment by traditional methods\nis expensive and inefficient, time-consuming, which negatively affects the\nspeed of scientific research. To this end, it is proposed to develop a robotic\n3D printing complex that provides maximum flexibility in creating mock-ups and\ntest samples of equipment for the production of biofuel components. The article\ndiscusses the experience of successfully creating equipment elements for the\nproduction of fuels using 3d printing. Next, the choice of a robotization\nscheme for a 3D printing installation is described and the choice of printing\ntechnology is substantiated. The article also presents the results of\ncalculating the parameters of the 3v-printer robot and the results of\ncalculating the similarity parameters for the implementation and evaluation of\ncontrol algorithms. The results of a numerical experiment for calculating the\nstrength characteristics of equipment elements manufactured using the selected\n3d printing technology are presented.",
    "descriptor": "\nComments: 14 pages, in Russian, 5 figures\n",
    "authors": [
      "K.A. Bashmur",
      "V.S. Tynchenko",
      "V.V. Bukhtoyarov",
      "M.V. Saramud"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.00889"
  },
  {
    "id": "arXiv:2202.00890",
    "title": "Robot-printer for creating elements of technological equipment for the  production of components of biofuel compositions",
    "abstract": "This study is devoted to the search for new scientific and technical\nsolutions in the field of renewable energy sources, in particular biofuels.\nBiomass is the main fuel for green energy, accounting for two thirds of the\nenergy produced from renewable sources. The further development of the industry\ndepends on the improvement of the equipment and technologies used in it. On the\nexample of a cleaning apparatus, a new technology for prototyping its parts\nusing a robotic module is shown and tested. The use of plastics as parts of\ntechnological equipment is a modern trend and may be due to the low adhesion\nstrength of various substances to the surface of these parts due to poor\nwettability and low values of the surface energy of these materials compared to\nmetals.",
    "descriptor": "\nComments: 10 pages, in Russian, 6 figures\n",
    "authors": [
      "K.A. Bashmur",
      "V.S. Tynchenko",
      "V.V. Bukhtoyarov",
      "M.V. Saramud"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.00890"
  },
  {
    "id": "arXiv:2202.00891",
    "title": "Extracting efficient exact real number computation from proofs in  constructive type theory",
    "abstract": "Exact real computation is an alternative to floating-point arithmetic where\noperations on real numbers are performed exactly, without the introduction of\nrounding errors. When proving the correctness of an implementation, one can\nfocus solely on the mathematical properties of the problem without thinking\nabout the subtleties of representing real numbers. We propose a new\naxiomatization of the real numbers in a dependent type theory with the goal of\nextracting certified exact real computation programs from constructive proofs.\nOur formalization differs from similar approaches, in that we formalize the\nreals in a conceptually similar way as some mature implementations of exact\nreal computation. Primitive operations on reals can be extracted directly to\nthe corresponding operations in such an implementation, producing more\nefficient programs. We particularly focus on the formalization of partial and\nnondeterministic computation, which is essential in exact real computation.\nWe prove the soundness of our formalization with regards of the standard\nrealizability interpretation from computable analysis and show how to relate\nour theory to a classical formalization of the reals. We demonstrate the\nfeasibility of our theory by implementing it in the Coq proof assistant and\npresent several natural examples. From the examples we have automatically\nextracted Haskell programs that use the exact real computation framework AERN\nfor efficiently performing exact operations on real numbers. In experiments,\nthe extracted programs behave similarly to native implementations in AERN in\nterms of running time and memory usage.",
    "descriptor": "",
    "authors": [
      "Michal Kone\u010dn\u00fd",
      "Sewon Park",
      "Holger Thies"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.00891"
  },
  {
    "id": "arXiv:2202.00892",
    "title": "Does Video Compression Impact Tracking Accuracy?",
    "abstract": "Everyone \"knows\" that compressing a video will degrade the accuracy of object\ntracking. Yet, a literature search on this topic reveals that there is very\nlittle documented evidence for this presumed fact. Part of the reason is that,\nuntil recently, there were no object tracking datasets for uncompressed video,\nwhich made studying the effects of compression on tracking accuracy difficult.\nIn this paper, using a recently published dataset that contains tracking\nannotations for uncompressed videos, we examined the degradation of tracking\naccuracy due to video compression using rigorous statistical methods.\nSpecifically, we examined the impact of quantization parameter (QP) and motion\nsearch range (MSR) on Multiple Object Tracking Accuracy (MOTA). The results\nshow that QP impacts MOTA at the 95% confidence level, while there is\ninsufficient evidence to claim that MSR impacts MOTA. Moreover, regression\nanalysis allows us to derive a quantitative relationship between MOTA and QP\nfor the specific tracker used in the experiments.",
    "descriptor": "\nComments: 5 pages, 6 figures, 3 tables, IEEE International Symposium on Circuits and Systems (ISCAS) 2022\n",
    "authors": [
      "Takehiro Tanaka",
      "Alon Harell",
      "Ivan V. Baji\u0107"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.00892"
  },
  {
    "id": "arXiv:2202.00893",
    "title": "Mold into a Graph: Efficient Bayesian Optimization over Mixed-Spaces",
    "abstract": "Real-world optimization problems are generally not just black-box problems,\nbut also involve mixed types of inputs in which discrete and continuous\nvariables coexist. Such mixed-space optimization possesses the primary\nchallenge of modeling complex interactions between the inputs. In this work, we\npropose a novel yet simple approach that entails exploiting the graph data\nstructure to model the underlying relationship between variables, i.e.,\nvariables as nodes and interactions defined by edges. Then, a variational graph\nautoencoder is used to naturally take the interactions into account. We first\nprovide empirical evidence of the existence of such graph structures and then\nsuggest a joint framework of graph structure learning and latent space\noptimization to adaptively search for optimal graph connectivity. Experimental\nresults demonstrate that our method shows remarkable performance, exceeding the\nexisting approaches with significant computational efficiency for a number of\nsynthetic and real-world tasks.",
    "descriptor": "\nComments: Under review by the International Conference on Machine Learning (ICML)\n",
    "authors": [
      "Jaeyeon Ahn",
      "Taehyeon Kim",
      "Seyoung Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00893"
  },
  {
    "id": "arXiv:2202.00894",
    "title": "Methodology for forecasting and optimization in IEEE-CIS 3rd Technical  Challenge",
    "abstract": "This report provides a description of the methodology I used in the IEEE-CIS\n3rd Technical Challenge.\nFor the forecast, I used a quantile regression forest approach using the\nsolar variables provided by the Bureau of Meterology of Australia (BOM) and\nmany of the weather variables from the European Centre for Medium-Range Weather\nForecasting (ECMWF).\nGroups of buildings and all of the solar instances were trained together as\nthey were observed to be closely correlated over time. Other variables used\nincluded Fourier values based on hour of day and day of year, and binary\nvariables for combinations of days of the week.\nThe start dates for the time series were carefully tuned based on phase 1 and\ncleaning and thresholding was used to reduce the observed error rate for each\ntime series.\nFor the optimization, a four-step approach was used using the forecast\ndeveloped. First, a mixed-integer program (MIP) was solved for the recurring\nand recurring plus once-off activities, then each of these was extended using a\nmixed-integer quadratic program (MIQP).\nThe general strategy was chosen from one of two (\"array\" from the \"array\" and\n\"tuples\" approaches) while the specific step improvement strategy was chosen\nfrom one of five (\"no forced discharge\").",
    "descriptor": "\nComments: 4 pages, 3 figures\n",
    "authors": [
      "Richard Bean"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00894"
  },
  {
    "id": "arXiv:2202.00898",
    "title": "Quantification and aggregation over concepts of the ontology",
    "abstract": "This paper focuses on quantifications whose nature, we believe, is generally\nundervalued within the Knowledge Representation community: they range over a\nset of concepts, i.e., of intensional objects identified in the ontology.\nHence, we extend first order logic to allow referring to the intension of a\nsymbol, i.e., to the concept it represents. Our formalism is more elaboration\ntolerant than simpler formalisms that require reification, but also introduces\nthe possibility of syntactically incorrect formula.We introduce a guarding\nmechanism to make formula syntactically correct, and present a method to verify\ncorrectness. The complexity of the method is linear with the length of the\nformula.\nWe also extend FO($\\cdot$) (aka FO-dot), a logic-based knowledge\nrepresentation language, in a similar way, and show how it helped solve\npractical problems.\nThe value of expressing intensional statements has been well-established in\nmodal logic. We show how our approach expands on the understanding of\nintensions as studied in modal settings by, e.g., Fitting, in a way that is of\nvalue in non-modal settings as well.",
    "descriptor": "\nComments: To be submitted to KR 2022\n",
    "authors": [
      "Pierre Carbonnelle",
      "Matthias Van der Hallen",
      "Marc Denecker"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00898"
  },
  {
    "id": "arXiv:2202.00899",
    "title": "Modal reduction principles across relational semantics",
    "abstract": "The present paper establishes systematic connections among the first-order\ncorrespondents of Sahlqvist modal reduction principles in various relational\nsemantic settings which include crisp and many-valued Kripke frames, and crisp\nand many-valued polarity-based frames (aka enriched formal contexts). Building\non unified correspondence theory, we aim at introducing a theoretical\nenvironment which makes it possible to: (a) compare and inter-relate the\nvarious frame correspondents (in different relational settings) of any given\nSahlqvist modal reduction principle; (b) recognize when first-order sentences\nin the frame-correspondence languages of different types of relational\nstructures encode the same \"modal content\"; (c) meaningfully transfer and\nrepresent well known relational properties such as reflexivity, transitivity,\nsymmetry, seriality, confluence, density, across different semantic contexts.\nThese results can be understood as a first step in a research program aimed at\nmaking correspondence theory not just (methodologically) unified, but also\n(effectively) parametric.",
    "descriptor": "",
    "authors": [
      "Willem Conradie",
      "Andrea De Domenico",
      "Krishna Manoorkar",
      "Alessandra Palmigiano",
      "Mattia Panettiere",
      "Daira Pinto Prieto",
      "Apostolos Tzimoulis"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.00899"
  },
  {
    "id": "arXiv:2202.00900",
    "title": "Augmenting Immersive Telepresence Experience with a Virtual Body",
    "abstract": "We propose augmenting immersive telepresence by adding a virtual body,\nrepresenting the user's own arm motions, as realized through a head-mounted\ndisplay and a 360-degree camera. Previous research has shown the effectiveness\nof having a virtual body in simulated environments; however, research on\nwhether seeing one's own virtual arms increases presence or preference for the\nuser in an immersive telepresence setup is limited. We conducted a study where\na host introduced a research lab while participants wore a head-mounted display\nwhich allowed them to be telepresent at the host's physical location via a\n360-degree camera, either with or without a virtual body. We first conducted a\npilot study of 20 participants, followed by a pre-registered 62 participant\nconfirmatory study. Whereas the pilot study showed greater presence and\npreference when the virtual body was present, the confirmatory study failed to\nreplicate these results, with only behavioral measures suggesting an increase\nin presence. After analyzing the qualitative data and modeling interactions, we\nsuspect that the quality and style of the virtual arms, and the contrast\nbetween animation and video, led to individual differences in reactions to the\nvirtual body which subsequently moderated feelings of presence.",
    "descriptor": "\nComments: Accepted for publication in Transactions in Visualization and Computer Graphics (TVCG), to be presented in IEEE VR 2022\n",
    "authors": [
      "Nikunj Arora",
      "Markku Suomalainen",
      "Matti Pouke",
      "Evan G. Center",
      "Katherine J. Mimnaugh",
      "Alexis P. Chambers",
      "Sakaria Pouke",
      "Steven M. LaValle"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Multimedia (cs.MM)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.00900"
  },
  {
    "id": "arXiv:2202.00901",
    "title": "Retrieve-and-Fill for Scenario-based Task-Oriented Semantic Parsing",
    "abstract": "Task-oriented semantic parsing models have achieved strong results in recent\nyears, but unfortunately do not strike an appealing balance between model size,\nruntime latency, and cross-domain generalizability. We tackle this problem by\nintroducing scenario-based semantic parsing: a variant of the original task\nwhich first requires disambiguating an utterance's \"scenario\" (an intent-slot\ntemplate with variable leaf spans) before generating its frame, complete with\nontology and utterance tokens. This formulation enables us to isolate\ncoarse-grained and fine-grained aspects of the task, each of which we solve\nwith off-the-shelf neural modules, also optimizing for the axes outlined above.\nConcretely, we create a Retrieve-and-Fill (RAF) architecture comprised of (1) a\nretrieval module which ranks the best scenario given an utterance and (2) a\nfilling module which imputes spans into the scenario to create the frame. Our\nmodel is modular, differentiable, interpretable, and allows us to garner extra\nsupervision from scenarios. RAF achieves strong results in high-resource,\nlow-resource, and multilingual settings, outperforming recent approaches by\nwide margins despite, using base pre-trained encoders, small sequence lengths,\nand parallel decoding.",
    "descriptor": "",
    "authors": [
      "Akshat Shrivastava",
      "Shrey Desai",
      "Anchit Gupta",
      "Ali Elkahky",
      "Aleksandr Livshits",
      "Alexander Zotov",
      "Ahmed Aly"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.00901"
  },
  {
    "id": "arXiv:2202.00907",
    "title": "Using Deep Learning to Bootstrap Abstractions for Hierarchical Robot  Planning",
    "abstract": "This paper addresses the problem of learning abstractions that boost robot\nplanning performance while providing strong guarantees of reliability. Although\nstate-of-the-art hierarchical robot planning algorithms allow robots to\nefficiently compute long-horizon motion plans for achieving user desired tasks,\nthese methods typically rely upon environment-dependent state and action\nabstractions that need to be hand-designed by experts.\nWe present a new approach for bootstrapping the entire hierarchical planning\nprocess. It shows how abstract states and actions for new environments can be\ncomputed automatically using the critical regions predicted by a deep\nneural-network with an auto-generated robot specific architecture. It uses the\nlearned abstractions in a novel multi-source bi-directional hierarchical robot\nplanning algorithm that is sound and probabilistically complete. An extensive\nempirical evaluation on twenty different settings using holonomic and\nnon-holonomic robots shows that (a) the learned abstractions provide the\ninformation necessary for efficient multi-source hierarchical planning; and\nthat (b) this approach of learning abstraction and planning outperforms\nstate-of-the-art baselines by nearly a factor of ten in terms of planning time\non test environments not seen during training.",
    "descriptor": "",
    "authors": [
      "Naman Shah",
      "Siddharth Srivastava"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00907"
  },
  {
    "id": "arXiv:2202.00908",
    "title": "Image Forgery Detection with Interpretability",
    "abstract": "In this work, we present a learning based method focusing on the\nconvolutional neural network (CNN) architecture to detect these forgeries. We\nconsider the detection of both copy-move forgeries and inpainting based\nforgeries. For these, we synthesize our own large dataset. In addition to\nclassification, the focus is also on interpretability of the forgery detection.\nAs the CNN classification yields the image-level label, it is important to\nunderstand if forged region has indeed contributed to the classification. For\nthis purpose, we demonstrate using the Grad-CAM heatmap, that in various\ncorrectly classified examples, that the forged region is indeed the region\ncontributing to the classification. Interestingly, this is also applicable for\nsmall forged regions, as is depicted in our results. Such an analysis can also\nhelp in establishing the reliability of the classification.",
    "descriptor": "",
    "authors": [
      "Ankit Katiyar",
      "Arnav Bhavsar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00908"
  },
  {
    "id": "arXiv:2202.00909",
    "title": "CSFlow: Learning Optical Flow via Cross Strip Correlation for Autonomous  Driving",
    "abstract": "Optical flow estimation is an essential task in self-driving systems, which\nhelps autonomous vehicles perceive temporal continuity information of\nsurrounding scenes. The calculation of all-pair correlation plays an important\nrole in many existing state-of-the-art optical flow estimation methods.\nHowever, the reliance on local knowledge often limits the model's accuracy\nunder complex street scenes. In this paper, we propose a new deep network\narchitecture for optical flow estimation in autonomous driving--CSFlow, which\nconsists of two novel modules: Cross Strip Correlation module (CSC) and\nCorrelation Regression Initialization module (CRI). CSC utilizes a striping\noperation across the target image and the attended image to encode global\ncontext into correlation volumes, while maintaining high efficiency. CRI is\nused to maximally exploit the global context for optical flow initialization.\nOur method has achieved state-of-the-art accuracy on the public autonomous\ndriving dataset KITTI-2015. Code is publicly available at\nhttps://github.com/MasterHow/CSFlow.",
    "descriptor": "\nComments: Code is publicly available at this https URL\n",
    "authors": [
      "Hao Shi",
      "Yifan Zhou",
      "Kailun Yang",
      "Xiaoting Yin",
      "Kaiwei Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.00909"
  },
  {
    "id": "arXiv:2202.00911",
    "title": "Active Multi-Task Representation Learning",
    "abstract": "To leverage the power of big data from source tasks and overcome the scarcity\nof the target task samples, representation learning based on multi-task\npretraining has become a standard approach in many applications. However, up\nuntil now, choosing which source tasks to include in the multi-task learning\nhas been more art than science. In this paper, we give the first formal study\non resource task sampling by leveraging the techniques from active learning. We\npropose an algorithm that iteratively estimates the relevance of each source\ntask to the target task and samples from each source task based on the\nestimated relevance. Theoretically, we show that for the linear representation\nclass, to achieve the same error rate, our algorithm can save up to a\n\\textit{number of source tasks} factor in the source task sample complexity,\ncompared with the naive uniform sampling from all source tasks. We also provide\nexperiments on real-world computer vision datasets to illustrate the\neffectiveness of our proposed method on both linear and convolutional neural\nnetwork representation classes. We believe our paper serves as an important\ninitial step to bring techniques from active learning to representation\nlearning.",
    "descriptor": "",
    "authors": [
      "Yifang Chen",
      "Simon S. Du",
      "Kevin Jamieson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00911"
  },
  {
    "id": "arXiv:2202.00912",
    "title": "Flipping the switch on local exploration: Genetic Algorithms with  Reversals",
    "abstract": "One important feature of complex systems are problem domains that have many\nlocal minima and substructure. Biological systems manage these local minima by\nswitching between different subsystems depending on their environmental or\ndevelopmental context. Genetic Algorithms (GA) can mimic this switching\nproperty as well as provide a means to overcome problem domain complexity.\nHowever, standard GA requires additional operators that will allow for\nlarge-scale exploration in a stochastic manner. Gradient-free heuristic search\ntechniques are suitable for providing an optimal solution in the discrete\ndomain to such single objective optimization tasks, particularly compared to\ngradient based methods which are noticeably slower. To do this, the authors\nturn to an optimization problem from the flight scheduling domain. The authors\ncompare the performance of such common gradient-free heuristic search\nalgorithms and propose variants of GAs which perform well over our problem and\nacross all benchmarks. The Iterated Chaining (IC) method is also introduced,\nbuilding upon traditional chaining techniques by triggering multiple local\nsearches instead of the singular action of a mutation operator. The authors\nwill show that the use of multiple local searches can improve performance on\nlocal stochastic searches, providing ample opportunity for application to a\nhost of other problem domains.",
    "descriptor": "\nComments: 26 pages, 3 Figures, 1 Table, Appendix I-IV\n",
    "authors": [
      "Ankit Grover",
      "Vaishali Yadav",
      "Bradly Alicea"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.00912"
  },
  {
    "id": "arXiv:2202.00914",
    "title": "Lipschitz-constrained Unsupervised Skill Discovery",
    "abstract": "We study the problem of unsupervised skill discovery, whose goal is to learn\na set of diverse and useful skills with no external reward. There have been a\nnumber of skill discovery methods based on maximizing the mutual information\n(MI) between skills and states. However, we point out that their MI objectives\nusually prefer static skills to dynamic ones, which may hinder the application\nfor downstream tasks. To address this issue, we propose Lipschitz-constrained\nSkill Discovery (LSD), which encourages the agent to discover more diverse,\ndynamic, and far-reaching skills. Another benefit of LSD is that its learned\nrepresentation function can be utilized for solving goal-following downstream\ntasks even in a zero-shot manner - i.e., without further training or complex\nplanning. Through experiments on various MuJoCo robotic locomotion and\nmanipulation environments, we demonstrate that LSD outperforms previous\napproaches in terms of skill diversity, state space coverage, and performance\non seven downstream tasks including the challenging task of following multiple\ngoals on Humanoid. Our code and videos are available at\nhttps://shpark.me/projects/lsd/.",
    "descriptor": "\nComments: Accepted to ICLR 2022\n",
    "authors": [
      "Seohong Park",
      "Jongwook Choi",
      "Jaekyeom Kim",
      "Honglak Lee",
      "Gunhee Kim"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.00914"
  },
  {
    "id": "arXiv:2202.00916",
    "title": "Decision-Focused Learning in Restless Multi-Armed Bandits with  Application to Maternal and Child Care Domain",
    "abstract": "This paper studies restless multi-armed bandit (RMAB) problems with unknown\narm transition dynamics but with known correlated arm features. The goal is to\nlearn a model to predict transition dynamics given features, where the Whittle\nindex policy solves the RMAB problems using predicted transitions. However,\nprior works often learn the model by maximizing the predictive accuracy instead\nof final RMAB solution quality, causing a mismatch between training and\nevaluation objectives. To address this shortcoming we propose a novel approach\nfor decision-focused learning in RMAB that directly trains the predictive model\nto maximize the Whittle index solution quality. We present three key\ncontributions: (i) we establish the differentiability of the Whittle index\npolicy to support decision-focused learning; (ii) we significantly improve the\nscalability of previous decision-focused learning approaches in sequential\nproblems; (iii) we apply our algorithm to the service call scheduling problem\non a real-world maternal and child health domain. Our algorithm is the first\nfor decision-focused learning in RMAB that scales to large-scale real-world\nproblems. \\end{abstract}",
    "descriptor": "",
    "authors": [
      "Kai Wang",
      "Shresth Verma",
      "Aditya Mate",
      "Sanket Shah",
      "Aparna Taneja",
      "Neha Madhiwalla",
      "Aparna Hegde",
      "Milind Tambe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00916"
  },
  {
    "id": "arXiv:2202.00919",
    "title": "Dynamic Time Slot Allocation Algorithm for Quadcopter Swarms",
    "abstract": "A swarm of quadcopters can perform cooperative tasks, such as monitoring of a\nlarge area, more efficiently than a single one. However, to be able to\nsuccessfully work together, the quadcopters must be aware of the position of\nthe other swarm members, especially to avoid collisions. A quadcopter can share\nits own position by transmitting it via radio waves and in order to allow\nmultiple quadcopters to communicate effectively, a decentralized channel access\nprotocol is essential. We propose a new dynamic channel access protocol, called\nDynamic time slot allocation (DTSA), where the quadcopters share the total\nchannel access time in a non-periodic and decentralized manner. Quadcopters\nwith higher communication demands occupy more time slots than less active ones.\nOur dynamic approach allows the agents to adapt to changing swarm situations\nand therefore to act efficiently, as compared to the state-of-the-art periodic\nchannel access protocol, time division multiple access (TDMA). Along with\nsimulations, we also do experiments using real Crazyflie quadcopters to show\nthe improved performance of DTSA as compared to TDMA.",
    "descriptor": "\nComments: Accepted in Robocom 2022 in conjunction with IEEE CCNC 2022\n",
    "authors": [
      "Sharif Azem",
      "Anam Tahir",
      "Heinz Koeppl"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.00919"
  },
  {
    "id": "arXiv:2202.00923",
    "title": "Semantics-Aware Active Fault Detection in Status Updating Systems",
    "abstract": "With its growing number of deployed devices and applications, the Internet of\nThings (IoT) raises significant challenges for network maintenance procedures.\nIn this work we address a problem of active fault detection in an IoT scenario,\nwhereby a monitor can probe a remote device in order to acquire fresh\ninformation and facilitate fault detection. However, probing could have a\nsignificant impact on the system's energy and communication resources. To this\nend, we utilize Age of Information as a measure of the freshness of information\nat the monitor and adopt a semantics-aware communication approach between the\nmonitor and the remote device. In semantics-aware communications, the processes\nof generating and transmitting information are treated jointly to consider the\nimportance of information and the purpose of communication. We formulate the\nproblem as a Partially Observable Markov Decision Process and show analytically\nthat the optimal policy is of a threshold type. Finally, we use a\ncomputationally efficient stochastic approximation algorithm to approximate the\noptimal policy and present numerical results that exhibit the advantage of our\napproach compared to a conventional delay-based probing policy.",
    "descriptor": "\nComments: Submitted for possible Journal publication\n",
    "authors": [
      "George Stamatakis",
      "Nikolaos Pappas",
      "Alexandros Fragkiadakis",
      "Apostolos Traganitis"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.00923"
  },
  {
    "id": "arXiv:2202.00932",
    "title": "Automatic Creation of Acceptance Tests by Extracting Conditionals from  Requirements: NLP Approach and Case Study",
    "abstract": "Acceptance testing is crucial to determine whether a system fulfills end-user\nrequirements. However, the creation of acceptance tests is a laborious task\nentailing two major challenges: (1) practitioners need to determine the right\nset of test cases that fully covers a requirement, and (2) they need to create\ntest cases manually due to insufficient tool support. Existing approaches for\nautomatically deriving test cases require semi-formal or even formal notations\nof requirements, though unrestricted natural language is prevalent in practice.\nIn this paper, we present our tool-supported approach CiRA (Conditionals in\nRequirements Artifacts) capable of creating the minimal set of required test\ncases from conditional statements in informal requirements. We demonstrate the\nfeasibility of CiRA in a case study with three industry partners. In our study,\nout of 578 manually created test cases, 71.8 % can be generated automatically.\nAdditionally, CiRA discovered 80 relevant test cases that were missed in manual\ntest case design. CiRA is publicly available at www.cira.bth.se/demo/.",
    "descriptor": "",
    "authors": [
      "Jannik Fischbach",
      "Julian Frattini",
      "Andreas Vogelsang",
      "Daniel Mendez",
      "Michael Unterkalmsteiner",
      "Andreas Wehrle",
      "Pablo Restrepo Henao",
      "Parisa Yousefi",
      "Tedi Juricic",
      "Jeannette Radduenz",
      "Carsten Wiecher"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.00932"
  },
  {
    "id": "arXiv:2202.00935",
    "title": "Non-Stationary Dueling Bandits",
    "abstract": "We study the non-stationary dueling bandits problem with $K$ arms, where the\ntime horizon $T$ consists of $M$ stationary segments, each of which is\nassociated with its own preference matrix. The learner repeatedly selects a\npair of arms and observes a binary preference between them as feedback. To\nminimize the accumulated regret, the learner needs to pick the Condorcet winner\nof each stationary segment as often as possible, despite preference matrices\nand segment lengths being unknown. We propose the $\\mathrm{Beat\\, the\\,\nWinner\\, Reset}$ algorithm and prove a bound on its expected binary weak regret\nin the stationary case, which tightens the bound of current state-of-art\nalgorithms. We also show a regret bound for the non-stationary case, without\nrequiring knowledge of $M$ or $T$. We further propose and analyze two\nmeta-algorithms, $\\mathrm{DETECT}$ for weak regret and $\\mathrm{Monitored\\,\nDueling\\, Bandits}$ for strong regret, both based on a detection-window\napproach that can incorporate any dueling bandit algorithm as a black-box\nalgorithm. Finally, we prove a worst-case lower bound for expected weak regret\nin the non-stationary case.",
    "descriptor": "",
    "authors": [
      "Patrick Kolpaczki",
      "Viktor Bengs",
      "Eyke H\u00fcllermeier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00935"
  },
  {
    "id": "arXiv:2202.00941",
    "title": "CTMSTOU driven markets: simulated environment for regime-awareness in  trading policie",
    "abstract": "Market regimes is a popular topic in quantitative finance even though there\nis little consensus on the details of how they should be defined. They arise as\na feature both in financial market prediction problems and financial market\ntask performing problems.\nIn this work we use discrete event time multi-agent market simulation to\nfreely experiment in a reproducible and understandable environment where\nregimes can be explicitly switched and enforced.\nWe introduce a novel stochastic process to model the fundamental value\nperceived by market participants: Continuous-Time Markov Switching Trending\nOrnstein-Uhlenbeck (CTMSTOU), which facilitates the study of trading policies\nin regime switching markets.\nWe define the notion of regime-awareness for a trading agent as well and\nillustrate its importance through the study of different order placement\nstrategies in the context of order execution problems.",
    "descriptor": "",
    "authors": [
      "Selim Amrouni",
      "Aymeric Moulin",
      "Tucker Balch"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)",
      "General Economics (econ.GN)",
      "Mathematical Finance (q-fin.MF)"
    ],
    "url": "https://arxiv.org/abs/2202.00941"
  },
  {
    "id": "arXiv:2202.00948",
    "title": "Eikonal Fields for Refractive Novel-View Synthesis",
    "abstract": "We tackle the problem of generating novel-view images from collections of 2D\nimages showing refractive and reflective objects. Current solutions assume\nopaque or transparent light transport along straight paths following the\nemission-absorption model. Instead, we optimize for a field of 3D-varying Index\nof Refraction (IoR) and trace light through it that bends toward the spatial\ngradients of said IoR according to the laws of eikonal light transport.",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Mojtaba Bemana",
      "Karol Myszkowski",
      "Jeppe Revall Frisvad",
      "Hans-Peter Seidel",
      "Tobias Ritschel"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00948"
  },
  {
    "id": "arXiv:2202.00954",
    "title": "Approximative Algorithms for Multi-Marginal Optimal Transport and  Free-Support Wasserstein Barycenters",
    "abstract": "Computationally solving multi-marginal optimal transport (MOT) with squared\nEuclidean costs for $N$ discrete probability measures has recently attracted\nconsiderable attention, in part because of the correspondence of its solutions\nwith Wasserstein-$2$ barycenters, which have many applications in data science.\nIn general, this problem is NP-hard, calling for practical approximative\nalgorithms. While entropic regularization has been successfully applied to\napproximate Wasserstein barycenters, this loses the sparsity of the optimal\nsolution, making it difficult to solve the MOT problem directly in practice\nbecause of the curse of dimensionality. Thus, for obtaining barycenters, one\nusually resorts to fixed-support restrictions to a grid, which is, however,\nprohibitive in higher ambient dimensions $d$. In this paper, after analyzing\nthe relationship between MOT and barycenters, we present two algorithms to\napproximate the solution of MOT directly, requiring mainly just $N-1$ standard\ntwo-marginal OT computations. Thus, they are fast, memory-efficient and easy to\nimplement and can be used with any sparse OT solver as a black box. Moreover,\nthey produce sparse solutions and show promising numerical results. We analyze\nthese algorithms theoretically, proving upper and lower bounds for the relative\napproximation error.",
    "descriptor": "",
    "authors": [
      "Johannes von Lindheim"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00954"
  },
  {
    "id": "arXiv:2202.00955",
    "title": "Asynchronous Decentralized Learning over Unreliable Wireless Networks",
    "abstract": "Decentralized learning enables edge users to collaboratively train models by\nexchanging information via device-to-device communication, yet prior works have\nbeen limited to wireless networks with fixed topologies and reliable workers.\nIn this work, we propose an asynchronous decentralized stochastic gradient\ndescent (DSGD) algorithm, which is robust to the inherent computation and\ncommunication failures occurring at the wireless network edge. We theoretically\nanalyze its performance and establish a non-asymptotic convergence guarantee.\nExperimental results corroborate our analysis, demonstrating the benefits of\nasynchronicity and outdated gradient information reuse in decentralized\nlearning over unreliable wireless networks.",
    "descriptor": "",
    "authors": [
      "Eunjeong Jeong",
      "Matteo Zecchin",
      "Marios Kountouris"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.00955"
  },
  {
    "id": "arXiv:2202.00956",
    "title": "Investigation of Alternative Measures for Mutual Information",
    "abstract": "Mutual information $I(X;Y)$ is a useful definition in information theory to\nestimate how much information the random variable $Y$ holds about the random\nvariable $X$. One way to define the mutual information is by comparing the\njoint distribution of $X$ and $Y$ with the product of the marginals through the\nKL-divergence. If the two distributions are close to each other there will be\nalmost no leakage of $X$ from $Y$ since the two variables are close to being\nindependent. In the discrete setting the mutual information has the nice\ninterpretation of how many bits $Y$ reveals about $X$ and if $I(X;Y)=H(X)$ (the\nShannon entropy of $X$) then $X$ is completely revealed. However, in the\ncontinuous case we do not have the same reasoning. For instance the mutual\ninformation can be infinite in the continuous case. This fact enables us to try\ndifferent metrics or divergences to define the mutual information. In this\npaper, we are evaluating different metrics or divergences such as\nKullback-Liebler (KL) divergence, Wasserstein distance, Jensen-Shannon\ndivergence and total variation distance to form alternatives to the mutual\ninformation in the continuous case. We deploy different methods to estimate or\nbound these metrics and divergences and evaluate their performances.",
    "descriptor": "",
    "authors": [
      "Bulut Kuskonmaz",
      "Jaron Skovsted Gundersen",
      "Rafal Wisniewski"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.00956"
  },
  {
    "id": "arXiv:2202.00961",
    "title": "Modularity-Aware Graph Autoencoders for Joint Community Detection and  Link Prediction",
    "abstract": "Graph autoencoders (GAE) and variational graph autoencoders (VGAE) emerged as\npowerful methods for link prediction. Their performances are less impressive on\ncommunity detection problems where, according to recent and concurring\nexperimental evaluations, they are often outperformed by simpler alternatives\nsuch as the Louvain method. It is currently still unclear to which extent one\ncan improve community detection with GAE and VGAE, especially in the absence of\nnode features. It is moreover uncertain whether one could do so while\nsimultaneously preserving good performances on link prediction. In this paper,\nwe show that jointly addressing these two tasks with high accuracy is possible.\nFor this purpose, we introduce and theoretically study a community-preserving\nmessage passing scheme, doping our GAE and VGAE encoders by considering both\nthe initial graph structure and modularity-based prior communities when\ncomputing embedding spaces. We also propose novel training and optimization\nstrategies, including the introduction of a modularity-inspired regularizer\ncomplementing the existing reconstruction losses for joint link prediction and\ncommunity detection. We demonstrate the empirical effectiveness of our\napproach, referred to as Modularity-Aware GAE and VGAE, through in-depth\nexperimental validation on various real-world graphs.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Guillaume Salha-Galvan",
      "Johannes F. Lutzeyer",
      "George Dasoulas",
      "Romain Hennequin",
      "Michalis Vazirgiannis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00961"
  },
  {
    "id": "arXiv:2202.00964",
    "title": "Understanding Knowledge Integration in Language Models with Graph  Convolutions",
    "abstract": "Pretrained language models (LMs) do not capture factual knowledge very well.\nThis has led to the development of a number of knowledge integration (KI)\nmethods which aim to incorporate external knowledge into pretrained LMs. Even\nthough KI methods show some performance gains over vanilla LMs, the\ninner-workings of these methods are not well-understood. For instance, it is\nunclear how and what kind of knowledge is effectively integrated into these\nmodels and if such integration may lead to catastrophic forgetting of already\nlearned knowledge. This paper revisits the KI process in these models with an\ninformation-theoretic view and shows that KI can be interpreted using a graph\nconvolution operation. We propose a probe model called \\textit{Graph\nConvolution Simulator} (GCS) for interpreting knowledge-enhanced LMs and\nexposing what kind of knowledge is integrated into these models. We conduct\nexperiments to verify that our GCS can indeed be used to correctly interpret\nthe KI process, and we use it to analyze two well-known knowledge-enhanced LMs:\nERNIE and K-Adapter, and find that only a small amount of factual knowledge is\nintegrated in them. We stratify knowledge in terms of various relation types\nand find that ERNIE and K-Adapter integrate different kinds of knowledge to\ndifferent extent. Our analysis also shows that simply increasing the size of\nthe KI corpus may not lead to better KI; fundamental advances may be needed.",
    "descriptor": "",
    "authors": [
      "Yifan Hou",
      "Guoji Fu",
      "Mrinmaya Sachan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00964"
  },
  {
    "id": "arXiv:2202.00965",
    "title": "GANSlider: How Users Control Generative Models for Images using Multiple  Sliders with and without Feedforward Information",
    "abstract": "We investigate how multiple sliders with and without feedforward\nvisualizations influence users' control of generative models. In an online\nstudy (N=138), we collected a dataset of people interacting with a generative\nadversarial network (StyleGAN2) in an image reconstruction task. We found that\nmore control dimensions (sliders) significantly increase task difficulty and\nuser actions. Visual feedforward partly mitigates this by enabling more\ngoal-directed interaction. However, we found no evidence of faster or more\naccurate task performance. This indicates a tradeoff between feedforward detail\nand implied cognitive costs, such as attention. Moreover, we found that\nvisualizations alone are not always sufficient for users to understand\nindividual control dimensions. Our study quantifies fundamental UI design\nfactors and resulting interaction behavior in this context, revealing\nopportunities for improvement in the UI design for interactive applications of\ngenerative models. We close by discussing design directions and further\naspects.",
    "descriptor": "\nComments: 15 pages, 10 figures, ACM CHI 2022\n",
    "authors": [
      "Hai Dang",
      "Lukas Mecke",
      "Daniel Buschek"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2202.00965"
  },
  {
    "id": "arXiv:2202.00973",
    "title": "Performance Analysis and Optimization for Jammer-Aided Multi-Antenna UAV  Covert Communication",
    "abstract": "Unmanned aerial vehicles (UAVs) have attracted a lot of research attention\nbecause of their high mobility and low cost in serving as temporary aerial base\nstations (BSs) and providing high data rates for next-generation communication\nnetworks. To protect user privacy while avoiding detection by a warden, we\ninvestigate a jammer-aided UAV covert communication system, which aims to\nmaximize the user's covert rate with optimized transmit and jamming power. The\nUAV is equipped with multi-antennas to serve multi-users simultaneously and\nenhance the Quality of Service. By considering the general composite fading and\nshadowing channel models, we derive the exact probability density (PDF) and\ncumulative distribution functions (CDF) of the signal-to-interference-plusnoise\nratio (SINR). The obtained PDF and CDF are used to derive the closed-form\nexpressions for detection error probability and covert rate. Furthermore, the\ncovert rate maximization problem is formulated as a Nash bargaining game, and\nthe Nash bargaining solution (NBS) is introduced to investigate the negotiation\namong users. To solve the NBS, we propose two algorithms, i.e., particle swarm\noptimization-based and joint twostage power allocation algorithms, to achieve\ncovertness and high data rates under the warden's optimal detection threshold.\nAll formulated problems are proven to be convex, and the complexity is\nanalyzed. The numerical results are presented to verify the theoretical\nperformance analysis and show the effectiveness and success of achieving the\ncovert communication of our algorithms.",
    "descriptor": "",
    "authors": [
      "Hongyang Du",
      "Dusit Niyato",
      "Yuan-ai Xie",
      "Yanyu Cheng",
      "Jiawen Kang",
      "Dong In Kim"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2202.00973"
  },
  {
    "id": "arXiv:2202.00979",
    "title": "A Versatile Dataset of Agile Open Source Software Projects",
    "abstract": "Agile software development is nowadays a widely adopted practise in both\nopen-source and industrial software projects. Agile teams typically heavily\nrely on issue management tools to document new issues and keep track of\noutstanding ones, in addition to storing their technical details, effort\nestimates, assignment to developers, and more. Previous work utilised the\nhistorical information stored in issue management systems for various purposes;\nhowever, when researchers make their empirical data public, it is usually\nrelevant solely to the study's objective. In this paper, we present a more\nholistic and versatile dataset containing a wealth of information on more than\n500,000 issues from 44 open-source Agile software, making it well-suited to\nseveral research avenues, and cross-analyses therein, including effort\nestimation, issue prioritization, issue assignment and many more. We make this\ndata publicly available on GitHub to facilitate ease of use, maintenance, and\nextensibility.",
    "descriptor": "\nComments: 5 pages, 1 figure\n",
    "authors": [
      "Vali Tawosi",
      "Afnan Al-Subaihin",
      "Rebecca Moussa",
      "Federica Sarro"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.00979"
  },
  {
    "id": "arXiv:2202.00980",
    "title": "Robust Training of Neural Networks using Scale Invariant Architectures",
    "abstract": "In contrast to SGD, adaptive gradient methods like Adam allow robust training\nof modern deep networks, especially large language models. However, the use of\nadaptivity not only comes at the cost of extra memory but also raises the\nfundamental question: can non-adaptive methods like SGD enjoy similar benefits?\nIn this paper, we provide an affirmative answer to this question by proposing\nto achieve both robust and memory-efficient training via the following general\nrecipe: (1) modify the architecture and make it scale invariant, i.e. the scale\nof parameter doesn't affect the output of the network, (2) train with SGD and\nweight decay, and optionally (3) clip the global gradient norm proportional to\nweight norm multiplied by $\\sqrt{\\tfrac{2\\lambda}{\\eta}}$, where $\\eta$ is\nlearning rate and $\\lambda$ is weight decay. We show that this general approach\nis robust to rescaling of parameter and loss by proving that its convergence\nonly depends logarithmically on the scale of initialization and loss, whereas\nthe standard SGD might not even converge for many initializations. Following\nour recipe, we design a scale invariant version of BERT, called SIBERT, which\nwhen trained simply by vanilla SGD achieves performance comparable to BERT\ntrained by adaptive methods like Adam on downstream tasks.",
    "descriptor": "\nComments: 36 pages, 7 figures\n",
    "authors": [
      "Zhiyuan Li",
      "Srinadh Bhojanapalli",
      "Manzil Zaheer",
      "Sashank J. Reddi",
      "Sanjiv Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00980"
  },
  {
    "id": "arXiv:2202.00989",
    "title": "Coding for Sensing: An Improved Scheme for Integrated Sensing and  Communication over MACs",
    "abstract": "A memoryless state-dependent multiple-access channel (MAC) is considered,\nwhere two transmitters wish to convey their messages to a single receiver while\nsimultaneously sensing (estimating) the respective states via generalized\nfeedbacks. For this channel, an improved inner bound is provided on the\n\\emph{fundamental rate-distortions tradeoff} which characterizes the\ncommunication rates the transmitters can achieve while simultaneously ensuring\nthat their state-estimates satisfy desired distortion criteria. The new inner\nbound is based on a scheme where each transmitter codes over the generalized\nfeedback so as to improve the state estimation at the other transmitter. This\nis in contrast to the schemes proposed for point-to-point and broadcast\nchannels where coding is used only for the transmission of messages and the\noptimal estimators operate on a symbol-by-symbol basis on the sequences of\nchannel inputs and feedback outputs.",
    "descriptor": "",
    "authors": [
      "Mehrasa Ahmadipour",
      "Michele Wigger",
      "Mari Kobayashi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.00989"
  },
  {
    "id": "arXiv:2202.00993",
    "title": "Normalise for Fairness: A Simple Normalisation Technique for Fairness in  Regression Machine Learning Problems",
    "abstract": "Algorithms and Machine Learning (ML) are increasingly affecting everyday life\nand several decision-making processes, where ML has an advantage due to\nscalability or superior performance. Fairness in such applications is crucial,\nwhere models should not discriminate their results based on race, gender, or\nother protected groups. This is especially crucial for models affecting very\nsensitive topics, like interview hiring or recidivism prediction. Fairness is\nnot commonly studied for regression problems compared to binary classification\nproblems; hence, we present a simple, yet effective method based on\nnormalisation (FaiReg), which minimises the impact of unfairness in regression\nproblems, especially due to labelling bias. We present a theoretical analysis\nof the method, in addition to an empirical comparison against two standard\nmethods for fairness, namely data balancing and adversarial training. We also\ninclude a hybrid formulation (FaiRegH), merging the presented method with data\nbalancing, in an attempt to face labelling and sample biases simultaneously.\nThe experiments are conducted on the multimodal dataset First Impressions (FI)\nwith various labels, namely personality prediction and interview screening\nscore. The results show the superior performance of diminishing the effects of\nunfairness better than data balancing, also without deteriorating the\nperformance of the original problem as much as adversarial training.",
    "descriptor": "\nComments: 12 pages (including references and appendix), 2 Figures, 5 Tables. Preprint for submission at ICML 2022\n",
    "authors": [
      "Mostafa M. Mohamed",
      "Bj\u00f6rn W. Schuller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.00993"
  },
  {
    "id": "arXiv:2202.00998",
    "title": "3PC: Three Point Compressors for Communication-Efficient Distributed  Training and a Better Theory for Lazy Aggregation",
    "abstract": "We propose and study a new class of gradient communication mechanisms for\ncommunication-efficient training -- three point compressors (3PC) -- as well as\nefficient distributed nonconvex optimization algorithms that can take advantage\nof them. Unlike most established approaches, which rely on a static compressor\nchoice (e.g., Top-$K$), our class allows the compressors to {\\em evolve}\nthroughout the training process, with the aim of improving the theoretical\ncommunication complexity and practical efficiency of the underlying methods. We\nshow that our general approach can recover the recently proposed\nstate-of-the-art error feedback mechanism EF21 (Richt\\'arik et al., 2021) and\nits theoretical properties as a special case, but also leads to a number of new\nefficient methods. Notably, our approach allows us to improve upon the state of\nthe art in the algorithmic and theoretical foundations of the {\\em lazy\naggregation} literature (Chen et al., 2018). As a by-product that may be of\nindependent interest, we provide a new and fundamental link between the lazy\naggregation and error feedback literature. A special feature of our work is\nthat we do not require the compressors to be unbiased.",
    "descriptor": "\nComments: 52 pages\n",
    "authors": [
      "Peter Richt\u00e1rik",
      "Igor Sokolov",
      "Ilyas Fatkhullin",
      "Elnur Gasanov",
      "Zhize Li",
      "Eduard Gorbunov"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.00998"
  },
  {
    "id": "arXiv:2202.01000",
    "title": "Data Processing Framework for Ship Performance Analysis",
    "abstract": "The hydrodynamic performance of a sea-going ship can be analysed using the\ndata obtained from the ship. Such data can be gathered from different sources,\nlike onboard recorded in-service data, AIS data, and noon reports. Each of\nthese sources is known to have their inherent problems. The current work gives\na brief introduction to these data sources as well as the common problems\nassociated with them, along with some examples. In order to resolve most of\nthese problems, a streamlined semi-automatic data processing framework for fast\ndata processing is developed and presented here. The data processing framework\ncan be used to process the data obtained from any of the above three mentioned\nsources. The framework incorporates processing steps like interpolating weather\nhindcast (metocean) data to ship's location in time, deriving additional\nfeatures, validating data, estimating resistance components, data cleaning, and\noutlier detection. A brief description of each of the processing steps is\nprovided with examples from existing datasets. The processed data can be\nfurther used to analyse the hydrodynamic performance of a ship.",
    "descriptor": "",
    "authors": [
      "Prateek Gupta",
      "Young-Rong Kim",
      "Sverre Steen",
      "Adil Rasheed"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.01000"
  },
  {
    "id": "arXiv:2202.01003",
    "title": "Thermal and Visual Tracking of Photovoltaic Plants for Autonomous UAV  inspection",
    "abstract": "Since the demand for renewable solar energy is continuously growing, the need\nfor more frequent, precise, and quick autonomous aerial inspections using\nUnmanned Aerial Vehicles (UAV) may become fundamental to reduce costs. However,\nUAV-based inspection of Photovoltaic (PV) arrays is still an open problem.\nCompanies in the field complain that GPS-based navigation is not adequate to\naccurately cover PV arrays to acquire images to be analyzed to determine the PV\npanels' status. Indeed, when instructing UAVs to move along a sequency of\nwaypoints at a low altitude, two sources of errors may deteriorate\nperformances: (i) the difference between the actual UAV position and the one\nestimated with the GPS, and (ii) the difference between the UAV position\nreturned by the GPS and the position of waypoints extracted from georeferenced\nimages acquired through Google Earth or similar tools. These errors make it\nimpossible to reliably track rows of PV modules without human intervention\nreliably.\nThe article proposes an approach for inspecting PV arrays with autonomous\nUAVs equipped with an RGB and a thermal camera, the latter being typically used\nto detect heat failures on the panels' surface: we introduce a portfolio of\ntechniques to process data from both cameras for autonomous navigation. %,\nincluding an optimization procedure for improving panel detection and an\nExtended Kalman Filter (EKF) to filter data from RGB and thermal cameras.\nExperimental tests performed in simulation and an actual PV plant are\nreported, confirming the validity of the approach.",
    "descriptor": "\nComments: 14 pages, 30 figures\n",
    "authors": [
      "Luca Morando",
      "Carmine Tommaso Recchiuto",
      "Jacopo Calla",
      "Paolo Scuteri",
      "Antonio Sgorbissa"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.01003"
  },
  {
    "id": "arXiv:2202.01008",
    "title": "Precoding and Decoding Schemes for Downlink MIMO-RSMA with Simultaneous  Diagonalization and User Exclusion",
    "abstract": "In this paper, we consider the precoder design for downlink multiple-input\nmultiple-output (MIMO) rate-splitting multiple access (RSMA) systems. The\nproposed scheme with simultaneous diagonalization (SD) decomposes the MIMO\nchannel matrices of the users into scalar channels via higher-order generalized\nsingular value decomposition for the common message (CM) and block\ndiagonalization (BD) for the private messages, thereby enabling low-complexity\nelement-by-element successive interference cancellation (SIC) and decoding at\nthe receivers. Furthermore, the proposed SD MIMO-RSMA overcomes a critical\nlimitation in RSMA systems, whereby the achievable rate of the CM is restricted\nby the users with weak effective MIMO channel for the CM, by excluding a subset\nof users from decoding the CM. We formulate a non-convex weighted sum rate\n(WSR) optimization problem for SD MIMO-RSMA and solve it via successive convex\napproximation to obtain a locally optimal solution. Our simulation results\nreveal that, for both perfect and imperfect CSI, the proposed SD MIMO-RSMA with\nuser exclusion outperforms baseline MIMO-RSMA schemes and linear BD precoding.",
    "descriptor": "\nComments: 6pp, 2 figures, submitted to the Workshop on Rate-Splitting Multiple Access for 6G at the IEEE Intl. Commun. Conf. (ICC) 2022\n",
    "authors": [
      "Rouaa Diab",
      "Aravindh Krishnamoorthy",
      "Robert Schober"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.01008"
  },
  {
    "id": "arXiv:2202.01011",
    "title": "Auto-Transfer: Learning to Route Transferrable Representations",
    "abstract": "Knowledge transfer between heterogeneous source and target networks and tasks\nhas received a lot of attention in recent times as large amounts of quality\nlabelled data can be difficult to obtain in many applications. Existing\napproaches typically constrain the target deep neural network (DNN) feature\nrepresentations to be close to the source DNNs feature representations, which\ncan be limiting. We, in this paper, propose a novel adversarial multi-armed\nbandit approach which automatically learns to route source representations to\nappropriate target representations following which they are combined in\nmeaningful ways to produce accurate target models. We see upwards of 5%\naccuracy improvements compared with the state-of-the-art knowledge transfer\nmethods on four benchmark (target) image datasets CUB200, Stanford Dogs, MIT67,\nand Stanford40 where the source dataset is ImageNet. We qualitatively analyze\nthe goodness of our transfer scheme by showing individual examples of the\nimportant features our target network focuses on in different layers compared\nwith the (closest) competitors. We also observe that our improvement over other\nmethods is higher for smaller target datasets making it an effective tool for\nsmall data applications that may benefit from transfer learning.",
    "descriptor": "\nComments: Accepted for publication in ICLR 2022, this https URL\n",
    "authors": [
      "Keerthiram Murugesan",
      "Vijay Sadashivaiah",
      "Ronny Luss",
      "Karthikeyan Shanmugam",
      "Pin-Yu Chen",
      "Amit Dhurandhar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01011"
  },
  {
    "id": "arXiv:2202.01013",
    "title": "Fairness of Machine Learning Algorithms in Demography",
    "abstract": "The paper is devoted to the study of the model fairness and process fairness\nof the Russian demographic dataset by making predictions of divorce of the 1st\nmarriage, religiosity, 1st employment and completion of education. Our goal was\nto make classifiers more equitable by reducing their reliance on sensitive\nfeatures while increasing or at least maintaining their accuracy. We took\ninspiration from \"dropout\" techniques in neural-based approaches and suggested\na model that uses \"feature drop-out\" to address process fairness. To evaluate a\nclassifier's fairness and decide the sensitive features to eliminate, we used\n\"LIME Explanations\". This results in a pool of classifiers due to feature\ndropout whose ensemble has been shown to be less reliant on sensitive features\nand to have improved or no effect on accuracy. Our empirical study was\nperformed on four families of classifiers (Logistic Regression, Random Forest,\nBagging, and Adaboost) and carried out on real-life dataset (Russian\ndemographic data derived from Generations and Gender Survey), and it showed\nthat all of the models became less dependent on sensitive features (such as\ngender, breakup of the 1st partnership, 1st partnership, etc.) and showed\nimprovements or no impact on accuracy",
    "descriptor": "\nComments: This is an empirical replication study but with other demographic data. The theory and method description is heavily based on the arXiv:2006.10531\n",
    "authors": [
      "Ibe Chukwuemeka Emmanuel",
      "Ekaterina Mitrofanova"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.01013"
  },
  {
    "id": "arXiv:2202.01017",
    "title": "Multi-Task Learning as a Bargaining Game",
    "abstract": "In Multi-task learning (MTL), a joint model is trained to simultaneously make\npredictions for several tasks. Joint training reduces computation costs and\nimproves data efficiency; however, since the gradients of these different tasks\nmay conflict, training a joint model for MTL often yields lower performance\nthan its corresponding single-task counterparts. A common method for\nalleviating this issue is to combine per-task gradients into a joint update\ndirection using a particular heuristic. In this paper, we propose viewing the\ngradients combination step as a bargaining game, where tasks negotiate to reach\nan agreement on a joint direction of parameter update. Under certain\nassumptions, the bargaining problem has a unique solution, known as the Nash\nBargaining Solution, which we propose to use as a principled approach to\nmulti-task learning. We describe a new MTL optimization procedure, Nash-MTL,\nand derive theoretical guarantees for its convergence. Empirically, we show\nthat Nash-MTL achieves state-of-the-art results on multiple MTL benchmarks in\nvarious domains.",
    "descriptor": "",
    "authors": [
      "Aviv Navon",
      "Aviv Shamsian",
      "Idan Achituve",
      "Haggai Maron",
      "Kenji Kawaguchi",
      "Gal Chechik",
      "Ethan Fetaya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.01017"
  },
  {
    "id": "arXiv:2202.01021",
    "title": "Grammars for Free: Toward Grammar Inference for Ad Hoc Parsers",
    "abstract": "Ad hoc parsers are everywhere: they appear any time a string is split, looped\nover, interpreted, transformed, or otherwise processed. Every ad hoc parser\ngives rise to a language: the possibly infinite set of input strings that the\nprogram accepts without going wrong. Any language can be described by a formal\ngrammar: a finite set of rules that can generate all strings of that language.\nBut programmers do not write grammars for ad hoc parsers -- even though they\nwould be eminently useful. Grammars can serve as documentation, aid program\ncomprehension, generate test inputs, and allow reasoning about\nlanguage-theoretic security. We propose an automatic grammar inference system\nfor ad hoc parsers that would enable all of these use cases, in addition to\nopening up new possibilities in mining software repositories and bi-directional\nparser synthesis.",
    "descriptor": "",
    "authors": [
      "Michael Schr\u00f6der",
      "J\u00fcrgen Cito"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.01021"
  },
  {
    "id": "arXiv:2202.01030",
    "title": "Too much information: CDCL solvers need to forget and perform restarts",
    "abstract": "Conflict-driven clause learning (CDCL) is a remarkably successful paradigm\nfor solving the satisfiability problem of propositional logic. Instead of a\nsimple depth-first backtracking approach, this kind of solver learns the reason\nbehind occurring conflicts in the form of additional clauses. However, despite\nthe enormous success of CDCL solvers, there is still only a shallow\nunderstanding of what influences the performance of these solvers in what way.\nThis paper will demonstrate, quite surprisingly, that clause learning\n(without being able to get rid of some clauses) can not only improve the\nruntime but can oftentimes deteriorate it dramatically. By conducting extensive\nempirical analysis, we find that the runtime distributions of CDCL solvers are\nmultimodal. This multimodality can be seen as a reason for the deterioration\nphenomenon described above. Simultaneously, it also gives an indication of why\nclause learning in combination with clause deletion and restarts is virtually\nthe de facto standard of SAT solving in spite of this phenomenon. As a final\ncontribution, we will show that Weibull mixture distributions can accurately\ndescribe the multimodal distributions. Thus, adding new clauses to a base\ninstance has an inherent effect of making runtimes long-tailed. This insight\nprovides a theoretical explanation as to why the techniques of restarts and\nclause deletion are useful in CDCL solvers.",
    "descriptor": "",
    "authors": [
      "Tom Kr\u00fcger",
      "Jan-Hendrik Lorenz",
      "Florian W\u00f6rz"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01030"
  },
  {
    "id": "arXiv:2202.01031",
    "title": "MMSys'22 Grand Challenge on AI-based Video Production for Soccer",
    "abstract": "Soccer has a considerable market share of the global sports industry, and the\ninterest in viewing videos from soccer games continues to grow. In this\nrespect, it is important to provide game summaries and highlights of the main\ngame events. However, annotating and producing events and summaries often\nrequire expensive equipment and a lot of tedious, cumbersome, manual labor.\nTherefore, automating the video production pipeline providing fast game\nhighlights at a much lower cost is seen as the \"holy grail\". In this context,\nrecent developments in Artificial Intelligence (AI) technology have shown great\npotential. Still, state-of-the-art approaches are far from being adequate for\npractical scenarios that have demanding real-time requirements, as well as\nstrict performance criteria (where at least the detection of official events\nsuch as goals and cards must be 100% accurate). In addition, event detection\nshould be thoroughly enhanced by annotation and classification, proper\nclipping, generating short descriptions, selecting appropriate thumbnails for\nhighlight clips, and finally, combining the event highlights into an overall\ngame summary, similar to what is commonly aired during sports news. Even though\nthe event tagging operation has by far received the most attention, an\nend-to-end video production pipeline also includes various other operations\nwhich serve the overall purpose of automated soccer analysis. This challenge\naims to assist the automation of such a production pipeline using AI. In\nparticular, we focus on the enhancement operations that take place after an\nevent has been detected, namely event clipping (Task 1), thumbnail selection\n(Task 2), and game summarization (Task 3). Challenge website:\nhttps://mmsys2022.ie/authors/grand-challenge.",
    "descriptor": "",
    "authors": [
      "Cise Midoglu",
      "Steven A. Hicks",
      "Vajira Thambawita",
      "Tomas Kupka",
      "P\u00e5l Halvorsen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2202.01031"
  },
  {
    "id": "arXiv:2202.01032",
    "title": "Understanding O-RAN: Architecture, Interfaces, Algorithms, Security, and  Research Challenges",
    "abstract": "Open Radio Access Network (RAN) and its embodiment through the O-RAN Alliance\nspecifications have the potential to truly transform the telecom ecosystem.\nO-RAN promotes virtualized and disaggregated RANs, where disaggregated\ncomponents are connected via open interfaces and optimized by intelligent\ncontrollers. The result is a new paradigm for the RAN design, deployment, and\noperations: O-RAN networks can be built with multi-vendor, interoperable\ncomponents, and can be programmatically optimized through a centralized\nabstraction layer and data-driven closed-loop control. Therefore, understanding\nO-RAN, its architecture, its interfaces, and workflows is key for researchers\nand practitioners in the wireless community. In this article, we present the\nfirst detailed tutorial on O-RAN. We also discuss the main research challenges\nand review early results. We provide a deep dive on the O-RAN specifications,\ndescribing its architecture, design principles, and the O-RAN interfaces. We\nthen describe how the O-RAN RAN Intelligent Controllers (RICs) can be used to\neffectively control and manage 3GPP-defined RANs. Based on this, we discuss\ninnovations and challenges that relate to O-RAN networks, including the\nArtificial Intelligence (AI) and Machine Learning (ML) workflows that the\narchitecture and interfaces enable, and security and standardization issues.\nFinally, we review experimental research platforms that can be used to design\nand test O-RAN networks, along with recent research results, and we outline\nfuture directions for O-RAN development.",
    "descriptor": "\nComments: 23 pages, 16 figures, 3 tables. Submitted for publication to the IEEE\n",
    "authors": [
      "Michele Polese",
      "Leonardo Bonati",
      "Salvatore D'Oro",
      "Stefano Basagni",
      "Tommaso Melodia"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.01032"
  },
  {
    "id": "arXiv:2202.01034",
    "title": "Maintaining fairness across distribution shift: do we have viable  solutions for real-world applications?",
    "abstract": "Fairness and robustness are often considered as orthogonal dimensions when\nevaluating machine learning models. However, recent work has revealed\ninteractions between fairness and robustness, showing that fairness properties\nare not necessarily maintained under distribution shift. In healthcare\nsettings, this can result in e.g. a model that performs fairly according to a\nselected metric in \"hospital A\" showing unfairness when deployed in \"hospital\nB\". While a nascent field has emerged to develop provable fair and robust\nmodels, it typically relies on strong assumptions about the shift, limiting its\nimpact for real-world applications. In this work, we explore the settings in\nwhich recently proposed mitigation strategies are applicable by referring to a\ncausal framing. Using examples of predictive models in dermatology and\nelectronic health records, we show that real-world applications are complex and\noften invalidate the assumptions of such methods. Our work hence highlights\ntechnical, practical, and engineering gaps that prevent the development of\nrobustly fair machine learning models for real-world applications. Finally, we\ndiscuss potential remedies at each step of the machine learning pipeline.",
    "descriptor": "",
    "authors": [
      "Jessica Schrouff",
      "Natalie Harris",
      "Oluwasanmi Koyejo",
      "Ibrahim Alabdulmohsin",
      "Eva Schnider",
      "Krista Opsahl-Ong",
      "Alex Brown",
      "Subhrajit Roy",
      "Diana Mincu",
      "Christina Chen",
      "Awa Dieng",
      "Yuan Liu",
      "Vivek Natarajan",
      "Alan Karthikesalingam",
      "Katherine Heller",
      "Silvia Chiappa",
      "Alexander D'Amour"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01034"
  },
  {
    "id": "arXiv:2202.01035",
    "title": "Detecting Privacy Requirements from User Stories with NLP Transfer  Learning Models",
    "abstract": "To provide privacy-aware software systems, it is crucial to consider privacy\nfrom the very beginning of the development. However, developers do not have the\nexpertise and the knowledge required to embed the legal and social requirements\nfor data protection into software systems. Objective: We present an approach to\ndecrease privacy risks during agile software development by automatically\ndetecting privacy-related information in the context of user story\nrequirements, a prominent notation in agile Requirement Engineering (RE).\nMethods: The proposed approach combines Natural Language Processing (NLP) and\nlinguistic resources with deep learning algorithms to identify privacy aspects\ninto User Stories. NLP technologies are used to extract information regarding\nthe semantic and syntactic structure of the text. This information is then\nprocessed by a pre-trained convolutional neural network, which paved the way\nfor the implementation of a Transfer Learning technique. We evaluate the\nproposed approach by performing an empirical study with a dataset of 1680 user\nstories. Results: The experimental results show that deep learning algorithms\nallow to obtain better predictions than those achieved with conventional\n(shallow) machine learning methods. Moreover, the application of Transfer\nLearning allows to considerably improve the accuracy of the predictions, ca.\n10%. Conclusions: Our study contributes to encourage software engineering\nresearchers in considering the opportunities to automate privacy detection in\nthe early phase of design, by also exploiting transfer learning models.",
    "descriptor": "",
    "authors": [
      "Francesco Casillo",
      "Vincenzo Deufemia",
      "Carmine Gravino"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01035"
  },
  {
    "id": "arXiv:2202.01037",
    "title": "RoboKrill : a metachronal drag-based swimmer robot",
    "abstract": "Marine exploration is essential to understanding ocean processes and\norganisms. While the use of current unmanned underwater vehicles has enabled\nmany discoveries, there are still plenty of limitations toward exploring\ncomplex environments. Bio-inspired robots are a promising solution for highly\nmaneuverable underwater swimming at moderate speeds. Krill, especially, are\nefficient swimmers in the intermediate Reynolds number regime and can inform\nengineering solutions for ocean exploration. In this paper, we present the\ndesign, manufacture, and validation of a new krill-inspired, metachronal,\ndrag-based robotic system. By combining active and passive actuation of the\njoints with 3D printed parts, our unique design recreates the swimming\nkinematics of Euphausia superba in a compact and reproducible robotic platform.\nThe motion of the anterior and posterior appendage segments is achieved using\nservo motors and a multi-link mechanism, while the out-of-plane motion of the\nbiramous distal segments is attained via fluid-structure interactions. Going\nforward, our platform will be leveraged to study metachronal, drag-based\nswimmers across taxa to identify unifying success mechanisms at different\nscales, facilitating the development of a new generation of underwater robots.",
    "descriptor": "",
    "authors": [
      "Sara Oliveira Santos",
      "Francisco Cuenca-Jim\u00e9nez",
      "P. Antonio Gomez-Valdez",
      "Oscar Morales-Lopez",
      "Monica M. Wilhelmus"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Biological Physics (physics.bio-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.01037"
  },
  {
    "id": "arXiv:2202.01038",
    "title": "Using Ballistocardiography for Sleep Stage Classification",
    "abstract": "A practical way of detecting sleep stages has become more necessary as we\nbegin to learn about the vast effects that sleep has on people's lives. The\ncurrent methods of sleep stage detection are expensive, invasive to a person's\nsleep, and not practical in a modern home setting. While the method of\ndetecting sleep stages via the monitoring of brain activity, muscle activity,\nand eye movement, through electroencephalogram in a lab setting, provide the\ngold standard for detection, this paper aims to investigate a new method that\nwill allow a person to gain similar insight and results with no obtrusion to\ntheir normal sleeping habits. Ballistocardiography (BCG) is a non-invasive\nsensing technology that collects information by measuring the ballistic forces\ngenerated by the heart. Using features extracted from BCG such as time of\nusage, heart rate, respiration rate, relative stroke volume, and heart rate\nvariability, we propose to implement a sleep stage detection algorithm and\ncompare it against sleep stages extracted from a Fitbit Sense Smart Watch. The\naccessibility, ease of use, and relatively-low cost of the BCG offers many\napplications and advantages for using this device. By standardizing this\ndevice, people will be able to benefit from the BCG in analyzing their own\nsleep patterns and draw conclusions on their sleep efficiency. This work\ndemonstrates the feasibility of using BCG for an accurate and non-invasive\nsleep monitoring method that can be set up in the comfort of a one's personal\nsleep environment.",
    "descriptor": "",
    "authors": [
      "iebei Liu",
      "Peter Morris",
      "Krista Nelson",
      "Mehdi Boukhechba"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.01038"
  },
  {
    "id": "arXiv:2202.01040",
    "title": "Knowledge Engineering in the Long Game of Artificial Intelligence: The  Case of Speech Acts",
    "abstract": "This paper describes principles and practices of knowledge engineering that\nenable the development of holistic language-endowed intelligent agents that can\nfunction across domains and applications, as well as expand their ontological\nand lexical knowledge through lifelong learning. For illustration, we focus on\ndialog act modeling, a task that has been widely pursued in linguistics,\ncognitive modeling, and statistical natural language processing. We describe an\nintegrative approach grounded in the OntoAgent knowledge-centric cognitive\narchitecture and highlight the limitations of past approaches that isolate\ndialog from other agent functionalities.",
    "descriptor": "\nComments: Presented at The Ninth Advances in Cognitive Systems (ACS) Conference 2021 (arXiv:2201.06134)\n",
    "authors": [
      "Marjorie McShane",
      "Jesse English",
      "Sergei Nirenburg"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01040"
  },
  {
    "id": "arXiv:2202.01044",
    "title": "Spectral Rank Monotonicity on Undirected Networks",
    "abstract": "We study the problem of score and rank monotonicity for spectral ranking\nmethods, such as eigenvector centrality and PageRank, in the case of undirected\nnetworks. Score monotonicity means that adding an edge increases the score at\nboth ends of the edge. Rank monotonicity means that adding an edge improves the\nrelative position of both ends of the edge with respect to the remaining nodes.\nIt is known that common spectral rankings are both score and rank monotone on\ndirected, strongly connected graphs. We show that, surprisingly, the situation\nis very different for undirected graphs, and in particular that PageRank is\nneither score nor rank monotone.",
    "descriptor": "",
    "authors": [
      "Paolo Boldi",
      "Flavio Furia",
      "Sebastiano Vigna"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.01044"
  },
  {
    "id": "arXiv:2202.01045",
    "title": "Metrics for Evaluating Social Conformity of Crowd Navigation Algorithms",
    "abstract": "Recent protocols and metrics for training and evaluating autonomous robot\nnavigation through crowds are inconsistent due to diversified definitions of\n\"social behavior\". This makes it difficult, if not impossible, to effectively\ncompare published navigation algorithms. Furthermore, with the lack of a good\nevaluation protocol, resulting algorithms may fail to generalize, due to lack\nof diversity in training. To address these gaps, this paper facilitates a more\ncomprehensive evaluation and objective comparison of crowd navigation\nalgorithms by proposing a consistent set of metrics that accounts for both\nefficiency and social conformity, and a systematic protocol comprising multiple\ncrowd navigation scenarios of varying complexity for evaluation. We tested four\nstate-of-the-art algorithms under this protocol. Results revealed that some\nstate-of-the-art algorithms have much challenge in generalizing, and using our\nprotocol for training, we were able to improve the algorithm's performance. We\ndemonstrate that the set of proposed metrics provides more insight and\neffectively differentiates the performance of these algorithms with respect to\nefficiency and social conformity.",
    "descriptor": "",
    "authors": [
      "Junxian Wang",
      "Wesley P. Chan",
      "Pamela Carreno-Medrano",
      "Akansel Cosgun",
      "Elizabeth Croft"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.01045"
  },
  {
    "id": "arXiv:2202.01046",
    "title": "Towards High-Payload Admittance Control for Manual Guidance with  Environmental Contact",
    "abstract": "Force control enables hands-on teaching and physical collaboration, with the\npotential to improve ergonomics and flexibility of automation. Established\nmethods for the design of compliance, impedance control, and \\rev{collision\nresponse} can achieve free-space stability and acceptable peak contact force on\nlightweight, lower payload robots. Scaling collaboration to higher payloads can\nallow new applications, but introduces challenges due to the more significant\npayload dynamics and the use of higher-payload industrial robots.\nTo achieve high-payload manual guidance with contact, this paper proposes and\nvalidates new mechatronic design methods: standard admittance control is\nextended with damping feedback, compliant structures are integrated to the\nenvironment, and a contact response method which allows continuous admittance\ncontrol is proposed. These methods are compared with respect to free-space\nstability, contact stability, and peak contact force. The resulting methods are\nthen applied to realize two contact-rich tasks on a 16 kg payload (peg in hole\nand slot assembly) and free-space co-manipulation of a 50 kg payload.",
    "descriptor": "\nComments: Accepted at IEEE RA-L\n",
    "authors": [
      "Kevin Haninger",
      "Marcel Radke",
      "Axel Vick",
      "J\u00f6rg Kr\u00fcger"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.01046"
  },
  {
    "id": "arXiv:2202.01059",
    "title": "PINNs and GaLS: An Priori Error Estimates for Shallow Physically  Informed Neural Network Applied to Elliptic Problems",
    "abstract": "Recently Physically Informed Neural Networks have gained more and more\npopularity to solve partial differential equations, given the fact they escape\nthe course of dimensionality. First Physically Informed Neural Networks are\nviewed as an underdetermined point matching collocation method then we expose\nthe connection between Galerkin Least Square (GALS) and PINNs, to develop an a\npriori error estimate, in the context of elliptic problems. In particular\ntechniques that belong to the realm of the least square finite elements and\nRademacher complexity analysis will be used to obtain the above mentioned error\nestimate.",
    "descriptor": "\nComments: This work has been submitted to IFAC for possible publication\n",
    "authors": [
      "Umberto Zerbinati"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.01059"
  },
  {
    "id": "arXiv:2202.01069",
    "title": "Image-based Navigation in Real-World Environments via Multiple Mid-level  Representations: Fusion Models, Benchmark and Efficient Evaluation",
    "abstract": "Navigating complex indoor environments requires a deep understanding of the\nspace the robotic agent is acting into to correctly inform the navigation\nprocess of the agent towards the goal location. In recent learning-based\nnavigation approaches, the scene understanding and navigation abilities of the\nagent are achieved simultaneously by collecting the required experience in\nsimulation. Unfortunately, even if simulators represent an efficient tool to\ntrain navigation policies, the resulting models often fail when transferred\ninto the real world. One possible solution is to provide the navigation model\nwith mid-level visual representations containing important domain-invariant\nproperties of the scene. But, what are the best representations that facilitate\nthe transfer of a model to the real-world? How can they be combined? In this\nwork we address these issues by proposing a benchmark of Deep Learning\narchitectures to combine a range of mid-level visual representations, to\nperform a PointGoal navigation task following a Reinforcement Learning setup.\nAll the proposed navigation models have been trained with the Habitat simulator\non a synthetic office environment and have been tested on the same real-world\nenvironment using a real robotic platform. To efficiently assess their\nperformance in a real context, a validation tool has been proposed to generate\nrealistic navigation episodes inside the simulator. Our experiments showed that\nnavigation models can benefit from the multi-modal input and that our\nvalidation tool can provide good estimation of the expected navigation\nperformance in the real world, while saving time and resources. The acquired\nsynthetic and real 3D models of the environment, together with the code of our\nvalidation tool built on top of Habitat, are publicly available at the\nfollowing link: https://iplab.dmi.unict.it/EmbodiedVN/",
    "descriptor": "",
    "authors": [
      "Marco Rosano",
      "Antonino Furnari",
      "Luigi Gulino",
      "Corrado Santoro",
      "Giovanni Maria Farinella"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01069"
  },
  {
    "id": "arXiv:2202.01072",
    "title": "Interpretability for Multimodal Emotion Recognition using Concept  Activation Vectors",
    "abstract": "Multimodal Emotion Recognition refers to the classification of input video\nsequences into emotion labels based on multiple input modalities (usually\nvideo, audio and text). In recent years, Deep Neural networks have shown\nremarkable performance in recognizing human emotions, and are on par with\nhuman-level performance on this task. Despite the recent advancements in this\nfield, emotion recognition systems are yet to be accepted for real world setups\ndue to the obscure nature of their reasoning and decision-making process. Most\nof the research in this field deals with novel architectures to improve the\nperformance for this task, with a few attempts at providing explanations for\nthese models' decisions. In this paper, we address the issue of\ninterpretability for neural networks in the context of emotion recognition\nusing Concept Activation Vectors (CAVs). To analyse the model's latent space,\nwe define human-understandable concepts specific to Emotion AI and map them to\nthe widely-used IEMOCAP multimodal database. We then evaluate the influence of\nour proposed concepts at multiple layers of the Bi-directional Contextual LSTM\n(BC-LSTM) network to show that the reasoning process of neural networks for\nemotion recognition can be represented using human-understandable concepts.\nFinally, we perform hypothesis testing on our proposed concepts to show that\nthey are significant for interpretability of this task.",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Ashish Ramayee Asokan",
      "Nidarshan Kumar",
      "Anirudh Venkata Ragam",
      "Shylaja S Sharath"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01072"
  },
  {
    "id": "arXiv:2202.01077",
    "title": "Comparison of human trust in an AI system, a human, and a social robot  as a task partner",
    "abstract": "This study investigated trust in a social robot compared with that in an AI\nsystem and a human as a task partner in consideration of four types of trust:\ninitial trust (trust before a task), early trust (trust in the beginning of a\ntask), trust decline due to a partner's errors, and trust recovery due to a\npartner's performance recovery. We conducted an online experiment using\ncalculation and emotion recognition tasks where participants answered after\nreferring to the answers of an AI, human, or robot partner. During the\nexperiment, the participants rated their levels of trust in their partners. As\na result, trust in a social robot was basically neither similar to that in the\nAI or in the human and settled between them. The results are discussed in\nconsideration of the previous studies.",
    "descriptor": "",
    "authors": [
      "Akihiro Maehigashi",
      "Takahiro Tsumura",
      "Seiji Yamada"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.01077"
  },
  {
    "id": "arXiv:2202.01078",
    "title": "Melody Extraction from Polyphonic Music by Deep Learning Approaches: A  Review",
    "abstract": "Melody extraction is a vital music information retrieval task among music\nresearchers for its potential applications in education pedagogy and the music\nindustry. Melody extraction is a notoriously challenging task due to the\npresence of background instruments. Also, often melodic source exhibits similar\ncharacteristics to that of the other instruments. The interfering background\naccompaniment with the vocals makes extracting the melody from the mixture\nsignal much more challenging. Until recently, classical signal processing-based\nmelody extraction methods were quite popular among melody extraction\nresearchers. The ability of the deep learning models to model large-scale data\nand the ability of the models to learn automatic features by exploiting spatial\nand temporal dependencies inspired many researchers to adopt deep learning\nmodels for melody extraction. In this paper, an attempt has been made to review\nthe up-to-date data-driven deep learning approaches for melody extraction from\npolyphonic music. The available deep models have been categorized based on the\ntype of neural network used and the output representation they use for\npredicting melody. Further, the architectures of the 25 melody extraction\nmodels are briefly presented. The loss functions used to optimize the model\nparameters of the melody extraction models are broadly categorized into four\ncategories and briefly describe the loss functions used by various melody\nextraction models. Also, the various input representations adopted by the\nmelody extraction models and the parameter settings are deeply described. A\nsection describing the explainability of the block-box melody extraction deep\nneural networks is included. The performance of 25 melody extraction methods is\ncompared. The possible future directions to explore/improve the melody\nextraction methods are also presented in the paper.",
    "descriptor": "\nComments: 72 pages\n",
    "authors": [
      "Gurunath Reddy M",
      "K. Sreenivasa Rao",
      "Partha Pratim Das"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.01078"
  },
  {
    "id": "arXiv:2202.01083",
    "title": "Control of Parasitism in Variational Integrators for Degenerate  Lagrangian Systems",
    "abstract": "This paper deals with the control of parasitism in variational integrators\nfor degenerate Lagrangian systems by writing them as general linear methods.\nThis enables us to calculate their parasitic growth parameters which are\nresponsible for the loss of long-time energy conservation properties of these\nalgorithms. As a remedy and to offset the effects of parasitism, the standard\nprojection technique is then applied to the general linear methods to\nnumerically preserve the invariants of the degenerate Lagrangian systems by\nprojecting the solution onto the desired manifold.",
    "descriptor": "\nComments: 13 Pages\n",
    "authors": [
      "Farrukh Shehzad",
      "Yousaf Habib",
      "Michael Kraus",
      "Zareen Akhtar"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.01083"
  },
  {
    "id": "arXiv:2202.01085",
    "title": "Giga-scale Kernel Matrix Vector Multiplication on GPU",
    "abstract": "Kernel matrix vector multiplication (KMVM) is a ubiquitous operation in\nmachine learning and scientific computing, spanning from the kernel literature\nto signal processing. As kernel matrix vector multiplication tends to scale\nquadratically in both memory and time, applications are often limited by these\ncomputational scaling constraints. We propose a novel approximation procedure\ncoined Faster-Fast and Free Memory Method ($\\text{F}^3$M) to address these\nscaling issues for KMVM. Extensive experiments demonstrate that $\\text{F}^3$M\nhas empirical \\emph{linear time and memory} complexity with a relative error of\norder $10^{-3}$ and can compute a full KMVM for a billion points \\emph{in under\none minute} on a high-end GPU, leading to a significant speed-up in comparison\nto existing CPU methods. We further demonstrate the utility of our procedure by\napplying it as a drop-in for the state-of-the-art GPU-based linear solver\nFALKON, \\emph{improving speed 3-5 times} at the cost of $<$1\\% drop in\naccuracy.",
    "descriptor": "",
    "authors": [
      "Robert Hu",
      "Dino Sejdinovic",
      "Joan Alexis Glaun\u00e8s"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.01085"
  },
  {
    "id": "arXiv:2202.01087",
    "title": "Communication Efficient Federated Learning for Generalized Linear  Bandits",
    "abstract": "Contextual bandit algorithms have been recently studied under the federated\nlearning setting to satisfy the demand of keeping data decentralized and\npushing the learning of bandit models to the client side. But limited by the\nrequired communication efficiency, existing solutions are restricted to linear\nmodels to exploit their closed-form solutions for parameter estimation. Such a\nrestricted model choice greatly hampers these algorithms' practical utility. In\nthis paper, we take the first step to addressing this challenge by studying\ngeneralized linear bandit models under a federated learning setting. We propose\na communication-efficient solution framework that employs online regression for\nlocal update and offline regression for global update. We rigorously proved\nthat, though the setting is more general and challenging, our algorithm can\nattain sub-linear rate in both regret and communication cost, which is also\nvalidated by our extensive empirical evaluations.",
    "descriptor": "\nComments: 36 pages, 3 figures\n",
    "authors": [
      "Chuanhao Li",
      "Hongning Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01087"
  },
  {
    "id": "arXiv:2202.01095",
    "title": "Minimizing Expected Intrusion Detection Time in Adversarial Patrolling",
    "abstract": "In adversarial patrolling games, a mobile Defender strives to discover\nintrusions at vulnerable targets initiated by an Attacker. The Attacker's\nutility is traditionally defined as the probability of completing an attack,\npossibly weighted by target costs. However, in many real-world scenarios, the\nactual damage caused by the Attacker depends on the \\emph{time} elapsed since\nthe attack's initiation to its detection. We introduce a formal model for such\nscenarios, and we show that the Defender always has an \\emph{optimal} strategy\nachieving maximal protection. We also prove that \\emph{finite-memory}\nDefender's strategies are sufficient for achieving protection arbitrarily close\nto the optimum. Then, we design an efficient \\emph{strategy synthesis}\nalgorithm based on differentiable programming and gradient descent.",
    "descriptor": "\nComments: A full version of the paper presented at AAMAS 2022\n",
    "authors": [
      "David Kla\u0161ka",
      "Anton\u00edn Ku\u010dera",
      "V\u00edt Musil",
      "Vojt\u011bch \u0158eh\u00e1k"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.01095"
  },
  {
    "id": "arXiv:2202.01096",
    "title": "Identifying Suitable Tasks for Inductive Transfer Through the Analysis  of Feature Attributions",
    "abstract": "Transfer learning approaches have shown to significantly improve performance\non downstream tasks. However, it is common for prior works to only report where\ntransfer learning was beneficial, ignoring the significant trial-and-error\nrequired to find effective settings for transfer. Indeed, not all task\ncombinations lead to performance benefits, and brute-force searching rapidly\nbecomes computationally infeasible. Hence the question arises, can we predict\nwhether transfer between two tasks will be beneficial without actually\nperforming the experiment? In this paper, we leverage explainability techniques\nto effectively predict whether task pairs will be complementary, through\ncomparison of neural network activation between single-task models. In this\nway, we can avoid grid-searches over all task and hyperparameter combinations,\ndramatically reducing the time needed to find effective task pairs. Our results\nshow that, through this approach, it is possible to reduce training time by up\nto 83.5% at a cost of only 0.034 reduction in positive-class F1 on the TREC-IS\n2020-A dataset.",
    "descriptor": "\nComments: Accepted at ECIR 2022\n",
    "authors": [
      "Alexander J. Hepburn",
      "Richard McCreadie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.01096"
  },
  {
    "id": "arXiv:2202.01097",
    "title": "Spectral and Energy Efficiency of DCO-OFDM in Visible Light  Communication Systems with Finite-Alphabet Inputs",
    "abstract": "The bound of the information transmission rate of direct current biased\noptical orthogonal frequency division multiplexing (DCO-OFDM) for visible light\ncommunication (VLC) with finite-alphabet inputs is yet unknown, where the\ncorresponding spectral efficiency (SE) and energy efficiency (EE) stems out as\nthe open research problems. In this paper, we derive the exact achievable rate\nof {the} DCO-OFDM system with finite-alphabet inputs for the first time.\nFurthermore, we investigate SE maximization problems of {the} DCO-OFDM system\nsubject to both electrical and optical power constraints. By exploiting the\nrelationship between the mutual information and the minimum mean-squared error,\nwe propose a multi-level mercury-water-filling power allocation scheme to\nachieve the maximum SE. Moreover, the EE maximization problems of {the}\nDCO-OFDM system are studied, and the Dinkelbach-type power allocation scheme is\ndeveloped for the maximum EE. Numerical results verify the effectiveness of the\nproposed theories and power allocation schemes.",
    "descriptor": "\nComments: 14 pages, 14 figures, accepted by IEEE Transactions on Wireless Communications\n",
    "authors": [
      "Ruixin Yang",
      "Shuai Ma",
      "Zihan Xu",
      "Hang Li",
      "Xiaodong Liu",
      "Xintong Ling",
      "Xiong Deng",
      "Xun Zhang",
      "Shiyin Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.01097"
  },
  {
    "id": "arXiv:2202.01099",
    "title": "On Lyapunov Stability of Positive and Conservative Time Integrators and  Application to Second Order Modified Patankar--Runge--Kutta Schemes",
    "abstract": "Since almost twenty years, modified Patankar--Runge--Kutta (MPRK) methods\nhave proven to be efficient and robust numerical schemes that preserve\npositivity and conservativity of the production-destruction system\nirrespectively of the time step size chosen. Due to these advantageous\nproperties they are used for a wide variety of applications. Nevertheless,\nuntil now, an analytic investigation of the stability of MPRK schemes is still\nmissing, since the usual approach by means of Dahlquist's equation is not\nfeasible. Therefore, we consider a positive and conservative 2D test problem\nand provide statements usable for a stability analysis of general positive and\nconservative time integrator schemes based on the center manifold theory. We\nuse this approach to investigate the Lyapunov stability of the second order\nMPRK22($\\alpha$) and MPRK22ncs($\\alpha$) schemes. We prove that\nMPRK22($\\alpha$) schemes are unconditionally stable and derive the stability\nregions of MPRK22ncs($\\alpha$) schemes. Finally, numerical experiments are\npresented, which confirm the theoretical results.",
    "descriptor": "",
    "authors": [
      "Thomas Izgin",
      "Stefan Kopecz",
      "Andreas Meister"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.01099"
  },
  {
    "id": "arXiv:2202.01100",
    "title": "Exact Privacy Analysis of the Gaussian Sparse Histogram Mechanism",
    "abstract": "Sparse histogram methods can be useful for returning differentially private\ncounts of items in large or infinite histograms, large group-by queries, and\nmore generally, releasing a set of statistics with sufficient item counts. We\nconsider the Gaussian version of the sparse histogram mechanism and study the\nexact $\\epsilon,\\delta$ differential privacy guarantees satisfied by this\nmechanism. We compare these exact $\\epsilon,\\delta$ parameters to the simpler\noverestimates used in prior work to quantify the impact of their looser privacy\nbounds.",
    "descriptor": "\nComments: 22 pages, 1 figure\n",
    "authors": [
      "Brian Karrer",
      "Daniel Kifer",
      "Arjun Wilkins",
      "Danfeng Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.01100"
  },
  {
    "id": "arXiv:2202.01102",
    "title": "System Identification with Variance Minimization via Input Design",
    "abstract": "The subspace method is one of the mainstream system identification method of\nlinear systems, and its basic idea is to estimate the system parameter matrices\nby projecting them into a subspace related to input and output. However, most\nof the existing subspace methods cannot have the statistic performance\nguaranteed since the lack of closed-form expression of the estimation.\nMeanwhile, traditional subspace methods cannot deal with the uncertainty of the\nnoise, and thus stable identification results cannot be obtained. In this\npaper, we propose a novel improved subspace method from the perspective of\ninput design, which guarantees the consistent and stable identification results\nwith the minimum variance. Specifically, we first obtain a closed-form\nestimation of the system matrix, then analyze the statistic performance by\nderiving the maximum identification deviation. This identification deviation\nmaximization problem is non-convex, and is solved by splitting it into two\nsub-problems with the optimal solution guaranteed. Next, an input design method\nis proposed to deal with the uncertainty and obtain stable identification\nresults by minimizing the variance. This problem is formulated as a constrained\nmin-max optimization problem. The optimal solution is obtained from\ntransforming the cost function into a convex function while ensuring the safety\nconstraints through the method of predictive control. We prove the consistency\nand the convergence of the proposed method. Simulation demonstrates the\neffectiveness of our method.",
    "descriptor": "",
    "authors": [
      "Xiangyu Mao",
      "Jianping He",
      "Chengcheng Zhao"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.01102"
  },
  {
    "id": "arXiv:2202.01103",
    "title": "A New Temporal Interpretation of Cluster Editing",
    "abstract": "The NP-complete graph problem Cluster Editing seeks to transform a static\ngraph into disjoint union of cliques by making the fewest possible edits to the\nedge set. We introduce a natural interpretation of this problem in the setting\nof temporal graphs, whose edge-sets are subject to discrete changes over time,\nwhich we call Editing to Temporal Cliques. This problem is NP-complete even\nwhen restricted to temporal graphs whose underlying graph is a path, but we\nobtain two polynomial-time algorithms for special cases with further\nrestrictions. In the static setting, it is well-known that a graph is a\ndisjoint union of cliques if and only if it contains no induced copy of $P_3$;\nwe demonstrate that no general characterisation involving sets of at most four\nvertices can exist in the temporal setting, but obtain a complete\ncharacterisation involving forbidden configurations on at most five vertices.\nThis characterisation gives rise to an FPT algorithm parameterised\nsimultaneously by the permitted number of modifications and the lifetime of the\ntemporal graph, which uses a simple search-tree strategy.",
    "descriptor": "\nComments: 24 pages, 2 figures\n",
    "authors": [
      "Cristiano Bocci",
      "Chiara Capresi",
      "Kitty Meeks",
      "John Sylvester"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)",
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.01103"
  },
  {
    "id": "arXiv:2202.01107",
    "title": "Keyword localisation in untranscribed speech using visually grounded  speech models",
    "abstract": "Keyword localisation is the task of finding where in a speech utterance a\ngiven query keyword occurs. We investigate to what extent keyword localisation\nis possible using a visually grounded speech (VGS) model. VGS models are\ntrained on unlabelled images paired with spoken captions. These models are\ntherefore self-supervised -- trained without any explicit textual label or\nlocation information. To obtain training targets, we first tag training images\nwith soft text labels using a pretrained visual classifier with a fixed\nvocabulary. This enables a VGS model to predict the presence of a written\nkeyword in an utterance, but not its location. We consider four ways to equip\nVGS models with localisations capabilities. Two of these -- a saliency approach\nand input masking -- can be applied to an arbitrary prediction model after\ntraining, while the other two -- attention and a score aggregation approach --\nare incorporated directly into the structure of the model. Masked-based\nlocalisation gives some of the best reported localisation scores from a VGS\nmodel, with an accuracy of 57% when the system knows that a keyword occurs in\nan utterance and need to predict its location. In a setting where localisation\nis performed after detection, an $F_1$ of 25% is achieved, and in a setting\nwhere a keyword spotting ranking pass is first performed, we get a localisation\nP@10 of 32%. While these scores are modest compared to the idealised setting\nwith unordered bag-of-word-supervision (from transcriptions), these models do\nnot receive any textual or location supervision. Further analyses show that\nthese models are limited by the first detection or ranking pass. Moreover,\nindividual keyword localisation performance is correlated with the tagging\nperformance from the visual classifier. We also show qualitatively how and\nwhere semantic mistakes occur, e.g. that the model locates surfer when queried\nwith ocean.",
    "descriptor": "\nComments: 10 figures, 5 tables\n",
    "authors": [
      "Kayode Olaleye",
      "Dan Oneata",
      "Herman Kamper"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.01107"
  },
  {
    "id": "arXiv:2202.01108",
    "title": "Learning to reason about and to act on physical cascading events",
    "abstract": "Reasoning and interacting with dynamic environments is a fundamental problem\nin AI, but it becomes extremely challenging when actions can trigger cascades\nof cross-dependent events. We introduce a new supervised learning setup called\n{\\em Cascade} where an agent is shown a video of a physically simulated dynamic\nscene, and is asked to intervene and trigger a cascade of events, such that the\nsystem reaches a \"counterfactual\" goal. For instance, the agent may be asked to\n\"Make the blue ball hit the red one, by pushing the green ball\". The agent\nintervention is drawn from a continuous space, and cascades of events makes the\ndynamics highly non-linear.\nWe combine semantic tree search with an event-driven forward model and devise\nan algorithm that learns to search in semantic trees in continuous spaces. We\ndemonstrate that our approach learns to effectively follow instructions to\nintervene in previously unseen complex scenes. It can also reason about\nalternative outcomes, when provided an observed cascade of events.",
    "descriptor": "",
    "authors": [
      "Yuval Atzmon",
      "Eli A. Meirom",
      "Shie Mannor",
      "Gal Chechik"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01108"
  },
  {
    "id": "arXiv:2202.01110",
    "title": "A Survey on Retrieval-Augmented Text Generation",
    "abstract": "Recently, retrieval-augmented text generation attracted increasing attention\nof the computational linguistics community. Compared with conventional\ngeneration models, retrieval-augmented text generation has remarkable\nadvantages and particularly has achieved state-of-the-art performance in many\nNLP tasks. This paper aims to conduct a survey about retrieval-augmented text\ngeneration. It firstly highlights the generic paradigm of retrieval-augmented\ngeneration, and then it reviews notable approaches according to different tasks\nincluding dialogue response generation, machine translation, and other\ngeneration tasks. Finally, it points out some important directions on top of\nrecent methods to facilitate future research.",
    "descriptor": "",
    "authors": [
      "Huayang Li",
      "Yixuan Su",
      "Deng Cai",
      "Yan Wang",
      "Lemao Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.01110"
  },
  {
    "id": "arXiv:2202.01112",
    "title": "On Joint Communication and Channel Discrimination",
    "abstract": "We consider a basic communication and sensing setup comprising a transmitter,\na receiver and a sensor. The transmitter sends an encoded sequence to the\nreceiver through a discrete memoryless channel, and the receiver is interested\nin decoding the sequence. On the other hand, the sensor picks up a noisy\nversion of the transmitted sequence through one of two possible discrete\nmemoryless channels. The sensor knows the transmitted sequence and wishes to\ndiscriminate between the two possible channels, i.e. to identify the channel\nthat has generated the output given the input. We study the trade-off between\ncommunication and sensing in the asymptotic regime, captured in terms of the\ncoding rate to the receiver against the discrimination error exponent at the\nsensor. We characterize the optimal rate-exponent trade-off for general\ndiscrete memoryless channels with an input cost constraint.",
    "descriptor": "",
    "authors": [
      "Han Wu",
      "Hamdi Joudeh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.01112"
  },
  {
    "id": "arXiv:2202.01115",
    "title": "NeuRegenerate: A Framework for Visualizing Neurodegeneration",
    "abstract": "Recent advances in high-resolution microscopy have allowed scientists to\nbetter understand the underlying brain connectivity. However, due to the\nlimitation that biological specimens can only be imaged at a single timepoint,\nstudying changes to neural projections is limited to general observations using\npopulation analysis. In this paper, we introduce NeuRegenerate, a novel\nend-to-end framework for the prediction and visualization of changes in neural\nfiber morphology within a subject, for specified age-timepoints.To predict\nprojections, we present neuReGANerator, a deep-learning network based on\ncycle-consistent generative adversarial network (cycleGAN) that translates\nfeatures of neuronal structures in a region, across age-timepoints, for large\nbrain microscopy volumes. We improve the reconstruction quality of neuronal\nstructures by implementing a density multiplier and a new loss function, called\nthe hallucination loss.Moreover, to alleviate artifacts that occur due to\ntiling of large input volumes, we introduce a spatial-consistency module in the\ntraining pipeline of neuReGANerator. We show that neuReGANerator has a\nreconstruction accuracy of 94% in predicting neuronal structures. Finally, to\nvisualize the predicted change in projections, NeuRegenerate offers two modes:\n(1) neuroCompare to simultaneously visualize the difference in the structures\nof the neuronal projections, across the age timepoints, and (2) neuroMorph, a\nvesselness-based morphing technique to interactively visualize the\ntransformation of the structures from one age-timepoint to the other. Our\nframework is designed specifically for volumes acquired using wide-field\nmicroscopy. We demonstrate our framework by visualizing the structural changes\nin neuronal fibers within the cholinergic system of the mouse brain between a\nyoung and old specimen.",
    "descriptor": "\nComments: Accepted for publication in IEEE Transactions on Visualization and Computer Graphics\n",
    "authors": [
      "Saeed Boorboor",
      "Shawn Mathew",
      "Mala Ananth",
      "David Talmage",
      "Lorna W. Role",
      "Arie E. Kaufman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Graphics (cs.GR)",
      "Human-Computer Interaction (cs.HC)",
      "Image and Video Processing (eess.IV)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2202.01115"
  },
  {
    "id": "arXiv:2202.01117",
    "title": "An Eye for an Eye: Defending against Gradient-based Attacks with  Gradients",
    "abstract": "Deep learning models have been shown to be vulnerable to adversarial attacks.\nIn particular, gradient-based attacks have demonstrated high success rates\nrecently. The gradient measures how each image pixel affects the model output,\nwhich contains critical information for generating malicious perturbations. In\nthis paper, we show that the gradients can also be exploited as a powerful\nweapon to defend against adversarial attacks. By using both gradient maps and\nadversarial images as inputs, we propose a Two-stream Restoration Network (TRN)\nto restore the adversarial images. To optimally restore the perturbed images\nwith two streams of inputs, a Gradient Map Estimation Mechanism is proposed to\nestimate the gradients of adversarial images, and a Fusion Block is designed in\nTRN to explore and fuse the information in two streams. Once trained, our TRN\ncan defend against a wide range of attack methods without significantly\ndegrading the performance of benign inputs. Also, our method is generalizable,\nscalable, and hard to bypass. Experimental results on CIFAR10, SVHN, and\nFashion MNIST demonstrate that our method outperforms state-of-the-art defense\nmethods.",
    "descriptor": "",
    "authors": [
      "Hanbin Hong",
      "Yuan Hong",
      "Yu Kong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01117"
  },
  {
    "id": "arXiv:2202.01118",
    "title": "On Linear Separability under Linear Compression with Applications to  Hard Support Vector Machine",
    "abstract": "This paper investigates the theoretical problem of maintaining linear\nseparability of the data-generating distribution under linear compression.\nWhile it has been long known that linear separability may be maintained by\nlinear transformations that approximately preserve the inner products between\nthe domain points, the limit to which the inner products are preserved in order\nto maintain linear separability was unknown. In this paper, we show that linear\nseparability is maintained as long as the distortion of the inner products is\nsmaller than the squared margin of the original data-generating distribution.\nThe proof is mainly based on the geometry of hard support vector machines (SVM)\nextended from the finite set of training examples to the (possibly) infinite\ndomain of the data-generating distribution. As applications, we derive bounds\non the (i) compression length of random sub-Gaussian matrices; and (ii)\ngeneralization error for compressive learning with hard-SVM.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Paul McVay",
      "Dr. Tie Liu",
      "Dr. Krishna Narayanan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2202.01118"
  },
  {
    "id": "arXiv:2202.01121",
    "title": "Decentralized Matching in Shared Intelligent Vehicles Fleet",
    "abstract": "High computational time is one of the most important operational issues in\ncentralized on-demand shared mobility systems. To resolve this issue, we\npropose a decentralized ride-matching system that is based on vehicle to\ninfrastructure (V2I) and infrastructure to infrastructure (I2I) communication.\nApplication on the downtown Toronto road network demonstrated that the\ndecentralized system resulted in a speed-up of 125 times in terms of\ncomputational time and showed high scalability. Moreover, the service rate in\nthe proposed system improved by 7% compared to the centralized. However, the\ncentralized system showed 29% and 17% improvement in wait time and detour time.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2104.10022\n",
    "authors": [
      "Seyed Mehdi Meshkani",
      "Bilal Farooq"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.01121"
  },
  {
    "id": "arXiv:2202.01123",
    "title": "An ASP approach for reasoning on neural networks under a finitely  many-valued semantics for weighted conditional knowledge bases",
    "abstract": "Weighted knowledge bases for description logics with typicality have been\nrecently considered under a \"concept-wise\" multipreference semantics (in both\nthe two-valued and fuzzy case), as the basis of a logical semantics of\nMultiLayer Perceptrons (MLPs). In this paper we consider weighted conditional\nALC knowledge bases with typicality in the finitely many-valued case, through\nthree different semantic constructions, based on coherent, faithful and\nphi-coherent interpretations. For the boolean fragment LC of ALC we exploit ASP\nand \"asprin\" for reasoning with the concept-wise multipreference entailment\nunder a phi-coherent semantics, suitable to characterize the stationary states\nof MLPs. As a proof of concept, we experiment the proposed approach for\nchecking properties of trained MLPs.",
    "descriptor": "\nComments: 21 pages. arXiv admin note: text overlap with arXiv:2110.03643, arXiv:2106.00390\n",
    "authors": [
      "Laura Giordano",
      "Daniele Theseider Dupr\u00e9"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01123"
  },
  {
    "id": "arXiv:2202.01128",
    "title": "Language Models Explain Word Reading Times Better Than Empirical  Predictability",
    "abstract": "Though there is a strong consensus that word length and frequency are the\nmost important single-word features determining visual-orthographic access to\nthe mental lexicon, there is less agreement as how to best capture syntactic\nand semantic factors. The traditional approach in cognitive reading research\nassumes that word predictability from sentence context is best captured by\ncloze completion probability (CCP) derived from human performance data. We\nreview recent research suggesting that probabilistic language models provide\ndeeper explanations for syntactic and semantic effects than CCP. Then we\ncompare CCP with (1) Symbolic n-gram models consolidate syntactic and semantic\nshort-range relations by computing the probability of a word to occur, given\ntwo preceding words. (2) Topic models rely on subsymbolic representations to\ncapture long-range semantic similarity by word co-occurrence counts in\ndocuments. (3) In recurrent neural networks (RNNs), the subsymbolic units are\ntrained to predict the next word, given all preceding words in the sentences.\nTo examine lexical retrieval, these models were used to predict single fixation\ndurations and gaze durations to capture rapidly successful and standard lexical\naccess, and total viewing time to capture late semantic integration. The linear\nitem-level analyses showed greater correlations of all language models with all\neye-movement measures than CCP. Then we examined non-linear relations between\nthe different types of predictability and the reading times using generalized\nadditive models. N-gram and RNN probabilities of the present word more\nconsistently predicted reading performance compared with topic models or CCP.",
    "descriptor": "",
    "authors": [
      "Markus J. Hofmann",
      "Steffen Remus",
      "Chris Biemann",
      "Ralph Radach",
      "Lars Kuchinke"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01128"
  },
  {
    "id": "arXiv:2202.01129",
    "title": "Structure-preserving GANs",
    "abstract": "Generative adversarial networks (GANs), a class of distribution-learning\nmethods based on a two-player game between a generator and a discriminator, can\ngenerally be formulated as a minmax problem based on the variational\nrepresentation of a divergence between the unknown and the generated\ndistributions. We introduce structure-preserving GANs as a data-efficient\nframework for learning distributions with additional structure such as group\nsymmetry, by developing new variational representations for divergences. Our\ntheory shows that we can reduce the discriminator space to its projection on\nthe invariant discriminator space, using the conditional expectation with\nrespect to the $\\sigma$-algebra associated to the underlying structure. In\naddition, we prove that the discriminator space reduction must be accompanied\nby a careful design of structured generators, as flawed designs may easily lead\nto a catastrophic \"mode collapse\" of the learned distribution. We contextualize\nour framework by building symmetry-preserving GANs for distributions with\nintrinsic group symmetry, and demonstrate that both players, namely the\nequivariant generator and invariant discriminator, play important but distinct\nroles in the learning process. Empirical experiments and ablation studies\nacross a broad range of data sets, including real-world medical imaging,\nvalidate our theory, and show our proposed methods achieve significantly\nimproved sample fidelity and diversity -- almost an order of magnitude measured\nin Fr\\'echet Inception Distance -- especially in the small data regime.",
    "descriptor": "\nComments: 38 pages, 15 figures\n",
    "authors": [
      "Jeremiah Birrell",
      "Markos A. Katsoulakis",
      "Luc Rey-Bellet",
      "Wei Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01129"
  },
  {
    "id": "arXiv:2202.01134",
    "title": "Ultra-Wideband Teach and Repeat",
    "abstract": "Autonomously retracing a manually-taught path is desirable for many\napplications, and Teach and Repeat (T&R) algorithms present an approach that is\nsuitable for long-range autonomy. In this paper, ultra-wideband (UWB)\nranging-based T&R is proposed for vehicles with limited resources. By fixing\nsingle UWB transceivers at far-apart unknown locations in an indoor\nenvironment, a robot with 3 UWB transceivers builds a locally consistent map\nduring the teach pass by fusing the range measurements under a custom ranging\nprotocol with an on-board IMU and height measurements. The robot then uses\ninformation from the teach pass to retrace the same trajectory autonomously.\nThe proposed ranging protocol and T&R algorithm are validated in simulation,\nwhere it is shown that the robot can successfully retrace the taught trajectory\nwith sub-metre tracking error.",
    "descriptor": "",
    "authors": [
      "Mohammed Ayman Shalaby",
      "Charles Champagne Cossette",
      "Jerome Le Ny",
      "James Richard Forbes"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.01134"
  },
  {
    "id": "arXiv:2202.01136",
    "title": "Probabilistically Robust Learning: Balancing Average- and Worst-case  Performance",
    "abstract": "Many of the successes of machine learning are based on minimizing an averaged\nloss function. However, it is well-known that this paradigm suffers from\nrobustness issues that hinder its applicability in safety-critical domains.\nThese issues are often addressed by training against worst-case perturbations\nof data, a technique known as adversarial training. Although empirically\neffective, adversarial training can be overly conservative, leading to\nunfavorable trade-offs between nominal performance and robustness. To this end,\nin this paper we propose a framework called probabilistic robustness that\nbridges the gap between the accurate, yet brittle average case and the robust,\nyet conservative worst case by enforcing robustness to most rather than to all\nperturbations. From a theoretical point of view, this framework overcomes the\ntrade-offs between the performance and the sample-complexity of worst-case and\naverage-case learning. From a practical point of view, we propose a novel\nalgorithm based on risk-aware optimization that effectively balances average-\nand worst-case performance at a considerably lower computational cost relative\nto adversarial training. Our results on MNIST, CIFAR-10, and SVHN illustrate\nthe advantages of this framework on the spectrum from average- to worst-case\nrobustness.",
    "descriptor": "",
    "authors": [
      "Alexander Robey",
      "Luiz F. O. Chamon",
      "George J. Pappas",
      "Hamed Hassani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.01136"
  },
  {
    "id": "arXiv:2202.01139",
    "title": "Surrogate Modeling for Physical Systems with Preserved Properties and  Adjustable Tradeoffs",
    "abstract": "Determining the proper level of details to develop and solve physical models\nis usually difficult when one encounters new engineering problems. Such\ndifficulty comes from how to balance the time (simulation cost) and accuracy\nfor the physical model simulation afterwards. We propose a framework for\nautomatic development of a family of surrogate models of physical systems that\nprovide flexible cost-accuracy tradeoffs to assist making such determinations.\nWe present both a model-based and a data-driven strategy to generate surrogate\nmodels. The former starts from a high-fidelity model generated from first\nprinciples and applies a bottom-up model order reduction (MOR) that preserves\nstability and convergence while providing a priori error bounds, although the\nresulting reduced-order model may lose its interpretability. The latter\ngenerates interpretable surrogate models by fitting artificial constitutive\nrelations to a presupposed topological structure using experimental or\nsimulation data. For the latter, we use Tonti diagrams to systematically\nproduce differential equations from the assumed topological structure using\nalgebraic topological semantics that are common to various lumped-parameter\nmodels (LPM). The parameter for the constitutive relations are estimated using\nstandard system identification algorithms. Our framework is compatible with\nvarious spatial discretization schemes for distributed parameter models (DPM),\nand can supports solving engineering problems in different domains of physics.",
    "descriptor": "\nComments: Paper #202\n",
    "authors": [
      "Randi Wang",
      "Morad Behandish"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.01139"
  },
  {
    "id": "arXiv:2202.01141",
    "title": "Federated Reinforcement Learning for Collective Navigation of Robotic  Swarms",
    "abstract": "The recent advancement of Deep Reinforcement Learning (DRL) contributed to\nrobotics by allowing automatic controller design. Automatic controller design\nis a crucial approach for designing swarm robotic systems, which require more\ncomplex controller than a single robot system to lead a desired collective\nbehaviour. Although DRL-based controller design method showed its\neffectiveness, the reliance on the central training server is a critical\nproblem in the real-world environments where the robot-server communication is\nunstable or limited. We propose a novel Federated Learning (FL) based DRL\ntraining strategy for use in swarm robotic applications. As FL reduces the\nnumber of robot-server communication by only sharing neural network model\nweights, not local data samples, the proposed strategy reduces the reliance on\nthe central server during controller training with DRL. The experimental\nresults from the collective learning scenario showed that the proposed FL-based\nstrategy dramatically reduced the number of communication by minimum 1600 times\nand even increased the success rate of navigation with the trained controller\nby 2.8 times compared to the baseline strategies that share a central server.\nThe results suggest that our proposed strategy can efficiently train swarm\nrobotic systems in the real-world environments with the limited robot-server\ncommunication, e.g. agri-robotics, underwater and damaged nuclear facilities.",
    "descriptor": "\nComments: 9 pages, 5 figures, submitted to IEEE Transactions on Cognitive and Developmental Systems Journal\n",
    "authors": [
      "Seongin Na",
      "Tom\u00e1\u0161 Krajn\u00edk",
      "Barry Lennox",
      "Farshad Arvin"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01141"
  },
  {
    "id": "arXiv:2202.01142",
    "title": "Pop Quiz! Can a Large Language Model Help With Reverse Engineering?",
    "abstract": "Large language models (such as OpenAI's Codex) have demonstrated impressive\nzero-shot multi-task capabilities in the software domain, including code\nexplanation. In this work, we examine if this ability can be used to help with\nreverse engineering. Specifically, we investigate prompting Codex to identify\nthe purpose, capabilities, and important variable names or values from code,\neven when the code is produced through decompilation. Alongside an examination\nof the model's responses in answering open-ended questions, we devise a\ntrue/false quiz framework to characterize the performance of the language\nmodel. We present an extensive quantitative analysis of the measured\nperformance of the language model on a set of program purpose identification\nand information extraction tasks: of the 136,260 questions we posed, it\nanswered 72,754 correctly. A key takeaway is that while promising, LLMs are not\nyet ready for zero-shot reverse engineering.",
    "descriptor": "\nComments: 18 pages, 19 figures. Linked dataset: this https URL\n",
    "authors": [
      "Hammond Pearce",
      "Benjamin Tan",
      "Prashanth Krishnamurthy",
      "Farshad Khorrami",
      "Ramesh Karri",
      "Brendan Dolan-Gavitt"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01142"
  },
  {
    "id": "arXiv:2202.01143",
    "title": "Improved Integrality Gap in Max-Min Allocation: or Topology at the North  Pole",
    "abstract": "In the max-min allocation problem a set $P$ of players are to be allocated\ndisjoint subsets of a set $R$ of indivisible resources, such that the minimum\nutility among all players is maximized. We study the restricted variant, also\nknown as the Santa Claus problem, where each resource has an intrinsic positive\nvalue, and each player covets a subset of the resources. Bez\\'akov\\'a and Dani\nshowed that this problem is NP-hard to approximate within a factor less than\n$2$, consequently a great deal of work has focused on approximate solutions.\nThe principal approach for obtaining approximation algorithms has been via the\nConfiguration LP (CLP) of Bansal and Sviridenko. Accordingly, there has been\nmuch interest in bounding the integrality gap of this CLP. The existing\nalgorithms and integrality gap estimations are all based one way or another on\nthe combinatorial augmenting tree argument of Haxell for finding perfect\nmatchings in certain hypergraphs. Our main innovation in this paper is to\nintroduce the use of topological methods for the restricted max-min allocation\nproblem, to replace the combinatorial argument. This approach yields\nsubstantial improvements in the integrality gap of the CLP. In particular we\nimprove the previously best known bound of $3.808$ to $3.534$. We also study\nthe $(1,\\varepsilon)$-restricted version, in which resources can take only two\nvalues, and improve the integrality gap in most cases.",
    "descriptor": "\nComments: This is the full version of our paper submitted to STOC\n",
    "authors": [
      "Penny Haxell",
      "Tibor Szab\u00f3"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.01143"
  },
  {
    "id": "arXiv:2202.01144",
    "title": "An Adiabatic Capacitive Artificial Neuron with RRAM-based Threshold  Detection for Energy-Efficient Neuromorphic Computing",
    "abstract": "In the quest for low power, bio-inspired computation both memristive and\nmemcapacitive-based Artificial Neural Networks (ANN) have been the subjects of\nincreasing focus for hardware implementation of neuromorphic computing. One\nstep further, regenerative capacitive neural networks, which call for the use\nof adiabatic computing, offer a tantalising route towards even lower energy\nconsumption, especially when combined with `memimpedace' elements. Here, we\npresent an artificial neuron featuring adiabatic synapse capacitors to produce\nmembrane potentials for the somas of neurons; the latter implemented via\ndynamic latched comparators augmented with Resistive Random-Access Memory\n(RRAM) devices. Our initial 4-bit adiabatic capacitive neuron proof-of-concept\nexample shows 90% synaptic energy saving. At 4 synapses/soma we already witness\nan overall 35% energy reduction. Furthermore, the impact of process and\ntemperature on the 4-bit adiabatic synapse shows a maximum energy variation of\n30% at 100 degree Celsius across the corners without any functionality loss.\nFinally, the efficacy of our adiabatic approach to ANN is tested for 512 & 1024\nsynapse/neuron for worst and best case synapse loading conditions and variable\nequalising capacitance's quantifying the expected trade-off between\nequalisation capacitance and range of optimal power-clock frequencies vs.\nloading (i.e. the percentage of active synapses).",
    "descriptor": "\nComments: This work has been submitted to the IEEE TCAS-I for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Sachin Maheshwari",
      "Alexander Serb",
      "Christos Papavassiliou",
      "Themistoklis Prodromakis"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.01144"
  },
  {
    "id": "arXiv:2202.01145",
    "title": "Relative Position Prediction as Pre-training for Text Encoders",
    "abstract": "Meaning is defined by the company it keeps. However, company is two-fold:\nIt's based on the identity of tokens and also on their position (topology). We\nargue that a position-centric perspective is more general and useful. The\nclassic MLM and CLM objectives in NLP are easily phrased as position\npredictions over the whole vocabulary. Adapting the relative position encoding\nparadigm in NLP to create relative labels for self-supervised learning, we seek\nto show superior pre-training judged by performance on downstream tasks.",
    "descriptor": "",
    "authors": [
      "Rickard Br\u00fcel-Gabrielsson",
      "Chris Scarvelis"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.01145"
  },
  {
    "id": "arXiv:2202.01147",
    "title": "Improving Screening Processes via Calibrated Subset Selection",
    "abstract": "Many selection processes such as finding patients qualifying for a medical\ntrial or retrieval pipelines in search engines consist of multiple stages,\nwhere an initial screening stage focuses the resources on shortlisting the most\npromising candidates. In this paper, we investigate what guarantees a screening\nclassifier can provide, independently of whether it is constructed manually or\ntrained. We find that current solutions do not enjoy distribution-free\ntheoretical guarantees -- we show that, in general, even for a perfectly\ncalibrated classifier, there always exist specific pools of candidates for\nwhich its shortlist is suboptimal. Then, we develop a distribution-free\nscreening algorithm -- called Calibrated Subset Selection (CSS) -- that, given\nany classifier and some amount of calibration data, finds near-optimal\nshortlists of candidates that contain a desired number of qualified candidates\nin expectation. Moreover, we show that a variant of our algorithm that\ncalibrates a given classifier multiple times across specific groups can create\nshortlists with provable diversity guarantees. Experiments on US Census survey\ndata validate our theoretical results and show that the shortlists provided by\nour algorithm are superior to those provided by several competitive baselines.",
    "descriptor": "",
    "authors": [
      "Lequn Wang",
      "Thorsten Joachims",
      "Manuel Gomez Rodriguez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.01147"
  },
  {
    "id": "arXiv:2202.01153",
    "title": "Analogies and Feature Attributions for Model Agnostic Explanation of  Similarity Learners",
    "abstract": "Post-hoc explanations for black box models have been studied extensively in\nclassification and regression settings. However, explanations for models that\noutput similarity between two inputs have received comparatively lesser\nattention. In this paper, we provide model agnostic local explanations for\nsimilarity learners applicable to tabular and text data. We first propose a\nmethod that provides feature attributions to explain the similarity between a\npair of inputs as determined by a black box similarity learner. We then propose\nanalogies as a new form of explanation in machine learning. Here the goal is to\nidentify diverse analogous pairs of examples that share the same level of\nsimilarity as the input pair and provide insight into (latent) factors\nunderlying the model's prediction. The selection of analogies can optionally\nleverage feature attributions, thus connecting the two forms of explanation\nwhile still maintaining complementarity. We prove that our analogy objective\nfunction is submodular, making the search for good-quality analogies efficient.\nWe apply the proposed approaches to explain similarities between sentences as\npredicted by a state-of-the-art sentence encoder, and between patients in a\nhealthcare utilization application. Efficacy is measured through quantitative\nevaluations, a careful user study, and examples of explanations.",
    "descriptor": "",
    "authors": [
      "Karthikeyan Natesan Ramamurthy",
      "Amit Dhurandhar",
      "Dennis Wei",
      "Zaid Bin Tariq"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01153"
  },
  {
    "id": "arXiv:2202.01155",
    "title": "The slurk Interaction Server Framework: Better Data for Better Dialog  Models",
    "abstract": "This paper presents the slurk software, a lightweight interaction server for\nsetting up dialog data collections and running experiments. Slurk enables a\nmultitude of settings including text-based, speech and video interaction\nbetween two or more humans or humans and bots, and a multimodal display area\nfor presenting shared or private interactive context. The software is\nimplemented in Python with an HTML and JS frontend that can easily be adapted\nto individual needs. It also provides a setup for pairing participants on\ncommon crowdworking platforms such as Amazon Mechanical Turk and some example\nbot scripts for common interaction scenarios.",
    "descriptor": "\nComments: submitted to LREC 2022\n",
    "authors": [
      "Jana G\u00f6tze",
      "Maike Paetzel-Pr\u00fcsmann",
      "Wencke Liermann",
      "Tim Diekmann",
      "David Schlangen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.01155"
  },
  {
    "id": "arXiv:2202.01157",
    "title": "Error Correction in ASR using Sequence-to-Sequence Models",
    "abstract": "Post-editing in Automatic Speech Recognition (ASR) entails automatically\ncorrecting common and systematic errors produced by the ASR system. The outputs\nof an ASR system are largely prone to phonetic and spelling errors. In this\npaper, we propose to use a powerful pre-trained sequence-to-sequence model,\nBART, further adaptively trained to serve as a denoising model, to correct\nerrors of such types. The adaptive training is performed on an augmented\ndataset obtained by synthetically inducing errors as well as by incorporating\nactual errors from an existing ASR system. We also propose a simple approach to\nrescore the outputs using word level alignments. Experimental results on\naccented speech data demonstrate that our strategy effectively rectifies a\nsignificant number of ASR errors and produces improved WER results when\ncompared against a competitive baseline.",
    "descriptor": "",
    "authors": [
      "Samrat Dutta",
      "Shreyansh Jain",
      "Ayush Maheshwari",
      "Ganesh Ramakrishnan",
      "Preethi Jyothi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01157"
  },
  {
    "id": "arXiv:2202.01158",
    "title": "GADGET: Online Resource Optimization for Scheduling Ring-All-Reduce  Learning Jobs",
    "abstract": "Fueled by advances in distributed deep learning (DDL), recent years have\nwitnessed a rapidly growing demand for resource-intensive distributed/parallel\ncomputing to process DDL computing jobs. To resolve network communication\nbottleneck and load balancing issues in distributed computing, the so-called\n``ring-all-reduce'' decentralized architecture has been increasingly adopted to\nremove the need for dedicated parameter servers. To date, however, there\nremains a lack of theoretical understanding on how to design resource\noptimization algorithms for efficiently scheduling ring-all-reduce DDL jobs in\ncomputing clusters. This motivates us to fill this gap by proposing a series of\nnew resource scheduling designs for ring-all-reduce DDL jobs. Our contributions\nin this paper are three-fold: i) We propose a new resource scheduling\nanalytical model for ring-all-reduce deep learning, which covers a wide range\nof objectives in DDL performance optimization (e.g., excessive training\navoidance, energy efficiency, fairness); ii) Based on the proposed performance\nanalytical model, we develop an efficient resource scheduling algorithm called\nGADGET (greedy ring-all-reduce distributed graph embedding technique), which\nenjoys a provable strong performance guarantee; iii) We conduct extensive\ntrace-driven experiments to demonstrate the effectiveness of the GADGET\napproach and its superiority over the state of the art.",
    "descriptor": "\nComments: Accepted in Proc. IEEE INFOCOM, Virtual Event, May 2022\n",
    "authors": [
      "Menglu Yu",
      "Ye Tian",
      "Bo Ji",
      "Chuan Wu",
      "Hridesh Rajan",
      "Jia Liu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.01158"
  },
  {
    "id": "arXiv:2202.01159",
    "title": "L3Cube-MahaCorpus and MahaBERT: Marathi Monolingual Corpus, Marathi BERT  Language Models, and Resources",
    "abstract": "We present L3Cube-MahaCorpus a Marathi monolingual data set scraped from\ndifferent internet sources. We expand the existing Marathi monolingual corpus\nwith 24.8M sentences and 289M tokens. We further present, MahaBERT, MahaAlBERT,\nand MahaRoBerta all BERT-based masked language models, and MahaFT, the fast\ntext word embeddings both trained on full Marathi corpus with 752M tokens. We\nshow the effectiveness of these resources on downstream classification and NER\ntasks. Marathi is a popular language in India but still lacks these resources.\nThis work is a step forward in building open resources for the Marathi\nlanguage. The data and models are available at\nhttps://github.com/l3cube-pune/MarathiNLP .",
    "descriptor": "",
    "authors": [
      "Raviraj Joshi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01159"
  },
  {
    "id": "arXiv:2202.01160",
    "title": "Saving Brian's Privacy: the Perils of Privacy Exposure through Reverse  DNS",
    "abstract": "Given the importance of privacy, many Internet protocols are nowadays\ndesigned with privacy in mind (e.g., using TLS for confidentiality). Foreseeing\nall privacy issues at the time of protocol design, however, is challenging and\nmay become near impossible when interaction out of protocol bounds occurs. One\ndemonstrably not well understood interaction occurs when DHCP exchanges are\naccompanied by automated changes to the global DNS, for example to dynamically\nadd hostnames for allocated IP addresses. As we will substantiate in this\npaper, this is a privacy risk: the presence of specific clients and network\ndynamics may be learned from virtually anywhere on the Internet, even if other\nmechanisms to limit tracking by outsiders (e.g., blocking pings) are in place.\nWe present a first of its kind study into this risk. We identify networks that\nexpose client identifiers in reverse DNS records and study the relation between\nthe presence of clients and said records. Our results show a strong link: in 9\nout of 10 cases, records linger for at most an hour, for a selection of\nacademic, enterprise and ISP networks alike. We also demonstrate how client\npatterns and network dynamics can be learned, by tracking devices owned by\npersons named Brian over time, revealing shifts in work patterns caused by\nCOVID-19 related work-from-home measures, and by determining a good time to\nstage a heist.",
    "descriptor": "",
    "authors": [
      "Olivier van der Toorn",
      "Raffaele Sommese",
      "Anna Sperotto",
      "Roland van Rijswijk-Deij",
      "Mattijs Jonker"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.01160"
  },
  {
    "id": "arXiv:2202.01169",
    "title": "Unified Scaling Laws for Routed Language Models",
    "abstract": "The performance of a language model has been shown to be effectively modeled\nas a power-law in its parameter count. Here we study the scaling behaviors of\nRouting Networks: architectures that conditionally use only a subset of their\nparameters while processing an input. For these models, parameter count and\ncomputational requirement form two independent axes along which an increase\nleads to better performance. In this work we derive and justify scaling laws\ndefined on these two variables which generalize those known for standard\nlanguage models and describe the performance of a wide range of routing\narchitectures trained via three different techniques. Afterwards we provide two\napplications of these laws: first deriving an Effective Parameter Count along\nwhich all models scale at the same rate, and then using the scaling\ncoefficients to give a quantitative comparison of the three routing techniques\nconsidered. Our analysis derives from an extensive evaluation of Routing\nNetworks across five orders of magnitude of size, including models with\nhundreds of experts and hundreds of billions of parameters.",
    "descriptor": "",
    "authors": [
      "Aidan Clark",
      "Diego de las Casas",
      "Aurelia Guy",
      "Arthur Mensch",
      "Michela Paganini",
      "Jordan Hoffmann",
      "Bogdan Damoc",
      "Blake Hechtman",
      "Trevor Cai",
      "Sebastian Borgeaud",
      "George van den Driessche",
      "Eliza Rutherford",
      "Tom Hennigan",
      "Matthew Johnson",
      "Katie Millican",
      "Albin Cassirer",
      "Chris Jones",
      "Elena Buchatskaya",
      "David Budden",
      "Laurent Sifre",
      "Simon Osindero",
      "Oriol Vinyals",
      "Jack Rae",
      "Erich Elsen",
      "Koray Kavukcuoglu",
      "Karen Simonyan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01169"
  },
  {
    "id": "arXiv:2202.01171",
    "title": "Low regularity integrators via decorated trees",
    "abstract": "We introduce a general framework of low regularity integrators which allows\nus to approximate the time dynamics of a large class of equations, including\nparabolic and hyperbolic problems, as well as dispersive equations, up to\narbitrary high order on general domains. The structure of the local error of\nthe new schemes is driven by nested commutators which in general require (much)\nlower regularity assumptions than classical methods do. Our main idea lies in\nembedding the central oscillations of the nonlinear PDE into the numerical\ndiscretisation. The latter is achieved by a novel decorated tree formalism\ninspired by singular SPDEs with Regularity Structures and allows us to control\nthe nonlinear interactions in the system up to arbitrary high order on the\ninfinite dimensional (continuous) as well as finite dimensional (discrete)\nlevel.",
    "descriptor": "\nComments: 55 pages\n",
    "authors": [
      "Yvonne Alama Bronsard",
      "Yvain Bruned",
      "Katharina Schratz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Analysis of PDEs (math.AP)",
      "Rings and Algebras (math.RA)"
    ],
    "url": "https://arxiv.org/abs/2202.01171"
  },
  {
    "id": "arXiv:2202.01176",
    "title": "Epidemic Dreams: Dreaming about health during the COVID-19 pandemic",
    "abstract": "The continuity hypothesis of dreams suggests that the content of dreams is\ncontinuous with the dreamer's waking experiences. Given the unprecedented\nnature of the experiences during COVID-19, we studied the continuity hypothesis\nin the context of the pandemic. We implemented a deep-learning algorithm that\ncan extract mentions of medical conditions from text and applied it to two\ndatasets collected during the pandemic: 2,888 dream reports (dreaming life\nexperiences), and 57M tweets mentioning the pandemic (waking life experiences).\nThe health expressions common to both sets were typical COVID-19 symptoms\n(e.g., cough, fever, and anxiety), suggesting that dreams reflected people's\nreal-world experiences. The health expressions that distinguished the two sets\nreflected differences in thought processes: expressions in waking life\nreflected a linear and logical thought process and, as such, described\nrealistic symptoms or related disorders (e.g., nasal pain, SARS, H1N1); those\nin dreaming life reflected a thought process closer to the visual and emotional\nspheres and, as such, described either conditions unrelated to the virus (e.g.,\nmaggots, deformities, snakebites), or conditions of surreal nature (e.g., teeth\nfalling out, body crumbling into sand). Our results confirm that dream reports\nrepresent an understudied yet valuable source of people's health experiences in\nthe real world.",
    "descriptor": "",
    "authors": [
      "Sanja \u0160\u0107epanovi\u0107",
      "Luca Maria Aiello",
      "Deirdre Barrett",
      "Daniele Quercia"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.01176"
  },
  {
    "id": "arXiv:2202.01178",
    "title": "Information Extraction through AI techniques: The KIDs use case at  CONSOB",
    "abstract": "In this paper we report on the initial activities carried out within a\ncollaboration between Consob and Sapienza University. We focus on Information\nExtraction from documents describing financial instruments. We discuss how we\nautomate this task, via both rule-based and machine learning-based methods and\nprovide our first results.",
    "descriptor": "",
    "authors": [
      "Domenico Lembo",
      "Alessandra Limosani",
      "Francesca Medda",
      "Alessandra Monaco",
      "Federico Maria Scafoglieri"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.01178"
  },
  {
    "id": "arXiv:2202.01179",
    "title": "AntidoteRT: Run-time Detection and Correction of Poison Attacks on  Neural Networks",
    "abstract": "We study backdoor poisoning attacks against image classification networks,\nwhereby an attacker inserts a trigger into a subset of the training data, in\nsuch a way that at test time, this trigger causes the classifier to predict\nsome target class. %There are several techniques proposed in the literature\nthat aim to detect the attack but only a few also propose to defend against it,\nand they typically involve retraining the network which is not always possible\nin practice. We propose lightweight automated detection and correction\ntechniques against poisoning attacks, which are based on neuron patterns mined\nfrom the network using a small set of clean and poisoned test samples with\nknown labels. The patterns built based on the mis-classified samples are used\nfor run-time detection of new poisoned inputs. For correction, we propose an\ninput correction technique that uses a differential analysis to identify the\ntrigger in the detected poisoned images, which is then reset to a neutral\ncolor. Our detection and correction are performed at run-time and input level,\nwhich is in contrast to most existing work that is focused on offline\nmodel-level defenses. We demonstrate that our technique outperforms existing\ndefenses such as NeuralCleanse and STRIP on popular benchmarks such as MNIST,\nCIFAR-10, and GTSRB against the popular BadNets attack and the more complex\nDFST attack.",
    "descriptor": "",
    "authors": [
      "Muhammad Usman",
      "Youcheng Sun",
      "Divya Gopinath",
      "Corina S. Pasareanu"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01179"
  },
  {
    "id": "arXiv:2202.01181",
    "title": "Make Some Noise: Reliable and Efficient Single-Step Adversarial Training",
    "abstract": "Recently, Wong et al. showed that adversarial training with single-step FGSM\nleads to a characteristic failure mode named catastrophic overfitting (CO), in\nwhich a model becomes suddenly vulnerable to multi-step attacks. They showed\nthat adding a random perturbation prior to FGSM (RS-FGSM) seemed to be\nsufficient to prevent CO. However, Andriushchenko and Flammarion observed that\nRS-FGSM still leads to CO for larger perturbations, and proposed an expensive\nregularizer (GradAlign) to avoid CO. In this work, we methodically revisit the\nrole of noise and clipping in single-step adversarial training. Contrary to\nprevious intuitions, we find that using a stronger noise around the clean\nsample combined with not clipping is highly effective in avoiding CO for large\nperturbation radii. Based on these observations, we then propose Noise-FGSM\n(N-FGSM) that, while providing the benefits of single-step adversarial\ntraining, does not suffer from CO. Empirical analyses on a large suite of\nexperiments show that N-FGSM is able to match or surpass the performance of\nprevious single-step methods while achieving a 3$\\times$ speed-up.",
    "descriptor": "",
    "authors": [
      "Pau de Jorge",
      "Adel Bibi",
      "Riccardo Volpi",
      "Amartya Sanyal",
      "Philip H. S. Torr",
      "Gr\u00e9gory Rogez",
      "Puneet K. Dokania"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01181"
  },
  {
    "id": "arXiv:2202.01182",
    "title": "Transfer in Reinforcement Learning via Regret Bounds for Learning Agents",
    "abstract": "We present an approach for the quantification of the usefulness of transfer\nin reinforcement learning via regret bounds for a multi-agent setting.\nConsidering a number of $\\aleph$ agents operating in the same Markov decision\nprocess, however possibly with different reward functions, we consider the\nregret each agent suffers with respect to an optimal policy maximizing her\naverage reward. We show that when the agents share their observations the total\nregret of all agents is smaller by a factor of $\\sqrt{\\aleph}$ compared to the\ncase when each agent has to rely on the information collected by herself. This\nresult demonstrates how considering the regret in multi-agent settings can\nprovide theoretical bounds on the benefit of sharing observations in transfer\nlearning.",
    "descriptor": "",
    "authors": [
      "Adrienne Tuynman",
      "Ronald Ortner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.01182"
  },
  {
    "id": "arXiv:2202.01186",
    "title": "Smoothed Embeddings for Certified Few-Shot Learning",
    "abstract": "Randomized smoothing is considered to be the state-of-the-art provable\ndefense against adversarial perturbations. However, it heavily exploits the\nfact that classifiers map input objects to class probabilities and do not focus\non the ones that learn a metric space in which classification is performed by\ncomputing distances to embeddings of classes prototypes. In this work, we\nextend randomized smoothing to few-shot learning models that map inputs to\nnormalized embeddings. We provide analysis of Lipschitz continuity of such\nmodels and derive robustness certificate against $\\ell_2$-bounded perturbations\nthat may be useful in few-shot learning scenarios. Our theoretical results are\nconfirmed by experiments on different datasets.",
    "descriptor": "",
    "authors": [
      "Mikhail Pautov",
      "Olesya Kuznetsova",
      "Nurislam Tursynbek",
      "Aleksandr Petiushko",
      "Ivan Oseledets"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01186"
  },
  {
    "id": "arXiv:2202.01197",
    "title": "VOS:Learning What You Don't Know by Virtual Outlier Synthesis",
    "abstract": "Out-of-distribution (OOD) detection has received much attention lately due to\nits importance in the safe deployment of neural networks. One of the key\nchallenges is that models lack supervision signals from unknown data, and as a\nresult, can produce overconfident predictions on OOD data. Previous approaches\nrely on real outlier datasets for model regularization, which can be costly and\nsometimes infeasible to obtain in practice. In this paper, we present VOS, a\nnovel framework for OOD detection by adaptively synthesizing virtual outliers\nthat can meaningfully regularize the model's decision boundary during training.\nSpecifically, VOS samples virtual outliers from the low-likelihood region of\nthe class-conditional distribution estimated in the feature space. Alongside,\nwe introduce a novel unknown-aware training objective, which contrastively\nshapes the uncertainty space between the ID data and synthesized outlier data.\nVOS achieves state-of-the-art performance on both object detection and image\nclassification models, reducing the FPR95 by up to 7.87% compared to the\nprevious best method. Code is available at\nhttps://github.com/deeplearning-wisc/vos.",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Xuefeng Du",
      "Zhaoning Wang",
      "Mu Cai",
      "Yixuan Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01197"
  },
  {
    "id": "arXiv:2202.01198",
    "title": "A Hybrid Compartmental Model with a Case Study of COVID-19 in Great  Britain and Israel",
    "abstract": "Given the severe impact of COVID-19 on several societal levels, it is of\ncrucial importance to model the impact of restriction measures on the pandemic\nevolution, so that governments are able to take informed decisions. Even though\nthere have been countless attempts to propose diverse models since the raise of\nthe outbreak, the increase in data availability and start of vaccination\ncampaigns calls for updated models and studies. Furthermore, most of the works\nare focused on a very particular place or application and we strive to attain a\nmore general model, resorting to data from different countries. In particular,\nwe compare Great Britain and Israel, two highly different scenarios in terms of\nvaccination plans and social structure. We build a network-based model, complex\nenough to model different scenarios of government-mandated restrictions, but\ngeneric enough to be applied to any population. To ease the computational load\nwe propose a decomposition strategy for our model.",
    "descriptor": "",
    "authors": [
      "Greta Malaspina",
      "Stevo Rackovi\u0107",
      "Filipa Valdeira"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2202.01198"
  },
  {
    "id": "arXiv:2202.00675",
    "title": "A training-free recursive multiresolution framework for diffeomorphic  deformable image registration",
    "abstract": "Diffeomorphic deformable image registration is one of the crucial tasks in\nmedical image analysis, which aims to find a unique transformation while\npreserving the topology and invertibility of the transformation. Deep\nconvolutional neural networks (CNNs) have yielded well-suited approaches for\nimage registration by learning the transformation priors from a large dataset.\nThe improvement in the performance of these methods is related to their ability\nto learn information from several sample medical images that are difficult to\nobtain and bias the framework to the specific domain of data. In this paper, we\npropose a novel diffeomorphic training-free approach; this is built upon the\nprinciple of an ordinary differential equation.\nOur formulation yields an Euler integration type recursive scheme to estimate\nthe changes of spatial transformations between the fixed and the moving image\npyramids at different resolutions. The proposed architecture is simple in\ndesign. The moving image is warped successively at each resolution and finally\naligned to the fixed image; this procedure is recursive in a way that at each\nresolution, a fully convolutional network (FCN) models a progressive change of\ndeformation for the current warped image. The entire system is end-to-end and\noptimized for each pair of images from scratch. In comparison to learning-based\nmethods, the proposed method neither requires a dedicated training set nor\nsuffers from any training bias. We evaluate our method on three cardiac image\ndatasets. The evaluation results demonstrate that the proposed method achieves\nstate-of-the-art registration accuracy while maintaining desirable\ndiffeomorphic properties.",
    "descriptor": "\nComments: 15 pages, 5 figures, 3 tables, 1 algorithm, The International Journal of Research on Intelligent Systems for Real Life Complex Problems\n",
    "authors": [
      "Ameneh Sheikhjafari",
      "Michelle Noga",
      "Kumaradevan Punithakumar",
      "Nilanjan Ray"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00675"
  },
  {
    "id": "arXiv:2202.00676",
    "title": "A deep residual learning implementation of Metamorphosis",
    "abstract": "In medical imaging, most of the image registration methods implicitly assume\na one-to-one correspondence between the source and target images (i.e.,\ndiffeomorphism). However, this is not necessarily the case when dealing with\npathological medical images (e.g., presence of a tumor, lesion, etc.). To cope\nwith this issue, the Metamorphosis model has been proposed. It modifies both\nthe shape and the appearance of an image to deal with the geometrical and\ntopological differences. However, the high computational time and load have\nhampered its applications so far. Here, we propose a deep residual learning\nimplementation of Metamorphosis that drastically reduces the computational time\nat inference. Furthermore, we also show that the proposed framework can easily\nintegrate prior knowledge of the localization of topological changes (e.g.,\nsegmentation masks) that can act as spatial regularization to correctly\ndisentangle appearance and shape changes. We test our method on the BraTS 2021\ndataset, showing that it outperforms current state-of-the-art methods in the\nalignment of images with brain tumors.",
    "descriptor": "\nComments: ISBI 2022\n",
    "authors": [
      "Matthis Maillard",
      "Anton Fran\u00e7ois",
      "Joan Glaun\u00e8s",
      "Isabelle Bloch",
      "Pietro Gori"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00676"
  },
  {
    "id": "arXiv:2202.00677",
    "title": "An Embarrassingly Simple Consistency Regularization Method for  Semi-Supervised Medical Image Segmentation",
    "abstract": "The scarcity of pixel-level annotation is a prevalent problem in medical\nimage segmentation tasks. In this paper, we introduce a novel regularization\nstrategy involving interpolation-based mixing for semi-supervised medical image\nsegmentation. The proposed method is a new consistency regularization strategy\nthat encourages segmentation of interpolation of two unlabelled data to be\nconsistent with the interpolation of segmentation maps of those data. This\nmethod represents a specific type of data-adaptive regularization paradigm\nwhich aids to minimize the overfitting of labelled data under high confidence\nvalues. The proposed method is advantageous over adversarial and generative\nmodels as it requires no additional computation. Upon evaluation on two\npublicly available MRI datasets: ACDC and MMWHS, experimental results\ndemonstrate the superiority of the proposed method in comparison to existing\nsemi-supervised models.",
    "descriptor": "\nComments: Accepted at ISBI 2022\n",
    "authors": [
      "Hritam Basak",
      "Rajarshi Bhattacharya",
      "Rukhshanda Hussain",
      "Agniv Chatterjee"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00677"
  },
  {
    "id": "arXiv:2202.00678",
    "title": "Classification of Skin Cancer Images using Convolutional Neural Networks",
    "abstract": "Skin cancer is the most common human malignancy(American Cancer Society)\nwhich is primarily diagnosed visually, starting with an initial clinical\nscreening and followed potentially by dermoscopic(related to skin) analysis, a\nbiopsy and histopathological examination. Skin cancer occurs when errors\n(mutations) occur in the DNA of skin cells. The mutations cause the cells to\ngrow out of control and form a mass of cancer cells. The aim of this study was\nto try to classify images of skin lesions with the help of convolutional neural\nnetworks. The deep neural networks show humongous potential for image\nclassification while taking into account the large variability exhibited by the\nenvironment. Here we trained images based on the pixel values and classified\nthem on the basis of disease labels. The dataset was acquired from an Open\nSource Kaggle Repository(Kaggle Dataset)which itself was acquired from\nISIC(International Skin Imaging Collaboration) Archive. The training was\nperformed on multiple models accompanied with Transfer Learning. The highest\nmodel accuracy achieved was over 86.65%. The dataset used is publicly available\nto ensure credibility and reproducibility of the aforementioned result.",
    "descriptor": "",
    "authors": [
      "Kartikeya Agarwal",
      "Tismeet Singh"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00678"
  },
  {
    "id": "arXiv:2202.00719",
    "title": "Point Cloud Compression for Efficient Data Broadcasting: A Performance  Comparison",
    "abstract": "The worldwide commercialization of fifth generation (5G) wireless networks\nand the exciting possibilities offered by connected and autonomous vehicles\n(CAVs) are pushing toward the deployment of heterogeneous sensors for tracking\ndynamic objects in the automotive environment. Among them, Light Detection and\nRanging (LiDAR) sensors are witnessing a surge in popularity as their\napplication to vehicular networks seem particularly promising. LiDARs can\nindeed produce a three-dimensional (3D) mapping of the surrounding environment,\nwhich can be used for object detection, recognition, and topography. These data\nare encoded as a point cloud which, when transmitted, may pose significant\nchallenges to the communication systems as it can easily congest the wireless\nchannel. Along these lines, this paper investigates how to compress point\nclouds in a fast and efficient way. Both 2D- and a 3D-oriented approaches are\nconsidered, and the performance of the corresponding techniques is analyzed in\nterms of (de)compression time, efficiency, and quality of the decompressed\nframe compared to the original. We demonstrate that, thanks to the matrix form\nin which LiDAR frames are saved, compression methods that are typically applied\nfor 2D images give equivalent results, if not better, than those specifically\ndesigned for 3D point clouds.",
    "descriptor": "\nComments: 6 pages, 5 figures, 1 table. This paper has been accepted for presentation at IEEE Wireless Communications and Networking Conference (WCNC) 2022. Please cite it as: F. Nardo, D. Peressoni, P. Testolina, M. Giordani, and A. Zanella, \"Point cloud compression for efficient data broadcasting: A performance comparison,\" IEEE Wireless Communications and Networking Conference (WCNC), Austin, USA, 2022\n",
    "authors": [
      "Francesco Nardo",
      "Davide Peressoni",
      "Paolo Testolina",
      "Marco Giordani",
      "Andrea Zanella"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.00719"
  },
  {
    "id": "arXiv:2202.00733",
    "title": "New Insights on Target Speaker Extraction",
    "abstract": "In recent years, researchers have become increasingly interested in speaker\nextraction (SE), which is the task of extracting the speech of a target speaker\nfrom a mixture of interfering speakers with the help of auxiliary information\nabout the target speaker. Several forms of auxiliary information have been\nemployed in single-channel SE, such as a speech snippet enrolled from the\ntarget speaker or visual information corresponding to the spoken utterance.\nMany SE studies have reported performance improvement compared to speaker\nseparation (SS) methods with oracle selection, arguing that this is due to the\nuse of auxiliary information. However, such works have not considered\nstate-of-the-art SS methods that have shown impressive separation performance.\nIn this paper, we revise and examine the role of the auxiliary information in\nSE. Specifically, we compare the performance of two SE systems (audio-based and\nvideo-based) with SS using a common framework that utilizes the\nstate-of-the-art dual-path recurrent neural network as the main learning\nmachine. In addition, we study how much the considered SE systems rely on the\nauxiliary information by analyzing the systems' output for random auxiliary\nsignals. Experimental evaluation on various datasets suggests that the main\npurpose of the auxiliary information in the considered SE systems is only to\nspecify the target speaker in the mixture and that it does not provide\nconsistent extraction performance gain when compared to the uninformed SS\nsystem.",
    "descriptor": "",
    "authors": [
      "Mohamed Elminshawi",
      "Wolfgang Mack",
      "Soumitro Chakrabarty",
      "Emanu\u00ebl A. P. Habets"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.00733"
  },
  {
    "id": "arXiv:2202.00749",
    "title": "Towards Positive Jacobian: Learn to Postprocess Diffeomorphic Image  Registration with Matrix Exponential",
    "abstract": "We present a postprocessing layer for deformable image registration to make a\nregistration field more diffeomorphic by encouraging Jacobians of the\ntransformation to be positive. Diffeomorphic image registration is important\nfor medical imaging studies because of the properties like invertibility,\nsmoothness of the transformation, and topology preservation/non-folding of the\ngrid. Violation of these properties can lead to destruction of the\nneighbourhood and the connectivity of anatomical structures during image\nregistration. Most of the recent deep learning methods do not explicitly\naddress this folding problem and try to solve it with a smoothness\nregularization on the registration field. In this paper, we propose a\ndifferentiable layer, which takes any registration field as its input, computes\nexponential of the Jacobian matrices of the input and reconstructs a new\nregistration field from the exponentiated Jacobian matrices using Poisson\nreconstruction. Our proposed Poisson reconstruction loss enforces positive\nJacobians for the final registration field. Thus, our method acts as a\npost-processing layer without any learnable parameters of its own and can be\nplaced at the end of any deep learning pipeline to form an end-to-end learnable\nframework. We show the effectiveness of our proposed method for a popular deep\nlearning registration method Voxelmorph and evaluate it with a dataset\ncontaining 3D brain MRI scans. Our results show that our post-processing can\neffectively decrease the number of non-positive Jacobians by a significant\namount without any noticeable deterioration of the registration accuracy, thus\nmaking the registration field more diffeomorphic. Our code is available online\nat\nhttps://github.com/Soumyadeep-Pal/Diffeomorphic-Image-Registration-Postprocess.",
    "descriptor": "",
    "authors": [
      "Soumyadeep Pal",
      "Matthew Tennant",
      "Nilanjan Ray"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00749"
  },
  {
    "id": "arXiv:2202.00755",
    "title": "Lagrangian Manifold Monte Carlo on Monge Patches",
    "abstract": "The efficiency of Markov Chain Monte Carlo (MCMC) depends on how the\nunderlying geometry of the problem is taken into account. For distributions\nwith strongly varying curvature, Riemannian metrics help in efficient\nexploration of the target distribution. Unfortunately, they have significant\ncomputational overhead due to e.g. repeated inversion of the metric tensor, and\ncurrent geometric MCMC methods using the Fisher information matrix to induce\nthe manifold are in practice slow. We propose a new alternative Riemannian\nmetric for MCMC, by embedding the target distribution into a higher-dimensional\nEuclidean space as a Monge patch and using the induced metric determined by\ndirect geometric reasoning. Our metric only requires first-order gradient\ninformation and has fast inverse and determinants, and allows reducing the\ncomputational complexity of individual iterations from cubic to quadratic in\nthe problem dimensionality. We demonstrate how Lagrangian Monte Carlo in this\nmetric efficiently explores the target distributions.",
    "descriptor": "",
    "authors": [
      "Marcelo Hartmann",
      "Mark Girolami",
      "Arto Klami"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00755"
  },
  {
    "id": "arXiv:2202.00782",
    "title": "Non-commutative Hermite--Pad\u00e9 approximation and integrability",
    "abstract": "We introduce and solve the non-commutative version of the Hermite-Pad\\'{e}\ntype I approximation problem. Its solution, expressed by quasideterminants,\nleads in a natural way to a subclass of solutions of the non-commutative Hirota\n(discrete Kadomtsev--Petviashvili) system and of its linear problem. We also\nprove integrability of the constrained system, which in the simplest case is\nthe non-commutative discrete-time Toda lattice equation known from the theory\nof non-commutative Pad\\'{e} approximants and matrix orthogonal polynomials.",
    "descriptor": "\nComments: 10 pages\n",
    "authors": [
      "Adam Doliwa"
    ],
    "subjectives": [
      "Exactly Solvable and Integrable Systems (nlin.SI)",
      "Mathematical Physics (math-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.00782"
  },
  {
    "id": "arXiv:2202.00792",
    "title": "AdaAnn: Adaptive Annealing Scheduler for Probability Density  Approximation",
    "abstract": "Approximating probability distributions can be a challenging task,\nparticularly when they are supported over regions of high geometrical\ncomplexity or exhibit multiple modes. Annealing can be used to facilitate this\ntask which is often combined with constant a priori selected increments in\ninverse temperature. However, using constant increments limit the computational\nefficiency due to the inability to adapt to situations where smooth changes in\nthe annealed density could be handled equally well with larger increments. We\nintroduce AdaAnn, an adaptive annealing scheduler that automatically adjusts\nthe temperature increments based on the expected change in the Kullback-Leibler\ndivergence between two distributions with a sufficiently close annealing\ntemperature. AdaAnn is easy to implement and can be integrated into existing\nsampling approaches such as normalizing flows for variational inference and\nMarkov chain Monte Carlo. We demonstrate the computational efficiency of the\nAdaAnn scheduler for variational inference with normalizing flows on a number\nof examples, including density approximation and parameter estimation for\ndynamical systems.",
    "descriptor": "",
    "authors": [
      "Emma R. Cobian",
      "Jonathan D. Hauenstein",
      "Fang Liu",
      "Daniele E. Schiavazzi"
    ],
    "subjectives": [
      "Computation (stat.CO)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00792"
  },
  {
    "id": "arXiv:2202.00803",
    "title": "Discrete Dirac reduction of implicit Lagrangian systems with abelian  symmetry groups",
    "abstract": "This paper develops the theory of discrete Dirac reduction of discrete\nLagrange-Dirac systems with an abelian symmetry group acting on the\nconfiguration space. We begin with the linear theory and, then, we extend it to\nthe nonlinear setting using retraction compatible charts. We consider the\nreduction of both the discrete Dirac structure and the discrete\nLagrange-Pontryagin principle, and show that they both lead to the same\ndiscrete Lagrange-Poincar\\'e-Dirac equations. The coordinatization of the\ndiscrete reduced spaces relies on the notion of discrete connections on\nprincipal bundles. At last, we demonstrate the method obtained by applying it\nto a charged particle in a magnetic field, and to the double spherical\npendulum.",
    "descriptor": "\nComments: 24 pages, 3 figures\n",
    "authors": [
      "\u00c1lvaro Rodr\u00edguez Abella",
      "Melvin Leok"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.00803"
  },
  {
    "id": "arXiv:2202.00812",
    "title": "Reinforcement learning of optimal active particle navigation",
    "abstract": "The development of self-propelled particles at the micro- and the nanoscale\nhas sparked a huge potential for future applications in active matter physics,\nmicrosurgery, and targeted drug delivery. However, while the latter\napplications provoke the quest on how to optimally navigate towards a target,\nsuch as e.g. a cancer cell, there is still no simple way known to determine the\noptimal route in sufficiently complex environments. Here we develop a machine\nlearning-based approach that allows us, for the first time, to determine the\nasymptotically optimal path of a self-propelled agent which can freely steer in\ncomplex environments. Our method hinges on policy gradient-based deep\nreinforcement learning techniques and, crucially, does not require any reward\nshaping or heuristics. The presented method provides a powerful alternative to\ncurrent analytical methods to calculate optimal trajectories and opens a route\ntowards a universal path planner for future intelligent active particles.",
    "descriptor": "",
    "authors": [
      "Mahdi Nasiri",
      "Benno Liebchen"
    ],
    "subjectives": [
      "Soft Condensed Matter (cond-mat.soft)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00812"
  },
  {
    "id": "arXiv:2202.00824",
    "title": "KSD Aggregated Goodness-of-fit Test",
    "abstract": "We investigate properties of goodness-of-fit tests based on the Kernel Stein\nDiscrepancy (KSD). We introduce a strategy to construct a test, called KSDAgg,\nwhich aggregates multiple tests with different kernels. KSDAgg avoids splitting\nthe data to perform kernel selection (which leads to a loss in test power), and\nrather maximises the test power over a collection of kernels. We provide\ntheoretical guarantees on the power of KSDAgg: we show it achieves the smallest\nuniform separation rate of the collection, up to a logarithmic term. KSDAgg can\nbe computed exactly in practice as it relies either on a parametric bootstrap\nor on a wild bootstrap to estimate the quantiles and the level corrections. In\nparticular, for the crucial choice of bandwidth of a fixed kernel, it avoids\nresorting to arbitrary heuristics (such as median or standard deviation) or to\ndata splitting. We find on both synthetic and real-world data that KSDAgg\noutperforms other state-of-the-art adaptive KSD-based goodness-of-fit testing\nprocedures.",
    "descriptor": "\nComments: 9 pages\n",
    "authors": [
      "Schrab Antonin",
      "Guedj Benjamin",
      "Gretton Arthur"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.00824"
  },
  {
    "id": "arXiv:2202.00842",
    "title": "Streaming Multi-Talker ASR with Token-Level Serialized Output Training",
    "abstract": "This paper proposes a token-level serialized output training (t-SOT), a novel\nframework for streaming multi-talker automatic speech recognition (ASR). Unlike\nexisting streaming multi-talker ASR models using multiple output layers, the\nt-SOT model has only a single output layer that generates recognition tokens\n(e.g., words, subwords) of multiple speakers in chronological order based on\ntheir emission times. A special token that indicates the change of \"virtual\"\noutput channels is introduced to keep track of the overlapping utterances.\nCompared to the prior streaming multi-talker ASR models, the t-SOT model has\nthe advantages of less inference cost and a simpler model architecture.\nMoreover, in our experiments with LibriSpeechMix and LibriCSS datasets, the\nt-SOT-based transformer transducer model achieves the state-of-the-art word\nerror rates by a significant margin to the prior results. For non-overlapping\nspeech, the t-SOT model is on par with a single-talker ASR model in terms of\nboth accuracy and computational cost, opening the door for deploying one model\nfor both single- and multi-talker scenarios.",
    "descriptor": "",
    "authors": [
      "Naoyuki Kanda",
      "Jian Wu",
      "Yu Wu",
      "Xiong Xiao",
      "Zhong Meng",
      "Xiaofei Wang",
      "Yashesh Gaur",
      "Zhuo Chen",
      "Jinyu Li",
      "Takuya Yoshioka"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.00842"
  },
  {
    "id": "arXiv:2202.00867",
    "title": "Efficient Algorithms for Learning to Control Bandits with Unobserved  Contexts",
    "abstract": "Contextual bandits are widely-used in the study of learning-based control\npolicies for finite action spaces. While the problem is well-studied for\nbandits with perfectly observed context vectors, little is known about the case\nof imperfectly observed contexts. For this setting, existing approaches are\ninapplicable and new conceptual and technical frameworks are required. We\npresent an implementable posterior sampling algorithm for bandits with\nimperfect context observations and study its performance for learning optimal\ndecisions. The provided numerical results relate the performance of the\nalgorithm to different quantities of interest including the number of arms,\ndimensions, observation matrices, posterior rescaling factors, and\nsignal-to-noise ratios. In general, the proposed algorithm exposes efficiency\nin learning from the noisy imperfect observations and taking actions\naccordingly. Enlightening understandings the analyses provide as well as\ninteresting future directions it points to, are discussed as well.",
    "descriptor": "\nComments: 12 pages, 4 figures\n",
    "authors": [
      "Hongju Park",
      "Mohamad Kazem Shirani Faradonbeh"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00867"
  },
  {
    "id": "arXiv:2202.00872",
    "title": "On the Effect of Log-Barrier Regularization in Decentralized Softmax  Gradient Play in Multiagent Systems",
    "abstract": "Softmax policy gradient is a popular algorithm for policy optimization in\nsingle-agent reinforcement learning, particularly since projection is not\nneeded for each gradient update. However, in multi-agent systems, the lack of\ncentral coordination introduces significant additional difficulties in the\nconvergence analysis. Even for a stochastic game with identical interest, there\ncan be multiple Nash Equilibria (NEs), which disables proof techniques that\nrely on the existence of a unique global optimum. Moreover, the softmax\nparameterization introduces non-NE policies with zero gradient, making\nNE-seeking difficult for gradient-based algorithms. In this paper, we study the\nfinite time convergence of decentralized softmax gradient play in a special\nform of game, Markov Potential Games (MPGs), which includes the identical\ninterest game as a special case. We investigate both gradient play and natural\ngradient play, with and without $\\log$-barrier regularization. Establishing\nconvergence for the unregularized cases relies on an assumption that the\nstationary policies are isolated, and yields convergence bounds that contain a\ntrajectory dependent constant that can be arbitrarily large. We introduce the\n$\\log$-barrier regularization to overcome these drawbacks, with the cost of\nslightly worse dependence on other factors such as the action set size. An\nempirical study on an identical interest matrix game confirms the theoretical\nfindings.",
    "descriptor": "",
    "authors": [
      "Runyu Zhang",
      "Jincheng Mei",
      "Bo Dai",
      "Dale Schuurmans",
      "Na Li"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.00872"
  },
  {
    "id": "arXiv:2202.00882",
    "title": "MPVNN: Mutated Pathway Visible Neural Network Architecture for  Interpretable Prediction of Cancer-specific Survival Risk",
    "abstract": "Survival risk prediction using gene expression data is important in making\ntreatment decisions in cancer. Standard neural network (NN) survival analysis\nmodels are black boxes with lack of interpretability. More interpretable\nvisible neural network (VNN) architectures are designed using biological\npathway knowledge. But they do not model how pathway structures can change for\nparticular cancer types. We propose a novel Mutated Pathway VNN or MPVNN\narchitecture, designed using prior signaling pathway knowledge and gene\nmutation data-based edge randomization simulating signal flow disruption. As a\ncase study, we use the PI3K-Akt pathway and demonstrate overall improved\ncancer-specific survival risk prediction results of MPVNN over standard non-NN\nand other similar sized NN survival analysis methods. We show that trained\nMPVNN architecture interpretation, which points to smaller sets of genes\nconnected by signal flow within the PI3K-Akt pathway that are important in risk\nprediction for particular cancer types, is reliable.",
    "descriptor": "\nComments: 11 pages, 2 figures\n",
    "authors": [
      "Gourab Ghosh Roy",
      "Nicholas Geard",
      "Karin Verspoor",
      "Shan He"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00882"
  },
  {
    "id": "arXiv:2202.00902",
    "title": "Matching Orderable and Separable Hypergraphs",
    "abstract": "A perfect matching in a hypergraph is a set of edges that partition the set\nof vertices. We study the complexity of deciding the existence of a perfect\nmatching in orderable and separable hypergraphs. We show that the class of\norderable hypergraphs is strictly contained in the class of separable\nhypergraphs. Accordingly, we show that for each fixed $k$, deciding perfect\nmatching for orderable $k$-hypergraphs is polynomial time doable, but for each\nfixed $k\\geq 3$, it is NP-complete for separable hypergraphs.",
    "descriptor": "",
    "authors": [
      "Shmuel Onn"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.00902"
  },
  {
    "id": "arXiv:2202.00913",
    "title": "Invariant Ancestry Search",
    "abstract": "Recently, methods have been proposed that exploit the invariance of\nprediction models with respect to changing environments to infer subsets of the\ncausal parents of a response variable. If the environments influence only few\nof the underlying mechanisms, the subset identified by invariant causal\nprediction, for example, may be small, or even empty. We introduce the concept\nof minimal invariance and propose invariant ancestry search (IAS). In its\npopulation version, IAS outputs a set which contains only ancestors of the\nresponse and is a superset of the output of ICP. When applied to data,\ncorresponding guarantees hold asymptotically if the underlying test for\ninvariance has asymptotic level and power. We develop scalable algorithms and\nperform experiments on simulated and real data.",
    "descriptor": "",
    "authors": [
      "Phillip B. Mogensen",
      "Nikolaj Thams",
      "Jonas Peters"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00913"
  },
  {
    "id": "arXiv:2202.00924",
    "title": "Designing Social Distancing Policies for the COVID-19 Pandemic: A  probabilistic model predictive control approach",
    "abstract": "The effective control of the COVID-19 pandemic is one the most challenging\nissues of nowadays. The design of optimal control policies is perplexed from a\nvariety of social, political, economical and epidemiological factors. Here,\nbased on epidemiological data reported in recent studies for the Italian region\nof Lombardy, which experienced one of the largest and most devastating\noutbreaks in Europe during the first wave of the pandemic, we address a\nprobabilistic model predictive control (PMPC) approach for the modelling and\nthe systematic study of what if scenarios of the social distancing in a\nretrospective analysis for the first wave of the pandemic in Lombardy. The\nperformance of the proposed PMPC scheme was assessed based on simulations of a\ncompartmental model that was developed to quantify the uncertainty in the level\nof the asymptomatic cases in the population, and the synergistic effect of\nsocial distancing in various activities, and public awareness campaign\nprompting people to adopt cautious behaviors to reduce the risk of disease\ntransmission. The PMPC scheme takes into account the social mixing effect, i.e.\nthe effect of the various activities in the potential transmission of the\ndisease. The proposed approach demonstrates the utility of a PMPC approach in\naddressing COVID-19 transmission and implementing public relaxation policies.",
    "descriptor": "",
    "authors": [
      "Antonis Armaou",
      "Bryce Katch",
      "Lucia Russo",
      "Constantinos Siettos"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Systems and Control (eess.SY)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.00924"
  },
  {
    "id": "arXiv:2202.00951",
    "title": "TONet: Tone-Octave Network for Singing Melody Extraction from Polyphonic  Music",
    "abstract": "Singing melody extraction is an important problem in the field of music\ninformation retrieval. Existing methods typically rely on frequency-domain\nrepresentations to estimate the sung frequencies. However, this design does not\nlead to human-level performance in the perception of melody information for\nboth tone (pitch-class) and octave. In this paper, we propose TONet, a\nplug-and-play model that improves both tone and octave perceptions by\nleveraging a novel input representation and a novel network architecture.\nFirst, we present an improved input representation, the Tone-CFP, that\nexplicitly groups harmonics via a rearrangement of frequency-bins. Second, we\nintroduce an encoder-decoder architecture that is designed to obtain a salience\nfeature map, a tone feature map, and an octave feature map. Third, we propose a\ntone-octave fusion mechanism to improve the final salience feature map.\nExperiments are done to verify the capability of TONet with various baseline\nbackbone models. Our results show that tone-octave fusion with Tone-CFP can\nsignificantly improve the singing voice extraction performance across various\ndatasets -- with substantial gains in octave and tone accuracy.",
    "descriptor": "\nComments: Preprint Version for ICASSP 2022, Singapore\n",
    "authors": [
      "Ke Chen",
      "Shuai Yu",
      "Cheng-i Wang",
      "Wei Li",
      "Taylor Berg-Kirkpatrick",
      "Shlomo Dubnov"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Multimedia (cs.MM)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.00951"
  },
  {
    "id": "arXiv:2202.00959",
    "title": "Efficient Random Walks on Riemannian Manifolds",
    "abstract": "According to a version of Donsker's theorem, geodesic random walks on\nRiemannian manifolds converge to the respective Brownian motion. From a\ncomputational perspective, however, evaluating geodesics can be quite costly.\nWe therefore introduce approximate geodesic random walks based on the concept\nof retractions. We show that these approximate walks converge to the correct\nBrownian motion in the Skorokhod topology as long as the geodesic equation is\napproximated up to second order. As a result we obtain an efficient algorithm\nfor sampling Brownian motion on compact Riemannian manifolds.",
    "descriptor": "",
    "authors": [
      "Michael Herrmann",
      "Simon Schwarz",
      "Anja Sturm",
      "Max Wardetzky"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Numerical Analysis (math.NA)",
      "Computation (stat.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.00959"
  },
  {
    "id": "arXiv:2202.00972",
    "title": "DCSAU-Net: A Deeper and More Compact Split-Attention U-Net for Medical  Image Segmentation",
    "abstract": "Image segmentation is a key step for medical image analysis. Approaches based\non deep neural networks have been introduced and performed more reliable\nresults than traditional image processing methods. However, many models focus\non one medical image application and still show limited abilities to work with\ncomplex images. In this paper, we propose a novel deeper and more compact\nsplit-attention u-shape network (DCSAU-Net) that extracts useful features using\nmulti-scale combined split-attention and deeper depthwise convolution. We\nevaluate the proposed model on CVC-ClinicDB, 2018 Data Science Bowl, ISIC-2018\nand SegPC-2021 datasets. As a result, DCSAU-Net displays better performance\nthan other state-of-the-art (SOTA) methods in terms of the mean Intersection\nover Union (mIoU) and F1-socre. More significantly, the proposed model\ndemonstrate better segmentation performance on challenging images.",
    "descriptor": "",
    "authors": [
      "Qing Xu",
      "Wenting Duan",
      "Na He"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00972"
  },
  {
    "id": "arXiv:2202.00975",
    "title": "VC-PCR: A Prediction Method based on Supervised Variable Selection and  Clustering",
    "abstract": "Sparse linear prediction methods suffer from decreased prediction accuracy\nwhen the predictor variables have cluster structure (e.g. there are highly\ncorrelated groups of variables). To improve prediction accuracy, various\nmethods have been proposed to identify variable clusters from the data and\nintegrate cluster information into a sparse modeling process. But none of these\nmethods achieve satisfactory performance for prediction, variable selection and\nvariable clustering simultaneously. This paper presents Variable Cluster\nPrincipal Component Regression (VC-PCR), a prediction method that supervises\nvariable selection and variable clustering in order to solve this problem.\nExperiments with real and simulated data demonstrate that, compared to\ncompetitor methods, VC-PCR achieves better prediction, variable selection and\nclustering performance when cluster structure is present.",
    "descriptor": "",
    "authors": [
      "Rebecca Marion",
      "Johannes Lederer",
      "Bernadette Govaerts",
      "Rainer von Sachs"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.00975"
  },
  {
    "id": "arXiv:2202.00986",
    "title": "Posterior temperature optimized Bayesian models for inverse problems in  medical imaging",
    "abstract": "We present Posterior Temperature Optimized Bayesian Inverse Models (POTOBIM),\nan unsupervised Bayesian approach to inverse problems in medical imaging using\nmean-field variational inference with a fully tempered posterior. Bayesian\nmethods exhibit useful properties for approaching inverse tasks, such as\ntomographic reconstruction or image denoising. A suitable prior distribution\nintroduces regularization, which is needed to solve the ill-posed problem and\nreduces overfitting the data. In practice, however, this often results in a\nsuboptimal posterior temperature, and the full potential of the Bayesian\napproach is not being exploited. In POTOBIM, we optimize both the parameters of\nthe prior distribution and the posterior temperature with respect to\nreconstruction accuracy using Bayesian optimization with Gaussian process\nregression. Our method is extensively evaluated on four different inverse tasks\non a variety of modalities with images from public data sets and we demonstrate\nthat an optimized posterior temperature outperforms both non-Bayesian and\nBayesian approaches without temperature optimization. The use of an optimized\nprior distribution and posterior temperature leads to improved accuracy and\nuncertainty estimation and we show that it is sufficient to find these\nhyperparameters per task domain. Well-tempered posteriors yield calibrated\nuncertainty, which increases the reliability in the predictions. Our source\ncode is publicly available at github.com/Cardio-AI/mfvi-dip-mia.",
    "descriptor": "\nComments: Accepted at Medical Image Analysis\n",
    "authors": [
      "Max-Heinrich Laves",
      "Malte T\u00f6lle",
      "Alexander Schlaefer",
      "Sandy Engelhardt"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00986"
  },
  {
    "id": "arXiv:2202.00990",
    "title": "Dictionary learning for clustering on hyperspectral images",
    "abstract": "Dictionary learning and sparse coding have been widely studied as mechanisms\nfor unsupervised feature learning. Unsupervised learning could bring enormous\nbenefit to the processing of hyperspectral images and to other remote sensing\ndata analysis because labelled data are often scarce in this field. We propose\na method for clustering the pixels of hyperspectral images using sparse\ncoefficients computed from a representative dictionary as features. We show\nempirically that the proposed method works more effectively than clustering on\nthe original pixels. We also demonstrate that our approach, in certain\ncircumstances, outperforms the clustering results of features extracted using\nprincipal component analysis and non-negative matrix factorisation.\nFurthermore, our method is suitable for applications in repetitively clustering\nan ever-growing amount of high-dimensional data, which is the case when working\nwith hyperspectral satellite imagery.",
    "descriptor": "\nComments: Springer Machine Learning Journal, 8 pages, 3 figures\n",
    "authors": [
      "Joshua Bruton",
      "Hairong Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00990"
  },
  {
    "id": "arXiv:2202.00992",
    "title": "Tight Convergence Rate Bounds for Optimization Under Power Law Spectral  Conditions",
    "abstract": "Performance of optimization on quadratic problems sensitively depends on the\nlow-lying part of the spectrum. For large (effectively infinite-dimensional)\nproblems, this part of the spectrum can often be naturally represented or\napproximated by power law distributions. In this paper we perform a systematic\nstudy of a range of classical single-step and multi-step first order\noptimization algorithms, with adaptive and non-adaptive, constant and\nnon-constant learning rates: vanilla Gradient Descent, Steepest Descent, Heavy\nBall, and Conjugate Gradients. For each of these, we prove that a power law\nspectral assumption entails a power law for convergence rate of the algorithm,\nwith the convergence rate exponent given by a specific multiple of the spectral\nexponent. We establish both upper and lower bounds, showing that the results\nare tight. Finally, we demonstrate applications of these results to kernel\nlearning and training of neural networks in the NTK regime.",
    "descriptor": "",
    "authors": [
      "Maksim Velikanov",
      "Dmitry Yarotsky"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.00992"
  },
  {
    "id": "arXiv:2202.00995",
    "title": "MD-GAN with multi-particle input: the machine learning of long-time  molecular behavior from short-time MD data",
    "abstract": "MD-GAN is a machine learning-based method that can evolve part of the system\nat any time step, accelerating the generation of molecular dynamics data. For\nthe accurate prediction of MD-GAN, sufficient information on the dynamics of a\npart of the system should be included with the training data. Therefore, the\nselection of the part of the system is important for efficient learning. In a\nprevious study, only one particle (or vector) of each molecule was extracted as\npart of the system. Therefore, we investigated the effectiveness of adding\ninformation from other particles to the learning process. In the experiment of\nthe polyethylene system, when the dynamics of three particles of each molecule\nwere used, the diffusion was successfully predicted using one-third of the time\nlength of the training data, compared to the single-particle input.\nSurprisingly, the unobserved transition of diffusion in the training data was\nalso predicted using this method.",
    "descriptor": "",
    "authors": [
      "Ryo Kawada",
      "Katsuhiro Endo",
      "Daisuke Yuhara",
      "Kenji Yasuoka"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00995"
  },
  {
    "id": "arXiv:2202.00997",
    "title": "Gradient Variance Loss for Structure-Enhanced Image Super-Resolution",
    "abstract": "Recent success in the field of single image super-resolution (SISR) is\nachieved by optimizing deep convolutional neural networks (CNNs) in the image\nspace with the L1 or L2 loss. However, when trained with these loss functions,\nmodels usually fail to recover sharp edges present in the high-resolution (HR)\nimages for the reason that the model tends to give a statistical average of\npotential HR solutions. During our research, we observe that gradient maps of\nimages generated by the models trained with the L1 or L2 loss have\nsignificantly lower variance than the gradient maps of the original\nhigh-resolution images. In this work, we propose to alleviate the above issue\nby introducing a structure-enhancing loss function, coined Gradient Variance\n(GV) loss, and generate textures with perceptual-pleasant details.\nSpecifically, during the training of the model, we extract patches from the\ngradient maps of the target and generated output, calculate the variance of\neach patch and form variance maps for these two images. Further, we minimize\nthe distance between the computed variance maps to enforce the model to produce\nhigh variance gradient maps that will lead to the generation of high-resolution\nimages with sharper edges. Experimental results show that the GV loss can\nsignificantly improve both Structure Similarity (SSIM) and peak signal-to-noise\nratio (PSNR) performance of existing image super-resolution (SR) deep learning\nmodels.",
    "descriptor": "\nComments: ICASSP 2022\n",
    "authors": [
      "Lusine Abrahamyan",
      "Anh Minh Truong",
      "Wilfried Philips",
      "Nikos Deligiannis"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.00997"
  },
  {
    "id": "arXiv:2202.01020",
    "title": "MedNeRF: Medical Neural Radiance Fields for Reconstructing 3D-aware  CT-Projections from a Single X-ray",
    "abstract": "Computed tomography (CT) is an effective medical imaging modality, widely\nused in the field of clinical medicine for the diagnosis of various\npathologies. Advances in Multidetector CT imaging technology have enabled\nadditional functionalities, including generation of thin slice multiplanar\ncross-sectional body imaging and 3D reconstructions. However, this involves\npatients being exposed to a considerable dose of ionising radiation. Excessive\nionising radiation can lead to deterministic and harmful effects on the body.\nThis paper proposes a Deep Learning model that learns to reconstruct CT\nprojections from a few or even a single-view X-ray. This is based on a novel\narchitecture that builds from neural radiance fields, which learns a continuous\nrepresentation of CT scans by disentangling the shape and volumetric depth of\nsurface and internal anatomical structures from 2D images. Our model is trained\non chest and knee datasets, and we demonstrate qualitative and quantitative\nhigh-fidelity renderings and compare our approach to other recent radiance\nfield-based methods. Our code and link to our datasets will be available at our\nGitHub.",
    "descriptor": "\nComments: 6 pages, 4 figures, submitted to IEEE EMBC 2022\n",
    "authors": [
      "Abril Corona-Figueroa",
      "Jonathan Frawley",
      "Sam Bond-Taylor",
      "Sarath Bethapudi",
      "Hubert P. H. Shum",
      "Chris G. Willcocks"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01020"
  },
  {
    "id": "arXiv:2202.01051",
    "title": "Element selection for functional materials discovery by integrated  machine learning of atomic contributions to properties",
    "abstract": "At the high level, the fundamental differences between materials originate\nfrom the unique nature of the constituent chemical elements. Before specific\ndifferences emerge according to the precise ratios of elements (composition) in\na given crystal structure (phase), the material can be represented by its phase\nfield defined simply as the set of the constituent chemical elements.\nClassification of the materials at the level of their phase fields can\naccelerate materials discovery by selecting the elemental combinations that are\nlikely to produce desirable functional properties in synthetically accessible\nmaterials. Here, we demonstrate that classification of the materials phase\nfield with respect to the maximum expected value of a target functional\nproperty can be combined with the ranking of the materials synthetic\naccessibility. This end-to-end machine learning approach (PhaseSelect) first\nderives the atomic characteristics from the compositional environments in all\ncomputationally and experimentally explored materials and then employs these\ncharacteristics to classify the phase field by their merit. PhaseSelect can\nquantify the materials potential at the level of the periodic table, which we\ndemonstrate with significant accuracy for three avenues of materials\napplications: high-temperature superconducting, high-temperature magnetic and\ntargetted energy band gap materials.",
    "descriptor": "",
    "authors": [
      "Andrij Vasylenko",
      "Dmytro Antypov",
      "Vladimir Gusev",
      "Michael W. Gaultois",
      "Matthew S. Dyer",
      "Matthew J. Rosseinsky"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Superconductivity (cond-mat.supr-con)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01051"
  },
  {
    "id": "arXiv:2202.01054",
    "title": "Improved quantum algorithms for linear and nonlinear differential  equations",
    "abstract": "We present substantially generalized and improved quantum algorithms over\nprior work for inhomogeneous linear and nonlinear ordinary differential\nequations (ODE). In Berry et al., (2017), a quantum algorithm for a certain\nclass of linear ODEs is given, where the matrix involved needs to be\ndiagonalizable. The quantum algorithm for linear ODEs presented here extends to\nmany classes of non-diagonalizable matrices. The algorithm here can also be\nexponentially faster for certain classes of diagonalizable matrices. Our linear\nODE algorithm is then applied to nonlinear differential equations using\nCarleman linearization (an approach taken recently by us in Liu et al.,\n(2021)). The improvement over that result is two-fold. First, we obtain an\nexponentially better dependence on error. This kind of logarithmic dependence\non error has also been achieved by Xue et al., (2021), but only for homogeneous\nnonlinear equations. Second, the present algorithm can handle any sparse,\ninvertible matrix (that models dissipation) if it has a negative log-norm\n(including non-diagonalizable matrices), whereas Liu et al., (2021) and Xue et\nal., (2021) additionally require normality.",
    "descriptor": "\nComments: 27 pages, 1 figure\n",
    "authors": [
      "Hari Krovi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)",
      "Plasma Physics (physics.plasm-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.01054"
  },
  {
    "id": "arXiv:2202.01079",
    "title": "AlphaDesign: A graph protein design method and benchmark on AlphaFoldDB",
    "abstract": "While DeepMind has tentatively solved protein folding, its inverse problem --\nprotein design which predicts protein sequences from their 3D structures --\nstill faces significant challenges. Particularly, the lack of large-scale\nstandardized benchmark and poor accuray hinder the research progress. In order\nto standardize comparisons and draw more research interest, we use AlphaFold\nDB, one of the world's largest protein structure databases, to establish a new\ngraph-based benchmark -- AlphaDesign. Based on AlphaDesign, we propose a new\nmethod called ADesign to improve accuracy by introducing protein angles as new\nfeatures, using a simplified graph transformer encoder (SGT), and proposing a\nconfidence-aware protein decoder (CPD). Meanwhile, SGT and CPD also improve\nmodel efficiency by simplifying the training and testing procedures.\nExperiments show that ADesign significantly outperforms previous graph models,\ne.g., the average accuracy is improved by 8\\%, and the inference speed is 40+\ntimes faster than before.",
    "descriptor": "",
    "authors": [
      "Zhangyang Gao",
      "Cheng Tan",
      "Stan. Z Li"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01079"
  },
  {
    "id": "arXiv:2202.01092",
    "title": "The CORAL++ Algorithm for Unsupervised Domain Adaptation of Speaker  Recogntion",
    "abstract": "State-of-the-art speaker recognition systems are trained with a large amount\nof human-labeled training data set. Such a training set is usually composed of\nvarious data sources to enhance the modeling capability of models. However, in\npractical deployment, unseen condition is almost inevitable. Domain mismatch is\na common problem in real-life applications due to the statistical difference\nbetween the training and testing data sets. To alleviate the degradation caused\nby domain mismatch, we propose a new feature-based unsupervised domain\nadaptation algorithm. The algorithm we propose is a further optimization based\non the well-known CORrelation ALignment (CORAL), so we call it CORAL++. On the\nNIST 2019 Speaker Recognition Evaluation (SRE19), we use SRE18 CTS set as the\ndevelopment set to verify the effectiveness of CORAL++. With the typical\nx-vector/PLDA setup, the CORAL++ outperforms the CORAL by 9.40% relatively on\nEER.",
    "descriptor": "\nComments: 5 pages, 1 figures. This paper has been accepted to IEEE ICASSP 2022\n",
    "authors": [
      "Rongjin Li",
      "Weibin Zhang",
      "Dongpeng Chen"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.01092"
  },
  {
    "id": "arXiv:2202.01094",
    "title": "RescoreBERT: Discriminative Speech Recognition Rescoring with BERT",
    "abstract": "Second-pass rescoring is an important component in automatic speech\nrecognition (ASR) systems that is used to improve the outputs from a first-pass\ndecoder by implementing a lattice rescoring or $n$-best re-ranking. While\npretraining with a masked language model (MLM) objective has received great\nsuccess in various natural language understanding (NLU) tasks, it has not\ngained traction as a rescoring model for ASR. Specifically, training a\nbidirectional model like BERT on a discriminative objective such as minimum WER\n(MWER) has not been explored. Here we where show how to train a BERT-based\nrescoring model with MWER loss, to incorporate the improvements of a\ndiscriminative loss into fine-tuning of deep bidirectional pretrained models\nfor ASR. We propose a fusion strategy that incorporates the MLM into the\ndiscriminative training process to effectively distill the knowledge from a\npretrained model. We further propose an alternative discriminative loss. We\nname this approach RescoreBERT, and evaluate it on the LibriSpeech corpus, and\nit reduces WER by 6.6%/3.4% relative on clean/other test sets over a BERT\nbaseline without discriminative objective. We also evaluate our method on an\ninternal dataset from a conversational agent and find that it reduces both\nlatency and WER (by 3-8% relative) over an LSTM rescoring model.",
    "descriptor": "\nComments: Accepted to ICASSP 2022\n",
    "authors": [
      "Liyan Xu",
      "Yile Gu",
      "Jari Kolehmainen",
      "Haidar Khan",
      "Ankur Gandhe",
      "Ariya Rastrow",
      "Andreas Stolcke",
      "Ivan Bulyko"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.01094"
  },
  {
    "id": "arXiv:2202.01113",
    "title": "Tailoring Gradient Methods for Differentially-Private Distributed  Optimization",
    "abstract": "Decentralized optimization is gaining increased traction due to its\nwidespread applications in large-scale machine learning and multi-agent\nsystems. The same mechanism that enables its success, i.e., information sharing\namong participating agents, however, also leads to the disclosure of individual\nagents' private information, which is unacceptable when sensitive data are\ninvolved. As differential privacy is becoming a de facto standard for privacy\npreservation, recently results have emerged integrating differential privacy\nwith distributed optimization. Although such differential-privacy based privacy\napproaches for distributed optimization are efficient in both computation and\ncommunication, directly incorporating differential privacy design in existing\ndistributed optimization approaches significantly compromises optimization\naccuracy. In this paper, we propose to redesign and tailor gradient methods for\ndifferentially-private distributed optimization, and propose two\ndifferential-privacy oriented gradient methods that can ensure both privacy and\noptimality. We prove that the proposed distributed algorithms can ensure almost\nsure convergence to an optimal solution under any persistent and\nvariance-bounded differential-privacy noise, which, to the best of our\nknowledge, has not been reported before. The first algorithm is based on\nstatic-consensus based gradient methods and only shares one variable in each\niteration. The second algorithm is based on dynamic-consensus\n(gradient-tracking) based distributed optimization methods and, hence, it is\napplicable to general directed interaction graph topologies. Numerical\ncomparisons with existing counterparts confirm the effectiveness of the\nproposed approaches.",
    "descriptor": "",
    "authors": [
      "Yongqiang Wang",
      "Angelia Nedic"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.01113"
  },
  {
    "id": "arXiv:2202.01116",
    "title": "Unpaired Image Super-Resolution with Optimal Transport Maps",
    "abstract": "Real-world image super-resolution (SR) tasks often do not have paired\ndatasets limiting the application of supervised techniques. As a result, the\ntasks are usually approached by unpaired techniques based on Generative\nAdversarial Networks (GANs) which yield complex training losses with several\nregularization terms such as content and identity losses. We theoretically\ninvestigate the optimization problems which arise in such models and find two\nsurprising observations. First, the learned SR map is always an optimal\ntransport (OT) map. Second, we empirically show that the learned map is biased,\ni.e., it may not actually transform the distribution of low-resolution images\nto high-resolution images. Inspired by these findings, we propose an algorithm\nfor unpaired SR which learns an unbiased OT map for the perceptual transport\ncost. Unlike existing GAN-based alternatives, our algorithm has a simple\noptimization objective reducing the neccesity to perform complex hyperparameter\nselection and use additional regularizations. At the same time, it provides\nnearly state-of-the-art performance on the large-scale unpaired AIM-19 dataset.",
    "descriptor": "",
    "authors": [
      "Milena Gazdieva",
      "Litu Rout",
      "Alexander Korotin",
      "Alexander Filippov",
      "Evgeny Burnaev"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.01116"
  },
  {
    "id": "arXiv:2202.01125",
    "title": "GLISp-r: A preference-based optimization algorithm with convergence  guarantees",
    "abstract": "Preference-based optimization algorithms are iterative procedures that seek\nthe optimal value for a decision variable based only on comparisons between\ncouples of different samples. At each iteration, a human decision-maker is\nasked to express a preference between two samples, highlighting which one, if\nany, is better than the other. The optimization procedure must use the observed\npreferences to find the value of the decision variable that is most preferred\nby the human decision-maker, while also minimizing the number of comparisons.\nIn this work, we propose GLISp-r, an extension of a recent preference-based\noptimization procedure called GLISp. The latter uses a Radial Basis Function\nsurrogate to describe the tastes of the individual. Iteratively, GLISp proposes\nnew samples to compare with the current best candidate by trading off\nexploitation of the surrogate model and exploration of the decision space. In\nGLISp-r, we propose a different criterion to use when looking for a new\ncandidate sample that is inspired by MSRS, a popular procedure in the black-box\noptimization framework (which is closely related to the preference-based one).\nCompared to GLISp, GLISp-r is less likely to get stuck on local optimizers of\nthe preference-based optimization problem. We motivate this claim\ntheoretically, with a proof of convergence, and empirically, by comparing the\nperformances of GLISp and GLISp-r on different benchmark optimization problems.",
    "descriptor": "\nComments: 26 pages, 8 figures and 3 tables\n",
    "authors": [
      "Davide Previtali",
      "Mirko Mazzoleni",
      "Antonio Ferramosca",
      "Fabio Previdi"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01125"
  },
  {
    "id": "arXiv:2202.01130",
    "title": "Well-posedness and dynamics of solutions to the generalized KdV with low  power nonlinearity",
    "abstract": "We consider two types of the generalized Korteweg - de Vries equation, where\nthe nonlinearity is given with or without absolute values, and, in particular,\nincluding the low powers of nonlinearity, an example of which is the Schamel\nequation. We first prove the local well-posedness of both equations in a\nweighted subspace of $H^1$ that includes functions with polynomial decay,\nextending the result of Linares et al [39] to fractional weights. We then\ninvestigate solutions numerically, confirming the well-posedness and extending\nit to a wider class of functions that includes exponential decay. We include a\ncomparison of solutions to both types of equations, in particular, we\ninvestigate soliton resolution for the positive and negative data with\ndifferent decay rates. Finally, we study the interaction of various solitary\nwaves in both models, showing the formation of solitons, dispersive radiation\nand even breathers, all of which are easier to track in nonlinearities with\nlower power.",
    "descriptor": "",
    "authors": [
      "Isaac Friedman",
      "Oscar Ria\u00f1o",
      "Svetlana Roudenko",
      "Diana Son",
      "Kai Yang"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.01130"
  },
  {
    "id": "arXiv:2202.01185",
    "title": "Heterogeneous manifolds for curvature-aware graph embedding",
    "abstract": "Graph embeddings, wherein the nodes of the graph are represented by points in\na continuous space, are used in a broad range of Graph ML applications. The\nquality of such embeddings crucially depends on whether the geometry of the\nspace matches that of the graph. Euclidean spaces are often a poor choice for\nmany types of real-world graphs, where hierarchical structure and a power-law\ndegree distribution are linked to negative curvature. In this regard, it has\nrecently been shown that hyperbolic spaces and more general manifolds, such as\nproducts of constant-curvature spaces and matrix manifolds, are advantageous to\napproximately match nodes pairwise distances. However, all these classes of\nmanifolds are homogeneous, implying that the curvature distribution is the same\nat each point, making them unsuited to match the local curvature (and related\nstructural properties) of the graph. In this paper, we study graph embeddings\nin a broader class of heterogeneous rotationally-symmetric manifolds. By adding\na single extra radial dimension to any given existing homogeneous model, we can\nboth account for heterogeneous curvature distributions on graphs and pairwise\ndistances. We evaluate our approach on reconstruction tasks on synthetic and\nreal datasets and show its potential in better preservation of high-order\nstructures and heterogeneous random graphs generation.",
    "descriptor": "",
    "authors": [
      "Francesco Di Giovanni",
      "Giulia Luise",
      "Michael Bronstein"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01185"
  },
  {
    "id": "arXiv:2202.01195",
    "title": "Mitigating cold start problems in drug-target affinity prediction with  interaction knowledge transferring",
    "abstract": "Motivation: Predicting the drug-target interaction is crucial for drug\ndiscovery as well as drug repurposing. Machine learning is commonly used in\ndrug-target affinity (DTA) problem. However, machine learning model faces the\ncold-start problem where the model performance drops when predicting the\ninteraction of a novel drug or target. Previous works try to solve the cold\nstart problem by learning the drug or target representation using unsupervised\nlearning. While the drug or target representation can be learned in an\nunsupervised manner, it still lacks the interaction information, which is\ncritical in drug-target interaction. Results: To incorporate the interaction\ninformation into the drug and protein interaction, we proposed using transfer\nlearning from chemical-chemical interaction (CCI) and protein-protein\ninteraction (PPI) task to drug-target interaction task. The representation\nlearned by CCI and PPI tasks can be transferred smoothly to the DTA task due to\nthe similar nature of the tasks. The result on the drug-target affinity\ndatasets shows that our proposed method has advantages compared to other\npretraining methods in the DTA task.",
    "descriptor": "",
    "authors": [
      "Tri Minh Nguyen",
      "Thin Nguyen",
      "Truyen Tran"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.01195"
  },
  {
    "id": "arXiv:1103.4723",
    "title": "Automatic Extraction of Open Space Area from High Resolution Urban  Satellite Imagery",
    "abstract": "Comments: Use of wrong data in calculations",
    "descriptor": "\nComments: Use of wrong data in calculations\n",
    "authors": [
      "B. G. Kodge",
      "P. S. Hiremath"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/1103.4723"
  },
  {
    "id": "arXiv:1701.06937",
    "title": "Optimizing tree decompositions in MSO",
    "abstract": "Optimizing tree decompositions in MSO",
    "descriptor": "",
    "authors": [
      "Miko\u0142aj Boja\u0144czyk",
      "Micha\u0142 Pilipczuk"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1701.06937"
  },
  {
    "id": "arXiv:1808.02759",
    "title": "A Class of Multirate Infinitesimal GARK Methods",
    "abstract": "A Class of Multirate Infinitesimal GARK Methods",
    "descriptor": "",
    "authors": [
      "Adrian Sandu"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1808.02759"
  },
  {
    "id": "arXiv:1809.06266",
    "title": "A Strongly Polynomial Algorithm for Linear Exchange Markets",
    "abstract": "A Strongly Polynomial Algorithm for Linear Exchange Markets",
    "descriptor": "",
    "authors": [
      "Jugal Garg",
      "L\u00e1szl\u00f3 A. V\u00e9gh"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/1809.06266"
  },
  {
    "id": "arXiv:1810.09177",
    "title": "Compositional Coding Capsule Network with K-Means Routing for Text  Classification",
    "abstract": "Comments: the paper is under consideration at Pattern Recognition Letters",
    "descriptor": "\nComments: the paper is under consideration at Pattern Recognition Letters\n",
    "authors": [
      "Hao Ren",
      "Hong Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1810.09177"
  },
  {
    "id": "arXiv:1908.00063",
    "title": "Intrinsic Interleaving Distance for Merge Trees",
    "abstract": "Intrinsic Interleaving Distance for Merge Trees",
    "descriptor": "",
    "authors": [
      "Ellen Gasparovic",
      "Elizabeth Munch",
      "Steve Oudot",
      "Katharine Turner",
      "Bei Wang",
      "Yusu Wang"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/1908.00063"
  },
  {
    "id": "arXiv:1908.03894",
    "title": "Lectures on error analysis of interpolation on simplicial triangulations  without the shape-regularity assumption Part 1: Lagrange interpolation on  triangles",
    "abstract": "Lectures on error analysis of interpolation on simplicial triangulations  without the shape-regularity assumption Part 1: Lagrange interpolation on  triangles",
    "descriptor": "",
    "authors": [
      "Kenta Kobayashi",
      "Takuya Tsuchiya"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/1908.03894"
  },
  {
    "id": "arXiv:1909.03212",
    "title": "AutoML for Contextual Bandits",
    "abstract": "Comments: Presented(peer-reviewed) at the REVEAL Workshop at the ACM RecSys Conference Copenhagen'19 [this https URL]",
    "descriptor": "\nComments: Presented(peer-reviewed) at the REVEAL Workshop at the ACM RecSys Conference Copenhagen'19 [this https URL]\n",
    "authors": [
      "Praneet Dutta",
      "Joe Cheuk",
      "Jonathan S Kim",
      "Massimo Mascaro"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1909.03212"
  },
  {
    "id": "arXiv:1911.03063",
    "title": "Is a Classification Procedure Good Enough? A Goodness-of-Fit Assessment  Tool for Classification Learning",
    "abstract": "Is a Classification Procedure Good Enough? A Goodness-of-Fit Assessment  Tool for Classification Learning",
    "descriptor": "",
    "authors": [
      "Jiawei Zhang",
      "Jie Ding",
      "Yuhong Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1911.03063"
  },
  {
    "id": "arXiv:1912.10989",
    "title": "Finding Optimal Triangulations Parameterized by Edge Clique Cover",
    "abstract": "Comments: 28 pages, 3 figures, appeared in IPEC'20, to appear in Algorithmica special issue of IPEC'20",
    "descriptor": "\nComments: 28 pages, 3 figures, appeared in IPEC'20, to appear in Algorithmica special issue of IPEC'20\n",
    "authors": [
      "Tuukka Korhonen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/1912.10989"
  },
  {
    "id": "arXiv:2002.08131",
    "title": "A Systematic Comparison of Architectures for Document-Level Sentiment  Classification",
    "abstract": "Comments: 5 pages, 2 figures",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Jeremy Barnes",
      "Vinit Ravishankar",
      "Lilja \u00d8vrelid",
      "Erik Velldal"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2002.08131"
  },
  {
    "id": "arXiv:2003.13749",
    "title": "The Operating System of the Neuromorphic BrainScaleS-1 System",
    "abstract": "The Operating System of the Neuromorphic BrainScaleS-1 System",
    "descriptor": "",
    "authors": [
      "Eric M\u00fcller",
      "Sebastian Schmitt",
      "Christian Mauch",
      "Sebastian Billaudelle",
      "Andreas Gr\u00fcbl",
      "Maurice G\u00fcttler",
      "Dan Husmann",
      "Joscha Ilmberger",
      "Sebastian Jeltsch",
      "Jakob Kaiser",
      "Johann Kl\u00e4hn",
      "Mitja Kleider",
      "Christoph Koke",
      "Jos\u00e9 Montes",
      "Paul M\u00fcller",
      "Johannes Partzsch",
      "Felix Passenberg",
      "Hartmut Schmidt",
      "Bernhard Vogginger",
      "Jonas Weidner",
      "Christian Mayr",
      "Johannes Schemmel"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2003.13749"
  },
  {
    "id": "arXiv:2004.09608",
    "title": "Flow-based Algorithms for Improving Clusters: A Unifying Framework,  Software, and Performance",
    "abstract": "Comments: 75 Pages, 21 Figures",
    "descriptor": "\nComments: 75 Pages, 21 Figures\n",
    "authors": [
      "K. Fountoulakis",
      "M. Liu",
      "D. F. Gleich",
      "M. W. Mahoney"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.09608"
  },
  {
    "id": "arXiv:2006.01106",
    "title": "Exit Time Analysis for Approximations of Gradient Descent Trajectories  Around Saddle Points",
    "abstract": "Comments: 61 pages; substantial revision of the first version, including expanded comparisons with existing works and new numerical results",
    "descriptor": "\nComments: 61 pages; substantial revision of the first version, including expanded comparisons with existing works and new numerical results\n",
    "authors": [
      "Rishabh Dixit",
      "Mert Gurbuzbalaban",
      "Waheed U. Bajwa"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2006.01106"
  },
  {
    "id": "arXiv:2006.12789",
    "title": "Value-oriented Legal Reasoning in LogiKEy: Methodology and Case Study",
    "abstract": "Comments: 56 pages, 21 figures; extended and improved version of our contribution to the 1st Workshop on Models of Legal Reasoning (MLR 2020)",
    "descriptor": "\nComments: 56 pages, 21 figures; extended and improved version of our contribution to the 1st Workshop on Models of Legal Reasoning (MLR 2020)\n",
    "authors": [
      "Christoph Benzm\u00fcller",
      "David Fuenmayor",
      "Bertram Lomfeld"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2006.12789"
  },
  {
    "id": "arXiv:2007.10529",
    "title": "Blockchain Meets COVID-19: A Framework for Contact Information Sharing  and Risk Notification System",
    "abstract": "Comments: 11 pages, 7 figures, this work has been accepted by IEEE International Conference on Mobile Ad-Hoc and Smart Systems (MASS) 2021",
    "descriptor": "\nComments: 11 pages, 7 figures, this work has been accepted by IEEE International Conference on Mobile Ad-Hoc and Smart Systems (MASS) 2021\n",
    "authors": [
      "Jinyue Song",
      "Tianbo Gu",
      "Zheng Fang",
      "Xiaotao Feng",
      "Yunjie Ge",
      "Hao Fu",
      "Pengfei Hu",
      "Prasant Mohapatra"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2007.10529"
  },
  {
    "id": "arXiv:2009.08062",
    "title": "Spectral Flow on the Manifold of SPD Matrices for Multimodal Data  Processing",
    "abstract": "Spectral Flow on the Manifold of SPD Matrices for Multimodal Data  Processing",
    "descriptor": "",
    "authors": [
      "Ori Katz",
      "Roy R. Lederman",
      "Ronen Talmon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.08062"
  },
  {
    "id": "arXiv:2009.10931",
    "title": "Drug repurposing for COVID-19 using graph neural network and harmonizing  multiple evidence",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Kanglin Hsieh",
      "Yinyin Wang",
      "Luyao Chen",
      "Zhongming Zhao",
      "Sean Savitz",
      "Xiaoqian Jiang",
      "Jing Tang",
      "Yejin Kim"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.10931"
  },
  {
    "id": "arXiv:2010.07769",
    "title": "A Patch-based Image Denoising Method Using Eigenvectors of the  Geodesics' Gramian Matrix",
    "abstract": "Comments: 25 pages, 5 figures, submitted into Pattern Recognition",
    "descriptor": "\nComments: 25 pages, 5 figures, submitted into Pattern Recognition\n",
    "authors": [
      "Kelum Gajamannage",
      "Randy Paffenroth",
      "Anura P. Jayasumana"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.07769"
  },
  {
    "id": "arXiv:2010.13471",
    "title": "Deep reinforced learning enables solving rich discrete-choice life cycle  models to analyze social security reforms",
    "abstract": "Deep reinforced learning enables solving rich discrete-choice life cycle  models to analyze social security reforms",
    "descriptor": "",
    "authors": [
      "Antti J. Tanskanen"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.13471"
  },
  {
    "id": "arXiv:2010.14314",
    "title": "Faster Lagrangian-Based Methods in Convex Optimization",
    "abstract": "Comments: Accepted for publication in SIAM Journal on Optimization",
    "descriptor": "\nComments: Accepted for publication in SIAM Journal on Optimization\n",
    "authors": [
      "Shoham Sabach",
      "Marc Teboulle"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2010.14314"
  },
  {
    "id": "arXiv:2010.15034",
    "title": "Learning Objective Functions Incrementally by Inverse Optimal Control",
    "abstract": "Learning Objective Functions Incrementally by Inverse Optimal Control",
    "descriptor": "",
    "authors": [
      "Zihao Liang",
      "Wanxin Jin",
      "Shaoshuai Mou"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2010.15034"
  },
  {
    "id": "arXiv:2011.00096",
    "title": "Independence in Infinite Probabilistic Databases",
    "abstract": "Independence in Infinite Probabilistic Databases",
    "descriptor": "",
    "authors": [
      "Martin Grohe",
      "Peter Lindner"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2011.00096"
  },
  {
    "id": "arXiv:2101.02313",
    "title": "A Note on Rough Set Algebra and Core Regular Double Stone Algebras",
    "abstract": "A Note on Rough Set Algebra and Core Regular Double Stone Algebras",
    "descriptor": "",
    "authors": [
      "Daniel J. Clouse"
    ],
    "subjectives": [
      "Rings and Algebras (math.RA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.02313"
  },
  {
    "id": "arXiv:2101.05408",
    "title": "The full approximation storage multigrid scheme: A 1D finite element  example",
    "abstract": "Comments: 19 pages, 7 figures",
    "descriptor": "\nComments: 19 pages, 7 figures\n",
    "authors": [
      "Ed Bueler"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2101.05408"
  },
  {
    "id": "arXiv:2101.07140",
    "title": "Specifying and Interpreting Reinforcement Learning Policies through  Simulatable Machine Learning",
    "abstract": "Specifying and Interpreting Reinforcement Learning Policies through  Simulatable Machine Learning",
    "descriptor": "",
    "authors": [
      "Pradyumna Tambwekar",
      "Andrew Silva",
      "Nakul Gopalan",
      "Matthew Gombolay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2101.07140"
  },
  {
    "id": "arXiv:2101.07312",
    "title": "Benchmarking Perturbation-based Saliency Maps for Explaining Atari  Agents",
    "abstract": "Benchmarking Perturbation-based Saliency Maps for Explaining Atari  Agents",
    "descriptor": "",
    "authors": [
      "Tobias Huber",
      "Benedikt Limmer",
      "Elisabeth Andr\u00e9"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2101.07312"
  },
  {
    "id": "arXiv:2102.02705",
    "title": "EFloat: EFloat: Entropy-coded Floating Point Format for Compressing  Vector Embedding Models",
    "abstract": "EFloat: EFloat: Entropy-coded Floating Point Format for Compressing  Vector Embedding Models",
    "descriptor": "",
    "authors": [
      "Rajesh Bordawekar",
      "Bulent Abali",
      "Ming-Hung Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2102.02705"
  },
  {
    "id": "arXiv:2102.06747",
    "title": "Realizable Universal Adversarial Perturbations for Malware",
    "abstract": "Comments: 19 pages, 10 figures",
    "descriptor": "\nComments: 19 pages, 10 figures\n",
    "authors": [
      "Raphael Labaca-Castro",
      "Luis Mu\u00f1oz-Gonz\u00e1lez",
      "Feargus Pendlebury",
      "Gabi Dreo Rodosek",
      "Fabio Pierazzi",
      "Lorenzo Cavallaro"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2102.06747"
  },
  {
    "id": "arXiv:2102.09788",
    "title": "Sequential- and Parallel- Constrained Max-value Entropy Search via  Information Lower Bound",
    "abstract": "Comments: 39pages, 8 figures",
    "descriptor": "\nComments: 39pages, 8 figures\n",
    "authors": [
      "Shion Takeno",
      "Tomoyuki Tamura",
      "Kazuki Shitara",
      "Masayuki Karasuyama"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.09788"
  },
  {
    "id": "arXiv:2102.10252",
    "title": "nTreeClus: a Tree-based Sequence Encoder for Clustering Categorical  Series",
    "abstract": "nTreeClus: a Tree-based Sequence Encoder for Clustering Categorical  Series",
    "descriptor": "",
    "authors": [
      "Hadi Jahanshahi",
      "Mustafa Gokce Baydogan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.10252"
  },
  {
    "id": "arXiv:2102.11350",
    "title": "A theory of Automated Market Makers in DeFi",
    "abstract": "Comments: Extended version of a paper with the same title presented at COORDINATION 2021",
    "descriptor": "\nComments: Extended version of a paper with the same title presented at COORDINATION 2021\n",
    "authors": [
      "Massimo Bartoletti",
      "James Hsin-yu Chiang",
      "Alberto Lluch-Lafuente"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2102.11350"
  },
  {
    "id": "arXiv:2103.06752",
    "title": "Knowledge Graph Question Answering using Graph-Pattern Isomorphism",
    "abstract": "Comments: Version published in the proceedings of the 17th International Conference on Semantic Systems",
    "descriptor": "\nComments: Version published in the proceedings of the 17th International Conference on Semantic Systems\n",
    "authors": [
      "Daniel Vollmers",
      "Rricha Jalota",
      "Diego Moussallem",
      "Hardik Topiwala",
      "Axel-Cyrille Ngonga Ngomo",
      "Ricardo Usbeck"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2103.06752"
  },
  {
    "id": "arXiv:2103.07299",
    "title": "Quasi-collocation based on CCC-Schoenberg operators and collocation  methods",
    "abstract": "Quasi-collocation based on CCC-Schoenberg operators and collocation  methods",
    "descriptor": "",
    "authors": [
      "Tina Bosner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.07299"
  },
  {
    "id": "arXiv:2103.11509",
    "title": "Scatter Correction in X-ray CT by Physics-Inspired Deep Learning",
    "abstract": "Scatter Correction in X-ray CT by Physics-Inspired Deep Learning",
    "descriptor": "",
    "authors": [
      "Berk Iskender",
      "Yoram Bresler"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2103.11509"
  },
  {
    "id": "arXiv:2103.12158",
    "title": "Convergence of Finite Memory Q-Learning for POMDPs and Near Optimality  of Learned Policies under Filter Stability",
    "abstract": "Convergence of Finite Memory Q-Learning for POMDPs and Near Optimality  of Learned Policies under Filter Stability",
    "descriptor": "",
    "authors": [
      "Ali Devran Kara",
      "Serdar Yuksel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2103.12158"
  },
  {
    "id": "arXiv:2103.12650",
    "title": "Deep Learning for fully automatic detection, segmentation, and Gleason  Grade estimation of prostate cancer in multiparametric Magnetic Resonance  Images",
    "abstract": "Deep Learning for fully automatic detection, segmentation, and Gleason  Grade estimation of prostate cancer in multiparametric Magnetic Resonance  Images",
    "descriptor": "",
    "authors": [
      "Oscar J. Pellicer-Valero",
      "Jos\u00e9 L. Marenco Jim\u00e9nez",
      "Victor Gonzalez-Perez",
      "Juan Luis Casanova Ram\u00f3n-Borja",
      "Isabel Mart\u00edn Garc\u00eda",
      "Mar\u00eda Barrios Benito",
      "Paula Pelechano G\u00f3mez",
      "Jos\u00e9 Rubio-Briones",
      "Mar\u00eda Jos\u00e9 Rup\u00e9rez",
      "Jos\u00e9 D. Mart\u00edn-Guerrero"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2103.12650"
  },
  {
    "id": "arXiv:2103.14755",
    "title": "Survival Regression with Proper Scoring Rules and Monotonic Neural  Networks",
    "abstract": "Survival Regression with Proper Scoring Rules and Monotonic Neural  Networks",
    "descriptor": "",
    "authors": [
      "David Rindt",
      "Robert Hu",
      "David Steinsaltz",
      "Dino Sejdinovic"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.14755"
  },
  {
    "id": "arXiv:2104.01723",
    "title": "An Energy-efficient Aerial Backhaul System with Reconfigurable  Intelligent Surface",
    "abstract": "Comments: 17 pages, 15 figures",
    "descriptor": "\nComments: 17 pages, 15 figures\n",
    "authors": [
      "Hong-Bae Jeon",
      "Sung-Ho Park",
      "Jaedon Park",
      "Kaibin Huang",
      "Chan-Byoung Chae"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2104.01723"
  },
  {
    "id": "arXiv:2104.03961",
    "title": "Generalized Approach to Matched Filtering using Neural Networks",
    "abstract": "Comments: 18 pages, 13 figures",
    "descriptor": "\nComments: 18 pages, 13 figures\n",
    "authors": [
      "Jingkai Yan",
      "Mariam Avagyan",
      "Robert E. Colgan",
      "Do\u011fa Veske",
      "Imre Bartos",
      "John Wright",
      "Zsuzsa M\u00e1rka",
      "Szabolcs M\u00e1rka"
    ],
    "subjectives": [
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Machine Learning (cs.LG)",
      "General Relativity and Quantum Cosmology (gr-qc)"
    ],
    "url": "https://arxiv.org/abs/2104.03961"
  },
  {
    "id": "arXiv:2104.09703",
    "title": "Bridging between soft and hard thresholding by scaling",
    "abstract": "Bridging between soft and hard thresholding by scaling",
    "descriptor": "",
    "authors": [
      "Katsuyuki Hagiwara"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.09703"
  },
  {
    "id": "arXiv:2104.10977",
    "title": "Designing IRS-Aided MIMO Systems for Secrecy Enhancement",
    "abstract": "Comments: 54 pages, 11 figures, A shortened version of this manuscript has been submitted to IEEE Transactions on Information Forensics and Security",
    "descriptor": "\nComments: 54 pages, 11 figures, A shortened version of this manuscript has been submitted to IEEE Transactions on Information Forensics and Security\n",
    "authors": [
      "Saba Asaad",
      "Yifei Wu",
      "Ali Bereyhi",
      "Ralf R. M\u00fcller",
      "Rafael F. Schaefer",
      "H. Vincent Poor"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2104.10977"
  },
  {
    "id": "arXiv:2105.06942",
    "title": "VICEROY: GDPR-/CCPA-compliant Enforcement of Verifiable Accountless  Consumer Requests",
    "abstract": "VICEROY: GDPR-/CCPA-compliant Enforcement of Verifiable Accountless  Consumer Requests",
    "descriptor": "",
    "authors": [
      "Scott Jordan",
      "Yoshimichi Nakatsuka",
      "Ercan Ozturk",
      "Andrew Paverd",
      "Gene Tsudik"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2105.06942"
  },
  {
    "id": "arXiv:2105.09121",
    "title": "Single-Layer Vision Transformers for More Accurate Early Exits with Less  Overhead",
    "abstract": "Comments: Code available at: this https URL",
    "descriptor": "\nComments: Code available at: this https URL\n",
    "authors": [
      "Arian Bakhtiarnia",
      "Qi Zhang",
      "Alexandros Iosifidis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.09121"
  },
  {
    "id": "arXiv:2105.09827",
    "title": "Total Coloring and Total Matching: Polyhedra and Facets",
    "abstract": "Comments: 29 pages, 5 figures",
    "descriptor": "\nComments: 29 pages, 5 figures\n",
    "authors": [
      "Luca Ferrarini",
      "Stefano Gualandi"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2105.09827"
  },
  {
    "id": "arXiv:2105.10310",
    "title": "Multi-Task, Multi-Domain Deep Segmentation with Shared Representations  and Contrastive Regularization for Sparse Pediatric Datasets",
    "abstract": "Comments: 11 pages, 4 figures, 2 tables, accepted at the 24th International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI 2021)",
    "descriptor": "\nComments: 11 pages, 4 figures, 2 tables, accepted at the 24th International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI 2021)\n",
    "authors": [
      "Arnaud Boutillon",
      "Pierre-Henri Conze",
      "Christelle Pons",
      "Val\u00e9rie Burdin",
      "Bhushan Borotikar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2105.10310"
  },
  {
    "id": "arXiv:2105.11724",
    "title": "SHAFF: Fast and consistent SHApley eFfect estimates via random Forests",
    "abstract": "SHAFF: Fast and consistent SHApley eFfect estimates via random Forests",
    "descriptor": "",
    "authors": [
      "Cl\u00e9ment B\u00e9nard",
      "G\u00e9rard Biau",
      "S\u00e9bastien da Veiga",
      "Erwan Scornet"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.11724"
  },
  {
    "id": "arXiv:2105.12070",
    "title": "Fast reactive flow simulations using analytical Jacobian and dynamic  load balancing in OpenFOAM",
    "abstract": "Comments: 45 pages, 12 figures",
    "descriptor": "\nComments: 45 pages, 12 figures\n",
    "authors": [
      "Ilya Morev",
      "Bulut Tekg\u00fcl",
      "Mahmoud Gadalla",
      "Ali Shahanaghi",
      "Jeevananthan Kannan",
      "Shervin Karimkashi",
      "Ossi Kaario",
      "Ville Vuorinen"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2105.12070"
  },
  {
    "id": "arXiv:2105.14490",
    "title": "Relational Graph Neural Network Design via Progressive Neural  Architecture Search",
    "abstract": "Relational Graph Neural Network Design via Progressive Neural  Architecture Search",
    "descriptor": "",
    "authors": [
      "Ailing Zeng",
      "Minhao Liu",
      "Zhiwei Liu",
      "Ruiyuan Gao",
      "Jing Qin",
      "Qiang Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14490"
  },
  {
    "id": "arXiv:2105.14608",
    "title": "Safety Embedded Differential Dynamic Programming Using Discrete Barrier  States",
    "abstract": "Comments: Added extensive quantitative comparisons and analysis in the implementation examples, and revised discussions and illustrations",
    "descriptor": "\nComments: Added extensive quantitative comparisons and analysis in the implementation examples, and revised discussions and illustrations\n",
    "authors": [
      "Hassan Almubarak",
      "Kyle Stachowicz",
      "Nader Sadegh",
      "Evangelos A. Theodorou"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2105.14608"
  },
  {
    "id": "arXiv:2106.01987",
    "title": "PRINS: Scalable Model Inference for Component-based System Logs",
    "abstract": "Comments: To appear in Empirical Software Engineering",
    "descriptor": "\nComments: To appear in Empirical Software Engineering\n",
    "authors": [
      "Donghwan Shin",
      "Domenico Bianculli",
      "Lionel Briand"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2106.01987"
  },
  {
    "id": "arXiv:2106.02613",
    "title": "Beyond Target Networks: Improving Deep $Q$-learning with Functional  Regularization",
    "abstract": "Beyond Target Networks: Improving Deep $Q$-learning with Functional  Regularization",
    "descriptor": "",
    "authors": [
      "Alexandre Pich\u00e9",
      "Valentin Thomas",
      "Joseph Marino",
      "Gian Maria Marconi",
      "Christopher Pal",
      "Mohammad Emtiyaz Khan"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02613"
  },
  {
    "id": "arXiv:2106.05187",
    "title": "Geometry-Consistent Neural Shape Representation with Implicit  Displacement Fields",
    "abstract": "Comments: Accepted to ICLR 2022, 20 pages including appendix. Code available at this https URL",
    "descriptor": "\nComments: Accepted to ICLR 2022, 20 pages including appendix. Code available at this https URL\n",
    "authors": [
      "Wang Yifan",
      "Lukas Rahmann",
      "Olga Sorkine-Hornung"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05187"
  },
  {
    "id": "arXiv:2106.05566",
    "title": "A Neural Tangent Kernel Perspective of GANs",
    "abstract": "A Neural Tangent Kernel Perspective of GANs",
    "descriptor": "",
    "authors": [
      "Jean-Yves Franceschi",
      "Emmanuel de B\u00e9zenac",
      "Ibrahim Ayed",
      "Micka\u00ebl Chen",
      "Sylvain Lamprier",
      "Patrick Gallinari"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.05566"
  },
  {
    "id": "arXiv:2106.07471",
    "title": "Signal processing on simplicial complexes",
    "abstract": "Comments: 29 pages; 5 figures. arXiv admin note: text overlap with arXiv:2101.05510",
    "descriptor": "\nComments: 29 pages; 5 figures. arXiv admin note: text overlap with arXiv:2101.05510\n",
    "authors": [
      "Michael T. Schaub",
      "Jean-Baptiste Seby",
      "Florian Frantzen",
      "T. Mitchell Roddenberry",
      "Yu Zhu",
      "Santiago Segarra"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.07471"
  },
  {
    "id": "arXiv:2106.07484",
    "title": "Conservative Integrators for Piecewise Smooth Systems with Transversal  Dynamics",
    "abstract": "Comments: Replaced Lemma 3.6 with an easier argument. Collected hypotheses of main theorem into the statement. Results unchanged. Added figures of conserved quantity error",
    "descriptor": "\nComments: Replaced Lemma 3.6 with an easier argument. Collected hypotheses of main theorem into the statement. Results unchanged. Added figures of conserved quantity error\n",
    "authors": [
      "Anil N. Hirani",
      "Andy T.S. Wan",
      "Nikolas Wojtalewicz"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2106.07484"
  },
  {
    "id": "arXiv:2106.07830",
    "title": "On the Convergence and Calibration of Deep Learning with Differential  Privacy",
    "abstract": "On the Convergence and Calibration of Deep Learning with Differential  Privacy",
    "descriptor": "",
    "authors": [
      "Zhiqi Bu",
      "Hua Wang",
      "Qi Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.07830"
  },
  {
    "id": "arXiv:2106.08323",
    "title": "VidHarm: A Clip Based Dataset for Harmful Content Detection",
    "abstract": "Comments: Updated with additional analysis on the dataset",
    "descriptor": "\nComments: Updated with additional analysis on the dataset\n",
    "authors": [
      "Johan Edstedt",
      "Amanda Berg",
      "Michael Felsberg",
      "Johan Karlsson",
      "Francisca Benavente",
      "Anette Novak",
      "Gustav Grund Pihlgren"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.08323"
  },
  {
    "id": "arXiv:2106.08363",
    "title": "Convergence of a Lagrangian-Eulerian scheme by a weak asymptotic  analysis for one-dimensional hyperbolic problems",
    "abstract": "Convergence of a Lagrangian-Eulerian scheme by a weak asymptotic  analysis for one-dimensional hyperbolic problems",
    "descriptor": "",
    "authors": [
      "Eduardo Abreu",
      "Arthur Esp\u00edrito Santo",
      "Wanderson Lambert",
      "John P\u00e9rez"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.08363"
  },
  {
    "id": "arXiv:2106.09659",
    "title": "Robustness and Consistency in Linear Quadratic Control with Untrusted  Predictions",
    "abstract": "Comments: 34 pages, 8 figures, ACM SIGMETRICS 2022",
    "descriptor": "\nComments: 34 pages, 8 figures, ACM SIGMETRICS 2022\n",
    "authors": [
      "Tongxin Li",
      "Ruixiao Yang",
      "Guannan Qu",
      "Guanya Shi",
      "Chenkai Yu",
      "Adam Wierman",
      "Steven Low"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.09659"
  },
  {
    "id": "arXiv:2106.09711",
    "title": "Visual Correspondence Hallucination",
    "abstract": "Visual Correspondence Hallucination",
    "descriptor": "",
    "authors": [
      "Hugo Germain",
      "Vincent Lepetit",
      "Guillaume Bourmaud"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.09711"
  },
  {
    "id": "arXiv:2106.09780",
    "title": "Gradient-free optimization of chaotic acoustics with reservoir computing",
    "abstract": "Comments: 16 figures, 26 pages",
    "descriptor": "\nComments: 16 figures, 26 pages\n",
    "authors": [
      "Francisco Huhn",
      "Luca Magri"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2106.09780"
  },
  {
    "id": "arXiv:2106.10065",
    "title": "Being a Bit Frequentist Improves Bayesian Neural Networks",
    "abstract": "Comments: AISTATS 2022",
    "descriptor": "\nComments: AISTATS 2022\n",
    "authors": [
      "Agustinus Kristiadi",
      "Matthias Hein",
      "Philipp Hennig"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.10065"
  },
  {
    "id": "arXiv:2106.11144",
    "title": "Scientific multi-agent reinforcement learning for wall-models of  turbulent flows",
    "abstract": "Scientific multi-agent reinforcement learning for wall-models of  turbulent flows",
    "descriptor": "",
    "authors": [
      "H. Jane Bae",
      "Petros Koumoutsakos"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2106.11144"
  },
  {
    "id": "arXiv:2106.12144",
    "title": "NodePiece: Compositional and Parameter-Efficient Representations of  Large Knowledge Graphs",
    "abstract": "Comments: Accepted to ICLR 2022",
    "descriptor": "\nComments: Accepted to ICLR 2022\n",
    "authors": [
      "Mikhail Galkin",
      "Etienne Denis",
      "Jiapeng Wu",
      "William L. Hamilton"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.12144"
  },
  {
    "id": "arXiv:2106.12479",
    "title": "Classifying Textual Data with Pre-trained Vision Models through Transfer  Learning and Data Transformations",
    "abstract": "Comments: Paper contains: 7 pages, 9 figures, 1 table",
    "descriptor": "\nComments: Paper contains: 7 pages, 9 figures, 1 table\n",
    "authors": [
      "Charaf Eddine Benarab"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.12479"
  },
  {
    "id": "arXiv:2106.13896",
    "title": "Optical MIMO Communication Using Holographic Spectral Multiplexing of  Pulsed Ultrashort Laser",
    "abstract": "Comments: Needs more improvement",
    "descriptor": "\nComments: Needs more improvement\n",
    "authors": [
      "Alireza Khodaei",
      "Jitender Deogun"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2106.13896"
  },
  {
    "id": "arXiv:2106.14662",
    "title": "Improving Uncertainty Calibration of Deep Neural Networks via Truth  Discovery and Geometric Optimization",
    "abstract": "Comments: Accepted for publication at 37th Conference on Uncertainty in Artificial Intelligence (UAI 2021); this https URL",
    "descriptor": "\nComments: Accepted for publication at 37th Conference on Uncertainty in Artificial Intelligence (UAI 2021); this https URL\n",
    "authors": [
      "Chunwei Ma",
      "Ziyun Huang",
      "Jiayi Xian",
      "Mingchen Gao",
      "Jinhui Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.14662"
  },
  {
    "id": "arXiv:2106.15560",
    "title": "HJB Based Optimal Safe Control Using Control Barrier Functions",
    "abstract": "HJB Based Optimal Safe Control Using Control Barrier Functions",
    "descriptor": "",
    "authors": [
      "Hassan Almubarak",
      "Evangelos A. Theodorou",
      "Nader Sadegh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2106.15560"
  },
  {
    "id": "arXiv:2107.01510",
    "title": "Directed Percolation in Temporal Networks",
    "abstract": "Comments: Implementation available at this https URL",
    "descriptor": "\nComments: Implementation available at this https URL\n",
    "authors": [
      "Arash Badie-Modiri",
      "Abbas K. Rizi",
      "M\u00e1rton Karsai",
      "Mikko Kivel\u00e4"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2107.01510"
  },
  {
    "id": "arXiv:2107.06130",
    "title": "Scalable Surface Reconstruction with Delaunay-Graph Neural Networks",
    "abstract": "Comments: The presentation of this work at SGP 2021 is available at this https URL",
    "descriptor": "\nComments: The presentation of this work at SGP 2021 is available at this https URL\n",
    "authors": [
      "Raphael Sulzer",
      "Loic Landrieu",
      "Renaud Marlet",
      "Bruno Vallet"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2107.06130"
  },
  {
    "id": "arXiv:2107.09224",
    "title": "From Predictions to Decisions: The Importance of Joint Predictive  Distributions",
    "abstract": "From Predictions to Decisions: The Importance of Joint Predictive  Distributions",
    "descriptor": "",
    "authors": [
      "Zheng Wen",
      "Ian Osband",
      "Chao Qin",
      "Xiuyuan Lu",
      "Morteza Ibrahimi",
      "Vikranth Dwaracherla",
      "Mohammad Asghari",
      "Benjamin Van Roy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.09224"
  },
  {
    "id": "arXiv:2107.09950",
    "title": "Boundary of Distribution Support Generator (BDSG): Sample Generation on  the Boundary",
    "abstract": "Comments: 5 pages, 2020 IEEE International Conference on Image Processing (ICIP)",
    "descriptor": "\nComments: 5 pages, 2020 IEEE International Conference on Image Processing (ICIP)\n",
    "authors": [
      "Nikolaos Dionelis",
      "Mehrdad Yaghoobi",
      "Sotirios A. Tsaftaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.09950"
  },
  {
    "id": "arXiv:2107.10955",
    "title": "Learning Linear Polytree Structural Equation Models",
    "abstract": "Comments: 36 pages, 4 figures, 3 tables",
    "descriptor": "\nComments: 36 pages, 4 figures, 3 tables\n",
    "authors": [
      "Xingmei Lou",
      "Yu Hu",
      "Xiaodong Li"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2107.10955"
  },
  {
    "id": "arXiv:2107.11658",
    "title": "Tail of Distribution GAN (TailGAN): Generative-Adversarial-Network-Based  Boundary Formation",
    "abstract": "Comments: 5 pages, 2020 Sensor Signal Processing for Defence Conference (SSPD)",
    "descriptor": "\nComments: 5 pages, 2020 Sensor Signal Processing for Defence Conference (SSPD)\n",
    "authors": [
      "Nikolaos Dionelis",
      "Mehrdad Yaghoobi",
      "Sotirios A. Tsaftaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.11658"
  },
  {
    "id": "arXiv:2107.11707",
    "title": "Boosting Video Captioning with Dynamic Loss Network",
    "abstract": "Comments: 8 pages, 4 figures, Preprint",
    "descriptor": "\nComments: 8 pages, 4 figures, Preprint\n",
    "authors": [
      "Nasib Ullah",
      "Partha Pratim Mohanta"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.11707"
  },
  {
    "id": "arXiv:2107.12168",
    "title": "Exploiting Language Model for Efficient Linguistic Steganalysis",
    "abstract": "Comments: Accepted to IEEE International Conference on Acoustics, Speech, and Signal Processing 2022",
    "descriptor": "\nComments: Accepted to IEEE International Conference on Acoustics, Speech, and Signal Processing 2022\n",
    "authors": [
      "Biao Yi",
      "Hanzhou Wu",
      "Guorui Feng",
      "Xinpeng Zhang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2107.12168"
  },
  {
    "id": "arXiv:2107.14586",
    "title": "An Efficient DP-SGD Mechanism for Large Scale NLP Models",
    "abstract": "An Efficient DP-SGD Mechanism for Large Scale NLP Models",
    "descriptor": "",
    "authors": [
      "Christophe Dupuy",
      "Radhika Arava",
      "Rahul Gupta",
      "Anna Rumshisky"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.14586"
  },
  {
    "id": "arXiv:2108.00789",
    "title": "Identifying historical roots in paediatric echocardiography using RPYS",
    "abstract": "Identifying historical roots in paediatric echocardiography using RPYS",
    "descriptor": "",
    "authors": [
      "Peter Kokol",
      "Jernej Zavrsnik",
      "Helena Blazun Vosner"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2108.00789"
  },
  {
    "id": "arXiv:2108.01466",
    "title": "Risk Adversarial Learning System for Connected and Autonomous Vehicle  Charging",
    "abstract": "Comments: Accepted Article By IEEE Internet of Things Journal, DOI:10.1109/JIOT.2022.3149038 (In Press)",
    "descriptor": "\nComments: Accepted Article By IEEE Internet of Things Journal, DOI:10.1109/JIOT.2022.3149038 (In Press)\n",
    "authors": [
      "Md. Shirajum Munir",
      "Ki Tae Kim",
      "Kyi Thar",
      "Dusit Niyato",
      "Choong Seon Hong"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computational Engineering, Finance, and Science (cs.CE)",
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2108.01466"
  },
  {
    "id": "arXiv:2108.04140",
    "title": "Reachability Analysis of Neural Feedback Loops",
    "abstract": "Reachability Analysis of Neural Feedback Loops",
    "descriptor": "",
    "authors": [
      "Michael Everett",
      "Golnaz Habibi",
      "Chuangchuang Sun",
      "Jonathan P. How"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.04140"
  },
  {
    "id": "arXiv:2108.04633",
    "title": "Channel Modeling and Channel Estimation for Holographic Massive MIMO  with Planar Arrays",
    "abstract": "Comments: 5 pages, 4 figures, submitted to IEEE letters",
    "descriptor": "\nComments: 5 pages, 4 figures, submitted to IEEE letters\n",
    "authors": [
      "\u00d6zlem Tu\u011ffe Demir",
      "Emil Bj\u00f6rnson",
      "Luca Sanguinetti"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2108.04633"
  },
  {
    "id": "arXiv:2108.04729",
    "title": "Spectral Robustness for Correlation Clustering Reconstruction in  Semi-Adversarial Models",
    "abstract": "Spectral Robustness for Correlation Clustering Reconstruction in  Semi-Adversarial Models",
    "descriptor": "",
    "authors": [
      "Flavio Chierichetti",
      "Alessandro Panconesi",
      "Giuseppe Re",
      "Luca Trevisan"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.04729"
  },
  {
    "id": "arXiv:2108.04896",
    "title": "Interpreting Generative Adversarial Networks for Interactive Image  Generation",
    "abstract": "Comments: An invited book chapter on explainable machine learning",
    "descriptor": "\nComments: An invited book chapter on explainable machine learning\n",
    "authors": [
      "Bolei Zhou"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.04896"
  },
  {
    "id": "arXiv:2108.05308",
    "title": "A Better Loss for Visual-Textual Grounding",
    "abstract": "A Better Loss for Visual-Textual Grounding",
    "descriptor": "",
    "authors": [
      "Davide Rigoni",
      "Luciano Serafini",
      "Alessandro Sperduti"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.05308"
  },
  {
    "id": "arXiv:2108.07739",
    "title": "A Simple and Efficient Reconstruction Backbone for Snapshot Compressive  Imaging",
    "abstract": "Comments: 17 pages, 15 figures. Code and pre-trained models: this https URL",
    "descriptor": "\nComments: 17 pages, 15 figures. Code and pre-trained models: this https URL\n",
    "authors": [
      "Jiamian Wang",
      "Yulun Zhang",
      "Xin Yuan",
      "Yun Fu",
      "Zhiqiang Tao"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.07739"
  },
  {
    "id": "arXiv:2108.12250",
    "title": "A comparison of approaches to improve worst-case predictive model  performance over patient subpopulations",
    "abstract": "A comparison of approaches to improve worst-case predictive model  performance over patient subpopulations",
    "descriptor": "",
    "authors": [
      "Stephen R. Pfohl",
      "Haoran Zhang",
      "Yizhe Xu",
      "Agata Foryciarz",
      "Marzyeh Ghassemi",
      "Nigam H. Shah"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.12250"
  },
  {
    "id": "arXiv:2108.12842",
    "title": "DASHA: Decentralized Autofocusing System with Hierarchical Agents",
    "abstract": "DASHA: Decentralized Autofocusing System with Hierarchical Agents",
    "descriptor": "",
    "authors": [
      "Anna Anikina",
      "Oleg Y. Rogov",
      "Dmitry V. Dylov"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2108.12842"
  },
  {
    "id": "arXiv:2108.13294",
    "title": "The missing link: Developing a safety case for perception components in  automated driving",
    "abstract": "The missing link: Developing a safety case for perception components in  automated driving",
    "descriptor": "",
    "authors": [
      "Rick Salay",
      "Krzysztof Czarnecki",
      "Hiroshi Kuwajima",
      "Hirotoshi Yasuoka",
      "Toshihiro Nakae",
      "Vahdat Abdelzad",
      "Chengjie Huang",
      "Maximilian Kahn",
      "Van Duong Nguyen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)",
      "Software Engineering (cs.SE)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2108.13294"
  },
  {
    "id": "arXiv:2109.00486",
    "title": "Survey of Low-Resource Machine Translation",
    "abstract": "Survey of Low-Resource Machine Translation",
    "descriptor": "",
    "authors": [
      "Barry Haddow",
      "Rachel Bawden",
      "Antonio Valerio Miceli Barone",
      "Jind\u0159ich Helcl",
      "Alexandra Birch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.00486"
  },
  {
    "id": "arXiv:2109.01902",
    "title": "Barycentric-alignment and invertibility for domain generalization",
    "abstract": "Comments: Results are updated",
    "descriptor": "\nComments: Results are updated\n",
    "authors": [
      "Boyang Lyu",
      "Thuan Nguyen",
      "Prakash Ishwar",
      "Matthias Scheutz",
      "Shuchin Aeron"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.01902"
  },
  {
    "id": "arXiv:2109.06479",
    "title": "Large-scale Autonomous Flight with Real-time Semantic SLAM under Dense  Forest Canopy",
    "abstract": "Comments: Xu Liu and Guilherme V. Nardari contributed equally to this work",
    "descriptor": "\nComments: Xu Liu and Guilherme V. Nardari contributed equally to this work\n",
    "authors": [
      "Xu Liu",
      "Guilherme V. Nardari",
      "Fernando Cladera Ojeda",
      "Yuezhan Tao",
      "Alex Zhou",
      "Thomas Donnelly",
      "Chao Qu",
      "Steven W. Chen",
      "Roseli A. F. Romero",
      "Camillo J. Taylor",
      "Vijay Kumar"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.06479"
  },
  {
    "id": "arXiv:2109.06949",
    "title": "Targeted Cross-Validation",
    "abstract": "Targeted Cross-Validation",
    "descriptor": "",
    "authors": [
      "Jiawei Zhang",
      "Jie Ding",
      "Yuhong Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06949"
  },
  {
    "id": "arXiv:2109.10960",
    "title": "Quantitative analysis of phase transitions in two-dimensional XY models  using persistent homology",
    "abstract": "Comments: 20 pages, 29 figures",
    "descriptor": "\nComments: 20 pages, 29 figures\n",
    "authors": [
      "Nicholas Sale",
      "Jeffrey Giansiracusa",
      "Biagio Lucini"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "High Energy Physics - Lattice (hep-lat)",
      "High Energy Physics - Theory (hep-th)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2109.10960"
  },
  {
    "id": "arXiv:2109.13473",
    "title": "Two time-stepping schemes for sub-diffusion equations with singular  source terms",
    "abstract": "Two time-stepping schemes for sub-diffusion equations with singular  source terms",
    "descriptor": "",
    "authors": [
      "Han Zhou",
      "Wenyi Tian"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.13473"
  },
  {
    "id": "arXiv:2109.14236",
    "title": "LightSecAgg: a Lightweight and Versatile Design for Secure Aggregation  in Federated Learning",
    "abstract": "Comments: This paper is accepted to the 5th MLSys Conference, Santa Clara, CA, USA, 2022",
    "descriptor": "\nComments: This paper is accepted to the 5th MLSys Conference, Santa Clara, CA, USA, 2022\n",
    "authors": [
      "Jinhyun So",
      "Chaoyang He",
      "Chien-Sheng Yang",
      "Songze Li",
      "Qian Yu",
      "Ramy E. Ali",
      "Basak Guler",
      "Salman Avestimehr"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.14236"
  },
  {
    "id": "arXiv:2110.02037",
    "title": "Autoregressive Diffusion Models",
    "abstract": "Comments: Published as a conference paper at International Conference on Learning Representations (ICLR) 2022",
    "descriptor": "\nComments: Published as a conference paper at International Conference on Learning Representations (ICLR) 2022\n",
    "authors": [
      "Emiel Hoogeboom",
      "Alexey A. Gritsenko",
      "Jasmijn Bastings",
      "Ben Poole",
      "Rianne van den Berg",
      "Tim Salimans"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.02037"
  },
  {
    "id": "arXiv:2110.02584",
    "title": "EdiTTS: Score-based Editing for Controllable Text-to-Speech",
    "abstract": "EdiTTS: Score-based Editing for Controllable Text-to-Speech",
    "descriptor": "",
    "authors": [
      "Jaesung Tae",
      "Hyeongju Kim",
      "Taesu Kim"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.02584"
  },
  {
    "id": "arXiv:2110.03155",
    "title": "Interpreting Distributional Reinforcement Learning: Regularization and  Optimization Perspectives",
    "abstract": "Comments: under review",
    "descriptor": "\nComments: under review\n",
    "authors": [
      "Ke Sun",
      "Yingnan Zhao",
      "Yi Liu",
      "Enze Shi",
      "Yafei Wang",
      "Aref Sadeghi",
      "Xiaodong Yan",
      "Bei Jiang",
      "Linglong Kong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03155"
  },
  {
    "id": "arXiv:2110.03536",
    "title": "Prototype Learning for Interpretable Respiratory Sound Analysis",
    "abstract": "Comments: Technical report of the paper accepted by IEEE ICASSP 2022",
    "descriptor": "\nComments: Technical report of the paper accepted by IEEE ICASSP 2022\n",
    "authors": [
      "Zhao Ren",
      "Thanh Tam Nguyen",
      "Wolfgang Nejdl"
    ],
    "subjectives": [
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.03536"
  },
  {
    "id": "arXiv:2110.04366",
    "title": "Towards a Unified View of Parameter-Efficient Transfer Learning",
    "abstract": "Comments: ICLR 2022 (spotlight presentation). Code is available at this https URL",
    "descriptor": "\nComments: ICLR 2022 (spotlight presentation). Code is available at this https URL\n",
    "authors": [
      "Junxian He",
      "Chunting Zhou",
      "Xuezhe Ma",
      "Taylor Berg-Kirkpatrick",
      "Graham Neubig"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04366"
  },
  {
    "id": "arXiv:2110.05057",
    "title": "Can Stochastic Gradient Langevin Dynamics Provide Differential Privacy  for Deep Learning?",
    "abstract": "Can Stochastic Gradient Langevin Dynamics Provide Differential Privacy  for Deep Learning?",
    "descriptor": "",
    "authors": [
      "Guy Heller",
      "Ethan Fetaya"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2110.05057"
  },
  {
    "id": "arXiv:2110.06914",
    "title": "What Happens after SGD Reaches Zero Loss? --A Mathematical Framework",
    "abstract": "Comments: 47 pages, 2 figures",
    "descriptor": "\nComments: 47 pages, 2 figures\n",
    "authors": [
      "Zhiyuan Li",
      "Tianhao Wang",
      "Sanjeev Arora"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.06914"
  },
  {
    "id": "arXiv:2110.07004",
    "title": "A Novel Hessian-Free Bilevel Optimizer via Evolution Strategies",
    "abstract": "Comments: Submitted for publication",
    "descriptor": "\nComments: Submitted for publication\n",
    "authors": [
      "Daouda Sow",
      "Kaiyi Ji",
      "Yingbin Liang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.07004"
  },
  {
    "id": "arXiv:2110.07647",
    "title": "Towards Understanding the Data Dependency of Mixup-style Training",
    "abstract": "Comments: 26 pages, 14 figures, Accepted to ICLR 2022 (Spotlight)",
    "descriptor": "\nComments: 26 pages, 14 figures, Accepted to ICLR 2022 (Spotlight)\n",
    "authors": [
      "Muthu Chidambaram",
      "Xiang Wang",
      "Yuzheng Hu",
      "Chenwei Wu",
      "Rong Ge"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.07647"
  },
  {
    "id": "arXiv:2110.07698",
    "title": "Directed Percolation in Random Temporal Network Models with  Heterogeneities",
    "abstract": "Comments: Implementation available at this https URL",
    "descriptor": "\nComments: Implementation available at this https URL\n",
    "authors": [
      "Arash Badie-Modiri",
      "Abbas K. Rizi",
      "M\u00e1rton Karsai",
      "Mikko Kivel\u00e4"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2110.07698"
  },
  {
    "id": "arXiv:2110.08775",
    "title": "Perturbative construction of mean-field equations in extensive-rank  matrix factorization and denoising",
    "abstract": "Comments: 30 pages (main text), 25 pages of references and appendices. v2: Adding clarifications and a new result to derive the optimal denoising estimator from the asymptotic free energy",
    "descriptor": "\nComments: 30 pages (main text), 25 pages of references and appendices. v2: Adding clarifications and a new result to derive the optimal denoising estimator from the asymptotic free energy\n",
    "authors": [
      "Antoine Maillard",
      "Florent Krzakala",
      "Marc M\u00e9zard",
      "Lenka Zdeborov\u00e1"
    ],
    "subjectives": [
      "Disordered Systems and Neural Networks (cond-mat.dis-nn)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Information Theory (cs.IT)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2110.08775"
  },
  {
    "id": "arXiv:2110.08782",
    "title": "Faster Algorithms for Bounded-Difference Min-Plus Product",
    "abstract": "Comments: 13 pages",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Shucheng Chi",
      "Ran Duan",
      "Tianle Xie"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.08782"
  },
  {
    "id": "arXiv:2110.10009",
    "title": "EEGminer: Discovering Interpretable Features of Brain Activity with  Learnable Filters",
    "abstract": "Comments: 14 pages, 8 figures",
    "descriptor": "\nComments: 14 pages, 8 figures\n",
    "authors": [
      "Siegfried Ludwig",
      "Stylianos Bakas",
      "Dimitrios A. Adamos",
      "Nikolaos Laskaris",
      "Yannis Panagakis",
      "Stefanos Zafeiriou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.10009"
  },
  {
    "id": "arXiv:2110.10132",
    "title": "FriendlyCore: Practical Differentially Private Aggregation",
    "abstract": "FriendlyCore: Practical Differentially Private Aggregation",
    "descriptor": "",
    "authors": [
      "Eliad Tsfadia",
      "Edith Cohen",
      "Haim Kaplan",
      "Yishay Mansour",
      "Uri Stemmer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.10132"
  },
  {
    "id": "arXiv:2110.11346",
    "title": "Data-Driven Offline Optimization For Architecting Hardware Accelerators",
    "abstract": "Comments: First two authors contributed equally; published at ICLR 2022",
    "descriptor": "\nComments: First two authors contributed equally; published at ICLR 2022\n",
    "authors": [
      "Aviral Kumar",
      "Amir Yazdanbakhsh",
      "Milad Hashemi",
      "Kevin Swersky",
      "Sergey Levine"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11346"
  },
  {
    "id": "arXiv:2110.15273",
    "title": "OMASGAN: Out-of-Distribution Minimum Anomaly Score GAN for Sample  Generation on the Boundary",
    "abstract": "Comments: Research work paper, 9 pages, 10 figures, Appendix",
    "descriptor": "\nComments: Research work paper, 9 pages, 10 figures, Appendix\n",
    "authors": [
      "Nikolaos Dionelis",
      "Mehrdad Yaghoobi",
      "Sotirios A. Tsaftaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.15273"
  },
  {
    "id": "arXiv:2111.02374",
    "title": "Can I use this publicly available dataset to build commercial AI  software? -- A Case Study on Publicly Available Image Datasets",
    "abstract": "Comments: This is revised version of the paper with updated co-authors",
    "descriptor": "\nComments: This is revised version of the paper with updated co-authors\n",
    "authors": [
      "Gopi Krishnan Rajbahadur",
      "Erika Tuck",
      "Li Zi",
      "Dayi Lin",
      "Boyuan Chen",
      "Zhen Ming",
      "Jiang",
      "Daniel Morales German"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2111.02374"
  },
  {
    "id": "arXiv:2111.03552",
    "title": "SmartDepthSync: Open Source Synchronized Video Recording System of  Smartphone RGB and Depth Camera Image Frames with Sub-millisecond Precision",
    "abstract": "Comments: IEEE Sensors Journal accepted paper",
    "descriptor": "\nComments: IEEE Sensors Journal accepted paper\n",
    "authors": [
      "Marsel Faizullin",
      "Anastasiia Kornilova",
      "Azat Akhmetyanov",
      "Konstantin Pakulev",
      "Andrey Sadkov",
      "Gonzalo Ferrer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2111.03552"
  },
  {
    "id": "arXiv:2111.06361",
    "title": "Flattening the Duck Curve: A Case for Distributed Decision Making",
    "abstract": "Comments: 5 pages, 4 figures, 1 table. This work has been accepted for presentation at the 2022 IEEE Power & Energy Society General Meeting, and will be a part of the conference proceedings.Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: 5 pages, 4 figures, 1 table. This work has been accepted for presentation at the 2022 IEEE Power & Energy Society General Meeting, and will be a part of the conference proceedings.Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Rabab Haider",
      "Giulio Ferro",
      "Michela Robba",
      "Anuradha M. Annaswamy"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.06361"
  },
  {
    "id": "arXiv:2111.10552",
    "title": "Accelerating non-LTE synthesis and inversions with graph networks",
    "abstract": "Comments: 16 pages, 10 figures, Accepted in ApJ on 01/02/2022 after A&A suggested to be published in a more specialized journal",
    "descriptor": "\nComments: 16 pages, 10 figures, Accepted in ApJ on 01/02/2022 after A&A suggested to be published in a more specialized journal\n",
    "authors": [
      "A. Vicente Ar\u00e9valo",
      "A. Asensio Ramos",
      "S. Esteban Pozuelo"
    ],
    "subjectives": [
      "Solar and Stellar Astrophysics (astro-ph.SR)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10552"
  },
  {
    "id": "arXiv:2111.11344",
    "title": "Modeling Irregular Time Series with Continuous Recurrent Units",
    "abstract": "Modeling Irregular Time Series with Continuous Recurrent Units",
    "descriptor": "",
    "authors": [
      "Mona Schirmer",
      "Mazin Eltayeb",
      "Stefan Lessmann",
      "Maja Rudolph"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.11344"
  },
  {
    "id": "arXiv:2111.12490",
    "title": "Matching Learned Causal Effects of Neural Networks with Domain Priors",
    "abstract": "Matching Learned Causal Effects of Neural Networks with Domain Priors",
    "descriptor": "",
    "authors": [
      "Sai Srinivas Kancheti",
      "Abbavaram Gowtham Reddy",
      "Vineeth N Balasubramanian",
      "Amit Sharma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2111.12490"
  },
  {
    "id": "arXiv:2111.12860",
    "title": "Exoskeleton Technology: State-of-the-art and -practice of Physical and  Cognitive Human Robot Interface",
    "abstract": "Exoskeleton Technology: State-of-the-art and -practice of Physical and  Cognitive Human Robot Interface",
    "descriptor": "",
    "authors": [
      "Farhad Nazari",
      "Navid Mohajer",
      "Darius Nahavandi",
      "Abbas Khosravi",
      "Saeid Nahavandi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2111.12860"
  },
  {
    "id": "arXiv:2111.15487",
    "title": "FROB: Few-shot ROBust Model for Classification and Out-of-Distribution  Detection",
    "abstract": "Comments: Paper, 22 pages, Figures, Tables",
    "descriptor": "\nComments: Paper, 22 pages, Figures, Tables\n",
    "authors": [
      "Nikolaos Dionelis",
      "Mehrdad Yaghoobi",
      "Sotirios A. Tsaftaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.15487"
  },
  {
    "id": "arXiv:2111.15646",
    "title": "The Exponentially Tilted Gaussian Prior for Variational Autoencoders",
    "abstract": "The Exponentially Tilted Gaussian Prior for Variational Autoencoders",
    "descriptor": "",
    "authors": [
      "Griffin Floto",
      "Stefan Kremer",
      "Mihai Nica"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.15646"
  },
  {
    "id": "arXiv:2112.01731",
    "title": "Push-sum Distributed Dual Averaging for Convex Optimization in  Multi-agent Systems with Communication Delays",
    "abstract": "Push-sum Distributed Dual Averaging for Convex Optimization in  Multi-agent Systems with Communication Delays",
    "descriptor": "",
    "authors": [
      "Cong Wang",
      "Shengyuan Xu",
      "Deming Yuan",
      "Baoyong Zhang",
      "Zhengqiang Zhang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.01731"
  },
  {
    "id": "arXiv:2112.02043",
    "title": "Multilingual training for Software Engineering",
    "abstract": "Comments: Accepted at International Conference on Software Engineering (ICSE-2022)",
    "descriptor": "\nComments: Accepted at International Conference on Software Engineering (ICSE-2022)\n",
    "authors": [
      "Toufique Ahmed",
      "Premkumar Devanbu"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.02043"
  },
  {
    "id": "arXiv:2112.03609",
    "title": "Predict and Optimize: Through the Lens of Learning to Rank",
    "abstract": "Comments: Preprint, under review",
    "descriptor": "\nComments: Preprint, under review\n",
    "authors": [
      "Jayanta Mandi",
      "V\u00edctor Bucarey",
      "Maxime Mulamba",
      "Tias Guns"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2112.03609"
  },
  {
    "id": "arXiv:2112.03763",
    "title": "Creating Multimodal Interactive Agents with Imitation and  Self-Supervised Learning",
    "abstract": "Creating Multimodal Interactive Agents with Imitation and  Self-Supervised Learning",
    "descriptor": "",
    "authors": [
      "DeepMind Interactive Agents Team",
      "Josh Abramson",
      "Arun Ahuja",
      "Arthur Brussee",
      "Federico Carnevale",
      "Mary Cassin",
      "Felix Fischer",
      "Petko Georgiev",
      "Alex Goldin",
      "Mansi Gupta",
      "Tim Harley",
      "Felix Hill",
      "Peter C Humphreys",
      "Alden Hung",
      "Jessica Landon",
      "Timothy Lillicrap",
      "Hamza Merzic",
      "Alistair Muldal",
      "Adam Santoro",
      "Guy Scully",
      "Tamara von Glehn",
      "Greg Wayne",
      "Nathaniel Wong",
      "Chen Yan",
      "Rui Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.03763"
  },
  {
    "id": "arXiv:2112.04251",
    "title": "FRETting about Requirements: Formalised Requirements for an Aircraft  Engine Controller",
    "abstract": "Comments: 22 pages, 3 figures",
    "descriptor": "\nComments: 22 pages, 3 figures\n",
    "authors": [
      "Marie Farrell",
      "Matt Luckcuck",
      "Oisin Sheridan",
      "Rosemary Monahan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2112.04251"
  },
  {
    "id": "arXiv:2112.04459",
    "title": "Self-Supervised Speaker Verification with Simple Siamese Network and  Self-Supervised Regularization",
    "abstract": "Comments: Accepted to ICASSP 2022",
    "descriptor": "\nComments: Accepted to ICASSP 2022\n",
    "authors": [
      "Mufan Sang",
      "Haoqi Li",
      "Fang Liu",
      "Andrew O. Arnold",
      "Li Wan"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2112.04459"
  },
  {
    "id": "arXiv:2112.06267",
    "title": "DiVA: A Scalable, Interactive and Customizable Visual Analytics Platform  for Information Diffusion on Large Networks",
    "abstract": "Comments: 26 pages, 15 figures",
    "descriptor": "\nComments: 26 pages, 15 figures\n",
    "authors": [
      "Dhruv Sahnan",
      "Vasu Goel",
      "Sarah Masud",
      "Chhavi Jain",
      "Vikram Goyal",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2112.06267"
  },
  {
    "id": "arXiv:2112.07342",
    "title": "Learning to Guide and to Be Guided in the Architect-Builder Problem",
    "abstract": "Learning to Guide and to Be Guided in the Architect-Builder Problem",
    "descriptor": "",
    "authors": [
      "Paul Barde",
      "Tristan Karch",
      "Derek Nowrouzezahrai",
      "Cl\u00e9ment Moulin-Frier",
      "Christopher Pal",
      "Pierre-Yves Oudeyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2112.07342"
  },
  {
    "id": "arXiv:2112.08830",
    "title": "Graph-wise Common Latent Factor Extraction for Unsupervised Graph  Representation Learning",
    "abstract": "Comments: Accepted to AAAI 2022",
    "descriptor": "\nComments: Accepted to AAAI 2022\n",
    "authors": [
      "Thilini Cooray",
      "Ngai-Man Cheung"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.08830"
  },
  {
    "id": "arXiv:2112.12354",
    "title": "A Riemann--Hilbert approach to the perturbation theory for orthogonal  polynomials: Applications to numerical linear algebra and random matrix  theory",
    "abstract": "A Riemann--Hilbert approach to the perturbation theory for orthogonal  polynomials: Applications to numerical linear algebra and random matrix  theory",
    "descriptor": "",
    "authors": [
      "Xiucai Ding",
      "Thomas Trogdon"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Mathematical Physics (math-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.12354"
  },
  {
    "id": "arXiv:2112.12693",
    "title": "Deadlock-free asynchronous message reordering in Rust with multiparty  session types",
    "abstract": "Comments: Full-version, 24 pages. Short version to appear in PPoPP 2022. Updated according to the latest modifications of the camera-ready conference version",
    "descriptor": "\nComments: Full-version, 24 pages. Short version to appear in PPoPP 2022. Updated according to the latest modifications of the camera-ready conference version\n",
    "authors": [
      "Zak Cutner",
      "Nobuko Yoshida",
      "Martin Vassor"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.12693"
  },
  {
    "id": "arXiv:2112.12887",
    "title": "A formal approach to good practices in Pseudo-Labeling for Unsupervised  Domain Adaptive Re-Identification",
    "abstract": "Comments: This paper is a preprint under submission at CVIU for review",
    "descriptor": "\nComments: This paper is a preprint under submission at CVIU for review\n",
    "authors": [
      "Fabian Dubourvieux",
      "Romaric Audigier",
      "Ang\u00e9lique Loesch",
      "Samia Ainouz",
      "St\u00e9phane Canu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.12887"
  },
  {
    "id": "arXiv:2112.13744",
    "title": "Improving the Performance of Backward Chained Behavior Trees that use  Reinforcement Learning",
    "abstract": "Improving the Performance of Backward Chained Behavior Trees that use  Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Mart Karta\u0161ev",
      "Justin Saler",
      "Petter \u00d6gren"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.13744"
  },
  {
    "id": "arXiv:2201.02707",
    "title": "ALPHA: Audit that Learns from Previously Hand-Audited Ballots",
    "abstract": "ALPHA: Audit that Learns from Previously Hand-Audited Ballots",
    "descriptor": "",
    "authors": [
      "Philip B. Stark"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Cryptography and Security (cs.CR)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2201.02707"
  },
  {
    "id": "arXiv:2201.03664",
    "title": "Structural complementarity and similarity: linking relational principles  to network structure",
    "abstract": "Comments: 31 pages; 5 figures; 4 tables; pre-review (significantly shortened and simplified version)",
    "descriptor": "\nComments: 31 pages; 5 figures; 4 tables; pre-review (significantly shortened and simplified version)\n",
    "authors": [
      "Szymon Talaga",
      "Andrzej Nowak"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2201.03664"
  },
  {
    "id": "arXiv:2201.05273",
    "title": "A Survey of Pretrained Language Models Based Text Generation",
    "abstract": "Comments: 37 pages, 2 figures, 2 tables",
    "descriptor": "\nComments: 37 pages, 2 figures, 2 tables\n",
    "authors": [
      "Junyi Li",
      "Tianyi Tang",
      "Wayne Xin Zhao",
      "Jian-Yun Nie",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.05273"
  },
  {
    "id": "arXiv:2201.06357",
    "title": "Disentangled Latent Transformer for Interpretable Monocular Height  Estimation",
    "abstract": "Disentangled Latent Transformer for Interpretable Monocular Height  Estimation",
    "descriptor": "",
    "authors": [
      "Zhitong Xiong",
      "Sining Chen",
      "Yilei Shi",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.06357"
  },
  {
    "id": "arXiv:2201.06468",
    "title": "Chaining Value Functions for Off-Policy Learning",
    "abstract": "Chaining Value Functions for Off-Policy Learning",
    "descriptor": "",
    "authors": [
      "Simon Schmitt",
      "John Shawe-Taylor",
      "Hado van Hasselt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.06468"
  },
  {
    "id": "arXiv:2201.07263",
    "title": "Health Advertising on Facebook: Privacy & Policy Considerations",
    "abstract": "Comments: 21 pages, 9 figures",
    "descriptor": "\nComments: 21 pages, 9 figures\n",
    "authors": [
      "Andrea Downing",
      "Eric Perakslis"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2201.07263"
  },
  {
    "id": "arXiv:2201.09042",
    "title": "Uncertainty-aware deep learning methods for robust diabetic retinopathy  classification",
    "abstract": "Uncertainty-aware deep learning methods for robust diabetic retinopathy  classification",
    "descriptor": "",
    "authors": [
      "Joel Jaskari",
      "Jaakko Sahlsten",
      "Theodoros Damoulas",
      "Jeremias Knoblauch",
      "Simo S\u00e4rkk\u00e4",
      "Leo K\u00e4rkk\u00e4inen",
      "Kustaa Hietala",
      "Kimmo Kaski"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.09042"
  },
  {
    "id": "arXiv:2201.10285",
    "title": "Efficient Approximations of the Fisher Matrix in Neural Networks using  Kronecker Product Singular Value Decomposition",
    "abstract": "Efficient Approximations of the Fisher Matrix in Neural Networks using  Kronecker Product Singular Value Decomposition",
    "descriptor": "",
    "authors": [
      "Abdoulaye Koroko",
      "Ani Anciaux-Sedrakian",
      "Ibtihel Gharbia",
      "Val\u00e9rie Gar\u00e8s",
      "Mounir Haddou",
      "Quang Huy Tran"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.10285"
  },
  {
    "id": "arXiv:2201.10713",
    "title": "Adaptive Resonance Theory-based Topological Clustering with a Divisive  Hierarchical Structure Capable of Continual Learning",
    "abstract": "Comments: This paper is currently under review",
    "descriptor": "\nComments: This paper is currently under review\n",
    "authors": [
      "Naoki Masuyama",
      "Narito Amako",
      "Yuna Yamada",
      "Yusuke Nojima",
      "Hisao Ishibuchi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2201.10713"
  },
  {
    "id": "arXiv:2201.11040",
    "title": "A Dependent Dependency Calculus (Extended Version)",
    "abstract": "Comments: Extended version of paper published in ESOP 2022, 2-7 April 2022, Munich, Germany",
    "descriptor": "\nComments: Extended version of paper published in ESOP 2022, 2-7 April 2022, Munich, Germany\n",
    "authors": [
      "Pritam Choudhury",
      "Harley Eades III",
      "Stephanie Weirich"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2201.11040"
  },
  {
    "id": "arXiv:2201.11969",
    "title": "Approximately Equivariant Networks for Imperfectly Symmetric Dynamics",
    "abstract": "Approximately Equivariant Networks for Imperfectly Symmetric Dynamics",
    "descriptor": "",
    "authors": [
      "Rui Wang",
      "Robin Walters",
      "Rose Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11969"
  },
  {
    "id": "arXiv:2201.12179",
    "title": "Plug & Play Attacks: Towards Robust and Flexible Model Inversion Attacks",
    "abstract": "Comments: 21 pages, 10 figures, 10 tables",
    "descriptor": "\nComments: 21 pages, 10 figures, 10 tables\n",
    "authors": [
      "Lukas Struppek",
      "Dominik Hintersdorf",
      "Antonio De Almeida Correia",
      "Antonia Adler",
      "Kristian Kersting"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12179"
  },
  {
    "id": "arXiv:2201.12216",
    "title": "Self-paced learning to improve text row detection in historical  documents with missing labels",
    "abstract": "Self-paced learning to improve text row detection in historical  documents with missing labels",
    "descriptor": "",
    "authors": [
      "Mihaela Gaman",
      "Lida Ghadamiyan",
      "Radu Tudor Ionescu",
      "Marius Popescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12216"
  },
  {
    "id": "arXiv:2201.12360",
    "title": "Variational Neural Cellular Automata",
    "abstract": "Comments: ICLR 2022",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Rasmus Berg Palm",
      "Miguel Gonz\u00e1lez-Duque",
      "Shyam Sudhakaran",
      "Sebastian Risi"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2201.12360"
  },
  {
    "id": "arXiv:2201.12870",
    "title": "General 2-path Problem",
    "abstract": "Comments: 14 pages,3 figures",
    "descriptor": "\nComments: 14 pages,3 figures\n",
    "authors": [
      "Qianghui Xiao"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2201.12870"
  },
  {
    "id": "arXiv:2201.12886",
    "title": "N-HiTS: Neural Hierarchical Interpolation for Time Series Forecasting",
    "abstract": "N-HiTS: Neural Hierarchical Interpolation for Time Series Forecasting",
    "descriptor": "",
    "authors": [
      "Cristian Challu",
      "Kin G. Olivares",
      "Boris N. Oreshkin",
      "Federico Garza",
      "Max Mergenthaler",
      "Artur Dubrawski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.12886"
  },
  {
    "id": "arXiv:2201.12925",
    "title": "Multimodal Maximum Entropy Dynamic Games",
    "abstract": "Comments: Under review for RSS 2022. Supplementary Video: this https URL",
    "descriptor": "\nComments: Under review for RSS 2022. Supplementary Video: this https URL\n",
    "authors": [
      "Oswin So",
      "Kyle Stachowicz",
      "Evangelos A. Theodorou"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.12925"
  },
  {
    "id": "arXiv:2201.13005",
    "title": "On Sub-optimality of Random Binning for Distributed Hypothesis Testing",
    "abstract": "Comments: 6 pages; v2 added a reference",
    "descriptor": "\nComments: 6 pages; v2 added a reference\n",
    "authors": [
      "Shun Watanabe"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.13005"
  },
  {
    "id": "arXiv:2201.13112",
    "title": "Bayesian Optimization for Distributionally Robust Chance-constrained  Problem",
    "abstract": "Comments: 18 pages, 2 figures",
    "descriptor": "\nComments: 18 pages, 2 figures\n",
    "authors": [
      "Yu Inatsu",
      "Shion Takeno",
      "Masayuki Karasuyama",
      "Ichiro Takeuchi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.13112"
  },
  {
    "id": "arXiv:2201.13402",
    "title": "Privacy Limitations Of Interest-based Advertising On The Web: A  Post-mortem Empirical Analysis Of Google's FLoC",
    "abstract": "Privacy Limitations Of Interest-based Advertising On The Web: A  Post-mortem Empirical Analysis Of Google's FLoC",
    "descriptor": "",
    "authors": [
      "Alex Berke",
      "Dan Calacci"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2201.13402"
  },
  {
    "id": "arXiv:2201.13446",
    "title": "A Note on the Relation between Recognisable Series and Regular  Sequences, and their Minimal Linear Representations",
    "abstract": "A Note on the Relation between Recognisable Series and Regular  Sequences, and their Minimal Linear Representations",
    "descriptor": "",
    "authors": [
      "Clemens Heuberger",
      "Daniel Krenn",
      "Gabriel F. Lipnik"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2201.13446"
  },
  {
    "id": "arXiv:2202.00054",
    "title": "Quantum machine learning with subspace states",
    "abstract": "Quantum machine learning with subspace states",
    "descriptor": "",
    "authors": [
      "Iordanis Kerenidis",
      "Anupam Prakash"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.00054"
  },
  {
    "id": "arXiv:2202.00117",
    "title": "Continuous Forecasting via Neural Eigen Decomposition of Stochastic  Dynamics",
    "abstract": "Continuous Forecasting via Neural Eigen Decomposition of Stochastic  Dynamics",
    "descriptor": "",
    "authors": [
      "Stav Belogolovsky",
      "Ido Greenberg",
      "Danny Eitan",
      "Shie Mannor"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.00117"
  },
  {
    "id": "arXiv:2202.00126",
    "title": "Handling Bias in Toxic Speech Detection: A Survey",
    "abstract": "Comments: 28 pages, 4 figures, 7 tables",
    "descriptor": "\nComments: 28 pages, 4 figures, 7 tables\n",
    "authors": [
      "Tanmay Garg",
      "Sarah Masud",
      "Tharun Suresh",
      "Tanmoy Chakraborty"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00126"
  },
  {
    "id": "arXiv:2202.00183",
    "title": "Mixed Variational Finite Elements for Implicit, General-Purpose  Simulation of Deformables",
    "abstract": "Mixed Variational Finite Elements for Implicit, General-Purpose  Simulation of Deformables",
    "descriptor": "",
    "authors": [
      "Ty Trusty",
      "Danny M. Kaufman",
      "David I W Levin"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2202.00183"
  },
  {
    "id": "arXiv:2202.00242",
    "title": "Globally Consistent and Tightly Coupled 3D LiDAR Inertial Mapping",
    "abstract": "Comments: IEEE International Conference on Robotics and Automation (ICRA2022) Video: this https URL",
    "descriptor": "\nComments: IEEE International Conference on Robotics and Automation (ICRA2022) Video: this https URL\n",
    "authors": [
      "Kenji Koide",
      "Masashi Yokozuka",
      "Shuji Oishi",
      "Atsuhiko Banno"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.00242"
  },
  {
    "id": "arXiv:2202.00282",
    "title": "Surrogate Gradients Design",
    "abstract": "Surrogate Gradients Design",
    "descriptor": "",
    "authors": [
      "Luca Herranz-Celotti",
      "Jean Rouat"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00282"
  },
  {
    "id": "arXiv:2202.00312",
    "title": "Rectangular GLT Sequences",
    "abstract": "Rectangular GLT Sequences",
    "descriptor": "",
    "authors": [
      "Giovanni Barbarino",
      "Carlo Garoni",
      "Mariarosa Mazza",
      "Stefano Serra-Capizzano"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.00312"
  },
  {
    "id": "arXiv:2202.00399",
    "title": "Language Dependencies in Adversarial Attacks on Speech Recognition  Systems",
    "abstract": "Language Dependencies in Adversarial Attacks on Speech Recognition  Systems",
    "descriptor": "",
    "authors": [
      "Karla Markert",
      "Donika Mirdita",
      "Konstantin B\u00f6ttinger"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.00399"
  },
  {
    "id": "arXiv:2202.00408",
    "title": "Dimensionality Reduction Meets Message Passing for Graph Node Embeddings",
    "abstract": "Comments: Changed colors in figures 3 and 5 to match the others",
    "descriptor": "\nComments: Changed colors in figures 3 and 5 to match the others\n",
    "authors": [
      "Krzysztof Sadowski",
      "Micha\u0142 Szarmach",
      "Eddie Mattia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00408"
  },
  {
    "id": "arXiv:2202.00424",
    "title": "Improving Parametric Neural Networks for High-Energy Physics (and  Beyond)",
    "abstract": "Comments: 18 pages, 13 figures, 5 tables; typos corrected in table, added caption",
    "descriptor": "\nComments: 18 pages, 13 figures, 5 tables; typos corrected in table, added caption\n",
    "authors": [
      "Luca Anzalone",
      "Tommaso Diotalevi",
      "Daniele Bonacorsi"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00424"
  },
  {
    "id": "arXiv:2202.00471",
    "title": "Causal effect of racial bias in data and machine learning algorithms on  user persuasiveness & discriminatory decision making: An Empirical Study",
    "abstract": "Causal effect of racial bias in data and machine learning algorithms on  user persuasiveness & discriminatory decision making: An Empirical Study",
    "descriptor": "",
    "authors": [
      "Kinshuk Sengupta",
      "Praveen Ranjan Srivastava"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.00471"
  },
  {
    "id": "arXiv:2202.00528",
    "title": "Examining Scaling and Transfer of Language Model Architectures for  Machine Translation",
    "abstract": "Examining Scaling and Transfer of Language Model Architectures for  Machine Translation",
    "descriptor": "",
    "authors": [
      "Biao Zhang",
      "Behrooz Ghorbani",
      "Ankur Bapna",
      "Yong Cheng",
      "Xavier Garcia",
      "Jonathan Shen",
      "Orhan Firat"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00528"
  },
  {
    "id": "arXiv:2202.00538",
    "title": "The impact of removing head movements on audio-visual speech enhancement",
    "abstract": "The impact of removing head movements on audio-visual speech enhancement",
    "descriptor": "",
    "authors": [
      "Zhiqi Kang",
      "Mostafa Sadeghi",
      "Radu Horaud",
      "Xavier Alameda-Pineda",
      "Jacob Donley",
      "Anurag Kumar"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.00538"
  },
  {
    "id": "arXiv:2202.00661",
    "title": "Questions for Flat-Minima Optimization of Modern Neural Networks",
    "abstract": "Questions for Flat-Minima Optimization of Modern Neural Networks",
    "descriptor": "",
    "authors": [
      "Jean Kaddour",
      "Linqing Liu",
      "Ricardo Silva",
      "Matt J. Kusner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00661"
  }
]
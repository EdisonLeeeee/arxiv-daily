[
  {
    "id": "arXiv:2202.07659",
    "title": "Survey of Big Data sizes in 2021",
    "abstract": "The modern increase in data production is driven by multiple factors, and\nseveral stakeholders from various sectors contribute to it. Although drawing a\ncomparison of the sizes at stake for different big data players is hard due to\nthe lack of official data, this report tries to reconstruct the yearly orders\nof magnitude generated by some of the most important organizations by mining\nseveral online sources. The estimation is based on retrieving meaningful\nunitary data production measures for each of the big data sources considered,\nand the yearly amounts are then obtained by conjecturing reasonable per-unit\nsizes. The final result is summarized in the form of a bubble plot.",
    "descriptor": "",
    "authors": [
      "Luca Clissa"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "General Literature (cs.GL)"
    ],
    "url": "https://arxiv.org/abs/2202.07659"
  },
  {
    "id": "arXiv:2202.07682",
    "title": "Better Together? An Evaluation of AI-Supported Code Translation",
    "abstract": "Generative machine learning models have recently been applied to source code,\nfor use cases including translating code between programming languages,\ncreating documentation from code, and auto-completing methods. Yet,\nstate-of-the-art models often produce code that is erroneous or incomplete. In\na controlled study with 32 software engineers, we examined whether such\nimperfect outputs are helpful in the context of Java-to-Python code\ntranslation. When aided by the outputs of a code translation model,\nparticipants produced code with fewer errors than when working alone. We also\nexamined how the quality and quantity of AI translations affected the work\nprocess and quality of outcomes, and observed that providing multiple\ntranslations had a larger impact on the translation process than varying the\nquality of provided translations. Our results tell a complex, nuanced story\nabout the benefits of generative code models and the challenges software\nengineers face when working with their outputs. Our work motivates the need for\nintelligent user interfaces that help software engineers effectively work with\ngenerative code models in order to understand and evaluate their outputs and\nachieve superior outcomes to working alone.",
    "descriptor": "\nComments: 35 pages, 3 figures. To be published in IUI 2022\n",
    "authors": [
      "Justin D. Weisz",
      "Michael Muller",
      "Steven I. Ross",
      "Fernando Martinez",
      "Stephanie Houde",
      "Mayank Agarwal",
      "Kartik Talamadupula",
      "John T. Richards"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.07682"
  },
  {
    "id": "arXiv:2202.07691",
    "title": "The Design and Analysis of a Mobility Game",
    "abstract": "In this paper, we study a routing and travel-mode choice problem for mobility\nsystems with a multimodal transportation network as a mobility game with\ncoupled hybrid action sets. The mobility resources (modes of transportation)\nmay experience delays that grow with the aggregate utilization of the resource.\nWe develop a theoretical framework based on repeated non-cooperative game\ntheory for the travelers' routing and travel-mode choice within a general\nmobility system. This framework aims to study the behavioral impact of the\ntravelers' decision-making on efficiency. We consider the traffic congestion\nand the waiting times at different transport hubs and introduce mobility\nmonetary incentives as part of a pricing scheme. We show that the travelers'\nselfish behavior results in a Nash equilibrium, and then we perform a Price of\nAnarchy analysis to establish that the mobility system's inefficiencies remain\nrelatively low as the number of travelers increases. We deviate from the\nstandard game-theoretic analysis of decision-making by extending our modeling\nframework to capture the subjective behavior of travelers using prospect\ntheory. Finally, we provide a simple example to showcase the effectiveness of\nour mobility game and incentives.",
    "descriptor": "",
    "authors": [
      "Ioannis Vasileios Chremos",
      "Andreas A. Malikopoulos"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.07691"
  },
  {
    "id": "arXiv:2202.07693",
    "title": "On Single Server Private Information Retrieval with Private Coded Side  Information",
    "abstract": "Motivated by an open problem and a conjecture, this work studies the problem\nof single server private information retrieval with private coded side\ninformation (PIR-PCSI) that was recently introduced by Heidarzadeh et al. The\ngoal of PIR-PCSI is to allow a user to efficiently retrieve a desired message\n$\\bm{W}_{\\bm{\\theta}}$, which is one of $K$ independent messages that are\nstored at a server, while utilizing private side information of a linear\ncombination of a uniformly chosen size-$M$ subset\n($\\bm{\\mathcal{S}}\\subset[K]$) of messages. The settings PIR-PCSI-I and\nPIR-PCSI-II correspond to the constraints that $\\bm{\\theta}$ is generated\nuniformly from $[K]\\setminus\\bm{\\mathcal{S}}$, and $\\bm{\\mathcal{S}}$,\nrespectively. In each case, $(\\bm{\\theta},\\bm{\\mathcal{S}})$ must be kept\nprivate from the server. The capacity is defined as the supremum over message\nand field sizes, of achievable rates (number of bits of desired message\nretrieved per bit of download) and is characterized by Heidarzadeh et al. for\nPIR-PCSI-I in general, and for PIR-PCSI-II for $M>(K+1)/2$ as $(K-M+1)^{-1}$.\nFor $2\\leq M\\leq (K+1)/2$ the capacity of PIR-PCSI-II remains open, and it is\nconjectured that even in this case the capacity is $(K-M+1)^{-1}$. We show the\ncapacity of PIR-PCSI-II is equal to $2/K$ for $2 \\leq M \\leq \\frac{K+1}{2}$,\nwhich is strictly larger than the conjectured value, and does not depend on $M$\nwithin this parameter regime. Remarkably, half the side-information is found to\nbe redundant. We also characterize the infimum capacity (infimum over fields\ninstead of supremum), and the capacity with private coefficients. The results\nare generalized to PIR-PCSI-I ($\\theta\\in[K]\\setminus\\mathcal{S}$) and PIR-PCSI\n($\\theta\\in[K]$) settings.",
    "descriptor": "",
    "authors": [
      "Yuxiang Lu",
      "Syed Ali Jafar"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.07693"
  },
  {
    "id": "arXiv:2202.07704",
    "title": "Simulating Malicious Attacks on VANETs for Connected and Autonomous  Vehicle Cybersecurity: A Machine Learning Dataset",
    "abstract": "Connected and Autonomous Vehicles (CAVs) rely on Vehicular Adhoc Networks\nwith wireless communication between vehicles and roadside infrastructure to\nsupport safe operation. However, cybersecurity attacks pose a threat to VANETs\nand the safe operation of CAVs. This study proposes the use of simulation for\nmodelling typical communication scenarios which may be subject to malicious\nattacks. The Eclipse MOSAIC simulation framework is used to model two typical\nroad scenarios, including messaging between the vehicles and infrastructure -\nand both replay and bogus information cybersecurity attacks are introduced. The\nmodel demonstrates the impact of these attacks, and provides an open dataset to\ninform the development of machine learning algorithms to provide anomaly\ndetection and mitigation solutions for enhancing secure communications and safe\ndeployment of CAVs on the road.",
    "descriptor": "\nComments: 12 page, 13 figures, 3 tables, conference CSNDSP 2022\n",
    "authors": [
      "Safras Iqbal",
      "Peter Ball",
      "Muhammad H Kamarudin",
      "Andrew Bradley"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07704"
  },
  {
    "id": "arXiv:2202.07706",
    "title": "Misinformation Detection in Social Media Video Posts",
    "abstract": "With the growing adoption of short-form video by social media platforms,\nreducing the spread of misinformation through video posts has become a critical\nchallenge for social media providers. In this paper, we develop methods to\ndetect misinformation in social media posts, exploiting modalities such as\nvideo and text. Due to the lack of large-scale public data for misinformation\ndetection in multi-modal datasets, we collect 160,000 video posts from Twitter,\nand leverage self-supervised learning to learn expressive representations of\njoint visual and textual data. In this work, we propose two new methods for\ndetecting semantic inconsistencies within short-form social media video posts,\nbased on contrastive learning and masked language modeling. We demonstrate that\nour new approaches outperform current state-of-the-art methods on both\nartificial data generated by random-swapping of positive samples and in the\nwild on a new manually-labeled test set for semantic misinformation.",
    "descriptor": "",
    "authors": [
      "Kehan Wang",
      "David Chan",
      "Seth Z. Zhao",
      "John Canny",
      "Avideh Zakhor"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07706"
  },
  {
    "id": "arXiv:2202.07707",
    "title": "On the Role of Channel Capacity in Learning Gaussian Mixture Models",
    "abstract": "This paper studies the sample complexity of learning the $k$ unknown centers\nof a balanced Gaussian mixture model (GMM) in $\\mathbb{R}^d$ with spherical\ncovariance matrix $\\sigma^2\\mathbf{I}$. In particular, we are interested in the\nfollowing question: what is the maximal noise level $\\sigma^2$, for which the\nsample complexity is essentially the same as when estimating the centers from\nlabeled measurements? To that end, we restrict attention to a Bayesian\nformulation of the problem, where the centers are uniformly distributed on the\nsphere $\\sqrt{d}\\mathcal{S}^{d-1}$. Our main results characterize the exact\nnoise threshold $\\sigma^2$ below which the GMM learning problem, in the large\nsystem limit $d,k\\to\\infty$, is as easy as learning from labeled observations,\nand above which it is substantially harder. The threshold occurs at $\\frac{\\log\nk}{d} = \\frac12\\log\\left( 1+\\frac{1}{\\sigma^2} \\right)$, which is the capacity\nof the additive white Gaussian noise (AWGN) channel. Thinking of the set of $k$\ncenters as a code, this noise threshold can be interpreted as the largest noise\nlevel for which the error probability of the code over the AWGN channel is\nsmall. Previous works on the GMM learning problem have identified the minimum\ndistance between the centers as a key parameter in determining the statistical\ndifficulty of learning the corresponding GMM. While our results are only proved\nfor GMMs whose centers are uniformly distributed over the sphere, they hint\nthat perhaps it is the decoding error probability associated with the center\nconstellation as a channel code that determines the statistical difficulty of\nlearning the corresponding GMM, rather than just the minimum distance.",
    "descriptor": "",
    "authors": [
      "Elad Romanov",
      "Tamir Bendory",
      "Or Ordentlich"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.07707"
  },
  {
    "id": "arXiv:2202.07710",
    "title": "Parallel Virtual Machines Placement with Provable Guarantees",
    "abstract": "Network Function Virtualization (NFV) carries the potential for on-demand\ndeployment of network algorithms in virtual machines (VMs). In large clouds,\nhowever, VM resource allocation incurs delays that hinder the dynamic scaling\nof such NFV deployment. Parallel resource management is a promising direction\nfor boosting performance, but it may significantly increase the communication\noverhead and the decline ratio of deployment attempts. Our work analyzes the\nperformance of various placement algorithms and provides empirical evidence\nthat state-of-the-art parallel resource management dramatically increases the\ndecline ratio of deterministic algorithms but hardly affects randomized\nalgorithms. We, therefore, introduce APSR -- an efficient parallel random\nresource management algorithm that requires information only from a small\nnumber of hosts and dynamically adjusts the degree of parallelism to provide\nprovable decline ratio guarantees. We formally analyze APSR, evaluate it on\nreal workloads, and integrate it into the popular OpenStack cloud management\nplatform. Our evaluation shows that APSR matches the throughput provided by\nother parallel schedulers, while achieving up to 13x lower decline ratio and a\nreduction of over 85% in communication overheads.",
    "descriptor": "",
    "authors": [
      "Itamar Cohen",
      "Gil Einziger",
      "Maayan Goldstein",
      "Yaniv Sa'ar",
      "Gabriel Scalosub",
      "Erez Waisbard"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.07710"
  },
  {
    "id": "arXiv:2202.07712",
    "title": "Privacy Preserving Visual Question Answering",
    "abstract": "We introduce a novel privacy-preserving methodology for performing Visual\nQuestion Answering on the edge. Our method constructs a symbolic representation\nof the visual scene, using a low-complexity computer vision model that jointly\npredicts classes, attributes and predicates. This symbolic representation is\nnon-differentiable, which means it cannot be used to recover the original\nimage, thereby keeping the original image private. Our proposed hybrid solution\nuses a vision model which is more than 25 times smaller than the current\nstate-of-the-art (SOTA) vision models, and 100 times smaller than end-to-end\nSOTA VQA models. We report detailed error analysis and discuss the trade-offs\nof using a distilled vision model and a symbolic representation of the visual\nscene.",
    "descriptor": "",
    "authors": [
      "Cristian-Paul Bara",
      "Qing Ping",
      "Abhinav Mathur",
      "Govind Thattai",
      "Rohith MV",
      "Gaurav S. Sukhatme"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07712"
  },
  {
    "id": "arXiv:2202.07716",
    "title": "Learning Model Predictive Control for Quadrotors",
    "abstract": "Aerial robots can enhance their safe and agile navigation in complex and\ncluttered environments by efficiently exploiting the information collected\nduring a given task. In this paper, we address the learning model predictive\ncontrol problem for quadrotors. We design a learning receding--horizon\nnonlinear control strategy directly formulated on the system nonlinear manifold\nconfiguration space SO(3)xR^3. The proposed approach exploits past successful\ntask iterations to improve the system performance over time while respecting\nsystem dynamics and actuator constraints. We further relax its computational\ncomplexity making it compatible with real-time quadrotor control requirements.\nWe show the effectiveness of the proposed approach in learning a minimum time\ncontrol task, respecting dynamics, actuators, and environment constraints.\nSeveral experiments in simulation and real-world set-up validate the proposed\napproach.",
    "descriptor": "\nComments: This paper has been accepted to the 2022 IEEE International Conference on Robotics and Automation. Please cite this paper with the standard IEEE Conference format. Link to the Video: this https URL\n",
    "authors": [
      "Guanrui Li",
      "Alex Tunchez",
      "Giuseppe Loianno"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.07716"
  },
  {
    "id": "arXiv:2202.07717",
    "title": "Finite- and Fixed-Time Nonovershooting Stabilizers and Safety Filters by  Homogeneous Feedback",
    "abstract": "Non-overshooting stabilization is a form of safe control where the setpoint\nchosen by the user is at the boundary of the safe set. Exponential\nnon-overshooting stabilization, including suitable extensions to systems with\ndeterministic and stochastic disturbances, has been solved by the second author\nand his coauthors. In this paper we develop homogeneous feedback laws for\nfixed-time nonovershooting stabilization for nonlinear systems that are\ninput-output linearizable with a full relative degree, i.e., for systems that\nare diffeomorphically equivalent to the chain of integrators. These homogeneous\nfeedback laws can also assume the secondary role of `fixed-time safety filters'\n(FxTSf filters) which keep the system within the closed safe set for all time\nbut, in the case where the user's nominal control commands approach to the\nunsafe set, allow the system to reach the boundary of the safe set no later\nthan a desired time that is independent of nominal control and independent of\nthe value of the state at the time the nominal control begins to be overridden.",
    "descriptor": "",
    "authors": [
      "Andrey Polyakov",
      "Miroslav Krstic"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.07717"
  },
  {
    "id": "arXiv:2202.07720",
    "title": "Active Uncertainty Learning for Human-Robot Interaction: An Implicit  Dual Control Approach",
    "abstract": "Predictive models are effective in reasoning about human motion, a crucial\npart that affects safety and efficiency in human-robot interaction. However,\nrobots often lack access to certain key parameters of such models, for example,\nhuman's objectives, their level of distraction, and willingness to cooperate.\nDual control theory addresses this challenge by treating unknown parameters as\nstochastic hidden states and identifying their values using information\ngathered during control of the robot. Despite its ability to optimally and\nautomatically trade off exploration and exploitation, dual control is\ncomputationally intractable for general human-in-the-loop motion planning,\nmainly due to nested trajectory optimization and human intent prediction. In\nthis paper, we present a novel algorithmic approach to enable active\nuncertainty learning for human-in-the-loop motion planning based on the\nimplicit dual control paradigm. Our approach relies on sampling-based\napproximation of stochastic dynamic programming, leading to a model predictive\ncontrol problem that can be readily solved by real-time gradient-based\noptimization methods. The resulting policy is shown to preserve the dual\ncontrol effect for generic human predictive models with both continuous and\ncategorical uncertainty. The efficacy of our approach is demonstrated with\nsimulated driving examples.",
    "descriptor": "",
    "authors": [
      "Haimin Hu",
      "Jaime F. Fisac"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.07720"
  },
  {
    "id": "arXiv:2202.07721",
    "title": "End-to-end Automatic Logic Optimization Exploration via Domain-specific  Multi-armed Bandit",
    "abstract": "Recent years have seen increasing employment of decision intelligence in\nelectronic design automation (EDA), which aims to reduce the manual efforts and\nboost the design closure process in modern toolflows. However, existing\napproaches either require a large number of labeled data and expensive training\nefforts, or are limited in practical EDA toolflow integration due to\ncomputation overhead. This paper presents a generic end-to-end sequential\ndecision making framework FlowTune for synthesis tooflow optimization, with a\nnovel high-performance domain-specific, multi-stage multi-armed bandit (MAB)\napproach. This framework addresses optimization problems on Boolean\noptimization problems such as a) And-Inv-Graphs (# nodes), b) Conjunction\nNormal Form (CNF) minimization (# clauses) for Boolean Satisfiability; logic\nsynthesis and technology mapping problems such as c) post static timing\nanalysis (STA) delay and area optimization for standard-cell technology\nmapping, and d) FPGA technology mapping for 6-in LUT architectures. Moreover,\nwe demonstrate the high extnsibility and generalizability of the proposed\ndomain-specific MAB approach with end-to-end FPGA design flow, evaluated at\npost-routing stage, with two different FPGA backend tools (OpenFPGA and VPR)\nand two different logic synthesis representations (AIGs and MIGs). FlowTune is\nfully integrated with ABC [1], Yosys [2], VTR [3], LSOracle [4], OpenFPGA [5],\nand industrial tools, and is released publicly. The experimental results\nconducted on various design stages in the flow all demonstrate that our\nframework outperforms both hand-crafted flows [1] and ML explored flows [6],\n[7] in quality of results, and is orders of magnitude faster compared to\nML-based approaches.",
    "descriptor": "\nComments: 13 pages\n",
    "authors": [
      "Walter Lau Neto",
      "Yingjie Li",
      "Pierre-Emmanuel Gaillardon",
      "Cunxi Yu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2202.07721"
  },
  {
    "id": "arXiv:2202.07722",
    "title": "Control Co-design of Actively Controlled Lightweight Structures for  High-acceleration Precision Motion Systems",
    "abstract": "Precision motion stages are an essential part of a wide range of\nmanufacturing equipment, and their motion performance are critical to the\nquality and throughput of the systems. The drastically increasing demand for\nhigher manufacturing throughput in various processes necessities the\ndevelopment of next-generation motion systems with reduced moving weight and\nhigh control bandwidth. However, the reduction of moving stage's weight can\nlower the stage's structural resonance frequencies, making the hardware\ndynamics and controller design problem strongly coupled. Aiming at this\nchallenge, this paper proposes a new formulation of nested hardware and control\nco-design framework for precision motion stages. The proposed framework\nexplicitly optimizes the closed-loop control bandwidth with guaranteed\nrobustness, and explicitly considers the limits in the physical system. Two\ncase studies, including a motivating example using lumped-parameter mechanical\nsystem and a finite-element-simulated lightweight motion stage, are being used\nto evaluate the effectiveness of the proposed nested CCD framework. Simulation\nresults show that the proposed nested CCD framework has 42\\% of weight\nreduction and 28\\% bandwidth improvement compared with a sequential design\nbaseline, which demonstrates the efficacy of the proposed approach.",
    "descriptor": "",
    "authors": [
      "Jingjie Wu",
      "Lei Zhou"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.07722"
  },
  {
    "id": "arXiv:2202.07726",
    "title": "Two Numerical Approaches for Nonlinear Weakly Singular Integral  Equations",
    "abstract": "Singularity subtraction for linear weakly singular Fredholm integral\nequations of the second kind is generalized to nonlinear integral equations.\nTwo approaches are presented: The Classical Approach discretizes the nonlinear\nproblem, and uses some finite dimensional linearization process to solve\nnumerically the discrete problem. Its convergence is proved under mild\nhypotheses on the nonlinearity and the quadrature rule of the singularity\nsubtraction scheme. The New Approach is based on linearization of the problem\nin its infinite dimensional setting, and discretization of the sequence of\nlinear problems by singularity subtraction. It is more efficient than the\nformer, as two numerical experiments confirm.",
    "descriptor": "\nComments: 25 pages, 4 figures, 4 tables\n",
    "authors": [
      "M. Ahues",
      "F. Dias d'Almeida",
      "R. Fernandes",
      "P. B. Vasconcelos"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.07726"
  },
  {
    "id": "arXiv:2202.07728",
    "title": "Don't Lie to Me! Robust and Efficient Explainability with Verified  Perturbation Analysis",
    "abstract": "A variety of methods have been proposed to try to explain how deep neural\nnetworks make their decisions. Key to those approaches is the need to sample\nthe pixel space efficiently in order to derive importance maps. However, it has\nbeen shown that the sampling methods used to date introduce biases and other\nartifacts, leading to inaccurate estimates of the importance of individual\npixels and severely limit the reliability of current explainability methods.\nUnfortunately, the alternative -- to exhaustively sample the image space is\ncomputationally prohibitive. In this paper, we introduce EVA (Explaining using\nVerified perturbation Analysis) -- the first explainability method guarantee to\nhave an exhaustive exploration of a perturbation space. Specifically, we\nleverage the beneficial properties of verified perturbation analysis -- time\nefficiency, tractability and guaranteed complete coverage of a manifold -- to\nefficiently characterize the input variables that are most likely to drive the\nmodel decision. We evaluate the approach systematically and demonstrate\nstate-of-the-art results on multiple benchmarks.",
    "descriptor": "",
    "authors": [
      "Thomas Fel",
      "Melanie Ducoffe",
      "David Vigouroux",
      "Remi Cadene",
      "Mikael Capelle",
      "Claire Nicodeme",
      "Thomas Serre"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07728"
  },
  {
    "id": "arXiv:2202.07730",
    "title": "Rankings in the Zerkani network by a game theoretical approach",
    "abstract": "This paper introduces the Banzhaf and Banzhaf-Owen values as novel centrality\nmeasures for ranking terrorists in a network. This new approach let integrate\nthe complete topology (i.e. nodes and edges) of the network and a coalitional\nstructure on the nodes of the network. More precisely, the characteristics of\nthe nodes (e.g., terrorists) of the network and their possible relationships\n(e.g., types of communication links), as well as coalitional information (e.g.\nlevel of hierarchies) independent of the network. First, for both centrality\nmeasures, we provide approximation algorithms and the corresponding R-codes.\nSecond, as illustration, we rank the members of the Zerkani network,\nresponsible for the attacks in Paris (2015) and Brussels (2016). Finally, we\ngive a comparison between the rankings established by Banzhaf and Banzhaf-Owen\nand the rankings obtained when using the Shapley value (cf. Hamers et al.,\n2019) and the Owen value as centrality measures",
    "descriptor": "",
    "authors": [
      "Encarnaci\u00f3n Algaba",
      "Andrea Prieto",
      "Alejandro Saavedra-Nieves"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2202.07730"
  },
  {
    "id": "arXiv:2202.07731",
    "title": "Enhancing Deformable Convolution based Video Frame Interpolation with  Coarse-to-fine 3D CNN",
    "abstract": "This paper presents a new deformable convolution-based video frame\ninterpolation (VFI) method, using a coarse to fine 3D CNN to enhance the\nmulti-flow prediction. This model first extracts spatio-temporal features at\nmultiple scales using a 3D CNN, and estimates multi-flows using these features\nin a coarse-to-fine manner. The estimated multi-flows are then used to warp the\noriginal input frames as well as context maps, and the warped results are fused\nby a synthesis network to produce the final output. This VFI approach has been\nfully evaluated against 12 state-of-the-art VFI methods on three commonly used\ntest databases. The results evidently show the effectiveness of the proposed\nmethod, which offers superior interpolation performance over other state of the\nart algorithms, with PSNR gains up to 0.19dB.",
    "descriptor": "",
    "authors": [
      "Duolikun Danier",
      "Fan Zhang",
      "David Bull"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.07731"
  },
  {
    "id": "arXiv:2202.07732",
    "title": "Multi-Modal Data Fusion in Enhancing Human-Machine Interaction for  Robotic Applications: A Survey",
    "abstract": "Human-machine interaction has been around for several decades now, with new\napplications emerging every day. One of the major goals that remain to be\nachieved is designing an interaction similar to how a human interacts with\nanother human. Therefore, there is a need to develop interactive systems that\ncould replicate a more realistic and easier human-machine interaction. On the\nother hand, developers and researchers need to be aware of state-of-the-art\nmethodologies being used to achieve this goal. We present this survey to\nprovide researchers with state-of-the-art data fusion technologies implemented\nusing multiple inputs to accomplish a task in the robotic application domain.\nMoreover, the input data modalities are broadly classified into uni-modal and\nmulti-modal systems and their application in myriad industries, including the\nhealth care industry, which contributes to the medical industry's future\ndevelopment. It will help the professionals to examine patients using different\nmodalities. The multi-modal systems are differentiated by a combination of\ninputs used as a single input, e.g., gestures, voice, sensor, and haptic\nfeedback. All these inputs may or may not be fused, which provides another\nclassification of multi-modal systems. The survey concludes with a summary of\ntechnologies in use for multi-modal systems.",
    "descriptor": "",
    "authors": [
      "Tauheed Khan Mohd",
      "Nicole Nguyen",
      "Ahmad Y Javaid"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.07732"
  },
  {
    "id": "arXiv:2202.07735",
    "title": "A Light-Weight Multi-Objective Asynchronous Hyper-Parameter Optimizer",
    "abstract": "We describe a light-weight yet performant system for hyper-parameter\noptimization that approximately minimizes an overall scalar cost function that\nis obtained by combining multiple performance objectives using a\ntarget-priority-limit scalarizer. It also supports a trade-off mode, where the\ngoal is to find an appropriate trade-off among objectives by interacting with\nthe user. We focus on the common scenario where there are on the order of tens\nof hyper-parameters, each with various attributes such as a range of continuous\nvalues, or a finite list of values, and whether it should be treated on a\nlinear or logarithmic scale. The system supports multiple asynchronous\nsimulations and is robust to simulation stragglers and failures.",
    "descriptor": "",
    "authors": [
      "Gabriel Maher",
      "Stephen Boyd",
      "Mykel Kochenderfer",
      "Cristian Matache",
      "Alex Ulitsky",
      "Slava Yukhymuk",
      "Leonid Kopman"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07735"
  },
  {
    "id": "arXiv:2202.07736",
    "title": "Hardness of the (Approximate) Shortest Vector Problem: A Simple Proof  via Reed-Solomon Codes",
    "abstract": "$\\newcommand{\\NP}{\\mathsf{NP}}\\newcommand{\\GapSVP}{\\textrm{GapSVP}}$We give a\nsimple proof that the (approximate, decisional) Shortest Vector Problem is\n$\\NP$-hard under a randomized reduction. Specifically, we show that for any $p\n\\geq 1$ and any constant $\\gamma < 2^{1/p}$, the $\\gamma$-approximate problem\nin the $\\ell_p$ norm ($\\gamma$-$\\GapSVP_p$) is not in $\\mathsf{RP}$ unless $\\NP\n\\subseteq \\mathsf{RP}$. Our proof follows an approach pioneered by Ajtai (STOC\n1998), and strengthened by Micciancio (FOCS 1998 and SICOMP 2000), for showing\nhardness of $\\gamma$-$\\GapSVP_p$ using locally dense lattices. We construct\nsuch lattices simply by applying \"Construction A\" to Reed-Solomon codes with\nsuitable parameters, and prove their local density via an elementary argument\noriginally used in the context of Craig lattices.\nAs in all known $\\NP$-hardness results for $\\GapSVP_p$ with $p < \\infty$, our\nreduction uses randomness. Indeed, it is a notorious open problem to prove\n$\\NP$-hardness via a deterministic reduction. To this end, we additionally\ndiscuss potential directions and associated challenges for derandomizing our\nreduction. In particular, we show that a close deterministic analogue of our\nlocal density construction would improve on the state-of-the-art explicit\nReed-Solomon list-decoding lower bounds of Guruswami and Rudra (STOC 2005 and\nIEEE Trans. Inf. Theory 2006).\nAs a related contribution of independent interest, we also give a\npolynomial-time algorithm for decoding $n$-dimensional \"Construction A\nReed-Solomon lattices\" (with different parameters than those used in our\nhardness proof) to a distance within an $O(\\sqrt{\\log n})$ factor of\nMinkowski's bound. This asymptotically matches the best known distance for\ndecoding near Minkowski's bound, due to Mook and Peikert (IEEE Trans. Inf.\nTheory 2022), whose work we build on with a somewhat simpler construction and\nanalysis.",
    "descriptor": "",
    "authors": [
      "Huck Bennett",
      "Chris Peikert"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.07736"
  },
  {
    "id": "arXiv:2202.07737",
    "title": "Ab-initio Contrast Estimation and Denoising of Cryo-EM Images",
    "abstract": "Background and Objective: The contrast of cryo-EM images vary from one to\nanother, primarily due to the uneven thickness of ice layers. The variation of\ncontrast can affect the quality of 2-D class averaging, 3-D ab-initio modeling,\nand 3-D heterogeneity analysis. Contrast estimation is currently performed\nduring 3-D iterative refinement. As a result, the estimates are not available\nfor class averaging and ab-initio modeling. However, these methods require good\ninitial estimates of 3-D volumes and 3-D rotations of molecules. This paper\naims to solve the contrast estimation problem in the ab-initio stage, without\nestimating the 3-D volume.\nMethods: The key observation underlying our analysis is that the 2-D\ncovariance matrix of the raw images is related to the covariance of the\nunderlying clean images, the noise variance, and the contrast variability\nbetween images. We show that the contrast variability can be derived from the\n2-D covariance matrix and use the existing Covariance Wiener Filtering (CWF)\nframework to estimate it. We also demonstrate a modification of CWF to estimate\nthe contrast of individual images.\nResults: Our method improves the contrast estimation by a large margin,\ncompared to the previous CWF method. Its estimation accuracy is often\ncomparable to that of an oracle that knows the ground truth covariance of the\nclean images. The more accurate contrast estimation also improves the quality\nof image denoising as demonstrated in both synthetic and experimental datasets.\nConclusions: This paper proposes an effective method for contrast estimation\ndirectly from noisy images without using any 3-D volume information. It enables\ncontrast correction in the earlier stage of single particle analysis, and may\nimprove the accuracy of downstream processing.",
    "descriptor": "",
    "authors": [
      "Yunpeng Shi",
      "Amit Singer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07737"
  },
  {
    "id": "arXiv:2202.07740",
    "title": "Attracting and Retaining OSS Contributors with a Maintainer Dashboard",
    "abstract": "Tools and artifacts produced by open source software (OSS) have been woven\ninto the foundation of the technology industry. To keep this foundation intact,\nthe open source community needs to actively invest in sustainable approaches to\nbring in new contributors and nurture existing ones. We take a first step at\nthis by collaboratively designing a maintainer dashboard that provides\nrecommendations on how to attract and retain open source contributors. For\nexample, by highlighting project goals (e.g., a social good cause) to attract\ndiverse contributors and mechanisms to acknowledge (e.g., a \"rising\ncontributor\" badge) existing contributors. Next, we conduct a project-specific\nevaluation with maintainers to better understand use cases in which this tool\nwill be most helpful at supporting their plans for growth. From analyzing\nfeedback, we find recommendations to be useful at signaling projects as\nwelcoming and providing gentle nudges for maintainers to proactively recognize\nemerging contributors. However, there are complexities to consider when\ndesigning recommendations such as the project current development state (e.g.,\ndeadlines, milestones, refactoring) and governance model. Finally, we distill\nour findings to share what the future of recommendations in open source looks\nlike and how to make these recommendations most meaningful over time.",
    "descriptor": "\nComments: 5 pages, Accepted at ICSE SEIS 2022\n",
    "authors": [
      "Mariam Guizani",
      "Thomas Zimmermann",
      "Anita Sarma",
      "Denae Ford"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.07740"
  },
  {
    "id": "arXiv:2202.07741",
    "title": "Disentangling Successor Features for Coordination in Multi-agent  Reinforcement Learning",
    "abstract": "Multi-agent reinforcement learning (MARL) is a promising framework for\nsolving complex tasks with many agents. However, a key challenge in MARL is\ndefining private utility functions that ensure coordination when training\ndecentralized agents. This challenge is especially prevalent in unstructured\ntasks with sparse rewards and many agents. We show that successor features can\nhelp address this challenge by disentangling an individual agent's impact on\nthe global value function from that of all other agents. We use this\ndisentanglement to compactly represent private utilities that support stable\ntraining of decentralized agents in unstructured tasks. We implement our\napproach using a centralized training, decentralized execution architecture and\ntest it in a variety of multi-agent environments. Our results show improved\nperformance and training time relative to existing methods and suggest that\ndisentanglement of successor features offers a promising approach to\ncoordination in MARL.",
    "descriptor": "\nComments: The paper is accepted in AAMAS 2022 (International Conference on Autonomous Agents and Multiagent Systems)\n",
    "authors": [
      "Seung Hyun Kim",
      "Neale Van Stralen",
      "Girish Chowdhary",
      "Huy T. Tran"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.07741"
  },
  {
    "id": "arXiv:2202.07745",
    "title": "High-dimensional dynamic factor models: a selective survey and lines of  future research",
    "abstract": "High-Dimensional Dynamic Factor Models are presented in detail: The main\nassumptions and their motivation, main results, illustrations by means of\nelementary examples. In particular, the role of singular ARMA models in the\ntheory and applications of High-Dimensional Dynamic Factor Models is\ndiscussed.The emphasis of the paper is on model classes and their structure\ntheory, rather than on estimation in the narrow sense. Our aim is not a\ncomprehensive survey. Rather we try to point out promising lines of research\nand applications that have not yet been sufficiently developed.",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Marco Lippi",
      "Manfred Deistler",
      "Brian Anderson"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2202.07745"
  },
  {
    "id": "arXiv:2202.07754",
    "title": "Normalized K-Means for Noise-Insensitive Multi-Dimensional Feature  Learning",
    "abstract": "Many measurement modalities which perform imaging by probing an object\npixel-by-pixel, such as via Photoacoustic Microscopy, produce a\nmulti-dimensional feature (typically a time-domain signal) at each pixel. In\nprinciple, the many degrees of freedom in the time-domain signal would admit\nthe possibility of significant multi-modal information being implicitly\npresent, much more than a single scalar \"brightness\", regarding the underlying\ntargets being observed. However, the measured signal is neither a weighted-sum\nof basis functions (such as principal components) nor one of a set of\nprototypes (K-means), which has motivated the novel clustering method proposed\nhere, capable of learning centroids (signal shapes) that are related to the\nunderlying, albeit unknown, target characteristics in a scalable and\nnoise-robust manner.",
    "descriptor": "\nComments: Submitted to ICPR 2022. 6 pages (excluding references), 4 figures\n",
    "authors": [
      "Nicholas Pellegrino",
      "Paul Fieguth",
      "Parsin Haji Reza"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.07754"
  },
  {
    "id": "arXiv:2202.07757",
    "title": "Architecture Agnostic Federated Learning for Neural Networks",
    "abstract": "With growing concerns regarding data privacy and rapid increase in data\nvolume, Federated Learning(FL) has become an important learning paradigm.\nHowever, jointly learning a deep neural network model in a FL setting proves to\nbe a non-trivial task because of the complexities associated with the neural\nnetworks, such as varied architectures across clients, permutation invariance\nof the neurons, and presence of non-linear transformations in each layer. This\nwork introduces a novel Federated Heterogeneous Neural Networks (FedHeNN)\nframework that allows each client to build a personalised model without\nenforcing a common architecture across clients. This allows each client to\noptimize with respect to local data and compute constraints, while still\nbenefiting from the learnings of other (potentially more powerful) clients. The\nkey idea of FedHeNN is to use the instance-level representations obtained from\npeer clients to guide the simultaneous training on each client. The extensive\nexperimental results demonstrate that the FedHeNN framework is capable of\nlearning better performing models on clients in both the settings of\nhomogeneous and heterogeneous architectures across clients.",
    "descriptor": "",
    "authors": [
      "Disha Makhija",
      "Xing Han",
      "Nhat Ho",
      "Joydeep Ghosh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07757"
  },
  {
    "id": "arXiv:2202.07760",
    "title": "Explainable Predictive Process Monitoring: A User Evaluation",
    "abstract": "Explainability is motivated by the lack of transparency of black-box Machine\nLearning approaches, which do not foster trust and acceptance of Machine\nLearning algorithms. This also happens in the Predictive Process Monitoring\nfield, where predictions, obtained by applying Machine Learning techniques,\nneed to be explained to users, so as to gain their trust and acceptance. In\nthis work, we carry on a user evaluation on explanation approaches for\nPredictive Process Monitoring aiming at investigating whether and how the\nexplanations provided (i) are understandable; (ii) are useful in decision\nmaking tasks;(iii) can be further improved for process analysts, with different\nMachine Learning expertise levels. The results of the user evaluation show\nthat, although explanation plots are overall understandable and useful for\ndecision making tasks for Business Process Management users -- with and without\nexperience in Machine Learning -- differences exist in the comprehension and\nusage of different plots, as well as in the way users with different Machine\nLearning expertise understand and use them.",
    "descriptor": "",
    "authors": [
      "Williams Rizzi",
      "Marco Comuzzi",
      "Chiara Di Francescomarino",
      "Chiara Ghidini",
      "Suhwan Lee",
      "Fabrizio Maria Maggi",
      "Alexander Nolte"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07760"
  },
  {
    "id": "arXiv:2202.07761",
    "title": "Further Collapses in TFNP",
    "abstract": "We show $\\textsf{EOPL}=\\textsf{PLS}\\cap\\textsf{PPAD}$. Here the class\n$\\textsf{EOPL}$ consists of all total search problems that reduce to the\nEnd-of-Potential-Line problem, which was introduced in the works by Hubacek and\nYogev (SICOMP 2020) and Fearnley et al. (JCSS 2020). In particular, our result\nyields a new simpler proof of the breakthrough collapse\n$\\textsf{CLS}=\\textsf{PLS}\\cap\\textsf{PPAD}$ by Fearnley et al. (STOC 2021). We\nalso prove a companion result $\\textsf{SOPL}=\\textsf{PLS}\\cap\\textsf{PPADS}$,\nwhere $\\textsf{SOPL}$ is the class associated with the Sink-of-Potential-Line\nproblem.",
    "descriptor": "",
    "authors": [
      "Mika G\u00f6\u00f6s",
      "Alexandros Hollender",
      "Siddhartha Jain",
      "Gilbert Maystre",
      "William Pires",
      "Robert Robere",
      "Ran Tao"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.07761"
  },
  {
    "id": "arXiv:2202.07765",
    "title": "General-purpose, long-context autoregressive modeling with Perceiver AR",
    "abstract": "Real-world data is high-dimensional: a book, image, or musical performance\ncan easily contain hundreds of thousands of elements even after compression.\nHowever, the most commonly used autoregressive models, Transformers, are\nprohibitively expensive to scale to the number of inputs and layers needed to\ncapture this long-range structure. We develop Perceiver AR, an autoregressive,\nmodality-agnostic architecture which uses cross-attention to map long-range\ninputs to a small number of latents while also maintaining end-to-end causal\nmasking. Perceiver AR can directly attend to over a hundred thousand tokens,\nenabling practical long-context density estimation without the need for\nhand-crafted sparsity patterns or memory mechanisms. When trained on images or\nmusic, Perceiver AR generates outputs with clear long-term coherence and\nstructure. Our architecture also obtains state-of-the-art likelihood on\nlong-sequence benchmarks, including 64 x 64 ImageNet images and PG-19 books.",
    "descriptor": "",
    "authors": [
      "Curtis Hawthorne",
      "Andrew Jaegle",
      "C\u0103t\u0103lina Cangea",
      "Sebastian Borgeaud",
      "Charlie Nash",
      "Mateusz Malinowski",
      "Sander Dieleman",
      "Oriol Vinyals",
      "Matthew Botvinick",
      "Ian Simon",
      "Hannah Sheahan",
      "Neil Zeghidour",
      "Jean-Baptiste Alayrac",
      "Jo\u00e3o Carreira",
      "Jesse Engel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.07765"
  },
  {
    "id": "arXiv:2202.07766",
    "title": "LIMREF: Local Interpretable Model Agnostic Rule-based Explanations for  Forecasting, with an Application to Electricity Smart Meter Data",
    "abstract": "Accurate electricity demand forecasts play a crucial role in sustainable\npower systems. To enable better decision-making especially for demand\nflexibility of the end-user, it is necessary to provide not only accurate but\nalso understandable and actionable forecasts. To provide accurate forecasts\nGlobal Forecasting Models (GFM) trained across time series have shown superior\nresults in many demand forecasting competitions and real-world applications\nrecently, compared with univariate forecasting approaches. We aim to fill the\ngap between the accuracy and the interpretability in global forecasting\napproaches. In order to explain the global model forecasts, we propose Local\nInterpretable Model-agnostic Rule-based Explanations for Forecasting (LIMREF),\na local explainer framework that produces k-optimal impact rules for a\nparticular forecast, considering the global forecasting model as a black-box\nmodel, in a model-agnostic way. It provides different types of rules that\nexplain the forecast of the global model and the counterfactual rules, which\nprovide actionable insights for potential changes to obtain different outputs\nfor given instances. We conduct experiments using a large-scale electricity\ndemand dataset with exogenous features such as temperature and calendar\neffects. Here, we evaluate the quality of the explanations produced by the\nLIMREF framework in terms of both qualitative and quantitative aspects such as\naccuracy, fidelity, and comprehensibility and benchmark those against other\nlocal explainers.",
    "descriptor": "\nComments: Accepted as a conference paper to AAAI 2022\n",
    "authors": [
      "Dilini Rajapaksha",
      "Christoph Bergmeir"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07766"
  },
  {
    "id": "arXiv:2202.07769",
    "title": "Bohemian Matrix Geometry",
    "abstract": "A Bohemian matrix family is a set of matrices all of whose entries are drawn\nfrom a fixed, usually discrete and hence bounded, subset of a field of\ncharacteristic zero. Originally these were integers -- hence the name, from the\nacronym BOunded HEight Matrix of Integers (BOHEMI) -- but other kinds of\nentries are also interesting. Some kinds of questions about Bohemian matrices\ncan be answered by numerical computation, but sometimes exact computation is\nbetter. In this paper we explore some Bohemian families (symmetric, upper\nHessenberg, or Toeplitz) computationally, and answer some open questions posed\nabout the distributions of eigenvalue densities.",
    "descriptor": "\nComments: 22 pages; 12 figures;\n",
    "authors": [
      "Robert M. Corless",
      "George Labahn",
      "Dan Piponi",
      "Leili Rafiee Sevyeri"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.07769"
  },
  {
    "id": "arXiv:2202.07775",
    "title": "The Promising Marriage of Mobile Edge Computing and Cell-Free Massive  MIMO",
    "abstract": "This paper considers a mobile edge computing-enabled cell-free massive MIMO\nwireless network. An optimization problem for the joint allocation of uplink\npowers and remote computational resources is formulated, aimed at minimizing\nthe total uplink power consumption under latency constraints, while\nsimultaneously also maximizing the minimum SE throughout the network. Since the\nconsidered problem is non-convex, an iterative algorithm based on sequential\nconvex programming is devised. A detailed performance comparison between the\nproposed distributed architecture and its co-located counterpart, based on a\nmulti-cell massive MIMO deployment, is provided. Numerical results reveal the\nnatural suitability of cell-free massive MIMO in supporting\ncomputation-offloading applications, with benefits over users' transmit power\nand energy consumption, the offloading latency experienced, and the total\namount of allocated remote computational resources.",
    "descriptor": "\nComments: Paper accepted for presentation in IEEE ICC 2022. {\\copyright} 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses. arXiv admin note: substantial text overlap with arXiv:2111.04678\n",
    "authors": [
      "Giovanni Interdonato",
      "Stefano Buzzi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.07775"
  },
  {
    "id": "arXiv:2202.07777",
    "title": "Generalizing continuous flexible Kokotsakis belts of the isogonal type",
    "abstract": "Kokotsakis studied the following problem in 1932: Given is a rigid closed\npolygonal line (planar or non-planar), which is surrounded by a polyhedral\nstrip, where at each polygon vertex three faces meet. Determine the geometries\nof these closed strips with a continuous mobility. On the one side, we\ngeneralize this problem by allowing the faces, which are adjacent to polygon\nline-segments, to be skew; i.e to be non-planar. But on the other side, we\nrestrict to the case where the four angles associated with each polygon vertex\nfulfill the so-called isogonality condition that both pairs of opposite angles\nare equal or supplementary. In more detail, we study the case where the\npolygonal line is a skew quad, as this corresponds to a (3x3) building block of\na so-called V-hedra composed of skew quads. The latter also gives a positive\nanswer to a question posed by Robert Sauer in his book of 1970 whether\ncontinuous flexible skew quad surfaces exist.",
    "descriptor": "\nComments: 12 pages, 6 figures\n",
    "authors": [
      "Georg Nawratil"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)",
      "Algebraic Geometry (math.AG)"
    ],
    "url": "https://arxiv.org/abs/2202.07777"
  },
  {
    "id": "arXiv:2202.07778",
    "title": "Beyond Deterministic Translation for Unsupervised Domain Adaptation",
    "abstract": "In this work we challenge the common approach of using a one-to-one mapping\n('translation') between the source and target domains in unsupervised domain\nadaptation (UDA). Instead, we rely on stochastic translation to capture\ninherent translation ambiguities. This allows us to (i) train more accurate\ntarget networks by generating multiple outputs conditioned on the same source\nimage, leveraging both accurate translation and data augmentation for\nappearance variability, (ii) impute robust pseudo-labels for the target data by\naveraging the predictions of a source network on multiple translated versions\nof a single target image and (iii) train and ensemble diverse networks in the\ntarget domain by modulating the degree of stochasticity in the translations. We\nreport improvements over strong recent baselines, leading to state-of-the-art\nUDA results on two challenging semantic segmentation benchmarks.",
    "descriptor": "",
    "authors": [
      "Eleni Chiou",
      "Eleftheria Panagiotaki",
      "Iasonas Kokkinos"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07778"
  },
  {
    "id": "arXiv:2202.07779",
    "title": "Binary Classification for High Dimensional Data using Supervised  Non-Parametric Ensemble Method",
    "abstract": "Medical Research data used for prognostication deals with binary\nclassification problems in most of the cases. The endocrinological disorders\nhave data available and it can be leveraged using Machine Learning. The dataset\nfor Polycystic Ovary Syndrome is available, which is termed as an\nendocrinological disorder in women. Non-Parametric Supervised Ensemble machine\nlearning methods can be used for prediction of the disorder in early stages. In\nthis paper we present the Bootstrap Aggregation Supervised Ensemble\nNon-parametric method for prognostication that competes state-of-the-art\nperformance with accuracy of over 92% along with in depth analysis of the data.",
    "descriptor": "\nComments: 9 pages, 8 figures\n",
    "authors": [
      "Nandan Kanvinde",
      "Abhishek Gupta",
      "Raunak Joshi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07779"
  },
  {
    "id": "arXiv:2202.07785",
    "title": "Predictability and Surprise in Large Generative Models",
    "abstract": "Large-scale pre-training has recently emerged as a technique for creating\ncapable, general purpose, generative models such as GPT-3, Megatron-Turing NLG,\nGopher, and many others. In this paper, we highlight a counterintuitive\nproperty of such models and discuss the policy implications of this property.\nNamely, these generative models have an unusual combination of predictable loss\non a broad training distribution (as embodied in their \"scaling laws\"), and\nunpredictable specific capabilities, inputs, and outputs. We believe that the\nhigh-level predictability and appearance of useful capabilities drives rapid\ndevelopment of such models, while the unpredictable qualities make it difficult\nto anticipate the consequences of model deployment. We go through examples of\nhow this combination can lead to socially harmful behavior with examples from\nthe literature and real world observations, and we also perform two novel\nexperiments to illustrate our point about harms from unpredictability.\nFurthermore, we analyze how these conflicting properties combine to give model\ndevelopers various motivations for deploying these models, and challenges that\ncan hinder deployment. We conclude with a list of possible interventions the AI\ncommunity may take to increase the chance of these models having a beneficial\nimpact. We intend this paper to be useful to policymakers who want to\nunderstand and regulate AI systems, technologists who care about the potential\npolicy impact of their work, and academics who want to analyze, critique, and\npotentially develop large generative models.",
    "descriptor": "",
    "authors": [
      "Deep Ganguli",
      "Danny Hernandez",
      "Liane Lovitt",
      "Nova DasSarma",
      "Tom Henighan",
      "Andy Jones",
      "Nicholas Joseph",
      "Jackson Kernion",
      "Ben Mann",
      "Amanda Askell",
      "Yuntao Bai",
      "Anna Chen",
      "Tom Conerly",
      "Dawn Drain",
      "Nelson Elhage",
      "Sheer El Showk",
      "Stanislav Fort",
      "Zac Hatfield-Dodds",
      "Scott Johnston",
      "Shauna Kravec",
      "Neel Nanda",
      "Kamal Ndousse",
      "Catherine Olsson",
      "Daniela Amodei",
      "Dario Amodei",
      "Tom Brown",
      "Jared Kaplan",
      "Sam McCandlish",
      "Chris Olah",
      "Jack Clark"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.07785"
  },
  {
    "id": "arXiv:2202.07787",
    "title": "Trustworthy Anomaly Detection: A Survey",
    "abstract": "Anomaly detection has a wide range of real-world applications, such as bank\nfraud detection and cyber intrusion detection. In the past decade, a variety of\nanomaly detection models have been developed, which lead to big progress\ntowards accurately detecting various anomalies. Despite the successes, anomaly\ndetection models still face many limitations. The most significant one is\nwhether we can trust the detection results from the models. In recent years,\nthe research community has spent a great effort to design trustworthy machine\nlearning models, such as developing trustworthy classification models. However,\nthe attention to anomaly detection tasks is far from sufficient. Considering\nthat many anomaly detection tasks are life-changing tasks involving human\nbeings, labeling someone as anomalies or fraudsters should be extremely\ncautious. Hence, ensuring the anomaly detection models conducted in a\ntrustworthy fashion is an essential requirement to deploy the models to conduct\nautomatic decisions in the real world. In this brief survey, we summarize the\nexisting efforts and discuss open problems towards trustworthy anomaly\ndetection from the perspectives of interpretability, fairness, robustness, and\nprivacy-preservation.",
    "descriptor": "\nComments: Paper list, see this https URL\n",
    "authors": [
      "Shuhan Yuan",
      "Xintao Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07787"
  },
  {
    "id": "arXiv:2202.07789",
    "title": "Safe Reinforcement Learning by Imagining the Near Future",
    "abstract": "Safe reinforcement learning is a promising path toward applying reinforcement\nlearning algorithms to real-world problems, where suboptimal behaviors may lead\nto actual negative consequences. In this work, we focus on the setting where\nunsafe states can be avoided by planning ahead a short time into the future. In\nthis setting, a model-based agent with a sufficiently accurate model can avoid\nunsafe states. We devise a model-based algorithm that heavily penalizes unsafe\ntrajectories, and derive guarantees that our algorithm can avoid unsafe states\nunder certain assumptions. Experiments demonstrate that our algorithm can\nachieve competitive rewards with fewer safety violations in several continuous\ncontrol tasks.",
    "descriptor": "\nComments: Accepted at NeurIPS 2021\n",
    "authors": [
      "Garrett Thomas",
      "Yuping Luo",
      "Tengyu Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07789"
  },
  {
    "id": "arXiv:2202.07790",
    "title": "Speech Denoising in the Waveform Domain with Self-Attention",
    "abstract": "In this work, we present CleanUNet, a causal speech denoising model on the\nraw waveform. The proposed model is based on an encoder-decoder architecture\ncombined with several self-attention blocks to refine its bottleneck\nrepresentations, which is crucial to obtain good results. The model is\noptimized through a set of losses defined over both waveform and\nmulti-resolution spectrograms. The proposed method outperforms the\nstate-of-the-art models in terms of denoised speech quality from various\nobjective and subjective evaluation metrics.",
    "descriptor": "\nComments: ICASSP 2022\n",
    "authors": [
      "Zhifeng Kong",
      "Wei Ping",
      "Ambrish Dantrey",
      "Bryan Catanzaro"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.07790"
  },
  {
    "id": "arXiv:2202.07791",
    "title": "Russian SuperGLUE 1.1: Revising the Lessons not Learned by Russian NLP  models",
    "abstract": "In the last year, new neural architectures and multilingual pre-trained\nmodels have been released for Russian, which led to performance evaluation\nproblems across a range of language understanding tasks.\nThis paper presents Russian SuperGLUE 1.1, an updated benchmark styled after\nGLUE for Russian NLP models. The new version includes a number of technical,\nuser experience and methodological improvements, including fixes of the\nbenchmark vulnerabilities unresolved in the previous version: novel and\nimproved tests for understanding the meaning of a word in context (RUSSE) along\nwith reading comprehension and common sense reasoning (DaNetQA, RuCoS, MuSeRC).\nTogether with the release of the updated datasets, we improve the benchmark\ntoolkit based on \\texttt{jiant} framework for consistent training and\nevaluation of NLP-models of various architectures which now supports the most\nrecent models for Russian. Finally, we provide the integration of Russian\nSuperGLUE with a framework for industrial evaluation of the open-source models,\nMOROCCO (MOdel ResOurCe COmparison), in which the models are evaluated\naccording to the weighted average metric over all tasks, the inference speed,\nand the occupied amount of RAM. Russian SuperGLUE is publicly available at\nhttps://russiansuperglue.com/.",
    "descriptor": "\nComments: Computational Linguistics and Intellectual Technologies Papers from the Annual International Conference \"Dialogue\" (2021) Issue 20\n",
    "authors": [
      "Alena Fenogenova",
      "Maria Tikhonova",
      "Vladislav Mikhailov",
      "Tatiana Shavrina",
      "Anton Emelyanov",
      "Denis Shevelev",
      "Alexandr Kukushkin",
      "Valentin Malykh",
      "Ekaterina Artemova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07791"
  },
  {
    "id": "arXiv:2202.07792",
    "title": "Efficient Content Delivery in Cache-Enabled VEN with  Deadline-Constrained Heterogeneous Demands: A User-Centric Approach",
    "abstract": "Modern connected vehicles (CVs) frequently require diverse types of content\nfor mission-critical decision-making and onboard users' entertainment. These\ncontents are required to be fully delivered to the requester CVs within\nstringent deadlines that the existing radio access technology (RAT) solutions\nmay fail to ensure. Motivated by the above consideration, this paper exploits\ncontent caching with a software-defined user-centric virtual cell (VC) based\nRAT solution for delivering the requested contents from a proximity edge\nserver. Moreover, to capture the heterogeneous demands of the CVs, we introduce\na preference-popularity tradeoff in their content request model. To that end,\nwe formulate a joint optimization problem for content placement, CV scheduling,\nVC configuration, VC-CV association and radio resource allocation to minimize\nlong-term content delivery delay. However, the joint problem is highly complex\nand cannot be solved efficiently in polynomial time. As such, we decompose the\noriginal problem into a cache placement problem and a content delivery delay\nminimization problem given the cache placement policy. We use deep\nreinforcement learning (DRL) as a learning solution for the first sub-problem.\nFurthermore, we transform the delay minimization problem into a priority-based\nweighted sum rate (WSR) maximization problem, which is solved leveraging\nmaximum bipartite matching (MWBM) and a simple linear search algorithm. Our\nextensive simulation results demonstrate the effectiveness of the proposed\nmethod.",
    "descriptor": "",
    "authors": [
      "Md Ferdous Pervej",
      "Richeng Jin",
      "Shih-Chun Lin",
      "Huaiyu Dai"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.07792"
  },
  {
    "id": "arXiv:2202.07793",
    "title": "Heuristic computation of exact treewidth",
    "abstract": "We are interested in computing the treewidth $\\tw(G)$ of a given graph $G$.\nOur approach is to design heuristic algorithms for computing a sequence of\nimproving upper bounds and a sequence of improving lower bounds, which would\nhopefully converge to $\\tw(G)$ from both sides. The upper bound algorithm\nextends and simplifies Tamaki's unpublished work on a heuristic use of the\ndynamic programming algorithm for deciding treewidth due to Bouchitt\\'{e} and\nTodinca. The lower bound algorithm is based on the well-known fact that, for\nevery minor $H$ of $G$, we have $\\tw(H) \\leq \\tw(G)$. Starting from a greedily\ncomputed minor $H_0$ of $G$, the algorithm tries to construct a sequence of\nminors $H_0$, $H_1$, \\ldots $H_k$ with $\\tw(H_i) < \\tw(H_{i + 1})$ for $0 \\leq\ni < k$ and hopefully $\\tw(H_k) = \\tw(G)$.\nWe have implemented a treewidth solver based on this approach and have\nevaluated it on the bonus instances from the exact treewidth track of PACE 2017\nalgorithm implementation challenge. The results show that our approach is\nextremely effective in tackling instances that are hard for conventional\nsolvers. Our solver has an additional advantage over conventional ones in that\nit attaches a compact certificate to the lower bound it computes.",
    "descriptor": "\nComments: Submitted to SEA2022\n",
    "authors": [
      "Hisao Tamaki"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.07793"
  },
  {
    "id": "arXiv:2202.07798",
    "title": "BB-ML: Basic Block Performance Prediction using Machine Learning  Techniques",
    "abstract": "Recent years have seen the adoption of Machine Learning (ML) techniques to\npredict the performance of large-scale applications, mostly at a coarse level.\nIn contrast, we propose to use ML techniques for performance prediction at much\nfiner granularity, namely at the levels of Basic Block (BB), which are the\nsingle entry-single exit code blocks that are used as analysis tools by all\ncompilers to break down a large code into manageable pieces. Utilizing ML and\nBB analysis together can enable scalable hardware-software co-design beyond the\ncurrent state of the art. In this work, we extrapolate the basic block\nexecution counts of GPU applications for large inputs sizes from the counts of\nsmaller input sizes of the same application.\nWe employ two ML models, a Poisson Neural Network (PNN) and a Bayesian\nRegularization Backpropagation Neural Network (BR-BPNN). We train both models\nusing the lowest input values of the application and random input values to\npredict basic block counts. Results show that our models accurately predict the\nbasic block execution counts of 16 benchmark applications. For PNN and BR-BPNN\nmodels, we achieve an average accuracy of 93.5% and 95.6%, respectively, while\nextrapolating the basic block counts for large input sets when the model is\ntrained using smaller input sets. Additionally, the models show an average\naccuracy of 97.7% and 98.1%, respectively, while predicting basic block counts\non random instances.",
    "descriptor": "",
    "authors": [
      "Shamminuj Aktar",
      "Hamdy Abdelkhalik",
      "Nazmul Haque Turja",
      "Yehia Arafa",
      "Atanu Barai",
      "Nishant Panda",
      "Gopinath Chennupati",
      "Nandakishore Santhi",
      "Abdel-Hameed Badawy",
      "Stephan Eidenbenz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2202.07798"
  },
  {
    "id": "arXiv:2202.07799",
    "title": "A Survey on Scheduling Techniques in the Edge Cloud: Issues, Challenges  and Future Directions",
    "abstract": "After the advent of the Internet of Things and 5G networks, edge computing\nbecame the center of attraction. The tasks demanding high computation are\ngenerally offloaded to the cloud since the edge is resource-limited. The Edge\nCloud is a promising platform where the devices can offload delay-sensitive\nworkloads. In this regard, scheduling holds great importance in offloading\ndecisions in the Edge Cloud collaboration. The ultimate objectives of\nscheduling are the quality of experience, minimizing latency, and increasing\nperformance. An abundance of efforts on scheduling has been done in the past.\nIn this paper, we have surveyed proposed scheduling strategies in the context\nof edge cloud computing in various aspects such as advantages and demerits, QoS\nparameters, and fault tolerance. We have also surveyed such scheduling\napproaches to evaluate which one is feasible under what circumstances. We first\nclassify all the algorithms into heuristic algorithms and meta-heuristics, and\nwe subcategorize algorithms in each class further based on extracted attributes\nof algorithms. We hope that this survey will be very thoughtful in the\ndevelopment of new scheduling techniques. Issues, challenges, and future\ndirections have also been examined.",
    "descriptor": "",
    "authors": [
      "Hassan Asghar",
      "Eun-Sung Jung"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.07799"
  },
  {
    "id": "arXiv:2202.07800",
    "title": "Not All Patches are What You Need: Expediting Vision Transformers via  Token Reorganizations",
    "abstract": "Vision Transformers (ViTs) take all the image patches as tokens and construct\nmulti-head self-attention (MHSA) among them. Complete leverage of these image\ntokens brings redundant computations since not all the tokens are attentive in\nMHSA. Examples include that tokens containing semantically meaningless or\ndistractive image backgrounds do not positively contribute to the ViT\npredictions. In this work, we propose to reorganize image tokens during the\nfeed-forward process of ViT models, which is integrated into ViT during\ntraining. For each forward inference, we identify the attentive image tokens\nbetween MHSA and FFN (i.e., feed-forward network) modules, which is guided by\nthe corresponding class token attention. Then, we reorganize image tokens by\npreserving attentive image tokens and fusing inattentive ones to expedite\nsubsequent MHSA and FFN computations. To this end, our method EViT improves\nViTs from two perspectives. First, under the same amount of input image tokens,\nour method reduces MHSA and FFN computation for efficient inference. For\ninstance, the inference speed of DeiT-S is increased by 50% while its\nrecognition accuracy is decreased by only 0.3% for ImageNet classification.\nSecond, by maintaining the same computational cost, our method empowers ViTs to\ntake more image tokens as input for recognition accuracy improvement, where the\nimage tokens are from higher resolution images. An example is that we improve\nthe recognition accuracy of DeiT-S by 1% for ImageNet classification at the\nsame computational cost of a vanilla DeiT-S. Meanwhile, our method does not\nintroduce more parameters to ViTs. Experiments on the standard benchmarks show\nthe effectiveness of our method. The code is available at\nhttps://github.com/youweiliang/evit",
    "descriptor": "\nComments: ICLR 2022 Spotlight\n",
    "authors": [
      "Youwei Liang",
      "Chongjian Ge",
      "Zhan Tong",
      "Yibing Song",
      "Jue Wang",
      "Pengtao Xie"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07800"
  },
  {
    "id": "arXiv:2202.07802",
    "title": "Generative Adversarial Network-Driven Detection of Adversarial Tasks in  Mobile Crowdsensing",
    "abstract": "Mobile Crowdsensing systems are vulnerable to various attacks as they build\non non-dedicated and ubiquitous properties. Machine learning (ML)-based\napproaches are widely investigated to build attack detection systems and ensure\nMCS systems security. However, adversaries that aim to clog the sensing\nfront-end and MCS back-end leverage intelligent techniques, which are\nchallenging for MCS platform and service providers to develop appropriate\ndetection frameworks against these attacks. Generative Adversarial Networks\n(GANs) have been applied to generate synthetic samples, that are extremely\nsimilar to the real ones, deceiving classifiers such that the synthetic samples\nare indistinguishable from the originals. Previous works suggest that GAN-based\nattacks exhibit more crucial devastation than empirically designed attack\nsamples, and result in low detection rate at the MCS platform. With this in\nmind, this paper aims to detect intelligently designed illegitimate sensing\nservice requests by integrating a GAN-based model. To this end, we propose a\ntwo-level cascading classifier that combines the GAN discriminator with a\nbinary classifier to prevent adversarial fake tasks. Through simulations, we\ncompare our results to a single-level binary classifier, and the numeric\nresults show that proposed approach raises Adversarial Attack Detection Rate\n(AADR), from $0\\%$ to $97.5\\%$ by KNN/NB, from $45.9\\%$ to $100\\%$ by Decision\nTree. Meanwhile, with two-levels classifiers, Original Attack Detection Rate\n(OADR) improves for the three binary classifiers, with comparison, such as NB\nfrom $26.1\\%$ to $61.5\\%$.",
    "descriptor": "\nComments: This paper contains pages, 4 figures which is accepted by IEEE ICC 2022\n",
    "authors": [
      "Zhiyan Chen",
      "Burak Kantarci"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07802"
  },
  {
    "id": "arXiv:2202.07806",
    "title": "Code Generation for Unknown Libraries via Reading API Documentations",
    "abstract": "Open-domain code generation is a challenging problem because the set of\nfunctions and classes that we use are frequently changed and extended in\nprogramming communities. We consider the challenge of code generation for\nunknown libraries without additional training. In this paper, we explore a\nframework of code generation that can refer to relevant API documentations like\nhuman programmers to handle unknown libraries. As a first step of this\ndirection, we implement a model that can extract relevant code signatures from\nAPI documentations based on a natural language intent and copy primitives from\nthe extracted signatures. Moreover, to evaluate code generation for unknown\nlibraries and our framework, we extend an existing dataset of open-domain code\ngeneration and resplit it so that the evaluation data consist of only examples\nusing the libraries that do not appear in the training data. Experiments on our\nnew split show that baseline encoder-decoder models cannot generate code using\nprimitives of unknown libraries as expected. In contrast, our model outperforms\nthe baseline on the new split and can properly generate unknown primitives when\nextracted code signatures are noiseless.",
    "descriptor": "",
    "authors": [
      "Koki Washio",
      "Yusuke Miyao"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07806"
  },
  {
    "id": "arXiv:2202.07808",
    "title": "Policy Learning and Evaluation with Randomized Quasi-Monte Carlo",
    "abstract": "Reinforcement learning constantly deals with hard integrals, for example when\ncomputing expectations in policy evaluation and policy iteration. These\nintegrals are rarely analytically solvable and typically esimated with the\nMonte Carlo method, which induces high variance in policy values and gradients.\nIn this work, we propose to replace Monte Carlo samples with low-discrepancy\npoint sets. We combine policy gradient methods with Randomized Quasi-Monte\nCarlo, yielding variance-reduced formulations of policy gradient and\nactor-critic algorithms. These formulations are effective for policy evaluation\nand policy improvement, as they outperform state-of-the-art algorithms on\nstandardized continuous control benchmarks. Our empirical analyses validate the\nintuition that replacing Monte Carlo with Quasi-Monte Carlo yields\nsignificantly more accurate gradient estimates.",
    "descriptor": "\nComments: AISTATS 2022 camera ready; more info at: this http URL\n",
    "authors": [
      "Sebastien M. R. Arnold",
      "Pierre L'Ecuyer",
      "Liyu Chen",
      "Yi-fan Chen",
      "Fei Sha"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07808"
  },
  {
    "id": "arXiv:2202.07815",
    "title": "Applying adversarial networks to increase the data efficiency and  reliability of Self-Driving Cars",
    "abstract": "Convolutional Neural Networks (CNNs) are vulnerable to misclassifying images\nwhen small perturbations are present. With the increasing prevalence of CNNs in\nself-driving cars, it is vital to ensure these algorithms are robust to prevent\ncollisions from occurring due to failure in recognizing a situation. In the\nAdversarial Self-Driving framework, a Generative Adversarial Network (GAN) is\nimplemented to generate realistic perturbations in an image that cause a\nclassifier CNN to misclassify data. This perturbed data is then used to train\nthe classifier CNN further. The Adversarial Self-driving framework is applied\nto an image classification algorithm to improve the classification accuracy on\nperturbed images and is later applied to train a self-driving car to drive in a\nsimulation. A small-scale self-driving car is also built to drive around a\ntrack and classify signs. The Adversarial Self-driving framework produces\nperturbed images through learning a dataset, as a result removing the need to\ntrain on significant amounts of data. Experiments demonstrate that the\nAdversarial Self-driving framework identifies situations where CNNs are\nvulnerable to perturbations and generates new examples of these situations for\nthe CNN to train on. The additional data generated by the Adversarial\nSelf-driving framework provides sufficient data for the CNN to generalize to\nthe environment. Therefore, it is a viable tool to increase the resilience of\nCNNs to perturbations. Particularly, in the real-world self-driving car, the\napplication of the Adversarial Self-Driving framework resulted in an 18 %\nincrease in accuracy, and the simulated self-driving model had no collisions in\n30 minutes of driving.",
    "descriptor": "",
    "authors": [
      "Aakash Kumar"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.07815"
  },
  {
    "id": "arXiv:2202.07817",
    "title": "Cross-view and Cross-domain Underwater Localization based on Optical  Aerial and Acoustic Underwater Images",
    "abstract": "Cross-view image matches have been widely explored on terrestrial image\nlocalization using aerial images from drones or satellites. This study expands\nthe cross-view image match idea and proposes a cross-domain and cross-view\nlocalization framework. The method identifies the correlation between color\naerial images and underwater acoustic images to improve the localization of\nunderwater vehicles that travel in partially structured environments such as\nharbors and marinas. The approach is validated on a real dataset acquired by an\nunderwater vehicle in a marina. The results show an improvement in the\nlocalization when compared to the dead reckoning of the vehicle.",
    "descriptor": "\nComments: This work has been submitted to the IEEE Robotics and Automation Letters (RA-L) for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Matheus M. Dos Santos",
      "Giovanni G. De Giacomo",
      "Paulo L. J. Drews-Jr",
      "Silvia S. C. Botelho"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.07817"
  },
  {
    "id": "arXiv:2202.07824",
    "title": "RNGDet: Road Network Graph Detection by Transformer in Aerial Images",
    "abstract": "Road network graphs provide critical information for autonomous vehicle\napplications, such as motion planning on drivable areas. However, manually\nannotating road network graphs is inefficient and labor-intensive.\nAutomatically detecting road network graphs could alleviate this issue, but\nexisting works are either segmentation-based approaches that could not ensure\nsatisfactory topology correctness, or graph-based approaches that could not\npresent precise enough detection results. To provide a solution to these\nproblems, we propose a novel approach based on transformer and imitation\nlearning named RNGDet (\\underline{R}oad \\underline{N}etwork \\underline{G}raph\n\\underline{Det}ection by Transformer) in this paper. In view of that\nhigh-resolution aerial images could be easily accessed all over the world\nnowadays, we make use of aerial images in our approach. Taken as input an\naerial image, our approach iteratively generates road network graphs\nvertex-by-vertex. Our approach can handle complicated intersection points of\nvarious numbers of road segments. We evaluate our approach on a publicly\navailable dataset. The superiority of our approach is demonstrated through the\ncomparative experiments.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Zhenhua Xu",
      "Yuxuan Liu",
      "Lu Gan",
      "Yuxiang Sun",
      "Ming Liu",
      "Lujia Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07824"
  },
  {
    "id": "arXiv:2202.07825",
    "title": "Reducing Overconfidence Predictions for Autonomous Driving Perception",
    "abstract": "In state-of-the-art deep learning for object recognition, SoftMax and Sigmoid\nfunctions are most commonly employed as the predictor outputs. Such layers\noften produce overconfident predictions rather than proper probabilistic\nscores, which can thus harm the decision-making of `critical' perception\nsystems applied in autonomous driving and robotics. Given this, the experiments\nin this work propose a probabilistic approach based on distributions calculated\nout of the Logit layer scores of pre-trained networks. We demonstrate that\nMaximum Likelihood (ML) and Maximum a-Posteriori (MAP) functions are more\nsuitable for probabilistic interpretations than SoftMax and Sigmoid-based\npredictions for object recognition. We explore distinct sensor modalities via\nRGB images and LiDARs (RV: range-view) data from the KITTI and Lyft Level-5\ndatasets, where our approach shows promising performance compared to the usual\nSoftMax and Sigmoid layers, with the benefit of enabling interpretable\nprobabilistic predictions. Another advantage of the approach introduced in this\npaper is that the ML and MAP functions can be implemented in existing trained\nnetworks, that is, the approach benefits from the output of the Logit layer of\npre-trained networks. Thus, there is no need to carry out a new training phase\nsince the ML and MAP functions are used in the test/prediction phase.",
    "descriptor": "\nComments: This work has been submitted to IEEE ACCESS for review and possible publication\n",
    "authors": [
      "Gledson Melotti",
      "Cristiano Premebida",
      "Jordan J. Bird",
      "Diego R. Faria",
      "Nuno Gon\u00e7alves"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07825"
  },
  {
    "id": "arXiv:2202.07826",
    "title": "CenGCN: Centralized Convolutional Networks with Vertex Imbalance for  Scale-Free Graphs",
    "abstract": "Graph Convolutional Networks (GCNs) have achieved impressive performance in a\nwide variety of areas, attracting considerable attention. The core step of GCNs\nis the information-passing framework that considers all information from\nneighbors to the central vertex to be equally important. Such equal importance,\nhowever, is inadequate for scale-free networks, where hub vertices propagate\nmore dominant information due to vertex imbalance. In this paper, we propose a\nnovel centrality-based framework named CenGCN to address the inequality of\ninformation. This framework first quantifies the similarity between hub\nvertices and their neighbors by label propagation with hub vertices. Based on\nthis similarity and centrality indices, the framework transforms the graph by\nincreasing or decreasing the weights of edges connecting hub vertices and\nadding self-connections to vertices. In each non-output layer of the GCN, this\nframework uses a hub attention mechanism to assign new weights to connected\nnon-hub vertices based on their common information with hub vertices. We\npresent two variants CenGCN\\_D and CenGCN\\_E, based on degree centrality and\neigenvector centrality, respectively. We also conduct comprehensive\nexperiments, including vertex classification, link prediction, vertex\nclustering, and network visualization. The results demonstrate that the two\nvariants significantly outperform state-of-the-art baselines.",
    "descriptor": "\nComments: 16 pages, 8 figures\n",
    "authors": [
      "Feng Xia",
      "Lei Wang",
      "Tao Tang",
      "Xin Chen",
      "Xiangjie Kong",
      "Giles Oatley",
      "Irwin King"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.07826"
  },
  {
    "id": "arXiv:2202.07829",
    "title": "Spatial Transformer K-Means",
    "abstract": "K-means defines one of the most employed centroid-based clustering algorithms\nwith performances tied to the data's embedding. Intricate data embeddings have\nbeen designed to push $K$-means performances at the cost of reduced theoretical\nguarantees and interpretability of the results. Instead, we propose preserving\nthe intrinsic data space and augment K-means with a similarity measure\ninvariant to non-rigid transformations. This enables (i) the reduction of\nintrinsic nuisances associated with the data, reducing the complexity of the\nclustering task and increasing performances and producing state-of-the-art\nresults, (ii) clustering in the input space of the data, leading to a fully\ninterpretable clustering algorithm, and (iii) the benefit of convergence\nguarantees.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2012.09743\n",
    "authors": [
      "Romain Cosentino",
      "Randall Balestriero",
      "Yanis Bahroun",
      "Anirvan Sengupta",
      "Richard Baraniuk",
      "Behnaam Aazhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07829"
  },
  {
    "id": "arXiv:2202.07831",
    "title": "CycleGAN for Undamaged-to-Damaged Domain Translation for Structural  Health Monitoring and Damage Detection",
    "abstract": "The accelerated advancements in the data science field in the last few\ndecades has benefitted many other fields including Structural Health Monitoring\n(SHM). Particularly, the employment of Artificial Intelligence (AI) such as\nMachine Learning (ML) and Deep Learning (DL) methods towards vibration-based\ndamage diagnostics of civil structures have seen a great interest due to their\nnature of supreme performance in learning from data. Along with diagnostics,\ndamage prognostics also hold a vital prominence, such as estimating the\nremaining useful life of civil structures. Currently used AI-based data-driven\nmethods for damage diagnostics and prognostics are centered on historical data\nof the structures and require a substantial amount of data to directly form the\nprediction models. Although some of these methods are generative-based models,\nafter learning the distribution of the data, they are used to perform ML or DL\ntasks such as classification, regression, clustering, etc. In this study, a\nvariant of Generative Adversarial Networks (GAN), Cycle-Consistent Wasserstein\nDeep Convolutional GAN with Gradient Penalty (CycleWDCGAN-GP) model is used to\nanswer some of the most important questions in SHM: \"How does the dynamic\nsignature of a structure transition from undamaged to damaged conditions?\" and\n\"What is the nature of such transition?\". The outcomes of this study\ndemonstrate that the proposed model can accurately generate the possible future\nresponses of a structure for potential future damaged conditions. In other\nwords, with the proposed methodology, the stakeholders will be able to\nunderstand the damaged condition of structures while the structures are still\nin healthy (undamaged) conditions. This tool will enable them to be more\nproactive in overseeing the life cycle performance of structures as well as\nassist in remaining useful life predictions.",
    "descriptor": "",
    "authors": [
      "Furkan Luleci",
      "F. Necati Catbas",
      "Onur Avci"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07831"
  },
  {
    "id": "arXiv:2202.07832",
    "title": "Heterogeneous Graph Learning for Explainable Recommendation over  Academic Networks",
    "abstract": "With the explosive growth of new graduates with research degrees every year,\nunprecedented challenges arise for early-career researchers to find a job at a\nsuitable institution. This study aims to understand the behavior of academic\njob transition and hence recommend suitable institutions for PhD graduates.\nSpecifically, we design a deep learning model to predict the career move of\nearly-career researchers and provide suggestions. The design is built on top of\nscholarly/academic networks, which contains abundant information about\nscientific collaboration among scholars and institutions. We construct a\nheterogeneous scholarly network to facilitate the exploring of the behavior of\ncareer moves and the recommendation of institutions for scholars. We devise an\nunsupervised learning model called HAI (Heterogeneous graph Attention InfoMax)\nwhich aggregates attention mechanism and mutual information for institution\nrecommendation. Moreover, we propose scholar attention and meta-path attention\nto discover the hidden relationships between several meta-paths. With these\nmechanisms, HAI provides ordered recommendations with explainability. We\nevaluate HAI upon a real-world dataset against baseline methods. Experimental\nresults verify the effectiveness and efficiency of our approach.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Xiangtai Chen",
      "Tao Tang",
      "Jing Ren",
      "Ivan Lee",
      "Honglong Chen",
      "Feng Xia"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07832"
  },
  {
    "id": "arXiv:2202.07835",
    "title": "Privacy-Preserving Graph Neural Network Training and Inference as a  Cloud Service",
    "abstract": "Graphs are widely used to model the complex relationships among entities. As\na powerful tool for graph analytics, graph neural networks (GNNs) have recently\ngained wide attention due to its end-to-end processing capabilities. With the\nproliferation of cloud computing, it is increasingly popular to deploy the\nservices of complex and resource-intensive model training and inference in the\ncloud due to its prominent benefits. However, GNN training and inference\nservices, if deployed in the cloud, will raise critical privacy concerns about\nthe information-rich and proprietary graph data (and the resulting model).\nWhile there has been some work on secure neural network training and inference,\nthey all focus on convolutional neural networks handling images and text rather\nthan complex graph data with rich structural information. In this paper, we\ndesign, implement, and evaluate SecGNN, the first system supporting\nprivacy-preserving GNN training and inference services in the cloud. SecGNN is\nbuilt from a synergy of insights on lightweight cryptography and machine\nlearning techniques. We deeply examine the procedure of GNN training and\ninference, and devise a series of corresponding secure customized protocols to\nsupport the holistic computation. Extensive experiments demonstrate that SecGNN\nachieves comparable plaintext training and inference accuracy, with practically\naffordable performance.",
    "descriptor": "",
    "authors": [
      "Songlei Wang",
      "Yifeng Zheng",
      "Xiaohua Jia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07835"
  },
  {
    "id": "arXiv:2202.07836",
    "title": "View Composition Algebra for Ad Hoc Comparison",
    "abstract": "Comparison is a core task in visual analysis. Although there are numerous\nguidelines to help users design effective visualizations to aid known\ncomparison tasks, there are few techniques available when users want to make ad\nhoc comparisons between marks, trends, or charts during data exploration and\nvisual analysis. For instance, to compare voting count maps from different\nyears, two stock trends in a line chart, or a scatterplot of country GDPs with\na textual summary of the average GDP. Ideally, users can directly select the\ncomparison targets and compare them, however what elements of a visualization\nshould be candidate targets, which combinations of targets are safe to compare,\nand what comparison operations make sense? This paper proposes a conceptual\nmodel that lets users compose combinations of values, marks, legend elements,\nand charts using a set of composition operators that summarize, compute\ndifferences, merge, and model their operands. We further define a View\nComposition Algebra (VCA) that is compatible with datacube-based\nvisualizations, derive an interaction design based on this algebra that\nsupports ad hoc visual comparisons, and illustrate its utility through several\nuse cases.",
    "descriptor": "",
    "authors": [
      "Eugene Wu"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.07836"
  },
  {
    "id": "arXiv:2202.07837",
    "title": "Application of Long Short-Term Memory Recurrent Neural Networks Based on  the BAT-MCS for Binary-State Network Approximated Time-Dependent Reliability  Problems",
    "abstract": "Reliability is an important tool for evaluating the performance of modern\nnetworks. Currently, it is NP-hard and #P-hard to calculate the exact\nreliability of a binary-state network when the reliability of each component is\nassumed to be fixed. However, this assumption is unrealistic because the\nreliability of each component always varies with time. To meet this practical\nrequirement, we propose a new algorithm called the LSTM-BAT-MCS, based on long\nshort-term memory (LSTM), the Monte Carlo simulation (MCS), and the\nbinary-adaption-tree algorithm (BAT). The superiority of the proposed\nLSTM-BAT-MCS was demonstrated by experimental results of three benchmark\nnetworks with at most 10-4 mean square error.",
    "descriptor": "",
    "authors": [
      "Wei-Chang Yeh"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07837"
  },
  {
    "id": "arXiv:2202.07841",
    "title": "Learning Deep Direct-Path Relative Transfer Function for Binaural Sound  Source Localization",
    "abstract": "Direct-path relative transfer function (DP-RTF) refers to the ratio between\nthe direct-path acoustic transfer functions of two microphone channels. Though\nDP-RTF fully encodes the sound spatial cues and serves as a reliable\nlocalization feature, it is often erroneously estimated in the presence of\nnoise and reverberation. This paper proposes to learn DP-RTF with deep neural\nnetworks for robust binaural sound source localization. A DP-RTF learning\nnetwork is designed to regress the binaural sensor signals to a real-valued\nrepresentation of DP-RTF. It consists of a branched convolutional neural\nnetwork module to separately extract the inter-channel magnitude and phase\npatterns, and a convolutional recurrent neural network module for joint feature\nlearning. To better explore the speech spectra to aid the DP-RTF estimation, a\nmonaural speech enhancement network is used to recover the direct-path\nspectrograms from the noisy ones. The enhanced spectrograms are stacked onto\nthe noisy spectrograms to act as the input of the DP-RTF learning network. We\ntrain one unique DP-RTF learning network using many different binaural arrays\nto enable the generalization of DP-RTF learning across arrays. This way avoids\ntime-consuming training data collection and network retraining for a new array,\nwhich is very useful in practical application. Experimental results on both\nsimulated and real-world data show the effectiveness of the proposed method for\ndirection of arrival (DOA) estimation in the noisy and reverberant environment,\nand a good generalization ability to unseen binaural arrays.",
    "descriptor": "\nComments: Accepted by TASLP 2021\n",
    "authors": [
      "Bing Yang",
      "Hong Liu",
      "Xiaofei Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.07841"
  },
  {
    "id": "arXiv:2202.07843",
    "title": "PCRP: Unsupervised Point Cloud Object Retrieval and Pose Estimation",
    "abstract": "An unsupervised point cloud object retrieval and pose estimation method,\ncalled PCRP, is proposed in this work. It is assumed that there exists a\ngallery point cloud set that contains point cloud objects with given pose\norientation information. PCRP attempts to register the unknown point cloud\nobject with those in the gallery set so as to achieve content-based object\nretrieval and pose estimation jointly, where the point cloud registration task\nis built upon an enhanced version of the unsupervised R-PointHop method.\nExperiments on the ModelNet40 dataset demonstrate the superior performance of\nPCRP in comparison with traditional and learning based methods.",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Pranav Kadam",
      "Qingyang Zhou",
      "Shan Liu",
      "C.-C. Jay Kuo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07843"
  },
  {
    "id": "arXiv:2202.07844",
    "title": "Data Capsule: A Self-Contained Data Model as an Access Policy  Enforcement Strategy",
    "abstract": "In this paper, we introduce a data capsule model, a self-contained and\nself-enforcing data container based on emerging self-sovereign identity\nstandards, blockchain, and attribute-based encryption. A data capsule allows\nfor a transparent, privacy-respecting, and secure exchange of personal data,\nenabling a progressive trust scheme in a semi-trusted environment. Each data\ncapsule is bundled with its own access policy structure and verifiable data,\ndrastically reducing the number of interactions needed among the user, the\nservice providers, and data custodians. Moreover, by relying on the\ndecentralized nature of blockchain and attribute-based encryption our proposed\nmodel ensures the access policies published by service providers are public,\ntransparent, and strictly followed.",
    "descriptor": "",
    "authors": [
      "Reza Soltani",
      "Uyen Trang Nguyen",
      "Aijun An"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.07844"
  },
  {
    "id": "arXiv:2202.07845",
    "title": "Near-optimal Top-k Pattern Mining",
    "abstract": "Nowadays, frequent pattern mining (FPM) on large graphs receives increasing\nattention, since it is crucial to a variety of applications, e.g., social\nanalysis. Informally, the FPM problem is defined as finding all the patterns in\na large graph with frequency above a user-defined threshold. However, this\nproblem is nontrivial due to the unaffordable computational and space costs in\nthe mining process. In light of this, we propose a cost-effective approach to\nmining near-optimal top-k patterns. Our approach applies a \"level-wise\"\nstrategy to incrementally detect frequent patterns, hence is able to terminate\nas soon as top-k patterns are discovered. Moreover, we develop a technique to\ncompute the lower bound of support with smart traverse strategy and compact\ndata structures. Extensive experimental studies on real-life and synthetic\ngraphs show that our approach performs well, i.e., it outperforms traditional\ncounterparts in efficiency, memory footprint, recall and scalability.",
    "descriptor": "",
    "authors": [
      "Xin Wang",
      "Zhuo Lan",
      "Yu-Ang He",
      "Yang Wang",
      "Zhi-Gui Liu",
      "Wen-Bo Xie"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.07845"
  },
  {
    "id": "arXiv:2202.07846",
    "title": "Deeply-Supervised Knowledge Distillation",
    "abstract": "Knowledge distillation aims to enhance the performance of a lightweight\nstudent model by exploiting the knowledge from a pre-trained cumbersome teacher\nmodel. However, in the traditional knowledge distillation, teacher predictions\nare only used to provide the supervisory signal for the last layer of the\nstudent model, which may result in those shallow student layers lacking\naccurate training guidance in the layer-by-layer back propagation and thus\nhinders effective knowledge transfer. To address this issue, we propose\nDeeply-Supervised Knowledge Distillation (DSKD), which fully utilizes class\npredictions and feature maps of the teacher model to supervise the training of\nshallow student layers. A loss-based weight allocation strategy is developed in\nDSKD to adaptively balance the learning process of each shallow layer, so as to\nfurther improve the student performance. Extensive experiments show that the\nperformance of DSKD consistently exceeds state-of-the-art methods on various\nteacher-student models, confirming the effectiveness of our proposed method.",
    "descriptor": "",
    "authors": [
      "Shiya Luo",
      "Defang Chen",
      "Can Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07846"
  },
  {
    "id": "arXiv:2202.07848",
    "title": "Singularity: Planet-Scale, Preemptible, Elastic Scheduling of AI  Workloads",
    "abstract": "Lowering costs by driving high utilization across deep learning workloads is\na crucial lever for cloud providers. We present Singularity, Microsoft's\nglobally distributed scheduling service for highly-efficient and reliable\nexecution of deep learning training and inference workloads. At the heart of\nSingularity is a novel, workload-aware scheduler that can transparently preempt\nand elastically scale deep learning workloads to drive high utilization without\nimpacting their correctness or performance, across a global fleet of AI\naccelerators (e.g., GPUs, FPGAs).\nAll jobs in Singularity are preemptable, migratable, and dynamically\nresizable (elastic) by default: a live job can be dynamically and transparently\n(a) preempted and migrated to a different set of nodes, cluster, data center or\na region and resumed exactly from the point where the execution was preempted,\nand (b) resized (i.e., elastically scaled-up/down) on a varying set of\naccelerators of a given type. Our mechanisms are transparent in that they do\nnot require the user to make any changes to their code or require using any\ncustom libraries that may limit flexibility. Additionally, our approach\nsignificantly improves the reliability of deep learning workloads. We show that\nthe resulting efficiency and reliability gains with Singularity are achieved\nwith negligible impact on the steady-state performance. Finally, our design\napproach is agnostic of DNN architectures and handles a variety of parallelism\nstrategies (e.g., data/pipeline/model parallelism).",
    "descriptor": "",
    "authors": [
      "Dharma Shukla",
      "Muthian Sivathanu",
      "Srinidhi Viswanatha",
      "Bhargav Gulavani",
      "Rimma Nehme",
      "Amey Agrawal",
      "Chen Chen",
      "Nipun Kwatra",
      "Ramachandran Ramjee",
      "Pankaj Sharma",
      "Atul Katiyar",
      "Vipul Modi",
      "Vaibhav Sharma",
      "Abhishek Singh",
      "Shreshth Singhal",
      "Kaustubh Welankar",
      "Lu Xun",
      "Ravi Anupindi",
      "Karthik Elangovan",
      "Hasibur Rahman",
      "Zhou Lin",
      "Rahul Seetharaman",
      "Cheng Xu",
      "Eddie Ailijiang",
      "Suresh Krishnappa",
      "Mark Russinovich"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07848"
  },
  {
    "id": "arXiv:2202.07853",
    "title": "A deep dive into the consistently toxic 1% of Twitter",
    "abstract": "Misbehavior in online social networks (OSN) is an ever-growing phenomenon.\nThe research to date tends to focus on the deployment of machine learning to\nidentify and classify types of misbehavior such as bullying, aggression, and\nracism to name a few. The main goal of identification is to curb natural and\nmechanical misconduct and make OSNs a safer place for social discourse. Going\nbeyond past works, we perform a longitudinal study of a large selection of\nTwitter profiles, which enables us to characterize profiles in terms of how\nconsistently they post highly toxic content. Our data spans 14 years of tweets\nfrom 122K Twitter profiles and more than 293M tweets. From this data, we\nselected the most extreme profiles in terms of consistency of toxic content and\nexamined their tweet texts, and the domains, hashtags, and URLs they shared. We\nfound that these selected profiles keep to a narrow theme with lower diversity\nin hashtags, URLs, and domains, they are thematically similar to each other (in\na coordinated manner, if not through intent), and have a high likelihood of\nbot-like behavior (likely to have progenitors with intentions to influence).\nOur work contributes a substantial and longitudinal online misbehavior dataset\nto the research community and establishes the consistency of a profile's toxic\nbehavior as a useful factor when exploring misbehavior as potential accessories\nto influence operations on OSNs.",
    "descriptor": "",
    "authors": [
      "Hina Qayyum",
      "Benjamin Zi Hao Zhao",
      "Ian D. Wood",
      "Muhammad Ikram",
      "Mohamed Ali Kaafar",
      "Nicolas Kourtellis"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.07853"
  },
  {
    "id": "arXiv:2202.07855",
    "title": "Conversational Speech Recognition By Learning Conversation-level  Characteristics",
    "abstract": "Conversational automatic speech recognition (ASR) is a task to recognize\nconversational speech including multiple speakers. Unlike sentence-level ASR,\nconversational ASR can naturally take advantages from specific characteristics\nof conversation, such as role preference and topical coherence. This paper\nproposes a conversational ASR model which explicitly learns conversation-level\ncharacteristics under the prevalent end-to-end neural framework. The highlights\nof the proposed model are twofold. First, a latent variational module (LVM) is\nattached to a conformer-based encoder-decoder ASR backbone to learn role\npreference and topical coherence. Second, a topic model is specifically adopted\nto bias the outputs of the decoder to words in the predicted topics.\nExperiments on two Mandarin conversational ASR tasks show that the proposed\nmodel achieves a maximum 12% relative character error rate (CER) reduction.",
    "descriptor": "\nComments: ICASSP 2022\n",
    "authors": [
      "Kun Wei",
      "Yike Zhang",
      "Sining Sun",
      "Lei Xie",
      "Long Ma"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.07855"
  },
  {
    "id": "arXiv:2202.07856",
    "title": "The NLP Task Effectiveness of Long-Range Transformers",
    "abstract": "Transformer models cannot easily scale to long sequences due to their O(N^2)\ntime and space complexity. This has led to Transformer variants seeking to\nlessen computational complexity, such as Longformer and Performer. While such\nmodels have theoretically greater efficiency, their effectiveness on real NLP\ntasks has not been well studied. We benchmark 7 variants of Transformer models\non 5 difficult NLP tasks and 7 datasets. We design experiments to isolate the\neffect of pretraining and hyperparameter settings, to focus on their capacity\nfor long-range attention. Moreover, we present various methods to investigate\nattention behaviors, to illuminate model details beyond metric scores. We find\nthat attention of long-range transformers has advantages on content selection\nand query-guided decoding, but they come with previously unrecognized drawbacks\nsuch as insufficient attention to distant tokens.",
    "descriptor": "",
    "authors": [
      "Guanghui Qin",
      "Yukun Feng",
      "Benjamin Van Durme"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07856"
  },
  {
    "id": "arXiv:2202.07857",
    "title": "Graph-Augmented Normalizing Flows for Anomaly Detection of Multiple Time  Series",
    "abstract": "Anomaly detection is a widely studied task for a broad variety of data types;\namong them, multiple time series appear frequently in applications, including\nfor example, power grids and traffic networks. Detecting anomalies for multiple\ntime series, however, is a challenging subject, owing to the intricate\ninterdependencies among the constituent series. We hypothesize that anomalies\noccur in low density regions of a distribution and explore the use of\nnormalizing flows for unsupervised anomaly detection, because of their superior\nquality in density estimation. Moreover, we propose a novel flow model by\nimposing a Bayesian network among constituent series. A Bayesian network is a\ndirected acyclic graph (DAG) that models causal relationships; it factorizes\nthe joint probability of the series into the product of easy-to-evaluate\nconditional probabilities. We call such a graph-augmented normalizing flow\napproach GANF and propose joint estimation of the DAG with flow parameters. We\nconduct extensive experiments on real-world datasets and demonstrate the\neffectiveness of GANF for density estimation, anomaly detection, and\nidentification of time series distribution drift.",
    "descriptor": "\nComments: ICLR 2022. Code is available at this https URL\n",
    "authors": [
      "Enyan Dai",
      "Jie Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.07857"
  },
  {
    "id": "arXiv:2202.07858",
    "title": "ITTC @ TREC 2021 Clinical Trials Track",
    "abstract": "This paper describes the submissions of the Natural Language Processing (NLP)\nteam from the Australian Research Council Industrial Transformation Training\nCentre (ITTC) for Cognitive Computing in Medical Technologies to the TREC 2021\nClinical Trials Track. The task focuses on the problem of matching eligible\nclinical trials to topics constituting a summary of a patient's admission\nnotes. We explore different ways of representing trials and topics using NLP\ntechniques, and then use a common retrieval model to generate the ranked list\nof relevant trials for each topic. The results from all our submitted runs are\nwell above the median scores for all topics, but there is still plenty of scope\nfor improvement.",
    "descriptor": "\nComments: 7 pages\n",
    "authors": [
      "Thinh Hung Truong",
      "Yulia Otmakhova",
      "Rahmad Mahendra",
      "Timothy Baldwin",
      "Jey Han Lau",
      "Trevor Cohn",
      "Lawrence Cavedon",
      "Damiano Spina",
      "Karin Verspoor"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.07858"
  },
  {
    "id": "arXiv:2202.07859",
    "title": "SRP-DNN: Learning Direct-Path Phase Difference for Multiple Moving Sound  Source Localization",
    "abstract": "Multiple moving sound source localization in real-world scenarios remains a\nchallenging issue due to interaction between sources, time-varying\ntrajectories, distorted spatial cues, etc. In this work, we propose to use deep\nlearning techniques to learn competing and time-varying direct-path phase\ndifferences for localizing multiple moving sound sources. A causal\nconvolutional recurrent neural network is designed to extract the direct-path\nphase difference sequence from signals of each microphone pair. To avoid the\nassignment ambiguity and the problem of uncertain output-dimension encountered\nwhen simultaneously predicting multiple targets, the learning target is\ndesigned in a weighted sum format, which encodes source activity in the weight\nand direct-path phase differences in the summed value. The learned direct-path\nphase differences for all microphone pairs can be directly used to construct\nthe spatial spectrum according to the formulation of steered response power\n(SRP). This deep neural network (DNN) based SRP method is referred to as\nSRP-DNN. The locations of sources are estimated by iteratively detecting and\nremoving the dominant source from the spatial spectrum, in which way the\ninteraction between sources is reduced. Experimental results on both simulated\nand real-world data show the superiority of the proposed method in the presence\nof noise and reverberation.",
    "descriptor": "\nComments: Accepted by ICASSP 2022\n",
    "authors": [
      "Bing Yang",
      "Hong Liu",
      "Xiaofei Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.07859"
  },
  {
    "id": "arXiv:2202.07861",
    "title": "Practical Network Acceleration with Tiny Sets",
    "abstract": "Network compression is effective in accelerating the inference of deep neural\nnetworks, but often requires finetuning with all the training data to recover\nfrom the accuracy loss. It is impractical in some applications, however, due to\ndata privacy issues or constraints in compression time budget. To deal with the\nabove issues, we propose a method named PRACTISE to accelerate the network with\ntiny sets of training images. By considering both the pruned part and the\nunpruned part of a compressed model, PRACTISE alleviates layer-wise error\naccumulation, which is the main drawback of previous methods. Furthermore,\nexisting methods are confined to few compression schemes, have limited speedup\nin terms of latency, and are unstable. In contrast, PRACTISE is stable, fast to\ntrain, versatile to handle various compression schemes, and achieves low\nlatency. We also propose that dropping entire blocks is a better way than\nexisting compression schemes when only tiny sets of training data are\navailable. Extensive experiments demonstrate that PRACTISE achieves much higher\naccuracy and more stable models than state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Guo-Hua Wang",
      "Jianxin Wu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07861"
  },
  {
    "id": "arXiv:2202.07862",
    "title": "See further upon the giants: Quantifying intellectual lineage in science",
    "abstract": "Newton's centuries-old wisdom of standing on the shoulders of giants raises a\ncrucial yet underexplored question: Out of all the prior works cited by a\ndiscovery, which one is its giant? Here, we develop a novel,\ndiscipline-independent method to identify the giant for any individual paper,\nallowing us to systematically examine the role and characteristics of giants in\nscience. We find that across disciplines, about 95% of papers stand on the\nshoulders of giants, yet the weight of scientific progress rests on relatively\nfew shoulders. Defining a new measure of giant index, we find that, while\npapers with high citations are more likely to be giants, for papers with the\nsame citations, their giant index sharply predicts a paper's future impact and\nprize-winning probabilities. Giants tend to originate from both small and large\nteams, being either highly disruptive or highly developmental. And papers that\ndid not have a giant but later became a giant tend to be home-run papers that\nare highly disruptive to science. Given the crucial importance of\ncitation-based measures in science, the developed concept of giants may offer a\nuseful new dimension in assessing scientific impact that goes beyond sheer\ncitation counts.",
    "descriptor": "",
    "authors": [
      "Woo Seong Jo",
      "Lu Liu",
      "Dashun Wang"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.07862"
  },
  {
    "id": "arXiv:2202.07868",
    "title": "Data-Driven Minimax Optimization with Expectation Constraints",
    "abstract": "Attention to data-driven optimization approaches, including the well-known\nstochastic gradient descent method, has grown significantly over recent\ndecades, but data-driven constraints have rarely been studied, because of the\ncomputational challenges of projections onto the feasible set defined by these\nhard constraints. In this paper, we focus on the non-smooth convex-concave\nstochastic minimax regime and formulate the data-driven constraints as\nexpectation constraints. The minimax expectation constrained problem subsumes a\nbroad class of real-world applications, including two-player zero-sum game and\ndata-driven robust optimization. We propose a class of efficient primal-dual\nalgorithms to tackle the minimax expectation-constrained problem, and show that\nour algorithms converge at the optimal rate of\n$\\mathcal{O}(\\frac{1}{\\sqrt{N}})$. We demonstrate the practical efficiency of\nour algorithms by conducting numerical experiments on large-scale real-world\napplications.",
    "descriptor": "",
    "authors": [
      "Shuoguang Yang",
      "Xudong Li",
      "Guanghui Lan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.07868"
  },
  {
    "id": "arXiv:2202.07869",
    "title": "Selective Inverse Kinematics: A Novel Approach to Finding Multiple  Solutions Fast for High-DoF Robotic",
    "abstract": "Inverse Kinematics (IK) solves the problem of mapping from the Cartesian\nspace to the joint configuration space of a robotic arm. It has a wide range of\napplications in areas such as computer graphics, protein structure prediction,\nand robotics. The problem is commonly solved analytically based on the\nstructure of the robotic arm or numerically by approximation through recursive\nmethods, e.g., Jacobian-based methods. Over the past decade, data-driven\nmethods have also been exploited. Unfortunately, these approaches to IK become\ninadequate for high Degree-of-Freedom (DoF) robotic arms. Theoretically, the\nredundant DoFs of such robotic arms can provide an infinite number of solutions\nto IK for reaching a given target position. The huge solution space could be\nexploited for more flexible operations of high-DoF robotic arms. The problem is\nthat existing approaches are confined and normally produce only one joint\nsolution for a target position. This paper presents the first work that solves\nhigh-DoF IK by generating multiple distinct joint solutions to reach any given\ntarget position in the working space. The proposed data-driven approach can be\napplied to any robotic arms without knowing detailed kinematics information. It\nnot only obtains multiple distinct joint solutions for a target position, but\nalso solves the high-DoF IK problem within a millisecond and achieves\nsubcentimeter distance errors with very sparse training data.",
    "descriptor": "",
    "authors": [
      "Chi-Kai Ho",
      "Chung-Ta King"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.07869"
  },
  {
    "id": "arXiv:2202.07870",
    "title": "IPD:An Incremental Prototype based DBSCAN for large-scale data with  cluster representatives",
    "abstract": "DBSCAN is a fundamental density-based clustering technique that identifies\nany arbitrary shape of the clusters. However, it becomes infeasible while\nhandling big data. On the other hand, centroid-based clustering is important\nfor detecting patterns in a dataset since unprocessed data points can be\nlabeled to their nearest centroid. However, it can not detect non-spherical\nclusters. For a large data, it is not feasible to store and compute labels of\nevery samples. These can be done as and when the information is required. The\npurpose can be accomplished when clustering act as a tool to identify cluster\nrepresentatives and query is served by assigning cluster labels of nearest\nrepresentative. In this paper, we propose an Incremental Prototype-based DBSCAN\n(IPD) algorithm which is designed to identify arbitrary-shaped clusters for\nlarge-scale data. Additionally, it chooses a set of representatives for each\ncluster.",
    "descriptor": "",
    "authors": [
      "Jayasree Saha",
      "Jayanta Mukherjee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.07870"
  },
  {
    "id": "arXiv:2202.07872",
    "title": "An efficient distributed scheduling algorithm for relay-assisted mmWave  backhaul networks",
    "abstract": "In this paper, a novel distributed scheduling algorithm is proposed, which\naims to efficiently schedule both the uplink and downlink backhaul traffic in\nthe relay-assisted mmWave backhaul network with a tree topology. The\nhandshaking of control messages, calculation of local schedules, and the\ndetermination of final valid schedule are all discussed. Simulation results\nshow that the performance of the distributed algorithm can reach very close to\nthe maximum traffic demand of the backhaul network, and it can also adapt to\nthe dynamic traffic with sharp traffic demand change of small-cell BSs quickly\nand accurately.",
    "descriptor": "",
    "authors": [
      "Qiang Hu",
      "Yuchen Liu",
      "Yan Yan",
      "Miao Liu",
      "Jun Zheng",
      "Douglas M. Blough"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.07872"
  },
  {
    "id": "arXiv:2202.07875",
    "title": "Knowledge Management for Cloud Computing Field",
    "abstract": "Migration legacy systems to cloud platforms is a knowledge intensive process.\nThere is an ever increasing body of knowledge reporting empirical scenarios of\nsuccessful and problematic cloud migration. Reusing this body of knowledge,\ndispersed and fragmented over the academic/multi-vocal literature, has\npractical values to mitigate costly risks and pitfalls in further projects of\nlegacy to-cloud and cloud-to-cloud migration. In line with this, knowledge\nmanagement systems/platforms pertinent to cloud migration are a prime\nprerequisite and a strategic imperative for an organization. We have conducted\na qualitative exploratory study to understand the benefits and challenges of\ndeveloping Knowledge Management Systems (KMS) for cloud migration in real\ntrials. Whilst our prototype system demonstration supported the importance and\nbene-fits of developing Cloud Migration KMS (CM-KMS), our semi-structured\nindustry interview study with 11 participants highlighted challenging\nimpediments against developing this class of KMS. As a result, this study\nproposes nine significant challenges that cause the abandon of the design and\nmaintenance of CM-KMS, including continuous changes and updates, integration of\nknowledge, knowledge granularity, preservation of context, automation,\ndeconstruction of traditional knowledge, dependency on experts, hybrid\nknowledge of both vendor-specific and vendor-neutral cloud platforms, and\nparsimony. Our results inform cloud architects to pay attention to adopt CM-KMS\nfor the legacy-to-cloud migration in their organizations.",
    "descriptor": "",
    "authors": [
      "Mahdi Fahmideh",
      "Jun Yan",
      "Jun Shen",
      "Aakash Ahmad",
      "Davoud Mougouei",
      "Anup Shrestha"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.07875"
  },
  {
    "id": "arXiv:2202.07880",
    "title": "CIS2: A Simplified Commonsense Inference Evaluation for Story Prose",
    "abstract": "Transformers have been showing near-human performance on a variety of tasks,\nbut they are not without their limitations. We discuss the issue of conflating\nresults of transformers that are instructed to do multiple tasks\nsimultaneously. In particular, we focus on the domain of commonsense reasoning\nwithin story prose, which we call contextual commonsense inference (CCI). We\nlook at the GLUCOSE (Mostafazadeh et al 2020) dataset and task for predicting\nimplicit commonsense inferences between story sentences. Since the GLUCOSE task\nsimultaneously generates sentences and predicts the CCI relation, there is a\nconflation in the results. Is the model really measuring CCI or is its ability\nto generate grammatical text carrying the results? In this paper, we introduce\nthe task contextual commonsense inference in sentence selection (CIS$^2$), a\nsimplified task that avoids conflation by eliminating language generation\naltogether. Our findings emphasize the necessity of future work to disentangle\nlanguage generation from the desired NLP tasks at hand.",
    "descriptor": "",
    "authors": [
      "Bryan Li",
      "Lara J. Martin",
      "Chris Callison-Burch"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07880"
  },
  {
    "id": "arXiv:2202.07881",
    "title": "The addition of temporal neighborhood makes the logic of prefixes and  sub-intervals EXPSPACE-complete",
    "abstract": "A classic result by Stockmeyer gives a non-elementary lower bound to the\nemptiness problem for star-free generalized regular expressions. This result is\nintimately connected to the satisfiability problem for interval temporal logic,\nnotably for formulas that make use of the so-called chop operator. Such an\noperator can indeed be interpreted as the inverse of the concatenation\noperation on regular languages, and this correspondence enables reductions\nbetween non-emptiness of star-free generalized regular expressions and\nsatisfiability of formulas of the interval temporal logic of chop under the\nhomogeneity assumption. In this paper, we study the complexity of the\nsatisfiability problem for suitable weakenings of the chop interval temporal\nlogic, that can be equivalently viewed as fragments of Halpern and Shoham\ninterval logic. We first consider the logic $\\mathsf{BD}_{hom}$ featuring\nmodalities $B$, for \\emph{begins}, corresponding to the prefix relation on\npairs of intervals, and $D$, for \\emph{during}, corresponding to the infix\nrelation. The homogeneous models of $\\mathsf{BD}_{hom}$ naturally correspond to\nlanguages defined by restricted forms of regular expressions, that use union,\ncomplementation, and the inverses of the prefix and infix relations. Such a\nfragment has been recently shown to be PSPACE-complete . In this paper, we\nstudy the extension $\\mathsf{BD}_{hom}$ with the temporal neighborhood modality\n$A$ (corresponding to the Allen relation \\emph{Meets}), and prove that it\nincreases both its expressiveness and complexity. In particular, we show that\nthe resulting logic $\\mathsf{BDA}_{hom}$ is EXPSPACE-complete.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2109.08320\n",
    "authors": [
      "L. Bozzelli",
      "A. Montanari",
      "A. Peron",
      "P. Sala"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.07881"
  },
  {
    "id": "arXiv:2202.07882",
    "title": "PhishChain: A Decentralized and Transparent System to Blacklist Phishing  URLs",
    "abstract": "Blacklists are a widely-used Internet security mechanism to protect Internet\nusers from financial scams, malicious web pages and other cyber attacks based\non blacklisted URLs. In this demo, we introduce PhishChain, a transparent and\ndecentralized system to blacklisting phishing URLs. At present, public/private\ndomain blacklists, such as PhishTank, CryptoScamDB, and APWG, are maintained by\na centralized authority, but operate in a crowd sourcing fashion to create a\nmanually verified blacklist periodically. In addition to being a single point\nof failure, the blacklisting process utilized by such systems is not\ntransparent. We utilize the blockchain technology to support transparency and\ndecentralization, where no single authority is controlling the blacklist and\nall operations are recorded in an immutable distributed ledger. Further, we\ndesign a page rank based truth discovery algorithm to assign a phishing score\nto each URL based on crowd sourced assessment of URLs. As an incentive for\nvoluntary participation, we assign skill points to each user based on their\nparticipation in URL verification.",
    "descriptor": "\nComments: phishing blockchain blocklisting\n",
    "authors": [
      "Shehan Edirimannage",
      "Mohamed Nabeel",
      "Charith Elvitigala",
      "Chamath Keppitiyagama"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.07882"
  },
  {
    "id": "arXiv:2202.07883",
    "title": "CGraph: Graph Based Extensible Predictive Domain Threat Intelligence  Platform",
    "abstract": "Ability to effectively investigate indicators of compromise and associated\nnetwork resources involved in cyber attacks is paramount not only to identify\naffected network resources but also to detect related malicious resources.\nToday, most of the cyber threat intelligence platforms are reactive in that\nthey can identify attack resources only after the attack is carried out.\nFurther, these systems have limited functionality to investigate associated\nnetwork resources. In this work, we propose an extensible predictive cyber\nthreat intelligence platform called cGraph that addresses the above\nlimitations. cGraph is built as a graph-first system where investigators can\nexplore network resources utilizing a graph based API. Further, cGraph provides\nreal-time predictive capabilities based on state-of-the-art inference\nalgorithms to predict malicious domains from network graphs with a few known\nmalicious and benign seeds. To the best of our knowledge, cGraph is the only\nthreat intelligence platform to do so. cGraph is extensible in that additional\nnetwork resources can be added to the system transparently.",
    "descriptor": "\nComments: threat intelligence graph investigation\n",
    "authors": [
      "Wathsara Daluwatta",
      "Ravindu De Silva",
      "Sanduni Kariyawasam",
      "Mohamed Nabeel",
      "Charith Elvitigala",
      "Kasun De Zoysa",
      "Chamath Keppitiyagama"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.07883"
  },
  {
    "id": "arXiv:2202.07884",
    "title": "Deep-Learning-Assisted Configuration of Reconfigurable Intelligent  Surfaces in Dynamic rich-scattering Environments",
    "abstract": "The integration of Reconfigurable Intelligent Surfaces (RISs) into wireless\nenvironments endows channels with programmability, and is expected to play a\nkey role in future communication standards. To date, most RIS-related efforts\nfocus on quasi-free-space, where wireless channels are typically modeled\nanalytically. Many realistic communication scenarios occur, however, in\nrich-scattering environments which, moreover, evolve dynamically. These\nconditions present a tremendous challenge in identifying an RIS configuration\nthat optimizes the achievable communication rate. In this paper, we make a\nfirst step toward tackling this challenge. Based on a simulator that is\nfaithful to the underlying wave physics, we train a deep neural network as\nsurrogate forward model to capture the stochastic dependence of wireless\nchannels on the RIS configuration under dynamic rich-scattering conditions.\nSubsequently, we use this model in combination with a genetic algorithm to\nidentify RIS configurations optimizing the communication rate. We numerically\ndemonstrate the ability of the proposed approach to tune RISs to improve the\nachievable rate in rich-scattering setups.",
    "descriptor": "\nComments: 5 pages; 3 figures; to be presented in IEEE ICASSP 2022\n",
    "authors": [
      "Kyriakos Stylianopoulos",
      "Nir Shlezinger",
      "Philipp del Hougne",
      "George C. Alexandropoulos"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.07884"
  },
  {
    "id": "arXiv:2202.07885",
    "title": "An Optimal-Time RLBWT Construction in BWT-runs Bounded Space",
    "abstract": "The compression of highly repetitive strings (i.e., strings with many\nrepetitions) has been a central research topic in string processing, and quite\na few compression methods for these strings have been proposed thus far. Among\nthem, an efficient compression format gathering increasing attention is the\nrun-length Burrows--Wheeler transform (RLBWT), which is a run-length encoded\nBWT as a reversible permutation of an input string on the lexicographical order\nof suffixes. State-of-the-art construction algorithms of RLBWT have a serious\nissue with respect to (i) non-optimal computation time or (ii) a working space\nthat is linearly proportional to the length of an input string. In this paper,\nwe present \\emph{r-comp}, the first optimal-time construction algorithm of\nRLBWT in BWT-runs bounded space. That is, the computational complexity of\nr-comp is $O(n + r \\log{r})$ time and $O(r\\log{n})$ bits of working space for\nthe length $n$ of an input string and the number $r$ of equal-letter runs in\nBWT. The computation time is optimal (i.e., $O(n)$) for strings with the\nproperty $r=O(n/\\log{n})$, which holds for most highly repetitive strings.\nExperiments using a real-world dataset of highly repetitive strings show the\neffectiveness of r-comp with respect to computation time and space.",
    "descriptor": "",
    "authors": [
      "Takaaki Nishimoto",
      "Shunsuke Kanda",
      "Yasuo Tabei"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.07885"
  },
  {
    "id": "arXiv:2202.07890",
    "title": "Online Control of Unknown Time-Varying Dynamical Systems",
    "abstract": "We study online control of time-varying linear systems with unknown dynamics\nin the nonstochastic control model. At a high level, we demonstrate that this\nsetting is \\emph{qualitatively harder} than that of either unknown\ntime-invariant or known time-varying dynamics, and complement our negative\nresults with algorithmic upper bounds in regimes where sublinear regret is\npossible. More specifically, we study regret bounds with respect to common\nclasses of policies: Disturbance Action (SLS), Disturbance Response (Youla),\nand linear feedback policies. While these three classes are essentially\nequivalent for LTI systems, we demonstrate that these equivalences break down\nfor time-varying systems.\nWe prove a lower bound that no algorithm can obtain sublinear regret with\nrespect to the first two classes unless a certain measure of system variability\nalso scales sublinearly in the horizon. Furthermore, we show that offline\nplanning over the state linear feedback policies is NP-hard, suggesting\nhardness of the online learning problem.\nOn the positive side, we give an efficient algorithm that attains a sublinear\nregret bound against the class of Disturbance Response policies up to the\naforementioned system variability term. In fact, our algorithm enjoys sublinear\n\\emph{adaptive} regret bounds, which is a strictly stronger metric than\nstandard regret and is more appropriate for time-varying systems. We sketch\nextensions to Disturbance Action policies and partial observation, and propose\nan inefficient algorithm for regret against linear state feedback policies.",
    "descriptor": "",
    "authors": [
      "Edgar Minasyan",
      "Paula Gradu",
      "Max Simchowitz",
      "Elad Hazan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.07890"
  },
  {
    "id": "arXiv:2202.07893",
    "title": "A Survey of Pretraining on Graphs: Taxonomy, Methods, and Applications",
    "abstract": "Pretrained Language Models (PLMs) such as BERT have revolutionized the\nlandscape of Natural Language Processing (NLP). Inspired by their\nproliferation, tremendous efforts have been devoted to Pretrained Graph Models\n(PGMs). Owing to the powerful model architectures of PGMs, abundant knowledge\nfrom massive labeled and unlabeled graph data can be captured. The knowledge\nimplicitly encoded in model parameters can benefit various downstream tasks and\nhelp to alleviate several fundamental issues of learning on graphs. In this\npaper, we provide the first comprehensive survey for PGMs. We firstly present\nthe limitations of graph representation learning and thus introduce the\nmotivation for graph pre-training. Then, we systematically categorize existing\nPGMs based on a taxonomy from four different perspectives. Next, we present the\napplications of PGMs in social recommendation and drug discovery. Finally, we\noutline several promising research directions that can serve as a guideline for\nfuture research.",
    "descriptor": "\nComments: 9 pages. Submitted to IJCAI 2022 (Survey Track)\n",
    "authors": [
      "Jun Xia",
      "Yanqiao Zhu",
      "Yuanqi Du",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Biomolecules (q-bio.BM)"
    ],
    "url": "https://arxiv.org/abs/2202.07893"
  },
  {
    "id": "arXiv:2202.07894",
    "title": "Knowledge Transfer from Large-scale Pretrained Language Models to  End-to-end Speech Recognizers",
    "abstract": "End-to-end speech recognition is a promising technology for enabling compact\nautomatic speech recognition (ASR) systems since it can unify the acoustic and\nlanguage model into a single neural network. However, as a drawback, training\nof end-to-end speech recognizers always requires transcribed utterances. Since\nend-to-end models are also known to be severely data hungry, this constraint is\ncrucial especially because obtaining transcribed utterances is costly and can\npossibly be impractical or impossible. This paper proposes a method for\nalleviating this issue by transferring knowledge from a language model neural\nnetwork that can be pretrained with text-only data. Specifically, this paper\nattempts to transfer semantic knowledge acquired in embedding vectors of\nlarge-scale language models. Since embedding vectors can be assumed as implicit\nrepresentations of linguistic information such as part-of-speech, intent, and\nso on, those are also expected to be useful modeling cues for ASR decoders.\nThis paper extends two types of ASR decoders, attention-based decoders and\nneural transducers, by modifying training loss functions to include embedding\nprediction terms. The proposed systems were shown to be effective for error\nrate reduction without incurring extra computational costs in the decoding\nphase.",
    "descriptor": "\nComments: To be presented in ICASSP 2022\n",
    "authors": [
      "Yotaro Kubo",
      "Shigeki Karita",
      "Michiel Bacchiani"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.07894"
  },
  {
    "id": "arXiv:2202.07896",
    "title": "Aryl: An Elastic Cluster Scheduler for Deep Learning",
    "abstract": "Companies build separate training and inference GPU clusters for deep\nlearning, and use separate schedulers to manage them. This leads to problems\nfor both training and inference: inference clusters have low GPU utilization\nwhen the traffic load is low; training jobs often experience long queueing time\ndue to lack of resources. We introduce Aryl, a new cluster scheduler to address\nthese problems. Aryl introduces capacity loaning to loan idle inference GPU\nservers for training jobs. It further exploits elastic scaling that scales a\ntraining job's GPU allocation to better utilize loaned resources. Capacity\nloaning and elastic scaling create new challenges to cluster management. When\nthe loaned servers need to be returned, we need to minimize the number of job\npreemptions; when more GPUs become available, we need to allocate them to\nelastic jobs and minimize the job completion time (JCT). Aryl addresses these\ncombinatorial problems using principled heuristics. It introduces the notion of\nserver preemption cost which it greedily reduces during server reclaiming. It\nfurther relies on the JCT reduction value defined for each additional worker\nfor an elastic job to solve the scheduling problem as a multiple-choice\nknapsack problem. Prototype implementation on a 64-GPU testbed and large-scale\nsimulation with 15-day traces of over 50,000 production jobs show that Aryl\nbrings 1.53x and 1.50x reductions in average queuing time and JCT, and improves\ncluster usage by up to 26.9% over the cluster scheduler without capacity\nloaning or elastic scaling.",
    "descriptor": "",
    "authors": [
      "Jiamin Li",
      "Hong Xu",
      "Yibo Zhu",
      "Zherui Liu",
      "Chuanxiong Guo",
      "Cong Wang"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07896"
  },
  {
    "id": "arXiv:2202.07901",
    "title": "Cross-Modal Common Representation Learning with Triplet Loss Functions",
    "abstract": "Common representation learning (CRL) learns a shared embedding between two or\nmore modalities to improve in a given task over using only one of the\nmodalities. CRL from different data types such as images and time-series data\n(e.g., audio or text data) requires a deep metric learning loss that minimizes\nthe distance between the modality embeddings. In this paper, we propose to use\nthe triplet loss, which uses positive and negative identities to create sample\npairs with different labels, for CRL between image and time-series modalities.\nBy adapting the triplet loss for CRL, higher accuracy in the main (time-series\nclassification) task can be achieved by exploiting additional information of\nthe auxiliary (image classification) task. Our experiments on synthetic data\nand handwriting recognition data from sensor-enhanced pens show an improved\nclassification accuracy, faster convergence, and a better generalizability.",
    "descriptor": "",
    "authors": [
      "Felix Ott",
      "David R\u00fcgamer",
      "Lucas Heublein",
      "Bernd Bischl",
      "Christopher Mutschler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07901"
  },
  {
    "id": "arXiv:2202.07902",
    "title": "When Does A Spectral Graph Neural Network Fail in Node Classification?",
    "abstract": "Spectral Graph Neural Networks (GNNs) with various graph filters have\nreceived extensive affirmation due to their promising performance in graph\nlearning problems. However, it is known that GNNs do not always perform well.\nAlthough graph filters provide theoretical foundations for model explanations,\nit is unclear when a spectral GNN will fail. In this paper, focusing on node\nclassification problems, we conduct a theoretical analysis of spectral GNNs\nperformance by investigating their prediction error. With the aid of graph\nindicators including homophily degree and response efficiency we proposed, we\nestablish a comprehensive understanding of complex relationships between graph\nstructure, node labels, and graph filters. We indicate that graph filters with\nlow response efficiency on label difference are prone to fail. To enhance GNNs\nperformance, we provide a provably better strategy for filter design from our\ntheoretical analysis - using data-driven filter banks, and propose simple\nmodels for empirical validation. Experimental results show consistency with our\ntheoretical results and support our strategy.",
    "descriptor": "",
    "authors": [
      "Zhixian Chen",
      "Tengfei Ma",
      "Yang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07902"
  },
  {
    "id": "arXiv:2202.07904",
    "title": "Blockchain Security when Messages are Lost",
    "abstract": "Security analyses for consensus protocols in blockchain research have\nprimarily focused on the synchronous model, where point-to-point communication\ndelays are upper bounded by a known finite constant. These models are\nunrealistic in noisy settings, where messages may be lost (i.e. incur infinite\ndelay). In this work, we study the impact of message losses on the security of\nthe proof-of-work longest-chain protocol. We introduce a new communication\nmodel to capture the impact of message loss called the $0-\\infty$ model, and\nderive a region of tolerable adversarial power under which the consensus\nprotocol is secure. The guarantees are derived as a simple bound for the\nprobability that a transaction violates desired security properties.\nSpecifically, we show that this violation probability decays almost\nexponentially in the security parameter. Our approach involves constructing\ncombinatorial objects from blocktrees, and identifying random variables\nassociated with them that are amenable to analysis. This approach improves\nexisting bounds and extends the known regime for tolerable adversarial\nthreshold in settings where messages may be lost.",
    "descriptor": "\nComments: 27 pages, 5 figures\n",
    "authors": [
      "Taha Ameen",
      "Suryanarayana Sankagiri",
      "Bruce Hajek"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.07904"
  },
  {
    "id": "arXiv:2202.07905",
    "title": "SoK: Human-Centered Phishing Susceptibility",
    "abstract": "Phishing is recognised as a serious threat to organisations and individuals.\nWhile there have been significant technical advances in blocking phishing\nattacks, people remain the last line of defence after phishing emails reach\ntheir email client. Most of the existing literature on this subject has focused\non the technical aspects related to phishing. However, the factors that cause\nhumans to be susceptible to phishing attacks are still not well-understood. To\nfill this gap, we reviewed the available literature and we propose a\nthree-stage Phishing Susceptibility Model (PSM) for explaining how humans are\ninvolved in phishing detection and prevention, and we systematically\ninvestigate the phishing susceptibility variables studied in the literature and\ntaxonomize them using our model. This model reveals several research gaps that\nneed to be addressed to improve users' detection performance. We also propose a\npractical impact assessment of the value of studying the phishing\nsusceptibility variables, and quality of evidence criteria. These can serve as\nguidelines for future research to improve experiment design, result quality,\nand increase the reliability and generalizability of findings.",
    "descriptor": "\nComments: 13 pages of content, 2 figures, 18 pages in total\n",
    "authors": [
      "Sijie Zhuo",
      "Robert Biddle",
      "Yun Sing Koh",
      "Danielle Lottridge",
      "Giovanni Russello"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.07905"
  },
  {
    "id": "arXiv:2202.07907",
    "title": "Singing-Tacotron: Global duration control attention and dynamic filter  for End-to-end singing voice synthesis",
    "abstract": "End-to-end singing voice synthesis (SVS) is attractive due to the avoidance\nof pre-aligned data. However, the auto learned alignment of singing voice with\nlyrics is difficult to match the duration information in musical score, which\nwill lead to the model instability or even failure to synthesize voice. To\nlearn accurate alignment information automatically, this paper proposes an\nend-to-end SVS framework, named Singing-Tacotron. The main difference between\nthe proposed framework and Tacotron is that the speech can be controlled\nsignificantly by the musical score's duration information. Firstly, we propose\na global duration control attention mechanism for the SVS model. The attention\nmechanism can control each phoneme's duration. Secondly, a duration encoder is\nproposed to learn a set of global transition tokens from the musical score.\nThese transition tokens can help the attention mechanism decide whether moving\nto the next phoneme or staying at each decoding step. Thirdly, to further\nimprove the model's stability, a dynamic filter is designed to help the model\novercome noise interference and pay more attention to local context\ninformation. Subjective and objective evaluation verify the effectiveness of\nthe method. Furthermore, the role of global transition tokens and the effect of\nduration control are explored. Examples of experiments can be found at\nhttps://hairuo55.github.io/SingingTacotron.",
    "descriptor": "\nComments: 5 pages, 7 figures\n",
    "authors": [
      "Tao Wang",
      "Ruibo Fu",
      "Jiangyan Yi",
      "Jianhua Tao",
      "Zhengqi Wen"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.07907"
  },
  {
    "id": "arXiv:2202.07908",
    "title": "Error Floor Analysis of Irregular Repetition ALOHA",
    "abstract": "With the rapid expansion of the Internet of Things, the efficient sharing of\nthe wireless medium by a large amount of simple transmitters is becoming\nessential. Scheduling-based solutions are inefficient for this setting, where\nsmall data units are broadcast sporadically by terminals that most of the time\nare idle. Modern random access has embraced the challenge and provides suitable\nslot-synchronous and asynchronous multiple access solutions based on\nreplicating the packets and exploiting successive interference cancellation\n(SIC) at the receiver. In this work, we focus on asynchronous modern random\naccess. Specifically, we derive an analytical approximation of the performance\nof irregular repetition ALOHA (IRA) in the so-called error floor region.\nNumerical results show the tightness of the derived approximation under various\nscenarios.",
    "descriptor": "\nComments: Accepted for publication at IEEE ICC 2022, Communication Theory symposium\n",
    "authors": [
      "Federico Clazzer",
      "Alexandre Graell i Amat"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.07908"
  },
  {
    "id": "arXiv:2202.07909",
    "title": "Can Deep Learning be Applied to Model-Based Multi-Object Tracking?",
    "abstract": "Multi-object tracking (MOT) is the problem of tracking the state of an\nunknown and time-varying number of objects using noisy measurements, with\nimportant applications such as autonomous driving, tracking animal behavior,\ndefense systems, and others. In recent years, deep learning (DL) has been\nincreasingly used in MOT for improving tracking performance, but mostly in\nsettings where the measurements are high-dimensional and there are no available\nmodels of the measurement likelihood and the object dynamics. The model-based\nsetting instead has not attracted as much attention, and it is still unclear if\nDL methods can outperform traditional model-based Bayesian methods, which are\nthe state of the art (SOTA) in this context. In this paper, we propose a\nTransformer-based DL tracker and evaluate its performance in the model-based\nsetting, comparing it to SOTA model-based Bayesian methods in a variety of\ndifferent tasks. Our results show that the proposed DL method can match the\nperformance of the model-based methods in simple tasks, while outperforming\nthem when the task gets more complicated, either due to an increase in the data\nassociation complexity, or to stronger nonlinearities of the models of the\nenvironment.",
    "descriptor": "",
    "authors": [
      "Juliano Pinto",
      "Georg Hess",
      "William Ljungbergh",
      "Yuxuan Xia",
      "Henk Wymeersch",
      "Lennart Svensson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.07909"
  },
  {
    "id": "arXiv:2202.07916",
    "title": "A spectral boundary integral method for the elastic obstacle scattering  problem in three dimensions",
    "abstract": "In this paper, we consider the scattering of a plane wave by a rigid obstacle\nembedded in a homogeneous and isotropic elastic medium in three dimensions.\nBased on the Helmholtz decomposition, the elastic scattering problem is reduced\nto a coupled boundary value problem for the Helmholtz and Maxwell equations. A\nnovel system of boundary integral equations is formulated and a spectral\nboundary integral method is developed for the coupled boundary value problem.\nNumerical experiments are presented to demonstrate the superior performance of\nthe proposed method.",
    "descriptor": "",
    "authors": [
      "Heping Dong",
      "Jun Lai",
      "Peijun Li"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.07916"
  },
  {
    "id": "arXiv:2202.07917",
    "title": "Non-standard linear recurring sequence subgroups and automorphisms of  irreducible cyclic codes",
    "abstract": "Let \\(\\cU\\) be the multiplicative group of order~\\(n\\) in the splitting field\n\\(\\bbF_{q^m}\\) of \\(x^n-1\\) over the finite field \\(\\bbF_q\\). Any map of the\nform \\(x\\rightarrow cx^t\\) with \\(c\\in \\cU\\) and \\(t=q^i\\), \\(0\\leq i<m\\), is\n\\(\\bbF_q\\)-linear on~\\(\\bbF_{q^m}\\) and fixes \\(\\cU\\) set-wise; maps of this\ntype will be called {\\em standard\\/}. Occasionally there are other, {\\em\nnon-standard\\/} \\(\\bbF_q\\)-linear maps on~\\(\\bbF_{q^m}\\) fixing \\(\\cU\\)\nset-wise, and in that case we say that the pair \\((n, q)\\) is {\\em\nnon-standard\\/}. We show that an irreducible cyclic code of length~\\(n\\) over\n\\(\\bbF_q\\) has ``extra'' permutation automorphisms (others than the {\\em\nstandard\\/} permutations generated by the cyclic shift and the Frobenius\nmapping that every such code has) precisely when the pair \\((n, q)\\) is\nnon-standard; we refer to such irreducible cyclic codes as {\\em non-standard\\/}\nor {\\em NSIC-codes\\/}. In addition, we relate these concepts to that of a\nnon-standard linear recurring sequence subgroup as investigated in a sequence\nof papers by Brison and Nogueira. We present several families of NSIC-codes,\nand two constructions called ``lifting'' and ``extension'' to create new\nNSIC-codes from existing ones. We show that all NSIC-codes of dimension two can\nbe obtained in this way, thus completing the classification for this case\nstarted by Brison and Nogueira.",
    "descriptor": "",
    "authors": [
      "Henk D.L. Hollmann"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.07917"
  },
  {
    "id": "arXiv:2202.07919",
    "title": "HousE: Knowledge Graph Embedding with Householder Parameterization",
    "abstract": "The effectiveness of knowledge graph embedding (KGE) largely depends on the\nability to model intrinsic relation patterns and mapping properties. However,\nexisting approaches can only capture some of them with insufficient modeling\ncapacity. In this work, we propose a more powerful KGE framework named HousE,\nwhich involves a novel parameterization based on two kinds of Householder\ntransformations: (1) Householder rotations to achieve superior capacity of\nmodeling relation patterns; (2) Householder projections to handle sophisticated\nrelation mapping properties. Theoretically, HousE is capable of modeling\ncrucial relation patterns and mapping properties simultaneously. Besides, HousE\nis a generalization of existing rotation-based models while extending the\nrotations to high-dimensional spaces. Empirically, HousE achieves new\nstate-of-the-art performance on five benchmark datasets. Our code is available\nat https://github.com/anrep/HousE.",
    "descriptor": "",
    "authors": [
      "Rui Li",
      "Jianan Zhao",
      "Chaozhuo Li",
      "Di He",
      "Yiqi Wang",
      "Yuming Liu",
      "Hao Sun",
      "Senzhang Wang",
      "Weiwei Deng",
      "Yanming Shen",
      "Xing Xie",
      "Qi Zhang"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07919"
  },
  {
    "id": "arXiv:2202.07922",
    "title": "ZeroGen: Efficient Zero-shot Learning via Dataset Generation",
    "abstract": "There is a growing interest in dataset generation recently due to the\nsuperior generative capacity of large pre-trained language models (PLMs). In\nthis paper, we study a flexible and efficient zero-short learning method,\nZeroGen. Given a zero-shot task, we first generate a dataset from scratch using\nPLMs in an unsupervised manner. Then, we train a tiny task model (e.g., LSTM)\nunder the supervision of the synthesized dataset. This approach allows highly\nefficient inference as the final task model only has orders of magnitude fewer\nparameters comparing to PLMs (e.g., GPT2-XL). Apart from being annotation-free\nand efficient, we argue that ZeroGen can also provide useful insights from the\nperspective of data-free model-agnostic knowledge distillation, and\nunreferenced text generation evaluation. Experiments and analysis on different\nNLP tasks, namely, text classification, question answering, and natural\nlanguage inference), show the effectiveness of ZeroGen.",
    "descriptor": "",
    "authors": [
      "Jiacheng Ye",
      "Jiahui Gao",
      "Qintong Li",
      "Hang Xu",
      "Jiangtao Feng",
      "Zhiyong Wu",
      "Tao Yu",
      "Lingpeng Kong"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07922"
  },
  {
    "id": "arXiv:2202.07925",
    "title": "ActionFormer: Localizing Moments of Actions with Transformers",
    "abstract": "Self-attention based Transformer models have demonstrated impressive results\nfor image classification and object detection, and more recently for video\nunderstanding. Inspired by this success, we investigate the application of\nTransformer networks for temporal action localization in videos. To this end,\nwe present ActionFormer -- a simple yet powerful model to identify actions in\ntime and recognize their categories in a single shot, without using action\nproposals or relying on pre-defined anchor windows. ActionFormer combines a\nmultiscale feature representation with local self-attention, and uses a\nlight-weighted decoder to classify every moment in time and estimate the\ncorresponding action boundaries. We show that this orchestrated design results\nin major improvements upon prior works. Without bells and whistles,\nActionFormer achieves 65.6% mAP at tIoU=0.5 on THUMOS14, outperforming the best\nprior model by 8.7 absolute percentage points and crossing the 60% mAP for the\nfirst time. Further, ActionFormer demonstrates strong results on ActivityNet\n1.3 (36.0% average mAP) and the more recent EPIC-Kitchens 100 (+13.5% average\nmAP over prior works). Our code is available at\nthis http URL",
    "descriptor": "",
    "authors": [
      "Chenlin Zhang",
      "Jianxin Wu",
      "Yin Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07925"
  },
  {
    "id": "arXiv:2202.07931",
    "title": "DBT-Net: Dual-branch federative magnitude and phase estimation with  attention-in-attention transformer for monaural speech enhancement",
    "abstract": "The decoupling-style concept begins to ignite in the speech enhancement area,\nwhich decouples the original complex spectrum estimation task into multiple\neasier sub-tasks (i.e., magnitude and phase), resulting in better performance\nand easier interpretability. In this paper, we propose a dual-branch federative\nmagnitude and phase estimation framework, dubbed DBT-Net, for monaural speech\nenhancement, which aims at recovering the coarse- and fine-grained regions of\nthe overall spectrum in parallel. From the complementary perspective, the\nmagnitude estimation branch is designed to filter out dominant noise components\nin the magnitude domain, while the complex spectrum purification branch is\nelaborately designed to inpaint the missing spectral details and implicitly\nestimate the phase information in the complex domain. To facilitate the\ninformation flow between each branch, interaction modules are introduced to\nleverage features learned from one branch, so as to suppress the undesired\nparts and recover the missing components of the other branch. Instead of\nadopting the conventional RNNs and temporal convolutional networks for sequence\nmodeling, we propose a novel attention-in-attention transformer-based network\nwithin each branch for better feature learning. More specially, it is composed\nof several adaptive spectro-temporal attention transformer-based modules and an\nadaptive hierarchical attention module, aiming to capture long-term\ntime-frequency dependencies and further aggregate intermediate hierarchical\ncontextual information. Comprehensive evaluations on the WSJ0-SI84 +\nDNS-Challenge and VoiceBank + DEMAND dataset demonstrate that the proposed\napproach consistently outperforms previous advanced systems and yields\nstate-of-the-art performance in terms of speech quality and intelligibility.",
    "descriptor": "\nComments: 13 pages;submitted to TASLP\n",
    "authors": [
      "Guochen Yu",
      "Andong Li",
      "Hui Wang",
      "Yutian Wang",
      "Yuxuan Ke",
      "Chengshi Zheng"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.07931"
  },
  {
    "id": "arXiv:2202.07932",
    "title": "On the Complexity of Scheduling Problems With a Fixed Number of  Identical Machines",
    "abstract": "In scheduling, we are given a set of jobs, together with a number of machines\nand our goal is to decide for every job, when and on which machine(s) it should\nbe scheduled in order to minimize some objective function. Different machine\nmodels, job characteristics and objective functions result in a multitude of\nscheduling problems and many of them are NP-hard, even for a fixed number of\nidentical machines. However, using pseudo-polynomial or approximation\nalgorithms, we can still hope to solve some of these problems efficiently. In\nthis work, we give conditional running time lower bounds for a large number of\nscheduling problems, indicating the optimality of some classical algorithms. In\nparticular, we show that the dynamic programming algorithm by Lawler and Moore\nis probably optimal for $1||\\sum w_jU_j$ and $Pm||C_{max}$. Moreover, the FPTAS\nby Gens and Levner for $1||\\sum w_jU_j$ and the algorithm by Lee and Uzsoy for\n$P2||\\sum w_jC_j$ are probably optimal as well. There is still small room for\nimprovement for the $1|Rej\\leq Q|\\sum w_jU_j$ algorithm by Zhang et al. and the\nalgorithm for $1||\\sum T_j$ by Lawler. We also give a lower bound for\n$P2|any|C_{max}$ and improve the dynamic program by Du and Leung from\n$\\mathcal{O}(nP^2)$ to $\\mathcal{O}(nP)$ to match this lower bound. Here, $P$\nis the sum of all processing times. The same idea also improves the algorithm\nfor $P3|any|C_{max}$ by Du and Leung from $\\mathcal{O}(nP^5)$ to\n$\\mathcal{O}(nP^2)$. The lower bounds in this work all either rely on the\n(Strong) Exponential Time Hypothesis or the $(\\min,+)$-conjecture. While our\nresults suggest the optimality of some classical algorithms, they also motivate\nfuture research in cases where the best known algorithms do not quite match the\nlower bounds.",
    "descriptor": "\nComments: 32 pages, 2 figures, submitted to SWAT 2022\n",
    "authors": [
      "Klaus Jansen",
      "Kai Kahler"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.07932"
  },
  {
    "id": "arXiv:2202.07937",
    "title": "Separation and Estimation of Periodic/Aperiodic State",
    "abstract": "Periodicity and aperiodicity can exist in a state simultaneously and\ntypically become quasi-periodicity and quasi-aperiodicity in a dynamically\nchanging state. The quasi-periodic and quasi-aperiodic states existing in the\nperiodic/aperiodic state mostly correspond to different phenomena and require\ndifferent controls. For separation control of these states, this paper defines\nthe periodic/aperiodic, quasi-periodic, and quasi-aperiodic states to construct\na periodic/aperiodic separation filter that separates the periodic/aperiodic\nstate into the quasi-periodic and quasi-aperiodic states. Based on these\ndefinitions, the linearity of periodic-pass and aperiodic-pass functions and\nthe orthogonality of quasi-periodic and quasi-aperiodic state functions are\nproved. Subsequently, the periodic/aperiodic separation filter composed of\nperiodic-pass and aperiodic-pass filters that realize the periodic-pass and\naperiodic-pass functions is designed and integrated with a Kalman filter for\nestimation of the quasi-periodic and quasi-aperiodic states.",
    "descriptor": "",
    "authors": [
      "Hisayoshi Muramatsu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.07937"
  },
  {
    "id": "arXiv:2202.07939",
    "title": "Clustering Enabled Few-Shot Load Forecasting",
    "abstract": "While the advanced machine learning algorithms are effective in load\nforecasting, they often suffer from low data utilization, and hence their\nsuperior performance relies on massive datasets. This motivates us to design\nmachine learning algorithms with improved data utilization. Specifically, we\nconsider the load forecasting for a new user in the system by observing only\nfew shots (data points) of its energy consumption. This task is challenging\nsince the limited samples are insufficient to exploit the temporal\ncharacteristics, essential for load forecasting. Nonetheless, we notice that\nthere are not too many temporal characteristics for residential loads due to\nthe limited kinds of human lifestyle. Hence, we propose to utilize the\nhistorical load profile data from existing users to conduct effective\nclustering, which mitigates the challenges brought by the limited samples.\nSpecifically, we first design a feature extraction clustering method for\ncategorizing historical data. Then, inheriting the prior knowledge from the\nclustering results, we propose a two-phase Long Short Term Memory (LSTM) model\nto conduct load forecasting for new users. The proposed method outperforms the\ntraditional LSTM model, especially when the training sample size fails to cover\na whole period (i.e., 24 hours in our task). Extensive case studies on two\nreal-world datasets and one synthetic dataset verify the effectiveness and\nefficiency of our method.",
    "descriptor": "\nComments: *The first two authors contributed equally to this work, and hence are co-first authors of this work. C. Wu is the corresponding author. This work was supported in part by the Shenzhen Institute of Artificial Intelligence and Robotics for Society\n",
    "authors": [
      "Qiyuan Wang",
      "Zhihui Chen",
      "Chenye Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.07939"
  },
  {
    "id": "arXiv:2202.07940",
    "title": "Meta Knowledge Distillation",
    "abstract": "Recent studies pointed out that knowledge distillation (KD) suffers from two\ndegradation problems, the teacher-student gap and the incompatibility with\nstrong data augmentations, making it not applicable to training\nstate-of-the-art models, which are trained with advanced augmentations.\nHowever, we observe that a key factor, i.e., the temperatures in the softmax\nfunctions for generating probabilities of both the teacher and student models,\nwas mostly overlooked in previous methods. With properly tuned temperatures,\nsuch degradation problems of KD can be much mitigated. However, instead of\nrelying on a naive grid search, which shows poor transferability, we propose\nMeta Knowledge Distillation (MKD) to meta-learn the distillation with learnable\nmeta temperature parameters. The meta parameters are adaptively adjusted during\ntraining according to the gradients of the learning objective. We validate that\nMKD is robust to different dataset scales, different teacher/student\narchitectures, and different types of data augmentation. With MKD, we achieve\nthe best performance with popular ViT architectures among compared methods that\nuse only ImageNet-1K as training data, ranging from tiny to large models. With\nViT-L, we achieve 86.5% with 600 epochs of training, 0.6% better than MAE that\ntrains for 1,650 epochs.",
    "descriptor": "\nComments: preprint\n",
    "authors": [
      "Jihao Liu",
      "Boxiao Liu",
      "Hongsheng Li",
      "Yu Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07940"
  },
  {
    "id": "arXiv:2202.07941",
    "title": "A Survey of Approaches for Event Sequence Analysis and Visualization  using the ESeVis Framework",
    "abstract": "Event sequence data is increasingly available. Many business operations are\nsupported by information systems that record transactions, events, state\nchanges, message exchanges, and so forth. This observation is equally valid for\nvarious industries, including production, logistics, healthcare, financial\nservices, education, to name but a few. The variety of application areas\nexplains that techniques for event sequence data analysis have been developed\nrather independently in different fields of computer science. Most prominent\nare contributions from information visualization and from process mining. So\nfar, the contributions from these two fields have neither been compared nor\nhave they been mapped to an integrated framework. In this paper, we develop the\nEvent Sequence Visualization framework (ESeVis) that gives due credit to the\ntraditions of both fields. Our mapping study provides an integrated perspective\non both fields and identifies potential for synergies for future research.",
    "descriptor": "",
    "authors": [
      "Anton Yeshchenko",
      "Jan Mendling"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.07941"
  },
  {
    "id": "arXiv:2202.07946",
    "title": "Turn Tree into Graph: Automatic Code Review via Simplified AST Driven  Graph Convolutional Network",
    "abstract": "Automatic code review (ACR), which can relieve the costs of manual\ninspection, is an indispensable and essential task in software engineering. To\ndeal with ACR, existing work is to serialize the abstract syntax tree (AST).\nHowever, making sense of the whole AST with sequence encoding approach is a\ndaunting task, mostly due to some redundant nodes in AST hinder the\ntransmission of node information. Not to mention that the serialized\nrepresentation is inadequate to grasp the information of tree structure in AST.\nIn this paper, we first present a new large-scale Apache Automatic Code Review\n(AACR) dataset for ACR task since there is still no publicly available dataset\nin this task. The release of this dataset would push forward the research in\nthis field. Based on it, we propose a novel Simplified AST based Graph\nConvolutional Network (SimAST-GCN) to deal with ACR task. Concretely, to\nimprove the efficiency of node information dissemination, we first simplify the\nAST of code by deleting the redundant nodes that do not contain connection\nattributes, and thus deriving a Simplified AST. Then, we construct a relation\ngraph for each code based on the Simplified AST to properly embody the\nrelations among code fragments of the tree structure into the graph.\nSubsequently, in the light of the merit of graph structure, we explore a graph\nconvolution networks architecture that follows an attention mechanism to\nleverage the crucial implications of code fragments to derive code\nrepresentations. Finally, we exploit a simple but effective subtraction\noperation in the representations between the original and revised code,\nenabling the revised difference to be preferably learned for deciding the\nresults of ACR. Experimental results on the AACR dataset illustrate that our\nproposed model outperforms the state-of-the-art methods.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "B. Wu",
      "B. Liang",
      "X. Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.07946"
  },
  {
    "id": "arXiv:2202.07948",
    "title": "NORM: An FPGA-based Non-volatile Memory Emulation Framework for  Intermittent Computing",
    "abstract": "Intermittent computing systems operate by relying only on harvested energy\naccumulated in their tiny energy reservoirs, typically capacitors. An\nintermittent device dies due to a power failure when there is no energy in its\ncapacitor and boots again when the harvested energy is sufficient to power its\nhardware components. Power failures prevent the forward progress of computation\ndue to the frequent loss of computational state. To remedy this problem,\nintermittent computing systems comprise built-in fast non-volatile memories\nwith high write endurance to store information that persists despite frequent\npower failures. However, the lack of design tools makes fast-prototyping these\nsystems difficult. Even though FPGAs are common platforms for fast prototyping\nand behavioral verification of continuously-powered architectures, they do not\ntarget prototyping intermittent computing systems. This article introduces a\nnew FPGA-based framework, named NORM (Non-volatile memORy eMulator), to emulate\nand verify the behavior of any intermittent computing system that exploits fast\nnon-volatile memories. Our evaluation showed that NORM can be used to emulate\nand validate FeRAM-based transiently-powered hardware architectures\nsuccessfully.",
    "descriptor": "\nComments: 19 pages, 11 figures\n",
    "authors": [
      "Simone Ruffini",
      "Luca Caronti",
      "Kas\u0131m Sinan Y\u0131ld\u0131r\u0131m",
      "Davide Brunelli"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Emerging Technologies (cs.ET)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.07948"
  },
  {
    "id": "arXiv:2202.07951",
    "title": "Energy Efficiency in Rate-Splitting Multiple Access with Mixed  Criticality",
    "abstract": "Future sixth generation (6G) wireless communication networks face the need to\nsimilarly meet unprecedented quality of service (QoS) demands while also\nproviding a larger energy efficiency (EE) to minimize their carbon footprint.\nMoreover, due to the diverseness of network participants, mixed criticality QoS\nlevels are assigned to the users of such networks. In this work, with a focus\non a cloud-radio access network (C-RAN), the fulfillment of desired QoS and\nminimized transmit power use is optimized jointly within a rate-splitting\nparadigm. Thereby, the optimization problem is non-convex. Hence, a\nlow-complexity algorithm is proposed based on fractional programming. Numerical\nresults validate that there is a trade-off between the QoS fulfillment and\npower minimization. Moreover, the energy efficiency of the proposed\nrate-splitting algorithm is larger than in comparative schemes, especially with\nmixed criticality.",
    "descriptor": "\nComments: 7 pages, 6 figures, 1 table. This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Robert-Jeron Reifert",
      "Stefan Roth",
      "Alaa Alameer Ahmad",
      "Aydin Sezgin"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.07951"
  },
  {
    "id": "arXiv:2202.07952",
    "title": "TimeREISE: Time-series Randomized Evolving Input Sample Explanation",
    "abstract": "Deep neural networks are one of the most successful classifiers across\ndifferent domains. However, due to their limitations concerning\ninterpretability their use is limited in safety critical context. The research\nfield of explainable artificial intelligence addresses this problem. However,\nmost of the interpretability methods are aligned to the image modality by\ndesign. The paper introduces TimeREISE a model agnostic attribution method\nspecifically aligned to success in the context of time series classification.\nThe method shows superior performance compared to existing approaches\nconcerning different well-established measurements. TimeREISE is applicable to\nany time series classification network, its runtime does not scale in a linear\nmanner concerning the input shape and it does not rely on prior data knowledge.",
    "descriptor": "\nComments: 8 pages, 6 figures, 6 tables\n",
    "authors": [
      "Dominique Mercier",
      "Andreas Dengel",
      "Sheraz Ahmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07952"
  },
  {
    "id": "arXiv:2202.07954",
    "title": "Unified smoke and fire detection in an evolutionary framework with  self-supervised progressive data augment",
    "abstract": "Few researches have studied simultaneous detection of smoke and flame\naccompanying fires due to their different physical natures that lead to\nuncertain fluid patterns. In this study, we collect a large image data set to\nre-label them as a multi-label image classification problem so as to identify\nsmoke and flame simultaneously. In order to solve the generalization ability of\nthe detection model on account of the movable fluid objects with uncertain\nshapes like fire and smoke, and their not compactible natures as well as the\ncomplex backgrounds with high variations, we propose a data augment method by\nrandom image stitch to deploy resizing, deforming, position variation, and\nbackground altering so as to enlarge the view of the learner. Moreover, we\npropose a self-learning data augment method by using the class activation map\nto extract the highly trustable region as new data source of positive examples\nto further enhance the data augment. By the mutual reinforcement between the\ndata augment and the detection model that are performed iteratively, both\nmodules make progress in an evolutionary manner. Experiments show that the\nproposed method can effectively improve the generalization performance of the\nmodel for concurrent smoke and fire detection.",
    "descriptor": "",
    "authors": [
      "Hang Zhang",
      "Su Yang",
      "Hongyong Wang",
      "zhongyan lu",
      "helin sun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07954"
  },
  {
    "id": "arXiv:2202.07959",
    "title": "EdgeFormer: A Parameter-Efficient Transformer for On-Device Seq2seq  Generation",
    "abstract": "We propose EdgeFormer -- a parameter-efficient Transformer of the\nencoder-decoder architecture for on-device seq2seq generation, which is\ncustomized under the strict computation and memory constraints. EdgeFormer\nproposes two novel principles for cost-effective parameterization and further\nenhance the model with efficient layer adaptation. We conduct extensive\nexperiments on two practical on-device seq2seq tasks: Machine Translation and\nGrammatical Error Correction, and show that EdgeFormer can effectively\noutperform previous parameter-efficient Transformer baselines and achieve very\ncompetitive results with knowledge distillation under both the computation and\nmemory constraints.",
    "descriptor": "",
    "authors": [
      "Tao Ge",
      "Furu Wei"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07959"
  },
  {
    "id": "arXiv:2202.07960",
    "title": "On a Variance Reduction Correction of the Temporal Difference for Policy  Evaluation in the Stochastic Continuous Setting",
    "abstract": "This paper deals with solving continuous time, state and action optimization\nproblems in stochastic settings, using reinforcement learning algorithms, and\nconsiders the policy evaluation process. We prove that standard learning\nalgorithms based on the discretized temporal difference are doomed to fail when\nthe time discretization tends to zero, because of the stochastic part. We\npropose a variance-reduction correction of the temporal difference, leading to\nnew learning algorithms that are stable with respect to vanishing time steps.\nThis allows us to give theoretical guarantees of convergence of our algorithms\nto the solutions of continuous stochastic optimization problems.",
    "descriptor": "",
    "authors": [
      "Ziad Kobeissi",
      "Francis Bach"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Analysis of PDEs (math.AP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.07960"
  },
  {
    "id": "arXiv:2202.07961",
    "title": "Identity testing for radical expressions",
    "abstract": "We study the \\emph{Radical Identity Testing} problem (RIT): Given an\nalgebraic circuit representing a multivariate polynomial $f(x_1, \\dots, x_k)$\nand nonnegative integers $a_1, \\dots, a_k$ and $d_1, \\dots,$ $d_k$, written in\nbinary, test whether the polynomial vanishes at the \\emph{real radicals}\n$\\sqrt[d_1]{a_1}, \\dots,\\sqrt[d_k]{a_k}$, i.e., test whether\n$f(\\sqrt[d_1]{a_1}, \\dots, \\sqrt[d_k]{a_k}) = 0$. We place the problem in\n{\\coNP} assuming the Generalised Riemann Hypothesis (GRH), improving on the\nstraightforward {\\PSPACE} upper bound obtained by reduction to the existential\ntheory of reals. Next we consider a restricted version, called $2$-RIT, where\nthe radicals are square roots of prime numbers, written in binary. It was known\nsince the work of Chen and Kao~\\cite{chen-kao} that $2$-RIT is at least as hard\nas the polynomial identity testing problem, however no better upper bound than\n{\\PSPACE} was known prior to our work. We show that $2$-RIT is in {\\coRP}\nassuming GRH and in {\\coNP} unconditionally. %While prior work~\\cite{blomer98,\nchen-kao} on {\\rit} relied on methods based on numerical approximation, we use\na symbolic approach and reduce the problem to evaluating the polynomial modulo\nsuitable prime ideals in the ring of integers of the number field\n$\\mathbb{Q}(\\sqrt[d_1]{a_1}, \\dots, \\sqrt[d_k]{a_k})$. Our proof relies on\ntheorems from algebraic and analytic number theory, such as the Chebotarev\ndensity theorem and quadratic reciprocity.",
    "descriptor": "\nComments: 32 pages\n",
    "authors": [
      "Nikhil Balaji",
      "Klara Nosan",
      "Mahsa Shirmohammadi",
      "James Worrell"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Logic in Computer Science (cs.LO)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2202.07961"
  },
  {
    "id": "arXiv:2202.07962",
    "title": "Revisiting Parameter-Efficient Tuning: Are We Really There Yet?",
    "abstract": "Parameter-efficient tuning (PETuning) methods have been deemed by many as the\nnew paradigm for using pretrained language models (PLMs). By tuning just a\nfraction amount of parameters comparing to full model finetuning, PETuning\nmethods claim to have achieved performance on par with or even better than\nfinetuning. In this work, we take a step back and re-examine these PETuning\nmethods by conducting the first comprehensive investigation into the training\nand evaluation of PETuning methods. We found the problematic validation and\ntesting practice in current studies, when accompanied by the instability nature\nof PETuning methods, has led to unreliable conclusions. When being compared\nunder a truly fair evaluation protocol, PETuning cannot yield consistently\ncompetitive performance while finetuning remains to be the best-performing\nmethod in medium- and high-resource settings. We delve deeper into the cause of\nthe instability and observed that model size does not explain the phenomenon\nbut training iteration positively correlates with the stability.",
    "descriptor": "",
    "authors": [
      "Guanzheng Chen",
      "Fangyu Liu",
      "Zaiqiao Meng",
      "Shangsong Liang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07962"
  },
  {
    "id": "arXiv:2202.07966",
    "title": "Guessing with Little Data",
    "abstract": "Reconstructing a hypothetical recurrence equation from the first terms of an\ninfinite sequence is a classical and well-known technique in experimental\nmathematics. We propose a variation of this technique which can succeed with\nfewer input terms.",
    "descriptor": "",
    "authors": [
      "Manuel Kauers",
      "Christoph Koutschan"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2202.07966"
  },
  {
    "id": "arXiv:2202.07968",
    "title": "On loss functions and evaluation metrics for music source separation",
    "abstract": "We investigate which loss functions provide better separations via\nbenchmarking an extensive set of those for music source separation. To that\nend, we first survey the most representative audio source separation losses we\nidentified, to later consistently benchmark them in a controlled experimental\nsetup. We also explore using such losses as evaluation metrics, via\ncross-correlating them with the results of a subjective test. Based on the\nobservation that the standard signal-to-distortion ratio metric can be\nmisleading in some scenarios, we study alternative evaluation metrics based on\nthe considered losses.",
    "descriptor": "\nComments: Accepted to ICASSP 2022\n",
    "authors": [
      "Enric Gus\u00f3",
      "Jordi Pons",
      "Santiago Pascual",
      "Joan Serr\u00e0"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.07968"
  },
  {
    "id": "arXiv:2202.07980",
    "title": "Querying Inconsistent Prioritized Data with ORBITS: Algorithms,  Implementation, and Experiments",
    "abstract": "We investigate practical algorithms for inconsistency-tolerant query\nanswering over prioritized knowledge bases, which consist of a logical theory,\na set of facts, and a priority relation between conflicting facts. We consider\nthree well-known semantics (AR, IAR and brave) based upon two notions of\noptimal repairs (Pareto and completion). Deciding whether a query answer holds\nunder these semantics is (co)NP-complete in data complexity for a large class\nof logical theories, and SAT-based procedures have been devised for\nrepair-based semantics when there is no priority relation, or the relation has\na special structure. The present paper introduces the first SAT encodings for\nPareto- and completion-optimal repairs w.r.t. general priority relations and\nproposes several ways of employing existing and new encodings to compute\nanswers under (optimal) repair-based semantics, by exploiting different\nreasoning modes of SAT solvers. The comprehensive experimental evaluation of\nour implementation compares both (i) the impact of adopting semantics based on\ndifferent kinds of repairs, and (ii) the relative performances of alternative\nprocedures for the same semantics.",
    "descriptor": "\nComments: 122 pages\n",
    "authors": [
      "Meghyn Bienvenu",
      "Camille Bourgaux"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2202.07980"
  },
  {
    "id": "arXiv:2202.07986",
    "title": "Towards a Better Understanding of Online Influence: Differences in  Twitter CommunicationBetween Companies and Influencers",
    "abstract": "In the last decade, Social Media platforms such as Twitter have gained\nimportance in the various marketing strategies of companies. This work aims to\nexamine the presence of influential content on a textual level, by\ninvestigating characteristics of tweets in the context of social impact theory,\nand its dimension immediacy. To this end, we analysed influential Twitter\ncommunication data during Black Friday 2018 with methods from social media\nanalytics such as sentiment analysis and degree centrality. Results show\nsignificant differences in communication style between companies and\ninfluencers. Companies published longer textual content and created more tweets\nwith a positive sentiment and more first-person pronouns than influencers.\nThese findings shall serve as a basis for a future experimental study to\nexamine the impact of text presence on consumer cognition and the willingness\nto purchase.",
    "descriptor": "\nComments: Australasian Conference on Information Systems, 2020, Wellington\n",
    "authors": [
      "Diana C. Hernandez-Bocanegra",
      "Angela Borchert",
      "Felix Br\u00fcnker",
      "Gautam Kishore Shahi",
      "Bj\u00f6rn Ross"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.07986"
  },
  {
    "id": "arXiv:2202.07987",
    "title": "Out-Of-Distribution Generalization on Graphs: A Survey",
    "abstract": "Graph machine learning has been extensively studied in both academia and\nindustry. Although booming with a vast number of emerging methods and\ntechniques, most of the literature is built on the I.I.D. hypothesis, i.e.,\ntesting and training graph data are independent and identically distributed.\nHowever, this I.I.D. hypothesis can hardly be satisfied in many real-world\ngraph scenarios where the model performance substantially degrades when there\nexist distribution shifts between testing and training graph data. To solve\nthis critical problem, out-of-distribution (OOD) generalization on graphs,\nwhich goes beyond the I.I.D. hypothesis, has made great progress and attracted\never-increasing attention from the research community. In this paper, we\ncomprehensively survey OOD generalization on graphs and present a detailed\nreview of recent advances in this area. First, we provide a formal problem\ndefinition of OOD generalization on graphs. Second, we categorize existing\nmethods into three classes from conceptually different perspectives, i.e.,\ndata, model, and learning strategy, based on their positions in the graph\nmachine learning pipeline, followed by detailed discussions for each category.\nWe also review the theories related to OOD generalization on graphs and\nintroduce the commonly used graph datasets for thorough evaluations. Last but\nnot least, we share our insights on future research directions. This paper is\nthe first systematic and comprehensive review of OOD generalization on graphs,\nto the best of our knowledge.",
    "descriptor": "",
    "authors": [
      "Haoyang Li",
      "Xin Wang",
      "Ziwei Zhang",
      "Wenwu Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07987"
  },
  {
    "id": "arXiv:2202.07989",
    "title": "High-order accurate entropy stable adaptive moving mesh finite  difference schemes for (multi-component) compressible Euler equations with  the stiffened equation of state",
    "abstract": "This paper extends the high-order entropy stable (ES) adaptive moving mesh\nfinite difference schemes developed in [14] to the two- and three-dimensional\n(multi-component) compressible Euler equations with the stiffened equation of\nstate. The two-point entropy conservative (EC) flux is first constructed in the\ncurvilinear coordinates. The high-order semi-discrete EC schemes are given with\nthe aid of the two-point EC flux and the high-order discretization of the\ngeometric conservation laws, and then the high-order semi-discrete ES schemes\nsatisfying the entropy inequality are derived by adding the high-order\ndissipation term based on the multi-resolution weighted essentially\nnon-oscillatory (WENO) reconstruction for the scaled entropy variables to the\nEC schemes. The explicit strong-stability-preserving Runge-Kutta methods are\nused for the time discretization and the mesh points are adaptively\nredistributed by iteratively solving the mesh redistribution equations with an\nappropriately chosen monitor function. Several 2D and 3D numerical tests are\nconducted on the parallel computer system with the MPI programming to validate\nthe accuracy and the ability to capture effectively the localized structures of\nthe proposed schemes.",
    "descriptor": "\nComments: 41 pages\n",
    "authors": [
      "Shangting Li",
      "Junming Duan",
      "Huazhong Tang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.07989"
  },
  {
    "id": "arXiv:2202.07991",
    "title": "ADIMA: Abuse Detection In Multilingual Audio",
    "abstract": "Abusive content detection in spoken text can be addressed by performing\nAutomatic Speech Recognition (ASR) and leveraging advancements in natural\nlanguage processing. However, ASR models introduce latency and often perform\nsub-optimally for profane words as they are underrepresented in training\ncorpora and not spoken clearly or completely. Exploration of this problem\nentirely in the audio domain has largely been limited by the lack of audio\ndatasets. Building on these challenges, we propose ADIMA, a novel,\nlinguistically diverse, ethically sourced, expert annotated and well-balanced\nmultilingual profanity detection audio dataset comprising of 11,775 audio\nsamples in 10 Indic languages spanning 65 hours and spoken by 6,446 unique\nusers. Through quantitative experiments across monolingual and cross-lingual\nzero-shot settings, we take the first step in democratizing audio based content\nmoderation in Indic languages and set forth our dataset to pave future work.",
    "descriptor": "",
    "authors": [
      "Vikram Gupta",
      "Rini Sharon",
      "Ramit Sawhney",
      "Debdoot Mukherjee"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.07991"
  },
  {
    "id": "arXiv:2202.07992",
    "title": "Improved analysis of randomized SVD for top-eigenvector approximation",
    "abstract": "Computing the top eigenvectors of a matrix is a problem of fundamental\ninterest to various fields. While the majority of the literature has focused on\nanalyzing the reconstruction error of low-rank matrices associated with the\nretrieved eigenvectors, in many applications one is interested in finding one\nvector with high Rayleigh quotient. In this paper we study the problem of\napproximating the top-eigenvector. Given a symmetric matrix $\\mathbf{A}$ with\nlargest eigenvalue $\\lambda_1$, our goal is to find a vector \\hu that\napproximates the leading eigenvector $\\mathbf{u}_1$ with high accuracy, as\nmeasured by the ratio\n$R(\\hat{\\mathbf{u}})=\\lambda_1^{-1}{\\hat{\\mathbf{u}}^T\\mathbf{A}\\hat{\\mathbf{u}}}/{\\hat{\\mathbf{u}}^T\\hat{\\mathbf{u}}}$.\nWe present a novel analysis of the randomized SVD algorithm of\n\\citet{halko2011finding} and derive tight bounds in many cases of interest.\nNotably, this is the first work that provides non-trivial bounds of\n$R(\\hat{\\mathbf{u}})$ for randomized SVD with any number of iterations. Our\ntheoretical analysis is complemented with a thorough experimental study that\nconfirms the efficiency and accuracy of the method.",
    "descriptor": "\nComments: Accepted to International Conference on Artificial Intelligence and Statistics (AISTATS) 2022\n",
    "authors": [
      "Ruo-Chun Tzeng",
      "Po-An Wang",
      "Florian Adriaens",
      "Aristides Gionis",
      "Chi-Jen Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.07992"
  },
  {
    "id": "arXiv:2202.07993",
    "title": "Planckian jitter: enhancing the color quality of self-supervised visual  representations",
    "abstract": "Several recent works on self-supervised learning are trained by mapping\ndifferent augmentations of the same image to the same feature representation.\nThe set of used data augmentations is of crucial importance for the quality of\nthe learned feature representation. We analyze how the traditionally used color\njitter negatively impacts the quality of the color features in the learned\nfeature representation. To address this problem, we replace this module with\nphysics-based color augmentation, called Planckian jitter, which creates\nrealistic variations in chromaticity, producing a model robust to llumination\nchanges that can be commonly observed in real life, while maintaining the\nability to discriminate the image content based on color information. We\nfurther improve the performance by introducing a latent space combination of\ncolor-sensitive and non-color-sensitive features. These are found to be\ncomplementary and the combination leads to large absolute performance gains\nover the default data augmentation on color classification tasks, including on\nFlowers-102 (+15%), Cub200 (+11%), VegFru (+15%), and T1K+ (+12%). Finally, we\npresent a color sensitivity analysis to document the impact of different\ntraining methods on the model neurons and we show that the performance of the\nlearned features is robust with respect to illuminant variations.",
    "descriptor": "",
    "authors": [
      "Simone Zini",
      "Marco Buzzelli",
      "Bart\u0142omiej Twardowski",
      "Joost van de Weijer"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07993"
  },
  {
    "id": "arXiv:2202.07994",
    "title": "Privacy-preserving Similarity Calculation of Speaker Features Using  Fully Homomorphic Encryption",
    "abstract": "Recent advances in machine learning techniques are enabling Automated Speech\nRecognition (ASR) more accurate and practical. The evidence of this can be seen\nin the rising number of smart devices with voice processing capabilities. More\nand more devices around us are in-built with ASR technology. This poses serious\nprivacy threats as speech contains unique biometric characteristics and\npersonal data. However, the privacy concern can be mitigated if the voice\nfeatures are processed in the encrypted domain. Within this context, this paper\nproposes an algorithm to redesign the back-end of the speaker verification\nsystem using fully homomorphic encryption techniques. The solution exploits the\nCheon-Kim-Kim-Song (CKKS) fully homomorphic encryption scheme to obtain a\nreal-time and non-interactive solution. The proposed solution contains a novel\napproach based on Newton Raphson method to overcome the limitation of CKKS\nscheme (i.e., calculating an inverse square-root of an encrypted number). This\nprovides an efficient solution with less multiplicative depths for a negligible\nloss in accuracy. The proposed algorithm is validated using a well-known speech\ndataset. The proposed algorithm performs encrypted-domain verification in\nreal-time (with less than 1.3 seconds delay) for a 2.8\\% equal-error-rate loss\ncompared to plain-domain verification.",
    "descriptor": "",
    "authors": [
      "Yogachandran Rahulamathavan"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.07994"
  },
  {
    "id": "arXiv:2202.07995",
    "title": "Branching Reinforcement Learning",
    "abstract": "In this paper, we propose a novel Branching Reinforcement Learning (Branching\nRL) model, and investigate both Regret Minimization (RM) and Reward-Free\nExploration (RFE) metrics for this model. Unlike standard RL where the\ntrajectory of each episode is a single $H$-step path, branching RL allows an\nagent to take multiple base actions in a state such that transitions branch out\nto multiple successor states correspondingly, and thus it generates a\ntree-structured trajectory. This model finds important applications in\nhierarchical recommendation systems and online advertising. For branching RL,\nwe establish new Bellman equations and key lemmas, i.e., branching value\ndifference lemma and branching law of total variance, and also bound the total\nvariance by only $O(H^2)$ under an exponentially-large trajectory. For RM and\nRFE metrics, we propose computationally efficient algorithms BranchVI and\nBranchRFE, respectively, and derive nearly matching upper and lower bounds. Our\nresults are only polynomial in problem parameters despite exponentially-large\ntrajectories.",
    "descriptor": "",
    "authors": [
      "Yihan Du",
      "Wei Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07995"
  },
  {
    "id": "arXiv:2202.08003",
    "title": "On higher order passivity preserving schemes for nonlinear Maxwell's  equations",
    "abstract": "We present two strategies for designing passivity preserving higher order\ndiscretization methods for Maxwell's equations in nonlinear Kerr-type media.\nBoth approaches are based on variational approximation schemes in space and\ntime. This allows to rigorously prove energy conservation or dissipation, and\nthus passivity, on the fully discrete level. For linear media, the proposed\nmethods coincide with certain combinations of mixed finite element and implicit\nRunge-Kutta schemes. The order optimal convergence rates, which can thus be\nexpected for linear problems, are also observed for nonlinear problems in the\nnumerical tests.",
    "descriptor": "",
    "authors": [
      "Herbert Egger",
      "Vsevolod Shashkov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.08003"
  },
  {
    "id": "arXiv:2202.08004",
    "title": "Deep Koopman Operator with Control for Nonlinear Systems",
    "abstract": "Recently Koopman operator has become a promising data-driven tool to\nfacilitate real-time control for unknown nonlinear systems. It maps nonlinear\nsystems into equivalent linear systems in embedding space, ready for real-time\nlinear control methods. However, designing an appropriate Koopman embedding\nfunction remains a challenging task. Furthermore, most Koopman-based algorithms\nonly consider nonlinear systems with linear control input, resulting in lousy\nprediction and control performance when the system is fully nonlinear with the\ncontrol input. In this work, we propose an end-to-end deep learning framework\nto learn the Koopman embedding function and Koopman Operator together to\nalleviate such difficulties. We first parameterize the embedding function and\nKoopman Operator with the neural network and train them end-to-end with the\nK-steps loss function. We then design an auxiliary control network to encode\nthe nonlinear state-dependent control term to model the nonlinearity in control\ninput. For linear control, this encoded term is considered the new control\nvariable instead, ensuring the linearity of the embedding space. Then we deploy\nLinear Quadratic Regulator (LQR) on the linear embedding space to derive the\noptimal control policy and decode the actual control input from the control\nnet. Experimental results demonstrate that our approach outperforms other\nexisting methods, reducing the prediction error by order-of-magnitude and\nachieving superior control performance in several nonlinear dynamic systems\nlike damping pendulum, CartPole, and 7 Dof robotic manipulator.",
    "descriptor": "",
    "authors": [
      "Haojie Shi",
      "Max Q.H. Meng"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08004"
  },
  {
    "id": "arXiv:2202.08005",
    "title": "Should You Mask 15% in Masked Language Modeling?",
    "abstract": "Masked language models conventionally use a masking rate of 15% due to the\nbelief that more masking would provide insufficient context to learn good\nrepresentations, and less masking would make training too expensive.\nSurprisingly, we find that masking up to 40% of input tokens can outperform the\n15% baseline, and even masking 80% can preserve most of the performance, as\nmeasured by fine-tuning on downstream tasks. Increasing the masking rates has\ntwo distinct effects, which we investigate through careful ablations: (1) A\nlarger proportion of input tokens are corrupted, reducing the context size and\ncreating a harder task, and (2) models perform more predictions, which benefits\ntraining. We observe that larger models in particular favor higher masking\nrates, as they have more capacity to perform the harder task. We also connect\nour findings to sophisticated masking schemes such as span masking and PMI\nmasking, as well as BERT's curious 80-10-10 corruption strategy, and find that\nsimple uniform masking with [MASK] replacements can be competitive at higher\nmasking rates. Our results contribute to a better understanding of masked\nlanguage modeling and point to new avenues for efficient pre-training.",
    "descriptor": "",
    "authors": [
      "Alexander Wettig",
      "Tianyu Gao",
      "Zexuan Zhong",
      "Danqi Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08005"
  },
  {
    "id": "arXiv:2202.08006",
    "title": "Recoloring Unit Interval Graphs with Logarithmic Recourse Budget",
    "abstract": "In this paper we study the problem of coloring a unit interval graph which\nchanges dynamically. In our model the unit intervals are added or removed one\nat the time, and have to be colored immediately, so that no two overlapping\nintervals share the same color. After each update only a limited number of\nintervals is allowed to be recolored. The limit on the number of recolorings\nper update is called the recourse budget. In this paper we show, that if the\ngraph remains $k$-colorable at all times, and the updates consist of insertions\nonly, then we can achieve the amortized recourse budget of $O(k^7 \\log n)$\nwhile maintaining a proper coloring with $k$ colors. This is an exponential\nimprovement over the result in [Bosek et al., Recoloring Interval Graphs with\nLimited Recourse Budget. SWAT 2020] in terms of both $k$ and $n$. We complement\nthis result by showing the lower bound of $\\Omega(n)$ on the amortized recourse\nbudget in the fully dynamic setting. Our incremental algorithm can be\nefficiently implemented.\nAs a byproduct of independent interest we include a new result on coloring\nproper circular arc graphs. Let $L$ be the maximum number of arcs intersecting\nin one point for some set of unit circular arcs $\\mathcal{A}$. We show that if\nthere is a set $\\mathcal{A}'$ of non-intersecting unit arcs of size $L^2-1$\nsuch that $\\mathcal{A} \\cup \\mathcal{A}'$ does not contain $L+1$ arcs\nintersecting in one point, then it is possible to color $\\mathcal{A}$ with $L$\ncolors. This complements the work on unit circular arc coloring, which\nspecifies sufficient conditions needed to color $\\mathcal{A}$ with $L+1$ colors\nor more.",
    "descriptor": "\nComments: 26 pages, 9 figures\n",
    "authors": [
      "Bart\u0142omiej Bosek",
      "Anna Zych-Pawlewicz"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.08006"
  },
  {
    "id": "arXiv:2202.08008",
    "title": "Near-Shortest Path Routing in Hybrid Communication Networks",
    "abstract": "Hybrid networks, i.e., networks that leverage different means of\ncommunication, become ever more widespread. To allow theoretical study of such\nnetworks, [Augustine et al., SODA'20] introduced the $\\mathsf{HYBRID}$ model,\nwhich is based on the concept of synchronous message passing and uses two\nfundamentally different principles of communication: a local mode, which allows\nevery node to exchange one message per round with each neighbor in a local\ncommunication graph; and a global mode where any pair of nodes can exchange\nmessages, but only few such exchanges can take place per round.\nA sizable portion of the previous research for the $\\mathsf{HYBRID}$ model\nrevolves around basic communication primitives and computing distances or\nshortest paths in networks. In this paper, we extend this study to a related\nfundamental problem of computing compact routing schemes for near-shortest\npaths in the local communication graph. We demonstrate that, for the case where\nthe local communication graph is a unit-disc graph with $n$ nodes that is\nrealized in the plane and has no radio holes, we can deterministically compute\na routing scheme that has constant stretch and uses labels and local routing\ntables of size $O(\\log n)$ bits in only $O(\\log n)$ rounds.",
    "descriptor": "",
    "authors": [
      "Sam Coy",
      "Artur Czumaj",
      "Michael Feldmann",
      "Kristian Hinnenthal",
      "Fabian Kuhn",
      "Christian Scheideler",
      "Philipp Schneider",
      "Martijn Struijs"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.08008"
  },
  {
    "id": "arXiv:2202.08010",
    "title": "360 Depth Estimation in the Wild -- The Depth360 Dataset and the SegFuse  Network",
    "abstract": "Single-view depth estimation from omnidirectional images has gained\npopularity with its wide range of applications such as autonomous driving and\nscene reconstruction. Although data-driven learning-based methods demonstrate\nsignificant potential in this field, scarce training data and ineffective 360\nestimation algorithms are still two key limitations hindering accurate\nestimation across diverse domains. In this work, we first establish a\nlarge-scale dataset with varied settings called Depth360 to tackle the training\ndata problem. This is achieved by exploring the use of a plenteous source of\ndata, 360 videos from the internet, using a test-time training method that\nleverages unique information in each omnidirectional sequence. With novel\ngeometric and temporal constraints, our method generates consistent and\nconvincing depth samples to facilitate single-view estimation. We then propose\nan end-to-end two-branch multi-task learning network, SegFuse, that mimics the\nhuman eye to effectively learn from the dataset and estimate high-quality depth\nmaps from diverse monocular RGB images. With a peripheral branch that uses\nequirectangular projection for depth estimation and a foveal branch that uses\ncubemap projection for semantic segmentation, our method predicts consistent\nglobal depth while maintaining sharp details at local regions. Experimental\nresults show favorable performance against the state-of-the-art methods.",
    "descriptor": "\nComments: 10 pages, 10 figures, 5 tables, submitted to IEEE VR 2022\n",
    "authors": [
      "Qi Feng",
      "Hubert P. H. Shum",
      "Shigeo Morishima"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08010"
  },
  {
    "id": "arXiv:2202.08011",
    "title": "Towards Identifying Social Bias in Dialog Systems: Frame, Datasets, and  Benchmarks",
    "abstract": "The research of open-domain dialog systems has been greatly prospered by\nneural models trained on large-scale corpora, however, such corpora often\nintroduce various safety problems (e.g., offensive languages, biases, and toxic\nbehaviors) that significantly hinder the deployment of dialog systems in\npractice. Among all these unsafe issues, addressing social bias is more complex\nas its negative impact on marginalized populations is usually expressed\nimplicitly, thus requiring normative reasoning and rigorous analysis. In this\npaper, we focus our investigation on social bias detection of dialog safety\nproblems. We first propose a novel Dial-Bias Frame for analyzing the social\nbias in conversations pragmatically, which considers more comprehensive\nbias-related analyses rather than simple dichotomy annotations. Based on the\nproposed framework, we further introduce CDail-Bias Dataset that, to our\nknowledge, is the first well-annotated Chinese social bias dialog dataset. In\naddition, we establish several dialog bias detection benchmarks at different\nlabel granularities and input types (utterance-level and context-level). We\nshow that the proposed in-depth analyses together with these benchmarks in our\nDial-Bias Frame are necessary and essential to bias detection tasks and can\nbenefit building safe dialog systems in practice.",
    "descriptor": "",
    "authors": [
      "Jingyan Zhou",
      "Jiawen Deng",
      "Fei Mi",
      "Yitong Li",
      "Yasheng Wang",
      "Minlie Huang",
      "Xin Jiang",
      "Qun Liu",
      "Helen Meng"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.08011"
  },
  {
    "id": "arXiv:2202.08017",
    "title": "Mechanization of LAGC Semantics in Isabelle",
    "abstract": "Formal programming language semantics are imperative when trying to verify\nproperties of programs in an automated manner. Using a new approach, Din et al.\nstrengthen the ability of reasoning about concurrent programs by proposing a\nmodular trace semantics, which can flexibly adapt to the most prominent\nimperative programming language paradigms. These semantics decouple the\nevaluation in the local environments from the evaluation in the global\nenvironment by generating abstract, symbolic traces for the individual, local\nsystems. The traces are then composed and concretized, resulting in global\ntraces for the global system. Hence, these semantics are called Locally\nAbstract, Globally Concrete (LAGC).\nIn this work, we present a formalization of the LAGC semantics in the popular\ntheorem proving environment Isabelle/HOL. The given model is based on the prior\nwork on the theory of LAGC semantics by Din et al. and includes formalizations\nof the basic theorems, the LAGC semantics for the While Language (WL), as well\nas the LAGC semantics for an extended version of the While Language (WLEXT). We\nfurthermore use our Isabelle model in order to provide formal proofs for\nseveral advanced properties of the LAGC semantics, which have not been analyzed\nin the original paper.\nWhilst the main goal of the work was to formalize the LAGC semantics in a\nmathematically rigorous manner, we also achieve a high level of proof\nautomatization and manage to contribute an efficient code-generation for the\ncomputation of program traces. As the formalization of the semantics is highly\nmodular, the given theories could in the future be extended with even more\nsophisticated programming language paradigms.",
    "descriptor": "",
    "authors": [
      "Niklas Heidler"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2202.08017"
  },
  {
    "id": "arXiv:2202.08019",
    "title": "Data-Driven Control of Event- and Self-Triggered Discrete-Time Systems",
    "abstract": "The present paper considers the model-based and data-driven control of\nunknown linear time-invariant discrete-time systems under event-triggering and\nself-triggering transmission schemes. To this end, we begin by presenting a\ndynamic event-triggering scheme (ETS) based on periodic sampling, and a\ndiscrete-time looped-functional (DLF) approach, through which a model-based\nstability condition is derived. Combining the model-based condition with a\nrecent data-based system representation, a data-driven stability criterion in\nthe form of linear matrix inequalities (LMIs) is established, which offers a\nway of co-designing the ETS matrix and the controller. To further alleviate the\nsampling burden of ETS due to its continuous/periodic detection, a\nself-triggering scheme (STS) is developed. Leveraging pre-collected input-state\ndata, an algorithm for predicting the next transmission instant is given, while\nachieving system stability. A co-design method of the ETS matrix and the\ncontroller under the proposed data-driven STS is given. Finally, numerical\nsimulations showcase the efficacy of ETS and STS in reducing data transmissions\nas well as of the proposed co-design methods.",
    "descriptor": "\nComments: 16 pages, 8 figres\n",
    "authors": [
      "Xin Wang",
      "Julian Berberich",
      "Jian Sun",
      "Gang Wang",
      "Frank Allg\u00f6wer",
      "Jie Chen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.08019"
  },
  {
    "id": "arXiv:2202.08023",
    "title": "Learning to Detect People on the Fly: A Bio-inspired Event-based Visual  System for Drones",
    "abstract": "We demonstrate for the first time that a biologicallyplausible spiking neural\nnetwork (SNN) equipped with Spike- Timing-Dependent Plasticity (STDP) learning\ncan continuously learn to detect walking people on the fly using\nretina-inspired, event-based camera data. Our pipeline works as follows. First,\na short sequence of event data (< 2 minutes), capturing a walking human from a\nflying drone, is shown to a convolutional SNNSTDP system which also receives\nteacher spiking signals from a convolutional readout (forming a semi-supervised\nsystem). Then, STDP adaptation is stopped and the learned system is assessed on\ntesting sequences. We conduct several experiments to study the effect of key\nmechanisms in our system and we compare our precision-recall performance to\nconventionally-trained CNNs working with either RGB or event-based camera\nframes.",
    "descriptor": "",
    "authors": [
      "Ali Safa",
      "Ilja Ocket",
      "Andr\u00e9 Bourdoux",
      "Hichem Sahli",
      "Francky Catthoor",
      "Georges Gielen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.08023"
  },
  {
    "id": "arXiv:2202.08025",
    "title": "Diagnosing Batch Normalization in Class Incremental Learning",
    "abstract": "Extensive researches have applied deep neural networks (DNNs) in class\nincremental learning (Class-IL). As building blocks of DNNs, batch\nnormalization (BN) standardizes intermediate feature maps and has been widely\nvalidated to improve training stability and convergence. However, we claim that\nthe direct use of standard BN in Class-IL models is harmful to both the\nrepresentation learning and the classifier training, thus exacerbating\ncatastrophic forgetting. In this paper we investigate the influence of BN on\nClass-IL models by illustrating such BN dilemma. We further propose BN Tricks\nto address the issue by training a better feature extractor while eliminating\nclassification bias. Without inviting extra hyperparameters, we apply BN Tricks\nto three baseline rehearsal-based methods, ER, DER++ and iCaRL. Through\ncomprehensive experiments conducted on benchmark datasets of Seq-CIFAR-10,\nSeq-CIFAR-100 and Seq-Tiny-ImageNet, we show that BN Tricks can bring\nsignificant performance gains to all adopted baselines, revealing its potential\ngenerality along this line of research.",
    "descriptor": "",
    "authors": [
      "Minghao Zhou",
      "Quanziang Wang",
      "Jun Shu",
      "Qian Zhao",
      "Deyu Meng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08025"
  },
  {
    "id": "arXiv:2202.08026",
    "title": "Frequency Response from Aggregated V2G Chargers With Uncertain EV  Connections",
    "abstract": "Fast frequency response (FR) is highly effective at securing frequency\ndynamics after a generator outage in low inertia systems. Electric vehicles\n(EVs) equipped with vehicle to grid (V2G) chargers could offer an abundant\nsource of FR in future. However, the uncertainty associated with V2G\naggregation, driven by the uncertain number of connected EVs at the time of an\noutage, has not been fully understood and prevents its participation in the\nexisting service provision framework. To tackle this limitation, this paper,\nfor the first time, incorporates such uncertainty into system frequency\ndynamics, from which probabilistic nadir and steady state frequency\nrequirements are enforced via a derived momeent-based distributionally-robust\nchance constraint. Field data from over 25,000 chargers is analysed to provide\nrealistic parameters and connection forecasts to examine the value of FR from\nV2G chargers in annual operation of the the GB 2030 system. The case study\ndemonstrates that uncertainty of EV connections can be effectively managed\nthrough the proposed scheduling framework, which results in annual savings of\n{\\pounds}6,300 or 37.4 tCO2 per charger. The sensitivity of this value to\nrenewable capacity and FR delays is explored, with V2G capacity shown to be a\nthird as valuable as the same grid battery capacity.",
    "descriptor": "",
    "authors": [
      "Cormac O'Malley",
      "Luis Badesa",
      "Fei Teng",
      "Goran Strbac"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.08026"
  },
  {
    "id": "arXiv:2202.08029",
    "title": "Code Search based on Context-aware Code Translation",
    "abstract": "Code search is a widely used technique by developers during software\ndevelopment. It provides semantically similar implementations from a large code\ncorpus to developers based on their queries. Existing techniques leverage deep\nlearning models to construct embedding representations for code snippets and\nqueries, respectively. Features such as abstract syntactic trees, control flow\ngraphs, etc., are commonly employed for representing the semantics of code\nsnippets. However, the same structure of these features does not necessarily\ndenote the same semantics of code snippets, and vice versa. In addition, these\ntechniques utilize multiple different word mapping functions that map query\nwords/code tokens to embedding representations. This causes diverged embeddings\nof the same word/token in queries and code snippets. We propose a novel\ncontext-aware code translation technique that translates code snippets into\nnatural language descriptions (called translations). The code translation is\nconducted on machine instructions, where the context information is collected\nby simulating the execution of instructions. We further design a shared word\nmapping function using one single vocabulary for generating embeddings for both\ntranslations and queries. We evaluate the effectiveness of our technique,\ncalled TranCS, on the CodeSearchNet corpus with 1,000 queries. Experimental\nresults show that TranCS significantly outperforms state-of-the-art techniques\nby 49.31% to 66.50% in terms of MRR (mean reciprocal rank).",
    "descriptor": "\nComments: to be published in the 44th IEEE/ACM International Conference on Software Engineering (ICSE 2022) (ICSE'22)\n",
    "authors": [
      "Weisong Sun",
      "Chunrong Fang",
      "Yuchen Chen",
      "Guanhong Tao",
      "Tingxu Han",
      "Quanjun Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08029"
  },
  {
    "id": "arXiv:2202.08033",
    "title": "Language Inclusion for Boundedly-Ambiguous Vector Addition Systems is  Decidable",
    "abstract": "We consider the problems of language inclusion and language equivalence for\nVector Addition Systems with States (VASSes) with the acceptance condition\ndefined by the set of accepting states (and more generally by some\nupward-closed conditions). In general the problem of language equivalence is\nundecidable even for one-dimensional VASSes, thus to get decidability we\ninvestigate restricted subclasses. On one hand we show that the problem of\nlanguage inclusion of a VASS in k-ambiguous VASS (for any natural k) is\ndecidable and even in Ackermann. On the other hand we prove that the language\nequivalence problem is Ackermann-hard already for deterministic VASSes. These\ntwo results imply Ackermann-completeness for language inclusion and equivalence\nin several possible restrictions. Some of our techniques can be also applied in\nmuch broader generality in infinite-state systems, namely for some subclass of\nwell-structured transition systems.",
    "descriptor": "",
    "authors": [
      "Wojciech Czerwi\u0144ski",
      "Piotr Hofman"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.08033"
  },
  {
    "id": "arXiv:2202.08036",
    "title": "No One Left Behind: Inclusive Federated Learning over Heterogeneous  Devices",
    "abstract": "Federated learning (FL) is an important paradigm for training global models\nfrom decentralized data in a privacy-preserving way. Existing FL methods\nusually assume the global model can be trained on any participating client.\nHowever, in real applications, the devices of clients are usually\nheterogeneous, and have different computing power. Although big models like\nBERT have achieved huge success in AI, it is difficult to apply them to\nheterogeneous FL with weak clients. The straightforward solutions like removing\nthe weak clients or using a small model to fit all clients will lead to some\nproblems, such as under-representation of dropped clients and inferior accuracy\ndue to data loss or limited model representation ability. In this work, we\npropose InclusiveFL, a client-inclusive federated learning method to handle\nthis problem. The core idea of InclusiveFL is to assign models of different\nsizes to clients with different computing capabilities, bigger models for\npowerful clients and smaller ones for weak clients. We also propose an\neffective method to share the knowledge among multiple local models with\ndifferent sizes. In this way, all the clients can participate in the model\nlearning in FL, and the final model can be big and powerful enough. Besides, we\npropose a momentum knowledge distillation method to better transfer knowledge\nin big models on powerful clients to the small models on weak clients.\nExtensive experiments on many real-world benchmark datasets demonstrate the\neffectiveness of the proposed method in learning accurate models from clients\nwith heterogeneous devices under the FL framework.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Ruixuan Liu",
      "Fangzhao Wu",
      "Chuhan Wu",
      "Yanlin Wang",
      "Lingjuan Lyu",
      "Hong Chen",
      "Xing Xie"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.08036"
  },
  {
    "id": "arXiv:2202.08037",
    "title": "A Review of Topological Data Analysis for Cybersecurity",
    "abstract": "In cybersecurity it is often the case that malicious or anomalous activity\ncan only be detected by combining many weak indicators of compromise, any one\nof which may not raise suspicion when taken alone. The path that such\nindicators take can also be critical. This makes the problem of analysing\ncybersecurity data particularly well suited to Topological Data Analysis (TDA),\na field that studies the high level structure of data using techniques from\nalgebraic topology, both for exploratory analysis and as part of a machine\nlearning workflow. By introducing TDA and reviewing the work done on its\napplication to cybersecurity, we hope to highlight to researchers a promising\nnew area with strong potential to improve cybersecurity data science.",
    "descriptor": "\nComments: v1\n",
    "authors": [
      "Thomas Davies"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08037"
  },
  {
    "id": "arXiv:2202.08041",
    "title": "Explainability of Predictive Process Monitoring Results: Can You See My  Data Issues?",
    "abstract": "Predictive business process monitoring (PPM) has been around for several\nyears as a use case of process mining. PPM enables foreseeing the future of a\nbusiness process through predicting relevant information about how a running\nprocess instance might end, related performance indicators, and other\npredictable aspects. A big share of PPM approaches adopts a Machine Learning\n(ML) technique to address a prediction task, especially non-process-aware PPM\napproaches. Consequently, PPM inherits the challenges faced by ML approaches.\nOne of these challenges concerns the need to gain user trust in the predictions\ngenerated. The field of explainable artificial intelligence (XAI) addresses\nthis issue. However, the choices made, and the techniques employed in a PPM\ntask, in addition to ML model characteristics, influence resulting\nexplanations. A comparison of the influence of different settings on the\ngenerated explanations is missing. To address this gap, we investigate the\neffect of different PPM settings on resulting data fed into an ML model and\nconsequently to a XAI method. We study how differences in resulting\nexplanations may indicate several issues in underlying data. We construct a\nframework for our experiments including different settings at each stage of PPM\nwith XAI integrated as a fundamental part. Our experiments reveal several\ninconsistencies, as well as agreements, between data characteristics (and hence\nexpectations about these data), important data used by the ML model as a result\nof querying it, and explanations of predictions of the investigated ML model.",
    "descriptor": "\nComments: 32 pages, 10 figures, 1 table\n",
    "authors": [
      "Ghada Elkhawaga",
      "Mervat Abuelkheir",
      "Manfred Reichert"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08041"
  },
  {
    "id": "arXiv:2202.08045",
    "title": "Learning to Generalize across Domains on Single Test Samples",
    "abstract": "We strive to learn a model from a set of source domains that generalizes well\nto unseen target domains. The main challenge in such a domain generalization\nscenario is the unavailability of any target domain data during training,\nresulting in the learned model not being explicitly adapted to the unseen\ntarget domains. We propose learning to generalize across domains on single test\nsamples. We leverage a meta-learning paradigm to learn our model to acquire the\nability of adaptation with single samples at training time so as to further\nadapt itself to each single test sample at test time. We formulate the\nadaptation to the single test sample as a variational Bayesian inference\nproblem, which incorporates the test sample as a conditional into the\ngeneration of model parameters. The adaptation to each test sample requires\nonly one feed-forward computation at test time without any fine-tuning or\nself-supervised training on additional data from the unseen domains. Extensive\nablation studies demonstrate that our model learns the ability to adapt models\nto each single sample by mimicking domain shifts during training. Further, our\nmodel achieves at least comparable -- and often better -- performance than\nstate-of-the-art methods on multiple benchmarks for domain generalization.",
    "descriptor": "",
    "authors": [
      "Zehao Xiao",
      "Xiantong Zhen",
      "Ling Shao",
      "Cees G. M. Snoek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08045"
  },
  {
    "id": "arXiv:2202.08046",
    "title": "Simulation-based Verification of SystemC-based VPs at the ESL",
    "abstract": "SystemC-based Virtual Prototypes (VPs) at the Electronic System Level (ESL)\nare increasingly adopted by the semiconductor industry. The main reason is that\nVPs are much earlier available, and their simulation is orders of magnitude\nfaster in comparison to the hardware models at lower levels of abstraction\n(e.g. RTL). This leads designers to use VPs as reference models for early\ndesign verification. Hence, the correctness of VPs is of utmost importance as\nundetected errors may propagate to less abstract levels in the design process,\nincreasing the fixing cost and effort. In this paper, we introduce a\ncomprehensive simulation-based verification approach to automatically validate\nthe simulation behavior of a given SystemC-based VP against both the TLM-2.0\nrules and its specifications, i.e. functional and timing behavior of\ncommunications in the VP.",
    "descriptor": "",
    "authors": [
      "Mehran Goli",
      "Rolf Drechsler"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2202.08046"
  },
  {
    "id": "arXiv:2202.08048",
    "title": "Decorrelate Irrelevant, Purify Relevant: Overcome Textual Spurious  Correlations from a Feature Perspective",
    "abstract": "Natural language understanding (NLU) models tend to rely on spurious\ncorrelations (\\emph{i.e.}, dataset bias) to achieve high performance on\nin-distribution datasets but poor performance on out-of-distribution ones. Most\nof the existing debiasing methods often identify and weaken these samples with\nbiased features (\\emph{i.e.}, superficial surface features that cause such\nspurious correlations). However, down-weighting these samples obstructs the\nmodel in learning from the non-biased parts of these samples. To tackle this\nchallenge, in this paper, we propose to eliminate spurious correlations in a\nfine-grained manner from a feature space perspective. Specifically, we\nintroduce Random Fourier Features and weighted re-sampling to decorrelate the\ndependencies between features to mitigate spurious correlations. After\nobtaining decorrelated features, we further design a mutual-information-based\nmethod to purify them, which forces the model to learn features that are more\nrelevant to tasks. Extensive experiments on two well-studied NLU tasks\nincluding Natural Language Inference and Fact Verification demonstrate that our\nmethod is superior to other comparative approaches.",
    "descriptor": "",
    "authors": [
      "Shihan Dou",
      "Rui Zheng",
      "Ting Wu",
      "Songyang Gao",
      "Qi Zhang",
      "Yueming Wu",
      "Xuanjing Huang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.08048"
  },
  {
    "id": "arXiv:2202.08055",
    "title": "HDC-MiniROCKET: Explicit Time Encoding in Time Series Classification  with Hyperdimensional Computing",
    "abstract": "Classification of time series data is an important task for many application\ndomains. One of the best existing methods for this task, in terms of accuracy\nand computation time, is MiniROCKET. In this work, we extend this approach to\nprovide better global temporal encodings using hyperdimensional computing (HDC)\nmechanisms. HDC (also known as Vector Symbolic Architectures, VSA) is a general\nmethod to explicitly represent and process information in high-dimensional\nvectors. It has previously been used successfully in combination with deep\nneural networks and other signal processing algorithms. We argue that the\ninternal high-dimensional representation of MiniROCKET is well suited to be\ncomplemented by the algebra of HDC. This leads to a more general formulation,\nHDC-MiniROCKET, where the original algorithm is only a special case. We will\ndiscuss and demonstrate that HDC-MiniROCKET can systematically overcome\ncatastrophic failures of MiniROCKET on simple synthetic datasets. These results\nare confirmed by experiments on the 128 datasets from the UCR time series\nclassification benchmark. The extension with HDC can achieve considerably\nbetter results on datasets with high temporal dependence without increasing the\ncomputational effort for inference.",
    "descriptor": "",
    "authors": [
      "Kenny Schlegel",
      "Peer Neubert",
      "Peter Protzel"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08055"
  },
  {
    "id": "arXiv:2202.08057",
    "title": "Understanding and Improving Graph Injection Attack by Promoting  Unnoticeability",
    "abstract": "Recently Graph Injection Attack (GIA) emerges as a practical attack scenario\non Graph Neural Networks (GNNs), where the adversary can merely inject few\nmalicious nodes instead of modifying existing nodes or edges, i.e., Graph\nModification Attack (GMA). Although GIA has achieved promising results, little\nis known about why it is successful and whether there is any pitfall behind the\nsuccess. To understand the power of GIA, we compare it with GMA and find that\nGIA can be provably more harmful than GMA due to its relatively high\nflexibility. However, the high flexibility will also lead to great damage to\nthe homophily distribution of the original graph, i.e., similarity among\nneighbors. Consequently, the threats of GIA can be easily alleviated or even\nprevented by homophily-based defenses designed to recover the original\nhomophily. To mitigate the issue, we introduce a novel constraint -- homophily\nunnoticeability that enforces GIA to preserve the homophily, and propose\nHarmonious Adversarial Objective (HAO) to instantiate it. Extensive experiments\nverify that GIA with HAO can break homophily-based defenses and outperform\nprevious GIA attacks by a significant margin. We believe our methods can serve\nfor a more reliable evaluation of the robustness of GNNs.",
    "descriptor": "\nComments: ICLR2022\n",
    "authors": [
      "Yongqiang Chen",
      "Han Yang",
      "Yonggang Zhang",
      "Kaili Ma",
      "Tongliang Liu",
      "Bo Han",
      "James Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.08057"
  },
  {
    "id": "arXiv:2202.08063",
    "title": "Knowledge Extraction in Low-Resource Scenarios: Survey and Perspective",
    "abstract": "Knowledge Extraction (KE) which aims to extract structural information from\nunstructured texts often suffers from data scarcity and emerging unseen types,\ni.e., low-resource scenarios. Many neural approaches on low-resource KE have\nbeen widely investigated and achieved impressive performance. In this paper, we\npresent a literature review towards KE in low-resource scenarios, and\nsystematically categorize existing works into three paradigms: (1) exploiting\nhigher-resource data, (2) exploiting stronger models, and (3) exploiting data\nand models together. In addition, we describe promising applications and\noutline some potential directions for future research. We hope that our survey\ncan help both the academic and industrial community to better understand this\nfield, inspire more ideas and boost broader applications.",
    "descriptor": "\nComments: Work in Progress\n",
    "authors": [
      "Shumin Deng",
      "Ningyu Zhang",
      "Hui Chen",
      "Feiyu Xiong",
      "Jeff Z. Pan",
      "Huajun Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.08063"
  },
  {
    "id": "arXiv:2202.08065",
    "title": "Graph Neural Network and Koopman Models for Learning Networked Dynamics:  A Comparative Study on Power Grid Transients Prediction",
    "abstract": "Continuous monitoring of the spatio-temporal dynamic behavior of critical\ninfrastructure networks, such as the power systems, is a challenging but\nimportant task. In particular, accurate and timely prediction of the\n(electro-mechanical) transient dynamic trajectories of the power grid is\nnecessary for early detection of any instability and prevention of catastrophic\nfailures. Existing approaches for the prediction of dynamic trajectories either\nrely on the availability of accurate physical models of the system, use\ncomputationally expensive time-domain simulations, or are applicable only at\nlocal prediction problems (e.g., a single generator). In this paper, we report\nthe application of two broad classes of data-driven learning models -- along\nwith their algorithmic implementation and performance evaluation -- in\npredicting transient trajectories in power networks using only streaming\nmeasurements and the network topology as input. One class of models is based on\nthe Koopman operator theory which allows for capturing the nonlinear dynamic\nbehavior via an infinite-dimensional linear operator. The other class of models\nis based on the graph convolutional neural networks which are adept at\ncapturing the inherent spatio-temporal correlations within the power network.\nTransient dynamic datasets for training and testing the models are synthesized\nby simulating a wide variety of load change events in the IEEE 68-bus system,\ncategorized by the load change magnitudes, as well as by the degree of\nconnectivity and the distance to nearest generator nodes. The results confirm\nthat the proposed predictive models can successfully predict the\npost-disturbance transient evolution of the system with a high level of\naccuracy.",
    "descriptor": "\nComments: 17 pages, this paper is currently under review in a journal\n",
    "authors": [
      "Sai Pushpak Nandanoori",
      "Sheng Guan",
      "Soumya Kundu",
      "Seemita Pal",
      "Khushbu Agarwal",
      "Yinghui Wu",
      "Sutanay Choudhury"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.08065"
  },
  {
    "id": "arXiv:2202.08066",
    "title": "Almost-Optimal Sublinear-Time Edit Distance in the Low Distance Regime",
    "abstract": "We revisit the task of computing the edit distance in sublinear time. In the\n$(k,K)$-gap edit distance problem the task is to distinguish whether the edit\ndistance of two strings is at most $k$ or at least $K$. It has been established\nby Goldenberg, Krauthgamer and Saha (FOCS '19), with improvements by Kociumaka\nand Saha (FOCS '20), that the $(k,k^2)$-gap problem can be solved in time\n$\\widetilde O(n/k+\\operatorname{poly}(k))$. One of the most natural questions\nin this line of research is whether the $(k,k^2)$-gap is best-possible for the\nrunning time $\\widetilde O(n/k+\\operatorname{poly}(k))$.\nIn this work we answer this question by significantly improving the gap.\nSpecifically, we show that in time $O(n/k+\\operatorname{poly}(k))$ we can even\nsolve the $(k,k^{1+o(1)})$-gap problem. This is the first algorithm that breaks\nthe $(k,k^2)$-gap in this running time. Our algorithm is almost optimal in the\nfollowing sense: In the low distance regime ($k\\le n^{0.19}$) our running time\nbecomes $O(n/k)$, which matches a known $n/k^{1+o(1)}$ lower bound for the\n$(k,k^{1+o(1)})$-gap problem up to lower order factors.\nOur result also reveals a surprising similarity of Hamming distance and edit\ndistance in the low distance regime: For both, the $(k,k^{1+o(1)})$-gap problem\nhas time complexity $n/k^{1\\pm o(1)}$ for small $k$.\nIn contrast to previous work, which employed a subsampled variant of the\nLandau-Vishkin algorithm, we instead build upon the algorithm of Andoni,\nKrauthgamer and Onak (FOCS '10). We first simplify their approach and then show\nhow to to effectively prune their computation tree in order to obtain a\nsublinear-time algorithm in the given time bound. Towards that, we use a\nvariety of structural insights on the (local and global) patterns that can\nemerge during this process and design appropriate property testers to\neffectively detect these patterns.",
    "descriptor": "\nComments: To appear at STOC'22. Abstract shortened to fit arXiv requirements\n",
    "authors": [
      "Karl Bringmann",
      "Alejandro Cassis",
      "Nick Fischer",
      "Vasileios Nakos"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.08066"
  },
  {
    "id": "arXiv:2202.08068",
    "title": "A Polyhedral Study of Lifted Multicuts",
    "abstract": "Fundamental to many applications in data analysis are the decompositions of a\ngraph, i.e. partitions of the node set into component-inducing subsets. One way\nof encoding decompositions is by multicuts, the subsets of those edges that\nstraddle distinct components. Recently, a lifting of multicuts from a graph $G\n= (V, E)$ to an augmented graph $\\hat G = (V, E \\cup F)$ has been proposed in\nthe field of image analysis, with the goal of obtaining a more expressive\ncharacterization of graph decompositions in which it is made explicit also for\npairs $F \\subseteq \\tbinom{V}{2} \\setminus E$ of non-neighboring nodes whether\nthese are in the same or distinct components. In this work, we study in detail\nthe polytope in $\\mathbb{R}^{E \\cup F}$ whose vertices are precisely the\ncharacteristic vectors of multicuts of $\\hat G$ lifted from $G$, connecting it,\nin particular, to the rich body of prior work on the clique partitioning and\nmultilinear polytope.",
    "descriptor": "\nComments: 63 pages, 18 figures\n",
    "authors": [
      "Bjoern Andres",
      "Silvia Di Gregorio",
      "Jannik Irmai",
      "Jan-Hendrik Lange"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.08068"
  },
  {
    "id": "arXiv:2202.08069",
    "title": "VLDB 2021: Designing a Hybrid Conference",
    "abstract": "In 2020, while main database conferences one by one had to adopt a virtual\nformat as a result of the ongoing COVID-19 pandemic, we decided to hold VLDB\n2021 in hybrid format. This paper describes how we defined the hybrid format\nfor VLDB 2021 going through the key design decisions. In addition, we list the\nlessons learned from running such a conference. Our goal is to share this\nknowledge with fellow conference organizers who target a hybrid conference\nformat as well, which is on its way to becoming the norm rather than the\nexception. For readers who are more interested in the highlights rather than\ndetails, a short version of this report appears in SIGMOD Record.",
    "descriptor": "",
    "authors": [
      "P\u0131nar T\u00f6z\u00fcn",
      "Felix Naumann",
      "Philippe Bonnet",
      "Xin Luna Dong"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.08069"
  },
  {
    "id": "arXiv:2202.08070",
    "title": "On Measuring Excess Capacity in Neural Networks",
    "abstract": "We study the excess capacity of deep networks in the context of supervised\nclassification. That is, given a capacity measure of the underlying hypothesis\nclass -- in our case, Rademacher complexity -- how much can we (a-priori)\nconstrain this class while maintaining an empirical error comparable to the\nunconstrained setting. To assess excess capacity in modern architectures, we\nfirst extend an existing generalization bound to accommodate function\ncomposition and addition, as well as the specific structure of convolutions.\nThis then facilitates studying residual networks through the lens of the\naccompanying capacity measure. The key quantities driving this measure are the\nLipschitz constants of the layers and the (2,1) group norm distance to the\ninitializations of the convolution weights. We show that these quantities (1)\ncan be kept surprisingly small and, (2) since excess capacity unexpectedly\nincreases with task difficulty, this points towards an unnecessarily large\ncapacity of unconstrained models.",
    "descriptor": "",
    "authors": [
      "Florian Graf",
      "Sebastian Zeng",
      "Marc Niethammer",
      "Roland Kwitt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.08070"
  },
  {
    "id": "arXiv:2202.08079",
    "title": "Modeling Strong Physically Unclonable Functions with Metaheuristics",
    "abstract": "Evolutionary algorithms have been successfully applied to attacking\nPhysically Unclonable Functions (PUFs). CMA-ES is recognized as the most\npowerful option for a type of attack called the reliability attack. While there\nis no reason to doubt the performance of CMA-ES, the lack of comparison with\ndifferent metaheuristics and results for the challenge-response pair-based\nattack leaves open questions if there are better-suited metaheuristics for the\nproblem.\nIn this paper, we take a step back and systematically evaluate several\nmetaheuristics for the challenge-response pair-based attack on strong PUFs. Our\nresults confirm that CMA-ES has the best performance, but we also note several\nother algorithms with similar performance while having smaller computational\ncosts. More precisely, if we provide a sufficient number of challenge-response\npairs to train the algorithm, various configurations show good results.\nConsequently, we conclude that EAs represent a strong option for\nchallenge-response pair-based attacks on PUFs.",
    "descriptor": "\nComments: 18 pages, 5 figures, 4 tables\n",
    "authors": [
      "Carlos Coello Coello",
      "Marko Djurasevic",
      "Domagoj Jakobovic",
      "Luca Mariot",
      "Stjepan Picek"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.08079"
  },
  {
    "id": "arXiv:2202.08080",
    "title": "NeVerMore: Exploiting RDMA Mistakes in NVMe-oF Storage Applications",
    "abstract": "This paper presents a security analysis of the InfiniBand architecture, a\nprevalent RDMA standard, and NVMe-over-Fabrics (NVMe-oF), a prominent protocol\nfor industrial disaggregated storage that exploits RDMA protocols to achieve\nlow-latency and high-bandwidth access to remote solid-state devices. Our work,\nNeVerMore, discovers new vulnerabilities in RDMA protocols that unveils several\nattack vectors on RDMA-enabled applications and the NVMe-oF protocol, showing\nthat the current security mechanisms of the NVMe-oF protocol do not address the\nsecurity vulnerabilities posed by the use of RDMA. In particular, we show how\nan unprivileged user can inject packets into any RDMA connection created on a\nlocal network controller, bypassing security mechanisms of the operating system\nand its kernel, and how the injection can be used to acquire unauthorized block\naccess to NVMe-oF devices. Overall, we implement four attacks on RDMA protocols\nand seven attacks on the NVMe-oF protocol and verify them on the two most\npopular implementations of NVMe-oF: SPDK and the Linux kernel. To mitigate the\ndiscovered attacks we propose multiple mechanisms that can be implemented by\nRDMA and NVMe-oF providers.",
    "descriptor": "",
    "authors": [
      "Konstantin Taranov",
      "Benjamin Rothenberger",
      "Daniele De Sensi",
      "Adrian Perrig",
      "Torsten Hoefler"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.08080"
  },
  {
    "id": "arXiv:2202.08081",
    "title": "Reasoning with fuzzy and uncertain evidence using epistemic random fuzzy  sets: general framework and practical models",
    "abstract": "We introduce a general theory of epistemic random fuzzy sets for reasoning\nwith fuzzy or crisp evidence. This framework generalizes both the\nDempster-Shafer theory of belief functions, and possibility theory. Independent\nepistemic random fuzzy sets are combined by the generalized\nproduct-intersection rule, which extends both Dempster's rule for combining\nbelief functions, and the product conjunctive combination of possibility\ndistributions. We introduce Gaussian random fuzzy numbers and their\nmulti-dimensional extensions, Gaussian random fuzzy vectors, as practical\nmodels for quantifying uncertainty about scalar or vector quantities.\nClosed-form expressions for the combination, projection and vacuous extension\nof Gaussian random fuzzy numbers and vectors are derived.",
    "descriptor": "",
    "authors": [
      "Thierry Denoeux"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.08081"
  },
  {
    "id": "arXiv:2202.08087",
    "title": "Extended Unconstrained Features Model for Exploring Deep Neural Collapse",
    "abstract": "The modern strategy for training deep neural networks for classification\ntasks includes optimizing the network's weights even after the training error\nvanishes to further push the training loss toward zero. Recently, a phenomenon\ntermed \"neural collapse\" (NC) has been empirically observed in this training\nprocedure. Specifically, it has been shown that the learned features (the\noutput of the penultimate layer) of within-class samples converge to their\nmean, and the means of different classes exhibit a certain tight frame\nstructure, which is also aligned with the last layer's weights. Recent papers\nhave shown that minimizers with this structure emerge when optimizing a\nsimplified \"unconstrained features model\" (UFM) with a regularized\ncross-entropy loss. In this paper, we further analyze and extend the UFM.\nFirst, we study the UFM for the regularized MSE loss, and show that the\nminimizers' features can be more structured than in the cross-entropy case.\nThis affects also the structure of the weights. Then, we extend the UFM by\nadding another layer of weights as well as ReLU nonlinearity to the model and\ngeneralize our previous results. Finally, we empirically demonstrate the\nusefulness of our nonlinear extended UFM in modeling the NC phenomenon that\noccurs with practical networks.",
    "descriptor": "",
    "authors": [
      "Tom Tirer",
      "Joan Bruna"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08087"
  },
  {
    "id": "arXiv:2202.08088",
    "title": "Latent Outlier Exposure for Anomaly Detection with Contaminated Data",
    "abstract": "Anomaly detection aims at identifying data points that show systematic\ndeviations from the majority of data in an unlabeled dataset. A common\nassumption is that clean training data (free of anomalies) is available, which\nis often violated in practice. We propose a strategy for training an anomaly\ndetector in the presence of unlabeled anomalies that is compatible with a broad\nclass of models. The idea is to jointly infer binary labels to each datum\n(normal vs. anomalous) while updating the model parameters. Inspired by outlier\nexposure (Hendrycks et al., 2018) that considers synthetically created, labeled\nanomalies, we thereby use a combination of two losses that share parameters:\none for the normal and one for the anomalous data. We then iteratively proceed\nwith block coordinate updates on the parameters and the most likely (latent)\nlabels. Our experiments with several backbone models on three image datasets,\n30 tabular data sets, and a video anomaly detection benchmark showed consistent\nand significant improvements over the baselines.",
    "descriptor": "",
    "authors": [
      "Chen Qiu",
      "Aodong Li",
      "Marius Kloft",
      "Maja Rudolph",
      "Stephan Mandt"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08088"
  },
  {
    "id": "arXiv:2202.08095",
    "title": "Refined RBF-FD analysis of non-Newtonian natural convection",
    "abstract": "In this paper we present a refined RBF-FD solution for a non-Newtonian fluid\nin a closed differentially heated cavity. The problem at hand is governed by\nthree coupled nonlinear partial differential equations, namely heat transport,\nmomentum transport and mass continuity. The non-Newtonian behaviour is modelled\nwith the Ostwald-de Weele power law and the buoyancy with the Boussinesq\napproximation. The problem domain is discretised with scattered nodes without\nany requirement for a topological relation between them. This allows a trivial\ngeneralisation of the solution procedure to complex irregular 3D domains, which\nis also demonstrated by solving the problem in a 2D and 3D geometry mimicking\nthe porous filter. The results in 2D are compared with two reference solutions\nthat use the Finite volume method in a conjunction with two different\nstabilisation techniques (upwind and QUICK), where we achieved good agreement\nwith the reference data. The refinement is implemented on top of a dedicated\nmeshless node positioning algorithm using piecewise linear node density\nfunction that ensures sufficient node density in the centre of the domain while\nmaximising the node density in a boundary layer where the most intense dynamic\nis expected. The results show that with a refined approach, up to 5 times fewer\nnodes are needed to obtain the results with the same accuracy compared to the\nregular discretisation. The paper also discusses the convergence for different\nscenarios for up to $2 \\cdot 10^5$ nodes, the behaviour of the flow in the\nboundary layer, the behaviour of the viscosity and the geometric flexibility of\nthe proposed solution procedure.",
    "descriptor": "",
    "authors": [
      "Miha Rot",
      "Gregor Kosec"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Physics (physics.comp-ph)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2202.08095"
  },
  {
    "id": "arXiv:2202.08096",
    "title": "Massive Unsourced Random Access: Exploiting Angular Domain Sparsity",
    "abstract": "This paper investigates the unsourced random access (URA) scheme to\naccommodate numerous machine-type users communicating to a base station\nequipped with multiple antennas. Existing works adopt a slotted transmission\nstrategy to reduce system complexity; they operate under the framework of\ncoupled compressed sensing (CCS) which concatenates an outer tree code to an\ninner compressed sensing code for slot-wise message stitching. We suggest that\nby exploiting the MIMO channel information in the angular domain, redundancies\nrequired by the tree encoder/decoder in CCS can be removed to improve spectral\nefficiency, thereby an uncoupled transmission protocol is devised. To perform\nactivity detection and channel estimation, we propose an\nexpectation-maximization-aided generalized approximate message passing\nalgorithm with a Markov random field support structure, which captures the\ninherent clustered sparsity structure of the angular domain channel. Then,\nmessage reconstruction in the form of a clustering decoder is performed by\nrecognizing slot-distributed channels of each active user based on similarity.\nWe put forward the slot-balanced K-means algorithm as the kernel of the\nclustering decoder, resolving constraints and collisions specific to the\napplication scene. Extensive simulations reveal that the proposed scheme\nachieves a better error performance at high spectral efficiency compared to the\nCCS-based URA schemes.",
    "descriptor": "\nComments: Accepted for publication in IEEE TCOM\n",
    "authors": [
      "Xinyu Xie",
      "Yongpeng Wu",
      "Jianping An",
      "Junyuan Gao",
      "Wenjun Zhang",
      "Chengwen Xing",
      "Kai-Kit Wong",
      "Chengshan Xiao"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.08096"
  },
  {
    "id": "arXiv:2202.08097",
    "title": "Optimizing over Serial Dictatorships",
    "abstract": "Motivated by the success of the {\\em serial dictatorship} mechanism in social\nchoice settings, we explore its usefulness in tackling various combinatorial\noptimization problems. We do so by considering an abstract model, in which a\nset of agents are asked to {\\em act} in a particular ordering, called the {\\em\naction sequence}. Each agent acts in a way that gives her the maximum possible\nvalue, given the actions of the agents who preceded her in the action sequence.\nOur goal is to compute action sequences that yield approximately optimal total\nvalue to the agents (a.k.a., {\\em social welfare}). We assume {\\em query\naccess} to the value $v_i(S)$ that the agent i gets when she acts after the\nagents in the ordered set $S$.\nWe establish tight bounds on the social welfare that can be achieved using\npolynomially many queries. Even though these bounds show a marginally sublinear\napproximation of optimal social welfare in general, excellent approximations\ncan be obtained when the valuations stem from an underlying combinatorial\ndomain. Indicatively, when the valuations are defined using bipartite\nmatchings, arborescences in directed graphs, and satisfiability of Boolean\nexpressions, simple query-efficient algorithms yield $2$-approximations. We\ndiscuss issues related to truthfulness and show how some of our algorithms can\nbe implemented truthfully using VCG-like payments. Finally, we introduce and\nstudy the {\\em price of serial dictatorship}, a notion that provides an\noptimistic measure of the quality of combinatorial optimization solutions\ngenerated by action sequences.",
    "descriptor": "",
    "authors": [
      "Ioannis Caragiannis",
      "Nidhi Rathi"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.08097"
  },
  {
    "id": "arXiv:2202.08098",
    "title": "Learning to Adapt to Light",
    "abstract": "Light adaptation or brightness correction is a key step in improving the\ncontrast and visual appeal of an image. There are multiple light-related tasks\n(for example, low-light enhancement and exposure correction) and previous\nstudies have mainly investigated these tasks individually. However, it is\ninteresting to consider whether these light-related tasks can be executed by a\nunified model, especially considering that our visual system adapts to external\nlight in such way. In this study, we propose a biologically inspired method to\nhandle light-related image-enhancement tasks with a unified network (called\nLA-Net). First, a frequency-based decomposition module is designed to decouple\nthe common and characteristic sub-problems of light-related tasks into two\npathways. Then, a new module is built inspired by biological visual adaptation\nto achieve unified light adaptation in the low-frequency pathway. In addition,\nnoise suppression or detail enhancement is achieved effectively in the\nhigh-frequency pathway regardless of the light levels. Extensive experiments on\nthree tasks -- low-light enhancement, exposure correction, and tone mapping --\ndemonstrate that the proposed method almost obtains state-of-the-art\nperformance compared with recent methods designed for these individual tasks.",
    "descriptor": "\nComments: 10 pages, 9 figures\n",
    "authors": [
      "Kai-Fu Yang",
      "Cheng Cheng",
      "Shi-Xuan Zhao",
      "Xian-Shi Zhang",
      "Yong-Jie Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08098"
  },
  {
    "id": "arXiv:2202.08099",
    "title": "Measuring Unintended Memorisation of Unique Private Features in Neural  Networks",
    "abstract": "Neural networks pose a privacy risk to training data due to their propensity\nto memorise and leak information. Focusing on image classification, we show\nthat neural networks also unintentionally memorise unique features even when\nthey occur only once in training data. An example of a unique feature is a\nperson's name that is accidentally present on a training image. Assuming access\nto the inputs and outputs of a trained model, the domain of the training data,\nand knowledge of unique features, we develop a score estimating the model's\nsensitivity to a unique feature by comparing the KL divergences of the model's\noutput distributions given modified out-of-distribution images. Our results\nsuggest that unique features are memorised by multi-layer perceptrons and\nconvolutional neural networks trained on benchmark datasets, such as MNIST,\nFashion-MNIST and CIFAR-10. We find that strategies to prevent overfitting\n(e.g.\\ early stopping, regularisation, batch normalisation) do not prevent\nmemorisation of unique features. These results imply that neural networks pose\na privacy risk to rarely occurring private information. These risks can be more\npronounced in healthcare applications if patient information is present in the\ntraining data.",
    "descriptor": "",
    "authors": [
      "John Hartley",
      "Sotirios A. Tsaftaris"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.08099"
  },
  {
    "id": "arXiv:2202.08100",
    "title": "Reversible data hiding with dual pixel-value-ordering and1minimum  prediction error expansion",
    "abstract": "Pixel Value Ordering (PVO) holds an impressive property for high fidelity\nReversible Data Hiding (RDH). In this paper, we introduce a dual-PVO (dPVO) for\nPrediction Error Expansion(PEE), and thereby develop a new RDH scheme to offer\na better rate-distortion performance. Particularly, we propose to embed in two\nphases: forward and backward. In the forward phase, PVO with classic PEE is\napplied to every non-overlapping image block of size 1x3. In the backward\nphase,minimum-set and maximum-set of pixels are determined from the pixels\npredicted in the forward phase. The minimum set only contains the lowest\npredicted pixels and the maximum set contains the largest predicted pixels of\neach image block. Proposed dPVO withPEE is then applied to both sets, so that\nthe pixel values of the minimum set are increased and that of the maximum set\nare decreased by a unit value. Thereby, the pixels predicted in the forward\nembedding can partially be restored to their original values resulting in both\nbetter-embedded image quality and a higher embedding rate. Experimental results\nhave recorded a promising rate-distortion performance of our scheme with a\nsignificant improvement of embedded image quality at higher embedding rates\ncompared to the popular and state-of-the-art PVO-based RDHschemes.",
    "descriptor": "\nComments: Submitted to Plos One [PONE-D-21-21353R1]\n",
    "authors": [
      "Md. Abdul Wahed",
      "Hussain Nyeem"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2202.08100"
  },
  {
    "id": "arXiv:2202.08102",
    "title": "A note on hospital financing: local financing vs. central financing",
    "abstract": "This note tries to study how hospital behaviors, with reference to\ninterhospital collaboration or competition, could be affected by hospital\nfinancing systems. For that this note simulates two scenarios which start with\nthe following baseline scenario: a State, with a set of hospitals, each with\nall types of wards at a basic level. The evolution of this baseline scenario\nconsists in the evolution of hospitals, that is, in the possibility of\nhospitals to make some of their wards excel. The State has a budget, for the\nevolution of this baseline scenario, which can be used by two financing\nsystems: either by a \"local financing\", i.e., by splitting the budget among the\nhospitals so that each hospital is managing its own portion of the budget by\npursuing the individual benefit, or by a \"central financing\", i.e., by not\nsplitting the budget among the hospitals so that the State is the sole manager\nof the budget, by pursuing the benefit of the whole community. The conclusions\nseem to be that: in the local financing system hospitals tend to diversify\ntheir excellences, while in the central financing system the State tends to\ncreate poles of excellence.",
    "descriptor": "",
    "authors": [
      "Raffaele Mosca"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Discrete Mathematics (cs.DM)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2202.08102"
  },
  {
    "id": "arXiv:2202.08103",
    "title": "Paraphrasing Magritte's Observation",
    "abstract": "Contrast Sensitivity of the human visual system can be explained from certain\nlow-level vision tasks (like retinal noise and optical blur removal), but not\nfrom others (like chromatic adaptation or pure reconstruction after simple\nbottlenecks). This conclusion still holds even under substantial change in\nstimulus statistics, as for instance considering cartoon-like images as opposed\nto natural images (Li et al. Journal of Vision, 2022, Preprint\narXiv:2103.00481).\nIn this note we present a method to generate original cartoon-like images\ncompatible with the statistical training used in (Li et al., 2022). Following\nthe classical observation in (Magritte, 1929), the stimuli generated by the\nproposed method certainly are not what they represent: Ceci n'est pas une pipe.\nThe clear distinction between representation (the stimuli generated by the\nproposed method) and reality (the actual object) avoids eventual problems for\nthe use of the generated stimuli in academic, non-profit, publications.",
    "descriptor": "\nComments: Keywords: Visual stimuli generation, Image representation in Surrealism, Cartoon-like images\n",
    "authors": [
      "Jesus Malo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2202.08103"
  },
  {
    "id": "arXiv:2202.08106",
    "title": "Sparse polynomial interpolation and division in soft-linear time",
    "abstract": "Given a way to evaluate an unknown polynomial with integer coefficients, we\npresent new algorithms to recover its nonzero coefficients and corresponding\nexponents. As an application, we adapt this interpolation algorithm to the\nproblem of computing the exact quotient of two given polynomials. These methods\nare efficient in terms of the bit-length of the sparse representation, that is,\nthe number of nonzero terms, the size of coefficients, the number of variables,\nand the logarithm of the degree. At the core of our results is a new Monte\nCarlo randomized algorithm to recover an integer polynomial $f(x)$ given a way\nto evaluate $f(\\theta) \\bmod m$ for any chosen integers $\\theta$ and $m$. This\nalgorithm has nearly-optimal bit complexity, meaning that the total bit-length\nof the probes, as well as the computational running time, is softly linear\n(ignoring logarithmic factors) in the bit-length of the resulting sparse\npolynomial. To our knowledge, this is the first sparse interpolation algorithm\nwith soft-linear bit complexity in the total output size. For integer\npolynomials, the best previously known results have at least a cubic dependency\non the bit-length of the exponents.",
    "descriptor": "",
    "authors": [
      "Pascal Giorgi",
      "Bruno Grenet",
      "Armelle Perret du Cray",
      "Daniel S. Roche"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.08106"
  },
  {
    "id": "arXiv:2202.08108",
    "title": "An alternative paradigm of fault diagnosis in dynamic systems:  orthogonal projection-based methods",
    "abstract": "In this paper, we propose a new paradigm of fault diagnosis in dynamic\nsystems as an alternative to the well-established observer-based framework. The\nbasic idea behind this work is to (i) formulate fault detection and isolation\nas projection of measurement signals onto (system) subspaces in Hilbert space,\nand (ii) solve the resulting problems by means of projection methods with\northogonal projection operators and gap metric as major tools. In the new\nframework, fault diagnosis issues are uniformly addressed both in the\nmodel-based and data-driven fashions. Moreover, the design and implementation\nof the projection-based fault diagnosis systems, from residual generation to\nthreshold setting, can be unifiedly handled. Thanks to the well-defined\ndistance metric for projections in Hilbert subspaces, the projection-based\nfault diagnosis systems deliver optimal fault detectability. In particular, a\nnew type of residual-driven thresholds is proposed, which significantly\nincreases the fault detectability. In this work, various design schemes are\nproposed, including a basic projection-based fault detection scheme, a fault\ndetection scheme for feedback control systems, fault classification as well as\ntwo modified fault detection schemes. As a part of our study, relations to the\nexisting observer-based fault detection systems are investigated, which\nshowcases that, with comparable online computations, the proposed\nprojection-based detection methods offer improved detection performance.",
    "descriptor": "",
    "authors": [
      "Steven X. Ding",
      "Linlin Li",
      "Tianyu Liu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.08108"
  },
  {
    "id": "arXiv:2202.08112",
    "title": "Typography-MNIST (TMNIST): an MNIST-Style Image Dataset to Categorize  Glyphs and Font-Styles",
    "abstract": "We present Typography-MNIST (TMNIST), a dataset comprising of 565,292\nMNIST-style grayscale images representing 1,812 unique glyphs in varied styles\nof 1,355 Google-fonts. The glyph-list contains common characters from over 150\nof the modern and historical language scripts with symbol sets, and each\nfont-style represents varying subsets of the total unique glyphs. The dataset\nhas been developed as part of the CognitiveType project which aims to develop\neye-tracking tools for real-time mapping of type to cognition and to create\ncomputational tools that allow for the easy design of typefaces with cognitive\nproperties such as readability. The dataset and scripts to generate MNIST-style\nimages for glyphs in different font styles are freely available at\nhttps://github.com/aiskunks/CognitiveType.",
    "descriptor": "",
    "authors": [
      "Nimish Magre",
      "Nicholas Brown"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08112"
  },
  {
    "id": "arXiv:2202.08114",
    "title": "Using Navigational Information to Learn Visual Representations",
    "abstract": "Children learn to build a visual representation of the world from\nunsupervised exploration and we hypothesize that a key part of this learning\nability is the use of self-generated navigational information as a similarity\nlabel to drive a learning objective for self-supervised learning. The goal of\nthis work is to exploit navigational information in a visual environment to\nprovide performance in training that exceeds the state-of-the-art\nself-supervised training. Here, we show that using spatial and temporal\ninformation in the pretraining stage of contrastive learning can improve the\nperformance of downstream classification relative to conventional contrastive\nlearning approaches that use instance discrimination to discriminate between\ntwo alterations of the same image or two different images. We designed a\npipeline to generate egocentric-vision images from a photorealistic ray-tracing\nenvironment (ThreeDWorld) and record relevant navigational information for each\nimage. Modifying the Momentum Contrast (MoCo) model, we introduced spatial and\ntemporal information to evaluate the similarity of two views in the pretraining\nstage instead of instance discrimination. This work reveals the effectiveness\nand efficiency of contextual information for improving representation learning.\nThe work informs our understanding of the means by which children might learn\nto see the world without external supervision.",
    "descriptor": "\nComments: Abstract submission to Computational and Systems Neuroscience (Cosyne) 2022, accepted\n",
    "authors": [
      "Lizhen Zhu",
      "Brad Wyble",
      "James Z. Wang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08114"
  },
  {
    "id": "arXiv:2202.08118",
    "title": "Smart Cities, Smart Libraries and Smart Knowledge Managers: Ushering in  the neo-Knowledge Society",
    "abstract": "The emergence of smart cities as a specific concept is not very old. In\nsimple terms, it refers to cities which are sustainable and driven\npredominantly by their Information and Communication Technology (ICT)\ninfrastructure. Smart libraries and smart knowledge managers, alongside its\nother smart component-entities, are vital for their emergence, sustenance and\nprogress. The paper attempts at deducing a symbiosis amongst smart cities,\nsmart libraries and smart knowledge managers. It further elaborates on how\nthese will usher in the neo-knowledge society, and the opportunities it'll\noffer vis-\\`a-vis Library and Information Science (LIS). Finally, it concludes\non an optimistic note, mentioning possible future research activities in this\nregard.",
    "descriptor": "",
    "authors": [
      "Mayukh Bagchi"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.08118"
  },
  {
    "id": "arXiv:2202.08124",
    "title": "XFBoost: Improving Text Generation with Controllable Decoders",
    "abstract": "Multimodal conditionality in transformer-based natural language models has\ndemonstrated state-of-the-art performance in the task of product description\ngeneration. Recent approaches condition a language model on one or more images\nand other textual metadata to achieve near-human performance for describing\nproducts from e-commerce stores. However, generated descriptions may exhibit\ndegrees of inaccuracy or even contradictory claims relative to the inputs of a\ngiven product. In this paper, we propose a controllable language generation\nframework called Extract-Finetune-Boost (XFBoost), which addresses the problem\nof inaccurate low-quality inference. By using visual semantic attributes as\nconstraints at the decoding stage of the generation process and finetuning the\nlanguage model with policy gradient techniques, the XFBoost framework is found\nto produce significantly more descriptive text with higher image relevancy,\noutperforming baselines and lowering the frequency of factually inaccurate\ndescriptions. We further demonstrate the application of XFBoost to online\nlearning wherein human-in-the-loop critics improve language models with active\nfeedback.",
    "descriptor": "",
    "authors": [
      "Xiangyu Peng",
      "Michael Sollami"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.08124"
  },
  {
    "id": "arXiv:2202.08125",
    "title": "Processing the structure of documents: Logical Layout Analysis of  historical newspapers in French",
    "abstract": "Background. In recent years, libraries and archives led important\ndigitisation campaigns that opened the access to vast collections of historical\ndocuments. While such documents are often available as XML ALTO documents, they\nlack information about their logical structure. In this paper, we address the\nproblem of Logical Layout Analysis applied to historical documents in French.\nWe propose a rule-based method, that we evaluate and compare with two\nMachine-Learning models, namely RIPPER and Gradient Boosting. Our data set\ncontains French newspapers, periodicals and magazines, published in the first\nhalf of the twentieth century in the Franche-Comt\\'e Region. Results. Our\nrule-based system outperforms the two other models in nearly all evaluations.\nIt has especially better Recall results, indicating that our system covers more\ntypes of every logical label than the other two models. When comparing RIPPER\nwith Gradient Boosting, we can observe that Gradient Boosting has better\nPrecision scores but RIPPER has better Recall scores. Conclusions. The\nevaluation shows that our system outperforms the two Machine Learning models,\nand provides significantly higher Recall. It also confirms that our system can\nbe used to produce annotated data sets that are large enough to envisage\nMachine Learning or Deep Learning approaches for the task of Logical Layout\nAnalysis. Combining rules and Machine Learning models into hybrid systems could\npotentially provide even better performances. Furthermore, as the layout in\nhistorical documents evolves rapidly, one possible solution to overcome this\nproblem would be to apply Rule Learning algorithms to bootstrap rule sets\nadapted to different publication periods.",
    "descriptor": "\nComments: 27 pages, 5 figures, 16 tables. This paper is to be submited to the NLP4DH edition of the Journal of Data Mining and Digital Humanities. To do so, the paper must first be deposited on arXiv\n",
    "authors": [
      "Nicolas Gutehrl\u00e9",
      "Iana Atanassova"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.08125"
  },
  {
    "id": "arXiv:2202.08131",
    "title": "Natural Language Proof Checking in Introduction to Proof Classes --  First Experiences with Diproche",
    "abstract": "We present and analyze the employment of the Diproche system, a natural\nlanguage proof checker, within a one-semester mathematics beginners lecture\nwith 228 participants. The system is used to check the students' solution\nattempts to proving exercises in Boolean set theory and elementary number\ntheory and to give them immediate feedback. The benefits of the employment of\nthe system are assessed via a questionnaire at the end of the semester and via\nanalyzing the solution attempts of a subgroup of the students. Based on our\nresults we develop approaches for future improvements.",
    "descriptor": "\nComments: In Proceedings ThEdu'21, arXiv:2202.02144\n",
    "authors": [
      "Merlin Carl",
      "Hinrich Lorenzen",
      "Michael Schmitz"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.08131"
  },
  {
    "id": "arXiv:2202.08132",
    "title": "Prospect Pruning: Finding Trainable Weights at Initialization using  Meta-Gradients",
    "abstract": "Pruning neural networks at initialization would enable us to find sparse\nmodels that retain the accuracy of the original network while consuming fewer\ncomputational resources for training and inference. However, current methods\nare insufficient to enable this optimization and lead to a large degradation in\nmodel performance. In this paper, we identify a fundamental limitation in the\nformulation of current methods, namely that their saliency criteria look at a\nsingle step at the start of training without taking into account the\ntrainability of the network. While pruning iteratively and gradually has been\nshown to improve pruning performance, explicit consideration of the training\nstage that will immediately follow pruning has so far been absent from the\ncomputation of the saliency criterion. To overcome the short-sightedness of\nexisting methods, we propose Prospect Pruning (ProsPr), which uses\nmeta-gradients through the first few steps of optimization to determine which\nweights to prune. ProsPr combines an estimate of the higher-order effects of\npruning on the loss and the optimization trajectory to identify the trainable\nsub-network. Our method achieves state-of-the-art pruning performance on a\nvariety of vision classification tasks, with less data and in a single shot\ncompared to existing pruning-at-initialization methods.",
    "descriptor": "",
    "authors": [
      "Milad Alizadeh",
      "Shyam A. Tailor",
      "Luisa M Zintgraf",
      "Joost van Amersfoort",
      "Sebastian Farquhar",
      "Nicholas Donald Lane",
      "Yarin Gal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08132"
  },
  {
    "id": "arXiv:2202.08134",
    "title": "GrADyS-SIM -- A OMNET++/INET simulation framework for Internet of Flying  things",
    "abstract": "This technical report describes GrADyS-SIM, a framework for simulating\ncooperating swarms of UAVs in joint mission in hypothetical landscape and\ncommunicating through RF radios. The framework was created to aid and verify\nthe communication, coordination and context-awareness protocols being developed\nin the GrADyS project. GrADyS-SIM uses the OMNeT++ simulation library and its\nINET model suite and and allows for addition of modified or customized versions\nof some simulated components, network configurations and vehicle coordination,\nso that new coordination protocols can be developed and tested through the\nframework. The framework simulates UAV movement dictated by file containing\nsome MAVLink instructions and affected on the fly by different network\nsituations. The UAV swarm coordination protocol emerges from individual\ninteractions between UAVs and has the objective of optimizing the collection of\nsensor data over an area. It also allows for the simulation of some types of\nfailures to test the protocol adaptability. Every node in the simulation is\nhighly configurable making testing different network opographies, coordination\nprotocols, node hardware configurations and more a quick task.",
    "descriptor": "",
    "authors": [
      "Thiago Lamenza",
      "Marcelo Paulon",
      "Breno Perricone",
      "Bruno Olivieri",
      "Markus Endler"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.08134"
  },
  {
    "id": "arXiv:2202.08137",
    "title": "A data-driven approach for learning to control computers",
    "abstract": "It would be useful for machines to use computers as humans do so that they\ncan aid us in everyday tasks. This is a setting in which there is also the\npotential to leverage large-scale expert demonstrations and human judgements of\ninteractive behaviour, which are two ingredients that have driven much recent\nsuccess in AI. Here we investigate the setting of computer control using\nkeyboard and mouse, with goals specified via natural language. Instead of\nfocusing on hand-designed curricula and specialized action spaces, we focus on\ndeveloping a scalable method centered on reinforcement learning combined with\nbehavioural priors informed by actual human-computer interactions. We achieve\nstate-of-the-art and human-level mean performance across all tasks within the\nMiniWob++ benchmark, a challenging suite of computer control problems, and find\nstrong evidence of cross-task transfer. These results demonstrate the\nusefulness of a unified human-agent interface when training machines to use\ncomputers. Altogether our results suggest a formula for achieving competency\nbeyond MiniWob++ and towards controlling computers, in general, as a human\nwould.",
    "descriptor": "",
    "authors": [
      "Peter C Humphreys",
      "David Raposo",
      "Toby Pohlen",
      "Gregory Thornton",
      "Rachita Chhaparia",
      "Alistair Muldal",
      "Josh Abramson",
      "Petko Georgiev",
      "Alex Goldin",
      "Adam Santoro",
      "Timothy Lillicrap"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08137"
  },
  {
    "id": "arXiv:2202.08138",
    "title": "When Did It Happen? Duration-informed Temporal Localization of Narrated  Actions in Vlogs",
    "abstract": "We consider the task of temporal human action localization in lifestyle\nvlogs. We introduce a novel dataset consisting of manual annotations of\ntemporal localization for 13,000 narrated actions in 1,200 video clips. We\npresent an extensive analysis of this data, which allows us to better\nunderstand how the language and visual modalities interact throughout the\nvideos. We propose a simple yet effective method to localize the narrated\nactions based on their expected duration. Through several experiments and\nanalyses, we show that our method brings complementary information with respect\nto previous methods, and leads to improvements over previous work for the task\nof temporal action localization.",
    "descriptor": "",
    "authors": [
      "Oana Ignat",
      "Santiago Castro",
      "Yuhang Zhou",
      "Jiajun Bao",
      "Dandan Shan"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.08138"
  },
  {
    "id": "arXiv:2202.08141",
    "title": "FUN-SIS: a Fully UNsupervised approach for Surgical Instrument  Segmentation",
    "abstract": "Automatic surgical instrument segmentation of endoscopic images is a crucial\nbuilding block of many computer-assistance applications for minimally invasive\nsurgery. So far, state-of-the-art approaches completely rely on the\navailability of a ground-truth supervision signal, obtained via manual\nannotation, thus expensive to collect at large scale. In this paper, we present\nFUN-SIS, a Fully-UNsupervised approach for binary Surgical Instrument\nSegmentation. FUN-SIS trains a per-frame segmentation model on completely\nunlabelled endoscopic videos, by solely relying on implicit motion information\nand instrument shape-priors. We define shape-priors as realistic segmentation\nmasks of the instruments, not necessarily coming from the same dataset/domain\nas the videos. The shape-priors can be collected in various and convenient\nways, such as recycling existing annotations from other datasets. We leverage\nthem as part of a novel generative-adversarial approach, allowing to perform\nunsupervised instrument segmentation of optical-flow images during training. We\nthen use the obtained instrument masks as pseudo-labels in order to train a\nper-frame segmentation model; to this aim, we develop a\nlearning-from-noisy-labels architecture, designed to extract a clean\nsupervision signal from these pseudo-labels, leveraging their peculiar noise\nproperties. We validate the proposed contributions on three surgical datasets,\nincluding the MICCAI 2017 EndoVis Robotic Instrument Segmentation Challenge\ndataset. The obtained fully-unsupervised results for surgical instrument\nsegmentation are almost on par with the ones of fully-supervised\nstate-of-the-art approaches. This suggests the tremendous potential of the\nproposed method to leverage the great amount of unlabelled data produced in the\ncontext of minimally invasive surgery.",
    "descriptor": "",
    "authors": [
      "Luca Sestini",
      "Benoit Rosa",
      "Elena De Momi",
      "Giancarlo Ferrigno",
      "Nicolas Padoy"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08141"
  },
  {
    "id": "arXiv:2202.08143",
    "title": "Bias in Automated Image Colorization: Metrics and Error Types",
    "abstract": "We measure the color shifts present in colorized images from the ADE20K\ndataset, when colorized by the automatic GAN-based DeOldify model. We introduce\nfine-grained local and regional bias measurements between the original and the\ncolorized images, and observe many colorization effects. We confirm a general\ndesaturation effect, and also provide novel observations: a shift towards the\ntraining average, a pervasive blue shift, different color shifts among image\ncategories, and a manual categorization of colorization errors in three\nclasses.",
    "descriptor": "\nComments: 5 pages, 8 figures\n",
    "authors": [
      "Frank Stapel",
      "Floris Weers",
      "Doina Bucur"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08143"
  },
  {
    "id": "arXiv:2202.08146",
    "title": "A Prospective Approach for Human-to-Human Interaction Recognition from  Wi-Fi Channel Data using Attention Bidirectional Gated Recurrent Neural  Network with GUI Application Implementation",
    "abstract": "With the recent advances in multi-disciplinary human activity recognition\ntechniques, it has become inevitable to find an efficient, economical &\nprivacy-friendly approach for human-to-human mutual interaction recognition in\norder to breakthrough the modern artificial intelligence centric indoor\nmonitoring & surveillance system. This study initially attempted to set its\nsights on the already proposed human activity recognition mechanisms and found\na void in mutual interaction recognition from Wi-Fi channel information which\nis convenient & affordable to be utilized. Then it elucidated on the\ncorresponding components of wireless local area network gadgets along with the\nchannel properties, and notable underlying causes of signal & channel\nperturbation. Thenceforth the study conducted three experiments on\nhuman-to-human mutual interaction recognition using the proposed Self-Attention\nfurnished Bidirectional Gated Recurrent Neural Network deep learning model\nwhich is perceived to become emergent nowadays for time-series data\nclassification through automated temporal feature extraction. Single pair\nmutual interaction recognition experiment achieved a maximum of 94% test\nbenchmark while the experiment involving ten subject-pairs secured 88%\nbenchmark with improved classification around interaction-transition region.\nDemonstration of a graphical user interface executable software designed using\nPyQt5 python module subsequently portrayed the overall mutual human-interaction\nrecognition procedure, and finally the study concluded with a brief discourse\nregarding the possible solutions to the handicaps that resulted in curtailments\nobserved in the case of cross-test experiment.",
    "descriptor": "\nComments: 18 Pages. This is the Pre-print version article submitted for Peer-Review to a prestigious journal\n",
    "authors": [
      "Md. Mohi Uddin Khan",
      "Abdullah Bin Shams",
      "Md. Mohsin Sarker Raihan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.08146"
  },
  {
    "id": "arXiv:2202.08149",
    "title": "Self-Supervised Class-Cognizant Few-Shot Classification",
    "abstract": "Unsupervised learning is argued to be the dark matter of human intelligence.\nTo build in this direction, this paper focuses on unsupervised learning from an\nabundance of unlabeled data followed by few-shot fine-tuning on a downstream\nclassification task. To this aim, we extend a recent study on adopting\ncontrastive learning for self-supervised pre-training by incorporating\nclass-level cognizance through iterative clustering and re-ranking and by\nexpanding the contrastive optimization loss to account for it. To our\nknowledge, our experimentation both in standard and cross-domain scenarios\ndemonstrate that we set a new state-of-the-art (SoTA) in (5-way, 1 and 5-shot)\nsettings of standard mini-ImageNet benchmark as well as the (5-way, 5 and\n20-shot) settings of cross-domain CDFSL benchmark. Our code and experimentation\ncan be found in our GitHub repository: https://github.com/ojss/c3lr.",
    "descriptor": "\nComments: 7 pages, 1 figure\n",
    "authors": [
      "Ojas Kishore Shirekar",
      "Hadi Jamali-Rad"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08149"
  },
  {
    "id": "arXiv:2202.08152",
    "title": "Cell-Free MIMO Systems Powered by Intelligent Reflecting Surfaces",
    "abstract": "Cell-free massive multiple-input multiple-output (MIMO) and intelligent\nreflecting surface (IRS) are considered as the prospective multiple antenna\ntechnologies for beyond the fifth-generation (5G) networks. Cell-free MIMO\nsystems powered by IRSs, combining both technologies, can further improve the\nperformance of cell-free MIMO systems at low cost and energy consumption. Prior\nworks focused on instantaneous performance metrics and relied on alternating\noptimization algorithms, which impose huge computational complexity and\nsignaling overhead. To address these challenges, we propose a novel two-step\nalgorithm that provides the long-term passive beamformers at the IRSs using\nstatistical channel state information (S-CSI) and short-term active precoders\nand long-term power allocation at the access points (APs) to maximize the\nminimum achievable rate. Simulation results verify that the proposed scheme\noutperforms benchmark schemes and brings a significant performance gain to the\ncell-free MIMO systems powered by IRSs.",
    "descriptor": "\nComments: 5 pages, 4 figures, accepted to IEEE Communications Letters\n",
    "authors": [
      "Taegyun Noh",
      "Junil Choi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.08152"
  },
  {
    "id": "arXiv:2202.08153",
    "title": "IoT Smart Plant Monitoring, Watering and Security System",
    "abstract": "Interest in home gardening has burgeoned since governments around the\nworld-imposed lockdowns to suppress the spread of COVID-19. Nowadays, most\nfamilies start to do gardening during this lockdown season because they can\ngrow vegetables and fruits or any other plants that they want in their\nday-to-day life. So, they can survive without spending money on online grocery\nshopping for fruits and vegetables during this lockdown season. In Sri Lanka,\nhome gardening was a trend during the past couple of months due to this\npandemic. Most of the families were trying to do gardening for their needs. But\nthe problem is, nowadays the government is trying to release those restrictions\nto start day-to-day work in Sri Lanka. With this situation, people are starting\nto do their jobs and they do not have time to spend in their gardens continuing\ntheir gardening. We thought about this problem and tried to find a solution to\ncontinue the gardening work while doing their jobs. The major concern is people\ncannot monitor their plants every time and protect their garden. So, we decided\nto automate the garden work. With our new solution, gardeners can monitor some\nimportant factors like the plant's healthiness, soil moisture level, air\nhumidity level, and the surrounding temperature and water their garden from\nanywhere in the world at any time by using our app. Plant health has a\nsignificant impact on plant development, production, and quality of\nagricultural goods. The goal of this study is to create an automated system\nthat can identify the presence of illness in plants based on variations in\nplant leaf health state is created utilizing sensors such as temperature,\nhumidity, and color....",
    "descriptor": "\nComments: 11 pages, 1 table, 3 figures\n",
    "authors": [
      "U.H.D. Thinura Nethpiya Ariyaratne",
      "V. Diyon Yasaswin Vitharana",
      "L.H. Don Ranul Deelaka",
      "H.M. Sumudu Maduranga Herath"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.08153"
  },
  {
    "id": "arXiv:2202.08156",
    "title": "A novel public key cryptography based on generalized Lucas matrices",
    "abstract": "In this article, we have proposed a generalized Lucas matrix (recursive\nmatrix of higher order) having relation with generalized Fibonacci sequences\nand established many special properties in addition to that usual matrix\nalgebra. Further, we have proposed a modified public key cryptography using\nthese matrices as keys in Affine cipher and key agreement for\nencryption-decryption with the combination of terms of generalized Lucas\nsequences under residue operations. In this scheme, instead of exchanging the\nwhole key matrix, only a pair of numbers(parameters) need to be exchanged,\nwhich reduces the time complexity as well as space complexity of the key\ntransmission and has a large key-space.",
    "descriptor": "\nComments: 14pages\n",
    "authors": [
      "Kalika Prasad",
      "Hrishikesh Mahato",
      "Munesh Kumari"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2202.08156"
  },
  {
    "id": "arXiv:2202.08159",
    "title": "Domain Adaptive Fake News Detection via Reinforcement Learning",
    "abstract": "With social media being a major force in information consumption, accelerated\npropagation of fake news has presented new challenges for platforms to\ndistinguish between legitimate and fake news. Effective fake news detection is\na non-trivial task due to the diverse nature of news domains and expensive\nannotation costs. In this work, we address the limitations of existing\nautomated fake news detection models by incorporating auxiliary information\n(e.g., user comments and user-news interactions) into a novel reinforcement\nlearning-based model called \\textbf{RE}inforced \\textbf{A}daptive\n\\textbf{L}earning \\textbf{F}ake \\textbf{N}ews \\textbf{D}etection (REAL-FND).\nREAL-FND exploits cross-domain and within-domain knowledge that makes it robust\nin a target domain, despite being trained in a different source domain.\nExtensive experiments on real-world datasets illustrate the effectiveness of\nthe proposed model, especially when limited labeled data is available in the\ntarget domain.",
    "descriptor": "\nComments: Accepted to The ACM Web Conference (WWW) 2022\n",
    "authors": [
      "Ahmadreza Mosallanezhad",
      "Mansooreh Karami",
      "Kai Shu",
      "Michelle V. Mancenido",
      "Huan Liu"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08159"
  },
  {
    "id": "arXiv:2202.08168",
    "title": "Small defects reconstruction in waveguides from multifrequency one-side  scattering data",
    "abstract": "Localization and reconstruction of small defects in acoustic or\nelectromagnetic waveguides is of crucial interest in nondestructive evaluation\nof structures. The aim of this work is to present a new multi-frequency\ninversion method to reconstruct small defects in a 2D waveguide. Given one-side\nmulti-frequency wave field measurements of propagating modes, we use a Born\napproximation to provide a L2-stable reconstruction of three types of defects:\na local perturbation inside the waveguide, a bending of the waveguide, and a\nlocalized defect in the geometry of the waveguide. This method is based on a\nmode-by-mode spacial Fourier inversion from the available partial data in the\nFourier domain. Indeed, in the available data, some high and low spatial\nfrequency information on the defect are missing. We overcome this issue using\nboth a compact support hypothesis and a minimal smoothness hypothesis on the\ndefects. We also provide a suitable numerical method for efficient\nreconstruction of such defects and we discuss its applications and limits.",
    "descriptor": "",
    "authors": [
      "Eric Bonnetier",
      "Ang\u00e8le Niclas",
      "Laurent Seppecher",
      "Gr\u00e9gory Vial"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.08168"
  },
  {
    "id": "arXiv:2202.08171",
    "title": "Capitalization Normalization for Language Modeling with an Accurate and  Efficient Hierarchical RNN Model",
    "abstract": "Capitalization normalization (truecasing) is the task of restoring the\ncorrect case (uppercase or lowercase) of noisy text. We propose a fast,\naccurate and compact two-level hierarchical word-and-character-based recurrent\nneural network model. We use the truecaser to normalize user-generated text in\na Federated Learning framework for language modeling. A case-aware language\nmodel trained on this normalized text achieves the same perplexity as a model\ntrained on text with gold capitalization. In a real user A/B experiment, we\ndemonstrate that the improvement translates to reduced prediction error rates\nin a virtual keyboard application. Similarly, in an ASR language model fusion\nexperiment, we show reduction in uppercase character error rate and word error\nrate.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:2108.11943\n",
    "authors": [
      "Hao Zhang",
      "You-Chi Cheng",
      "Shankar Kumar",
      "W. Ronny Huang",
      "Mingqing Chen",
      "Rajiv Mathews"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08171"
  },
  {
    "id": "arXiv:2202.08173",
    "title": "Distributed k-Means with Outliers in General Metrics",
    "abstract": "Center-based clustering is a pivotal primitive for unsupervised learning and\ndata analysis. A popular variant is undoubtedly the k-means problem, which,\ngiven a set $P$ of points from a metric space and a parameter $k<|P|$, requires\nto determine a subset $S$ of $k$ centers minimizing the sum of all squared\ndistances of points in $P$ from their closest center. A more general\nformulation, known as k-means with $z$ outliers, introduced to deal with noisy\ndatasets, features a further parameter $z$ and allows up to $z$ points of $P$\n(outliers) to be disregarded when computing the aforementioned sum. We present\na distributed coreset-based 3-round approximation algorithm for k-means with\n$z$ outliers for general metric spaces, using MapReduce as a computational\nmodel. Our distributed algorithm requires sublinear local memory per reducer,\nand yields a solution whose approximation ratio is an additive term $O(\\gamma)$\naway from the one achievable by the best known sequential (possibly bicriteria)\nalgorithm, where $\\gamma$ can be made arbitrarily small. An important feature\nof our algorithm is that it obliviously adapts to the intrinsic complexity of\nthe dataset, captured by the doubling dimension $D$ of the metric space. To the\nbest of our knowledge, no previous distributed approaches were able to attain\nsimilar quality-performance tradeoffs for general metrics.",
    "descriptor": "",
    "authors": [
      "Enrico Dandolo",
      "Andrea Pietracaprina",
      "Geppino Pucci"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08173"
  },
  {
    "id": "arXiv:2202.08174",
    "title": "Towards Battery-Free Machine Learning and Inference in Underwater  Environments",
    "abstract": "This paper is motivated by a simple question: Can we design and build\nbattery-free devices capable of machine learning and inference in underwater\nenvironments? An affirmative answer to this question would have significant\nimplications for a new generation of underwater sensing and monitoring\napplications for environmental monitoring, scientific exploration, and\nclimate/weather prediction.\nTo answer this question, we explore the feasibility of bridging advances from\nthe past decade in two fields: battery-free networking and low-power machine\nlearning. Our exploration demonstrates that it is indeed possible to enable\nbattery-free inference in underwater environments. We designed a device that\ncan harvest energy from underwater sound, power up an ultra-low-power\nmicrocontroller and on-board sensor, perform local inference on sensed\nmeasurements using a lightweight Deep Neural Network, and communicate the\ninference result via backscatter to a receiver. We tested our prototype in an\nemulated marine bioacoustics application, demonstrating the potential to\nrecognize underwater animal sounds without batteries. Through this exploration,\nwe highlight the challenges and opportunities for making underwater\nbattery-free inference and machine learning ubiquitous.",
    "descriptor": "\nComments: 6 pages, HotMobile '22, March 9-10, 2022, Tempe, AZ, USA\n",
    "authors": [
      "Yuchen Zhao",
      "Sayed Saad Afzal",
      "Waleed Akbar",
      "Osvy Rodriguez",
      "Fan Mo",
      "David Boyle",
      "Fadel Adib",
      "Hamed Haddadi"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.08174"
  },
  {
    "id": "arXiv:2202.08175",
    "title": "GraphNLI: A Graph-based Natural Language Inference Model for Polarity  Prediction in Online Debates",
    "abstract": "Online forums that allow participatory engagement between users have been\ntransformative for public discussion of important issues. However, debates on\nsuch forums can sometimes escalate into full blown exchanges of hate or\nmisinformation. An important tool in understanding and tackling such problems\nis to be able to infer the argumentative relation of whether a reply is\nsupporting or attacking the post it is replying to. This so called polarity\nprediction task is difficult because replies may be based on external context\nbeyond a post and the reply whose polarity is being predicted. We propose\nGraphNLI, a novel graph-based deep learning architecture that uses graph walk\ntechniques to capture the wider context of a discussion thread in a principled\nfashion. Specifically, we propose methods to perform root-seeking graph walks\nthat start from a post and captures its surrounding context to generate\nadditional embeddings for the post. We then use these embeddings to predict the\npolarity relation between a reply and the post it is replying to. We evaluate\nthe performance of our models on a curated debate dataset from Kialo, an online\ndebating platform. Our model outperforms relevant baselines, including S-BERT,\nwith an overall accuracy of 83%.",
    "descriptor": "\nComments: To appear at The ACM Web Conference 2022\n",
    "authors": [
      "Vibhor Agarwal",
      "Sagar Joglekar",
      "Anthony P. Young",
      "Nishanth Sastry"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08175"
  },
  {
    "id": "arXiv:2202.08176",
    "title": "Bias and unfairness in machine learning models: a systematic literature  review",
    "abstract": "One of the difficulties of artificial intelligence is to ensure that model\ndecisions are fair and free of bias. In research, datasets, metrics,\ntechniques, and tools are applied to detect and mitigate algorithmic unfairness\nand bias. This study aims to examine existing knowledge on bias and unfairness\nin Machine Learning models, identifying mitigation methods, fairness metrics,\nand supporting tools. A Systematic Literature Review found 40 eligible articles\npublished between 2017 and 2022 in the Scopus, IEEE Xplore, Web of Science, and\nGoogle Scholar knowledge bases. The results show numerous bias and unfairness\ndetection and mitigation approaches for ML technologies, with clearly defined\nmetrics in the literature, and varied metrics can be highlighted. We recommend\nfurther research to define the techniques and metrics that should be employed\nin each case to standardize and ensure the impartiality of the machine learning\nmodel, thus, allowing the most appropriate metric to detect bias and unfairness\nin a given context.",
    "descriptor": "",
    "authors": [
      "Tiago Palma Pagano",
      "Rafael Bessa Loureiro",
      "Maira Matos Araujo",
      "Fernanda Vitoria Nascimento Lisboa",
      "Rodrigo Matos Peixoto",
      "Guilherme Aragao de Sousa Guimaraes",
      "Lucas Lisboa dos Santos",
      "Gustavo Oliveira Ramos Cruz",
      "Ewerton Lopes Silva de Oliveira",
      "Marco Cruz",
      "Ingrid Winkler",
      "Erick Giovani Sperandio Nascimento"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08176"
  },
  {
    "id": "arXiv:2202.08182",
    "title": "An Intrusion Response System utilizing Deep Q-Networks and System  Partitions",
    "abstract": "Intrusion Response is a relatively new field of research. Recent approaches\nfor the creation of Intrusion Response Systems (IRSs) use Reinforcement\nLearning (RL) as a primary technique for the optimal or near-optimal selection\nof the proper countermeasure to take in order to stop or mitigate an ongoing\nattack. However, most of them do not consider the fact that systems can change\nover time or, in other words, that systems exhibit a non-stationary behavior.\nFurthermore, stateful approaches, such as those based on RL, suffer the curse\nof dimensionality, due to a state space growing exponentially with the size of\nthe protected system.\nIn this paper, we introduce and develop an IRS software prototype, named\nirs-partition. It leverages the partitioning of the protected system and Deep\nQ-Networks to address the curse of dimensionality by supporting a multi-agent\nformulation. Furthermore, it exploits transfer learning to follow the evolution\nof non-stationary systems.",
    "descriptor": "\nComments: Keywords - Intrusion Response System,Self-Protection, Self-Adaptation\n",
    "authors": [
      "Valeria Cardellini",
      "Emiliano Casalicchio",
      "Stefano Iannucci",
      "Matteo Lucantonio",
      "Sudip Mittal",
      "Damodar Panigrahi",
      "Andrea Silvi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08182"
  },
  {
    "id": "arXiv:2202.08185",
    "title": "The Adversarial Security Mitigations of mmWave Beamforming Prediction  Models using Defensive Distillation and Adversarial Retraining",
    "abstract": "The design of a security scheme for beamforming prediction is critical for\nnext-generation wireless networks (5G, 6G, and beyond). However, there is no\nconsensus about protecting the beamforming prediction using deep learning\nalgorithms in these networks. This paper presents the security vulnerabilities\nin deep learning for beamforming prediction using deep neural networks (DNNs)\nin 6G wireless networks, which treats the beamforming prediction as a\nmulti-output regression problem. It is indicated that the initial DNN model is\nvulnerable against adversarial attacks, such as Fast Gradient Sign Method\n(FGSM), Basic Iterative Method (BIM), Projected Gradient Descent (PGD), and\nMomentum Iterative Method (MIM), because the initial DNN model is sensitive to\nthe perturbations of the adversarial samples of the training data. This study\nalso offers two mitigation methods, such as adversarial training and defensive\ndistillation, for adversarial attacks against artificial intelligence\n(AI)-based models used in the millimeter-wave (mmWave) beamforming prediction.\nFurthermore, the proposed scheme can be used in situations where the data are\ncorrupted due to the adversarial examples in the training data. Experimental\nresults show that the proposed methods effectively defend the DNN models\nagainst adversarial attacks in next-generation wireless networks.",
    "descriptor": "\nComments: 26 pages, under review\n",
    "authors": [
      "Murat Kuzlu",
      "Ferhat Ozgur Catak",
      "Umit Cali",
      "Evren Catak",
      "Ozgur Guler"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.08185"
  },
  {
    "id": "arXiv:2202.08187",
    "title": "Differential Privacy and Fairness in Decisions and Learning Tasks: A  Survey",
    "abstract": "This paper surveys recent work in the intersection of differential privacy\n(DP) and fairness. It reviews the conditions under which privacy and fairness\nmay have aligned or contrasting goals, analyzes how and why DP may exacerbate\nbias and unfairness in decision problems and learning tasks, and describes\navailable mitigation measures for the fairness issues arising in DP systems.\nThe survey provides a unified understanding of the main challenges and\npotential risks arising when deploying privacy-preserving machine-learning or\ndecisions-making tasks under a fairness lens.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Ferdinando Fioretto",
      "Cuong Tran",
      "Pascal Van Hentenryck",
      "Keyu Zhu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08187"
  },
  {
    "id": "arXiv:2202.08192",
    "title": "Flexible-Modal Face Anti-Spoofing: A Benchmark",
    "abstract": "Face anti-spoofing (FAS) plays a vital role in securing face recognition\nsystems from presentation attacks. Benefitted from the maturing camera sensors,\nsingle-modal (RGB) and multi-modal (e.g., RGB+Depth) FAS has been applied in\nvarious scenarios with different configurations of sensors/modalities. Existing\nsingle- and multi-modal FAS methods usually separately train and deploy models\nfor each possible modality scenario, which might be redundant and inefficient.\nCan we train a unified model, and flexibly deploy it under various modality\nscenarios? In this paper, we establish the first flexible-modal FAS benchmark\nwith the principle `train one for all'. To be specific, with trained\nmulti-modal (RGB+Depth+IR) FAS models, both intra- and cross-dataset testings\nare conducted on four flexible-modal sub-protocols (RGB, RGB+Depth, RGB+IR, and\nRGB+Depth+IR). We also investigate prevalent deep models and feature fusion\nstrategies for flexible-modal FAS. We hope this new benchmark will facilitate\nthe future research of the multi-modal FAS. The protocols and codes are\navailable at https://github.com/ZitongYu/Flex-Modal-FAS.",
    "descriptor": "",
    "authors": [
      "Zitong Yu",
      "Chenxu Zhao",
      "Kevin H. M. Cheng",
      "Xu Cheng",
      "Guoying Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08192"
  },
  {
    "id": "arXiv:2202.08194",
    "title": "Deep Contextual Bandits for Orchestrating Multi-User MISO Systems with  Multiple RISs",
    "abstract": "The emergent technology of Reconfigurable Intelligent Surfaces (RISs) has the\npotential to transform wireless environments into controllable systems, through\nprogrammable propagation of information-bearing signals. Techniques stemming\nfrom the field of Deep Reinforcement Learning (DRL) have recently gained\npopularity in maximizing the sum-rate performance in multi-user communication\nsystems empowered by RISs. Such approaches are commonly based on Markov\nDecision Processes (MDPs). In this paper, we instead investigate the sum-rate\ndesign problem under the scope of the Multi-Armed Bandits (MAB) setting, which\nis a relaxation of the MDP framework. Nevertheless, in many cases, the MAB\nformulation is more appropriate to the channel and system models under the\nassumptions typically made in the RIS literature. To this end, we propose a\nsimpler DRL approach for orchestrating multiple metasurfaces in RIS-empowered\nmulti-user Multiple-Input Single-Output (MISO) systems, which we numerically\nshow to perform equally well with a state-of-the-art MDP-based approach, while\nbeing less demanding computationally.",
    "descriptor": "\nComments: 6 pages, 4 figures, to be presented in IEEE ICC 2022\n",
    "authors": [
      "Kyriakos Stylianopoulos",
      "George Alexandropoulos",
      "Chongwen Huang",
      "Chau Yuen",
      "Mehdi Bennis",
      "and M\u00e9rouane Debbah"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.08194"
  },
  {
    "id": "arXiv:2202.08198",
    "title": "Analysis of Random Sequential Message Passing Algorithms for Approximate  Inference",
    "abstract": "We analyze the dynamics of a random sequential message passing algorithm for\napproximate inference with large Gaussian latent variable models in a\nstudent-teacher scenario. To model nontrivial dependencies between the latent\nvariables, we assume random covariance matrices drawn from rotation invariant\nensembles. Moreover, we consider a model mismatching setting, where the teacher\nmodel and the one used by the student may be different. By means of dynamical\nfunctional approach, we obtain exact dynamical mean-field equations\ncharacterizing the dynamics of the inference algorithm. We also derive a range\nof model parameters for which the sequential algorithm does not converge. The\nboundary of this parameter range coincides with the de Almeida Thouless (AT)\nstability condition of the replica symmetric ansatz for the static\nprobabilistic model.",
    "descriptor": "",
    "authors": [
      "Burak \u00c7akmak",
      "Yue M. Lu",
      "Manfred Opper"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08198"
  },
  {
    "id": "arXiv:2202.08199",
    "title": "Less is More: Surgical Phase Recognition from Timestamp Supervision",
    "abstract": "Surgical phase recognition is a fundamental task in computer-assisted surgery\nsystems. Most existing works require expensive frame-wise annotations, which is\nvery time-consuming. In this paper, we introduce timestamp supervision to\nsurgical phase recognition for the first time, which only requires randomly\nlabeling one frame for each phase in a video. With timestamp supervision,\ncurrent methods in natural videos aim to generate pseudo labels of full frames.\nHowever, due to the surgical videos containing ambiguous boundaries, these\nmethods would generate many noisy and inconsistent pseudo labels, leading to\nlimited performance. We argue that less is more in surgical phase\nrecognition,~\\ie, less but discriminative pseudo labels outperform full but\nambiguous frames. To this end, we propose a novel method called\nuncertainty-aware temporal diffusion to generate trustworthy pseudo labels. Our\napproach evaluates the confidence of generated pseudo labels based on\nuncertainty estimation. Then, we treat the annotated frames as anchors and make\npseudo labels diffuse to both sides, starting from anchors and stopping at the\nhigh-uncertainty frames. In this way, our proposed method can generate\ncontiguous confident pseudo labels while discarding the uncertain ones.\nExtensive experiments demonstrate that our method not only significantly save\nannotation cost, but also outperforms fully supervised methods. Moreover, our\nproposed approach can be used to clean noisy labels near boundaries and improve\nthe performance of the current surgical phase recognition methods.",
    "descriptor": "",
    "authors": [
      "Zixun Wang",
      "Xinpeng Ding",
      "Wei Zhao",
      "Xiaomeng Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08199"
  },
  {
    "id": "arXiv:2202.08205",
    "title": "SemiRetro: Semi-template framework boosts deep retrosynthesis prediction",
    "abstract": "Recently, template-based (TB) and template-free (TF) molecule graph learning\nmethods have shown promising results to retrosynthesis. TB methods are more\naccurate using pre-encoded reaction templates, and TF methods are more scalable\nby decomposing retrosynthesis into subproblems, i.e., center identification and\nsynthon completion. To combine both advantages of TB and TF, we suggest\nbreaking a full-template into several semi-templates and embedding them into\nthe two-step TF framework. Since many semi-templates are reduplicative, the\ntemplate redundancy can be reduced while the essential chemical knowledge is\nstill preserved to facilitate synthon completion. We call our method SemiRetro,\nintroduce a new GNN layer (DRGAT) to enhance center identification, and propose\na novel self-correcting module to improve semi-template classification.\nExperimental results show that SemiRetro significantly outperforms both\nexisting TB and TF methods. In scalability, SemiRetro covers 98.9\\% data using\n150 semi-templates, while previous template-based GLN requires 11,647 templates\nto cover 93.3\\% data. In top-1 accuracy, SemiRetro exceeds template-free G2G\n4.8\\% (class known) and 6.0\\% (class unknown). Besides, SemiRetro has better\ntraining efficiency than existing methods.",
    "descriptor": "",
    "authors": [
      "Zhangyang Gao",
      "Cheng Tan",
      "Lirong Wu",
      "Stan Z. Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.08205"
  },
  {
    "id": "arXiv:2202.08208",
    "title": "Front Transport Reduction for Complex Moving Fronts",
    "abstract": "This work addresses model order reduction for complex moving fronts, which\nare transported by advection or through a reaction-diffusion process. Such\nsystems are especially challenging for model order reduction since the\ntransport cannot be captured by linear reduction methods. Moreover, topological\nchanges, such as splitting or merging of fronts pose difficulties for many\nnonlinear reduction methods and the small non-vanishing support of the\nunderlying partial differential equations dynamics makes most nonlinear\nhyper-reduction methods infeasible. We propose a new decomposition method\ntogether with a hyper-reduction scheme that addresses these shortcomings. The\ndecomposition uses a level-set function to parameterize the transport and a\nnonlinear activation function that captures the structure of the front. This\napproach is similar to autoencoder artificial neural networks, but additionally\nprovides insights into the system, which can be used for efficient reduced\norder models. We make use of this property and are thus able to solve the\nadvection equation with the same complexity as the POD-Galerkin approach while\nobtaining errors of less than one percent for representative examples.\nFurthermore, we outline a special hyper-reduction method for more complicated\nadvection-reaction-diffusion systems. The capability of the approach is\nillustrated by various numerical examples in one and two spatial dimensions,\nincluding real-life applications to a two-dimensional Bunsen flame.",
    "descriptor": "\nComments: Preprint including 21 pages, Code available: this https URL\n",
    "authors": [
      "Philipp Krah",
      "Steffen B\u00fcchholz",
      "Matthias H\u00e4ringer",
      "Julius Reiss"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2202.08208"
  },
  {
    "id": "arXiv:2202.08214",
    "title": "Resolution with Counting: Lower Bounds for Proofs of Membership in the  Complement of a Linear Map Image of the Boolean Cube",
    "abstract": "We propose a new approach to proving lower bounds for sizes of dag-like\nproofs in the proof system Res(lin$_{\\mathbb{F}_p}$), where $\\mathbb{F}_p$ is a\nfinite field of prime order $p\\geq 5$. An exponential lower bound on sizes of\narbitrary dag-like refutations in proof systems Res(lin$_{\\mathbb{F}}$) has\npreviously been proven in (Part, Tzameret, ITCS'20) in case $\\mathbb{F}$ is a\nfield of characteristic $0$ for an instance, which is not CNF: for the binary\nvalue principle $x_1+2x_2+\\dots+2^{n-1}x_n = -1$. The proof of this lower bound\nsubstantially uses peculiarities of characteristic $0$ regime and does not give\na clue on how to prove lower bounds neither for finite fields nor for CNFs.\nAiming at constructing a bridge between lower bounds for the binary value\nprinciple and CNF lower bounds we initiate the development of methods for\nproving dag-like Res(lin$_{\\mathbb{F}_p}$) lower bounds for tautologies of the\nform $b\\notin A(\\{0,1\\}^n)$, where $A$ is a linear map. The negation of such a\ntautology can be represented in the language of Res(lin$_{\\mathbb{F}_p}$) as a\nsystem of linear equations $A\\cdot x = b$ unsatisfiable over the boolean\nassignments. Instances of this form are in some ways simpler than CNFs, this\nmakes analysis of their Res(lin$_{\\mathbb{F}_p}$) refutations more approachable\nand might be aided by tools from linear algebra and additive combinatorics.\nWe identify hardness criterions for instances of the form $A\\cdot x = b$\nusing notions of an error correcting code and what we call $(s, r)$-robustness,\na combinatorial, algebraic property of linear systems $A\\cdot x = b$, which we\nintroduce. We prove two lower bounds for fragments of Res(lin$_{\\mathbb{F}_p}$)\nthat capture two complementary aspects of Res(lin$_{\\mathbb{F}_p}$) refutations\nand constitute a combinatorial toolbox for approaching general dag-like\nRes(lin$_{\\mathbb{F}_p}$) refutations.",
    "descriptor": "",
    "authors": [
      "Fedor Part"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.08214"
  },
  {
    "id": "arXiv:2202.08216",
    "title": "TalkTive: A Conversational Agent Using Backchannels to Engage Older  Adults in Neurocognitive Disorders Screening",
    "abstract": "Conversational agents (CAs) have the great potential in mitigating the\nclinicians' burden in screening for neurocognitive disorders among older\nadults. It is important, therefore, to develop CAs that can be engaging, to\nelicit conversational speech input from older adult participants for supporting\nassessment of cognitive abilities. As an initial step, this paper presents\nresearch in developing the backchanneling ability in CAs in the form of a\nverbal response to engage the speaker. We analyzed 246 conversations of\ncognitive assessments between older adults and human assessors, and derived the\ncategories of reactive backchannels (e.g. \"hmm\") and proactive backchannels\n(e.g. \"please keep going\"). This is used in the development of TalkTive, a CA\nwhich can predict both timing and form of backchanneling during cognitive\nassessments. The study then invited 36 older adult participants to evaluate the\nbackchanneling feature. Results show that proactive backchanneling is more\nappreciated by participants than reactive backchanneling.",
    "descriptor": "\nComments: Accepted by CHI2022\n",
    "authors": [
      "Zijian Ding",
      "Jiawen Kang",
      "Tinky Oi Ting HO",
      "Ka Ho Wong",
      "Helene H. Fung",
      "Helen Meng",
      "Xiaojuan Ma"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.08216"
  },
  {
    "id": "arXiv:2202.08221",
    "title": "Evolutionary Construction of Perfectly Balanced Boolean Functions",
    "abstract": "Finding Boolean functions suitable for cryptographic primitives is a complex\ncombinatorial optimization problem, since they must satisfy several properties\nto resist cryptanalytic attacks, and the space is very large, which grows super\nexponentially with the number of input variables. Recent research has focused\non the study of Boolean functions that satisfy properties on restricted sets of\ninputs due to their importance in the development of the FLIP stream cipher. In\nthis paper, we consider one such property, perfect balancedness, and\ninvestigate the use of Genetic Programming (GP) and Genetic Algorithms (GA) to\nconstruct Boolean functions that satisfy this property along with a good\nnonlinearity profile. We formulate the related optimization problem and define\ntwo encodings for the candidate solutions, namely the truth table and the\nweightwise balanced representations. Somewhat surprisingly, the results show\nthat GA with the weightwise balanced representation outperforms GP with the\nclassical truth table phenotype in finding highly nonlinear WPB functions. This\nfinding is in stark contrast to previous findings on the evolution of globally\nbalanced Boolean functions, where GP always performs best.",
    "descriptor": "\nComments: 19 pages, 2 figures, 3 tables\n",
    "authors": [
      "Luca Mariot",
      "Stjepan Picek",
      "Domagoj Jakobovic",
      "Marko Djurasevic",
      "Alberto Leporati"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.08221"
  },
  {
    "id": "arXiv:2202.08227",
    "title": "Ditto: Building Digital Twins of Articulated Objects from Interaction",
    "abstract": "Digitizing physical objects into the virtual world has the potential to\nunlock new research and applications in embodied AI and mixed reality. This\nwork focuses on recreating interactive digital twins of real-world articulated\nobjects, which can be directly imported into virtual environments. We introduce\nDitto to learn articulation model estimation and 3D geometry reconstruction of\nan articulated object through interactive perception. Given a pair of visual\nobservations of an articulated object before and after interaction, Ditto\nreconstructs part-level geometry and estimates the articulation model of the\nobject. We employ implicit neural representations for joint geometry and\narticulation modeling. Our experiments show that Ditto effectively builds\ndigital twins of articulated objects in a category-agnostic way. We also apply\nDitto to real-world objects and deploy the recreated digital twins in physical\nsimulation. Code and additional results are available at\nhttps://ut-austin-rpl.github.io/Ditto",
    "descriptor": "\nComments: 14 pages, 7 figures; Code and additional results are available at this https URL\n",
    "authors": [
      "Zhenyu Jiang",
      "Cheng-Chun Hsu",
      "Yuke Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.08227"
  },
  {
    "id": "arXiv:2202.08228",
    "title": "Performance of QUIC Implementations Over Geostationary Satellite Links",
    "abstract": "QUIC was recently standardized as RFC 9000, but the performance of QUIC over\ngeostationary satellite links is problematic due to the non-applicability of\nPerformance Enhancing Proxies. As of today, there are more than a dozen of\ndifferent QUIC implementations. So far performance evaluations of QUIC over\nsatellite links were limited to specific QUIC implementations. By deploying a\nmodified version of the IETF QUIC-Interop-Runner, this paper evaluates the\nperformance of multiple QUIC implementations over multiple geostationary\nsatellite links. This includes two emulated ones (with and without packet loss)\nand two real ones. The results show that the goodput achieved with QUIC over\ngeostationary satellite links is very poor in general, and especially poor when\nthere is packet loss. Some implementations fail completely and the performance\nof the other implementations varies greatly. The performance depends on both\nclient and server implementation.",
    "descriptor": "",
    "authors": [
      "Sebastian Endres",
      "J\u00f6rg Deutschmann",
      "Kai-Steffen Hielscher",
      "Reinhard German"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2202.08228"
  },
  {
    "id": "arXiv:2202.08229",
    "title": "Beyond COVID-19 Pandemic: Topology-aware optimisation of vaccination  strategy for minimising virus spreading",
    "abstract": "The mitigation of an infectious disease spreading has recently gained\nconsiderable attention from the research community. It may be obtained by\nadopting sanitary measurements social rules, together with an extensive\nvaccination campaign. Vaccination is currently the primary way for mitigating\nthe Coronavirus Disease (COVID-19) outbreak without severe lockdown. Its\neffectiveness also depends on the number and timeliness of administrations and\nthus demands strict prioritization criteria. Almost all countries have\nprioritized similar classes of exposed workers obtaining to maximize the\nsurvival of patients and years of life saved. The mitigation of an infectious\ndisease spreading has recently gained considerable attention from the research\ncommunity. It may be obtained by adopting sanitary measurements, social rules,\ntogether with an extensive vaccination campaign. Vaccination is currently the\nprimary way for mitigating the Coronavirus Disease (COVID-19) outbreak without\nsevere lockdown. Its effectiveness also depends on the number and timeliness of\nadministrations and thus demands strict prioritization criteria. Almost all\ncountries have prioritized similar classes of exposed workers: healthcare\nprofessionals and the elderly, obtaining to maximize the survival of patients\nand years of life saved. Nevertheless, the virus is currently spreading at high\nrates, and any prioritization criterion so far adopted did not account for the\nstructural organization of the contact networks.",
    "descriptor": "",
    "authors": [
      "Francesco Petrizzelli",
      "Pietro Hiram Guzzi",
      "Tommaso Mazza"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.08229"
  },
  {
    "id": "arXiv:2202.08235",
    "title": "Data Augmentation for Deep Graph Learning: A Survey",
    "abstract": "Graph neural networks, as powerful deep learning tools to model\ngraph-structured data, have demonstrated remarkable performance on numerous\ngraph learning tasks. To counter the data noise and data scarcity issues in\ndeep graph learning (DGL), increasing graph data augmentation research has been\nconducted lately. However, conventional data augmentation methods can hardly\nhandle graph-structured data which is defined on non-Euclidean space with\nmulti-modality. In this survey, we formally formulate the problem of graph data\naugmentation and further review the representative techniques in this field.\nSpecifically, we first propose a taxonomy for graph data augmentation and then\nprovide a structured review by categorizing the related work based on the\naugmented information modalities. Focusing on the two challenging problems in\nDGL (i.e., optimal graph learning and low-resource graph learning), we also\ndiscuss and review the existing learning paradigms which are based on graph\ndata augmentation. Finally, we point out a few directions and challenges on\npromising future works.",
    "descriptor": "\nComments: Under Review\n",
    "authors": [
      "Kaize Ding",
      "Zhe Xu",
      "Hanghang Tong",
      "Huan Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08235"
  },
  {
    "id": "arXiv:2202.08239",
    "title": "\"Way back then\": A Data-driven View of 25+ years of Web Evolution",
    "abstract": "Since the inception of the first web page three decades back, the Web has\nevolved considerably, from static HTML pages in the beginning to the dynamic\nweb pages of today, from mainly the text-based pages of the 1990s to today's\nmultimedia rich pages, etc. Although much of this is known anecdotally, to our\nknowledge, there is no quantitative documentation of the extent and timing of\nthese changes. This paper attempts to address this gap in the literature by\nlooking at the top 100 Alexa websites for over 25 years from the Internet\nArchive or the \"Wayback Machine\", archive.org. We study the changes in\npopularity, from Geocities and Yahoo! in the mid-to-late 1990s to the likes of\nGoogle, Facebook, and Tiktok of today. We also look at different categories of\nwebsites and their popularity over the years and find evidence for the decline\nin popularity of news and education-related websites, which have been replaced\nby streaming media and social networking sites. We explore the emergence and\nrelative prevalence of different MIME-types (text vs. image vs. video vs.\njavascript and json) and study whether the use of text on the Internet is\ndeclining.",
    "descriptor": "\nComments: To appear at The ACM Web Conference 2022\n",
    "authors": [
      "Vibhor Agarwal",
      "Nishanth Sastry"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.08239"
  },
  {
    "id": "arXiv:2202.08246",
    "title": "Galois connecting call-by-value and call-by-name",
    "abstract": "We establish a general framework for reasoning about the relationship between\ncall-by-value and call-by-name.\nIn languages with side-effects, call-by-value and call-by-name executions of\nprograms often have different, but related, observable behaviours. For example,\nif a program might diverge but otherwise has no side-effects, then whenever it\nterminates under call-by-value, it terminates with the same result under\ncall-by-name. We propose a technique for stating and proving these properties.\nThe key ingredient is Levy's call-by-push-value calculus, which we use as a\nframework for reasoning about evaluation orders. We construct maps between the\ncall-by-value and call-by-name interpretations of types. We then identify\nproperties of side-effects that imply these maps form a Galois connection.\nThese properties hold for some side-effects (such as divergence), but not\nothers (such as mutable state). This gives rise to a general reasoning\nprinciple that relates call-by-value and call-by-name. We apply the reasoning\nprinciple to example side-effects including divergence and nondeterminism.",
    "descriptor": "",
    "authors": [
      "Dylan McDermott",
      "Alan Mycroft"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2202.08246"
  },
  {
    "id": "arXiv:2202.08248",
    "title": "Preconditioners for computing multiple solutions in three-dimensional  fluid topology optimization",
    "abstract": "Topology optimization problems generally support multiple local minima, and\nreal-world applications are typically three-dimensional. In previous work [I.\nP. A. Papadopoulos, P. E. Farrell, and T. M. Surowiec, Computing multiple\nsolutions of topology optimization problems, SIAM Journal on Scientific\nComputing, (2021)], the authors developed the deflated barrier method, an\nalgorithm that can systematically compute multiple solutions of topology\noptimization problems. In this work we develop preconditioners for the linear\nsystems arising in the application of this method to Stokes flow, making it\npractical for use in three dimensions. In particular, we develop a nested block\npreconditioning approach which reduces the linear systems to solving two\nsymmetric positive-definite matrices and an augmented momentum block. An\naugmented Lagrangian term is used to control the innermost Schur complement and\nwe apply a geometric multigrid method with a kernel-capturing relaxation method\nfor the augmented momentum block. We present multiple solutions in\nthree-dimensional examples computed using the proposed iterative solver.",
    "descriptor": "",
    "authors": [
      "Ioannis P. A. Papadopoulos",
      "Patrick E. Farrell"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.08248"
  },
  {
    "id": "arXiv:2202.08250",
    "title": "On Learning and Enforcing Latent Assessment Models using Binary Feedback  from Human Auditors Regarding Black-Box Classifiers",
    "abstract": "Algorithmic fairness literature presents numerous mathematical notions and\nmetrics, and also points to a tradeoff between them while satisficing some or\nall of them simultaneously. Furthermore, the contextual nature of fairness\nnotions makes it difficult to automate bias evaluation in diverse algorithmic\nsystems. Therefore, in this paper, we propose a novel model called latent\nassessment model (LAM) to characterize binary feedback provided by human\nauditors, by assuming that the auditor compares the classifier's output to his\nor her own intrinsic judgment for each input. We prove that individual and\ngroup fairness notions are guaranteed as long as the auditor's intrinsic\njudgments inherently satisfy the fairness notion at hand, and are relatively\nsimilar to the classifier's evaluations. We also demonstrate this relationship\nbetween LAM and traditional fairness notions on three well-known datasets,\nnamely COMPAS, German credit and Adult Census Income datasets. Furthermore, we\nalso derive the minimum number of feedback samples needed to obtain PAC\nlearning guarantees to estimate LAM for black-box classifiers. These guarantees\nare also validated via training standard machine learning algorithms on real\nbinary feedback elicited from 400 human auditors regarding COMPAS.",
    "descriptor": "\nComments: Submitted to ACM FAccT 22. arXiv admin note: text overlap with arXiv:2107.01277\n",
    "authors": [
      "Mukund Telukunta",
      "Venkata Sriram Siddhardh Nadendla"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08250"
  },
  {
    "id": "arXiv:2110.11254",
    "title": "Quantum Teleportation with One Classical Bit",
    "abstract": "Quantum teleportation allows one to transmit an arbitrary qubit from point A\nto point B using a pair of (pre-shared) entangled qubits and classical bits of\ninformation. The conventional protocol for teleportation uses two bits of\nclassical information and assumes that the sender has access to only one copy\nof the arbitrary qubit to the sent. Here, we ask whether we can do better than\ntwo bits of classical information if the sender has access to multiple copies\nof the qubit to be teleported. We place no restrictions on the qubit states.\nConsequently, we propose a modified quantum teleportation protocol that allows\nAlice to reset the state of the entangled pair to its initial state using only\nlocal operations. As a result, the proposed teleportation protocol requires the\ntransmission of only one classical bit with a probability greater than\none-half. This has implications for efficient quantum communications and\nsecurity of quantum cryptographic protocols based on quantum entanglement.",
    "descriptor": "\nComments: 6 pages, 1 figure, typos corrected\n",
    "authors": [
      "Abhishek Parakh"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)",
      "Cryptography and Security (cs.CR)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2110.11254"
  },
  {
    "id": "arXiv:2202.06105",
    "title": "On Federated Learning with Energy Harvesting Clients",
    "abstract": "Catering to the proliferation of Internet of Things devices and distributed\nmachine learning at the edge, we propose an energy harvesting federated\nlearning (EHFL) framework in this paper. The introduction of EH implies that a\nclient's availability to participate in any FL round cannot be guaranteed,\nwhich complicates the theoretical analysis. We derive novel convergence bounds\nthat capture the impact of time-varying device availabilities due to the random\nEH characteristics of the participating clients, for both parallel and local\nstochastic gradient descent (SGD) with non-convex loss functions. The results\nsuggest that having a uniform client scheduling that maximizes the minimum\nnumber of clients throughout the FL process is desirable, which is further\ncorroborated by the numerical experiments using a real-world FL task and a\nstate-of-the-art EH scheduler.",
    "descriptor": "\nComments: Full version of accepted ICASSP 2022 paper\n",
    "authors": [
      "Cong Shen",
      "Jing Yang",
      "Jie Xu"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06105"
  },
  {
    "id": "arXiv:2202.07679",
    "title": "Taking a Step Back with KCal: Multi-Class Kernel-Based Calibration for  Deep Neural Networks",
    "abstract": "Deep neural network (DNN) classifiers are often overconfident, producing\nmiscalibrated class probabilities. Most existing calibration methods either\nlack theoretical guarantees for producing calibrated outputs or reduce the\nclassification accuracy in the process. This paper proposes a new Kernel-based\ncalibration method called KCal. Unlike other calibration procedures, KCal does\nnot operate directly on the logits or softmax outputs of the DNN. Instead, it\nuses the penultimate-layer latent embedding to train a metric space in a\nsupervised manner. In effect, KCal amounts to a supervised dimensionality\nreduction of the neural network embedding, and generates a prediction using\nkernel density estimation on a holdout calibration set. We first analyze KCal\ntheoretically, showing that it enjoys a provable asymptotic calibration\nguarantee. Then, through extensive experiments, we confirm that KCal\nconsistently outperforms existing calibration methods in terms of both the\nclassification accuracy and the (confidence and class-wise) calibration error.",
    "descriptor": "",
    "authors": [
      "Zhen Lin",
      "Shubhendu Trivedi",
      "Jimeng Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.07679"
  },
  {
    "id": "arXiv:2202.07697",
    "title": "A new discrete theory of pseudoconvexity",
    "abstract": "Recently geometric hypergraphs that can be defined by intersections of\npseudohalfplanes with a finite point set were defined in a purely combinatorial\nway. This led to extensions of earlier results about points and halfplanes to\npseudohalfplanes, including polychromatic colorings and discrete Helly-type\ntheorems about pseudohalfplanes.\nHere we continue this line of research and introduce the notion of convex\nsets of such pseudohalfplane hypergraphs. In this context we prove several\nresults corresponding to classical results about convexity, namely Helly\nTheorem, Carath\\'eodory's Theorem, Kirchberger's Theorem, Separation Theorem,\nRadon's Theorem and the Cup-Cap Theorem. These results imply the respective\nresults about pseudoconvex sets in the plane defined using pseudohalfplanes.\nIt turns out that most of our results can be also proved using oriented\nmatroids and topological affine planes (TAPs) but our approach is different\nfrom both of them. Compared to oriented matroids, our theory is based on a\nlinear ordering of the vertex set which makes our definitions and proofs quite\ndifferent and perhaps more elementary. Compared to TAPs, which are continuous\nobjects, our proofs are purely combinatorial and again quite different in\nflavor. Altogether, we believe that our new approach can further our\nunderstanding of these fundamental convexity results.",
    "descriptor": "",
    "authors": [
      "Bal\u00e1zs Keszegh"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2202.07697"
  },
  {
    "id": "arXiv:2202.07727",
    "title": "A Subjective Quality Study for Video Frame Interpolation",
    "abstract": "Video frame interpolation (VFI) is one of the fundamental research areas in\nvideo processing and there has been extensive research on novel and enhanced\ninterpolation algorithms. The same is not true for quality assessment of the\ninterpolated content. In this paper, we describe a subjective quality study for\nVFI based on a newly developed video database, BVI-VFI. BVI-VFI contains 36\nreference sequences at three different frame rates and 180 distorted videos\ngenerated using five conventional and learning based VFI algorithms. Subjective\nopinion scores have been collected from 60 human participants, and then\nemployed to evaluate eight popular quality metrics, including PSNR, SSIM and\nLPIPS which are all commonly used for assessing VFI methods. The results\nindicate that none of these metrics provide acceptable correlation with the\nperceived quality on interpolated content, with the best-performing metric,\nLPIPS, offering a SROCC value below 0.6. Our findings show that there is an\nurgent need to develop a bespoke perceptual quality metric for VFI. The BVI-VFI\ndataset is publicly available and can be accessed at\nhttps://danielism97.github.io/BVI-VFI/.",
    "descriptor": "",
    "authors": [
      "Duolikun Danier",
      "Fan Zhang",
      "David Bull"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07727"
  },
  {
    "id": "arXiv:2202.07750",
    "title": "Nonverbal Sound Detection for Disordered Speech",
    "abstract": "Voice assistants have become an essential tool for people with various\ndisabilities because they enable complex phone- or tablet-based interactions\nwithout the need for fine-grained motor control, such as with touchscreens.\nHowever, these systems are not tuned for the unique characteristics of\nindividuals with speech disorders, including many of those who have a\nmotor-speech disorder, are deaf or hard of hearing, have a severe stutter, or\nare minimally verbal. We introduce an alternative voice-based input system\nwhich relies on sound event detection using fifteen nonverbal mouth sounds like\n\"pop,\" \"click,\" or \"eh.\" This system was designed to work regardless of ones'\nspeech abilities and allows full access to existing technology. In this paper,\nwe describe the design of a dataset, model considerations for real-world\ndeployment, and efforts towards model personalization. Our fully-supervised\nmodel achieves segment-level precision and recall of 88.6% and 88.4% on an\ninternal dataset of 710 adults, while achieving 0.31 false positives per hour\non aggressors such as speech. Five-shot personalization enables satisfactory\nperformance in 84.5% of cases where the generic model fails.",
    "descriptor": "\nComments: Accepted at ICASSP 2022\n",
    "authors": [
      "Colin Lea",
      "Zifang Huang",
      "Dhruv Jain",
      "Lauren Tooley",
      "Zeinab Liaghat",
      "Shrinath Thelapurath",
      "Leah Findlater",
      "Jeffrey P. Bigham"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.07750"
  },
  {
    "id": "arXiv:2202.07752",
    "title": "The treewidth and pathwidth of graph unions",
    "abstract": "For two graphs $G_1$ and $G_2$ on the same vertex set $[n]:=\\{1,2, \\ldots,\nn\\}$, and a permutation $\\varphi$ of $[n]$, the union of $G_1$ and $G_2$ along\n$\\varphi$ is the graph which is the union of $G_2$ and the graph obtained from\n$G_1$ by renaming its vertices according to $\\varphi$. We examine the behaviour\nof the treewidth and pathwidth of graphs under this \"gluing\" operation. We show\nthat under certain conditions on $G_1$ and $G_2$, we may bound those parameters\nfor such unions in terms of their values for the original graphs, regardless of\nwhat permutation $\\varphi$ we choose. In some cases, however, this is only\nachievable if $\\varphi$ is chosen carefully, while yet in others, it is always\nimpossible to achieve boundedness. More specifically, among other results, we\nprove that if $G_1$ has treewidth $k$ and $G_2$ has pathwidth $\\ell$, then they\ncan be united into a graph of treewidth at most $k + 3 \\ell + 1$. On the other\nhand, we show that for any natural number $c$ there exists a pair of trees\n$G_1$ and $G_2$ whose every union has treewidth more than $c$.",
    "descriptor": "",
    "authors": [
      "Bogdan Alecu",
      "Vadim Lozin",
      "Daniel A. Quiroz",
      "Roman Rabinovich",
      "Igor Razgon",
      "Viktor Zamaraev"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.07752"
  },
  {
    "id": "arXiv:2202.07755",
    "title": "Deep Learning-Assisted Co-registration of Full-Spectral Autofluorescence  Lifetime Microscopic Images with H&E-Stained Histology Images",
    "abstract": "Autofluorescence lifetime images reveal unique characteristics of endogenous\nfluorescence in biological samples. Comprehensive understanding and clinical\ndiagnosis rely on co-registration with the gold standard, histology images,\nwhich is extremely challenging due to the difference of both images. Here, we\nshow an unsupervised image-to-image translation network that significantly\nimproves the success of the co-registration using a conventional\noptimisation-based regression network, applicable to autofluorescence lifetime\nimages at different emission wavelengths. A preliminary blind comparison by\nexperienced researchers shows the superiority of our method on co-registration.\nThe results also indicate that the approach is applicable to various image\nformats, like fluorescence intensity images. With the registration, stitching\noutcomes illustrate the distinct differences of the spectral lifetime across an\nunstained tissue, enabling macro-level rapid visual identification of lung\ncancer and cellular-level characterisation of cell variants and common types.\nThe approach could be effortlessly extended to lifetime images beyond this\nrange and other staining technologies.",
    "descriptor": "\nComments: 21 pages, 9 figures, 5 equations, 1 table\n",
    "authors": [
      "Qiang Wang",
      "Susan Fernandes",
      "Gareth O. S. Williams",
      "Neil Finlayson",
      "Ahsan R. Akram",
      "Kevin Dhaliwal",
      "James R. Hopgood",
      "Marta Vallejo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2202.07755"
  },
  {
    "id": "arXiv:2202.07764",
    "title": "Paving the Way towards 800 Gbps Quantum-Secured Optical Channel  Deployment in Mission-Critical Environments",
    "abstract": "This article describes experimental research studies conducted towards\nunderstanding the implementation aspects of high-capacity quantum-secured\noptical channels in mission-critical metro-scale operational environments based\non Quantum Key Distribution (QKD) technology. The test bed for this research\nstudy was carefully designed to mimic such environments. To the best of our\nknowledge, this is the first time that an 800 Gbps quantum-secured optical\nchannel--along with several other Dense Wavelength Division Multiplexed (DWDM)\nchannels on the C-band and multiplexed with the QKD channel on the O-band--was\nestablished at distances up to 100 km, with secure-key rates relevant for\npractical industry use cases. In addition, during the course of these trials,\ntransporting a blockchain application over this established channel was\nutilized as a demonstration of securing a financial transaction in transit over\na quantum-secured optical channel. In a real-world operational environment,\ndeployment of such high-capacity quantum-secured optical channels multiplexed\nwith the quantum channel will inevitably introduce challenges due to their\nstrict requirements, such as high launch powers and polarization fluctuations.\nTherefore, in the course of this research, experimental studies were conducted\non the impact on the system performance--and specifically on the quantum\nchannel--of several degradation factors present in real-world operational\nenvironments, including inter-channel interference (due to Raman scattering and\nnonlinear effects), attenuation, polarization fluctuations and distance\ndependency. The findings of this research pave the way towards the deployment\nof QKD-secured optical channels in high-capacity, metro-scale, mission-critical\noperational environments, such as Inter-Data Center Interconnects.",
    "descriptor": "\nComments: 11 pages, 9 figures, 2 tables\n",
    "authors": [
      "Farzam Toudeh-Fallah",
      "Marco Pistoia",
      "Yasushi Kawakura",
      "Navid Moazzami",
      "David H. Kramer",
      "Robert I. Woodward",
      "Greg Sysak",
      "Benny John",
      "Omar Amer",
      "Antigoni O. Polychroniadou",
      "Jeffrey Lyon",
      "Suresh Shetty",
      "Tulasi D. Movva",
      "Sudhir Upadhyay",
      "Monik R. Behera",
      "Joseph A. Dolphin",
      "Paul A. Haigh",
      "James F. Dynes",
      "Andrew J. Shields"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)",
      "Optics (physics.optics)"
    ],
    "url": "https://arxiv.org/abs/2202.07764"
  },
  {
    "id": "arXiv:2202.07773",
    "title": "The efficacy and generalizability of conditional GANs for posterior  inference in physics-based inverse problems",
    "abstract": "In this work, we train conditional Wasserstein generative adversarial\nnetworks to effectively sample from the posterior of physics-based Bayesian\ninference problems. The generator is constructed using a U-Net architecture,\nwith the latent information injected using conditional instance normalization.\nThe former facilitates a multiscale inverse map, while the latter enables the\ndecoupling of the latent space dimension from the dimension of the measurement,\nand introduces stochasticity at all scales of the U-Net. We solve PDE-based\ninverse problems to demonstrate the performance of our approach in quantifying\nthe uncertainty in the inferred field. Further, we show the generator can learn\ninverse maps which are local in nature, which in turn promotes generalizability\nwhen testing with out-of-distribution samples.",
    "descriptor": "",
    "authors": [
      "Deep Ray",
      "Harisankar Ramaswamy",
      "Dhruv V. Patel",
      "Assad A. Oberai"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07773"
  },
  {
    "id": "arXiv:2202.07774",
    "title": "The pseudofinite monadic second order theory of finite words",
    "abstract": "We analyse the pseudofinite monadic second order theory of words over a fixed\nalphabet. That is we consider the shared monadic second order theory of finite\nwords over a fixed alphabet. In particular we give a straightforward human\nreadable theory which axiomatises the shared monadic second order theory of\nsuch words, working in a one-sorted first order framework. To each finite word\nw we attach a first order structure M(w) expanding the Boolean algebra of\nsubsets of the linear order underlying w. The analysis hinges on the fact that\nconcatenation of finite words interacts nicely with monadic second order logic,\nparticularly for the signature which we adopt. More precisely, we heavily\nexploit the fact working over this signature, for each natural number k,\nequivalence of (monadic second order versions of) words with respect to\nformulas of quantifier depth at most k is a congruence for concatenation. The\ncentral result of the paper is a proof that the theory theory which we\nintroduced is indeed an axiomatisation for the pseudofinite monadic second\norder theory of words.\nAs an application, the property of concatenation described above is then\nfurther exploited to present an alternative proof of a theorem connecting\nrecognisable languages and finitely generated free profinite monoids via\nextended Stone duality, due to Gehrke, Grigorieff, and Pin. Our proof makes no\nappeals to heavy machinery from duality theory.",
    "descriptor": "",
    "authors": [
      "Deacon Linkhorn"
    ],
    "subjectives": [
      "Logic (math.LO)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.07774"
  },
  {
    "id": "arXiv:2202.07786",
    "title": "Saturated Kripke Structures as Vietoris Coalgebras",
    "abstract": "We show that the category of coalgebras for the compact Vietoris endofunctor\n$\\mathbb{V}$ on the category Top of topological spaces and continuous mappings\nis isomorphic to the category of all modally saturated Kripke structures.\nExtending a result of Bezhanishvili, Fontaine and Venema, we also show that\nVietoris subcoalgebras as well as bisimulations admit topological closure and\nthat the category of Vietoris coalgebras has a terminal object.",
    "descriptor": "",
    "authors": [
      "Heinz-Peter Gumm",
      "Mona Taheri"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.07786"
  },
  {
    "id": "arXiv:2202.07795",
    "title": "The Biosensor based on electrochemical dynamics of fermentation in yeast  Saccharomyces Cerevisiae",
    "abstract": "The zymase activity of the yeast Saccharomyces Cerevisiae is sensitive to\nenvironmental parameters and is therefore used as a microbiological sensor for\nwater quality assessment, ecotoxicological characterization or environmental\nmonitoring. Comparing to bacterial bioluminescence approach, this method has no\ntoxicity, excludes usage of genetically modified microorganisms, and enables\nlow-cost express analysis. This work focuses on measuring the yeast\nfermentation dynamics based on multichannel pressure sensing and\nelectrochemical impedance spectroscopy (EIS). Measurement results are compared\nwith each other in terms of accuracy, reproducibility and ease of use in the\nfield conditions. It has been shown that EIS provides more information about\nionic dynamics of metabolic processes and requires less complex measurements.\nThe conducted experiments demonstrated the sensitivity of this approach for\nassessing biophotonic phenomena, non-chemical water treatments and impact of\nenvironmental stressors.",
    "descriptor": "",
    "authors": [
      "Serge Kernbach",
      "Olga Kernbach",
      "Igor Kuksin",
      "Andreas Kernbach",
      "Yury Nepomnyashchiy",
      "Timo Dochow",
      "Andrew Bobrov"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Robotics (cs.RO)",
      "Biological Physics (physics.bio-ph)",
      "Instrumentation and Detectors (physics.ins-det)"
    ],
    "url": "https://arxiv.org/abs/2202.07795"
  },
  {
    "id": "arXiv:2202.07796",
    "title": "Low Latency Real-Time Seizure Detection Using Transfer Deep Learning",
    "abstract": "Scalp electroencephalogram (EEG) signals inherently have a low\nsignal-to-noise ratio due to the way the signal is electrically transduced.\nTemporal and spatial information must be exploited to achieve accurate\ndetection of seizure events. Most popular approaches to seizure detection using\ndeep learning do not jointly model this information or require multiple passes\nover the signal, which makes the systems inherently non-causal. In this paper,\nwe exploit both simultaneously by converting the multichannel signal to a\ngrayscale image and using transfer learning to achieve high performance. The\nproposed system is trained end-to-end with only very simple pre- and\npostprocessing operations which are computationally lightweight and have low\nlatency, making them conducive to clinical applications that require real-time\nprocessing. We have achieved a performance of 42.05% sensitivity with 5.78\nfalse alarms per 24 hours on the development dataset of v1.5.2 of the Temple\nUniversity Hospital Seizure Detection Corpus. On a single-core CPU operating at\n1.7 GHz, the system runs faster than real-time (0.58 xRT), uses 16 Gbytes of\nmemory, and has a latency of 300 msec.",
    "descriptor": "",
    "authors": [
      "Vahid Khalkhali",
      "Nabila Shawki",
      "Vinit Shah",
      "Meysam Golmohammadi",
      "Iyad Obeid",
      "Joseph Picone"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07796"
  },
  {
    "id": "arXiv:2202.07816",
    "title": "ProsoSpeech: Enhancing Prosody With Quantized Vector Pre-training in  Text-to-Speech",
    "abstract": "Expressive text-to-speech (TTS) has become a hot research topic recently,\nmainly focusing on modeling prosody in speech. Prosody modeling has several\nchallenges: 1) the extracted pitch used in previous prosody modeling works have\ninevitable errors, which hurts the prosody modeling; 2) different attributes of\nprosody (e.g., pitch, duration and energy) are dependent on each other and\nproduce the natural prosody together; and 3) due to high variability of prosody\nand the limited amount of high-quality data for TTS training, the distribution\nof prosody cannot be fully shaped. To tackle these issues, we propose\nProsoSpeech, which enhances the prosody using quantized latent vectors\npre-trained on large-scale unpaired and low-quality text and speech data.\nSpecifically, we first introduce a word-level prosody encoder, which quantizes\nthe low-frequency band of the speech and compresses prosody attributes in the\nlatent prosody vector (LPV). Then we introduce an LPV predictor, which predicts\nLPV given word sequence. We pre-train the LPV predictor on large-scale text and\nlow-quality speech data and fine-tune it on the high-quality TTS dataset.\nFinally, our model can generate expressive speech conditioned on the predicted\nLPV. Experimental results show that ProsoSpeech can generate speech with richer\nprosody compared with baseline methods.",
    "descriptor": "\nComments: Accepted by ICASSP 2022\n",
    "authors": [
      "Yi Ren",
      "Ming Lei",
      "Zhiying Huang",
      "Shiliang Zhang",
      "Qian Chen",
      "Zhijie Yan",
      "Zhou Zhao"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.07816"
  },
  {
    "id": "arXiv:2202.07820",
    "title": "A Survey of Semen Quality Evaluation in Microscopic Videos Using  Computer Assisted Sperm Analysis",
    "abstract": "The Computer Assisted Sperm Analysis (CASA) plays a crucial role in male\nreproductive health diagnosis and Infertility treatment. With the development\nof the computer industry in recent years, a great of accurate algorithms are\nproposed. With the assistance of those novel algorithms, it is possible for\nCASA to achieve a faster and higher quality result. Since image processing is\nthe technical basis of CASA, including pre-processing,feature extraction,\ntarget detection and tracking, these methods are important technical steps in\ndealing with CASA. The various works related to Computer Assisted Sperm\nAnalysis methods in the last 30 years (since 1988) are comprehensively\nintroduced and analysed in this survey. To facilitate understanding, the\nmethods involved are analysed in the sequence of general steps in sperm\nanalysis. In other words, the methods related to sperm detection (localization)\nare first analysed, and then the methods of sperm tracking are analysed. Beside\nthis, we analyse and prospect the present situation and future of CASA.\nAccording to our work, the feasible for applying in sperm microscopic video of\nmethods mentioned in this review is explained. Moreover, existing challenges of\nobject detection and tracking in microscope video are potential to be solved\ninspired by this survey.",
    "descriptor": "",
    "authors": [
      "Wenwei Zhao",
      "Pingli Ma",
      "Chen Li",
      "Xiaoning Bu",
      "Shuojia Zou",
      "Tao Jang",
      "Marcin Grzegorzek"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07820"
  },
  {
    "id": "arXiv:2202.07823",
    "title": "Segmentation and Risk Score Prediction of Head and Neck Cancers in  PET/CT Volumes with 3D U-Net and Cox Proportional Hazard Neural Networks",
    "abstract": "We utilized a 3D nnU-Net model with residual layers supplemented by squeeze\nand excitation (SE) normalization for tumor segmentation from PET/CT images\nprovided by the Head and Neck Tumor segmentation chal-lenge (HECKTOR). Our\nproposed loss function incorporates the Unified Fo-cal and Mumford-Shah losses\nto take the advantage of distribution, region, and boundary-based loss\nfunctions. The results of leave-one-out-center-cross-validation performed on\ndifferent centers showed a segmentation performance of 0.82 average Dice score\n(DSC) and 3.16 median Hausdorff Distance (HD), and our results on the test set\nachieved 0.77 DSC and 3.01 HD. Following lesion segmentation, we proposed\ntraining a case-control proportional hazard Cox model with an MLP neural net\nbackbone to predict the hazard risk score for each discrete lesion. This hazard\nrisk prediction model (CoxCC) was to be trained on a number of PET/CT radiomic\nfeatures extracted from the segmented lesions, patient and lesion demographics,\nand encoder features provided from the penultimate layer of a multi-input 2D\nPET/CT convolutional neural network tasked with predicting time-to-event for\neach lesion. A 10-fold cross-validated CoxCC model resulted in a c-index\nvalidation score of 0.89, and a c-index score of 0.61 on the HECKTOR challenge\ntest dataset.",
    "descriptor": "",
    "authors": [
      "Fereshteh Yousefirizi",
      "Ian Janzen",
      "Natalia Dubljevic",
      "Yueh-En Liu",
      "Chloe Hill",
      "Calum MacAulay",
      "Arman Rahmim"
    ],
    "subjectives": [
      "Medical Physics (physics.med-ph)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.07823"
  },
  {
    "id": "arXiv:2202.07866",
    "title": "Fixed-time Synchronization of Networked Uncertain Euler-Lagrange Systems",
    "abstract": "This paper considers the fixed-time control problem of a multi-agent system\ncomposed of a class of Euler-Lagrange dynamics with parametric uncertainty and\na dynamic leader under a directed communication network. A distributed\nfixed-time observer is first proposed to estimate the desired trajectory and\nthen a fixed-time controller is constructed by transforming uncertain\nEuler-Lagrange systems into second-order systems and utilizing the backstepping\ndesign procedure. The overall design guarantees that the synchronization errors\nconverge to zero in a prescribed time independent of initial conditions. The\ncontrol design conditions can also be relaxed for a weaker finite-time control\nrequirement.",
    "descriptor": "",
    "authors": [
      "Yi Dong",
      "Zhiyong Chen"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.07866"
  },
  {
    "id": "arXiv:2202.07930",
    "title": "Willems' fundamental lemma for linear descriptor systems and its use for  data-driven output-feedback MPC",
    "abstract": "In this paper we investigate data-driven predictive control of discrete-time\nlinear descriptor systems. Specifically, we give a tailored variant of Willems'\nfundamental lemma, which shows that for descriptor systems the non-parametric\nmodelling via a Hankel matrix requires less data compared to linear\ntime-invariant systems without algebraic constraints. Moreover, we use this\ndescription to propose a data-driven framework for optimal control and\npredictive control of discrete-time linear descriptor systems. For the latter,\nwe provide a sufficient stability condition for receding-horizon control before\nwe illustrate our findings with an example.",
    "descriptor": "",
    "authors": [
      "Philipp Schmitz",
      "Timm Faulwasser",
      "Karl Worthmann"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.07930"
  },
  {
    "id": "arXiv:2202.07955",
    "title": "Robust Nonparametric Distribution Forecast with Backtest-based Bootstrap  and Adaptive Residual Selection",
    "abstract": "Distribution forecast can quantify forecast uncertainty and provide various\nforecast scenarios with their corresponding estimated probabilities. Accurate\ndistribution forecast is crucial for planning - for example when making\nproduction capacity or inventory allocation decisions. We propose a practical\nand robust distribution forecast framework that relies on backtest-based\nbootstrap and adaptive residual selection. The proposed approach is robust to\nthe choice of the underlying forecasting model, accounts for uncertainty around\nthe input covariates, and relaxes the independence between residuals and\ncovariates assumption. It reduces the Absolute Coverage Error by more than 63%\ncompared to the classic bootstrap approaches and by 2% - 32% compared to a\nvariety of State-of-the-Art deep learning approaches on in-house product sales\ndata and M4-hourly competition data.",
    "descriptor": "\nComments: ICASSP 2022 - \"Copyright 20XX IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising/promotional purposes, creating new collective works, for resale/redistribution to servers/lists, or reuse of any copyrighted component of this work in other works.\"\n",
    "authors": [
      "Longshaokan Wang",
      "Lingda Wang",
      "Mina Georgieva",
      "Paulo Machado",
      "Abinaya Ulagappa",
      "Safwan Ahmed",
      "Yan Lu",
      "Arjun Bakshi",
      "Farhad Ghassemi"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07955"
  },
  {
    "id": "arXiv:2202.07965",
    "title": "GAN Estimation of Lipschitz Optimal Transport Maps",
    "abstract": "This paper introduces the first statistically consistent estimator of the\noptimal transport map between two probability distributions, based on neural\nnetworks. Building on theoretical and practical advances in the field of\nLipschitz neural networks, we define a Lipschitz-constrained generative\nadversarial network penalized by the quadratic transportation cost. Then, we\ndemonstrate that, under regularity assumptions, the obtained generator\nconverges uniformly to the optimal transport map as the sample size increases\nto infinity. Furthermore, we show through a number of numerical experiments\nthat the learnt mapping has promising performances. In contrast to previous\nwork tackling either statistical guarantees or practicality, we provide an\nexpressive and feasible estimator which paves way for optimal transport\napplications where the asymptotic behaviour must be certified.",
    "descriptor": "",
    "authors": [
      "Alberto Gonz\u00e1lez-Sanz",
      "Lucas de Lara",
      "Louis B\u00e9thune",
      "Jean-Michel Loubes"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07965"
  },
  {
    "id": "arXiv:2202.07971",
    "title": "Large-System Insensitivity of Zero-Waiting Load Balancing Algorithms",
    "abstract": "This paper studies the sensitivity (or insensitivity) of a class of load\nbalancing algorithms that achieve asymptotic zero-waiting in the\nsub-Halfin-Whitt regime, named LB-zero. Most existing results on zero-waiting\nload balancing algorithms assume the service time distribution is exponential.\nThis paper establishes the {\\em large-system insensitivity} of LB-zero for jobs\nwhose service time follows a Coxian distribution with a finite number of\nphases. This result suggests that LB-zero achieves asymptotic zero-waiting for\na large class of service time distributions, which is confirmed in our\nsimulations. To prove this result, this paper develops a new technique, called\n\"Iterative State-Space Peeling\" (or ISSP for short). ISSP first identifies an\niterative relation between the upper and lower bounds on the queue states and\nthen proves that the system lives near the fixed point of the iterative bounds\nwith a high probability. Based on ISSP, the steady-state distribution of the\nsystem is further analyzed by applying Stein's method in the neighborhood of\nthe fixed point. ISSP, like state-space collapse in heavy-traffic analysis, is\na general approach that may be used to study other complex stochastic systems.",
    "descriptor": "",
    "authors": [
      "Xin Liu",
      "Kang Gong",
      "Lei Ying"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2202.07971"
  },
  {
    "id": "arXiv:2202.07981",
    "title": "m-Nearly k-Universal Words -- Investigating Simon Congruence",
    "abstract": "Determining the index of the Simon congruence is a long outstanding open\nproblem. Two words $u$ and $v$ are called Simon congruent if they have the same\nset of scattered factors, which are parts of the word in the correct order but\nnot necessarily consecutive, e.g., $\\mathtt{oath}$ is a scattered factor of\n$\\mathtt{logarithm}$. Following the idea of scattered factor $k$-universality,\nwe investigate $m$-nearly $k$-universality, i.e., words where $m$ scattered\nfactors of length $k$ are absent, w.r.t. Simon congruence. We present a full\ncharacterisation as well as the index of the congruence for $m=1$. For $m\\neq\n1$, we show some results if in addition $w$ is $(k-1)$-universal as well as\nsome further insights for different $m$.",
    "descriptor": "",
    "authors": [
      "Pamela Fleischmann",
      "Lukas Haschke",
      "Annika Huch",
      "Annika Mayrock",
      "Dirk Nowotka"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07981"
  },
  {
    "id": "arXiv:2202.07983",
    "title": "ADAM Challenge: Detecting Age-related Macular Degeneration from Fundus  Images",
    "abstract": "Age-related macular degeneration (AMD) is the leading cause of visual\nimpairment among elderly in the world. Early detection of AMD is of great\nimportance as the vision loss caused by AMD is irreversible and permanent.\nColor fundus photography is the most cost-effective imaging modality to screen\nfor retinal disorders. \\textcolor{red}{Recently, some algorithms based on deep\nlearning had been developed for fundus image analysis and automatic AMD\ndetection. However, a comprehensive annotated dataset and a standard evaluation\nbenchmark are still missing.} To deal with this issue, we set up the Automatic\nDetection challenge on Age-related Macular degeneration (ADAM) for the first\ntime, held as a satellite event of the ISBI 2020 conference. The ADAM challenge\nconsisted of four tasks which cover the main topics in detecting AMD from\nfundus images, including classification of AMD, detection and segmentation of\noptic disc, localization of fovea, and detection and segmentation of lesions.\nThe ADAM challenge has released a comprehensive dataset of 1200 fundus images\nwith the category labels of AMD, the pixel-wise segmentation masks of the full\noptic disc and lesions (drusen, exudate, hemorrhage, scar, and other), as well\nas the location coordinates of the macular fovea. A uniform evaluation\nframework has been built to make a fair comparison of different models. During\nthe ADAM challenge, 610 results were submitted for online evaluation, and\nfinally, 11 teams participated in the onsite challenge. This paper introduces\nthe challenge, dataset, and evaluation methods, as well as summarizes the\nmethods and analyzes the results of the participating teams of each task. In\nparticular, we observed that ensembling strategy and clinical prior knowledge\ncan better improve the performances of the deep learning models.",
    "descriptor": "\nComments: 22pages, 10figures\n",
    "authors": [
      "Huihui Fang",
      "Fei Li",
      "Huazhu Fu",
      "Xu Sun",
      "Xingxing Cao",
      "Fengbin Lin",
      "Jaemin Son",
      "Sunho Kim",
      "Gwenole Quellec",
      "Sarah Matta",
      "Sharath M Shankaranarayana",
      "Yi-Ting Chen",
      "Chuen-heng Wang",
      "Nisarg A. Shah",
      "Chia-Yen Lee",
      "Chih-Chung Hsu",
      "Hai Xie",
      "Baiying Lei",
      "Ujjwal Baid",
      "Shubham Innani",
      "Kang Dang",
      "Wenxiu Shi",
      "Ravi Kamble",
      "Nitin Singhal",
      "Jos\u00e9 Ignacio Orlando",
      "Hrvoje Bogunovi\u0107",
      "Xiulan Zhang",
      "Yanwu Xu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07983"
  },
  {
    "id": "arXiv:2202.07988",
    "title": "On the Self Shuffle Language",
    "abstract": "The shuffle product \\(u\\shuffle v\\) of two words \\(u\\) and \\(v\\) is the set\nof all words which can be obtained by interleaving \\(u\\) and \\(v\\). Motivated\nby the paper \\emph{The Shuffle Product: New Research Directions} by Restivo\n(2015) we investigate a special case of the shuffle product. In this work we\nconsider the shuffle of a word with itself called the \\emph{self shuffle} or\n\\emph{shuffle square}, showing first that the self shuffle language and the\nshuffle of the language are in general different sets. We prove that the\nlanguage of all words arising as a self shuffle of some word is context\nsensitive but not context free. Furthermore, we show that the self shuffle \\(w\n\\shuffle w\\) uniquely determines \\(w\\).",
    "descriptor": "",
    "authors": [
      "Pamela Fleischmann",
      "Tero Harju",
      "Lukas Haschke",
      "Jonas H\u00f6fer",
      "Dirk Nowotka"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07988"
  },
  {
    "id": "arXiv:2202.07998",
    "title": "DeepTx: Deep Learning Beamforming with Channel Prediction",
    "abstract": "Machine learning algorithms have recently been considered for many tasks in\nthe field of wireless communications. Previously, we have proposed the use of a\ndeep fully convolutional neural network (CNN) for receiver processing and shown\nit to provide considerable performance gains. In this study, we focus on\nmachine learning algorithms for the transmitter. In particular, we consider\nbeamforming and propose a CNN which, for a given uplink channel estimate as\ninput, outputs downlink channel information to be used for beamforming. The CNN\nis trained in a supervised manner considering both uplink and downlink\ntransmissions with a loss function that is based on UE receiver performance.\nThe main task of the neural network is to predict the channel evolution between\nuplink and downlink slots, but it can also learn to handle inefficiencies and\nerrors in the whole chain, including the actual beamforming phase. The provided\nnumerical experiments demonstrate the improved beamforming performance.",
    "descriptor": "\nComments: 24 pages, this work has been submitted to the IEEE for possible publication\n",
    "authors": [
      "Janne M.J. Huttunen",
      "Dani Korpi",
      "Mikko~Honkala"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07998"
  },
  {
    "id": "arXiv:2202.08021",
    "title": "Toward Development of Machine Learned Techniques for Production of  Compact Kinetic Models",
    "abstract": "Chemical kinetic models are an essential component in the development and\noptimisation of combustion devices through their coupling to multi-dimensional\nsimulations such as computational fluid dynamics (CFD). Low-dimensional kinetic\nmodels which retain good fidelity to the reality are needed, the production of\nwhich requires considerable human-time cost and expert knowledge. Here, we\npresent a novel automated compute intensification methodology to produce\noverly-reduced and optimised (compact) chemical kinetic models. This algorithm,\ntermed Machine Learned Optimisation of Chemical Kinetics (MLOCK),\nsystematically perturbs each of the four sub-models of a chemical kinetic model\nto discover what combinations of terms results in a good model. A virtual\nreaction network comprised of n species is first obtained using conventional\nmechanism reduction. To counteract the imposed decrease in model performance,\nthe weights (virtual reaction rate constants) of important connections (virtual\nreactions) between each node (species) of the virtual reaction network are\nnumerically optimised to replicate selected calculations across four sequential\nphases. The first version of MLOCK, (MLOCK1.0) simultaneously perturbs all\nthree virtual Arrhenius reaction rate constant parameters for important\nconnections and assesses the suitability of the new parameters through\nobjective error functions, which quantify the error in each compact model\ncandidate's calculation of the optimisation targets, which may be comprised of\ndetailed model calculations and/or experimental data. MLOCK1.0 is demonstrated\nby creating compact models for the archetypal case of methane air combustion.\nIt is shown that the NUGMECH1.0 detailed model comprised of 2,789 species is\nreliably compacted to 15 species (nodes), whilst retaining an overall fidelity\nof ~87% to the detailed model calculations, outperforming the prior\nstate-of-art.",
    "descriptor": "",
    "authors": [
      "Mark Kelly",
      "Mark Fortune",
      "Gilles Bourque",
      "Stephen Dooley"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.08021"
  },
  {
    "id": "arXiv:2202.08024",
    "title": "Towards AutoQML: A Cloud-Based Automated Circuit Architecture Search  Framework",
    "abstract": "The learning process of classical machine learning algorithms is tuned by\nhyperparameters that need to be customized to best learn and generalize from an\ninput dataset. In recent years, Quantum Machine Learning (QML) has been gaining\ntraction as a possible application of quantum computing which may provide\nquantum advantage in the future. However, quantum versions of classical machine\nlearning algorithms introduce a plethora of additional parameters and circuit\nvariations that have their own intricacies in being tuned.\nIn this work, we take the first steps towards Automated Quantum Machine\nLearning (AutoQML). We propose a concrete description of the problem, and then\ndevelop a classical-quantum hybrid cloud architecture that allows for\nparallelized hyperparameter exploration and model training.\nAs an application use-case, we train a quantum Generative Adversarial neural\nNetwork (qGAN) to generate energy prices that follow a known historic data\ndistribution. Such a QML model can be used for various applications in the\nenergy economics sector.",
    "descriptor": "\nComments: 8 pages, to appear in QSA 2022 (IEEE ICSA 2022)\n",
    "authors": [
      "Ra\u00fal Berganza G\u00f3mez",
      "Corey O'Meara",
      "Giorgio Cortiana",
      "Christian B. Mendl",
      "Juan Bernab\u00e9-Moreno"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2202.08024"
  },
  {
    "id": "arXiv:2202.08028",
    "title": "APPLADE: Adjustable Plug-and-play Audio Declipper Combining DNN with  Sparse Optimization",
    "abstract": "In this paper, we propose an audio declipping method that takes advantages of\nboth sparse optimization and deep learning. Since sparsity-based audio\ndeclipping methods have been developed upon constrained optimization, they are\nadjustable and well-studied in theory. However, they always uniformly promote\nsparsity and ignore the individual properties of a signal. Deep neural network\n(DNN)-based methods can learn the properties of target signals and use them for\naudio declipping. Still, they cannot perform well if the training data have\nmismatches and/or constraints in the time domain are not imposed. In the\nproposed method, we use a DNN in an optimization algorithm. It is inspired by\nan idea called plug-and-play (PnP) and enables us to promote sparsity based on\nthe learned information of data, considering constraints in the time domain.\nOur experiments confirmed that the proposed method is stable and robust to\nmismatches between training and test data.",
    "descriptor": "\nComments: 5 pages, 7 figures, accepted to IEEE Int. Conf. Acoust. Speech Signal Process. (ICASSP), 2022\n",
    "authors": [
      "Tomoro Tanaka",
      "Kohei Yatabe",
      "Masahiro Yasuda",
      "Yasuhiro Oikawa"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.08028"
  },
  {
    "id": "arXiv:2202.08035",
    "title": "The Pareto cover problem",
    "abstract": "We introduce the problem of finding a set $B$ of $k$ points in $[0,1]^n$ such\nthat the expected cost of the cheapest point in $B$ that dominates a random\npoint from $[0,1]^n$ is minimized. We study the case where the coordinates of\nthe random points are independently distributed and the cost function is\nlinear. This problem arises naturally in various application areas where\ncustomers' requests are satisfied based on predefined products, each\ncorresponding to a subset of features. We show that the problem is NP-hard\nalready for $k=2$ when each coordinate is drawn from $\\{0,1\\}$, and obtain an\nFPTAS for general fixed $k$ under mild assumptions on the distributions.",
    "descriptor": "\nComments: 33 pages\n",
    "authors": [
      "Bento Natura",
      "Meike Neuwohner",
      "Stefan Weltge"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Computational Geometry (cs.CG)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.08035"
  },
  {
    "id": "arXiv:2202.08053",
    "title": "Image translation of Ultrasound to Pseudo Anatomical Display Using  Artificial Intelligence",
    "abstract": "Ultrasound is the second most used modality in medical imaging. It is cost\neffective, hazardless, portable and implemented routinely in numerous clinical\nprocedures. Nonetheless, image quality is characterized by granulated\nappearance, poor SNR and speckle noise. Specific for malignant tumors, the\nmargins are blurred and indistinct. Thus, there is a great need for improving\nultrasound image quality. We hypothesize that this can be achieved by\ntranslation into a more realistic anatomic display, using neural networks. In\norder to achieve this goal, the preferable approach would be to use a set of\npaired images. However, this is practically impossible in our case. Therefore,\nCycleGAN was used, to learn each domain properties separately and enforce cross\ndomain cycle consistency. The two datasets which were used for training the\nmodel were \"Breast Ultrasound Images\" (BUSI) and a set of optic images of\npoultry breast tissue samples acquired at our lab. The generated pseudo\nanatomical images provide improved visual discrimination of the lesions with\nclearer border definition and pronounced contrast. Furthermore, the algorithm\nmanages to overcome the acoustic shadows artifacts commonly appearing in\nultrasonic images. In order to evaluate the preservation of the anatomical\nfeatures, the lesions in the ultrasonic images and the generated pseudo\nanatomical images were both automatically segmented and compared. This\ncomparison yielded median dice score of 0.78 for the benign tumors and 0.43 for\nthe malignancies. Median lesion center error of 2.38% and 8.42% for the benign\nand malignancies respectively and median area error index of 0.77% and 5.06%\nfor the benign and malignancies respectively. In conclusion, these generated\npseudo anatomical images, which are presented in a more intuitive way, preserve\ntissue anatomy and can potentially simplify the diagnosis and improve the\nclinical outcome.",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Lilach Barkat",
      "Moti Freiman",
      "Haim Azhari"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.08053"
  },
  {
    "id": "arXiv:2202.08061",
    "title": "Holonomic control of a three-qubits system in an NV center using a  near-term quantum computer",
    "abstract": "The holonomic approach to controlling (nitrogen-vacancy) NV-center qubits\nprovides an elegant way of theoretically devising universal quantum gates that\noperate on qubits via calculable microwave pulses. There is, however, a lack of\nsimulated results from the theory of holonomic control of quantum registers\nwith more than two qubits describing the transition between the dark states. In\nlight of this, we have been experimenting with the IBM Quantum Experience\ntechnology to determine the capabilities of simulating holonomic control of\nNV-centers for three qubits describing an eight-level system that produces a\nnon-Abelian geometric phase. The tunability of the geometric phase via the\ndetuning frequency is demonstrated through the high fidelity (about 80%) of\n3-qubit off-resonant holonomic gates over the on-resonant ones. The transition\nbetween the dark states shows the alignment of the gate dark state with the\nqubits initial state hence decoherence of the multi-qubit system is\nwell-controlled through a 0.33pi rotation. The electron return probability can\nexhibit spin-orbit coupling-like behavior as observed in topological materials\nbased on the extra geometric phase.",
    "descriptor": "\nComments: 4 figures\n",
    "authors": [
      "Shaman Bhattacharyya",
      "Somnath Bhattacharyya"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.08061"
  },
  {
    "id": "arXiv:2202.08064",
    "title": "Learning a Single Neuron for Non-monotonic Activation Functions",
    "abstract": "We study the problem of learning a single neuron $\\mathbf{x}\\mapsto\n\\sigma(\\mathbf{w}^T\\mathbf{x})$ with gradient descent (GD). All the existing\npositive results are limited to the case where $\\sigma$ is monotonic. However,\nit is recently observed that non-monotonic activation functions outperform the\ntraditional monotonic ones in many applications. To fill this gap, we establish\nlearnability without assuming monotonicity. Specifically, when the input\ndistribution is the standard Gaussian, we show that mild conditions on $\\sigma$\n(e.g., $\\sigma$ has a dominating linear part) are sufficient to guarantee the\nlearnability in polynomial time and polynomial samples. Moreover, with a\nstronger assumption on the activation function, the condition of input\ndistribution can be relaxed to a non-degeneracy of the marginal distribution.\nWe remark that our conditions on $\\sigma$ are satisfied by practical\nnon-monotonic activation functions, such as SiLU/Swish and GELU. We also\ndiscuss how our positive results are related to existing negative results on\ntraining two-layer neural networks.",
    "descriptor": "\nComments: AISTATS 2022\n",
    "authors": [
      "Lei Wu"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.08064"
  },
  {
    "id": "arXiv:2202.08082",
    "title": "Formulating Beurling LASSO for Source Separation via Proximal Gradient  Iteration",
    "abstract": "Beurling LASSO generalizes the LASSO problem to finite Radon measures\nregularized via their total variation. Despite its theoretical appeal, this\nspace is hard to parametrize, which poses an algorithmic challenge. We propose\na formulation of continuous convolutional source separation with Beurling LASSO\nthat avoids the explicit computation of the measures and instead employs the\nduality transform of the proximal mapping.",
    "descriptor": "",
    "authors": [
      "S\u00f6ren Schulze",
      "Emily J. King"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Retrieval (cs.IR)",
      "Functional Analysis (math.FA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.08082"
  },
  {
    "id": "arXiv:2202.08119",
    "title": "The Parameterized Complexity of Quantum Verification",
    "abstract": "We initiate the study of parameterized complexity of $\\textsf{QMA}$ problems\nin terms of the number of non-Clifford gates in the problem description. We\nshow that for the problem of parameterized quantum circuit satisfiability,\nthere exists a classical algorithm solving the problem with a runtime scaling\nexponentially in the number of non-Clifford gates but only polynomially with\nthe system size. This result follows from our main result, that for any\nClifford + $t$ $T$-gate quantum circuit satisfiability problem, the search\nspace of optimal witnesses can be reduced to a stabilizer subspace isomorphic\nto at most $t$ qubits (independent of the system size). Furthermore, we derive\nnew lower bounds on the $T$-count of circuit satisfiability instances and the\n$T$-count of the $W$-state assuming the classical exponential time hypothesis\n($\\textsf{ETH}$). Lastly, we explore the parameterized complexity of the\nquantum non-identity check problem.",
    "descriptor": "",
    "authors": [
      "Srinivasan Arunachalam",
      "Sergey Bravyi",
      "Chinmay Nirkhe",
      "Bryan O'Gorman"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.08119"
  },
  {
    "id": "arXiv:2202.08147",
    "title": "Modular multi-source prediction of drug side-effects with DruGNN",
    "abstract": "Drug Side-Effects (DSEs) have a high impact on public health, care system\ncosts, and drug discovery processes. Predicting the probability of\nside-effects, before their occurrence, is fundamental to reduce this impact, in\nparticular on drug discovery. Candidate molecules could be screened before\nundergoing clinical trials, reducing the costs in time, money, and health of\nthe participants. Drug side-effects are triggered by complex biological\nprocesses involving many different entities, from drug structures to\nprotein-protein interactions. To predict their occurrence, it is necessary to\nintegrate data from heterogeneous sources. In this work, such heterogeneous\ndata is integrated into a graph dataset, expressively representing the\nrelational information between different entities, such as drug molecules and\ngenes. The relational nature of the dataset represents an important novelty for\ndrug side-effect predictors. Graph Neural Networks (GNNs) are exploited to\npredict DSEs on our dataset with very promising results. GNNs are deep learning\nmodels that can process graph-structured data, with minimal information loss,\nand have been applied on a wide variety of biological tasks. Our experimental\nresults confirm the advantage of using relationships between data entities,\nsuggesting interesting future developments in this scope. The experimentation\nalso shows the importance of specific subsets of data in determining\nassociations between drugs and side-effects.",
    "descriptor": "\nComments: 19 pages, 3 figures\n",
    "authors": [
      "Pietro Bongini",
      "Franco Scarselli",
      "Monica Bianchini",
      "Giovanna Maria Dimitri",
      "Niccol\u00f2 Pancino",
      "Pietro Li\u00f2"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08147"
  },
  {
    "id": "arXiv:2202.08164",
    "title": "Voice Filter: Few-shot text-to-speech speaker adaptation using voice  conversion as a post-processing module",
    "abstract": "State-of-the-art text-to-speech (TTS) systems require several hours of\nrecorded speech data to generate high-quality synthetic speech. When using\nreduced amounts of training data, standard TTS models suffer from speech\nquality and intelligibility degradations, making training low-resource TTS\nsystems problematic. In this paper, we propose a novel extremely low-resource\nTTS method called Voice Filter that uses as little as one minute of speech from\na target speaker. It uses voice conversion (VC) as a post-processing module\nappended to a pre-existing high-quality TTS system and marks a conceptual shift\nin the existing TTS paradigm, framing the few-shot TTS problem as a VC task.\nFurthermore, we propose to use a duration-controllable TTS system to create a\nparallel speech corpus to facilitate the VC task. Results show that the Voice\nFilter outperforms state-of-the-art few-shot speech synthesis techniques in\nterms of objective and subjective metrics on one minute of speech on a diverse\nset of voices, while being competitive against a TTS model built on 30 times\nmore data.",
    "descriptor": "\nComments: Accepted at ICASSP 2022\n",
    "authors": [
      "Adam Gabry\u015b",
      "Goeric Huybrechts",
      "Manuel Sam Ribeiro",
      "Chung-Ming Chien",
      "Julian Roth",
      "Giulia Comini",
      "Roberto Barra-Chicote",
      "Bartek Perz",
      "Jaime Lorenzo-Trueba"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08164"
  },
  {
    "id": "arXiv:2202.08177",
    "title": "Generative modeling with projected entangled-pair states",
    "abstract": "We argue and demonstrate that projected entangled-pair states (PEPS)\noutperform matrix product states significantly for the task of generative\nmodeling of datasets with an intrinsic two-dimensional structure such as\nimages. Our approach builds on a recently introduced algorithm for sampling\nPEPS, which allows for the efficient optimization and sampling of the\ndistributions.",
    "descriptor": "",
    "authors": [
      "Tom Vieijra",
      "Laurens Vanderstraeten",
      "Frank Verstraete"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08177"
  },
  {
    "id": "arXiv:2202.08179",
    "title": "The Helmholtz problem in slowly varying waveguides at locally resonant  frequencies",
    "abstract": "This article aims to present a general study of the Helmholtz problem in\nslowly varying waveguides. This work is of particular interest at locally\nresonant frequencies, where a phenomenon close to the tunnel effect for\nSchr\\\"odinger equation in quantum mechanics can be observed. In this situation,\nlocally resonant modes propagate in the waveguide under the form of Airy\nfunctions. Using previous mathematical results on the Schr\\\"odinger equation,\nwe prove the existence of a unique solution to the Helmholtz source problem\nwith outgoing conditions in such waveguides. We provide an explicit modal\napproximation of this solution, as well as a control of the approximation error\nin H1loc. The main theorem is proved in the case of a waveguide with a\nmonotonously varying profile and then generalized using a matching strategy. We\nfinally validate the modal approximation by comparing it to numerical solutions\nbased on the finite element method.",
    "descriptor": "",
    "authors": [
      "Eric Bonnetier",
      "Ang\u00e8le Niclas",
      "Laurent Seppecher",
      "Gr\u00e9gory Vial"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.08179"
  },
  {
    "id": "arXiv:2202.08180",
    "title": "Geometry of the Minimum Volume Confidence Sets",
    "abstract": "Computation of confidence sets is central to data science and machine\nlearning, serving as the workhorse of A/B testing and underpinning the\noperation and analysis of reinforcement learning algorithms. This paper studies\nthe geometry of the minimum-volume confidence sets for the multinomial\nparameter. When used in place of more standard confidence sets and intervals\nbased on bounds and asymptotic approximation, learning algorithms can exhibit\nimproved sample complexity. Prior work showed the minimum-volume confidence\nsets are the level-sets of a discontinuous function defined by an exact\np-value. While the confidence sets are optimal in that they have minimum\naverage volume, computation of membership of a single point in the set is\nchallenging for problems of modest size. Since the confidence sets are\nlevel-sets of discontinuous functions, little is apparent about their geometry.\nThis paper studies the geometry of the minimum volume confidence sets by\nenumerating and covering the continuous regions of the exact p-value function.\nThis addresses a fundamental question in A/B testing: given two multinomial\noutcomes, how can one determine if their corresponding minimum volume\nconfidence sets are disjoint? We answer this question in a restricted setting.",
    "descriptor": "",
    "authors": [
      "Heguang Lin",
      "Mengze Li",
      "Daniel Pimentel-Alarc\u00f3n",
      "Matthew Malloy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08180"
  },
  {
    "id": "arXiv:2202.08186",
    "title": "Quantum speedups for treewidth",
    "abstract": "In this paper, we study quantum algorithms for computing the exact value of\nthe treewidth of a graph. Our algorithms are based on the classical algorithm\nby Fomin and Villanger (Combinatorica 32, 2012) that uses $O(2.616^n)$ time and\npolynomial space. We show three quantum algorithms with the following\ncomplexity, using QRAM in both exponential space algorithms: $\\bullet$\n$O(1.618^n)$ time and polynomial space; $\\bullet$ $O(1.554^n)$ time and\n$O(1.452^n)$ space; $\\bullet$ $O(1.538^n)$ time and space. In contrast, the\nfastest known classical algorithm for treewidth uses $O(1.755^n)$ time and\nspace. The first two speed-ups are obtained in a fairly straightforward way.\nThe first version uses additionally only Grover's search and provides a\nquadratic speedup. The second speedup is more time-efficient and uses both\nGrover's search and the quantum exponential dynamic programming by Ambainis et\nal. (SODA '19). The third version uses the specific properties of the classical\nalgorithm and treewidth, with a modified version of the quantum dynamic\nprogramming on the hypercube. Lastly, as a small side result, we also give a\nnew classical time-space tradeoff for computing treewidth in $O^*(2^n)$ time\nand $O^*(\\sqrt{2^n})$ space.",
    "descriptor": "",
    "authors": [
      "Vladislavs K\u013cevickis",
      "Kri\u0161j\u0101nis Pr\u016bsis",
      "Jevg\u0113nijs Vihrovs"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2202.08186"
  },
  {
    "id": "arXiv:2202.08191",
    "title": "Sampling The Lowest Eigenfunction to Recover the Potential in a  One-Dimensional Schr\u00f6dinger Equation",
    "abstract": "We consider the BVP $-y\" + qy = \\lambda y$ with $y(0)=y(1)=0$. The inverse\nspectral problems asks one to recover $q$ from spectral information. In this\npaper, we present a very simple method to recover a potential by sampling one\neigenfunction. The spectral asymptotics imply that for larger modes, more and\nmore information is lost due to imprecise measurements (i.e. relative errors\n\\textit{increases}) and so it is advantageous to use data from lower modes. Our\nmethod also allows us to recover \"any\" potential from \\textit{one} boundary\ncondition.",
    "descriptor": "\nComments: 15 pages; 16 figures\n",
    "authors": [
      "Rob Rahm"
    ],
    "subjectives": [
      "Spectral Theory (math.SP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.08191"
  },
  {
    "id": "arXiv:2202.08195",
    "title": "Label Propagation for Annotation-Efficient Nuclei Segmentation from  Pathology Images",
    "abstract": "Nuclei segmentation is a crucial task for whole slide image analysis in\ndigital pathology. Generally, the segmentation performance of fully-supervised\nlearning heavily depends on the amount and quality of the annotated data.\nHowever, it is time-consuming and expensive for professional pathologists to\nprovide accurate pixel-level ground truth, while it is much easier to get\ncoarse labels such as point annotations. In this paper, we propose a\nweakly-supervised learning method for nuclei segmentation that only requires\npoint annotations for training. The proposed method achieves label propagation\nin a coarse-to-fine manner as follows. First, coarse pixel-level labels are\nderived from the point annotations based on the Voronoi diagram and the k-means\nclustering method to avoid overfitting. Second, a co-training strategy with an\nexponential moving average method is designed to refine the incomplete\nsupervision of the coarse labels. Third, a self-supervised visual\nrepresentation learning method is tailored for nuclei segmentation of pathology\nimages that transforms the hematoxylin component images into the H\\&E stained\nimages to gain better understanding of the relationship between the nuclei and\ncytoplasm. We comprehensively evaluate the proposed method using two public\ndatasets. Both visual and quantitative results demonstrate the superiority of\nour method to the state-of-the-art methods, and its competitive performance\ncompared to the fully-supervised methods. The source codes for implementing the\nexperiments will be released after acceptance.",
    "descriptor": "",
    "authors": [
      "Yi Lin",
      "Zhiyong Qu",
      "Hao Chen",
      "Zhongke Gao",
      "Yuexiang Li",
      "Lili Xia",
      "Kai Ma",
      "Yefeng Zheng",
      "Kwang-Ting Cheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2202.08195"
  },
  {
    "id": "arXiv:2202.08209",
    "title": "An Extension Of Combinatorial Contextuality For Cognitive Protocols",
    "abstract": "This article extends the combinatorial approach to support the determination\nof contextuality amidst causal influences. Contextuality is an active field of\nstudy in Quantum Cognition, in systems relating to mental phenomena, such as\nconcepts in human memory [Aerts et al., 2013]. In the cognitive field of study,\na contemporary challenge facing the determination of whether a phenomenon is\ncontextual has been the identification and management of disturbances\n[Dzhafarov et al., 2016]. Whether or not said disturbances are identified\nthrough the modelling approach, constitute causal influences, or are\ndisregardableas as noise is important, as contextuality cannot be adequately\ndetermined in the presence of causal influences [Gleason, 1957]. To address\nthis challenge, we first provide a formalisation of necessary elements of the\ncombinatorial approach within the language of canonical9 causal models. Through\nthis formalisation, we extend the combinatorial approach to support a\nmeasurement and treatment of disturbance, and offer techniques to separately\ndistinguish noise and causal influences. Thereafter, we develop a protocol\nthrough which these elements may be represented within a cognitive experiment.\nAs human cognition seems rife with causal influences, cognitive modellers may\napply the extended combinatorial approach to practically determine the\ncontextuality of cognitive phenomena.",
    "descriptor": "\nComments: 28 pages, 10 figures, 5 tables\n",
    "authors": [
      "Abdul Karim Obeid",
      "Peter Bruza",
      "Catarina Moreira",
      "Axel Bruns",
      "Daniel Angus"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.08209"
  },
  {
    "id": "arXiv:2202.08210",
    "title": "Automatic Depression Detection: An Emotional Audio-Textual Corpus and a  GRU/BiLSTM-based Model",
    "abstract": "Depression is a global mental health problem, the worst case of which can\nlead to suicide. An automatic depression detection system provides great help\nin facilitating depression self-assessment and improving diagnostic accuracy.\nIn this work, we propose a novel depression detection approach utilizing speech\ncharacteristics and linguistic contents from participants' interviews. In\naddition, we establish an Emotional Audio-Textual Depression Corpus\n(EATD-Corpus) which contains audios and extracted transcripts of responses from\ndepressed and non-depressed volunteers. To the best of our knowledge,\nEATD-Corpus is the first and only public depression dataset that contains audio\nand text data in Chinese. Evaluated on two depression datasets, the proposed\nmethod achieves the state-of-the-art performances. The outperforming results\ndemonstrate the effectiveness and generalization ability of the proposed\nmethod. The source code and EATD-Corpus are available at\nhttps://github.com/speechandlanguageprocessing/ICASSP2022-Depression.",
    "descriptor": "",
    "authors": [
      "Ying Shen",
      "Huiyu Yang",
      "Lin Lin"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Sound (cs.SD)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2202.08210"
  },
  {
    "id": "arXiv:2202.08232",
    "title": "Quantum Lazy Training",
    "abstract": "In the training of over-parameterized model functions via gradient descent,\nsometimes the parameters do not change significantly and remain close to their\ninitial values. This phenomenon is called lazy training, and motivates\nconsideration of the linear approximation of the model function around the\ninitial parameters. In the lazy regime, this linear approximation imitates the\nbehavior of the parameterized function whose associated kernel, called the\ntangent kernel, specifies the training performance of the model. Lazy training\nis known to occur in the case of (classical) neural networks with large widths.\nIn this paper, we show that the training of geometrically local parameterized\nquantum circuits enters the lazy regime for large numbers of qubits. More\nprecisely, we prove bounds on the rate of changes of the parameters of such a\ngeometrically local parameterized quantum circuit in the training process, and\non the precision of the linear approximation of the associated quantum model\nfunction; both of these bounds tend to zero as the number of qubits grows. We\nsupport our analytic results with numerical simulations.",
    "descriptor": "\nComments: 18 pages, 7 figures + 5 page appendix\n",
    "authors": [
      "Erfan Abedi",
      "Salman Beigi",
      "Leila Taghavi"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08232"
  },
  {
    "id": "arXiv:2202.08236",
    "title": "Using the left Gram matrix to cluster high dimensional data",
    "abstract": "For high dimensional data, where P features for N objects (P >> N) are\nrepresented in an NxP matrix X, we describe a clustering algorithm based on the\nnormalized left Gram matrix, G = XX'/P. Under certain regularity conditions,\nthe rows in G that correspond to objects in the same cluster converge to the\nsame mean vector. By clustering on the row means, the algorithm does not\nrequire preprocessing by dimension reduction or feature selection techniques\nand does not require specification of tuning or hyperparameter values. Because\nit is based on the NxN matrix G, it has a lower computational cost than many\nmethods based on clustering the feature matrix X. When compared to 14 other\nclustering algorithms applied to 32 benchmarked microarray datasets, the\nproposed algorithm provided the most accurate estimate of the underlying\ncluster configuration more than twice as often as its closest competitors.",
    "descriptor": "",
    "authors": [
      "Shahina Rahman",
      "Valen E. Johnson",
      "Suhasini Subba Rao"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08236"
  },
  {
    "id": "arXiv:2202.08238",
    "title": "A multi-reconstruction study of breast density estimation using Deep  Learning",
    "abstract": "Breast density estimation is one of the key tasks in recognizing individuals\npredisposed to breast cancer. It is often challenging because of low contrast\nand fluctuations in mammograms' fatty tissue background. Most of the time, the\nbreast density is estimated manually where a radiologist assigns one of the\nfour density categories decided by the Breast Imaging and Reporting Data\nSystems (BI-RADS). There have been efforts in the direction of automating a\nbreast density classification pipeline.\nBreast density estimation is one of the key tasks performed during a\nscreening exam. Dense breasts are more susceptible to breast cancer. The\ndensity estimation is challenging because of low contrast and fluctuations in\nmammograms' fatty tissue background. Traditional mammograms are being replaced\nby tomosynthesis and its other low radiation dose variants (for example\nHologic' Intelligent 2D and C-View). Because of the low-dose requirement,\nincreasingly more screening centers are favoring the Intelligent 2D view and\nC-View. Deep-learning studies for breast density estimation use only a single\nmodality for training a neural network. However, doing so restricts the number\nof images in the dataset. In this paper, we show that a neural network trained\non all the modalities at once performs better than a neural network trained on\nany single modality. We discuss these results using the area under the receiver\noperator characteristics curves.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Vikash Gupta",
      "Mutlu Demirer",
      "Robert W. Maxwell",
      "Richard D. White",
      "Barabaros Selnur Erdal"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.08238"
  },
  {
    "id": "arXiv:1805.10833",
    "title": "Bayesian Learning with Wasserstein Barycenters",
    "abstract": "Bayesian Learning with Wasserstein Barycenters",
    "descriptor": "",
    "authors": [
      "Julio Backhoff-Veraguas",
      "Joaquin Fontbona",
      "Gonzalo Rios",
      "Felipe Tobar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/1805.10833"
  },
  {
    "id": "arXiv:1906.04199",
    "title": "Deciding the Computability of Regular Functions over Infinite Words",
    "abstract": "Deciding the Computability of Regular Functions over Infinite Words",
    "descriptor": "",
    "authors": [
      "V. Dave",
      "E. Filiot",
      "S. Krishna",
      "N. Lhote"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/1906.04199"
  },
  {
    "id": "arXiv:1912.01765",
    "title": "Universal approximation of symmetric and anti-symmetric functions",
    "abstract": "Universal approximation of symmetric and anti-symmetric functions",
    "descriptor": "",
    "authors": [
      "Jiequn Han",
      "Yingzhou Li",
      "Lin Lin",
      "Jianfeng Lu",
      "Jiefu Zhang",
      "Linfeng Zhang"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/1912.01765"
  },
  {
    "id": "arXiv:1912.03802",
    "title": "Group Fairness in Bandit Arm Selection",
    "abstract": "Comments: Accepted to AAMAS 2022",
    "descriptor": "\nComments: Accepted to AAMAS 2022\n",
    "authors": [
      "Candice Schumann",
      "Zhi Lang",
      "Nicholas Mattei",
      "John P. Dickerson"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/1912.03802"
  },
  {
    "id": "arXiv:2001.06358",
    "title": "Generative Datalog with Continuous Distributions",
    "abstract": "Comments: Extended Version",
    "descriptor": "\nComments: Extended Version\n",
    "authors": [
      "Martin Grohe",
      "Benjamin Lucien Kaminski",
      "Joost-Pieter Katoen",
      "Peter Lindner"
    ],
    "subjectives": [
      "Databases (cs.DB)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2001.06358"
  },
  {
    "id": "arXiv:2001.09969",
    "title": "On the quality of matching-based aggregates for algebraic coarsening of  SPD matrices in AMG",
    "abstract": "On the quality of matching-based aggregates for algebraic coarsening of  SPD matrices in AMG",
    "descriptor": "",
    "authors": [
      "Pasqua D'Ambra",
      "Fabio Durastante",
      "Salvatore Filippone",
      "Ludmil Zikatanov"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2001.09969"
  },
  {
    "id": "arXiv:2004.03951",
    "title": "Expand Globally, Shrink Locally: Discriminant Multi-label Learning with  Missing Labels",
    "abstract": "Comments: Accepted by Pattern Recognition. arXiv admin note: text overlap with arXiv:1704.01415 by other authors",
    "descriptor": "\nComments: Accepted by Pattern Recognition. arXiv admin note: text overlap with arXiv:1704.01415 by other authors\n",
    "authors": [
      "Zhongchen Ma",
      "Songcan Chen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2004.03951"
  },
  {
    "id": "arXiv:2006.04004",
    "title": "Distributionally Robust Weighted $k$-Nearest Neighbors",
    "abstract": "Distributionally Robust Weighted $k$-Nearest Neighbors",
    "descriptor": "",
    "authors": [
      "Shixiang Zhu",
      "Liyan Xie",
      "Minghe Zhang",
      "Rui Gao",
      "Yao Xie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2006.04004"
  },
  {
    "id": "arXiv:2006.10340",
    "title": "Perfectly Matched Layers on Cubic Domains forPauli's Equations",
    "abstract": "Perfectly Matched Layers on Cubic Domains forPauli's Equations",
    "descriptor": "",
    "authors": [
      "Laurence Halpern",
      "Jeffrey Rauch"
    ],
    "subjectives": [
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2006.10340"
  },
  {
    "id": "arXiv:2006.10564",
    "title": "Distribution-free binary classification: prediction sets, confidence  intervals and calibration",
    "abstract": "Comments: 34 pages; significant updates from previous version (unambiguous notation, better exposition, and cleaner results); originally appeared as a spotlight at Neural Information Processing Systems (NeurIPS) '20",
    "descriptor": "\nComments: 34 pages; significant updates from previous version (unambiguous notation, better exposition, and cleaner results); originally appeared as a spotlight at Neural Information Processing Systems (NeurIPS) '20\n",
    "authors": [
      "Chirag Gupta",
      "Aleksandr Podkopaev",
      "Aaditya Ramdas"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2006.10564"
  },
  {
    "id": "arXiv:2006.15390",
    "title": "A Stabilization of a Continuous Limit of the Ensemble Kalman Inversion",
    "abstract": "A Stabilization of a Continuous Limit of the Ensemble Kalman Inversion",
    "descriptor": "",
    "authors": [
      "Dieter Armbruster",
      "Michael Herty",
      "Giuseppe Visconti"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Dynamical Systems (math.DS)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2006.15390"
  },
  {
    "id": "arXiv:2007.01441",
    "title": "Joint Frequency and Image Space Learning for MRI Reconstruction and  Analysis",
    "abstract": "Comments: 27 pages, 12 figures, image reconstruction, motion correction, denoising, magnetic resonance imaging, deep learning",
    "descriptor": "\nComments: 27 pages, 12 figures, image reconstruction, motion correction, denoising, magnetic resonance imaging, deep learning\n",
    "authors": [
      "Nalini M. Singh",
      "Juan Eugenio Iglesias",
      "Elfar Adalsteinsson",
      "Adrian V. Dalca",
      "Polina Golland"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2007.01441"
  },
  {
    "id": "arXiv:2007.06169",
    "title": "An Adversarial Approach to Structural Estimation",
    "abstract": "Comments: 70 pages, 4 tables, 16 figures",
    "descriptor": "\nComments: 70 pages, 4 tables, 16 figures\n",
    "authors": [
      "Tetsuya Kaji",
      "Elena Manresa",
      "Guillaume Pouliot"
    ],
    "subjectives": [
      "Econometrics (econ.EM)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Methodology (stat.ME)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2007.06169"
  },
  {
    "id": "arXiv:2007.08745",
    "title": "Backdoor Learning: A Survey",
    "abstract": "Comments: 17 pages. A curated list of backdoor learning resources in this paper is presented in the Github Repo (this https URL). We will try our best to continuously maintain this Github Repo",
    "descriptor": "\nComments: 17 pages. A curated list of backdoor learning resources in this paper is presented in the Github Repo (this https URL). We will try our best to continuously maintain this Github Repo\n",
    "authors": [
      "Yiming Li",
      "Yong Jiang",
      "Zhifeng Li",
      "Shu-Tao Xia"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2007.08745"
  },
  {
    "id": "arXiv:2007.13374",
    "title": "Decomposing Generation Networks with Structure Prediction for Recipe  Generation",
    "abstract": "Comments: Accepted at Pattern Recognition",
    "descriptor": "\nComments: Accepted at Pattern Recognition\n",
    "authors": [
      "Hao Wang",
      "Guosheng Lin",
      "Steven C. H. Hoi",
      "Chunyan Miao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2007.13374"
  },
  {
    "id": "arXiv:2008.11700",
    "title": "Safe Active Dynamics Learning and Control: A Sequential  Exploration-Exploitation Framework",
    "abstract": "Comments: Accepted as a Regular Paper to the IEEE Transactions on Robotics (T-RO)",
    "descriptor": "\nComments: Accepted as a Regular Paper to the IEEE Transactions on Robotics (T-RO)\n",
    "authors": [
      "Thomas Lew",
      "Apoorva Sharma",
      "James Harrison",
      "Andrew Bylard",
      "Marco Pavone"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2008.11700"
  },
  {
    "id": "arXiv:2009.00774",
    "title": "Vulnerability-Aware Poisoning Mechanism for Online RL with Unknown  Dynamics",
    "abstract": "Vulnerability-Aware Poisoning Mechanism for Online RL with Unknown  Dynamics",
    "descriptor": "",
    "authors": [
      "Yanchao Sun",
      "Da Huo",
      "Furong Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2009.00774"
  },
  {
    "id": "arXiv:2009.01325",
    "title": "Learning to summarize from human feedback",
    "abstract": "Comments: NeurIPS 2020",
    "descriptor": "\nComments: NeurIPS 2020\n",
    "authors": [
      "Nisan Stiennon",
      "Long Ouyang",
      "Jeff Wu",
      "Daniel M. Ziegler",
      "Ryan Lowe",
      "Chelsea Voss",
      "Alec Radford",
      "Dario Amodei",
      "Paul Christiano"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2009.01325"
  },
  {
    "id": "arXiv:2010.05429",
    "title": "TUTOR: Training Neural Networks Using Decision Rules as Model Priors",
    "abstract": "Comments: 14 pages, 4 figures",
    "descriptor": "\nComments: 14 pages, 4 figures\n",
    "authors": [
      "Shayan Hassantabar",
      "Prerit Terway",
      "Niraj K. Jha"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2010.05429"
  },
  {
    "id": "arXiv:2010.09895",
    "title": "Multi-Window Data Augmentation Approach for Speech Emotion Recognition",
    "abstract": "Multi-Window Data Augmentation Approach for Speech Emotion Recognition",
    "descriptor": "",
    "authors": [
      "Sarala Padi",
      "Dinesh Manocha",
      "Ram D.Sriram"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2010.09895"
  },
  {
    "id": "arXiv:2011.00444",
    "title": "Discriminative Adversarial Domain Generalization with Meta-learning  based Cross-domain Validation",
    "abstract": "Discriminative Adversarial Domain Generalization with Meta-learning  based Cross-domain Validation",
    "descriptor": "",
    "authors": [
      "Keyu Chen",
      "Di Zhuang",
      "J. Morris Chang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2011.00444"
  },
  {
    "id": "arXiv:2011.11198",
    "title": "Complex-valued Iris Recognition Network",
    "abstract": "Comments: This paper has been accepted for publication in T-PAMI",
    "descriptor": "\nComments: This paper has been accepted for publication in T-PAMI\n",
    "authors": [
      "Kien Nguyen",
      "Clinton Fookes",
      "Sridha Sridharan",
      "Arun Ross"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2011.11198"
  },
  {
    "id": "arXiv:2011.14482",
    "title": "A Near-Optimal Parallel Algorithm for Joining Binary Relations",
    "abstract": "Comments: Short versions of this article appeared in PODS'17 and ICDT'20",
    "descriptor": "\nComments: Short versions of this article appeared in PODS'17 and ICDT'20\n",
    "authors": [
      "Bas Ketsman",
      "Dan Suciu",
      "Yufei Tao"
    ],
    "subjectives": [
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2011.14482"
  },
  {
    "id": "arXiv:2012.00936",
    "title": "MAUIL: Multi-level Attribute Embedding for Semi-supervised User Identity  Linkage",
    "abstract": "Comments: Accepted by Information Sciences in Feb. 2022",
    "descriptor": "\nComments: Accepted by Information Sciences in Feb. 2022\n",
    "authors": [
      "Baiyang Chen",
      "Xiaoliang Chen"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2012.00936"
  },
  {
    "id": "arXiv:2012.05362",
    "title": "Kineverse: A Symbolic Articulation Model Framework for Model-Agnostic  Mobile Manipulation",
    "abstract": "Comments: 8 pages, 8 figures, Published in: IEEE Robotics and Automation Letters ( Volume: 7, Issue: 2, April 2022)",
    "descriptor": "\nComments: 8 pages, 8 figures, Published in: IEEE Robotics and Automation Letters ( Volume: 7, Issue: 2, April 2022)\n",
    "authors": [
      "Adrian R\u00f6fer",
      "Georg Bartels",
      "Wolfram Burgard",
      "Abhinav Valada",
      "Michael Beetz"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2012.05362"
  },
  {
    "id": "arXiv:2012.10452",
    "title": "Experimental relativistic zero-knowledge proofs",
    "abstract": "Comments: 8 pages, 3 figures",
    "descriptor": "\nComments: 8 pages, 3 figures\n",
    "authors": [
      "Pouriya Alikhani",
      "Nicolas Brunner",
      "Claude Cr\u00e9peau",
      "S\u00e9bastien Designolle",
      "Rapha\u00ebl Houlmann",
      "Weixu Shi",
      "Nan Yang",
      "Hugo Zbinden"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2012.10452"
  },
  {
    "id": "arXiv:2012.14048",
    "title": "Learning to predict synchronization of coupled oscillators on  heterogeneous graphs",
    "abstract": "Comments: 17 pages, 12 figures, 4 tables",
    "descriptor": "\nComments: 17 pages, 12 figures, 4 tables\n",
    "authors": [
      "Hardeep Bassi",
      "Richard Yim",
      "Rohith Kodukula",
      "Joshua Vendrow",
      "Cherlin Zhu",
      "Hanbaek Lyu"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "Adaptation and Self-Organizing Systems (nlin.AO)"
    ],
    "url": "https://arxiv.org/abs/2012.14048"
  },
  {
    "id": "arXiv:2101.05519",
    "title": "BiGCN: A Bi-directional Low-Pass Filtering Graph Neural Network",
    "abstract": "BiGCN: A Bi-directional Low-Pass Filtering Graph Neural Network",
    "descriptor": "",
    "authors": [
      "Zhixian Chen",
      "Tengfei Ma",
      "Zhihua Jin",
      "Yangqiu Song",
      "Yang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2101.05519"
  },
  {
    "id": "arXiv:2101.06467",
    "title": "Weakly nonlocal Poisson brackets: tools, examples, computations",
    "abstract": "Comments: 30 pages. Keywords: Poisson bracket, Hamiltonian operator, Schouten bracket, partial differential equations, integrable systems",
    "descriptor": "\nComments: 30 pages. Keywords: Poisson bracket, Hamiltonian operator, Schouten bracket, partial differential equations, integrable systems\n",
    "authors": [
      "Matteo Casati",
      "Paolo Lorenzoni",
      "Daniele Valeri",
      "Raffaele Vitolo"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Symbolic Computation (cs.SC)",
      "Exactly Solvable and Integrable Systems (nlin.SI)"
    ],
    "url": "https://arxiv.org/abs/2101.06467"
  },
  {
    "id": "arXiv:2101.12614",
    "title": "Modeling blood flow in networks of viscoelastic vessels with the 1-D  augmented fluid-structure interaction system",
    "abstract": "Comments: 42 pages, 19 figures",
    "descriptor": "\nComments: 42 pages, 19 figures\n",
    "authors": [
      "Francesco Piccioli",
      "Giulia Bertaglia",
      "Alessandro Valiani",
      "Valerio Caleffi"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2101.12614"
  },
  {
    "id": "arXiv:2102.00082",
    "title": "Settling the Sharp Reconstruction Thresholds of Random Graph Matching",
    "abstract": "Settling the Sharp Reconstruction Thresholds of Random Graph Matching",
    "descriptor": "",
    "authors": [
      "Yihong Wu",
      "Jiaming Xu",
      "Sophie H. Yu"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.00082"
  },
  {
    "id": "arXiv:2102.01229",
    "title": "Doubly robust Thompson sampling for linear payoffs",
    "abstract": "Comments: Accepted for NeurIPS 2021 (Spotlight)",
    "descriptor": "\nComments: Accepted for NeurIPS 2021 (Spotlight)\n",
    "authors": [
      "Wonyoung Kim",
      "Gi-soo Kim",
      "Myunghee Cho Paik"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.01229"
  },
  {
    "id": "arXiv:2102.01240",
    "title": "Fair Dynamic Rationing",
    "abstract": "Fair Dynamic Rationing",
    "descriptor": "",
    "authors": [
      "Vahideh Manshadi",
      "Rad Niazadeh",
      "Scott Rodilitz"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2102.01240"
  },
  {
    "id": "arXiv:2102.03450",
    "title": "Wasserstein Graph Neural Networks for Graphs with Missing Attributes",
    "abstract": "Wasserstein Graph Neural Networks for Graphs with Missing Attributes",
    "descriptor": "",
    "authors": [
      "Zhixian Chen",
      "Tengfei Ma",
      "Yangqiu Song",
      "Yang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.03450"
  },
  {
    "id": "arXiv:2102.03622",
    "title": "Deep Semi-Supervised Learning for Time Series Classification",
    "abstract": "Deep Semi-Supervised Learning for Time Series Classification",
    "descriptor": "",
    "authors": [
      "Jann Goschenhofer",
      "Rasmus Hvingelby",
      "David R\u00fcgamer",
      "Janek Thomas",
      "Moritz Wagner",
      "Bernd Bischl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.03622"
  },
  {
    "id": "arXiv:2102.03625",
    "title": "uTango: an open-source TEE for IoT devices",
    "abstract": "uTango: an open-source TEE for IoT devices",
    "descriptor": "",
    "authors": [
      "Daniel Oliveira",
      "Tiago Gomes",
      "Sandro Pinto"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2102.03625"
  },
  {
    "id": "arXiv:2102.05139",
    "title": "Solving time-fractional differential equation via rational approximation",
    "abstract": "Comments: 26 pages, 10 figures",
    "descriptor": "\nComments: 26 pages, 10 figures\n",
    "authors": [
      "Ustim Khristenko",
      "Barbara Wohlmuth"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2102.05139"
  },
  {
    "id": "arXiv:2102.06278",
    "title": "Unsupervised Ground Metric Learning using Wasserstein Singular Vectors",
    "abstract": "Unsupervised Ground Metric Learning using Wasserstein Singular Vectors",
    "descriptor": "",
    "authors": [
      "Geert-Jan Huizing",
      "Laura Cantini",
      "Gabriel Peyr\u00e9"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.06278"
  },
  {
    "id": "arXiv:2102.07215",
    "title": "Large-Scale Meta-Learning with Continual Trajectory Shifting",
    "abstract": "Large-Scale Meta-Learning with Continual Trajectory Shifting",
    "descriptor": "",
    "authors": [
      "Jaewoong Shin",
      "Hae Beom Lee",
      "Boqing Gong",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.07215"
  },
  {
    "id": "arXiv:2102.09844",
    "title": "E(n) Equivariant Graph Neural Networks",
    "abstract": "E(n) Equivariant Graph Neural Networks",
    "descriptor": "",
    "authors": [
      "Victor Garcia Satorras",
      "Emiel Hoogeboom",
      "Max Welling"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2102.09844"
  },
  {
    "id": "arXiv:2102.10757",
    "title": "Self-Supervised Learning of Graph Neural Networks: A Unified Review",
    "abstract": "Comments: 26 pages, 7 figures",
    "descriptor": "\nComments: 26 pages, 7 figures\n",
    "authors": [
      "Yaochen Xie",
      "Zhao Xu",
      "Jingtun Zhang",
      "Zhengyang Wang",
      "Shuiwang Ji"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.10757"
  },
  {
    "id": "arXiv:2103.02631",
    "title": "RotoGrad: Gradient Homogenization in Multitask Learning",
    "abstract": "Comments: Spotlight at ICLR 2022. 24 pages, 9 figures",
    "descriptor": "\nComments: Spotlight at ICLR 2022. 24 pages, 9 figures\n",
    "authors": [
      "Adri\u00e1n Javaloy",
      "Isabel Valera"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.02631"
  },
  {
    "id": "arXiv:2103.03032",
    "title": "Wanted Dead or Alive : Epistemic logic for impure simplicial complexes",
    "abstract": "Wanted Dead or Alive : Epistemic logic for impure simplicial complexes",
    "descriptor": "",
    "authors": [
      "Hans van Ditmarsch",
      "Roman Kuznets"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2103.03032"
  },
  {
    "id": "arXiv:2103.04582",
    "title": "A Virtual Finite Element Method for Two Dimensional Maxwell Interface  Problems with a Background Unfitted Mesh",
    "abstract": "A Virtual Finite Element Method for Two Dimensional Maxwell Interface  Problems with a Background Unfitted Mesh",
    "descriptor": "",
    "authors": [
      "Shuhao Cao",
      "Long Chen",
      "Ruchi Guo"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2103.04582"
  },
  {
    "id": "arXiv:2103.04730",
    "title": "Efficient Algorithms for Finite Horizon and Streaming Restless  Multi-Armed Bandit Problems",
    "abstract": "Efficient Algorithms for Finite Horizon and Streaming Restless  Multi-Armed Bandit Problems",
    "descriptor": "",
    "authors": [
      "Aditya Mate",
      "Arpita Biswas",
      "Christoph Siebenbrunner",
      "Susobhan Ghosh",
      "Milind Tambe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2103.04730"
  },
  {
    "id": "arXiv:2103.13736",
    "title": "Deep Similarity Learning for Sports Team Ranking",
    "abstract": "Deep Similarity Learning for Sports Team Ranking",
    "descriptor": "",
    "authors": [
      "Daniel Yazbek",
      "Jonathan Sandile Sibindi",
      "Terence L. Van Zyl"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2103.13736"
  },
  {
    "id": "arXiv:2103.15450",
    "title": "Joint Sampling and Transmission Policies for Minimizing Cost under AoI  Constraints",
    "abstract": "Comments: 32 pages, submitted on a journal",
    "descriptor": "\nComments: 32 pages, submitted on a journal\n",
    "authors": [
      "Emmanouil Fountoulakis",
      "Marian Codreanu",
      "Anthony Ephremides",
      "Nikolaos Pappas"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2103.15450"
  },
  {
    "id": "arXiv:2103.16938",
    "title": "Unpaired Single-Image Depth Synthesis with cycle-consistent Wasserstein  GANs",
    "abstract": "Comments: The paper had a major revision and significant changes of the content do not allow for a replacement",
    "descriptor": "\nComments: The paper had a major revision and significant changes of the content do not allow for a replacement\n",
    "authors": [
      "Christoph Angermann",
      "Ad\u00e9la Moravov\u00e1",
      "Markus Haltmeier",
      "Steinbj\u00f6rn J\u00f3nsson",
      "Christian Laubichler"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2103.16938"
  },
  {
    "id": "arXiv:2104.07794",
    "title": "An $L^2$ Analysis of Reinforcement Learning in High Dimensions with  Kernel and Neural Network Approximation",
    "abstract": "An $L^2$ Analysis of Reinforcement Learning in High Dimensions with  Kernel and Neural Network Approximation",
    "descriptor": "",
    "authors": [
      "Jihao Long",
      "Jiequn Han",
      "Weinan E"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.07794"
  },
  {
    "id": "arXiv:2104.09202",
    "title": "Monitoring Data Requests in Decentralized Data Storage Systems: A Case  Study of IPFS",
    "abstract": "Monitoring Data Requests in Decentralized Data Storage Systems: A Case  Study of IPFS",
    "descriptor": "",
    "authors": [
      "Leonhard Balduf",
      "Sebastian Henningsen",
      "Martin Florian",
      "Sebastian Rust",
      "Bj\u00f6rn Scheuermann"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2104.09202"
  },
  {
    "id": "arXiv:2104.09771",
    "title": "GLiDE: Generalizable Quadrupedal Locomotion in Diverse Environments with  a Centroidal Model",
    "abstract": "Comments: video: this https URL",
    "descriptor": "\nComments: video: this https URL\n",
    "authors": [
      "Zhaoming Xie",
      "Xingye Da",
      "Buck Babich",
      "Animesh Garg",
      "Michiel van de Panne"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.09771"
  },
  {
    "id": "arXiv:2104.10150",
    "title": "Bayesian subset selection and variable importance for interpretable  prediction and classification",
    "abstract": "Bayesian subset selection and variable importance for interpretable  prediction and classification",
    "descriptor": "",
    "authors": [
      "Daniel R. Kowal"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)",
      "Computation (stat.CO)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2104.10150"
  },
  {
    "id": "arXiv:2105.01976",
    "title": "GRAPHOPT: constrained-optimization-based parallelization of irregular  graphs",
    "abstract": "GRAPHOPT: constrained-optimization-based parallelization of irregular  graphs",
    "descriptor": "",
    "authors": [
      "Nimish Shah",
      "Wannes Meert",
      "Marian Verhelst"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2105.01976"
  },
  {
    "id": "arXiv:2105.08559",
    "title": "Simulating 3-symbol Turing machines with SIMD||DNA",
    "abstract": "Simulating 3-symbol Turing machines with SIMD||DNA",
    "descriptor": "",
    "authors": [
      "David Doty",
      "Aaron Ong"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Molecular Networks (q-bio.MN)"
    ],
    "url": "https://arxiv.org/abs/2105.08559"
  },
  {
    "id": "arXiv:2105.14097",
    "title": "Reinforcement Learning for on-line Sequence Transformation",
    "abstract": "Reinforcement Learning for on-line Sequence Transformation",
    "descriptor": "",
    "authors": [
      "Grzegorz Rype\u015b\u0107",
      "\u0141ukasz Lepak",
      "Pawe\u0142 Wawrzy\u0144ski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14097"
  },
  {
    "id": "arXiv:2105.14490",
    "title": "Relational Graph Neural Network Design via Progressive Neural  Architecture Search",
    "abstract": "Relational Graph Neural Network Design via Progressive Neural  Architecture Search",
    "descriptor": "",
    "authors": [
      "Ailing Zeng",
      "Minhao Liu",
      "Zhiwei Liu",
      "Ruiyuan Gao",
      "Jing Qin",
      "Qiang Xu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.14490"
  },
  {
    "id": "arXiv:2106.01981",
    "title": "ProtoRes: Proto-Residual Network for Pose Authoring via Learned Inverse  Kinematics",
    "abstract": "ProtoRes: Proto-Residual Network for Pose Authoring via Learned Inverse  Kinematics",
    "descriptor": "",
    "authors": [
      "Boris N. Oreshkin",
      "Florent Bocquelet",
      "F\u00e9lix G. Harvey",
      "Bay Raitt",
      "Dominic Laflamme"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.01981"
  },
  {
    "id": "arXiv:2106.02850",
    "title": "Tetrad: Actively Secure 4PC for Secure Training and Inference",
    "abstract": "Tetrad: Actively Secure 4PC for Secure Training and Inference",
    "descriptor": "",
    "authors": [
      "Nishat Koti",
      "Arpita Patra",
      "Rahul Rachuri",
      "Ajith Suresh"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.02850"
  },
  {
    "id": "arXiv:2106.03097",
    "title": "Preservation of the Global Knowledge by Not-True Self Knowledge  Distillation in Federated Learning",
    "abstract": "Comments: Under review",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Gihun Lee",
      "Minchan Jeong",
      "Yongjin Shin",
      "Sangmin Bae",
      "Se-Young Yun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.03097"
  },
  {
    "id": "arXiv:2106.03131",
    "title": "The Fine-Grained Hardness of Sparse Linear Regression",
    "abstract": "The Fine-Grained Hardness of Sparse Linear Regression",
    "descriptor": "",
    "authors": [
      "Aparna Gupte",
      "Vinod Vaikuntanathan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.03131"
  },
  {
    "id": "arXiv:2106.03171",
    "title": "Feature-based Style Randomization for Domain Generalization",
    "abstract": "Comments: To appear in IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)",
    "descriptor": "\nComments: To appear in IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)\n",
    "authors": [
      "Yue Wang",
      "Lei Qi",
      "Yinghuan Shi",
      "Yang Gao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.03171"
  },
  {
    "id": "arXiv:2106.03787",
    "title": "Concave Utility Reinforcement Learning: the Mean-Field Game Viewpoint",
    "abstract": "Comments: AAMAS 2022",
    "descriptor": "\nComments: AAMAS 2022\n",
    "authors": [
      "Matthieu Geist",
      "Julien P\u00e9rolat",
      "Mathieu Lauri\u00e8re",
      "Romuald Elie",
      "Sarah Perrin",
      "Olivier Bachem",
      "R\u00e9mi Munos",
      "Olivier Pietquin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2106.03787"
  },
  {
    "id": "arXiv:2106.04405",
    "title": "Federated Neural Collaborative Filtering",
    "abstract": "Federated Neural Collaborative Filtering",
    "descriptor": "",
    "authors": [
      "Vasileios Perifanis",
      "Pavlos S. Efraimidis"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.04405"
  },
  {
    "id": "arXiv:2106.04464",
    "title": "Augmenting Molecular Deep Generative Models with Topological Data  Analysis Representations",
    "abstract": "Comments: Accepted to ICASSP, 2022",
    "descriptor": "\nComments: Accepted to ICASSP, 2022\n",
    "authors": [
      "Yair Schiff",
      "Vijil Chenthamarakshan",
      "Samuel Hoffman",
      "Karthikeyan Natesan Ramamurthy",
      "Payel Das"
    ],
    "subjectives": [
      "Chemical Physics (physics.chem-ph)",
      "Machine Learning (cs.LG)",
      "Algebraic Topology (math.AT)"
    ],
    "url": "https://arxiv.org/abs/2106.04464"
  },
  {
    "id": "arXiv:2106.05424",
    "title": "Fair Disaster Containment via Graph-Cut Problems",
    "abstract": "Comments: To appear at AISTATS 2022",
    "descriptor": "\nComments: To appear at AISTATS 2022\n",
    "authors": [
      "Michael Dinitz",
      "Aravind Srinivasan",
      "Leonidas Tsepenekas",
      "Anil Vullikanti"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.05424"
  },
  {
    "id": "arXiv:2106.05648",
    "title": "Unsupervised Behaviour Discovery with Quality-Diversity Optimisation",
    "abstract": "Unsupervised Behaviour Discovery with Quality-Diversity Optimisation",
    "descriptor": "",
    "authors": [
      "Luca Grillotti",
      "Antoine Cully"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2106.05648"
  },
  {
    "id": "arXiv:2106.06745",
    "title": "Minimization and Canonization of GFG Transition-Based Automata",
    "abstract": "Comments: 33 pages, 12 figures, added intuition and explanations between the technical results, added Section 5 with a detailed example of the operation of our algorithm on a GFG-helpful language, typos corrected, modified some proofs. arXiv admin note: substantial text overlap with arXiv:2009.10885",
    "descriptor": "\nComments: 33 pages, 12 figures, added intuition and explanations between the technical results, added Section 5 with a detailed example of the operation of our algorithm on a GFG-helpful language, typos corrected, modified some proofs. arXiv admin note: substantial text overlap with arXiv:2009.10885\n",
    "authors": [
      "Bader Abu Radi",
      "Orna Kupferman"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2106.06745"
  },
  {
    "id": "arXiv:2106.06768",
    "title": "Planning Spatial Networks with Monte Carlo Tree Search",
    "abstract": "Planning Spatial Networks with Monte Carlo Tree Search",
    "descriptor": "",
    "authors": [
      "Victor-Alexandru Darvariu",
      "Stephen Hailes",
      "Mirco Musolesi"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2106.06768"
  },
  {
    "id": "arXiv:2106.07990",
    "title": "The Connection between Process Complexity of Event Sequences and Models  discovered by Process Mining",
    "abstract": "The Connection between Process Complexity of Event Sequences and Models  discovered by Process Mining",
    "descriptor": "",
    "authors": [
      "Adriano Augusto",
      "Jan Mendling",
      "Maxim Vidgof",
      "Bastian Wurm"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2106.07990"
  },
  {
    "id": "arXiv:2106.09362",
    "title": "Frustratingly Easy Transferability Estimation",
    "abstract": "Frustratingly Easy Transferability Estimation",
    "descriptor": "",
    "authors": [
      "Long-Kai Huang",
      "Ying Wei",
      "Yu Rong",
      "Qiang Yang",
      "Junzhou Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.09362"
  },
  {
    "id": "arXiv:2106.13863",
    "title": "Steerable 3D Spherical Neurons",
    "abstract": "Steerable 3D Spherical Neurons",
    "descriptor": "",
    "authors": [
      "Pavlo Melnyk",
      "Michael Felsberg",
      "M\u00e5rten Wadenb\u00e4ck"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13863"
  },
  {
    "id": "arXiv:2107.02692",
    "title": "ML-Quadrat & DriotData: A Model-Driven Engineering Tool and a Low-Code  Platform for Smart IoT Services",
    "abstract": "Comments: ICSE'22 Tool Demo",
    "descriptor": "\nComments: ICSE'22 Tool Demo\n",
    "authors": [
      "Armin Moin",
      "Andrei Mituca",
      "Moharram Challenger",
      "Atta Badii",
      "Stephan G\u00fcnnemann"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.02692"
  },
  {
    "id": "arXiv:2107.05256",
    "title": "Rate-Splitting Multiple Access for Communications and Jamming in  Multi-Antenna Multi-Carrier Cognitive Radio Systems",
    "abstract": "Rate-Splitting Multiple Access for Communications and Jamming in  Multi-Antenna Multi-Carrier Cognitive Radio Systems",
    "descriptor": "",
    "authors": [
      "Onur Dizdar",
      "Bruno Clerckx"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2107.05256"
  },
  {
    "id": "arXiv:2107.05899",
    "title": "Speech Representation Learning Combining Conformer CPC with Deep Cluster  for the ZeroSpeech Challenge 2021",
    "abstract": "Speech Representation Learning Combining Conformer CPC with Deep Cluster  for the ZeroSpeech Challenge 2021",
    "descriptor": "",
    "authors": [
      "Takashi Maekaku",
      "Xuankai Chang",
      "Yuya Fujita",
      "Li-Wei Chen",
      "Shinji Watanabe",
      "Alexander Rudnicky"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2107.05899"
  },
  {
    "id": "arXiv:2107.07183",
    "title": "Streaming Submodular Maximization under Matroid Constraints",
    "abstract": "Comments: 44 pages",
    "descriptor": "\nComments: 44 pages\n",
    "authors": [
      "Moran Feldman",
      "Paul Liu",
      "Ashkan Norouzi-Fard",
      "Ola Svensson",
      "Rico Zenklusen"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2107.07183"
  },
  {
    "id": "arXiv:2107.07623",
    "title": "Correlation detection in trees for planted graph alignment",
    "abstract": "Comments: 39 pages, 11 figures",
    "descriptor": "\nComments: 39 pages, 11 figures\n",
    "authors": [
      "Luca Ganassali",
      "Laurent Massouli\u00e9",
      "Marc Lelarge"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.07623"
  },
  {
    "id": "arXiv:2107.08848",
    "title": "Algorithms for hard-constraint point processes via discretization",
    "abstract": "Algorithms for hard-constraint point processes via discretization",
    "descriptor": "",
    "authors": [
      "Tobias Friedrich",
      "Andreas G\u00f6bel",
      "Maximilian Katzmann",
      "Martin S. Krejca",
      "Marcus Pappik"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2107.08848"
  },
  {
    "id": "arXiv:2107.09777",
    "title": "Conjugate Beamforming with Fractional-Exponent Normalization and  Scalable Power Control in Cell-Free Massive MIMO",
    "abstract": "Comments: Paper published in the proceedings of IEEE SPAWC 2021. {\\copyright} 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses",
    "descriptor": "\nComments: Paper published in the proceedings of IEEE SPAWC 2021. {\\copyright} 2021 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses\n",
    "authors": [
      "Giovanni Interdonato",
      "Stefano Buzzi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2107.09777"
  },
  {
    "id": "arXiv:2107.11304",
    "title": "Finite-Bit Quantization For Distributed Algorithms With Linear  Convergence",
    "abstract": "Comments: Submitted to the IEEE Transactions on Information Theory",
    "descriptor": "\nComments: Submitted to the IEEE Transactions on Information Theory\n",
    "authors": [
      "Nicol\u00f2 Michelusi",
      "Gesualdo Scutari",
      "Chang-Shen Lee"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.11304"
  },
  {
    "id": "arXiv:2107.11941",
    "title": "Computation of Reachable Sets Based on Hamilton-Jacobi-Bellman Equation  with Running Cost Function",
    "abstract": "Computation of Reachable Sets Based on Hamilton-Jacobi-Bellman Equation  with Running Cost Function",
    "descriptor": "",
    "authors": [
      "Weiwei Liao",
      "Tao Liang"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.11941"
  },
  {
    "id": "arXiv:2107.13282",
    "title": "Dense Graph Partitioning on sparse and dense graphs",
    "abstract": "Dense Graph Partitioning on sparse and dense graphs",
    "descriptor": "",
    "authors": [
      "Cristina Bazgan",
      "Katrin Casel",
      "Pierre Cazals"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)"
    ],
    "url": "https://arxiv.org/abs/2107.13282"
  },
  {
    "id": "arXiv:2107.13659",
    "title": "Quantum Annealing Algorithms for Boolean Tensor Networks",
    "abstract": "Comments: Reduced size to 14 pages",
    "descriptor": "\nComments: Reduced size to 14 pages\n",
    "authors": [
      "Elijah Pelofske",
      "Georg Hahn",
      "Daniel O'Malley",
      "Hristo N. Djidjev",
      "Boian S. Alexandrov"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2107.13659"
  },
  {
    "id": "arXiv:2107.14293",
    "title": "Self-Supervised Transformer for Sparse and Irregularly Sampled  Multivariate Clinical Time-Series",
    "abstract": "Comments: Changed title to better reflect the challenges dealt with in the paper. Improved section 4.6. Changed the format to use ACM camera-ready template",
    "descriptor": "\nComments: Changed title to better reflect the challenges dealt with in the paper. Improved section 4.6. Changed the format to use ACM camera-ready template\n",
    "authors": [
      "Sindhu Tipirneni",
      "Chandan K. Reddy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2107.14293"
  },
  {
    "id": "arXiv:2108.00709",
    "title": "Biobjective Optimization Problems on Matroids with Binary Costs",
    "abstract": "Biobjective Optimization Problems on Matroids with Binary Costs",
    "descriptor": "",
    "authors": [
      "Jochen Gorski",
      "Kathrin Klamroth",
      "Julia Sudhoff"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2108.00709"
  },
  {
    "id": "arXiv:2108.02214",
    "title": "A FAIR and AI-ready Higgs boson decay dataset",
    "abstract": "Comments: 13 pages, 3 figures. v2: Accepted to Nature Scientific Data. Learn about the FAIR4HEP project at this https URL See our invited Behind the Paper Blog in Springer Nature Research Data Community at this https URL",
    "descriptor": "\nComments: 13 pages, 3 figures. v2: Accepted to Nature Scientific Data. Learn about the FAIR4HEP project at this https URL See our invited Behind the Paper Blog in Springer Nature Research Data Community at this https URL\n",
    "authors": [
      "Yifan Chen",
      "E. A. Huerta",
      "Javier Duarte",
      "Philip Harris",
      "Daniel S. Katz",
      "Mark S. Neubauer",
      "Daniel Diaz",
      "Farouk Mokhtar",
      "Raghav Kansal",
      "Sang Eon Park",
      "Volodymyr V. Kindratenko",
      "Zhizhen Zhao",
      "Roger Rusack"
    ],
    "subjectives": [
      "High Energy Physics - Experiment (hep-ex)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)",
      "High Energy Physics - Phenomenology (hep-ph)"
    ],
    "url": "https://arxiv.org/abs/2108.02214"
  },
  {
    "id": "arXiv:2108.02336",
    "title": "A Fracture Multiscale Model for Peridynamic enrichment within the  Partition of Unity Method: Part I",
    "abstract": "A Fracture Multiscale Model for Peridynamic enrichment within the  Partition of Unity Method: Part I",
    "descriptor": "",
    "authors": [
      "Matthias Birner",
      "Patrick Diehl",
      "Robert Lipton",
      "Marc Alexander Schweitzer"
    ],
    "subjectives": [
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2108.02336"
  },
  {
    "id": "arXiv:2108.02465",
    "title": "On Regularization via Frame Decompositions with Applications in  Tomography",
    "abstract": "Comments: 30 pages, 6 figures",
    "descriptor": "\nComments: 30 pages, 6 figures\n",
    "authors": [
      "Simon Hubmer",
      "Ronny Ramlau",
      "Lukas Weissinger"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2108.02465"
  },
  {
    "id": "arXiv:2108.06891",
    "title": "Efficient Network Analysis Under Single Link Deletion",
    "abstract": "Comments: Found previous published results with similar findings",
    "descriptor": "\nComments: Found previous published results with similar findings\n",
    "authors": [
      "Max Ward",
      "Amitava Datta",
      "Hung X. Nguyen",
      "Jason Eshraghian"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2108.06891"
  },
  {
    "id": "arXiv:2108.13105",
    "title": "COMPRA: A COMPact Reactive Autonomy framework for subterranean MAV based  search-and-rescue operations",
    "abstract": "Comments: 27 pages, 21 figures",
    "descriptor": "\nComments: 27 pages, 21 figures\n",
    "authors": [
      "Bj\u00f6rn Lindqvist",
      "Christoforos Kanellakis",
      "Sina Sharif Mansouri",
      "Ali-akbar Agha-mohammadi",
      "George Nikolakopoulos"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2108.13105"
  },
  {
    "id": "arXiv:2108.13551",
    "title": "Regularizing Instabilities in Image Reconstruction Arising from Learned  Denoisers",
    "abstract": "Regularizing Instabilities in Image Reconstruction Arising from Learned  Denoisers",
    "descriptor": "",
    "authors": [
      "Abinash Nayak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2108.13551"
  },
  {
    "id": "arXiv:2109.00969",
    "title": "Reference Publication Year Spectroscopy (RPYS) in practice: A software  tutorial",
    "abstract": "Comments: 29 pages, 6 figures, and 5 tables",
    "descriptor": "\nComments: 29 pages, 6 figures, and 5 tables\n",
    "authors": [
      "Robin Haunschild",
      "Lutz Bornmann"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2109.00969"
  },
  {
    "id": "arXiv:2109.04784",
    "title": "A Dynamic Scheduling Policy for a Network with Heterogeneous  Time-Sensitive Traffic",
    "abstract": "Comments: Submitted in a journal",
    "descriptor": "\nComments: Submitted in a journal\n",
    "authors": [
      "Emmanouil Fountoulakis",
      "Themistoklis Charalambous",
      "Anthony Ephremides",
      "Nikolaos Pappas"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.04784"
  },
  {
    "id": "arXiv:2109.06332",
    "title": "Achieving Zero Constraint Violation for Concave Utility Constrained  Reinforcement Learning via Primal-Dual Approach",
    "abstract": "Achieving Zero Constraint Violation for Concave Utility Constrained  Reinforcement Learning via Primal-Dual Approach",
    "descriptor": "",
    "authors": [
      "Qinbo Bai",
      "Amrit Singh Bedi",
      "Mridul Agarwal",
      "Alec Koppel",
      "Vaneet Aggarwal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.06332"
  },
  {
    "id": "arXiv:2109.08776",
    "title": "Exploring the Training Robustness of Distributional Reinforcement  Learning against Noisy State Observations",
    "abstract": "Exploring the Training Robustness of Distributional Reinforcement  Learning against Noisy State Observations",
    "descriptor": "",
    "authors": [
      "Ke Sun",
      "Yi Liu",
      "Yingnan Zhao",
      "Hengshuai Yao",
      "Shangling Jui",
      "Linglong Kong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.08776"
  },
  {
    "id": "arXiv:2109.10231",
    "title": "SalienTrack: providing salient information for semi-automated  self-tracking feedback with model explanations",
    "abstract": "SalienTrack: providing salient information for semi-automated  self-tracking feedback with model explanations",
    "descriptor": "",
    "authors": [
      "Yunlong Wang",
      "Jiaying Liu",
      "Homin Park",
      "Jordan Schultz-McArdle",
      "Stephanie Rosenthal",
      "Judy Kay",
      "Brian Y. Lim"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2109.10231"
  },
  {
    "id": "arXiv:2109.10481",
    "title": "Sparse Uniformity Testing",
    "abstract": "Comments: 33 pages, 1 figure",
    "descriptor": "\nComments: 33 pages, 1 figure\n",
    "authors": [
      "Bhaswar B. Bhattacharya",
      "Rajarshi Mukherjee"
    ],
    "subjectives": [
      "Statistics Theory (math.ST)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.10481"
  },
  {
    "id": "arXiv:2109.10659",
    "title": "Improved variants of the Hutch++ algorithm for trace estimation",
    "abstract": "Improved variants of the Hutch++ algorithm for trace estimation",
    "descriptor": "",
    "authors": [
      "David Persson",
      "Alice Cortinovis",
      "Daniel Kressner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2109.10659"
  },
  {
    "id": "arXiv:2109.10691",
    "title": "Query Evaluation in DatalogMTL -- Taming Infinite Query Results",
    "abstract": "Query Evaluation in DatalogMTL -- Taming Infinite Query Results",
    "descriptor": "",
    "authors": [
      "Luigi Bellomarini",
      "Markus Nissl",
      "Emanuel Sallinger"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Artificial Intelligence (cs.AI)",
      "Databases (cs.DB)"
    ],
    "url": "https://arxiv.org/abs/2109.10691"
  },
  {
    "id": "arXiv:2109.10888",
    "title": "A Functional Operator for Model Uncertainty Quantification in the RKHS",
    "abstract": "Comments: Fig. 1 updated. Minor corrections added. Figure captions and labels corrected. Updated version of arXiv:2103.01374",
    "descriptor": "\nComments: Fig. 1 updated. Minor corrections added. Figure captions and labels corrected. Updated version of arXiv:2103.01374\n",
    "authors": [
      "Rishabh Singh",
      "Jose C. Principe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.10888"
  },
  {
    "id": "arXiv:2109.11091",
    "title": "Shape Control of Deformable Linear Objects with Offline and Online  Learning of Local Linear Deformation Models",
    "abstract": "Comments: Accepted by ICRA 2022",
    "descriptor": "\nComments: Accepted by ICRA 2022\n",
    "authors": [
      "Mingrui Yu",
      "Hanzhong Zhong",
      "Xiang Li"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.11091"
  },
  {
    "id": "arXiv:2109.11576",
    "title": "Efficient, Interpretable Graph Neural Network Representation for  Angle-dependent Properties and its Application to Optical Spectroscopy",
    "abstract": "Efficient, Interpretable Graph Neural Network Representation for  Angle-dependent Properties and its Application to Optical Spectroscopy",
    "descriptor": "",
    "authors": [
      "Tim Hsu",
      "Tuan Anh Pham",
      "Nathan Keilbart",
      "Stephen Weitzner",
      "James Chapman",
      "Penghao Xiao",
      "S. Roger Qiu",
      "Xiao Chen",
      "Brandon C. Wood"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2109.11576"
  },
  {
    "id": "arXiv:2109.11679",
    "title": "Safe Policy Learning through Extrapolation: Application to Pre-trial  Risk Assessment",
    "abstract": "Safe Policy Learning through Extrapolation: Application to Pre-trial  Risk Assessment",
    "descriptor": "",
    "authors": [
      "Eli Ben-Michael",
      "D. James Greiner",
      "Kosuke Imai",
      "Zhichao Jiang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2109.11679"
  },
  {
    "id": "arXiv:2109.11941",
    "title": "Two-Stage Mesh Deep Learning for Automated Tooth Segmentation and  Landmark Localization on 3D Intraoral Scans",
    "abstract": "Comments: 9 pages, 8 figures, submitted to IEEE TMI",
    "descriptor": "\nComments: 9 pages, 8 figures, submitted to IEEE TMI\n",
    "authors": [
      "Tai-Hsien Wu",
      "Chunfeng Lian",
      "Sanghee Lee",
      "Matthew Pastewait",
      "Christian Piers",
      "Jie Liu",
      "Fang Wang",
      "Li Wang",
      "Chiung-Ying Chiu",
      "Wenchi Wang",
      "Christina Jackson",
      "Wei-Lun Chao",
      "Dinggang Shen",
      "Ching-Chang Ko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.11941"
  },
  {
    "id": "arXiv:2109.12401",
    "title": "Incentives in Dominant Resource Fair Allocation under Dynamic Demands",
    "abstract": "Incentives in Dominant Resource Fair Allocation under Dynamic Demands",
    "descriptor": "",
    "authors": [
      "Giannis Fikioris",
      "Rachit Agarwal",
      "\u00c9va Tardos"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2109.12401"
  },
  {
    "id": "arXiv:2109.13656",
    "title": "Opinionated practices for teaching reproducibility: motivation, guided  instruction and practice",
    "abstract": "Opinionated practices for teaching reproducibility: motivation, guided  instruction and practice",
    "descriptor": "",
    "authors": [
      "Joel Ostblom",
      "Tiffany Timbers"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2109.13656"
  },
  {
    "id": "arXiv:2109.14004",
    "title": "Joint Communication and Motion Planning for Cobots",
    "abstract": "Joint Communication and Motion Planning for Cobots",
    "descriptor": "",
    "authors": [
      "Mehdi Dadvar",
      "Keyvan Majd",
      "Elena Oikonomou",
      "Georgios Fainekos",
      "Siddharth Srivastava"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.14004"
  },
  {
    "id": "arXiv:2110.00165",
    "title": "Large-scale ASR Domain Adaptation using Self- and Semi-supervised  Learning",
    "abstract": "Comments: ICASSP 2022 accepted, 5 pages, 2 figures, 5 tables",
    "descriptor": "\nComments: ICASSP 2022 accepted, 5 pages, 2 figures, 5 tables\n",
    "authors": [
      "Dongseong Hwang",
      "Ananya Misra",
      "Zhouyuan Huo",
      "Nikhil Siddhartha",
      "Shefali Garg",
      "David Qiu",
      "Khe Chai Sim",
      "Trevor Strohman",
      "Fran\u00e7oise Beaufays",
      "Yanzhang He"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.00165"
  },
  {
    "id": "arXiv:2110.00466",
    "title": "A Graph-theoretic Algorithm for Small Bowel Path Tracking in CT Scans",
    "abstract": "Comments: Accepted to SPIE Medical Imaging 2022",
    "descriptor": "\nComments: Accepted to SPIE Medical Imaging 2022\n",
    "authors": [
      "Seung Yeon Shin",
      "Sungwon Lee",
      "Ronald M. Summers"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.00466"
  },
  {
    "id": "arXiv:2110.02687",
    "title": "Objects in Semantic Topology",
    "abstract": "Comments: ICLR 2022",
    "descriptor": "\nComments: ICLR 2022\n",
    "authors": [
      "Shuo Yang",
      "Peize Sun",
      "Yi Jiang",
      "Xiaobo Xia",
      "Ruiheng Zhang",
      "Zehuan Yuan",
      "Changhu Wang",
      "Ping Luo",
      "Min Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.02687"
  },
  {
    "id": "arXiv:2110.02898",
    "title": "Coresets for Kernel Clustering",
    "abstract": "Coresets for Kernel Clustering",
    "descriptor": "",
    "authors": [
      "Shaofeng H.-C. Jiang",
      "Robert Krauthgamer",
      "Jianing Lou",
      "Yubo Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.02898"
  },
  {
    "id": "arXiv:2110.03155",
    "title": "Interpreting Distributional Reinforcement Learning: Regularization and  Optimization Perspectives",
    "abstract": "Interpreting Distributional Reinforcement Learning: Regularization and  Optimization Perspectives",
    "descriptor": "",
    "authors": [
      "Ke Sun",
      "Yingnan Zhao",
      "Yi Liu",
      "Enze Shi",
      "Yafei Wang",
      "Aref Sadeghi",
      "Xiaodong Yan",
      "Bei Jiang",
      "Linglong Kong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03155"
  },
  {
    "id": "arXiv:2110.03689",
    "title": "DeepECMP: Predicting Extracellular Matrix Proteins using Deep Learning",
    "abstract": "Comments: Required improving",
    "descriptor": "\nComments: Required improving\n",
    "authors": [
      "Mohamed Ghafoor",
      "Anh Nguyen"
    ],
    "subjectives": [
      "Quantitative Methods (q-bio.QM)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.03689"
  },
  {
    "id": "arXiv:2110.03691",
    "title": "Direct design of biquad filter cascades with deep learning by sampling  random polynomials",
    "abstract": "Comments: Accepted to ICASSP 2022",
    "descriptor": "\nComments: Accepted to ICASSP 2022\n",
    "authors": [
      "Joseph T. Colonel",
      "Christian J. Steinmetz",
      "Marcus Michelen",
      "Joshua D. Reiss"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.03691"
  },
  {
    "id": "arXiv:2110.06773",
    "title": "Leveraging Automated Unit Tests for Unsupervised Code Translation",
    "abstract": "Leveraging Automated Unit Tests for Unsupervised Code Translation",
    "descriptor": "",
    "authors": [
      "Baptiste Roziere",
      "Jie M. Zhang",
      "Francois Charton",
      "Mark Harman",
      "Gabriel Synnaeve",
      "Guillaume Lample"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.06773"
  },
  {
    "id": "arXiv:2110.06841",
    "title": "On Language Model Integration for RNN Transducer based Speech  Recognition",
    "abstract": "Comments: accepted at ICASSP2022",
    "descriptor": "\nComments: accepted at ICASSP2022\n",
    "authors": [
      "Wei Zhou",
      "Zuoyun Zheng",
      "Ralf Schl\u00fcter",
      "Hermann Ney"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.06841"
  },
  {
    "id": "arXiv:2110.08128",
    "title": "Label-Wise Message Passing Graph Neural Network on Heterophilic Graphs",
    "abstract": "Label-Wise Message Passing Graph Neural Network on Heterophilic Graphs",
    "descriptor": "",
    "authors": [
      "Enyan Dai",
      "Shijie Zhou",
      "Zhimeng Guo",
      "Suhang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08128"
  },
  {
    "id": "arXiv:2110.09202",
    "title": "Finding Strong Gravitational Lenses Through Self-Attention",
    "abstract": "Comments: 17 Pages, 4 tables and 19 Figures",
    "descriptor": "\nComments: 17 Pages, 4 tables and 19 Figures\n",
    "authors": [
      "Hareesh Thuruthipilly",
      "Adam Zadrozny",
      "Agnieszka Pollo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Astrophysics of Galaxies (astro-ph.GA)",
      "Instrumentation and Methods for Astrophysics (astro-ph.IM)"
    ],
    "url": "https://arxiv.org/abs/2110.09202"
  },
  {
    "id": "arXiv:2110.10132",
    "title": "FriendlyCore: Practical Differentially Private Aggregation",
    "abstract": "FriendlyCore: Practical Differentially Private Aggregation",
    "descriptor": "",
    "authors": [
      "Eliad Tsfadia",
      "Edith Cohen",
      "Haim Kaplan",
      "Yishay Mansour",
      "Uri Stemmer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2110.10132"
  },
  {
    "id": "arXiv:2110.10324",
    "title": "Semantic Sensing and Planning for Human-Robot Collaboration in Uncertain  Environments",
    "abstract": "Semantic Sensing and Planning for Human-Robot Collaboration in Uncertain  Environments",
    "descriptor": "",
    "authors": [
      "Luke Burks",
      "Hunter M. Ray",
      "Jamison McGinley",
      "Sousheel Vunnam",
      "Nisar Ahmed"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2110.10324"
  },
  {
    "id": "arXiv:2110.11073",
    "title": "RL4RS: A Real-World Benchmark for Reinforcement Learning based  Recommender System",
    "abstract": "Comments: second version",
    "descriptor": "\nComments: second version\n",
    "authors": [
      "Kai Wang",
      "Zhene Zou",
      "Yue Shang",
      "Qilin Deng",
      "Minghao Zhao",
      "Runze Wu",
      "Xudong Shen",
      "Tangjie Lyu",
      "Changjie Fan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11073"
  },
  {
    "id": "arXiv:2110.12919",
    "title": "WOLF: A modular estimation framework for robotics based on factor graphs",
    "abstract": "Comments: 8 pages, 12 figures. v1: removed repository link. v2: add TERRINET thanks. v3: full review, authors addition and fix. v4: Fix one citation",
    "descriptor": "\nComments: 8 pages, 12 figures. v1: removed repository link. v2: add TERRINET thanks. v3: full review, authors addition and fix. v4: Fix one citation\n",
    "authors": [
      "Joan Sola",
      "Joan Vallve",
      "Joaquim Casals",
      "Jeremie Deray",
      "Mederic Fourmy",
      "Dinesh Atchuthan",
      "Andreu Corominas-Murtra",
      "Juan Andrade-Cetto"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.12919"
  },
  {
    "id": "arXiv:2110.13786",
    "title": "Diversity and Generalization in Neural Network Ensembles",
    "abstract": "Diversity and Generalization in Neural Network Ensembles",
    "descriptor": "",
    "authors": [
      "Luis A. Ortega",
      "Rafael Caba\u00f1as",
      "Andr\u00e9s R. Masegosa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2110.13786"
  },
  {
    "id": "arXiv:2110.14532",
    "title": "FacTeR-Check: Semi-automated fact-checking through Semantic Similarity  and Natural Language Inference",
    "abstract": "FacTeR-Check: Semi-automated fact-checking through Semantic Similarity  and Natural Language Inference",
    "descriptor": "",
    "authors": [
      "Alejandro Mart\u00edn",
      "Javier Huertas-Tato",
      "\u00c1lvaro Huertas-Garc\u00eda",
      "Guillermo Villar-Rodr\u00edguez",
      "David Camacho"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.14532"
  },
  {
    "id": "arXiv:2110.14728",
    "title": "Lung Cancer Lesion Detection in Histopathology Images Using Graph-Based  Sparse PCA Network",
    "abstract": "Comments: 10 pages, 9 figures, 3 tables",
    "descriptor": "\nComments: 10 pages, 9 figures, 3 tables\n",
    "authors": [
      "Sundaresh Ram",
      "Wenfei Tang",
      "Alexander J. Bell",
      "Cara Spencer",
      "Alexander Buschhaus",
      "Charles R. Hatt",
      "Marina Pasca diMagliano",
      "Jeffrey J. Rodriguez",
      "Stefanie Galban",
      "Craig J. Galban"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2110.14728"
  },
  {
    "id": "arXiv:2110.14953",
    "title": "Multi-Task Neural Processes",
    "abstract": "Comments: 33 pages, 13 figures",
    "descriptor": "\nComments: 33 pages, 13 figures\n",
    "authors": [
      "Donggyun Kim",
      "Seongwoong Cho",
      "Wonkwang Lee",
      "Seunghoon Hong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2110.14953"
  },
  {
    "id": "arXiv:2110.15018",
    "title": "TorchAudio: Building Blocks for Audio and Speech Processing",
    "abstract": "Comments: Accepted by ICASSP 2022",
    "descriptor": "\nComments: Accepted by ICASSP 2022\n",
    "authors": [
      "Yao-Yuan Yang",
      "Moto Hira",
      "Zhaoheng Ni",
      "Anjali Chourdia",
      "Artyom Astafurov",
      "Caroline Chen",
      "Ching-Feng Yeh",
      "Christian Puhrsch",
      "David Pollack",
      "Dmitriy Genzel",
      "Donny Greenberg",
      "Edward Z. Yang",
      "Jason Lian",
      "Jay Mahadeokar",
      "Jeff Hwang",
      "Ji Chen",
      "Peter Goldsborough",
      "Prabhat Roy",
      "Sean Narenthiran",
      "Shinji Watanabe",
      "Soumith Chintala",
      "Vincent Quenneville-B\u00e9lair",
      "Yangyang Shi"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.15018"
  },
  {
    "id": "arXiv:2110.15701",
    "title": "Xi-Learning: Successor Feature Transfer Learning for General Reward  Functions",
    "abstract": "Comments: source code available at this https URL [v2] added experiments with learned features",
    "descriptor": "\nComments: source code available at this https URL [v2] added experiments with learned features\n",
    "authors": [
      "Chris Reinke",
      "Xavier Alameda-Pineda"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.15701"
  },
  {
    "id": "arXiv:2111.00113",
    "title": "Fast & Accurate Randomized Algorithms for Linear Systems and Eigenvalue  Problems",
    "abstract": "Comments: 30 pages, 6 figures",
    "descriptor": "\nComments: 30 pages, 6 figures\n",
    "authors": [
      "Yuji Nakatsukasa",
      "Joel A. Tropp"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2111.00113"
  },
  {
    "id": "arXiv:2111.00607",
    "title": "Do Language Models Learn Commonsense Knowledge?",
    "abstract": "Do Language Models Learn Commonsense Knowledge?",
    "descriptor": "",
    "authors": [
      "Xiang Lorraine Li",
      "Adhiguna Kuncoro",
      "Cyprien de Masson d'Autume",
      "Phil Blunsom",
      "Aida Nematzadeh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.00607"
  },
  {
    "id": "arXiv:2111.01701",
    "title": "Improve Single-Point Zeroth-Order Optimization Using High-Pass and  Low-Pass Filters",
    "abstract": "Improve Single-Point Zeroth-Order Optimization Using High-Pass and  Low-Pass Filters",
    "descriptor": "",
    "authors": [
      "Xin Chen",
      "Yujie Tang",
      "Na Li"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.01701"
  },
  {
    "id": "arXiv:2111.03122",
    "title": "Functional connectivity ensemble method to enhance BCI performance  (FUCONE)",
    "abstract": "Functional connectivity ensemble method to enhance BCI performance  (FUCONE)",
    "descriptor": "",
    "authors": [
      "Marie-Constance Corsi",
      "Sylvain Chevallier",
      "Fabrizio De Vico Fallani",
      "Florian Yger"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.03122"
  },
  {
    "id": "arXiv:2111.04986",
    "title": "Unified Group Fairness on Federated Learning",
    "abstract": "Unified Group Fairness on Federated Learning",
    "descriptor": "",
    "authors": [
      "Fengda Zhang",
      "Kun Kuang",
      "Yuxuan Liu",
      "Long Chen",
      "Chao Wu",
      "Fei Wu",
      "Jiaxun Lu",
      "Yunfeng Shao",
      "Jun Xiao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.04986"
  },
  {
    "id": "arXiv:2111.05995",
    "title": "Parallel Quantum Annealing",
    "abstract": "Comments: 12 pages",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Elijah Pelofske",
      "Georg Hahn",
      "Hristo N. Djidjev"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2111.05995"
  },
  {
    "id": "arXiv:2111.06839",
    "title": "The self-supervised spectral-spatial attention-based transformer network  for automated, accurate prediction of crop nitrogen status from UAV imagery",
    "abstract": "The self-supervised spectral-spatial attention-based transformer network  for automated, accurate prediction of crop nitrogen status from UAV imagery",
    "descriptor": "",
    "authors": [
      "Xin Zhang",
      "Liangxiu Han",
      "Tam Sobeih",
      "Lewis Lappin",
      "Mark Lee",
      "Andew Howard",
      "Aron Kisdi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.06839"
  },
  {
    "id": "arXiv:2111.07401",
    "title": "Neural Capacity Estimators: How Reliable Are They?",
    "abstract": "Comments: 7 pages, 5 figures, accepted for publication at the 2022 IEEE International Conference on Communications (ICC)",
    "descriptor": "\nComments: 7 pages, 5 figures, accepted for publication at the 2022 IEEE International Conference on Communications (ICC)\n",
    "authors": [
      "Farhad Mirkarimi",
      "Stefano Rini",
      "Nariman Farsad"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2111.07401"
  },
  {
    "id": "arXiv:2111.07478",
    "title": "Physics in the Machine: Integrating Physical Knowledge in Autonomous  Phase-Mapping",
    "abstract": "Physics in the Machine: Integrating Physical Knowledge in Autonomous  Phase-Mapping",
    "descriptor": "",
    "authors": [
      "A. Gilad Kusne",
      "Austin McDannald",
      "Brian DeCost",
      "Corey Oses",
      "Cormac Toher",
      "Stefano Curtarolo",
      "Apurva Mehta",
      "Ichiro Takeuchi"
    ],
    "subjectives": [
      "Materials Science (cond-mat.mtrl-sci)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.07478"
  },
  {
    "id": "arXiv:2111.08211",
    "title": "FedCG: Leverage Conditional GAN for Protecting Privacy and Maintaining  Competitive Performance in Federated Learning",
    "abstract": "FedCG: Leverage Conditional GAN for Protecting Privacy and Maintaining  Competitive Performance in Federated Learning",
    "descriptor": "",
    "authors": [
      "Yuezhou Wu",
      "Yan Kang",
      "Jiahuan Luo",
      "Yuanqin He",
      "Qiang Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08211"
  },
  {
    "id": "arXiv:2111.08410",
    "title": "Thoughts on the Consistency between Ricci Flow and Neural Network  Behavior",
    "abstract": "Thoughts on the Consistency between Ricci Flow and Neural Network  Behavior",
    "descriptor": "",
    "authors": [
      "Jun Chen",
      "Tianxin Huang",
      "Wenzhou Chen",
      "Yong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.08410"
  },
  {
    "id": "arXiv:2111.11266",
    "title": "Modular structure of the Weyl algebra",
    "abstract": "Comments: Minor corrections. To appear in Communications in Mathematical Physics",
    "descriptor": "\nComments: Minor corrections. To appear in Communications in Mathematical Physics\n",
    "authors": [
      "Roberto Longo"
    ],
    "subjectives": [
      "Mathematical Physics (math-ph)",
      "Information Theory (cs.IT)",
      "High Energy Physics - Theory (hep-th)",
      "Analysis of PDEs (math.AP)",
      "Operator Algebras (math.OA)"
    ],
    "url": "https://arxiv.org/abs/2111.11266"
  },
  {
    "id": "arXiv:2112.01097",
    "title": "CoviChain: A Blockchain Based COVID-19 Vaccination Passport",
    "abstract": "CoviChain: A Blockchain Based COVID-19 Vaccination Passport",
    "descriptor": "",
    "authors": [
      "Hitesh Tewari"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.01097"
  },
  {
    "id": "arXiv:2112.01641",
    "title": "Hamiltonian Operator Disentanglement of Content and Motion in Image  Sequences",
    "abstract": "Hamiltonian Operator Disentanglement of Content and Motion in Image  Sequences",
    "descriptor": "",
    "authors": [
      "Asif Khan",
      "Amos Storkey"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.01641"
  },
  {
    "id": "arXiv:2112.02174",
    "title": "Unifying the geometric decompositions of full and trimmed polynomial  spaces in finite element exterior calculus",
    "abstract": "Comments: 21 pages",
    "descriptor": "\nComments: 21 pages\n",
    "authors": [
      "Toby Isaac"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2112.02174"
  },
  {
    "id": "arXiv:2112.02418",
    "title": "YourTTS: Towards Zero-Shot Multi-Speaker TTS and Zero-Shot Voice  Conversion for everyone",
    "abstract": "YourTTS: Towards Zero-Shot Multi-Speaker TTS and Zero-Shot Voice  Conversion for everyone",
    "descriptor": "",
    "authors": [
      "Edresson Casanova",
      "Julian Weber",
      "Christopher Shulby",
      "Arnaldo Candido Junior",
      "Eren G\u00f6lge",
      "Moacir Antonelli Ponti"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2112.02418"
  },
  {
    "id": "arXiv:2112.02758",
    "title": "A Tool for Rejuvenating Feature Logging Levels via Git Histories and  Degree of Interest",
    "abstract": "Comments: 4 pages, ICSE '22 (tool demo track)",
    "descriptor": "\nComments: 4 pages, ICSE '22 (tool demo track)\n",
    "authors": [
      "Yiming Tang",
      "Allan Spektor",
      "Raffi Khatchadourian",
      "Mehdi Bagherzadeh"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2112.02758"
  },
  {
    "id": "arXiv:2112.03120",
    "title": "Faster Cut Sparsification of Weighted Graphs",
    "abstract": "Faster Cut Sparsification of Weighted Graphs",
    "descriptor": "",
    "authors": [
      "Sebastian Forster",
      "Tijn de Vos"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2112.03120"
  },
  {
    "id": "arXiv:2112.06402",
    "title": "MotionBenchMaker: A Tool to Generate and Benchmark Motion Planning  Datasets",
    "abstract": "Comments: accepted in IEEE Robotics and Automation Letters (RAL), 2022. Supplementary video: this https URL Code: this https URL",
    "descriptor": "\nComments: accepted in IEEE Robotics and Automation Letters (RAL), 2022. Supplementary video: this https URL Code: this https URL\n",
    "authors": [
      "Constantinos Chamzas",
      "Carlos Quintero-Pe\u00f1a",
      "Zachary Kingston",
      "Andreas Orthey",
      "Daniel Rakita",
      "Michael Gleicher",
      "Marc Toussaint",
      "Lydia E. Kavraki"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2112.06402"
  },
  {
    "id": "arXiv:2112.06428",
    "title": "Holistic Interpretation of Public Scenes Using Computer Vision and  Temporal Graphs to Identify Social Distancing Violations",
    "abstract": "Comments: 35 pages, 22 figures",
    "descriptor": "\nComments: 35 pages, 22 figures\n",
    "authors": [
      "Gihan Jayatilaka",
      "Jameel Hassan",
      "Suren Sritharan",
      "Janith Bandara Senananayaka",
      "Harshana Weligampola",
      "Roshan Godaliyadda",
      "Parakrama Ekanayake",
      "Vijitha Herath",
      "Janaka Ekanayake",
      "Samath Dharmaratne"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2112.06428"
  },
  {
    "id": "arXiv:2112.11172",
    "title": "Dynamically Stable Poincar\u00e9 Embeddings for Neural Manifolds",
    "abstract": "Dynamically Stable Poincar\u00e9 Embeddings for Neural Manifolds",
    "descriptor": "",
    "authors": [
      "Jun Chen",
      "Yuang Liu",
      "Xiangrui Zhao",
      "Mengmeng Wang",
      "Yong Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Mathematical Physics (math-ph)"
    ],
    "url": "https://arxiv.org/abs/2112.11172"
  },
  {
    "id": "arXiv:2112.12228",
    "title": "Direct Behavior Specification via Constrained Reinforcement Learning",
    "abstract": "Direct Behavior Specification via Constrained Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Julien Roy",
      "Roger Girgis",
      "Joshua Romoff",
      "Pierre-Luc Bacon",
      "Christopher Pal"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2112.12228"
  },
  {
    "id": "arXiv:2112.13747",
    "title": "Scenario Adaptive Mixture-of-Experts for Promotion-Aware Click-Through  Rate Prediction",
    "abstract": "Scenario Adaptive Mixture-of-Experts for Promotion-Aware Click-Through  Rate Prediction",
    "descriptor": "",
    "authors": [
      "Xiaofeng Pan",
      "Yibin Shen",
      "Jing Zhang",
      "Keren Yu",
      "Hong Wen",
      "Shui Liu",
      "Chengjun Mao",
      "Bo Cao"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2112.13747"
  },
  {
    "id": "arXiv:2112.13838",
    "title": "Tracking Most Significant Arm Switches in Bandits",
    "abstract": "Tracking Most Significant Arm Switches in Bandits",
    "descriptor": "",
    "authors": [
      "Joe Suk",
      "Samory Kpotufe"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2112.13838"
  },
  {
    "id": "arXiv:2112.14233",
    "title": "Learning Across Bandits in High Dimension via Robust Statistics",
    "abstract": "Learning Across Bandits in High Dimension via Robust Statistics",
    "descriptor": "",
    "authors": [
      "Kan Xu",
      "Hamsa Bastani"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2112.14233"
  },
  {
    "id": "arXiv:2201.00703",
    "title": "Stochastic Continuous Submodular Maximization: Boosting via  Non-oblivious Function",
    "abstract": "Comments: 29 pages, 5 figures, 2 tables",
    "descriptor": "\nComments: 29 pages, 5 figures, 2 tables\n",
    "authors": [
      "Qixin Zhang",
      "Zengde Deng",
      "Zaiyi Chen",
      "Haoyuan Hu",
      "Yu Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2201.00703"
  },
  {
    "id": "arXiv:2201.02311",
    "title": "Electric Vehicle Routing Problem with Spatio-temporal Varying  Electricity Price and Incentive-aware Customers",
    "abstract": "Comments: The manuscript hasn't been reviewed by one of authors",
    "descriptor": "\nComments: The manuscript hasn't been reviewed by one of authors\n",
    "authors": [
      "Canqi Yao",
      "Shibo Chen",
      "Mauro Salazar",
      "Zaiyue Yang"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.02311"
  },
  {
    "id": "arXiv:2201.02993",
    "title": "Rethink the Evaluation for Attack Strength of Backdoor Attacks in  Natural Language Processing",
    "abstract": "Rethink the Evaluation for Attack Strength of Backdoor Attacks in  Natural Language Processing",
    "descriptor": "",
    "authors": [
      "Lingfeng Shen",
      "Haiyun Jiang",
      "Lemao Liu",
      "Shuming Shi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.02993"
  },
  {
    "id": "arXiv:2201.03339",
    "title": "NeuroPack: An Algorithm-level Python-based Simulator for  Memristor-empowered Neuro-inspired Computing",
    "abstract": "NeuroPack: An Algorithm-level Python-based Simulator for  Memristor-empowered Neuro-inspired Computing",
    "descriptor": "",
    "authors": [
      "Jinqi Huang",
      "Spyros Stathopoulos",
      "Alex Serb",
      "Themis Prodromakis"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.03339"
  },
  {
    "id": "arXiv:2201.03681",
    "title": "FairEdit: Preserving Fairness in Graph Neural Networks through Greedy  Graph Editing",
    "abstract": "FairEdit: Preserving Fairness in Graph Neural Networks through Greedy  Graph Editing",
    "descriptor": "",
    "authors": [
      "Donald Loveland",
      "Jiayi Pan",
      "Aaresh Farrokh Bhathena",
      "Yiyang Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.03681"
  },
  {
    "id": "arXiv:2201.03707",
    "title": "Rate Distortion Theory for Descriptive Statistics",
    "abstract": "Comments: 6 pages, 4 figures",
    "descriptor": "\nComments: 6 pages, 4 figures\n",
    "authors": [
      "Peter Harremo\u00ebs"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2201.03707"
  },
  {
    "id": "arXiv:2201.08093",
    "title": "AirPose: Multi-View Fusion Network for Aerial 3D Human Pose and Shape  Estimation",
    "abstract": "AirPose: Multi-View Fusion Network for Aerial 3D Human Pose and Shape  Estimation",
    "descriptor": "",
    "authors": [
      "Nitin Saini",
      "Elia Bonetto",
      "Eric Price",
      "Aamir Ahmad",
      "Michael J. Black"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.08093"
  },
  {
    "id": "arXiv:2201.08996",
    "title": "Linear Array Network for Low-light Image Enhancement",
    "abstract": "Linear Array Network for Low-light Image Enhancement",
    "descriptor": "",
    "authors": [
      "Keqi Wang",
      "Ziteng Cui",
      "Jieru Jia",
      "Hao Xu",
      "Ge Wu",
      "Yin Zhuang",
      "Lu Chen",
      "Zhiguo Hu",
      "Yuhua Qian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2201.08996"
  },
  {
    "id": "arXiv:2201.09827",
    "title": "Mixed Precision GMRES-based Iterative Refinement with Recycling",
    "abstract": "Comments: 18 pages",
    "descriptor": "\nComments: 18 pages\n",
    "authors": [
      "Eda Oktay",
      "Erin Carson"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.09827"
  },
  {
    "id": "arXiv:2201.10001",
    "title": "The Enforced Transfer: A Novel Domain Adaptation Algorithm",
    "abstract": "The Enforced Transfer: A Novel Domain Adaptation Algorithm",
    "descriptor": "",
    "authors": [
      "Ye Gao",
      "Brian Baucom",
      "Karen Rose",
      "Kristina Gordon",
      "Hongning Wang",
      "John Stankovic"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.10001"
  },
  {
    "id": "arXiv:2201.10618",
    "title": "The ABBE Corpus: Animate Beings Being Emotional",
    "abstract": "Comments: 9 pages, 1 figure",
    "descriptor": "\nComments: 9 pages, 1 figure\n",
    "authors": [
      "Samira Zad",
      "Joshuan Jimenez",
      "Mark A. Finlayson"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2201.10618"
  },
  {
    "id": "arXiv:2201.10890",
    "title": "One Student Knows All Experts Know: From Sparse to Dense",
    "abstract": "One Student Knows All Experts Know: From Sparse to Dense",
    "descriptor": "",
    "authors": [
      "Fuzhao Xue",
      "Xiaoxin He",
      "Xiaozhe Ren",
      "Yuxuan Lou",
      "Yang You"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.10890"
  },
  {
    "id": "arXiv:2201.11324",
    "title": "Efficient Distributed Learning in Stochastic Non-cooperative Games  without Information Exchange",
    "abstract": "Efficient Distributed Learning in Stochastic Non-cooperative Games  without Information Exchange",
    "descriptor": "",
    "authors": [
      "Haidong Li",
      "Anzhi Sheng",
      "Yijie Peng",
      "Long Wang"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2201.11324"
  },
  {
    "id": "arXiv:2201.11411",
    "title": "Restarted Nonconvex Accelerated Gradient Descent: No More  Polylogarithmic Factor in the $O(\u03b5^{-7/4})$ Complexity",
    "abstract": "Comments: Only change the template",
    "descriptor": "\nComments: Only change the template\n",
    "authors": [
      "Huan Li",
      "Zhouchen Lin"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11411"
  },
  {
    "id": "arXiv:2201.11463",
    "title": "Quantile-Based Policy Optimization for Reinforcement Learning",
    "abstract": "Quantile-Based Policy Optimization for Reinforcement Learning",
    "descriptor": "",
    "authors": [
      "Jinyang Jiang",
      "Jiaqiao Hu",
      "Yijie Peng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.11463"
  },
  {
    "id": "arXiv:2201.11817",
    "title": "Exploration With a Finite Brain",
    "abstract": "Exploration With a Finite Brain",
    "descriptor": "",
    "authors": [
      "Marcel Binz",
      "Eric Schulz"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11817"
  },
  {
    "id": "arXiv:2201.11967",
    "title": "Pseudo-Differential Integral Operator for Learning Solution Operators of  Partial Differential Equations",
    "abstract": "Comments: 18 pages, 12 figures",
    "descriptor": "\nComments: 18 pages, 12 figures\n",
    "authors": [
      "Jin Young Shin",
      "Jae Yong Lee",
      "Hyung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.11967"
  },
  {
    "id": "arXiv:2201.12083",
    "title": "DynaMixer: A Vision MLP Architecture with Dynamic Mixing",
    "abstract": "DynaMixer: A Vision MLP Architecture with Dynamic Mixing",
    "descriptor": "",
    "authors": [
      "Ziyu Wang",
      "Wenhao Jiang",
      "Yiming Zhu",
      "Li Yuan",
      "Yibing Song",
      "Wei Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12083"
  },
  {
    "id": "arXiv:2201.12133",
    "title": "O-ViT: Orthogonal Vision Transformer",
    "abstract": "O-ViT: Orthogonal Vision Transformer",
    "descriptor": "",
    "authors": [
      "Yanhong Fei",
      "Yingjie Liu",
      "Xian Wei",
      "Mingsong Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12133"
  },
  {
    "id": "arXiv:2201.12165",
    "title": "Graph autoencoder with constant dimensional latent space",
    "abstract": "Graph autoencoder with constant dimensional latent space",
    "descriptor": "",
    "authors": [
      "Adam Ma\u0142kowski",
      "Jakub Grzechoci\u0144ski",
      "Pawe\u0142 Wawrzy\u0144ski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12165"
  },
  {
    "id": "arXiv:2201.12170",
    "title": "Unsupervised Single-shot Depth Estimation using Perceptual  Reconstruction",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2103.16938",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2103.16938\n",
    "authors": [
      "Christoph Angermann",
      "Matthias Schwab",
      "Markus Haltmeier",
      "Christian Laubichler",
      "Steinbj\u00f6rn J\u00f3nsson"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12170"
  },
  {
    "id": "arXiv:2201.12293",
    "title": "Understanding Why Generalized Reweighting Does Not Improve Over ERM",
    "abstract": "Comments: 41 pages",
    "descriptor": "\nComments: 41 pages\n",
    "authors": [
      "Runtian Zhai",
      "Chen Dan",
      "Zico Kolter",
      "Pradeep Ravikumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.12293"
  },
  {
    "id": "arXiv:2201.12433",
    "title": "FedGCN: Convergence and Communication Tradeoffs in Federated Training of  Graph Convolutional Networks",
    "abstract": "FedGCN: Convergence and Communication Tradeoffs in Federated Training of  Graph Convolutional Networks",
    "descriptor": "",
    "authors": [
      "Yuhang Yao",
      "Carlee Joe-Wong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2201.12433"
  },
  {
    "id": "arXiv:2201.12570",
    "title": "AntBO: Towards Real-World Automated Antibody Design with Combinatorial  Bayesian Optimisation",
    "abstract": "AntBO: Towards Real-World Automated Antibody Design with Combinatorial  Bayesian Optimisation",
    "descriptor": "",
    "authors": [
      "Asif Khan",
      "Alexander I. Cowen-Rivers",
      "Derrick-Goh-Xin Deik",
      "Antoine Grosnit",
      "Kamil Dreczkowski",
      "Philippe A. Robert",
      "Victor Greiff",
      "Rasul Tutunov",
      "Dany Bou-Ammar",
      "Jun Wang",
      "Haitham Bou-Ammar"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.12570"
  },
  {
    "id": "arXiv:2201.12571",
    "title": "Probabilistic load flow calculation of AC/DC hybrid system based on  cumulant method",
    "abstract": "Probabilistic load flow calculation of AC/DC hybrid system based on  cumulant method",
    "descriptor": "",
    "authors": [
      "Yinfeng Sun",
      "Dapeng Xia",
      "Zichun Gao",
      "Zhenhao Wang",
      "Guoqing Li",
      "Weihua Lu",
      "Xueguang Wu",
      "Yang Li"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2201.12571"
  },
  {
    "id": "arXiv:2201.12589",
    "title": "FedMed-ATL: Misaligned Unpaired Brain Image Synthesis via Affine  Transform Loss",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2201.08953",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2201.08953\n",
    "authors": [
      "Guoyang Xie",
      "Jinbao Wang",
      "Yawen Huang",
      "Yefeng Zheng",
      "Feng Zheng",
      "Yaochu Jin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12589"
  },
  {
    "id": "arXiv:2201.12728",
    "title": "Video-based Facial Micro-Expression Analysis: A Survey of Datasets,  Features and Algorithms",
    "abstract": "Video-based Facial Micro-Expression Analysis: A Survey of Datasets,  Features and Algorithms",
    "descriptor": "",
    "authors": [
      "Xianye Ben",
      "Yi Ren",
      "Junping Zhang",
      "Su-Jing Wang",
      "Kidiyo Kpalma",
      "Weixiao Meng",
      "Yong-Jin Liu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12728"
  },
  {
    "id": "arXiv:2201.12738",
    "title": "AutoSNN: Towards Energy-Efficient Spiking Neural Networks",
    "abstract": "AutoSNN: Towards Energy-Efficient Spiking Neural Networks",
    "descriptor": "",
    "authors": [
      "Byunggook Na",
      "Jisoo Mok",
      "Seongsik Park",
      "Dongjin Lee",
      "Hyeokjun Choe",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12738"
  },
  {
    "id": "arXiv:2201.12947",
    "title": "Fair Wrapping for Black-box Predictions",
    "abstract": "Fair Wrapping for Black-box Predictions",
    "descriptor": "",
    "authors": [
      "Alexander Soen",
      "Ibrahim Alabdulmohsin",
      "Sanmi Koyejo",
      "Yishay Mansour",
      "Nyalleng Moorosi",
      "Richard Nock",
      "Ke Sun",
      "Lexing Xie"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.12947"
  },
  {
    "id": "arXiv:2201.12994",
    "title": "GSN: A Universal Graph Neural Network Inspired by Spring Network",
    "abstract": "Comments: 15 pages. Preprint, under review",
    "descriptor": "\nComments: 15 pages. Preprint, under review\n",
    "authors": [
      "Guanyu Cui",
      "Zhewei Wei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2201.12994"
  },
  {
    "id": "arXiv:2201.13392",
    "title": "MHSnet: Multi-head and Spatial Attention Network with False-Positive  Reduction for Pulmonary Nodules Detection",
    "abstract": "MHSnet: Multi-head and Spatial Attention Network with False-Positive  Reduction for Pulmonary Nodules Detection",
    "descriptor": "",
    "authors": [
      "Juanyun Mai",
      "Minghao Wang",
      "Jiayin Zheng",
      "Yanbo Shao",
      "Zhaoqi Diao",
      "Xinliang Fu",
      "Yulong Chen",
      "Jianyu Xiao",
      "Jian You",
      "Airu Yin",
      "Yang Yang",
      "Xiangcheng Qiu",
      "Jinsheng Tao",
      "Bo Wang",
      "Hua Ji"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.13392"
  },
  {
    "id": "arXiv:2201.13403",
    "title": "Vibration Fault Diagnosis in Wind Turbines based on Automated Feature  Learning",
    "abstract": "Vibration Fault Diagnosis in Wind Turbines based on Automated Feature  Learning",
    "descriptor": "",
    "authors": [
      "Angela Meyer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.13403"
  },
  {
    "id": "arXiv:2202.00159",
    "title": "Content addressable memory without catastrophic forgetting by  heteroassociation with a fixed scaffold",
    "abstract": "Content addressable memory without catastrophic forgetting by  heteroassociation with a fixed scaffold",
    "descriptor": "",
    "authors": [
      "Sugandha Sharma",
      "Sarthak Chandra",
      "Ila R. Fiete"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00159"
  },
  {
    "id": "arXiv:2202.00528",
    "title": "Examining Scaling and Transfer of Language Model Architectures for  Machine Translation",
    "abstract": "Examining Scaling and Transfer of Language Model Architectures for  Machine Translation",
    "descriptor": "",
    "authors": [
      "Biao Zhang",
      "Behrooz Ghorbani",
      "Ankur Bapna",
      "Yong Cheng",
      "Xavier Garcia",
      "Jonathan Shen",
      "Orhan Firat"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00528"
  },
  {
    "id": "arXiv:2202.00769",
    "title": "Distributional Reinforcement Learning via Sinkhorn Iterations",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2110.03155",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2110.03155\n",
    "authors": [
      "Ke Sun",
      "Yingnan Zhao",
      "Yi Liu",
      "Bei Jiang",
      "Linglong Kong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00769"
  },
  {
    "id": "arXiv:2202.00789",
    "title": "Team Belief DAG Form: A Concise Representation for Team-Correlated  Game-Theoretic Decision Making",
    "abstract": "Team Belief DAG Form: A Concise Representation for Team-Correlated  Game-Theoretic Decision Making",
    "descriptor": "",
    "authors": [
      "Brian Hu Zhang",
      "Gabriele Farina",
      "Tuomas Sandholm"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.00789"
  },
  {
    "id": "arXiv:2202.00796",
    "title": "On the Benefits of Selectivity in Pseudo-Labeling for Unsupervised  Multi-Source-Free Domain Adaptation",
    "abstract": "On the Benefits of Selectivity in Pseudo-Labeling for Unsupervised  Multi-Source-Free Domain Adaptation",
    "descriptor": "",
    "authors": [
      "Maohao Shen",
      "Yuheng Bu",
      "Gregory Wornell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.00796"
  },
  {
    "id": "arXiv:2202.00805",
    "title": "Context Uncertainty in Contextual Bandits with Applications to  Recommender Systems",
    "abstract": "Comments: To appear at AAAI 2022",
    "descriptor": "\nComments: To appear at AAAI 2022\n",
    "authors": [
      "Hao Wang",
      "Yifei Ma",
      "Hao Ding",
      "Yuyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00805"
  },
  {
    "id": "arXiv:2202.01038",
    "title": "Using Ballistocardiography for Sleep Stage Classification",
    "abstract": "Using Ballistocardiography for Sleep Stage Classification",
    "descriptor": "",
    "authors": [
      "Jiebei Liu",
      "Peter Morris",
      "Krista Nelson",
      "Mehdi Boukhechba"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.01038"
  },
  {
    "id": "arXiv:2202.02001",
    "title": "Introducing Block-Toeplitz Covariance Matrices to Remaster Linear  Discriminant Analysis for Event-related Potential Brain-computer Interfaces",
    "abstract": "Comments: Updated references, changed layout",
    "descriptor": "\nComments: Updated references, changed layout\n",
    "authors": [
      "Jan Sosulski",
      "Michael Tangermann"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2202.02001"
  },
  {
    "id": "arXiv:2202.02142",
    "title": "Deep invariant networks with differentiable augmentation layers",
    "abstract": "Deep invariant networks with differentiable augmentation layers",
    "descriptor": "",
    "authors": [
      "C\u00e9dric Rommel",
      "Thomas Moreau",
      "Alexandre Gramfort"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02142"
  },
  {
    "id": "arXiv:2202.02371",
    "title": "Boundary-aware Information Maximization for Self-supervised Medical  Image Segmentation",
    "abstract": "Boundary-aware Information Maximization for Self-supervised Medical  Image Segmentation",
    "descriptor": "",
    "authors": [
      "Jizong Peng",
      "Ping Wang",
      "Marco Pedersoli",
      "Christian Desrosiers"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02371"
  },
  {
    "id": "arXiv:2202.02393",
    "title": "Deep Dynamic Effective Connectivity Estimation from Multivariate Time  Series",
    "abstract": "Comments: In review",
    "descriptor": "\nComments: In review\n",
    "authors": [
      "Usman Mahmood",
      "Zening Fu",
      "Vince Calhoun",
      "Sergey Plis"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02393"
  },
  {
    "id": "arXiv:2202.02442",
    "title": "Transfer Reinforcement Learning for Differing Action Spaces via  Q-Network Representations",
    "abstract": "Comments: 5 pages, 2 figures, 1 table",
    "descriptor": "\nComments: 5 pages, 2 figures, 1 table\n",
    "authors": [
      "Nathan Beck",
      "Abhiramon Rajasekharan",
      "Hieu Tran"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.02442"
  },
  {
    "id": "arXiv:2202.02514",
    "title": "Score-based Generative Modeling of Graphs via the System of Stochastic  Differential Equations",
    "abstract": "Score-based Generative Modeling of Graphs via the System of Stochastic  Differential Equations",
    "descriptor": "",
    "authors": [
      "Jaehyeong Jo",
      "Seul Lee",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02514"
  },
  {
    "id": "arXiv:2202.02958",
    "title": "A comprehensive survey on computational learning methods for analysis of  gene expression data in genomics",
    "abstract": "Comments: 51 pages, 9 figures, 5 tables",
    "descriptor": "\nComments: 51 pages, 9 figures, 5 tables\n",
    "authors": [
      "Nikita Bhandari",
      "Rahee Walambe",
      "Ketan Kotecha",
      "Satyajeet Khare"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02958"
  },
  {
    "id": "arXiv:2202.03169",
    "title": "CITRIS: Causal Identifiability from Temporal Intervened Sequences",
    "abstract": "Comments: 47 pages",
    "descriptor": "\nComments: 47 pages\n",
    "authors": [
      "Phillip Lippe",
      "Sara Magliacane",
      "Sindy L\u00f6we",
      "Yuki M. Asano",
      "Taco Cohen",
      "Efstratios Gavves"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.03169"
  },
  {
    "id": "arXiv:2202.03348",
    "title": "Failure and success of the spectral bias prediction for Kernel Ridge  Regression: the case of low-dimensional data",
    "abstract": "Comments: 34 pages, 11 figures",
    "descriptor": "\nComments: 34 pages, 11 figures\n",
    "authors": [
      "Umberto M. Tomasini",
      "Antonio Sclocchi",
      "Matthieu Wyart"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistical Mechanics (cond-mat.stat-mech)"
    ],
    "url": "https://arxiv.org/abs/2202.03348"
  },
  {
    "id": "arXiv:2202.03580",
    "title": "Convolutional Neural Networks on Graphs with Chebyshev Approximation,  Revisited",
    "abstract": "Comments: 16 pages",
    "descriptor": "\nComments: 16 pages\n",
    "authors": [
      "Mingguo He",
      "Zhewei Wei",
      "Ji-Rong Wen"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03580"
  },
  {
    "id": "arXiv:2202.03813",
    "title": "Learning to Predict Graphs with Fused Gromov-Wasserstein Barycenters",
    "abstract": "Learning to Predict Graphs with Fused Gromov-Wasserstein Barycenters",
    "descriptor": "",
    "authors": [
      "Luc Brogat-Motte",
      "R\u00e9mi Flamary",
      "C\u00e9line Brouard",
      "Juho Rousu",
      "Florence d'Alch\u00e9-Buc"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.03813"
  },
  {
    "id": "arXiv:2202.03903",
    "title": "KENN: Enhancing Deep Neural Networks by Leveraging Knowledge for Time  Series Forecasting",
    "abstract": "KENN: Enhancing Deep Neural Networks by Leveraging Knowledge for Time  Series Forecasting",
    "descriptor": "",
    "authors": [
      "Muhammad Ali Chattha",
      "Ludger van Elst",
      "Muhammad Imran Malik",
      "Andreas Dengel",
      "Sheraz Ahmed"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.03903"
  },
  {
    "id": "arXiv:2202.04124",
    "title": "A Mini-Block Natural Gradient Method for Deep Neural Networks",
    "abstract": "A Mini-Block Natural Gradient Method for Deep Neural Networks",
    "descriptor": "",
    "authors": [
      "Achraf Bahamou",
      "Donald Goldfarb",
      "Yi Ren"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04124"
  },
  {
    "id": "arXiv:2202.04206",
    "title": "Covariate-informed Representation Learning with Samplewise Optimal  Identifiable Variational Autoencoders",
    "abstract": "Covariate-informed Representation Learning with Samplewise Optimal  Identifiable Variational Autoencoders",
    "descriptor": "",
    "authors": [
      "Young-geun Kim",
      "Ying Liu",
      "Xuexin Wei"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04206"
  },
  {
    "id": "arXiv:2202.04427",
    "title": "Revisiting QMIX: Discriminative Credit Assignment by Gradient Entropy  Regularization",
    "abstract": "Revisiting QMIX: Discriminative Credit Assignment by Gradient Entropy  Regularization",
    "descriptor": "",
    "authors": [
      "Jian Zhao",
      "Yue Zhang",
      "Xunhan Hu",
      "Weixun Wang",
      "Wengang Zhou",
      "Jianye Hao",
      "Jiangcheng Zhu",
      "Houqiang Li"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04427"
  },
  {
    "id": "arXiv:2202.04476",
    "title": "Counting Kernels in Directed Graphs with Arbitrary Orientations",
    "abstract": "Comments: 18 pages, 3 figures, added: analysis of running times",
    "descriptor": "\nComments: 18 pages, 3 figures, added: analysis of running times\n",
    "authors": [
      "Bruno Jartoux"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2202.04476"
  },
  {
    "id": "arXiv:2202.04675",
    "title": "Bayesian Nonparametrics for Offline Skill Discovery",
    "abstract": "Bayesian Nonparametrics for Offline Skill Discovery",
    "descriptor": "",
    "authors": [
      "Valentin Villecroze",
      "Harry J. Braviner",
      "Panteha Naderian",
      "Chris J. Maddison",
      "Gabriel Loaiza-Ganem"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04675"
  },
  {
    "id": "arXiv:2202.04770",
    "title": "Iterative Bilinear Temporal-Spectral Fusion for Unsupervised Time-Series  Representation Learning",
    "abstract": "Iterative Bilinear Temporal-Spectral Fusion for Unsupervised Time-Series  Representation Learning",
    "descriptor": "",
    "authors": [
      "Ling Yang",
      "Shenda Hong",
      "Luxia Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04770"
  },
  {
    "id": "arXiv:2202.04828",
    "title": "Learning Latent Causal Dynamics",
    "abstract": "Learning Latent Causal Dynamics",
    "descriptor": "",
    "authors": [
      "Weiran Yao",
      "Guangyi Chen",
      "Kun Zhang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04828"
  },
  {
    "id": "arXiv:2202.04843",
    "title": "A Stieltjes algorithm for generating multivariate orthogonal polynomials",
    "abstract": "Comments: 23 pages, 8 figures",
    "descriptor": "\nComments: 23 pages, 8 figures\n",
    "authors": [
      "Zexin Liu",
      "Akil Narayan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.04843"
  },
  {
    "id": "arXiv:2202.04868",
    "title": "Understanding Value Decomposition Algorithms in Deep Cooperative  Multi-Agent Reinforcement Learning",
    "abstract": "Comments: 37 pages",
    "descriptor": "\nComments: 37 pages\n",
    "authors": [
      "Zehao Dou",
      "Jakub Grudzien Kuba",
      "Yaodong Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.04868"
  },
  {
    "id": "arXiv:2202.04936",
    "title": "Graph Neural Network for Local Corruption Recovery",
    "abstract": "Graph Neural Network for Local Corruption Recovery",
    "descriptor": "",
    "authors": [
      "Bingxin Zhou",
      "Yuanhong Jiang",
      "Yu Guang Wang",
      "Jingwei Liang",
      "Junbin Gao",
      "Shirui Pan",
      "Xiaoqun Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04936"
  },
  {
    "id": "arXiv:2202.05126",
    "title": "Deep Learning for Computational Cytology: A Survey",
    "abstract": "Deep Learning for Computational Cytology: A Survey",
    "descriptor": "",
    "authors": [
      "Hao Jiang",
      "Yanning Zhou",
      "Yi Lin",
      "Ronald CK Chan",
      "Jiang Liu",
      "Hao Chen"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05126"
  },
  {
    "id": "arXiv:2202.05331",
    "title": "Describing image focused in cognitive and visual details for visually  impaired people: An approach to generating inclusive paragraphs",
    "abstract": "Comments: Accepted in the 17th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications (VISAPP) 2022",
    "descriptor": "\nComments: Accepted in the 17th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications (VISAPP) 2022\n",
    "authors": [
      "Daniel Louzada Fernandes",
      "Marcos Henrique Fonseca Ribeiro",
      "Fabio Ribeiro Cerqueira",
      "Michel Melo Silva"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05331"
  },
  {
    "id": "arXiv:2202.05404",
    "title": "Regularized Q-learning",
    "abstract": "Regularized Q-learning",
    "descriptor": "",
    "authors": [
      "Han-Dong Lim",
      "Do Wan Kim",
      "Donghwan Lee"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05404"
  },
  {
    "id": "arXiv:2202.05435",
    "title": "Dual Task Framework for Improving Persona-grounded Dialogue Dataset",
    "abstract": "Comments: Accepted to AAAI2022",
    "descriptor": "\nComments: Accepted to AAAI2022\n",
    "authors": [
      "Minju Kim",
      "Beong-woo Kwak",
      "Youngwook Kim",
      "Hong-in Lee",
      "Seung-won Hwang",
      "Jinyoung Yeo"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05435"
  },
  {
    "id": "arXiv:2202.05619",
    "title": "Self-Sovereign Personal Cryptocurrencies: Foundations for Grassroots  Cryptoeconomy",
    "abstract": "Self-Sovereign Personal Cryptocurrencies: Foundations for Grassroots  Cryptoeconomy",
    "descriptor": "",
    "authors": [
      "Ehud Shapiro"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.05619"
  },
  {
    "id": "arXiv:2202.06159",
    "title": "Robust alignment of cross-session recordings of neural population  activity by behaviour via unsupervised domain adaptation",
    "abstract": "Robust alignment of cross-session recordings of neural population  activity by behaviour via unsupervised domain adaptation",
    "descriptor": "",
    "authors": [
      "Justin Jude",
      "Matthew G Perich",
      "Lee E Miller",
      "Matthias H Hennig"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06159"
  },
  {
    "id": "arXiv:2202.06163",
    "title": "Evolving Neural Networks with Optimal Balance between Information Flow  and Connections Cost",
    "abstract": "Evolving Neural Networks with Optimal Balance between Information Flow  and Connections Cost",
    "descriptor": "",
    "authors": [
      "Abdullah Khalili",
      "Abdelhamid Bouchachia"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06163"
  },
  {
    "id": "arXiv:2202.06191",
    "title": "Incentivizing Participation in Clinical Trials",
    "abstract": "Incentivizing Participation in Clinical Trials",
    "descriptor": "",
    "authors": [
      "Yingkai Li",
      "Aleksandrs Slivkins"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.06191"
  },
  {
    "id": "arXiv:2202.06208",
    "title": "Metric Learning-enhanced Optimal Transport for Biochemical Regression  Domain Adaptation",
    "abstract": "Metric Learning-enhanced Optimal Transport for Biochemical Regression  Domain Adaptation",
    "descriptor": "",
    "authors": [
      "Fang Wu",
      "Nicolas Courty",
      "Zhang Qiang",
      "jiyu Cui",
      "Ziqing Li"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2202.06208"
  },
  {
    "id": "arXiv:2202.06382",
    "title": "Neural Network Trojans Analysis and Mitigation from the Input Domain",
    "abstract": "Neural Network Trojans Analysis and Mitigation from the Input Domain",
    "descriptor": "",
    "authors": [
      "Zhenting Wang",
      "Hailun Ding",
      "Juan Zhai",
      "Shiqing Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.06382"
  },
  {
    "id": "arXiv:2202.06443",
    "title": "Learning Reward Models for Cooperative Trajectory Planning with Inverse  Reinforcement Learning and Monte Carlo Tree Search",
    "abstract": "Learning Reward Models for Cooperative Trajectory Planning with Inverse  Reinforcement Learning and Monte Carlo Tree Search",
    "descriptor": "",
    "authors": [
      "Karl Kurzer",
      "Matthias Bitzer",
      "J. Marius Z\u00f6llner"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.06443"
  },
  {
    "id": "arXiv:2202.06488",
    "title": "Finding Dynamics Preserving Adversarial Winning Tickets",
    "abstract": "Comments: Accepted by AISTATS2022",
    "descriptor": "\nComments: Accepted by AISTATS2022\n",
    "authors": [
      "Xupeng Shi",
      "Pengfei Zheng",
      "A. Adam Ding",
      "Yuan Gao",
      "Weizhong Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06488"
  },
  {
    "id": "arXiv:2202.06511",
    "title": "GAMMA Challenge:Glaucoma grAding from Multi-Modality imAges",
    "abstract": "GAMMA Challenge:Glaucoma grAding from Multi-Modality imAges",
    "descriptor": "",
    "authors": [
      "Junde Wu",
      "Huihui Fang",
      "Fei Li",
      "Huazhu Fu",
      "Fengbin Lin",
      "Jiongcheng Li",
      "Lexing Huang",
      "Qinji Yu",
      "Sifan Song",
      "Xingxing Xu",
      "Yanyu Xu",
      "Wensai Wang",
      "Lingxiao Wang",
      "Shuai Lu",
      "Huiqi Li",
      "Shihua Huang",
      "Zhichao Lu",
      "Chubin Ou",
      "Xifei Wei",
      "Bingyuan Liu",
      "Riadh Kobbi",
      "Xiaoying Tang",
      "Li Lin",
      "Qiang Zhou",
      "Qiang Hu",
      "Hrvoje Bogunovic",
      "Jos\u00e9 Ignacio Orlando",
      "Xiulan Zhang",
      "Yanwu Xu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.06511"
  },
  {
    "id": "arXiv:2202.06539",
    "title": "Deduplicating Training Data Mitigates Privacy Risks in Language Models",
    "abstract": "Deduplicating Training Data Mitigates Privacy Risks in Language Models",
    "descriptor": "",
    "authors": [
      "Nikhil Kandpal",
      "Eric Wallace",
      "Colin Raffel"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06539"
  },
  {
    "id": "arXiv:2202.06558",
    "title": "SAUTE RL: Almost Surely Safe Reinforcement Learning Using State  Augmentation",
    "abstract": "SAUTE RL: Almost Surely Safe Reinforcement Learning Using State  Augmentation",
    "descriptor": "",
    "authors": [
      "Aivar Sootla",
      "Alexander I. Cowen-Rivers",
      "Taher Jafferjee",
      "Ziyan Wang",
      "David Mguni",
      "Jun Wang",
      "Haitham Bou-Ammar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.06558"
  },
  {
    "id": "arXiv:2202.06839",
    "title": "Close-up and Whispering: An Understanding of Multimodal and Parasocial  Interactions in YouTube ASMR videos",
    "abstract": "Comments: 4 pages",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Shuo Niu",
      "Hugh S. Manon",
      "Ava Bartolome",
      "Nguyen B. Ha",
      "Keegan Veazey"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.06839"
  },
  {
    "id": "arXiv:2202.06939",
    "title": "A simple proof that the $hp$-FEM does not suffer from the pollution  effect for the constant-coefficient full-space Helmholtz equation",
    "abstract": "A simple proof that the $hp$-FEM does not suffer from the pollution  effect for the constant-coefficient full-space Helmholtz equation",
    "descriptor": "",
    "authors": [
      "Euan A. Spence"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.06939"
  },
  {
    "id": "arXiv:2202.06983",
    "title": "Evolvability Degeneration in Multi-Objective Genetic Programming for  Symbolic Regression",
    "abstract": "Evolvability Degeneration in Multi-Objective Genetic Programming for  Symbolic Regression",
    "descriptor": "",
    "authors": [
      "Dazhuang Liu",
      "Marco Virgolin",
      "Tanja Alderliesten",
      "Peter A. N. Bosman"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.06983"
  },
  {
    "id": "arXiv:2202.06991",
    "title": "Transformer Memory as a Differentiable Search Index",
    "abstract": "Transformer Memory as a Differentiable Search Index",
    "descriptor": "",
    "authors": [
      "Yi Tay",
      "Vinh Q. Tran",
      "Mostafa Dehghani",
      "Jianmo Ni",
      "Dara Bahri",
      "Harsh Mehta",
      "Zhen Qin",
      "Kai Hui",
      "Zhe Zhao",
      "Jai Gupta",
      "Tal Schuster",
      "William W. Cohen",
      "Donald Metzler"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06991"
  },
  {
    "id": "arXiv:2202.06997",
    "title": "A Survey of Cross-Modality Brain Image Synthesis",
    "abstract": "A Survey of Cross-Modality Brain Image Synthesis",
    "descriptor": "",
    "authors": [
      "Guoyang Xie",
      "Jinbao Wang",
      "Yawen Huang",
      "Yefeng Zheng",
      "Feng Zheng",
      "Yaochu Jin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.06997"
  },
  {
    "id": "arXiv:2202.07165",
    "title": "OLIVE: Oblivious and Differentially Private Federated Learning on  Trusted Execution Environment",
    "abstract": "OLIVE: Oblivious and Differentially Private Federated Learning on  Trusted Execution Environment",
    "descriptor": "",
    "authors": [
      "Fumiyuki Kato",
      "Yang Cao",
      "Masatoshi Yoshikawa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.07165"
  },
  {
    "id": "arXiv:2202.07170",
    "title": "Fairness Amidst Non-IID Graph Data: A Literature Review",
    "abstract": "Fairness Amidst Non-IID Graph Data: A Literature Review",
    "descriptor": "",
    "authors": [
      "Wenbin Zhang",
      "Jeremy C. Weiss",
      "Shuigeng Zhou",
      "Toby Walsh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07170"
  },
  {
    "id": "arXiv:2202.07179",
    "title": "G-Mixup: Graph Data Augmentation for Graph Classification",
    "abstract": "G-Mixup: Graph Data Augmentation for Graph Classification",
    "descriptor": "",
    "authors": [
      "Xiaotian Han",
      "Zhimeng Jiang",
      "Ninghao Liu",
      "Xia Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07179"
  },
  {
    "id": "arXiv:2202.07200",
    "title": "Unsupervised word-level prosody tagging for controllable speech  synthesis",
    "abstract": "Comments: 5 pages, 6 figures, accepted to ICASSP2022",
    "descriptor": "\nComments: 5 pages, 6 figures, accepted to ICASSP2022\n",
    "authors": [
      "Yiwei Guo",
      "Chenpeng Du",
      "Kai Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.07200"
  },
  {
    "id": "arXiv:2202.07215",
    "title": "Balancing Domain Experts for Long-Tailed Camera-Trap Recognition",
    "abstract": "Comments: 5 pages, 4 figures",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Byeongjun Park",
      "Jeongsoo Kim",
      "Seungju Cho",
      "Heeseon Kim",
      "Changick Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07215"
  },
  {
    "id": "arXiv:2202.07230",
    "title": "Geometrically Equivariant Graph Neural Networks: A Survey",
    "abstract": "Comments: 8 pages",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Jiaqi Han",
      "Yu Rong",
      "Tingyang Xu",
      "Wenbing Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07230"
  },
  {
    "id": "arXiv:2202.07261",
    "title": "Exploring the Devil in Graph Spectral Domain for 3D Point Cloud Attacks",
    "abstract": "Exploring the Devil in Graph Spectral Domain for 3D Point Cloud Attacks",
    "descriptor": "",
    "authors": [
      "Qianjiang Hu",
      "Daizong Liu",
      "Wei Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.07261"
  },
  {
    "id": "arXiv:2202.07439",
    "title": "Inclusive Study Group Formation At Scale",
    "abstract": "Inclusive Study Group Formation At Scale",
    "descriptor": "",
    "authors": [
      "Sumer Kohli",
      "Neelesh Ramachandran",
      "Ana Tudor",
      "Gloria Tumushabe",
      "Olivia Hsu",
      "Gireeja Ranade"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.07439"
  },
  {
    "id": "arXiv:2202.07447",
    "title": "Trustworthy Autonomous Systems (TAS): Engaging TAS experts in curriculum  design",
    "abstract": "Trustworthy Autonomous Systems (TAS): Engaging TAS experts in curriculum  design",
    "descriptor": "",
    "authors": [
      "Mohammad Naiseh",
      "Caitlin Bentley",
      "Sarvapali D. Ramchurn"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07447"
  },
  {
    "id": "arXiv:2202.07530",
    "title": "Optimal Algorithms for Stochastic Multi-Level Compositional Optimization",
    "abstract": "Optimal Algorithms for Stochastic Multi-Level Compositional Optimization",
    "descriptor": "",
    "authors": [
      "Wei Jiang",
      "Bokun Wang",
      "Yibo Wang",
      "Lijun Zhang",
      "Tianbao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07530"
  },
  {
    "id": "arXiv:2202.07532",
    "title": "Closing the Management Gap for Satellite-Integrated Community Networks:  A Hierarchical Approach to Self-Maintenance",
    "abstract": "Closing the Management Gap for Satellite-Integrated Community Networks:  A Hierarchical Approach to Self-Maintenance",
    "descriptor": "",
    "authors": [
      "Peng Hu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07532"
  },
  {
    "id": "arXiv:2202.07549",
    "title": "Robust Multi-Objective Bayesian Optimization Under Input Noise",
    "abstract": "Comments: 41 pages. Code is available at this https URL",
    "descriptor": "\nComments: 41 pages. Code is available at this https URL\n",
    "authors": [
      "Samuel Daulton",
      "Sait Cakmak",
      "Maximilian Balandat",
      "Michael A. Osborne",
      "Enlu Zhou",
      "Eytan Bakshy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.07549"
  },
  {
    "id": "arXiv:2202.07569",
    "title": "Constant-weight PIR: Single-round Keyword PIR via Constant-weight  Equality Operators",
    "abstract": "Constant-weight PIR: Single-round Keyword PIR via Constant-weight  Equality Operators",
    "descriptor": "",
    "authors": [
      "Rasoul Akhavan Mahdavi",
      "Florian Kerschbaum"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.07569"
  },
  {
    "id": "arXiv:2202.07648",
    "title": "EvoKG: Jointly Modeling Event Time and Network Structure for Reasoning  over Temporal Knowledge Graphs",
    "abstract": "Comments: WSDM 2022",
    "descriptor": "\nComments: WSDM 2022\n",
    "authors": [
      "Namyong Park",
      "Fuchen Liu",
      "Purvanshi Mehta",
      "Dana Cristofor",
      "Christos Faloutsos",
      "Yuxiao Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.07648"
  }
]
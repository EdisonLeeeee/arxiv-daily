[
  {
    "id": "arXiv:2202.06946",
    "title": "Prototyping a Virtual Agent for Pre-school English Teaching",
    "abstract": "This paper describes a case study and the insights gained from prototyping an\nIntelligent Virtual Agent (IVA) for English vocabulary building for\nSpanish-speaking preschool children. After an initial exploration to evaluate\nthe feasibility of developing an IVA, we followed a Human-Centered Design (HCD)\napproach to create a prototype. We report on the multidisciplinary process used\nthat incorporated two well-known educative concepts: gamification and\nstory-telling as the main components for engagement. Our results suggest that a\nmultidisciplinary approach to developing an educational IVA is effective. We\nreport on the relevant aspects of the ideation and design processes that\ninformed the vision and mission of the project.",
    "descriptor": "\nComments: Accepted in the IEEE Virtual Reality Conference 2022, Christchurch, New Zealand\n",
    "authors": [
      "Eduardo Benitez Sandoval",
      "Diego Vazquez Rojas",
      "Clarissa A. Parada Cereceres",
      "Alvaro Anzueto Rios",
      "Amit Barde",
      "Mark Billinghurst"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.06946"
  },
  {
    "id": "arXiv:2202.06948",
    "title": "Towards Best Practice of Interpreting Deep Learning Models for EEG-based  Brain Computer Interfaces",
    "abstract": "Understanding deep learning models is important for EEG-based brain-computer\ninterface (BCI), since it not only can boost trust of end users but also\npotentially shed light on reasons that cause a model to fail. However, deep\nlearning interpretability has not yet raised wide attention in this field. It\nremains unknown how reliably existing interpretation techniques can be used and\nto which extent they can reflect the model decisions. In order to fill this\nresearch gap, we conduct the first quantitative evaluation and explore the best\npractice of interpreting deep learning models designed for EEG-based BCI. We\ndesign metrics and test seven well-known interpretation techniques on benchmark\ndeep learning models. Results show that methods of GradientInput, DeepLIFT,\nintegrated gradient, and layer-wise relevance propagation (LRP) have similar\nand better performance than saliency map, deconvolution and guided\nbackpropagation methods for interpreting the model decisions. In addition, we\npropose a set of processing steps that allow the interpretation results to be\nvisualized in an understandable and trusted way. Finally, we illustrate with\nsamples on how deep learning interpretability can benefit the domain of\nEEG-based BCI. Our work presents a promising direction of introducing deep\nlearning interpretability to EEG-based BCI.",
    "descriptor": "",
    "authors": [
      "Jian Cui",
      "Bin Weng"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.06948"
  },
  {
    "id": "arXiv:2202.06949",
    "title": "Consensus Division in an Arbitrary Ratio",
    "abstract": "We consider the problem of partitioning a line segment into two subsets, so\nthat $n$ finite measures all has the same ratio of values for the subsets.\nLetting $\\alpha\\in[0,1]$ denote the desired ratio, this generalises the\nPPA-complete consensus-halving problem, in which $\\alpha=\\frac{1}{2}$. It is\nknown that for any $\\alpha$, there exists a solution using $2n$ cuts of the\nsegment. Here we show that if $\\alpha$ is irrational, that upper bound is\nalmost optimal. We also obtain bounds that are nearly exact for a large subset\nof rational values $\\alpha$. On the computational side, we explore its\ndependence on the number of cuts available. More specifically,\n1. when using the minimal number of cuts for each instance is required, the\nproblem is NP-hard for any $\\alpha$;\n2. for a large subset of rational $\\alpha = \\frac{\\ell}{k}$, when\n$\\frac{k-1}{k} \\cdot 2n$ cuts are available, the problem is in the Turing\nclosure of PPA-$k$;\n3. when $2n$ cuts are allowed, the problem belongs to PPA for any $\\alpha$;\nfurthermore, the problem belong to PPA-$p$ for any prime $p$ if $2(p-1)\\cdot\n\\frac{\\lceil p/2 \\rceil}{\\lfloor p/2 \\rfloor} \\cdot n$ cuts are available.",
    "descriptor": "\nComments: 20 pages, 2 figures\n",
    "authors": [
      "Paul W. Goldberg",
      "Jiawei Li"
    ],
    "subjectives": [
      "Computational Complexity (cs.CC)",
      "Discrete Mathematics (cs.DM)",
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.06949"
  },
  {
    "id": "arXiv:2202.06954",
    "title": "LiDiTE: a Full-Fledged and Featherweight Digital Twin Framework",
    "abstract": "The rising of the Cyber-Physical System (CPS) and the Industry 4.0 paradigms\ndemands the design and the implementation of Digital Twin Frameworks (DTFs)\nthat may support the quick build of reliable Digital Twins (DTs) for\nexperimental and testing purposes. Most of the current DTF proposals allow\ngenerating DTs at a good pace but affect generality, scalability, portability,\nand completeness. As a consequence, current DTF are mostly domain-specific and\nhardly span several application domains (e.g., from simple IoT deployments to\nthe modeling of complex critical infrastructures). Furthermore, the generated\nDTs often requires a high amount of computational resource to run. In this\npaper, we present LiDiTE, a novel DTF that overcomes the previous limitations\nby, on the one hand, supporting the building of general-purpose DTs at a\nfine-grained level, but, on the other hand, with a reduced resource footprint\nw.r.t. the current state of the art. We show the characteristics of the LiDiTE\nby building the DT of a complex and real critical infrastructure (i.e., the\nSmart Poligeneration Microgrid of the Savona Campus) and evaluating its\nresource consumption. The source code of LiDiTE, as well as the experimental\ndataset, is publicly available.",
    "descriptor": "",
    "authors": [
      "Enrico Russo",
      "Gabriele Costa",
      "Giacomo Longo",
      "Alessandro Armando",
      "Alessio Merlo"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.06954"
  },
  {
    "id": "arXiv:2202.06983",
    "title": "Evolvability Degeneration in Multi-Objective Genetic Programming for  Symbolic Regression",
    "abstract": "Genetic programming (GP) is one of the best approaches today to discover\nsymbolic regression models. To find models that trade off accuracy and\ncomplexity, the non-dominated sorting genetic algorithm II (NSGA-II) is widely\nused. Unfortunately, it has been shown that NSGA-II can be inefficient: in\nearly generations, low-complexity models over-replicate and take over most of\nthe population. Consequently, studies have proposed different approaches to\npromote diversity. Here, we study the root of this problem, in order to design\na superior approach. We find that the over-replication of low complexity-models\nis due to a lack of evolvability, i.e., the inability to produce offspring with\nimproved accuracy. We therefore extend NSGA-II to track, over time, the\nevolvability of models of different levels of complexity. With this\ninformation, we limit how many models of each complexity level are allowed to\nsurvive the generation. We compare this new version of NSGA-II,\n\\emph{evoNSGA-II}, with the use of seven existing multi-objective GP approaches\non ten widely-used data sets, and find that evoNSGA-II is equal or superior to\nusing these approaches in almost all comparisons. Furthermore, our results\nconfirm that evoNSGA-II behaves as intended: models that are more evolvable\nform the majority of the population.",
    "descriptor": "",
    "authors": [
      "Dazhuang Liu",
      "Marco Virgolin",
      "Tanja Alderliesten",
      "Peter A. N. Bosman"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.06983"
  },
  {
    "id": "arXiv:2202.06985",
    "title": "Deep Ensembles Work, But Are They Necessary?",
    "abstract": "Ensembling neural networks is an effective way to increase accuracy, and can\noften match the performance of larger models. This observation poses a natural\nquestion: given the choice between a deep ensemble and a single neural network\nwith similar accuracy, is one preferable over the other? Recent work suggests\nthat deep ensembles may offer benefits beyond predictive power: namely,\nuncertainty quantification and robustness to dataset shift. In this work, we\ndemonstrate limitations to these purported benefits, and show that a single\n(but larger) neural network can replicate these qualities. First, we show that\nensemble diversity, by any metric, does not meaningfully contribute to an\nensemble's ability to detect out-of-distribution (OOD) data, and that one can\nestimate ensemble diversity by measuring the relative improvement of a single\nlarger model. Second, we show that the OOD performance afforded by ensembles is\nstrongly determined by their in-distribution (InD) performance, and -- in this\nsense -- is not indicative of any \"effective robustness\". While deep ensembles\nare a practical way to achieve performance improvement (in agreement with prior\nwork), our results show that they may be a tool of convenience rather than a\nfundamentally better model class.",
    "descriptor": "",
    "authors": [
      "Taiga Abe",
      "E. Kelly Buchanan",
      "Geoff Pleiss",
      "Richard Zemel",
      "John P. Cunningham"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.06985"
  },
  {
    "id": "arXiv:2202.06987",
    "title": "ASC me to Do Anything: Multi-task Training for Embodied AI",
    "abstract": "Embodied AI has seen steady progress across a diverse set of independent\ntasks. While these varied tasks have different end goals, the basic skills\nrequired to complete them successfully overlap significantly. In this paper,\nour goal is to leverage these shared skills to learn to perform multiple tasks\njointly. We propose Atomic Skill Completion (ASC), an approach for multi-task\ntraining for Embodied AI, where a set of atomic skills shared across multiple\ntasks are composed together to perform the tasks. The key to the success of\nthis approach is a pre-training scheme that decouples learning of the skills\nfrom the high-level tasks making joint training effective. We use ASC to train\nagents within the AI2-THOR environment to perform four interactive tasks\njointly and find it to be remarkably effective. In a multi-task setting, ASC\nimproves success rates by a factor of 2x on Seen scenes and 4x on Unseen scenes\ncompared to no pre-training. Importantly, ASC enables us to train a multi-task\nagent that has a 52% higher Success Rate than training 4 independent single\ntask agents. Finally, our hierarchical agents are more interpretable than\ntraditional black-box architectures.",
    "descriptor": "\nComments: 22 pages, 11 figures\n",
    "authors": [
      "Jiasen Lu",
      "Jordi Salvador",
      "Roozbeh Mottaghi",
      "Aniruddha Kembhavi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.06987"
  },
  {
    "id": "arXiv:2202.06991",
    "title": "Transformer Memory as a Differentiable Search Index",
    "abstract": "In this paper, we demonstrate that information retrieval can be accomplished\nwith a single Transformer, in which all information about the corpus is encoded\nin the parameters of the model. To this end, we introduce the Differentiable\nSearch Index (DSI), a new paradigm that learns a text-to-text model that maps\nstring queries directly to relevant docids; in other words, a DSI model answers\nqueries directly using only its parameters, dramatically simplifying the whole\nretrieval process. We study variations in how documents and their identifiers\nare represented, variations in training procedures, and the interplay between\nmodels and corpus sizes. Experiments demonstrate that given appropriate design\nchoices, DSI significantly outperforms strong baselines such as dual encoder\nmodels. Moreover, DSI demonstrates strong generalization capabilities,\noutperforming a BM25 baseline in a zero-shot setup.",
    "descriptor": "",
    "authors": [
      "Yi Tay",
      "Vinh Q. Tran",
      "Mostafa Dehghani",
      "Jianmo Ni",
      "Dara Bahri",
      "Harsh Mehta",
      "Zhen Qin",
      "Kai Hui",
      "Zhe Zhao",
      "Jai Gupta",
      "Tal Schuster",
      "William W. Cohen",
      "Donald Metzler"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06991"
  },
  {
    "id": "arXiv:2202.06995",
    "title": "Intent-Aware Permission Architecture: A Model for Rethinking Informed  Consent for Android Apps",
    "abstract": "As data privacy continues to be a crucial human-right concern as recognized\nby the UN, regulatory agencies have demanded developers obtain user permission\nbefore accessing user-sensitive data. Mainly through the use of privacy\npolicies statements, developers fulfill their legal requirements to keep users\nabreast of the requests for their data. In addition, platforms such as Android\nenforces explicit permission request using the permission model. Nonetheless,\nrecent research has shown that service providers hardly make full disclosure\nwhen requesting data in these statements. Neither is the current permission\nmodel designed to provide adequate informed consent. Often users have no clear\nunderstanding of the reason and scope of usage of the data request. This paper\nproposes an unambiguous, informed consent process that provides developers with\na standardized method for declaring Intent. Our proposed Intent-aware\npermission architecture extends the current Android permission model with a\nprecise mechanism for full disclosure of purpose and scope limitation. The\ndesign of which is based on an ontology study of data requests purposes. The\noverarching objective of this model is to ensure end-users are adequately\ninformed before making decisions on their data. Additionally, this model has\nthe potential to improve trust between end-users and developers.",
    "descriptor": "\nComments: 11 pages, 5 Figures,The International Conference on Information Systems Security and Privacy-ICISSP 2022\n",
    "authors": [
      "Md Rashedur Rahman",
      "Elizabeth Miller",
      "Moinul Hossain",
      "Aisha Ali-Gombe"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.06995"
  },
  {
    "id": "arXiv:2202.07005",
    "title": "Continuously Generalized Ordinal Regression for Linear and Deep Models",
    "abstract": "Ordinal regression is a classification task where classes have an order and\nprediction error increases the further the predicted class is from the true\nclass. The standard approach for modeling ordinal data involves fitting\nparallel separating hyperplanes that optimize a certain loss function. This\nassumption offers sample efficient learning via inductive bias, but is often\ntoo restrictive in real-world datasets where features may have varying effects\nacross different categories. Allowing class-specific hyperplane slopes creates\ngeneralized logistic ordinal regression, increasing the flexibility of the\nmodel at a cost to sample efficiency. We explore an extension of the\ngeneralized model to the all-thresholds logistic loss and propose a\nregularization approach that interpolates between these two extremes. Our\nmethod, which we term continuously generalized ordinal logistic, significantly\noutperforms the standard ordinal logistic model over a thorough set of ordinal\nregression benchmark datasets. We further extend this method to deep learning\nand show that it achieves competitive or lower prediction error compared to\nprevious models over a range of datasets and modalities. Furthermore, two\nprimary alternative models for deep learning ordinal regression are shown to be\nspecial cases of our framework.",
    "descriptor": "",
    "authors": [
      "Fred Lu",
      "Francis Ferraro",
      "Edward Raff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07005"
  },
  {
    "id": "arXiv:2202.07006",
    "title": "A Survey of Visual Sensory Anomaly Detection",
    "abstract": "Visual sensory anomaly detection (AD) is an essential problem in computer\nvision, which is gaining momentum recently thanks to the development of AI for\ngood. Compared with semantic anomaly detection which detects anomaly at the\nlabel level (semantic shift), visual sensory AD detects the abnormal part of\nthe sample (covariate shift). However, no thorough review has been provided to\nsummarize this area for the computer vision community. In this survey, we are\nthe first one to provide a comprehensive review of visual sensory AD and\ncategory into three levels according to the form of anomalies. Furthermore, we\nclassify each kind of anomaly according to the level of supervision. Finally,\nwe summarize the challenges and provide open directions for this community. All\nresources are available at\nhttps://github.com/M-3LAB/awesome-visual-sensory-anomaly-detection.",
    "descriptor": "",
    "authors": [
      "Xi Jiang",
      "Guoyang Xie",
      "Jinbao Wang",
      "Yong Liu",
      "Chengjie Wang",
      "Feng Zheng",
      "Yaochu Jin"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07006"
  },
  {
    "id": "arXiv:2202.07008",
    "title": "Autonomous Vehicles on the Edge: A Survey on Autonomous Vehicle Racing",
    "abstract": "The rising popularity of self-driving cars has led to the emergence of a new\nresearch field in the recent years: Autonomous racing. Researchers are\ndeveloping software and hardware for high performance race vehicles which aim\nto operate autonomously on the edge of the vehicles limits: High speeds, high\naccelerations, low reaction times, highly uncertain, dynamic and adversarial\nenvironments. This paper represents the first holistic survey that covers the\nresearch in the field of autonomous racing. We focus on the field of autonomous\nracecars only and display the algorithms, methods and approaches that are used\nin the fields of perception, planning and control as well as end-to-end\nlearning. Further, with an increasing number of autonomous racing competitions,\nresearchers now have access to a range of high performance platforms to test\nand evaluate their autonomy algorithms. This survey presents a comprehensive\noverview of the current autonomous racing platforms emphasizing both the\nsoftware-hardware co-evolution to the current stage. Finally, based on\nadditional discussion with leading researchers in the field we conclude with a\nsummary of open research challenges that will guide future researchers in this\nfield.",
    "descriptor": "\nComments: 29 pages, 12 figures, 6 tables, 242 references\n",
    "authors": [
      "Johannes Betz",
      "Hongrui Zheng",
      "Alexander Liniger",
      "Ugo Rosolia",
      "Phillip Karle",
      "Madhur Behl",
      "Venkat Krovi",
      "Rahul Mangharam"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.07008"
  },
  {
    "id": "arXiv:2202.07012",
    "title": "Building Inspection Toolkit: Unified Evaluation and Strong Baselines for  Damage Recognition",
    "abstract": "In recent years, several companies and researchers have started to tackle the\nproblem of damage recognition within the scope of automated inspection of built\nstructures. While companies are neither willing to publish associated data nor\nmodels, researchers are facing the problem of data shortage on one hand and\ninconsistent dataset splitting with the absence of consistent metrics on the\nother hand. This leads to incomparable results. Therefore, we introduce the\nbuilding inspection toolkit -- bikit -- which acts as a simple to use data hub\ncontaining relevant open-source datasets in the field of damage recognition.\nThe datasets are enriched with evaluation splits and predefined metrics,\nsuiting the specific task and their data distribution. For the sake of\ncompatibility and to motivate researchers in this domain, we also provide a\nleaderboard and the possibility to share model weights with the community. As\nstarting point we provide strong baselines for multi-target classification\ntasks utilizing extensive hyperparameter search using three transfer learning\napproaches for state-of-the-art algorithms. The toolkit and the leaderboard are\navailable online.",
    "descriptor": "\nComments: 6 pages, 4 figures, 7 tables\n",
    "authors": [
      "Johannes Flotzinger",
      "Philipp J. R\u00f6sch",
      "Norbert Oswald",
      "Thomas Braml"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07012"
  },
  {
    "id": "arXiv:2202.07013",
    "title": "Robust Policy Learning over Multiple Uncertainty Sets",
    "abstract": "Reinforcement learning (RL) agents need to be robust to variations in\nsafety-critical environments. While system identification methods provide a way\nto infer the variation from online experience, they can fail in settings where\nfast identification is not possible. Another dominant approach is robust RL\nwhich produces a policy that can handle worst-case scenarios, but these methods\nare generally designed to achieve robustness to a single uncertainty set that\nmust be specified at train time. Towards a more general solution, we formulate\nthe multi-set robustness problem to learn a policy robust to different\nperturbation sets. We then design an algorithm that enjoys the benefits of both\nsystem identification and robust RL: it reduces uncertainty where possible\ngiven a few interactions, but can still act robustly with respect to the\nremaining uncertainty. On a diverse set of control tasks, our approach\ndemonstrates improved worst-case performance on new environments compared to\nprior methods based on system identification and on robust RL alone.",
    "descriptor": "\nComments: Project webpage at this https URL\n",
    "authors": [
      "Annie Xie",
      "Shagun Sodhani",
      "Chelsea Finn",
      "Joelle Pineau",
      "Amy Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.07013"
  },
  {
    "id": "arXiv:2202.07014",
    "title": "Strategy Discovery and Mixture in Lifelong Learning from Heterogeneous  Demonstration",
    "abstract": "Learning from Demonstration (LfD) approaches empower end-users to teach\nrobots novel tasks via demonstrations of the desired behaviors, democratizing\naccess to robotics. A key challenge in LfD research is that users tend to\nprovide heterogeneous demonstrations for the same task due to various\nstrategies and preferences. Therefore, it is essential to develop LfD\nalgorithms that ensure \\textit{flexibility} (the robot adapts to personalized\nstrategies), \\textit{efficiency} (the robot achieves sample-efficient\nadaptation), and \\textit{scalability} (robot reuses a concise set of strategies\nto represent a large amount of behaviors). In this paper, we propose a novel\nalgorithm, Dynamic Multi-Strategy Reward Distillation (DMSRD), which distills\ncommon knowledge between heterogeneous demonstrations, leverages learned\nstrategies to construct mixture policies, and continues to improve by learning\nfrom all available data. Our personalized, federated, and lifelong LfD\narchitecture surpasses benchmarks in two continuous control problems with an\naverage 77\\% improvement in policy returns and 42\\% improvement in log\nlikelihood, alongside stronger task reward correlation and more precise\nstrategy rewards.",
    "descriptor": "\nComments: Accepted at the AAAI-22 Workshop on Interactive Machine Learning (IML@AAAI'22)\n",
    "authors": [
      "Sravan Jayanthi",
      "Letian Chen",
      "Matthew Gombolay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07014"
  },
  {
    "id": "arXiv:2202.07016",
    "title": "Discrete Adjoint Momentum-Weighted Interpolation Strategies",
    "abstract": "This Technical Note outlines an adjoint complement to a critical building\nblock of pressure-based Finite-Volume (FV) flow solvers that employ a\ncollocated variable arrangement to simulate virtually incompressible fluids.\nThe focal point is to strengthen the adjoint pressure-velocity coupling by\nusing an adjoint Momentum-Weighted Interpolation (MWI) strategy. To this end,\nanalogies of established primal MWI techniques are derived and investigated.\nThe study reveals the merits of an adjoint MWI but also highlights the\nimportance of its careful implementation.",
    "descriptor": "",
    "authors": [
      "Niklas K\u00fchl",
      "Thomas Rung"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2202.07016"
  },
  {
    "id": "arXiv:2202.07021",
    "title": "QuadSim: A Quadcopter Rotational Dynamics Simulation Framework For  Reinforcement Learning Algorithms",
    "abstract": "This study focuses on designing and developing a mathematically based\nquadcopter rotational dynamics simulation framework for testing reinforcement\nlearning (RL) algorithms in many flexible configurations. The design of the\nsimulation framework aims to simulate both linear and nonlinear representations\nof a quadcopter by solving initial value problems for ordinary differential\nequation (ODE) systems. In addition, the simulation environment is capable of\nmaking the simulation deterministic/stochastic by adding random Gaussian noise\nin the forms of process and measurement noises. In order to ensure that the\nscope of this simulation environment is not limited only with our own RL\nalgorithms, the simulation environment has been expanded to be compatible with\nthe OpenAI Gym toolkit. The framework also supports multiprocessing\ncapabilities to run simulation environments simultaneously in parallel. To test\nthese capabilities, many state-of-the-art deep RL algorithms were trained in\nthis simulation framework and the results were compared in detail.",
    "descriptor": "\nComments: for source codes, please visit this https URL\n",
    "authors": [
      "Burak Han Demirbilek"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07021"
  },
  {
    "id": "arXiv:2202.07023",
    "title": "Exhaustivity and anti-exhaustivity in the RSA framework: Testing the  effect of prior beliefs",
    "abstract": "During communication, the interpretation of utterances is sensitive to a\nlistener's probabilistic prior beliefs, something which is captured by one\ncurrently influential model of pragmatics, the Rational Speech Act (RSA)\nframework. In this paper we focus on cases when this sensitivity to priors\nleads to counterintuitive predictions of the framework. Our domain of interest\nis exhaustivity effects, whereby a sentence such as \"Mary came\" is understood\nto mean that only Mary came. We show that in the baseline RSA model, under\ncertain conditions, anti-exhaustive readings are predicted (e.g., \"Mary came\"\nwould be used to convey that both Mary and Peter came). The specific question\nwe ask is the following: should exhaustive interpretations be derived as purely\npragmatic inferences (as in the classical Gricean view, endorsed in the\nbaseline RSA model), or should they rather be generated by an encapsulated\nsemantic mechanism (as argued in some of the recent formal literature)? To\nanswer this question, we provide a detailed theoretical analysis of different\nRSA models and evaluate them against data obtained in a new study which tested\nthe effects of prior beliefs on both production and comprehension, improving on\nprevious empirical work. We found no anti-exhaustivity effects, but observed\nthat message choice is sensitive to priors, as predicted by the RSA framework\noverall. The best models turn out to be those which include an encapsulated\nexhaustivity mechanism (as other studies concluded on the basis of very\ndifferent data). We conclude that, on the one hand, in the division of labor\nbetween semantics and pragmatics, semantics plays a larger role than is often\nthought, but, on the other hand, the tradeoff between informativity and cost\nwhich characterizes all RSA models does play a central role for genuine\npragmatic effects.",
    "descriptor": "",
    "authors": [
      "Alexandre Cremers",
      "Ethan G. Wilcox",
      "Benjamin Spector"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07023"
  },
  {
    "id": "arXiv:2202.07025",
    "title": "Box Supervised Video Segmentation Proposal Network",
    "abstract": "Video Object Segmentation (VOS) has been targeted by various fully-supervised\nand self-supervised approaches. While fully-supervised methods demonstrate\nexcellent results, self-supervised ones, which do not use pixel-level ground\ntruth, attract much attention. However, self-supervised approaches pose a\nsignificant performance gap. Box-level annotations provide a balanced\ncompromise between labeling effort and result quality for image segmentation\nbut have not been exploited for the video domain. In this work, we propose a\nbox-supervised video object segmentation proposal network, which takes\nadvantage of intrinsic video properties. Our method incorporates object motion\nin the following way: first, motion is computed using a bidirectional temporal\ndifference and a novel bounding box-guided motion compensation. Second, we\nintroduce a novel motion-aware affinity loss that encourages the network to\npredict positive pixel pairs if they share similar motion and color. The\nproposed method outperforms the state-of-the-art self-supervised benchmark by\n16.4% and 6.9% $\\mathcal{J}$ &$\\mathcal{F}$ score and the majority of fully\nsupervised methods on the DAVIS and Youtube-VOS dataset without imposing\nnetwork architectural specifications. We provide extensive tests and ablations\non the datasets, demonstrating the robustness of our method.",
    "descriptor": "",
    "authors": [
      "Tanveer Hannan",
      "Rajat Koner",
      "Jonathan Kobold",
      "Matthias Schubert"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07025"
  },
  {
    "id": "arXiv:2202.07026",
    "title": "Analysis of Neural Fragility: Bounding the Norm of a Rank-One  Perturbation Matrix",
    "abstract": "Over 15 million epilepsy patients worldwide do not respond to drugs and\nrequire surgical treatment. Successful surgical treatment requires complete\nremoval, or disconnection of the epileptogenic zone (EZ), but without a\nprospective biomarker of the EZ, surgical success rates vary between 30%-70%.\nNeural fragility is a model recently proposed to localize the EZ. Neural\nfragility is computed as the l2 norm of a structured rank-one perturbation of\nan estimated linear dynamical system. However, an analysis of its numerical\nproperties have not been explored. We show that neural fragility is a\nwell-defined model given a good estimator of the linear dynamical system from\ndata. Specifically, we provide bounds on neural fragility as a function of the\nunderlying linear system and noise.",
    "descriptor": "",
    "authors": [
      "Adam Li",
      "Chester Huynh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Quantitative Methods (q-bio.QM)"
    ],
    "url": "https://arxiv.org/abs/2202.07026"
  },
  {
    "id": "arXiv:2202.07028",
    "title": "One Step at a Time: Long-Horizon Vision-and-Language Navigation with  Milestones",
    "abstract": "We study the problem of developing autonomous agents that can follow human\ninstructions to infer and perform a sequence of actions to complete the\nunderlying task. Significant progress has been made in recent years, especially\nfor tasks with short horizons. However, when it comes to long-horizon tasks\nwith extended sequences of actions, an agent can easily ignore some\ninstructions or get stuck in the middle of the long instructions and eventually\nfail the task. To address this challenge, we propose a model-agnostic\nmilestone-based task tracker (M-TRACK) to guide the agent and monitor its\nprogress. Specifically, we propose a milestone builder that tags the\ninstructions with navigation and interaction milestones which the agent needs\nto complete step by step, and a milestone checker that systemically checks the\nagent's progress in its current milestone and determines when to proceed to the\nnext. On the challenging ALFRED dataset, our M-TRACK leads to a notable 45% and\n70% relative improvement in unseen success rate over two competitive base\nmodels.",
    "descriptor": "\nComments: 10 pages, 5 figures\n",
    "authors": [
      "Chan Hee Song",
      "Jihyung Kil",
      "Tai-Yu Pan",
      "Brian M. Sadler",
      "Wei-Lun Chao",
      "Yu Su"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.07028"
  },
  {
    "id": "arXiv:2202.07029",
    "title": "The Multi-Billion Dollar Software Supply Chain of Ethereum",
    "abstract": "The rise of blockchain technologies has triggered tremendous research\ninterests, coding efforts, and monetary investments in the last decade.\nEthereum is the largest programmable blockchain platform today. It features\ncryptocurrency trading, digital art, and decentralized finance through smart\ncontracts. So-called Ethereum nodes operate the blockchain, relying on a vast\nsupply chain of third-party software dependencies maintained by diverse\norganizations. These software suppliers have a direct impact on the reliability\nand the security of Ethereum. In this article, we perform the first analysis of\nthe software supply chain of Java Ethereum nodes and distill the challenges of\nmaintaining and securing the Ethereum supply chain.",
    "descriptor": "\nComments: 8 pages, 2 figures, 2 tables\n",
    "authors": [
      "C\u00e9sar Soto-Valero",
      "Martin Monperrus",
      "Benoit Baudry"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.07029"
  },
  {
    "id": "arXiv:2202.07036",
    "title": "Benchmarking Online Sequence-to-Sequence and Character-based Handwriting  Recognition from IMU-Enhanced Pens",
    "abstract": "Handwriting is one of the most frequently occurring patterns in everyday life\nand with it come challenging applications such as handwriting recognition\n(HWR), writer identification, and signature verification. In contrast to\noffline HWR that only uses spatial information (i.e., images), online HWR\n(OnHWR) uses richer spatio-temporal information (i.e., trajectory data or\ninertial data). While there exist many offline HWR datasets, there is only\nlittle data available for the development of OnHWR methods as it requires\nhardware-integrated pens. This paper presents data and benchmark models for\nreal-time sequence-to-sequence (seq2seq) learning and single character-based\nrecognition. Our data is recorded by a sensor-enhanced ballpoint pen, yielding\nsensor data streams from triaxial accelerometers, a gyroscope, a magnetometer\nand a force sensor at 100Hz. We propose a variety of datasets including\nequations and words for both the writer-dependent and writer-independent tasks.\nWe provide an evaluation benchmark for seq2seq and single character-based HWR\nusing recurrent and temporal convolutional networks and Transformers combined\nwith a connectionist temporal classification (CTC) loss and cross entropy\nlosses. Our methods do not resort to language or lexicon models.",
    "descriptor": "\nComments: 34 pages. Submitted to TIST\n",
    "authors": [
      "Felix Ott",
      "David R\u00fcgamer",
      "Lucas Heublein",
      "Tim Hamann",
      "Jens Barth",
      "Bernd Bischl",
      "Christopher Mutschler"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07036"
  },
  {
    "id": "arXiv:2202.07047",
    "title": "Vector Coded Caching Multiplicatively Boosts the Throughput of Realistic  Downlink Systems",
    "abstract": "The recent introduction of vector coded caching has revealed that multi-rank\ntransmissions in the presence of receiver-side cache content can dramatically\nameliorate the file-size bottleneck of coded caching and substantially boost\nperformance in error-free wire-like channels. We here employ large-matrix\nanalysis to explore the effect of vector coded caching in realistic wireless\nmulti-antenna downlink systems. Our analysis answers a simple question: Under a\nfixed set of antenna and SNR resources, and a given downlink MISO system which\ncan already enjoy an optimized exploitation of multiplexing and beamforming\ngains, what is the multiplicative boost in the throughput when we are now\nallowed to occasionally add content inside reasonably-sized receiver-side\ncaches? The derived closed-form expressions capture various linear precoders,\nand a variety of practical considerations such as power dissemination across\nsignals, realistic SNR values, as well as feedback costs. The schemes are very\nsimple (we simply collapse precoding vectors into a single vector), and the\nrecorded gains are notable. For example, for 32 transmit antennas, a received\nSNR of 20 dB, a coherence bandwidth of 300 kHz, a coherence period of 40 ms,\nand under realistic file-size and cache-size constraints, vector coded caching\nis here shown to offer a multiplicative throughput boost of about 310% with\nZF/RZF precoding and a 430% boost in the performance of already optimized\nMF-based systems. Interestingly, vector coded caching also accelerates channel\nhardening to the benefit of feedback acquisition, often surpassing 540% gains\nover traditional hardening-constrained downlink systems.",
    "descriptor": "",
    "authors": [
      "Hui Zhao",
      "Antonio Bazco-Nogueras",
      "Petros Elia"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.07047"
  },
  {
    "id": "arXiv:2202.07049",
    "title": "Road Segmentation based Localization using Open Street Maps for Rural  Roads",
    "abstract": "Accurate pose estimation is a fundamental ability that all mobile robots must\nposses in order to traverse robustly in a given environment. Much like a human,\nthis ability is dependent on the robot's understanding of a given scene. For\nAutonomous Vehicles (AV's), detailed 3D maps created beforehand are widely used\nto augment the perceptive abilities and estimate pose based on current sensor\nmeasurements. This approach however is less suited for rural communities that\nare sparsely connected and cover large areas. To deal with the challenge of\nlocalizing a vehicle in a rural setting, this paper presents a data-set of\nrural road scenes, along with an approach for fast segmentation of roads using\nLIDAR point clouds. The segmented point cloud in concert with road network\ninformation from Open Street Maps (OSM) is used for pose estimation. We propose\ntwo measurement models which are compared with state of the art methods for\nlocalization on OSM for tracking as well as global localization. The results\nshow that the proposed algorithm is able to estimate pose within a 2 sq. km\narea with mean accuracy of 6.5 meters.",
    "descriptor": "",
    "authors": [
      "Stephen Ninan",
      "Sivakumar Rathinam"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.07049"
  },
  {
    "id": "arXiv:2202.07050",
    "title": "Artificial Intelligence-Based Smart Grid Vulnerabilities and Potential  Solutions for Fake-Normal Attacks: A Short Review",
    "abstract": "Smart grid systems are critical to the power industry, however their\nsophisticated architectural design and operations expose them to a number of\ncybersecurity threats, such as data tampering, data eavesdropping, and Denial\nof Service, among others. Artificial Intelligence (AI)-based technologies are\nbecoming increasingly popular for detecting cyber assaults in a variety of\ncomputer settings, and several efforts have been made to secure various\nsystems. The present AI systems are being exposed and vanquished because of the\nrecent emergence of sophisticated adversarial systems such as Generative\nAdversarial Networks (GAN). The purpose of this short review is to outline some\nof the initiatives to protect smart grid systems, their obstacles, and what\nmight be a potential future AI research direction",
    "descriptor": "",
    "authors": [
      "J.D. Ndibwile"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07050"
  },
  {
    "id": "arXiv:2202.07052",
    "title": "Orthogonalising gradients to speed up neural network optimisation",
    "abstract": "The optimisation of neural networks can be sped up by orthogonalising the\ngradients before the optimisation step, ensuring the diversification of the\nlearned representations. We orthogonalise the gradients of the layer's\ncomponents/filters with respect to each other to separate out the intermediate\nrepresentations. Our method of orthogonalisation allows the weights to be used\nmore flexibly, in contrast to restricting the weights to an orthogonalised\nsub-space. We tested this method on ImageNet and CIFAR-10 resulting in a large\ndecrease in learning time, and also obtain a speed-up on the semi-supervised\nlearning BarlowTwins. We obtain similar accuracy to SGD without fine-tuning and\nbetter accuracy for na\\\"ively chosen hyper-parameters.",
    "descriptor": "",
    "authors": [
      "Mark Tuddenham",
      "Adam Pr\u00fcgel-Bennett",
      "Jonathan Hare"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07052"
  },
  {
    "id": "arXiv:2202.07054",
    "title": "Universal Adversarial Examples in Remote Sensing: Methodology and  Benchmark",
    "abstract": "Deep neural networks have achieved great success in many important remote\nsensing tasks. Nevertheless, their vulnerability to adversarial examples should\nnot be neglected. In this study, we systematically analyze the universal\nadversarial examples in remote sensing data for the first time, without any\nknowledge from the victim model. Specifically, we propose a novel black-box\nadversarial attack method, namely Mixup-Attack, and its simple variant\nMixcut-Attack, for remote sensing data. The key idea of the proposed methods is\nto find common vulnerabilities among different networks by attacking the\nfeatures in the shallow layer of a given surrogate model. Despite their\nsimplicity, the proposed methods can generate transferable adversarial examples\nthat deceive most of the state-of-the-art deep neural networks in both scene\nclassification and semantic segmentation tasks with high success rates. We\nfurther provide the generated universal adversarial examples in the dataset\nnamed UAE-RS, which is the first dataset that provides black-box adversarial\nsamples in the remote sensing field. We hope UAE-RS may serve as a benchmark\nthat helps researchers to design deep neural networks with strong resistance\ntoward adversarial attacks in the remote sensing field. Codes and the UAE-RS\ndataset will be available online.",
    "descriptor": "",
    "authors": [
      "Yonghao Xu",
      "Pedram Ghamisi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07054"
  },
  {
    "id": "arXiv:2202.07058",
    "title": "Features of Linear Models that May Compromise Model-Based, Plant-Wide  Control Techniques. The Case of the Tennessee Eastman Plant",
    "abstract": "This work examines a set of features that impact the reliability of linear\nmodels within the context of plant-wide control design (PWC). The study case is\nthe Tennessee-Eastman (TE) plant. This benchmark problem is well-known for\nchallenging many control design approaches. Analyses involve eigenvalues,\naverage errors between simulations, condition numbers, and loss of rank across\nfrequencies. These studies offer guidance for designing an effective plant-wide\ncontrol system based on linear models.",
    "descriptor": "",
    "authors": [
      "Sergio F. Yapur"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.07058"
  },
  {
    "id": "arXiv:2202.07064",
    "title": "Towards hardware Implementation of WTA for CPG-based control of a  Spiking Robotic Arm",
    "abstract": "Biological nervous systems typically perform the control of numerous degrees\nof freedom for example in animal limbs. Neuromorphic engineers study these\nsystems by emulating them in hardware for a deeper understanding and its\npossible application to solve complex problems in engineering and robotics.\nCentral-Pattern-Generators (CPGs) are part of neuro-controllers, typically used\nat their last steps to produce rhythmic patterns for limbs movement. Different\npatterns and gaits typically compete through winner-take-all (WTA) circuits to\nproduce the right movements. In this work we present a WTA circuit implemented\nin a Spiking-Neural-Network (SNN) processor to produce such patterns for\ncontrolling a robotic arm in real-time. The robot uses spike-based\nproportional-integrativederivative (SPID) controllers to keep a commanded joint\nposition from the winner population of neurons of the WTA circuit. Experiments\ndemonstrate the feasibility of robotic control with spiking circuits following\nbrain-inspiration.",
    "descriptor": "\nComments: 5 pages, 4 figures, submitted to ISCAS2022\n",
    "authors": [
      "A. Linares-Barranco",
      "E. Pinero-Fuentes",
      "S. Canas-Moreno",
      "A. Rios-Navarro",
      "Maryada",
      "Chenxi Wu",
      "Jingyue Zhao",
      "D. Zendrikov",
      "G. Indiveri"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.07064"
  },
  {
    "id": "arXiv:2202.07065",
    "title": "Automatic Generation of Individual Fuzzy Cognitive Maps from  Longitudinal Data",
    "abstract": "Fuzzy Cognitive Maps (FCMs) are computational models that represent how\nfactors (nodes) change over discrete interactions based on causal impacts\n(weighted directed edges) from other factors. This approach has traditionally\nbeen used as an aggregate, similarly to System Dynamics, to depict the\nfunctioning of a system. There has been a growing interest in taking this\naggregate approach at the individual-level, for example by equipping each agent\nof an Agent-Based Model with its own FCM to express its behavior. Although\nframeworks and studies have already taken this approach, an ongoing limitation\nhas been the difficulty of creating as many FCMs as there are individuals.\nIndeed, current studies have been able to create agents whose traits are\ndifferent, but whose decision-making modules are often identical, thus limiting\nthe behavioral heterogeneity of the simulated population. In this paper, we\naddress this limitation by using Genetic Algorithms to create one FCM for each\nagent, thus providing the means to automatically create a virtual population\nwith heterogeneous behaviors. Our algorithm builds on prior work from Stach and\ncolleagues by introducing additional constraints into the process and applying\nit over longitudinal, individual-level data. A case study from a real-world\nintervention on nutrition confirms that our approach can generate heterogeneous\nagents that closely follow the trajectories of their real-world human\ncounterparts. Future works include technical improvements such as lowering the\ncomputational time of the approach, or case studies in computational\nintelligence that use our virtual populations to test new behavior change\ninterventions.",
    "descriptor": "",
    "authors": [
      "Maciej K Wozniak",
      "Samvel Mkhitaryan",
      "Philippe j. Giabbanelli"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07065"
  },
  {
    "id": "arXiv:2202.07068",
    "title": "Motivating Physical Activity via Competitive Human-Robot Interaction",
    "abstract": "This project aims to motivate research in competitive human-robot interaction\nby creating a robot competitor that can challenge human users in certain\nscenarios such as physical exercise and games. With this goal in mind, we\nintroduce the Fencing Game, a human-robot competition used to evaluate both the\ncapabilities of the robot competitor and user experience. We develop the robot\ncompetitor through iterative multi-agent reinforcement learning and show that\nit can perform well against human competitors. Our user study additionally\nfound that our system was able to continuously create challenging and enjoyable\ninteractions that significantly increased human subjects' heart rates. The\nmajority of human subjects considered the system to be entertaining and\ndesirable for improving the quality of their exercise.",
    "descriptor": "\nComments: Conference on Robot Learning. PMLR, 2022\n",
    "authors": [
      "Boling Yang",
      "Golnaz Habibi",
      "Patrick E. Lancaster",
      "Byron Boots",
      "Joshua R. Smith"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Human-Computer Interaction (cs.HC)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.07068"
  },
  {
    "id": "arXiv:2202.07071",
    "title": "A Unified Perspective on Value Backup and Exploration in Monte-Carlo  Tree Search",
    "abstract": "Monte-Carlo Tree Search (MCTS) is a class of methods for solving complex\ndecision-making problems through the synergy of Monte-Carlo planning and\nReinforcement Learning (RL). The highly combinatorial nature of the problems\ncommonly addressed by MCTS requires the use of efficient exploration strategies\nfor navigating the planning tree and quickly convergent value backup methods.\nThese crucial problems are particularly evident in recent advances that combine\nMCTS with deep neural networks for function approximation. In this work, we\npropose two methods for improving the convergence rate and exploration based on\na newly introduced backup operator and entropy regularization. We provide\nstrong theoretical guarantees to bound convergence rate, approximation error,\nand regret of our methods. Moreover, we introduce a mathematical framework\nbased on the use of the $\\alpha$-divergence for backup and exploration in MCTS.\nWe show that this theoretical formulation unifies different approaches,\nincluding our newly introduced ones, under the same mathematical framework,\nallowing to obtain different methods by simply changing the value of $\\alpha$.\nIn practice, our unified perspective offers a flexible way to balance between\nexploration and exploitation by tuning the single $\\alpha$ parameter according\nto the problem at hand. We validate our methods through a rigorous empirical\nstudy from basic toy problems to the complex Atari games, and including both\nMDP and POMDP problems.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2007.00391\n",
    "authors": [
      "Tuan Dam",
      "Carlo D'Eramo",
      "Jan Peters",
      "Joni Pajarinen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07071"
  },
  {
    "id": "arXiv:2202.07073",
    "title": "Discriminability-enforcing loss to improve representation learning",
    "abstract": "During the training process, deep neural networks implicitly learn to\nrepresent the input data samples through a hierarchy of features, where the\nsize of the hierarchy is determined by the number of layers. In this paper, we\nfocus on enforcing the discriminative power of the high-level representations,\nthat are typically learned by the deeper layers (closer to the output). To this\nend, we introduce a new loss term inspired by the Gini impurity, which is aimed\nat minimizing the entropy (increasing the discriminative power) of individual\nhigh-level features with respect to the class labels. Although our Gini loss\ninduces highly-discriminative features, it does not ensure that the\ndistribution of the high-level features matches the distribution of the\nclasses. As such, we introduce another loss term to minimize the\nKullback-Leibler divergence between the two distributions. We conduct\nexperiments on two image classification data sets (CIFAR-100 and Caltech 101),\nconsidering multiple neural architectures ranging from convolutional networks\n(ResNet-17, ResNet-18, ResNet-50) to transformers (CvT). Our empirical results\nshow that integrating our novel loss terms into the training objective\nconsistently outperforms the models trained with cross-entropy alone.",
    "descriptor": "",
    "authors": [
      "Florinel-Alin Croitoru",
      "Diana-Nicoleta Grigore",
      "Radu Tudor Ionescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07073"
  },
  {
    "id": "arXiv:2202.07074",
    "title": "Benchmarking Robot Manipulation with the Rubik's Cube",
    "abstract": "Benchmarks for robot manipulation are crucial to measuring progress in the\nfield, yet there are few benchmarks that demonstrate critical manipulation\nskills, possess standardized metrics, and can be attempted by a wide array of\nrobot platforms. To address a lack of such benchmarks, we propose Rubik's cube\nmanipulation as a benchmark to measure simultaneous performance of precise\nmanipulation and sequential manipulation. The sub-structure of the Rubik's cube\ndemands precise positioning of the robot's end effectors, while its highly\nreconfigurable nature enables tasks that require the robot to manage pose\nuncertainty throughout long sequences of actions. We present a protocol for\nquantitatively measuring both the accuracy and speed of Rubik's cube\nmanipulation. This protocol can be attempted by any general-purpose\nmanipulator, and only requires a standard 3x3 Rubik's cube and a flat surface\nupon which the Rubik's cube initially rests (e.g. a table). We demonstrate this\nprotocol for two distinct baseline approaches on a PR2 robot. The first\nbaseline provides a fundamental approach for pose-based Rubik's cube\nmanipulation. The second baseline demonstrates the benchmark's ability to\nquantify improved performance by the system, particularly that resulting from\nthe integration of pre-touch sensing. To demonstrate the benchmark's\napplicability to other robot platforms and algorithmic approaches, we present\nthe functional blocks required to enable the HERB robot to manipulate the\nRubik's cube via push-grasping.",
    "descriptor": "\nComments: IEEE RAL\n",
    "authors": [
      "Boling Yang",
      "Patrick E. Lancaster",
      "Siddhartha S. Srinivasa",
      "Joshua R. Smith"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07074"
  },
  {
    "id": "arXiv:2202.07075",
    "title": "Regional Differences in Information Privacy Concerns After the  Facebook-Cambridge Analytica Data Scandal",
    "abstract": "While there is increasing global attention to data privacy, most of their\ncurrent theoretical understanding is based on research conducted in a few\ncountries. Prior work argues that people's cultural backgrounds might shape\ntheir privacy concerns; thus, we could expect people from different world\nregions to conceptualize them in diverse ways. We collected and analyzed a\nlarge-scale dataset of tweets about the #CambridgeAnalytica scandal in Spanish\nand English to start exploring this hypothesis. We employed word embeddings and\nqualitative analysis to identify which information privacy concerns are present\nand characterize language and regional differences in emphasis on these\nconcerns. Our results suggest that related concepts, such as regulations, can\nbe added to current information privacy frameworks. We also observe a greater\nemphasis on data collection in English than in Spanish. Additionally, data from\nNorth America exhibits a narrower focus on awareness compared to other regions\nunder study. Our results call for more diverse sources of data and nuanced\nanalysis of data privacy concerns around the globe.",
    "descriptor": "",
    "authors": [
      "Felipe Gonz\u00e1lez-Pizarro",
      "Andrea Figueroa",
      "Claudia L\u00f3pez",
      "Cecilia Aragon"
    ],
    "subjectives": [
      "Social and Information Networks (cs.SI)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.07075"
  },
  {
    "id": "arXiv:2202.07082",
    "title": "Graph Neural Networks for Graphs with Heterophily: A Survey",
    "abstract": "Recent years have witnessed fast developments of graph neural networks (GNNs)\nthat have benefited myriads of graph analytic tasks and applications. In\ngeneral, most GNNs depend on the homophily assumption that nodes belonging to\nthe same class are more likely to be connected. However, as a ubiquitous graph\nproperty in numerous real-world scenarios, heterophily, i.e., nodes with\ndifferent labels tend to be linked, significantly limits the performance of\ntailor-made homophilic GNNs. Hence, \\textit{GNNs for heterophilic graphs} are\ngaining increasing attention in this community. To the best of our knowledge,\nin this paper, we provide a comprehensive review of GNNs for heterophilic\ngraphs for the first time. Specifically, we propose a systematic taxonomy that\nessentially governs existing heterophilic GNN models, along with a general\nsummary and detailed analysis. Furthermore, we summarize the mainstream\nheterophilic graph benchmarks to facilitate robust and fair evaluations. In the\nend, we point out the potential directions to advance and stimulate future\nresearch and applications on heterophilic graphs.",
    "descriptor": "\nComments: 8 pages, 2 figures\n",
    "authors": [
      "Xin Zheng",
      "Yixin Liu",
      "Shirui Pan",
      "Miao Zhang",
      "Di Jin",
      "Philip S. Yu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07082"
  },
  {
    "id": "arXiv:2202.07085",
    "title": "How to De-Escalate a Cyber Conflict",
    "abstract": "De-escalation of a cyber conflict can be substantially more difficult than\nde-escalation of a conventional military conflict. This paper will first\nexplain the reasons why de-escalation of a cyber conflict can be so difficult,\nand then present a list of suggestions about how to overcome these specific\ndifficulties.",
    "descriptor": "\nComments: 4 pages\n",
    "authors": [
      "Robert Axelrod"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.07085"
  },
  {
    "id": "arXiv:2202.07086",
    "title": "Price Cycles in Ridesharing Platforms",
    "abstract": "In ridesharing platforms such as Uber and Lyft, it is observed that drivers\nsometimes collaboratively go offline when the price is low, and then return\nafter the price has risen due to the perceived lack of supply. This collective\nstrategy leads to cyclic fluctuations in prices and available drivers,\nresulting in poor reliability and social welfare. We study a continuous time,\nnon-atomic model and prove that such online/offline strategies may form a Nash\nequilibrium among drivers, but lead to a lower total driver payoff if the\nmarket is sufficiently dense. Further, we show how to set price floors that\neffectively mitigate the emergence and impact of price cycles.",
    "descriptor": "",
    "authors": [
      "Chenkai Yu",
      "Hongyao Ma",
      "Adam Wierman"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Multiagent Systems (cs.MA)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.07086"
  },
  {
    "id": "arXiv:2202.07088",
    "title": "Scaling up Ranking under Constraints for Live Recommendations by  Replacing Optimization with Prediction",
    "abstract": "Many important multiple-objective decision problems can be cast within the\nframework of ranking under constraints and solved via a weighted bipartite\nmatching linear program. Some of these optimization problems, such as\npersonalized content recommendations, may need to be solved in real time and\nthus must comply with strict time requirements to prevent the perception of\nlatency by consumers. Classical linear programming is too computationally\ninefficient for such settings. We propose a novel approach to scale up ranking\nunder constraints by replacing the weighted bipartite matching optimization\nwith a prediction problem in the algorithm deployment stage. We show\nempirically that the proposed approximate solution to the ranking problem leads\nto a major reduction in required computing resources without much sacrifice in\nconstraint compliance and achieved utility, allowing us to solve larger\nconstrained ranking problems real-time, within the required 50 milliseconds,\nthan previously reported.",
    "descriptor": "\nComments: 12 pages, 2 figures, 3 tables\n",
    "authors": [
      "Yegor Tkachenko",
      "Wassim Dhaouadi",
      "Kamel Jedidi"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07088"
  },
  {
    "id": "arXiv:2202.07092",
    "title": "A Reliability-aware Distributed Framework to Schedule Residential  Charging of Electric Vehicles",
    "abstract": "Residential consumers have become active participants in the power\ndistribution network after being equipped with residential EV charging\nprovisions. This creates a challenge for the network operator tasked with\ndispatching electric power to the residential consumers through the existing\ndistribution network infrastructure in a reliable manner. In this paper, we\naddress the problem of scheduling residential EV charging for multiple\nconsumers while maintaining network reliability. An additional challenge is the\nrestricted exchange of information: where the consumers do not have access to\nnetwork information and the network operator does not have access to consumer\nload parameters. We propose a distributed framework which generates an optimal\nEV charging schedule for individual residential consumers based on their\npreferences and iteratively updates it until the network reliability\nconstraints set by the operator are satisfied. We validate the proposed\napproach for different EV adoption levels in a synthetically created digital\ntwin of an actual power distribution network. The results demonstrate that the\nnew approach can achieve a higher level of network reliability compared to the\ncase where residential consumers charge EVs based solely on their individual\npreferences, thus providing a solution for the existing grid to keep up with\nincreased adoption rates without significant investments in increasing grid\ncapacity.",
    "descriptor": "\nComments: 6 pages main conference paper, 3 pages appendix\n",
    "authors": [
      "Rounak Meyur",
      "Swapna Thorve",
      "Madhav Marathe",
      "Anil Vullikanti",
      "Samarth Swarup",
      "Henning Mortveit"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.07092"
  },
  {
    "id": "arXiv:2202.07094",
    "title": "Matching Tweets With Applicable Fact-Checks Across Languages",
    "abstract": "An important challenge for news fact-checking is the effective dissemination\nof existing fact-checks. This in turn brings the need for reliable methods to\ndetect previously fact-checked claims. In this paper, we focus on automatically\nfinding existing fact-checks for claims made in social media posts (tweets). We\nconduct both classification and retrieval experiments, in monolingual (English\nonly), multilingual (Spanish, Portuguese), and cross-lingual (Hindi-English)\nsettings using multilingual transformer models such as XLM-RoBERTa and\nmultilingual embeddings such as LaBSE and SBERT. We present promising results\nfor \"match\" classification (93% average accuracy) in four language pairs. We\nalso find that a BM25 baseline outperforms state-of-the-art multilingual\nembedding models for the retrieval task during our monolingual experiments. We\nhighlight and discuss NLP challenges while addressing this problem in different\nlanguages, and we introduce a novel curated dataset of fact-checks and\ncorresponding tweets for future research.",
    "descriptor": "\nComments: Accepted to De-Factify Workshop at AAAI 2022\n",
    "authors": [
      "Ashkan Kazemi",
      "Zehua Li",
      "Ver\u00f3nica P\u00e9rez-Rosas",
      "Scott A. Hale",
      "Rada Mihalcea"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07094"
  },
  {
    "id": "arXiv:2202.07096",
    "title": "Learning to Discover Medicines",
    "abstract": "Discovering new medicines is the hallmark of human endeavor to live a better\nand longer life. Yet the pace of discovery has slowed down as we need to\nventure into more wildly unexplored biomedical space to find one that matches\ntoday's high standard. Modern AI-enabled by powerful computing, large\nbiomedical databases, and breakthroughs in deep learning-offers a new hope to\nbreak this loop as AI is rapidly maturing, ready to make a huge impact in the\narea. In this paper we review recent advances in AI methodologies that aim to\ncrack this challenge. We organize the vast and rapidly growing literature of AI\nfor drug discovery into three relatively stable sub-areas: (a) representation\nlearning over molecular sequences and geometric graphs; (b) data-driven\nreasoning where we predict molecular properties and their binding, optimize\nexisting compounds, generate de novo molecules, and plan the synthesis of\ntarget molecules; and (c) knowledge-based reasoning where we discuss the\nconstruction and reasoning over biomedical knowledge graphs. We will also\nidentify open challenges and chart possible research directions for the years\nto come.",
    "descriptor": "",
    "authors": [
      "Tri Minh Nguyen",
      "Thin Nguyen",
      "Truyen Tran"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07096"
  },
  {
    "id": "arXiv:2202.07098",
    "title": "Statistical Inference After Adaptive Sampling in Non-Markovian  Environments",
    "abstract": "There is a great desire to use adaptive sampling methods, such as\nreinforcement learning (RL) and bandit algorithms, for the real-time\npersonalization of interventions in digital applications like mobile health and\neducation. A major obstacle preventing more widespread use of such algorithms\nin practice is the lack of assurance that the resulting adaptively collected\ndata can be used to reliably answer inferential questions, including questions\nabout time-varying causal effects. Current methods for statistical inference on\nsuch data are insufficient because they (a) make strong assumptions regarding\nthe environment dynamics, e.g., assume a contextual bandit or Markovian\nenvironment, or (b) require data to be collected with one adaptive sampling\nalgorithm per user, which excludes data collected by algorithms that learn to\nselect actions by pooling the data of multiple users. In this work, we make\ninitial progress by introducing the adaptive sandwich estimator to quantify\nuncertainty; this estimator (a) is valid even when user rewards and contexts\nare non-stationary and highly dependent over time, and (b) accommodates\nsettings in which an online adaptive sampling algorithm learns using the data\nof all users. Furthermore, our inference method is robust to misspecification\nof the reward models used by the adaptive sampling algorithm. This work is\nmotivated by our work designing experiments in which RL algorithms are used to\nselect actions, yet reliable statistical inference is essential for conducting\nprimary analyses after the trial is over.",
    "descriptor": "",
    "authors": [
      "Kelly W Zhang",
      "Lucas Janson",
      "Susan A Murphy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.07098"
  },
  {
    "id": "arXiv:2202.07101",
    "title": "A Survey on Dynamic Neural Networks for Natural Language Processing",
    "abstract": "Effectively scaling large Transformer models is a main driver of recent\nadvances in natural language processing. Dynamic neural networks, as an\nemerging research direction, are capable of scaling up neural networks with\nsub-linear increases in computation and time by dynamically adjusting their\ncomputational path based on the input. Dynamic neural networks could be a\npromising solution to the growing parameter numbers of pretrained language\nmodels, allowing both model pretraining with trillions of parameters and faster\ninference on mobile devices. In this survey, we summarize progress of three\ntypes of dynamic neural networks in NLP: skimming, mixture of experts, and\nearly exit. We also highlight current challenges in dynamic neural networks and\ndirections for future research.",
    "descriptor": "",
    "authors": [
      "Canwen Xu",
      "Julian McAuley"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07101"
  },
  {
    "id": "arXiv:2202.07104",
    "title": "The Hitchhiker's Guide to Fused Twins -- A Conceptualization to Access  Digital Twins in situ in Smart Cities",
    "abstract": "Smart Cities are happening everywhere around us and yet they are still\nincomprehensibly far from directly impacting everyday life. What needs to\nhappen to make cities really smart? Digital Twins (DTs) represent their\nPhysical Twin (PT) in the real world through models, sensed data, context\nawareness, and interactions. A Digital Twin of a city appears to offer the\nright combination to make the Smart City accessible and thus usable. However,\nwithout appropriate interfaces, the complexity of a city cannot be represented.\nUltimately, fully leveraging the potential of Smart Cities requires going\nbeyond the Digital Twin. Can this issue be addressed? I advance embedding the\nDigital Twin into the Physical Twin, i.e. Fused Twins. Thus, this fusion allows\naccess to data where it is generated in a context that can make it easily\nunderstandable. The Fused Twins paradigm is the formalization of this vision.\nPrototypes of Fused Twins are appearing at an neck-break speed from different\ndomains but Smart Cities will be the context where Fused Twins will\npredominantly be seen in the future. This paper reviews Digital Twins to\nunderstand how Fused Twins can be constructed from Augmented Reality,\nGeographic Information Systems, Building/City Information Models and Digital\nTwins and provides an overview of current research and future directions.",
    "descriptor": "",
    "authors": [
      "Jascha Gr\u00fcbel"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "General Literature (cs.GL)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.07104"
  },
  {
    "id": "arXiv:2202.07105",
    "title": "A Survey on Model Compression for Natural Language Processing",
    "abstract": "With recent developments in new architectures like Transformer and\npretraining techniques, significant progress has been made in applications of\nnatural language processing (NLP). However, the high energy cost and long\ninference delay of Transformer is preventing NLP from entering broader\nscenarios including edge and mobile computing. Efficient NLP research aims to\ncomprehensively consider computation, time and carbon emission for the entire\nlife-cycle of NLP, including data preparation, model training and inference. In\nthis survey, we focus on the inference stage and review the current state of\nmodel compression for NLP, including the benchmarks, metrics and methodology.\nWe outline the current obstacles and future research directions.",
    "descriptor": "",
    "authors": [
      "Canwen Xu",
      "Julian McAuley"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07105"
  },
  {
    "id": "arXiv:2202.07106",
    "title": "Learning to Mitigate AI Collusion on Economic Platforms",
    "abstract": "Algorithmic pricing on online e-commerce platforms raises the concern of\ntacit collusion, where reinforcement learning algorithms learn to set collusive\nprices in a decentralized manner and through nothing more than profit feedback.\nThis raises the question as to whether collusive pricing can be prevented\nthrough the design of suitable \"buy boxes,\" i.e., through the design of the\nrules that govern the elements of e-commerce sites that promote particular\nproducts and prices to consumers. In previous work, Johnson et al. (2020)\ndesigned hand-crafted buy box rules that use demand-steering, based on the\nhistory of pricing by sellers, to prevent collusive behavior. Although\neffective against price collusion, these rules effect this by imposing severe\nrestrictions on consumer choice and consumer welfare. In this paper, we\ndemonstrate that reinforcement learning (RL) can also be used by platforms to\nlearn buy box rules that are effective in preventing collusion by RL sellers,\nand to do so without reducing consumer choice. For this, we adopt the\nmethodology of Stackelberg MDPs, and demonstrate success in learning robust\nrules that continue to provide high consumer welfare together with sellers\nemploying different behavior models or having out-of-distribution costs for\ngoods.",
    "descriptor": "",
    "authors": [
      "Gianluca Brero",
      "Nicolas Lepore",
      "Eric Mibuari",
      "David C. Parkes"
    ],
    "subjectives": [
      "Multiagent Systems (cs.MA)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07106"
  },
  {
    "id": "arXiv:2202.07114",
    "title": "Recent Advances in Reliable Deep Graph Learning: Adversarial Attack,  Inherent Noise, and Distribution Shift",
    "abstract": "Deep graph learning (DGL) has achieved remarkable progress in both business\nand scientific areas ranging from finance and e-commerce to drug and advanced\nmaterial discovery. Despite the progress, applying DGL to real-world\napplications faces a series of reliability threats including adversarial\nattacks, inherent noise, and distribution shift. This survey aims to provide a\ncomprehensive review of recent advances for improving the reliability of DGL\nalgorithms against the above threats. In contrast to prior related surveys\nwhich mainly focus on adversarial attacks and defense, our survey covers more\nreliability-related aspects of DGL, i.e., inherent noise and distribution\nshift. Additionally, we discuss the relationships among above aspects and\nhighlight some important issues to be explored in future research.",
    "descriptor": "",
    "authors": [
      "Bingzhe Wu",
      "Jintang Li",
      "Chengbin Hou",
      "Guoji Fu",
      "Yatao Bian",
      "Liang Chen",
      "Junzhou Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.07114"
  },
  {
    "id": "arXiv:2202.07115",
    "title": "Graph Neural Network-Based Scheduling for Multi-UAV-Enabled  Communications in D2D Networks",
    "abstract": "In this paper, we jointly design the power control and position dispatch for\nMulti-unmanned aerial vehicle (UAV)-enabled communication in device-to-device\n(D2D) networks. Our objective is to maximize the total transmission rate of\ndownlink users (DUs). Meanwhile, the quality of service (QoS) of all D2D users\nmust be satisfied. We comprehensively considered the interference among D2D\ncommunications and downlink transmissions. The original problem is strongly\nnon-convex, which requires high computational complexity for traditional\noptimization methods. And to make matters worse, the results are not\nnecessarily globally optimal. In this paper, we propose a novel graph neural\nnetworks (GNN) based approach that can map the considered system into a\nspecific graph structure and achieve the optimal solution in a low complexity\nmanner. Particularly, we first construct a GNN-based model for the proposed\nnetwork, in which the transmission links and interference links are formulated\nas vertexes and edges, respectively. Then, by taking the channel state\ninformation and the coordinates of ground users as the inputs, as well as the\nlocation of UAVs and the transmission power of all transmitters as outputs, we\nobtain the mapping from inputs to outputs through training the parameters of\nGNN. Simulation results verified that the way to maximize the total\ntransmission rate of DUs can be extracted effectively via the training on\nsamples. Moreover, it also shows that the performance of proposed GNN-based\nmethod is better than that of traditional means.",
    "descriptor": "",
    "authors": [
      "Pei Li",
      "Lingyi Wang",
      "Wei Wu",
      "Fuhui Zhou",
      "Baoyun Wang",
      "Qihui Wu"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.07115"
  },
  {
    "id": "arXiv:2202.07123",
    "title": "Rethinking Network Design and Local Geometry in Point Cloud: A Simple  Residual MLP Framework",
    "abstract": "Point cloud analysis is challenging due to irregularity and unordered data\nstructure. To capture the 3D geometries, prior works mainly rely on exploring\nsophisticated local geometric extractors using convolution, graph, or attention\nmechanisms. These methods, however, incur unfavorable latency during inference,\nand the performance saturates over the past few years. In this paper, we\npresent a novel perspective on this task. We notice that detailed local\ngeometrical information probably is not the key to point cloud analysis -- we\nintroduce a pure residual MLP network, called PointMLP, which integrates no\nsophisticated local geometrical extractors but still performs very\ncompetitively. Equipped with a proposed lightweight geometric affine module,\nPointMLP delivers the new state-of-the-art on multiple datasets. On the\nreal-world ScanObjectNN dataset, our method even surpasses the prior best\nmethod by 3.3% accuracy. We emphasize that PointMLP achieves this strong\nperformance without any sophisticated operations, hence leading to a superior\ninference speed. Compared to most recent CurveNet, PointMLP trains 2x faster,\ntests 7x faster, and is more accurate on ModelNet40 benchmark. We hope our\nPointMLP may help the community towards a better understanding of point cloud\nanalysis. The code is available at https://github.com/ma-xu/pointMLP-pytorch.",
    "descriptor": "\nComments: Accepted by ICLR 2022. Codes are made publically available at this https URL\n",
    "authors": [
      "Xu Ma",
      "Can Qin",
      "Haoxuan You",
      "Haoxi Ran",
      "Yun Fu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07123"
  },
  {
    "id": "arXiv:2202.07125",
    "title": "Transformers in Time Series: A Survey",
    "abstract": "Transformers have achieved superior performances in many tasks in natural\nlanguage processing and computer vision, which also intrigues great interests\nin the time series community. Among multiple advantages of transformers, the\nability to capture long-range dependencies and interactions is especially\nattractive for time series modeling, leading to exciting progress in various\ntime series applications. In this paper, we systematically review transformer\nschemes for time series modeling by highlighting their strengths as well as\nlimitations through a new taxonomy to summarize existing time series\ntransformers in two perspectives. From the perspective of network\nmodifications, we summarize the adaptations of module level and architecture\nlevel of the time series transformers. From the perspective of applications, we\ncategorize time series transformers based on common tasks including\nforecasting, anomaly detection, and classification. Empirically, we perform\nrobust analysis, model size analysis, and seasonal-trend decomposition analysis\nto study how Transformers perform in time series. Finally, we discuss and\nsuggest future directions to provide useful research guidance. To the best of\nour knowledge, this paper is the first work to comprehensively and\nsystematically summarize the recent advances of Transformers for modeling time\nseries data. We hope this survey will ignite further research interests in time\nseries Transformers.",
    "descriptor": "\nComments: 8 pages, 1 figure, 4 tables, 65 referred papers\n",
    "authors": [
      "Qingsong Wen",
      "Tian Zhou",
      "Chaoli Zhang",
      "Weiqi Chen",
      "Ziqing Ma",
      "Junchi Yan",
      "Liang Sun"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.07125"
  },
  {
    "id": "arXiv:2202.07127",
    "title": "Computing with Modular Robots",
    "abstract": "Propagating patterns are used to transfer and process information in chemical\nand physical prototypes of unconventional computing devices. Logical values are\nrepresented by fronts of traveling diffusive, trigger or phase waves. We apply\nthis concept of pattern based computation to develop experimental prototypes of\ncomputing circuits implemented in small modular robots. In the experimental\nprototypes the modular robots Cubelets are concatenated into channels and\njunction. The structures developed by Cubelets propagate signals in parallel\nand asynchronously. The approach is illustrated with a working circuit of a\none-bit full adder. Complementarily a formalization of these constructions are\ndeveloped across Sleptsov nets. Finally, a perspective to swarm dynamics is\ndiscussed.",
    "descriptor": "\nComments: 33 pages, 23 figures, 5 tables\n",
    "authors": [
      "Genaro J. Martinez",
      "Andrew Adamatzky",
      "Ricardo Q. Figueroa",
      "Eric Schweikardt",
      "Dmitry A. Zaitsev",
      "Ivan Zelinka",
      "Luz N. Oliva-Moreno"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2202.07127"
  },
  {
    "id": "arXiv:2202.07130",
    "title": "STaR: Knowledge Graph Embedding by Scaling, Translation and Rotation",
    "abstract": "The bilinear method is mainstream in Knowledge Graph Embedding (KGE), aiming\nto learn low-dimensional representations for entities and relations in\nKnowledge Graph (KG) and complete missing links. Most of the existing works are\nto find patterns between relationships and effectively model them to accomplish\nthis task. Previous works have mainly discovered 6 important patterns like\nnon-commutativity. Although some bilinear methods succeed in modeling these\npatterns, they neglect to handle 1-to-N, N-to-1, and N-to-N relations (or\ncomplex relations) concurrently, which hurts their expressiveness. To this end,\nwe integrate scaling, the combination of translation and rotation that can\nsolve complex relations and patterns, respectively, where scaling is a\nsimplification of projection. Therefore, we propose a corresponding bilinear\nmodel Scaling Translation and Rotation (STaR) consisting of the above two\nparts. Besides, since translation cannot be incorporated into the bilinear\nmodel directly, we introduce translation matrix as the equivalent. Theoretical\nanalysis proves that STaR is capable of modeling all patterns and handling\ncomplex relations simultaneously, and experiments demonstrate its effectiveness\non commonly used benchmarks for link prediction.",
    "descriptor": "",
    "authors": [
      "Jiayi Li",
      "Yujiu Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07130"
  },
  {
    "id": "arXiv:2202.07132",
    "title": "Memory via Temporal Delays in weightless Spiking Neural Network",
    "abstract": "A common view in the neuroscience community is that memory is encoded in the\nconnection strength between neurons. This perception led artificial neural\nnetwork models to focus on connection weights as the key variables to modulate\nlearning. In this paper, we present a prototype for weightless spiking neural\nnetworks that can perform a simple classification task. The memory in this\nnetwork is stored in the timing between neurons, rather than the strength of\nthe connection, and is trained using a Hebbian Spike Timing Dependent\nPlasticity (STDP), which modulates the delays of the connection.",
    "descriptor": "",
    "authors": [
      "Hananel Hazan",
      "Simon Caby",
      "Christopher Earl",
      "Hava Siegelmann",
      "Michael Levin"
    ],
    "subjectives": [
      "Neural and Evolutionary Computing (cs.NE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07132"
  },
  {
    "id": "arXiv:2202.07133",
    "title": "Sim-to-Real Domain Adaptation for Lane Detection and Classification in  Autonomous Driving",
    "abstract": "While supervised detection and classification frameworks in autonomous\ndriving require large labelled datasets to converge, Unsupervised Domain\nAdaptation (UDA) approaches, facilitated by synthetic data generated from\nphoto-real simulated environments, are considered low-cost and less\ntime-consuming solutions. In this paper, we propose UDA schemes using\nadversarial discriminative and generative methods for lane detection and\nclassification applications in autonomous driving. We also present Simulanes\ndataset generator to create a synthetic dataset that is naturalistic utilizing\nCARLA's vast traffic scenarios and weather conditions. The proposed UDA\nframeworks take the synthesized dataset with labels as the source domain,\nwhereas the target domain is the unlabelled real-world data. Using adversarial\ngenerative and feature discriminators, the learnt models are tuned to predict\nthe lane location and class in the target domain. The proposed techniques are\nevaluated using both real-world and our synthetic datasets. The results\nmanifest that the proposed methods have shown superiority over other baseline\nschemes in terms of detection and classification accuracy and consistency. The\nablation study reveals that the size of the simulation dataset plays important\nroles in the classification performance of the proposed methods. Our UDA\nframeworks are available at https://github.com/anita-hu/sim2real-lane-detection\nand our dataset generator is released at https://github.com/anita-hu/simulanes",
    "descriptor": "",
    "authors": [
      "Chuqing Hu",
      "Sinclair Hudson",
      "Martin Ethier",
      "Mohammad Al-Sharman",
      "Derek Rayside",
      "William Melek"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07133"
  },
  {
    "id": "arXiv:2202.07135",
    "title": "Compositional Scene Representation Learning via Reconstruction: A Survey",
    "abstract": "Visual scene representation learning is an important research problem in the\nfield of computer vision. The performance on vision tasks could be improved if\nmore suitable representations are learned for visual scenes. Complex visual\nscenes are the composition of relatively simple visual concepts, and have the\nproperty of combinatorial explosion. Compared with directly representing the\nentire visual scene, extracting compositional scene representations can better\ncope with the diverse combination of background and objects. Because\ncompositional scene representations abstract the concept of objects, performing\nvisual scene analysis and understanding based on these representations could be\neasier and more interpretable. Moreover, learning compositional scene\nrepresentations via reconstruction can greatly reduce the need for training\ndata annotations. Therefore, compositional scene representation learning via\nreconstruction has important research significance. In this survey, we first\ndiscuss representative methods that either learn from a single viewpoint or\nmultiple viewpoints without object-level supervision, then the applications of\ncompositional scene representations, and finally the future directions on this\ntopic.",
    "descriptor": "",
    "authors": [
      "Jinyang Yuan",
      "Tonglin Chen",
      "Bin Li",
      "Xiangyang Xue"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07135"
  },
  {
    "id": "arXiv:2202.07136",
    "title": "Debiased Pseudo Labeling in Self-Training",
    "abstract": "Deep neural networks achieve remarkable performances on a wide range of tasks\nwith the aid of large-scale labeled datasets. However, large-scale annotations\nare time-consuming and labor-exhaustive to obtain on realistic tasks. To\nmitigate the requirement for labeled data, self-training is widely used in both\nacademia and industry by pseudo labeling on readily-available unlabeled data.\nDespite its popularity, pseudo labeling is well-believed to be unreliable and\noften leads to training instability. Our experimental studies further reveal\nthat the performance of self-training is biased due to data sampling,\npre-trained models, and training strategies, especially the inappropriate\nutilization of pseudo labels. To this end, we propose Debiased, in which the\ngeneration and utilization of pseudo labels are decoupled by two independent\nheads. To further improve the quality of pseudo labels, we introduce a\nworst-case estimation of pseudo labeling and seamlessly optimize the\nrepresentations to avoid the worst-case. Extensive experiments justify that the\nproposed Debiased not only yields an average improvement of $14.4$\\% against\nstate-of-the-art algorithms on $11$ tasks (covering generic object recognition,\nfine-grained object recognition, texture classification, and scene\nclassification) but also helps stabilize training and balance performance\nacross classes.",
    "descriptor": "",
    "authors": [
      "Baixu Chen",
      "Junguang Jiang",
      "Ximei Wang",
      "Jianmin Wang",
      "Mingsheng Long"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07136"
  },
  {
    "id": "arXiv:2202.07137",
    "title": "Ultra Wide Band THz IRS Communications: Applications, Challenges, Key  Techniques, and Research Opportunities",
    "abstract": "Terahertz (THz) communication is a promising technology for future wireless\nnetworks due to its ultra-wide bandwidth. However, THz signals suffer from\nsevere attenuation and poor diffraction capability, making it vulnerable to\nblocking obstacles. To compensate for these two shortcomings and improve the\nsystem performance, an intelligent reflecting surface (IRS) can be exploited to\nchange the propagation direction and enhance the signal strength. In this\narticle, we investigate this promising ultra wide band (UWB) THz IRS\ncommunication paradigm. We start by motivating our research and describing\nseveral potential application scenarios. Then, we identify major challenges\nfaced by UWB THz IRS communications. To overcome these challenges, several\neffective key techniques are developed, i.e., the time delayer-based sparse\nradio frequency antenna structure, delay hybrid precoding and IRS deployment.\nSimulation results are also presented to compare the system performance for\nthese proposed techniques, thus demonstrating their effectiveness. Finally, we\nhighlight several open issues and research opportunities for UWB THz IRS\ncommunications.",
    "descriptor": "",
    "authors": [
      "Wanming Hao",
      "Fuhui Zhou",
      "Ming Zeng",
      "Octavia A. Dobre",
      "Naofal Al-Dhahir"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.07137"
  },
  {
    "id": "arXiv:2202.07138",
    "title": "Integrating AI Planning with Natural Language Processing: A Combination  of Explicit and Tacit Knowledge",
    "abstract": "Automated planning focuses on strategies, building domain models and\nsynthesizing plans to transit initial states to goals. Natural language\nprocessing concerns with the interactions between agents and human language,\nespecially processing and analyzing large amounts of natural language data.\nThese two fields have abilities to generate explicit knowledge, e.g.,\npreconditions and effects of action models, and learn from tacit knowledge,\ne.g., neural models, respectively. Integrating AI planning and natural language\nprocessing effectively improves the communication between human and intelligent\nagents. This paper outlines the commons and relations between AI planning and\nnatural language processing, argues that each of them can effectively impact on\nthe other one by four areas: (1) planning-based text understanding, (2)\nplanning-based text generation, (3) text-based human-robot interaction, and (4)\ntext-based explainable planning. We also explore some potential future issues\nbetween AI planning and natural language processing.",
    "descriptor": "",
    "authors": [
      "Kebing Jin",
      "Hankz Hankui Zhuo"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07138"
  },
  {
    "id": "arXiv:2202.07140",
    "title": "Securing Reconfigurable Intelligent Surface-Aided Cell-Free Networks",
    "abstract": "In this paper, we investigate the physical layer security in the\nreconfigurable intelligent surface (RIS)-aided cell-free networks. A maximum\nweighted sum secrecy rate problem is formulated by jointly optimizing the\nactive beamforming (BF) at the base stations and passive BF at the RISs. To\nhandle this non-trivial problem, we adopt the alternating optimization to\ndecouple the original problem into two sub-ones, which are solved using the\nsemidefinite relaxation and continuous convex approximation theory. To decrease\nthe complexity for obtaining overall channel state information (CSI), we extend\nthe proposed framework to the case that only requires part of the RIS' CSI.\nThis is achieved via deliberately discarding the RIS that has a small\ncontribution to the user's secrecy rate. Based on this, we formulate a mixed\ninteger non-linear programming problem, and the linear conic relaxation is used\nto obtained the solutions. Finally, the simulation results show that the\nproposed schemes can obtain a higher secrecy rate than the existing ones.",
    "descriptor": "",
    "authors": [
      "Wanming Hao",
      "Junjie Li",
      "Gangcan Sun",
      "Ming Zeng",
      "Octavia A. Dobre"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.07140"
  },
  {
    "id": "arXiv:2202.07141",
    "title": "Machine Learning in Aerodynamic Shape Optimization",
    "abstract": "Large volumes of experimental and simulation aerodynamic data have been\nrapidly advancing aerodynamic shape optimization (ASO) via machine learning\n(ML), whose effectiveness has been growing thanks to continued developments in\ndeep learning. In this review, we first introduce the state of the art and the\nunsolved challenges in ASO. Next, we present a description of ML fundamentals\nand detail the ML algorithms that have succeeded in ASO. Then we review ML\napplications contributing to ASO from three fundamental perspectives: compact\ngeometric design space, fast aerodynamic analysis, and efficient optimization\narchitecture. In addition to providing a comprehensive summary of the research,\nwe comment on the practicality and effectiveness of the developed methods. We\nshow how cutting-edge ML approaches can benefit ASO and address challenging\ndemands like interactive design optimization. However, practical large-scale\ndesign optimizations remain a challenge due to the costly ML training expense.\nA deep coupling of ML model construction with ASO prior experience and\nknowledge, such as taking physics into account, is recommended to train ML\nmodels effectively.",
    "descriptor": "\nComments: 93 pages, 47 figures, submitted to Progress in Aerospace Sciences\n",
    "authors": [
      "Jichao Li",
      "Xiaosong Du",
      "Joaquim R. R. A. Martins"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Fluid Dynamics (physics.flu-dyn)"
    ],
    "url": "https://arxiv.org/abs/2202.07141"
  },
  {
    "id": "arXiv:2202.07145",
    "title": "GAN-generated Faces Detection: A Survey and New Perspectives",
    "abstract": "Generative Adversarial Networks (GAN) have led to the generation of very\nrealistic face images, which have been used in fake social media accounts and\nother disinformation matters that can generate profound impacts. Therefore, the\ncorresponding GAN-face detection techniques are under active development that\ncan examine and expose such fake faces. In this work, we aim to provide a\ncomprehensive review of recent progress in GAN-face detection. We focus on\nmethods that can detect face images that are generated or synthesized from GAN\nmodels. We classify the existing detection works into four categories: (1) deep\nlearning-based, (2) physical-based, (3) physiological-based methods, and (4)\nevaluation and comparison against human visual performance. For each category,\nwe summarize the key ideas and connect them with method implementations. We\nalso discuss open problems and suggest future research directions.",
    "descriptor": "",
    "authors": [
      "Xin Wang",
      "Hui Guo",
      "Shu Hu",
      "Ming-Ching Chang",
      "Siwei Lyu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07145"
  },
  {
    "id": "arXiv:2202.07146",
    "title": "NewsPod: Automatic and Interactive News Podcasts",
    "abstract": "News podcasts are a popular medium to stay informed and dive deep into news\ntopics. Today, most podcasts are handcrafted by professionals. In this work, we\nadvance the state-of-the-art in automatically generated podcasts, making use of\nrecent advances in natural language processing and text-to-speech technology.\nWe present NewsPod, an automatically generated, interactive news podcast. The\npodcast is divided into segments, each centered on a news event, with each\nsegment structured as a Question and Answer conversation, whose goal is to\nengage the listener. A key aspect of the design is the use of distinct voices\nfor each role (questioner, responder), to better simulate a conversation.\nAnother novel aspect of NewsPod allows listeners to interact with the podcast\nby asking their own questions and receiving automatically generated answers. We\nvalidate the soundness of this system design through two usability studies,\nfocused on evaluating the narrative style and interactions with the podcast,\nrespectively. We find that NewsPod is preferred over a baseline by\nparticipants, with 80% claiming they would use the system in the future.",
    "descriptor": "\nComments: Accepted at IUI 2022, 16 pages, 10 figures\n",
    "authors": [
      "Philippe Laban",
      "Elicia Ye",
      "Srujay Korlakunta",
      "John Canny",
      "Marti A. Hearst"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07146"
  },
  {
    "id": "arXiv:2202.07147",
    "title": "Graph Meta-Reinforcement Learning for Transferable Autonomous  Mobility-on-Demand",
    "abstract": "Autonomous Mobility-on-Demand (AMoD) systems represent an attractive\nalternative to existing transportation paradigms, currently challenged by\nurbanization and increasing travel needs. By centrally controlling a fleet of\nself-driving vehicles, these systems provide mobility service to customers and\nare currently starting to be deployed in a number of cities around the world.\nCurrent learning-based approaches for controlling AMoD systems are limited to\nthe single-city scenario, whereby the service operator is allowed to take an\nunlimited amount of operational decisions within the same transportation\nsystem. However, real-world system operators can hardly afford to fully\nre-train AMoD controllers for every city they operate in, as this could result\nin a high number of poor-quality decisions during training, making the\nsingle-city strategy a potentially impractical solution. To address these\nlimitations, we propose to formalize the multi-city AMoD problem through the\nlens of meta-reinforcement learning (meta-RL) and devise an actor-critic\nalgorithm based on recurrent graph neural networks. In our approach, AMoD\ncontrollers are explicitly trained such that a small amount of experience\nwithin a new city will produce good system performance. Empirically, we show\nhow control policies learned through meta-RL are able to achieve near-optimal\nperformance on unseen cities by learning rapidly adaptable policies, thus\nmaking them more robust not only to novel environments, but also to\ndistribution shifts common in real-world operations, such as special events,\nunexpected congestion, and dynamic pricing schemes.",
    "descriptor": "\nComments: 11 pages, 4 figures\n",
    "authors": [
      "Daniele Gammelli",
      "Kaidi Yang",
      "James Harrison",
      "Filipe Rodrigues",
      "Francisco C. Pereira",
      "Marco Pavone"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.07147"
  },
  {
    "id": "arXiv:2202.07152",
    "title": "L2C2: Locally Lipschitz Continuous Constraint towards Stable and Smooth  Reinforcement Learning",
    "abstract": "This paper proposes a new regularization technique for reinforcement learning\n(RL) towards making policy and value functions smooth and stable. RL is known\nfor the instability of the learning process and the sensitivity of the acquired\npolicy to noise. Several methods have been proposed to resolve these problems,\nand in summary, the smoothness of policy and value functions learned mainly in\nRL contributes to these problems. However, if these functions are extremely\nsmooth, their expressiveness would be lost, resulting in not obtaining the\nglobal optimal solution. This paper therefore considers RL under local\nLipschitz continuity constraint, so-called L2C2. By designing the\nspatio-temporal locally compact space for L2C2 from the state transition at\neach time step, the moderate smoothness can be achieved without loss of\nexpressiveness. Numerical noisy simulations verified that the proposed L2C2\noutperforms the task performance while smoothing out the robot action generated\nfrom the learned policy.",
    "descriptor": "\nComments: 8 pages, 6 figures\n",
    "authors": [
      "Taisuke Kobayashi"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07152"
  },
  {
    "id": "arXiv:2202.07156",
    "title": "On Tracking Dialogue State by Inheriting Slot Values in Mentioned Slot  Pools",
    "abstract": "Dialogue state tracking (DST) is a component of the task-oriented dialogue\nsystem. It is responsible for extracting and managing slot values according to\ndialogue utterances, where each slot represents an essential part of the\ninformation to accomplish a task, and slot value is updated recurrently in each\ndialogue turn. However, many DST models cannot update slot values\nappropriately. These models may repeatedly inherit wrong slot values extracted\nin previous turns, resulting in the fail of the entire DST task.They cannot\nupdate indirectly mentioned slots well, either. This study designed a model\nwith a mentioned slot pool (MSP) to tackle the update problem. The MSP is a\nslot-specific memory that records all mentioned slot values that may be\ninherited, and our model updates slot values according to the MSP and the\ndialogue context. Our model rejects inheriting the previous slot value when it\npredicates the value is wrong. Then, it re-extracts the slot value from the\ncurrent dialogue context. As the contextual information accumulates with the\ndialogue progress, the new value is more likely to be correct. It also can\ntrack the indirectly mentioned slot by picking a value from the MSP.\nExperimental results showed our model reached state-of-the-art DST performance\non MultiWOZ 2.1 and 2.2 datasets.",
    "descriptor": "\nComments: 7 pages, 3 figures, 4 tables\n",
    "authors": [
      "Zhoujian Sun",
      "Zhengxing Huang",
      "Nai Ding"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07156"
  },
  {
    "id": "arXiv:2202.07157",
    "title": "Phase-insensitive versus phase-sensitive ultrasound absorption  tomography in the frequency domain",
    "abstract": "The sensitivity of phase-sensitive detectors, such as piezoelectric\ndetectors, becomes increasingly directional as the detector element size\nincreases. In contrast, pyroelectric sensors, which are phase-insensitive,\nretain their omni-directionality even for large element sizes, although they\nhave significantly poorer temporal resolution. This study uses numerical models\nto examine whether phase-insensitive detectors can be used advantageously in\nultrasound tomography, specifically absorption tomography, when the number of\ndetectors is sparse. We present measurement models for phase-sensitive and\nphase-insensitive sensors and compare the quality of the absorption\nreconstructions between these sensor types based on image contrast metrics. We\nperform the inversion using synthetic data with a Jacobian-based linearised\nmatrix inversion approach.",
    "descriptor": "\nComments: 18 pages, 7 figures. Submitted to Inverse Problems\n",
    "authors": [
      "Santeri Kaupinm\u00e4ki",
      "Ben Cox",
      "Simon Arridge"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.07157"
  },
  {
    "id": "arXiv:2202.07165",
    "title": "OLIVE: Oblivious and Differentially Private Federated Learning on  Trusted Execution Environment",
    "abstract": "By combining Federated Learning with Differential Privacy, it has become\npossible to train deep models while taking privacy into account. Using Local\nDifferential Privacy (LDP) does not require trust in the server, but its\nutility is limited due to strong gradient perturbations. On the other hand,\nclient-level Central Differential Privacy (CDP) provides a good balance between\nthe privacy and utility of the trained model, but requires trust in the central\nserver since they have to share raw gradients. We propose OLIVE, a system that\ncan benefit from CDP while eliminating the need for trust in the server as LDP\nachieves, by using Trusted Execution Environment (TEE), which has attracted\nmuch attention in recent years. In particular, OLIVE provides an efficient data\noblivious algorithm to minimize the privacy risk that can occur during\naggregation in a TEE even on a privileged untrusted server. In this work,\nfirstly, we design an inference attack to leak training data privacy from index\ninformation of gradients which can be obtained by side channels in a sparsified\ngradients setting, and demonstrate the attack's effectiveness on real world\ndataset. Secondly, we propose a fully-oblivious but efficient algorithm that\nkeeps the memory access patterns completely uniform and secure to protect\nprivacy against the designed attack. We also demonstrate that our method works\npractically by various empirical experiments. Our experimental results show our\nproposed algorithm is more efficient compared to state-of-the-art\ngeneral-purpose Oblivious RAM, and can be a practical method in the real-world\nscales.",
    "descriptor": "",
    "authors": [
      "Fumiyuki Kato",
      "Yang Cao",
      "Masatoshi Yoshikawa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.07165"
  },
  {
    "id": "arXiv:2202.07167",
    "title": "Efficient Distributed Computations in Anonymous Dynamic Congested  Systems with Opportunistic Connectivity",
    "abstract": "In this work we address the question of efficiency of distributed computing\nin anonymous, congested and highly dynamic and not-always-connected\nnetworks/systems. More precisely, the system consists of an unknown number of\nanonymous nodes with congestion on links and local computation. Links can\nchange arbitrarily from round to round, with only limitation that the union of\nany T consecutive networks must form a temporarily connected (multi-)graph on\nall nodes (knowledge of T is the only information the nodes require, otherwise\nthe communication would not be feasible). Nodes do not have any IDs, only some\nnumber l of them have a bit distinguishing them from nodes without such a bit.\nIn each round a node can send and receive messages from its current neighbors.\nLinks and nodes are congested, in the sense that the length of messages and\nlocal cache memory for local computation is (asymptotically) logarithmic.\nAll-to-all communication is a fundamental principle in distributed computing\n- it assumes that each node has an input message to be delivered to all other\nnodes. Without loss of generality, the size of each input message is\nlogarithmic to fit in the link and node congestion assumption; otherwise, they\ncould be split in logarithmic batches and considered one-by-one. Because of\nanonymity, each node needs to receive only a set of all input messages, each\naccompanied by a number of initiating nodes (message multiplicity). We prove\nthat this task can be done in time polynomial in the (initially unknown) number\nof nodes n and in the lower bound on the isoperimetric numbers of dynamically\nevolving graphs. This allows to efficiently emulate a popular Congested Clique\nmodel on top of Anonymous Dynamic Congested Systems (ADCS) with Opportunistic\nConnectivity, even if the number of nodes may arbitrarily change in the\nbeginning of emulation.",
    "descriptor": "\nComments: 28 pages\n",
    "authors": [
      "Dariusz R. Kowalski",
      "Miguel A. Mosteiro"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.07167"
  },
  {
    "id": "arXiv:2202.07169",
    "title": "Documentation based Semantic-Aware Log Parsing",
    "abstract": "With the recent advances of deep learning techniques, there are rapidly\ngrowing interests in applying machine learning to log data. As a fundamental\npart of log analytics, accurate log parsing that transforms raw logs to\nstructured events is critical for subsequent machine learning and data mining\ntasks. Previous approaches either analyze the source code for parsing or are\ndata-driven such as text clustering. They largely neglect to exploit another\nwidely available and valuable resource, software documentation that provides\ndetailed explanations for the messages, to improve accuracy. In this paper, we\npropose an approach and system framework to use documentation knowledge for log\nparsing. With parameter value identification, it not only can improve the\nparsing accuracy for documented messages but also for undocumented messages. In\naddition, it can discover the linkages between event templates that are\nestablished by sharing parameters and indicate the correlation of the event\ncontext.",
    "descriptor": "",
    "authors": [
      "Lei Yu",
      "Tian Wu",
      "Jiaqi Li",
      "Patrick Chan",
      "Hong Min",
      "Fanjing Meng"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.07169"
  },
  {
    "id": "arXiv:2202.07170",
    "title": "Fairness Amidst Non-IID Graph Data: A Literature Review",
    "abstract": "Fairness in machine learning (ML), the process to understand and correct\nalgorithmic bias, has gained increasing attention with numerous literature\nbeing carried out, commonly assume the underlying data is independent and\nidentically distributed (IID). On the other hand, graphs are a ubiquitous data\nstructure to capture connections among individual units and is non-IID by\nnature. It is therefore of great importance to bridge the traditional fairness\nliterature designed on IID data and ubiquitous non-IID graph representations to\ntackle bias in ML systems. In this survey, we review such recent advance in\nfairness amidst non-IID graph data and identify datasets and evaluation metrics\navailable for future research. We also point out the limitations of existing\nwork as well as promising future directions.",
    "descriptor": "",
    "authors": [
      "Wenbin Zhang",
      "Jeremy C. Weiss",
      "Shuigeng Zhou",
      "Toby Walsh"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07170"
  },
  {
    "id": "arXiv:2202.07176",
    "title": "DeepONet-Grid-UQ: A Trustworthy Deep Operator Framework for Predicting  the Power Grid's Post-Fault Trajectories",
    "abstract": "This paper proposes a new data-driven method for the reliable prediction of\npower system post-fault trajectories. The proposed method is based on the\nfundamentally new concept of Deep Operator Networks (DeepONets). Compared to\ntraditional neural networks that learn to approximate functions, DeepONets are\ndesigned to approximate nonlinear operators. Under this operator framework, we\ndesign a DeepONet to (1) take as inputs the fault-on trajectories collected,\nfor example, via simulation or phasor measurement units, and (2) provide as\noutputs the predicted post-fault trajectories. In addition, we endow our method\nwith a much-needed ability to balance efficiency with reliable/trustworthy\npredictions via uncertainty quantification. To this end, we propose and compare\ntwo methods that enable quantifying the predictive uncertainty. First, we\npropose a \\textit{Bayesian DeepONet} (B-DeepONet) that uses stochastic gradient\nHamiltonian Monte-Carlo to sample from the posterior distribution of the\nDeepONet parameters. Then, we propose a \\textit{Probabilistic DeepONet}\n(Prob-DeepONet) that uses a probabilistic training strategy to equip DeepONets\nwith a form of automated uncertainty quantification, at virtually no extra\ncomputational cost. Finally, we validate the predictive power and uncertainty\nquantification capability of the proposed B-DeepONet and Prob-DeepONet using\nthe IEEE 16-machine 68-bus system.",
    "descriptor": "",
    "authors": [
      "Christian Moya",
      "Shiqi Zhang",
      "Meng Yue",
      "Guang Lin"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07176"
  },
  {
    "id": "arXiv:2202.07177",
    "title": "Tombo Propeller: Bio-Inspired Deformable Structure toward  Collision-Accommodated Control for Drones",
    "abstract": "There is a growing need for vertical take-off and landing vehicles, including\ndrones, which are safe to use and can adapt to collisions. The risks of damage\nby collision, to humans, obstacles in the environment, and drones themselves,\nare significant. This has prompted a search into nature for a highly resilient\nstructure that can inform a design of propellers to reduce those risks and\nenhance safety. Inspired by the flexibility and resilience of dragonfly wings,\nwe propose a novel design for a biomimetic drone propeller called Tombo\npropeller. Here, we report on the design and fabrication process of this\nbiomimetic propeller that can accommodate collisions and recover quickly, while\nmaintaining sufficient thrust force to hover and fly. We describe the\ndevelopment of an aerodynamic model and experiments conducted to investigate\nperformance characteristics for various configurations of the propeller\nmorphology, and related properties, such as generated thrust force, thrust\nforce deviation, collision force, recovery time, lift-to-drag ratio, and noise.\nFinally, we design and showcase a control strategy for a drone equipped with\nTombo propellers that collides in mid-air with an obstacle and recovers from\ncollision continuing flying. The results show that the maximum collision force\ngenerated by the proposed Tombo propeller is less than two-thirds that of a\ntraditional rigid propeller, which suggests the concrete possibility to employ\ndeformable propellers for drones flying in a cluttered environment. This\nresearch can contribute to morphological design of flying vehicles for agile\nand resilient performance.",
    "descriptor": "",
    "authors": [
      "Son Tien Bui",
      "Quan Khanh Luu",
      "Dinh Quang Nguyen",
      "Nhat Dinh Minh Le",
      "Giuseppe Loianno",
      "Van Anh Ho"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.07177"
  },
  {
    "id": "arXiv:2202.07178",
    "title": "Federated Learning with Sparsified Model Perturbation: Improving  Accuracy under Client-Level Differential Privacy",
    "abstract": "Federated learning (FL) that enables distributed clients to collaboratively\nlearn a shared statistical model while keeping their training data locally has\nreceived great attention recently and can improve privacy and communication\nefficiency in comparison with traditional centralized machine learning\nparadigm. However, sensitive information about the training data can still be\ninferred from model updates shared in FL. Differential privacy (DP) is the\nstate-of-the-art technique to defend against those attacks. The key challenge\nto achieve DP in FL lies in the adverse impact of DP noise on model accuracy,\nparticularly for deep learning models with large numbers of model parameters.\nThis paper develops a novel differentially-private FL scheme named Fed-SMP that\nprovides client-level DP guarantee while maintaining high model accuracy. To\nmitigate the impact of privacy protection on model accuracy, Fed-SMP leverages\na new technique called Sparsified Model Perturbation (SMP), where local models\nare sparsified first before being perturbed with additive Gaussian noise. Two\nsparsification strategies are considered in Fed-SMP: random sparsification and\ntop-$k$ sparsification. We also apply R{\\'e}nyi differential privacy to\nproviding a tight analysis for the end-to-end DP guarantee of Fed-SMP and prove\nthe convergence of Fed-SMP with general loss functions. Extensive experiments\non real-world datasets are conducted to demonstrate the effectiveness of\nFed-SMP in largely improving model accuracy with the same level of DP guarantee\nand saving communication cost simultaneously.",
    "descriptor": "",
    "authors": [
      "Rui Hu",
      "Yanmin Gong",
      "Yuanxiong Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.07178"
  },
  {
    "id": "arXiv:2202.07179",
    "title": "G-Mixup: Graph Data Augmentation for Graph Classification",
    "abstract": "This work develops \\emph{mixup for graph data}. Mixup has shown superiority\nin improving the generalization and robustness of neural networks by\ninterpolating features and labels between two random samples. Traditionally,\nMixup can work on regular, grid-like, and Euclidean data such as image or\ntabular data. However, it is challenging to directly adopt Mixup to augment\ngraph data because different graphs typically: 1) have different numbers of\nnodes; 2) are not readily aligned; and 3) have unique typologies in\nnon-Euclidean space. To this end, we propose $\\mathcal{G}$-Mixup to augment\ngraphs for graph classification by interpolating the generator (i.e., graphon)\nof different classes of graphs. Specifically, we first use graphs within the\nsame class to estimate a graphon. Then, instead of directly manipulating\ngraphs, we interpolate graphons of different classes in the Euclidean space to\nget mixed graphons, where the synthetic graphs are generated through sampling\nbased on the mixed graphons. Extensive experiments show that\n$\\mathcal{G}$-Mixup substantially improves the generalization and robustness of\nGNNs.",
    "descriptor": "",
    "authors": [
      "Xiaotian Han",
      "Zhimeng Jiang",
      "Ninghao Liu",
      "Xia Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07179"
  },
  {
    "id": "arXiv:2202.07183",
    "title": "A Survey of Neural Trojan Attacks and Defenses in Deep Learning",
    "abstract": "Artificial Intelligence (AI) relies heavily on deep learning - a technology\nthat is becoming increasingly popular in real-life applications of AI, even in\nthe safety-critical and high-risk domains. However, it is recently discovered\nthat deep learning can be manipulated by embedding Trojans inside it.\nUnfortunately, pragmatic solutions to circumvent the computational requirements\nof deep learning, e.g. outsourcing model training or data annotation to third\nparties, further add to model susceptibility to the Trojan attacks. Due to the\nkey importance of the topic in deep learning, recent literature has seen many\ncontributions in this direction. We conduct a comprehensive review of the\ntechniques that devise Trojan attacks for deep learning and explore their\ndefenses. Our informative survey systematically organizes the recent literature\nand discusses the key concepts of the methods while assuming minimal knowledge\nof the domain on the readers part. It provides a comprehensible gateway to the\nbroader community to understand the recent developments in Neural Trojans.",
    "descriptor": "\nComments: 15 pages\n",
    "authors": [
      "Jie Wang",
      "Ghulam Mubashar Hassan",
      "Naveed Akhtar"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07183"
  },
  {
    "id": "arXiv:2202.07184",
    "title": "On the Origins of the Block Structure Phenomenon in Neural Network  Representations",
    "abstract": "Recent work has uncovered a striking phenomenon in large-capacity neural\nnetworks: they contain blocks of contiguous hidden layers with highly similar\nrepresentations. This block structure has two seemingly contradictory\nproperties: on the one hand, its constituent layers exhibit highly similar\ndominant first principal components (PCs), but on the other hand, their\nrepresentations, and their common first PC, are highly dissimilar across\ndifferent random seeds. Our work seeks to reconcile these discrepant properties\nby investigating the origin of the block structure in relation to the data and\ntraining methods. By analyzing properties of the dominant PCs, we find that the\nblock structure arises from dominant datapoints - a small group of examples\nthat share similar image statistics (e.g. background color). However, the set\nof dominant datapoints, and the precise shared image statistic, can vary across\nrandom seeds. Thus, the block structure reflects meaningful dataset statistics,\nbut is simultaneously unique to each model. Through studying hidden layer\nactivations and creating synthetic datapoints, we demonstrate that these simple\nimage statistics dominate the representational geometry of the layers inside\nthe block structure. We explore how the phenomenon evolves through training,\nfinding that the block structure takes shape early in training, but the\nunderlying representations and the corresponding dominant datapoints continue\nto change substantially. Finally, we study the interplay between the block\nstructure and different training mechanisms, introducing a targeted\nintervention to eliminate the block structure, as well as examining the effects\nof pretraining and Shake-Shake regularization.",
    "descriptor": "",
    "authors": [
      "Thao Nguyen",
      "Maithra Raghu",
      "Simon Kornblith"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07184"
  },
  {
    "id": "arXiv:2202.07186",
    "title": "Interpolants and Explicit Definitions in Extensions of the Description  Logic EL",
    "abstract": "We show that the vast majority of extensions of the description logic\n$\\mathcal{EL}$ do not enjoy the Craig interpolation nor the projective Beth\ndefinability property. This is the case, for example, for $\\mathcal{EL}$ with\nnominals, $\\mathcal{EL}$ with the universal role, $\\mathcal{EL}$ with a role\ninclusion of the form $r\\circ s\\sqsubseteq s$, and for $\\mathcal{ELI}$. It\nfollows in particular that the existence of an explicit definition of a concept\nor individual name cannot be reduced to subsumption checking via implicit\ndefinability. We show that nevertheless the existence of interpolants and\nexplicit definitions can be decided in polynomial time for standard tractable\nextensions of $\\mathcal{EL}$ (such as $\\mathcal{EL}^{++}$) and in ExpTime for\n$\\mathcal{ELI}$ and various extensions. It follows that these existence\nproblems are not harder than subsumption which is in sharp contrast to the\nsituation for expressive DLs. We also obtain tight bounds for the size of\ninterpolants and explicit definitions and the complexity of computing them:\nsingle exponential for tractable standard extensions of $\\mathcal{EL}$ and\ndouble exponential for $\\mathcal{ELI}$ and extensions. We close with a\ndiscussion of Horn-DLs such as Horn-$\\mathcal{ALCI}$.",
    "descriptor": "",
    "authors": [
      "Marie Fortin",
      "Boris Konev",
      "Frank Wolter"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.07186"
  },
  {
    "id": "arXiv:2202.07188",
    "title": "Survivable Free Space Optical Mesh Network using High-Altitude Platforms",
    "abstract": "Free space optical (FSO) communication refers to the information transmission\ntechnology based on the propagation of optical signals in space. FSO\ncommunication requires that the transmitter and receiver directly see each\nother. High-altitude platforms (HAPs) have been proposed for carrying FSO\ntransceivers in the stratosphere. A multihop HAP network with FSO links can\nrelay traffic between ground FSO nodes. In this study, we propose an end-to-end\nswitching model for forwarding traffic between massive pairs of ground FSO\nnodes over a HAP network. A protection mechanism is employed for improving the\ncommunication survivability in the presence of clouds, which may break the line\nof sight (LoS) between HAPs and ground nodes. We propose an algorithm for\ndesigning the topology of the survivable HAP network, given a set of ground FSO\nnodes. The results demonstrate that, even though networks with survivable\ncapacity use more resources, they are not necessary much more expensive than\nthose without survivability in terms of equipment, i.e., HAPs and FSO devices,\nand in terms of wavelength resource utilization.",
    "descriptor": "",
    "authors": [
      "Dieu Linh Truong",
      "Xuan Vuong Dang",
      "Ngoc Dang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.07188"
  },
  {
    "id": "arXiv:2202.07189",
    "title": "Longest (Sub-)Periodic Subsequence",
    "abstract": "We present an algorithm computing the longest periodic subsequence of a\nstring of length $n$ in $O(n^7)$ time with $O(n^4)$ words of space. We obtain\nimprovements when restricting the exponents or extending the search allowing\nthe reported subsequence to be subperiodic down to $O(n^3)$ time and $O(n^2)$\nwords of space.",
    "descriptor": "",
    "authors": [
      "Hideo Bannai",
      "Tomohiro I",
      "Dominik K\u00f6ppl"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.07189"
  },
  {
    "id": "arXiv:2202.07190",
    "title": "Pruning Networks with Cross-Layer Ranking & k-Reciprocal Nearest Filters",
    "abstract": "This paper focuses on filter-level network pruning. A novel pruning method,\ntermed CLR-RNF, is proposed. We first reveal a \"long-tail\" long-tail pruning\nproblem in magnitude-based weight pruning methods, and then propose a\ncomputation-aware measurement for individual weight importance, followed by a\nCross-Layer Ranking (CLR) of weights to identify and remove the bottom-ranked\nweights. Consequently, the per-layer sparsity makes up of the pruned network\nstructure in our filter pruning. Then, we introduce a recommendation-based\nfilter selection scheme where each filter recommends a group of its closest\nfilters. To pick the preserved filters from these recommended groups, we\nfurther devise a k-Reciprocal Nearest Filter (RNF) selection scheme where the\nselected filters fall into the intersection of these recommended groups. Both\nour pruned network structure and the filter selection are non-learning\nprocesses, which thus significantly reduce the pruning complexity, and\ndifferentiate our method from existing works. We conduct image classification\non CIFAR-10 and ImageNet to demonstrate the superiority of our CLR-RNF over the\nstate-of-the-arts. For example, on CIFAR-10, CLR-RNF removes 74.1% FLOPs and\n95.0% parameters from VGGNet-16 with even 0.3\\% accuracy improvements. On\nImageNet, it removes 70.2% FLOPs and 64.8% parameters from ResNet-50 with only\n1.7% top-5 accuracy drops. Our project is at https://github.com/lmbxmu/CLR-RNF.",
    "descriptor": "",
    "authors": [
      "Mingbao Lin",
      "Liujuan Cao",
      "Yuxin Zhang",
      "Ling Shao",
      "Chia-Wen Lin",
      "Rongrong Ji"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07190"
  },
  {
    "id": "arXiv:2202.07191",
    "title": "Improving Human Sperm Head Morphology Classification with Unsupervised  Anatomical Feature Distillation",
    "abstract": "With rising male infertility, sperm head morphology classification becomes\ncritical for accurate and timely clinical diagnosis. Recent deep learning (DL)\nmorphology analysis methods achieve promising benchmark results, but leave\nperformance and robustness on the table by relying on limited and possibly\nnoisy class labels. To address this, we introduce a new DL training framework\nthat leverages anatomical and image priors from human sperm microscopy crops to\nextract useful features without additional labeling cost. Our core idea is to\ndistill sperm head information with reliably-generated pseudo-masks and\nunsupervised spatial prediction tasks. The predicted foreground masks from this\ndistillation step are then leveraged to regularize and reduce image and label\nnoise in the tuning stage. We evaluate our new approach on two public sperm\ndatasets and achieve state-of-the-art performances (e.g. 65.9% SCIAN accuracy\nand 96.5% HuSHeM accuracy).",
    "descriptor": "\nComments: Accepted to ISBI 2022 proceedings\n",
    "authors": [
      "Yejia Zhang",
      "Jingjing Zhang",
      "Xiaomin Zha",
      "Yiru Zhou",
      "Yunxia Cao",
      "Danny Chen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07191"
  },
  {
    "id": "arXiv:2202.07196",
    "title": "Polar Coded Modulation via Hybrid Bit Labeling",
    "abstract": "Bit-interleaved coded modulation (BICM) and multilevel coded modulation (MLC)\nare commonly used to combine polar codes with high order modulation. While BICM\nbenefits from simple design and the separation of coding and modulation, MLC\nshows better performance under successive-cancellation decoding. In this paper\nwe propose a hybrid polar coded modulation scheme that lies between BICM and\nMLC, wherein a fraction of bits are assigned to set-partition (SP) labeling and\nthe remaining bits are assigned for Gray labeling. The SP labeled bits undergo\nsequential demodulation, using iterative demodulation and polar decoding\nsimilar to MLC, whereas the Gray labeled bits are first demodulated in parallel\nand then sent for decoding similar to BICM. Either polar codes or other channel\ncodes (such as LDPC codes) can be used for the Gray labeled bits. For length\n2048 rate 1/2 polar code on 256-QAM, the performance gap between BICM (Gray\nlabeling only) and MLC (SP labeling only) can be almost fully closed by the\nhybrid scheme. Notably, the hybrid scheme has a significant latency advantage\nover MLC. These performance gains make the proposed scheme attractive for\nfuture communication systems such as 6G.",
    "descriptor": "",
    "authors": [
      "Hanwen Yao",
      "Jinfeng Du",
      "Alexander Vardy"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.07196"
  },
  {
    "id": "arXiv:2202.07201",
    "title": "Holistic Adversarial Robustness of Deep Learning Models",
    "abstract": "Adversarial robustness studies the worst-case performance of a machine\nlearning model to ensure safety and reliability. With the proliferation of\ndeep-learning based technology, the potential risks associated with model\ndevelopment and deployment can be amplified and become dreadful\nvulnerabilities. This paper provides a comprehensive overview of research\ntopics and foundational principles of research methods for adversarial\nrobustness of deep learning models, including attacks, defenses, verification,\nand novel applications.",
    "descriptor": "\nComments: survey paper on holistic adversarial robustness for deep learning\n",
    "authors": [
      "Pin-Yu Chen",
      "Sijia Liu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.07201"
  },
  {
    "id": "arXiv:2202.07203",
    "title": "Collision-free Path Planning in the Latent Space through cGANs",
    "abstract": "We show a new method for collision-free path planning by cGANs by mapping its\nlatent space to only the collision-free areas of the robot joint space. Our\nmethod simply provides this collision-free latent space after which any\nplanner, using any optimization conditions, can be used to generate the most\nsuitable paths on the fly. We successfully verified this method with a\nsimulated two-link robot arm.",
    "descriptor": "\nComments: 10pages, 9figures\n",
    "authors": [
      "Tomoki Ando",
      "Hiroki Mori",
      "Ryota Torishima",
      "Kuniyuki Takahashi",
      "Shoichiro Yamaguchi",
      "Daisuke Okanohara",
      "Tetsuya Ogata"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.07203"
  },
  {
    "id": "arXiv:2202.07206",
    "title": "Impact of Pretraining Term Frequencies on Few-Shot Reasoning",
    "abstract": "Pretrained Language Models (LMs) have demonstrated ability to perform\nnumerical reasoning by extrapolating from a few examples in few-shot settings.\nHowever, the extent to which this extrapolation relies on robust reasoning is\nunclear. In this paper, we investigate how well these models reason with terms\nthat are less frequent in the pretraining data. In particular, we examine the\ncorrelations between the model performance on test instances and the frequency\nof terms from those instances in the pretraining data. We measure the strength\nof this correlation for a number of GPT-based language models (pretrained on\nthe Pile dataset) on various numerical deduction tasks (e.g., arithmetic and\nunit conversion). Our results consistently demonstrate that models are more\naccurate on instances whose terms are more prevalent, in some cases above\n$70\\%$ (absolute) more accurate on the top 10\\% frequent terms in comparison to\nthe bottom 10\\%. Overall, although LMs exhibit strong performance at few-shot\nnumerical reasoning tasks, our results raise the question of how much models\nactually generalize beyond pretraining data, and we encourage researchers to\ntake the pretraining data into account when interpreting evaluation results.",
    "descriptor": "",
    "authors": [
      "Yasaman Razeghi",
      "Robert L. Logan IV",
      "Matt Gardner",
      "Sameer Singh"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07206"
  },
  {
    "id": "arXiv:2202.07208",
    "title": "Time Domain Simulation of DFIG-Based Wind Power System using  Differential Transform Method",
    "abstract": "This paper proposes a new non-iterative time-domain simulation approach using\nDifferential Transform Method (DTM) to solve the set of non-linear\nDifferential-Algebraic Equations (DAEs) involved in a DFIG-based wind power\nsystem. The DTM is an analytical as well as numerical approach applied to solve\nhigh dimensional non-linear dynamical systems and the solution can be expressed\nin the form of a series. In this approach, there is no need to compute\nhigher-order derivatives as DAEs are converted into a set of linear equations\nafter applying transformation rules so that the power series coefficients can\nbe computed directly. The transformation rules are used to transform power\nsystem models of various devices, such as induction generator, wind turbine,\nrotor and grid side converter, which includes trigonometric, square root,\nexponential functions etc. Further, to increase the interval of convergence for\nthe series solutions, the multi-step DTM (MsDTM) approach is used. The\nnumerical performance of the proposed approach is compared with the traditional\nnumerical RK-4 method to demonstrate the potential of the proposed approach in\nsolving power system non-linear DAEs",
    "descriptor": "\nComments: 10 pages, 11 figures\n",
    "authors": [
      "Pradeep Singh",
      "Upasana Buragohain",
      "Nilanjan Senroy"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.07208"
  },
  {
    "id": "arXiv:2202.07209",
    "title": "Case law retrieval: problems, methods, challenges and evaluations in the  last 20 years",
    "abstract": "Case law retrieval is the retrieval of judicial decisions relevant to a legal\nquestion. Case law retrieval comprises a significant amount of a lawyer's time,\nand is important to ensure accurate advice and reduce workload. We survey\nmethods for case law retrieval from the past 20 years and outline the problems\nand challenges facing evaluation of case law retrieval systems going forward.\nLimited published work has focused on improving ranking in ad-hoc case law\nretrieval. But there has been significant work in other areas of case law\nretrieval, and legal information retrieval generally. This is likely due to\nlegal search providers being unwilling to give up the secrets of their success\nto competitors. Most evaluations of case law retrieval have been undertaken on\nsmall collections and focus on related tasks such as question-answer systems or\nrecommender systems. Work has not focused on Cranfield style evaluations and\nbaselines of methods for case law retrieval on publicly available test\ncollections are not present. This presents a major challenge going forward. But\nthere are reasons to question the extent of this problem, at least in a\ncommercial setting. Without test collections to baseline approaches it cannot\nbe known whether methods are promising. Works by commercial legal search\nproviders show the effectiveness of natural language systems as well as query\nexpansion for case law retrieval. Machine learning is being applied to more and\nmore legal search tasks, and undoubtedly this represents the future of case law\nretrieval.",
    "descriptor": "",
    "authors": [
      "Daniel Locke",
      "Guido Zuccon"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07209"
  },
  {
    "id": "arXiv:2202.07215",
    "title": "Balancing Domain Experts for Long-Tailed Camera-Trap Recognition",
    "abstract": "Label distributions in camera-trap images are highly imbalanced and\nlong-tailed, resulting in neural networks tending to be biased towards\nhead-classes that appear frequently. Although long-tail learning has been\nextremely explored to address data imbalances, few studies have been conducted\nto consider camera-trap characteristics, such as multi-domain and multi-frame\nsetup. Here, we propose a unified framework and introduce two datasets for\nlong-tailed camera-trap recognition. We first design domain experts, where each\nexpert learns to balance imperfect decision boundaries caused by data\nimbalances and complement each other to generate domain-balanced decision\nboundaries. Also, we propose a flow consistency loss to focus on moving\nobjects, expecting class activation maps of multi-frame matches the flow with\noptical flow maps for input images. Moreover, two long-tailed camera-trap\ndatasets, WCS-LT and DMZ-LT, are introduced to validate our methods.\nExperimental results show the effectiveness of our framework, and proposed\nmethods outperform previous methods on recessive domain samples.",
    "descriptor": "\nComments: 5 pages, 4 figures\n",
    "authors": [
      "Byeongjun Park",
      "Jeongsoo Kim",
      "Seungju Cho",
      "Heeseon Kim"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07215"
  },
  {
    "id": "arXiv:2202.07219",
    "title": "Multi-style Training for South African Call Centre Audio",
    "abstract": "Mismatched data is a challenging problem for automatic speech recognition\n(ASR) systems. One of the most common techniques used to address mismatched\ndata is multi-style training (MTR), a form of data augmentation that attempts\nto transform the training data to be more representative of the testing data;\nand to learn robust representations applicable to different conditions. This\ntask can be very challenging if the test conditions are unknown. We explore the\nimpact of different MTR styles on system performance when testing conditions\nare different from training conditions in the context of deep neural network\nhidden Markov model (DNN-HMM) ASR systems. A controlled environment is created\nusing the LibriSpeech corpus, where we isolate the effect of different MTR\nstyles on final system performance. We evaluate our findings on a South African\ncall centre dataset that contains noisy, WAV49-encoded audio.",
    "descriptor": "\nComments: 9 pages, 8 tables, Southern African Conference for Artificial Intelligence Research 2021, Part of the Communications in Computer and Information Science book series (CCIS, volume 1551, pp 111-124), Springer\n",
    "authors": [
      "Walter Heymans",
      "Marelie H. Davel",
      "Charl van Heerden"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Human-Computer Interaction (cs.HC)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.07219"
  },
  {
    "id": "arXiv:2202.07221",
    "title": "Navigating Local Minima in Quantized Spiking Neural Networks",
    "abstract": "Spiking and Quantized Neural Networks (NNs) are becoming exceedingly\nimportant for hyper-efficient implementations of Deep Learning (DL) algorithms.\nHowever, these networks face challenges when trained using error\nbackpropagation, due to the absence of gradient signals when applying hard\nthresholds. The broadly accepted trick to overcoming this is through the use of\nbiased gradient estimators: surrogate gradients which approximate thresholding\nin Spiking Neural Networks (SNNs), and Straight-Through Estimators (STEs),\nwhich completely bypass thresholding in Quantized Neural Networks (QNNs). While\nnoisy gradient feedback has enabled reasonable performance on simple supervised\nlearning tasks, it is thought that such noise increases the difficulty of\nfinding optima in loss landscapes, especially during the later stages of\noptimization. By periodically boosting the Learning Rate (LR) during training,\nwe expect the network can navigate unexplored solution spaces that would\notherwise be difficult to reach due to local minima, barriers, or flat\nsurfaces. This paper presents a systematic evaluation of a cosine-annealed LR\nschedule coupled with weight-independent adaptive moment estimation as applied\nto Quantized SNNs (QSNNs). We provide a rigorous empirical evaluation of this\ntechnique on high precision and 4-bit quantized SNNs across three datasets,\ndemonstrating (close to) state-of-the-art performance on the more complex\ndatasets. Our source code is available at this link:\nhttps://github.com/jeshraghian/QSNNs.",
    "descriptor": "",
    "authors": [
      "Jason K. Eshraghian",
      "Corey Lammie",
      "Mostafa Rahimi Azghadi",
      "Wei D. Lu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.07221"
  },
  {
    "id": "arXiv:2202.07228",
    "title": "MeshLeTemp: Leveraging the Learnable Vertex-Vertex Relationship to  Generalize Human Pose and Mesh Reconstruction for In-the-Wild Scenes",
    "abstract": "We present MeshLeTemp, a powerful method for 3D human pose and mesh\nreconstruction from a single image. In terms of human body priors encoding, we\npropose using a learnable template human mesh instead of a constant template\nutilized by previous state-of-the-art methods. The proposed learnable template\nreflects not only vertex-vertex interactions but also the human pose and body\nshape, being able to adapt to diverse images. We also introduce a strategy to\nenrich the training data that contains both 2D and 3D annotations. We conduct\nextensive experiments to show the generalizability of our method and the\neffectiveness of our data strategy. As one of our ablation studies, we adapt\nMeshLeTemp to another domain which is 3D hand reconstruction.",
    "descriptor": "",
    "authors": [
      "Trung Q. Tran",
      "Cuong C. Than",
      "Hai T. Nguyen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07228"
  },
  {
    "id": "arXiv:2202.07230",
    "title": "Geometrically Equivariant Graph Neural Networks: A Survey",
    "abstract": "Many scientific problems require to process data in the form of geometric\ngraphs. Unlike generic graph data, geometric graphs exhibit symmetries of\ntranslations, rotations, and/or reflections. Researchers have leveraged such\ninductive bias and developed geometrically equivariant Graph Neural Networks\n(GNNs) to better characterize the geometry and topology of geometric graphs.\nDespite fruitful achievements, it still lacks a survey to depict how\nequivariant GNNs are progressed, which in turn hinders the further development\nof equivariant GNNs. To this end, based on the necessary but concise\nmathematical preliminaries, we analyze and classify existing methods into three\ngroups regarding how the message passing and aggregation in GNNs are\nrepresented. We also summarize the benchmarks as well as the related datasets\nto facilitate later researches for methodology development and experimental\nevaluation. The prospect for future potential directions is also provided.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Jiaqi Han",
      "Yu Rong",
      "Tingyang Xu",
      "Wenbing Huang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07230"
  },
  {
    "id": "arXiv:2202.07231",
    "title": "Few-shot semantic segmentation via mask aggregation",
    "abstract": "Few-shot semantic segmentation aims to recognize novel classes with only very\nfew labelled data. This challenging task requires mining of the relevant\nrelationships between the query image and the support images. Previous works\nhave typically regarded it as a pixel-wise classification problem. Therefore,\nvarious models have been designed to explore the correlation of pixels between\nthe query image and the support images. However, they focus only on pixel-wise\ncorrespondence and ignore the overall correlation of objects. In this paper, we\nintroduce a mask-based classification method for addressing this problem. The\nmask aggregation network (MANet), which is a simple mask classification model,\nis proposed to simultaneously generate a fixed number of masks and their\nprobabilities of being targets. Then, the final segmentation result is obtained\nby aggregating all the masks according to their locations. Experiments on both\nthe PASCAL-5^i and COCO-20^i datasets show that our method performs comparably\nto the state-of-the-art pixel-based methods. This competitive performance\ndemonstrates the potential of mask classification as an alternative baseline\nmethod in few-shot semantic segmentation. Our source code will be made\navailable at https://github.com/TinyAway/MANet.",
    "descriptor": "",
    "authors": [
      "Wei Ao",
      "Shunyi Zheng",
      "Yan Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07231"
  },
  {
    "id": "arXiv:2202.07233",
    "title": "Eliciting Best Practices for Collaboration with Computational Notebooks",
    "abstract": "Despite the widespread adoption of computational notebooks, little is known\nabout best practices for their usage in collaborative contexts. In this paper,\nwe fill this gap by eliciting a catalog of best practices for collaborative\ndata science with computational notebooks. With this aim, we first look for\nbest practices through a multivocal literature review. Then, we conduct\ninterviews with professional data scientists to assess their awareness of these\nbest practices. Finally, we assess the adoption of best practices through the\nanalysis of 1,380 Jupyter notebooks retrieved from the Kaggle platform.\nFindings reveal that experts are mostly aware of the best practices and tend to\nadopt them in their daily work. Nonetheless, they do not consistently follow\nall the recommendations as, depending on specific contexts, some are deemed\nunfeasible or counterproductive due to the lack of proper tool support. As\nsuch, we envision the design of notebook solutions that allow data scientists\nnot to have to prioritize exploration and rapid prototyping over writing code\nof quality.",
    "descriptor": "",
    "authors": [
      "Luigi Quaranta",
      "Fabio Calefato",
      "Filippo Lanubile"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07233"
  },
  {
    "id": "arXiv:2202.07235",
    "title": "Radial-recombination for rigid rotational alignment of images and  volumes",
    "abstract": "A common task in single particle electron cryomicroscopy (cryo-EM) is the\nrigid alignment of images and/or volumes. In the context of images, a rigid\nalignment involves estimating the inner-product between one image of $N\\times\nN$ pixels and another image that has been translated by some displacement and\nrotated by some angle $\\gamma$. In many situations the number of rotations\n$\\gamma$ considered is large (e.g., $\\mathcal{O}(N)$), while the number of\ntranslations considered is much smaller (e.g., $\\mathcal{O}(1)$). In these\nscenarios a naive algorithm requires $\\mathcal{O}(N^{3})$ operations to\ncalculate the array of inner-products for each image-pair. This computation can\nbe accelerated by using a fourier-bessel basis and the fast-fourier-transform\n(FFT), requiring only $\\mathcal{O}(N^2)$ operations per image-pair. We propose\na simple data-driven compression algorithm to further accelerate this\ncomputation, which we refer to as the `radial-SVD'. Our approach involves\nlinearly-recombining the different rings of the original images (expressed in\npolar-coordinates), taking advantage of the singular-value-decomposition (SVD)\nto choose a low-rank combination which both compresses the images and optimizes\na certain measure of angular discriminability. When aligning multiple images to\nmultiple targets, the complexity of our approach is $\\mathcal{O}(N(\\log(N)+H))$\nper image-pair, where $H$ is the rank of the SVD used in the compression above.\nThe advantage gained by this approach depends on the ratio between $H$ and $N$;\nthe smaller $H$ is the better. In many applications $H$ can be quite a bit\nsmaller than $N$ while still maintaining accuracy. We present numerical results\nin a cryo-EM application demonstrating that the radial- and degree-SVD can help\nsave a factor of $5$--$10$ for both image- and volume-alignment.",
    "descriptor": "\nComments: 36 pages, 12 figures\n",
    "authors": [
      "Aaditya V. Rangan"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.07235"
  },
  {
    "id": "arXiv:2202.07241",
    "title": "Learning to Solve Routing Problems via Distributionally Robust  Optimization",
    "abstract": "Recent deep models for solving routing problems always assume a single\ndistribution of nodes for training, which severely impairs their\ncross-distribution generalization ability. In this paper, we exploit group\ndistributionally robust optimization (group DRO) to tackle this issue, where we\njointly optimize the weights for different groups of distributions and the\nparameters for the deep model in an interleaved manner during training. We also\ndesign a module based on convolutional neural network, which allows the deep\nmodel to learn more informative latent pattern among the nodes. We evaluate the\nproposed approach on two types of well-known deep models including GCN and\nPOMO. The experimental results on the randomly synthesized instances and the\nones from two benchmark dataset (i.e., TSPLib and CVRPLib) demonstrate that our\napproach could significantly improve the cross-distribution generalization\nperformance over the original models.",
    "descriptor": "",
    "authors": [
      "Yuan Jiang",
      "Yaoxin Wu",
      "Zhiguang Cao",
      "Jie Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07241"
  },
  {
    "id": "arXiv:2202.07242",
    "title": "Neural Architecture Search for Dense Prediction Tasks in Computer Vision",
    "abstract": "The success of deep learning in recent years has lead to a rising demand for\nneural network architecture engineering. As a consequence, neural architecture\nsearch (NAS), which aims at automatically designing neural network\narchitectures in a data-driven manner rather than manually, has evolved as a\npopular field of research. With the advent of weight sharing strategies across\narchitectures, NAS has become applicable to a much wider range of problems. In\nparticular, there are now many publications for dense prediction tasks in\ncomputer vision that require pixel-level predictions, such as semantic\nsegmentation or object detection. These tasks come with novel challenges, such\nas higher memory footprints due to high-resolution data, learning multi-scale\nrepresentations, longer training times, and more complex and larger neural\narchitectures. In this manuscript, we provide an overview of NAS for dense\nprediction tasks by elaborating on these novel challenges and surveying ways to\naddress them to ease future research and application of existing methods to\nnovel problems.",
    "descriptor": "",
    "authors": [
      "Thomas Elsken",
      "Arber Zela",
      "Jan Hendrik Metzen",
      "Benedikt Staffler",
      "Thomas Brox",
      "Abhinav Valada",
      "Frank Hutter"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07242"
  },
  {
    "id": "arXiv:2202.07244",
    "title": "Explaining Reject Options of Learning Vector Quantization Classifiers",
    "abstract": "While machine learning models are usually assumed to always output a\nprediction, there also exist extensions in the form of reject options which\nallow the model to reject inputs where only a prediction with an unacceptably\nlow certainty would be possible. With the ongoing rise of eXplainable AI, a lot\nof methods for explaining model predictions have been developed. However,\nunderstanding why a given input was rejected, instead of being classified by\nthe model, is also of interest. Surprisingly, explanations of rejects have not\nbeen considered so far.\nWe propose to use counterfactual explanations for explaining rejects and\ninvestigate how to efficiently compute counterfactual explanations of different\nreject options for an important class of models, namely prototype-based\nclassifiers such as learning vector quantization models.",
    "descriptor": "",
    "authors": [
      "Andr\u00e9 Artelt",
      "Johannes Brinkrolf",
      "Roel Visser",
      "Barbara Hammer"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07244"
  },
  {
    "id": "arXiv:2202.07247",
    "title": "CommerceMM: Large-Scale Commerce MultiModal Representation Learning with  Omni Retrieval",
    "abstract": "We introduce CommerceMM - a multimodal model capable of providing a diverse\nand granular understanding of commerce topics associated to the given piece of\ncontent (image, text, image+text), and having the capability to generalize to a\nwide range of tasks, including Multimodal Categorization, Image-Text Retrieval,\nQuery-to-Product Retrieval, Image-to-Product Retrieval, etc. We follow the\npre-training + fine-tuning training regime and present 5 effective pre-training\ntasks on image-text pairs. To embrace more common and diverse commerce data\nwith text-to-multimodal, image-to-multimodal, and multimodal-to-multimodal\nmapping, we propose another 9 novel cross-modal and cross-pair retrieval tasks,\ncalled Omni-Retrieval pre-training. The pre-training is conducted in an\nefficient manner with only two forward/backward updates for the combined 14\ntasks. Extensive experiments and analysis show the effectiveness of each task.\nWhen combining all pre-training tasks, our model achieves state-of-the-art\nperformance on 7 commerce-related downstream tasks after fine-tuning.\nAdditionally, we propose a novel approach of modality randomization to\ndynamically adjust our model under different efficiency constraints.",
    "descriptor": "\nComments: 10 pages, 7 figures. Commerce Multimodal Model towards Real Applications at Facebook\n",
    "authors": [
      "Licheng Yu",
      "Jun Chen",
      "Animesh Sinha",
      "Mengjiao MJ Wang",
      "Hugo Chen",
      "Tamara L. Berg",
      "Ning Zhang"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Multimedia (cs.MM)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.07247"
  },
  {
    "id": "arXiv:2202.07253",
    "title": "Exploiting Data Sparsity in Secure Cross-Platform Social Recommendation",
    "abstract": "Social recommendation has shown promising improvements over traditional\nsystems since it leverages social correlation data as an additional input. Most\nexisting work assumes that all data are available to the recommendation\nplatform. However, in practice, user-item interaction data (e.g.,rating) and\nuser-user social data are usually generated by different platforms, and both of\nwhich contain sensitive information. Therefore, \"How to perform secure and\nefficient social recommendation across different platforms, where the data are\nhighly-sparse in nature\" remains an important challenge. In this work, we bring\nsecure computation techniques into social recommendation, and propose S3Rec, a\nsparsity-aware secure cross-platform social recommendation framework. As a\nresult, our model can not only improve the recommendation performance of the\nrating platform by incorporating the sparse social data on the social platform,\nbut also protect data privacy of both platforms. Moreover, to further improve\nmodel training efficiency, we propose two secure sparse matrix multiplication\nprotocols based on homomorphic encryption and private information retrieval.\nOur experiments on two benchmark datasets demonstrate the effectiveness of\nS3Rec.",
    "descriptor": "",
    "authors": [
      "Jamie Cui",
      "Chaochao Chen",
      "Lingjuan Lyu",
      "Carl Yang",
      "Li Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.07253"
  },
  {
    "id": "arXiv:2202.07255",
    "title": "Enhancing Cross-lingual Prompting with Mask Token Augmentation",
    "abstract": "Prompting shows promising results in few-shot scenarios. However, its\nstrength for multilingual/cross-lingual problems has not been fully exploited.\nZhao and Sch\\\"utze (2021) made initial explorations in this direction by\npresenting that cross-lingual prompting outperforms cross-lingual finetuning.\nIn this paper, we conduct empirical analysis on the effect of each component in\ncross-lingual prompting and derive Universal Prompting across languages, which\nhelps alleviate the discrepancies between source-language training and\ntarget-language inference. Based on this, we propose a mask token augmentation\nframework to further improve the performance of prompt-based cross-lingual\ntransfer. Notably, for XNLI, our method achieves 46.54% with only 16 English\ntraining examples per class, significantly better than 34.99% of finetuning.",
    "descriptor": "",
    "authors": [
      "Meng Zhou",
      "Xin Li",
      "Yue Jiang",
      "Lidong Bing"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07255"
  },
  {
    "id": "arXiv:2202.07256",
    "title": "Federated Graph Neural Networks: Overview, Techniques and Challenges",
    "abstract": "With its powerful capability to deal with graph data widely found in\npractical applications, graph neural networks (GNNs) have received significant\nresearch attention. However, as societies become increasingly concerned with\ndata privacy, GNNs face the need to adapt to this new normal. This has led to\nthe rapid development of federated graph neural networks (FedGNNs) research in\nrecent years. Although promising, this interdisciplinary field is highly\nchallenging for interested researchers to enter into. The lack of an insightful\nsurvey on this topic only exacerbates this problem. In this paper, we bridge\nthis gap by offering a comprehensive survey of this emerging field. We propose\na unique 3-tiered taxonomy of the FedGNNs literature to provide a clear view\ninto how GNNs work in the context of Federated Learning (FL). It puts existing\nworks into perspective by analyzing how graph data manifest themselves in FL\nsettings, how GNN training is performed under different FL system architectures\nand degrees of graph data overlap across data silo, and how GNN aggregation is\nperformed under various FL settings. Through discussions of the advantages and\nlimitations of existing works, we envision future research directions that can\nhelp build more robust, dynamic, efficient, and interpretable FedGNNs.",
    "descriptor": "",
    "authors": [
      "Rui Liu",
      "Han Yu"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07256"
  },
  {
    "id": "arXiv:2202.07258",
    "title": "Accelerating Non-Negative and Bounded-Variable Linear Regression  Algorithms with Safe Screening",
    "abstract": "Non-negative and bounded-variable linear regression problems arise in a\nvariety of applications in machine learning and signal processing. In this\npaper, we propose a technique to accelerate existing solvers for these problems\nby identifying saturated coordinates in the course of iterations. This is akin\nto safe screening techniques previously proposed for sparsity-regularized\nregression problems. The proposed strategy is provably safe as it provides\ntheoretical guarantees that the identified coordinates are indeed saturated in\nthe optimal solution. Experimental results on synthetic and real data show\ncompelling accelerations for both non-negative and bounded-variable problems.",
    "descriptor": "",
    "authors": [
      "Cassio Dantas",
      "Emmanuel Soubies",
      "C\u00e9dric F\u00e9votte"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.07258"
  },
  {
    "id": "arXiv:2202.07259",
    "title": "Review of the Fingerprint Liveness Detection (LivDet) competition  series: from 2009 to 2021",
    "abstract": "Fingerprint authentication systems are highly vulnerable to artificial\nreproductions of fingerprint, called fingerprint presentation attacks.\nDetecting presentation attacks is not trivial because attackers refine their\nreplication techniques from year to year. The International Fingerprint\nliveness Detection Competition (LivDet), an open and well-acknowledged meeting\npoint of academies and private companies that deal with the problem of\npresentation attack detection, has the goal to assess the performance of\nfingerprint presentation attack detection (FPAD) algorithms by using standard\nexperimental protocols and data sets. Each LivDet edition, held biannually\nsince 2009, is characterized by a different set of challenges against which\ncompetitors must be dealt with. The continuous increase of competitors and the\nnoticeable decrease in error rates across competitions demonstrate a growing\ninterest in the topic. This paper reviews the LivDet editions from 2009 to 2021\nand points out their evolution over the years.",
    "descriptor": "\nComments: Chapter of the Handbook of Biometric Anti-Spoofing (Third Edition)\n",
    "authors": [
      "Marco Micheletto",
      "Giulia Orr\u00f9",
      "Roberto Casula",
      "David Yambay",
      "Gian Luca Marcialis",
      "Stephanie C. Schuckers"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07259"
  },
  {
    "id": "arXiv:2202.07260",
    "title": "Learning Disentangled Behaviour Patterns for Wearable-based Human  Activity Recognition",
    "abstract": "In wearable-based human activity recognition (HAR) research, one of the major\nchallenges is the large intra-class variability problem. The collected activity\nsignal is often, if not always, coupled with noises or bias caused by personal,\nenvironmental, or other factors, making it difficult to learn effective\nfeatures for HAR tasks, especially when with inadequate data. To address this\nissue, in this work, we proposed a Behaviour Pattern Disentanglement (BPD)\nframework, which can disentangle the behavior patterns from the irrelevant\nnoises such as personal styles or environmental noises, etc. Based on a\ndisentanglement network, we designed several loss functions and used an\nadversarial training strategy for optimization, which can disentangle activity\nsignals from the irrelevant noises with the least dependency (between them) in\nthe feature space. Our BPD framework is flexible, and it can be used on top of\nexisting deep learning (DL) approaches for feature refinement. Extensive\nexperiments were conducted on four public HAR datasets, and the promising\nresults of our proposed BPD scheme suggest its flexibility and effectiveness.\nThis is an open-source project, and the code can be found at\nthis http URL",
    "descriptor": "\nComments: Accepted to ACM IMWUT 2022\n",
    "authors": [
      "Jie Su",
      "Zhenyu Wen",
      "Tao Lin",
      "Yu Guan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.07260"
  },
  {
    "id": "arXiv:2202.07261",
    "title": "Exploring the Devil in Graph Spectral Domain for 3D Point Cloud Attacks",
    "abstract": "3D dynamic point clouds provide a discrete representation of real-world\nobjects or scenes in motion, which have been widely applied in immersive\ntelepresence, autonomous driving, surveillance, \\textit{etc}. However, point\nclouds acquired from sensors are usually perturbed by noise, which affects\ndownstream tasks such as surface reconstruction and analysis. Although many\nefforts have been made for static point cloud denoising, few works address\ndynamic point cloud denoising. In this paper, we propose a novel gradient-based\ndynamic point cloud denoising method, exploiting the temporal correspondence\nfor the estimation of gradient fields -- also a fundamental problem in dynamic\npoint cloud processing and analysis. The gradient field is the gradient of the\nlog-probability function of the noisy point cloud, based on which we perform\ngradient ascent so as to converge each point to the underlying clean surface.\nWe estimate the gradient of each surface patch by exploiting the temporal\ncorrespondence, where the temporally corresponding patches are searched\nleveraging on rigid motion in classical mechanics. In particular, we treat each\npatch as a rigid object, which moves in the gradient field of an adjacent frame\nvia force until reaching a balanced state, i.e., when the sum of gradients over\nthe patch reaches 0. Since the gradient would be smaller when the point is\ncloser to the underlying surface, the balanced patch would fit the underlying\nsurface well, thus leading to the temporal correspondence. Finally, the\nposition of each point in the patch is updated along the direction of the\ngradient averaged from corresponding patches in adjacent frames. Experimental\nresults demonstrate that the proposed model outperforms state-of-the-art\nmethods.",
    "descriptor": "",
    "authors": [
      "Qianjiang Hu",
      "Daizong Liu",
      "Wei Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.07261"
  },
  {
    "id": "arXiv:2202.07265",
    "title": "A data availability attack on a blockchain protocol based on LDPC codes",
    "abstract": "In a blockchain Data Availability Attack (DAA), a malicious node publishes a\nblock header but withholds part of the block, which contains invalid\ntransactions. Honest full nodes, which can download and store the full\nblockchain, are aware that some data are not available but they have no formal\nway to prove it to light nodes, i.e., nodes that have limited resources and are\nnot able to access the whole blockchain data. A common solution to counter\nthese attacks exploits linear error correcting codes to encode the block\ncontent. A recent protocol, called SPAR, employs coded Merkle trees and\nlow-density parity-check (LDPC) codes to counter DAAs. We show that the sparse\nnature of LDPC matrices and the use of the so-called peeling decoder make the\nprotocol less secure than expected, owing to a new possible attack strategy\nthat can be followed by malicious nodes.",
    "descriptor": "",
    "authors": [
      "Massimo Battaglioni",
      "Paolo Santini",
      "Giulia Rafaiani",
      "Franco Chiaraluce",
      "Marco Baldi"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.07265"
  },
  {
    "id": "arXiv:2202.07267",
    "title": "High-Throughput Split-Tree Architecture for Nonbinary SCL Polar Decoder",
    "abstract": "Nonbinary polar codes defined over Galois field GF(q) have shown improved\nerror-correction performance than binary polar codes using\nsuccessive-cancellation list (SCL) decoding. However, nonbinary operations are\ncomplex and a direct-mapped decoder results in a low throughput, representing\ndifficulties for practical adoptions. In this work, we develop, to the best of\nour knowledge, the first hardware implementation for nonbinary SCL polar\ndecoding. We present a high-throughput decoder architecture using a split-tree\nalgorithm. The sub-trees are decoded in parallel by smaller sub-decoders with a\nreconciliation stage to maintain constraints between sub-trees. A skimming\nalgorithm is proposed to reduce the reconciliation complexity for further\nimproved throughput. The split-tree nonbinary SCL (S-NBSCL) polar decoder is\nprototyped using a 28nm CMOS technology for a (128,64) polar code over GF(256).\nThe decoder delivers 26.1 Mb/s throughput, 11.65 Mb/s/mm$^2$ area efficiency\nand 28.8 nJ/b energy efficiency, outperforming the direct-mapped decoder by\n10.3x, 4.4x and 2.7x, respectively, while achieving excellent error-correction\nperformance.",
    "descriptor": "\nComments: Accepted in ISCAS 2022\n",
    "authors": [
      "Yaoyu Tao",
      "Cedric Choi"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.07267"
  },
  {
    "id": "arXiv:2202.07268",
    "title": "Convolutional Network Fabric Pruning With Label Noise",
    "abstract": "This paper presents an iterative pruning strategy for Convolutional Network\nFabrics (CNF) in presence of noisy training and testing data. With the\ncontinuous increase in size of neural network models, various authors have\ndeveloped pruning approaches to build more compact network structures requiring\nless resources, while preserving performance. As we show in this paper, because\nof their intrinsic structure and function, Convolutional Network Fabrics are\nideal candidates for pruning. We present a series of pruning strategies that\ncan significantly reduce both the final network size and required training time\nby pruning either entire convolutional filters or individual weights, so that\nthe grid remains visually understandable but that overall execution quality\nstays within controllable boundaries. Our approach can be iteratively applied\nduring training so that the network complexity decreases rapidly, saving\ncomputational time. The paper addresses both data-dependent and dataindependent\nstrategies, and also experimentally establishes the most efficient approaches\nwhen training or testing data contain annotation errors.",
    "descriptor": "",
    "authors": [
      "Ilias Benjelloun",
      "Bart Lamiroy",
      "Efoevi Koudou"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.07268"
  },
  {
    "id": "arXiv:2202.07271",
    "title": "Hyper-relationship Learning Network for Scene Graph Generation",
    "abstract": "Generating informative scene graphs from images requires integrating and\nreasoning from various graph components, i.e., objects and relationships.\nHowever, current scene graph generation (SGG) methods, including the unbiased\nSGG methods, still struggle to predict informative relationships due to the\nlack of 1) high-level inference such as transitive inference between\nrelationships and 2) efficient mechanisms that can incorporate all interactions\nof graph components. To address the issues mentioned above, we devise a\nhyper-relationship learning network, termed HLN, for SGG. Specifically, the\nproposed HLN stems from hypergraphs and two graph attention networks (GATs) are\ndesigned to infer relationships: 1) the object-relationship GAT or OR-GAT to\nexplore interactions between objects and relationships, and 2) the\nhyper-relationship GAT or HR-GAT to integrate transitive inference of\nhyper-relationships, i.e., the sequential relationships between three objects\nfor transitive reasoning. As a result, HLN significantly improves the\nperformance of scene graph generation by integrating and reasoning from object\ninteractions, relationship interactions, and transitive inference of\nhyper-relationships. We evaluate HLN on the most popular SGG dataset, i.e., the\nVisual Genome dataset, and the experimental results demonstrate its great\nsuperiority over recent state-of-the-art methods. For example, the proposed HLN\nimproves the recall per relationship from 11.3\\% to 13.1\\%, and maintains the\nrecall per image from 19.8\\% to 34.9\\%. We will release the source code and\npretrained models on GitHub.",
    "descriptor": "",
    "authors": [
      "Yibing Zhan",
      "Zhi Chen",
      "Jun Yu",
      "BaoSheng Yu",
      "Dacheng Tao",
      "Yong Luo"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07271"
  },
  {
    "id": "arXiv:2202.07273",
    "title": "SpeechPainter: Text-conditioned Speech Inpainting",
    "abstract": "We propose SpeechPainter, a model for filling in gaps of up to one second in\nspeech samples by leveraging an auxiliary textual input. We demonstrate that\nthe model performs speech inpainting with the appropriate content, while\nmaintaining speaker identity, prosody and recording environment conditions, and\ngeneralizing to unseen speakers. Our approach significantly outperforms\nbaselines constructed using adaptive TTS, as judged by human raters in\nside-by-side preference and MOS tests.",
    "descriptor": "",
    "authors": [
      "Zal\u00e1n Borsos",
      "Matt Sharifi",
      "Marco Tagliasacchi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.07273"
  },
  {
    "id": "arXiv:2202.07275",
    "title": "HiMA: A Fast and Scalable History-based Memory Access Engine for  Differentiable Neural Computer",
    "abstract": "Memory-augmented neural networks (MANNs) provide better inference performance\nin many tasks with the help of an external memory. The recently developed\ndifferentiable neural computer (DNC) is a MANN that has been shown to\noutperform in representing complicated data structures and learning long-term\ndependencies. DNC's higher performance is derived from new history-based\nattention mechanisms in addition to the previously used content-based attention\nmechanisms. History-based mechanisms require a variety of new compute\nprimitives and state memories, which are not supported by existing neural\nnetwork (NN) or MANN accelerators. We present HiMA, a tiled, history-based\nmemory access engine with distributed memories in tiles. HiMA incorporates a\nmulti-mode network-on-chip (NoC) to reduce the communication latency and\nimprove scalability. An optimal submatrix-wise memory partition strategy is\napplied to reduce the amount of NoC traffic; and a two-stage usage sort method\nleverages distributed tiles to improve computation speed. To make HiMA\nfundamentally scalable, we create a distributed version of DNC called DNC-D to\nallow almost all memory operations to be applied to local memories with\ntrainable weighted summation to produce the global memory output. Two\napproximation techniques, usage skimming and softmax approximation, are\nproposed to further enhance hardware efficiency. HiMA prototypes are created in\nRTL and synthesized in a 40nm technology. By simulations, HiMA running DNC and\nDNC-D demonstrates 6.47x and 39.1x higher speed, 22.8x and 164.3x better area\nefficiency, and 6.1x and 61.2x better energy efficiency over the\nstate-of-the-art MANN accelerator. Compared to an Nvidia 3080Ti GPU, HiMA\ndemonstrates speedup by up to 437x and 2,646x when running DNC and DNC-D,\nrespectively.",
    "descriptor": "\nComments: Published in MICRO 2021\n",
    "authors": [
      "Yaoyu Tao",
      "Zhengya Zhang"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07275"
  },
  {
    "id": "arXiv:2202.07278",
    "title": "Worldwide Gender Differences in Public Code Contributions",
    "abstract": "Gender imbalance is a well-known phenomenon observed throughout sciences\nwhich is particularly severe in software development and Free/Open Source\nSoftware communities. Little is know yet about the geography of this phenomenon\nin particular when considering large scales for both its time and space\ndimensions. We contribute to fill this gap with a longitudinal study of the\npopulation of contributors to publicly available software source code. We\nanalyze the development history of 160 million software projects for a total of\n2.2 billion commits contributed by 43 million distinct authors over a period of\n50 years. We classify author names by gender using name frequencies and author\ngeographical locations using heuristics based on email addresses and time\nzones. We study the evolution over time of contributions to public code by\ngender and by world region. For the world overall, we confirm previous findings\nabout the low but steadily increasing ratio of contributions by female authors.\nWhen breaking down by world regions we find that the long-term growth of female\nparticipation is a worldwide phenomenon. We also observe a decrease in the\nratio of female participation during the COVID-19 pandemic, suggesting that\nwomen's ability to contribute to public code has been more hindered than that\nof men.",
    "descriptor": "\nComments: 44th International Conference on Software Engineering (ICSE 2022) - Software Engineering in Society (SEIS) Track, May 2022, Pittsburgh, MA, United States\n",
    "authors": [
      "Davide Rossi",
      "Stefano Zacchiroli"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.07278"
  },
  {
    "id": "arXiv:2202.07280",
    "title": "Saving Dense Retriever from Shortcut Dependency in Conversational Search",
    "abstract": "In conversational search (CS), it needs holistic understanding over\nconversational inputs to retrieve relevant passages. In this paper, we\ndemonstrate the existence of a retrieval shortcut in CS, which causes models to\nretrieve passages solely relying on partial history while disregarding the\nlatest question. With in-depth analysis, we first show naively trained dense\nretrievers heavily exploit the shortcut and hence perform poorly when asked to\nanswer history-independent questions. To prevent models from solely relying on\nthe shortcut, we explore iterative hard negatives mined by pre-trained dense\nretrievers. Experimental results show that training with the iterative hard\nnegatives effectively mitigates the dependency on the shortcut and makes\nsubstantial improvement on recent CS benchmarks. Our retrievers achieve new\nstate-of-the-art results, outperforming the previous best models by 9.7 in\nRecall@10 on QReCC and 12.4 in Recall@5 on TopiOCQA. Furthermore, in our\nend-to-end QA experiments, FiD readers combined with our retrievers surpass the\nprevious state-of-the-art models by 3.7 and 1.0 EM scores on QReCC and\nTopiOCQA, respectively.",
    "descriptor": "\nComments: 9 pages, 4 figures\n",
    "authors": [
      "Sungdong Kim",
      "Gangwoo Kim"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07280"
  },
  {
    "id": "arXiv:2202.07281",
    "title": "Towards Effective Multi-Task Interaction for Entity-Relation Extraction:  A Unified Framework with Selection Recurrent Network",
    "abstract": "Entity-relation extraction aims to jointly solve named entity recognition\n(NER) and relation extraction (RE). Recent approaches use either one-way\nsequential information propagation in a pipeline manner or two-way implicit\ninteraction with a shared encoder. However, they still suffer from poor\ninformation interaction due to the gap between the different task forms of NER\nand RE, raising a controversial question whether RE is really beneficial to\nNER. Motivated by this, we propose a novel and unified cascade framework that\ncombines the advantages of both sequential information propagation and implicit\ninteraction. Meanwhile, it eliminates the gap between the two tasks by\nreformulating entity-relation extraction as unified span-extraction tasks.\nSpecifically, we propose a selection recurrent network as a shared encoder to\nencode task-specific independent and shared representations and design two\nsequential information propagation strategies to realize the sequential\ninformation flow between NER and RE. Extensive experiments demonstrate that our\napproaches can achieve state-of-the-art results on two common benchmarks, ACE05\nand SciERC, and effectively model the multi-task interaction, which realizes\nsignificant mutual benefits of NER and RE.",
    "descriptor": "",
    "authors": [
      "An Wang",
      "Ao Liu",
      "Hieu Hanh Le",
      "Haruo Yokota"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07281"
  },
  {
    "id": "arXiv:2202.07283",
    "title": "A Simple LP-Based Approximation Algorithm for the Matching Augmentation  Problem",
    "abstract": "The Matching Augmentation Problem (MAP) has recently received significant\nattention as an important step towards better approximation algorithms for\nfinding cheap $2$-edge connected subgraphs. This has culminated in a\n$\\frac{5}{3}$-approximation algorithm. However, the algorithm and its analysis\nare fairly involved and do not compare against the problem's well-known LP\nrelaxation called the cut LP. In this paper, we propose a simple algorithm\nthat, guided by an optimal solution to the cut LP, first selects a DFS tree and\nthen finds a solution to MAP by computing an optimum augmentation of this tree.\nUsing properties of extreme point solutions, we show that our algorithm always\nreturns (in polynomial time) a better than $2$-approximation when compared to\nthe cut LP. We thereby also obtain an improved upper bound on the integrality\ngap of this natural relaxation.",
    "descriptor": "\nComments: To appear in IPCO 2022\n",
    "authors": [
      "Etienne Bamas",
      "Marina Drygala",
      "Ola Svensson"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Combinatorics (math.CO)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.07283"
  },
  {
    "id": "arXiv:2202.07284",
    "title": "Efficient Post-Processors for Improving Error-Correcting Performance of  LDPC Codes",
    "abstract": "The error floor phenomenon, associated with iterative decoders, is one of the\nmost significant limitations to the applications of low-density parity-check\n(LDPC) codes. A variety of techniques from code design to decoder\nimplementation have been proposed to address the error floor problem, among\nwhich post-processors have shown to be both effective and\nimplementation-friendly. In this work, we take the inspiration from simulated\nannealing to generalize the post-processor design using three methods:\nquenching, extended heating, and focused heating, each of which targets a\ndifferent error structure. The resulting post-processor is demonstrated to\nlower the error floors by two orders of magnitude for two structured code\nexamples, a (2209, 1978) array LDPC code, and a (1944, 1620) LDPC code used by\nthe IEEE 802.11n standard. The post-processor can be integrated to a\nbelief-propagation decoder with minimal overhead. The post-processor design is\nequally applicable to other structured LDPC codes.",
    "descriptor": "\nComments: Published in TCAS-I 2018\n",
    "authors": [
      "Yaoyu Tao",
      "Shuanghong Sun",
      "Zhengya Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2202.07284"
  },
  {
    "id": "arXiv:2202.07285",
    "title": "Disentangling Domain and Content",
    "abstract": "Many real-world datasets can be divided into groups according to certain\nsalient features (e.g. grouping images by subject, grouping text by font,\netc.). Often, machine learning tasks require that these features be represented\nseparately from those manifesting independently of the grouping. For example,\nimage translation entails changing the style of an image while preserving its\ncontent. We formalize these two kinds of attributes as two complementary\ngenerative factors called \"domain\" and \"content\", and address the problem of\ndisentangling them in a fully unsupervised way. To achieve this, we propose a\nprincipled, generalizable probabilistic model inspired by the Variational\nAutoencoder. Our model exhibits state-of-the-art performance on the composite\ntask of generating images by combining the domain of one input with the content\nof another. Distinctively, it can perform this task in a few-shot, unsupervised\nmanner, without being provided with explicit labelling for either domain or\ncontent. The disentangled representations are learned through the combination\nof a group-wise encoder and a novel domain-confusion loss.",
    "descriptor": "",
    "authors": [
      "Dan Andrei Iliescu",
      "Aliaksei Mikhailiuk",
      "Damon Wischik",
      "Rafal Mantiuk"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2202.07285"
  },
  {
    "id": "arXiv:2202.07291",
    "title": "Beyond Natural Motion: Exploring Discontinuity for Video Frame  Interpolation",
    "abstract": "Video interpolation is the task that synthesizes the intermediate frame given\ntwo consecutive frames. Most of the previous studies have focused on\nappropriate frame warping operations and refinement modules for the warped\nframes. These studies have been conducted on natural videos having only\ncontinuous motions. However, many practical videos contain a lot of\ndiscontinuous motions, such as chat windows, watermarks, GUI elements, or\nsubtitles. We propose three techniques to expand the concept of transition\nbetween two consecutive frames to address these issues. First is a new\narchitecture that can separate continuous and discontinuous motion areas. We\nalso propose a novel data augmentation strategy called figure-text mixing (FTM)\nto make our model learn more general scenarios. Finally, we propose loss\nfunctions to give supervisions of the discontinuous motion areas with the data\naugmentation. We collected a special dataset consisting of some mobile games\nand chatting videos. We show that our method significantly improves the\ninterpolation qualities of the videos on the special dataset. Moreover, our\nmodel outperforms the state-of-the-art methods for natural video datasets\ncontaining only continuous motions, such as DAVIS and UCF101.",
    "descriptor": "\nComments: CVPR2022 appear\n",
    "authors": [
      "Sangjin Lee",
      "Hyeongmin Lee",
      "Chajin Shin",
      "Hanbin Son",
      "Sangyoun Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07291"
  },
  {
    "id": "arXiv:2202.07292",
    "title": "Contextual Importance and Utility: aTheoretical Foundation",
    "abstract": "This paper provides new theory to support to the eXplainable AI (XAI) method\nContextual Importance and Utility (CIU). CIU arithmetic is based on the\nconcepts of Multi-Attribute Utility Theory, which gives CIU a solid theoretical\nfoundation. The novel concept of contextual influence is also defined, which\nmakes it possible to compare CIU directly with so-called additive feature\nattribution (AFA) methods for model-agnostic outcome explanation. One key\ntakeaway is that the \"influence\" concept used by AFA methods is inadequate for\noutcome explanation purposes even for simple models to explain. Experiments\nwith simple models show that explanations using contextual importance (CI) and\ncontextual utility (CU) produce explanations where influence-based methods\nfail. It is also shown that CI and CU guarantees explanation faithfulness\ntowards the explained model.",
    "descriptor": "\nComments: In Proceedings of the 34th Australasian Joint Conference on Artificial Intelligence, 2-4 February 2022, Sydney\n",
    "authors": [
      "Kary Fr\u00e4mling"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07292"
  },
  {
    "id": "arXiv:2202.07295",
    "title": "An Automated FPGA-based Framework for Rapid Prototyping of Nonbinary  LDPC Codes",
    "abstract": "Nonbinary LDPC codes have shown superior performance close to the Shannon\nlimit. Compared to binary LDPC codes of similar lengths, they can reach orders\nof magnitudes lower error rate. However, multitude of design freedoms of\nnonbinary LDPC codes complicates the practical code and decoder design process.\nFast simulations are critically important to evaluate the pros and cons. Rapid\nprototyping on FPGA is attractive but takes significant design efforts due to\nits high design complexity. We propose a high-throughput reconfigurable\nhardware emulation architecture with decoder and peripheral co-design. The\narchitecture enables a library and script-based framework that automates the\nconstruction of FPGA emulations. Code and decoder design parameters are\nprogrammed either during run time or by script in design time. We demonstrate\nthe capability of the framework in evaluating practical code and decoder design\nby experimenting with two popular nonbinary LDPC codes, regular (2, dc) codes\nand quasi-cyclic codes: each emulation model can be auto-constructed within\nhours and the decoder delivers excellent error-correcting performance on a\nXilinx Virtex-5 FPGA with throughput of up to hundreds of Mbps.",
    "descriptor": "\nComments: Published in ISCAS 2019\n",
    "authors": [
      "Yaoyu Tao",
      "Qi Wu"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Hardware Architecture (cs.AR)"
    ],
    "url": "https://arxiv.org/abs/2202.07295"
  },
  {
    "id": "arXiv:2202.07296",
    "title": "Roomsemble: Progressive web application for intuitive property search",
    "abstract": "A successful real estate search process involves locating a property that\nmeets a user's search criteria subject to an allocated budget and time\nconstraints. Many studies have investigated modeling housing prices over time.\nHowever, little is known about how a user's tastes influence their real estate\nsearch and purchase decisions. It is unknown what house a user would choose\ntaking into account an individual's personal tastes, behaviors, and\nconstraints, and, therefore, creating an algorithm that finds the perfect\nmatch. In this paper, we investigate the first step in understanding a user's\ntastes by building a system to capture personal preferences. We concentrated\nour research on real estate photos, being inspired by house aesthetics, which\noften motivates prospective buyers into considering a property as a candidate\nfor purchase. We designed a system that takes a user-provided photo\nrepresenting that person's personal taste and recommends properties similar to\nthe photo available on the market. The user can additionally filter the\nrecommendations by budget and location when conducting a property search. The\npaper describes the application's overall layout including frontend design and\nbackend processes for locating a desired property. The proposed model, which\nserves as the application's core, was tested with 25 users, and the study's\nfindings, as well as some key conclusions, are detailed in this paper.",
    "descriptor": "",
    "authors": [
      "Chris Kottmyer",
      "Kevin Zhao",
      "Zona Kostic",
      "Aleksandar Jevremovic"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.07296"
  },
  {
    "id": "arXiv:2202.07301",
    "title": "User-Oriented Robust Reinforcement Learning",
    "abstract": "Recently, improving the robustness of policies across different environments\nattracts increasing attention in the reinforcement learning (RL) community.\nExisting robust RL methods mostly aim to achieve the max-min robustness by\noptimizing the policy's performance in the worst-case environment. However, in\npractice, a user that uses an RL policy may have different preferences over its\nperformance across environments. Clearly, the aforementioned max-min robustness\nis oftentimes too conservative to satisfy user preference. Therefore, in this\npaper, we integrate user preference into policy learning in robust RL, and\npropose a novel User-Oriented Robust RL (UOR-RL) framework. Specifically, we\ndefine a new User-Oriented Robustness (UOR) metric for RL, which allocates\ndifferent weights to the environments according to user preference and\ngeneralizes the max-min robustness metric. To optimize the UOR metric, we\ndevelop two different UOR-RL training algorithms for the scenarios with or\nwithout a priori known environment distribution, respectively. Theoretically,\nwe prove that our UOR-RL training algorithms converge to near-optimal policies\neven with inaccurate or completely no knowledge about the environment\ndistribution. Furthermore, we carry out extensive experimental evaluations in 4\nMuJoCo tasks. The experimental results demonstrate that UOR-RL is comparable to\nthe state-of-the-art baselines under the average and worst-case performance\nmetrics, and more importantly establishes new state-of-the-art performance\nunder the UOR metric.",
    "descriptor": "",
    "authors": [
      "Haoyi You",
      "Beichen Yu",
      "Haiming Jin",
      "Zhaoxing Yang",
      "Jiahui Sun",
      "Xinbing Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07301"
  },
  {
    "id": "arXiv:2202.07304",
    "title": "XAI for Transformers: Better Explanations through Conservative  Propagation",
    "abstract": "Transformers have become an important workhorse of machine learning, with\nnumerous applications. This necessitates the development of reliable methods\nfor increasing their transparency. Multiple interpretability methods, often\nbased on gradient information, have been proposed. We show that the gradient in\na Transformer reflects the function only locally, and thus fails to reliably\nidentify the contribution of input features to the prediction. We identify\nAttention Heads and LayerNorm as main reasons for such unreliable explanations\nand propose a more stable way for propagation through these layers. Our\nproposal, which can be seen as a proper extension of the well-established LRP\nmethod to Transformers, is shown both theoretically and empirically to overcome\nthe deficiency of a simple gradient-based approach, and achieves\nstate-of-the-art explanation performance on a broad range of Transformer models\nand datasets.",
    "descriptor": "",
    "authors": [
      "Ameen Ali",
      "Thomas Schnake",
      "Oliver Eberle",
      "Gr\u00e9goire Montavon",
      "Klaus-Robert M\u00fcller",
      "Lior Wolf"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07304"
  },
  {
    "id": "arXiv:2202.07305",
    "title": "ViNTER: Image Narrative Generation with Emotion-Arc-Aware Transformer",
    "abstract": "Image narrative generation describes the creation of stories regarding the\ncontent of image data from a subjective viewpoint. Given the importance of the\nsubjective feelings of writers, characters, and readers in storytelling, image\nnarrative generation methods must consider human emotion, which is their major\ndifference from descriptive caption generation tasks. The development of\nautomated methods to generate story-like text associated with images may be\nconsidered to be of considerable social significance, because stories serve\nessential functions both as entertainment and also for many practical purposes\nsuch as education and advertising. In this study, we propose a model called\nViNTER (Visual Narrative Transformer with Emotion arc Representation) to\ngenerate image narratives that focus on time series representing varying\nemotions as \"emotion arcs,\" to take advantage of recent advances in multimodal\nTransformer-based pre-trained models. We present experimental results of both\nmanual and automatic evaluations, which demonstrate the effectiveness of the\nproposed emotion-aware approach to image narrative generation.",
    "descriptor": "",
    "authors": [
      "Kohei Uehara",
      "Yusuke Mori",
      "Yusuke Mukuta",
      "Tatsuya Harada"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07305"
  },
  {
    "id": "arXiv:2202.07308",
    "title": "HAA4D: Few-Shot Human Atomic Action Recognition via 3D Spatio-Temporal  Skeletal Alignment",
    "abstract": "Human actions involve complex pose variations and their 2D projections can be\nhighly ambiguous. Thus 3D spatio-temporal or 4D (i.e., 3D+T) human skeletons,\nwhich are photometric and viewpoint invariant, are an excellent alternative to\n2D+T skeletons/pixels to improve action recognition accuracy. This paper\nproposes a new 4D dataset HAA4D which consists of more than 3,300 RGB videos in\n300 human atomic action classes. HAA4D is clean, diverse, class-balanced where\neach class is viewpoint-balanced with the use of 4D skeletons, in which as few\nas one 4D skeleton per class is sufficient for training a deep recognition\nmodel. Further, the choice of atomic actions makes annotation even easier,\nbecause each video clip lasts for only a few seconds. All training and testing\n3D skeletons in HAA4D are globally aligned, using a deep alignment model to the\nsame global space, making each skeleton face the negative z-direction. Such\nalignment makes matching skeletons more stable by reducing intraclass\nvariations and thus with fewer training samples per class needed for action\nrecognition. Given the high diversity and skeletal alignment in HAA4D, we\nconstruct the first baseline few-shot 4D human atomic action recognition\nnetwork without bells and whistles, which produces comparable or higher\nperformance than relevant state-of-the-art techniques relying on embedded space\nencoding without explicit skeletal alignment, using the same small number of\ntraining samples of unseen classes.",
    "descriptor": "",
    "authors": [
      "Mu-Ruei Tseng",
      "Abhishek Gupta",
      "Chi-Keung Tang",
      "Yu-Wing Tai"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07308"
  },
  {
    "id": "arXiv:2202.07315",
    "title": "Using Social Media Images for Building Function Classification",
    "abstract": "Urban land use on a building instance level is crucial geo-information for\nmany applications, yet difficult to obtain. An intuitive approach to close this\ngap is predicting building functions from ground level imagery. Social media\nimage platforms contain billions of images, with a large variety of motifs\nincluding but not limited to street perspectives. To cope with this issue this\nstudy proposes a filtering pipeline to yield high quality, ground level imagery\nfrom large social media image datasets. The pipeline ensures that all resulting\nimages have full and valid geotags with a compass direction to relate image\ncontent and spatial objects from maps.\nWe analyze our method on a culturally diverse social media dataset from\nFlickr with more than 28 million images from 42 cities around the world. The\nobtained dataset is then evaluated in a context of 3-classes building function\nclassification task. The three building classes that are considered in this\nstudy are: commercial, residential, and other. Fine-tuned state-of-the-art\narchitectures yield F1-scores of up to 0.51 on the filtered images. Our\nanalysis shows that the performance is highly limited by the quality of the\nlabels obtained from OpenStreetMap, as the metrics increase by 0.2 if only\nhuman validated labels are considered. Therefore, we consider these labels to\nbe weak and publish the resulting images from our pipeline together with the\nbuildings they are showing as a weakly labeled dataset.",
    "descriptor": "",
    "authors": [
      "Eike Jens Hoffmann",
      "Karam Abdulahhad",
      "Xiao Xiang Zhu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07315"
  },
  {
    "id": "arXiv:2202.07318",
    "title": "An algorithmic solution to the Blotto game using multi-marginal  couplings",
    "abstract": "We describe an efficient algorithm to compute solutions for the general\ntwo-player Blotto game on n battlefields with heterogeneous values. While\nexplicit constructions for such solutions have been limited to specific,\nlargely symmetric or homogeneous, setups, this algorithmic resolution covers\nthe most general situation to date: value-asymmetric game with asymmetric\nbudget. The proposed algorithm rests on recent theoretical advances regarding\nSinkhorn iterations for matrix and tensor scaling. An important case which had\nbeen out of reach of previous attempts is that of heterogeneous but symmetric\nbattlefield values with asymmetric budget. In this case, the Blotto game is\nconstant-sum so optimal solutions exist, and our algorithm samples from an\n\\eps-optimal solution in time O(n^2 + \\eps^{-4}), independently of budgets and\nbattlefield values. In the case of asymmetric values where optimal solutions\nneed not exist but Nash equilibria do, our algorithm samples from an \\eps-Nash\nequilibrium with similar complexity but where implicit constants depend on\nvarious parameters of the game such as battlefield values.",
    "descriptor": "",
    "authors": [
      "Vianney Perchet",
      "Philippe Rigollet",
      "Thibaut Le Gouic"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07318"
  },
  {
    "id": "arXiv:2202.07327",
    "title": "Treating Interference as Noise in Cell-Free Massive MIMO Networks",
    "abstract": "How to manage the interference introduced by the enormous wireless devices is\na crucial issue to address in the prospective sixth-generation (6G)\ncommunications. The treating interference as noise (TIN) optimality conditions\nare commonly used for interference management and thus attract significant\ninterest in existing wireless systems. Cell-free massive multiple-input\nmultiple-output (CF mMIMO) is a promising technology in 6G that exhibits high\nsystem throughput and excellent interference management by exploiting a large\nnumber of access points (APs) to serve the users collaboratively. In this\npaper, we take the first step on studying TIN in CF mMIMO systems from a\nstochastic geometry perspective by investigating the probability that the TIN\nconditions hold with spatially distributed network nodes. We propose a novel\nanalytical framework for TIN in a CF mMIMO system with both Binomial Point\nProcess (BPP) and Poisson Point Process (PPP) approximations. We derive the\nprobability that the TIN conditions hold in close form using the PPP\napproximation. Numerical results validate our derived expressions and\nillustrate the impact of various system parameters on the probability that the\nTIN conditions hold.",
    "descriptor": "\nComments: This paper has been accepted to IEEE ICC 2022\n",
    "authors": [
      "Shuaifei Chen",
      "Jiayi Zhang",
      "Zheng Chen",
      "Bo Ai"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.07327"
  },
  {
    "id": "arXiv:2202.07328",
    "title": "Secure Beamforming Design for Rate-Splitting Multiple Access in  Multi-antenna Broadcast Channel with Confidential Messages",
    "abstract": "As physical layer security evolves to multi-user systems, multi-user\ninterference (MUI) becomes an unavoidable issue. Recently, rate-splitting\nmultiple access (RSMA) emerges as a powerful non-orthogonal transmission\nframework and interference management strategy with high spectral efficiency.\nUnlike most works fully treating MUI as noise, we take all users' secrecy rate\nrequirements into consideration and propose an RSMA-based secure beamforming\napproach to maximize the weighted sum-rate (WSR), where MUI is partially\ndecoded and partially treated as noise. User messages are split and encoded\ninto common and private streams. Each user not only decodes the common stream\nand the intended private stream, but also tries to eavesdrop other users'\nprivate streams. A successive convex approximation (SCA)-based approach is\nproposed to maximize the instantaneous WSR under perfect channel state\ninformation at the transmitter (CSIT). We then propose a joint weighted minimum\nmean square error and SCA-based alternating optimization algorithm to maximize\nthe weighted ergodic sum-rate under imperfect CSIT. Numerical results\ndemonstrate RSMA achieves better WSR and is more robust to channel errors than\nconventional multi-user linear precoding technique while ensuring all users'\nsecurity requirements. Besides, RSMA can satisfy all users' secrecy rate\nrequirements without introducing WSR loss thanks to its powerful interference\nmanagement capability.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2201.08472\n",
    "authors": [
      "Huiyun Xia",
      "Yijie Mao",
      "Xiaokang Zhou",
      "Bruno Clerckx",
      "Shuai Han",
      "Cheng Li"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.07328"
  },
  {
    "id": "arXiv:2202.07329",
    "title": "The directed plump ordering",
    "abstract": "Based on Taylor's hereditarily directed plump ordinals, we define the\ndirected plump ordering on W-types in Martin-L\\\"of type theory. This ordering\nis similar to the plump ordering but comes equipped with non-empty finite joins\nin addition to the usual properties of the plump ordering.",
    "descriptor": "",
    "authors": [
      "Daniel Gratzer",
      "Michael Shulman",
      "Jonathan Sterling"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.07329"
  },
  {
    "id": "arXiv:2202.07340",
    "title": "Low-rank tensor approximations for solving multi-marginal optimal  transport problems",
    "abstract": "By adding entropic regularization, multi-marginal optimal transport problems\ncan be transformed into tensor scaling problems, which can be solved\nnumerically using the multi-marginal Sinkhorn algorithm. The main computational\nbottleneck of this algorithm is the repeated evaluation of marginals. In\n[Haasler et al., IEEE Trans. Inf. Theory, 67 (2021)], it has been suggested\nthat this evaluation can be accelerated when the application features an\nunderlying graphical model. In this work, we accelerate the computation further\nby combining the tensor network dual of the graphical model with additional\nlow-rank approximations. For the color transfer of images, these added low rank\napproximations save more than 96% of the computation time.",
    "descriptor": "",
    "authors": [
      "Christoph Str\u00f6ssner",
      "Daniel Kressner"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.07340"
  },
  {
    "id": "arXiv:2202.07342",
    "title": "Unreasonable Effectiveness of Last Hidden Layer Activations",
    "abstract": "In standard Deep Neural Network (DNN) based classifiers, the general\nconvention is to omit the activation function in the last (output) layer and\ndirectly apply the softmax function on the logits to get the probability scores\nof each class. In this type of architectures, the loss value of the classifier\nagainst any output class is directly proportional to the difference between the\nfinal probability score and the label value of the associated class. Standard\nWhite-box adversarial evasion attacks, whether targeted or untargeted, mainly\ntry to exploit the gradient of the model loss function to craft adversarial\nsamples and fool the model. In this study, we show both mathematically and\nexperimentally that using some widely known activation functions in the output\nlayer of the model with high temperature values has the effect of zeroing out\nthe gradients for both targeted and untargeted attack cases, preventing\nattackers from exploiting the model's loss function to craft adversarial\nsamples. We've experimentally verified the efficacy of our approach on MNIST\n(Digit), CIFAR10 datasets. Detailed experiments confirmed that our approach\nsubstantially improves robustness against gradient-based targeted and\nuntargeted attack threats. And, we showed that the increased non-linearity at\nthe output layer has some additional benefits against some other attack methods\nlike Deepfool attack.",
    "descriptor": "\nComments: 22 pages, Under review\n",
    "authors": [
      "Omer Faruk Tuna",
      "Ferhat Ozgur Catak",
      "M. Taner Eskil"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07342"
  },
  {
    "id": "arXiv:2202.07349",
    "title": "IF-City: Intelligible Fair City Planning to Measure, Explain and  Mitigate Inequality",
    "abstract": "With the increasing pervasiveness of Artificial Intelligence (AI), many\nvisual analytics tools have been proposed to examine fairness, but they mostly\nfocus on data scientist users. Instead, tackling fairness must be inclusive and\ninvolve domain experts with specialized tools and workflows. Thus,\ndomain-specific visualizations are needed for algorithmic fairness.\nFurthermore, while much work on AI fairness has focused on predictive\ndecisions, less has been done for fair allocation and planning, which require\nhuman expertise and iterative design to integrate myriad constraints. We\npropose the Intelligible Fair Allocation (IF-Alloc) Framework that leverages\nexplanations of causal attribution (Why), contrastive (Why Not) and\ncounterfactual reasoning (What If, How To) to aid domain experts to assess and\nalleviate unfairness in allocation problems. We apply the framework to fair\nurban planning for designing cities that provide equal access to amenities and\nbenefits for diverse resident types. Specifically, we propose an interactive\nvisual tool, Intelligible Fair City Planner (IF-City), to help urban planners\nto perceive inequality across groups, identify and attribute sources of\ninequality, and mitigate inequality with automatic allocation simulations and\nconstraint-satisfying recommendations. We demonstrate and evaluate the usage\nand usefulness of IF-City on a real neighborhood in New York City, US, with\npracticing urban planners from multiple countries, and discuss generalizing our\nfindings, application, and framework to other use cases and applications of\nfair allocation.",
    "descriptor": "\nComments: 18 pages including references and bios, 11 figures, submitted to IEEE Transactions on Visualization and Computer Graphics\n",
    "authors": [
      "Yan Lyu",
      "Hangxin Lu",
      "Min Kyung Lee",
      "Gerhard Schmitt",
      "Brian Y. Lim"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.07349"
  },
  {
    "id": "arXiv:2202.07350",
    "title": "Generalisation and the Risk--Entropy Curve",
    "abstract": "In this paper we show that the expected generalisation performance of a\nlearning machine is determined by the distribution of risks or equivalently its\nlogarithm -- a quantity we term the risk entropy -- and the fluctuations in a\nquantity we call the training ratio. We show that the risk entropy can be\nempirically inferred for deep neural network models using Markov Chain Monte\nCarlo techniques. Results are presented for different deep neural networks on a\nvariety of problems. The asymptotic behaviour of the risk entropy acts in an\nanalogous way to the capacity of the learning machine, but the generalisation\nperformance experienced in practical situations is determined by the behaviour\nof the risk entropy before the asymptotic regime is reached. This performance\nis strongly dependent on the distribution of the data (features and targets)\nand not just on the capacity of the learning machine.",
    "descriptor": "",
    "authors": [
      "Dominic Belcher",
      "Antonia Marcu",
      "Adam Pr\u00fcgel-Bennett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07350"
  },
  {
    "id": "arXiv:2202.07358",
    "title": "A Unified Framework for Masked and Mask-Free Face Recognition via  Feature Rectification",
    "abstract": "Face recognition under ideal conditions is now considered a well-solved\nproblem with advances in deep learning. Recognizing faces under occlusion,\nhowever, still remains a challenge. Existing techniques often fail to recognize\nfaces with both the mouth and nose covered by a mask, which is now very common\nunder the COVID-19 pandemic. Common approaches to tackle this problem include\n1) discarding information from the masked regions during recognition and 2)\nrestoring the masked regions before recognition. Very few works considered the\nconsistency between features extracted from masked faces and from their\nmask-free counterparts. This resulted in models trained for recognizing masked\nfaces often showing degraded performance on mask-free faces. In this paper, we\npropose a unified framework, named Face Feature Rectification Network\n(FFR-Net), for recognizing both masked and mask-free faces alike. We introduce\nrectification blocks to rectify features extracted by a state-of-the-art\nrecognition model, in both spatial and channel dimensions, to minimize the\ndistance between a masked face and its mask-free counterpart in the rectified\nfeature space. Experiments show that our unified framework can learn a\nrectified feature space for recognizing both masked and mask-free faces\neffectively, achieving state-of-the-art results. Project code:\nhttps://github.com/haoosz/FFR-Net",
    "descriptor": "\nComments: 5 pages, 4 figures, conference\n",
    "authors": [
      "Shaozhe Hao",
      "Chaofeng Chen",
      "Zhenfang Chen",
      "Kwan-Yee K. Wong"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.07358"
  },
  {
    "id": "arXiv:2202.07359",
    "title": "textless-lib: a Library for Textless Spoken Language Processing",
    "abstract": "Textless spoken language processing research aims to extend the applicability\nof standard NLP toolset onto spoken language and languages with few or no\ntextual resources. In this paper, we introduce textless-lib, a PyTorch-based\nlibrary aimed to facilitate research in this research area. We describe the\nbuilding blocks that the library provides and demonstrate its usability by\ndiscuss three different use-case examples: (i) speaker probing, (ii) speech\nresynthesis and compression, and (iii) speech continuation. We believe that\ntextless-lib substantially simplifies research the textless setting and will be\nhandful not only for speech researchers but also for the NLP community at\nlarge. The code, documentation, and pre-trained models are available at\nhttps://github.com/facebookresearch/textlesslib/ .",
    "descriptor": "\nComments: The library is available here this https URL\n",
    "authors": [
      "Eugene Kharitonov",
      "Jade Copet",
      "Kushal Lakhotia",
      "Tu Anh Nguyen",
      "Paden Tomasello",
      "Ann Lee",
      "Ali Elkahky",
      "Wei-Ning Hsu",
      "Abdelrahman Mohamed",
      "Emmanuel Dupoux",
      "Yossi Adi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.07359"
  },
  {
    "id": "arXiv:2202.07360",
    "title": "Multimodal Driver Referencing: A Comparison of Pointing to Objects  Inside and Outside the Vehicle",
    "abstract": "Advanced in-cabin sensing technologies, especially vision based approaches,\nhave tremendously progressed user interaction inside the vehicle, paving the\nway for new applications of natural user interaction. Just as humans use\nmultiple modes to communicate with each other, we follow an approach which is\ncharacterized by simultaneously using multiple modalities to achieve natural\nhuman-machine interaction for a specific task: pointing to or glancing towards\nobjects inside as well as outside the vehicle for deictic references. By\ntracking the movements of eye-gaze, head and finger, we design a multimodal\nfusion architecture using a deep neural network to precisely identify the\ndriver's referencing intent. Additionally, we use a speech command as a trigger\nto separate each referencing event. We observe differences in driver behavior\nin the two pointing use cases (i.e. for inside and outside objects), especially\nwhen analyzing the preciseness of the three modalities eye, head, and finger.\nWe conclude that there is no single modality that is solely optimal for all\ncases as each modality reveals certain limitations. Fusion of multiple\nmodalities exploits the relevant characteristics of each modality, hence\novercoming the case dependent limitations of each individual modality.\nUltimately, we propose a method to identity whether the driver's referenced\nobject lies inside or outside the vehicle, based on the predicted pointing\ndirection.",
    "descriptor": "",
    "authors": [
      "Abdul Rafey Aftab",
      "Michael von der Beeck"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07360"
  },
  {
    "id": "arXiv:2202.07361",
    "title": "Deep Learning-based Anomaly Detection on X-ray Images of Fuel Cell  Electrodes",
    "abstract": "Anomaly detection in X-ray images has been an active and lasting research\narea in the last decades, especially in the domain of medical X-ray images. For\nthis work, we created a real-world labeled anomaly dataset, consisting of\n16-bit X-ray image data of fuel cell electrodes coated with a platinum catalyst\nsolution and perform anomaly detection on the dataset using a deep learning\napproach. The dataset contains a diverse set of anomalies with 11 identified\ncommon anomalies where the electrodes contain e.g. scratches, bubbles, smudges\netc. We experiment with 16-bit image to 8-bit image conversion methods to\nutilize pre-trained Convolutional Neural Networks as feature extractors\n(transfer learning) and find that we achieve the best performance by maximizing\nthe contrasts globally across the dataset during the 16-bit to 8-bit\nconversion, through histogram equalization. We group the fuel cell electrodes\nwith anomalies into a single class called abnormal and the normal fuel cell\nelectrodes into a class called normal, thereby abstracting the anomaly\ndetection problem into a binary classification problem. We achieve a balanced\naccuracy of 85.18\\%. The anomaly detection is used by the company, Serenergy,\nfor optimizing the time spend on the quality control of the fuel cell\nelectrodes",
    "descriptor": "\nComments: 10 pages, 9 figures, VISAPP2022\n",
    "authors": [
      "Simon B. Jensen",
      "Thomas B. Moeslund",
      "S\u00f8ren J. Andreasen"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.07361"
  },
  {
    "id": "arXiv:2202.07362",
    "title": "MuLD: The Multitask Long Document Benchmark",
    "abstract": "The impressive progress in NLP techniques has been driven by the development\nof multi-task benchmarks such as GLUE and SuperGLUE. While these benchmarks\nfocus on tasks for one or two input sentences, there has been exciting work in\ndesigning efficient techniques for processing much longer inputs. In this\npaper, we present MuLD: a new long document benchmark consisting of only\ndocuments over 10,000 tokens. By modifying existing NLP tasks, we create a\ndiverse benchmark which requires models to successfully model long-term\ndependencies in the text. We evaluate how existing models perform, and find\nthat our benchmark is much more challenging than their `short document'\nequivalents. Furthermore, by evaluating both regular and efficient\ntransformers, we show that models with increased context length are better able\nto solve the tasks presented, suggesting that future improvements in these\nmodels are vital for solving similar long document problems. We release the\ndata and code for baselines to encourage further research on efficient NLP\nmodels.",
    "descriptor": "",
    "authors": [
      "G Thomas Hudson",
      "Noura Al Moubayed"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07362"
  },
  {
    "id": "arXiv:2202.07364",
    "title": "Zero-Shot Assistance in Novel Decision Problems",
    "abstract": "We consider the problem of creating assistants that can help agents - often\nhumans - solve novel sequential decision problems, assuming the agent is not\nable to specify the reward function explicitly to the assistant. Instead of\naiming to automate, and act in place of the agent as in current approaches, we\ngive the assistant an advisory role and keep the agent in the loop as the main\ndecision maker. The difficulty is that we must account for potential biases\ninduced by limitations or constraints of the agent which may cause it to\nseemingly irrationally reject advice. To do this we introduce a novel\nformalization of assistance that models these biases, allowing the assistant to\ninfer and adapt to them. We then introduce a new method for planning the\nassistant's advice which can scale to large decision making problems. Finally,\nwe show experimentally that our approach adapts to these agent biases, and\nresults in higher cumulative reward for the agent than automation-based\nalternatives.",
    "descriptor": "\nComments: 14 pages, 9 figures\n",
    "authors": [
      "Sebastiaan De Peuter",
      "Samuel Kaski"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Multiagent Systems (cs.MA)"
    ],
    "url": "https://arxiv.org/abs/2202.07364"
  },
  {
    "id": "arXiv:2202.07371",
    "title": "Personalized Prompt Learning for Explainable Recommendation",
    "abstract": "Providing user-understandable explanations to justify recommendations could\nhelp users better understand the recommended items, increase the system's ease\nof use, and gain users' trust. A typical approach to realize it is natural\nlanguage generation. However, previous works mostly adopt recurrent neural\nnetworks to meet the ends, leaving the potentially more effective pre-trained\nTransformer models under-explored. In fact, user and item IDs, as important\nidentifiers in recommender systems, are inherently in different semantic space\nas words that pre-trained models were already trained on. Thus, how to\neffectively fuse IDs into such models becomes a critical issue. Inspired by\nrecent advancement in prompt learning, we come up with two solutions: find\nalternative words to represent IDs (called discrete prompt learning), and\ndirectly input ID vectors to a pre-trained model (termed continuous prompt\nlearning). In the latter case, ID vectors are randomly initialized but the\nmodel is trained in advance on large corpora, so they are actually in different\nlearning stages. To bridge the gap, we further propose two training strategies:\nsequential tuning and recommendation as regularization. Extensive experiments\nshow that our continuous prompt learning approach equipped with the training\nstrategies consistently outperforms strong baselines on three datasets of\nexplainable recommendation.",
    "descriptor": "",
    "authors": [
      "Lei Li",
      "Yongfeng Zhang",
      "Li Chen"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07371"
  },
  {
    "id": "arXiv:2202.07376",
    "title": "Deep-QPP: A Pairwise Interaction-based Deep Learning Model for  Supervised Query Performance Prediction",
    "abstract": "Motivated by the recent success of end-to-end deep neural models for ranking\ntasks, we present here a supervised end-to-end neural approach for query\nperformance prediction (QPP). In contrast to unsupervised approaches that rely\non various statistics of document score distributions, our approach is entirely\ndata-driven. Further, in contrast to weakly supervised approaches, our method\nalso does not rely on the outputs from different QPP estimators. In particular,\nour model leverages information from the semantic interactions between the\nterms of a query and those in the top-documents retrieved with it. The\narchitecture of the model comprises multiple layers of 2D convolution filters\nfollowed by a feed-forward layer of parameters. Experiments on standard test\ncollections demonstrate that our proposed supervised approach outperforms other\nstate-of-the-art supervised and unsupervised approaches.",
    "descriptor": "",
    "authors": [
      "Suchana Datta",
      "Debasis Ganguly",
      "Derek Greene",
      "Mandar Mitra"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.07376"
  },
  {
    "id": "arXiv:2202.07377",
    "title": "The aperiodic Domino problem in higher dimension",
    "abstract": "The classical Domino problem asks whether there exists a tiling in which none\nof the forbidden patterns given as input appear. In this paper, we consider the\naperiodic version of the Domino problem: given as input a family of forbidden\npatterns, does it allow an aperiodic tiling? The input may correspond to a\nsubshift of finite type, a sofic subshift or an effective subshift.\narXiv:1805.08829 proved that this problem is co-recursively enumerable\n($\\Pi_0^1$-complete) in dimension 2 for geometrical reasons. We show that it is\nmuch harder, namely analytic ($\\Sigma_1^1$-complete), in higher dimension: $d\n\\geq 4$ in the finite type case, $d \\geq 3$ for sofic and effective subshifts.\nThe reduction uses a subshift embedding universal computation and two\nadditional dimensions to control periodicity. This complexity jump is\nsurprising for two reasons: first, it separates 2- and 3-dimensional subshifts,\nwhereas most subshift properties are the same in dimension 2 and higher;\nsecond, it is unexpectedly large.",
    "descriptor": "\nComments: 15 pages, accepted to STACS 2022\n",
    "authors": [
      "Antonin Callard",
      "Benjamin Hellouin de Menibus"
    ],
    "subjectives": [
      "Discrete Mathematics (cs.DM)",
      "Computational Complexity (cs.CC)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.07377"
  },
  {
    "id": "arXiv:2202.07380",
    "title": "GuaranTEE: Introducing Control-Flow Attestation for Trusted Execution  Environments",
    "abstract": "The majority of cloud providers offers users the possibility to deploy\nTrusted Execution Environments (TEEs) in order to protect their data and\nprocesses from high privileged adversaries. This offer is intended to address\nconcerns of users when moving critical tasks into the cloud. However, TEEs only\nallow to attest the integrity of the environment at launch-time. To also enable\nthe attestation of a TEE's integrity at run-time, we present GuaranTEE.\nGuaranTEE uses control-flow attestation to ensure the integrity of a service\nrunning within a TEE. By additionally placing all components of GuaranTEE in\nTEEs, we are able to not only detect a compromised target, but are also able to\nprotect ourselves from malicious administrators. We show the practicability of\nGuaranTEE by providing a detailed performance and security evaluation of our\nprototype based on Intel SGX in Microsoft Azure. Our evaluation shows that the\nneed to transfer information between TEEs and the additional verification\nprocess add considerable overhead. Yet, we are able to reduce this overhead by\nsecurely caching collected information and by performing the analysis in\nparallel to executing the application. In summary, our results show that\nGuaranTEE is able to provide a practical solution for cloud users focused on\nprotecting the integrity of their data and processes at run-time.",
    "descriptor": "",
    "authors": [
      "Mathias Morbitzer",
      "Benedikt Kopf",
      "Philipp Zieris"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.07380"
  },
  {
    "id": "arXiv:2202.07381",
    "title": "Monolithic multigrid for implicit Runge-Kutta discretizations of  incompressible fluid flow",
    "abstract": "Most research on preconditioners for time-dependent PDEs has focused on\nimplicit multi-step or diagonally-implicit multi-stage temporal\ndiscretizations. In this paper, we consider monolithic multigrid\npreconditioners for fully-implicit multi-stage Runge-Kutta (RK) time\nintegration methods. These temporal discretizations have very attractive\naccuracy and stability properties, but they couple the spatial degrees of\nfreedom across multiple time levels, requiring the solution of very large\nlinear systems. We extend the classical Vanka relaxation scheme to implicit RK\ndiscretizations of saddle point problems. We present numerical results for the\nincompressible Stokes, Navier-Stokes, and resistive magnetohydrodynamics\nequations, in two and three dimensions, confirming that these relaxation\nschemes lead to robust and scalable monolithic multigrid methods for a\nchallenging range of incompressible fluid-flow models.",
    "descriptor": "\nComments: 22 pages, 9 figures. Submitted to Journal of Computational Physics on Feb 14 2022\n",
    "authors": [
      "Razan Abu-Labdeh",
      "Scott MacLachlan",
      "Patrick E. Farrell"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.07381"
  },
  {
    "id": "arXiv:2202.07382",
    "title": "Phase Vocoder Done Right",
    "abstract": "The phase vocoder (PV) is a widely spread technique for processing audio\nsignals. It employs a short-time Fourier transform (STFT)\nanalysis-modify-synthesis loop and is typically used for time-scaling of\nsignals by means of using different time steps for STFT analysis and synthesis.\nThe main challenge of PV used for that purpose is the correction of the STFT\nphase. In this paper, we introduce a novel method for phase correction based on\nphase gradient estimation and its integration. The method does not require\nexplicit peak picking and tracking nor does it require detection of transients\nand their separate treatment. Yet, the method does not suffer from the typical\nphase vocoder artifacts even for extreme time stretching factors.",
    "descriptor": "",
    "authors": [
      "Zdenek Prusa",
      "Nicki Holighaus"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Mathematical Software (cs.MS)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.07382"
  },
  {
    "id": "arXiv:2202.07390",
    "title": "Practical Testing of a C99 Compiler Using Output Comparison",
    "abstract": "A simple technique is presented for testing a C99 compiler, by comparison of\nits output with output from preexisting tools. The advantage to this approach\nis that new test cases can be added in bulk from existing sources, reducing the\nneed for in-depth investigation of correctness issues, and for creating new\ntest code by hand. This technique was used in testing the PalmSource Palm OS\nCobalt ARM C/C++ cross-compiler for Palm-Powered personal digital assistants,\nprimarily for standards-compliance and correct execution of generated code. The\ntechnique described here found several hundred bugs, mostly in our in-house\ncode, but also in longstanding high-quality front- and back-end code from\nEdison Design Group and Apogee Software. It also found eighteen bugs in the GNU\nC compiler, as well as a bug specific to the Apple version of GCC, a bug\nspecific to the Suse version of GCC, and a dozen bugs in versions of GCC for\nthe ARM processor, several of them critical.",
    "descriptor": "\nComments: Preprint with bibliography in alphabetical order\n",
    "authors": [
      "Flash Sheridan"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.07390"
  },
  {
    "id": "arXiv:2202.07391",
    "title": "Exploring Deep Reinforcement Learning-Assisted Federated Learning for  Online Resource Allocation in EdgeIoT",
    "abstract": "Federated learning (FL) has been increasingly considered to preserve data\ntraining privacy from eavesdropping attacks in mobile edge computing-based\nInternet of Thing (EdgeIoT). On the one hand, the learning accuracy of FL can\nbe improved by selecting the IoT devices with large datasets for training,\nwhich gives rise to a higher energy consumption. On the other hand, the energy\nconsumption can be reduced by selecting the IoT devices with small datasets for\nFL, resulting in a falling learning accuracy. In this paper, we formulate a new\nresource allocation problem for EdgeIoT to balance the learning accuracy of FL\nand the energy consumption of the IoT device. We propose a new federated\nlearning-enabled twin-delayed deep deterministic policy gradient (FLDLT3)\nframework to achieve the optimal accuracy and energy balance in a continuous\ndomain. Furthermore, long short term memory (LSTM) is leveraged in FL-DLT3 to\npredict the time-varying network state while FL-DLT3 is trained to select the\nIoT devices and allocate the transmit power. Numerical results demonstrate that\nthe proposed FL-DLT3 achieves fast convergence (less than 100 iterations) while\nthe FL accuracy-to-energy consumption ratio is improved by 51.8% compared to\nexisting state-of-the-art benchmark.",
    "descriptor": "",
    "authors": [
      "Jingjing Zheng",
      "Kai Li",
      "Naram Mhaisen",
      "Wei Ni",
      "Eduardo Tovar",
      "Mohsen Guizani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07391"
  },
  {
    "id": "arXiv:2202.07394",
    "title": "IEC61850 Sample-Value Service Based on Reduced Application Service Data  Unit for Energy IOT",
    "abstract": "With the development of 5G technology and low-power wireless communication\ntechnology, a large number of IOT devices are introduced into energy systems.\nExisting IOT communication protocols such as MQQT and COAP cannot meet the\nrequirements of high reliability and real-time performance. However, the\n61850-9-2 Sample value protocol is relatively complex and the message length is\nlarge, difficult to ensure real-time transmission for IOT devices with limited\ntransmission rate. This paper proposes a 9-2 Sample Value protocol for IOT\ncontroller based on Application Service Data Unit. The communication protocol\nis strictly in accordance with IEC61850-9-2 and can be recognized by existing\nintelligent electronic devices such as merging units. The protocol simplifies\nand trims some parameters, and changes the floating point value to integer\ndata. Considering the instability of wireless communication, uni-cast or\nmulticast UDP/IP is utilized to send SV Payload based on the 2.4GHz WIFI. The\nmaximum transmission rate can be up to 30 Mbps. The hardware to implement\nreduced SV adopts ESP32-S, which is a dual-core MCU supporting WIFI with\nfrequency of 240MHz. Software is based on FreeRTOS, LWIP and Libiec61850. A PC\nor raspberry PI is used as the Host to receive and analyze packets, verifying\nfeasibility of reduced SV protocols.",
    "descriptor": "\nComments: 6 pages, 4 figure, conference\n",
    "authors": [
      "Wenhao Xu",
      "Nan Xie"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.07394"
  },
  {
    "id": "arXiv:2202.07398",
    "title": "A numerical energy minimisation approach for semilinear  diffusion-reaction boundary value problems based on steady state iterations",
    "abstract": "We present a novel energy-based numerical analysis of semilinear\ndiffusion-reaction boundary value problems. Based on a suitable variational\nsetting, the proposed computational scheme can be seen as an energy\nminimisation approach. More specifically, this procedure aims to generate a\nsequence of numerical approximations, which results from the iterative solution\nof related (stabilised) linearised discrete problems, and tends to a local\nminimum of the underlying energy functional. Simultaneously, the\nfinite-dimensional approximation spaces are adaptively refined; this is\nimplemented in terms of a new mesh refinement strategy in the context of finite\nelement discretisations, which again relies on the energy structure of the\nproblem under consideration, and does not involve any a posteriori error\nindicators. In combination, the resulting adaptive algorithm consists of an\niterative linearisation procedure on a sequence of hierarchically refined\ndiscrete spaces, which we prove to converge towards a solution of the\ncontinuous problem in an appropriate sense. Numerical experiments demonstrate\nthe robustness and reliability of our approach for a series of examples.",
    "descriptor": "",
    "authors": [
      "Mario Amrein",
      "Pascal Heid",
      "Thomas P. Wihler"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.07398"
  },
  {
    "id": "arXiv:2202.07402",
    "title": "SODAR: Segmenting Objects by DynamicallyAggregating Neighboring Mask  Representations",
    "abstract": "Recent state-of-the-art one-stage instance segmentation model SOLO divides\nthe input image into a grid and directly predicts per grid cell object masks\nwith fully-convolutional networks, yielding comparably good performance as\ntraditional two-stage Mask R-CNN yet enjoying much simpler architecture and\nhigher efficiency. We observe SOLO generates similar masks for an object at\nnearby grid cells, and these neighboring predictions can complement each other\nas some may better segment certain object part, most of which are however\ndirectly discarded by non-maximum-suppression. Motivated by the observed gap,\nwe develop a novel learning-based aggregation method that improves upon SOLO by\nleveraging the rich neighboring information while maintaining the architectural\nefficiency. The resulting model is named SODAR. Unlike the original per grid\ncell object masks, SODAR is implicitly supervised to learn mask representations\nthat encode geometric structure of nearby objects and complement adjacent\nrepresentations with context. The aggregation method further includes two novel\ndesigns: 1) a mask interpolation mechanism that enables the model to generate\nmuch fewer mask representations by sharing neighboring representations among\nnearby grid cells, and thus saves computation and memory; 2) a deformable\nneighbour sampling mechanism that allows the model to adaptively adjust\nneighbor sampling locations thus gathering mask representations with more\nrelevant context and achieving higher performance. SODAR significantly improves\nthe instance segmentation performance, e.g., it outperforms a SOLO model with\nResNet-101 backbone by 2.2 AP on COCO \\texttt{test} set, with only about 3\\%\nadditional computation. We further show consistent performance gain with the\nSOLOv2 model.",
    "descriptor": "\nComments: accepted to IEEE Transactions on Image Processing (TIP)\n",
    "authors": [
      "Tao Wang",
      "Jun Hao Liew",
      "Yu Li",
      "Yunpeng Chen",
      "Jiashi Feng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07402"
  },
  {
    "id": "arXiv:2202.07409",
    "title": "A Lower Bounding Framework for Motion Planning amid Dynamic Obstacles in  2D",
    "abstract": "This work considers a Motion Planning Problem with Dynamic Obstacles (MPDO)\nin 2D that requires finding a minimum-arrival-time collision-free trajectory\nfor a point robot between its start and goal locations amid dynamic obstacles\nmoving along known trajectories. Existing methods, such as continuous Dijkstra\nparadigm, can find an optimal solution by restricting the shape of the\nobstacles or the motion of the robot, while this work makes no such\nassumptions. Other methods, such as search-based planners and sampling-based\napproaches can compute a feasible solution to this problem but do not provide\napproximation bounds. Since finding the optimum is challenging for MPDO, this\npaper develops a framework that can provide tight lower bounds to the optimum.\nThese bounds acts as proxies for the optimum which can then be use to bound the\ndeviation of a feasible solution from the optimum. To accomplish this, we\ndevelop a framework that consists of (i) a bi-level discretization approach\nthat converts the MPDO to a relaxed path planning problem, and (ii) an\nalgorithm that can solve the relaxed problem to obtain lower bounds. We also\npresent preliminary numerical results to corroborate the performance of the\nproposed framework. These results show that the bounds obtained by our approach\nfor some instances are three times larger than a naive baseline approach\nshowcasing potential advantages of the proposed approach.",
    "descriptor": "",
    "authors": [
      "Zhongqiang Ren",
      "Sivakumar Rathinam",
      "Howie Choset"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.07409"
  },
  {
    "id": "arXiv:2202.07412",
    "title": "Knowledge Graph Reasoning with Logics and Embeddings: Survey and  Perspective",
    "abstract": "Knowledge graph (KG) reasoning is becoming increasingly popular in both\nacademia and industry. Conventional KG reasoning based on symbolic logic is\ndeterministic, with reasoning results being explainable, while modern\nembedding-based reasoning can deal with uncertainty and predict plausible\nknowledge, often with high efficiency via vector computation. A promising\ndirection is to integrate both logic-based and embedding-based methods, with\nthe vision to have advantages of both. It has attracted wide research attention\nwith more and more works published in recent years. In this paper, we\ncomprehensively survey these works, focusing on how logics and embeddings are\nintegrated. We first briefly introduce preliminaries, then systematically\ncategorize and discuss works of logic and embedding-aware KG reasoning from\ndifferent perspectives, and finally conclude and discuss the challenges and\nfurther directions.",
    "descriptor": "\nComments: This is a survey of Knowledge Graph Reasoning with Logics and Embeddings. We discuss methods from diverse perspectives\n",
    "authors": [
      "Wen Zhang",
      "Jiaoyan Chen",
      "Juan Li",
      "Zezhong Xu",
      "Jeff Z. Pan",
      "Huajun Chen"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07412"
  },
  {
    "id": "arXiv:2202.07414",
    "title": "Interpretable Reinforcement Learning with Multilevel Subgoal Discovery",
    "abstract": "We propose a novel Reinforcement Learning model for discrete environments,\nwhich is inherently interpretable and supports the discovery of deep subgoal\nhierarchies. In the model, an agent learns information about environment in the\nform of probabilistic rules, while policies for (sub)goals are learned as\ncombinations thereof. No reward function is required for learning; an agent\nonly needs to be given a primary goal to achieve. Subgoals of a goal G from the\nhierarchy are computed as descriptions of states, which if previously achieved\nincrease the total efficiency of the available policies for G. These state\ndescriptions are introduced as new sensor predicates into the rule language of\nthe agent, which allows for sensing important intermediate states and for\nupdating environment rules and policies accordingly.",
    "descriptor": "",
    "authors": [
      "Alexander Demin",
      "Denis Ponomaryov"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07414"
  },
  {
    "id": "arXiv:2202.07415",
    "title": "NeuPL: Neural Population Learning",
    "abstract": "Learning in strategy games (e.g. StarCraft, poker) requires the discovery of\ndiverse policies. This is often achieved by iteratively training new policies\nagainst existing ones, growing a policy population that is robust to exploit.\nThis iterative approach suffers from two issues in real-world games: a) under\nfinite budget, approximate best-response operators at each iteration needs\ntruncating, resulting in under-trained good-responses populating the\npopulation; b) repeated learning of basic skills at each iteration is wasteful\nand becomes intractable in the presence of increasingly strong opponents. In\nthis work, we propose Neural Population Learning (NeuPL) as a solution to both\nissues. NeuPL offers convergence guarantees to a population of best-responses\nunder mild assumptions. By representing a population of policies within a\nsingle conditional model, NeuPL enables transfer learning across policies.\nEmpirically, we show the generality, improved performance and efficiency of\nNeuPL across several test domains. Most interestingly, we show that novel\nstrategies become more accessible, not less, as the neural population expands.",
    "descriptor": "",
    "authors": [
      "Siqi Liu",
      "Luke Marris",
      "Daniel Hennes",
      "Josh Merel",
      "Nicolas Heess",
      "Thore Graepel"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.07415"
  },
  {
    "id": "arXiv:2202.07416",
    "title": "The Membership Problem for Hypergeometric Sequences with Rational  Parameters",
    "abstract": "We investigate the Membership Problem for hypergeometric sequences: given a\nhypergeometric sequence $\\langle u_n \\rangle_{n=0}^\\infty$ of rational numbers\nand a target $t \\in \\mathbb{Q}$, decide whether $t$ occurs in the sequence. We\nshow decidability of this problem under the assumption that in the defining\nrecurrence $p(n)u_{n+1}=q(n)u_n$, the roots of the polynomials $p(x)$ and\n$q(x)$ are all rational numbers. Our proof relies on bounds on the density of\nprimes in arithmetic progressions. We also observe a relationship between the\ndecidability of the Membership problem (and variants) and the Rohrlich-Lang\nconjecture in transcendence theory.",
    "descriptor": "",
    "authors": [
      "Klara Nosan",
      "Amaury Pouly",
      "Mahsa Shirmohammadi",
      "James Worrell"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2202.07416"
  },
  {
    "id": "arXiv:2202.07419",
    "title": "Characterising Cybercriminals: A Review",
    "abstract": "This review provides an overview of current research on the known\ncharacteristics and motivations of offenders engaging in cyber-dependent\ncrimes. Due to the shifting dynamics of cybercriminal behaviour, and the\navailability of prior reviews in 2013, this review focuses on original research\nconducted from 2012 onwards, although some older studies that were not included\nin prior reviews are also considered. As a basis for interpretation of results,\na limited quality assessment was also carried out on included studies through\nexamination of key indicators.",
    "descriptor": "",
    "authors": [
      "Matthew Edwards",
      "Emma Williams",
      "Claudia Peersman",
      "Awais Rashid"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.07419"
  },
  {
    "id": "arXiv:2202.07421",
    "title": "Adversarial Attacks and Defense Methods for Power Quality Recognition",
    "abstract": "Vulnerability of various machine learning methods to adversarial examples has\nbeen recently explored in the literature. Power systems which use these\nvulnerable methods face a huge threat against adversarial examples. To this\nend, we first propose a signal-specific method and a universal signal-agnostic\nmethod to attack power systems using generated adversarial examples. Black-box\nattacks based on transferable characteristics and the above two methods are\nalso proposed and evaluated. We then adopt adversarial training to defend\nsystems against adversarial attacks. Experimental analyses demonstrate that our\nsignal-specific attack method provides less perturbation compared to the FGSM\n(Fast Gradient Sign Method), and our signal-agnostic attack method can generate\nperturbations fooling most natural signals with high probability. What's more,\nthe attack method based on the universal signal-agnostic algorithm has a higher\ntransfer rate of black-box attacks than the attack method based on the\nsignal-specific algorithm. In addition, the results show that the proposed\nadversarial training improves robustness of power systems to adversarial\nexamples.",
    "descriptor": "\nComments: Technical report\n",
    "authors": [
      "Jiwei Tian",
      "Buhong Wang",
      "Jing Li",
      "Zhen Wang",
      "Mete Ozay"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07421"
  },
  {
    "id": "arXiv:2202.07424",
    "title": "The potential of artificial intelligence for achieving healthy and  sustainable societies",
    "abstract": "In this chapter we extend earlier work (Vinuesa et al., Nature Communications\n11, 2020) on the potential of artificial intelligence (AI) to achieve the 17\nSustainable Development Goals (SDGs) proposed by the United Nations (UN) for\nthe 2030 Agenda. The present contribution focuses on three SDGs related to\nhealthy and sustainable societies, i.e. SDG 3 (on good health), SDG 11 (on\nsustainable cities) and SDG 13 (on climate action). This chapter extends the\nprevious study within those three goals, and goes beyond the 2030 targets.\nThese SDGs are selected because they are closely related to the coronavirus\ndisease 19 (COVID-19) pandemic, and also to crises like climate change, which\nconstitute important challenges to our society.",
    "descriptor": "",
    "authors": [
      "B. Sirmacek",
      "S. Gupta",
      "F. Mallor",
      "H. Azizpour",
      "Y. Ban",
      "H. Eivazi",
      "H. Fang",
      "F. Golzar",
      "I. Leite",
      "G. I. Melsion",
      "K. Smith",
      "F. Fuso Nerini",
      "R. Vinuesa"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.07424"
  },
  {
    "id": "arXiv:2202.07427",
    "title": "On the Complementarity of Images and Text for the Expression of Emotions  in Social Media",
    "abstract": "Authors of posts in social media communicate their emotions and what causes\nthem with text and images. While there is work on emotion and stimulus\ndetection for each modality separately, it is yet unknown if the modalities\ncontain complementary emotion information in social media. We aim at filling\nthis research gap and contribute a novel, annotated corpus of English\nmultimodal Reddit posts. On this resource, we develop models to automatically\ndetect the relation between image and text, an emotion stimulus category and\nthe emotion class. We evaluate if these tasks require both modalities and find\nfor the image-text relations, that text alone is sufficient for most categories\n(complementary, illustrative, opposing): the information in the text allows to\npredict if an image is required for emotion understanding. The emotions of\nanger and sadness are best predicted with a multimodal model, while text alone\nis sufficient for disgust, joy, and surprise. Stimuli depicted by objects,\nanimals, food, or a person are best predicted by image-only models, while\nmultimodal models are most effective on art, events, memes, places, or\nscreenshots.",
    "descriptor": "",
    "authors": [
      "Anna Khlyzova",
      "Carina Silberer",
      "Roman Klinger"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07427"
  },
  {
    "id": "arXiv:2202.07432",
    "title": "A precortical module for robust CNNs to light variations",
    "abstract": "We present a simple mathematical model for the mammalian low visual pathway,\ntaking into account its key elements: retina, lateral geniculate nucleus (LGN),\nprimary visual cortex (V1). The analogies between the cortical level of the\nvisual system and the structure of popular CNNs, used in image classification\ntasks, suggests the introduction of an additional preliminary convolutional\nmodule inspired to precortical neuronal circuits to improve robustness with\nrespect to global light intensity and contrast variations in the input images.\nWe validate our hypothesis on the popular databases MNIST, FashionMNIST and\nSVHN, obtaining significantly more robust CNNs with respect to these\nvariations, once such extra module is added.",
    "descriptor": "",
    "authors": [
      "R. Fioresi",
      "J. Petkovic"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Differential Geometry (math.DG)"
    ],
    "url": "https://arxiv.org/abs/2202.07432"
  },
  {
    "id": "arXiv:2202.07435",
    "title": "State of AI Ethics Report (Volume 6, February 2022)",
    "abstract": "This report from the Montreal AI Ethics Institute (MAIEI) covers the most\nsalient progress in research and reporting over the second half of 2021 in the\nfield of AI ethics. Particular emphasis is placed on an \"Analysis of the AI\nEcosystem\", \"Privacy\", \"Bias\", \"Social Media and Problematic Information\", \"AI\nDesign and Governance\", \"Laws and Regulations\", \"Trends\", and other areas\ncovered in the \"Outside the Boxes\" section. The two AI spotlights feature\napplication pieces on \"Constructing and Deconstructing Gender with AI-Generated\nArt\" as well as \"Will an Artificial Intellichef be Cooking Your Next Meal at a\nMichelin Star Restaurant?\". Given MAIEI's mission to democratize AI,\nsubmissions from external collaborators have featured, such as pieces on the\n\"Challenges of AI Development in Vietnam: Funding, Talent and Ethics\" and using\n\"Representation and Imagination for Preventing AI Harms\". The report is a\ncomprehensive overview of what the key issues in the field of AI ethics were in\n2021, what trends are emergent, what gaps exist, and a peek into what to expect\nfrom the field of AI ethics in 2022. It is a resource for researchers and\npractitioners alike in the field to set their research and development agendas\nto make contributions to the field of AI ethics.",
    "descriptor": "\nComments: 295 pages\n",
    "authors": [
      "Abhishek Gupta",
      "Connor Wright",
      "Marianna Bergamaschi Ganapini",
      "Masa Sweidan",
      "Renjie Butalid"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07435"
  },
  {
    "id": "arXiv:2202.07437",
    "title": "Mathematical Cookbook for Snapshot Compressive Imaging",
    "abstract": "The author intends to provide you with a beautiful, elegant, user-friendly\ncookbook for mathematics in Snapshot Compressive Imaging (SCI). Currently, the\ncookbook is composed of introduction and conventional optimization, using\nregularization-based optimization algorithms for SCI. The latest releases are\nstrongly recommended! For any other questions, suggestions, or comments, feel\nfree to email the author.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2201.06931\n",
    "authors": [
      "Yaping Zhao"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07437"
  },
  {
    "id": "arXiv:2202.07438",
    "title": "An Automated Analysis Framework for Trajectory Datasets",
    "abstract": "Trajectory datasets of road users have become more important in the last\nyears for safety validation of highly automated vehicles. Several naturalistic\ntrajectory datasets with each more than 10.000 tracks were released and others\nwill follow. Considering this amount of data, it is necessary to be able to\ncompare these datasets in-depth with ease to get an overview. By now, the\ndatasets' own provided information is mainly limited to meta-data and\nqualitative descriptions which are mostly not consistent with other datasets.\nThis is insufficient for users to differentiate the emerging datasets for\napplication-specific selection. Therefore, an automated analysis framework is\nproposed in this work. Starting with analyzing individual tracks, fourteen\nelementary characteristics, so-called detection types, are derived and used as\nthe base of this framework. To describe each traffic scenario precisely, the\ndetections are subdivided into common metrics, clustering methods and anomaly\ndetection. Those are combined using a modular approach. The detections are\ncomposed into new scores to describe three defined attributes of each track\ndata quantitatively: interaction, anomaly and relevance. These three scores are\ncalculated hierarchically for different abstract layers to provide an overview\nnot just between datasets but also for tracks, spatial regions and individual\nsituations. So, an objective comparison between datasets can be realized.\nFurthermore, it can help to get a deeper understanding of the recorded\ninfrastructure and its effect on road user behavior. To test the validity of\nthe framework, a study is conducted to compare the scores with human\nperception. Additionally, several datasets are compared.",
    "descriptor": "\nComments: 13 pages, 13 figures\n",
    "authors": [
      "Christoph Glasmacher",
      "Robert Krajewski",
      "Lutz Eckstein"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07438"
  },
  {
    "id": "arXiv:2202.07439",
    "title": "Inclusive Study Group Formation At Scale",
    "abstract": "The student peer-group is one of the most important influences on student\ndevelopment. Group work is essential for creating positive learning\nexperiences, especially in remote-learning where student interactions are more\nchallenging. While the benefits of study groups are established, students from\nunderrepresented communities often face challenges in finding social support\nfor their education when compared with those from majority groups. We present a\nsystem for flexible and inclusive study group formation that can scale to\nthousands of students.\nOur focus is on long-term study groups that persist throughout the semester\nand beyond. Students are periodically provided opportunities to obtain a new\nstudy group if they feel their current group is not a good fit. In contrast to\nprior work that generates single-use groups, our process enables continuous\nrefinement of groups for each student, which in turn informs our algorithm for\nfuture iterations.\nWe trialed our approach in a 1000+ student introductory Electrical\nEngineering and Computer Science course that was conducted entirely online\nduring the COVID-19 pandemic. We found that of all students matched to study\ngroups through our algorithm, a large majority felt comfortable asking\nquestions (78%) and sharing ideas (74%) with their group. Students from\nunderrepresented backgrounds were more likely to request software-matching for\nstudy groups when compared with students from majority groups. However,\nunderrepresented students that we did match into study groups had group\nexperiences that were just as successful as students from' majority groups.\nStudents in engaged, regularly participating study groups had more positive\nresults across all other indicators of the study group experience, and certain\npositive group experiences were associated with higher exam scores overall.",
    "descriptor": "",
    "authors": [
      "Sumer Kohli",
      "Neelesh Ramchandran",
      "Ana Tudor",
      "Gloria Tumushabe",
      "Olivia Hsu",
      "Gireeja Ranade"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.07439"
  },
  {
    "id": "arXiv:2202.07441",
    "title": "Artificial Intelligence-Based Analytics for Impacts of COVID-19 and  Online Learning on College Students' Mental Health",
    "abstract": "COVID-19, the disease caused by the novel coronavirus (SARS-CoV-2), was first\nfound in Wuhan, China late in the December of 2019. Not long after that the\nvirus spread worldwide and was declared a pandemic by the World Health\nOrganization in March 2020. This caused many changes around the world and in\nthe United States. One of these changes was the shift towards online learning.\nIn this paper, we seek to understand how the COVID-19 pandemic and online\nlearning impact college students' emotional wellbeing. To do this we use\nseveral machine learning and statistical models to analyze data collected by\nthe Faculty of Public Administration at the University of Ljubljana, Slovenia\nin conjunction with an international consortium of universities, other higher\neducation institutions and students' associations. Our results indicate that\nlearning modality (face-to-face, online synchronous, online asynchronous, etc.)\nis the main predictor of students' emotional wellbeing, followed by financial\nsecurity. Factors such as satisfaction with their university's and government's\nhandling of the pandemic are also important predictors.",
    "descriptor": "\nComments: 42 pages, 22 Figures, 3 Tables\n",
    "authors": [
      "Mostafa Rezapour",
      "Scott K. Elmshaeuser"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07441"
  },
  {
    "id": "arXiv:2202.07445",
    "title": "A Global Survey of Technological Resources and Datasets on COVID-19",
    "abstract": "The application and successful utilization of technological resources in\ndeveloping solutions to health, safety, and economic issues caused by COVID-19\nindicate the importance of technology in curbing COVID-19. Also, the medical\nfield has had to race against tie to develop and distribute the COVID-19\nvaccine. This endeavour became successful with the vaccines created and\napproved in less than a year, a feat in medical history. Currently, much work\nis being done on data collection, where all significant factors impacting the\ndisease are recorded. These factors include confirmed cases, death rates,\nvaccine rates, hospitalization data, and geographic regions affected by the\npandemic. Continued research and use of technological resources are highly\nrecommendable-the paper surveys list of packages, applications and datasets\nused to analyse COVID-19.",
    "descriptor": "",
    "authors": [
      "Manoj Muniswamaiah",
      "Tilak Agerwala",
      "Charles C. Tappert"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.07445"
  },
  {
    "id": "arXiv:2202.07446",
    "title": "Relational Artificial Intelligence",
    "abstract": "The impact of Artificial Intelligence does not depend only on fundamental\nresearch and technological developments, but for a large part on how these\nsystems are introduced into society and used in everyday situations. Even\nthough AI is traditionally associated with rational decision making,\nunderstanding and shaping the societal impact of AI in all its facets requires\na relational perspective. A rational approach to AI, where computational\nalgorithms drive decision making independent of human intervention, insights\nand emotions, has shown to result in bias and exclusion, laying bare societal\nvulnerabilities and insecurities. A relational approach, that focus on the\nrelational nature of things, is needed to deal with the ethical, legal,\nsocietal, cultural, and environmental implications of AI. A relational approach\nto AI recognises that objective and rational reasoning cannot does not always\nresult in the 'right' way to proceed because what is 'right' depends on the\ndynamics of the situation in which the decision is taken, and that rather than\nsolving ethical problems the focus of design and use of AI must be on asking\nthe ethical question. In this position paper, I start with a general discussion\nof current conceptualisations of AI followed by an overview of existing\napproaches to governance and responsible development and use of AI. Then, I\nreflect over what should be the bases of a social paradigm for AI and how this\nshould be embedded in relational, feminist and non-Western philosophies, in\nparticular the Ubuntu philosophy.",
    "descriptor": "",
    "authors": [
      "Virginia Dignum"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07446"
  },
  {
    "id": "arXiv:2202.07447",
    "title": "Trustworthy Autonomous Systems (TAS): Engaging TAS experts in curriculum  design",
    "abstract": "Recent advances in artificial intelligence, specifically machine learning,\ncontributed positively to enhancing the autonomous systems industry, along with\nintroducing social, technical, legal and ethical challenges to make them\ntrustworthy. Although Trustworthy Autonomous Systems (TAS) is an established\nand growing research direction that has been discussed in multiple disciplines,\ne.g., Artificial Intelligence, Human-Computer Interaction, Law, and Psychology.\nThe impact of TAS on education curricula and required skills for future TAS\nengineers has rarely been discussed in the literature. This study brings\ntogether the collective insights from a number of TAS leading experts to\nhighlight significant challenges for curriculum design and potential TAS\nrequired skills posed by the rapid emergence of TAS. Our analysis is of\ninterest not only to the TAS education community but also to other researchers,\nas it offers ways to guide future research toward operationalising TAS\neducation.",
    "descriptor": "",
    "authors": [
      "Mohammad Naiseh",
      "Caitlin Bentley",
      "Sarvapali D. Ramchurn"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07447"
  },
  {
    "id": "arXiv:2202.07448",
    "title": "Towards a Unified Pandemic Management Architecture: Survey, Challenges  and Future Directions",
    "abstract": "The pandemic caused by SARS-CoV-2 has left an unprecedented impact on health,\neconomy and society worldwide. Emerging strains are making pandemic management\nincreasingly challenging. There is an urge to collect epidemiological,\nclinical, and physiological data to make an informed decision on mitigation\nmeasures. Advances in the Internet of Things (IoT) and edge computing provide\nsolutions for pandemic management through data collection and intelligent\ncomputation. While existing data-driven architectures attempt to automate\ndecision-making, they do not capture the multifaceted interaction among\ncomputational models, communication infrastructure, and the generated data. In\nthis paper, we perform a survey of the existing approaches for pandemic\nmanagement, including online data repositories and contact-tracing\napplications. We then envision a unified pandemic management architecture that\nleverages the IoT and edge computing to automate recommendations on vaccine\ndistribution, dynamic lockdown, mobility scheduling and pandemic prediction. We\nelucidate the flow of data among the layers of the architecture, namely, cloud,\nedge and end device layers. Moreover, we address the privacy implications,\nthreats, regulations, and existing solutions that may be adapted to optimize\nthe utility of health data with security guarantees. The paper ends with a\nlowdown on the limitations of the architecture and research directions to\nenhance its practicality.",
    "descriptor": "\nComments: 30 pages and 10 figures\n",
    "authors": [
      "Satyaki Roy",
      "Nirnay Ghosh",
      "Nitish Uplavikar",
      "Preetam Ghosh"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.07448"
  },
  {
    "id": "arXiv:2202.07453",
    "title": "Random Walks for Adversarial Meshes",
    "abstract": "A polygonal mesh is the most-commonly used representation of surfaces in\ncomputer graphics; thus, a variety of classification networks have been\nrecently proposed. However, while adversarial attacks are wildly researched in\n2D, almost no works on adversarial meshes exist. This paper proposes a novel,\nunified, and general adversarial attack, which leads to misclassification of\nnumerous state-of-the-art mesh classification neural networks. Our attack\napproach is black-box, i.e. it has access only to the network's predictions,\nbut not to the network's full architecture or gradients. The key idea is to\ntrain a network to imitate a given classification network. This is done by\nutilizing random walks along the mesh surface, which gather geometric\ninformation. These walks provide insight onto the regions of the mesh that are\nimportant for the correct prediction of the given classification network. These\nmesh regions are then modified more than other regions in order to attack the\nnetwork in a manner that is barely visible to the naked eye.",
    "descriptor": "",
    "authors": [
      "Amir Belder",
      "Gal Yefet",
      "Ran Ben Izhak",
      "Ayellet Tal"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07453"
  },
  {
    "id": "arXiv:2202.07455",
    "title": "Transforming agrifood production systems and supply chains with digital  twins",
    "abstract": "Digital twins can transform agricultural production systems and supply\nchains, curbing greenhouse gas emissions, food waste and malnutrition. However,\nthe potential of these advanced virtualization technologies is yet to be\nrealized. Here, we consider the promise of digital twins across five typical\nagrifood supply chain steps and emphasize key implementation barriers.",
    "descriptor": "",
    "authors": [
      "Asaf Tzachor",
      "Catherine E. Richards",
      "Scott Jeen"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.07455"
  },
  {
    "id": "arXiv:2202.07456",
    "title": "A Survey on Image Deblurring",
    "abstract": "With the improvement of social life quality and the real needs of daily work,\nimages are more and more all around us. Image blurring due to camera shake,\nhuman movement, etc. has become the key to affecting image quality. How to\nremove image blur and restore clear image has gradually become an important\nresearch direction in the field of computer vision. After more than half a\ncentury of unremitting efforts, the majority of scientific and technological\nworkers have made fruitful progress in image deblurring. This article reviews\nthe work of image deblurring and specifically introduces more classic image\ndeblurring methods, which is helpful to understand current research and look\nforward to future trends. This article reviews the traditional image deblurring\nmethods and depth-represented image deblurring methods, and comprehensively\nclassifies and introduces the corresponding technical methods. This review can\nprovide some guidance for researchers in the field of image deblurring, and at\nthe same time facilitate their subsequent study and research.",
    "descriptor": "",
    "authors": [
      "ChuMiao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07456"
  },
  {
    "id": "arXiv:2202.07457",
    "title": "Teacher and Student Experiences in Online Classes During COVID-19  Pandemic in Serbia, Bosnia and Herzegovina and Croatia",
    "abstract": "In March 2020, the World Health Organization declared the COVID pandemic,\nwhich caused interruptions and delays in many activities, but most importantly,\nit led to some huge changes in education. Online teaching will prove to be the\nmost commonly used method that should compensate for the inability to work in\nthe classroom and allow the educational process to continue. Of course, this\nteaching method was not created in 2020, but it was only presented and\nimplemented in Serbia, Bosnia and Herzegovina and Croatia with the beginning of\nthe pandemic. In this paper, we see how these countries have faced abrupt\nchanges in teaching, and how this change has affected students. Online teaching\ncannot be a mere transfer of analog content to digital; a different approach is\nneeded in the implementation of teaching as required and offered by the digital\nmedium, but at the same time it is necessary to preserve the basic principles\nof the lecturer and the curriculum. It is a call, both for teachers and\nstudents. Since this is a current and universal problem, we hope that the\nconclusions presented are useful.",
    "descriptor": "\nComments: this https URL\n",
    "authors": [
      "Amila Dautbasic",
      "Senad Becirovic"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.07457"
  },
  {
    "id": "arXiv:2202.07458",
    "title": "IMPACT: Integrated Multi-Domain Emission Pathways For Cities Under  Land-Use Policy, Technology Adoption, Climate Change And Grid Decarbonization",
    "abstract": "Increasing urbanization puts ever-increasing pressure on cities to prioritize\nsustainable growth and avoid carbon lock-in, yet available modeling frameworks\nand tools fall acutely short of robustly guiding such pivotal decision-making\nat the local level. Financial incentives, behavioral interventions, and\nmandates can drive technology adoption, while land-use zoning policies provide\nthe framework for development of the built environment. Often policies and\ntheir impacts are evaluated top down, typically on a national scale, or\npost-hoc on developments vis-\\`a-vis different policies in the past. Such\nhigh-level analyses and post-hoc evaluations cannot show possible developments\npathways for specific cities, and hence cannot serve as input to policymakers\nat the local level such as county, municipal, or city governments. Here, we\npresent IMPACT pathways from a bottom-up model with residence level granularity\nthat integrate policy for technology adoption with zoning policy, climate\nchange, and grid decarbonization scenarios. With the city at the heart of the\nanalysis, our results show potential greenhouse gas emission pathways, identify\nsynergies and trade-offs between policies, and show the importance of\nappropriate baselines.",
    "descriptor": "\nComments: Under review\n",
    "authors": [
      "Zoltan Nagy",
      "Juliana Felkner",
      "Ariane L. Beck",
      "D. Cale Reeves",
      "Steven Richter",
      "Vivek Shastry",
      "Eli Ramthun",
      "Edward Mbata",
      "Stephen Zigmund",
      "Benjamin Marshall",
      "Linnea Marks",
      "Vianey Rueda",
      "Jasmine Triplett",
      "Sarah Domedead",
      "Jose R Vazquez-Canteli",
      "Varun Rai"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.07458"
  },
  {
    "id": "arXiv:2202.07462",
    "title": "Vau da muntanialas: Energy-efficient multi-die scalable acceleration of  RNN inference",
    "abstract": "Recurrent neural networks such as Long Short-Term Memories (LSTMs) learn\ntemporal dependencies by keeping an internal state, making them ideal for\ntime-series problems such as speech recognition. However, the output-to-input\nfeedback creates distinctive memory bandwidth and scalability challenges in\ndesigning accelerators for RNNs. We present Muntaniala, an RNN accelerator\narchitecture for LSTM inference with a silicon-measured energy-efficiency of\n3.25$TOP/s/W$ and performance of 30.53$GOP/s$ in UMC 65 $nm$ technology. The\nscalable design of Muntaniala allows running large RNN models by combining\nmultiple tiles in a systolic array. We keep all parameters stationary on every\ndie in the array, drastically reducing the I/O communication to only loading\nnew features and sharing partial results with other dies. For quantifying the\noverall system power, including I/O power, we built Vau da Muntanialas, to the\nbest of our knowledge, the first demonstration of a systolic multi-chip-on-PCB\narray of RNN accelerator. Our multi-die prototype performs LSTM inference with\n192 hidden states in 330$\\mu s$ with a total system power of 9.0$mW$ at 10$MHz$\nconsuming 2.95$\\mu J$. Targeting the 8/16-bit quantization implemented in\nMuntaniala, we show a phoneme error rate (PER) drop of approximately 3% with\nrespect to floating-point (FP) on a 3L-384NH-123NI LSTM network on the TIMIT\ndataset.",
    "descriptor": "",
    "authors": [
      "Gianna Paulin",
      "Francesco Conti",
      "Lukas Cavigelli",
      "Luca Benini"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Neural and Evolutionary Computing (cs.NE)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.07462"
  },
  {
    "id": "arXiv:2202.07463",
    "title": "Can Online Customer Reviews Help Design More Sustainable Products? A  Preliminary Study on Amazon Climate Pledge Friendly Products",
    "abstract": "Online product reviews are a valuable resource for product developers to\nimprove the design of their products. Yet, the potential value of customer\nfeedback to improve the sustainability performance of products is still to be\nexploited. The present paper investigates and analyzes Amazon product reviews\nto bring new light on the following question: ``What sustainable design\ninsights can be identified or interpreted from online product reviews?''. To do\nso, the top 100 reviews, evenly distributed by star ratings, for three product\ncategories (laptop, printer, cable) are collected, manually annotated, analyzed\nand interpreted. For each product category, the reviews of two similar products\n(one with environmental certification and one standard version) are compared\nand combined to come up with sustainable design solutions. In all, for the six\nproducts considered, between 12% and 20% of the reviews mentioned directly or\nindirectly aspects or attributes that could be exploited to improve the design\nof these products from a sustainability perspective. Concrete examples of\nsustainable design leads that could be elicited from product reviews are given\nand discussed. As such, this contribution provides a baseline for future work\nwilling to automate this process to gain further insights from online product\nreviews. Notably, the deployment of machine learning tools and the use of\nnatural language processing techniques to do so are discussed as promising\nlines for future research.",
    "descriptor": "\nComments: ASME 2021 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, Aug 2021, Virtual, United States\n",
    "authors": [
      "Michael Saidani",
      "Harrison Kim",
      "Nawres Ayadhi",
      "Bernard Yannou"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07463"
  },
  {
    "id": "arXiv:2202.07464",
    "title": "DeepSensor: Deep Learning Testing Framework Based on Neuron Sensitivity",
    "abstract": "Despite impressive capabilities and outstanding performance, deep neural\nnetwork(DNN) has captured increasing public concern for its security problem,\ndue to frequent occurrence of erroneous behaviors. Therefore, it is necessary\nto conduct systematically testing before its deployment to real-world\napplications. Existing testing methods have provided fine-grained criteria\nbased on neuron coverage and reached high exploratory degree of testing. But\nthere is still a gap between the neuron coverage and model's robustness\nevaluation. To bridge the gap, we observed that neurons which change the\nactivation value dramatically due to minor perturbation are prone to trigger\nincorrect corner cases. Motivated by it, we propose neuron sensitivity and\ndevelop a novel white-box testing framework for DNN, donated as DeepSensor. The\nnumber of sensitive neurons is maximized by particle swarm optimization, thus\ndiverse corner cases could be triggered and neuron coverage be further improved\nwhen compared with baselines. Besides, considerable robustness enhancement can\nbe reached when adopting testing examples based on neuron sensitivity for\nretraining. Extensive experiments implemented on scalable datasets and models\ncan well demonstrate the testing effectiveness and robustness improvement of\nDeepSensor.",
    "descriptor": "\nComments: 8 pages\n",
    "authors": [
      "Haibo Jin",
      "Ruoxi Chen",
      "Haibin Zheng",
      "Jinyin Chen",
      "Zhenguang Liu",
      "Qi Xuan",
      "Yue Yu",
      "Yao Cheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07464"
  },
  {
    "id": "arXiv:2202.07466",
    "title": "Perspectives on risk prioritization of data center vulnerabilities using  rank aggregation and multi-objective optimization",
    "abstract": "Nowadays, data has become an invaluable asset to entities and companies, and\nkeeping it secure represents a major challenge. Data centers are responsible\nfor storing data provided by software applications. Nevertheless, the number of\nvulnerabilities has been increasing every day. Managing such vulnerabilities is\nessential for building a reliable and secure network environment. Releasing\npatches to fix security flaws in software is a common practice to handle these\nvulnerabilities. However, prioritization becomes crucial for organizations with\nan increasing number of vulnerabilities since time and resources to fix them\nare usually limited. This review intends to present a survey of vulnerability\nranking techniques and promote a discussion on how multi-objective optimization\ncould benefit the management of vulnerabilities risk prioritization. The\nstate-of-the-art approaches for risk prioritization were reviewed, intending to\ndevelop an effective model for ranking vulnerabilities in data centers. The\nmain contribution of this work is to point out multi-objective optimization as\na not commonly explored but promising strategy to prioritize vulnerabilities,\nenabling better time management and increasing security.",
    "descriptor": "",
    "authors": [
      "Bruno Grisci",
      "Gabriela Kuhn",
      "Felipe Colombelli",
      "V\u00edtor Matter",
      "Leomar Lima",
      "Karine Heinen",
      "Mauricio Pegoraro",
      "Marcio Borges",
      "Sandro Rigo",
      "Jorge Barbosa",
      "Rodrigo da Rosa Righi",
      "Cristiano Andr\u00e9 da Costa",
      "Gabriel de Oliveira Ramos"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.07466"
  },
  {
    "id": "arXiv:2202.07467",
    "title": "The Perception of Filipinos on the Advent of Cryptocurrency and  Non-Fungible Token (NFT) Games",
    "abstract": "This study aims to shed light on the rise of play-to-earn games in the\nPhilippines alongside cryptocurrency. The lack of research and public\nunderstanding of its benefits and drawbacks prompted the researchers to\ninvestigate its market. As such, the study tried to look into the risks and\nbenefits of crypto gaming if it would be regulated by the government, and how\nmarket volatility influences the churn rate of crypto games. The research used\na descriptive study to determine the perception of people who are engaged in\nplaying a crypto-game named as Axie Infinity. The results showed that most\nplayers spend their time playing Axie Infinity for about 1 to 4 hours a day.\nPredominantly, the return of investments for playing the game will take about 1\nto 3 months. It also showed that these players agreed that there is a possible\nfinancial instability in a volatile market. With this, they have a high trust\nissue in terms of price manipulation, privacy and security, and its design and\nusability. Understanding the cryptocurrency market requires comprehending the\nperspective of the people who are engaged in a play-to-earn game, and their\nconcerns are critical for any government actions aimed at regulating\nself-employed income earners playing (Non-fungible Tokens) NFT games in the\nPhilippines.",
    "descriptor": "\nComments: presented in National Research Conference in Computer Engineering and Technology\n",
    "authors": [
      "Ryan Francisco",
      "Nelson Rodelas",
      "John Edison Ubaldo"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.07467"
  },
  {
    "id": "arXiv:2202.07470",
    "title": "Federated Contrastive Learning for Dermatological Disease Diagnosis via  On-device Learning",
    "abstract": "Deep learning models have been deployed in an increasing number of edge and\nmobile devices to provide healthcare. These models rely on training with a\ntremendous amount of labeled data to achieve high accuracy. However, for\nmedical applications such as dermatological disease diagnosis, the private data\ncollected by mobile dermatology assistants exist on distributed mobile devices\nof patients, and each device only has a limited amount of data. Directly\nlearning from limited data greatly deteriorates the performance of learned\nmodels. Federated learning (FL) can train models by using data distributed on\ndevices while keeping the data local for privacy. Existing works on FL assume\nall the data have ground-truth labels. However, medical data often comes\nwithout any accompanying labels since labeling requires expertise and results\nin prohibitively high labor costs. The recently developed self-supervised\nlearning approach, contrastive learning (CL), can leverage the unlabeled data\nto pre-train a model, after which the model is fine-tuned on limited labeled\ndata for dermatological disease diagnosis. However, simply combining CL with FL\nas federated contrastive learning (FCL) will result in ineffective learning\nsince CL requires diverse data for learning but each device only has limited\ndata. In this work, we propose an on-device FCL framework for dermatological\ndisease diagnosis with limited labels. Features are shared in the FCL\npre-training process to provide diverse and accurate contrastive information.\nAfter that, the pre-trained model is fine-tuned with local labeled data\nindependently on each device or collaboratively with supervised federated\nlearning on all devices. Experiments on dermatological disease datasets show\nthat the proposed framework effectively improves the recall and precision of\ndermatological disease diagnosis compared with state-of-the-art methods.",
    "descriptor": "",
    "authors": [
      "Yawen Wu",
      "Dewen Zeng",
      "Zhepeng Wang",
      "Yi Sheng",
      "Lei Yang",
      "Alaina J. James",
      "Yiyu Shi",
      "Jingtong Hu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.07470"
  },
  {
    "id": "arXiv:2202.07471",
    "title": "SQuant: On-the-Fly Data-Free Quantization via Diagonal Hessian  Approximation",
    "abstract": "Quantization of deep neural networks (DNN) has been proven effective for\ncompressing and accelerating DNN models. Data-free quantization (DFQ) is a\npromising approach without the original datasets under privacy-sensitive and\nconfidential scenarios. However, current DFQ solutions degrade accuracy, need\nsynthetic data to calibrate networks, and are time-consuming and costly. This\npaper proposes an on-the-fly DFQ framework with sub-second quantization time,\ncalled SQuant, which can quantize networks on inference-only devices with low\ncomputation and memory requirements. With the theoretical analysis of the\nsecond-order information of DNN task loss, we decompose and approximate the\nHessian-based optimization objective into three diagonal sub-items, which have\ndifferent areas corresponding to three dimensions of weight tensor:\nelement-wise, kernel-wise, and output channel-wise. Then, we progressively\ncompose sub-items and propose a novel data-free optimization objective in the\ndiscrete domain, minimizing Constrained Absolute Sum of Error (or CASE in\nshort), which surprisingly does not need any dataset and is even not aware of\nnetwork architecture. We also design an efficient algorithm without\nback-propagation to further reduce the computation complexity of the objective\nsolver. Finally, without fine-tuning and synthetic datasets, SQuant accelerates\nthe data-free quantization process to a sub-second level with >30% accuracy\nimprovement over the existing data-free post-training quantization works, with\nthe evaluated models under 4-bit quantization. We have open-sourced the SQuant\nframework at https://github.com/clevercool/SQuant.",
    "descriptor": "\nComments: 18 pages, 2 figures, ICLR 2022\n",
    "authors": [
      "Cong Guo",
      "Yuxian Qiu",
      "Jingwen Leng",
      "Xiaotian Gao",
      "Chen Zhang",
      "Yunxin Liu",
      "Fan Yang",
      "Yuhao Zhu",
      "Minyi Guo"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07471"
  },
  {
    "id": "arXiv:2202.07472",
    "title": "Sequential Bayesian experimental designs via reinforcement learning",
    "abstract": "Bayesian experimental design (BED) has been used as a method for conducting\nefficient experiments based on Bayesian inference. The existing methods,\nhowever, mostly focus on maximizing the expected information gain (EIG); the\ncost of experiments and sample efficiency are often not taken into account. In\norder to address this issue and enhance practical applicability of BED, we\nprovide a new approach Sequential Experimental Design via Reinforcement\nLearning to construct BED in a sequential manner by applying reinforcement\nlearning in this paper. Here, reinforcement learning is a branch of machine\nlearning in which an agent learns a policy to maximize its reward by\ninteracting with the environment. The characteristics of interacting with the\nenvironment are similar to the sequential experiment, and reinforcement\nlearning is indeed a method that excels at sequential decision making.\nBy proposing a new real-world-oriented experimental environment, our approach\naims to maximize the EIG while keeping the cost of experiments and sample\nefficiency in mind simultaneously. We conduct numerical experiments for three\ndifferent examples. It is confirmed that our method outperforms the existing\nmethods in various indices such as the EIG and sampling efficiency, indicating\nthat our proposed method and experimental environment can make a significant\ncontribution to application of BED to the real world.",
    "descriptor": "\nComments: Bachelor thesis\n",
    "authors": [
      "Hikaru Asano"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Methodology (stat.ME)"
    ],
    "url": "https://arxiv.org/abs/2202.07472"
  },
  {
    "id": "arXiv:2202.07474",
    "title": "Do Lessons from Metric Learning Generalize to Image-Caption Retrieval?",
    "abstract": "The triplet loss with semi-hard negatives has become the de facto choice for\nimage-caption retrieval (ICR) methods that are optimized from scratch. Recent\nprogress in metric learning has given rise to new loss functions that\noutperform the triplet loss on tasks such as image retrieval and representation\nlearning. We ask whether these findings generalize to the setting of ICR by\ncomparing three loss functions on two ICR methods. We answer this question\nnegatively: the triplet loss with semi-hard negative mining still outperforms\nnewly introduced loss functions from metric learning on the ICR task. To gain a\nbetter understanding of these outcomes, we introduce an analysis method to\ncompare loss functions by counting how many samples contribute to the gradient\nw.r.t. the query representation during optimization. We find that loss\nfunctions that result in lower evaluation scores on the ICR task, in general,\ntake too many (non-informative) samples into account when computing a gradient\nw.r.t. the query representation, which results in sub-optimal performance. The\ntriplet loss with semi-hard negatives is shown to outperform the other loss\nfunctions, as it only takes one (hard) negative into account when computing the\ngradient.",
    "descriptor": "\nComments: Accepted to ECIR 2022 Reproducibility track\n",
    "authors": [
      "Maurits Bleeker",
      "Maarten de Rijke"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.07474"
  },
  {
    "id": "arXiv:2202.07475",
    "title": "A Real-time System for Detecting Landslide Reports on Social Media using  Artificial Intelligence",
    "abstract": "This paper presents an online system that leverages social media data in real\ntime to identify landslide-related information automatically using\nstate-of-the-art artificial intelligence techniques. The designed system can\n(i) reduce the information overload by eliminating duplicate and irrelevant\ncontent, (ii) identify landslide images, (iii) infer geolocation of the images,\nand (iv) categorize the user type (organization or person) of the account\nsharing the information. The system was deployed in February 2020 online at\nhttps://landslide-aidr.qcri.org/landslide_system.php to monitor live Twitter\ndata stream and has been running continuously since then to provide\ntime-critical information to partners such as British Geological Survey and\nEuropean Mediterranean Seismological Centre. We trust this system can both\ncontribute to harvesting of global landslide data for further research and\nsupport global landslide maps to facilitate emergency response and decision\nmaking.",
    "descriptor": "\nComments: Landslide detection, Social media, Online system, Real time, Image classification, Computer vision, Artificial intelligence\n",
    "authors": [
      "Ferda Ofli",
      "Umair Qazi",
      "Muhammad Imran",
      "Julien Roch",
      "Catherine Pennington",
      "Vanessa Banks",
      "Remy Bossu"
    ],
    "subjectives": [
      "Computers and Society (cs.CY)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07475"
  },
  {
    "id": "arXiv:2202.07476",
    "title": "MGCVAE: Multi-objective Inverse Design via Molecular Graph Conditional  Variational Autoencoder",
    "abstract": "The ultimate goal of various fields is to directly generate molecules with\ndesired properties, such as finding water-soluble molecules in drug development\nand finding molecules suitable for organic light-emitting diode (OLED) or\nphotosensitizers in the field of development of new organic materials. In this\nrespect, this study proposes a molecular graph generative model based on the\nautoencoder for de novo design. The performance of molecular graph conditional\nvariational autoencoder (MGCVAE) for generating molecules having specific\ndesired properties is investigated by comparing it to molecular graph\nvariational autoencoder (MGVAE). Furthermore, multi-objective optimization for\nMGCVAE was applied to satisfy two selected properties simultaneously. In this\nstudy, two physical properties -- logP and molar refractivity -- were used as\noptimization targets for the purpose of designing de novo molecules, especially\nin drug discovery. As a result, it was confirmed that among generated\nmolecules, 25.89% optimized molecules were generated in MGCVAE compared to\n0.66% in MGVAE. Hence, it demonstrates that MGCVAE effectively produced\ndrug-like molecules with two target properties. The results of this study\nsuggest that these graph-based data-driven models are one of the effective\nmethods of designing new molecules that fulfill various physical properties,\nsuch as drug discovery.",
    "descriptor": "\nComments: preprint, under review\n",
    "authors": [
      "Myeonghun Lee",
      "Kyoungmin Min"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Chemical Physics (physics.chem-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.07476"
  },
  {
    "id": "arXiv:2202.07479",
    "title": "Audio Inpainting via $\\ell_1$-Minimization and Dictionary Learning",
    "abstract": "Audio inpainting refers to signal processing techniques that aim at restoring\nmissing or corrupted consecutive samples in audio signals. Prior works have\nshown that $\\ell_1$- minimization with appropriate weighting is capable of\nsolving audio inpainting problems, both for the analysis and the synthesis\nmodels. These models assume that audio signals are sparse with respect to some\nredundant dictionary and exploit that sparsity for inpainting purposes.\nRemaining within the sparsity framework, we utilize dictionary learning to\nfurther increase the sparsity and combine it with weighted\n$\\ell_1$-minimization adapted for audio inpainting to compensate for the loss\nof energy within the gap after restoration. Our experiments demonstrate that\nour approach is superior in terms of signal-to-distortion ratio (SDR) and\nobjective difference grade (ODG) compared with its original counterpart.",
    "descriptor": "",
    "authors": [
      "Shristi Rajbamshi",
      "Georg Taub\u00f6ck",
      "Peter Balazs",
      "Nicki Holighaus"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.07479"
  },
  {
    "id": "arXiv:2202.07480",
    "title": "Fast Symbolic Algorithms for Omega-Regular Games under Strong Transition  Fairness",
    "abstract": "We consider fixpoint algorithms for two-player games on graphs with\n$\\omega$-regular winning conditions, where the environment is constrained by a\nstrong transition fairness assumption. Strong transition fairness is a widely\noccurring special case of strong fairness, which requires that any execution is\nstrongly fair with respect to a specified set of live edges: whenever the\nsource vertex of a live edge is visited infinitely often along a play, the edge\nitself is traversed infinitely often along the play as well.\nWe show that, surprisingly, strong transition fairness retains the\nalgorithmic characteristics of the fixpoint algorithms for $\\omega$-regular\ngames -- the new algorithms can be obtained simply by replacing certain\noccurrences of the controllable predecessor by a new almost sure predecessor\noperator. For Rabin games with $k$ pairs, the complexity of the new algorithm\nis $O(n^{k+2}k!)$ symbolic steps, which is independent of the number of live\nedges in the strong transition fairness assumption. Further, we show that GR(1)\nspecifications with strong transition fairness assumptions can be solved with a\n3-nested fixpoint algorithm, same as the usual algorithm. In contrast, strong\nfairness necessarily requires increasing the alternation depth depending on the\nnumber of fairness assumptions.\nWe get symbolic algorithms for (generalized) Rabin, parity and GR(1)\nobjectives under strong transition fairness assumptions as well as a direct\nsymbolic algorithm for qualitative winning in stochastic $\\omega$-regular games\nthat runs in $O(n^{k+2}k!)$ symbolic steps, improving the state of the art.\nFinally, we have implemented a BDD-based synthesis engine based on our\nalgorithm. We show on a set of synthetic and real benchmarks that our algorithm\nis scalable, parallelizable, and outperforms previous algorithms by orders of\nmagnitude.",
    "descriptor": "",
    "authors": [
      "Tamajit Banerjee",
      "Rupak Majumdar",
      "Kaushik Mallik",
      "Anne-Kathrin Schmuck",
      "Sadegh Soudjani"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)",
      "Symbolic Computation (cs.SC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.07480"
  },
  {
    "id": "arXiv:2202.07481",
    "title": "DualConv: Dual Convolutional Kernels for Lightweight Deep Neural  Networks",
    "abstract": "CNN architectures are generally heavy on memory and computational\nrequirements which makes them infeasible for embedded systems with limited\nhardware resources. We propose dual convolutional kernels (DualConv) for\nconstructing lightweight deep neural networks. DualConv combines 3$\\times$3 and\n1$\\times$1 convolutional kernels to process the same input feature map channels\nsimultaneously and exploits the group convolution technique to efficiently\narrange convolutional filters. DualConv can be employed in any CNN model such\nas VGG-16 and ResNet-50 for image classification, YOLO and R-CNN for object\ndetection, or FCN for semantic segmentation. In this paper, we extensively test\nDualConv for classification since these network architectures form the\nbackbones for many other tasks. We also test DualConv for image detection on\nYOLO-V3. Experimental results show that, combined with our structural\ninnovations, DualConv significantly reduces the computational cost and number\nof parameters of deep neural networks while surprisingly achieving slightly\nhigher accuracy than the original models in some cases. We use DualConv to\nfurther reduce the number of parameters of the lightweight MobileNetV2 by 54%\nwith only 0.68% drop in accuracy on CIFAR-100 dataset. When the number of\nparameters is not an issue, DualConv increases the accuracy of MobileNetV1 by\n4.11% on the same dataset. Furthermore, DualConv significantly improves the\nYOLO-V3 object detection speed and improves its accuracy by 4.4% on PASCAL VOC\ndataset.",
    "descriptor": "\nComments: Accepted for publication in IEEE TNNLS\n",
    "authors": [
      "Jiachen Zhong",
      "Junying Chen",
      "Ajmal Mian"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07481"
  },
  {
    "id": "arXiv:2202.07484",
    "title": "Phase-Based Signal Representations for Scattering",
    "abstract": "The scattering transform is a non-linear signal representation method based\non cascaded wavelet transform magnitudes. In this paper we introduce phase\nscattering, a novel approach where we use phase derivatives in a scattering\nprocedure. We first revisit phase-related concepts for representing\ntime-frequency information of audio signals, in particular, the partial\nderivatives of the phase in the time-frequency domain. By putting analytical\nand numerical results in a new light, we set the basis to extend the\nphase-based representations to higher orders by means of a scattering\ntransform, which leads to well localized signal representations of large-scale\nstructures. All the ideas are introduced in a general way and then applied\nusing the STFT.",
    "descriptor": "",
    "authors": [
      "Daniel Haider",
      "Peter Balazs",
      "Nicki Holighaus"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.07484"
  },
  {
    "id": "arXiv:2202.07487",
    "title": "On the cartesian product of well-orderings",
    "abstract": "The width of a well partial ordering (wpo) is the ordinal rank of the set of\nits antichains ordered by inclusion. We compute the width of wpos obtained as\ncartesian products of finitely many well-orderings.",
    "descriptor": "",
    "authors": [
      "Isa Vialard"
    ],
    "subjectives": [
      "Logic in Computer Science (cs.LO)",
      "Combinatorics (math.CO)",
      "Logic (math.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.07487"
  },
  {
    "id": "arXiv:2202.07496",
    "title": "Beyond the Policy Gradient Theorem for Efficient Policy Updates in  Actor-Critic Algorithms",
    "abstract": "In Reinforcement Learning, the optimal action at a given state is dependent\non policy decisions at subsequent states. As a consequence, the learning\ntargets evolve with time and the policy optimization process must be efficient\nat unlearning what it previously learnt. In this paper, we discover that the\npolicy gradient theorem prescribes policy updates that are slow to unlearn\nbecause of their structural symmetry with respect to the value target. To\nincrease the unlearning speed, we study a novel policy update: the gradient of\nthe cross-entropy loss with respect to the action maximizing $q$, but find that\nsuch updates may lead to a decrease in value. Consequently, we introduce a\nmodified policy update devoid of that flaw, and prove its guarantees of\nconvergence to global optimality in $\\mathcal{O}(t^{-1})$ under classic\nassumptions. Further, we assess standard policy updates and our cross-entropy\npolicy updates along six analytical dimensions. Finally, we empirically\nvalidate our theoretical findings.",
    "descriptor": "\nComments: 9p+appendix, accepted to AISTATS 2022\n",
    "authors": [
      "Romain Laroche",
      "Remi Tachet"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.07496"
  },
  {
    "id": "arXiv:2202.07498",
    "title": "Non-iterative Filter Bank Phase (Re)Construction",
    "abstract": "Signal reconstruction from magnitude-only measurements presents a\nlong-standing problem in signal processing. In this contribution, we propose a\nphase (re)construction method for filter banks with uniform decimation and\ncontrolled frequency variation. The suggested procedure extends the recently\nintroduced phase-gradient heap integration and relies on a phase-magnitude\nrelationship for filter bank coefficients obtained from Gaussian filters.\nAdmissible filter banks are modeled as the discretization of certain\ngeneralized translation-invariant systems, for which we derive the\nphase-magnitude relationship explicitly. The implementation for discrete\nsignals is described and the performance of the algorithm is evaluated on a\nrange of real and synthetic signals.",
    "descriptor": "",
    "authors": [
      "Zden\u011bk Pr\u016f\u0161a",
      "Nicki Holighaus"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Mathematical Software (cs.MS)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.07498"
  },
  {
    "id": "arXiv:2202.07499",
    "title": "Texture Aware Autoencoder Pre-training And Pairwise Learning Refinement  For Improved Iris Recognition",
    "abstract": "This paper presents a texture aware end-to-end trainable iris recognition\nsystem, specifically designed for datasets like iris having limited training\ndata. We build upon our previous stagewise learning framework with certain key\noptimization and architectural innovations. First, we pretrain a Stage-1\nencoder network with an unsupervised autoencoder learning optimized with an\nadditional data relation loss on top of usual reconstruction loss. The data\nrelation loss enables learning better texture representation which is pivotal\nfor a texture rich dataset such as iris. Robustness of Stage-1 feature\nrepresentation is further enhanced with an auxiliary denoising task. Such\npre-training proves beneficial for effectively training deep networks on data\nconstrained iris datasets. Next, in Stage-2 supervised refinement, we design a\npairwise learning architecture for an end-to-end trainable iris recognition\nsystem. The pairwise learning includes the task of iris matching inside the\ntraining pipeline itself and results in significant improvement in recognition\nperformance compared to usual offline matching. We validate our model across\nthree publicly available iris datasets and the proposed model consistently\noutperforms both traditional and deep learning baselines for both\nWithin-Dataset and Cross-Dataset configurations",
    "descriptor": "",
    "authors": [
      "Manashi Chakraborty",
      "Aritri Chakraborty",
      "Prabir Kumar Biswas",
      "Pabitra Mitra"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07499"
  },
  {
    "id": "arXiv:2202.07503",
    "title": "BED: A Real-Time Object Detection System for Edge Devices",
    "abstract": "Deploying machine learning models to edge devices has many real-world\napplications, especially for the scenarios that demand low latency, low power,\nor data privacy. However, it requires substantial research and engineering\nefforts due to the limited computational resources and memory of edge devices.\nIn this demo, we present BED, an object detection system for edge devices\npracticed on the MAX78000 DNN accelerator. BED integrates on-device DNN\ninference with a camera and a screen for image acquisition and output\nexhibition, respectively. Experiment results indicate BED can provide accurate\ndetection with an only 300KB tiny DNN model.",
    "descriptor": "",
    "authors": [
      "Guanchu Wang",
      "Zaid Pervaiz Bhat",
      "Zhimeng Jiang",
      "Yi-Wei Chen",
      "Daochen Zha",
      "Alfredo Costilla Reyes",
      "Afshin Niktash",
      "Gorkem Ulkar",
      "Erman Okman",
      "Xia Hu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07503"
  },
  {
    "id": "arXiv:2202.07504",
    "title": "vue4logs -- Automatic Structuring of Heterogeneous Computer System Logs",
    "abstract": "Computer system log data is commonly used in system monitoring, performance\ncharacteristic investigation, workflow modeling and anomaly detection. Log data\nis inherently unstructured or semi-structured, which makes it harder to\nunderstand the event flow or other important information of a system by reading\nraw logs. The process of structuring log files first identifies the log message\ngroups based on the system events that triggered them, and extracts an event\ntemplate to represent the log messages of each event. This paper introduces a\nnovel method to extract event templates from raw system log files, by using the\nvector space model commonly used in the field of Information Retrieval to\nvectorize log data and group log messages into event templates based on their\nvector similarity. Template extraction process is further enhanced with the use\nof character and length based filters. When evaluated on publicly available\nreal-world log data benchmarks, this proposed method outperforms all the\navailable state-of-the-art systems in terms of accuracy and robustness.",
    "descriptor": "",
    "authors": [
      "Isuru Boyagane",
      "Oshadha Katulanda",
      "Surangika Ranathunga",
      "Srinath Perera"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2202.07504"
  },
  {
    "id": "arXiv:2202.07509",
    "title": "On Polynomial Ideals And Overconvergence In Tate Algebras",
    "abstract": "In this paper, we study ideals spanned by polynomials or overconvergent\nseries in a Tate algebra. With state-of-the-art algorithms for computing Tate\nGr{\\\"o}bner bases, even if the input is polynomials, the size of the output\ngrows with the required precision, both in terms of the size of the\ncoefficients and the size of the support of the series. We prove that ideals\nwhich are spanned by polynomials admit a Tate Gr{\\\"o}bner basis made of\npolynomials, and we propose an algorithm, leveraging Mora's weak normal form\nalgorithm, for computing it. As a result, the size of the output of this\nalgorithm grows linearly with the precision. Following the same ideas, we\npropose an algorithm which computes an overconvergent basis for an ideal\nspanned by overconvergent series. Finally, we prove the existence of a\nuniversal analytic Gr{\\\"o}bner basis for polynomial ideals in Tate algebras,\ncompatible with all convergence radii.",
    "descriptor": "",
    "authors": [
      "Xavier Caruso",
      "Tristan Vaccon",
      "Thibaut Verron"
    ],
    "subjectives": [
      "Symbolic Computation (cs.SC)",
      "Algebraic Geometry (math.AG)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2202.07509"
  },
  {
    "id": "arXiv:2202.07511",
    "title": "Pessimistic Minimax Value Iteration: Provably Efficient Equilibrium  Learning from Offline Datasets",
    "abstract": "We study episodic two-player zero-sum Markov games (MGs) in the offline\nsetting, where the goal is to find an approximate Nash equilibrium (NE) policy\npair based on a dataset collected a priori. When the dataset does not have\nuniform coverage over all policy pairs, finding an approximate NE involves\nchallenges in three aspects: (i) distributional shift between the behavior\npolicy and the optimal policy, (ii) function approximation to handle large\nstate space, and (iii) minimax optimization for equilibrium solving. We propose\na pessimism-based algorithm, dubbed as pessimistic minimax value iteration\n(PMVI), which overcomes the distributional shift by constructing pessimistic\nestimates of the value functions for both players and outputs a policy pair by\nsolving NEs based on the two value functions. Furthermore, we establish a\ndata-dependent upper bound on the suboptimality which recovers a sublinear rate\nwithout the assumption on uniform coverage of the dataset. We also prove an\ninformation-theoretical lower bound, which suggests that the data-dependent\nterm in the upper bound is intrinsic. Our theoretical results also highlight a\nnotion of \"relative uncertainty\", which characterizes the necessary and\nsufficient condition for achieving sample efficiency in offline MGs. To the\nbest of our knowledge, we provide the first nearly minimax optimal result for\noffline MGs with function approximation.",
    "descriptor": "",
    "authors": [
      "Han Zhong",
      "Wei Xiong",
      "Jiyuan Tan",
      "Liwei Wang",
      "Tong Zhang",
      "Zhaoran Wang",
      "Zhuoran Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Science and Game Theory (cs.GT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.07511"
  },
  {
    "id": "arXiv:2202.07516",
    "title": "OpenStreetMap-based LiDAR Global Localization in Urban Environment  without a Prior LiDAR Map",
    "abstract": "Using publicly accessible maps, we propose a novel vehicle localization\nmethod that can be applied without using prior light detection and ranging\n(LiDAR) maps. Our method generates OSM descriptors by calculating the distances\nto buildings from a location in OpenStreetMap at a regular angle, and LiDAR\ndescriptors by calculating the shortest distances to building points from the\ncurrent location at a regular angle. Comparing the OSM descriptors and LiDAR\ndescriptors yields a highly accurate vehicle localization result. Compared to\nmethods that use prior LiDAR maps, our method presents two main advantages: (1)\nvehicle localization is not limited to only places with previously acquired\nLiDAR maps, and (2) our method is comparable to LiDAR map-based methods, and\nespecially outperforms the other methods with respect to the top one candidate\nat KITTI dataset sequence 00.",
    "descriptor": "",
    "authors": [
      "Younghun Cho",
      "Giseop Kim",
      "Sangmin Lee",
      "Jee-Hwan Ryu"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.07516"
  },
  {
    "id": "arXiv:2202.07519",
    "title": "Social Science Theories in Software Engineering Research",
    "abstract": "As software engineering research becomes more concerned with the\npsychological, sociological and managerial aspects of software development,\nrelevant theories from reference disciplines are increasingly important for\nunderstanding the field's core phenomena of interest. However, the degree to\nwhich software engineering research draws on relevant social sciences remains\nunclear. This study therefore investigates the use of social science theories\nin five influential software engineering journals over 13 years. It analyzes\nnot only the extent of theory use but also what, how and where these theories\nare used. While 87 different theories are used, less than two percent of papers\nuse a social science theory, most theories are used in only one paper, most\nsocial sciences are ignored, and the theories are rarely tested for\napplicability to software engineering contexts. Ignoring relevant social\nscience theories may (1) undermine the community's ability to generate,\nelaborate and maintain a cumulative body of knowledge; and (2) lead to\noversimplified models of software engineering phenomena. More attention to\ntheory is needed for software engineering to mature as a scientific discipline.",
    "descriptor": "",
    "authors": [
      "Tobias Lorey",
      "Paul Ralph",
      "Michael Felderer"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.07519"
  },
  {
    "id": "arXiv:2202.07521",
    "title": "5G Enabled Fault Detection and Diagnostics: How Do We Achieve  Efficiency?",
    "abstract": "The 5th-generation wireless networks (5G) technologies and mobile edge\ncomputing (MEC) provide great promises of enabling new capabilities for the\nindustrial Internet of Things. However, the solutions enabled by the 5G\nultra-reliable low-latency communication (URLLC) paradigm come with challenges,\nwhere URLLC alone does not necessarily guarantee the efficient execution of\ntime-critical fault detection and diagnostics (FDD) applications. Based on the\nTennessee Eastman Process model, we propose the concept of the\ncommunication-edge-computing (CEC) loop and a system model for evaluating the\nefficiency of FDD applications. We then formulate an optimization problem for\nachieving the defined CEC efficiency and discuss some typical solutions to the\ngeneric CEC-based FDD services, and propose a new uplink-based communication\nprotocol called \"ReFlexUp\". From the performance analysis and numerical\nresults, the proposed ReFlexUp protocol shows its effectiveness compared to the\ntypical protocols such as Selective Repeat ARQ, HARQ, and \"Occupy CoW\" in terms\nof the key metrics such as latency, reliability, and efficiency. These results\nare further convinced from the mmWave-based simulations in a typical 5G\nMEC-based implementation.",
    "descriptor": "",
    "authors": [
      "Peng Hu",
      "Jinhuan Zhang"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.07521"
  },
  {
    "id": "arXiv:2202.07530",
    "title": "Optimal Algorithms for Stochastic Multi-Level Compositional Optimization",
    "abstract": "In this paper, we investigate the problem of stochastic multi-level\ncompositional optimization, where the objective function is a composition of\nmultiple smooth but possibly non-convex functions. Existing methods for solving\nthis problem either suffer from sub-optimal sample complexities or need a huge\nbatch size. To address this limitation, we propose a Stochastic Multi-level\nVariance Reduction method (SMVR), which achieves the optimal sample complexity\nof $\\mathcal{O}\\left(1 / \\epsilon^{3}\\right)$ to find an $\\epsilon$-stationary\npoint for non-convex objectives. Furthermore, when the objective function\nsatisfies the convexity or Polyak-Lojasiewicz (PL) condition, we propose a\nstage-wise variant of SMVR and improve the sample complexity to\n$\\mathcal{O}\\left(1 / \\epsilon^{2}\\right)$ for convex functions or\n$\\mathcal{O}\\left(1 /(\\mu\\epsilon)\\right)$ for non-convex functions satisfying\nthe $\\mu$-PL condition. The latter result implies the same complexity for\n$\\mu$-strongly convex functions. To make use of adaptive learning rates, we\nalso develop Adaptive SMVR, which achieves the same optimal complexities but\nconverges faster in practice. All our complexities match the lower bounds not\nonly in terms of $\\epsilon$ but also in terms of $\\mu$ (for PL or strongly\nconvex functions), without using a large batch size in each iteration.",
    "descriptor": "",
    "authors": [
      "Wei Jiang",
      "Bokun Wang",
      "Yibo Wang",
      "Lijun Zhang",
      "Tianbao Yang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07530"
  },
  {
    "id": "arXiv:2202.07532",
    "title": "Closing the Management Gap for Satellite-Integrated Community Networks:  A Hierarchical Approach to Self-Maintenance",
    "abstract": "Community networks (CNs) have become an important paradigm for providing\nessential Internet connectivity in unserved and underserved areas across the\nworld. However, an indispensable part for CNs is network management, where\nresponsive and autonomous maintenance is much needed. With the technological\nadvancement in telecommunications networks, a classical satellite-dependent CN\nis envisioned to be transformed into a satellite-integrated CN (SICN), which\nwill embrace significant autonomy, intelligence, and scalability in network\nmanagement. This article discusses the machine-learning (ML) based hierarchical\napproach to enabling autonomous self-maintenance for SICNs. The approach is\nsplit into the anomaly identification and anomaly mitigation phases, where the\nrelated ML methods, data collection means, deployment options, and mitigation\nschemes are presented. With the case study, we discuss a typical scenario using\nsatellite and fixed connections as backhaul options and show the effectiveness\n\\hl{and performance improvements} of the proposed approach \\hl{with recurrent\nneural network and ensemble methods",
    "descriptor": "",
    "authors": [
      "Peng Hu"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07532"
  },
  {
    "id": "arXiv:2202.07537",
    "title": "Information-Theoretic Analysis of Minimax Excess Risk",
    "abstract": "Two main concepts studied in machine learning theory are generalization gap\n(difference between train and test error) and excess risk (difference between\ntest error and the minimum possible error). While information-theoretic tools\nhave been used extensively to study the generalization gap of learning\nalgorithms, the information-theoretic nature of excess risk has not yet been\nfully investigated. In this paper, some steps are taken toward this goal. We\nconsider the frequentist problem of minimax excess risk as a zero-sum game\nbetween algorithm designer and the world. Then, we argue that it is desirable\nto modify this game in a way that the order of play can be swapped. We prove\nthat, under some regularity conditions, if the world and designer can play\nrandomly the duality gap is zero and the order of play can be changed. In this\ncase, a Bayesian problem surfaces in the dual representation. This makes it\npossible to utilize recent information-theoretic results on minimum excess risk\nin Bayesian learning to provide bounds on the minimax excess risk. We\ndemonstrate the applicability of the results by providing information theoretic\ninsight on two important classes of problems: classification when the\nhypothesis space has finite VC-dimension, and regularized least squares.",
    "descriptor": "",
    "authors": [
      "Hassan Hafez-Kolahi",
      "Behrad Moniri",
      "Shohreh Kasaei"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.07537"
  },
  {
    "id": "arXiv:2202.07541",
    "title": "Coding and Bounds for Partially Defective Memory Cells",
    "abstract": "This paper considers coding for so-called partially stuck (defect) memory\ncells. Such memory cells can only store partial information as some of their\nlevels cannot be used fully due to, e.g., wearout. First, we present new\nconstructions that are able to mask $u$ partially stuck cells while correcting\nat the same time $t$ random errors. The process of \"masking\" determines a word\nwhose entries coincide with writable levels at the (partially) stuck cells. For\n$u>1$ and alphabet size $q>2$, our new constructions improve upon the required\nredundancy of known constructions for $t=0$, and require less redundancy for\nmasking partially stuck cells than former works required for masking fully\nstuck cells (which cannot store any information). Second, we show that treating\nsome of the partially stuck cells as erroneous cells can decrease the required\nredundancy for some parameters. Lastly, we derive Singleton-like,\nsphere-packing-like, and Gilbert--Varshamov-like bounds. Numerical comparisons\nstate that our constructions match the Gilbert--Varshamov-like bounds for\nseveral code parameters, e.g., BCH codes that contain all-one word by our first\nconstruction.",
    "descriptor": "\nComments: 18 pages, 9 Figures, 5 tables, and has been submitted to IEEE Transactions on Information Theory\n",
    "authors": [
      "Haider Al Kim",
      "Sven Puchinger",
      "Ludo Tolhuizen",
      "Antonia Wachter-Zeh"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.07541"
  },
  {
    "id": "arXiv:2202.07543",
    "title": "BLUE at Memotion 2.0 2022: You have my Image, my Text and my Transformer",
    "abstract": "Memes are prevalent on the internet and continue to grow and evolve alongside\nour culture. An automatic understanding of memes propagating on the internet\ncan shed light on the general sentiment and cultural attitudes of people. In\nthis work, we present team BLUE's solution for the second edition of the\nMEMOTION competition. We showcase two approaches for meme classification (i.e.\nsentiment, humour, offensive, sarcasm and motivation levels) using a text-only\nmethod using BERT, and a Multi-Modal-Multi-Task transformer network that\noperates on both the meme image and its caption to output the final scores. In\nboth approaches, we leverage state-of-the-art pretrained models for text (BERT,\nSentence Transformer) and image processing (EfficientNetV4, CLIP). Through our\nefforts, we obtain first place in task A, second place in task B and third\nplace in task C. In addition, our team obtained the highest average score for\nall three tasks.",
    "descriptor": "",
    "authors": [
      "Ana-Maria Bucur",
      "Adrian Cosma",
      "Ioan-Bogdan Iordache"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07543"
  },
  {
    "id": "arXiv:2202.07549",
    "title": "Robust Multi-Objective Bayesian Optimization Under Input Noise",
    "abstract": "Bayesian optimization (BO) is a sample-efficient approach for tuning design\nparameters to optimize expensive-to-evaluate, black-box performance metrics. In\nmany manufacturing processes, the design parameters are subject to random input\nnoise, resulting in a product that is often less performant than expected.\nAlthough BO methods have been proposed for optimizing a single objective under\ninput noise, no existing method addresses the practical scenario where there\nare multiple objectives that are sensitive to input perturbations. In this\nwork, we propose the first multi-objective BO method that is robust to input\nnoise. We formalize our goal as optimizing the multivariate value-at-risk\n(MVaR), a risk measure of the uncertain objectives. Since directly optimizing\nMVaR is computationally infeasible in many settings, we propose a scalable,\ntheoretically-grounded approach for optimizing MVaR using random\nscalarizations. Empirically, we find that our approach significantly\noutperforms alternative methods and efficiently identifies optimal robust\ndesigns that will satisfy specifications across multiple metrics with high\nprobability.",
    "descriptor": "\nComments: 35 pages. Code is available at this https URL\n",
    "authors": [
      "Samuel Daulton",
      "Sait Cakmak",
      "Maximilian Balandat",
      "Michael A. Osborne",
      "Enlu Zhou",
      "Eytan Bakshy"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.07549"
  },
  {
    "id": "arXiv:2202.07551",
    "title": "Fair Division of Indivisible Goods: A Survey",
    "abstract": "Allocating resources to individuals in a fair manner has been a topic of\ninterest since the ancient times, with most of the early rigorous mathematical\nwork on the problem focusing on infinitely divisible resources. Recently, there\nhas been a surge of papers studying computational questions regarding various\ndifferent notions of fairness for the indivisible case, like maximin share\nfairness (MMS) and envy-freeness up to any good (EFX). We survey the most\nimportant results in the discrete fair division literature, focusing on the\ncase of additive valuation functions and paying particular attention to the\nprogress made in the last 10 years.",
    "descriptor": "",
    "authors": [
      "Georgios Amanatidis",
      "Georgios Birmpas",
      "Aris Filos-Ratsikas",
      "Alexandros A. Voudouris"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2202.07551"
  },
  {
    "id": "arXiv:2202.07552",
    "title": "A Theory of PAC Learnability under Transformation Invariances",
    "abstract": "Transformation invariances are present in many real-world problems. For\nexample, image classification is usually invariant to rotation and color\ntransformation: a rotated car in a different color is still identified as a\ncar. Data augmentation, which adds the transformed data into the training set\nand trains a model on the augmented data, is one commonly used technique to\nbuild these invariances into the learning process. However, it is unclear how\ndata augmentation performs theoretically and what the optimal algorithm is in\npresence of transformation invariances. In this paper, we study PAC\nlearnability under transformation invariances in three settings according to\ndifferent levels of realizability: (i) A hypothesis fits the augmented data;\n(ii) A hypothesis fits only the original data and the transformed data lying in\nthe support of the data distribution; (iii) Agnostic case. One interesting\nobservation is that distinguishing between the original data and the\ntransformed data is necessary to achieve optimal accuracy in setting (ii) and\n(iii), which implies that any algorithm not differentiating between the\noriginal and transformed data (including data augmentation) is not optimal.\nFurthermore, this type of algorithms can even \"harm\" the accuracy. In setting\n(i), although it is unnecessary to distinguish between the two data sets, data\naugmentation still does not perform optimally. Due to such a difference, we\npropose two combinatorial measures characterizing the optimal sample complexity\nin setting (i) and (ii)(iii) and provide the optimal algorithms.",
    "descriptor": "",
    "authors": [
      "Han Shao",
      "Omar Montasser",
      "Avrim Blum"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07552"
  },
  {
    "id": "arXiv:2202.07553",
    "title": "On Deciding Feature Membership in Explanations of SDD & Related  Classifiers",
    "abstract": "When reasoning about explanations of Machine Learning (ML) classifiers, a\npertinent query is to decide whether some sensitive features can serve for\nexplaining a given prediction. Recent work showed that the feature membership\nproblem (FMP) is hard for $\\Sigma_2^P$ for a broad class of classifiers. In\ncontrast, this paper shows that for a number of families of classifiers, FMP is\nin NP. Concretely, the paper proves that any classifier for which an\nexplanation can be computed in polynomial time, then deciding feature\nmembership in an explanation can be decided with one NP oracle call. The paper\nthen proposes propositional encodings for classifiers represented with\nSentential Decision Diagrams (SDDs) and for other related propositional\nlanguages. The experimental results confirm the practical efficiency of the\nproposed approach.",
    "descriptor": "",
    "authors": [
      "Xuanxiang Huang",
      "Joao Marques-Silva"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07553"
  },
  {
    "id": "arXiv:2202.07554",
    "title": "Between Stochastic and Adversarial Online Convex Optimization: Improved  Regret Bounds via Smoothness",
    "abstract": "Stochastic and adversarial data are two widely studied settings in online\nlearning. But many optimization tasks are neither i.i.d. nor fully adversarial,\nwhich makes it of fundamental interest to get a better theoretical\nunderstanding of the world between these extremes. In this work we establish\nnovel regret bounds for online convex optimization in a setting that\ninterpolates between stochastic i.i.d. and fully adversarial losses. By\nexploiting smoothness of the expected losses, these bounds replace a dependence\non the maximum gradient length by the variance of the gradients, which was\npreviously known only for linear losses. In addition, they weaken the i.i.d.\nassumption by allowing adversarially poisoned rounds or shifts in the data\ndistribution. To accomplish this goal, we introduce two key quantities\nassociated with the loss sequence, that we call the cumulative stochastic\nvariance and the adversarial variation. Our upper bounds are attained by\ninstances of optimistic follow the regularized leader, and we design adaptive\nlearning rates that automatically adapt to the cumulative stochastic variance\nand adversarial variation. In the fully i.i.d. case, our bounds match the rates\none would expect from results in stochastic acceleration, and in the fully\nadversarial case they gracefully deteriorate to match the minimax regret. We\nfurther provide lower bounds showing that our regret upper bounds are tight for\nall intermediate regimes for the cumulative stochastic variance and the\nadversarial variation.",
    "descriptor": "",
    "authors": [
      "Sarah Sachs",
      "H\u00e9di Hadiji",
      "Tim van Erven",
      "Crist\u00f3bal Guzm\u00e1n"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.07554"
  },
  {
    "id": "arXiv:2202.07559",
    "title": "Unsupervised Learning of Group Invariant and Equivariant Representations",
    "abstract": "Equivariant neural networks, whose hidden features transform according to\nrepresentations of a group G acting on the data, exhibit training efficiency\nand an improved generalisation performance. In this work, we extend group\ninvariant and equivariant representation learning to the field of unsupervised\ndeep learning. We propose a general learning strategy based on an\nencoder-decoder framework in which the latent representation is disentangled in\nan invariant term and an equivariant group action component. The key idea is\nthat the network learns the group action on the data space and thus is able to\nsolve the reconstruction task from an invariant data representation, hence\navoiding the necessity of ad-hoc group-specific implementations. We derive the\nnecessary conditions on the equivariant encoder, and we present a construction\nvalid for any G, both discrete and continuous. We describe explicitly our\nconstruction for rotations, translations and permutations. We test the validity\nand the robustness of our approach in a variety of experiments with diverse\ndata types employing different network architectures.",
    "descriptor": "",
    "authors": [
      "Robin Winter",
      "Marco Bertolini",
      "Tuan Le",
      "Frank No\u00e9",
      "Djork-Arn\u00e9 Clevert"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07559"
  },
  {
    "id": "arXiv:2202.07565",
    "title": "CUP: A Conservative Update Policy Algorithm for Safe Reinforcement  Learning",
    "abstract": "Safe reinforcement learning (RL) is still very challenging since it requires\nthe agent to consider both return maximization and safe exploration. In this\npaper, we propose CUP, a Conservative Update Policy algorithm with a\ntheoretical safety guarantee. We derive the CUP based on the new proposed\nperformance bounds and surrogate functions. Although using bounds as surrogate\nfunctions to design safe RL algorithms have appeared in some existing works, we\ndevelop them at least three aspects: (i) We provide a rigorous theoretical\nanalysis to extend the surrogate functions to generalized advantage estimator\n(GAE). GAE significantly reduces variance empirically while maintaining a\ntolerable level of bias, which is an efficient step for us to design CUP; (ii)\nThe proposed bounds are tighter than existing works, i.e., using the proposed\nbounds as surrogate functions are better local approximations to the objective\nand safety constraints. (iii) The proposed CUP provides a non-convex\nimplementation via first-order optimizers, which does not depend on any convex\napproximation. Finally, extensive experiments show the effectiveness of CUP\nwhere the agent satisfies safe constraints. We have opened the source code of\nCUP at https://github.com/RL-boxes/Safe-RL.",
    "descriptor": "",
    "authors": [
      "Long Yang",
      "Jiaming Ji",
      "Juntao Dai",
      "Yu Zhang",
      "Pengfei Li",
      "Gang Pan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07565"
  },
  {
    "id": "arXiv:2202.07568",
    "title": "StratDef: a strategic defense against adversarial attacks in malware  detection",
    "abstract": "Over the years, most research towards defenses against adversarial attacks on\nmachine learning models has been in the image processing domain. The malware\ndetection domain has received less attention despite its importance. Moreover,\nmost work exploring defenses focuses on feature-based, gradient-based or\nrandomized methods but with no strategy when applying them. In this paper, we\nintroduce StratDef, which is a strategic defense system tailored for the\nmalware detection domain based on a Moving Target Defense and Game Theory\napproach. We overcome challenges related to the systematic construction,\nselection and strategic use of models to maximize adversarial robustness.\nStratDef dynamically and strategically chooses the best models to increase the\nuncertainty for the attacker, whilst minimizing critical aspects in the\nadversarial ML domain like attack transferability. We provide the first\ncomprehensive evaluation of defenses against adversarial attacks on machine\nlearning for malware detection, where our threat model explores different\nlevels of threat, attacker knowledge, capabilities, and attack intensities. We\nshow that StratDef performs better than other defenses even when facing the\npeak adversarial threat. We also show that, from the existing defenses, only a\nfew adversarially-trained models provide substantially better protection than\njust using vanilla models but are still outperformed by StratDef.",
    "descriptor": "",
    "authors": [
      "Aqib Rashid",
      "Jose Such"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07568"
  },
  {
    "id": "arXiv:2202.07569",
    "title": "Constant-weight PIR: Single-round Keyword PIR via Constant-weight  EqualityOperators",
    "abstract": "Equality operators are an essential building block in tasks over secure\ncomputation such as private information retrieval. In private information\nretrieval (PIR), a user queries a database such that the server does not learn\nwhich element is queried. In this work, we propose \\emph{equality operators for\nconstant-weight codewords}. A constant-weight code is a collection of codewords\nthat share the same Hamming weight. Constant-weight equality operators have a\nmultiplicative depth that depends only on the Hamming weight of the code, not\nthe bit-length of the elements. In our experiments, we show how these equality\noperators are up to 10 times faster than existing equality operators.\nFurthermore, we propose PIR using the constant-weight equality operator or\n\\emph{constant-weight PIR}, which is a PIR protocol using an approach\npreviously deemed impractical. We show that for private retrieval of large,\nstreaming data, constant-weight PIR has a smaller communication complexity and\nlower runtime compared to SEALPIR and MulPIR, respectively, which are two\nstate-of-the-art solutions for PIR. Moreover, we show how constant-weight PIR\ncan be extended to keyword PIR. In keyword PIR, the desired element is\nretrieved by a unique identifier pertaining to the sought item, e.g., the name\nof a file. Previous solutions to keyword PIR require one or multiple rounds of\ncommunication to reduce the problem to normal PIR. We show that constant-weight\nPIR is the first practical single-round solution to single-server keyword PIR.",
    "descriptor": "",
    "authors": [
      "Rasoul Akhavan Mahdavi",
      "Florian Kerschbaum"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.07569"
  },
  {
    "id": "arXiv:2202.07570",
    "title": "ScoreNet: Learning Non-Uniform Attention and Augmentation for  Transformer-Based Histopathological Image Classification",
    "abstract": "Progress in digital pathology is hindered by high-resolution images and the\nprohibitive cost of exhaustive localized annotations. The commonly used\nparadigm to categorize pathology images is patch-based processing, which often\nincorporates multiple instance learning (MIL) to aggregate local patch-level\nrepresentations yielding image-level prediction. Nonetheless, diagnostically\nrelevant regions may only take a small fraction of the whole tissue, and\nMIL-based aggregation operation assumes that all patch representations are\nindependent and thus mislays the contextual information from adjacent cell and\ntissue microenvironments. Consequently, the computational resources dedicated\nto a specific region are independent of its information contribution. This\npaper proposes a transformer-based architecture specifically tailored for\nhistopathological image classification, which combines fine-grained local\nattention with a coarse global attention mechanism to learn meaningful\nrepresentations of high-resolution images at an efficient computational cost.\nMore importantly, based on the observation above, we propose a novel\nmixing-based data-augmentation strategy, namely ScoreMix, by leveraging the\ndistribution of the semantic regions of images during the training and\ncarefully guiding the data mixing via sampling the locations of discriminative\nimage content. Thorough experiments and ablation studies on three challenging\nrepresentative cohorts of Haematoxylin & Eosin (H&E) tumour regions-of-interest\n(TRoIs) datasets have validated the superiority of our approach over existing\nstate-of-the-art methods and effectiveness of our proposed components, e.g.,\ndata augmentation in improving classification performance. We also demonstrate\nour method's interpretability, robustness, and cross-domain generalization\ncapability.",
    "descriptor": "\nComments: 17 pages, 7 figures\n",
    "authors": [
      "Thomas Stegm\u00fcller",
      "Antoine Spahr",
      "Behzad Bozorgtabar",
      "Jean-Philippe Thiran"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07570"
  },
  {
    "id": "arXiv:2202.07572",
    "title": "On Representation Learning with Feedback",
    "abstract": "This note complements the author's recent paper \"Robust representation\nlearning with feedback for single image deraining\" by providing heuristically\ntheoretical explanations on the mechanism of representation learning with\nfeedback, namely an essential merit of the works presented in this recent\narticle. This note facilitates understanding of key points in the mechanism of\nrepresentation learning with feedback.",
    "descriptor": "",
    "authors": [
      "Hao Li"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07572"
  },
  {
    "id": "arXiv:2202.07574",
    "title": "Damped Online Newton Step for Portfolio Selection",
    "abstract": "We revisit the classic online portfolio selection problem, where at each\nround a learner selects a distribution over a set of portfolios to allocate its\nwealth. It is known that for this problem a logarithmic regret with respect to\nCover's loss is achievable using the Universal Portfolio Selection algorithm,\nfor example. However, all existing algorithms that achieve a logarithmic regret\nfor this problem have per-round time and space complexities that scale\npolynomially with the total number of rounds, making them impractical. In this\npaper, we build on the recent work by Haipeng et al. 2018 and present the first\npractical online portfolio selection algorithm with a logarithmic regret and\nwhose per-round time and space complexities depend only logarithmically on the\nhorizon. Behind our approach are two key technical novelties of independent\ninterest. We first show that the Damped Online Newton steps can approximate\nmirror descent iterates well, even when dealing with time-varying regularizers.\nSecond, we present a new meta-algorithm that achieves an adaptive logarithmic\nregret (i.e. a logarithmic regret on any sub-interval) for mixable losses.",
    "descriptor": "",
    "authors": [
      "Zakaria Mhammedi",
      "Alexander Rakhlin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.07574"
  },
  {
    "id": "arXiv:2202.07577",
    "title": "Weighted Programming",
    "abstract": "We study weighted programming, a programming paradigm for specifying\nmathematical models. More specifically, the weighted programs we investigate\nare like usual imperative programs with two additional features: (1)\nnondeterministic branching and (2) weighting execution traces. Weights can be\nnumbers but also other objects like words from an alphabet, polynomials, formal\npower series, or cardinal numbers. We argue that weighted programming as a\nparadigm can be used to specify mathematical models beyond probability\ndistributions (as is done in probabilistic programming).\nWe develop weakest-precondition- and weakest-liberal-precondition-style\ncalculi \\`{a} la Dijkstra for reasoning about mathematical models specified by\nweighted programs. We present several case studies. For instance, we use\nweighted programming to model the ski rental problem - an optimization problem.\nWe model not only the optimization problem itself, but also the best\ndeterministic online algorithm for solving this problem as weighted programs.\nBy means of weakest-precondition-style reasoning, we can determine the\ncompetitive ratio of the online algorithm on source code level.",
    "descriptor": "\nComments: 69 pages\n",
    "authors": [
      "Kevin Batz",
      "Adrian Gallus",
      "Benjamin Lucien Kaminski",
      "Joost-Pieter Katoen",
      "Tobias Winkler"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.07577"
  },
  {
    "id": "arXiv:2202.07583",
    "title": "Crypto-ransomware detection using machine learning models in  file-sharing network scenario with encrypted traffic",
    "abstract": "Ransomware is considered as a significant threat for most enterprises since\nthe past few years. In scenarios wherein users can access all files on a shared\nserver, one infected host can lock the access to all shared files. We propose a\ntool to detect ransomware infection based on file-sharing traffic analysis. The\ntool monitors the traffic exchanged between the clients and the file servers\nand using machine learning techniques it searches for patterns in the traffic\nthat betray ransomware actions while reading and overwriting files. The\nproposal is designed to work for clear text and for encrypted file-sharing\nprotocols. We compare three machine learning models and choose the best for\nvalidation. We train and test the detection model using more than 70 ransomware\nbinaries from 26 different strains and more than 2500 hours of not infected\ntraffic from real users. The results reveal that the proposed tool can detect\nall ransomware binaries, including those not used in training phase (unseen).\nThis paper provides a validation of the algorithm by studying the false\npositive rate and the amount of information from user files that the ransomware\ncould encrypt before being detected.",
    "descriptor": "\nComments: 26 pages, 9 figures\n",
    "authors": [
      "Eduardo Berrueta",
      "Daniel Morato",
      "Eduardo Maga\u00f1a",
      "Mikel Izal"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2202.07583"
  },
  {
    "id": "arXiv:2202.07584",
    "title": "Multi-class granular approximation by means of disjoint and adjacent  fuzzy granules",
    "abstract": "In granular computing, fuzzy sets can be approximated by granularly\nrepresentable sets that are as close as possible to the original fuzzy set\nw.r.t. a given closeness measure. Such sets are called granular approximations.\nIn this article, we introduce the concepts of disjoint and adjacent granules\nand we examine how the new definitions affect the granular approximations.\nFirst, we show that the new concepts are important for binary classification\nproblems since they help to keep decision regions separated (disjoint granules)\nand at the same time to cover as much as possible of the attribute space\n(adjacent granules). Later, we consider granular approximations for multi-class\nclassification problems leading to the definition of a multi-class granular\napproximation. Finally, we show how to efficiently calculate multi-class\ngranular approximations for {\\L}ukasiewicz fuzzy connectives. We also provide\ngraphical illustrations for a better understanding of the introduced concepts.",
    "descriptor": "",
    "authors": [
      "Marko Palangeti\u0107",
      "Chris Cornelis",
      "Salvatore Greco",
      "Roman S\u0142owi\u0144ski"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07584"
  },
  {
    "id": "arXiv:2202.07586",
    "title": "Deep Generative model with Hierarchical Latent Factors for Time Series  Anomaly Detection",
    "abstract": "Multivariate time series anomaly detection has become an active area of\nresearch in recent years, with Deep Learning models outperforming previous\napproaches on benchmark datasets. Among reconstruction-based models, most\nprevious work has focused on Variational Autoencoders and Generative\nAdversarial Networks. This work presents DGHL, a new family of generative\nmodels for time series anomaly detection, trained by maximizing the observed\nlikelihood by posterior sampling and alternating back-propagation. A top-down\nConvolution Network maps a novel hierarchical latent space to time series\nwindows, exploiting temporal dynamics to encode information efficiently.\nDespite relying on posterior sampling, it is computationally more efficient\nthan current approaches, with up to 10x shorter training times than RNN based\nmodels. Our method outperformed current state-of-the-art models on four popular\nbenchmark datasets. Finally, DGHL is robust to variable features between\nentities and accurate even with large proportions of missing values, settings\nwith increasing relevance with the advent of IoT. We demonstrate the superior\nrobustness of DGHL with novel occlusion experiments in this literature. Our\ncode is available at https://github.com/cchallu/dghl.",
    "descriptor": "\nComments: accepted at AISTATS 2022\n",
    "authors": [
      "Cristian Challu",
      "Peihong Jiang",
      "Ying Nian Wu",
      "Laurent Callot"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07586"
  },
  {
    "id": "arXiv:2202.07587",
    "title": "Shifting Trends of COVID-19 Tweet Sentiment with Respect to Voting  Preferences in the 2020 Election Year of the United States",
    "abstract": "COVID-19 related policies were extensively politicized during the 2020\nelection year of the United States, resulting in polarizing viewpoints. Twitter\nusers were particularly engaged during the 2020 election year. Here we\ninvestigated whether COVID-19 related tweets were associated with the overall\nelection results at the state level during the period leading up to the\nelection day. We observed weak correlations between the average sentiment of\nCOVID-19 related tweets and popular votes in two-week intervals, and the trends\ngradually become opposite. We then compared the average sentiments of COVID-19\nrelated tweets between states called in favor of Republican (red states) or\nDemocratic parties (blue states). We found that at the beginning of lockdowns\nsentiments in the blue states were much more positive than those in the red\nstates. However, sentiments in the red states gradually become more positive\nduring the summer of 2020 and persisted until the election day.",
    "descriptor": "\nComments: 4 pages, 3 figures\n",
    "authors": [
      "Megan Doman",
      "Jacob Motley",
      "Hong Qin",
      "Mengjun Xie",
      "Li Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.07587"
  },
  {
    "id": "arXiv:2202.07591",
    "title": "Enhancing Healthcare System Using Blockchain Smart Contracts",
    "abstract": "The concept of blockchain has emerged as an effective solution for\ndata-sensitive domains, such as healthcare, financial services, etc., due to\nits various attributes like immutability, non-repudiation, and availability.\nThus, implementation of this technology in various domains rose exponentially;\none of such fields is the healthcare supply chain. Managing healthcare supply\nchain processes effectively is very crucial for the healthcare system. Despite\nvarious innovations in the method of treatment methodologies, the healthcare\nsupply chain management system is not up to the mark and lacks efficiency. The\ntraditional healthcare supply chain system is time-consuming and lacks the work\nsynergy among the various stakeholders of the supply chain. Thus, In this\npaper, we propose a framework based on blockchain smart contracts and\ndecentralized storage to connect all the supply chain stakeholders. Smart\ncontracts in the framework enforce and depict various interactions and\ntransactions among the stakeholders, thus helping to automate these processes,\npromote transparency, improve efficiency, and minimize service time. The\npreliminary results show that the proposed framework is more efficient, secure,\nand economically feasible.",
    "descriptor": "",
    "authors": [
      "Shashank Joshi",
      "Arhan Choudhury",
      "Ojas Saraswat"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.07591"
  },
  {
    "id": "arXiv:2202.07592",
    "title": "Deep Convolutional Autoencoder for Assessment of Anomalies in  Multi-stream Sensor Data",
    "abstract": "A fully convolutional autoencoder is developed for the detection of anomalies\nin multi-sensor vehicle drive-cycle data from the powertrain domain.\nPreliminary results collected on real-world powertrain data show that the\nreconstruction error of faulty drive cycles deviates significantly relative to\nthe reconstruction of healthy drive cycles using the trained autoencoder. The\nresults demonstrate applicability for identifying faulty drive-cycles, and for\nimproving the accuracy of system prognosis and predictive maintenance in\nconnected vehicles.",
    "descriptor": "\nComments: 7 pages, 4 figures, IEEE\n",
    "authors": [
      "Anthony Geglio",
      "Eisa Hedayati",
      "Mark Tascillo",
      "Dyche Anderson",
      "Jonathan Barker",
      "Timothy C. Havens"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.07592"
  },
  {
    "id": "arXiv:2202.07593",
    "title": "The dependency of spectral gaps on the convergence of the inverse  iteration for a nonlinear eigenvector problem",
    "abstract": "In this paper we consider the generalized inverse iteration for computing\nground states of the Gross-Pitaevskii eigenvector problem (GPE). For that we\nprove explicit linear convergence rates that depend on the maximum eigenvalue\nin magnitude of a weighted linear eigenvalue problem. Furthermore, we show that\nthis eigenvalue can be bounded by the first spectral gap of a linearized\nGross-Pitaevskii operator, recovering the same rates as for linear eigenvector\nproblems. With this we establish the first local convergence result for the\nbasic inverse iteration for the GPE without damping. We also show how our\nfindings directly generalize to extended inverse iterations, such as the\nGradient Flow Discrete Normalized (GFDN) proposed in [W. Bao, Q. Du, SIAM J.\nSci. Comput., 25 (2004)] or the damped inverse iteration suggested in [P.\nHenning, D. Peterseim, SIAM J. Numer. Anal., 53 (2020)]. Our analysis also\nreveals why the inverse iteration for the GPE does not react favourably to\nspectral shifts. This empirical observation can now be explained with a blow-up\nof a weighting function that crucially contributes to the convergence rates.\nOur findings are illustrated by numerical experiments.",
    "descriptor": "",
    "authors": [
      "Patrick Henning"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.07593"
  },
  {
    "id": "arXiv:2202.07595",
    "title": "Bayesian Optimisation for Active Monitoring of Air Pollution",
    "abstract": "Air pollution is one of the leading causes of mortality globally, resulting\nin millions of deaths each year. Efficient monitoring is important to measure\nexposure and enforce legal limits. New low-cost sensors can be deployed in\ngreater numbers and in more varied locations, motivating the problem of\nefficient automated placement. Previous work suggests Bayesian optimisation is\nan appropriate method, but only considered a satellite data set, with data\naggregated over all altitudes. It is ground-level pollution, that humans\nbreathe, which matters most. We improve on those results using hierarchical\nmodels and evaluate our models on urban pollution data in London to show that\nBayesian optimisation can be successfully applied to the problem.",
    "descriptor": "\nComments: To be presented at AAAI 2022 in the Special Track on AI for Social Impact\n",
    "authors": [
      "Sigrid Passano Hellan",
      "Christopher G. Lucas",
      "Nigel H. Goddard"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Atmospheric and Oceanic Physics (physics.ao-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.07595"
  },
  {
    "id": "arXiv:2202.07596",
    "title": "A General Framework for Modelling Conditional Reasoning -- Preliminary  Report",
    "abstract": "We introduce and investigate here a formalisation for conditionals that\nallows the definition of a broad class of reasoning systems. This framework\ncovers the most popular kinds of conditional reasoning in logic-based KR: the\nsemantics we propose is appropriate for a structural analysis of those\nconditionals that do not satisfy closure properties associated to classical\nlogics.",
    "descriptor": "\nComments: 21 pages, 2 figures\n",
    "authors": [
      "Giovanni Casini",
      "Umberto Straccia"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07596"
  },
  {
    "id": "arXiv:2202.07600",
    "title": "Bayesian Imitation Learning for End-to-End Mobile Manipulation",
    "abstract": "In this work we investigate and demonstrate benefits of a Bayesian approach\nto imitation learning from multiple sensor inputs, as applied to the task of\nopening office doors with a mobile manipulator. Augmenting policies with\nadditional sensor inputs, such as RGB + depth cameras, is a straightforward\napproach to improving robot perception capabilities, especially for tasks that\nmay favor different sensors in different situations. As we scale multi-sensor\nrobotic learning to unstructured real-world settings (e.g. offices, homes) and\nmore complex robot behaviors, we also increase reliance on simulators for cost,\nefficiency, and safety. Consequently, the sim-to-real gap across multiple\nsensor modalities also increases, making simulated validation more difficult.\nWe show that using the Variational Information Bottleneck (Alemi et al., 2016)\nto regularize convolutional neural networks improves generalization to held-out\ndomains and reduces the sim-to-real gap in a sensor-agnostic manner. As a side\neffect, the learned embeddings also provide useful estimates of model\nuncertainty for each sensor. We demonstrate that our method is able to help\nclose the sim-to-real gap and successfully fuse RGB and depth modalities based\non understanding of the situational uncertainty of each sensor. In a real-world\noffice environment, we achieve 96% task success, improving upon the baseline by\n+16%.",
    "descriptor": "",
    "authors": [
      "Yuqing Du",
      "Daniel Ho",
      "Alexander A. Alemi",
      "Eric Jang",
      "Mohi Khansari"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07600"
  },
  {
    "id": "arXiv:2202.07602",
    "title": "Accelerating the convergence of Dynamic Iteration method with Restricted  Additive Schwarz splitting for the solution of RLC circuits",
    "abstract": "The dynamic iteration method with a restricted additive Schwarz splitting is\ninvestigated to co-simulate linear differential algebraic equations system\ncoming from RLC electrical circuit with linear components. We show the pure\nlinear convergence or divergence of the method with respect to the linear\noperator belonging to the restricted additive Schwarz interface. It allows us\nto accelerate it toward the true solution with the Aitken's technique for\naccelerating convergence. This provides a dynamic iteration method less\nsensitive to the splitting. Numerical examples with convergent and divergent\nsplitting show the efficiency of the proposed approach. We also test it on a\nlinear RLC circuit combining different types of circuit modeling (Transient\nStability model and Electro-Magnetic Transient model) with overlapping\npartitions. Finally, some results for a weakly nonlinear differential algebraic\nequations system are also provided.",
    "descriptor": "\nComments: 16 pages, 7 figures, 1 table\n",
    "authors": [
      "Helena Shourick",
      "Damien Tromeur-Dervout",
      "Laurent Chedot"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.07602"
  },
  {
    "id": "arXiv:2202.07603",
    "title": "Fairness Indicators for Systematic Assessments of Visual Feature  Extractors",
    "abstract": "Does everyone equally benefit from computer vision systems? Answers to this\nquestion become more and more important as computer vision systems are deployed\nat large scale, and can spark major concerns when they exhibit vast performance\ndiscrepancies between people from various demographic and social backgrounds.\nSystematic diagnosis of fairness, harms, and biases of computer vision systems\nis an important step towards building socially responsible systems. To initiate\nan effort towards standardized fairness audits, we propose three fairness\nindicators, which aim at quantifying harms and biases of visual systems. Our\nindicators use existing publicly available datasets collected for fairness\nevaluations, and focus on three main types of harms and bias identified in the\nliterature, namely harmful label associations, disparity in learned\nrepresentations of social and demographic traits, and biased performance on\ngeographically diverse images from across the world.We define precise\nexperimental protocols applicable to a wide range of computer vision models.\nThese indicators are part of an ever-evolving suite of fairness probes and are\nnot intended to be a substitute for a thorough analysis of the broader impact\nof the new computer vision technologies. Yet, we believe it is a necessary\nfirst step towards (1) facilitating the widespread adoption and mandate of the\nfairness assessments in computer vision research, and (2) tracking progress\ntowards building socially responsible models. To study the practical\neffectiveness and broad applicability of our proposed indicators to any visual\nsystem, we apply them to off-the-shelf models built using widely adopted model\ntraining paradigms which vary in their ability to whether they can predict\nlabels on a given image or only produce the embeddings. We also systematically\nstudy the effect of data domain and model size.",
    "descriptor": "",
    "authors": [
      "Priya Goyal",
      "Adriana Romero Soriano",
      "Caner Hazirbas",
      "Levent Sagun",
      "Nicolas Usunier"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.07603"
  },
  {
    "id": "arXiv:2202.07605",
    "title": "UserBERT: Modeling Long- and Short-Term User Preferences via  Self-Supervision",
    "abstract": "E-commerce platforms generate vast amounts of customer behavior data, such as\nclicks and purchases, from millions of unique users every day. However,\neffectively using this data for behavior understanding tasks is challenging\nbecause there are usually not enough labels to learn from all users in a\nsupervised manner. This paper extends the BERT model to e-commerce user data\nfor pre-training representations in a self-supervised manner. By viewing user\nactions in sequences as analogous to words in sentences, we extend the existing\nBERT model to user behavior data. Further, our model adopts a unified structure\nto simultaneously learn from long-term and short-term user behavior, as well as\nuser attributes. We propose methods for the tokenization of different types of\nuser behavior sequences, the generation of input representation vectors, and a\nnovel pretext task to enable the pre-trained model to learn from its own input,\neliminating the need for labeled training data. Extensive experiments\ndemonstrate that the learned representations result in significant improvements\nwhen transferred to three different real-world tasks, particularly compared to\ntask-specific modeling and multi-task representation learning",
    "descriptor": "",
    "authors": [
      "Tianyu Li",
      "Ali Cevahir",
      "Derek Cho",
      "Hao Gong",
      "DuyKhuong Nguyen",
      "Bjorn Stenger"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07605"
  },
  {
    "id": "arXiv:2202.07606",
    "title": "Improving Pedestrian Prediction Models with Self-Supervised Continual  Learning",
    "abstract": "Autonomous mobile robots require accurate human motion predictions to safely\nand efficiently navigate among pedestrians, whose behavior may adapt to\nenvironmental changes. This paper introduces a self-supervised continual\nlearning framework to improve data-driven pedestrian prediction models online\nacross various scenarios continuously. In particular, we exploit online streams\nof pedestrian data, commonly available from the robot's detection and tracking\npipeline, to refine the prediction model and its performance in unseen\nscenarios. To avoid the forgetting of previously learned concepts, a problem\nknown as catastrophic forgetting, our framework includes a regularization loss\nto penalize changes of model parameters that are important for previous\nscenarios and retrains on a set of previous examples to retain past knowledge.\nExperimental results on real and simulation data show that our approach can\nimprove prediction performance in unseen scenarios while retaining knowledge\nfrom seen scenarios when compared to naively training the prediction model\nonline.",
    "descriptor": "\nComments: To be published in IEEE Robotics and Automation Letters. Accepted for presentation at 2022 IEEE International Conference on Robotics and Automation (ICRA)\n",
    "authors": [
      "Luzia Knoedler",
      "Chadi Salmi",
      "Hai Zhu",
      "Bruno Brito",
      "Javier Alonso-Mora"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.07606"
  },
  {
    "id": "arXiv:2202.07612",
    "title": "CodeGen-Test: An Automatic Code Generation Model Integrating Program  Test Information",
    "abstract": "Automatic code generation is to generate the program code according to the\ngiven natural language description. The current mainstream approach uses neural\nnetworks to encode natural language descriptions, and output abstract syntax\ntrees (AST) at the decoder, then convert the AST into program code. While the\ngenerated code largely conforms to specific syntax rules, two problems are\nstill ignored. One is missing program testing, an essential step in the process\nof complete code implementation; the other is only focusing on the syntax\ncompliance of the generated code, while ignoring the more important program\nfunctional requirements. The paper proposes a CodeGen-Test model, which adds\nprogram testing steps and incorporates program testing information to\niteratively generate code that meets the functional requirements of the\nprogram, thereby improving the quality of code generation. At the same time,\nthe paper proposes a new evaluation metric, test accuracy (Test-Acc), which\nrepresents the proportion of passing program test in generated code. Different\nfrom the previous evaluation metric, which only evaluates the quality of code\ngeneration from the perspective of character similarity, the Test-Acc can\nevaluate the quality of code generation from the Program functions. Moreover,\nthe paper evaluates the CodeGen-test model on a python data set \"hearthstone\nlegend\". The experimental results show the proposed method can effectively\nimprove the quality of generated code. Compared with the existing optimal\nmodel, CodeGen-Test model improves the Bleu value by 0.2%, Rouge-L value by\n0.3% and Test-Acc by 6%.",
    "descriptor": "\nComments: 10 paper pages, 7 figures; 2 appendix pages, 5 appendix figures\n",
    "authors": [
      "Maosheng Zhong",
      "Gen Liu",
      "Hongwei Li",
      "Jiangling Kuang",
      "Jinshan Zeng",
      "Mingwen Wang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.07612"
  },
  {
    "id": "arXiv:2202.07614",
    "title": "Judging a socially assistive robot (SAR) by its cover; The effect of  body structure, outline, and color on users' perception",
    "abstract": "Human-SAR (socially assistive robot) relationships vary by the context of use\nand interaction level. We argue that context and interaction considerations\nmust be incorporated into the SAR's physical design requirements to align the\nrobotic visual qualities (VQs) with users' expectations. We propose to consider\nsituational-based and dynamics-based human-SAR relationship models in\nconstructing the requirements. Previous studies contributed to the\nunderstanding of users` perceptions and preferences regarding existing\ncommercially available SARs. Yet, very few studies regarding SARs' appearance\nused designated SAR designs, and even fewer evaluated isolated visual features.\nIn this work, we aim to systematically assess the effect of isolated VQs. To\nachieve this, we first deconstruct the VQs attributed to SARs. Then, a\nreconstruction of body structure, outline, and color scheme was done, resulting\nin the creation of 30 new SAR models that differ in their VQs, allowing us to\nisolate one character at a time. We used these new designs to evaluate users'\npreferences and perceptions in two empirical studies. Our empirical findings\nlink visual qualities with perceptions of SAR characteristics. Together with\nthe relationship models, the outcomes are an exemplar of how to form guidelines\nfor the industrial design processes of new SARs to match user expectations.",
    "descriptor": "\nComments: Submitted to Transactions on Human-Robot Interaction\n",
    "authors": [
      "Ela Liberman-Pincu",
      "Yisrael Parmet",
      "Tal Oron-Gilad"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.07614"
  },
  {
    "id": "arXiv:2202.07615",
    "title": "PILED: An Identify-and-Localize Framework for Few-Shot Event Detection",
    "abstract": "Practical applications of event extraction systems have long been hindered by\ntheir need for heavy human annotation. In order to scale up to new domains and\nevent types, models must learn to cope with limited supervision, as in few-shot\nlearning settings. To this end, the major challenge is to let the model master\nthe semantics of event types, without requiring abundant event mention\nannotations. In our study, we employ cloze prompts to elicit event-related\nknowledge from pretrained language models and further use event definitions and\nkeywords to pinpoint the trigger word. By formulating the event detection task\nas an identify-then-localize procedure, we minimize the number of type-specific\nparameters, enabling our model to quickly adapt to event detection tasks for\nnew types. Experiments on three event detection benchmark datasets (ACE,\nFewEvent, MAVEN) show that our proposed method performs favorably under fully\nsupervised settings and surpasses existing few-shot methods by 21% F1 on the\nFewEvent dataset and 20% on the MAVEN dataset when only 5 examples are provided\nfor each event type.",
    "descriptor": "\nComments: 12 pages\n",
    "authors": [
      "Sha Li",
      "Liyuan Liu",
      "Yiqing Xie",
      "Heng Ji",
      "Jiawei Han"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07615"
  },
  {
    "id": "arXiv:2202.07623",
    "title": "Defending against Reconstruction Attacks with R\u00e9nyi Differential  Privacy",
    "abstract": "Reconstruction attacks allow an adversary to regenerate data samples of the\ntraining set using access to only a trained model. It has been recently shown\nthat simple heuristics can reconstruct data samples from language models,\nmaking this threat scenario an important aspect of model release. Differential\nprivacy is a known solution to such attacks, but is often used with a\nrelatively large privacy budget (epsilon > 8) which does not translate to\nmeaningful guarantees. In this paper we show that, for a same mechanism, we can\nderive privacy guarantees for reconstruction attacks that are better than the\ntraditional ones from the literature. In particular, we show that larger\nprivacy budgets do not protect against membership inference, but can still\nprotect extraction of rare secrets. We show experimentally that our guarantees\nhold against various language models, including GPT-2 finetuned on\nWikitext-103.",
    "descriptor": "",
    "authors": [
      "Pierre Stock",
      "Igor Shilov",
      "Ilya Mironov",
      "Alexandre Sablayrolles"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Cryptography and Security (cs.CR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.07623"
  },
  {
    "id": "arXiv:2202.07626",
    "title": "Random Feature Amplification: Feature Learning and Generalization in  Neural Networks",
    "abstract": "In this work, we provide a characterization of the feature-learning process\nin two-layer ReLU networks trained by gradient descent on the logistic loss\nfollowing random initialization. We consider data with binary labels that are\ngenerated by an XOR-like function of the input features. We permit a constant\nfraction of the training labels to be corrupted by an adversary. We show that,\nalthough linear classifiers are no better than random guessing for the\ndistribution we consider, two-layer ReLU networks trained by gradient descent\nachieve generalization error close to the label noise rate, refuting the\nconjecture of Malach and Shalev-Shwartz that 'deeper is better only when\nshallow is good'. We develop a novel proof technique that shows that at\ninitialization, the vast majority of neurons function as random features that\nare only weakly correlated with useful features, and the gradient descent\ndynamics 'amplify' these weak, random features to strong, useful features.",
    "descriptor": "\nComments: 41 pages\n",
    "authors": [
      "Spencer Frei",
      "Niladri S. Chatterji",
      "Peter L. Bartlett"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.07626"
  },
  {
    "id": "arXiv:2202.07629",
    "title": "Deciding What is Good-for-MDPs",
    "abstract": "Nondeterministic Good-for-MDP (GFM) automata are for MDP model checking and\nreinforcement learning what good-for-games automata are for synthesis: a more\ncompact alternative to deterministic automata that displays nondeterminism, but\nonly so much that it can be resolved locally, such that a syntactic product can\nbe analysed. GFM has recently been introduced as a property for reinforcement\nlearning, where the simpler B\\\"uchi acceptance conditions it allows to use is\nkey. However, while there are classic and novel techniques to obtain automata\nthat are GFM, there has not been a decision procedure for checking whether or\nnot an automaton is GFM. We show that GFM-ness is decidable and provide an\nEXPTIME decision procedure as well as a PSPACE-hardness proof.",
    "descriptor": "\nComments: 17 pages (excluding references)\n",
    "authors": [
      "Sven Schewe",
      "Qiyi Tang",
      "Tansholpan Zhanabekova"
    ],
    "subjectives": [
      "Formal Languages and Automata Theory (cs.FL)"
    ],
    "url": "https://arxiv.org/abs/2202.07629"
  },
  {
    "id": "arXiv:2202.07630",
    "title": "Delving Deeper into Cross-lingual Visual Question Answering",
    "abstract": "Visual question answering (VQA) is one of the crucial vision-and-language\ntasks. Yet, the bulk of research until recently has focused only on the English\nlanguage due to the lack of appropriate evaluation resources. Previous work on\ncross-lingual VQA has reported poor zero-shot transfer performance of current\nmultilingual multimodal Transformers and large gaps to monolingual performance,\nattributed mostly to misalignment of text embeddings between the source and\ntarget languages, without providing any additional deeper analyses. In this\nwork, we delve deeper and address different aspects of cross-lingual VQA\nholistically, aiming to understand the impact of input data, fine-tuning and\nevaluation regimes, and interactions between the two modalities in\ncross-lingual setups. 1) We tackle low transfer performance via novel methods\nthat substantially reduce the gap to monolingual English performance, yielding\n+10 accuracy points over existing transfer methods. 2) We study and dissect\ncross-lingual VQA across different question types of varying complexity, across\ndifferent multilingual multi-modal Transformers, and in zero-shot and few-shot\nscenarios. 3) We further conduct extensive analyses on modality biases in\ntraining data and models, aimed to further understand why zero-shot performance\ngaps remain for some question types and languages. We hope that the novel\nmethods and detailed analyses will guide further progress in multilingual VQA.",
    "descriptor": "",
    "authors": [
      "Chen Liu",
      "Jonas Pfeiffer",
      "Anna Korhonen",
      "Ivan Vulic",
      "Iryna Gurevych"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07630"
  },
  {
    "id": "arXiv:2202.07631",
    "title": "One Configuration to Rule Them All? Towards Hyperparameter Transfer in  Topic Models using Multi-Objective Bayesian Optimization",
    "abstract": "Topic models are statistical methods that extract underlying topics from\ndocument collections. When performing topic modeling, a user usually desires\ntopics that are coherent, diverse between each other, and that constitute good\ndocument representations for downstream tasks (e.g. document classification).\nIn this paper, we conduct a multi-objective hyperparameter optimization of\nthree well-known topic models. The obtained results reveal the conflicting\nnature of different objectives and that the training corpus characteristics are\ncrucial for the hyperparameter selection, suggesting that it is possible to\ntransfer the optimal hyperparameter configurations between datasets.",
    "descriptor": "\nComments: 17 pages, 7 figures\n",
    "authors": [
      "Silvia Terragni",
      "Ismail Harrando",
      "Pasquale Lisena",
      "Raphael Troncy",
      "Elisabetta Fersini"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07631"
  },
  {
    "id": "arXiv:2202.07632",
    "title": "Wireless Resource Management in Intelligent Semantic Communication  Networks",
    "abstract": "The prosperity of artificial intelligence (AI) has laid a promising paradigm\nof communication system, i.e., intelligent semantic communication (ISC), where\nsemantic contents, instead of traditional bit sequences, are coded by AI models\nfor efficient communication. Due to the unique demand of background knowledge\nfor semantic recovery, wireless resource management faces new challenges in\nISC. In this paper, we address the user association (UA) and bandwidth\nallocation (BA) problems in an ISC-enabled heterogeneous network (ISC-HetNet).\nWe first introduce the auxiliary knowledge base (KB) into the system model, and\ndevelop a new performance metric for the ISC-HetNet, named system throughput in\nmessage (STM). Joint optimization of UA and BA is then formulated with the aim\nof STM maximization subject to KB matching and wireless bandwidth constraints.\nTo this end, we propose a two-stage solution, including a stochastic\nprogramming method in the first stage to obtain a deterministic objective with\nsemantic confidence, and a heuristic algorithm in the second stage to reach the\noptimality of UA and BA. Numerical results show great superiority and\nreliability of our proposed solution on the STM performance when compared with\ntwo baseline algorithms.",
    "descriptor": "\nComments: This work has been accepted for publication by 2022 IEEE International Conference on Computer Communications (INFOCOM). Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Le Xia",
      "Yao Sun",
      "Xiaoqian Li",
      "Gang Feng",
      "Muhammad Ali Imran"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Artificial Intelligence (cs.AI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.07632"
  },
  {
    "id": "arXiv:2202.07636",
    "title": "On Dynamic Lifting and Effect Typing in Circuit Description Languages  (Extended Version)",
    "abstract": "In the realm of quantum computing, circuit description languages represent a\nvalid alternative to traditional QRAM-style languages. They indeed allow for\nfiner control over the output circuit, without sacrificing flexibility nor\nmodularity. We introduce a generalization of the paradigmatic lambda-calculus\nProto-Quipper-M, itself modeling the core features of the quantum circuit\ndescription language Quipper. The extension, called Proto-Quipper-K, is meant\nto capture a very general form of dynamic lifting. This is made possible by the\nintroduction of a rich type and effect system in which not only computations,\nbut also the very types are effectful. The main results we give for the\nintroduced language are the classic type soundness results, namely subject\nreduction and progress.",
    "descriptor": "\nComments: 26 pages, 21 figures\n",
    "authors": [
      "Andrea Colledan",
      "Ugo Dal Lago"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Logic in Computer Science (cs.LO)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.07636"
  },
  {
    "id": "arXiv:2202.07638",
    "title": "On the design of scalable networks to reject polynomial disturbances",
    "abstract": "This paper is concerned with the problem of designing distributed control\nprotocols for network systems affected by delays and disturbances consisting of\na polynomial component and a residual signal. We propose the use of a multiplex\narchitecture to design distributed control protocols to reject polynomial\ndisturbances up to ramps and guarantee a scalability property that prohibits\nthe amplification of residual disturbances. For this architecture, we give a\ndelay-independent sufficient condition on the control protocols to guarantee\nscalability and ramps rejection. The effectiveness of the result, which can be\nused to study networks of nonlinearly coupled nonlinear agents, is illustrated\nvia a robot formation control problem.",
    "descriptor": "",
    "authors": [
      "Shihao Xie",
      "Giovanni Russo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.07638"
  },
  {
    "id": "arXiv:2202.07643",
    "title": "Lie Point Symmetry Data Augmentation for Neural PDE Solvers",
    "abstract": "Neural networks are increasingly being used to solve partial differential\nequations (PDEs), replacing slower numerical solvers. However, a critical issue\nis that neural PDE solvers require high-quality ground truth data, which\nusually must come from the very solvers they are designed to replace. Thus, we\nare presented with a proverbial chicken-and-egg problem. In this paper, we\npresent a method, which can partially alleviate this problem, by improving\nneural PDE solver sample complexity -- Lie point symmetry data augmentation\n(LPSDA). In the context of PDEs, it turns out that we are able to\nquantitatively derive an exhaustive list of data transformations, based on the\nLie point symmetry group of the PDEs in question, something not possible in\nother application areas. We present this framework and demonstrate how it can\neasily be deployed to improve neural PDE solver sample complexity by an order\nof magnitude.",
    "descriptor": "",
    "authors": [
      "Johannes Brandstetter",
      "Max Welling",
      "Daniel E. Worrall"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07643"
  },
  {
    "id": "arXiv:2202.07645",
    "title": "Towards a maturity model for crypto-agility assessment",
    "abstract": "This work proposes the Crypto-Agility Maturity Model (CAMM for short), a\nmaturity model for determining the state of crypto-agility of a given software\nor IT landscape. CAMM consists of five levels, for each level a set of\nrequirements have been formulated based on literature review. Initial feedback\nfrom field experts confirms that CAMM has a well-designed structure and is easy\nto comprehend. Based on our model, the crytographic agility of an IT landscape\ncan be systematically measured and improved step by step. We expect that this\nwill enable companies and to respond better and faster to threats resulting\nfrom broken cryptographic schemes. This work serves to promote CAMM and\nencourage others to apply it in practice and develop it jointly.",
    "descriptor": "",
    "authors": [
      "Julian Hohm",
      "Andreas Heinemann",
      "Alexander Wiesmaier"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.07645"
  },
  {
    "id": "arXiv:2202.07646",
    "title": "Quantifying Memorization Across Neural Language Models",
    "abstract": "Large language models (LMs) have been shown to memorize parts of their\ntraining data, and when prompted appropriately, they will emit the memorized\ntraining data verbatim. This is undesirable because memorization violates\nprivacy (exposing user data), degrades utility (repeated easy-to-memorize text\nis often low quality), and hurts fairness (some texts are memorized over\nothers).\nWe describe three log-linear relationships that quantify the degree to which\nLMs emit memorized training data. Memorization significantly grows as we\nincrease (1) the capacity of a model, (2) the number of times an example has\nbeen duplicated, and (3) the number of tokens of context used to prompt the\nmodel. Surprisingly, we find the situation becomes complicated when\ngeneralizing these results across model families. On the whole, we find that\nmemorization in LMs is more prevalent than previously believed and will likely\nget worse as models continues to scale, at least without active mitigations.",
    "descriptor": "",
    "authors": [
      "Nicholas Carlini",
      "Daphne Ippolito",
      "Matthew Jagielski",
      "Katherine Lee",
      "Florian Tramer",
      "Chiyuan Zhang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07646"
  },
  {
    "id": "arXiv:2202.07648",
    "title": "EvoKG: Jointly Modeling Event Time and Network Structure for Reasoning  over Temporal Knowledge Graphs",
    "abstract": "How can we perform knowledge reasoning over temporal knowledge graphs (TKGs)?\nTKGs represent facts about entities and their relations, where each fact is\nassociated with a timestamp. Reasoning over TKGs, i.e., inferring new facts\nfrom time-evolving KGs, is crucial for many applications to provide intelligent\nservices. However, despite the prevalence of real-world data that can be\nrepresented as TKGs, most methods focus on reasoning over static knowledge\ngraphs, or cannot predict future events. In this paper, we present a problem\nformulation that unifies the two major problems that need to be addressed for\nan effective reasoning over TKGs, namely, modeling the event time and the\nevolving network structure. Our proposed method EvoKG jointly models both tasks\nin an effective framework, which captures the ever-changing structural and\ntemporal dynamics in TKGs via recurrent event modeling, and models the\ninteractions between entities based on the temporal neighborhood aggregation\nframework. Further, EvoKG achieves an accurate modeling of event time, using\nflexible and efficient mechanisms based on neural density estimation.\nExperiments show that EvoKG outperforms existing methods in terms of\neffectiveness (up to 77% and 116% more accurate time and link prediction) and\nefficiency.",
    "descriptor": "\nComments: WSDM 2022\n",
    "authors": [
      "Namyong Park",
      "Fuchen Liu",
      "Purvanshi Mehta",
      "Dana Cristofor",
      "Christos Faloutsos",
      "Yuxiao Dong"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2202.07648"
  },
  {
    "id": "arXiv:2202.07650",
    "title": "Conformal Prediction Sets with Limited False Positives",
    "abstract": "We develop a new approach to multi-label conformal prediction in which we aim\nto output a precise set of promising prediction candidates with a bounded\nnumber of incorrect answers. Standard conformal prediction provides the ability\nto adapt to model uncertainty by constructing a calibrated candidate set in\nplace of a single prediction, with guarantees that the set contains the correct\nanswer with high probability. In order to obey this coverage property, however,\nconformal sets can become inundated with noisy candidates -- which can render\nthem unhelpful in practice. This is particularly relevant to practical\napplications where there is a limited budget, and the cost (monetary or\notherwise) associated with false positives is non-negligible. We propose to\ntrade coverage for a notion of precision by enforcing that the presence of\nincorrect candidates in the predicted conformal sets (i.e., the total number of\nfalse positives) is bounded according to a user-specified tolerance. Subject to\nthis constraint, our algorithm then optimizes for a generalized notion of set\ncoverage (i.e., the true positive rate) that allows for any number of true\nanswers for a given query (including zero). We demonstrate the effectiveness of\nthis approach across a number of classification tasks in natural language\nprocessing, computer vision, and computational chemistry.",
    "descriptor": "",
    "authors": [
      "Adam Fisch",
      "Tal Schuster",
      "Tommi Jaakkola",
      "Regina Barzilay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07650"
  },
  {
    "id": "arXiv:2202.07652",
    "title": "Predicting on the Edge: Identifying Where a Larger Model Does Better",
    "abstract": "Much effort has been devoted to making large and more accurate models, but\nrelatively little has been put into understanding which examples are benefiting\nfrom the added complexity. In this paper, we demonstrate and analyze the\nsurprisingly tight link between a model's predictive uncertainty on individual\nexamples and the likelihood that larger models will improve prediction on them.\nThrough extensive numerical studies on the T5 encoder-decoder architecture, we\nshow that large models have the largest improvement on examples where the small\nmodel is most uncertain. On more certain examples, even those where the small\nmodel is not particularly accurate, large models are often unable to improve at\nall, and can even perform worse than the smaller model. Based on these\nfindings, we show that a switcher model which defers examples to a larger model\nwhen a small model is uncertain can achieve striking improvements in\nperformance and resource usage. We also explore committee-based uncertainty\nmetrics that can be more effective but less practical.",
    "descriptor": "",
    "authors": [
      "Taman Narayan",
      "Heinrich Jiang",
      "Sen Zhao",
      "Sanjiv Kumar"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.07652"
  },
  {
    "id": "arXiv:2202.07654",
    "title": "Tomayto, Tomahto. Beyond Token-level Answer Equivalence for Question  Answering Evaluation",
    "abstract": "The predictions of question answering (QA) systems are typically evaluated\nagainst manually annotated finite sets of one or more answers. This leads to a\ncoverage limitation that results in underestimating the true performance of\nsystems, and is typically addressed by extending over exact match (EM) with\npredefined rules or with the token-level F1 measure. In this paper, we present\nthe first systematic conceptual and data-driven analysis to examine the\nshortcomings of token-level equivalence measures.\nTo this end, we define the asymmetric notion of answer equivalence (AE),\naccepting answers that are equivalent to or improve over the reference, and\ncollect over 26K human judgements for candidates produced by multiple QA\nsystems on SQuAD. Through a careful analysis of this data, we reveal and\nquantify several concrete limitations of the F1 measure, such as false\nimpression of graduality, missing dependence on question, and more.\nSince collecting AE annotations for each evaluated model is expensive, we\nlearn a BERT matching BEM measure to approximate this task. Being a simpler\ntask than QA, we find BEM to provide significantly better AE approximations\nthan F1, and more accurately reflect the performance of systems.\nFinally, we also demonstrate the practical utility of AE and BEM on the\nconcrete application of minimal accurate prediction sets, reducing the number\nof required answers by up to 2.6 times.",
    "descriptor": "",
    "authors": [
      "Jannis Bulian",
      "Christian Buck",
      "Wojciech Gajewski",
      "Benjamin Boerschinger",
      "Tal Schuster"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07654"
  },
  {
    "id": "arXiv:2202.06804",
    "title": "Flexible learning of quantum states with generative query neural  networks",
    "abstract": "Deep neural networks are a powerful tool for characterizing quantum states.\nIn this task, neural networks are typically trained with measurement data\ngathered from the quantum state to be characterized. But is it possible to\ntrain a neural network in a general-purpose way, which makes it applicable to\nmultiple unknown quantum states? Here we show that learning across multiple\nquantum states and different measurement settings can be achieved by a\ngenerative query neural network, a type of neural network originally used in\nthe classical domain for learning 3D scenes from 2D pictures. Our network can\nbe trained offline with classically simulated data, and later be used to\ncharacterize unknown quantum states from real experimental data. With little\nguidance of quantum physics, the network builds its own data-driven\nrepresentation of quantum states, and then uses it to predict the outcome\nprobabilities of requested quantum measurements on the states of interest. This\napproach can be applied to state learning scenarios where quantum measurement\nsettings are not informationally complete and predictions must be given in real\ntime, as experimental data become available, as well as to adversarial\nscenarios where measurement choices and prediction requests are designed to\nexpose learning inaccuracies. The internal representation produced by the\nnetwork can be used for other tasks beyond state characterization, including\nclustering of states and prediction of physical properties. The features of our\nmethod are illustrated on many-qubit ground states of Ising model and\ncontinuous-variable non-Gaussian states.",
    "descriptor": "",
    "authors": [
      "Yan Zhu",
      "Ya-Dong Wu",
      "Ge Bai",
      "Yuexuan Wang",
      "Giulio Chiribella"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06804"
  },
  {
    "id": "arXiv:2202.06950",
    "title": "Minimax in Geodesic Metric Spaces: Sion's Theorem and Algorithms",
    "abstract": "Determining whether saddle points exist or are approximable for\nnonconvex-nonconcave problems is usually intractable. We take a step towards\nunderstanding certain nonconvex-nonconcave minimax problems that do remain\ntractable. Specifically, we study minimax problems cast in geodesic metric\nspaces, which provide a vast generalization of the usual convex-concave saddle\npoint problems. The first main result of the paper is a geodesic metric space\nversion of Sion's minimax theorem; we believe our proof is novel and\ntransparent, as it relies on Helly's theorem only. In our second main result,\nwe specialize to geodesically complete Riemannian manifolds: we devise and\nanalyze the complexity of first-order methods for smooth minimax problems.",
    "descriptor": "\nComments: 19 pages, 2 figures\n",
    "authors": [
      "Peiyuan Zhang",
      "Jingzhao Zhang",
      "Suvrit Sra"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.06950"
  },
  {
    "id": "arXiv:2202.06956",
    "title": "DermX: an end-to-end framework for explainable automated dermatological  diagnosis",
    "abstract": "Dermatological diagnosis automation is essential in addressing the high\nprevalence of skin diseases and critical shortage of dermatologists. Despite\napproaching expert-level diagnosis performance, convolutional neural network\n(ConvNet) adoption in clinical practice is impeded by their limited\nexplainability, and by subjective, expensive explainability validations. We\nintroduce DermX and DermX+, an end-to-end framework for explainable automated\ndermatological diagnosis. DermX is a clinically-inspired explainable\ndermatological diagnosis ConvNet, trained using DermXDB, a 554 images dataset\nannotated by eight dermatologists with diagnoses and supporting explanations.\nDermX+ extends DermX with guided attention training for explanation attention\nmaps. Both methods achieve near-expert diagnosis performance, with DermX,\nDermX+, and dermatologist F1 scores of 0.79, 0.79, and 0.87, respectively. We\nassess the explanation plausibility in terms of identification and\nlocalization, by comparing model-selected with dermatologist-selected\nexplanations, and gradient-weighted class-activation maps with dermatologist\nexplanation maps. Both DermX and DermX+ obtain an identification F1 score of\n0.78. The localization F1 score is 0.39 for DermX and 0.35 for DermX+.\nExplanation faithfulness is assessed through contrasting samples, DermX\nobtaining 0.53 faithfulness and DermX+ 0.25. These results show that\nexplainability does not necessarily come at the expense of predictive power, as\nour high-performance models provide both plausible and faithful explanations\nfor their diagnoses.",
    "descriptor": "",
    "authors": [
      "Raluca Jalaboi",
      "Frederik Faye",
      "Mauricio Orbes-Arteaga",
      "Dan J\u00f8rgensen",
      "Ole Winther",
      "Alfiia Galimzianova"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06956"
  },
  {
    "id": "arXiv:2202.06988",
    "title": "Learned Turbulence Modelling with Differentiable Fluid Solvers",
    "abstract": "In this paper, we train turbulence models based on convolutional neural\nnetworks. These learned turbulence models improve under-resolved low resolution\nsolutions to the incompressible Navier-Stokes equations at simulation time. Our\nmethod involves the development of a differentiable numerical solver that\nsupports the propagation of optimisation gradients through multiple solver\nsteps. We showcase the significance of this property by demonstrating the\nsuperior stability and accuracy of those models that featured a higher number\nof unrolled steps during training. This approach is applied to three\ntwo-dimensional turbulence flow scenarios, a homogeneous decaying turbulence\ncase, a temporally evolving mixing layer and a spatially evolving mixing layer.\nOur method achieves significant improvements of long-term \\textit{a-posteriori}\nstatistics when compared to no-model simulations, without requiring these\nstatistics to be directly included in the learning targets. At inference time,\nour proposed method also gains substantial performance improvements over\nsimilarly accurate, purely numerical methods.",
    "descriptor": "\nComments: Further information and source code available at: this https URL\n",
    "authors": [
      "Bj\u00f6rn List",
      "Li-Wei Chen",
      "Nils Thuerey"
    ],
    "subjectives": [
      "Fluid Dynamics (physics.flu-dyn)",
      "Machine Learning (cs.LG)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.06988"
  },
  {
    "id": "arXiv:2202.06996",
    "title": "Unlabeled Data Help: Minimax Analysis and Adversarial Robustness",
    "abstract": "The recent proposed self-supervised learning (SSL) approaches successfully\ndemonstrate the great potential of supplementing learning algorithms with\nadditional unlabeled data. However, it is still unclear whether the existing\nSSL algorithms can fully utilize the information of both labelled and unlabeled\ndata. This paper gives an affirmative answer for the reconstruction-based SSL\nalgorithm \\citep{lee2020predicting} under several statistical models. While\nexisting literature only focuses on establishing the upper bound of the\nconvergence rate, we provide a rigorous minimax analysis, and successfully\njustify the rate-optimality of the reconstruction-based SSL algorithm under\ndifferent data generation models. Furthermore, we incorporate the\nreconstruction-based SSL into the existing adversarial training algorithms and\nshow that learning from unlabeled data helps improve the robustness.",
    "descriptor": "",
    "authors": [
      "Yue Xing",
      "Qifan Song",
      "Guang Cheng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06996"
  },
  {
    "id": "arXiv:2202.06997",
    "title": "A Survey of Cross-Modality Brain Image Synthesis",
    "abstract": "The existence of completely aligned and paired multi-modal neuroimaging data\nhas proved its effectiveness in diagnosis of brain diseases. However,\ncollecting the full set of well-aligned and paired data is impractical or even\nluxurious, since the practical difficulties may include high cost, long time\nacquisition, image corruption, and privacy issues. A realistic solution is to\nexplore either an unsupervised learning or a semi-supervised learning to\nsynthesize the absent neuroimaging data. In this paper, we tend to approach\nmulti-modality brain image synthesis task from different perspectives, which\ninclude the level of supervision, the range of modality synthesis, and the\nsynthesis-based downstream tasks. Particularly, we provide in-depth analysis on\nhow cross-modality brain image synthesis can improve the performance of\ndifferent downstream tasks. Finally, we evaluate the challenges and provide\nseveral open directions for this community. All resources are available at\nhttps://github.com/M-3LAB/awesome-multimodal-brain-image-systhesis",
    "descriptor": "",
    "authors": [
      "Guoyang Xie",
      "Jinbao Wang",
      "Yawen Huang",
      "Yefeng Zheng",
      "Feng Zheng",
      "Yaochu Jin"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.06997"
  },
  {
    "id": "arXiv:2202.07001",
    "title": "Handcrafted Histological Transformer (H2T): Unsupervised Representation  of Whole Slide Images",
    "abstract": "Diagnostic, prognostic and therapeutic decision-making of cancer in pathology\nclinics can now be carried out based on analysis of multi-gigapixel tissue\nimages, also known as whole-slide images (WSIs). Recently, deep convolutional\nneural networks (CNNs) have been proposed to derive unsupervised WSI\nrepresentations; these are attractive as they rely less on expert annotation\nwhich is cumbersome. However, a major trade-off is that higher predictive power\ngenerally comes at the cost of interpretability, posing a challenge to their\nclinical use where transparency in decision-making is generally expected. To\naddress this challenge, we present a handcrafted framework based on deep CNN\nfor constructing holistic WSI-level representations. Building on recent\nfindings about the internal working of the Transformer in the domain of natural\nlanguage processing, we break down its processes and handcraft them into a more\ntransparent framework that we term as the Handcrafted Histological Transformer\nor H2T. Based on our experiments involving various datasets consisting of a\ntotal of 5,306 WSIs, the results demonstrate that H2T based holistic WSI-level\nrepresentations offer competitive performance compared to recent\nstate-of-the-art methods and can be readily utilized for various downstream\nanalysis tasks. Finally, our results demonstrate that the H2T framework can be\nup to 14 times faster than the Transformer models.",
    "descriptor": "",
    "authors": [
      "Quoc Dang Vu",
      "Kashif Rajpoot",
      "Shan E Ahmed Raza",
      "Nasir Rajpoot"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07001"
  },
  {
    "id": "arXiv:2202.07022",
    "title": "Recurrent Neural Networks for Dynamical Systems: Applications to  Ordinary Differential Equations, Collective Motion, and Hydrological Modeling",
    "abstract": "Classical methods of solving spatiotemporal dynamical systems include\nstatistical approaches such as autoregressive integrated moving average, which\nassume linear and stationary relationships between systems' previous outputs.\nDevelopment and implementation of linear methods are relatively simple, but\nthey often do not capture non-linear relationships in the data. Thus,\nartificial neural networks (ANNs) are receiving attention from researchers in\nanalyzing and forecasting dynamical systems. Recurrent neural networks (RNN),\nderived from feed-forward ANNs, use internal memory to process variable-length\nsequences of inputs. This allows RNNs to applicable for finding solutions for a\nvast variety of problems in spatiotemporal dynamical systems. Thus, in this\npaper, we utilize RNNs to treat some specific issues associated with dynamical\nsystems. Specifically, we analyze the performance of RNNs applied to three\ntasks: reconstruction of correct Lorenz solutions for a system with a\nformulation error, reconstruction of corrupted collective motion trajectories,\nand forecasting of streamflow time series possessing spikes, representing three\nfields, namely, ordinary differential equations, collective motion, and\nhydrological modeling, respectively. We train and test RNNs uniquely in each\ntask to demonstrate the broad applicability of RNNs in reconstruction and\nforecasting the dynamics of dynamical systems.",
    "descriptor": "\nComments: 15 pages, 9 figures, submitted into \"Chaos: An Interdisciplinary Journal of Nonlinear Science\"\n",
    "authors": [
      "Yonggi Park",
      "Kelum Gajamannage",
      "Dilhani I. Jayathilake",
      "Erik M. Bollt"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.07022"
  },
  {
    "id": "arXiv:2202.07035",
    "title": "Testing the Tools of Systems Neuroscience on Artificial Neural Networks",
    "abstract": "Neuroscientists apply a range of common analysis tools to recorded neural\nactivity in order to glean insights into how neural circuits implement\ncomputations. Despite the fact that these tools shape the progress of the field\nas a whole, we have little empirical evidence that they are effective at\nquickly identifying the phenomena of interest. Here I argue that these tools\nshould be explicitly tested and that artificial neural networks (ANNs) are an\nappropriate testing grounds for them. The recent resurgence of the use of ANNs\nas models of everything from perception to memory to motor control stems from a\nrough similarity between artificial and biological neural networks and the\nability to train these networks to perform complex high-dimensional tasks.\nThese properties, combined with the ability to perfectly observe and manipulate\nthese systems, makes them well-suited for vetting the tools of systems and\ncognitive neuroscience. I provide here both a roadmap for performing this\ntesting and a list of tools that are suitable to be tested on ANNs. Using ANNs\nto reflect on the extent to which these tools provide a productive\nunderstanding of neural systems -- and on exactly what understanding should\nmean here -- has the potential to expedite progress in the study of the brain.",
    "descriptor": "\nComments: Perspective article; 10 pages, 2 figures\n",
    "authors": [
      "Grace W. Lindsay"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.07035"
  },
  {
    "id": "arXiv:2202.07037",
    "title": "Principal Manifold Flows",
    "abstract": "Normalizing flows map an independent set of latent variables to their samples\nusing a bijective transformation. Despite the exact correspondence between\nsamples and latent variables, their high level relationship is not well\nunderstood. In this paper we characterize the geometric structure of flows\nusing principal manifolds and understand the relationship between latent\nvariables and samples using contours. We introduce a novel class of normalizing\nflows, called principal manifold flows (PF), whose contours are its principal\nmanifolds, and a variant for injective flows (iPF) that is more efficient to\ntrain than regular injective flows. PFs can be constructed using any flow\narchitecture, are trained with a regularized maximum likelihood objective and\ncan perform density estimation on all of their principal manifolds. In our\nexperiments we show that PFs and iPFs are able to learn the principal manifolds\nover a variety of datasets. Additionally, we show that PFs can perform density\nestimation on data that lie on a manifold with variable dimensionality, which\nis not possible with existing normalizing flows.",
    "descriptor": "",
    "authors": [
      "Edmond Cunningham",
      "Adam Cobb",
      "Susmit Jha"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07037"
  },
  {
    "id": "arXiv:2202.07053",
    "title": "Rank-one Boolean tensor factorization and the multilinear polytope",
    "abstract": "We consider the NP-hard problem of approximating a tensor with binary entries\nby a rank-one tensor, referred to as rank-one Boolean tensor factorization\nproblem. We formulate this problem, in an extended space of variables, as the\nproblem of minimizing a linear function over a highly structured multilinear\nset. Leveraging on our prior results regarding the facial structure of\nmultilinear polytopes, we propose novel linear programming relaxations for\nrank-one Boolean tensor factorization. To analyze the performance of the\nproposed linear programs, we consider a random corruption model for the input\ntensor. We first consider the original NP-hard problem and establish\ninformation theoretic limits under the random model. Next, we obtain sufficient\nconditions under which the proposed linear programming relaxations recover the\nground truth with high probability. Our theoretical results as well as\nnumerical simulations indicate that certain facets of the multilinear polytope\nsignificantly improve the recovery properties of linear programming relaxations\nfor rank-one Boolean tensor factorization.",
    "descriptor": "",
    "authors": [
      "Alberto Del Pia",
      "Aida Khajavirad"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.07053"
  },
  {
    "id": "arXiv:2202.07069",
    "title": "Quantalic Behavioural Distances",
    "abstract": "Behavioural distances measure the deviation between states in quantitative\nsystems, such as probabilistic or weighted systems. There is growing interest\nin generic approaches to behavioural distances. In particular, coalgebraic\nmethods capture variations in the system type (nondeterministic, probabilistic,\ngame-based etc.), and the notion of quantale abstracts over actual values\ndistances take, thus covering, e.g., two-valued equivalences, metrics, and\nprobabilistic metrics. Coalgebraic behavioural distances have variously been\nbased on liftings of $\\mathsf{Set}$-functors to categories of metric spaces; on\nmodalities modeled as predicate liftings, via a generalised Kantorovich\nconstruction; and on lax extensions of $\\mathsf{Set}$-functors to categories of\nquantitative relations. Every lax extension induces a functor lifting in a\nstraightforward manner. Moreover, it has recently been shown that every lax\nextension is Kantorovich, i.e. induced by a suitable choice of monotone\npredicate liftings. In the present work, we complete this picture by\ndetermining, in coalgebraic and quantalic generality, when a functor lifting is\ninduced by a class of predicate liftings or by a lax extension. We subsequently\nshow coincidence of the respective induced notions of behavioural distances, in\na unified approach via double categories that applies even more widely, e.g. to\n(quasi)uniform spaces.",
    "descriptor": "",
    "authors": [
      "Sergey Goncharov",
      "Dirk Hofmann",
      "Pedro Nora",
      "Lutz Schr\u00f6der",
      "Paul Wild"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.07069"
  },
  {
    "id": "arXiv:2202.07079",
    "title": "Synthetically Controlled Bandits",
    "abstract": "This paper presents a new dynamic approach to experiment design in settings\nwhere, due to interference or other concerns, experimental units are coarse.\n`Region-split' experiments on online platforms are one example of such a\nsetting. The cost, or regret, of experimentation is a natural concern here. Our\nnew design, dubbed Synthetically Controlled Thompson Sampling (SCTS), minimizes\nthe regret associated with experimentation at no practically meaningful loss to\ninferential ability. We provide theoretical guarantees characterizing the\nnear-optimal regret of our approach, and the error rates achieved by the\ncorresponding treatment effect estimator. Experiments on synthetic and real\nworld data highlight the merits of our approach relative to both fixed and\n`switchback' designs common to such experimental settings.",
    "descriptor": "",
    "authors": [
      "Vivek Farias",
      "Ciamac Moallemi",
      "Tianyi Peng",
      "Andrew Zheng"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07079"
  },
  {
    "id": "arXiv:2202.07081",
    "title": "Introducing the ICBe Dataset: Very High Recall and Precision Event  Extraction from Narratives about International Crises",
    "abstract": "How do international crises unfold? We conceive of international affairs as a\nstrategic chess game between adversaries, necessitating a systematic way to\nmeasure pieces, moves, and gambits accurately and consistently over different\ncontexts and periods. We develop such a measurement strategy with an ontology\nof crisis actions and interactions and apply it to a high-quality corpus of\ncrisis narratives recorded by the International Crisis Behavior (ICB) Project.\nWe demonstrate that the ontology has high coverage over most of the thoughts,\nspeech, and actions contained in these narratives and produces high inter-coder\nagreement when applied by human coders. We introduce a new crisis event dataset\nICB Events (ICBe). We find that ICBe captures the process of a crisis with\ngreater accuracy and granularity than other well-regarded events or crisis\ndatasets. We make the data, replication material, and additional visualizations\navailable at a companion website www.crisisevents.org.",
    "descriptor": "",
    "authors": [
      "Rex W. Douglass",
      "Thomas Leo Scherer",
      "J. Andr\u00e9s Gannon",
      "Erik Gartzke",
      "Jon Lindsay",
      "Shannon Carcelli",
      "Jonathan Wilkenfeld",
      "David M. Quinn",
      "Catherine Aiken",
      "Jose Miguel Cabezas Navarro",
      "Neil Lund",
      "Egle Murauskaite",
      "Diana Partridge"
    ],
    "subjectives": [
      "Applications (stat.AP)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.07081"
  },
  {
    "id": "arXiv:2202.07107",
    "title": "Gaze-Guided Class Activation Mapping: Leveraging Human Attention for  Network Attention in Chest X-rays Classification",
    "abstract": "The increased availability and accuracy of eye-gaze tracking technology has\nsparked attention-related research in psychology, neuroscience, and, more\nrecently, computer vision and artificial intelligence. The attention mechanism\nin artificial neural networks is known to improve learning tasks. However, no\nprevious research has combined the network attention and human attention. This\npaper describes a gaze-guided class activation mapping (GG-CAM) method to\ndirectly regulate the formation of network attention based on expert\nradiologists' visual attention for the chest X-ray pathology classification\nproblem, which remains challenging due to the complex and often nuanced\ndifferences among images. GG-CAM is a lightweight ($3$ additional trainable\nparameters for regulating the learning process) and generic extension that can\nbe easily applied to most classification convolutional neural networks (CNN).\nGG-CAM-modified CNNs do not require human attention as an input when fully\ntrained. Comparative experiments suggest that two standard CNNs with the GG-CAM\nextension achieve significantly greater classification performance. The median\narea under the curve (AUC) metrics for ResNet50 increases from $0.721$ to\n$0.776$. For EfficientNetv2 (s), the median AUC increases from $0.723$ to\n$0.801$. The GG-CAM also brings better interpretability of the network that\nfacilitates the weakly-supervised pathology localization and analysis.",
    "descriptor": "\nComments: This manuscript was submitted to WACV 2022 on Aug. 18, 2021\n",
    "authors": [
      "Hongzhi Zhu",
      "Septimiu Salcudean",
      "Robert Rohling"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07107"
  },
  {
    "id": "arXiv:2202.07108",
    "title": "Dynamic optical contrast imaging for real-time delineation of tumor  resection margins using head and neck cancer as a model",
    "abstract": "Complete surgical resection of the tumor for Head and neck squamous cell\ncarcinoma (HNSCC) remains challenging, given the devastating side effects of\naggressive surgery and the anatomic proximity to vital structures. To address\nthe clinical challenges, we introduce a wide-field, label-free imaging tool\nthat can assist surgeons delineate tumor margins real-time. We assume that\nautofluorescence lifetime is a natural indicator of the health level of\ntissues, and ratio-metric measurement of the emission-decay state to the\nemission-peak state of excited fluorophores will enable rapid lifetime mapping\nof tissues. Here, we describe the principle, instrumentation, characterization\nof the imager and the intraoperative imaging of resected tissues from 13\npatients undergoing head and neck cancer resection. 20 x 20 mm2 imaging takes 2\nsecond/frame with a working distance of 50 mm, and characterization shows that\nthe spatial resolution reached 70 {\\mu}m and the least distinguishable\nfluorescence lifetime difference is 0.14 ns. Tissue imaging and\nHematoxylin-Eosin stain slides comparison reveals its capability of delineating\ncancerous boundaries with submillimeter accuracy and a sensitivity of 91.86%\nand specificity of 84.38%.",
    "descriptor": "\nComments: 21 pages, 7 figures and 1 table\n",
    "authors": [
      "Yong Hu",
      "Shan Huang",
      "Albert Y. Han",
      "Seong Moon",
      "Jeffrey F. Krane",
      "Oscar Stafsudd",
      "Maie A. St. John"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Systems and Control (eess.SY)",
      "Biological Physics (physics.bio-ph)",
      "Medical Physics (physics.med-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.07108"
  },
  {
    "id": "arXiv:2202.07109",
    "title": "Asymptotics of the quantization errors for Markov-type measures with  complete overlaps",
    "abstract": "Let $\\mathcal{G}$ be a directed graph with vertices $1,2,\\ldots, 2N$. Let\n$\\mathcal{T}=(T_{i,j})_{(i,j)\\in\\mathcal{G}}$ be a family of contractive\nsimilarity mappings. For every $1\\leq i\\leq N$, let $i^+:=i+N$. Let\n$\\mathcal{M}_{i,j}=\\{(i,j),(i,j^+),(i^+,j),(i^+,j^+)\\}\\cap\\mathcal{G}$. We\nassume that $T_{\\widetilde{i},\\widetilde{j}}=T_{i,j}$ for every\n$(\\widetilde{i},\\widetilde{j})\\in \\mathcal{M}_{i,j}$. Let $K$ denote the\nMauldin-Williams fractal determined by $\\mathcal{T}$. Let\n$\\chi=(\\chi_i)_{i=1}^{2N}$ be a positive probability vector and $P$ a\nrow-stochastic matrix which serves as an incidence matrix for $\\mathcal{G}$.\nLet $\\nu$ be the Markov-type measure associated with $\\chi$ and $P$. Let\n$\\Omega=\\{1,\\ldots,2N\\}$ and\n$G_\\infty=\\{\\sigma\\in\\Omega^{\\mathbb{N}}:(\\sigma_i,\\sigma_{i+1})\\in\\mathcal{G},\n\\;i\\geq 1\\}$. Let $\\pi$ be the natural projection from $G_\\infty$ to $K$ and\n$\\mu=\\nu\\circ\\pi^{-1}$. We consider two cases: 1. $\\mathcal{G}$ has two\nstrongly connected components consisting of $N$ vertices; 2. $\\mathcal{G}$ is\nstrongly connected. With some assumptions for $\\mathcal{G}$ and $\\mathcal{T}$,\nfor case 1, we determine the exact value $s_r$ of $D_r(\\mu)$ and prove that the\n$s_r$-dimensional lower quantization coefficient $\\underline{Q}_r^{s_r}(\\mu)$\nis always positive, but the upper one $\\overline{Q}_r^{s_r}(\\mu)$ can be\ninfinite; we establish a necessary and sufficient condition for\n$\\overline{Q}_r^{s_r}(\\mu)$ to be finite; for case 2, we determine\n$D_r(\\mu)=:t_r$ by means of a pressure-like function and prove that\n$\\underline{Q}_r^{t_r}(\\mu)$ and $\\overline{Q}_r^{t_r}(\\mu)$ are always\npositive and finite.",
    "descriptor": "",
    "authors": [
      "Sanguo Zhu"
    ],
    "subjectives": [
      "Functional Analysis (math.FA)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2202.07109"
  },
  {
    "id": "arXiv:2202.07118",
    "title": "Multi-task UNet: Jointly Boosting Saliency Prediction and Disease  Classification on Chest X-ray Images",
    "abstract": "Human visual attention has recently shown its distinct capability in boosting\nmachine learning models. However, studies that aim to facilitate medical tasks\nwith human visual attention are still scarce. To support the use of visual\nattention, this paper describes a novel deep learning model for visual saliency\nprediction on chest X-ray (CXR) images. To cope with data deficiency, we\nexploit the multi-task learning method and tackles disease classification on\nCXR simultaneously. For a more robust training process, we propose a further\noptimized multi-task learning scheme to better handle model overfitting.\nExperiments show our proposed deep learning model with our new learning scheme\ncan outperform existing methods dedicated either for saliency prediction or\nimage classification. The code used in this paper is available at\nhttps://github.com/hz-zhu/MT-UNet.",
    "descriptor": "",
    "authors": [
      "Hongzhi Zhu",
      "Robert Rohling",
      "Septimiu Salcudean"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07118"
  },
  {
    "id": "arXiv:2202.07122",
    "title": "Gigahertz Sub-Landauer Momentum Computing",
    "abstract": "We introduce a fast and highly-efficient physically-realizable bit swap.\nEmploying readily available and scalable Josephson junction microtechnology,\nthe design implements the recently introduced paradigm of momentum computing.\nIts nanosecond speeds and sub-Landauer thermodynamic efficiency arise from\ndynamically storing memory in momentum degrees of freedom. As such, during the\nswap, the microstate distribution is never near equilibrium and the\nmemory-state dynamics fall far outside of stochastic thermodynamics that\nassumes detailed-balanced Markovian dynamics. The device implements a bit-swap\noperation -- a fundamental operation necessary to build reversible universal\ncomputing. Extensive, physically-calibrated simulations demonstrate that device\nperformance is robust and that momentum computing can support\nthermodynamically-efficient, high-speed, large-scale general-purpose computing.",
    "descriptor": "\nComments: 17 pages, 10 figures, 6 appendices; this http URL\n",
    "authors": [
      "Kyle J. Ray",
      "James P. Crutchfield"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Emerging Technologies (cs.ET)",
      "Dynamical Systems (math.DS)",
      "Chaotic Dynamics (nlin.CD)",
      "Computational Physics (physics.comp-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.07122"
  },
  {
    "id": "arXiv:2202.07172",
    "title": "TURF: A Two-factor, Universal, Robust, Fast Distribution Learning  Algorithm",
    "abstract": "Approximating distributions from their samples is a canonical\nstatistical-learning problem. One of its most powerful and successful\nmodalities approximates every distribution to an $\\ell_1$ distance essentially\nat most a constant times larger than its closest $t$-piece degree-$d$\npolynomial, where $t\\ge1$ and $d\\ge0$. Letting $c_{t,d}$ denote the smallest\nsuch factor, clearly $c_{1,0}=1$, and it can be shown that $c_{t,d}\\ge 2$ for\nall other $t$ and $d$. Yet current computationally efficient algorithms show\nonly $c_{t,1}\\le 2.25$ and the bound rises quickly to $c_{t,d}\\le 3$ for $d\\ge\n9$. We derive a near-linear-time and essentially sample-optimal estimator that\nestablishes $c_{t,d}=2$ for all $(t,d)\\ne(1,0)$. Additionally, for many\npractical distributions, the lowest approximation distance is achieved by\npolynomials with vastly varying number of pieces. We provide a method that\nestimates this number near-optimally, hence helps approach the best possible\napproximation. Experiments combining the two techniques confirm improved\nperformance over existing methodologies.",
    "descriptor": "\nComments: 18 pages, 9 figures\n",
    "authors": [
      "Yi Hao",
      "Ayush Jain",
      "Alon Orlitsky",
      "Vaishakh Ravindrakumar"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Statistics Theory (math.ST)"
    ],
    "url": "https://arxiv.org/abs/2202.07172"
  },
  {
    "id": "arXiv:2202.07173",
    "title": "To what extent can Plug-and-Play methods outperform neural networks  alone in low-dose CT reconstruction",
    "abstract": "The Plug-and-Play (PnP) framework was recently introduced for low-dose CT\nreconstruction to leverage the interpretability and the flexibility of\nmodel-based methods to incorporate various plugins, such as trained deep\nlearning (DL) neural networks. However, the benefits of PnP vs.\nstate-of-the-art DL methods have not been clearly demonstrated. In this work,\nwe proposed an improved PnP framework to address the previous limitations and\ndevelop clinical-relevant segmentation metrics for quantitative result\nassessment. Compared with the DL alone methods, our proposed PnP framework was\nslightly inferior in MSE and PSNR. However, the power spectrum of the resulting\nimages better matched that of full-dose images than that of DL denoised images.\nThe resulting images supported higher accuracy in airway segmentation than DL\ndenoised images for all the ten patients in the test set, more substantially on\nthe airways with a cross-section smaller than 0.61cm$^2$, and outperformed the\nDL denoised images for 45 out of 50 lung lobes in lobar segmentation. Our PnP\nmethod proved to be significantly better at preserving the image texture, which\ntranslated to task-specific benefits in automated structure segmentation and\ndetection.",
    "descriptor": "\nComments: Accepted to IEEE ISBI 2022\n",
    "authors": [
      "Qifan Xu",
      "Qihui Lyu",
      "Dan Ruan",
      "Ke Sheng"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07173"
  },
  {
    "id": "arXiv:2202.07187",
    "title": "On the Sample Complexity of Stabilizing LTI Systems on a Single  Trajectory",
    "abstract": "Stabilizing an unknown dynamical system is one of the central problems in\ncontrol theory. In this paper, we study the sample complexity of the\nlearn-to-stabilize problem in Linear Time-Invariant (LTI) systems on a single\ntrajectory. Current state-of-the-art approaches require a sample complexity\nlinear in $n$, the state dimension, which incurs a state norm that blows up\nexponentially in $n$. We propose a novel algorithm based on spectral\ndecomposition that only needs to learn \"a small part\" of the dynamical matrix\nacting on its unstable subspace. We show that, under proper assumptions, our\nalgorithm stabilizes an LTI system on a single trajectory with $\\tilde{O}(k)$\nsamples, where $k$ is the instability index of the system. This represents the\nfirst sub-linear sample complexity result for the stabilization of LTI systems\nunder the regime when $k = o(n)$.",
    "descriptor": "\nComments: 40 pages, 2 figures, submitted to COLT 2022\n",
    "authors": [
      "Yang Hu",
      "Adam Wierman",
      "Guannan Qu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.07187"
  },
  {
    "id": "arXiv:2202.07194",
    "title": "One-bit Submission for Locally Private Quasi-MLE: Its Asymptotic  Normality and Limitation",
    "abstract": "Local differential privacy~(LDP) is an information-theoretic privacy\ndefinition suitable for statistical surveys that involve an untrusted data\ncurator. An LDP version of quasi-maximum likelihood estimator~(QMLE) has been\ndeveloped, but the existing method to build LDP QMLE is difficult to implement\nfor a large-scale survey system in the real world due to long waiting time,\nexpensive communication cost, and the boundedness assumption of derivative of a\nlog-likelihood function. We provided an alternative LDP protocol without those\nissues, which is potentially much easily deployable to a large-scale survey. We\nalso provided sufficient conditions for the consistency and asymptotic\nnormality and limitations of our protocol. Our protocol is less burdensome for\nthe users, and the theoretical guarantees cover more realistic cases than those\nfor the existing method.",
    "descriptor": "\nComments: To appear in AISTATS2022\n",
    "authors": [
      "Hajime Ono",
      "Kazuhiro Minami",
      "Hideitsu Hino"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07194"
  },
  {
    "id": "arXiv:2202.07200",
    "title": "Unsupervised word-level prosody tagging for controllable speech  synthesis",
    "abstract": "Although word-level prosody modeling in neural text-to-speech (TTS) has been\ninvestigated in recent research for diverse speech synthesis, it is still\nchallenging to control speech synthesis manually without a specific reference.\nThis is largely due to lack of word-level prosody tags. In this work, we\npropose a novel approach for unsupervised word-level prosody tagging with two\nstages, where we first group the words into different types with a decision\ntree according to their phonetic content and then cluster the prosodies using\nGMM within each type of words separately. This design is based on the\nassumption that the prosodies of different type of words, such as long or short\nwords, should be tagged with different label sets. Furthermore, a TTS system\nwith the derived word-level prosody tags is trained for controllable speech\nsynthesis. Experiments on LJSpeech show that the TTS model trained with\nword-level prosody tags not only achieves better naturalness than a typical\nFastSpeech2 model, but also gains the ability to manipulate word-level prosody.",
    "descriptor": "\nComments: 5 pages, 6 figures, accepted to ICASSP2022\n",
    "authors": [
      "Yiwei Guo",
      "Chenpeng Du",
      "Kai Yu"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.07200"
  },
  {
    "id": "arXiv:2202.07205",
    "title": "Probabilistic Modeling Using Tree Linear Cascades",
    "abstract": "We introduce tree linear cascades, a class of linear structural equation\nmodels for which the error variables are uncorrelated but need not be Gaussian\nnor independent. We show that, in spite of this weak assumption, the tree\nstructure of this class of models is identifiable. In a similar vein, we\nintroduce a constrained regression problem for fitting a tree-structured linear\nstructural equation model and solve the problem analytically. We connect these\nresults to the classical Chow-Liu approach for Gaussian graphical models. We\nconclude by giving an empirical-risk form of the regression and illustrating\nthe computationally attractive implications of our theoretical results on a\nbasic example involving stock prices.",
    "descriptor": "\nComments: long form of an article to appear in the proceedings of the 2022 American Control Conference (ACC 2022). 8 pages, 1 figure; includes an appendix which the conference version omits\n",
    "authors": [
      "Nicholas C. Landolfi",
      "Sanjay Lall"
    ],
    "subjectives": [
      "Methodology (stat.ME)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2202.07205"
  },
  {
    "id": "arXiv:2202.07216",
    "title": "Multiparameter Bernoulli Factories",
    "abstract": "We consider the problem of computing with many coins of unknown bias. We are\ngiven samples access to $n$ coins with \\emph{unknown} biases $p_1,\\dots, p_n$\nand are asked to sample from a coin with bias $f(p_1, \\dots, p_n)$ for a given\nfunction $f:[0,1]^n \\rightarrow [0,1]$. We give a complete characterization of\nthe functions $f$ for which this is possible. As a consequence, we show how to\nextend various combinatorial sampling procedures (most notably, the classic\nSampford Sampling for $k$-subsets) to the boundary of the hypercube.",
    "descriptor": "",
    "authors": [
      "Renato Paes Leme",
      "Jon Schneider"
    ],
    "subjectives": [
      "Probability (math.PR)",
      "Discrete Mathematics (cs.DM)",
      "Data Structures and Algorithms (cs.DS)"
    ],
    "url": "https://arxiv.org/abs/2202.07216"
  },
  {
    "id": "arXiv:2202.07252",
    "title": "Quantifying team chemistry in scientific collaboration",
    "abstract": "Team chemistry is the holy grail of understanding collaborative human\nbehavior, yet its quantitative understanding remains inconclusive. To reveal\nthe presence and mechanisms of team chemistry in scientific collaboration, we\nreconstruct the publication histories of 560,689 individual scientists and\n1,026,196 duos of scientists. We identify ability discrepancies between teams\nand their members, enabling us to evaluate team chemistry in a way that is\nrobust against prior experience of collaboration and inherent randomness.\nFurthermore, our network analysis uncovers a nontrivial modular structure that\nallows us to predict team chemistry between scientists who have never\ncollaborated before. Research interest is the highest correlated ingredient of\nteam chemistry among six personal characteristics that have been commonly\nattributed as the keys to successful collaboration, yet the diversity of the\ncharacteristics cannot completely explain team chemistry. Our results may lead\nto unlocking the hidden potential of collaboration by the matching of\nwell-paired scientists.",
    "descriptor": "",
    "authors": [
      "Gangmin Son",
      "Jinhyuk Yun",
      "Hawoong Jeong"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2202.07252"
  },
  {
    "id": "arXiv:2202.07254",
    "title": "REPID: Regional Effect Plots with implicit Interaction Detection",
    "abstract": "Machine learning models can automatically learn complex relationships, such\nas non-linear and interaction effects. Interpretable machine learning methods\nsuch as partial dependence plots visualize marginal feature effects but may\nlead to misleading interpretations when feature interactions are present.\nHence, employing additional methods that can detect and measure the strength of\ninteractions is paramount to better understand the inner workings of machine\nlearning models. We demonstrate several drawbacks of existing global\ninteraction detection approaches, characterize them theoretically, and evaluate\nthem empirically. Furthermore, we introduce regional effect plots with implicit\ninteraction detection, a novel framework to detect interactions between a\nfeature of interest and other features. The framework also quantifies the\nstrength of interactions and provides interpretable and distinct regions in\nwhich feature effects can be interpreted more reliably, as they are less\nconfounded by interactions. We prove the theoretical eligibility of our method\nand show its applicability on various simulation and real-world examples.",
    "descriptor": "",
    "authors": [
      "Julia Herbinger",
      "Bernd Bischl",
      "Giuseppe Casalicchio"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07254"
  },
  {
    "id": "arXiv:2202.07262",
    "title": "Stochastic Gradient Descent-Ascent: Unified Theory and New Efficient  Methods",
    "abstract": "Stochastic Gradient Descent-Ascent (SGDA) is one of the most prominent\nalgorithms for solving min-max optimization and variational inequalities\nproblems (VIP) appearing in various machine learning tasks. The success of the\nmethod led to several advanced extensions of the classical SGDA, including\nvariants with arbitrary sampling, variance reduction, coordinate randomization,\nand distributed variants with compression, which were extensively studied in\nthe literature, especially during the last few years. In this paper, we propose\na unified convergence analysis that covers a large variety of stochastic\ngradient descent-ascent methods, which so far have required different\nintuitions, have different applications and have been developed separately in\nvarious communities. A key to our unified framework is a parametric assumption\non the stochastic estimates. Via our general theoretical framework, we either\nrecover the sharpest known rates for the known special cases or tighten them.\nMoreover, to illustrate the flexibility of our approach we develop several new\nvariants of SGDA such as a new variance-reduced method (L-SVRGDA), new\ndistributed methods with compression (QSGDA, DIANA-SGDA, VR-DIANA-SGDA), and a\nnew method with coordinate randomization (SEGA-SGDA). Although variants of the\nnew methods are known for solving minimization problems, they were never\nconsidered or analyzed for solving min-max problems and VIPs. We also\ndemonstrate the most important properties of the new methods through extensive\nnumerical experiments.",
    "descriptor": "\nComments: 63 pages, 5 figures, 3 tables\n",
    "authors": [
      "Aleksandr Beznosikov",
      "Eduard Gorbunov",
      "Hugo Berard",
      "Nicolas Loizou"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07262"
  },
  {
    "id": "arXiv:2202.07269",
    "title": "Media Slant is Contagious",
    "abstract": "This paper analyzes the influence of partisan content from national cable TV\nnews on local reporting in U.S. newspapers. We provide a new\nmachine-learning-based measure of cable news slant, trained on a corpus of 40K\ntranscribed TV episodes from Fox News Channel (FNC), CNN, and MSNBC\n(2005-2008). Applying the method to a corpus of 24M local newspaper articles,\nwe find that in response to an exogenous increase in local viewership of FNC\nrelative to CNN/MSNBC, local newspaper articles become more similar to FNC\ntranscripts (and vice versa). Consistent with newspapers responding to changes\nin reader preferences, we see a shift in the framing of local news coverage\nrather than just direct borrowing of cable news content. Further, cable news\nslant polarizes local news content: right-leaning newspapers tend to adopt\nright-wing FNC language, while left-leaning newspapers tend to become more\nleft-wing. Media slant is contagious.",
    "descriptor": "",
    "authors": [
      "Philine Widmer",
      "Sergio Galletta",
      "Elliott Ash"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Computation and Language (cs.CL)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.07269"
  },
  {
    "id": "arXiv:2202.07282",
    "title": "Adaptive Conformal Predictions for Time Series",
    "abstract": "Uncertainty quantification of predictive models is crucial in decision-making\nproblems. Conformal prediction is a general and theoretically sound answer.\nHowever, it requires exchangeable data, excluding time series. While recent\nworks tackled this issue, we argue that Adaptive Conformal Inference (ACI,\nGibbs and Cand{\\`e}s, 2021), developed for distribution-shift time series, is a\ngood procedure for time series with general dependency. We theoretically\nanalyse the impact of the learning rate on its efficiency in the exchangeable\nand auto-regressive case. We propose a parameter-free method, AgACI, that\nadaptively builds upon ACI based on online expert aggregation. We lead\nextensive fair simulations against competing methods that advocate for ACI's\nuse in time series. We conduct a real case study: electricity price\nforecasting. The proposed aggregation algorithm provides efficient prediction\nintervals for day-ahead forecasting. All the code and data to reproduce the\nexperiments is made available.",
    "descriptor": "",
    "authors": [
      "Margaux Zaffran",
      "Aymeric Dieuleveut",
      "Olivier F\u00e9ron",
      "Yannig Goude",
      "Julie Josse"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07282"
  },
  {
    "id": "arXiv:2202.07290",
    "title": "Don't stop the training: continuously-updating self-supervised  algorithms best account for auditory responses in the cortex",
    "abstract": "Over the last decade, numerous studies have shown that deep neural networks\nexhibit sensory representations similar to those of the mammalian brain, in\nthat their activations linearly map onto cortical responses to the same sensory\ninputs. However, it remains unknown whether these artificial networks also\nlearn like the brain. To address this issue, we analyze the brain responses of\ntwo ferret auditory cortices recorded with functional UltraSound imaging (fUS),\nwhile the animals were presented with 320 10\\,s sounds. We compare these brain\nresponses to the activations of Wav2vec 2.0, a self-supervised neural network\npretrained with 960\\,h of speech, and input with the same 320 sounds.\nCritically, we evaluate Wav2vec 2.0 under two distinct modes: (i) \"Pretrained\",\nwhere the same model is used for all sounds, and (ii) \"Continuous Update\",\nwhere the weights of the pretrained model are modified with back-propagation\nafter every sound, presented in the same order as the ferrets. Our results show\nthat the Continuous-Update mode leads Wav2Vec 2.0 to generate activations that\nare more similar to the brain than a Pretrained Wav2Vec 2.0 or than other\ncontrol models using different training modes. These results suggest that the\ntrial-by-trial modifications of self-supervised algorithms induced by\nback-propagation aligns with the corresponding fluctuations of cortical\nresponses to sounds. Our finding thus provides empirical evidence of a common\nlearning mechanism between self-supervised models and the mammalian cortex\nduring sound processing.",
    "descriptor": "",
    "authors": [
      "Pierre Orhan",
      "Yves Boubenec",
      "Jean-R\u00e9mi King"
    ],
    "subjectives": [
      "Neurons and Cognition (q-bio.NC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07290"
  },
  {
    "id": "arXiv:2202.07300",
    "title": "Choosing an algorithmic fairness metric for an online marketplace:  Detecting and quantifying algorithmic bias on LinkedIn",
    "abstract": "In this paper, we derive an algorithmic fairness metric for the\nrecommendation algorithms that power LinkedIn from the fairness notion of equal\nopportunity for equally qualified candidates. We borrow from the economic\nliterature on discrimination to arrive at a test for detecting algorithmic\ndiscrimination, which we then use to audit two algorithms from LinkedIn with\nrespect to gender bias. Moreover, we introduce a framework for distinguishing\nalgorithmic bias from human bias, both of which can potentially exist on a\ntwo-sided platform.",
    "descriptor": "",
    "authors": [
      "YinYin Yu",
      "Guillaume Saint-Jacques"
    ],
    "subjectives": [
      "General Economics (econ.GN)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2202.07300"
  },
  {
    "id": "arXiv:2202.07356",
    "title": "Realistic Counterfactual Explanations by Learned Relations",
    "abstract": "Many existing methods of counterfactual explanations ignore the intrinsic\nrelationships between data attributes and thus fail to generate realistic\ncounterfactuals. Moreover, the existing methods that account for relationships\nbetween data attributes require domain knowledge, which limits their\napplicability in complex real-world applications. In this paper, we propose a\nnovel approach to realistic counterfactual explanations that preserve\nrelationships between data attributes. The model directly learns the\nrelationships by a variational auto-encoder without domain knowledge and then\nlearns to disturb the latent space accordingly. We conduct extensive\nexperiments on both synthetic and real-world datasets. The results demonstrate\nthat the proposed method learns relationships from the data and preserves these\nrelationships in generated counterfactuals.",
    "descriptor": "",
    "authors": [
      "Xintao Xiang",
      "Artem Lenskiy"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07356"
  },
  {
    "id": "arXiv:2202.07365",
    "title": "A Statistical Learning View of Simple Kriging",
    "abstract": "In the Big Data era, with the ubiquity of geolocation sensors in particular,\nmassive datasets exhibiting a possibly complex spatial dependence structure are\nbecoming increasingly available. In this context, the standard probabilistic\ntheory of statistical learning does not apply directly and guarantees of the\ngeneralization capacity of predictive rules learned from such data are left to\nestablish. We analyze here the simple Kriging task, the flagship problem in\nGeostatistics: the values of a square integrable random field $X=\\{X_s\\}_{s\\in\nS}$, $S\\subset \\mathbb{R}^2$, with unknown covariance structure are to be\npredicted with minimum quadratic risk, based upon observing a single\nrealization of the spatial process at a finite number of locations $s_1,\\;\n\\ldots,\\; s_n$ in $S$. Despite the connection of this minimization problem with\nkernel ridge regression, establishing the generalization capacity of empirical\nrisk minimizers is far from straightforward, due to the non i.i.d. nature of\nthe spatial data $X_{s_1},\\; \\ldots,\\; X_{s_n}$ involved. In this article,\nnonasymptotic bounds of order $O_{\\mathbb{P}}(1/n)$ are proved for the excess\nrisk of a plug-in predictive rule mimicking the true minimizer in the case of\nisotropic stationary Gaussian processes observed at locations forming a regular\ngrid. These theoretical results, as well as the role played by the technical\nconditions required to establish them, are illustrated by various numerical\nexperiments and hopefully pave the way for further developments in statistical\nlearning based on spatial data.",
    "descriptor": "",
    "authors": [
      "Emilia Siviero",
      "Emilie Chautru",
      "Stephan Cl\u00e9men\u00e7on"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07365"
  },
  {
    "id": "arXiv:2202.07399",
    "title": "Interpreting a Machine Learning Model for Detecting Gravitational Waves",
    "abstract": "We describe a case study of translational research, applying interpretability\ntechniques developed for computer vision to machine learning models used to\nsearch for and find gravitational waves. The models we study are trained to\ndetect black hole merger events in non-Gaussian and non-stationary advanced\nLaser Interferometer Gravitational-wave Observatory (LIGO) data. We produced\nvisualizations of the response of machine learning models when they process\nadvanced LIGO data that contains real gravitational wave signals, noise\nanomalies, and pure advanced LIGO noise. Our findings shed light on the\nresponses of individual neurons in these machine learning models. Further\nanalysis suggests that different parts of the network appear to specialize in\nlocal versus global features, and that this difference appears to be rooted in\nthe branched architecture of the network as well as noise characteristics of\nthe LIGO detectors. We believe efforts to whiten these \"black box\" models can\nsuggest future avenues for research and help inform the design of interpretable\nmachine learning models for gravitational wave astrophysics.",
    "descriptor": "\nComments: 19 pages, to be submitted, comments are welcome. Movies based on this work can be accessed via: this https URL this https URL\n",
    "authors": [
      "Mohammadtaher Safarzadeh",
      "Asad Khan",
      "E. A. Huerta",
      "Martin Wattenberg"
    ],
    "subjectives": [
      "General Relativity and Quantum Cosmology (gr-qc)",
      "High Energy Astrophysical Phenomena (astro-ph.HE)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.07399"
  },
  {
    "id": "arXiv:2202.07403",
    "title": "Deep learning and differential equations for modeling changes in  individual-level latent dynamics between observation periods",
    "abstract": "When modeling longitudinal biomedical data, often dimensionality reduction as\nwell as dynamic modeling in the resulting latent representation is needed. This\ncan be achieved by artificial neural networks for dimension reduction, and\ndifferential equations for dynamic modeling of individual-level trajectories.\nHowever, such approaches so far assume that parameters of individual-level\ndynamics are constant throughout the observation period. Motivated by an\napplication from psychological resilience research, we propose an extension\nwhere different sets of differential equation parameters are allowed for\nobservation sub-periods. Still, estimation for intra-individual sub-periods is\ncoupled for being able to fit the model also with a relatively small dataset.\nWe subsequently derive prediction targets from individual dynamic models of\nresilience in the application. These serve as interpretable resilience-related\noutcomes, to be predicted from characteristics of individuals, measured at\nbaseline and a follow-up time point, and selecting a small set of important\npredictors. Our approach is seen to successfully identify individual-level\nparameters of dynamic models that allows us to stably select predictors, i.e.,\nresilience factors. Furthermore, we can identify those characteristics of\nindividuals that are the most promising for updates at follow-up, which might\ninform future study design. This underlines the usefulness of our proposed deep\ndynamic modeling approach with changes in parameters between observation\nsub-periods.",
    "descriptor": "",
    "authors": [
      "G\u00f6ran K\u00f6ber",
      "Raffael Kalisch",
      "Lara Puhlmann",
      "Andrea Chmitorz",
      "Anita Schick",
      "Harald Binder"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2202.07403"
  },
  {
    "id": "arXiv:2202.07422",
    "title": "Explainable COVID-19 Infections Identification and Delineation Using  Calibrated Pseudo Labels",
    "abstract": "The upheaval brought by the arrival of the COVID-19 pandemic has continued to\nbring fresh challenges over the past two years. During this COVID-19 pandemic,\nthere has been a need for rapid identification of infected patients and\nspecific delineation of infection areas in computed tomography (CT) images.\nAlthough deep supervised learning methods have been established quickly, the\nscarcity of both image-level and pixellevel labels as well as the lack of\nexplainable transparency still hinder the applicability of AI. Can we identify\ninfected patients and delineate the infections with extreme minimal\nsupervision? Semi-supervised learning (SSL) has demonstrated promising\nperformance under limited labelled data and sufficient unlabelled data.\nInspired by SSL, we propose a model-agnostic calibrated pseudo-labelling\nstrategy and apply it under a consistency regularization framework to generate\nexplainable identification and delineation results. We demonstrate the\neffectiveness of our model with the combination of limited labelled data and\nsufficient unlabelled data or weakly-labelled data. Extensive experiments have\nshown that our model can efficiently utilize limited labelled data and provide\nexplainable classification and segmentation results for decision-making in\nclinical routine.",
    "descriptor": "\nComments: 10 pages, 6 figures, submitted to IEEE TETCI\n",
    "authors": [
      "Ming Li",
      "Yingying Fang",
      "Zeyu Tang",
      "Chibudom Onuorah",
      "Jun Xia",
      "Javier Del Ser",
      "Simon Walsh",
      "Guang Yang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07422"
  },
  {
    "id": "arXiv:2202.07423",
    "title": "DeepPAMM: Deep Piecewise Exponential Additive Mixed Models for Complex  Hazard Structures in Survival Analysis",
    "abstract": "Survival analysis (SA) is an active field of research that is concerned with\ntime-to-event outcomes and is prevalent in many domains, particularly\nbiomedical applications. Despite its importance, SA remains challenging due to\nsmall-scale data sets and complex outcome distributions, concealed by\ntruncation and censoring processes. The piecewise exponential additive mixed\nmodel (PAMM) is a model class addressing many of these challenges, yet PAMMs\nare not applicable in high-dimensional feature settings or in the case of\nunstructured or multimodal data. We unify existing approaches by proposing\nDeepPAMM, a versatile deep learning framework that is well-founded from a\nstatistical point of view, yet with enough flexibility for modeling complex\nhazard structures. We illustrate that DeepPAMM is competitive with other\nmachine learning approaches with respect to predictive performance while\nmaintaining interpretability through benchmark experiments and an extended case\nstudy.",
    "descriptor": "\nComments: 13 pages, 2 figures, This work has been accepted by the 26th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD2022)\n",
    "authors": [
      "Philipp Kopper",
      "Simon Wiegrebe",
      "Bernd Bischl",
      "Andreas Bender",
      "David R\u00fcgamer"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07423"
  },
  {
    "id": "arXiv:2202.07425",
    "title": "Algebraic function based Banach space valued ordinary and fractional  neural network approximations",
    "abstract": "Here we research the univariate quantitative approximation, ordinary and\nfractional, of Banach space valued continuous functions on a compact interval\nor all the real line by quasi-interpolation Banach space valued neural network\noperators. These approximations are derived by establishing Jackson type\ninequalities involving the modulus of continuity of the engaged function or its\nBanach space valued high order derivative of fractional derivatives. Our\noperators are defined by using a density function generated by an algebraic\nsigmoid function. The approximations are pointwise and of the uniform norm. The\nrelated Banach space valued feed-forward neural networks are with one hidden\nlayer.",
    "descriptor": "\nComments: arXiv admin note: substantial text overlap with arXiv:1404.6449\n",
    "authors": [
      "George A Anastassiou"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Classical Analysis and ODEs (math.CA)"
    ],
    "url": "https://arxiv.org/abs/2202.07425"
  },
  {
    "id": "arXiv:2202.07428",
    "title": "Learning Contextually Fused Audio-visual Representations for  Audio-visual Speech Recognition",
    "abstract": "With the advance in self-supervised learning for audio and visual modalities,\nit has become possible to learn a robust audio-visual speech representation.\nThis would be beneficial for improving the audio-visual speech recognition\n(AVSR) performance, as the multi-modal inputs contain more fruitful information\nin principle. In this paper, based on existing self-supervised representation\nlearning methods for audio modality, we therefore propose an audio-visual\nrepresentation learning approach. The proposed approach explores both the\ncomplementarity of audio-visual modalities and long-term context dependency\nusing a transformer-based fusion module and a flexible masking strategy. After\npre-training, the model is able to extract fused representations required by\nAVSR. Without loss of generality, it can be applied to single-modal tasks, e.g.\naudio/visual speech recognition by simply masking out one modality in the\nfusion module. The proposed pre-trained model is evaluated on speech\nrecognition and lipreading tasks using one or two modalities, where the\nsuperiority is revealed.",
    "descriptor": "",
    "authors": [
      "Zi-Qiang Zhang",
      "Jie Zhang",
      "Jian-Shu Zhang",
      "Ming-Hui Wu",
      "Xin Fang",
      "Li-Rong Dai"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.07428"
  },
  {
    "id": "arXiv:2202.07477",
    "title": "Understanding DDPM Latent Codes Through Optimal Transport",
    "abstract": "Diffusion models have recently outperformed alternative approaches to model\nthe distribution of natural images, such as GANs. Such diffusion models allow\nfor deterministic sampling via the probability flow ODE, giving rise to a\nlatent space and an encoder map. While having important practical applications,\nsuch as estimation of the likelihood, the theoretical properties of this map\nare not yet fully understood. In the present work, we partially address this\nquestion for the popular case of the VP SDE (DDPM) approach. We show that,\nperhaps surprisingly, the DDPM encoder map coincides with the optimal transport\nmap for common distributions; we support this claim theoretically and by\nextensive numerical experiments.",
    "descriptor": "",
    "authors": [
      "Valentin Khrulkov",
      "Ivan Oseledets"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Analysis of PDEs (math.AP)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.07477"
  },
  {
    "id": "arXiv:2202.07506",
    "title": "Confidence Threshold Neural Diving",
    "abstract": "Finding a better feasible solution in a shorter time is an integral part of\nsolving Mixed Integer Programs. We present a post-hoc method based on Neural\nDiving to build heuristics more flexibly. We hypothesize that variables with\nhigher confidence scores are more definite to be included in the optimal\nsolution. For our hypothesis, we provide empirical evidence that confidence\nthreshold technique produces partial solutions leading to final solutions with\nbetter primal objective values. Our method won 2nd place in the primal task on\nthe NeurIPS 2021 ML4CO competition. Also, our method shows the best score among\nother learning-based methods in the competition.",
    "descriptor": "\nComments: Published on the NeurIPS 2021 ML4CO Competition Proceedings section, see this https URL\n",
    "authors": [
      "Taehyun Yoon"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Artificial Intelligence (cs.AI)",
      "Discrete Mathematics (cs.DM)",
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2202.07506"
  },
  {
    "id": "arXiv:2202.07508",
    "title": "Deep Constrained Least Squares for Blind Image Super-Resolution",
    "abstract": "In this paper, we tackle the problem of blind image super-resolution(SR) with\na reformulated degradation model and two novel modules. Following the common\npractices of blind SR, our method proposes to improve both the kernel\nestimation as well as the kernel based high resolution image restoration. To be\nmore specific, we first reformulate the degradation model such that the\ndeblurring kernel estimation can be transferred into the low resolution space.\nOn top of this, we introduce a dynamic deep linear filter module. Instead of\nlearning a fixed kernel for all images, it can adaptively generate deblurring\nkernel weights conditional on the input and yields more robust kernel\nestimation. Subsequently, a deep constrained least square filtering module is\napplied to generate clean features based on the reformulation and estimated\nkernel. The deblurred feature and the low input image feature are then fed into\na dual-path structured SR network and restore the final high resolution result.\nTo evaluate our method, we further conduct evaluations on several benchmarks,\nincluding Gaussian8 and DIV2KRK. Our experiments demonstrate that the proposed\nmethod achieves better accuracy and visual improvements against\nstate-of-the-art methods.",
    "descriptor": "\nComments: 11 pages, 7 tables, 11 figures\n",
    "authors": [
      "Ziwei Luo",
      "Haibin Huang",
      "Lei Yu",
      "Youwei Li",
      "Haoqiang Fan",
      "Shuaicheng Liu"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07508"
  },
  {
    "id": "arXiv:2202.07513",
    "title": "Post-Training Quantization for Cross-Platform Learned Image Compression",
    "abstract": "It has been witnessed that learned image compression has outperformed\nconventional image coding techniques and tends to be practical in industrial\napplications. One of the most critical issues that need to be considered is the\nnon-deterministic calculation, which makes the probability prediction\ncross-platform inconsistent and frustrates successful decoding. We propose to\nsolve this problem by introducing well-developed post-training quantization and\nmaking the model inference integer-arithmetic-only, which is much simpler than\npresently existing training and fine-tuning based approaches yet still keeps\nthe superior rate-distortion performance of learned image compression. Based on\nthat, we further improve the discretization of the entropy parameters and\nextend the deterministic inference to fit Gaussian mixture models. With our\nproposed methods, the current state-of-the-art image compression models can\ninfer in a cross-platform consistent manner, which makes the further\ndevelopment and practice of learned image compression more promising.",
    "descriptor": "",
    "authors": [
      "Dailan He",
      "Ziming Yang",
      "Yuan Chen",
      "Qi Zhang",
      "Hongwei Qin",
      "Yan Wang"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07513"
  },
  {
    "id": "arXiv:2202.07523",
    "title": "SpaIn-Net: Spatially-Informed Stereophonic Music Source Separation",
    "abstract": "With the recent advancements of data driven approaches using deep neural\nnetworks, music source separation has been formulated as an instrument-specific\nsupervised problem. While existing deep learning models implicitly absorb the\nspatial information conveyed by the multi-channel input signals, we argue that\na more explicit and active use of spatial information could not only improve\nthe separation process but also provide an entry-point for many\nuser-interaction based tools. To this end, we introduce a control method based\non the stereophonic location of the sources of interest, expressed as the\npanning angle. We present various conditioning mechanisms, including the use of\nraw angle and its derived feature representations, and show that spatial\ninformation helps. Our proposed approaches improve the separation performance\ncompared to location agnostic architectures by 1.8 dB SI-SDR in our Slakh-based\nsimulated experiments. Furthermore, the proposed methods allow for the\ndisentanglement of same-class instruments, for example, in mixtures containing\ntwo guitar tracks. Finally, we also demonstrate that our approach is robust to\nincorrect source panning information, which can be incurred by our proposed\nuser interaction.",
    "descriptor": "\nComments: To Appear in Proc. ICASSP2022\n",
    "authors": [
      "Darius Petermann",
      "Minje Kim"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.07523"
  },
  {
    "id": "arXiv:2202.07550",
    "title": "Label fusion and training methods for reliable representation of  inter-rater uncertainty",
    "abstract": "Medical tasks are prone to inter-rater variability due to multiple factors\nsuch as image quality, professional experience and training, or guideline\nclarity. Training deep learning networks with annotations from multiple raters\nis a common practice that mitigates the model's bias towards a single expert.\nReliable models generating calibrated outputs and reflecting the inter-rater\ndisagreement are key to the integration of artificial intelligence in clinical\npractice. Various methods exist to take into account different expert labels.\nWe focus on comparing three label fusion methods: STAPLE, average of the\nrater's segmentation, and random sampling each rater's segmentation during\ntraining. Each label fusion method is studied using the conventional training\nframework or the recently published SoftSeg framework that limits information\nloss by treating the segmentation task as a regression. Our results, across 10\ndata splittings on two public datasets, indicate that SoftSeg models,\nregardless of the ground truth fusion method, had better calibration and\npreservation of the inter-rater rater variability compared with their\nconventional counterparts without impacting the segmentation performance.\nConventional models, i.e., trained with a Dice loss, with binary inputs, and\nsigmoid/softmax final activate, were overconfident and underestimated the\nuncertainty associated with inter-rater variability. Conversely, fusing labels\nby averaging with the SoftSeg framework led to underconfident outputs and\noverestimation of the rater disagreement. In terms of segmentation performance,\nthe best label fusion method was different for the two datasets studied,\nindicating this parameter might be task-dependent. However, SoftSeg had\nsegmentation performance systematically superior or equal to the conventionally\ntrained models and had the best calibration and preservation of the inter-rater\nvariability.",
    "descriptor": "",
    "authors": [
      "Andreanne Lemay",
      "Charley Gros",
      "Julien Cohen-Adad"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07550"
  },
  {
    "id": "arXiv:2202.07562",
    "title": "Improving the repeatability of deep learning models with Monte Carlo  dropout",
    "abstract": "The integration of artificial intelligence into clinical workflows requires\nreliable and robust models. Repeatability is a key attribute of model\nrobustness. Repeatable models output predictions with low variation during\nindependent tests carried out under similar conditions. During model\ndevelopment and evaluation, much attention is given to classification\nperformance while model repeatability is rarely assessed, leading to the\ndevelopment of models that are unusable in clinical practice. In this work, we\nevaluate the repeatability of four model types (binary classification,\nmulti-class classification, ordinal classification, and regression) on images\nthat were acquired from the same patient during the same visit. We study the\nperformance of binary, multi-class, ordinal, and regression models on four\nmedical image classification tasks from public and private datasets: knee\nosteoarthritis, cervical cancer screening, breast density estimation, and\nretinopathy of prematurity. Repeatability is measured and compared on ResNet\nand DenseNet architectures. Moreover, we assess the impact of sampling Monte\nCarlo dropout predictions at test time on classification performance and\nrepeatability. Leveraging Monte Carlo predictions significantly increased\nrepeatability for all tasks on the binary, multi-class, and ordinal models\nleading to an average reduction of the 95\\% limits of agreement by 16% points\nand of the disagreement rate by 7% points. The classification accuracy improved\nin most settings along with the repeatability. Our results suggest that beyond\nabout 20 Monte Carlo iterations, there is no further gain in repeatability. In\naddition to the higher test-retest agreement, Monte Carlo predictions were\nbetter calibrated which leads to output probabilities reflecting more\naccurately the true likelihood of being correctly classified.",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2111.06754\n",
    "authors": [
      "Andreanne Lemay",
      "Katharina Hoebel",
      "Christopher P. Bridge",
      "Brian Befano",
      "Silvia De Sanjos\u00e9",
      "Diden Egemen",
      "Ana Cecilia Rodriguez",
      "Mark Schiffman",
      "John Peter Campbell",
      "Jayashree Kalpathy-Cramer"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.07562"
  },
  {
    "id": "arXiv:2202.07575",
    "title": "Forecasting Global Weather with Graph Neural Networks",
    "abstract": "We present a data-driven approach for forecasting global weather using graph\nneural networks. The system learns to step forward the current 3D atmospheric\nstate by six hours, and multiple steps are chained together to produce skillful\nforecasts going out several days into the future. The underlying model is\ntrained on reanalysis data from ERA5 or forecast data from GFS. Test\nperformance on metrics such as Z500 (geopotential height) and T850\n(temperature) improves upon previous data-driven approaches and is comparable\nto operational, full-resolution, physical models from GFS and ECMWF, at least\nwhen evaluated on 1-degree scales and when using reanalysis initial conditions.\nWe also show results from connecting this data-driven model to live,\noperational forecasts from GFS.",
    "descriptor": "",
    "authors": [
      "Ryan Keisler"
    ],
    "subjectives": [
      "Atmospheric and Oceanic Physics (physics.ao-ph)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07575"
  },
  {
    "id": "arXiv:2202.07582",
    "title": "Monoidal Width",
    "abstract": "We introduce monoidal width as a measure of the difficulty of decomposing\nmorphisms in monoidal categories. For graphs, we show that monoidal width and\ntwo variations capture existing notions, namely branch width, tree width and\npath width. Through these and other examples, we propose that monoidal width:\n(i) is a promising concept that, while capturing known measures, can similarly\nbe instantiated in other settings, avoiding the need for ad-hoc domain-specific\ndefinitions and (ii) comes with a general, formal algebraic notion of\ndecomposition using the language of monoidal categories.",
    "descriptor": "\nComments: 23 pages\n",
    "authors": [
      "Elena Di Lavore",
      "Pawe\u0142 Soboci\u0144ski"
    ],
    "subjectives": [
      "Category Theory (math.CT)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.07582"
  },
  {
    "id": "arXiv:2202.07590",
    "title": "Identifying equivalent Calabi--Yau topologies: A discrete challenge from  math and physics for machine learning",
    "abstract": "We review briefly the characteristic topological data of Calabi--Yau\nthreefolds and focus on the question of when two threefolds are equivalent\nthrough related topological data. This provides an interesting test case for\nmachine learning methodology in discrete mathematics problems motivated by\nphysics.",
    "descriptor": "\nComments: 6 pages, 3 figures; Contribution to proceedings of 2021 Nankai symposium on Mathematical Dialogues in celebration of S. S. Chern's 110th anniversary\n",
    "authors": [
      "Vishnu Jejjala",
      "Washington Taylor",
      "Andrew Turner"
    ],
    "subjectives": [
      "High Energy Physics - Theory (hep-th)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.07590"
  },
  {
    "id": "arXiv:2202.07608",
    "title": "Graphs of bounded twin-width are quasi-polynomially $\u03c7$-bounded",
    "abstract": "We prove that for every $t\\in \\mathbb{N}$ there is a constant $\\gamma_t$ such\nthat every graph with twin-width at most $t$ and clique number $\\omega$ has\nchromatic number bounded by $2^{\\gamma_t \\log^{4t+3} \\omega}$. In other words,\nwe prove that graph classes of bounded twin-width are quasi-polynomially\n$\\chi$-bounded. This provides a significant step towards resolving the question\nof Bonnet et al. [ICALP 2021] about whether they are polynomially\n$\\chi$-bounded.",
    "descriptor": "\nComments: 21 pages, 2 figures\n",
    "authors": [
      "Micha\u0142 Pilipczuk",
      "Marek Soko\u0142owski"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2202.07608"
  },
  {
    "id": "arXiv:2202.07617",
    "title": "Sensitivity of a Chaotic Logic Gate",
    "abstract": "Chaotic logic gates or `chaogates' are a promising mixed-signal approach to\ndesigning universal computers. However, chaotic systems are exponentially\nsensitive to small perturbations, and the effects of noise can cause chaotic\ncomputers to fail. Here, we examine the sensitivity of a simulated chaogate to\nnoise and other parameter variations (such as differences in supply voltage).\nWe find that the regions in parameter space corresponding to chaotic dynamics\ncoincide with the regions of maximum error in the computation. Further, this\nerror grows exponentially within 4-10 iterations of the chaotic map. As such,\nwe discuss the fundamental limitations of chaotic computing, and suggest\npotential improvements. Our Python simulation methods are open-source and\navailable at https://github.com/Noeloikeau/chaogate.",
    "descriptor": "",
    "authors": [
      "Noeloikeau Charlot",
      "Daniel J. Gauthier"
    ],
    "subjectives": [
      "Chaotic Dynamics (nlin.CD)",
      "Hardware Architecture (cs.AR)",
      "Logic in Computer Science (cs.LO)"
    ],
    "url": "https://arxiv.org/abs/2202.07617"
  },
  {
    "id": "arXiv:2202.07621",
    "title": "Second Best, Third Worst, Fourth in Line",
    "abstract": "We investigate decomposable combinatorial labeled structures more fully,\nfocusing on the exp-log class of type a=1 or 1/2. For instance, the modal\nlength of the second longest cycle in a random n-permutation is (0.2350...)n,\nwhereas the modal length of the second smallest component in a random n-mapping\nis 2 (conjecturally, given n>=434). As in earlier work, our approach is to\nestablish how well existing theory matches experimental data and to raise open\nquestions.",
    "descriptor": "\nComments: 17 pages\n",
    "authors": [
      "Steven Finch"
    ],
    "subjectives": [
      "Combinatorics (math.CO)",
      "Discrete Mathematics (cs.DM)",
      "Number Theory (math.NT)"
    ],
    "url": "https://arxiv.org/abs/2202.07621"
  },
  {
    "id": "arXiv:1609.02000",
    "title": "Cybernetic Cities: Designing and controlling adaptive and robust urban  systems",
    "abstract": "Cybernetic Cities: Designing and controlling adaptive and robust urban  systems",
    "descriptor": "",
    "authors": [
      "Carlos Gershenson",
      "Paolo Santi",
      "Carlo Ratti"
    ],
    "subjectives": [
      "Adaptation and Self-Organizing Systems (nlin.AO)",
      "Computers and Society (cs.CY)",
      "Physics and Society (physics.soc-ph)"
    ],
    "url": "https://arxiv.org/abs/1609.02000"
  },
  {
    "id": "arXiv:1911.03069",
    "title": "Towards local testability for quantum coding",
    "abstract": "Comments: 44 pages, an extended abstract appeared at ITCS 2021 v2: journal version",
    "descriptor": "\nComments: 44 pages, an extended abstract appeared at ITCS 2021 v2: journal version\n",
    "authors": [
      "Anthony Leverrier",
      "Vivien Londe",
      "Gilles Z\u00e9mor"
    ],
    "subjectives": [
      "Quantum Physics (quant-ph)",
      "Information Theory (cs.IT)",
      "Geometric Topology (math.GT)"
    ],
    "url": "https://arxiv.org/abs/1911.03069"
  },
  {
    "id": "arXiv:2002.09658",
    "title": "An Efficient MPC Algorithm For Switched Systems with Minimum Dwell Time  Constraints",
    "abstract": "An Efficient MPC Algorithm For Switched Systems with Minimum Dwell Time  Constraints",
    "descriptor": "",
    "authors": [
      "Yutao Chen",
      "Mircea Lazar"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2002.09658"
  },
  {
    "id": "arXiv:2004.01079",
    "title": "Understanding Linearity of Cross-Lingual Word Embedding Mappings",
    "abstract": "Understanding Linearity of Cross-Lingual Word Embedding Mappings",
    "descriptor": "",
    "authors": [
      "Xutan Peng",
      "Mark Stevenson",
      "Chenghua Lin",
      "Chen Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2004.01079"
  },
  {
    "id": "arXiv:2005.03645",
    "title": "XEM: An Explainable-by-Design Ensemble Method for Multivariate Time  Series Classification",
    "abstract": "Comments: Accepted for publication in Data Mining and Knowledge Discovery",
    "descriptor": "\nComments: Accepted for publication in Data Mining and Knowledge Discovery\n",
    "authors": [
      "Kevin Fauvel",
      "\u00c9lisa Fromont",
      "V\u00e9ronique Masson",
      "Philippe Faverdin",
      "Alexandre Termier"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.03645"
  },
  {
    "id": "arXiv:2005.12419",
    "title": "Network Comparison with Interpretable Contrastive Network Representation  Learning",
    "abstract": "Comments: To appear in Journal of Data Science, Statistics, and Visualisation. The previous preprint version was titled \"Interpretable Contrastive Learning for Networks\" (arXiv:2005.12419v1)",
    "descriptor": "\nComments: To appear in Journal of Data Science, Statistics, and Visualisation. The previous preprint version was titled \"Interpretable Contrastive Learning for Networks\" (arXiv:2005.12419v1)\n",
    "authors": [
      "Takanori Fujiwara",
      "Jian Zhao",
      "Francine Chen",
      "Yaoliang Yu",
      "Kwan-Liu Ma"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2005.12419"
  },
  {
    "id": "arXiv:2006.07540",
    "title": "MetaPerturb: Transferable Regularizer for Heterogeneous Tasks and  Architectures",
    "abstract": "MetaPerturb: Transferable Regularizer for Heterogeneous Tasks and  Architectures",
    "descriptor": "",
    "authors": [
      "Jeongun Ryu",
      "Jaewoong Shin",
      "Hae Beom Lee",
      "Sung Ju Hwang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2006.07540"
  },
  {
    "id": "arXiv:2006.10724",
    "title": "Cyclic Differentiable Architecture Search",
    "abstract": "Comments: Accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)",
    "descriptor": "\nComments: Accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)\n",
    "authors": [
      "Hongyuan Yu",
      "Houwen Peng",
      "Yan Huang",
      "Jianlong Fu",
      "Hao Du",
      "Liang Wang",
      "Haibin Ling"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2006.10724"
  },
  {
    "id": "arXiv:2007.00903",
    "title": "Optimality of the coordinate-wise median mechanism for strategyproof  facility location in two dimensions",
    "abstract": "Comments: 24 pages",
    "descriptor": "\nComments: 24 pages\n",
    "authors": [
      "Sumit Goel",
      "Wade Hann-Caruthers"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)"
    ],
    "url": "https://arxiv.org/abs/2007.00903"
  },
  {
    "id": "arXiv:2010.16115",
    "title": "The New Rewriting Engine of Dedukti",
    "abstract": "The New Rewriting Engine of Dedukti",
    "descriptor": "",
    "authors": [
      "Gabriel Hondet",
      "Fr\u00e9d\u00e9ric Blanqui"
    ],
    "subjectives": [
      "Programming Languages (cs.PL)",
      "Symbolic Computation (cs.SC)"
    ],
    "url": "https://arxiv.org/abs/2010.16115"
  },
  {
    "id": "arXiv:2011.14212",
    "title": "Approximate Midpoint Policy Iteration for Linear Quadratic Control",
    "abstract": "Approximate Midpoint Policy Iteration for Linear Quadratic Control",
    "descriptor": "",
    "authors": [
      "Benjamin Gravell",
      "Iman Shames",
      "Tyler Summers"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)",
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2011.14212"
  },
  {
    "id": "arXiv:2012.01375",
    "title": "Proper Selection of Obreshkov-Like Numerical Integrators Used as  Numerical Differentiators for Power System Transient Simulation",
    "abstract": "Comments: Accepted by the 2022 IEEE PES General Meeting",
    "descriptor": "\nComments: Accepted by the 2022 IEEE PES General Meeting\n",
    "authors": [
      "Sheng Lei",
      "Alexander Flueck"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2012.01375"
  },
  {
    "id": "arXiv:2101.04662",
    "title": "Output Regulation of Linear Aperiodic Sampled-Data Systems",
    "abstract": "Comments: Accepted for presentation at the American Control Conference 2022",
    "descriptor": "\nComments: Accepted for presentation at the American Control Conference 2022\n",
    "authors": [
      "Himadri Basu",
      "Francesco Ferrante",
      "Se Young Yoon"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2101.04662"
  },
  {
    "id": "arXiv:2101.10518",
    "title": "Autonomous Vehicle-to-Grid Design for Provision of Frequency Control  Ancillary Service and Distribution Voltage Regulation",
    "abstract": "Comments: 28 pages, 23 figures",
    "descriptor": "\nComments: 28 pages, 23 figures\n",
    "authors": [
      "Shota Yumiki",
      "Yoshihiko Susuki",
      "Yuta Oshikubo",
      "Yutaka Ota",
      "Ryo Masegi",
      "Akihiko Kawashima",
      "Atsushi Ishigame",
      "Shinkichi Inagaki",
      "Tatsuya Suzuki"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)",
      "Dynamical Systems (math.DS)"
    ],
    "url": "https://arxiv.org/abs/2101.10518"
  },
  {
    "id": "arXiv:2102.05082",
    "title": "Domain Invariant Representation Learning with Domain Density  Transformations",
    "abstract": "Comments: NeurIPS 2021",
    "descriptor": "\nComments: NeurIPS 2021\n",
    "authors": [
      "A. Tuan Nguyen",
      "Toan Tran",
      "Yarin Gal",
      "At\u0131l\u0131m G\u00fcne\u015f Baydin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.05082"
  },
  {
    "id": "arXiv:2102.11938",
    "title": "Baby Intuitions Benchmark (BIB): Discerning the goals, preferences, and  actions of others",
    "abstract": "Comments: Published in Advances in Neural Information Processing Systems (NeurIPS) 34",
    "descriptor": "\nComments: Published in Advances in Neural Information Processing Systems (NeurIPS) 34\n",
    "authors": [
      "Kanishk Gandhi",
      "Gala Stojnic",
      "Brenden M. Lake",
      "Moira R. Dillon"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2102.11938"
  },
  {
    "id": "arXiv:2103.03036",
    "title": "A Survey on Graph Structure Learning: Progress and Opportunities",
    "abstract": "Comments: Work in progress, in submission to IJCAI 2022 (Survey Track)",
    "descriptor": "\nComments: Work in progress, in submission to IJCAI 2022 (Survey Track)\n",
    "authors": [
      "Yanqiao Zhu",
      "Weizhi Xu",
      "Jinghao Zhang",
      "Yuanqi Du",
      "Jieyu Zhang",
      "Qiang Liu",
      "Carl Yang",
      "Shu Wu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Social and Information Networks (cs.SI)"
    ],
    "url": "https://arxiv.org/abs/2103.03036"
  },
  {
    "id": "arXiv:2103.06169",
    "title": "On the primitivity of the AES-128 key-schedule",
    "abstract": "On the primitivity of the AES-128 key-schedule",
    "descriptor": "",
    "authors": [
      "Riccardo Aragona",
      "Roberto Civino",
      "Francesca Dalla Volta"
    ],
    "subjectives": [
      "Group Theory (math.GR)",
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2103.06169"
  },
  {
    "id": "arXiv:2103.12415",
    "title": "Towards 6G Holographic Localization: Enabling Technologies and  Perspectives",
    "abstract": "Comments: 7 pages, 4 figures",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Ahmed Elzanaty",
      "Anna Guerra",
      "Francesco Guidi",
      "Davide Dardari",
      "Mohamed-Slim Alouini"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2103.12415"
  },
  {
    "id": "arXiv:2104.11725",
    "title": "SpectralFly: Ramanujan Graphs as Flexible and Efficient Interconnection  Networks",
    "abstract": "SpectralFly: Ramanujan Graphs as Flexible and Efficient Interconnection  Networks",
    "descriptor": "",
    "authors": [
      "Stephen Young",
      "Sinan Aksoy",
      "Jesun Firoz",
      "Roberto Gioiosa",
      "Tobias Hagge",
      "Mark Kempton",
      "Juan Escobedo",
      "Mark Raugas"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Discrete Mathematics (cs.DM)"
    ],
    "url": "https://arxiv.org/abs/2104.11725"
  },
  {
    "id": "arXiv:2104.11803",
    "title": "Automata-based Controller Synthesis for Stochastic Systems: A Game  Framework via Approximate Probabilistic Relations",
    "abstract": "Comments: 36 pages, 10 figures",
    "descriptor": "\nComments: 36 pages, 10 figures\n",
    "authors": [
      "Bingzhuo Zhong",
      "Abolfazl Lavaei",
      "Majid Zamani",
      "Marco Caccamo"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2104.11803"
  },
  {
    "id": "arXiv:2104.14362",
    "title": "From Distributed Machine Learning to Federated Learning: A Survey",
    "abstract": "Comments: 36 pages, 8 figures",
    "descriptor": "\nComments: 36 pages, 8 figures\n",
    "authors": [
      "Ji Liu",
      "Jizhou Huang",
      "Yang Zhou",
      "Xuhong Li",
      "Shilei Ji",
      "Haoyi Xiong",
      "Dejing Dou"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2104.14362"
  },
  {
    "id": "arXiv:2105.03725",
    "title": "DAMOV: A New Methodology and Benchmark Suite for Evaluating Data  Movement Bottlenecks",
    "abstract": "Comments: Our open source software is available at this https URL",
    "descriptor": "\nComments: Our open source software is available at this https URL\n",
    "authors": [
      "Geraldo F. Oliveira",
      "Juan G\u00f3mez-Luna",
      "Lois Orosa",
      "Saugata Ghose",
      "Nandita Vijaykumar",
      "Ivan Fernandez",
      "Mohammad Sadrosadati",
      "Onur Mutlu"
    ],
    "subjectives": [
      "Hardware Architecture (cs.AR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2105.03725"
  },
  {
    "id": "arXiv:2105.10368",
    "title": "Development and evaluation of an Explainable Prediction Model for  Chronic Kidney Disease Patients based on Ensemble Trees",
    "abstract": "Development and evaluation of an Explainable Prediction Model for  Chronic Kidney Disease Patients based on Ensemble Trees",
    "descriptor": "",
    "authors": [
      "Pedro A. Moreno-Sanchez"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2105.10368"
  },
  {
    "id": "arXiv:2105.11636",
    "title": "FILTRA: Rethinking Steerable CNN by Filter Transform",
    "abstract": "Comments: ICML 2021",
    "descriptor": "\nComments: ICML 2021\n",
    "authors": [
      "Bo Li",
      "Qili Wang",
      "Gim Hee Lee"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2105.11636"
  },
  {
    "id": "arXiv:2105.14137",
    "title": "What Makes a Game High-rated? Towards Factors of Video Game Success",
    "abstract": "What Makes a Game High-rated? Towards Factors of Video Game Success",
    "descriptor": "",
    "authors": [
      "Gabriel Ullmann",
      "Cristiano Politowski",
      "Yann-G\u00e4el Gu\u00e9h\u00e9neuc",
      "Fabio Petrillo"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2105.14137"
  },
  {
    "id": "arXiv:2105.14150",
    "title": "Annotation Inconsistency and Entity Bias in MultiWOZ",
    "abstract": "Comments: Accepted by SIGDIAL 2021",
    "descriptor": "\nComments: Accepted by SIGDIAL 2021\n",
    "authors": [
      "Kun Qian",
      "Ahmad Beirami",
      "Zhouhan Lin",
      "Ankita De",
      "Alborz Geramifard",
      "Zhou Yu",
      "Chinnadhurai Sankar"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2105.14150"
  },
  {
    "id": "arXiv:2106.02024",
    "title": "Combinatorial Algorithms for Matching Markets via Nash Bargaining:  One-Sided, Two-Sided and Non-Bipartite",
    "abstract": "Comments: 52 pages",
    "descriptor": "\nComments: 52 pages\n",
    "authors": [
      "Ioannis Panageas",
      "Thorben Tr\u00f6bst",
      "Vijay V. Vazirani"
    ],
    "subjectives": [
      "Computer Science and Game Theory (cs.GT)",
      "General Economics (econ.GN)"
    ],
    "url": "https://arxiv.org/abs/2106.02024"
  },
  {
    "id": "arXiv:2106.05319",
    "title": "Stein Latent Optimization for Generative Adversarial Networks",
    "abstract": "Comments: ICLR 2022 camera ready",
    "descriptor": "\nComments: ICLR 2022 camera ready\n",
    "authors": [
      "Uiwon Hwang",
      "Heeseung Kim",
      "Dahuin Jung",
      "Hyemi Jang",
      "Hyungyu Lee",
      "Sungroh Yoon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2106.05319"
  },
  {
    "id": "arXiv:2106.05885",
    "title": "Balanced End-to-End Monolingual pre-training for Low-Resourced Indic  Languages Code-Switching Speech Recognition",
    "abstract": "Balanced End-to-End Monolingual pre-training for Low-Resourced Indic  Languages Code-Switching Speech Recognition",
    "descriptor": "",
    "authors": [
      "Amir Hussein",
      "Shammur Chowdhury",
      "Najim Dehak",
      "Ahmed Ali"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2106.05885"
  },
  {
    "id": "arXiv:2106.06012",
    "title": "Learning distinct features helps, provably",
    "abstract": "Comments: 17 pages, 3 figure",
    "descriptor": "\nComments: 17 pages, 3 figure\n",
    "authors": [
      "Firas Laakom",
      "Jenni Raitoharju",
      "Alexandros Iosifidis",
      "Moncef Gabbouj"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2106.06012"
  },
  {
    "id": "arXiv:2106.07831",
    "title": "Efficient Asynchronous Byzantine Agreement without Private Setups",
    "abstract": "Efficient Asynchronous Byzantine Agreement without Private Setups",
    "descriptor": "",
    "authors": [
      "Yingzi Gao",
      "Yuan Lu",
      "Zhenliang Lu",
      "Qiang Tang",
      "Jing Xu",
      "Zhenfeng Zhang"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2106.07831"
  },
  {
    "id": "arXiv:2106.08374",
    "title": "Warning signs for non-Markovian bifurcations: colour blindness and  scaling laws",
    "abstract": "Warning signs for non-Markovian bifurcations: colour blindness and  scaling laws",
    "descriptor": "",
    "authors": [
      "Christian Kuehn",
      "Kerstin Lux",
      "Alexandra Neamtu"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Numerical Analysis (math.NA)",
      "Probability (math.PR)",
      "Chaotic Dynamics (nlin.CD)"
    ],
    "url": "https://arxiv.org/abs/2106.08374"
  },
  {
    "id": "arXiv:2106.09408",
    "title": "Predicting cognitive scores with graph neural networks through sample  selection learning",
    "abstract": "Comments: Corrected two typos (dimension of weight matrix and i -&gt; i+1) in description of GNN architecture",
    "descriptor": "\nComments: Corrected two typos (dimension of weight matrix and i -&gt; i+1) in description of GNN architecture\n",
    "authors": [
      "Martin Hanik",
      "Mehmet Arif Demirta\u015f",
      "Mohammed Amine Gharsallaoui",
      "Islem Rekik"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neurons and Cognition (q-bio.NC)"
    ],
    "url": "https://arxiv.org/abs/2106.09408"
  },
  {
    "id": "arXiv:2106.13746",
    "title": "On Incorporating Inductive Biases into VAEs",
    "abstract": "On Incorporating Inductive Biases into VAEs",
    "descriptor": "",
    "authors": [
      "Ning Miao",
      "Emile Mathieu",
      "N. Siddharth",
      "Yee Whye Teh",
      "Tom Rainforth"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.13746"
  },
  {
    "id": "arXiv:2106.14465",
    "title": "Exploring convolutional neural networks with transfer learning for  diagnosing Lyme disease from skin lesion images",
    "abstract": "Exploring convolutional neural networks with transfer learning for  diagnosing Lyme disease from skin lesion images",
    "descriptor": "",
    "authors": [
      "Sk Imran Hossain",
      "Jocelyn de Go\u00ebr de Herve",
      "Md Shahriar Hassan",
      "Delphine Martineau",
      "Evelina Petrosyan",
      "Violaine Corbain",
      "Jean Beytout",
      "Isabelle Lebert",
      "Elisabeth Baux",
      "C\u00e9line Cazorla",
      "Carole Eldin",
      "Yves Hansmann",
      "Solene Patrat-Delon",
      "Thierry Prazuck",
      "Alice Raffetin",
      "Pierre Tattevin",
      "Gwena\u00ebl Vourc'H",
      "Olivier Lesens",
      "Engelbert Nguifo"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2106.14465"
  },
  {
    "id": "arXiv:2106.14817",
    "title": "A fast Chebyshev method for the Bingham closure with application to  active nematic suspensions",
    "abstract": "A fast Chebyshev method for the Bingham closure with application to  active nematic suspensions",
    "descriptor": "",
    "authors": [
      "Scott Weady",
      "Michael J. Shelley",
      "David B. Stein"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2106.14817"
  },
  {
    "id": "arXiv:2106.15216",
    "title": "A Non-parametric View of FedAvg and FedProx: Beyond Stationary Points",
    "abstract": "A Non-parametric View of FedAvg and FedProx: Beyond Stationary Points",
    "descriptor": "",
    "authors": [
      "Lili Su",
      "Jiaming Xu",
      "Pengkun Yang"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2106.15216"
  },
  {
    "id": "arXiv:2107.02371",
    "title": "Weighted Gaussian Process Bandits for Non-stationary Environments",
    "abstract": "Weighted Gaussian Process Bandits for Non-stationary Environments",
    "descriptor": "",
    "authors": [
      "Yuntian Deng",
      "Xingyu Zhou",
      "Baekjin Kim",
      "Ambuj Tewari",
      "Abhishek Gupta",
      "Ness Shroff"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2107.02371"
  },
  {
    "id": "arXiv:2107.05134",
    "title": "Dual Training of Energy-Based Models with Overparametrized Shallow  Neural Networks",
    "abstract": "Dual Training of Energy-Based Models with Overparametrized Shallow  Neural Networks",
    "descriptor": "",
    "authors": [
      "Carles Domingo-Enrich",
      "Alberto Bietti",
      "Marylou Gabri\u00e9",
      "Joan Bruna",
      "Eric Vanden-Eijnden"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2107.05134"
  },
  {
    "id": "arXiv:2107.08386",
    "title": "A Bilevel Programming Framework for Joint Edge Resource Management and  Pricing",
    "abstract": "A Bilevel Programming Framework for Joint Edge Resource Management and  Pricing",
    "descriptor": "",
    "authors": [
      "Tarannum Nisha",
      "Duong Tung Nguyen",
      "Vijay K. Bhargava"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2107.08386"
  },
  {
    "id": "arXiv:2107.09992",
    "title": "Levels of Automation for a Mobile Robot Teleoperated by a Caregiver",
    "abstract": "Comments: 13 pages, 4 figures, 4 tables",
    "descriptor": "\nComments: 13 pages, 4 figures, 4 tables\n",
    "authors": [
      "Samuel Olatunji",
      "Andre Potenza",
      "Andrey Kiselev",
      "Tal Oron-Gilad",
      "Amy Loutfi",
      "Yael Edan"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2107.09992"
  },
  {
    "id": "arXiv:2107.10689",
    "title": "Testing isomorphism of chordal graphs of bounded leafage is  fixed-parameter tractable",
    "abstract": "Testing isomorphism of chordal graphs of bounded leafage is  fixed-parameter tractable",
    "descriptor": "",
    "authors": [
      "Vikraman Arvind",
      "Roman Nedela",
      "Ilia Ponomarenko",
      "Peter Zeman"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Discrete Mathematics (cs.DM)",
      "Combinatorics (math.CO)"
    ],
    "url": "https://arxiv.org/abs/2107.10689"
  },
  {
    "id": "arXiv:2107.12108",
    "title": "Development of a 3D Digital Twin of the Swalmen Tunnel in the  Rijkswaterstaat Project",
    "abstract": "Development of a 3D Digital Twin of the Swalmen Tunnel in the  Rijkswaterstaat Project",
    "descriptor": "",
    "authors": [
      "J. van Hegelsom",
      "J.M. van de Mortel-Fronczak",
      "L. Moormann",
      "D.A. van Beek",
      "J.E. Rooda"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2107.12108"
  },
  {
    "id": "arXiv:2108.03900",
    "title": "Multi-Scale STATCN: Self-Attention based Spatiotemporal Model for  Short-Term Metro Origin-Destination Matrix Prediction",
    "abstract": "Comments: 12 pages, 6 figures, 3 tables",
    "descriptor": "\nComments: 12 pages, 6 figures, 3 tables\n",
    "authors": [
      "Jiexia Ye",
      "Furong Zheng",
      "Juanjuan Zhao",
      "Chengzhong Xu"
    ],
    "subjectives": [
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.03900"
  },
  {
    "id": "arXiv:2108.04108",
    "title": "Team Power Dynamics and Team Impact: New Perspectives on Scientific  Collaboration using Career Age as a Proxy for Team Power",
    "abstract": "Team Power Dynamics and Team Impact: New Perspectives on Scientific  Collaboration using Career Age as a Proxy for Team Power",
    "descriptor": "",
    "authors": [
      "Huimin Xu",
      "Yi Bu",
      "Meijun Liu",
      "Chenwei Zhang",
      "Mengyi Sun",
      "Yi Zhang",
      "Eric Meyer",
      "Eduardo Salas",
      "Ying Ding"
    ],
    "subjectives": [
      "Physics and Society (physics.soc-ph)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2108.04108"
  },
  {
    "id": "arXiv:2108.12373",
    "title": "FAST-PCA: A Fast and Exact Algorithm for Distributed Principal Component  Analysis",
    "abstract": "Comments: 16 pages (two-column version); substantially revised version, including expanded comparisons with other works",
    "descriptor": "\nComments: 16 pages (two-column version); substantially revised version, including expanded comparisons with other works\n",
    "authors": [
      "Arpita Gang",
      "Waheed U. Bajwa"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Signal Processing (eess.SP)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2108.12373"
  },
  {
    "id": "arXiv:2108.12383",
    "title": "A Guide to Computational Reproducibility in Signal Processing and  Machine Learning",
    "abstract": "Comments: 20 pages; preprint of a magazine article",
    "descriptor": "\nComments: 20 pages; preprint of a magazine article\n",
    "authors": [
      "Joseph Shenouda",
      "Waheed U. Bajwa"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2108.12383"
  },
  {
    "id": "arXiv:2109.00046",
    "title": "Scalable Spatiotemporally Varying Coefficient Modelling with Bayesian  Kernelized Tensor Regression",
    "abstract": "Scalable Spatiotemporally Varying Coefficient Modelling with Bayesian  Kernelized Tensor Regression",
    "descriptor": "",
    "authors": [
      "Mengying Lei",
      "Aurelie Labbe",
      "Lijun Sun"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.00046"
  },
  {
    "id": "arXiv:2109.00595",
    "title": "Boundary and Taxonomy of Integrator Reach Sets",
    "abstract": "Comments: arXiv admin note: text overlap with arXiv:2102.11423",
    "descriptor": "\nComments: arXiv admin note: text overlap with arXiv:2102.11423\n",
    "authors": [
      "Shadi Haddad",
      "Abhishek Halder"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.00595"
  },
  {
    "id": "arXiv:2109.02473",
    "title": "A Robust Cybersecurity Topic Classification Tool",
    "abstract": "Comments: Extended journal version for IJNSA (this https URL)",
    "descriptor": "\nComments: Extended journal version for IJNSA (this https URL)\n",
    "authors": [
      "Elijah Pelofske",
      "Lorie M. Liebrock",
      "Vincent Urias"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2109.02473"
  },
  {
    "id": "arXiv:2109.03011",
    "title": "LEAF: Navigating Concept Drift in Cellular Networks",
    "abstract": "LEAF: Navigating Concept Drift in Cellular Networks",
    "descriptor": "",
    "authors": [
      "Shinan Liu",
      "Francesco Bronzino",
      "Paul Schmitt",
      "Arjun Nitin Bhagoji",
      "Nick Feamster",
      "Hector Garcia Crespo",
      "Timothy Coyle",
      "Brian Ward"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)",
      "Performance (cs.PF)"
    ],
    "url": "https://arxiv.org/abs/2109.03011"
  },
  {
    "id": "arXiv:2109.03530",
    "title": "Logistic growth on networks: exact solutions for the SI model",
    "abstract": "Comments: 15 pages, 4 figures, accompanied by a software package at this https URL v2: extended explanation and incorporated supplemental material into the main text. Accepted for publication in Phys.Rev. E",
    "descriptor": "\nComments: 15 pages, 4 figures, accompanied by a software package at this https URL v2: extended explanation and incorporated supplemental material into the main text. Accepted for publication in Phys.Rev. E\n",
    "authors": [
      "Wout Merbis",
      "Ivano Lodato"
    ],
    "subjectives": [
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Social and Information Networks (cs.SI)",
      "Physics and Society (physics.soc-ph)",
      "Populations and Evolution (q-bio.PE)"
    ],
    "url": "https://arxiv.org/abs/2109.03530"
  },
  {
    "id": "arXiv:2109.04968",
    "title": "Uncertainty-Aware Capacity Allocation in Flow-Based Market Coupling",
    "abstract": "Uncertainty-Aware Capacity Allocation in Flow-Based Market Coupling",
    "descriptor": "",
    "authors": [
      "Richard Weinhold",
      "Robert Mieth"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.04968"
  },
  {
    "id": "arXiv:2109.05714",
    "title": "Vision-Aided Autonomous Navigation of Underactuated Bipedal Robots in  Height-Constrained Environments",
    "abstract": "Comments: submitted to International Journal of Robotics Research (IJRR)",
    "descriptor": "\nComments: submitted to International Journal of Robotics Research (IJRR)\n",
    "authors": [
      "Zhongyu Li",
      "Jun Zeng",
      "Shuxiao Chen",
      "Koushil Sreenath"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Artificial Intelligence (cs.AI)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2109.05714"
  },
  {
    "id": "arXiv:2109.05812",
    "title": "UniMS: A Unified Framework for Multimodal Summarization with Knowledge  Distillation",
    "abstract": "Comments: Accepted at AAAI2022",
    "descriptor": "\nComments: Accepted at AAAI2022\n",
    "authors": [
      "Zhengkun Zhang",
      "Xiaojun Meng",
      "Yasheng Wang",
      "Xin Jiang",
      "Qun Liu",
      "Zhenglu Yang"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2109.05812"
  },
  {
    "id": "arXiv:2109.06593",
    "title": "Online Algorithms with Lookaround",
    "abstract": "Online Algorithms with Lookaround",
    "descriptor": "",
    "authors": [
      "Amirreza Akbari",
      "Henrik Lievonen",
      "Darya Melnyk",
      "Joona S\u00e4rkij\u00e4rvi",
      "Jukka Suomela"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Distributed, Parallel, and Cluster Computing (cs.DC)"
    ],
    "url": "https://arxiv.org/abs/2109.06593"
  },
  {
    "id": "arXiv:2109.07868",
    "title": "The Influence of Human Aspects on Requirements Engineering-related  Activities: Software Practitioners Perspective",
    "abstract": "Comments: Submitted to ACM Transactions on Software Engineering and Methodology (under review), 37 pages, 8 figures, 7 tables",
    "descriptor": "\nComments: Submitted to ACM Transactions on Software Engineering and Methodology (under review), 37 pages, 8 figures, 7 tables\n",
    "authors": [
      "Dulaji Hidellaarachchi",
      "John Grundy",
      "Rashina Hoda",
      "Ingo Mueller"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2109.07868"
  },
  {
    "id": "arXiv:2109.09828",
    "title": "iRNN: Integer-only Recurrent Neural Network",
    "abstract": "iRNN: Integer-only Recurrent Neural Network",
    "descriptor": "",
    "authors": [
      "Eyy\u00fcb Sari",
      "Vanessa Courville",
      "Vahid Partovi Nia"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2109.09828"
  },
  {
    "id": "arXiv:2109.11615",
    "title": "Keypoints-Based Deep Feature Fusion for Cooperative Vehicle Detection of  Autonomous Driving",
    "abstract": "Keypoints-Based Deep Feature Fusion for Cooperative Vehicle Detection of  Autonomous Driving",
    "descriptor": "",
    "authors": [
      "Yunshuang Yuan",
      "Hao Cheng",
      "Monika Sester"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2109.11615"
  },
  {
    "id": "arXiv:2109.13596",
    "title": "Exploratory State Representation Learning",
    "abstract": "Exploratory State Representation Learning",
    "descriptor": "",
    "authors": [
      "Astrid Merckling",
      "Nicolas Perrin-Gilbert",
      "Alex Coninx",
      "St\u00e9phane Doncieux"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2109.13596"
  },
  {
    "id": "arXiv:2109.14545",
    "title": "A Comprehensive Survey and Performance Analysis of Activation Functions  in Deep Learning",
    "abstract": "A Comprehensive Survey and Performance Analysis of Activation Functions  in Deep Learning",
    "descriptor": "",
    "authors": [
      "Shiv Ram Dubey",
      "Satish Kumar Singh",
      "Bidyut Baran Chaudhuri"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Neural and Evolutionary Computing (cs.NE)"
    ],
    "url": "https://arxiv.org/abs/2109.14545"
  },
  {
    "id": "arXiv:2109.14820",
    "title": "A Generalized Hierarchical Nonnegative Tensor Decomposition",
    "abstract": "Comments: 6 pages, 2 figues, 3 tables",
    "descriptor": "\nComments: 6 pages, 2 figues, 3 tables\n",
    "authors": [
      "Joshua Vendrow",
      "Jamie Haddock",
      "Deanna Needell"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2109.14820"
  },
  {
    "id": "arXiv:2109.15226",
    "title": "Coding for Straggler Mitigation in Federated Learning",
    "abstract": "Comments: 6 pages, 3 figures, published at the IEEE International Conference on Communications 2022",
    "descriptor": "\nComments: 6 pages, 3 figures, published at the IEEE International Conference on Communications 2022\n",
    "authors": [
      "Siddhartha Kumar",
      "Reent Schlegel",
      "Eirik Rosnes",
      "Alexandre Graell i Amat"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2109.15226"
  },
  {
    "id": "arXiv:2110.00957",
    "title": "Graph Representation Learning for Spatial Image Steganalysis",
    "abstract": "Comments: this https URL&hl=en",
    "descriptor": "\nComments: this https URL&hl=en\n",
    "authors": [
      "Qiyun Liu",
      "Hanzhou Wu"
    ],
    "subjectives": [
      "Multimedia (cs.MM)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2110.00957"
  },
  {
    "id": "arXiv:2110.01098",
    "title": "Garbage Collection Makes Rust Easier to Use: A Randomized Controlled  Trial of the Bronze Garbage Collector",
    "abstract": "Comments: Michael Coblenz, Michelle L. Mazurek, and Michael Hicks. 2022. Garbage Collection Makes Rust Easier to Use: A Randomized Controlled Trial of the Bronze Garbage Collector. In 44th International Conference on Software Engineering (ICSE '22), May 21-29, 2022, Pittsburgh, PA, USA. ACM, New York, NY, USA, 12 pages. this https URL",
    "descriptor": "\nComments: Michael Coblenz, Michelle L. Mazurek, and Michael Hicks. 2022. Garbage Collection Makes Rust Easier to Use: A Randomized Controlled Trial of the Bronze Garbage Collector. In 44th International Conference on Software Engineering (ICSE '22), May 21-29, 2022, Pittsburgh, PA, USA. ACM, New York, NY, USA, 12 pages. this https URL\n",
    "authors": [
      "Michael Coblenz",
      "Michelle Mazurek",
      "Michael Hicks"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Programming Languages (cs.PL)"
    ],
    "url": "https://arxiv.org/abs/2110.01098"
  },
  {
    "id": "arXiv:2110.01691",
    "title": "AI Chains: Transparent and Controllable Human-AI Interaction by Chaining  Large Language Model Prompts",
    "abstract": "AI Chains: Transparent and Controllable Human-AI Interaction by Chaining  Large Language Model Prompts",
    "descriptor": "",
    "authors": [
      "Tongshuang Wu",
      "Michael Terry",
      "Carrie J. Cai"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)",
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2110.01691"
  },
  {
    "id": "arXiv:2110.02258",
    "title": "Thumb Stabilization and Assistance in a Robotic Hand Orthosis for  Post-Stroke Hemiparesis",
    "abstract": "Comments: 7 pages, 4 figures",
    "descriptor": "\nComments: 7 pages, 4 figures\n",
    "authors": [
      "Ava Chen",
      "Lauren Winterbottom",
      "Sangwoo Park",
      "Jingxi Xu",
      "Dawn Nilsen",
      "Joel Stein",
      "Matei Ciocarlie"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2110.02258"
  },
  {
    "id": "arXiv:2110.02878",
    "title": "An Investigation of the Effectiveness of Phase for Audio Classification",
    "abstract": "Comments: 5 pages, 3 figures",
    "descriptor": "\nComments: 5 pages, 3 figures\n",
    "authors": [
      "Shunsuke Hidaka",
      "Kohei Wakamiya",
      "Tokihiko Kaburagi"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.02878"
  },
  {
    "id": "arXiv:2110.03545",
    "title": "Privacy-Preserving Coded Mobile Edge Computing for Low-Latency  Distributed Inference",
    "abstract": "Comments: 12 pages, 6 figures, published in the Journal on Selected Areas in Communications",
    "descriptor": "\nComments: 12 pages, 6 figures, published in the Journal on Selected Areas in Communications\n",
    "authors": [
      "Reent Schlegel",
      "Siddhartha Kumar",
      "Eirik Rosnes",
      "Alexandre Graell i Amat"
    ],
    "subjectives": [
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.03545"
  },
  {
    "id": "arXiv:2110.04525",
    "title": "Generating Disentangled Arguments with Prompts: A Simple Event  Extraction Framework that Works",
    "abstract": "Comments: Accepted at ICASSP 2022. Without the strict length constraint, this version (slightly) extends the conference camera-ready version",
    "descriptor": "\nComments: Accepted at ICASSP 2022. Without the strict length constraint, this version (slightly) extends the conference camera-ready version\n",
    "authors": [
      "Jinghui Si",
      "Xutan Peng",
      "Chen Li",
      "Haotian Xu",
      "Jianxin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.04525"
  },
  {
    "id": "arXiv:2110.06084",
    "title": "Implicit Bias of Linear Equivariant Networks",
    "abstract": "Comments: 21 pages, 19 figures",
    "descriptor": "\nComments: 21 pages, 19 figures\n",
    "authors": [
      "Hannah Lawrence",
      "Kristian Georgiev",
      "Andrew Dienes",
      "Bobak T. Kiani"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2110.06084"
  },
  {
    "id": "arXiv:2110.07537",
    "title": "Toward Degradation-Robust Voice Conversion",
    "abstract": "Comments: To appear in the proceedings of ICASSP 2022, equal contribution from first two authors",
    "descriptor": "\nComments: To appear in the proceedings of ICASSP 2022, equal contribution from first two authors\n",
    "authors": [
      "Chien-yu Huang",
      "Kai-Wei Chang",
      "Hung-yi Lee"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2110.07537"
  },
  {
    "id": "arXiv:2110.08128",
    "title": "Label-Wise Message Passing Graph Neural Network on Heterophilic Graphs",
    "abstract": "Label-Wise Message Passing Graph Neural Network on Heterophilic Graphs",
    "descriptor": "",
    "authors": [
      "Enyan Dai",
      "Shijie Zhou",
      "Zhimeng Guo",
      "Suhang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08128"
  },
  {
    "id": "arXiv:2110.08248",
    "title": "Probabilistic Time Series Forecasts with Autoregressive Transformation  Models",
    "abstract": "Probabilistic Time Series Forecasts with Autoregressive Transformation  Models",
    "descriptor": "",
    "authors": [
      "David R\u00fcgamer",
      "Philipp F.M. Baumann",
      "Thomas Kneib",
      "Torsten Hothorn"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.08248"
  },
  {
    "id": "arXiv:2110.10093",
    "title": "Stochastic Primal-Dual Deep Unrolling",
    "abstract": "Stochastic Primal-Dual Deep Unrolling",
    "descriptor": "",
    "authors": [
      "Junqi Tang",
      "Subhadip Mukherjee",
      "Carola-Bibiane Sch\u00f6nlieb"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2110.10093"
  },
  {
    "id": "arXiv:2110.10457",
    "title": "Knowledge Graph informed Fake News Classification via Heterogeneous  Representation Ensembles",
    "abstract": "Knowledge Graph informed Fake News Classification via Heterogeneous  Representation Ensembles",
    "descriptor": "",
    "authors": [
      "Boshko Koloski",
      "Timen Stepi\u0161nik-Perdih",
      "Marko Robnik-\u0160ikonja",
      "Senja Pollak",
      "Bla\u017e \u0160krlj"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Computers and Society (cs.CY)"
    ],
    "url": "https://arxiv.org/abs/2110.10457"
  },
  {
    "id": "arXiv:2110.11073",
    "title": "RL4RS: A Real-World Benchmark for Reinforcement Learning based  Recommender System",
    "abstract": "Comments: second version",
    "descriptor": "\nComments: second version\n",
    "authors": [
      "Kai Wang",
      "Zhene Zou",
      "Yue Shang",
      "Qilin Deng",
      "Minghao Zhao",
      "Runze Wu",
      "Xudong Shen",
      "Tangjie Lyu",
      "Changjie Fan"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.11073"
  },
  {
    "id": "arXiv:2110.11104",
    "title": "Intelligent Reflecting Surface for Multi-Path Beam Routing with  Active/Passive Beam Splitting and Combining",
    "abstract": "Comments: 6 pages, 4 figures. Accepted for publication by IEEE Communications Letters. Our other works on multi-IRS aided wireless network: IRS-user associations (arXiv:2009.02551), single-beam multi-hop routing (arXiv:2010.13589), multi-beam multi-hop routing (arXiv:2101.00217), distributed beam training (arXiv:2106.11896), and a tutorial paper (arXiv:2109.13641)",
    "descriptor": "\nComments: 6 pages, 4 figures. Accepted for publication by IEEE Communications Letters. Our other works on multi-IRS aided wireless network: IRS-user associations (arXiv:2009.02551), single-beam multi-hop routing (arXiv:2010.13589), multi-beam multi-hop routing (arXiv:2101.00217), distributed beam training (arXiv:2106.11896), and a tutorial paper (arXiv:2109.13641)\n",
    "authors": [
      "Weidong Mei",
      "Rui Zhang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.11104"
  },
  {
    "id": "arXiv:2110.11499",
    "title": "Wav2CLIP: Learning Robust Audio Representations From CLIP",
    "abstract": "Comments: Copyright 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
    "descriptor": "\nComments: Copyright 2022 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works\n",
    "authors": [
      "Ho-Hsiang Wu",
      "Prem Seetharaman",
      "Kundan Kumar",
      "Juan Pablo Bello"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2110.11499"
  },
  {
    "id": "arXiv:2110.13328",
    "title": "Eigenvalue Bounds for Double Saddle-Point Systems",
    "abstract": "Eigenvalue Bounds for Double Saddle-Point Systems",
    "descriptor": "",
    "authors": [
      "Susanne Bradley",
      "Chen Greif"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2110.13328"
  },
  {
    "id": "arXiv:2110.14034",
    "title": "r-local sensing: Improved algorithm and applications",
    "abstract": "r-local sensing: Improved algorithm and applications",
    "descriptor": "",
    "authors": [
      "Ahmed Ali Abbasi",
      "Abiy Tasissa",
      "Shuchin Aeron"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2110.14034"
  },
  {
    "id": "arXiv:2110.14127",
    "title": "Constrained Optimization Involving Nonconvex $\\ell_p$ Norms: Optimality  Conditions, Algorithm and Convergence",
    "abstract": "Constrained Optimization Involving Nonconvex $\\ell_p$ Norms: Optimality  Conditions, Algorithm and Convergence",
    "descriptor": "",
    "authors": [
      "Hao Wang",
      "Yining Gao",
      "Jiashan Wang",
      "Hongying Liu"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2110.14127"
  },
  {
    "id": "arXiv:2110.14879",
    "title": "Pilot Optimization and Channel Estimation for Two-way Relaying Network  Aided by IRS with Finite Discrete Phase Shifters",
    "abstract": "Comments: 5 pages, 5 figures",
    "descriptor": "\nComments: 5 pages, 5 figures\n",
    "authors": [
      "Zhongwen Sun",
      "Xuehui Wang",
      "Siling Feng",
      "Xinrong Guan",
      "Feng Shu",
      "Jiangzhou Wang"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2110.14879"
  },
  {
    "id": "arXiv:2111.02020",
    "title": "Analysis of Receiver Covered by Heterogeneous Receptors in Molecular  Communications",
    "abstract": "Comments: 6 pages, 4 figures. Accepted by IEEE International Conference on Communications (ICC) 2022",
    "descriptor": "\nComments: 6 pages, 4 figures. Accepted by IEEE International Conference on Communications (ICC) 2022\n",
    "authors": [
      "Xinyu Huang",
      "Yuting Fang",
      "Stuart T. Johnston",
      "Matthew Faria",
      "Nan Yang",
      "Robert Schober"
    ],
    "subjectives": [
      "Emerging Technologies (cs.ET)"
    ],
    "url": "https://arxiv.org/abs/2111.02020"
  },
  {
    "id": "arXiv:2111.02708",
    "title": "Quasi-Newton Methods for Saddle Point Problems and Beyond",
    "abstract": "Quasi-Newton Methods for Saddle Point Problems and Beyond",
    "descriptor": "",
    "authors": [
      "Chengchang Liu",
      "Luo Luo"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.02708"
  },
  {
    "id": "arXiv:2111.03711",
    "title": "Spatiotemporal Impact Assessment of Hurricanes on Electric Power Systems",
    "abstract": "Comments: 6 pages, 7 figures, accepted in 2022 Power and Energy Society General Meeting",
    "descriptor": "\nComments: 6 pages, 7 figures, accepted in 2022 Power and Energy Society General Meeting\n",
    "authors": [
      "Abodh Poudyal",
      "Vishnu Iyengar",
      "Diego Garcia-Camargo",
      "Anamika Dubey"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2111.03711"
  },
  {
    "id": "arXiv:2111.05062",
    "title": "Look back, look around: a systematic analysis of effective predictors  for new outlinks in focused Web crawling",
    "abstract": "Comments: 23 pages, 15 figures, 4 tables, uses arxiv.sty, added new title, heuristic features and their results added, figures 7, 14, and 15 updated",
    "descriptor": "\nComments: 23 pages, 15 figures, 4 tables, uses arxiv.sty, added new title, heuristic features and their results added, figures 7, 14, and 15 updated\n",
    "authors": [
      "Thi Kim Nhung Dang",
      "Doina Bucur",
      "Berk Atil",
      "Guillaume Pitel",
      "Frank Ruis",
      "Hamidreza Kadkhodaei",
      "Nelly Litvak"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.05062"
  },
  {
    "id": "arXiv:2111.05320",
    "title": "Robust Estimation for Random Graphs",
    "abstract": "Robust Estimation for Random Graphs",
    "descriptor": "",
    "authors": [
      "Jayadev Acharya",
      "Ayush Jain",
      "Gautam Kamath",
      "Ananda Theertha Suresh",
      "Huanyu Zhang"
    ],
    "subjectives": [
      "Data Structures and Algorithms (cs.DS)",
      "Information Theory (cs.IT)",
      "Statistics Theory (math.ST)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.05320"
  },
  {
    "id": "arXiv:2111.06501",
    "title": "A variational approach based on perturbed eigenvalue analysis for  improving spectral properties of isogeometric multipatch discretizations",
    "abstract": "A variational approach based on perturbed eigenvalue analysis for  improving spectral properties of isogeometric multipatch discretizations",
    "descriptor": "",
    "authors": [
      "Thi-Hoa Nguyen",
      "Ren\u00e9 R. Hiemstra",
      "Stein K. F. Stoter",
      "Dominik Schillinger"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)",
      "Computational Engineering, Finance, and Science (cs.CE)"
    ],
    "url": "https://arxiv.org/abs/2111.06501"
  },
  {
    "id": "arXiv:2111.07402",
    "title": "Textless Speech Emotion Conversion using Discrete and Decomposed  Representations",
    "abstract": "Textless Speech Emotion Conversion using Discrete and Decomposed  Representations",
    "descriptor": "",
    "authors": [
      "Felix Kreuk",
      "Adam Polyak",
      "Jade Copet",
      "Eugene Kharitonov",
      "Tu-Anh Nguyen",
      "Morgane Rivi\u00e8re",
      "Wei-Ning Hsu",
      "Abdelrahman Mohamed",
      "Emmanuel Dupoux",
      "Yossi Adi"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2111.07402"
  },
  {
    "id": "arXiv:2111.08051",
    "title": "Common Language for Goal-Oriented Semantic Communications: A Curriculum  Learning Framework",
    "abstract": "Common Language for Goal-Oriented Semantic Communications: A Curriculum  Learning Framework",
    "descriptor": "",
    "authors": [
      "Mohammad Karimzadeh Farshbafan",
      "Walid Saad",
      "Merouane Debbah"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08051"
  },
  {
    "id": "arXiv:2111.08177",
    "title": "Score-Based Generative Models for Robust Channel Estimation",
    "abstract": "Score-Based Generative Models for Robust Channel Estimation",
    "descriptor": "",
    "authors": [
      "Marius Arvinte",
      "Jonathan I Tamir"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.08177"
  },
  {
    "id": "arXiv:2111.09486",
    "title": "Linking-Enhanced Pre-Training for Table Semantic Parsing",
    "abstract": "Linking-Enhanced Pre-Training for Table Semantic Parsing",
    "descriptor": "",
    "authors": [
      "Bowen Qin",
      "Lihan Wang",
      "Binyuan Hui",
      "Ruiying Geng",
      "Zheng Cao",
      "Min Yang",
      "Jian Sun",
      "Yongbin Li"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2111.09486"
  },
  {
    "id": "arXiv:2111.10272",
    "title": "Resilience from Diversity: Population-based approach to harden models  against adversarial attacks",
    "abstract": "Comments: 12 pages, 6 figures, 5 tables",
    "descriptor": "\nComments: 12 pages, 6 figures, 5 tables\n",
    "authors": [
      "Jasser Jasser",
      "Ivan Garibay"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.10272"
  },
  {
    "id": "arXiv:2111.12389",
    "title": "Track Boosting and Synthetic Data Aided Drone Detection",
    "abstract": "Comments: Published at AVSS 2022",
    "descriptor": "\nComments: Published at AVSS 2022\n",
    "authors": [
      "Fatih Cagatay Akyon",
      "Ogulcan Eryuksel",
      "Kamil Anil Ozfuttu",
      "Sinan Onur Altinuc"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2111.12389"
  },
  {
    "id": "arXiv:2111.12631",
    "title": "Unity is strength: Improving the Detection of Adversarial Examples with  Ensemble Approaches",
    "abstract": "Comments: Code is available at this https URL",
    "descriptor": "\nComments: Code is available at this https URL\n",
    "authors": [
      "Francesco Craighero",
      "Fabrizio Angaroni",
      "Fabio Stella",
      "Chiara Damiani",
      "Marco Antoniotti",
      "Alex Graudenzi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2111.12631"
  },
  {
    "id": "arXiv:2111.13057",
    "title": "Evaluating the Robustness of Retrieval Pipelines with Query Variation  Generators",
    "abstract": "Comments: Accepted for publication in the 44nd European Conference on Information Retrieval (ECIR'22). V3: Fixed Table 2",
    "descriptor": "\nComments: Accepted for publication in the 44nd European Conference on Information Retrieval (ECIR'22). V3: Fixed Table 2\n",
    "authors": [
      "Gustavo Penha",
      "Arthur C\u00e2mara",
      "Claudia Hauff"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)"
    ],
    "url": "https://arxiv.org/abs/2111.13057"
  },
  {
    "id": "arXiv:2111.14427",
    "title": "Self-Training of Halfspaces with Generalization Guarantees under Massart  Mislabeling Noise Model",
    "abstract": "Self-Training of Halfspaces with Generalization Guarantees under Massart  Mislabeling Noise Model",
    "descriptor": "",
    "authors": [
      "Lies Hadjadj",
      "Massih-Reza Amini",
      "Sana Louhichi",
      "Alexis Deschamps"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2111.14427"
  },
  {
    "id": "arXiv:2111.15626",
    "title": "Variational Autoencoders for Precoding Matrices with High Spectral  Efficiency",
    "abstract": "Comments: The work is prepared for the MOTOR 22 conference, it contains 12 pages and 3 figures",
    "descriptor": "\nComments: The work is prepared for the MOTOR 22 conference, it contains 12 pages and 3 figures\n",
    "authors": [
      "Evgeny Bobrov",
      "Alexander Markov",
      "Sviatoslav Panchenko",
      "Dmitry Vetrov"
    ],
    "subjectives": [
      "Signal Processing (eess.SP)",
      "Artificial Intelligence (cs.AI)",
      "Information Theory (cs.IT)"
    ],
    "url": "https://arxiv.org/abs/2111.15626"
  },
  {
    "id": "arXiv:2112.04283",
    "title": "Adverse Weather Image Translation with Asymmetric and Uncertainty-aware  GAN",
    "abstract": "Comments: BMVC 2021, codes are available in here: this https URL",
    "descriptor": "\nComments: BMVC 2021, codes are available in here: this https URL\n",
    "authors": [
      "Jeong-gi Kwak",
      "Youngsaeng Jin",
      "Yuanming Li",
      "Dongsik Yoon",
      "Donghyeon Kim",
      "Hanseok Ko"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2112.04283"
  },
  {
    "id": "arXiv:2112.09238",
    "title": "Benchmarking Differentially Private Synthetic Data Generation Algorithms",
    "abstract": "Benchmarking Differentially Private Synthetic Data Generation Algorithms",
    "descriptor": "",
    "authors": [
      "Yuchao Tao",
      "Ryan McKenna",
      "Michael Hay",
      "Ashwin Machanavajjhala",
      "Gerome Miklau"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2112.09238"
  },
  {
    "id": "arXiv:2112.12901",
    "title": "A machine learning analysis of the relationship between some underlying  medical conditions and COVID-19 susceptibility",
    "abstract": "Comments: 38 pages, 23 figures",
    "descriptor": "\nComments: 38 pages, 23 figures\n",
    "authors": [
      "Mostafa Rezapour",
      "Colin A. Varady"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Applications (stat.AP)"
    ],
    "url": "https://arxiv.org/abs/2112.12901"
  },
  {
    "id": "arXiv:2112.14845",
    "title": "Learned Autoscaling for Cloud Microservices with Multi-Armed Bandits",
    "abstract": "Learned Autoscaling for Cloud Microservices with Multi-Armed Bandits",
    "descriptor": "",
    "authors": [
      "Vighnesh Sachidananda",
      "Anirudh Sivaraman"
    ],
    "subjectives": [
      "Distributed, Parallel, and Cluster Computing (cs.DC)",
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2112.14845"
  },
  {
    "id": "arXiv:2201.03115",
    "title": "Semantic and sentiment analysis of selected Bhagavad Gita translations  using BERT-based language framework",
    "abstract": "Semantic and sentiment analysis of selected Bhagavad Gita translations  using BERT-based language framework",
    "descriptor": "",
    "authors": [
      "Rohitash Chandra",
      "Venkatesh Kulkarni"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2201.03115"
  },
  {
    "id": "arXiv:2201.06210",
    "title": "Deep convolutional neural network for shape optimization using level-set  approach",
    "abstract": "Deep convolutional neural network for shape optimization using level-set  approach",
    "descriptor": "",
    "authors": [
      "Wrik Mallik",
      "Neil Farvolden",
      "Jasmin Jelovica",
      "Rajeev K. Jaiman"
    ],
    "subjectives": [
      "Optimization and Control (math.OC)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.06210"
  },
  {
    "id": "arXiv:2201.06645",
    "title": "Risk-aware Trajectory Sampling for Quadrotor Obstacle Avoidance in  Dynamic Environments",
    "abstract": "Risk-aware Trajectory Sampling for Quadrotor Obstacle Avoidance in  Dynamic Environments",
    "descriptor": "",
    "authors": [
      "Gang Chen",
      "Peng Peng",
      "Peihan Zhang",
      "Wei Dong"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2201.06645"
  },
  {
    "id": "arXiv:2201.07511",
    "title": "Gaussian Process Position-Dependent Feedforward: With Application to a  Wire Bonder",
    "abstract": "Comments: in IEEE 17th International Conference on Advanced Motion Control, Padova, Italy, 2022",
    "descriptor": "\nComments: in IEEE 17th International Conference on Advanced Motion Control, Padova, Italy, 2022\n",
    "authors": [
      "Max van Haren",
      "Maurice Poot",
      "Dragan Kosti\u0107",
      "Robin van Es",
      "Jim Portegies",
      "Tom Oomen"
    ],
    "subjectives": [
      "Systems and Control (eess.SY)"
    ],
    "url": "https://arxiv.org/abs/2201.07511"
  },
  {
    "id": "arXiv:2201.07730",
    "title": "SCOTCH: An Efficient Secure Computation Framework for Secure Aggregation",
    "abstract": "Comments: Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI-22), Third AAAI Privacy-Preserving Artificial Intelligence (PPAI-22) Workshop",
    "descriptor": "\nComments: Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI-22), Third AAAI Privacy-Preserving Artificial Intelligence (PPAI-22) Workshop\n",
    "authors": [
      "Yash More",
      "Prashanthi Ramachandran",
      "Priyam Panda",
      "Arup Mondal",
      "Harpreet Virk",
      "Debayan Gupta"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.07730"
  },
  {
    "id": "arXiv:2201.08266",
    "title": "A Real-Time Rendering Method for Light Field Display",
    "abstract": "A Real-Time Rendering Method for Light Field Display",
    "descriptor": "",
    "authors": [
      "Quanzhen Wan"
    ],
    "subjectives": [
      "Graphics (cs.GR)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.08266"
  },
  {
    "id": "arXiv:2201.08862",
    "title": "Stochastic normalizing flows as non-equilibrium transformations",
    "abstract": "Comments: 1+28 pages, 8 figures; v2: 1+29 pages, 8 figures, added references, discussion in section 4 improved",
    "descriptor": "\nComments: 1+28 pages, 8 figures; v2: 1+29 pages, 8 figures, added references, discussion in section 4 improved\n",
    "authors": [
      "Michele Caselle",
      "Elia Cellini",
      "Alessandro Nada",
      "Marco Panero"
    ],
    "subjectives": [
      "High Energy Physics - Lattice (hep-lat)",
      "Statistical Mechanics (cond-mat.stat-mech)",
      "Machine Learning (cs.LG)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2201.08862"
  },
  {
    "id": "arXiv:2201.08900",
    "title": "Approximating the discrete and continuous median line segments in $d$  dimensions",
    "abstract": "Comments: There is an error in the packing argument used to determine the number of well separated pairs/subsets. The error first appears in the proof in Appendix C -- on page 17, in the first mathematical expression, the term $||ab||$ should be $||ab||/E[x]$",
    "descriptor": "\nComments: There is an error in the packing argument used to determine the number of well separated pairs/subsets. The error first appears in the proof in Appendix C -- on page 17, in the first mathematical expression, the term $||ab||$ should be $||ab||/E[x]$\n",
    "authors": [
      "Ovidiu Daescu",
      "Ka Yaw Teo"
    ],
    "subjectives": [
      "Computational Geometry (cs.CG)"
    ],
    "url": "https://arxiv.org/abs/2201.08900"
  },
  {
    "id": "arXiv:2201.09429",
    "title": "End-to-End Neural Speech Coding for Real-Time Communications",
    "abstract": "Comments: ICASSP 2022 (Accepted)",
    "descriptor": "\nComments: ICASSP 2022 (Accepted)\n",
    "authors": [
      "Xue Jiang",
      "Xiulian Peng",
      "Chengyu Zheng",
      "Huaying Xue",
      "Yuan Zhang",
      "Yan Lu"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Machine Learning (cs.LG)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2201.09429"
  },
  {
    "id": "arXiv:2201.09658",
    "title": "Real-Time Computer-Generated EIA for Light Field Display by  Pre-Calculating and Pre-Storing the Invariable Voxel-Pixel Mapping",
    "abstract": "Real-Time Computer-Generated EIA for Light Field Display by  Pre-Calculating and Pre-Storing the Invariable Voxel-Pixel Mapping",
    "descriptor": "",
    "authors": [
      "Quanzhen Wan"
    ],
    "subjectives": [
      "Graphics (cs.GR)"
    ],
    "url": "https://arxiv.org/abs/2201.09658"
  },
  {
    "id": "arXiv:2201.09815",
    "title": "Analytic Mutual Information in Bayesian Neural Networks",
    "abstract": "Analytic Mutual Information in Bayesian Neural Networks",
    "descriptor": "",
    "authors": [
      "Jae Oh Woo"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.09815"
  },
  {
    "id": "arXiv:2201.11067",
    "title": "ROMA: Resource Orchestration for Microservices-based 5G Applications",
    "abstract": "Comments: Accepted at 2022 IEEE/IFIP Network Operations and Management Symposium",
    "descriptor": "\nComments: Accepted at 2022 IEEE/IFIP Network Operations and Management Symposium\n",
    "authors": [
      "Anousheh Gholami",
      "Kunal Rao",
      "Wang-Pin Hsiung",
      "Oliver Po",
      "Murugan Sankaradas",
      "Srimat Chakradhar"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)"
    ],
    "url": "https://arxiv.org/abs/2201.11067"
  },
  {
    "id": "arXiv:2201.11147",
    "title": "OntoProtein: Protein Pretraining With Gene Ontology Embedding",
    "abstract": "Comments: Accepted by ICLR 2022",
    "descriptor": "\nComments: Accepted by ICLR 2022\n",
    "authors": [
      "Ningyu Zhang",
      "Zhen Bi",
      "Xiaozhuan Liang",
      "Siyuan Cheng",
      "Haosen Hong",
      "Shumin Deng",
      "Jiazhang Lian",
      "Qiang Zhang",
      "Huajun Chen"
    ],
    "subjectives": [
      "Biomolecules (q-bio.BM)",
      "Computation and Language (cs.CL)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2201.11147"
  },
  {
    "id": "arXiv:2201.12086",
    "title": "BLIP: Bootstrapping Language-Image Pre-training for Unified  Vision-Language Understanding and Generation",
    "abstract": "BLIP: Bootstrapping Language-Image Pre-training for Unified  Vision-Language Understanding and Generation",
    "descriptor": "",
    "authors": [
      "Junnan Li",
      "Dongxu Li",
      "Caiming Xiong",
      "Steven Hoi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2201.12086"
  },
  {
    "id": "arXiv:2201.13323",
    "title": "Constructing coarse-scale bifurcation diagrams from spatio-temporal  observations of microscopic simulations: A parsimonious machine learning  approach",
    "abstract": "Constructing coarse-scale bifurcation diagrams from spatio-temporal  observations of microscopic simulations: A parsimonious machine learning  approach",
    "descriptor": "",
    "authors": [
      "Evangelos Galaris",
      "Gianluca Fabiani",
      "Ioannis Gallos",
      "Ioannis Kevrekidis",
      "Constantinos Siettos"
    ],
    "subjectives": [
      "Dynamical Systems (math.DS)",
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2201.13323"
  },
  {
    "id": "arXiv:2202.00075",
    "title": "SUGAR: Efficient Subgraph-level Training via Resource-aware Graph  Partitioning",
    "abstract": "SUGAR: Efficient Subgraph-level Training via Resource-aware Graph  Partitioning",
    "descriptor": "",
    "authors": [
      "Zihui Xue",
      "Yuedong Yang",
      "Mengtian Yang",
      "Radu Marculescu"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.00075"
  },
  {
    "id": "arXiv:2202.00081",
    "title": "On solutions of the distributional Bellman equation",
    "abstract": "Comments: Comments: slightly expanded version",
    "descriptor": "\nComments: Comments: slightly expanded version\n",
    "authors": [
      "Julian Gerstenberg",
      "Ralph Neininger",
      "Denis Spiegel"
    ],
    "subjectives": [
      "Machine Learning (stat.ML)",
      "Machine Learning (cs.LG)",
      "Probability (math.PR)"
    ],
    "url": "https://arxiv.org/abs/2202.00081"
  },
  {
    "id": "arXiv:2202.00113",
    "title": "Imbedding Deep Neural Networks",
    "abstract": "Comments: Accepted as a spotlight paper at the 10th International Conference on Learning Representations (ICLR), 2022",
    "descriptor": "\nComments: Accepted as a spotlight paper at the 10th International Conference on Learning Representations (ICLR), 2022\n",
    "authors": [
      "Andrew Corbett",
      "Dmitry Kangin"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.00113"
  },
  {
    "id": "arXiv:2202.00173",
    "title": "Industry Experiences with Large-Scale Refactoring",
    "abstract": "Comments: 10 pages, 7 figures, 4 tables",
    "descriptor": "\nComments: 10 pages, 7 figures, 4 tables\n",
    "authors": [
      "James Ivers",
      "Robert L. Nord",
      "Ipek Ozkaya",
      "Chris Seifried",
      "Christopher S. Timperley",
      "Marouane Kessentini"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.00173"
  },
  {
    "id": "arXiv:2202.00248",
    "title": "Entanglement-Assisted Quantum Error-Correcting Codes over Local  Frobenius Rings",
    "abstract": "Comments: 16 pages, long version of a paper submitted to ISIT 2022",
    "descriptor": "\nComments: 16 pages, long version of a paper submitted to ISIT 2022\n",
    "authors": [
      "Tania Sidana",
      "Navin Kashyap"
    ],
    "subjectives": [
      "Information Theory (cs.IT)",
      "Quantum Physics (quant-ph)"
    ],
    "url": "https://arxiv.org/abs/2202.00248"
  },
  {
    "id": "arXiv:2202.00805",
    "title": "Context Uncertainty in Contextual Bandits with Applications to  Recommender Systems",
    "abstract": "Comments: To appear at AAAI 2022",
    "descriptor": "\nComments: To appear at AAAI 2022\n",
    "authors": [
      "Hao Wang",
      "Yifei Ma",
      "Hao Ding",
      "Yuyang Wang"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)",
      "Information Retrieval (cs.IR)",
      "Machine Learning (stat.ML)"
    ],
    "url": "https://arxiv.org/abs/2202.00805"
  },
  {
    "id": "arXiv:2202.00964",
    "title": "Understanding Knowledge Integration in Language Models with Graph  Convolutions",
    "abstract": "Comments: Code is available: this https URL",
    "descriptor": "\nComments: Code is available: this https URL\n",
    "authors": [
      "Yifan Hou",
      "Guoji Fu",
      "Mrinmaya Sachan"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Information Theory (cs.IT)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.00964"
  },
  {
    "id": "arXiv:2202.01624",
    "title": "MFA: TDNN with Multi-scale Frequency-channel Attention for  Text-independent Speaker Verification with Short Utterances",
    "abstract": "Comments: Accepted by ICASSP 2022",
    "descriptor": "\nComments: Accepted by ICASSP 2022\n",
    "authors": [
      "Tianchi Liu",
      "Rohan Kumar Das",
      "Kong Aik Lee",
      "Haizhou Li"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Computation and Language (cs.CL)",
      "Audio and Speech Processing (eess.AS)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.01624"
  },
  {
    "id": "arXiv:2202.01924",
    "title": "Zero-Shot Aspect-Based Sentiment Analysis",
    "abstract": "Zero-Shot Aspect-Based Sentiment Analysis",
    "descriptor": "",
    "authors": [
      "Lei Shu",
      "Hu Xu",
      "Bing Liu",
      "Jiahua Chen"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.01924"
  },
  {
    "id": "arXiv:2202.02179",
    "title": "DelTact: A Vision-based Tactile Sensor Using Dense Color Pattern",
    "abstract": "Comments: 8 pages contents, 1 page references, 9 figures, 2 tables",
    "descriptor": "\nComments: 8 pages contents, 1 page references, 9 figures, 2 tables\n",
    "authors": [
      "Guanlan Zhang",
      "Yipai Du",
      "Hongyu Yu",
      "Michael Yu Wang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.02179"
  },
  {
    "id": "arXiv:2202.02543",
    "title": "Unsupervised Learning on 3D Point Clouds by Clustering and Contrasting",
    "abstract": "Unsupervised Learning on 3D Point Clouds by Clustering and Contrasting",
    "descriptor": "",
    "authors": [
      "Guofeng Mei",
      "Litao Yu",
      "Qiang Wu",
      "Jian Zhang",
      "Mohammed Bennamoun"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Optimization and Control (math.OC)"
    ],
    "url": "https://arxiv.org/abs/2202.02543"
  },
  {
    "id": "arXiv:2202.02626",
    "title": "Layer-wise Regularized Adversarial Training using Layers Sustainability  Analysis (LSA) framework",
    "abstract": "Comments: Layers Sustainability Analysis (LSA) framework",
    "descriptor": "\nComments: Layers Sustainability Analysis (LSA) framework\n",
    "authors": [
      "Mohammad Khalooei",
      "Mohammad Mehdi Homayounpour",
      "Maryam Amirmazlaghani"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02626"
  },
  {
    "id": "arXiv:2202.02951",
    "title": "Deep Deterministic Independent Component Analysis for Hyperspectral  Unmixing",
    "abstract": "Comments: Accepted by ICASSP 2022",
    "descriptor": "\nComments: Accepted by ICASSP 2022\n",
    "authors": [
      "Hongming Li",
      "Shujian Yu",
      "Jose C. Principe"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)"
    ],
    "url": "https://arxiv.org/abs/2202.02951"
  },
  {
    "id": "arXiv:2202.02958",
    "title": "A survey on computational learning methods for analysis of gene  expression data in genomics",
    "abstract": "Comments: 51 pages, 9 figures, 5 tables",
    "descriptor": "\nComments: 51 pages, 9 figures, 5 tables\n",
    "authors": [
      "Nikita Bhandari",
      "Rahee Walambe",
      "Ketan Kotecha",
      "Satyajeet Khare"
    ],
    "subjectives": [
      "Genomics (q-bio.GN)",
      "Artificial Intelligence (cs.AI)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.02958"
  },
  {
    "id": "arXiv:2202.03310",
    "title": "Exploratory analysis of text duplication in peer-review reveals  peer-review fraud and paper mills",
    "abstract": "Exploratory analysis of text duplication in peer-review reveals  peer-review fraud and paper mills",
    "descriptor": "",
    "authors": [
      "Adam Day"
    ],
    "subjectives": [
      "Digital Libraries (cs.DL)"
    ],
    "url": "https://arxiv.org/abs/2202.03310"
  },
  {
    "id": "arXiv:2202.04172",
    "title": "A Speech Intelligibility Enhancement Model based on Canonical  Correlation and Deep Learning for Hearing-Assistive Technologies",
    "abstract": "Comments: We would like to withdraw this article because we have accidentally uploaded the revised version of the same article from another account. The updated version is titled \"A Novel Speech Intelligibility Enhancement Model based on Canonical Correlation and Deep Learning\" (arXiv:2202.05756)",
    "descriptor": "\nComments: We would like to withdraw this article because we have accidentally uploaded the revised version of the same article from another account. The updated version is titled \"A Novel Speech Intelligibility Enhancement Model based on Canonical Correlation and Deep Learning\" (arXiv:2202.05756)\n",
    "authors": [
      "Tassadaq Hussain",
      "Muhammad Diyan",
      "Mandar Gogate",
      "Kia Dashtipour",
      "Ahsan Adeel",
      "Yu Tsao",
      "Amir Hussain"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.04172"
  },
  {
    "id": "arXiv:2202.04301",
    "title": "Log-based Anomaly Detection with Deep Learning: How Far Are We?",
    "abstract": "Comments: Accepted by The 44th International Conference on Software Engineering (ICSE 2022)",
    "descriptor": "\nComments: Accepted by The 44th International Conference on Software Engineering (ICSE 2022)\n",
    "authors": [
      "Van-Hoang Le",
      "Hongyu Zhang"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.04301"
  },
  {
    "id": "arXiv:2202.04312",
    "title": "Using 5G in Smart Cities: A Systematic Mapping Study",
    "abstract": "Comments: Preprint accepted for publication in Intelligent Systems with Applications, 2022",
    "descriptor": "\nComments: Preprint accepted for publication in Intelligent Systems with Applications, 2022\n",
    "authors": [
      "Chen Yang",
      "Peng Liang",
      "Liming Fu",
      "Guorui Cui",
      "Fei Huang",
      "Feng Teng",
      "Yawar Abbas Bangash"
    ],
    "subjectives": [
      "Networking and Internet Architecture (cs.NI)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.04312"
  },
  {
    "id": "arXiv:2202.04986",
    "title": "Enhanced Digital Halftoning via Weighted Sigma-Delta Modulation",
    "abstract": "Comments: 34 pages, 23 figures",
    "descriptor": "\nComments: 34 pages, 23 figures\n",
    "authors": [
      "Felix Krahmer",
      "Anna Veselovska"
    ],
    "subjectives": [
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.04986"
  },
  {
    "id": "arXiv:2202.04996",
    "title": "AA-TransUNet: Attention Augmented TransUNet For Nowcasting Tasks",
    "abstract": "Comments: 8 pages, 8 figures",
    "descriptor": "\nComments: 8 pages, 8 figures\n",
    "authors": [
      "Yimin Yang",
      "Siamak Mehrkanoon"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.04996"
  },
  {
    "id": "arXiv:2202.05152",
    "title": "Feature-level augmentation to improve robustness of deep neural networks  to affine transformations",
    "abstract": "Feature-level augmentation to improve robustness of deep neural networks  to affine transformations",
    "descriptor": "",
    "authors": [
      "Adrian Sandru",
      "Mariana-Iuliana Georgescu",
      "Radu Tudor Ionescu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05152"
  },
  {
    "id": "arXiv:2202.05163",
    "title": "Machine Learning and Data Science: Foundations, Concepts, Algorithms,  and Tools",
    "abstract": "Comments: in Persian language",
    "descriptor": "\nComments: in Persian language\n",
    "authors": [
      "Milad Vazan"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.05163"
  },
  {
    "id": "arXiv:2202.05354",
    "title": "Optimal Transport for Super Resolution Applied to Astronomy Imaging",
    "abstract": "Comments: 5 pages, 2 figures",
    "descriptor": "\nComments: 5 pages, 2 figures\n",
    "authors": [
      "Michael Rawson",
      "Jakob Hultgren"
    ],
    "subjectives": [
      "Image and Video Processing (eess.IV)",
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Signal Processing (eess.SP)"
    ],
    "url": "https://arxiv.org/abs/2202.05354"
  },
  {
    "id": "arXiv:2202.05826",
    "title": "End-to-end Algorithm Synthesis with Recurrent Networks: Logical  Extrapolation Without Overthinking",
    "abstract": "End-to-end Algorithm Synthesis with Recurrent Networks: Logical  Extrapolation Without Overthinking",
    "descriptor": "",
    "authors": [
      "Arpit Bansal",
      "Avi Schwarzschild",
      "Eitan Borgnia",
      "Zeyad Emam",
      "Furong Huang",
      "Micah Goldblum",
      "Tom Goldstein"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.05826"
  },
  {
    "id": "arXiv:2202.05972",
    "title": "Low-light Image Enhancement by Retinex Based Algorithm Unrolling and  Adjustment",
    "abstract": "Low-light Image Enhancement by Retinex Based Algorithm Unrolling and  Adjustment",
    "descriptor": "",
    "authors": [
      "Xinyi Liu",
      "Qi Xie",
      "Qian Zhao",
      "Hong Wang",
      "Deyu Meng"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Image and Video Processing (eess.IV)"
    ],
    "url": "https://arxiv.org/abs/2202.05972"
  },
  {
    "id": "arXiv:2202.05994",
    "title": "Physics-Guided Problem Decomposition for Scaling Deep Learning of  High-dimensional Eigen-Solvers: The Case of Schr\u00f6dinger's Equation",
    "abstract": "Comments: 9 pages, Submitted to SIGKDD in Feb 2022",
    "descriptor": "\nComments: 9 pages, Submitted to SIGKDD in Feb 2022\n",
    "authors": [
      "Sangeeta Srivastava",
      "Samuel Olin",
      "Viktor Podolskiy",
      "Anuj Karpatne",
      "Wei-Cheng Lee",
      "Anish Arora"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)",
      "Numerical Analysis (math.NA)"
    ],
    "url": "https://arxiv.org/abs/2202.05994"
  },
  {
    "id": "arXiv:2202.06003",
    "title": "Robust Learning from Observation with Model Misspecification",
    "abstract": "Comments: accepted to AAMAS 2022 (camera-ready version)",
    "descriptor": "\nComments: accepted to AAMAS 2022 (camera-ready version)\n",
    "authors": [
      "Luca Viano",
      "Yu-Ting Huang",
      "Parameswaran Kamalaruban",
      "Craig Innes",
      "Subramanian Ramamoorthy",
      "Adrian Weller"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06003"
  },
  {
    "id": "arXiv:2202.06033",
    "title": "Reflekt: a Library for Compile-Time Reflection in Kotlin",
    "abstract": "Comments: 10 pages, 10 figures",
    "descriptor": "\nComments: 10 pages, 10 figures\n",
    "authors": [
      "Anastasiia Birillo",
      "Elena Lyulina",
      "Maria Malysheva",
      "Vladislav Tankov",
      "Timofey Bryksin"
    ],
    "subjectives": [
      "Software Engineering (cs.SE)"
    ],
    "url": "https://arxiv.org/abs/2202.06033"
  },
  {
    "id": "arXiv:2202.06164",
    "title": "Complete Inertial Pose Dataset: from raw measurements to pose with  low-cost and high-end MARG sensors",
    "abstract": "Comments: Submitted to journal",
    "descriptor": "\nComments: Submitted to journal\n",
    "authors": [
      "Manuel Palermo",
      "Sara Cerqueira",
      "Jo\u00e3o Andr\u00e9",
      "Ant\u00f3nio Pereira",
      "Cristina P. Santos"
    ],
    "subjectives": [
      "Human-Computer Interaction (cs.HC)"
    ],
    "url": "https://arxiv.org/abs/2202.06164"
  },
  {
    "id": "arXiv:2202.06200",
    "title": "Improving Graph Collaborative Filtering with Neighborhood-enriched  Contrastive Learning",
    "abstract": "Comments: 10 pages, 6 figures. Accepted by TheWebConf 2022",
    "descriptor": "\nComments: 10 pages, 6 figures. Accepted by TheWebConf 2022\n",
    "authors": [
      "Zihan Lin",
      "Changxin Tian",
      "Yupeng Hou",
      "Wayne Xin Zhao"
    ],
    "subjectives": [
      "Information Retrieval (cs.IR)",
      "Artificial Intelligence (cs.AI)"
    ],
    "url": "https://arxiv.org/abs/2202.06200"
  },
  {
    "id": "arXiv:2202.06358",
    "title": "Diverse facial inpainting guided by exemplars",
    "abstract": "Comments: There are 13 pages, 11 figures in this paper",
    "descriptor": "\nComments: There are 13 pages, 11 figures in this paper\n",
    "authors": [
      "Wanglong Lu",
      "Hanli Zhao",
      "Xianta Jiang",
      "Xiaogang Jin",
      "Min Wang",
      "Jiankai Lyu",
      "Kaijie Shi"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Artificial Intelligence (cs.AI)",
      "Graphics (cs.GR)",
      "Multimedia (cs.MM)"
    ],
    "url": "https://arxiv.org/abs/2202.06358"
  },
  {
    "id": "arXiv:2202.06472",
    "title": "Asymptotically Unbiased Estimation for Delayed Feedback Modeling via  Label Correction",
    "abstract": "Comments: This paper has been accepted by WWW 2022",
    "descriptor": "\nComments: This paper has been accepted by WWW 2022\n",
    "authors": [
      "Yu Chen",
      "Jiaqi Jin",
      "Hui Zhao",
      "Pengjie Wang",
      "Guojun Liu",
      "Jian Xu",
      "Bo Zheng"
    ],
    "subjectives": [
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06472"
  },
  {
    "id": "arXiv:2202.06477",
    "title": "Characterizing Differentially-Private Techniques in the Era of  Internet-of-Vehicles",
    "abstract": "Comments: Technical Report-Feb-03 at User-Centric Computing Group, University of Nottingham Ningbo China",
    "descriptor": "\nComments: Technical Report-Feb-03 at User-Centric Computing Group, University of Nottingham Ningbo China\n",
    "authors": [
      "Yicun Duan",
      "Junyu Liu",
      "Wangkai Jin",
      "Xiangjun Peng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.06477"
  },
  {
    "id": "arXiv:2202.06483",
    "title": "BiFSMN: Binary Neural Network for Keyword Spotting",
    "abstract": "Comments: request from company",
    "descriptor": "\nComments: request from company\n",
    "authors": [
      "Haotong Qin",
      "Xudong Ma",
      "Yifu Ding",
      "Xiaoyang Li",
      "Yang Zhang",
      "Yao Tian",
      "Zejun Ma",
      "Jie Luo",
      "Xianglong Liu"
    ],
    "subjectives": [
      "Computation and Language (cs.CL)"
    ],
    "url": "https://arxiv.org/abs/2202.06483"
  },
  {
    "id": "arXiv:2202.06484",
    "title": "ADeADA: Adaptive Density-aware Active Domain Adaptation for Semantic  Segmentation",
    "abstract": "Comments: 8 pages, 5 figures",
    "descriptor": "\nComments: 8 pages, 5 figures\n",
    "authors": [
      "Tsung-Han Wu",
      "Yi-Syuan Liou",
      "Shao-Ji Yuan",
      "Hsin-Ying Lee",
      "Tung-I Chen",
      "Winston H. Hsu"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06484"
  },
  {
    "id": "arXiv:2202.06495",
    "title": "HUT: Enabling High-UTility, Batched Queries under Differential Privacy  Protection for Internet-of-Vehicles",
    "abstract": "Comments: Technical Report-Feb-02 at User-Centric Computing Group, University of Nottingham Ningbo China",
    "descriptor": "\nComments: Technical Report-Feb-02 at User-Centric Computing Group, University of Nottingham Ningbo China\n",
    "authors": [
      "Junyu Liu",
      "Wangkai Jin",
      "Zhenyong He",
      "Xiaoxing Ming",
      "Yicun Duan",
      "Zeyu Xiong",
      "Xiangjun Peng"
    ],
    "subjectives": [
      "Cryptography and Security (cs.CR)"
    ],
    "url": "https://arxiv.org/abs/2202.06495"
  },
  {
    "id": "arXiv:2202.06674",
    "title": "Learning to Ground Objects for Robot Task and Motion Planning",
    "abstract": "Learning to Ground Objects for Robot Task and Motion Planning",
    "descriptor": "",
    "authors": [
      "Yan Ding",
      "Xiaohan Zhang",
      "Xingyue Zhan",
      "Shiqi Zhang"
    ],
    "subjectives": [
      "Robotics (cs.RO)"
    ],
    "url": "https://arxiv.org/abs/2202.06674"
  },
  {
    "id": "arXiv:2202.06684",
    "title": "Partially Fake Audio Detection by Self-attention-based Fake Span  Discovery",
    "abstract": "Comments: Submitted to ICASSP 2022",
    "descriptor": "\nComments: Submitted to ICASSP 2022\n",
    "authors": [
      "Haibin Wu",
      "Heng-Cheng Kuo",
      "Naijun Zheng",
      "Kuo-Hsuan Hung",
      "Hung-Yi Lee",
      "Yu Tsao",
      "Hsin-Min Wang",
      "Helen Meng"
    ],
    "subjectives": [
      "Audio and Speech Processing (eess.AS)",
      "Machine Learning (cs.LG)",
      "Sound (cs.SD)"
    ],
    "url": "https://arxiv.org/abs/2202.06684"
  },
  {
    "id": "arXiv:2202.06843",
    "title": "Continual Learning from Demonstration of Robotic Skills",
    "abstract": "Comments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible",
    "descriptor": "\nComments: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible\n",
    "authors": [
      "Sayantan Auddy",
      "Jakob Hollenstein",
      "Matteo Saveriano",
      "Antonio Rodr\u00edguez-S\u00e1nchez",
      "Justus Piater"
    ],
    "subjectives": [
      "Robotics (cs.RO)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06843"
  },
  {
    "id": "arXiv:2202.06850",
    "title": "Multi-Task Deep Residual Echo Suppression with Echo-aware Loss",
    "abstract": "Comments: ICASSP 2022",
    "descriptor": "\nComments: ICASSP 2022\n",
    "authors": [
      "Shimin Zhang",
      "Ziteng Wang",
      "Jiayao Sun",
      "Yihui Fu",
      "Biao Tian",
      "Qiang Fu",
      "Lei Xie"
    ],
    "subjectives": [
      "Sound (cs.SD)",
      "Audio and Speech Processing (eess.AS)"
    ],
    "url": "https://arxiv.org/abs/2202.06850"
  },
  {
    "id": "arXiv:2202.06934",
    "title": "Slicing Aided Hyper Inference and Fine-tuning for Small Object Detection",
    "abstract": "Comments: Submitted to ICIP 2022, 5 pages, 4 figures, 2 tables",
    "descriptor": "\nComments: Submitted to ICIP 2022, 5 pages, 4 figures, 2 tables\n",
    "authors": [
      "Fatih Cagatay Akyon",
      "Sinan Onur Altinuc",
      "Alptekin Temizel"
    ],
    "subjectives": [
      "Computer Vision and Pattern Recognition (cs.CV)",
      "Machine Learning (cs.LG)"
    ],
    "url": "https://arxiv.org/abs/2202.06934"
  }
]